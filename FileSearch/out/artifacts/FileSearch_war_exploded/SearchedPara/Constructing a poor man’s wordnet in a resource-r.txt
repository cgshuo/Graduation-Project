 Abstract In this paper we present a language-independent, fully modular and automatic approach to bootstrap a wordnet for a new language by recycling different types of already existing language resources, such as machine-readable dictionaries, parallel corpora, and Wikipedia. The approach, which we apply here to Slovene, takes into account monosemous and polysemous words, general and specialised vocabulary as well as simple and multi-word lexemes. The extracted words are then assigned one or several synset ids, based on a classifier that relies on several features including distributional similarity. Finally, we identify and remove highly dubious ( literal, synset ) pairs, based on simple distributional information extracted from a large corpus in an unsupervised way. Automatic, manual and task-based evaluations show that the resulting resource, the latest version of the Slovene wordnet, is already a valuable source of lexico-semantic information.
 Keywords Wordnet development Multilingual lexicon extraction Word-sense disambiguation Distributional similarity 1 Introduction Motivation. In the past decade, the role of lexical knowledge has increased in many areas of natural language processing as it has been shown that exploiting lexical resources benefits the performance of various tasks. For example, Gabrilovich and Markovitch ( 2006 ) have demonstrated that using encyclopaedic knowledge improves automatic document classification. Similarly, Nastase ( 2008 ) have employed it to help text summarisation. An improvement in a question-answering system that takes advantage of dependencies between words in a lexico-semantic network has been achieved by Harabagiu et al. ( 2000 ), the advantages of which have also been shown in word-sense disambiguation (Cuadros and Rigau 2006 ) and machine translation tasks (Carpuat and Wu 2007 ).

Several frameworks for organising and representing lexical knowledge have been proposed, such as ACQUILEX 1 (Copestake et al. 1993 ), Roget X  X  Thesaurus 2 (Kirkpatrick 1987 ), MindNet 3 (Richardson et al. 1998 ), ConceptNet 4 (Liu 2003 )or Cyc 5 (Matuszek et al. 2006 ). But one of the best known and most widely used lexico-semantic resources for natural language understanding and interpretation as well as in Semantic Web applications are Princeton WordNet (Fellbaum 1998 ) and its sister wordnets for languages other than English, developed within projects such as EuroWordnet (Vossen 1999 ), BalkaNet (Tufis  X  2000 ), AsianWordNet (Sornlert-lamvanich 2010 ) and the most recent project, called the Open Multilingual Wordnet 6 that has normalised and merged all the wordnets that allow redistribution, and currently contain wordnets for 27 languages (Bond and Foster 2013 ).
While it is true that wordnets were originally constructed manually in order to maximise linguistic soundness and accuracy of the developed database, such an endeavour is too time-consuming and expensive to be feasible for many languages still lacking a wordnet. This is why semi-or fully automatic approaches have become popular, which exploit various types of existing resources to facilitate the development of a new wordnet. However, a common problem with automatically induced wordnets is the necessary trade-off between limited coverage and the desired level of accuracy, both of which are required if the developed resource is to be useful in a practical application. An important advantage of our approach compared to related work is that our approach is much more lightweight and straightforward: it does not require complex processing available only for some languages (e.g., computing parses for syntactical distributional similarity), lan-guage-dependent rules (e.g., patterns for extracting hypernymy relations) or costly lexical resources (e.g., large-scale thesauri).

Contribution. In this paper we present a two-step automated approach for building wordnets. The approach is language-independent as shown with its successful application to the development of the French wordnet WOLF (Sagot and Fis  X  er 2008 ). It is suited for research scenarios that do not allow for long-running resource development by a team of professional lexicographers. Instead, it recycles different types of resources that are already available for the target language, such as machine-readable dictionaries, parallel corpora and Wikipedia in a way that maximises the amount of extracted lexical information from each type of the resource used. The created wordnets are directly aligned to Princeton WordNet as well as among each other. They can therefore be used in multilingual tasks, such as machine translation, cross-lingual information retrieval and question answering, the demand for which is growing with the increased multilinguality of the web (Nie 2010 ). As opposed to most related work relying solely on Wikipedia, our approach is not limited only to nominal concepts but can handle all parts-of-speech. Our approach is also comprehensive in that we handle monosemous and polysemous words, general and specialised vocabulary as well as simple and multi-word lexemes.

Preliminary and partial versions of the full methodology described here were already used for building the first freely available wordnet for Slovene (Fis  X  er and Sagot 2008 ). However, since the first version, our techniques have been substantially refined and extended. In this paper, we recall how the first versions of sloWNet were built and, more importantly, how the refinements allowed us to more than double its size while increasing its overall accuracy. The result is the first freely available semantic lexicon for Slovene wordnet called sloWNet.

Overview. This paper is structured as follows: in Sect. 2 we give an overview of related work. In Sect. 3 we describe the process of extracting lexico-semantic information from structured, semi-structured and unstructured resources. In Sect. 4 we explain the two-step process used for merging this information and constructing sloWNet: we first built restricted resources containing only the literals with the highest certainty level and then used these in a large-scale enrichment step as training data for a maximum entropy classifier used for computing whether a less certain literal extracted from the existing resources is an appropriate candidate for a given synset. Section 5 is dedicated to the evaluation of the created resource, and Sect. 6 discusses the results and points towards future directions of research. 2 Related work Automatic techniques for wordnet development can be divided in two approaches: the merge approach and the extend approach (Vossen 1999 ). In the merge approach, an independent wordnet for a certain language is first created based on monolingual resources and then mapped to other wordnets (Rudnicka et al. 2012 ). In the extend approach, which we used in this work, a fixed set of synsets from Princeton WordNet (PWN) are translated into the target language, preserving the structure of the original wordnet. The extend approach relies on the assumption that concepts and semantic relations between them are language independent, at least to a large extent. Apart from faster and cheaper construction of the lexical resource, the biggest advantage of this approach is that the resulting wordnet is automatically aligned to all other wordnets built on the same principle and therefore available for use in multi-lingual applications, such as machine translation and cross-language information retrieval.

The downside of the expand approach is that the target wordnets inherit any inconsistencies in PWN but are also biased by PWN and may, in an extreme case, become arbitrary (Orav and Vider 2004 ), (Wong 2004 ). For example, PWN contains a synset { performer , performing artist } which is defined as an entertainer who performs a dramatic or musical work for an audience . However, there is no word or phrase in Slovene that denotes the concept describing actors and singers collectively. Such cases have been dealt with in several wordnet development projects by providing the closest possible match for the synset and aligning the two wordnets with a near_synonym relation. In this way, the overall structure of straightforward cases remained intact and the exceptions encoded. Despite these difficulties, the approach is still attractive due to its much greater simplicity, which outweighs the language difference issues. What is more, the fact that the resulting resource is aligned with the PWN, and therefore also with all other resources and tools that follow the PWN principles, is highly valuable. This is why the expand model has been adopted in a number of recent projects, such as the BalkaNet (Tufis  X  2000 ), MultiWordNet (Pianta et al. 2004 ) and BableNet (Navigli and Ponzetto 2010 ). With this we do not suggest that the expand approach is universally superior to the merge approach but that in our research settings, and we believe this applies to many other researchers as well, it was the optimal one. As a result, issues regarding the inventory or the relative position of synsets in the resulting semantic network do exist, but analysing them and adapting wordnet structure accordingly lies beyond the scope of this study.

Under the setting of the expand approach, approaches vary according to the type of resources that are available for the construction of a wordnet in a particular language. Early approaches link English entries from machine-readable bilingual dictionaries to PWN synsets under the assumption that their counterparts in the target language correspond to the same synset (Knight and Luk 1994 ; Yokoi 1995 ). A well-known problem with this approach is that bilingual dictionaries are generally not concept-based but follow traditional lexicographic principles, which is why the biggest obstacle is the disambiguation of dictionary entries. Also, bilingual machine-readable dictionaries often have limited coverage or are not digitally available for the relevant language pair at all.

This problem is overcome by a different set of approaches in which bi-or multilingual lexicons are extracted from parallel corpora (Resnik and Yarowsky 1997 ; Fung 1995 ). The main underlying assumption in these approaches is that senses of ambiguous words in one language are often translated into distinct words in another language. Furthermore, if two or more words are translated into the same word in another language, then they often share some element of meaning. This results in sense distinctions of a polysemous source word or yields synonym sets. As a result, parallel corpora have been utilised to induce synsets for a new language (Dyvik 2002 ; Ide et al. 2002 ; Diab 2004 ).

The third set of approaches that have become popular in the past few years draw upon Wikipedia, a large-scale collaborative encyclopaedic resource available for many languages. New wordnets have been induced by associating Wikipedia pages with the most frequent WordNet sense (Suchanek et al. 2008 ) by using structural information to assign Wikipedia categories to WordNet (Ponzetto and Navigli 2009 ) or by extracting keywords from Wikipedia articles (Reiter et al. 2008 ). Vector-space models have been developed to map Wikipedia pages to WordNet (Ruiz-Casado et al. 2005 ; Declerck et al. 2006 ). The most advanced approaches use Wikipedia and related projects, such as Wiktionary, to bootstrap wordnets for multiple languages (de Melo and Weikum 2009 ; Navigli and Ponzetto 2010 , 2012 ).
Our attempt in the construction of sloWNet has been designed to benefit from the combination of the available resources, which were of three different types: general and domain-specific bilingual dictionaries, parallel corpora and Wiki resources (Wikipedia and Wiktionaries). A basic version of the approach has already proved to be successful in our previous work where we created an initial Slovene wordnet drawing from these resources (Erjavec and Fis  X  er 2006 ; Fis  X  er and Sagot 2008 ). The focus in this paper, however, is to take the approach a step further and not limit the extraction of translations to monosemous words only but to extend it to polysemous words as well in order to take full advantage of each resource and at the same time mitigate the limitations each one of them brings by weighting candidates for synsets according to a selection of features. 3 Automatic extraction of lexico-semantic information In this section we describe the extraction of translation pairs from three types of resources: structured (general and domain-specific dictionaries and lexica), semi-structured (Wikipedia articles) and unstructured (parallel corpora). In the extraction process our task is to extract as many translation variants for each word or multi-word expression as possible in order to capture as many of its senses as possible. The goal of the procedure is to obtain wordnet candidates from the extracted translation pairs in the form of pairs consisting of a literal and its synset, i.e. translation of a source word with an assigned synset id from wordnet.

The acquisition of Slovene wordnet candidates is based on PWN concepts (synsets) and proceeds as follows: we take a PWN literal which appears in several synsets (say, n s synsets) and has many possible translations (say, n t translations) according to the information extracted from the various resources. Our aim is therefore to select the best candidates among the n s : n t possible ones by disambiguating each of these translations either in context thanks to parallel corpora, or out-of-context for all translation pairs extracted from dictionaries and Wikipedia. If the PWN literal is monosemous, 7 we simply assign the same concept (its synset id) to its translation. If the PWN literal is polysemous, we choose the best synset id for its translation by defining a synset proximity metric that is based on the initial restricted version of the Slovene wordnet. 3.1 Extracting lexico-semantic information from structured resources Bilingual dictionaries are very rich sources of lexico-semantic information that have already been compiled, analysed and structured, which is why they are an obvious first choice for harvesting the lexico-semantic information needed to populate a wordnet for a new language. Most bilingual dictionaries contain very little noise, have good coverage of general vocabulary across all parts of speech, contain translations for several senses of polysemous words and sometimes even definitions. However, bilingual dictionaries provide non-contextualised information and even when sense distinctions are explicitly encoded in the dictionary structure they are usually coarser-grained than PWN, which is why dictionary entries cannot be mapped directly to PWN concepts. Our approach for assigning synset ids to the translation pairs we extracted from dictionaries is described in Sect. 4 . Here we present the dictionaries we used, the extraction process and the results we obtained.
Wiktionaries 8 are freely available collaboratively constructed bilingual dic-tionaries which were originally designed as lexical companions to Wikipedia. They contain definitions of words as well as some additional information, including their translations into other languages which are sometimes structured into senses. We used English and Slovene Wiktionaries and extracted translation pairs for all parts-of-speech from these two resources on the basis of translation sections within the articles. However, Wiktionaries do not (yet) have good coverage of Slovene, which is why the number of lexicon entries we were able to extract is relatively low: 7,029 translation pairs from the Slovene Wiktionary and 6,052 from the English Wiktionary. For each entry, we also tried to extract a gloss based either on the first sentence of the Wiktionary article, or, if available, from the short glosses associated with each sense.

In order to extract the general vocabulary that was largely missing in Wiktionary, we used a digitised traditional English X  X lovene (Grad et al. 1999 ) and a Slovene X  English dictionary (Grad and Leeming 1999 ). The dictionaries do not contain definitions but we were able to harvest 207,972 translation pairs from the English X  Slovene dictionary and 72,954 from the Slovene X  X nglish one.

For domain-specific vocabulary we used Wikispecies , 9 which is a taxonomy of living species that includes Latin standard names as well as vernacular terms for the common species. This allowed us to extract 2,360 English X  X lovene pairs. In a similar way, we obtained 31,702 translation English X  X lovene pairs from the domain-specific thesaurus Eurovoc , 10 an on-line dictionary of informatics islovar 11 and a military glossary (Koros  X  ec et al. 2002 ).

The result of our extraction process is a large bilingual lexicon containing 282,789 unique English X  X lovene translation pairs with the name of the resource(s) they originate from. The figures for this extracted bilingual lexicon are summarised in the upper part of Table 1 . 3.2 Extracting lexico-semantic information from semi-structured resources Less structured than dictionaries but still with a much more predefined structure than free text is the on-line multilingual collaborative encyclopaedia Wikipedia . 12 We used English and Slovene Wikipedia for extracting a bilingual lexicon by following inter-language links that relate two articles on the same topic in the two corresponding Wikipedias. We enhanced the extraction process with a simple pattern-based analysis of article bodies based on regular expressions. More precisely, we first looked across each article body for all non-sentence-initial occurrences of its title, ignoring capitalisation, and compared the relative frequency of all capitalisation variants. This allowed us to resolve ambiguities arising from the capitalisation of article titles (e.g., Grass_author , Grass_plant ). Our pattern-based analysis allowed us also to extract relevant information from the structure of the first sentence of each article, thus identifying synonyms for the key terms (e.g., Cannabis , also known as marijuana ), their definitions (e.g., Hockey is a family of sports in which two teams play against each other by trying to manoeuvre a ball or a puck into the opponent X  X  goal using a hockey stick. ) and usage examples (e.g., The true grasses include cereals, bamboo and the grasses of lawns (turf) and grassland. ). It would also be possible to further analyse article bodies in order to extract other semantically related terms (e.g., hockey: sports [hypernym], hockey: ball, puck, goal, hockey stick [meronym] ) which we plan to do in our future work.
As a result, we obtained 32,669 Slovene X  X nglish entries that are predominantly nouns or nominal multi-word expressions (common or proper), yielding 32,161 unique translation pairs (see Table 1 ). 3.3 Extracting lexico-semantic information from unstructured resources The final type of the resources used in our experiment are the unstructured resources, that is free text. We used the SEE X  X RA.NET corpus (Tufis  X  et al. 2009 ), a 1.5-million-word subcorpus of JRC-Acquis (Steinberger et al. 2006) in eight languages. Apart from Slovene, we used English, Romanian, Czech and Bulgarian. We used different tools to PoS-tag and lemmatise the corpus before word-aligning it with Uplug (Tiedemann 2003 ). Because word-alignment was performed on single words only, we were not able to generate any translation equivalents for multi-word expressions. The output of the word alignment process is a file with word links between word occurrences and information on word link certainty.

This allowed us to build bilingual lexicons that include all translation variants of words as well as frequency, part-of-speech and token id information for each entry. Note that we base this decision on the fact that the quality of word-alignment is far from perfect in general but is improved when the languages in question are closely related, as is the case for example for Slovene and Czech. The bilingual lexicons we extracted range from 43,024 entries for the cs X  X n lexicon to 50,289 for the cs X  X g one. These bilingual lexicons are then combined into five multilingual lexicons which all involve at least Slovene and two other languages. They contain between 52,193 (Slovene X  X zech X  X nglish) and 55,768 (Slovene X  X zech X  X ulgarian X  X nglish) entries (see details in Table 2 ). Obviously, not all these candidates are correct; errors may appear for several reasons, such as tagging, lemmatisation, or alignment problems. However, many of these errors are eliminated in the next stage of the process. 3.4 Assigning synset ids to translation pairs As explained above, creating or expanding a wordnet by preserving PWN structure and synset inventory can be viewed as generating ( literal, synset ) pairs. This is achieved by assigning synset ids to the extracted translation pairs. The resources we used can be divided in two groups: lexicon-based and alignment-based resources, the difference between them being that lexicon-based entries are not associated with a particular occurrence in a particular context while the alignment-based entries are. This is why the process of assigning synset ids differs for these two groups. The lexicon-based bilingual entries we extracted are extremely valuable because they are far more numerous and accurate than word-alignment based information.

Let us consider for example the following English X  X lovene entry we extracted from Wiktionary:  X  organ en ; organ sl  X  . It does not contain any information that would make it possible for us to determine which of the 6 PWN synsets containing organ en as a literal would be appropriate to be translated with organ sl in sloWNet. In this case, only the  X  X ody part X  sense of English organ en can be translated as organ sl in Slovene, but not the  X  X usical instrument X  sense (which translates as orgle en ). In Wiktionary articles, translations of a given word are sometimes organised by senses that are associated with short glosses. These have been compared to PWN glosses in order to map Wiktionary senses to PWN synsets (Bernhard and Gurevych 2009 ; Casses 2010 ). The first sentence of a Wikipedia article can be used in a similar way (Ruiz-Casado et al. 2005 ). However, this is not the case for all Wiktionary entries or other resources in this category. We therefore decided to assign a synset id only to those translation pairs that contain a monosemous English word and postpone the disambiguation of polysemous lexicon-based entries to a later stage (see Sect. 4 ).
On the other hand, alignment-based entries contain contextual information that enables semantic disambiguation, as they are composed of translation equivalents which have been word-aligned at least once in the multilingual corpus. For each entry, we gathered the set of all possible synset ids associated with each word in each language involved (apart from Slovene) using the corresponding BalkaNet wordnets (Tufis  X  2000 ). Since all BalkaNet wordnets use the same synset inventory and synset ids as PWN, we were then able to compute the intersection of ids for all languages. The result contains all synset that are shared among all non-Slovene literals in this particular multilingual lexical entry. We then assigned these synset ids to their Slovene equivalent.

To illustrate this process, Table 3 shows how a few entries from the en X  X s X  X o X  bg X  X l lexicon are disambiguated and associated with a synset id, thus generating (literal, synset) candidates. The first two 5-lingual entries provide different translation variants for the English noun  X  X arty, X  which are strana (cs), partid (ro), these words appear in in the respective wordnets shows that the translation variants from the two lexicon entries do not have any synset ids in common, which suggests that they are translations of different senses of the polysemous English noun  X  X arty X . A different intersecting synset id in each lexicon entry is therefore assigned to their Slovene translations, which results in generating two different Slovene candidates, namely ( stranka , 07758173) for the  X  X olitical party X  sense and ( zabava , 07753857) for the  X  X ocial occasion X  sense. On the other hand, the last two entries in the lexicon are for the English word  X  X rmy X  and are the same in all languages except in Slovene. Since translation variants in both lexical entries share the same intersecting synset id, it is assigned to both Slovene variants. This generates two synonym candidates (i.e. the synset id in both candidates is the same), namely ( armada , 07686671) and ( vojska , 07686671). Using multiple language in this way on polysemous lexical entries eliminates most alignment errors. Indeed, it is rather unlikely that the same polysemy occurs in many different languages or that alignment errors lead to a non-empty intersection. Therefore, the intersection of all possible senses in each language is likely to output only the correct synset id(s). Obviously, this is even more so when using more different languages than when using only one language apart from English and Slovene, which is the minimum required for the intersection to actually be possible. On the other hand, the more languages are used, the more reliable but the less numerous the generated candidates will be because intersecting more translation sets in more languages can only lead to a smaller intersection.

Applied to the above-mentioned multilingual lexicons, this technique yielded five different sets of candidates filling different synsets with at least one Slovene literal. They include between 1,364 (sl-ro-cs-bg-en) and 4,232 (sl-cs-en) entries. Because the pre-processing stages, such as tagging, lemmatisation and word-alignment were not perfect, it is expected that the synsets created in this way will inherit some of the errors which will hopefully be filtered out by the classifier (see Sect. 4.3 ). 4 Automatic induction of synsets for wordnet extension The development of the initial sloWNet was achieved in a three-step process. First, we created baseline versions of wordnets (Fis  X  er and Sagot 2008 ) by using only ( literal, synset ) pairs obtained from the parallel corpus which could be disam-biguated based on other languages, and monosemous words extracted from the dictionaries, lexica and Wikipedia which required no disambiguation. Such a restricted wordnet was relatively reliable but did not use full potential of the available resources. This is why, after making a few improvements on this initial sloWNet, we performed a large-scale extension process, aiming at taking full advantage of the resources and improving the coverage of the resource without lowering its accuracy (Sagot and Fis  X  er 2011 ). In this section we briefly describe the two first steps and then give a detailed account of the novel extension step. 4.1 Developing baseline wordnets The first step in the development of sloWNet was achieved in 2008, when the first version was created (Fis  X  er and Sagot 2008 ). 13 For this first step only monosemous PWN literals were translated using bilingual resources, thus avoiding disambigua-tion issues. However, all PWN literals were used for adding target language literals in the synsets found by the alignment-based approach. If the same ( literal, synset ) pair was created from more than one resource (e.g., from a multilingual lexicon that was extracted from the word-aligned corpus and from a bilingual lexicon that was extracted from Wikipedia), the information on the source of the generated synset was retained. This enabled us to perform a simple heuristic filtering according to the reliability of each resource, on the number of different resources that assign a given literal to the same synset and on frequency information (for resources from the alignment approach).

Automatic insertion of Slovene literals to synsets inevitably leads to gaps in the hierarchy. Because we are aware of the importance of the conceptual density and hierarchy preservation principles for applications (Tufis  X  2000 ), we inherited the structure and relations of the missing synsets from PWN, thus leaving many empty synsets. Therefore, in case an application runs into an empty synset, it can still use the relation information to access a more general concept. Other language-independent information (e.g., PoS, domain, semantic relations) was inherited from the PWN as well. We also adopted the three Base Concept Sets (BCS) which were introduced in the BalkaNet project (Tufis  X  and Cristea 2002 ) and comprise 8,516 synsets that have been commonly agreed to be implemented by all consortium members in order to obtain a guaranteed overlap of lexicalised concepts between the BalkaNet languages, such as building , vehicle , animal , etc. The Base Concepts are the concepts that play the most important role in the various wordnets of different languages. This role is measured in terms of two main criteria: (1) a high position in the semantic hierarchy and (2) having many relations to other concepts (Weisscher 2013 ). The Base Concepts play a crucial role in wordnet building that is typically top-down: first, a core wordnet is developed around the Base Concepts that contains about 5,000 X  10,000 synsets and is highly compatible in coverage and semantic interpretation with wordnets in other languages, and then the core wordnet is extended beyond 20,000 synsets in a top-down fashion, given the semantic basis of the core wordnet.
The figures for the first version of sloWNet (version 2.0) are given in the second column in Table 4 , together with corresponding figures about PWN 2.0, and more recent versions of sloWNet (version 2.2 and version 3.0 resulting from the work described in this paper). 4.2 Enhancing baseline sloWNet After the restricted and automatically produced version of sloWNet (version 2.0) was built, it underwent some improvement steps. First of all, because legal aspects regarding the use of the traditional English X  X lovene and Slovene X  X nglish dictionaries were unclear, we re-ran all experiments without using this resource. Second, due to poor parsing of Wikipedia articles, many synsets contained duplicate literals that were identical except in stress markings (e.g., kolo and kol X  ) which were therefore normalised and merged. Since sloWNet was used for manual semantic annotation of a corpus (Fis  X  er and Erjavec 2009 ), it was also extensively manually edited in order to delete erroneous senses of words that were annotated and add the missing ones. This is why the published Slovene baseline wordnet (version 2.2), used during the large-scale extension experiments described in the next section, is significantly different and smaller than the automatically produced version 2.0. Finally, sloWNet 2.2 uses the synset inventory from PWN 3.0, whereas sloWNet 2.0 uses the synset inventory from PWN 2.0. 14 Note however that, in the end, we did use the traditional dictionaries during that large-scale extension step. 4.3 Large-scale wordnet extension Restricting the use of a bilingual lexicon to monosemous English literals is a safe but limited approach that does not exploit the available resources to their full potential. However, using lexicon-based candidates generated from polysemous English literals is only possible if we can establish the likelihood with which a word should be added to a particular synset, i.e. can compute the semantic distance between a given Slovene literal and synset id. We designed such a technique based on the already-existing Slovene wordnet (version 2.2) and we present it in this section. 4.3.1 Using a probabilistic classifier Our technique relies on a probabilistic classifier that uses various features associated with each ( literal, synset ) candidate. The underlying idea is as follows: we have a baseline wordnet at our disposal, and a large set of lexicon-based candidates to evaluate. We extract all ( literal, synset ) pairs that are already in the baseline wordnet and consider these candidates as valid ones while all the other candidates are considered invalid, thus creating a  X  X  X opper standard X  X , i.e. a reasonable although noisy training set for a probabilistic model. The training set is noisy for two reasons: first, the baseline wordnet itself contains noise because not all synsets were manually validated; second, and more importantly, many of our new candidates are valid even though they are not in the baseline wordnet. In fact, such candidates are exactly those that we are looking for to extend our wordnet. In order to use the copper standard as the training set for a classifier, we need to extract suitable features for the candidates which was performed with the Maximum-Entropy package megam (Daume  X  2004 ) based on the features described below. The result of our classifiers on training data is a certainty value between 0 and 1. We empirically set the threshold at 0.1 (see Sect. 6.1 for motivations for this value) and added all the candidates that pass the threshold to the wordnet. 4.3.2 Feature selection This section contains a description of the features we used to train our candidate evaluation models. The most important feature models the semantic proximity between a literal and a synset. Let us illustrate it on the previous example  X  organ en ; organ sl  X  . In PWN (3.0), 6 synsets contain the literal organ en , which is why we also generate 6 different ( literal, synset ) candidates from the bilingual entry  X  organ en ; organ sl  X  . We now need to know which of these 6 candidates are valid, i.e. to which of the 6 corresponding synsets the Slovene literal organ sl should be added in sloWNet. We therefore compute the semantic similarity of the Slovene literal organ sl w.r.t. each of these 6 synsets.

We first represent each sloWNet synset by a bag of words obtained by extracting all literals from this synset and all the synsets up to two nodes apart in sloWNet, i.e. related via a path of length at most two involving any type(s) of lexical relation(s). 15 For example, the synset f organ en ; pipe organ g in PWN is represented by the bag of words { glasbilo , Anton Bruckner , glasbenik , Johann Sebastian Bach , pisalni , klavirska , harmonika ,...} ( X  X usical instrument, X   X  X nton Bruckner, X   X  X usician, X   X  X ohann Sebastian Bach, X   X  X riting adj , X   X  X iano adj , X   X  X ccordion, X   X  X evice, X ...).
Next, we use a distributional semantic model for evaluating the semantic similarity of orgle w.r.t. this bag of words. We use the freely-available SemanticVectors package (Widdows and Ferraro 2008 ), 16 which relies on the Lucene indexing system. 17 This package is able to build a word-document frequency matrix from a large set of documents, reduce the dimensionality of this matrix by a random projection technique, and finally extract one semantic vector per word from this reduced matrix. The package then allows for assessing the distributional semantic similarity of two bags of words using Latent Semantic Analysis. The documents we used for building such distributional semantic models are 334,000 lemmatised paragraphs from the FidaPLUS corpus (Arhar and Gorjanc 2007 ) (180,000 distinct lemmas). 18 Applied to our example, the semantic similarity between organ sl and the synset { organ en , pipe organ } is only 0.021, while the similarity between organ sl and one of its valid synsets, f organ en g , defined as a fully differentiated structural and functional unit in an animal that is specialised for some particular function , is 0.668. Indeed, in Slovene, organ sl has the  X  X ody part X  meaning but not the  X  X usical instrument X  ( orgle , in Slovene).

Apart from that semantic similarity measure, the other features we used are the target language, here Slovene) that has been generated because our bilingual l  X  X  are among s  X  X  literals. The number of such PWN literals is one of the features. Each possible source (e.g., the English wiktionary) corresponds to one feature, which receives value 1 if and only if at least one of the  X  l e ; i ; l t  X  bilingual lexical entries was extracted from this source. Moreover, we extract the lowest polysemy index among all the occurences of l e ; i . For example, if the least polysemous l e ; i is in two PWN synsets, this feature receives value 2. The idea is that if the candidate is generated from at least one monosemous PWN literal, then it is very likely to be correct, whereas if it is generated from only highly polysemous PWN literals, it is much more questionable. Finally, the number of tokens in l t is used as a feature as well (literals with many tokens are usually not translations of PWN literals but rather glosses that arise from Wikipedia or Wiktionary, and are therefore incorrect). 4.3.3 Building classification models The resulting models are shown in Table 5 . They clearly show that semantic similarity is relevant and useful as it is the feature with the highest weight. As expected, the lowest polysemy index among English literals also contributes positively, as does the number of different English literals yielding the generation of the candidate, and the number of sources involved. On the other hand, as predicted as well, the number of tokens in the target language literal negatively contributes to the certainty score. Finally, the different sources are also associated with a weight. 4.3.4 Results of the classification After having trained these models, we used them to score all 685,633 Slovene candidates generated from our bilingual resources as explained in Sect. 3.4 . Using the above-mentioned threshold on the models X  output, we retained 68,070 candidates. Among these candidates, 5,056 (7 %) correspond to ( literal, synset ) pairs already present in sloWNet 2.2, which means that 63,014 (93 %) new ones were added; as a consequence, 25,102 synsets that were previously empty in sloWNet now have at least one Slovene literal.

Quantitative information on the resulting wordnets (sloWNet 3.0) is provided in the last column of Table 4 . In short, sloWNet 3.0 has as much as 141 % more non-empty synsets than before the extension. As far as ( literal, synset ) pairs contained in the resources are concerned, the increase is even higher: the extension of sloWNet has increased the number of such pairs from 24,081 to 82,721 ( ? 244 %). The evaluation of the newly added ( literal, synset ) pairs is described in Sect. 6.1 . Evaluations of the resulting extended resource with respect to other wordnets (a gold standard Slovene wordnet and two other automatically generated wordnet-like semantic repositories) is given in Sects. 6.3 and 6.4 . A task-based evaluation in a machine translation setting is given in Sect. 6.5 . 5 Cleaning noisy synsets Despite the satisfying results obtained in the previous section, the technique we used, as all state-of-the art methods for the population of wordnets, is still far from perfect, resulting in noisy synsets. This is why we developed a language-independent, corpus-based approach to detect outliers in automatically generated synsets and filter them out in order to obtain a cleaner, more useful lexico-semantic resource for human use as well as for various NLP tasks (Sagot and Fis  X  er 2012 ).
The cleaning approach falls within the scope of distributional methods for detecting semantic similarity between words (Lin et al. 2003 ), but instead of identifying most closely related words according to the contexts they appear in, we start from a (noisy) list of synonym candidates in the form of an automatically induced wordnet. In a way, our task is not very different from the lexical substitution framework (Mihalcea et al. 2010 ), with the exception that we are most interested in the bottom of the ranked list of potential synonyms. In addition, our notion of synonymy is much stricter because it is our aim to clean all the synsets in an automatically created wordnet, which is very fine-grained.

At the same time, the notion of polysemy that is of key importance for this work is translation-motivated. This means that regardless of the number of synsets a word appears in, the distinction between those senses that are lexicalised differently is the only relevant one in this work.

We focused on identifying and eliminating the most obvious errors in synsets that occurred due to errors in word-alignment of parallel corpora (e.g. misaligned elements of multi-word expressions) and inappropriate word-sense disambiguation of homonymous words (e.g. assigning a valid translation of one sense of a homonymous source word to all its senses). It is precisely these errors in wordnets that have the biggest impact in NLP applications and decrease the value of the resource the most.

Our approach for cleaning noisy synsets relies on a simple hypothesis: lexemes, defined here as ( literal, synset ) pairs, tend to co-occur in corpora with other lexemes that are semantically related, as made explicit by relations between synsets in a wordnet. This is possible because, provided that the wordnet is large enough, this technique can provide a sufficient number of semantically related lexemes for most lexemes with a high precision (the precision of sloWNet 3.0 has been evaluated as 86 %, see Sect. 6 ).

The method we used for cleaning our wordnets can be divided in two steps: 1. Co-occurrence-based evaluation of the similarity between each nominal 2. Global assessment of all nominal ( literal, synset ) pairs based on these similarity 5.1 Basic co-occurrence-based scoring of (literal, synset) pairs In order to achieve step 1 in the enumeration above, we first associate each synset from the input wordnet with a set of related synsets, i.e. a subset of all synsets (nominal or not) that are related to the base synset by relation paths of length 0, 1 or 2, based on manually designed relation patterns shown in Fig. 1 . Second, we associate each synset pair with the list of its related literals, i.e. all literals that belong to any of its related synsets.

Next, given an occurrence of a nominal literal in the corpus, we look at all literals that co-occur in the same paragraph. We chose paragraphs as contexts because sentences are too small to provide us with enough literals, and because paragraphs constitute the smallest linguistically motivated and typographically discernible text units that are larger than sentences. We then apply a variant of the wordnet-based Lesk algorithm for word sense disambiguation (Lesk 1986 ). Lesk X  X  algorithm relies on the assumption that the relatedness of two words is proportional to the extent of overlaps of their dictionary definitions. This algorithm was later extended to also use literals from related synsets as well as wordnet usage examples in addition to the dictionary definition (Banerjee and Pedersen 2002 ). We adapted this idea to our task, by comparing each paragraph where a given literal occurs, represented by its content words (co-occurring literals) with each possible synset for this literal, represented by the literals found in their respective sets of related synsets, as defined above.

More formally, let l be a nominal literal in paragraph p . We refer to the set of all synsets containing a literal l 0 in the input wordnet as S  X  l 0  X  , and to the number of such synsets j S  X  l 0  X j . Let C  X  p  X  be the set of (PoS-tagged) literals in paragraph p , and related to a synset s in the input wordnet as R  X  s  X  . Finally, let length  X  p  X  be the receives for paragraph p a local score local score  X  l ; s ; p  X  defined as follows: The corpus-wide score global score  X  l ; s  X  for the (literal, synset) pair  X  l ; s  X  is then simply the sum of the local scores of each of its occurrences: Let us illustrate this on an example. Consider the Slovene noun ikona ( X  X con (religion) X  or  X  X con (computer science) X ). It appears in 4 synsets in sloWNet 3.0, among which:  X  eng-30-07269916-n { icon }; the Slovene literal ikona is correct in this synset;  X  eng-30-03931044-n { icon , ikon , image , picture }; the Slovene literal ikona is not In our corpus, the Slovene noun ikona occurs 3,488 times. The global score for the correct ( ikona , eng-30-07269916-n) pair, based on the above-mentioned related literals, is only 1.02, whereas that for the incorrect ( ikona , eng-30-03931044-n) pair it is 5.99. This shows that global scores do not necessarily allow us to correctly detect the erroneous ( literal, synset ) pair. Therefore, we take into account additional information, as shown in the next section. 5.2 Extracting outlier candidates for ( literal, synset ) pairs At this stage, we have for each ( literal, synset ) pair a global score that is the sum of the local scores of its occurrences in the corpus. We first normalise this global score by pairs involving the same synset s . This is used to assess the contribution of a given literal the input wordnet. We define synset global score  X  s  X  in a straightforward way: The contribution of l to the synset s is then: This contribution is then normalised by the number of occurrences occ  X  l  X  of the If we go back to the example given in Sect. 5.1 , the synset global score for eng-30-07269916-n is 1.02, and is 234 for eng-30-03931044-n. Their respective contribu-tions are thus 1 and 0.026. Consequently, our last formula leads to a score of 0.287 for ( ikona , eng-30-07269916-n), whereas the score for ( ikona , eng-30-03931044-n) is 0.007. The final score now correctly identifies the correct vs. incorrect (literal, synset) pairs. Additional examples are provided together with their manual evaluation in Sect. 6.6 , which is, along with Sect. 6.7 , dedicated to evaluation and validation procedures of outlier candidates. 6 Evaluation of the results In previous sections we have described the development of sloWNet: first, we developed a baseline version (sloWNet 2.0), second, we performed some manual improvements of the generated wordnet, and third, we extended the resulting sloWNet (version 2.2) with additional lexical information and identified outliers. Because only the final two steps are novel and because they have contributed to a considerable increase compared to previous versions, we begin with a manual evaluation of the extension step. We evaluate the accuracy of the candidates we obtained as well as the accuracy of the candidates we discarded. Next, we perform two series of contrastive evaluations of the extended wordnet. With this we will gain insight into the precision and recall of the wordnets we created, before and after the extension. First, we compare it with a small-scale gold standard, a small, manually constructed wordnet for Slovene (SWN). Second, we compare it with other automatically generated wordnets, namely the multilingual Universal WordNet (UWN) (de Melo and Weikum 2009 ) and the latest version of BabelNet (version 2.0) (Navigli and Ponzetto 2010 , 2012 ). Finally, we illustrate how this extended wordnet performs in task-based settings. In addition, we also provide insights into the quality of the outlier detection task, via manual assessments by an expert and crowdsourcing-based validation results.

In all our evaluation settings we assess if the synset assigned to a given literal is correct (i.e. if it is an appropriate lexicalisation of the concept in question). In order for the candidate to be considered valid, it has to be a perfect match for the assigned synset; if the literal denotes a more general or more specific concept (a hyper-or hyponym) than the concept represented by the synset in question, it is marked as incorrect. 6.1 Manual evaluation of the wordnet extension step Before evaluating sloWNet as a whole, we wanted to measure the accuracy of our extension approach (see Sect. 4 ). We therefore randomly selected 400 (literal, synset) candidates and evaluated them manually. Since we have found that the errors performed by the automatic sense assignment step are not very fine-grained, we did not see the need to check inter-annotator agreement. Instead, manual evaluation was performed by a single annotator who used only two tags:  X  X  X ES X  X  if it was correct to add that literal to the synset, and  X  X  X O X  X  if it was wrong, regardless of the reason for the error and its semantic relatedness to the synset. The accuracy of a set of candidates is as usual the proportion of candidates receiving the  X  X  X ES X  X  tag. Moreover, in order to assess the quality of our scoring technique, we compared the accuracy of the candidates per quartile w.r.t. their certainty scores. The results are shown in Table 6 . We observe a strong correlation between the certainty score they received and the accuracy of the candidates, leading us to set the threshold value at 0.1. Other threshold values could have been used: higher values would have provided candidates with an even higher accuracy but the scale of the wordnet extension would have been lower; on the other hand, lower threshold values would have extended our wordnets even more but would have also introduced more noise. The 0.1 value, which corresponds approximately to the upper decile, seemed to provide a good balance. It leads to retaining 68,070 candidates (out of 685,633) that, however, have a precision of only 64 %. 19 6.2 Manual evaluation of the extended wordnet The most straightforward way to evaluate the accuracy of a wordnet is to randomly select a significant amount of ( literal, synset ) pairs and evaluate them manually. In order to obtain a meaningful per-PoS evaluation, we have decided to evaluate 100 randomly selected ( literal, synset ) pairs per PoS. This also allows for an estimate of the overall accuracy of the extended sloWNet (version 3.0), by weighting per-PoS accuracy scores by the relative number of (literal, synset) pairs for each PoS.
The results of this evaluation are provided in Table 7 . It shows that the overall accuracy of sloWNet 3.0 is 82 %. With the proposed method we were able to generate most nominal synsets that at the same time have a very high accuracy (87 %). The only more accurate are adverbial synsets (96 %), which is understandable since they have the lowest degree of polysemy. The results for adjectives (85 %) are comparable to those of nouns, only verbal synsets perform much worse (59 %). On the one hand, this can be expected since verbs are much more polysemous (while average polysemy for nouns in PWN is 1.24, it is 2.17 for verbs 20 ), but on the other hand their translations depend on target language syntax much more than translations of nouns or adjectives. This is why they are a much more difficult problem to address with the proposed approach. 6.3 Contrastive evaluation of the extended wordnet against a small-scale gold A direct manual evaluation such as the one described in the previous section leads to precise overall accuracy results. However, such an evaluation does not provide insights into at least two questions: (i) the recall of sloWNet 3.0, and (ii) the accuracy of BCS synsets in sloWNet 3.0.
 In order to obtain information on these issues, we compared sloWNet 3.0 to the Slovene WordNet (SWN). SWN is a small-scale manually built gold standard, obtained by validating the results of the preliminary Slovene wordnet construction experiments based on the Serbian wordnet (Erjavec and Fis  X  er 2006 ). Because it has been developed manually, SWN only contains synsets from the three Base Concept Sets (Tufis  X  and Cristea 2002 ). 21 Therefore, evaluating sloWNet 3.0 on those synsets which are not empty in SWN is a first step towards an answer to question (ii) above. Moreover, because SWN has been developed manually, it is reasonable to make the assumption that a non-empty SWN synset contains all Slovene literals that should be found in that synset. In other words, one can estimate the recall of sloWNet 3.0 by comparing its coverage w.r.t. non-empty synsets in SWN. However, such an evaluation is strongly biased, as it is restricted to the above-mentioned BCS synsets only. This evaluation therefore cannot be considered a definitive answer to question (i) above.

The accuracy-oriented evaluation was performed as follows. First, we consider any ( literal, synset ) pair that is found in both SWN and sloWNet 3.0 as correct. Second, in order to assess the accuracy of ( literal, synset ) pairs found in sloWNet 3.0 but not in SWN, we randomly selected 100 such pairs per category and evaluated them manually. For adjectival synsets, there are only 45 such pairs, so we evaluated them all. As there are no adverbial synsets in SWN, no figures can be obtained on such synsets.

The results of this evaluation are given in Table 8 . The average accuracy result which we obtain, namely 70 %, is much lower than the overall accuracy of sloWNet 3.0 which we obtained in the previous section, namely 82 %. This is because evaluation against SWN is restricted to BCS synsets which denote general concepts, typically lexicalised with high-frequency vocabulary. Since general, frequent words are typically highly polysemous, they present the biggest challenge in automatic sense assignment, causing the lower accuracy score. In order to confirm this we randomly chose 100 pairs among the 67,393 sloWNet 3.0 pairs that are in synsets which are empty in SWN. This evaluation yielded an accuracy score of 92 %. This latter figure, together with the 70 % accuracy score on pairs from the non-empty SWN synsets, results in a new estimate of 86 % for the new overall accuracy of sloWNet 3.0. The discrepancy between the 82 % obtained in the previous section and the 86 % measured here is thus an artefact of the random selection process
Table 9 details our results w.r.t. SWN from a recall-oriented perspective. It is difficult to interpret these results because they are computed only on BCS synsets, which contain literals that in general display a higher degree of polysemy (e.g. plant ), as opposed to literals denoting specialised concepts (e.g. hellebore ), and therefore cause a negative bias for recall. On the other hand, taking SWN non-empty synsets as necessarily complete would again be an incorrect approximation, causing a positive bias for recall. Table 8 shows a comparison of incomplete SWN synsets with their extended sloWNet 3.0 counterparts where we can see that many correct BCS ( literal, synset ) pairs are found in sloWNet 3.0 but not in SWN. 6.4 Contrastive evaluation of the extended wordnet against two other Another way to evaluate sloWNet, and more specifically to evaluate the approach we used for building it, is to compare it with comparable resources, namely other automatically generated wordnets. We have evaluated it against two highly multilingual wordnets, namely BabelNet (Navigli and Ponzetto 2010 , 2012 ) 22 and the Universal WordNet (UWN) (de Melo and Weikum 2009 ).

Even though both UWN and BabelNet are built from the same basic resource as sloWNet, it must be recalled that their aim is to be massively multilingual networks, while we focused on translating the Princeton WordNet from English to an individual language, here Slovene. As a result, the Slovene subpart of UWN is much smaller than sloWNet as it contains only 9,924 (literal, synset) pairs, 23 to be compared with the 82,721 such pairs in sloWNet 3.0. This is not the case with BabelNet (version 2.0), which contains as many as 131,964 literals. However, as we will see, the accuracy of the Slovene subpart of BabelNet is much lower than that of sloWNet 3.0.

Table 10 shows the number of (literal, synset) pairs for each of the 7 possible situations obtained by crossing the presence or absence of a pair in each of the three resources. Comparing sloWNet 3.0 with UWN and with BabelNet respectively, we get the following results:  X  Among the 9,924 (literal, synset) pairs in the Slovene subpart of UWN, 5,590  X  Among the 131,964 ( literal, synset ) pairs in the Slovene subpart of BabelNet Overall, as many as 64,663 ( literal, synset ) pairs are only found in sloWNet 3.0. Only 901 pairs are both in BabelNet and in UWN but missing in sloWNet 3.0.
In order to better quantify and analyse the differences between these three resources in terms of accuracy, we carried out a manual evaluation of 50 randomly selected ( literal, synset ) pairs for each of the 7 possible situations mentioned above. The results are shown in Table 10 . Based on the results, we can draw the following conclusions:  X  The overall accuracy score obtained for sloWNet 3.0 in this evaluation is 88 %.  X  The overall accuracy of sloWNet 3.0 and UWN are similar, despite the fact that  X  The accuracy of the 64,663 sloWNet-only (literal, synset) pairs is around 86 %;  X  The three approaches used for building these resources are complementary in the  X  BabelNet, which is very large, is also quite noisy, and therefore not fully More specifically, and apart from real disambiguation issues, errors among sloWNet-only pairs are mostly related to strange and/or archaic words, whereas errors among UWN-only pairs and BabelNet-only pairs are often related to normalisation errors: English literals, titles of Wikipedia pages that are not literals (e.g., Seznam Arheolo X kih Dob  X  X ist of archeological ages X ), Slovene words that are correct semantically but are in the wrong part of speech, in feminine form, preceded by a numeral, followed by a dot or a disambiguation word from Wikipedia (e.g., Mars (bog)  X  X ars (god) X ), etc. Table 11 gives an example of a synset with all literals from sloWNet 3.0, UWN and BabelNet 2.0, including a short comment for each literal. In total, we find 9 literal candidates for this synset in all three resources. sloWNet contains two, both of which are correct. UWN contains the two correct ones plus two incorrect ones and the noisiest is BableNet which contains 9 literal candidates, including the two correct ones.

Given the results of this section and the previous one, we believe that sloWNet 3.0 can be considered as the most adequate Slovene wordnet to date. 6.5 Task-based evaluation of the extended wordnet The evaluations presented in the previous sections provide direct insights into the quality of sloWNet 3.0. However, developing a wordnet is not necessarily a goal per se , which is why we decided to carry out a small-scale task-based evaluation as well. In this section, we present the results of an evaluation of the extended sloWNet which was used to improve machine translation at the lexical level (Fis  X  er and Vintar 2010 ). Mistranslations often arise due to inadequate word-sense disambiguation of polysemous words and detection of multi-word expressions, and parallel wordnets can help with both problems.

In order to examine the importance of correct sense identification in an MT task, we created a small parallel corpus of 500 articles from the EU news portal that contained about 120,000 Slovene and 140,000 English tokens. We lemmatised, PoS-tagged and sentence-aligned the corpus and then semantically disambiguated all literals in the corpus with the freely-available graph-based UKB tool (Agirre and Soroa 2009 ), i.e. each of them received a unique synset id depending of their meaning in context. In sense assignment, UKB takes into account only direct ( literal, synset ) pairs, not their hypernyms or hyponyms, which could also be utilised in a future extension of the experiment. Next, we machine-translated both parts of the corpus with two MT systems; the rule-based Presis 24 and the statistical GoogleTranslate, 25 and compared the machine-translated solutions with human translations, which we treated as a gold standard, and translation equivalents obtained via synset ids from the two wordnets.

A comparison of MT-output, WN-equivalents and the human translations show that there were about 38,000 polysemous tokens (32 % of all the polysemous tokens in the corpus) in the Slovene part of the corpus. About 40 % of them were translated identically by both MT systems, wordnet-based WSD and the gold standard. But there were 1,558 tokens (4.1 % of all the polysemous tokens in the corpus) for which Slo ! Eng Presis and 867 Google translations (2.3 % of all the tokens in the corpus) did not match the translations in the gold standard but were assigned the correct wordnet sense. This is illustrated in Fig. 2 where the word koza was incorrectly translated by Presis as smallpox , while goat , the correct translation, was suggested by sloWNet.

When translating in the opposite direction, there were 48,000 polysemous tokens (34 % of all the tokens in the corpus) and only about 32 % of them were translated identically by both MT systems, wordnet-based WSD and the gold standard. Interestingly, the discrepancy between semantic misrepresentation of polysemous tokens by the MT systems with respect to wordnet-based WSD was even larger: 3,730 tokens (2.7 % of all the polysemous tokens in the corpus) that were mistranslated according to the gold standard by Presis were correctly disambiguated with sloWNet, and 901 (1.9 % of all the polysemous tokens in the corpus) by Google.

In a random sample of 200 sentence pairs that were manually checked, there were also 166 multi-word expressions which were not identified as such by the machine-translation system and therefore incorrectly translated, but were found in wordnet, e.g., biotska raznovrstnost  X  X iotic diversity X  instead of biodiversity ; vezani les  X  X ied wood X  instead of plywood .

This analysis shows that the extended sloWNet, when used in parallel with PWN, can be a very useful resource in MT systems, especially with polysemous words and multi-word expressions that are a major source of errors by MT systems, rule-based and statistical alike. The reason why GoogleTranslate performed better than Presis overall is that Google X  X  MT uses parallel texts found on the web, which was also the source of our parallel corpus and had probably already been detected by Google. 6.6 Manual evaluation of outlier candidates As mentioned above, the overall error rate in the extended sloWNet has been evaluated as being about 15 %, i.e. around 12,000 incorrect ( literal, synset ) pairs. Given our set of outlier candidates, we have empirically chosen a threshold on the outlier score such that the number of candidate outliers has the same order of magnitude than the estimated number of erroneous (literal, synsets) pairs. This resulted in a threshold of 4 10 6 , thus generating 12,578 candidate outliers, i.e. approximately one third of all outlier candidates.

We manually evaluated a random sample of 100 candidate outliers. Among these, the proportion of ( literal, synset ) pairs which have correctly been detected as errors is 64 %. These figures can be compared with the estimated overall error rates in the input wordnets, namely 15 % as recalled above. Considering that we expanded sloWNet using thresholds that led to a reasonable balance between recall (more candidates is better) and precision (less erroneous candidates is better), we inevitably included erroneous candidates as well. The fact that our outlier detection method manages to suggest candidate outliers out of which 64 % are real errors is very good: first, it means that our outlier detection algorithm manages to spot many more errors than randomly selecting ( literal, synset ) pairs; second, this outlier detection algorithm relies heavily on its input wordnet, i.e. on the extended wordnet: in other words, the information available to the outlier detection algorithm includes the entire extended wordnet, something that the wordnet extension algorithm could obviously not rely on.
Examples of candidate outliers from sloWNet extracted from our manual evaluation data are shown in Table 12 . Apart from the synset and literal we indicate the corresponding score as well as the outcome of manual evaluation in which the  X  X  X ES X  X  label means that the (literal, synset) pair has been correctly detected as incorrect, while the  X  X  X O X  X  label means that the ( literal, synset ) pair is indeed correct, and that its detection as a candidate outlier is erroneous. 6.7 Crowdsourcing-based validation of outlier candidates The identified outlier candidates were earmarked for manual examination during which they would be rejected as errors and therefore deleted from the wordnet or validated as correct and kept in the resource. In order to facilitate manual work, we have developed a simple on-line tool called sloWCrowd (Tavc  X  ar et al. 2012 ) that works on the principle of crowdsourcing. The tool is open-source and based on popular technologies, such as PHP and MySQL. It consists of an administrator and a user interface. The administrator interface enables the creation of crowdsourcing projects, management of on-going projects and export of the results, while the user interface allows users to vote on the (in)correctness of the randomly displayed literals. The reliability of each user is checked against a gold standard so that the users with a very low accuracy can be automatically excluded from the final results. In order to achieve as high consensus about the answers as possible, the same question is repeated five times, each time to a different user, and the final decision is based on the majority vote. The user interface for validating outlier candidates is shown in Fig. 3 where the user is asked the following question: Is the automatically translated expression X an appropriate lexicalisation of the concept Y?
To date, 26 275 users have provided 34,867 answers, including answers to gold standard requests, and have validated 7,276 outlier candidates. On average, each user provided 126.79 answers, whereas the maximum number of answers provided by a single user is 4,200 and the minimum is 1. Users X  accuracy ranges between 25 and 100 %, but is 79.72 % on average. According to the majority vote, 44 % of the outlier candidates have been voted as correct and 56 % as incorrect. This is in line with the results of manual evaluation of a sample of 400 outlier candidates, 64 % of which have been considered as genuine errors (see Sect. 6.6 ). All the outlier candidates that were rejected by the majority of the users were deleted from sloWNet. The crowdsourcing task will continue until we collect votes for all 12,578 candidate outliers we obtained from our automatic outlier detection procedure. Once all the votes are collected, the outlier candidates with the majority negative vote will be deleted from sloWNet and version 4.0 will be announced. 7 Conclusions and future work In this paper, we have described the different resources and techniques we used for automatic construction, extension and cleaning of sloWNet, a wordnet for Slovene. We first outlined the construction of the baseline wordnet based on bilingual lexicons extracted from Wikipedia, Wiktionaries and other bilingual resources which we used for translating monosemous literals, and word-aligned parallel corpora for translating and disambiguating polysemous literals. Then we described a follow-up experiment in which we used the same bilingual lexicons much more exhaustively than the baseline wordnets. By using various features, including distributional similarity, we were able to reuse the same resources for translating and disambiguating polysemous literals as well, which had been dealt with only by word-aligned corpora up to this point. This enrichment step has increased the number of non-empty synsets in sloWNet from 17,817 to 42,919. The number of ( literal, synset ) pairs in sloWNet went up from 24,081 to 82,721 ( ? 244 %).
The resulting wordnet was then carefully evaluated, both in terms of accuracy of the content and as a resource in a machine-translation setting. The accuracy of ( literal, synset ) pairs is estimated at approximately 85 %. These figures show that the enhanced resource has a much higher coverage than the baseline wordnet and that it outperforms the gold Slovene WordNet.

The latest version of sloWNet has been uploaded to sloWTool , 27 a freely available tool that incorporates browsing, editing and visualisation of wordnet content with hyperbolic graphs and images (Fis  X  er and Novak 2011 ). It is freely available and based on MySQL and PHP technologies, which makes the tool light-weight, portable and efficient. Scripts for automatic database transformations from and into several standardised formats, such as DEBVisDic XML and LMF, are provided so that a wordnet for another language can be imported at any time. The on-line browser is simple to use for non-experts but also enables advanced searching and view settings for expert users that can enter complex search queries and decide which fields to display as well as toggle between a mono-and a multilingual option. Through sloWTool, sloWNet is now available to language students, translators and other linguists who can examine the Slovene lexical inventory and semantic network which they can also compare to English and French since wordnets for these languages are cross-aligned via the Princeton WordNet synset IDs and are available on the sloWTool as well (Fig. 4 ).

In the future we plan to work in five complementary directions. First, more attention should be given to the multi-word expressions, such as phrasal verbs, compound nouns and idiomatic expressions, since they represent a substantial segment of our semantic repository and pose a major obstacle in NLP applications. Second, the extraction of lexico-semantic information from Wikipedia and Wiktionary can be improved even further by adding definitions and examples to the created wordnets as well as extend and validate the current network by mining semantically related words from article bodies. Third, we have already started adapting the alignment-based approach to work with non-parallel texts (Fis  X  er et al. 2012 ), which is a very promising line of research as large comparable corpora are much easier to obtain from the rich web data. Fourth, there are many more features that could be used for lexical disambiguation still keeping our development process lightweight (i.e. without the need for advanced NLP tools that are rarely available for most languages, such as parsers or WSD systems). Such features could include Lesk-like measures for comparing contexts of definitions or glosses; similarity between cognates, etc. And last but not least, since our approach has already proven efficient and useful for two languages as different as French and Slovene (Sagot and Fis  X  er 2008 ; Fis  X  er and Sagot 2008 ; Sagot and Fis  X  er 2011 , 2012a , b ), for which the amount and nature of the available sources is very different as well, we would like to create wordnets for other under-resourced languages, such as Croatian.
We believe the work presented in this paper has two main consequences. First, it shows that it is possible to build large-scale reliable wordnets with fully automatic approaches (although manual work was involved in intermediate steps of the construction process, it has affected only a small number of senses included in the latest version of sloWNet). Second, this work has resulted in a freely available lexical semantic resource for a language that was lacking such a resource, which is large and accurate enough to be used in real NLP applications. The developed sloWNet is distributed under the Creative Commons BY-SA 3.0 licence at http://nl.ijs.si/sloWNet .
 References
 Abstract In this paper we present a language-independent, fully modular and automatic approach to bootstrap a wordnet for a new language by recycling different types of already existing language resources, such as machine-readable dictionaries, parallel corpora, and Wikipedia. The approach, which we apply here to Slovene, takes into account monosemous and polysemous words, general and specialised vocabulary as well as simple and multi-word lexemes. The extracted words are then assigned one or several synset ids, based on a classifier that relies on several features including distributional similarity. Finally, we identify and remove highly dubious ( literal, synset ) pairs, based on simple distributional information extracted from a large corpus in an unsupervised way. Automatic, manual and task-based evaluations show that the resulting resource, the latest version of the Slovene wordnet, is already a valuable source of lexico-semantic information.
 Keywords Wordnet development Multilingual lexicon extraction Word-sense disambiguation Distributional similarity 1 Introduction Motivation. In the past decade, the role of lexical knowledge has increased in many areas of natural language processing as it has been shown that exploiting lexical resources benefits the performance of various tasks. For example, Gabrilovich and Markovitch ( 2006 ) have demonstrated that using encyclopaedic knowledge improves automatic document classification. Similarly, Nastase ( 2008 ) have employed it to help text summarisation. An improvement in a question-answering system that takes advantage of dependencies between words in a lexico-semantic network has been achieved by Harabagiu et al. ( 2000 ), the advantages of which have also been shown in word-sense disambiguation (Cuadros and Rigau 2006 ) and machine translation tasks (Carpuat and Wu 2007 ).

Several frameworks for organising and representing lexical knowledge have been proposed, such as ACQUILEX 1 (Copestake et al. 1993 ), Roget X  X  Thesaurus 2 (Kirkpatrick 1987 ), MindNet 3 (Richardson et al. 1998 ), ConceptNet 4 (Liu 2003 )or Cyc 5 (Matuszek et al. 2006 ). But one of the best known and most widely used lexico-semantic resources for natural language understanding and interpretation as well as in Semantic Web applications are Princeton WordNet (Fellbaum 1998 ) and its sister wordnets for languages other than English, developed within projects such as EuroWordnet (Vossen 1999 ), BalkaNet (Tufis  X  2000 ), AsianWordNet (Sornlert-lamvanich 2010 ) and the most recent project, called the Open Multilingual Wordnet 6 that has normalised and merged all the wordnets that allow redistribution, and currently contain wordnets for 27 languages (Bond and Foster 2013 ).
While it is true that wordnets were originally constructed manually in order to maximise linguistic soundness and accuracy of the developed database, such an endeavour is too time-consuming and expensive to be feasible for many languages still lacking a wordnet. This is why semi-or fully automatic approaches have become popular, which exploit various types of existing resources to facilitate the development of a new wordnet. However, a common problem with automatically induced wordnets is the necessary trade-off between limited coverage and the desired level of accuracy, both of which are required if the developed resource is to be useful in a practical application. An important advantage of our approach compared to related work is that our approach is much more lightweight and straightforward: it does not require complex processing available only for some languages (e.g., computing parses for syntactical distributional similarity), lan-guage-dependent rules (e.g., patterns for extracting hypernymy relations) or costly lexical resources (e.g., large-scale thesauri).

Contribution. In this paper we present a two-step automated approach for building wordnets. The approach is language-independent as shown with its successful application to the development of the French wordnet WOLF (Sagot and Fis  X  er 2008 ). It is suited for research scenarios that do not allow for long-running resource development by a team of professional lexicographers. Instead, it recycles different types of resources that are already available for the target language, such as machine-readable dictionaries, parallel corpora and Wikipedia in a way that maximises the amount of extracted lexical information from each type of the resource used. The created wordnets are directly aligned to Princeton WordNet as well as among each other. They can therefore be used in multilingual tasks, such as machine translation, cross-lingual information retrieval and question answering, the demand for which is growing with the increased multilinguality of the web (Nie 2010 ). As opposed to most related work relying solely on Wikipedia, our approach is not limited only to nominal concepts but can handle all parts-of-speech. Our approach is also comprehensive in that we handle monosemous and polysemous words, general and specialised vocabulary as well as simple and multi-word lexemes.

Preliminary and partial versions of the full methodology described here were already used for building the first freely available wordnet for Slovene (Fis  X  er and Sagot 2008 ). However, since the first version, our techniques have been substantially refined and extended. In this paper, we recall how the first versions of sloWNet were built and, more importantly, how the refinements allowed us to more than double its size while increasing its overall accuracy. The result is the first freely available semantic lexicon for Slovene wordnet called sloWNet.

Overview. This paper is structured as follows: in Sect. 2 we give an overview of related work. In Sect. 3 we describe the process of extracting lexico-semantic information from structured, semi-structured and unstructured resources. In Sect. 4 we explain the two-step process used for merging this information and constructing sloWNet: we first built restricted resources containing only the literals with the highest certainty level and then used these in a large-scale enrichment step as training data for a maximum entropy classifier used for computing whether a less certain literal extracted from the existing resources is an appropriate candidate for a given synset. Section 5 is dedicated to the evaluation of the created resource, and Sect. 6 discusses the results and points towards future directions of research. 2 Related work Automatic techniques for wordnet development can be divided in two approaches: the merge approach and the extend approach (Vossen 1999 ). In the merge approach, an independent wordnet for a certain language is first created based on monolingual resources and then mapped to other wordnets (Rudnicka et al. 2012 ). In the extend approach, which we used in this work, a fixed set of synsets from Princeton WordNet (PWN) are translated into the target language, preserving the structure of the original wordnet. The extend approach relies on the assumption that concepts and semantic relations between them are language independent, at least to a large extent. Apart from faster and cheaper construction of the lexical resource, the biggest advantage of this approach is that the resulting wordnet is automatically aligned to all other wordnets built on the same principle and therefore available for use in multi-lingual applications, such as machine translation and cross-language information retrieval.

The downside of the expand approach is that the target wordnets inherit any inconsistencies in PWN but are also biased by PWN and may, in an extreme case, become arbitrary (Orav and Vider 2004 ), (Wong 2004 ). For example, PWN contains a synset { performer , performing artist } which is defined as an entertainer who performs a dramatic or musical work for an audience . However, there is no word or phrase in Slovene that denotes the concept describing actors and singers collectively. Such cases have been dealt with in several wordnet development projects by providing the closest possible match for the synset and aligning the two wordnets with a near_synonym relation. In this way, the overall structure of straightforward cases remained intact and the exceptions encoded. Despite these difficulties, the approach is still attractive due to its much greater simplicity, which outweighs the language difference issues. What is more, the fact that the resulting resource is aligned with the PWN, and therefore also with all other resources and tools that follow the PWN principles, is highly valuable. This is why the expand model has been adopted in a number of recent projects, such as the BalkaNet (Tufis  X  2000 ), MultiWordNet (Pianta et al. 2004 ) and BableNet (Navigli and Ponzetto 2010 ). With this we do not suggest that the expand approach is universally superior to the merge approach but that in our research settings, and we believe this applies to many other researchers as well, it was the optimal one. As a result, issues regarding the inventory or the relative position of synsets in the resulting semantic network do exist, but analysing them and adapting wordnet structure accordingly lies beyond the scope of this study.

Under the setting of the expand approach, approaches vary according to the type of resources that are available for the construction of a wordnet in a particular language. Early approaches link English entries from machine-readable bilingual dictionaries to PWN synsets under the assumption that their counterparts in the target language correspond to the same synset (Knight and Luk 1994 ; Yokoi 1995 ). A well-known problem with this approach is that bilingual dictionaries are generally not concept-based but follow traditional lexicographic principles, which is why the biggest obstacle is the disambiguation of dictionary entries. Also, bilingual machine-readable dictionaries often have limited coverage or are not digitally available for the relevant language pair at all.

This problem is overcome by a different set of approaches in which bi-or multilingual lexicons are extracted from parallel corpora (Resnik and Yarowsky 1997 ; Fung 1995 ). The main underlying assumption in these approaches is that senses of ambiguous words in one language are often translated into distinct words in another language. Furthermore, if two or more words are translated into the same word in another language, then they often share some element of meaning. This results in sense distinctions of a polysemous source word or yields synonym sets. As a result, parallel corpora have been utilised to induce synsets for a new language (Dyvik 2002 ; Ide et al. 2002 ; Diab 2004 ).

The third set of approaches that have become popular in the past few years draw upon Wikipedia, a large-scale collaborative encyclopaedic resource available for many languages. New wordnets have been induced by associating Wikipedia pages with the most frequent WordNet sense (Suchanek et al. 2008 ) by using structural information to assign Wikipedia categories to WordNet (Ponzetto and Navigli 2009 ) or by extracting keywords from Wikipedia articles (Reiter et al. 2008 ). Vector-space models have been developed to map Wikipedia pages to WordNet (Ruiz-Casado et al. 2005 ; Declerck et al. 2006 ). The most advanced approaches use Wikipedia and related projects, such as Wiktionary, to bootstrap wordnets for multiple languages (de Melo and Weikum 2009 ; Navigli and Ponzetto 2010 , 2012 ).
Our attempt in the construction of sloWNet has been designed to benefit from the combination of the available resources, which were of three different types: general and domain-specific bilingual dictionaries, parallel corpora and Wiki resources (Wikipedia and Wiktionaries). A basic version of the approach has already proved to be successful in our previous work where we created an initial Slovene wordnet drawing from these resources (Erjavec and Fis  X  er 2006 ; Fis  X  er and Sagot 2008 ). The focus in this paper, however, is to take the approach a step further and not limit the extraction of translations to monosemous words only but to extend it to polysemous words as well in order to take full advantage of each resource and at the same time mitigate the limitations each one of them brings by weighting candidates for synsets according to a selection of features. 3 Automatic extraction of lexico-semantic information In this section we describe the extraction of translation pairs from three types of resources: structured (general and domain-specific dictionaries and lexica), semi-structured (Wikipedia articles) and unstructured (parallel corpora). In the extraction process our task is to extract as many translation variants for each word or multi-word expression as possible in order to capture as many of its senses as possible. The goal of the procedure is to obtain wordnet candidates from the extracted translation pairs in the form of pairs consisting of a literal and its synset, i.e. translation of a source word with an assigned synset id from wordnet.

The acquisition of Slovene wordnet candidates is based on PWN concepts (synsets) and proceeds as follows: we take a PWN literal which appears in several synsets (say, n s synsets) and has many possible translations (say, n t translations) according to the information extracted from the various resources. Our aim is therefore to select the best candidates among the n s : n t possible ones by disambiguating each of these translations either in context thanks to parallel corpora, or out-of-context for all translation pairs extracted from dictionaries and Wikipedia. If the PWN literal is monosemous, 7 we simply assign the same concept (its synset id) to its translation. If the PWN literal is polysemous, we choose the best synset id for its translation by defining a synset proximity metric that is based on the initial restricted version of the Slovene wordnet. 3.1 Extracting lexico-semantic information from structured resources Bilingual dictionaries are very rich sources of lexico-semantic information that have already been compiled, analysed and structured, which is why they are an obvious first choice for harvesting the lexico-semantic information needed to populate a wordnet for a new language. Most bilingual dictionaries contain very little noise, have good coverage of general vocabulary across all parts of speech, contain translations for several senses of polysemous words and sometimes even definitions. However, bilingual dictionaries provide non-contextualised information and even when sense distinctions are explicitly encoded in the dictionary structure they are usually coarser-grained than PWN, which is why dictionary entries cannot be mapped directly to PWN concepts. Our approach for assigning synset ids to the translation pairs we extracted from dictionaries is described in Sect. 4 . Here we present the dictionaries we used, the extraction process and the results we obtained.
Wiktionaries 8 are freely available collaboratively constructed bilingual dic-tionaries which were originally designed as lexical companions to Wikipedia. They contain definitions of words as well as some additional information, including their translations into other languages which are sometimes structured into senses. We used English and Slovene Wiktionaries and extracted translation pairs for all parts-of-speech from these two resources on the basis of translation sections within the articles. However, Wiktionaries do not (yet) have good coverage of Slovene, which is why the number of lexicon entries we were able to extract is relatively low: 7,029 translation pairs from the Slovene Wiktionary and 6,052 from the English Wiktionary. For each entry, we also tried to extract a gloss based either on the first sentence of the Wiktionary article, or, if available, from the short glosses associated with each sense.

In order to extract the general vocabulary that was largely missing in Wiktionary, we used a digitised traditional English X  X lovene (Grad et al. 1999 ) and a Slovene X  English dictionary (Grad and Leeming 1999 ). The dictionaries do not contain definitions but we were able to harvest 207,972 translation pairs from the English X  Slovene dictionary and 72,954 from the Slovene X  X nglish one.

For domain-specific vocabulary we used Wikispecies , 9 which is a taxonomy of living species that includes Latin standard names as well as vernacular terms for the common species. This allowed us to extract 2,360 English X  X lovene pairs. In a similar way, we obtained 31,702 translation English X  X lovene pairs from the domain-specific thesaurus Eurovoc , 10 an on-line dictionary of informatics islovar 11 and a military glossary (Koros  X  ec et al. 2002 ).

The result of our extraction process is a large bilingual lexicon containing 282,789 unique English X  X lovene translation pairs with the name of the resource(s) they originate from. The figures for this extracted bilingual lexicon are summarised in the upper part of Table 1 . 3.2 Extracting lexico-semantic information from semi-structured resources Less structured than dictionaries but still with a much more predefined structure than free text is the on-line multilingual collaborative encyclopaedia Wikipedia . 12 We used English and Slovene Wikipedia for extracting a bilingual lexicon by following inter-language links that relate two articles on the same topic in the two corresponding Wikipedias. We enhanced the extraction process with a simple pattern-based analysis of article bodies based on regular expressions. More precisely, we first looked across each article body for all non-sentence-initial occurrences of its title, ignoring capitalisation, and compared the relative frequency of all capitalisation variants. This allowed us to resolve ambiguities arising from the capitalisation of article titles (e.g., Grass_author , Grass_plant ). Our pattern-based analysis allowed us also to extract relevant information from the structure of the first sentence of each article, thus identifying synonyms for the key terms (e.g., Cannabis , also known as marijuana ), their definitions (e.g., Hockey is a family of sports in which two teams play against each other by trying to manoeuvre a ball or a puck into the opponent X  X  goal using a hockey stick. ) and usage examples (e.g., The true grasses include cereals, bamboo and the grasses of lawns (turf) and grassland. ). It would also be possible to further analyse article bodies in order to extract other semantically related terms (e.g., hockey: sports [hypernym], hockey: ball, puck, goal, hockey stick [meronym] ) which we plan to do in our future work.
As a result, we obtained 32,669 Slovene X  X nglish entries that are predominantly nouns or nominal multi-word expressions (common or proper), yielding 32,161 unique translation pairs (see Table 1 ). 3.3 Extracting lexico-semantic information from unstructured resources The final type of the resources used in our experiment are the unstructured resources, that is free text. We used the SEE X  X RA.NET corpus (Tufis  X  et al. 2009 ), a 1.5-million-word subcorpus of JRC-Acquis (Steinberger et al. 2006) in eight languages. Apart from Slovene, we used English, Romanian, Czech and Bulgarian. We used different tools to PoS-tag and lemmatise the corpus before word-aligning it with Uplug (Tiedemann 2003 ). Because word-alignment was performed on single words only, we were not able to generate any translation equivalents for multi-word expressions. The output of the word alignment process is a file with word links between word occurrences and information on word link certainty.

This allowed us to build bilingual lexicons that include all translation variants of words as well as frequency, part-of-speech and token id information for each entry. Note that we base this decision on the fact that the quality of word-alignment is far from perfect in general but is improved when the languages in question are closely related, as is the case for example for Slovene and Czech. The bilingual lexicons we extracted range from 43,024 entries for the cs X  X n lexicon to 50,289 for the cs X  X g one. These bilingual lexicons are then combined into five multilingual lexicons which all involve at least Slovene and two other languages. They contain between 52,193 (Slovene X  X zech X  X nglish) and 55,768 (Slovene X  X zech X  X ulgarian X  X nglish) entries (see details in Table 2 ). Obviously, not all these candidates are correct; errors may appear for several reasons, such as tagging, lemmatisation, or alignment problems. However, many of these errors are eliminated in the next stage of the process. 3.4 Assigning synset ids to translation pairs As explained above, creating or expanding a wordnet by preserving PWN structure and synset inventory can be viewed as generating ( literal, synset ) pairs. This is achieved by assigning synset ids to the extracted translation pairs. The resources we used can be divided in two groups: lexicon-based and alignment-based resources, the difference between them being that lexicon-based entries are not associated with a particular occurrence in a particular context while the alignment-based entries are. This is why the process of assigning synset ids differs for these two groups. The lexicon-based bilingual entries we extracted are extremely valuable because they are far more numerous and accurate than word-alignment based information.

Let us consider for example the following English X  X lovene entry we extracted from Wiktionary:  X  organ en ; organ sl  X  . It does not contain any information that would make it possible for us to determine which of the 6 PWN synsets containing organ en as a literal would be appropriate to be translated with organ sl in sloWNet. In this case, only the  X  X ody part X  sense of English organ en can be translated as organ sl in Slovene, but not the  X  X usical instrument X  sense (which translates as orgle en ). In Wiktionary articles, translations of a given word are sometimes organised by senses that are associated with short glosses. These have been compared to PWN glosses in order to map Wiktionary senses to PWN synsets (Bernhard and Gurevych 2009 ; Casses 2010 ). The first sentence of a Wikipedia article can be used in a similar way (Ruiz-Casado et al. 2005 ). However, this is not the case for all Wiktionary entries or other resources in this category. We therefore decided to assign a synset id only to those translation pairs that contain a monosemous English word and postpone the disambiguation of polysemous lexicon-based entries to a later stage (see Sect. 4 ).
On the other hand, alignment-based entries contain contextual information that enables semantic disambiguation, as they are composed of translation equivalents which have been word-aligned at least once in the multilingual corpus. For each entry, we gathered the set of all possible synset ids associated with each word in each language involved (apart from Slovene) using the corresponding BalkaNet wordnets (Tufis  X  2000 ). Since all BalkaNet wordnets use the same synset inventory and synset ids as PWN, we were then able to compute the intersection of ids for all languages. The result contains all synset that are shared among all non-Slovene literals in this particular multilingual lexical entry. We then assigned these synset ids to their Slovene equivalent.

To illustrate this process, Table 3 shows how a few entries from the en X  X s X  X o X  bg X  X l lexicon are disambiguated and associated with a synset id, thus generating (literal, synset) candidates. The first two 5-lingual entries provide different translation variants for the English noun  X  X arty, X  which are strana (cs), partid (ro), these words appear in in the respective wordnets shows that the translation variants from the two lexicon entries do not have any synset ids in common, which suggests that they are translations of different senses of the polysemous English noun  X  X arty X . A different intersecting synset id in each lexicon entry is therefore assigned to their Slovene translations, which results in generating two different Slovene candidates, namely ( stranka , 07758173) for the  X  X olitical party X  sense and ( zabava , 07753857) for the  X  X ocial occasion X  sense. On the other hand, the last two entries in the lexicon are for the English word  X  X rmy X  and are the same in all languages except in Slovene. Since translation variants in both lexical entries share the same intersecting synset id, it is assigned to both Slovene variants. This generates two synonym candidates (i.e. the synset id in both candidates is the same), namely ( armada , 07686671) and ( vojska , 07686671). Using multiple language in this way on polysemous lexical entries eliminates most alignment errors. Indeed, it is rather unlikely that the same polysemy occurs in many different languages or that alignment errors lead to a non-empty intersection. Therefore, the intersection of all possible senses in each language is likely to output only the correct synset id(s). Obviously, this is even more so when using more different languages than when using only one language apart from English and Slovene, which is the minimum required for the intersection to actually be possible. On the other hand, the more languages are used, the more reliable but the less numerous the generated candidates will be because intersecting more translation sets in more languages can only lead to a smaller intersection.

Applied to the above-mentioned multilingual lexicons, this technique yielded five different sets of candidates filling different synsets with at least one Slovene literal. They include between 1,364 (sl-ro-cs-bg-en) and 4,232 (sl-cs-en) entries. Because the pre-processing stages, such as tagging, lemmatisation and word-alignment were not perfect, it is expected that the synsets created in this way will inherit some of the errors which will hopefully be filtered out by the classifier (see Sect. 4.3 ). 4 Automatic induction of synsets for wordnet extension The development of the initial sloWNet was achieved in a three-step process. First, we created baseline versions of wordnets (Fis  X  er and Sagot 2008 ) by using only ( literal, synset ) pairs obtained from the parallel corpus which could be disam-biguated based on other languages, and monosemous words extracted from the dictionaries, lexica and Wikipedia which required no disambiguation. Such a restricted wordnet was relatively reliable but did not use full potential of the available resources. This is why, after making a few improvements on this initial sloWNet, we performed a large-scale extension process, aiming at taking full advantage of the resources and improving the coverage of the resource without lowering its accuracy (Sagot and Fis  X  er 2011 ). In this section we briefly describe the two first steps and then give a detailed account of the novel extension step. 4.1 Developing baseline wordnets The first step in the development of sloWNet was achieved in 2008, when the first version was created (Fis  X  er and Sagot 2008 ). 13 For this first step only monosemous PWN literals were translated using bilingual resources, thus avoiding disambigua-tion issues. However, all PWN literals were used for adding target language literals in the synsets found by the alignment-based approach. If the same ( literal, synset ) pair was created from more than one resource (e.g., from a multilingual lexicon that was extracted from the word-aligned corpus and from a bilingual lexicon that was extracted from Wikipedia), the information on the source of the generated synset was retained. This enabled us to perform a simple heuristic filtering according to the reliability of each resource, on the number of different resources that assign a given literal to the same synset and on frequency information (for resources from the alignment approach).

Automatic insertion of Slovene literals to synsets inevitably leads to gaps in the hierarchy. Because we are aware of the importance of the conceptual density and hierarchy preservation principles for applications (Tufis  X  2000 ), we inherited the structure and relations of the missing synsets from PWN, thus leaving many empty synsets. Therefore, in case an application runs into an empty synset, it can still use the relation information to access a more general concept. Other language-independent information (e.g., PoS, domain, semantic relations) was inherited from the PWN as well. We also adopted the three Base Concept Sets (BCS) which were introduced in the BalkaNet project (Tufis  X  and Cristea 2002 ) and comprise 8,516 synsets that have been commonly agreed to be implemented by all consortium members in order to obtain a guaranteed overlap of lexicalised concepts between the BalkaNet languages, such as building , vehicle , animal , etc. The Base Concepts are the concepts that play the most important role in the various wordnets of different languages. This role is measured in terms of two main criteria: (1) a high position in the semantic hierarchy and (2) having many relations to other concepts (Weisscher 2013 ). The Base Concepts play a crucial role in wordnet building that is typically top-down: first, a core wordnet is developed around the Base Concepts that contains about 5,000 X  10,000 synsets and is highly compatible in coverage and semantic interpretation with wordnets in other languages, and then the core wordnet is extended beyond 20,000 synsets in a top-down fashion, given the semantic basis of the core wordnet.
The figures for the first version of sloWNet (version 2.0) are given in the second column in Table 4 , together with corresponding figures about PWN 2.0, and more recent versions of sloWNet (version 2.2 and version 3.0 resulting from the work described in this paper). 4.2 Enhancing baseline sloWNet After the restricted and automatically produced version of sloWNet (version 2.0) was built, it underwent some improvement steps. First of all, because legal aspects regarding the use of the traditional English X  X lovene and Slovene X  X nglish dictionaries were unclear, we re-ran all experiments without using this resource. Second, due to poor parsing of Wikipedia articles, many synsets contained duplicate literals that were identical except in stress markings (e.g., kolo and kol X  ) which were therefore normalised and merged. Since sloWNet was used for manual semantic annotation of a corpus (Fis  X  er and Erjavec 2009 ), it was also extensively manually edited in order to delete erroneous senses of words that were annotated and add the missing ones. This is why the published Slovene baseline wordnet (version 2.2), used during the large-scale extension experiments described in the next section, is significantly different and smaller than the automatically produced version 2.0. Finally, sloWNet 2.2 uses the synset inventory from PWN 3.0, whereas sloWNet 2.0 uses the synset inventory from PWN 2.0. 14 Note however that, in the end, we did use the traditional dictionaries during that large-scale extension step. 4.3 Large-scale wordnet extension Restricting the use of a bilingual lexicon to monosemous English literals is a safe but limited approach that does not exploit the available resources to their full potential. However, using lexicon-based candidates generated from polysemous English literals is only possible if we can establish the likelihood with which a word should be added to a particular synset, i.e. can compute the semantic distance between a given Slovene literal and synset id. We designed such a technique based on the already-existing Slovene wordnet (version 2.2) and we present it in this section. 4.3.1 Using a probabilistic classifier Our technique relies on a probabilistic classifier that uses various features associated with each ( literal, synset ) candidate. The underlying idea is as follows: we have a baseline wordnet at our disposal, and a large set of lexicon-based candidates to evaluate. We extract all ( literal, synset ) pairs that are already in the baseline wordnet and consider these candidates as valid ones while all the other candidates are considered invalid, thus creating a  X  X  X opper standard X  X , i.e. a reasonable although noisy training set for a probabilistic model. The training set is noisy for two reasons: first, the baseline wordnet itself contains noise because not all synsets were manually validated; second, and more importantly, many of our new candidates are valid even though they are not in the baseline wordnet. In fact, such candidates are exactly those that we are looking for to extend our wordnet. In order to use the copper standard as the training set for a classifier, we need to extract suitable features for the candidates which was performed with the Maximum-Entropy package megam (Daume  X  2004 ) based on the features described below. The result of our classifiers on training data is a certainty value between 0 and 1. We empirically set the threshold at 0.1 (see Sect. 6.1 for motivations for this value) and added all the candidates that pass the threshold to the wordnet. 4.3.2 Feature selection This section contains a description of the features we used to train our candidate evaluation models. The most important feature models the semantic proximity between a literal and a synset. Let us illustrate it on the previous example  X  organ en ; organ sl  X  . In PWN (3.0), 6 synsets contain the literal organ en , which is why we also generate 6 different ( literal, synset ) candidates from the bilingual entry  X  organ en ; organ sl  X  . We now need to know which of these 6 candidates are valid, i.e. to which of the 6 corresponding synsets the Slovene literal organ sl should be added in sloWNet. We therefore compute the semantic similarity of the Slovene literal organ sl w.r.t. each of these 6 synsets.

We first represent each sloWNet synset by a bag of words obtained by extracting all literals from this synset and all the synsets up to two nodes apart in sloWNet, i.e. related via a path of length at most two involving any type(s) of lexical relation(s). 15 For example, the synset f organ en ; pipe organ g in PWN is represented by the bag of words { glasbilo , Anton Bruckner , glasbenik , Johann Sebastian Bach , pisalni , klavirska , harmonika ,...} ( X  X usical instrument, X   X  X nton Bruckner, X   X  X usician, X   X  X ohann Sebastian Bach, X   X  X riting adj , X   X  X iano adj , X   X  X ccordion, X   X  X evice, X ...).
Next, we use a distributional semantic model for evaluating the semantic similarity of orgle w.r.t. this bag of words. We use the freely-available SemanticVectors package (Widdows and Ferraro 2008 ), 16 which relies on the Lucene indexing system. 17 This package is able to build a word-document frequency matrix from a large set of documents, reduce the dimensionality of this matrix by a random projection technique, and finally extract one semantic vector per word from this reduced matrix. The package then allows for assessing the distributional semantic similarity of two bags of words using Latent Semantic Analysis. The documents we used for building such distributional semantic models are 334,000 lemmatised paragraphs from the FidaPLUS corpus (Arhar and Gorjanc 2007 ) (180,000 distinct lemmas). 18 Applied to our example, the semantic similarity between organ sl and the synset { organ en , pipe organ } is only 0.021, while the similarity between organ sl and one of its valid synsets, f organ en g , defined as a fully differentiated structural and functional unit in an animal that is specialised for some particular function , is 0.668. Indeed, in Slovene, organ sl has the  X  X ody part X  meaning but not the  X  X usical instrument X  ( orgle , in Slovene).

Apart from that semantic similarity measure, the other features we used are the target language, here Slovene) that has been generated because our bilingual l  X  X  are among s  X  X  literals. The number of such PWN literals is one of the features. Each possible source (e.g., the English wiktionary) corresponds to one feature, which receives value 1 if and only if at least one of the  X  l e ; i ; l t  X  bilingual lexical entries was extracted from this source. Moreover, we extract the lowest polysemy index among all the occurences of l e ; i . For example, if the least polysemous l e ; i is in two PWN synsets, this feature receives value 2. The idea is that if the candidate is generated from at least one monosemous PWN literal, then it is very likely to be correct, whereas if it is generated from only highly polysemous PWN literals, it is much more questionable. Finally, the number of tokens in l t is used as a feature as well (literals with many tokens are usually not translations of PWN literals but rather glosses that arise from Wikipedia or Wiktionary, and are therefore incorrect). 4.3.3 Building classification models The resulting models are shown in Table 5 . They clearly show that semantic similarity is relevant and useful as it is the feature with the highest weight. As expected, the lowest polysemy index among English literals also contributes positively, as does the number of different English literals yielding the generation of the candidate, and the number of sources involved. On the other hand, as predicted as well, the number of tokens in the target language literal negatively contributes to the certainty score. Finally, the different sources are also associated with a weight. 4.3.4 Results of the classification After having trained these models, we used them to score all 685,633 Slovene candidates generated from our bilingual resources as explained in Sect. 3.4 . Using the above-mentioned threshold on the models X  output, we retained 68,070 candidates. Among these candidates, 5,056 (7 %) correspond to ( literal, synset ) pairs already present in sloWNet 2.2, which means that 63,014 (93 %) new ones were added; as a consequence, 25,102 synsets that were previously empty in sloWNet now have at least one Slovene literal.

Quantitative information on the resulting wordnets (sloWNet 3.0) is provided in the last column of Table 4 . In short, sloWNet 3.0 has as much as 141 % more non-empty synsets than before the extension. As far as ( literal, synset ) pairs contained in the resources are concerned, the increase is even higher: the extension of sloWNet has increased the number of such pairs from 24,081 to 82,721 ( ? 244 %). The evaluation of the newly added ( literal, synset ) pairs is described in Sect. 6.1 . Evaluations of the resulting extended resource with respect to other wordnets (a gold standard Slovene wordnet and two other automatically generated wordnet-like semantic repositories) is given in Sects. 6.3 and 6.4 . A task-based evaluation in a machine translation setting is given in Sect. 6.5 . 5 Cleaning noisy synsets Despite the satisfying results obtained in the previous section, the technique we used, as all state-of-the art methods for the population of wordnets, is still far from perfect, resulting in noisy synsets. This is why we developed a language-independent, corpus-based approach to detect outliers in automatically generated synsets and filter them out in order to obtain a cleaner, more useful lexico-semantic resource for human use as well as for various NLP tasks (Sagot and Fis  X  er 2012 ).
The cleaning approach falls within the scope of distributional methods for detecting semantic similarity between words (Lin et al. 2003 ), but instead of identifying most closely related words according to the contexts they appear in, we start from a (noisy) list of synonym candidates in the form of an automatically induced wordnet. In a way, our task is not very different from the lexical substitution framework (Mihalcea et al. 2010 ), with the exception that we are most interested in the bottom of the ranked list of potential synonyms. In addition, our notion of synonymy is much stricter because it is our aim to clean all the synsets in an automatically created wordnet, which is very fine-grained.

At the same time, the notion of polysemy that is of key importance for this work is translation-motivated. This means that regardless of the number of synsets a word appears in, the distinction between those senses that are lexicalised differently is the only relevant one in this work.

We focused on identifying and eliminating the most obvious errors in synsets that occurred due to errors in word-alignment of parallel corpora (e.g. misaligned elements of multi-word expressions) and inappropriate word-sense disambiguation of homonymous words (e.g. assigning a valid translation of one sense of a homonymous source word to all its senses). It is precisely these errors in wordnets that have the biggest impact in NLP applications and decrease the value of the resource the most.

Our approach for cleaning noisy synsets relies on a simple hypothesis: lexemes, defined here as ( literal, synset ) pairs, tend to co-occur in corpora with other lexemes that are semantically related, as made explicit by relations between synsets in a wordnet. This is possible because, provided that the wordnet is large enough, this technique can provide a sufficient number of semantically related lexemes for most lexemes with a high precision (the precision of sloWNet 3.0 has been evaluated as 86 %, see Sect. 6 ).

The method we used for cleaning our wordnets can be divided in two steps: 1. Co-occurrence-based evaluation of the similarity between each nominal 2. Global assessment of all nominal ( literal, synset ) pairs based on these similarity 5.1 Basic co-occurrence-based scoring of (literal, synset) pairs In order to achieve step 1 in the enumeration above, we first associate each synset from the input wordnet with a set of related synsets, i.e. a subset of all synsets (nominal or not) that are related to the base synset by relation paths of length 0, 1 or 2, based on manually designed relation patterns shown in Fig. 1 . Second, we associate each synset pair with the list of its related literals, i.e. all literals that belong to any of its related synsets.

Next, given an occurrence of a nominal literal in the corpus, we look at all literals that co-occur in the same paragraph. We chose paragraphs as contexts because sentences are too small to provide us with enough literals, and because paragraphs constitute the smallest linguistically motivated and typographically discernible text units that are larger than sentences. We then apply a variant of the wordnet-based Lesk algorithm for word sense disambiguation (Lesk 1986 ). Lesk X  X  algorithm relies on the assumption that the relatedness of two words is proportional to the extent of overlaps of their dictionary definitions. This algorithm was later extended to also use literals from related synsets as well as wordnet usage examples in addition to the dictionary definition (Banerjee and Pedersen 2002 ). We adapted this idea to our task, by comparing each paragraph where a given literal occurs, represented by its content words (co-occurring literals) with each possible synset for this literal, represented by the literals found in their respective sets of related synsets, as defined above.

More formally, let l be a nominal literal in paragraph p . We refer to the set of all synsets containing a literal l 0 in the input wordnet as S  X  l 0  X  , and to the number of such synsets j S  X  l 0  X j . Let C  X  p  X  be the set of (PoS-tagged) literals in paragraph p , and related to a synset s in the input wordnet as R  X  s  X  . Finally, let length  X  p  X  be the receives for paragraph p a local score local score  X  l ; s ; p  X  defined as follows: The corpus-wide score global score  X  l ; s  X  for the (literal, synset) pair  X  l ; s  X  is then simply the sum of the local scores of each of its occurrences: Let us illustrate this on an example. Consider the Slovene noun ikona ( X  X con (religion) X  or  X  X con (computer science) X ). It appears in 4 synsets in sloWNet 3.0, among which:  X  eng-30-07269916-n { icon }; the Slovene literal ikona is correct in this synset;  X  eng-30-03931044-n { icon , ikon , image , picture }; the Slovene literal ikona is not In our corpus, the Slovene noun ikona occurs 3,488 times. The global score for the correct ( ikona , eng-30-07269916-n) pair, based on the above-mentioned related literals, is only 1.02, whereas that for the incorrect ( ikona , eng-30-03931044-n) pair it is 5.99. This shows that global scores do not necessarily allow us to correctly detect the erroneous ( literal, synset ) pair. Therefore, we take into account additional information, as shown in the next section. 5.2 Extracting outlier candidates for ( literal, synset ) pairs At this stage, we have for each ( literal, synset ) pair a global score that is the sum of the local scores of its occurrences in the corpus. We first normalise this global score by pairs involving the same synset s . This is used to assess the contribution of a given literal the input wordnet. We define synset global score  X  s  X  in a straightforward way: The contribution of l to the synset s is then: This contribution is then normalised by the number of occurrences occ  X  l  X  of the If we go back to the example given in Sect. 5.1 , the synset global score for eng-30-07269916-n is 1.02, and is 234 for eng-30-03931044-n. Their respective contribu-tions are thus 1 and 0.026. Consequently, our last formula leads to a score of 0.287 for ( ikona , eng-30-07269916-n), whereas the score for ( ikona , eng-30-03931044-n) is 0.007. The final score now correctly identifies the correct vs. incorrect (literal, synset) pairs. Additional examples are provided together with their manual evaluation in Sect. 6.6 , which is, along with Sect. 6.7 , dedicated to evaluation and validation procedures of outlier candidates. 6 Evaluation of the results In previous sections we have described the development of sloWNet: first, we developed a baseline version (sloWNet 2.0), second, we performed some manual improvements of the generated wordnet, and third, we extended the resulting sloWNet (version 2.2) with additional lexical information and identified outliers. Because only the final two steps are novel and because they have contributed to a considerable increase compared to previous versions, we begin with a manual evaluation of the extension step. We evaluate the accuracy of the candidates we obtained as well as the accuracy of the candidates we discarded. Next, we perform two series of contrastive evaluations of the extended wordnet. With this we will gain insight into the precision and recall of the wordnets we created, before and after the extension. First, we compare it with a small-scale gold standard, a small, manually constructed wordnet for Slovene (SWN). Second, we compare it with other automatically generated wordnets, namely the multilingual Universal WordNet (UWN) (de Melo and Weikum 2009 ) and the latest version of BabelNet (version 2.0) (Navigli and Ponzetto 2010 , 2012 ). Finally, we illustrate how this extended wordnet performs in task-based settings. In addition, we also provide insights into the quality of the outlier detection task, via manual assessments by an expert and crowdsourcing-based validation results.

In all our evaluation settings we assess if the synset assigned to a given literal is correct (i.e. if it is an appropriate lexicalisation of the concept in question). In order for the candidate to be considered valid, it has to be a perfect match for the assigned synset; if the literal denotes a more general or more specific concept (a hyper-or hyponym) than the concept represented by the synset in question, it is marked as incorrect. 6.1 Manual evaluation of the wordnet extension step Before evaluating sloWNet as a whole, we wanted to measure the accuracy of our extension approach (see Sect. 4 ). We therefore randomly selected 400 (literal, synset) candidates and evaluated them manually. Since we have found that the errors performed by the automatic sense assignment step are not very fine-grained, we did not see the need to check inter-annotator agreement. Instead, manual evaluation was performed by a single annotator who used only two tags:  X  X  X ES X  X  if it was correct to add that literal to the synset, and  X  X  X O X  X  if it was wrong, regardless of the reason for the error and its semantic relatedness to the synset. The accuracy of a set of candidates is as usual the proportion of candidates receiving the  X  X  X ES X  X  tag. Moreover, in order to assess the quality of our scoring technique, we compared the accuracy of the candidates per quartile w.r.t. their certainty scores. The results are shown in Table 6 . We observe a strong correlation between the certainty score they received and the accuracy of the candidates, leading us to set the threshold value at 0.1. Other threshold values could have been used: higher values would have provided candidates with an even higher accuracy but the scale of the wordnet extension would have been lower; on the other hand, lower threshold values would have extended our wordnets even more but would have also introduced more noise. The 0.1 value, which corresponds approximately to the upper decile, seemed to provide a good balance. It leads to retaining 68,070 candidates (out of 685,633) that, however, have a precision of only 64 %. 19 6.2 Manual evaluation of the extended wordnet The most straightforward way to evaluate the accuracy of a wordnet is to randomly select a significant amount of ( literal, synset ) pairs and evaluate them manually. In order to obtain a meaningful per-PoS evaluation, we have decided to evaluate 100 randomly selected ( literal, synset ) pairs per PoS. This also allows for an estimate of the overall accuracy of the extended sloWNet (version 3.0), by weighting per-PoS accuracy scores by the relative number of (literal, synset) pairs for each PoS.
The results of this evaluation are provided in Table 7 . It shows that the overall accuracy of sloWNet 3.0 is 82 %. With the proposed method we were able to generate most nominal synsets that at the same time have a very high accuracy (87 %). The only more accurate are adverbial synsets (96 %), which is understandable since they have the lowest degree of polysemy. The results for adjectives (85 %) are comparable to those of nouns, only verbal synsets perform much worse (59 %). On the one hand, this can be expected since verbs are much more polysemous (while average polysemy for nouns in PWN is 1.24, it is 2.17 for verbs 20 ), but on the other hand their translations depend on target language syntax much more than translations of nouns or adjectives. This is why they are a much more difficult problem to address with the proposed approach. 6.3 Contrastive evaluation of the extended wordnet against a small-scale gold A direct manual evaluation such as the one described in the previous section leads to precise overall accuracy results. However, such an evaluation does not provide insights into at least two questions: (i) the recall of sloWNet 3.0, and (ii) the accuracy of BCS synsets in sloWNet 3.0.
 In order to obtain information on these issues, we compared sloWNet 3.0 to the Slovene WordNet (SWN). SWN is a small-scale manually built gold standard, obtained by validating the results of the preliminary Slovene wordnet construction experiments based on the Serbian wordnet (Erjavec and Fis  X  er 2006 ). Because it has been developed manually, SWN only contains synsets from the three Base Concept Sets (Tufis  X  and Cristea 2002 ). 21 Therefore, evaluating sloWNet 3.0 on those synsets which are not empty in SWN is a first step towards an answer to question (ii) above. Moreover, because SWN has been developed manually, it is reasonable to make the assumption that a non-empty SWN synset contains all Slovene literals that should be found in that synset. In other words, one can estimate the recall of sloWNet 3.0 by comparing its coverage w.r.t. non-empty synsets in SWN. However, such an evaluation is strongly biased, as it is restricted to the above-mentioned BCS synsets only. This evaluation therefore cannot be considered a definitive answer to question (i) above.

The accuracy-oriented evaluation was performed as follows. First, we consider any ( literal, synset ) pair that is found in both SWN and sloWNet 3.0 as correct. Second, in order to assess the accuracy of ( literal, synset ) pairs found in sloWNet 3.0 but not in SWN, we randomly selected 100 such pairs per category and evaluated them manually. For adjectival synsets, there are only 45 such pairs, so we evaluated them all. As there are no adverbial synsets in SWN, no figures can be obtained on such synsets.

The results of this evaluation are given in Table 8 . The average accuracy result which we obtain, namely 70 %, is much lower than the overall accuracy of sloWNet 3.0 which we obtained in the previous section, namely 82 %. This is because evaluation against SWN is restricted to BCS synsets which denote general concepts, typically lexicalised with high-frequency vocabulary. Since general, frequent words are typically highly polysemous, they present the biggest challenge in automatic sense assignment, causing the lower accuracy score. In order to confirm this we randomly chose 100 pairs among the 67,393 sloWNet 3.0 pairs that are in synsets which are empty in SWN. This evaluation yielded an accuracy score of 92 %. This latter figure, together with the 70 % accuracy score on pairs from the non-empty SWN synsets, results in a new estimate of 86 % for the new overall accuracy of sloWNet 3.0. The discrepancy between the 82 % obtained in the previous section and the 86 % measured here is thus an artefact of the random selection process
Table 9 details our results w.r.t. SWN from a recall-oriented perspective. It is difficult to interpret these results because they are computed only on BCS synsets, which contain literals that in general display a higher degree of polysemy (e.g. plant ), as opposed to literals denoting specialised concepts (e.g. hellebore ), and therefore cause a negative bias for recall. On the other hand, taking SWN non-empty synsets as necessarily complete would again be an incorrect approximation, causing a positive bias for recall. Table 8 shows a comparison of incomplete SWN synsets with their extended sloWNet 3.0 counterparts where we can see that many correct BCS ( literal, synset ) pairs are found in sloWNet 3.0 but not in SWN. 6.4 Contrastive evaluation of the extended wordnet against two other Another way to evaluate sloWNet, and more specifically to evaluate the approach we used for building it, is to compare it with comparable resources, namely other automatically generated wordnets. We have evaluated it against two highly multilingual wordnets, namely BabelNet (Navigli and Ponzetto 2010 , 2012 ) 22 and the Universal WordNet (UWN) (de Melo and Weikum 2009 ).

Even though both UWN and BabelNet are built from the same basic resource as sloWNet, it must be recalled that their aim is to be massively multilingual networks, while we focused on translating the Princeton WordNet from English to an individual language, here Slovene. As a result, the Slovene subpart of UWN is much smaller than sloWNet as it contains only 9,924 (literal, synset) pairs, 23 to be compared with the 82,721 such pairs in sloWNet 3.0. This is not the case with BabelNet (version 2.0), which contains as many as 131,964 literals. However, as we will see, the accuracy of the Slovene subpart of BabelNet is much lower than that of sloWNet 3.0.

Table 10 shows the number of (literal, synset) pairs for each of the 7 possible situations obtained by crossing the presence or absence of a pair in each of the three resources. Comparing sloWNet 3.0 with UWN and with BabelNet respectively, we get the following results:  X  Among the 9,924 (literal, synset) pairs in the Slovene subpart of UWN, 5,590  X  Among the 131,964 ( literal, synset ) pairs in the Slovene subpart of BabelNet Overall, as many as 64,663 ( literal, synset ) pairs are only found in sloWNet 3.0. Only 901 pairs are both in BabelNet and in UWN but missing in sloWNet 3.0.
In order to better quantify and analyse the differences between these three resources in terms of accuracy, we carried out a manual evaluation of 50 randomly selected ( literal, synset ) pairs for each of the 7 possible situations mentioned above. The results are shown in Table 10 . Based on the results, we can draw the following conclusions:  X  The overall accuracy score obtained for sloWNet 3.0 in this evaluation is 88 %.  X  The overall accuracy of sloWNet 3.0 and UWN are similar, despite the fact that  X  The accuracy of the 64,663 sloWNet-only (literal, synset) pairs is around 86 %;  X  The three approaches used for building these resources are complementary in the  X  BabelNet, which is very large, is also quite noisy, and therefore not fully More specifically, and apart from real disambiguation issues, errors among sloWNet-only pairs are mostly related to strange and/or archaic words, whereas errors among UWN-only pairs and BabelNet-only pairs are often related to normalisation errors: English literals, titles of Wikipedia pages that are not literals (e.g., Seznam Arheolo X kih Dob  X  X ist of archeological ages X ), Slovene words that are correct semantically but are in the wrong part of speech, in feminine form, preceded by a numeral, followed by a dot or a disambiguation word from Wikipedia (e.g., Mars (bog)  X  X ars (god) X ), etc. Table 11 gives an example of a synset with all literals from sloWNet 3.0, UWN and BabelNet 2.0, including a short comment for each literal. In total, we find 9 literal candidates for this synset in all three resources. sloWNet contains two, both of which are correct. UWN contains the two correct ones plus two incorrect ones and the noisiest is BableNet which contains 9 literal candidates, including the two correct ones.

Given the results of this section and the previous one, we believe that sloWNet 3.0 can be considered as the most adequate Slovene wordnet to date. 6.5 Task-based evaluation of the extended wordnet The evaluations presented in the previous sections provide direct insights into the quality of sloWNet 3.0. However, developing a wordnet is not necessarily a goal per se , which is why we decided to carry out a small-scale task-based evaluation as well. In this section, we present the results of an evaluation of the extended sloWNet which was used to improve machine translation at the lexical level (Fis  X  er and Vintar 2010 ). Mistranslations often arise due to inadequate word-sense disambiguation of polysemous words and detection of multi-word expressions, and parallel wordnets can help with both problems.

In order to examine the importance of correct sense identification in an MT task, we created a small parallel corpus of 500 articles from the EU news portal that contained about 120,000 Slovene and 140,000 English tokens. We lemmatised, PoS-tagged and sentence-aligned the corpus and then semantically disambiguated all literals in the corpus with the freely-available graph-based UKB tool (Agirre and Soroa 2009 ), i.e. each of them received a unique synset id depending of their meaning in context. In sense assignment, UKB takes into account only direct ( literal, synset ) pairs, not their hypernyms or hyponyms, which could also be utilised in a future extension of the experiment. Next, we machine-translated both parts of the corpus with two MT systems; the rule-based Presis 24 and the statistical GoogleTranslate, 25 and compared the machine-translated solutions with human translations, which we treated as a gold standard, and translation equivalents obtained via synset ids from the two wordnets.

A comparison of MT-output, WN-equivalents and the human translations show that there were about 38,000 polysemous tokens (32 % of all the polysemous tokens in the corpus) in the Slovene part of the corpus. About 40 % of them were translated identically by both MT systems, wordnet-based WSD and the gold standard. But there were 1,558 tokens (4.1 % of all the polysemous tokens in the corpus) for which Slo ! Eng Presis and 867 Google translations (2.3 % of all the tokens in the corpus) did not match the translations in the gold standard but were assigned the correct wordnet sense. This is illustrated in Fig. 2 where the word koza was incorrectly translated by Presis as smallpox , while goat , the correct translation, was suggested by sloWNet.

When translating in the opposite direction, there were 48,000 polysemous tokens (34 % of all the tokens in the corpus) and only about 32 % of them were translated identically by both MT systems, wordnet-based WSD and the gold standard. Interestingly, the discrepancy between semantic misrepresentation of polysemous tokens by the MT systems with respect to wordnet-based WSD was even larger: 3,730 tokens (2.7 % of all the polysemous tokens in the corpus) that were mistranslated according to the gold standard by Presis were correctly disambiguated with sloWNet, and 901 (1.9 % of all the polysemous tokens in the corpus) by Google.

In a random sample of 200 sentence pairs that were manually checked, there were also 166 multi-word expressions which were not identified as such by the machine-translation system and therefore incorrectly translated, but were found in wordnet, e.g., biotska raznovrstnost  X  X iotic diversity X  instead of biodiversity ; vezani les  X  X ied wood X  instead of plywood .

This analysis shows that the extended sloWNet, when used in parallel with PWN, can be a very useful resource in MT systems, especially with polysemous words and multi-word expressions that are a major source of errors by MT systems, rule-based and statistical alike. The reason why GoogleTranslate performed better than Presis overall is that Google X  X  MT uses parallel texts found on the web, which was also the source of our parallel corpus and had probably already been detected by Google. 6.6 Manual evaluation of outlier candidates As mentioned above, the overall error rate in the extended sloWNet has been evaluated as being about 15 %, i.e. around 12,000 incorrect ( literal, synset ) pairs. Given our set of outlier candidates, we have empirically chosen a threshold on the outlier score such that the number of candidate outliers has the same order of magnitude than the estimated number of erroneous (literal, synsets) pairs. This resulted in a threshold of 4 10 6 , thus generating 12,578 candidate outliers, i.e. approximately one third of all outlier candidates.

We manually evaluated a random sample of 100 candidate outliers. Among these, the proportion of ( literal, synset ) pairs which have correctly been detected as errors is 64 %. These figures can be compared with the estimated overall error rates in the input wordnets, namely 15 % as recalled above. Considering that we expanded sloWNet using thresholds that led to a reasonable balance between recall (more candidates is better) and precision (less erroneous candidates is better), we inevitably included erroneous candidates as well. The fact that our outlier detection method manages to suggest candidate outliers out of which 64 % are real errors is very good: first, it means that our outlier detection algorithm manages to spot many more errors than randomly selecting ( literal, synset ) pairs; second, this outlier detection algorithm relies heavily on its input wordnet, i.e. on the extended wordnet: in other words, the information available to the outlier detection algorithm includes the entire extended wordnet, something that the wordnet extension algorithm could obviously not rely on.
Examples of candidate outliers from sloWNet extracted from our manual evaluation data are shown in Table 12 . Apart from the synset and literal we indicate the corresponding score as well as the outcome of manual evaluation in which the  X  X  X ES X  X  label means that the (literal, synset) pair has been correctly detected as incorrect, while the  X  X  X O X  X  label means that the ( literal, synset ) pair is indeed correct, and that its detection as a candidate outlier is erroneous. 6.7 Crowdsourcing-based validation of outlier candidates The identified outlier candidates were earmarked for manual examination during which they would be rejected as errors and therefore deleted from the wordnet or validated as correct and kept in the resource. In order to facilitate manual work, we have developed a simple on-line tool called sloWCrowd (Tavc  X  ar et al. 2012 ) that works on the principle of crowdsourcing. The tool is open-source and based on popular technologies, such as PHP and MySQL. It consists of an administrator and a user interface. The administrator interface enables the creation of crowdsourcing projects, management of on-going projects and export of the results, while the user interface allows users to vote on the (in)correctness of the randomly displayed literals. The reliability of each user is checked against a gold standard so that the users with a very low accuracy can be automatically excluded from the final results. In order to achieve as high consensus about the answers as possible, the same question is repeated five times, each time to a different user, and the final decision is based on the majority vote. The user interface for validating outlier candidates is shown in Fig. 3 where the user is asked the following question: Is the automatically translated expression X an appropriate lexicalisation of the concept Y?
To date, 26 275 users have provided 34,867 answers, including answers to gold standard requests, and have validated 7,276 outlier candidates. On average, each user provided 126.79 answers, whereas the maximum number of answers provided by a single user is 4,200 and the minimum is 1. Users X  accuracy ranges between 25 and 100 %, but is 79.72 % on average. According to the majority vote, 44 % of the outlier candidates have been voted as correct and 56 % as incorrect. This is in line with the results of manual evaluation of a sample of 400 outlier candidates, 64 % of which have been considered as genuine errors (see Sect. 6.6 ). All the outlier candidates that were rejected by the majority of the users were deleted from sloWNet. The crowdsourcing task will continue until we collect votes for all 12,578 candidate outliers we obtained from our automatic outlier detection procedure. Once all the votes are collected, the outlier candidates with the majority negative vote will be deleted from sloWNet and version 4.0 will be announced. 7 Conclusions and future work In this paper, we have described the different resources and techniques we used for automatic construction, extension and cleaning of sloWNet, a wordnet for Slovene. We first outlined the construction of the baseline wordnet based on bilingual lexicons extracted from Wikipedia, Wiktionaries and other bilingual resources which we used for translating monosemous literals, and word-aligned parallel corpora for translating and disambiguating polysemous literals. Then we described a follow-up experiment in which we used the same bilingual lexicons much more exhaustively than the baseline wordnets. By using various features, including distributional similarity, we were able to reuse the same resources for translating and disambiguating polysemous literals as well, which had been dealt with only by word-aligned corpora up to this point. This enrichment step has increased the number of non-empty synsets in sloWNet from 17,817 to 42,919. The number of ( literal, synset ) pairs in sloWNet went up from 24,081 to 82,721 ( ? 244 %).
The resulting wordnet was then carefully evaluated, both in terms of accuracy of the content and as a resource in a machine-translation setting. The accuracy of ( literal, synset ) pairs is estimated at approximately 85 %. These figures show that the enhanced resource has a much higher coverage than the baseline wordnet and that it outperforms the gold Slovene WordNet.

The latest version of sloWNet has been uploaded to sloWTool , 27 a freely available tool that incorporates browsing, editing and visualisation of wordnet content with hyperbolic graphs and images (Fis  X  er and Novak 2011 ). It is freely available and based on MySQL and PHP technologies, which makes the tool light-weight, portable and efficient. Scripts for automatic database transformations from and into several standardised formats, such as DEBVisDic XML and LMF, are provided so that a wordnet for another language can be imported at any time. The on-line browser is simple to use for non-experts but also enables advanced searching and view settings for expert users that can enter complex search queries and decide which fields to display as well as toggle between a mono-and a multilingual option. Through sloWTool, sloWNet is now available to language students, translators and other linguists who can examine the Slovene lexical inventory and semantic network which they can also compare to English and French since wordnets for these languages are cross-aligned via the Princeton WordNet synset IDs and are available on the sloWTool as well (Fig. 4 ).

In the future we plan to work in five complementary directions. First, more attention should be given to the multi-word expressions, such as phrasal verbs, compound nouns and idiomatic expressions, since they represent a substantial segment of our semantic repository and pose a major obstacle in NLP applications. Second, the extraction of lexico-semantic information from Wikipedia and Wiktionary can be improved even further by adding definitions and examples to the created wordnets as well as extend and validate the current network by mining semantically related words from article bodies. Third, we have already started adapting the alignment-based approach to work with non-parallel texts (Fis  X  er et al. 2012 ), which is a very promising line of research as large comparable corpora are much easier to obtain from the rich web data. Fourth, there are many more features that could be used for lexical disambiguation still keeping our development process lightweight (i.e. without the need for advanced NLP tools that are rarely available for most languages, such as parsers or WSD systems). Such features could include Lesk-like measures for comparing contexts of definitions or glosses; similarity between cognates, etc. And last but not least, since our approach has already proven efficient and useful for two languages as different as French and Slovene (Sagot and Fis  X  er 2008 ; Fis  X  er and Sagot 2008 ; Sagot and Fis  X  er 2011 , 2012a , b ), for which the amount and nature of the available sources is very different as well, we would like to create wordnets for other under-resourced languages, such as Croatian.
We believe the work presented in this paper has two main consequences. First, it shows that it is possible to build large-scale reliable wordnets with fully automatic approaches (although manual work was involved in intermediate steps of the construction process, it has affected only a small number of senses included in the latest version of sloWNet). Second, this work has resulted in a freely available lexical semantic resource for a language that was lacking such a resource, which is large and accurate enough to be used in real NLP applications. The developed sloWNet is distributed under the Creative Commons BY-SA 3.0 licence at http://nl.ijs.si/sloWNet .
 References
