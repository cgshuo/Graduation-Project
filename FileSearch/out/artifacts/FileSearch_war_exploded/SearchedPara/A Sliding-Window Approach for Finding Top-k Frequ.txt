 Top-k Frequent itemset (top-k FI) mining in certain data streams has been thoroughly studied. However, previous approaches almost coped with the certain data streams that contain precise data. Actually, a numbe r of applications today need to analyze streaming data that is uncertain, such as medical data managing and mobile object tracking. These applications has attracted a lot of attention recently [1, 2]. Since large amounts of uncertain streaming data could arrive at high speed, there are two main challenges to handle it, the first one stems from the limited memory and CPU re-course, the other is how to deal with the exponential blowup in the number of FIs. While streaming data is highly time sensitive, people are generally more interested in the most recent transactions than those in the past, and dated uncertain transactions are no longer interesting. In this situation, sliding window model can be used to deal with these recent transactions directly. 
Most previous algorithms like Lossy Counting algorithm [3] for processing data streams are controlled by an error parameter  X  set by the users. However, the setting of  X  is quite subtle, which often leads to a dilemma.  X  too big yields inaccurate results and makes the number of itemsets large while setting it too small leads to excessive memory consumption. To solve the above questions, we propose an algorithm, called UTK-FI (Top-K Frequent Itemset mining in Uncertain streams), for finding top-k FIs in a sliding window, and we apply Chernoff bound technique [4] to reset  X  that is not given by user and neither fixed with the window sliding, and design an increasing expected support function to compute the potentially expected support for each item-set. Our experiments show that UTK-FI algorithm is significantly efficient. An uncertain stream S is a continuous sequence of transactions, { T 1 , T 2 , ..., T n , ...}. A transaction T i ( T i  X  S ) contains a number of items, and each item x in T i is associated with a probability P Ti ( x ), which expresses the possibility that x exists in T i . A possible world model in [5] can be adopted to interpret the uncertain streams. Each probability P
Ti ( x ) with an item x deduces two possible worlds, pw 1 and pw 2 . In pw 1 , item x exists with an existence probability, denoted as P ( pw i ) that the possible world happens, then we can get P ( pw 1 )= P Ti ( x ) and P ( pw 2 )=1-P Ti ( x ). 
A sliding window is a window that slides forward for every time unit with a fixed current sliding window, respectively. Let W tl = { pw 1 , pw 2 , ...} be the set space of all | T | be the number of transactions that arrive in t l , and P ( pw j ) be the probability of pw j . Assuming that all items in each sliding window are independent, we have We define tran ( Sw ) as the set of transactions over a sliding window Sw , | tran ( Sw )| as all the number of transactions in tran ( Sw ), W Sw as the worlds space that consists of all items in tran ( Sw ) over Sw , and | W Sw | as the number of possible worlds in W Sw . For an uncertain stream, we do not determine whether a transaction contains X , since X is associated with a probability. We can depend on the possible worlds model to propose the notion of expected support count of an itemset over Sw , denoted as E_S ( X , Sw ). 
Given a support threshold,  X  (0 &lt;  X   X  1), we define X as a frequent itemset over Sw than ( k -1) FIs whose expected support count is higher than that of X . In uncertain streams, we cannot obtain the true support count of X , but has to make an approximation. Many methods often use an error parameter  X  to estimate the support of X . However, the setting of the parameter is quite subtle, which often leads to a dilemma. Since all itemsets whose expected support count over time unit t l is less than r  X  | tran ( t l )| are discarded, we define the potentially expected support count (denoted as PE_S ( X , t l )) of the itemsets as follows. 
We can define the expected support count of X over time unit t l , as E_S ( X , t l ). | W tl | denotes the number of possible worlds in the set W tl over t l . Clearly, we can get the potentially expected support count over the current window Sw  X  (denoted as PE _ S ( X , Sw  X  )), which is defined as the following formula. 
Based on Chernoff bound method, we do not use the fixed error  X  = r  X  to control is the reliability parameter, n is the number of transactions observed in each window. recent R time units in Sw  X  , where 1  X  R  X  w . The increasing expected support function of an itemset, denoted as IE _ S ( R ), is defined as the following formula. An X is a potentially frequent itemset (denoted as PFI) if PE _ S ( X , Sw R )  X  IE _ S ( R ). expected support count is higher than that of X , then X is defined as a potential top-k respectively. Hence, the task of finding ptop-k FIs over an SW is to update C with F . Our algorithm utilizes a Top-K Prefix tree, called TK_Ptree, to store all the ptop-k FIs. Each entry in TK_Ptree presents an itemset X , which contain three fields: item , t id which X is inserted the tree. PE _ S ( X ) presents the potentially expected support count TK_Ptree in the following way: For each mined X , if X does not belong to TK_Ptree, recursively we can create a new entry of form ( X , i , PE _ S ( X )). On the other hand, if X belongs to the tree, we should insert PE _ S ( X , t i ) into PE _ S ( X ). 
Table 1 presents the UTK-FI algorithm. After initializing the tree, we should slide the window, and process the added transactions in the arriving time units and deleted the condition in line 17, its support must be subtracted from PE _ S ( X ). For an arriving time unit t  X  , if X meets the condition in line 9, we should remove it from the TK_Ptree, otherwise, we insert the PE _ S ( X , t  X  ) into the PE _ S ( X ). We perform experiments on a PC computer with 2.0 GHz Pentium 4 CPU, 1.0 GB main memory. We compare UTK-FI with UTK-LC algorithm that is an improved Lossy Counting algorithm for finding Top-K FIs on Uncertain streams. We generate a synthetic dataset, T 15 I 4 D 100K, applying IBM synthetic dataset generator [6]. During generating T 15 I 4 D 100K. We randomly assign probability values 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, and 0.2 to the items of each transaction, respectively. In these experi-ments, the default parameters setting is: w =100,000, r =0.1 and  X  =0.01. 
We first study how  X  affects the two algorithms. Table 2 shows that UTK-FI algo-rithm can achieve over 98% precision and recall. However, the precision and the recall of UTK-LC descends clearly. Especially, when  X  =0.07%, UTK-LC only obtain 70% precision and 71% recall. Fig.1 (a) and (b) show that the memory usage and the runtime of UTK-FI remain near ly invariable when changes  X  from 0.005 to 0.07, but that of UTK-LC are changed largely. From the runtime viewpoint, UTK-FI is about 2.5 times faster than UTK-LC. We evaluate how the parameter k impacts on the performances of UTK-FI and UTK-LC. Fig. 2 (a) and Fig. 2 (b) show that UTK-FI algorithm can obtain 100% precision and 100% recall, and UTK-LC can only achieve average 85% recall and number of ptop-k FIs kept by UTK-LC is approximately 3 times larger than that of UTK-FI, and UTK-FI is nearly 3 times faster than UTK-LC. In this paper, we studied the problem of finding top-k frequent itemsets on uncertain streams, which is different in semantics from the past proposals of top-k frequent itemsets on certain data streams. A novel algorithm, UTK-FI based on time-sensitive sliding window and Chernoff bound was developed and evaluated. We evaluated the performances of our methods through the above experiments, and the experimental results showed that UTK-FI algorithm is efficient and feasible. 
