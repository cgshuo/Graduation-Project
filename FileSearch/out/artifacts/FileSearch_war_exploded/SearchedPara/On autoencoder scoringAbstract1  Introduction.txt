 Hanna Kamyshanska kamyshanska@fias.uni-frankfurt.de Roland Memisevic memisevr@iro.umontreal.ca Unsupervised learning has been based traditionally on probabilistic modeling and maximum likelihood esti-mation. In recent years, a variety of models have been proposed which define learning as the construction of an unnormalized energy surface and inference as find-ing local minima of that surface. Training such energy-based models amounts to decreasing energy near the observed training data points and increasing it every-where else (Hinton, 2002; lec). Maximum likelihood learning can be viewed as a special case, where the exponential of the negative energy integrates to 1. The probably most successful recent examples of non-probabilistic unsupervised learning are autoencoder networks, which were shown to yield state-of-the-art performance in a wide variety of tasks, ranging from object recognition and learning invariant representa-tions to syntatic modeling of text (Le et al., 2012; Socher et al., 2011; Rolfe &amp; LeCun, 2013; Swersky et al., 2011; Vincent, 2011; Memisevic, 2011; Zou et al., 2012). Learning amounts to minimizing reconstruction error using back-prop. Typically, one regularizes the autoencoder, for example, by adding noise to the in-put data or by adding a penalty term to the training objective (Vincent et al., 2008; Rifai et al., 2011). The most common operation after training is to in-fer the latent representation from data, which can be used, for example, for classification. For the autoen-coder, extracting the latent representation amounts to evaluating a feed-forward mapping. Since training is entirely unsupervised, one autoencoder is typically trained for all classes, and it is the job of the classifier to find and utilize class-specific differences in the repre-sentation. This is in contrast to the way in which prob-abilistic models have been used predominantly in the past: Although probabilistic models (such as Gaussian mixtures) may be used to extract class-independent features for classification, it has been more common to train one model per class and to subsequently use Bayes X  rule for classification (Duda &amp; Hart, 2001). In the case where an energy-based model can assign con-fidence scores to data, such class-specific unsupervised learning is possible without Bayes X  rule: When scores do not integrate to 1 one can, for example, train a classifier on the vector of scores across classes (Hin-ton, 2002), or back-propagate label information to the class-specific models using a  X  X ated softmax X  response (Memisevic et al., 2011).
 1.1. Autoencoder scoring It is not immediatly obvious how one may compute scores from an autoencoder, because the energy land-scape does not come in an explicit form. This is in contrast to undirected probability models like the Re-stricted Boltzmann Machine (RBM) or Markov Ran-dom Fields, which define the score (or negative energy) as an unnormalized probability distribution. Recent work has shown that autoencoders can assign scores, too, if they are trained in a certain way: If noise is added to the input data during training, minimizing squared error is related to performing score matching (Hyv  X arinen, 2005) in an undirect probabilistic model, as shown by (Swersky et al., 2011) and (Vincent, 2011). This, in turn, makes it possible to use the RBM energy as a score. A similar argument can be made for other, related training criteria. For example, (Rifai et al., 2011) suggest training autoencoders using a  X  X ontrac-tion penalty X  that encourages latent representations to be locally flat, and (Alain &amp; Bengio, 2013) show that such regularization penalty allows us to interpret the autoencoder reconstruction function as an estimate of All these approaches to defining confidence scores rely on a regularized training criterion (such as denoising or contraction), and scores are computed by using the relationship with a probabilistic model. As a result scores can be computed easily only for autoencoders that have sigmoid hidden unit activations and linear outputs, and that are trained by minimizing squared error (Alain &amp; Bengio, 2013). The restriction of ac-tivation function is at odds with the growing interest in unconventional activation functions, like quadratic or rectified linear units which seem to work better in supervised recognition tasks (eg., (Krizhevsky et al., 2012)).
 In this work, we show how autoencoder confidence scores may be derived by interpreting the autoencoder as a dynamical system . The view of the autoencoder as a dynamical system was proposed by (Seung, 1998), who also demonstrated how de-noising as a learning criterion follows naturally from this perspective. To compute scores, we will assume  X  X ied weights X , that is, decoder and encoder weights are transposes of each other. In contrast to probabilistic arguments based on score matching and regularization (Swersky et al., 2011; Vincent, 2011; Alain &amp; Bengio, 2013), the dy-namical systems perspective allows us to assign con-fidence scores to networks with sigmoid output units (binary data) and arbitrary hidden unit activations (as long as these are integrable). In contrast to (Rolfe &amp; LeCun, 2013), we do not address the role of dynamics in learning. In fact, we show how one may derive con-fidence scores that are entirely agnostic to the learning procedure used to train the model.
 As an application of autoencoder confidence scores we describe a generative classifier based on class-specific autoencoders. The model achieves 1 . 27% error rate on permutation invariant MNIST, and yields competitive performance on the deep learning benchmark dataset by (Larochelle et al., 2007). Autoencoders are feed forward neural networks used to learn representations of data. They map input data to a hidden representation using an encoder function from which the data is reconstructed using a linear decoder We shall assume that A = W T in the following ( X  X ied weights X ). This is common in practice, because it re-duces the number of parameters and because related probabilistic models, like the RBM, are based on tied weights, too.
 For training, one typically minimizes squared recon-struction error ( r ( x )  X  x ) 2 for a set of training cases. When the number of hidden units is small, autoen-coders learn to perform dimensionality reduction. In practice, it is more common to learn sparse represen-tations by using a large number of hidden units and training with a regularizer (eg., (Rifai et al., 2011; Vin-cent et al., 2008)). A wide variety of models can be learned that way, depending on the activation func-tion, number of hidden units and nature of the regu-larization during training. The function h (  X  ) can be the identity or it can be an element-wise non-linearity, such as a sigmoid function. Autoencoders defined us-ing Eq. 2 with tied weights and logistic sigmoid non-linearity h ( a ) = 1 + exp(  X  a )  X  1 are closely related to RBMs (Swersky et al., 2011; Vincent, 2011; Alain &amp; Bengio, 2013), one can assign confidence scores to data in the form of unnormalized probabilities. For binary data, the decoder typically gets replaced by and training is done by minimizing cross-entropy loss. Even though confidence scores (negative free energies) are well-defined for binary output RBMs, there has been no analogous score function for the autoencoder, because the relationships with score matching breaks down in the binary case (Alain &amp; Bengio, 2013). As we shall show, the perspective of dynamical systems allows us to attribute the missing link to the lack of symmetry. We also show how we can regain symme-try and thereby obtain a confidence score for binary output autoencoders by applying a log-odds transfor-mation on the outputs of the autoencoder. 2.1. Reconstruction as energy minimization Autoencoders may be viewed as dynamical systems, by noting that the function r ( x )  X  x (using the defini-tion in Eq. 2) is a vector field which represents the lin-ear transformation that x undergoes as a result of ap-plying the reconstruction function r ( x ) (Seung, 1998; Alain &amp; Bengio, 2013). Repeatedly applying the re-construction function (possibly with a small inference rate ) to an initial x will trace out a non-linear tra-jectory x ( t ) in the data-space.
 If the number of hidden units is smaller than the num-ber of data dimensions, then the set of fixed points of the dynamical system will be approximately a low-dimensional manifold in the data-space (Seung, 1998). For overcomplete hiddens it can be a more complex structure. (Alain &amp; Bengio, 2013), for example, show that for denoising and contractive autoencoder, the reconstruc-tion is proportional to the derivative of the log proba-bility of x : Running the autoencoder by following a trajectory as prescribed by the vector field may also be viewed in analogy to running a Gibbs sampler in an RBM, where the fixed points play the role of a maximum probability  X  X idge X  and where the samples are deterministic not stochastic.
 Some vector fields can be written as the derivative of a scalar field: In such a case, running the dynamical sys-tem can be thought of as performing gradient descent in the scalar field. We may call this scalar field energy E ( x ) and interpret the vector field as a correspond-ing  X  X orce X  in analogy to physics, where the potential force acting on a point is the gradient of the potential energy at that point. The autoencoder reconstruction may thus be viewed as pushing data samples in the direction of lower energy (Alain &amp; Bengio, 2013). The reason why evaluating the potential energy for the autoencoder would be useful is that it allows us to asses how much the autoencoder  X  X ikes X  a given input x (up to a normalizing constant which is the same for any two inputs). That way, the potential energy plays an analogous role to the free energy in an RBM (Hinton, 2002; Swersky et al., 2011). As shown by (Alain &amp; Bengio, 2013), the view of the autoencoder as modeling an energy surface implies that reconstruction error is not a good measure of confidence, because the reconstruction error will be low at both local minima and local maxima of the energy.
 A simple condition for a vector field to be a gradient field is given by Poincare X  X  integrability criterion : For some open, simple connected set U , a continuously differentiable function F : U  X  R n defines a gradient field if and only if In other words, integrability follows from symmetry of the partial derivatives.
 Consider an autoencoder with shared weight matrix W and biases b h and b r , which has some activation function h ( . ) (e.g. sigmoid, hyperbolic tangent, lin-ear). We have:  X  ( r m ( x )  X  x m ) so the integrability criterion is satisfied. 2.2. Computing the energy surface One way to find the potential energy whose derivative is r ( x )  X  x , is to integrate the vector field (compute its forward for autoencoders with a single hidden layer, linear output activations, and symmetric weights, in other words where h (  X  ) is an elementwise activation function, such as the sigmoid. We can now write F ( x ) = By defining the auxiliary variables u = W x + b h and using we get F ( x ) = W T W  X  T where the last equation uses the fact that b r does not depend on x .
 If h ( u ) is an elementwise activation function, then the final integral is simply the sum over the antiderivatives of the hidden unit activation functions applied to x . In other words, we can compute the integral using the following recipe: 1. compute the net inputs to the hidden units: 2. compute hidden unit activations using the an-3. sum up the activations and subtract 1 Example: sigmoid hiddens. In the case of sigmoid activation functions h ( u ) = (1 + exp(  X  u ))  X  1 , we get =
Z =
X which is identical to the free energy in a binary-Gaussian RBM (eg., (Welling et al., 2005)). It is inter-esting to note that in the case of contractive or denois-ing training (Alain &amp; Bengio, 2013), the energy can in fact be shown to approximate the log-probability of the data (cf., Eq. 4): But Eq. 11 is more general as it holds independently of the training procedure.
 Example: linear hiddens. The antiderivative of the linear activation, h ( u ) = u , is u 2 , so for PCA and a linear autoencoder, it is simply the norm of the latent representation. More precisely, we have = It is interesting to note that, if we disregard biases and assume WW T = I (the PCA solution), then F l inear ( x ) turns into the negative squared reconstruction error. This is how one would typically assign confidences to PCA models, for example, in a PCA based classfier. It is straightforward to calculate the energies for other hidden unit activations, including those for which the energy cannot be normalized, in which case there is no corresponding RBM. Two commonly deployed activa-tion functions are, for example: the rectifier, whose antiderivative is the  X  X alf-square X  ( sign ( x )+1) the softplus activation whose antiderivative is the so-called polylogarithm. A variety of activation functions and their antiderivatives are shown in Fig. 1. 2.3. Binary data When dealing with binary data it is common to use sigmoid activations on the outputs: and training the model using cross-entropy (but like in the case of real outputs, the criterion used for training will not be relevant to compute scores). In the case of sigmoid outputs activations, the integrability criterion (Eq. 6) does not hold, because of the lack of symmetry of the derivatives. However, we can obtain confidence scores by monotonically transforming the vector space as follows: We apply the inverse of the logistic sigmoid (the  X  X og-odds X  transformation) in the input domain. Now we can define the new vector field v ( x ) =  X  ( r ( x ))  X   X  ( x ) The vector field v ( x ) has the same fixed points as r ( x )  X  x , because invertibility of  X  ( x ) implies So the original and transformed autoencoder converge to the same representations of x . By integrating v ( x ), we get F ( x ) = Due to the convention 0  X  log 0 = 0, the second term,  X  log 1  X  x  X  x log x (Cover &amp; Thomas, 1991). In that case, the energy takes exactly the same form as the free energy of a binary output RBM with binary hidden units (Hin-ton, 2002). However, hidden unit activation functions can be chosen arbitrarily and enter the score using the recipe described above. Also, training data may not always be binary. When it takes on values between 0 and 1, the log-terms do not equal 0 and have to be included in the energy computation. Being able to assign unnormalized scores to data can be useful in a variety of tasks, including visualization or classification based on ranking of data examples. Like for the RBM, the lack of normalization causes scores to be relative not absolute. This means that we can compare the scores that an autoencoder assigns to multiple data-points but we cannot compare the scores that multiple autoencoders assign to the same data-point. We shall now discuss how we can turn these into a classification decision.
 Fig. 2 shows exemplary energies that various types of contractive autoencoder (cAE, (Rifai et al., 2011)), trained on MNISTsmall digits 6 and 9, assign to test cases from those classes. It shows that all models yield fairly well separated confidence scores, when the apro-priate anti-derivatives are used. Squared error on the sigmoid networks separates these examples fairly well too (rightmost plot). However, in a multi-class task, using reconstruction error typically does not work well (Susskind et al., 2011), and it is not a good confi-dence measure as we discussed in Section 2. As we shall show, one can achieve competitive classification performance on MNIST and other data-sets by using properly  X  X alibrated X  energies, however. 3.1. Supervised finetuning Since the energy scores are unnormalized, we cannot use Bayes X  rule for classification unlike with directed graphical models. Here, we adopt the approach pro-posed by (Memisevic et al., 2011) for Restricted Boltz-mann Machines and adopt it to autoencoders.
 In particular, denoting the energy scores that the autoencoders for different classes assign to data as E ( x ) ,i = 1 ,...,K , we can define the conditional dis-tribution over classes y i as the softmax response where C i is the bias term for class y i . Each C i may be viewed also as the normalizing constant of the i th au-toencoder, which, since it cannot be determined from the input data, needs to be trained from the labeled data.
 Eq. 19 may be viewed as a  X  contrastive  X  objective function that compares class y i against all other classes in order to determine the missing normalizing con-stants of the individual autoencoders. It is remi-niscent of noise-contrastive estimation (Gutmann &amp; Hyv  X arinen, 2012), with the difference that the con-trastive signal is provided by other classes not noise. Optimizing the log-probabilities (log of Eq. 19) is sim-ply a form of logistic regression. We shall refer to the model as autoencoder scoring (AES) in the following. Like the gated softmax model (Memisevic et al., 2011), we may optimize Eq. 19 wrt. the autoencoder param-eters by back-propagating the logistic regression cost to the autoencoder parameters. 3.2. Parameter factorization We showed in Section 2 that scores can be com-puted for autoencoders with a single hidden layer only. However, if we train multi-layer autoencoders whose bottom layer weights are tied across models, we may view the bottom layers as a way to perform class-independent pre-processing . In many classifica-tion tasks this kind of pre-processing makes sense, be-cause similar features may appear in several classes, so there is no need to learn them separately for each class. Class-specific autoencoders with shared bottom-layer weights can also be interpreted as standard au-toencoders with factorized weight matrices (Memisevic et al., 2011).
 Fig. 3 shows an illustration of a factored autoencoder. which are shared among the classes, as well as matri-ces W f , B h and B r which consist of stacked class-dependent feature-weights and bias vectors. Using one-hot encoded labels, we can write the hidden unit activations as h This model combines m class-dependent AEs with tied where each weight matrix W j is a product of two class-independent (shared) matrices W x and W h and one class-dependent vector W f j . : The first encoder-layer ( W x ) learns the class-independent features, the second layer ( w f ) learns, how important these features are for a class and weights them accordingly. Finally, the third layer ( W h ) learns how to overlay the weighted features to get the hidden representation. All these layers have linear activations except for the last one. Reconstruc-tions takes the form To learn the model, we pre-train all m autoen-coders together on data across all classes, and we use the labels to determine for each observation which intermediate-level weights to train. 3.3. Performance evaluation We tested the model (factored and plain) on the  X  X eep learning benchmark X  (Larochelle et al., 2007). Details on the data sets are listed in Table 1.
 To learn the initial representations, we trained the class-specific autoencoders with contraction penalty (Rifai et al., 2011), and the factored models as de-noising models (Vincent et al., 2008) (contraction penalties are not feasible in multilayer networks (Ri-fai et al., 2011)). For comparability with (Memisevic et al., 2011), we used logistic sigmoid hiddens as de-scribed in Section 3.2 unless otherwise noted. To train class-dependent autoencoders, we used labeled sam-ples ( x , t ), where labels t are in one-hot encoding. For pre-training, we fixed both the contraction penalty and corruption level to 0.5. In some cases we normal-ized filters after each gradient-step during pretraining. The model type (factored vs. non-factored) and pa-rameters for classification (number of hidden units, number of factors, weight decay and learning rate) were chosen based on a validation set. In most cases we tested 100, 300 and 500 hiddens and factors. The mod-els were trained by gradient descent for 100 epochs. We compared our approach from Section 3 to a variety of baselines and variations: 1. Train an autoencoder for each class. Then 2. Train an autoencoder for each class. Then learn 3. Optimize Eq. 19 wrt. the autoencoder parame-4. Assign data samples to the AEs with the smallest Method 4 seems straightforward, but it did not lead to any reasonable results. Methods 1 and 2 run very fast due to the small amount of trainable parameters, but they do not show good performance either. Method 3 lead to consistently better results, but as illustrated in Fig. 4 it performs worse than the procedure from Section 3. Two lessons to learn from this are that (i) generative training of each autoencoder on its own class is crucial to achieve good performance, (ii) it is not sufficient to tweak normalizing constants, since backpropagating to the autoencoder parameters sig-nificantly improves performance.
 Table 2 shows the classification error rates of the method from Section 3 in comparison to various com-parable models from the literature. It shows that class-specific autoencoders can yield highly competi-tive classification results. For the GSM (Memisevic et al., 2011), we report the best performance of fac-tored vs. non-factored on the test data, which may introduce a bias in favor of that model. In Tab. 3 we furthermore compare the AES performance for differ-ent activation functions on MNIST using contractive AEs with 100 hidden units. The corresponding AE en-ergies are shown in Fig. 2. Some example images with corresponding filters learned by the ordinary and fac-tored AES model are displayed in Fig. 5. We used the Python Theano library (Bergstra et al., 2010) for most of our experiments. An implementation of the model is available at: www.iro.umontreal.ca/ ~ memisevr/ aescoring We showed how we may assign unnormalized confi-dence scores to autoencoder networks by interpret-ing them as dynamical systems. Unlike previous ap-proaches to computing scores, the dynamical systems perspective allows us to compute scores for various transfer functions and independently of the training criterion. We also show how multiple class-specific au-toencoders can be turned into a generative classifier that yields competitive performance in difficult bench-mark tasks.
 While a class-independent processing hierarchy is likely to be a good model for early processing in many tasks, class-specific dynamical systems may of-fer an appealing view of higher level processing. Un-der this view, a class is represented by a dynamic sub-network not just a classifier weight. Such a sub-network makes it particularly easy to model complex invariances, since it uses a lot of resources to encode the within-class variability.
 Acknowledgements We thank the members of the LISA Lab at Montreal, in particular Yoshua Bengio, for helpful discussions. This work was supported in part by the German Fed-eral Ministry of Education and Research (BMBF) in the project 01GQ0841 (BFNT Frankfurt).
 Alain, G. and Bengio, Y. What regularized auto-encoders learn from the data generating distribu-tion. In International Conference on Learning Rep-resentations (ICLR) , 2013.
 Bergstra, J., Breuleux, O., Bastien, F., Lamblin, P., Pascanu, R., Desjardins, G., Turian, J., Warde-Farley, D., and Bengio., Y. Theano: a CPU and
GPU math expression compiler. In Python for Sci-entic Computing Conference (SciPy) , 2010.
 Cover, TM and Thomas, J. Elements of Information Theory . New York: John Wiley &amp; Sons, Inc, 1991. Duda, H. and Hart, P. Pattern Classification . John Wiley &amp; Sons, 2001.
 Gutmann, M. U. and Hyv  X arinen, A. Noise-contrastive estimation of unnormalized statistical models, with applications to natural image statistics. Journal of Machine Learning Research , 13:307 X 361, March 2012.
 Hinton, G. E. Training products of experts by mini-mizing contrastive divergence. Neural Computation , 14(8):1771 X 1800, 2002.
 Hyv  X arinen, A. Estimation of non-normalized statisti-cal models by score matching. Journal of Machine Learning Research , 6:695 X 709, December 2005.
 Krizhevsky, A., Sutskever, I., and Hinton, G. Ima-genet classification with deep convolutional neural networks. In Advances in Neural Information Pro-cessing Systems (NIPS) . 2012.
 Larochelle, H., Erhan, D., Courville, A., Bergstra,
J., and Bengio, Y. An empirical evaluation of deep architectures on problems with many factors of variation. In International Conference on Machine Learning (ICML) , 2007.
 Le, Q., Ranzato, M.A., Monga, R., Devin, M., Chen,
K., Corrado, G., Dean, J., and Ng, A. Building high-level features using large scale unsupervised learn-ing. In International Conference on Machine Learn-ing (ICML) , 2012.
 Memisevic, R. Gradient-based learning of higher-order image features. In the International Conference on Computer Vision (ICCV) , 2011.
 Memisevic, R., Zach, C., Hinton, G., and Pollefeys, M. Gated softmax classification. Advances in Neural Information Processing Systems (NIPS) , 23, 2011. Rifai, S., Vincent, P., Muller, X., Glorot, X., and
Bengio, Y. Contractive auto-encoders: Explicit in-variance during feature extraction. In International Conference on Machine Learning (ICML) , 2011.
 Rolfe, J. T. and LeCun, Y. Discriminative recurrent sparse auto-encoders. In International Conference on Learning Representations (ICLR) , 2013.
 Seung, H.S. Learning continuous attractors in recur-rent networks. Advances in neural information pro-cessing systems (NIPS) , 10:654 X 660, 1998.
 Socher, R., Pennington, J., Huang, E. H., Ng, A. Y., and Manning, C. D. Semi-Supervised Recursive Au-toencoders for Predicting Sentiment Distributions. In Conference on Empirical Methods in Natural Language Processing (EMNLP) , 2011.
 Susskind, J., Memisevic, R., Hinton, G., and Pollefeys,
M. Modeling the joint density of two images under a variety of transformations. In International Confer-ence on Computer Vision and Pattern Recognition (CVPR) , 2011.
 Swersky, K., Buchman, D., Marlin, B.M., and de Fre-itas, N. On autoencoders and score matching for energy based models. In International Conference on Machine Learning (ICML) , 2011.
 Vincent, P., Larochelle, H., Bengio, Y., and Manzagol,
P. A. Extracting and composing robust features with denoising autoencoders. In International Con-ference on Machine Learning (ICML) , 2008.
 Vincent, P., Larochelle, H., Lajoie, I., Bengio, Y., and Manzagol, P.A. Stacked denoising autoencoders:
Learning useful representations in a deep network with a local denoising criterion. Journal of Machine Learning Research , 11:3371 X 3408, 2010.
 Vincent, Pascal. A connection between score matching and denoising autoencoders. Neural Computation , 23(7):1661 X 1674, July 2011.
 Welling, M., Rosen-Zvi, M., and Hinton, G. Expo-nential family harmoniums with an application to information retrieval. Advances in neural informa-tion processing systems (NIPS) , 17, 2005.
 Zou, W.Y., Zhu, S., Ng, A., and Yu, K. Deep learning of invariant features via simulated fixations in video.
In Advances in Neural Information Processing Sys-
