 In several applications involving regression or classification, along with making predictions it is important to assess how accurate or reliable individual predictions are. This is par-ticularly important in cases where due to finite resources or domain requirements, one wants to make decisions based only on the most reliable rather than on the entire set of pre-dictions. This paper introduces novel and effective ways of ranking predictions by their accuracy for problems involving large-scale, heterogeneous data with a dyadic structure, i.e., where the independent variables can be naturally decom-posed into three groups associated with two sets of elements and their combination. These approaches are based on mod-eling the data by a collection of localized models learnt while simultaneously partitioning (co-clustering) the data. For re-gression this leads to the concept of  X  X ertainty lift X . We also develop a robust predictive modeling technique that identifies and models only the most coherent regions of the data to give high predictive accuracy on the selected subset of response values. Extensive experimentation on real life datasets highlights the utility of our proposed approaches. H.2.8 [ Database Management ]: Database Applications X  Data Mining Algorithms Ranking predictions, dyadic data, co-clustering, regression
In certain prediction problem s, one is interested in only the most accurate or useful predictions rather than in the performance over the entire test/scoring data. Such sce-narios typically arise in applications where acting on each prediction requires a certain quantity of a limited resource and/or the cost incurred depends on the inaccuracy of the prediction. Perhaps the most well known example comes from direct marketing where one is interested in identifying a subset of the target population most likely to respond to a solicitation (positive class) [20]. Since making irrelevant offers is not only unprofitable but also harmful to customer experience, the choice of the target sub-population is criti-cal. In this context, the performance of a model is evaluated based on the response rate in the top x quintiles via a gain (lift) chart, rather than on the overall classification accu-racy. Determining the most relevant documents/pages for a search query has a similar flavor. Note that these are both classification examples in which there is a rare positive class, and one tries to identify a small subset of the records that most likely belong to this class.

A qualitatively different consideration is encountered in certain regression settings. Consider a stock market player in options, who wants to predict closing stock prices. The sign of price change is not critical as he can use both  X  X uts X  and  X  X alls X , and he can bet on only a limited number of stocks because of a limited budget. In this situation, the accuracy of prediction (difference from the actual closing value) for a limited number of stocks is key to this person X  X  ability to maximize his expected returns. A similar situation is faced in predicting other fu tures (energy usage, currency rates, etc.) for arbitraging strategies. Note that there has been little study of selection/ranking of regression results based on accuracy in the data mining literature. In this paper, we focus on the problem of ranking predictions of numeric quantities by their reliability, so that one is able to identify a subset of predictions that are the most accurate. Though the emphasis is on regression settings, we will also show how the methodology can be applied to classification problems as well.

The problem of estimating the uncertainty associated with the prediction of a regression model has been examined in the statistics and neural networks literature [12, 2, 13]. The typical approach is to learn a linear/non-linear map from the independent variables to the response variable and then esti-mate the uncertainty of each prediction as a function of the uncertainty in the regression coefficients. In this paper we show that a radically different and more effective approach can be taken if the data is structured such that the inde-pendent variables can be naturally partitioned into two (or more) groups and a pivoting operation on the response vari-ables can result in organizing them as entries in a matrix . Data with this structure is referred to as dyadic (bi-modal) data [1] and is now pervasive in a variety of real life appli-cations. Dyadic data consists of measurements on dyads, which are pairs of elements from two different sets (modes). The measurements can be represented as the entries of a ma-trix, whose rows and columns are the two sets of elements. The independent variables, also referred to as covariates are associated with the entities along the two modes. Contin-uing with the stock market example, assume that we have the prices for a set of stocks predicted by a certain number of analysts. The independent variables are attributes asso-ciated with each stock, characteristics of each analyst and attributes associated with a stock-analyst pair, e.g., how good the analyst X  X  prediction has been for the stock in the past. The data can now be thought of as a stocks by analysts matrix with the response variable, i.e., the predicted price, represented by each cell of the matrix. Note that the known entries in this matrix form the labeled dataset and the miss-ing values are the ones that we desire to estimate. Datasets consisting of web page-ad clicks, search query-web page rel-evance, user-movie ratings or customer-product preferences are other examples of dyadic data. While this paper pri-marily considers dyadic data, the extension of our proposed approach to tensor (multi-modal) data is straightforward.
We begin by formulating a simple but effective ranking strategy using a single model learned on the data. Motivated by the observation that in a realistic setting the dataset is typically too large and heterogeneous to be adequately rep-resented by a single global model, we propose ranking strate-gies based on the Simultaneous CO-clustering And Learning (SCOAL) framework [7]. SCOAL is a technique proposed for modeling large-scale, heterogeneous data by partitioning the data matrix into a grid of blocks (co-clusters) while simul-taneously learning models in each block. We formulate two novel ranking schemes, (i) Row-Column Ranking, and (ii) Block Ranking, and show that the use of multiple localized models that are learnt on dyadic data leads to a better as well as more actionable ranking.

Another contribution of our work is Robust SCOAL, a novel predictive modeling technique that selectively mod-els only the most coherent parts of the data. A different viewpoint of this technique is as an approach for automatic outlier detection and removal that is carried out simultane-ously with the modeling process. Robust SCOAL identifies and retains only those parts of the data where accurate pre-dictive models can be learnt. The predictions within the selected data subset can be subsequently ranked. Finally, we introduce a new certainty lift measure that evaluates the improvement in error for a selected subset of predictions.
What distinguishes our proposed approaches from the tra-ditional techniques for error bar estimation [12, 2, 13] is that, our approaches can take advantage of the structure of dyadic data rather than treat it as a flat collection of points. Moreover, while most existing techniques are based on learning a single model using the available training data, we learn a collection of localized models that provide a bet-ter representation of the input space and a finer resolution of prediction uncertainty. Comparisons of our ranking proce-dure with ranking based on standard methods of prediction error estimation on real life datasets highlight the benefits of our approach. Additionally, our ranking strategies with a collection of localized models are readily applicable to both regression and classification problems.
Determining the standard error of the predictions of a linear regression model is well established, text-book mate-rial [14]. This is not as direct for non-linear models, and there has been a considerable amount of work in the neu-ral network community on determining the uncertainty of network predictions [17, 13]. There are several references in the literature on the application of resampling based tech-niques for prediction error estimation. Heskes [12] uses the variance of the outputs of an ensemble of neural networks, trained on bootstrap replicates of the training dataset, for computing confidence intervals on the output for new data points. This technique is shown to do better than [17] on synthetic data. High computational effort however is one of the main drawbacks of resampling approaches. While re-sampling techniques construct multiple global models, each of which represents the entire input space, our approach is based on a collection of local models (Section 5). To the best of our knowledge, no one has used an ensemble of localized models for estimating the accuracy of individual predictions.
Bayesian techniques provide another way of estimating prediction uncertainty based on the variance of the predic-tive distribution computed as a function of the input [3, 2]. We compare our proposed techniques with a Bayesian linear regression approach [3] in Section 10.

An example of a recent non-Bayesian approach is the work by Cawley et al. [5] where they assume heteroscedasticity as in [2] and use an iterative procedure based on kernel ridge regression to simultaneously model the mean and variance of the target distribution as functions of the input. A novel approach by Shrestha and Solomatine [21] involves cluster-ing the residuals into homogeneous groups using fuzzy c-means and then constructing the prediction limits for each cluster, based on the distribution of the errors within the cluster. The prediction limits for each training point are then estimated according to its membership in each cluster. A linear/non-linear mapping learnt from each input point to its prediction intervals is used to make estimates for test points. While the learning of the model and clustering the model residues are sequential steps in this work, our ap-proach, discussed in Section 5, is based on performing these two tasks simultaneously.

Another related body of work, specific to classification problems, is that on abstaining/cautious classifiers, where the classifier refrains from making a decision in cases where its prediction is uncertain or unreliable [6, 9]. The challenge here is to suitably trade off the reduction of the number of misclassified instances (errors) and the number of unclassi-fied instances (abstentions). Recently, techniques that use ROC analysis to efficiently build an abstaining binary clas-sifier that is optimal according to three different, practically relevant performance criteria have also been proposed [18]. We develop a strategy to rank predictions based on their reliability (Section 7), using which, the most reliable n pre-dictions can be selected, given n . Cautious classifiers are complementary since they can provide a suitable value of n based on the error rate/abstention tradeoff.

The recently proposed SCOAL [7] and PDLF [1] approaches deal with predictive modeling of large, heterogeneous dyadic data. More details on the SCOAL approach are presented in Section 5. The Predictive Discrete Latent Factor (PDLF) model simultaneously incorporates the effect of the covari-ates, through a global model as well as any local structure that may be present in the data, through a block (co-cluster) specific constant. However, neither of these techniques con-sider the uncertainty of the predicted values.

Our proposed idea of ranking co-clusters and rows/columns of the data matrix based on their prediction accuracy is in-spired by the recent work in co-clustering, which involves mining dense, coherent co-clusters from large, noisy datasets, by pruning away irrelevant regions of the data [8]. Note that [8] is only focused on clustering; no prediction models are formed.

Notation : Lower case letters represent scalars, e.g., a , z , lower case, bold face letters represent vectors, e.g., b , c , upper case letters like Z, W represent matrices and calli-graphic upper case letters like T represent sets. Individual elements of a matrix, e.g., Z are represented as z ij ,where i and j are the row and column indices respectively.
Let the set of training data points be represented by pairs ( x k ,y k ), where x k is the vector of independent variables (covariates) and y k is the corresponding target. The problem is to learn a model that maps x to y and outputs a ranking of the model predictions on the test set by an estimate of their accuracy.

In the case of dyadic data, as discussed in Section 1, the response variable is associated with elements from two differ-ent sets (modes), which can be represented by the rows and columns of a matrix. The independent variables can be natu-rally partitioned into 3 groups; variables associated with the  X  X ow X  mode, those associated with the  X  X olumn X  mode and those associated with row-column pairs. More concretely, the response variable y can now be represented as the cells z ij of an m  X  n matrix Z , and we now denote the correspond-ing covariates x by x ij , which represents the independent variables associated with z ij 1 . We specifically adopt this notation to emphasize the dyadic nature of the data. The co-variate vector x ij can be partitioned into row attributes, r column attributes, c j as well as annotations associated with a row-column pair, a ij , i.e., x ij T =[ r i T , c j T , a up to two of these three vectors ( r i , c j , a ij ) could be absent. Example: A dataset of user-movie ratings is represented by amatrix Z of users by movies, with z ij denoting the rating given by user i to movie j . r i is the vector of user attributes, e.g., age, income, gender, c i represents the movie attributes, e.g., genre, release year, and a ij represents attributes asso-ciated with a user-movie pair, e.g., whether a user X  X  favorite actor is in the movie.

The matrix Z has missing values, which form the set of responses to be predicted. The missing values are handled by associating a weight w ij with each cell z ij .Theweightsof the known (training) matrix cell values can be set to 1, while missing values can be ignored during the modeling process by setting their weights to 0. In general, the weights are not restricted to 0 or 1 and can take other non-negative val-ues that reflect uncertainties associated with the responses. The problem can now be posed as predicting the missing entries in matrix Z , along with an estimate of the good-ness/certainty of the predictions. This will enable the selec-tion of a specified number of missing data entries on which the most accurate predictions are expected to be made.
Two subscripts are now used to denote row and column indices.
A simple approach to the above problem is to train a single  X  X lobal X  model that learns a map from the covariates to the response variable. For ease of exposition, consider a linear model y k =  X  T x k + u k ,where( x k ,y k )isthe k th data point. u k is the unobserved error term, assumed to be a random variable with E ( u k | x k )=0.

In the dyadic data notation, the response variable z ij  X  R is estimated by a linear combination of the corresponding covariates:  X  z ij =  X  T x ij ,where x ij T =[1 , r i T , c vector consisting of the covariates augmented with x 0 =1for the intercept, and the least squares estimates of the model parameters are  X  T =[  X  0 ,  X  x T ]. Let T represent the set of training data instances, of size s and let p be the number of independent variables.

Since  X  is estimated with imprecision, the predicted value  X  z ij is also subject to error. For the above multivariate linear regression model, the error variance is estimated by the fol-lowing standard approach [14], which we refer to as Global Var
Y is the design matrix, with rows of the form x uv T ,where ( u, v )  X  X  , i.e., w uv = 1 for a 0-1 weight matrix W .  X  be estimated by the mean squared error, given by The square root of (1) gives the standard error of the pre-diction  X  z ij . In the experiments in Section 10, we use ridge regression with error variance estimated as where  X   X  0 controls the amount of regularization [10].
Other alternatives to estimate prediction uncertainty, as discussed in Section 2, are to employ a resampling based technique [12] or a Bayesian technique [3], where the uncer-tainty is estimated by the variance of the predictive distri-bution. However, all these procedures implicitly flatten the data matrix and hence fail to exploit the inherent dyadic structure of the data.

For dyadic data fitted with a single (linear or non-linear) model, we propose a new approach, referred to as Global Rank, to rank predictions by their estimated accuracy. 1. The average error for row i is its training mean squared 2. Similarly, the average error for column j is given by 3. Assuming independence of row and column errors, the 4. A ranking of the predicted entries is obtained based on
While a single learned model is adequate for simple pre-diction problems, it may not be sufficient to represent the heterogeneous population that very large classification or re-gression problems often involve. For instance, the problem of predicting customer preferences for products typically in-volves a diverse population of customers and a wide range of different products. It is unlikely that all the customer-product preferences can be well explained by a single model. Since it is more natural for a model to closely represent the preferences of only a subset of the customers for a subset of the products, the data might be better modeled by a collec-tion of suitably trained localized models [7].
The recently proposed simultaneous co-clustering and learn-ing (SCOAL) framework [7] aims to solve prediction prob-lems in heterogeneous domains, where the independent vari-ables can be naturally partitioned into two (or more) groups. The key idea is to co-cluster the entire data matrix into a grid of blocks (co-clusters) such that each block can be well characterized by a single predictive model that relates the independent variables to the response variables in the block.
For building the necessary background, we now provide a brief summary of SCOAL. The problem setting assumed is similar to that described in Section 3. Formally, let k , l represent the number of row and column clusters and let  X  ,  X  be mappings from the m rows to the k row clusters and from the n columns to the l column clusters respectively. Considering a regression problem, let us start with linear generative models for the data, for ease of exposition 2 .The aim of SCOAL is to find a co-clustering defined by (  X ,  X  ) and the associated k  X  l regression models that minimize the following objective function where
A suitable co-clustering (  X ,  X  ) can be obtained by an al-gorithm that iterates over two steps; the model update step and the row and column cluster reassignment step. In the model update step, the  X  for each co-cluster is a solution to a least squares problem. The cluster reassignment step greedily assigns each row/column to the row/column cluster that minimizes the squared error for the row/column. Each step is guaranteed to reduce the objective function and the algorithm hence converges to a locally optimal solution. Af-ter the algorithm converges, a missing value z ij is predicted as  X  z ij =  X  gh T x ij ,where  X  ( i )= g and  X  ( j )= h .
By generating multiple localized models, SCOAL provides novel ways to rank predictions by their expected quality. In this section we propose two such approaches: (i) Row-Col Ranking, (ii) Block Ranking.
 Row-Col Ranking. The Row-Col Ranking technique is based on an estimation of the prediction errors as given by Generalization to other models is discussed in Section 5.1. Equation (3). The average error for row i ,where  X  ( i )= g is given by The average error for column j is computed similarly. As before, the error for a missing entry z ij is the sum of the corresponding average row and co lumn errors. Intuitively, since the collection of local models characterize the data better than a single model, the resulting ranking would be expected to be better as well.
 Block Ranking. The intuition here is that for a hetero-geneous dataset the fit of the co-cluster models, quantified by the training reconstruction error (MSE), differs across co-clusters. Models in noisy and sparse regions of the input space will have poorer fit, while other models may capture more coherent relationships between the covariates and the response variables. Hence, the first step is to rank the pre-dictions by the mean squared error of the co-clusters they are assigned to. The mean error for co-cluster ( g, h )iscom-puted as
P Ranking by co-cluster membership helps in identifying re-gions of the input space that are not adequately represented by the learnt models and gives the predictions in these re-gions a lower rank. Further, a second level of ranking can be done within each co-cluster ( g, h ), in which the predictions are ranked by estimating their prediction errors as a sum of the average co-cluster row and co-cluster column errors, i.e., the error for a predicted value in row i ,column j is E i where,
SCOAL and the associated Row-Col and Block Ranking procedures are readily extensible to other predictive mod-els as well as to classification problems by modifying (4) and/or (5) [7]. For example, the data can be modeled by a collection of neural network models or regression models with the L 1 norm (Lasso [11]). In our experiments described in Section 10 we use ridge regression, which reduces the pos-sibility of overfitting while learning a larger number of model parameters ( k  X  l  X  vectors) as compared to a single linear regression model.
As discussed in Section 1, for several applications the ob-jective is not to make predictions for every missing data en-try, but to make very accurate predictions for a certain frac-tion of the missing data. Moreover, several domains involve datasets that are often large and noisy, and the discrimina-tive patterns are limited to only a small subset of the data. Also, the data could contain outliers that could largely skew the prediction models that include them. Simpler and more generalizable models can be learnt by ignoring the outliers and the non-informative parts of the data. Hence we pro-pose Robust SCOAL, a technique for selecting and modeling a suitable subset of the data.

Robust SCOAL aims at simultaneously co-clustering the data and learning predictive models in each co-cluster, with the added constraint that only a predetermined number of rows and columns are assigned to row and column clusters. More concretely, with the same problem setting as before (Section 3), our aim here is to simultaneously select and cluster s r  X  m rows and s c  X  n columns of Z ,intoagridof k row clusters and l column clusters, such that the response values in each co-cluster are predicted by a common regres-sion model. The exact value of s r and s c is not critical in the setting of this paper, as this induces the first stage of selection only, and a second stage is needed in any case so long as s r and s c are not too small. Let K and L denote the sets consisting of the s r clustered rows and the s c clustered columns respectively. Let  X  be a mapping from the s r rows  X  X  to the k row clusters and  X  be a mapping from the s c columns  X  X  to the l column clusters. We want to find a co-clustering defined by (  X ,  X  ), sets K and L and the asso-ciated set of regression models {  X  s } for specified s r that minimize the following objective function P
Note that the objective function (6) (i) involves the squared error summed only over s r  X  s c elements of Z , and that (ii) it is based on the mean error rather than the total error. In the presence of missing entries in the data matrix, the denominator in (6) will differ for different choices of sets and L and hence needs to be considered in the cost function. This point is especially important for sparse data, where a substantial number of matrix entries are missing. In this scenario, if the total error was optimized rather than the mean error, the solution would be a very sparse subset of the data with highly overfit models, since missing entries have w uv = 0 and do not contribute to the error. In the most extreme case, the solution would be an empty s r  X  s block of the matrix Z with zero error.
As in the case of SCOAL, a co-clustering (  X ,  X  ), that de-creases the cost function can be obtained by an iterative algorithm that alternately updates co-cluster models and row/column cluster assignments. The algorithm begins by initializing (  X ,  X  ) either randomly or by a suitable clustering procedure followed by a selection of s r rows and s c columns. Given the initial cluster assignments (  X ,  X  )oftheselected s rows and s c columns, the co-cluster models are constructed, i.e., the coefficient vector  X  is learnt for each co-cluster. In case of 0/1 weights, this is done by least squares regression using only the non-missing (training) values within the co-cluster. In case of a general set of weights, the  X  is a solution to a weighted least squares problem.

For a fixed column cluster assignment and a set of co-cluster models, the row cluster update step involves assign-ing rows to row clusters and selecting s r of m rows to par-ticipate in the current clustering. If row u is assigned to row cluster g , i.e.,  X  ( u )= g , the row error is the error summed over the appropriate s c elements in the row given by For a fixed L ,  X  and set of  X  s,thebestchoiceoftherow cluster assignment for row u is the g that minimizes the row error, i.e.,  X  new ( u )=arg g min E u ( g ). Each of the m rows is hence assigned to the row cluster that minimizes the row error.

Since the objective function (6) includes the sum of weights term in the denominator, it cannot be decomposed over the rows. A naive greedy solution of selecting the s r rows with lowest mean row error is hence not optimal for the row selec-tion problem. Instead, we select the s r rows that minimize An optimal selection of s r rows can now be obtained by using a standard dynamic programming approach akin to the solution of the knapsack problem in [16].

A similar approach is used to update the column clus-ters. Note that the rows/columns that are not included in the current s r / s c rows/columns assigned to co-clusters are still retained since they could be included in the co-clusters in future iterations. The algorithm alternates between the row/column cluster update and model update steps until convergence. The overall algorithm is described in Figure 1. Step 1 reduces the objective function because of the optimal-ity of the pseudo-inverse solution to linear regression, steps 2 and 3 are greedy updates and directly reduce the objective function. The objective function hence decreases in every it-eration. Since this function is bounded from below by zero, the algorithm is guaranteed to converge to a local minimum.
If the data is extremely sparse then, for given s r and s the row/column selection step could involve empty rows or columns, which have zero weight and hence zero cost. Al-though selecting such rows/columns will be optimal from the point of view of the cost function, it will not result in a well generalizable set of models for making accurate predictions on test data. We hence restrict the dynamic programming steps (2b and 3b) to select from the set of non-empty rows/columns. This avoids the modeled part of the data matrix from including rows and columns with all entries missing.

While steps 1, 2a and 3a of the Robust SCOAL algorithm are linear in the size of the data, the complexity of steps 2b and 3b is O( ms r )andO( ns c ), i.e., quadratic in the worst case. If the number of missing entries in the data matrix is comparatively small and the entries are missing at ran-dom, then the (6) does not vary too much over different s r  X  s c blocks of the matrix and can be ignored. An efficient heuristic then is to replace the dynamic programming steps 2b and 3b by a greedy selection of the s r rows and s c columns with the lowest row and column errors respectively. This greedy se-lection can be performed in linear time by the efficient order statistics based algorithm proposed by Blum et al. [4]. We verified empirically on the ERIM dataset (Section 10) that there is no significant difference between the greedy strategy and dynamic programming in terms of prediction accuracy. Algorithm: Robust SCOAL Input: Z m  X  n , W m  X  n ,covariates, s r , s c , k , l
Output: (  X ,  X  ), co-cluster models  X  s 1. Begin with an initial co-clustering (  X ,  X  ) 2. Repeat 3. Step 1: Update co-cluster models 4.  X  [ g ] k 1 ,[ h ] l 1 , 5. Train a linear regression model with 6. all the training samples ( x uv ,z uv )in 7. co-cluster ( g, h ), with weights w uv , 8. to obtain an updated  X  gh . 9. Step 2: Update  X  10. 2a.  X  [ u ] m 1 , 11.  X  ( u )=arg g min 13. 2b. K =thesetof s r rows selected 14. by dynamic programming. 15. Step 3: Update  X  16. 3a.  X  [ v ] n 1 , 17.  X  ( v )=arg h min 19. 3b. L =thesetof s c columns selected 20. by dynamic programming. 21. Until Convergence 22. Return (  X ,  X  )and  X   X  X  Similar to the Row-Col Ranking procedure described in Section 5, the Robust SCOAL predictions can be ranked by an estimation of the predi ction error, which is the sum of the average row and column errors. Note that the aver-age row/column error is computed over only the rows and columnsthatbelongtosets K and L respectively.

Analogous to the discussion in Section 5.1, Robust SCOAL can also be generalized to other predictive models and/or loss functions. For instance, the experiments in Section 10 use Robust SCOAL with ridge regression.
The focus so far has been on assessing the reliability of the output of a regression model. In classification problems as well, it may be of interest to select a specified number of the most accurate or reliable predictions. A motivating example is the ecological problem of predicting the absence/presence of a set of species in a set of locations. Extremely reli-able predictions for a few location-species pairs lead to more fruitful ground research rather than the burdensome task of investigating a larger set of predictions with lower overall accuracy. In this section, we show that if a classification problem involves data with a dyadic structure as described in Section 1, we can adapt the proposed ranking technique to obtain a ranking of the classifier predictions by their reli-ability. Analogous to the regression setting, note that for a 2-class problem we treat the 2 classes symmetrically and aim to find the most accurate predictions, irrespective of the pre-dicted class label. Our perception of prediction  X  X ccuracy X  in this case is simply the probability of correct classification for x ij , and so aposteriori class probabilities very close to 0 or 1 are ranked higher as compared to probabilities close to the prior. Hence, if the data is modeled by a single,  X  X lobal X  probabilistic classifier, max i ( P (class i | x k )) can be used to rank predicted values.

For data with a dyadic structure, the response variable is represented as the entries of a matrix Z as before, with covariates associated with the corresponding modes. The entries in matrix Z are now class labels, e.g., +1 ,  X  1 for 2-class problems. We use the SCOAL (meta)-algorithm to si-multaneously partition the matrix into co-clusters and learn classification models in each co-cluster. One can use logis-tic regression classifiers, in which case the SCOAL objective function will be the total log loss. We then get a ranking of the missing class labels based on the class membership prob-abilities estimated by the co-cluster models. Experimental evaluation shows that the ranking provided by this approach is better than that obtained by a global model. The Robust SCOAL algorithm described in Section 6.1 can also be easily extended to classification models by suitably changing the objective function (6) to the loss function of the classifier.
The ranking techniques discussed so far in Sections 4, 5 and 6 result in 3 conceptually different approaches for select-ing the subset of the missing entries to be predicted. Both Global Rank and Row-Col Ranking select individual entries in the data matrix. In contrast, for Block Ranking the unit of selection is a co-cluster rather than individual matrix en-tries, since the first level of ranking is based on co-cluster membership. Finally, Robust SCOAL selects the most accu-rately predictable parts of the data matrix by throwing away rows and columns with large e rrors. Its unit of selection is hence individual rows and columns. The selection technique that is the most relevant to a certain problem depends on the application.
 In applications involving extremely large datasets, Robust SCOAL identifies a smaller subset of the data that can be focused on and analyzed in further detail. For example, in a direct marketing application, it identifies a group of cus-tomers and products for which predictions can be made with very high confidence. This result is possibly more action-able from a marketing viewpoint than selecting individual customer-product combinations in an unstructured manner from the entire customer-product base. Robust SCOAL is also well suited to datasets known to have substantial out-liers since it performs simultaneous outlier detection and pruning during the modeling process.

Selection at the co-cluster level is the most appropriate when the subset of the predictions on which decisions/actions are taken is required to satisfy certain criteria imposed by the application. For example, a certain e-commerce appli-cation might constrain the predictions to be localized to a certain geographical region or to users in a certain age or income group. A retail business may want to identify cus-tomers whose purchase decisions are heavily influenced by the price, and provide special discounts to them on products they are most likely to purchase. Ranking by co-clusters is also very interpretable since the co-cluster models can pro-vide insights on the degree to which different factors influ-ence customer purchases in various customer-product sub-groups.

An interesting point is that the proposed ranking ap-proaches can be combined to make selections at multiple resolutions. Robust SCOAL can first select a set of rows and columns, which can be followed by a ranking of the co-clusters, with a finer ranking of individual entries within each co-cluster.
Having discussed a number of approaches to select the most certain predictions, we now formulate a  X  X ertainty lift X  measure that evaluates the improvement in the error of a selected subset of model predictions as compared to the error of a baseline model on the entire test set. With squared error as the loss function, the certainty lift is defined as where U represents the test set, V X  X  ,and s = |U| and  X  s = |V| . The baseline model is simply the mean of the response values in the training dataset, given by  X  y y model is the value output by a predictive model learnt on T . For example, for a given model, a certainty lift of 5 on a subset V of U , implies that the mean squared error on V is 5 times lower than the baseline error on U .
In this section we evaluate the proposed ranking proce-dures on real life datasets from two different regression ap-plications. Section 10.1 presents results on the MovieLens data, while Section 10.2 discusses results on the ERIM Mar-keting dataset.
The MovieLens dataset consists of 100,000 ratings (1-5) from 943 users on 1682 movies made available by the Grou-pLens Research Project at the University of Minnesota 3 . We use a set of 23 attributes including user demographics like age, gender, employment status and movie release year and genre. The dataset is extremely sparse, with the pro-portion of known user-movie ratings as small as 0 . 7%ofthe size of the data matrix. We assume ridge regression mod-els to predict the ratings and evaluate the quality of the predictions using mean squared error.

We evaluate our ranking techniques by comparing with three traditional approaches for computing the uncertainty of predictions of a linear regression model. The first is Global Var, which computes the standard error of a pre-dicted value using Eq. (2) 4 . The second approach, Global Resample, trains a set of ridge regression models on boot-strap samples of the training dataset and computes the vari-ance of the values predicted by the ensemble of models. A
The data can be downloaded from http://www.grouplens. org/system/files/ml-data.tar__0.gz
The value of the regularization parameter (  X  ), selected by cross validation, came out to be 0 for a global ridge regres-sion model. Hence, the standard error is equivalent to that given by Eq. (1). ranking of the data points in the test set is then obtained by sorting them in ascending order of their estimated stan-dard error/variance values. We a lso consider Bayesian linear regression (Bayesian LinReg), with a zero-mean, isotropic Gaussian prior [3]. The precision parameter of the Gaussian prior is selected by cross validation, while the variance of the additive Gaussian noise is set to the MSE obtained with a linear least-squares model. The ranking is based on the es-timated variance of the predictive distribution for each test point. Figure 2 compares the Global Var, Global Resam-ple (with 25 bootstrap samples) and Bayesian LinReg tech-niques with Global Rank, which uses the dyadic data struc-ture to provide the ranking (Eq. (3)), the SCOAL based Row-Col Ranking and Block Ranking and Robust SCOAL. k =4and l = 4 for the SCOAL techniques. Robust SCOAL is run to select s r = 890 rows and s c = 1550 columns, fol-lowed by Row-Col Ranking to rank order the selected pre-dictions. The SCOAL techniques use ridge regression mod-els with  X  =0 . 78, selected by cross validation. The x-axis specifies the fraction of the points in the test set that are pre-dicted, while the y-axis gives the cumulative mean squared error on the predicted set of points. At the last point on thex-axisalltheentriesinthetestsetarepredictedand included in the MSE. The plotted values are averaged over 10 random 80  X  20 % splits of the data as the training and test set. Figure 2: Comparison of ranking techniques on the MovieLens dataset.

The plot shows a significant improvement in the ranking obtained by techniques that use the dyadic data structure as compared to Global Var, Global Resample and Bayesian LinReg (almost superimposed in Figure 2, with MSE around 1 . 2 ). Since a collection of co-cluster models characterizes the data better than a single global model [7], the MSE of SCOAL on the entire training dataset is significantly lower than the MSE of a single global model, illustrated by the last point on the x-axis. Row-Col Ranking results in a use-ful ranking of the predicted values, with 10% of the test en-tries very accurately predicted with a MSE of 0 . 52. Robust SCOAL performs as good as Row-Col ranking, while Block Ranking, which ranks predicted values by co-cluster MSE, results in a flatter plot, possibly due to its more constrained ranking mechanism.

Figure 3 illustrates the certainty lift, computed according to Eq. (7), for different prediction techniques. The SCOAL based approaches as well as Global Rank provide substantial improvement over the baseline and also do much better than Global Var. Figure 3: Certainty Lift of different prediction ap-proaches on the MovieLens dataset.
In this section we use the publicly available ERIM dataset consisting of household panel data collected by A.C. Nielsen, which is well known in the marketing community and has been used by several researchers [15, 19]. This dataset has purchase information for six product categories over a period of 3 years from 1985-1988 for households in Sioux Falls, South Dakota and includes household demographics and product characteristics. We preprocess the data as dis-cussed in [7], resulting in a data matrix of 1714 households and 121 products from 6 product categories (ketchup, tuna, sugar, tissue, margarine and peanut butter). The covari-ates include 6 household attributes -income, number of res-idents, male head employed, female head employed, total visits and total expense and 3 product attributes -market share, price and the number of times the product was ad-vertised. The matrix cell values are the number of units of a product purchased by a household, aggregated over the time the household was tracked.

The data matrix is extremely sparse, with 74.86% of the values being 0. The distribution of the response values is also very skewed. 99.12% of the values are below 20, while the remaining values are very large and range up to around 200. We consider these few, large values ( &gt; 20 # of units purchased) as outliers with respect to the rest of the data.
Since the products are from 6 different product categories, the product attributes and the number of units of the prod-uct purchased vary widely from one category to another. We hence standardize the product attributes and the matrix cell values as done in [7] to make them comparable across cate-gories.

Figure 4 compares various ranking techniques on the ERIM dataset. The SCOAL techniques are run with k =4and l =4andRobustSCOALisrunwith s r = 1700, s c = 150. The ridge regression parameter  X  for the SCOAL techniques is set to 0 . 98 and is selected by cross validation. The  X  se-lected for a global ridge regression model is 0 . 84. Note that the MSE is computed on the original data, by back trans-forming the standardized values. The trend of the results is
URL: http://www.gsb.uchicago.edu/kilts/research/ db/erim/ similar to that in Figure 2. Global Rank and the SCOAL ap-proaches (Row-Col and Block Ranking) that use the dyadic data structure do significantly better than the resampling, the Bayesian linear regression and the standard error esti-mation approaches. Although the average prediction error of Row-Col Ranking and Global Rank on the entire test set is almost the same, one can observe that over different fractions of the test entries predicted, Row-Col Ranking is slightly better than Global Rank. This is possibly due to a better estimation of prediction errors caused by an improve-ment in the overall fit of the co-cluster models as compared to a single global model. Figure 5 compares the certainty lift for different prediction techniques. Observe that Row-Col Ranking gives an improvement of almost 25 times on 10% of the test set. Figure 4: Comparison of ranking techniques on the ERIM dataset. Figure 5: Certainty Lift of different prediction ap-proaches on the ERIM dataset.

Linear regression based on the squared error cost func-tion is not very robust to outliers and a few outliers could completely skew the model results. While the use of ridge regression models mitigates the effect of outliers to some ex-tent, there is still some sensitivity to outliers, resulting in a largeMSEontheentiretestset. Wenowevaluatetheabil-ity of Robust SCOAL to automatically identify and prune away outliers, where an outlier is defined as a response value (# of units purchased) &gt; 20. Table 1 displays the percent-age of the total number of outliers detected and discarded by Robust SCOAL for different sizes of the data modeled, specified by the s r and s c values. k and l are both set to 4 for Robust SCOAL. The results are averaged over 10 ran-dom 80  X  20 % train-test splits of the data. The last row of the table is for the case where s r = m and s c = n , i.e., no rows and columns are discarded. One can observe that the % of outliers discarded is consistently much larger relative to the % of data discarded. The ratio of the % of outliers discarded to the % of data discarded (last column) is hence high, indicating that Robust SCOAL is able to selectively prune away outliers. It is interesting that discarding even a few rows and columns results in throwing away a large fraction of the outliers. This results in a dramatic reduction in the prediction error on the selected subset of test points, which is still a substantial fraction of the missing values, e.g., the MSE on 85 . 9 % of the test points is 8 . 225 when s = 1573 and s c = 115, as compared to a MSE of 15 . 787 ontheentiretestset. Table 1: Outlier pruning by Robust SCOAL for varying s r and s c values on the ERIM dataset.
The task of selecting the top n predictions based on their certainty has not been adequately explored, although it is very naturally applicable in a wide range of practical scenar-ios. In this paper we propose novel approaches for mining the most certain predictions in regression and classification problems involving large, heterogeneous data with a dyadic structure. Our approaches are based on the key idea of modeling the data by a collection of multiple, localized mod-els learnt by exploiting the dyadic structure. As illustrated in Section 10, the proposed ranking techniques give supe-rior results on a variety of real life datasets as compared to classical uncertainty estimation approaches based on global models. Of the proposed ranking methods, Robust SCOAL and Block Ranking are more useful than Row-Col Rank-ing from a practical viewpoint since they enable selection of structured subspaces of the data, which is more actionable. Another advantage of our multiple models based approach is that the selection of  X  X ertain X  predictions can be done at varying resolutions, providing application specific flexibility as well as interpretability.

The idea of  X  X ertainty lift X  can be useful in several appli-cations. In addition, it can be used as a basis for devel-oping active learning techniques that are radically different from traditional uncertainty sampling approaches. Another aspect worth exploring is th e use of robust error functions, which suitably weigh errors from different entries in the data matrix differently. This will provide a  X  X oft X  selection of the subset of the data to be modeled, which may be more flex-ible than pruning entire matrix rows/columns as done by Robust SCOAL.
 Acknowledgments : This research was supported by NSF grant IIS 0713142. [1] D. Agarwal and S. Merugu. Predictive discrete latent [2] C. Bishop and C. Quazaz. Bayesian inference of noise [3] C.M.Bishop. Pattern Recognition and Machine [4] M. Blum, R. Floyd, V. Pratt, R. Rivest, and [5] G. Cawley, N. Talbot, and O. Chapelle. Estimating [6] C. Chow. On optimum recognition error and reject [7] M. Deodhar and J. Ghosh. A framework for [8] M. Deodhar, G. Gupta, J. Ghosh, H. Cho, and [9] C. Ferri and J. Hernandez-Orallo. Cautious classifiers. [10] J. Fox. Applied Regression Analysis, Linear Models, [11] T. Hastie, R. Tibshirani, and J. Friedman. The [12] T. Heskes. Practical confidence and prediction [13] J.Leonard, M.Kramer, and L.Ungar. Using radial basis [14] J. Johnston. Econometric Methods .NewYork: [15] B. Kim and M. Sullivan. The effect of parent brand [16] J. Kleinberg and E. Tardos. Algorithm Design . [17] A. Nix and A. Weigend. Estimating the mean and [18] T. Pietraszek. On the use of ROC analysis for the [19] P. Seetharaman, A. Ainslie, and P. Chintagunta. [20] D. Shepard. The New Direct Marketing: How to [21] D. Shrestha and D. Solomatine. Machine learning
