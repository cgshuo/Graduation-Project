 Many data providers make their data available through Web service APIs. In order to unleash the potential of these sources for intelligent applications, the data has to be com-bined across different APIs. However, due to the heterogene-ity of schemas, the integration of different APIs remains a mainly manual task to date. In this paper, we model an API method as a view with binding patterns over a global RDF schema. We present an algorithm that can automatically in-fer the view definition of a method in the global schema. We also show how to compute transformation functions that can transform API call results into this schema. The key idea of our approach is to exploit the intersection of API call re-sults with a knowledge base and with other call results. Our experiments on more than 50 real Web services show that we can automatically infer the schema with a precision of 81%-100%.
 H.4 [ Information Systems Applications ]: Miscellaneous Algorithms Schema mapping, web services, views Web Services (WS). In recent years, several important content providers such as Amazon , musicbrainz , IMDB , geonames , Google , and Twitter have chosen to export their data through Web services. These services cover a large vari-ety of domains: books, music, movies, geographic databases, transportation networks, social media, even personal data. This trend gained momentum thanks to the Open Data Ini-tiative, the success of mash-up applications, and new ini-c  X  http://www.last.fm/api/getAlbums?query=artist
Parameters: tiatives that grant users programmatic access to their per-sonal data. Users can access the data by invoking services, but they can hardly copy the entire content of the remote source. Hence, a Web service seems to be a sweet-spot in the trade-off between sharing the data and protecting it.
The wealth of data exported by Web services is an oppor-tunity for the development of new intelligent applications. For instance, it is possible to develop an application that proposes a trip to a concert. This application could gather concert recommendations from a social Web service such as Facebook  X  X  or Twitter  X  X , retrieve offers for concert tick-ets from a ticketing Web service, check the user X  X  calendar through a Web service from Google Calendar, load train stations from Geonames, and plan the trip through a travel Web service. The central challenge to such an endeavor is that the application has to join data across different services. This is difficult, because each Web service operates under its own local schema.
 Modeling Web Services. A Web service is essentially a parameterized query over a remote source. In this paper, we concentrate on REST Web services. These services work by accessing a parameterized URL. For example, Last.fm offers a Web Service which, given an artist as input entity, returns the birthdate, the gender, and the albums of the artist. Fig-ure 2 shows how this service is presented on the Last.fm Web page. We say that artist is the input type of this Web Service. In order to call this Web service, we replace the string  X  X rtist X  by an input entity , says  X  X rank Sinatra X , and access the URL. The server responds by sending the results of the request, which are usually in XML or JSON. Figure 3 shows the result of our example call. It contains the albums of Sinatra with their title, and all their singers, including Sinatra himself. The challenge is now to make this output interoperable with the results from other Web services. Global Schemas. In order to make the service interoper-able with other services, the state of art solution [15] is to assume a common global schema. Then, the Web services are represented as parameterized conjunctive queries (i.e., views with binding patterns) over this global schema. In our example, the global schema could contain relations such as created (for an artist who released an album) or label (for the relationship between an entity and its name). Expressed ) , birthdate ( x,y 3 ) , gender ( x,g ) , label ( g,y 5 ) in this global schema, the service becomes the query shown in Figure 1. Such a view is essentially a parameterized con-junctive query , where y 4 is the input parameter (the name of the artist) and all the other arguments are output param-eters (the birthdate, the gender, the album, and the release date of the album). It is common to distinguish between an entity and its name. For example, while the g will be some internal identifier for a gender, the y 5 will be the label of that gender, such as, e.g.,  X  X emale X . The goal is to have all Web services expressed as views over the same global schema. This way, applications can uniformly reason about Web services in the terms of the global schema.
 Problem Description. The central challenge with global schemas is that each Web service has to be mapped into this global schema. While the orchestration of Web ser-vices has received much attention lately, the transformation of services into the global schema is often done manually. Our goal is to deduce the schema fully automatically. More precisely, our goal is
Given: -the URL and the input type of a Web service (Fig. 2) -a global schema
Compute: -the view of the Web service in the global schema (Fig. 1) The URL of the Web Service and the input type can be found by a non-expert user on the Web page of the Web service (as in Figure 2). No knowledge of the output schema of the Web service is required. On the contrary, our goal is to deduce this output schema automatically.

This problem is challenging for several reasons. First, the node labels in the call results are usually vacuous and do not give away any semantics. In the example (Figure 3), they are just  X  X  X ,  X  X  X , and  X  X  X . Second, it is not clear which nodes in the call result correspond to entities in the global schema. In the example, one can guess that the nodes labeled with  X  X  X  correspond to singers. However, the nodes labeled with  X  X  X  correspond to nothing in particular. Third, relations in the global schema can correspond to paths of different length in the call result. For example, the gender of an  X  X  X  node is 1 hop away, but the birth date is 2 hops away. Finally, the challenge is to transform a call result (Figure 3) into tuples in the global schema.
 Our Approach. Our idea is to build upon existing knowl-edge bases (KBs). KBs such as YAGO [27] or DBpedia [3] provide a schema, a taxonomy of classes with their instances, and a several million facts in that schema. The instances can be used for probing the Web service. The facts can be used to guess the schema of the Web service. Our contributions are as follows:  X  An algorithm that, given the URL and the input type of a Web service, computes the view in the global schema fully automatically.  X  A method to compute a transformation function from the call results into the global schema.  X  A variant of our algorithm that can be used to discover hidden input types for Web services.  X  Experiments on more than 50 real-world Web services, showing that we can automatically create views with a precision between 81% and 100%, and discover hidden input types with a precision of more than 80%.
 The rest of this paper is structured as follows: Section 2 dis-cusses related work and Section 3 describes our data model. Sections 4 and 5 provide more details on the different parts of our method. Section 6 shows a baseline approach to our subject. Section 7 describes our algorithm for mining hidden input types. Section 8 presents experimental results, before Section 9 concludes.
To the best of our knowledge, no existing work can auto-matically infer views with binding patterns from Web ser-vices. However, our problem shares similarities with schema matching, query discovery, and Web service discovery. Schema Matching. Determining the description of a Web service in terms of a global schema can be seen as a special case of schema mapping or ontology alignment. This is the problem of matching the concepts and the relations of one schema to the concepts and relations of another schema. Several approaches have been developed to this end. ( i ) Approaches such as [4, 19] align the schemas of two KBs. In our scenario, we have only one KB, and the other  X  X B X  is the Web service with no formal schema. Even when we call the service, we do not necessarily get information about its schema. This is because the output of the service usually contains only vacuous node labels and no concept names (as in Figure 3). Therefore, schema based approaches cannot be applied in our setting. ( ii ) Several approaches use the overlap of instances to compute the alignment between two KBs [26, 16]. For us, the instances of the one  X  X B X  is a tree (the call result of the WS) in which some nodes may correspond to entities, and other nodes are just intermediate nodes. The tree does not tell us which nodes are entities and which are not. One solution is to convert every possible path of the tree into a fact. However, as we will see in Section 8, this solution does not work well for Web services. The reason is twofold: First, a node in the tree may actually combine the properties of several entities, which leads the approach ad absurdum. Second, a fact from the call result may correspond to a join of several relations in the KB. State-of-the-art approaches for KB alignment, however, expect a one-to-one mapping. ( iii ) Other approaches use machine learning to determine a mapping [9, 18]. They require training data, which is either provided by experts [9] or learned from pre-defined mappings [18]. In contrast, our solution requires no such input. We assume no human assistance during the mapping process. The user has no knowledge of the schema of the output. ( iv ) Works such as [25, 31] aim to bootstrap a global schema. In [25] e.g., the authors show how the schema of a new ontology can be bootstrapped by using as input the WSDL schema descriptions of the Web Services using the SOAP protocol. In our scenario, we target the REST pro-tocol, which provides no such information. Rather, our goal is to map services into an existing schema. ( v ) We differentiate our work from works that map HTML tables to KBs (e.g. [17, 30]). For tables it is clear that columns are mapped to class entities and pairs of columns to relations. In our case, in contrast, the encoding of relations is unknown.
 Query Discovery. Query discovery is concerned with the actual translation of data from one source to another. The state of art solution [19] exploits schema constraints, which are not available for Web services. Closest to our work, [28] derives intensional descriptions for WSs. However, the approach is semi-automatic, and requires the user X  X  assis-tance during the process. Furthermore, it assumes an im-plicit translation of call results into tables. It can only deal with WSs that return properties for one class of entities. Our approach, in contrast, can deal with the general case where WSs return nested descriptions of entities of different types.
 Web Service Discovery. The approaches of [10, 24] an-notate a Web service with the concepts for which it returns instances. Our work goes beyond that. We compute views with binding patterns that map the entire call results to the KB. We also compute transformation functions that enable a uniform access to different Web services and which can be directly used for orchestrating Web services.
 Orchestration and Mash-ups. Web service orchestration is concerned with joining several Web services in order to reply to a query [5, 23]. This work does not map services to a common schema. On the contrary, it requires that mapping as input. Other work proposes a new semantic model for representing Web services or mash-ups [22, 29]. Our work, in contrast, aims to represent Web services in the standard model of views with binding patterns [15].
 Wrapper induction. Wrapper induction algorithms [8, 12] are concerned with automatically constructing informa-tion extraction rules ( X  X rappers X ) for Web pages. However, wrapper induction does not map the sources to a global tar-get schema. Our work, in contrast, translates the schema of the WS into the classes and the relations of the KB. Data Fusion. Given a schema mapping, data fusion [11] is concerned with aligning the instances from several sources. In contrast, our goal is to compute the schema mapping. RDF Knowledge Bases. RDF is the standard of knowl-edge representation on the Semantic Web. The RDF model assumes a set of URIs, a set of literals, a set of classes, and a set of binary relations. A URI is an identifier of a real-world entity such as an organisation, a person or an ab-stract concept. These entities typically have a name , i.e., a human-readable string that identifies the entity. A literal is a string, a date, or a number. A class corresponds to a set of entities, such as the class of singers or the class of cities. A relation holds between two entities or between an entity and a literal. An element of a relation is called a fact , and we write r ( x,y ) to say that the entity with URI x stands in the relation r with the entity with URI y . A knowledge base (KB) is a collection of facts. The domain of a rela-tion is the class from which all first arguments of its facts are taken. Analogously, the range is the class of the second arguments. A relation is called the inverse of a relation r , written r  X  1 , if  X  x,y : r ( x,y )  X  r  X  ( y,x ). We assume that the KB contains all inverse relations and their correspond-ing facts. This extension results in facts that have literals as their first argument, a minor digression from the standard. It is common to depict a KB as a labeled directed graph, where the nodes are entities or literals and the edges denote facts. Figure 4 shows a snippet of a KB. The entities are shown in boxes while literals are shown in quotation marks.
A relation is called functional , if there are no two distinct facts that share the relation and the first argument. Real life KBs may be noisy, and contain distinct facts for relations that should be functional (such as bornIn ). Therefore, we make use of the functionality [26]: Here, # x :  X  is the number of values for x for which  X  holds. Perfect functional relations will have a functionality of 1.
We assume that the KB schema contains the standard relations type (connecting an entity to a class), subclassOf (connecting a class to a more general class), and label (con-necting an entity to a literal representing its name). If the KB contains the facts type(e, c) and subclassOf(c, g) , then by inference, it also contains the fact type(e, g) . We assume that all such inferences have been materialized.
 KB Paths. In all of the following, we assume a given KB. We will write r 1 ,...,r n ( x,y ) to mean that there is a path r ,...,r n from x to y that does not visit any node twice:  X  x 1 ,...,x n  X  1 : r 1 ( x,x 1 )  X  ...  X  r n ( x n  X  1 ,y )  X |{ x We write r 1 ,...,r n ( x ) to mean all entities reachable by that path from x , i.e., r 1 ,...,r n ( x ) := { y : r 1 ,...,r simplicity, we also use p for a path of one or several relation names. Web Services. A Web service API provides several Web services (WS). A WS can be called by accessing a parame-terized URL and by retrieving the call result document from the server. This document is typically in XML or JSON. For uniformity, we assume that call results in JSON are trans-formed to XML. This can be done by standard tools. In line with the XML standard, we represent an XML document as a rooted, unordered, labeled tree. We call the elements or the attributes of an XML tree structure nodes , and the values of the attributes or the contents of the elements text nodes . In Figure 3, structure nodes are depicted as circles while text nodes are shown in quotation marks.
 WS Paths. Given a WS f , we refer to the root of the call result for x by  X  f ( x ). We will omit the subscript f if it is clear from the context. We label an edge in the call result with the label of the target node of the edge. In Figure 3, e.g., the topmost edge will be labeled with  X  X  X . If an edge leads to a text node, we label the edge with the generic label  X  . As for KBs, we write l 1 /.../l n ( x,y ) to say that there is a path l 1 /.../l n with edge labels l 1 ,...,l n between node x and node y . In the example, r/a/id/ X  (  X  ( FrankSinatra ) , 456). As before, we write p for l 1 /.../l n and we define p ( x ) := { y : p ( x,y ) } .

This gives us a simple language that can express paths both in the call result and in the KB. This language is com-patible with SPARQL [1] (the language for querying KBs), with XPath (the language for querying XML documents), and with XSLT [2] (the language used for our transforma-tion functions). To distinguish paths in the call result from paths in the KB, we use  X / X  for XML and  X . X  for RDF data. Views With Binding Patterns. We abstract a WS as a view with binding patterns . Formally, a view with binding patterns is a conjunctive query of the form where r 1 ,...,r n are relation names from the global KB and q is a new relation name. The tuples  X  x 1 ,  X  x 2 ,...  X  x either variables or constants. The query must be safe , i.e. also in the body). Every variable is adorned in  X  a with a letter. We use i for input-output variables, and o for output variables. By input-output variable we mean that the result might return new bindings for that variable. A Web service returns information about the input entity. The problem is that this information can be expressed in a multitude of ways in the call results. However, we have noticed that in practice, the call results follow a number of common sense principles.
 I. The KB and the WS overlap. If the WS and the KB are from the same thematic domain (or if the KB is a general purpose KB), then we expect to see some overlap between the entities that the KB knows and the entities that the WS knows.
 II. The call result is connected to the input entity. A Web service call always contains data related to its input entities. Hence, we expect that the entities contained in the call result appear in the KB and that they are connected to the input entities by paths that do not exceed a certain length. In practice, this length is not larger than three [21]. III. An injective mapping from entities to nodes. Whenever a call result contains an entity, this entity is usu-ally represented as a structured node with sub-nodes. For example, in Figure 3, every album is represented by a sub-tree that is rooted in an a -node. Hence, we assume that for every entity in call result, there is at least one structured node that is shared by no other entity of the same class. We call this node an entity node .
 IV. Relations correspond to linear path queries. We observed that typically, a relation between two entities is encoded as a path between the entity nodes and that the sequence of path labels is used consistently, i.e., it always expresses the same relation.
 V. Text nodes map to literals in the KB. We have noticed that text nodes typically correspond to literals in the KB. Using a simple string similarity function, we can map a text node to an equivalent literal in the KB in the vast majority of cases.
Our algorithm for discovering the schema of a WS requires as input (1) a KB, (2) the URL of the WS, and (3) the input type of the WS. We assume that the input type is given as a class of the KB. Our algorithm proceeds in 4 steps: 1. Probing: We call the WS with several entities from the 2. Path Discovery: We discover paths in the call results 3. Path Alignment: We align the paths in the call results 4. View &amp; Transformation Function Construction: Based We will now detail these steps.
Our schema discovery algorithm requires a number of sam-ple call results from the WS. To generate these, we make use of the input type of the WS: We can call the WS with in-stances of the input type from the KB. For example, if the input type is given as singer , we call the WS with instances of the class singer from the KB.

Not every instance of the input type in the KB will return a valid call result from the WS. The WS may not know all instances. However, it is likely that the WS stores data for known entities such as famous actors, acclaimed books, or big cities. Our intuition is that the KB, on the other hand, will likely contain more facts about such  X  X mportant X  entities. Therefore, we rank the entities of the input type by the descending number of facts about them, and call the WS with the top k of them. In our experiments (Section 8), we show that a number of k = 100 samples is usually sufficient. This corresponds to less than 0 . 01% of the data that the tested APIs contain.
 Some WSs have more than one input. If we encounter a WS with input types t 1 ,...,t n , we find  X  X mportant X  entities of t 1 . Then we find in the KB the entities of t 2 ,...,t are connected to the entity for t 1 . Finally, we probe the WS with these n entities. In what follows, we treat the call results as if they were call results about the single input entity from t 1 . This will not hurt our mapping algorithm, since the other input entities are connected in the KB. If they are present in the call results, they will be discovered.
The probing gives us a set of input entities for which the calls have been executed and the results have been materi-alised. We call to such entities samples .
Given a sample x , our goal is to align paths in the call result that originate at the root  X  ( x ) with paths in the KB that originate at the input entity x . For example, for the call result in Figure 3, we want to find that the path r/a/t/ X  con-nects the root to the title of a song. So we want to align the path r/a/t/ X  in the call result with the path created.label in the KB. In the following, we assume a fixed sample input entity x , and we write ( r/a/t/ X ,created.label ) for our path alignment. To find these path alignments, we first generate all paths in the call result from the root to a literal, and all paths in the KB from the input entity x to a literal, and then align these paths.
 Generating XML Paths. We first enumerate the paths from the root  X  ( x ) to text nodes. The result is a set of pairs of a path p and a text node y , ( p,y ) , s.t. y  X  p (  X  ( x )). This set is easily computed in a depth first traversal of the XML tree. Hence, the computation is linear in the size of the call result.
 Generating KB Paths. Next, we generate the paths in the KB from x to literals. We compute the pairs of a path p and a KB node y 0 ( p 0 ,y 0 ) , s.t. y  X  p 0 ( x ) and y eral. As per Observation II , we limit the search to paths of length smaller or equal to three. Hence, the results can be computed in a depth first traversal of the KB graph origi-nating at x .

However, even short paths may lead to a huge number of results. For instance, livesIn.hasNationality  X  connects a person to all the other persons who have the nationality of the country where the person lives. Hence, the path con-nects  X  X nrelated X  entities via the very general concept coun-try . Our goal is to exclude relationships with an absurdly high number of outgoing edges such as hasNationality hasYearOfBirth  X  , hasGender  X  . For this purpose, we dis-card paths with relations whose functionality is smaller than  X  = 0 . 1. In practice, this value proved to be safe as no re-sults were lost.
 Path Pairs. The next step generates path pairs that are candidates for the alignment. Two paths are candidates if they select at least one value in common. Given the results of the previous steps for the sample, it computes pairs of form This means that we implicitly align the input entity x with the root  X  ( x ) (Observation II ).
 String normalization. Note that we need to check the equality of two strings ( y = y 0 ). However, caution is needed when comparing text values extracted from the XML result to literals in the KB, because the two sources may use dif-ferent writings. For example, the XML result may contain the string  X  X inatra, Frank X , while the KB may contain the string  X  X rank Sinatra X . The alignment of strings across such differences is a well-studied field of research. In our imple-mentation, we considered two strings equal if they share the same words, independent of punctuation signs, word order-ing, and case. For this purpose, we normalise the values by lowercasing the string, reordering the words in alphabetical order, and omitting punctuation. Let norm be the normali-sation function. Hence, in Equation (1), the equality y = y is replaced by norm ( y ) = norm ( y 0 ).
 Aligning Paths with Common Values. A simple pair-wise comparison of text nodes in the call result to literals in the KB can be highly inefficient. The number of pairs can easily exceed one thousand. Thanks to our normalisation, however, a pairwise comparison for similarity is no longer necessary: two strings are either identical or not considered similar. Therefore, we can use a merge-join algorithm. We sort each of the two sets of tuples produced in the previ-ous steps by the normalised value of the second component. Then we can merge the two lists in order to produce the re-sults. The complexity is n  X  log ( n ) where n is the cumulated size of the two lists. This yields a set of pairs of the form ( p,p 0 ), where p is a path from the call result and p 0 from the KB and both lead to the same value. These are our candidates for the path alignment. For a set of samples S , and a candidate pair of paths ( p,p we need to compute a confidence score for the alignment of p and p 0 with respect to S . We present two strategies to this end.
 Method. The simplest method to align an XML path p with a KB path p 0 (which works best in practice) is to use the overlapping of the results. We say that p 0 overlaps with p , if For simplicity, we use y to denote a literal and a text node with the same (normalised) value. An overlap can be stronger or weaker, depending on the proportion of sam-ples that overlap. We compute the confidence of the overlap as the number of samples for which their results overlap, divided by the total number of samples: Weaknesses of the Method. Although this simple method leads to remarkably good results, some alignments are lost. For instance, consider the alignment: ( r/a/s/l/e/  X  , diedOnDate ). If the living singers represent more than half of the input entities selected for sampling, then this align-ment is lost. Hence, we also experimented with a second strategy for path alignment, which is based on subsumption. Method. The subsumption strategy aligns two paths if the results of one are included in the results of the other. We are interested in mining KB paths subsumed by XML paths and vice-versa, XML paths subsumed by KB paths. Let p and p 0 two paths. We say that p 0 subsumes p , if For instance, consider the path pair ( /r/a/s/n/  X  , label ). The XML path selects the name of the input entity for which albums are returned as well as the names of the other persons who released the respective albums. However, the KB path selects only the name of the input entity. Hence we have: label  X  /r/a/s/n/  X  .
 Confidence. There are different ways to compute the con-fidence of such rules [20, 7, 13]. The problem in our case is that our data on both sides is incomplete: When the KB does not contain a certain fact, the WS can still return it, and vice versa. Hence, we opted to use the PCA confidence , a measure developed for AMIE [13]. This measure is partic-ularly suited for incomplete relations. The measure assumes that a source knows either all or none of the p -attributes of some x . Under this assumption, the formula counts as counter-examples for a rule p ( x,y )  X  p 0 ( x,y ) only those instances x for which the query paths p return an answer, but where y is not among these answers. This yields the following confidence measure: where #( x,y ) : A is the number of pairs ( x,y ) that fulfill A .
This formula gives high confidence even if the align-ments have small overlap. For instance, in our experiments, we found that the alignment diedOnDate  X  r/a/s/l/e/  X  achieves the highest confidence ( pcaconf = 1). Hence, we can use pcaconf to spot possible alignments even if there is very small overlap. In such cases, the alignment is very risky. Hence, we have to validate such alignments through more probing. This works as follows: Whenever a path alignment achieves high PCA confidence, we select for probing, enti-ties for which the newly discovered KB property is defined. Then we re-probe the WS with these entities.

The result of the path alignment is a set of pairs of the form ( p,p 0 ), where p is a path in the call result and p a path in the KB. Figure 5 shows the alignment for our running example. Branching Points. Our next step is to indicate branch-ing points in the XML paths and the KB paths. These are denoted by the  X * X  in Figure 5. A branching point in a path means that there are several outgoing edges in the graph starting from that point of the path that are la-beled with the same name. For example, following the path r/a/t/ X  in the call result of Figure 3, we encounter several edges labeled with a . Hence, a is a branching point. For-mally, we say that l i is a branching point for the XML path /l We use a path summary in the form of a DataGuide tree [14] to keep track of all possible paths in the samples and of their branching points. Its construction requires only a depth first traversal of each sample tree and its size is small because we do not need to store the text nodes.

For the KB paths, we insert branching points whenever a relation is not a function. Some KBs explicitly declare their functions. If that is not the case, we compute the functionality for each relation (Section 3). Since KBs may contain some noise, we insert branching points at a relation only if its functionality is lower than  X  = 0 . 9. Figure 5: Results of the path alignment step for getAlbumsByArtist ( r/a*, created ) z ( r/a*/s*, ) x ( r/a*/t/  X  , created*label ) y 1 ( r/a*/d/  X  , created*date ) y 2 ( r/a*/s*/l/b/  X  , birthdate ) y 3 ( r/a*/s*/n/  X  , label ) y 4 ( r/a*/s*/g/  X  , gender.label ) y 5 F igure 6: New path alignments and their associated variables for getAlbumsByArtist (left) and the tree-like hierarchy of paths in XML (right).
 Cut and Align. We now want to align also sub-portions of the paths. Our input are the path alignments produced by the previous step, annotated with branching points, and our output will be more path alignments. The clue of our algorithm is the insight that if we have a path of functional relations on the KB side, then this path has to be aligned to a (sub-)path with no branching points on the XML side. This means that the rightmost  X  annotation of one path is aligned with the right most  X  of the other path in the pair. Let us write P  X  p to denote a path such that P  X  ends in a branching point or it is the empty path, and p has no branching points. Then we generate new path alignments by recursively applying the following rule: For the path alignments in Figure 5, this gives rise to the new alignments in the Figure 6 (left).
 Weakness of the Method. The annotation with branch-ing points on the XML paths is biased by the set of XML call result samples. For example, if all call results return only singers that have released a single album, then our method will not annotate /s as a branching point.
 Duplicate Elimination. The previous step may result in associating the same KB path to different XML paths. This means that the same relationship appears multiple times in the call result. If this happens, we select the alignment that was generated from the pair with the highest confidence. Also, it may happen that several KB paths map to the same XML path. If the KB paths select literals, we use the same approach. If not, then they concern relationships between complex entities. For instance, we may have as candidates created and bornIn.producedIn  X  . In that case, we select the path where the maximal functionality of its relations is min-imal.
 View Definition. We now want to deduce the view defini-tion from our path alignments. We introduce a new variable for each path alignment (shown in the middle in Figure 6). Now, the view definition is simply the join of the KB paths with the appropriate variables. More precisely, let us write P 0  X  v , if some alignment ( P,P 0 ) is associated to a variable v . Then, we construct the body of the view definition with the following rules: The resulting atoms are added to the body of the view def-inition. The head atom of the view definition is the name of the WS. It contains only the variables that correspond to literals. This is because the entity identifiers used by the KB cannot be obtained by calling the WS. For our running example, we obtain exactly the view definition of Figure 1. Transformation Function. We have shown how to de-rive automatically the view definition of a WS in the global schema. Now, we turn to the question of how we can trans-form a concrete call result into tuples of this view definition. Our idea is to use an XSLT script for this purpose. Given a call result of a WS, the script will extract bindings for the variables in the head of the view definition of the WS. We now explain how to derive this script automatically from our path alignments.

We first organise the XML paths of the path alignment as a tree. The root of the tree is labeled with  X / X , and the other nodes represent variables. Edges are labeled with path queries. In the example of Figure 6 (left), this leads to the tree shown in Figure 6 (right).
 Algorithm 1 transforms such a tree into an XSLT script. It requires as input the root node of the tree. We assume that the functions isRoot(), isLeaf(), getChildren() , and pathFromParent() are available for every node. Let path-FromParent() return the path query on the edge between the node and its parent. For leaf nodes, the function omits the last part  X  X ext() X  (  X  ). For instance, y 1 . pathFromParent()=t . Our algorithm performs a depth-first search on the tree, and outputs a variable assignment for each edge of the tree. Algorithm 1 makeXSLT(TreeNode v ) if v .isRoot() then print &lt; xsl:template match= X / X  &gt; for v 0 : v .getChildren() do makeXSLT( v 0 ) end for print &lt; /xsl:template &gt; end if if v .isLeaf() then print { v : &lt; xsl:for-each select= X  v .pathFromParent() X  &gt; { &lt; xsl:value select= X . X  &gt; } &lt; /xsl:for-each &gt; } else print { &lt; xsl:for-each select= X  v .pathFromParent() X  &gt; for v 0 : v .getChildren() do makeXSLT( v 0 ) end for print &lt; /xsl:for-each &gt; } end if
The output of this algorithm is an XSLT script. This script is generated only once per WS. Each time a client calls the WS, the client has to execute the XSLT script on the call results, which will yield tuples in the view definition of the WS. We remark that this gives us an end-to-end solution for integrating Web services into a global schema: Given a schema and a WS, we can automatically derive a view definition of the WS, and a method to map the call results into that view definition.
We have presented an end-to-end solution for the map-ping of a Web service into a global schema. We will now present a baseline solution to this problem, which is based on wrapper induction. We adopt the approach that [21] has developed for mapping Deep Web forms into a KB. The approach creates a wrapper that extracts a pseudo-KB on the result pages of the Deep Web form. This pseudo-KB is then aligned with the reference KB using the PARIS ontol-ogy alignment algorithm [26]. A similar approach has been presented in [6] for mapping XML documents to RDF on-tologies.

In the spirit of wrappers, we construct entities for repet-itive structures. In our case, these are subtrees rooted at nodes that can have sibling nodes labeled with the same name. In our running example (Figure 3), these are the nodes labeled with a and s . We use an XSLT script to im-plement this wrapper. Conveniently, we can use Algorithm 1 to generate this script. As input, we use the DataGuide that we computed for our samples. The branching points and the leaf nodes are annotated with variables. Two XML paths with the same labels are mapped to the same relation in the pseudo-KB. Running this script on the call results will yield a pseudo-KB, much like in [21]. Then, we use PARIS to align this pseudo-KB with the reference KB.

Although this solution may seem reasonable, our exper-imental evaluation shows that it does not lead to good re-sults. One problem with this approach is that two entities in the reference KB may map to the same entity node in the pseudo-KB. Another problem is that a single relation in the pseudo-KB may correspond to an entire path of relations in the reference KB. This derails KB alignment approaches such as PARIS, which assume that a single relation in one KB corresponds to a single relation in the other KB.
For some WSs the type of the input can be hidden -is defined locally by the Web service. Many API providers use internal ids rather than names to identify entities. Since ids are internal to the API, they can almost never be obtained from external sources (such as the KB). However, if they are contained in the result of some WS of the same API, they can be inferred by joining the data of the two WSs. While some Web services may be joinable, others may be incompatible. For example, it does not make sense to use the output of a WS that delivers albums id as inputs to a WS that expects movies id. We will now show that our approach for mapping Web services into a global schema can also be used to determine which Web services are joinable. Let  X  f be a function that maps a variable in the view of a WS f to its bindings in our samples of f . We consider the following problem: Given a WS f O that has been mapped to the KB, and given another WS f I with only one input of unknown type, compute join dependencies of the form: Here, x is variable in the view of f O . p is an XML path such that  X  x 0  X   X  f O ( x ), p ( x 0 ) has values for the input of f f returns data relevant to x 0 . Example 1. Let f O =getAlbumsByArtist and let f I be a WS that returns songs by album-id. We aim to discover the following join dependency: ( f O ,z, id/  X ,f I ). Here, z is the variable used for album entities in the view in Figure 1. In the call result depicted in Figure 3, z had as bindings the two nodes labeled with a . Note that the path id/  X  selects exactly the ids of the respective albums.
 Mini-KB Extraction. The interesting aspect of our ex-ample join dependency is that it concerns paths in f O that were not yet mapped to KB relations (namely id/  X  ). Our goal is now to extend our view definition and our transfor-mation function to these unmapped paths. For each vari-able x in the view of f O , and for each XML path p  X  x the schema of the KB, and we map p 0 to that new relation name. The XSLT script for f O is updated accordingly. Let mini-KB( x ) be a KB computed by applying the updated XSLT script to every call result in our sample for f O . Generating candidates. A candidate join dependency of the form ( f O ,x,p,f I ) is computed for every variable x from the view of f O and every path p in f O where In our experiments, we set  X  = 20. For probing f I extract from mini-KB( x ) tuples of the form: where l serves to call f I , but we see x k as the input entity of that respective call. We now discuss when we keep a candidate join dependency ( f O ,x,p,f I ).
 Step 1: Catch Error Messages. If f I returns systemati-cally an error message, we discard the candidate. However, some WSs will not return an error message if fed with a bad input entity. Instead they will return results for all entities whose names or other attributes are similar to the input entity. Therefore, our first step cannot filter out all bad candidate join dependencies.
 Step 2: Checking Input X  X  Position in the Output. If the call is valid, then it should return information about the input value. This value should consistently appear under the same path(s) from the root (Observation IV ). Assume that we discover that the input value occurs always under the path p i in the call results of f I . Then, we can filter out every candidate ( f  X  O ,x  X  ,p  X  ,f I ) that did not discover p being the path with the inputs.
 Step 3: Align f I and the mini-KB. Finally, we use the path alignment algorithm from Section 4 to align label paths in the outputs of f I with path relations in mini-KB ( x ). We rank the candidates between f I and f O according to the number of paths produced by the alignment. We select as solution the top candidate. The intuition is that f I should return some of the properties of x returned also by f O . For instance, for our example, we expect that the second WS recalls the singer of the album in its results, which in turn appears also in the output of getAlbumsByArtist .
 Discovering Types for WS Inputs. Let our candidate ( f
O ,x,p,f I ) be a join dependency. Hence, f I returns data relevant to x . Thus, we can say that the input of f I has as type the class of x k (or x ) in the KB. However, the relation that links x k to l in the KB might not be the default relation label . Hence, the input of f I is annotated with the class of x k (its input entity) and the (new) relation to which p is mapped to. With this, f I is now ready to be mapped to the target KB. Our algorithms are fully implemented in a system called DORIS (Discovering Ontological Relations In Services). Data Sources. We have tested DORIS on more than 50 real WSs provided by more than 10 APIs. The data exported by the WSs cover four domains: music, movies, books, and geographic data. Table 1 shows the WS APIs that we consid-ered, grouped by thematic domain. The first column shows the APIs. The third column shows the WSs offered by these APIs. Several APIs can provide the same WS. For example, both book APIs support getAuthorInfoByName . Therefore, the second column shows how many APIs support a given WS.
 We have conducted experiments for three target KBs: YAGO [27] and DBpedia [3] (which are extracted from Wikipedia), and BNF (bnf.fr) (a KB from the domain of books curated by the National Library of France). We probed each Web Service for 100 samples.
 Platform. Our system is implemented in Java (JVM 1.7). We use standard Java libraries to parse the XML and JSON call results. We use the Jena 2.11 library to store the KBs, and the Jena SPARQL functionality to query them. We ran all experiments on a personal laptop (2,9 GHz Intel Core i7, 8GB). Our method takes roughly 2 minutes to derive the schema of a WS (Path Alignment and Class &amp; Atom Alignment ).
 Our first series of experiments concerns the path alignment (Section 4). We probed each WS with instances of the in-put domain from the YAGO KB. As a gold standard, we designed the correct path alignments manually for each WS of each API.

Our first goal is to determine the right threshold for the overlapping algorithm. We examine the performance of our method with respect to different threshold values. Table 2 shows the average F-measure across all WSs for the align-ment under different thresholds. The threshold 0.5 produces the best results, hence we use it for what follows. Table 2: Average performance of Path Alignment
Then, we ran experiments for both alignment strategies: the overlapping and the subsumption strategy. For the sub-sumption, we checked whether the results of the KB path are subsumed by the results of the XML path ( KB  X  WS ), and vice-versa ( WS  X  KB ). Table 1 shows the precision and the recall for each WS (averaged over the APIs that provide the WS).

Our experiments show that the overlapping strategy (Overlap columns) can align paths with a precision (P) of 57%-100%. In the vast majority of cases, the precision is over 80%. Recall (R), likewise, is well over 90% in the ma-jority of cases.

The subsumption strategy performs less well. The main reason is that the PCA confidence does not penalise align-ments that have the support of a small number of sam-ples. This yields many spurious matches. On the other hand, this allows aligning paths with incomplete relations such as diedOnDate , wasCreatedOnDate , hasLongintude , and hasLatitude . In order to find these alignments also with the overlapping method, more samples would be needed. We refer to the bindings of a variable in the view using the term class. By atom we mean an atom of the view. We say that a class or an atom are correctly aligned if the transfor-mation function extracts correct values for them. In order to evaluate the class and atom alignment, we first generated the ideal class and atom alignment manually. Then, we ran our alignment algorithm and compared the results to this gold standard. As input, we used the path alignments com-puted by the overlapping strategy.
 Duplicate Removal. We first wanted to see whether du-plicate removal helps precision and recall for the class and atom alignment (see Section 5). Hence, we ran the alignment with and without duplicate removal and measured precision and recall. Our experiments show that the technique helps: By removing the duplicates, the average precision across all Web services for YAGO relations rises from 45% to 91%. At the same time, recall is almost the same. It decreases from 95% for the algorithm that allows duplicates to 93% for the one that removes them. The precision and recall for classes remains unchanged. Therefore, we decided to remove duplicates in what follows.
 YAGO. The results of aligning the Web services to the YAGO KB are presented in Table 1 on the right. We are happy to report that our system achieves a perfect precision and a perfect recall on nearly all WSs. Only very few WSs could not be mapped entirely correctly. We reckon that this is the first time that the result of WSs can be mapped fully automatically to the schema of a target KB.
 Other KBs. We have also tested our algorithm on DBpedia and BNF. For DBpedia, we used all 50 WSs. For BNF, which is a domain-specific KB, we ran only the WSs from the Books domain. We present an average of the precision and recall of our class and atom alignment in Table 3. Since the BNF contains data that overlaps a lot with the WS, we obtain a perfect precision and recall for this KB. The other alignments are also of very respectable quality, with recall and precision values well over 90%.
 Comparison to Baseline. In Section 6, we introduced a baseline approach to the problem of WS alignment. This approach transforms the WS call results into a pseudo-KB, and uses a state-of-the-art alignment approach (PARIS [26]) to align the pseudo-KB to the reference KB.
 We ran PARIS with exactly the same data as DORIS. PARIS computes a confidence score for each alignment. We used a threshold of 0.6 on this score to determine the final output, which was the value for which PARIS performed best. The results of this approach are shown in the last two columns of Table 1. As we see, DORIS outperforms PARIS by a huge margin. DORIS achieves near-perfect alignment, while the precision and recall for PARIS are more in the area of 30%-60%. The reason is that PARIS performs very well when the schemas of the two ontologies are similar. This is not the case at all in our problem. Moreover, PARIS cannot discover complex relations alignments like hasGender.label , while DORIS discovered them.
 Our next experiment evaluates our algorithm for discovering join dependencies for WSs whose input type is hidden (Sec-tion 7). For each API, we determined the joins manually. Then, we ran our algorithm for each API, and compared the results to the true ones. Table 4 shows the precision and the recall for several variants of the algorithm: S1 and S2 imple-ment Step 1 and Step 2 respectively. S23 implements Steps 2 and 3 together. We find that Step 1 sometimes excludes good answers, which leads to a drop in recall. The good news is that all strategies have a very high recall, which is almost perfect for S2 and S23. Furthermore, S23 achieves a precision that is consistently over 80%. Hence, our method is able to discover join dependencies and input types fully automatically with high accuracy.

API Precision Recall S1 S2 S23 S1 S2 S23 deezer 0.21 0.67 0.95 0.77 1 1 discogs 0.27 0.83 0.81 1 1 1 echonest 0.78 1 1 1 1 1 isbndb 0.48 0.82 0.82 1 1 1 last fm 0.24 1 1 1 1 1 library thing 0.57 0.6 1 1 1 1 music brainz 0.1 0.84 0.84 0.93 0.93 0.93 musixmatch 0.11 0.55 0.83 1 1 1 themoviedb 0.19 0.78 0.89 1 1 1 In this paper, we have shown how to map the results of a Web service fully automatically into the schema of a knowl-edge base. Our approach aligns the call results of the Web service to relations of the KB, it derives a view definition of the service in the schema of the KB, and it discovers join dependencies between different WSs. Our experiments show that our approach produces near-perfect results on over 50 real Web services in a variety of domains. We hope that our techniques can provide a bridge between different data providers, and thus help the rise of tomorrow X  X  knowledge-centric applications.
 Acknowledgments. This work is supported by the re-search projects EDOP (PATRIMA LabEx) and ALODIS (PEPS FASCIDO 2015 -CNRS). [1] Sparql: http://www.w3.org/TR/rdf-sparql-query/ . [2] Xslt: http://www.w3.org/TR/xslt20/ . [3] S. Auer, C. Bizer, G. Kobilarov, J. Lehmann, [4] D. Aumueller, H. H. Do, S. Massmann, and E. Rahm. [5] V. B  X ar  X any, M. Benedikt, and P. Bourhis. Access [6] I. F. Cruz, H. Xiao, and F. Hsu. Peer-to-peer semantic [7] L. Dehaspe and H. Toivonen. Discovery of frequent [8] N. Derouiche, B. Cautis, and T. Abdessalem.
 [9] A. Doan, P. Domingos, and A. Y. Halevy. Reconciling [10] X. Dong, A. Y. Halevy, J. Madhavan, E. Nemes, and [11] X. L. Dong, E. Gabrilovich, G. Heitz, W. Horn, [12] T. Furche, G. Gottlob, G. Grasso, X. Guo, G. Orsi, [13] L. Gal  X arraga, C. Teflioudi, K. Hose, and F. M. [14] R. Goldman and J. Widom. DataGuides: Enabling [15] A. Y. Halevy. Answering queries using views: A [16] T. Kirsten, A. Thor, and E. Rahm. Instance-based [17] G. Limaye, S. Sarawagi, and S. Chakrabarti.
 [18] J. Madhavan, P. A. Bernstein, A. Doan, and A. Y. [19] R. J. Miller, L. M. Haas, and M. A. Hern  X andez. [20] S. Muggleton. Learning from positive data. In ILP , [21] M. Oita, A. Amarilli, and P. Senellart.
 [22] D. L. Phuoc, A. Polleres, M. Hauswirth, [23] N. Preda, F. M. Suchanek, W. Yuan, and G. Weikum. [24] S. Quarteroni, M. Brambilla, and S. Ceri. A [25] A. Segev and Q. Z. Sheng. Bootstrapping ontologies [26] F. M. Suchanek, S. Abiteboul, and P. Senellart. [27] F. M. Suchanek, G. Kasneci, and G. Weikum. YAGO: [28] M. Taheriyan, C. A. Knoblock, P. A. Szekely, and [29] P. Traverso and M. Pistore. Automated composition [30] P. Venetis, A. Y. Halevy, J. Madhavan, M. Pasca, [31] J. Wang, J. Wen, F. H. Lochovsky, and W. Ma.

