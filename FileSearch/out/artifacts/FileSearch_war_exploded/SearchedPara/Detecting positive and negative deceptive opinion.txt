 1. Introduction  X  their minds about purchases based on negative information they found online. fake comments, fake blogs, fake social network postings and deceptive texts. Opinion spam reviews may be detected by in order to deceive the consumers.
 The detection of deceptive opinion spam has been recently solved by means of supervised text classification techniques.
These techniques have demonstrated to be very robust if they are trained using large sets of labeled instances from both classes, deceptive and truthful opinions. For example, some works have reported F the consideration that deceptive opinion spam can be accurately generated using a Mechanical Turk crowdsourcing service as suggested by Ott et al. (2011) .

The PU-learning approach was originally used and evaluated in thematic text classification, in problems showing high cohesion among the documents from the target (positive) class, and having great diversity in the unlabeled subset ( Liu opinions are very diverse in content and style, and there are only slightly differences between deceptive and truthful opinions.
 hundred of examples of deceptive opinions for training it is possible to reach classification F there are common characteristics in the way people write positive and negative opinion spam.

Section 6 presents our conclusions and discusses some future work directions. 2. Related work The detection of spam on the Web has been mainly approached as a binary classification problem (spam vs. non-spam). 2011 ). Nevertheless, the construction of automatic detection methods for this task is more complex than for the others since manually gathering labeled reviews  X  particularly truthful opinions  X  is very hard, if not impossible ( Mukherjee et al., 2011 ).

Due to the lack of reliable labeled data, most initial works regarding the detection of opinion spam considered unsuper-vised approaches which relied on meta-information from reviews and reviewers. For example, Jindal and Liu (2008) proposed detecting opinion spam by identifying duplicate content. Although this method showed good precision in a review
In this same category of unsupervised approaches, Mukherjee et al. (2011) proposed a method for detecting groups of opinion spammers based on criteria such as the number of products for which the group work together and a high content similarity of their reviews. Similarly, in Wu, Greene, and Cunningham (2010) the authors present a method to detect hotels which are more likely to be involved in spamming. They proposed a number of criteria that might be indicative
Their criteria mainly derive from characteristics of the network of reviewers and also from the impact and ratings of ulated by possible spam reviews. Supported by this observation they proposed a spam detection method based on tem-poral pattern discovery.

It was only after the release of the gold-standard datasets by Ott et al. (2011) and Ott et al. (2013) , which contain examples of positive and negative deceptive opinion spam, that it was possible to conduct supervised learning and a same approach to classify negative opinions. The main conclusion from these works is that standard text categorization techniques using unigrams and bigrams word features are effective at detecting deception in text, and that their results significantly outperform those from human judges. Following this research direction, Feng, Banerjee, and Choi (2012a, 2012b) extended Ott et al. X  X  n-gram feature set by incorporating deep syntax features, i.e., syntactic production rules derived from Probabilistic Context Free Grammar (PCFG) parse trees. Their experimental results consistently find statis-tical evidence that deep syntactic patterns are helpful in discriminating deceptive writing. Similarly, Feng and Hirst between the personal experience described in a test review and a product profile derived from a collection of reference reviews about the same product. This idea was supported on the hypothesis that since the writer of a deceptive review usually does not have any actual experience with that product, the resulting review might contain some contradictions with facts about the product. This approach showed to significantly improve the performance of identifying deceptive reviews.

The method proposed in this paper is similar to the above-mentioned works in the sense that it also applies a super-vised approach to automatically identify deceptive and truthful reviews. However, all these methods exhibit a key prob-lem: they depend on the availability of large amounts of labeled examples of deceptive and truthful opinions. This is particularly evident for the last two works which look for syntactic patterns and profile features. In order to overcome this limitation and be able to deal with real application scenarios, in Hern X ndez-Fusilier, Guzm X n-Cabrera, Montes-y-
G X mez, and Rosso (2013) we proposed a method that learns only from a few examples of deceptive opinions and a set
This paper extends our previous work in four ways: it compares the performance of the proposed approach and the ori-method when using word unigrams and bigrams as features as well as different classifiers, particularly SVM and Na X ve
Bayes. 3. PU-learning for opinion spam detection  X  presumably  X  containing a combination of deceptive and truthful opinions.
 iteration.

Algorithm 1. Original PU-learning algorithm. P and U are the sets of positive and unlabeled examples respectively; C binary classifier at iteration i ; Q i represents the set of unlabeled examples from U set of reliable negative examples gathered from iteration 1 to iteration i . 1: i 1 2: C i Generate Classifier  X  P ; U  X  3: U L i C i  X  U  X  4: Q i Extract Negati v es U L i 5: RN i Q i 6: U i U Q i 7: while j Q i j &gt; ; do 8: i i  X  1 9: C i Generate Classifier  X  P ; RN i 1  X  10: U L i C i  X  U i 1  X  11: Q i Extract Negati v es U L i 12: U i U i 1 Q i 13: RN i RN i 1  X  Q i 14: Return  X  C i  X  conservative variant of the original PU-learning algorithm. This new algorithm, herein referred as modified PU-learning, the original PU-learning approach.

Algorithm 2. ModifiedPU-learningalgorithm. P and U arethe sets ofpositiveandunlabeledexamples respectively; Q represent the sets of identified and retained reliable negative examples at iteration i , and C 1: i 1; 2: C i Generate Classifier  X  P ; U  X  3: U L i C i  X  U  X  4: Q i Extract Negati v es U L i 5: RN i Q i 6: Q 0 Q i 7: while  X j Q i j &lt;  X j Q i 1 j and j P j &lt; j RN i j X  do 8: i i  X  1 9: C i Generate Classifier  X  P ; RN i 1  X  10: RN L i C i  X  RN i 1  X  11: Q i Extract Negati v es RN L i 12: RN i Q i 13: Return  X  C i  X  4. Datasets
The evaluation of the proposed method was carried out using the corpora assembled by Ott et al. (2011) and Ott et al. the words  X  X  X xperience X  X ,  X  X  X y husband X  X ,  X  X  X  X  X ,  X  X  X eel X  X ,  X  X  X usiness X  X , and  X  X  X acation X  X  more than genuine ones. Example of a positive deceptive opinion.

My husband and I stayed for two nights at the Hilton Chicago, and enjoyed every minute of it! The bedrooms are immac-in Chicago. The bathroom was quite spacious, and I loved the smell of the shampoo they provided-not like most hotel shampoos. Their service was amazing, and we absolutely loved the beautiful indoor pool. I would recommend staying here to anyone.
 Example of a positive truthful opinion.

The TV was Ok, a 27 X  CRT Flat Screen. The concierge was very friendly when we need. The room was very cleaned when leaving the building, always use the Michigan Ave exit. It is a great view.

In order to simulate real scenarios to evaluate the performance of the proposed PU-learning method we assembled sev-iments we built five different examples for each subset configuration, and that we always report their average results. we first randomly selected 80 deceptive opinions and 80 truthful opinions to build a fixed test set. Then, the remaining distribution of 320 truthful opinions and 200 positive deceptive opinions.
 and 400 truthful negative opinions from Ott et al. X  X  corpora. Accordingly, we randomly selected 80 negative deceptive opinions and 80 negative truthful opinions to build the test set. Then, the remaining 640 negative opinions were used tion of 320 negative truthful opinions and 200 negative deceptive opinions.
 Datasets of mixed polarity : These datasets were built to analyse the role of polarity in the detection of opinion spam.
They were mainly assembled by combining the positive and negative sets previously described. Therefore, we form a test set consisting of 160 deceptive and 160 truthful opinions, and using the remaining 1280 opinions we built six training sets containing 40, 80, 120, 160, 200 deceptive opinions respectively (half of them positive opinions and the other half negative). In all cases it was used a set of 1040 unlabeled instances containing a distribution of 640 truthful opinions and 400 deceptive opinions. 5. Experimental evaluation 5.1. Experimental settings
Document preprocessing : We removed all punctuation marks and numerical symbols, i.e., we only considered alpha-betic tokens. We maintained the stop words, and converted all words to lowercase letter. These operations were applied on both labeled and unlabeled documents.
Learning algorithms : We used the Na X ve Bayes (NB) classifier for all the experiments. We employed the implementation by Weka ( Hall et al., 2009 ), considering all words occurring more than once in the training set as features. For the reported experiments we applied a binary weighting scheme. Additionally, in Section 5.5 , we report results from a
SVM classifier considering word unigrams and bigrams as features as suggested by Ott et al. (2011) and Ott et al. (2013) . For this experiment we also employed the SVM implementation by Weka using a linear kernel and default parameters.

Evaluation measure : The evaluation of the effectiveness of the proposed method was carried out by means of the macro we report the average results on the five different examples for each subset configuration of the datasets. The F for each opinion category O i is computed as follows: Statistical comparison of methods : Following the recommendation by Dem X ar (2006) , we used the Wilcoxon Signed
Ranks Test for comparing our method against other classification approaches. For these comparisons, we considered a to mention that for comparing any two methods, we created two distributions with 20 values each, corresponding to their results in 5 folds from 4 collections (60, 80, 100 and 120 training instances). 5.2. Experiment 1: lower and upper bounds for the PU-learning approach istic scenarios.
 obtained by training a NB classifier using the whole unlabeled set as the negative class. of results for the different training subsets of datasets of positive and negative opinions.
 ideal PU-learning approach could obtained a F 1  X  0 : 85. Furthermore, the improvement in the classification performance
Another interesting observation from Fig. 1 is that PU-learning was incapable to learn a suitable classifier when having ing the diversity in content and style of deceptive opinions from a small number of examples. 5.3. Experiment 2: original vs. modified PU-learning
This experiment focused on the comparison of the original and modified PU-learning methods in the classification of tive opinions respectively. Using the Wilcoxon test as explained in Section 5.1 , we found that the proposed PU-learning kind of opinions the best result of the proposed method was F therefore, that there larger training sets are needed for their adequate modelling.
 of positive deceptive opinions; whereas the original PU-learning approach obtained a maximum result of F opinions. The best result by the proposed method was F 1  X  0 : 657. However, the average improvement of the proposed negative instances was uncorrelated with the number of labeled training instances. 5.4. Experiment 3: polarity and deception under PU-learning in the context of the proposed PU-learning method. To carry out this analysis we used the dataset of mixed polarity configuration, each one of the classifiers was trained using only half of the data.
 opinions), in which the improvement was around 25%. These results are quite interesting and unexpected; they show that, ered in this study, more data, even from a different polarity, it is always useful. 5.5. Experiment 4: on the choice of features and classifier
The goal of this last experiment was to evaluate the variation in the performance of the proposed PU-learning method whatever the set of features was used. Somehow this conclusion was not completely unexpected; Forman and Cohen (2004) bution, and surpass SVM when there is a shortage of positives or negatives.

Regarding the used features results are not equally clear, the combination of unigrams and bigrams obtained better ferent for the two selected classifiers, it is important to point out that the proposed PU-learning method showed improvements to baseline results for the two polarities using any of the classifiers. 6. Conclusions and future work
PU-learning technique because of the scarcity of deceptive examples we believe it is the most adequate way; (ii) we pro-deceptive opinions. The results are encouraging and indicate that using only a hundred of examples of deceptive opinions ment where the role of opinions X  polarity in the detection of deception is analysed, the obtained results confirm that common characteristics in the way people write positive and negative deceptive opinions.

As future work we aim at applying the novel PU-learning for detecting deceptive language to approach problems such as the detection of online sexual predators as well as the detection of lies in general.
 Acknowledgments 7 Marie Curie. The work of the third author was in the framework the DIANA-APPLICATIONS-Finding Hidden Knowledge in
Texts: Applications (TIN2012-38603-C02-01) project, and the VLC/CAMPUS Microcluster on Multimodal Interaction in Intel-ligent Systems.
 References
