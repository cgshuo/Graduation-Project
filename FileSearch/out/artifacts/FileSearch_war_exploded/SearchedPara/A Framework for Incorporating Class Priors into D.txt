 Machine learning approaches to classificatio n usually fall either into the discrimina-tive (or conditional modeling) category, or the generative category. Discriminative classification directly attempts to model (|) py x One difference between them is the conditional model usually only focuses on the relationship between the input features and the class label, while the generative model has to explain both how the inputs are genera ted and how the class label is associated with the input data. One usually finds that state-of-the-art conditional models perform better than generative models on classification problems. More detailed studies of the comparison of conditional models and generative models can be found in [8]. 
However, compared to discriminative a pproaches, generative approaches have the class labels. Knowledge of the class priors or proportions can be very useful in several contexts. Assume that the learning algorithm is provided with labeled training data and unlabeled test data. First, if the training data does not have the same proportions data. Second, sometimes the class conditional probabilities ( | ) px y different from the training data to the test data. This is a situation which most learning algorithms are not designed for, but it occurs in practice due to the fact that the label-ing process can be biased. Incorporating kn owledge of the class priors can make a learning algorithm more robust to inaccuracies in the class conditional probabilities obtained from training data. In the extreme case, the inputs of the training data and the test data may be completely random numbers and only the class priors are consistent through the whole dataset. The best strategy of predicting class labels for the test data would be to always predict the class label with the highest prior. Unfortunately, since discriminative models focus on learning the mapping from input data to class label, (|) py x model or take advantage of the marginal class distribution, ( ) py . prior information into discriminative learning. This framework is based on the as-sumption that the class priors give a reas onably accurate description for the class distribution of the test data. Therefore, the discriminative model learned from the training data should not only explain the class labels for the training data well but also predict the class labels for the test data in such a way that the distribution of the pre-this framework differs from the traditional approach for discriminative learning where assigned class labels on the training dataset. Furthermore, our framework is able to utilize both training data and testing data in the construction of discriminative models, while traditional approaches for discriminative learning only take advantage of train-ing data. 
This framework can be useful when the training data and the test data have the same class priors but do not have exactly the same feature distributions and therefore the model learned from the training data may not be appropriate for the test data. Differences between the training data and the test data can be caused by the fact that test data, or the amount of training data is too small to give a good representation for the whole dataset. The other interesting aspect of this framework is that it allows the discriminative model to use a mixture of training data and test data. Thus, this frame-work is able to deal with learning problems in which only a small number of training examples are available and the majority of instances are unlabelled. Unlike previous works on the combination of labeled data and unlabeled data, which mainly focus on the generative model, the framework provides room for the discriminative model to take advantage of unlabeled data. The formal description of the framework is presented in Section 3. Section 4 de-scribes the empirical study of this framework. Conclusions and future work are pre-sented in Section 5. As already discussed in the introduction, the main idea of this paper is to incorporate class prior information into discriminative learning. Therefore, it combines some aspects of learning both discriminative and generative models. There have been sev-eral studies on the improvement of discriminative models using information from a generative model [6]. The motivation of that work is based on the observation that sometimes the generative model captures properties of the input distribution that are meaningful to the discrimination problem. Therefore, if we can influence the dis-criminative model with a generative model that is specific to the problem, for exam-ple choosing a discriminative function that is coherent with the generative density, we may be able to gain better performance than using a generic discriminative model. Approaches based on this idea, such as combining the support vector machine with fisher kernels derived from a generative model, have shown significant improvement in classification problems. Unlike that work, in our framework we don X  X  change the kernel function; instead, we only consider th e class prior information as an extra hint to be used by the discriminative model. 
Since this framework is taking advantage of both the training data and the test data, beled data [9]. Many of works on this problem assume some form of generative model, which is used to explain both the labeled data (i.e. the inputs and the label) and the unlabeled data (i.e. just the inputs). In cases where only a small amount of data are labeled, a model learned from this data can be quite skewed and the incorporation of unlabeled data can help avoid idiosyncrasies of the labeled data to some extent. Unlike this work, our framework focuses on incorporating unlabeled data into dis-criminative training. Other works on learning from the mixture of labeled and unla-beled data have focused on using unlabeled data for model regularization and model selection. One example is the transductive SVM [7], where the classification margin is influenced both by the labeled and unlabeled data. Unlike their work, in this frame-work, we refine the learned model by only examining the discrepancy between the class distribution of the predicted labels of unlabeled data and the  X  X rue X  class priors. The basic logic behind this framework can be simply understood as follows: consider tions, if the training data and testing data come from different sources. Then, applying the discriminative model that is learned from the training data directly to label the test data will be problematic. If we have prior knowledge on the class distribution for the examining the difference between the class priors and the distribution of the class labels for the test data predicted by the discriminative model. If there is a significant discrepancy between these two distributions, we will suspect that the learned model may not be appropriate for the test data and needs to be adjusted. In order to refine the discriminative model, we need to do two things: first, we can adjust the probability of classes for the test data computed from the original discriminative model in such a shifted toward the class priors. Then, the test data with the adjusted class probabilities will be included in the training data and a discriminative model will be retrained over the  X  X nlarged training dataset X . The procedures of adjusting the class probabilities for test data using priors and retraining the discriminative model will be carried out itera-tively until it reaches some local maximum. 3.1 Model Description The essence of a discriminative model is the computation of the conditional probabil-ity for a class label y given the input vector x criminative model can be formalized as the search for a model that maximizes the log-likelihood of the training data, i.e. where M stands for a discriminative model, i x stands for its class label. 
In order to incorporate class prior information into a model, a discriminative model will not only have to explain the training data well but also to predict class labels for data is consistent with class priors. Therefore, we need an extra term in Equation (1) that can account for the discrepancy between the two distributions. In the following sections, we will discuss three different approaches. To this end, for every instance in the test dataset, an unknown distribution over class labels is introduced. This repre-sents the estimated distribution over classes, which will incorporate both the prior class constraints and the model predictions. Moreover, we will see that it considerably simplifies the computation in optimization. Let r k be this estimated class distribution point to be in class y . To enforce the consistency between class priors of training data and test data, we impose the following constraint on the estimated class probability r , i.e., function. Of course, we want the distribution of class labels predicted by model M , i.e., (| , ) k py x the objective in (1) can be modified as: In above, the KL divergence is introduced as the measurement of consistency between (| , ) k py x forces consistency between the class prio rs of test data and of training data. 3.2 Finding the Optimal Solution As indicated in Equation (3), the objective function contains two different sets of parameters, namely the model parameters M and the estimated class distribution r k,y . Therefore, we can optimize the objective function in (3) by alternatively freezing one (3) using only the discriminative model para meters, and then search for the estimated see that the strategy used in the optimization exactly corresponds to the intuition stated at the beginning of this section. can be trained with almost no modification except that both the training data and the test data are fed into the learning module. Of course, any discriminative classifier that accepts distributions as targets can be used here. 
For the second step of optimization, we n eed to find the set of estimated class dis-tributions that maximizes the objective function in (3) subject to the constraints in (2). Since parameters for the discriminative model are frozen, the objective function in (3) is simplified as: The problem of maximizing (3 X ) under the constraints in (2) is exactly the same prob-lem as solved in maximum entropy (ME) models [1]. The original version of maxi-mum entropy model is to find a set of probabilities that not only maximize the entropy case when the objective function is not an entropy function but a KL divergence be-tween the distribution to be optimized and a set of given probabilities, i.e. a minimum relative entropy (MRE) problem, which is exactly our problem. In this experiment, we examined the effectiveness of our model in terms of using class priors to improve classification accu racy. More specifically, we would like to address two scenarios of application for this framework: 1) A scenario of a small number of labeled examples. In this case, we will expose the 2) A scenario of heterogeneous training and testing examples. In this case, we as-4.1 Experiment Design The discriminative model used for the experiment is the conditional exponential model [1], in which conditional probability ) | ( x y p (|) exp( ) () y py x x Zx  X  = X  the normalization factor. A conjugate gradient [10] is used to find the appropriate weight vectors. 
To illustrate the effectiveness of our framework on the two different scenarios mentioned before, we tested the algorithm against two different groups of datasets. For the first scenario, we use five UCI datasets as the testbed. We use a small portion of each UCI dataset as training examples and leave majority of the dataset as testing examples. The detailed information about the five datasets is listed in Table 1. For the second scenario, we tested our algorithm on both the synthesized data that are gener-circumstance in which test data and training data have different feature distributions, for every feature, we uniformly randomly generate a weight factor ranging from 1 to 1.5 and multiple it with the corresponding feature of the testing data. By this  X  X orrup-tion X  procedure, the weights of the exponential model learned from the training data will not be appropriate for the test data because the scale of the test are changed. By tively our framework is able to adjust the model parameters y  X  number of unlabeled data. 
The other dataset that we used for the second scenario is the image dataset. We use the images downloaded from the image direct ory of Google as the training examples and images from Corel image database as testing examples [3]. Six image categories ages. The training images are acquired by querying the image directory of Google with the name of categories as the query words. The top ranked 100 images from Google are used as the training examples. The testing images are collected by ran-domly sampling 100 images out of the corresponding categories from Corel database. Apparently, images downloaded from Google image database will be considerably different from images from Corel database. The extended color co-occurrence matrix [5] is used for image representation, which have shown its effectiveness in image classification. For each image, totally 500 image features are extracted. More detailed discussion about image classification can be found in [2, 4, 11]. 
The key component in this framework is the knowledge of class priors. To examine the impact of class prior accuracy on cla ssification performance, we introduce three different ways of estimating class priors: 1)  X  X mpirical Estimate X : Estimate the class priors only based on the training data. 2)  X  X ptimal Estimate X : Estimate the class priors based on the test data. Of course, this 3)  X  X ntermediate Estimate X : Estimate the class priors based on all the data including 4.2 Scenario 1: A Small Number of Labeled Examples respectively. The averaged classification er rors based on cross validation for the pro-posed algorithm are listed in Table 2 and 3. We also included the classification results when no class priors information is used. 
First, by comparing the performance listed in Table 2 to what listed in Table 3, it is clear that, by decreasing the amount of trai ning examples from 25% to 10%, all learn-ing methods on most UCI datasets suffers degradation in performance except the  X  X lass X  dataset. Second, comparing the proposed framework using different estima-tors of class priors, it is clear that the new framework with optimal estimator appears to have the best performance while the intermediate estimator gives the second best performance. The new framework with these two estimators of the class priors ap-pears to substantially outperform the baseline model, i.e., the simple discriminative model without using class priors. This fact in dicates that our algorithm is effective in improving the performance of discriminative classifier with reliable estimates of class priors. Third, the proposed algorithm with empirical estimates appears to perform significantly worse than the original discriminative model without using class priors. Since the empirical estimator bases its estimates on the empirical class distribution of the empirical estimates usually gives poor estimation of class priors, which results in poor performance of the proposed algorithm. Based on this fact, we can see that, it is very important to our algorithm to ha ve accurate estimates of class priors. 4.3 Scenario 2: Heterogeneous Training Data and Testing Data vant scenario, which is rarely studied in machine learning. First, we will test the pro-pose algorithm on the synthesized datasets, which are generated from the five UCI datasets. The  X  X orruption X  procedure has already been described in section 4.1. The results for the proposed algorithm with three different estimators of class priors to-gether with the discriminative model without class priors are listed in Table 4 and 5. 
First, by comparing the results in Table 4 and 5 to the results in Table 2 and 3, it is clear that, by multiplying the testing data with a random weight factor, the perform-ance of the discriminative model without using class priors suffers from a severe degradation. On the contrary, the proposed algorithm appears to suffer from much smaller degradation for all three different estimators. This fact indicates that, the pro-the discriminative model without class priors. Unlike the results presented in previous scenario, where the empirical estimates gives rise to poor performance due to its inac-curate estimation on class priors, for this sc enario, even the empirical estimate is able to result in a better performance than the original discriminative model for most data-sets. The fact that the proposed algorithm is able to outperform the discriminative model without class priors indicates that our algorithm is effective in dealing with the situation when the testing data are quite different from the training data. 
In addition to testing our algorithm against the synthesized dataset, we also exam-ine our algorithm over the problem of image classification. The details of image da-tabsets have already been described in the section 4.1. The downloaded 600 images are used as training examples and the 600 images from Corel database are used as testing instances. The classification error for the discriminative model without class priors is 66.9% and 60.9% for the proposed model assuming that the class priors equal to 1/6. Again, with accurate knowledge on class priors, we are able to decrease periment is quite high, over 60%, while some image classification works show ex-tremely good performance over Corel datasets. We believe the main reason for that is because the images from Google do not resemble the images from Corel in many cases. Table 6 shows two images of category  X  X ird X  from both Google and Corel data-base. Apparently, the training examples are very different from testing images, either reason why this task is so hard and causes so large testing errors. In this paper, we proposed a framework that is able to incorporate class prior informa-machine learning algorithm which allows a discriminative model to use a mixture of labeled and unlabeled data. In the empirical study over five different UCI datasets and Corel image database, this algorithm is able to improve the performance of the condi-tional exponential model significantly when the number of training examples is small and when the test data are heterogeneous from the training data. Therefore, we con-clude that the new algorithm is able to help the performance even with inaccurate estimation for class priors and the improvement depends on the accuracy of the esti-mation. Usually large improvements were found when accurate class priors were incorporated into training but these improv ements vanished when the class priors had substantial inaccuracies. Thus, more research work is needed in order to study how to improve the classification accuracy in case of inaccurate class priors. We thank Dr. Zoubin Ghahramani and Dr. Huan Liu for their discussion and sugges-tion on this work. 
