 Alon Gonen alongnn@cs.huji.ac.il Benin School of CSE, The Hebrew University Sivan Sabato sivan.sabato@microsoft.com Microsoft Reserach New England Shai Shalev-Shwartz shais@cs.huji.ac.il Benin School of CSE, The Hebrew University We consider pool-based active learning (McCallum &amp; Nigam, 1998), in which a learner receives a pool of un-labeled examples, and can iteratively query a teacher for the labels of examples from the pool. The goal of the learner is to return a low-error prediction rule for the labels of the examples, using a small number of queries. The number of queries used by the learner is termed its label complexity . This setting is most use-ful when unlabeled data is abundant but labeling is expensive, a common case in many data-laden appli-cations. A pool-based algorithm can be used to learn a classifier in the standard PAC model, while query-ing fewer labels. This can be done by first drawing a random unlabeled sample to be used as the pool, then using pool-based active learning to identify its labels with few queries, and then using the resulting labeled sample as input to a regular  X  X assive X  PAC-learner. Most active learning approaches can be loosely de-scribed as more  X  X ggressive X  or more  X  X ellow X . A more aggressive approach is one in which only  X  X ighly infor-mative X  queries are requested (Tong &amp; Koller, 2002; Balcan et al., 2007; Dasgupta et al., 2005), while the mellow approach, first proposed in the CAL algorithm (Cohn et al., 1994), is one in which the learner essen-tially queries all the labels it has not inferred yet. In recent years a significant advancement has been made for active learning in the PAC model. In particu-lar, it has been shown that when the data is realizable (that is, incurs zero error under some assumed hypoth-esis class), the mellow approach can guarantee an ex-ponential improvement in label complexity, compared to passive learning (Balcan et al., 2006). This expo-nential improvement depends on the properties of the distribution, as quantified by the Disagreement Coeffi-cient proposed by Hanneke (2007). Specifically, when learning half-spaces in Euclidean space, the disagree-ment coefficient implies a low label complexity when the data distribution is uniform or close to uniform. El-Yaniv &amp; Wiener (2012) have shown guarantees if the data distribution is a finite mixture of Gaussians. An advantage of the mellow approach is its ability to obtain label complexity improvements in the ag-nostic setting, which allows an arbitrary and large labeling error (Balcan et al., 2006; Dasgupta et al., 2007). Nonetheless, in the realizable case the mellow approach is not always optimal, even for the uniform distribution (Balcan et al., 2007). In this work we re-visit the aggressive approach for the realizable case, and in particular for active learning of half-spaces in Euclidean space. We show that it can be made efficient and practical, while also having theoretical guarantees under reasonable assumptions. We further show, both theoretically and experimentally, that it can some-times be preferable to mellow approaches.
 In the first part of this work we construct an efficient aggressive active learner for half-spaces in Euclidean space, which is approximately optimal if the pool is separable with a margin. While our analysis is fo-cused on the realizable setting, we show that a simple heuristic allows using the same algorithm successfully for pools with low error as well. Our algorithm for halfspaces is based on a greedy query selection ap-proach as proposed in Tong &amp; Koller (2002); Dasgupta (2005). We obtain improved target-dependent approx-imation guarantees for greedy selection in a general active learning setting. These guarantees allow us to prove meaningful approximation guarantees for halfs-paces based on a margin assumption.
 In the second part of this work we compare the greedy approach to the mellow approach. We prove that there are cases in which this highly aggressive greedy ap-proach results in significantly better label complexity compared to the mellow approach. We demonstrate experimentally that substantial improvements in label complexity can be achieved compared to mellow ap-proaches, for both realizable and low-error settings. The first greedy query selection algorithm for learning halfspaces in Euclidean space was proposed by Tong &amp; Koller (2002). The greedy algorithm is based on the notion of a version space : the set of all hypotheses in the hypothesis class that are consistent with the labels currently known to the learner. In the case of halfs-paces, each version space is a convex body in Euclidean space. Each possible query thus splits the current ver-sion space into two parts: the version space that would result if the query received a positive label, and the one resulting from a negative label. Tong and Koller pro-posed to query the example from the pool that splits the version space as evenly as possible. To implement this policy, one would need to calculate the volume of a convex body in Euclidean space, a problem which is known to be computationally intractable (Brightwell &amp; Winkler, 1991). Tong and Koller thus implemented several heuristics that attempt to follow their proposed selection principle using an efficient algorithm. For in-stance, they suggest to choose the example which is closest to the max-margin solution of the data labeled so far. However, none of their heuristics provably fol-low this greedy selection policy.
 The label complexity of greedy pool-based active learning algorithms can be analyzed by comparing it to the best possible label complexity of any pool-based active learner on the same pool. The worst-case label complexity of an active learner is the maximal number of queries it would make on the given pool, where the maximum is over all the possible classification rules that can be consistent with the pool according to the given hypothesis class. The average-case label com-plexity of an active learner is the average number of queries it would make on the given pool, where the average is taken with respect to some fixed probabil-ity distribution P over the possible classifiers in the hypothesis class. For each of these definitions, the op-timal label complexity is the lowest label complexity that can be achieved by an active learner on the given pool. Since implementing the optimal label complexity is usually computationally intractable, an alternative is to implement an efficient algorithm, and to guar-antee a bounded factor of approximation on its label complexity, compared to the optimal label complexity. Dasgupta (2005) showed that if a greedy algorithm splits the probability mass of the version space as evenly as possible, as defined by the fixed probabil-ity distribution P over the hypothesis class, then the approximation factor for its average label complexity, with respect to the same distribution, is bounded by O (log(1 /p min )), where p min is the minimal probability of any possible labeling of the pool, if the classifier is drawn according to the fixed distribution. Golovin &amp; Krause (2010) extended Dasgupta X  X  result and showed that a similar bound holds for an approximate greedy rule. They also showed that the approximation factor for the worst-case label complexity of an approximate greedy rule is also bounded by O (log(1 /p min )), thus extending a result of Arkin et al. (1993). Note that in the worst-case analysis, the fixed distribution is only an analysis tool, and does not represent any assump-tion on the true probability of the possible labelings. Returning to greedy selection of halfspaces in Eu-clidean space, we can see that the fixed distribu-tion over hypotheses that matches the volume-splitting strategy is the distribution that draws a halfspace uni-formly from the unit ball. The analysis presented above thus can result in poor approximation factors, since if there are instances in the pool that are very close to each other, then p min might be very small. We first show that mild conditions suffice to guarantee that p min is bounded from below. By proving a variant of a result due to Muroga et al. (1961), we show that if the examples in the pool are stored using number of a finite accuracy 1 /c , then p min  X  ( c/d ) d 2 , where d is the dimensionality of the space. It follows that the ap-proximation factor for the worst-case label complexity of our algorithm is at most O ( d 2 log( d/c )). While this result provides us with a uniform lower bound on p min , in many real-world situations the prob-ability of the target hypothesis (i.e., one that is con-sistent with the true labeling) could be much larger than p min . A noteworthy example is when the tar-get hypothesis separates the pool with a margin of  X  . In this case, it can be shown that the probability of the target hypothesis is at least  X  d , which can be sig-nificantly larger than p min . An immediate question is therefore: can we obtain a target-dependent label com-plexity approximation factor that would depend on the probability of the target hypothesis, P ( h ), instead of the minimal probability of any labeling? We prove that such a target dependent bound does not hold for a general approximate-greedy algorithm. To overcome this, we introduce an algorithmic change to the approximate greedy policy, which allows us to obtain a label complexity approximation factor of log(1 /P ( h )). This can be achieved by running the approximate-greedy procedure, but stopping the pro-cedure early, before reaching a pure version space that exactly matches the labeling of the pool. Then, an ap-proximate majority vote over the version space can be used to determine the labels of the pool. This result is general and holds for any hypothesis class and distri-bution. For halfspaces, it implies an approximation-factor guarantee of O ( d log(1 / X  )).
 We use this result to provide an efficient approximately-optimal active learner for half-spaces, called ALuMA , which relies on randomized approximation of the volume of the version space (Kannan et al., 1997). This allows us to prove a margin-dependent approximation factor guarantee for ALuMA. The assumption of separation with a margin can be relaxed if a lower bound on the total hinge-loss of the best separator for the pool can be assumed. We show that under such an assumption a simple transformation on the data allows running ALuMA as if the data was separable with a margin. This results in approximately optimal label complexity with respect to the new representation.
 We also derive lower bounds, showing that the depen-dence of our label-complexity guarantee on the accu-racy c , or the margin parameter  X  , is indeed neces-sary and is not an artifact of our analysis. We do not know if the dependence of our bounds on d is tight. It should be noted that some of the most popular learning algorithms (e.g. SVM, Perceptron, and Ad-aBoost) rely on a large-margin assumption to derive dimension-independent sample complexity guarantees. In contrast, here we use the margin for computational reasons. Our approximation guarantee depends loga-rithmically on the margin parameter, while the sample complexities of SVM, Perceptron, and AdaBoost de-pend polynomially on the margin. Hence, we require a much smaller margin than these algorithms do. In a related work, Balcan et al. (2007) proposed an active learning algorithm with dimension-independent guar-antees under a margin assumption. These guarantees hold for a restricted class of data distributions. In the second part of this work, we compare the greedy approach to the mellow approach of CAL in the re-alizable case, both theoretically and experimentally. Our theoretical results show the following: (1) In the simple learning setting of thresholds on the line, our margin-based approach is preferable to the mellow ap-proach when the true margin of the target hypothesis is large. (2) There exists a distribution in Euclidean space such that the mellow approach cannot achieve a significant improvement in label complexity over pas-sive learning for halfspaces, while the greedy approach achieves such an improvement using more unlabeled examples. (3) There exists a pool in Euclidean space such that the mellow approach requires exponentially more labels than the greedy approach.
 We further compare the two approaches experimen-tally, both on separable data and on data with small error. The empirical evaluation indicates that our algorithm, which can be implemented in practice, achieves state-of-the-art results. It further suggests that aggressive approaches can be significantly better than mellow approaches in some practical settings. We show main results for the greedy algorithm in Sec-tion 2. The ALuMA algorithm is described in Sec-tion 3. Results and experiments for the aggressive and the mellow approaches are presented in Section 4. Full proofs and additional experiments are provided in the full version of this paper (Gonen et al., 2012). Let us first introduce some notation. Given a pool X = { x 1 ,...,x m } , where each instance x i is associated with an unknown label L ( i )  X  { X  1 } , the goal of the learner is to find the values L (1) ,...,L ( m ) using as few calls to the oracle L as possible. We assume that L is determined by a function h taken from a predefined hypothesis class H . That is,  X  h  X  H such that for all i , L ( i ) = h ( x i ). We denote this by L W h . An active learning algorithm A obtains ( X,L,T ) as input, where T is the label budget of A . We denote by N ( A ,h ) the number of calls to L that A makes before outputting ( L ( x 1 ) ,...,L ( x m )), under the assumption that L W h . The worst-case label complexity of A is defined to be c wc ( A ) worst-case label complexity for the given pool by OPT. Formally, we define OPT = min A c wc ( A ), where the minimum is taken over all possible active learners for the given pool.
 For a given active learner, we denote by V t  X  H the version space of an active learner after t queries. For-mally, suppose that the active learning queried in-stances i 1 ,...,i t in the first t iterations needed. Then For a given pool example x  X  X , denote by V j t,x the version spaces that would result if the algorithm now queried x and received label j . Formally, Given X and H , we define, for each h  X  X  , the equiva-lence class of h over H , [ h ] = { h 0  X  X | X  x  X  X, h ( x ) = h ( x ) } . We consider a probability distribution P over H such that P ([ h ]) is defined for all h  X  X  . For brevity, we denote P ( h ) = P ([ h ]). Let p min = min h  X  X  P ( h ). Consider an active learning algorithm A . For any  X   X  1, A is  X  -approximately greedy with respect to a probability distribution P over H , if at any itera-tion of the algorithm t , the query x  X  X chosen by A satisfies and the algorithm returns a labeling consistent with V
T upon termination. Golovin &amp; Krause (2010) have shown that any  X  -approximately greedy algo-rithm finds the correct labeling after at most O (  X   X  OPT log(1 /p min )) queries.
 We start by showing that by slightly changing the policy of an approximately-greedy algorithm, we can achieve a better approximation factor whenever the true target hypothesis has a larger probability than p min . This can be done by allowing the algorithm to stop before it reaches a pure version space, and re-quiring that in this case, it would output the labeling which is most likely based on the current version space and the fixed probability distribution P .
 We say that A outputs an approximate majority vote if whenever V T is pure enough, the algorithm outputs the majority vote on V T . Formally, we define this as follows.
 Definition 1. An algorithm A outputs a  X  -approximate majority vote for  X   X  ( 1 2 , 1) if when-ever there exists a labeling Z : X  X  { X  1 } such that P h  X  P [ Z W h | h  X  V T ]  X   X  , A outputs Z .
 In the following theorem we provide the target-dependent label complexity bound, which holds for any approximate greedy algorithm that outputs an ap-proximate majority vote. We give here a sketch of the proof idea. The full proof is provided in Gonen et al. (2012).
 Theorem 1. Let X = { x 1 ,...,x m } . Let H be a hy-pothesis class, and let P be a distribution over H . Sup-pose that A is  X  -approximately greedy with respect to P . Further suppose that it outputs a  X  -approximate majority vote. If A is executed with input ( X,L,T ) where L W h  X  X  , then for all A outputs L (1) ,...,L ( m ) .
 Sketch. Fix a pool X . For any algorithm alg, denote by V t (alg ,h ) the version space induced by the first n labels it queries if the true labeling of the pool is con-sistent with h . Denote the average version space re-duction of alg after t queries by Golovin &amp; Krause (2010) prove that since A is  X  -approximately greedy, for any pool-based algorithm alg, and for every k,t  X  N , Let opt be an algorithm that achieves OPT. We show that for any hypothesis h  X  H and any active learner alg, f avg (opt , OPT)  X  f avg (alg ,t )  X  P ( h )( P ( V t (alg ,h ))  X  P ( h )) . Combining this with Equa-tion (1) we conclude that if A is  X  -approximately greedy then This means that if P ( h ) is large enough and we run an approximate greedy algorithm, then after a suffi-cient number of iterations, most of the remaining ver-sion space induces the correct labeling of the sample. Specifically, if n  X   X  (2 ln(1 /P ( h )) + ln(  X  1  X   X  ))  X  OPT , then P ( h ) /P ( V t ( A ,h ))  X   X  . Since A outputs a  X  -approximate majority labeling from V t ( A ,h ), A re-turns the correct labeling.
 When P ( h ) p min , the bound in Theorem 1 is stronger than the guarantee obtained by Golovin &amp; Krause (2010). Importantly, such an improved ap-proximation factor cannot be obtained for a general approximate-greedy algorithm, even in a very simple setting. Thus, we can conclude that some algorith-mic change is necessary. To show this, consider the setting of thresholds on the line . In this setting, the domain of examples is [0 , 1], and the hypothesis class H line includes all the hypotheses which are positive if the example is larger than some threshold in [0 , 1]. Theorem 2. Consider pool-based active learning on H line , and assume that P on H line selects h c by draw-ing the value c uniformly from [0 , 1] . For any  X  &gt; 1 there exists an  X  -approximately greedy algorithm A such that for any m &gt; 0 there exists a pool X  X  [0 , 1] of size m , and a threshold c such that P ( h c ) = 1 / 2 , while the label-complexity of A for L W h c is m d log( m ) e  X  OPT . Interestingly, this theorem does not hold for  X  = 1, that is for the exact greedy algorithm. This follows from Theorem 4, which we state and prove in Section 4. So far we have considered a general hypothesis class. We now discuss the class of halfspaces in R d , W = { x 7 X  sgn(  X  w,x  X  ) : w  X  B d 1 } , where B d 1 is the unit ball in R d . For simplicity, we will slightly overload no-tation and sometimes use w to denote the halfspace it determines. We fix the distribution P to be the one that selects a vector w uniformly from B d 1 . The follow-ing lemma shows that our active learning algorithm for halfspaces has the desired properties described above with high probability.
 Lemma 1. If ALuMA is executed with confidence  X  , then with probability 1  X   X  over its internal randomiza-tion, ALuMA is 4 -approximately greedy and outputs a 2 / 3 -approximate majority vote. ALuMA is polynomial in the pool size, the dimension, and log(1 / X  ) . Combining the above lemma with Theorem 1 we immediately obtain that ALuMA X  X  label complex-ity is O (log(1 /P ( h ))  X  OPT). We can upper-bound log(1 /P ( h )) using the familiar notion of margin : For any hypothesis h  X  W defined by some w  X  R d , let  X  ( h ) be the maximal margin of the labeling of X by h , show that for all h  X  W , P ( h )  X   X  ( h ) 2 and Lemma 1, we obtain the following corollary, which provides a guarantee for ALuMA that depends on the margin of the target hypothesis.
 Corollary 1. Let X = { x 1 ,...,x m }  X  B d 1 , where B d is the unit Euclidean ball of R d . Let  X   X  (0 , 1) be a confidence parameter. Suppose that ALuMA is exe-cuted with input ( X,L,T, X  ) , where L W h  X  W and T  X  4(2 d ln(2 / X  ( h )) + ln(2))  X  OPT . Then, with proba-bility of at least 1  X   X  over ALuMA X  X  own randomiza-tion, it outputs L (1) ,...,L ( m ) .
 Our result for ALuMA provides a target-dependent ap-proximation factor guarantee, depending on the mar-gin of the target hypothesis. 1 We can also consider the minimal possible margin,  X  = min h  X  X   X  ( h ), and de-duce from Theorem 1, or from the results of Golovin &amp; Krause (2010), a uniform approximation factor of O ( d log(1 / X  )). How small can  X  be? The following result bounds this minimal margin from below under the reasonable assumption that the examples are rep-resented by numbers of a finite accuracy.
 Lemma 2. Let c &gt; 0 be such that 1 /c is an integer and suppose that X  X  { X  1 ,  X  1 + c,..., 1  X  c, 1 } d . Then, min h  X  X   X  ( h )  X  ( c/ The proof is an adaptation of a classic result due to Muroga et al. (1961). We conclude that under this assumption for halfspaces, p min =  X (( c/d ) d 2 ), and de-duce an approximation factor of d 2 log( d/c ) for the worst-case label complexity of ALuMA. The exponen-tial dependence of the minimal margin on d here is necessary; as shown in H  X astad (1994), the minimal margin can indeed be exponentially small, even if the points are taken only from { X  1 } d .
 We also derive a lower bound, showing that the depen-dence of our bounds on  X  or on c is necessary. Whether the dependence on d is also necessary is an open ques-tion for future work.
 Theorem 3. For any  X   X  (0 , 1 / 8) , there exists a pool X  X  B 2 1  X  X  X  1 , 1 + c,..., 1  X  c, 1 } 2 for c =  X (  X  ) , and a target hypothesis h  X   X  X  for which  X  ( h  X  ) =  X (  X  ) , such that there exists an exact greedy algorithm that requires  X (ln(1 / X  )) =  X (ln(1 /c )) labels in order to output a correct majority vote, while the optimal algorithm re-quires only O (log(log(1 / X  ))) queries. We now describe our algorithm, listed below as Alg. 1, and explain why Lemma 1 holds. We name the algo-rithm Active Learning under a Margin Assumption or ALuMA. Its inputs are the unlabeled sample X , the labeling oracle L , the maximal allowed number of la-bel queries T , and the desired confidence  X   X  (0 , 1). It returns the labels of all the examples in X .
 Recall that we take P to be uniform over W , the class of homogeneous half-spaces in R d . In each iteration we wish to choose, among the instances in the pool, the instance whose label would lead to the maximal expected reduction in the version space. Denote by I t the set of indices corresponding to the elements in the pool whose label was not queried yet ( I 0 = [ m ]). This is equivalent to finding, in round t , In order to be able to solve Equation (2), we need to calculate the volumes of the sets V 1 t,x and V  X  1 t,x every element x in the pool. Both of these sets are convex sets obtained by intersecting the unit ball with halfspaces. The problem of calculating the volume of such convex sets in R d is #P-hard if d is not fixed (Brightwell &amp; Winkler, 1991). Moreover, determinis-tically approximating the volume is NP-hard in the general case (Matou X sek, 2002). Luckily, it is possi-ble to approximate this volume using randomization. Specifically, in Kannan et al. (1997) a randomized al-gorithm with the following guarantees is provided: Lemma 3. Let K  X  R d be a convex body with an efficient separation oracle. There exists a randomized algorithm, such that given , X  &gt; 0 , with probability at least 1  X   X  the algorithm returns a number  X   X  0 such that (1  X  ) X  &lt; P ( K ) &lt; (1 + ) X  . The running time of the algorithm is polynomial in d, 1 /, ln(1 / X  ) . We denote an execution of this algorithm on a con-vex body K by  X   X  VolEst( K,, X  ). The algorithm is polynomial in d, 1 /, ln(1 / X  ). ALuMA uses this algo-rithm to estimate P ( V 1 t,x ) and P ( V  X  1 t,x ) with sufficient accuracy. We denote these approximations by  X  v x, 1 and  X  v x,  X  1 respectively. Using Lemma 3 we show that w.p. at least 1  X   X / 2, ALuMA is 4-approximately greedy. After T iterations, ALuMA needs to output the major-ity vote of a version space V that has a high enough purity level. To do this, we would like to uniformly draw several hypotheses from V and label X accord-ing to a majority vote over these hypotheses. This can be approximated using the hit-and-run algorithm (Lov  X asz, 1999), which efficiently draws a random sam-ple from a convex body K  X  R d , according to a distri-bution which is  X  -close in total variation distance to the uniform distribution over K , in time  X  O ( d 3 / X  2 the final step of ALuMA, we produce a majority vote Algorithm 1 The ALuMA algorithm 1: Input: X = { x 1 ,...,x m } , L : [ m ]  X  { X  1 , 1 } , T , 2: I 1  X  [ m ], V 1  X  B d 1 3: for t = 1 to T do 4:  X  i  X  I t ,j  X  X  X  1 } ,  X  v x i ,j  X  VolEst( V j t,x 5: Select i t  X  argmax i  X  I 7: Request y = L ( i t ) 8: V t +1  X  V t  X  X  w : y  X  w,x i t  X  &gt; 0 } 9: end for 10: M  X  X  72 ln(2 / X  ) e . 11: Draw w 1 ,...,w M 1 12 -uniformly from V T +1 . 12: For each x i return y i = sgn P M j =1 sgn(  X  w j ,x i classification from a distribution which is 1 12 -close to uniform. This allows proving that ALuMA outputs a 2 / 3-approximate majority vote w.p. at least 1  X   X / 2. 3.1. Non-Separable Data and Kernels If the data pool X is not separable, but a small up-per bound on the total hinge-loss of the best separator can be assumed, then ALuMA can be applied after a preprocessing step. This preprocessing step maps the points in X to a set of points in a higher dimen-sion, which are separable using the original labels of X . The dimensionality depends on the margin and on the bound on the total hinge-loss of the original represen-tation. The preprocessing step can be enhanced also to support kernel representations, so that the original X can be represented by a kernel matrix as well. Apply-ing ALuMA after this preprocessing steps results in an approximately optimal label complexity, however OPT here is measured with respect to the new repre-sentation. See the full details in Gonen et al. (2012). We demonstrate that in practice, this procedure pro-vides good results on real data sets. Investigating the relationship between OPT in the new representation and OPT in the original representation is an impor-tant question for future work. We now compare the effectiveness of the approach of ALuMA to other active learning strategies. ALuMA can be characterized by two properties: (1) its  X  X b-jective X  is to reduce the volume of the version space; (2) at each iteration, it aggressively selects an exam-ple from the pool so as to (approximately) minimize its objective as much as possible (in a greedy sense). We discuss the implications of these properties by com-paring to other strategies. Property (1) is contrasted with strategies that focus on increasing the number of examples whose label is known. Property (2) is con-trasted with strategies which are  X  X ellow X , in that their criterion for querying examples is softer. Much research has been devoted to the challenge of ob-taining a substantial guaranteed improvement of label complexity over regular  X  X assive X  learning for halfs-paces in R d . Examples (for the realizable case) in-clude QBC (Seung et al., 1992; Freund et al., 1997), CAL (Cohn et al., 1994), and Active Perceptron (Das-gupta et al., 2005). These algorithms are not  X  X ool-based X  but rather use  X  X elective-sampling X : they sam-ple one example at each iteration, and immediately decide whether to ask for its label. Out of these algo-rithms, CAL is the most mellow, since it queries any example whose label is yet undetermined by the ver-sion space. Its  X  X bjective X  can be described as reduc-ing the number of examples which are labeled incor-rectly, since it has been shown to do so in many cases (Hanneke, 2007; 2011; Friedman, 2009). QBC and the Active Perceptron are less mellow. Their  X  X bjective X  is similar to that of ALuMA since they decide on ex-amples to query based on geometric considerations. In Section 4.1 we discuss the theoretical advantages and disadvantages of different strategies, by consider-ing some interesting cases from a theoretical perspec-tive. In Section 4.2 we report an empirical comparison of several algorithms and discuss our conclusions. 4.1. Theoretical Comparison The label complexity of the algorithms mentioned above is usually analyzed in the PAC setting, thus we translate our guarantees into the PAC setting as well for the sake of comparison. We define the ( ,m,D )-label complexity of an active learning algorithm to be the number of label queries that are required in or-der to guarantee that given a sample of m unlabeled examples drawn from D , the error of the learned clas-sifier will be at most (with probability of at least 1  X   X  over the choice of sample). A pool-based active learner can be used to learn a classifier in the PAC model by sampling a pool of m unlabeled examples from D , applying the pool-based active learner to this pool, and running a passive learner on the labeled pool to obtain a classifier. For the class of halfspaces, if we sample an unlabeled pool of m =  X   X ( d/ ) examples, the learned classifier will have an error of at most (with high probability).
 To demonstrate the effect of property (1) presented above, consider again the case of thresholds on the line defined in Section 2. Compare two greedy pool-based active learners for H line : The first follows a bi-nary search procedure, greedily selecting the example that increases the number of known labels the most. This requires d log( m ) e queries to identify the correct labeling of the pool. The second algorithm queries the example that splits the version space as evenly as possible. Theorem 1 implies a label complexity of O (log( m ) log(1 / X  ( h ))) for such an algorithm, since OPT max = O (log( m )). However, a better result holds: Theorem 4. In the problem of thresholds on the line, for any pool with labeling L , the exact greedy algorithm, and any approximate greedy algorithm that outputs a majority vote, require at most O (log(1 / X  ( h ))) labels. Comparing the d log( m ) e guarantee of the first algo-rithm to the log(1 / X  ( h )) guarantee of the second, we reach the (unsurprising) conclusion, that the first al-gorithm is preferable when the true labeling has a small margin, while the second is preferable when the true labeling has a large margin. This simple exam-ple accentuates the implications of selecting the vol-ume of the version space as an objective. A sim-ilar implication can be derived in the PAC setting, when comparing CAL to ALuMA, with m =  X   X (1 / ). When d = 1, CAL achieves a label-complexity of O (log(1 / )) = O (log( m )), similarly to the binary search strategy. Thus when is large compared to  X  ( h ), CAL is better than being greedy on the volume, and the opposite holds when the condition is reversed. QBC will behave similarly to ALuMA in this setting. To demonstrate the effect of property (2) described above X  X eing aggressive versus being mellow X  X e con-sider an example adapted from Dasgupta (2006). In this example the distribution is supported by two cir-cles in R 3 , one around the origin and one slightly above it. Dasgupta has demonstrated via this example that active learning can gain in label complexity from hav-ing significantly more unlabeled data. The following theorem shows that the aggressive strategy employed by ALuMA indeed achieves an exponential improve-ment when there are more unlabeled samples. In many applications, unlabeled examples are virtually free to sample, thus it can be worthwhile to allow the ac-tive learner to sample more examples than the passive sample complexity and use an aggressive strategy. In contrast, the mellow strategy of CAL does not signif-icantly improve over passive learning in this case. We note that these results hold for any selective-sampling method that guarantees an error rate similar to pas-sive ERM given the same sample size. This falls in line with the observation of Balcan et al. (2007), that in some cases a more aggressive approach is preferable. Theorem 5. For all small enough  X  (0 , 1) there is a distribution D of points in R 3 , such that 1. For m = O (1 / ) , the ( ,m,D ) -label complexity 2. For m =  X (log 2 (1 / ) / 2 ) , the ( ,m,D ) -label 3. For any value of m , the ( ,m,D ) -label complexity This theorem demonstrates a case where more un-labeled examples can help ALuMA use less labels, whereas they do not help CAL. In fact, in some cases the label complexity of CAL can be significantly worse than that of the optimal algorithm, even without more unlabeled examples that the optimal algorithm can ex-ploit. An example is provided in Gonen et al. (2012). 4.2. Empirical Comparison We now report an empirical comparison between ag-gressive and mellow algorithms. Our goal is twofold: First, to evaluate ALuMA in practice, and second, to compare the performance of aggressive strategies and mellow strategies. The aggressive strategy is repre-sented by ALuMA and by Tong &amp; Koller (2002). The mellow strategy is represented by CAL. QBC repre-sents a middle-ground between aggressive and mellow. We also compare to a passive ERM algorithm X  X ne that uses random labeled examples.
 Our implementation of ALuMA uses hit-and-run sam-ples instead of full-blown volume estimation. See Go-nen et al. (2012) for full details. QBC was also im-plemented using hit-and-run (Gilad-Bachrach et al., 2005). CAL and QBC were provided with a random ordering of the pool. The algorithm TK is the first heuristic proposed in Tong &amp; Koller (2002), in which at each iteration the example closest to the max-margin solution of the labeled examples is selected. Since the active learners operate by reducing the training error, the graphs below compare the achieved training errors. In all algorithms, we classify the training examples us-ing the version space defined by the queried labels. The theory for CAL and ERM allows selecting an ar-bitrary predictor from the version space. In QBC, the predictor should be drawn uniformly at random from the version space. We found that all the algorithms perform significantly better if the majority vote classi-fication proposed for ALuMA is used for them. There-fore, we used this methodology in for all algorithms. First, we conducted a synthetic experiment on a sam-ple from the uniform distribution on a sphere. Fig-ure 1 depicts the training error as a function of the la-bel budget when learning a random halfspace over the uniform distribution in R 100 . ALuMA and TK out-perform CAL and QBC here. In Gonen et al. (2012), we show the behavior in R 10 as well. The difference between the performance of the different algorithms is less marked in the lower dimension, suggesting that the difference might grow with the dimension. These results indicate that ALuMA might have a better guar-antee than the general relative analysis in the case of the uniform distribution. Achieving such an analysis is an open question which is left for future work. We next tested MNIST, 2 which depicts gray-scale im-ages of digits in dimension 784. Figure 2(left) shows the training error as a function of the label budget for learning to distinguish between the digits 3 and 5. Strikingly, CAL provides no improvement over pas-sive ERM in the first 1000 examples, ALuMA and TK reach zero training error. We tested also PCMAC, 3 after a random projection from the original dimension of 7511 to dimension 300. The results are shown in Figure 2(right). Again, CAL does not improve over passive ERM unlike the aggressive approaches.
 In the experiments reported so far, TK and ALuMA perform about the same, showing that the TK heuris-tic is very successful. However, there are cases where TK performs much worse than ALuMA. We report a relevant synthetic experiment in Gonen et al. (2012). We also present experiments on non-separable data sets, showing that when the error is low and an up-per bound on the hinge-loss can be assumed, ALuMA can improve performance over mellow approaches.
