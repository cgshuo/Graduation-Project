 The translation quality of state-of-the-art, phrase-based statistical machine translation ( SMT ) approaches hea vily depends on the amount of bilingual language resources available to train the statistical models. For frequently used language pairs lik e Frenc h-English or Chinese-English , lar ge-sized text data sets are readily available. There exist several data collection initiati ves lik e the Lin-guistic Data Consortium 1 , the Eur opean Langua ge Re-sour ce Association 2 , or the GSK 3 , amassing and distrib ut-ing lar ge amounts of textual data. Ho we ver, for less fre-quently used language pairs, e.g., most of the Asian lan-guages, only a limited amount of bilingual resources are available, if at all.

In order to overcome such language resource limita-tions, recent research on multilingual SMT focuses on the usage of pivot langua ges . Instead of a direct translation between two languages where only a limited amount of bilingual resources is available, the pivot translation ap-proach mak es use of a third language that is more appro-priate due to the availability of more bilingual corpora and/or its relatedness towards either the source or the tar -get language. Several pivot translation techniques lik e cascading , phr ase-table combination , or pseudo corpus gener ation have already been proposed (cf. Section 2).
Ho we ver, for most recent research efforts, English is the pivot language of choice due to the richness of avail-able language resources. For example, the Europarl cor -pus is exploited in (Utiyama and Isahara, 2007) for com-paring pivot translation approaches between Frenc h , Ger -man and Spanish via English . Other research efforts tried to exploit the closeness between specic language pairs to generate high-quality translation hypotheses in the rst step to minimize the pivot detoriation effects, e.g., for Catalan -to-English translations via Spanish (Gispert and Marino, 2006).

This paper investig ates the appropriateness of lan-guages other than English as pivot languages to support future research on machine translation between under -resourced language pairs. Pivot translation experiments using state-of-the-art SMT techniques are carried out to translate between twelv e of the major world languages covering Indo-European as well as Asian languages and the effects of selecting a non-English language as the pivot language are discussed in Section 3. Pivot translation is a translation from a source language ( SRC ) to a tar get language ( TRG ) through an intermedi-ate pivot (or bridging ) langua ge ( PVT ). Within the SMT frame work, the follo wing coupling strate gies have al-ready been investig ated: 1. cascading of two translation systems where the rst 2. pseudo corpus approach that (i) creates a  X noisy X  3. phr ase-table composition in which the translation 4. bridging at translation time where the coupling is The effects of using dif ferent pivot languages are inves-tig ated using the multilingual Basic Travel Expr essions Corpus (BTEC), which is a collection of sentences that bilingual tra vel experts consider useful for people going to or coming from another country . For the pivot transla-tion experiments, we selected twelv e of the major world languages covered by BTEC, favoring languages that are acti vely being researched on, i.e., Chinese (zh), English (en), Frenc h (fr), German (de), Hindi (hi), Indonesian (id), Japanese (ja), Korean (ko), Malay (ms), Spanish (es), Thai (th), and Vietnamese (vi). These languages dif fer lar gely in wor d order (SV O, SO V), segmentation unit (phrase, word, none), and degree of inflection (high, moderate, light). All data sets were case-sensiti ve with punctuation marks preserv ed.

Ho we ver, in a real-w orld application, identical lan-guage resources covering three or more languages are not necessarily to be expected. In order to avoid a trilingual scenario for the pivot translation experiments described in this paper , the 160k sentence-aligned BTEC corpus was randomly split into two subsets of 80k sentences each, whereby the rst set of sentence pairs was used to train the source-to-pi vot translation models ( 80 k sp ) and the second subset of sentence pairs was used to train the pivot-to-tar get translation models ( 80 k pt ). Table 1 sum-marizes the characteristics of the BTEC corpus data sets used for the training ( train ) of the SMT models, the tun-ing of model weights ( dev ), and the evaluation of transla-tion quality ( eval ). Besides the number of sentences ( sen ) and the vocab ulary ( voc ), the sentence length ( len ) is also given, as the average number of words per sentence.
For the training of the SMT models, standard word alignment (Och and Ne y, 2003) and language modeling (Stolck e, 2002) tools were used. Minimum error rate training ( MER T ) was used to tune the decoder' s param-eters, and performed on the dev set using the technique proposed in (Och and Ne y, 2003). For the translation, an in-house multi-stack phrase-based decoder compara-ble to MOSES was used. For the evaluation of trans-lation quality , we applied standard automatic evaluation metrics, i.e., BLEU (Papineni et al., 2002) and METEOR (Banerjee and La vie, 2005). For the experimental results in this paper , the given scores are calculated as the aver-age of the respecti ve BLEU and METEOR scores obtained for each system output and are listed as percent gures.
In order to get an idea of how dif cult the translation task for the dif ferent languages is supposed to be, the automatic evaluation scores for the direct translation ap-proach using the 80 k sp language resources are summa-rized in Section 3.1. The effects of the pivot language se-lection are discussed in Section 3.2 using the pivot trans-lation method of cascading two SMT systems . In addition, the dependenc y between selecting the optimal pivot lan-guage for a given language pair and the amount of avail-able training resources are described in Section 3.3. 3.1 Dir ect Translation Results The automatic evaluation scores for all source and tar get language pair combinations of the direct translation ap-proach are given in Table 2. For each tar get language, the highest evaluation scores are mark ed in boldf ace and the lowest scores are mark ed in type writer mode.
 The highest translation quality was achie ved for the Japanese , Korean , Indonesian , Malay , and Span-ish , English translation tasks. In addition, relati vely high evaluation scores were achie ved for Japanese ,
Chinese and for translations from English into Ger -man , Frenc h , Hindi , Thai , and Vietnamese . On the other hand, the most dif cult translation tasks were those hav-ing Korean or Chinese as the source language. 3.2 Pivot Translation Results The automatic evaluation scores for all pivot translation combinations are summarized in Table 3 whereby for each source-tar get language pair , the results of the exper -iments using (i) English ( en ) and (ii) the best performing language ( best ) as the pivot language are listed.
Comparing the results of the pivot translation experi-ments towards the direct translation results, we can see that in general the pivot translation approach performs worse than the direct translation approach due to the ef-fect of error chaining, i.e., translation errors of the SRC-PVT engine cause a degradation in translation quality of the PVT -TRG system output. Ho we ver, for language pairs lik e Korean , German , Japanese , Indonesian and German/Spanish , Korean , the best pivot transla-tion system outperforms the direct translation approach slightly . This phenomenon is caused mainly by the high SRC-PVT ( PVT -TRG ) translation quality in combination with a better PVT -TRG ( SRC-PVT ) performance compared to the direct SRC-TRG system output results.

Besides the automatic evaluation scores, Table 3 lists also the optimal pivot language for each source-tar get language pair in boldf ace. The experimental results sho w that English is indeed the best pivot language when trans-lating between languages, lik e German , Spanish , Frenc h , Hindi , Thai , and Vietnamese , whose direct translation performance from/into English is high. For these six languages, all language pair combinations achie ved the highest scores using the English pivot translation ap-proach. In contrast, English is the pivot language of choice for only 16.2% (11 out of 68) of the language pairs when translating from/into Japanese , Korean , Indone-sian , or Malay . In the remaining cases, the language with the highest direct translation scores is in general selected as the optimal pivot language, i.e., Japanese for Korean , Malay for Indonesian and vice versa. For Chinese , the choice of the optimal pivot language varies lar gely de-pending on the language direction. Ho we ver, the selec-tion of the optimal pivot language is not symmetric for 34.5% of the language pairs, i.e., a dif ferent optimal pivot language was obtained for the SRC-TRG compared to the TRG-SRC translation task. This indicates that the choice of the optimal pivot language depends on the relatedness of the SRC and PVT languages as well as the relatedness of the PVT and TRG languages.
 The distrib ution of the optimal pivot language selection for all language pairs is given in Table 4. The gures sho w that the English pivot approach still achie ves the highest scores for the majority of the examined language pairs. Ho we ver, in 55.5% (61 out of 110) of the cases, a non-English pivot language, mainly Malay , Indonesian , Japanese , or Korean , is to be preferred. 3.3 Training Data Size Dependency In order to investig ate the dependenc y between selecting the optimal pivot language for a given language pair and the amount of available training resources, we repeated the pivot translation experiments described in Section 3.2 for statistical models trained on subsets of 10k sentences randomly extracted from the 80 k sp and the 80 k pt cor -pora, respecti vely .

The results sho wed that 75.5% of the pivot language selections are identical for small (10k) and lar ge (80k) training data sets. For the remaining 27 out of 110 trans-lation tasks, Table 5 lists how the optimal pivot language selection changed. In the case of small training data sets, the pivot language is closely related (in terms of high direct translation quality) to the source language. Ho w-ever, for lar ger training data sets, the focus shifts towards closely related tar get languages. Therefore, the higher the translation quality of the pivot translation task is, the more dependend the selection of the optimal pivot lan-guage is on the system performance of the PVT -TRG task. In this paper , the effects of using non-English pivot lan-guages for translations between twelv e major world lan-guages were compared to the standard English pivot translation approach. The experimental results revealed that English was indeed more frequently (45.5% out of 110 language pairs) selected as the best pivot language over any other examined language. Ho we ver, its usage is limited to translations between Indo-European languages and some Asian languages lik e Thai or Vietnamese . Oth-erwise, the English pivot approach is lar gely outper -formed by using Asian languages as the pivot languages, especially Japanese , Malay , Indonesian , or Korean .
The analysis of the results revealed that the selection of the optimal pivot language lar gely depends on the SRC-PVT and PVT -TRG translation performance, i.e., for small training corpora, the relationship between source/pi vot languages seems to be more important, whereas the se-lection criteria mo ves towards the relationship between pivot/tar get languages for lar ger amounts of training data and thus for MT engines of higher translation quality .
In order to explore the question of pivot selection fur -ther and arri ve at rmer conclusions, future work will have to investig ate in detail what kind of features are im-portant in selecting a pivot language for a given language pair . Besides the translation quality of SMT engines, au-tomatic metrics to measure the relatedness of a language pair should also be tak en into account to nd optimal pivot languages. For example, (Birch et al., 2008) pro-poses features lik e amount of reor dering , the morpholo g-ical comple xity of the tar get langua ge , and historical re-latedness of the two langua ges as strong predictors for the variability of SMT system performance.

In addition, concerning the question of how the pivot language selection criteria depends on the choice of the pivot translation method, future work will also have to investig ate the effects of pivot language selection for the other pivot translation approaches described in Section 2.
Based on these ndings, we plan to determine the con-trib ution of dif ferent language characteristics on the sys-tem performance automatically to obtain useful indica-tors that could be used to train statistical classication models to predict the best pivot language for a new lan-guage pair and impro ve the usability of machine transla-tion between under -resourced languages further . This work is partly supported by the Grant-in-Aid for Sci-entic Research (C) Number 19500137 and  X Construc-tion of speech translation foundation aiming to overcome the barrier between Asian languages X , the Special Coor -dination Funds for Promoting Science and Technology of the Ministry of Education, Culture, Sports, Science and Technology , Japan.

