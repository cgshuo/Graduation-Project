 We present a prototype of an inductive database. Our sys-tem enables the user to query not only the data stored in the database but also generalizations (e.g. rules or trees) ove r these data through the use of virtual mining views. The mining views are relational tables that virtually contain t he complete output of data mining algorithms executed over a given dataset. The prototype implemented into PostgreSQL currently integrates frequent itemset, association rule a nd decision tree mining. We illustrate the interactive and it-erative capabilities of our system with a description of a complete data mining scenario.
 Categories and Subject Descriptors: H.2.4 [Database Management]: System.
 General Terms: Algorithms, Experimentation.
 Keywords: Data Mining, Inductive Databases.
Data mining is not a one-shot activity, but rather an it-erative and interactive process. During the whole discover y process, typically, many different data mining tasks are per -formed, their results are combined, and possibly used as input for other data mining tasks. To support this knowl-edge discovery process, there is a need for integrating data mining with data storage and management. The concept of inductive databases (IDBs) has been proposed as a means of achieving such integration [7]. In [3, 4, 5, 6], we describ e how such an inductive database can be designed in practice, by using virtual mining views .

In an IDB, one can not only query the data stored in the database, but also the patterns that are implicitly present in these data. One of the main advantages of our system is the flexibility of ad-hoc querying, that is, the user can specify new types of constraints and query the patterns and models in combination with the data itself and so forth. In this paper, we illustrate this feature with a data mining sce -nario in which we first learn a classifier over a given dataset and, afterwards, we look for correct association rules, whi ch describes the misclassified examples w.r.t this classifier. No-tice that the functionality of an inductive database goes fa r beyond that of data mining suites such as, Weka [10] and Yale [8]. These systems have the advantage of imposing one uniform data format for a group of algorithms. On the other hand, they do not allow ad-hoc queries.

The rest of the paper is organized as follows. Section 2 addresses the idea behind the development of our proto-type. Section 3 presents the virtual mining views framework . In Section 4, we describe how the system is implemented. Finally, Section 5 describes a complete database scenario, which illustrates the interactive and iterative capabilit ies of our system.
The system presented in this paper builds upon our pre-liminary work in [3, 5, 6]. In contrast to the numerous pro-posals for data mining query languages, we propose to inte-grate data mining into database systems without extending the query language. Instead, we extend the database schema with new tables containing, for instance, association rule s, decision trees, or other descriptive or predictive models. As far as the user is concerned, these tables contain all possi-ble patterns, trees, and models that can be learned over the data. Of course, such tables would in most cases be huge. Therefore, they are in fact implemented as views, called vir -tual mining views.

Whenever a query is formulated, selecting for instance as-sociation rules from these tables, a run of a data mining algorithm is triggered (e.g., Apriori [1]) to compute the re -sult of the query, in exactly the same way that normal views in databases are only computed at query time, and only to the extent necessary for answering the query.

When the user formulates his or her mining query, the parser is invoked by the DBMS, creating an equivalent re-lational algebra expression. At this point, the expression is processed by the Mining Extension , which extracts from the query the constraints that can be pushed into the data mining algorithms. The output of these algorithms is then materialized in the virtual mining views. After the materia l-ization, the work-flow of the DBMS continues as usual and, as a result, the query is executed as if all patterns and mod-els were stored in the database. Observe that this system can possibly cover every mining technique whose output can be completely stored in relational tables.

This approach also integrates constraint-based mining in a natural way. Within a query, one can impose conditions on the kind of patterns or models that one wants to find. In many cases, these constraints can be pushed into the min-ing process. In [5], Calders et al. present an algorithm that extracts from a query a set of constraints relevant for association rules to be pushed into the mining algorithm. In this way, not all possible patterns or models need to be generated, but only those required to evaluate the query correctly as if all possible patterns or models were stored. We have extended this constraint extraction algorithm to extract constraints from queries over decision trees. The reader can refer to [3] for more details on the algorithm.
The virtual mining views framework consists of a set of relational tables that virtually contain the complete outp ut of data mining algorithms executed over a given dataset. Every time a dataset D is created in the system, all virtual mining views associated with D are automatically created. Figure 1 illustrates the virtual mining views for the datase t Playtennis [9]. They are the following:
In Section 5, we give some concrete examples of common data mining tasks and well-known constraints (such as min-imum confidence and minimum accuracy) that can be ex-pressed quite naturally with SQL queries over the mining views. For more examples, we refer the reader to [3, 4].
Figure 1: The Virtual Mining Views Framework. C ). We adapted the web-based administration tool PhpP-
When the user writes a query, PostgreSQL generates a data structure representing its corresponding relational al-gebra expression. After this data structure is generated, o ur Mining Extension is called. Here, we process the relational algebra structure, extract the constraints, trigger the da ta mining algorithms and materialize the results in the virtua l mining views. Just after the materialization, the work-flow of the DBMS continues and the query is executed as if the patterns or models were there all the time.

The system is currently linked to algorithms for frequent itemset mining, association rule discovery and exhaustive decision tree learning [6]. The constraints represented as attributes of the mining views (size, accuracy, support, co n-fidence) can be extracted and efficiently exploited by the integrated data mining algorithms.

Experiments published in [4] showed that the execution times of the queries are rather low which support our claim that the virtual mining views provide an elegant way to in-corporate data mining capacities to database systems with-out changing the query language. Figure 3: Mining views for table simple mushroom.
In this section, we describe an extended scenario that ex-plores the interactive and iterative capabilities of our sy s-tem. The scenario consists of mining decision trees over the mushroom dataset [2] and also association rules over inter-mediate query results. We assume that table mushroom is already stored in our system. It contains 8,124 tuples and 23 categorical attributes. The attribute class discriminates mushrooms from being poisonous or edible, while the other attributes describe features of the mushrooms, such as the color of the cap and odor.

To illustrate how it is possible to preprocess data using our system, we create a new table called simple mushroom selecting only a subset of the attributes of the original tab le mushroom .

Figure 2 shows the corresponding pre-procecessing query, followed by a query that adds an identifier to every example in the new table (it is worth noticing that the chosen at-tributes are known to be important for classification). The mining views automatically created for table simple mush-room can be visualized in the screenshot in Figure 3.
In this step, we look for decision trees over table sim-ple mushroom , targetting the attribute class and with max-imum accuracy among those trees of size  X  5.

The query is shown in Figure 4. The subquery selects the maximum accuracy achieved by the trees with size  X  5 and accuracy  X  90% (the latter constraint is added in order to Figure 4: Query selecting trees with maximum ac-curacy. prune the search space of possible trees). The main query creates a table containing the trees with the characteristi cs mentioned above, having the pre-selected maximum accu-racy. We use views Concepts and T reescharac in order to retrieve the concepts of the trees along with their characte r-istics. In the end, 3 trees are stored in table best tree of them have an accuracy of 95% and 5 nodes.

Having learned the trees with maximum accuracy in the previous step, we now want to explore the predictive capac-ity of these trees. Since all trees have the same accuracy, we choose the most balanced one, presented in Figure 5. This tree has treeid equal to 6.
 Figure 5: Decision tree (  X  foul = { spicy, pungent, none, musty, fishy, creosote, anise, almond } )
Next, we want to store in the database the examples in simple mushroom that are misclassified w.r.t. the selected tree. To classify a new example using that tree, one simply looks up the concept that covers the new example. More generally, if we have a test set S , all predictions of the ex-amples in S are obtained by equi-joining S with the semantic representation of the tree given in the view Concepts . We join S to Concepts using a variant of the equi-join that re-quires that either the values are equal or there is a wildcard value  X ? X .

Figure 6 shows the corresponding query. To suit our pur-poses, the equi-join is made between tables simple mush-room and best tree , from which the tree with treeid = 6 is selected. The misclassified examples are those for which the prediction is different from the real class (stated in the last line of the query).

In this final step, we are interested in describing the mis-Figure 6: Query selecting the misclassified mush-rooms. classified examples obtained in the former step. To this end, first we create table mushroom status in which every ex-ample in table simple mushroom is labeled as well classi-fied ( status = 1) or misclassified ( status = 0). The query is shown in Figure 7. Figure 7: Query labeling the examples w.r.t. the selected decision tree.

Second, we mine table mushroom status for correct (100% confidence) class association rules (the class is the attrib ute status ), having one attribute-value pair in the antecedent, i.e. the most general rules. The query is shown in Figure 8.
Figure 9 shows a screenshot with the rules output by the query in Figure 8. As we are interested in describing the misclassified examples, we focus on the rules having conse-Figure 9: Association rules describing the well clas-sified and misclassified mushrooms. quent X  status =0 X . Clearly, these rules reveal odor = X  X usty X , gill color = X  X reen X , cap color = {  X  X reen X , X  X urple X  } , and spore print color = {  X  X reen X , X  X urple X  } as discriminative fea-tures to explain the misclassifications.

This ends the data mining scenario. In conclusion, we have developed a prototype of an inductive database based on virtual mining views. The advantages of our system are threefold: Firstly, the data are mined where they are lo-cated: in the database. Secondly, the user can specify in a declarative way (SQL queries) the patterns or models in which he or she is interested. Finally, thanks to the flexi-bility of ad-hoc querying of our system, the output of some queries can be used as input for subsequent queries. Hendrik Blockeel is a post-doctoral fellow from the Researc h Foundation  X  Flanders (FWO-Vlaanderen). This research was funded through K.U.Leuven GOA project 2003/8  X  X n-ductive Knowledge bases X , FWO project  X  X oundations for inductive databases X , and the EU project X  X nductive Querie s for Mining Patterns and Models X .
