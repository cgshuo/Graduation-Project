 Background: word embedding and composition models Progress in terms of tasks:  X  Machine translation  X  Dialogue  X  Reasoning  X  Image captioning  X  Natural language parsing  X  ... ...
 Progress in terms of methodology (focus of this tutorial):  X  Attention models  X  External memories  X  Differentiable data structures  X  End-to-end learning  X  Distributed representation of words  X  From words to sentences and beyond  X  Gated RNN (e.g., LSTM, GRU) as encoder and decoder  X  Attention model for automatic alignment  X  End-to-end learning  X  Outperforming STM  X  Comparing with statistical machine translation (SMT)  X  Interesting topic: How to combine NMT and SMT  X  Four-layer LSTMs (deep models)  X  End-to-end learning  X  RNN encoder decoder framework  X  End-to-end learning, differentiable data structure  X  Single turn dialogue and multi turn dialogue  X  Single turn dialogue  X  Multi turn dialogue  X  Sequence-to-sequence learning for single-turn dialogue  X  End-to-end learning  X  End-to-end learning  X  Task-dependent multi-turn dialogue  X  End-to-end learning  X  Architecture  X  Complicated task controlled by networks,  X  Reasoning over facts  X  Natural logic reasoning  X  Reasoning over facts, language modeling, etc  X  Attention model, external memory  X  Architecture  X  External memory, end-to-end learning  X  Architecture  X  Reasoning over facts  X  External memory, differentiable data  X  Architecture  X  Write and read intermediate results into  X  Model: deep neural network or deep tensor network  X  What is differentiable data-structure?  X  A general formulation  X  Addressing strategies  X  Memory: types and structures  X  Examples  X  Concluding remarks  X  What is differentiable data-structure?  X  A general formulation  X  Addressing strategies  X  Memory: types and structures  X  Examples  X  Concluding remarks  X  Representative Examples: (Too) many examples  X  Hard attention  X  Varying number of memory cells  X  Other structural operations  X  Other symbolic stuff (Too) many examples  X  Hard attention  X  Varying number of memory units  X  Other structural operations  X  Other symbolic stuff  X  What is differentiable data-structure?  X  A general formulation  X  Addressing strategies  X  Memory: types and structures  X  Examples  X  Concluding remarks A general formulation: A general formulation: A general formulation: A general formulation: Reading Reading Reading Reading Reading Reading Reading  X  The generic NTM won X  X  work for most real-world tasks  X  What is differentiable data-structure?  X  A general formulation  X  Memory: types and structures  X  Addressing strategies  X  Examples  X  Concluding remarks Roughly , three types  X  Location -based addressing  X  Content -based addressing  X  Hybrid addressing  X  What is differentiable data-structure?  X  A general formulation  X  Memory: types and structures  X  Addressing strategies  X  Examples  X  Concluding remarks A very sloppy categorization  X  Short-term memory  X  Intermediate memory  X  Long-term memory  X  Pre-determined Size (generic NTM)  X  Linear (Neural Stack, Neural Queue)  X  Stacked -Memory ( DeepMemory ) Deep memory-based architecture for NLP  X  Has been applied to many tasks with success  X  What is differentiable data-structure?  X  A general formulation  X  Addressing strategies  X  Memory: types and structures  X  Examples  X  Concluding Remarks  X  A neural network system for querying KB tables  X  A neural network system for querying KB tables  X  A neural network system for querying KB tables  X  What is differentiable data-structure?  X  A general formulation  X  Addressing strategies  X  Memory: types and structures  X  Examples  X  Concluding Remarks advantages and disadvantages  X  Overview  X  End -to-end learning (or not?)  X  Dealing with non-differentiability  X  Grounding -based learning It is a complex (and powerful) mixture of  X  Supervised learning :  X  Unsupervised learning:  X  Reinforcement learning:  X  Explanation-based learning:  X  End-to-end vs.  X  X tep-by-step X   X  Gradient descent vs. Non-differentiable objectives  X  Supervision from  X  X rounding X  or human labeling  X  Supervised learning vs. Reinforcement learning  X  End-to-end vs.  X  X tep-by-step X   X  Gradient-based vs. Non-differentiable objectives  X  Supervision from  X  X rounding X  or human labeling  X  Supervised learning vs. Reinforcement learning  X  End-to-end vs.  X  X tep-by-step X   X  Gradient-based vs. Non-differentiable objectives  X  Supervision from  X  X rounding X  or human labeling  X  Supervised learning vs. Reinforcement learning  X  End-to-end vs.  X  X tep-by-step X   X  Gradient-based vs. Non-differentiable objectives  X  Supervision from  X  X rounding X  or human labeling  X  Supervised learning vs. Reinforcement learning  X  End-to-end vs.  X  X tep-by-step X   X  Gradient-based vs. Non-differentiable objectives  X  Supervision from  X  X rounding X  or human labeling  X  Supervised learning vs. Reinforcement learning  X  End-to-end vs.  X  X tep-by-step X   X  Gradient -based vs. Non-differentiable objectives  X  Supervision from  X  X rounding X  or human labeling  X  Supervised learning vs. Reinforcement learning  X  End-to-end learning: sequence-to-sequence learning  X  Non-differentiable objective: BLEU  X  Human labeling: human given reference  X  Overview  X  End -to-end learning (or not?)  X  Dealing with non-differentiability  X  Grounding -based learning  X  Deep NLP model in action  X  Deep NLP model in learning An example of w eird problem structure Most serious end-to-end neural systems are rather deep Most serious end-to-end neural systems are rather deep Most serious end-to-end neural systems are rather deep Most serious end-to-end neural systems are rather deep  X  A few examples  X  Neural Programmer-Interpreter Pros:  X  It allows you to focus on the architecture design  X  The model can learn from scratch (often with just BP) Cons:  X  Overview  X  End -to-end learning (or not?)  X  Dealing with non-differentiability  X  Grounding -based learning For example, What to do Maximizing the BLEU score Maximizing the BLEU score Maximizing the BLEU score Markov Decision Process (M DP )  X  set of states S , set of actions A , initial state S  X  transition model P ( s , a , s  X )  X  reward function r ( s )  X  Goal: maximize cumulative reward in the long run  X  Policy: mapping from S to A  X  Reinforcement learning RL is useful for deep NLP models, when General ideas:  X  Sequential prediction as decision making  X  Strategy (in dialogue) as discrete action Real applications:  X  Text game  X  RL for natural language generation  X  RL for policy learning in dialogue system Real applications: Real applications:  X  Simple policy gradient to maximize the BLEU RL for policy learning in dialogue system Pros:  X  More modeling flexibility (discrete decision allowed) Cons: Pros:  X  More modeling flexibility (discrete decision allowed) Cons: Pros:  X  More modeling flexibility (discrete decision allowed) Cons:  X  Overview  X  End -to-end learning (or not?)  X  Dealing with non-differentiability  X  Grounding -based learning Grounded on its interaction with other agent  X  Example: Text game Grounded on other modality  X  Example: Image/video captioning and image QA Grounded on its interaction with KB  X  Example : Table querying Grounded on its interaction with other agent  X  Example: Text game Grounded on other modality  X  Example: Image/video captioning and image QA Grounded on its interaction with KB  X  Example : Table querying Grounded on its interaction with a knowledge-base  X  1. Table querying Exciting progress in deep learning for NLP Models Tasks :  X  Differentiable data-structure is powerful  X  We need more learning paradigms 
