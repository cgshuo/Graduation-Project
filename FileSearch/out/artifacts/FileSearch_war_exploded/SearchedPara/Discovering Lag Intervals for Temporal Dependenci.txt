 Time lag is a key feature of hidden temporal dependencies within sequential data. In many real-world applications, time lag plays an essential role in interpreting the cause of discovered temporal dependencies. Traditional tempo-ral mining methods either use a predefined time window to analyze the item sequence, or employ statistical techniques to simply derive the time dependencies among items. Such paradigms cannot effectively handle varied data with special properties, e.g., the interleaved temporal dependencies.
In this paper, we study the problem of finding lag intervals for temporal dependency analysis. We first investigate the correlations between the temporal dependencies and other temporal patterns, and then propose a generalized frame-work to resolve the problem. By utilizing the sorted table in representing time lags among items, the proposed algorithm achieves an elegant balance between the time cost and the space cost. Extensive empirical evaluation on both synthet-ic and real data sets demonstrates the efficiency and effec-tiveness of our proposed algorithm in finding the temporal dependencies with lag intervals in sequential data. H.2.8 [ Database applications ]: Data mining Temporal dependency, Time lag
Sequential data is prevalent in business, system manage-ment, health-care and many scientific domains. One fun-damental problem in temporal data mining is to discover hidden temporal dependencies in the sequential data [23] [11] [13] [8] [29]. In temporal data mining, the input da-ta is typically a sequence of discrete items associated with time stamps [24] [23]. Let A and B be two types of items, a temporal dependency for A and B , written as A ! B , denotes that the occurrence of B depends on the occurrence of A . The dependency indicates that an item A is often fol-lowed by an item B . Let [ t 1 ; t 2 ] be the range of the lag for two dependent A and B . This temporal dependency with [ t ; t 2 ] is written as A ! [ t 1 ;t 2 ] B [7]. For example, in system management, disk capacity alert and database alert are two item types. When the disk capacity is full, the database engine often raises a database alert in the next 5 to 6 min-utes as shown in Figure 1. Hence, the disk capacity has a temporal dependency with the database. [5 min ; 6 min ] is the lag interval between the two dependent system alert-s. disk capacity al ert ! [5 min ; 6 min ] database al ert describes the temporal dependency with the associated lag interval. This paper studies the problem of finding appropriate lag intervals for two dependent item types.
 Fi gure 1: Lag Interval for Temporal Dependency Temporal dependencies are often used for prediction. In Figure 1, [5 min ; 6 min ] is the predicted time range, indicating when a database alert occurs after a disk capacity alert is received. Furthermore, the associated lag interval charac-terizes the cause of a temporal dependency. For example, if the database is writing a huge temporal log file which is larger than the disk free space, the database alert is imme-diately raised in [0 min ; 1 min ]. But if the disk free capacity is consumed by other applications, the database engine can only detect this alert when it runs queries. The associate time lags in such a case would be larger than 1 minute.
Previous work for discovering temporal dependencies does not consider interleaved dependencies [17] [4] [21]. For A B , they assume that an item A can only have a dependency with its first following B . However, it is possible that an item A has a dependency with any following B . For exam-ple, in Figure 1, the time lag for two dependent A and B is 5 to 6 minutes, but the time lag for two adjacent A  X  X  is only 4 minutes. All A  X  X  have a dependency with the second follow-ing B , not the first following B . Hence, the dependencies among these dependent A and B are interleaved. For two item types, the numbers of time stamps are both O ( n ), The number of possible time lags is O ( n 2 ). Thus, the number of lag intervals is O ( n 4 ). The challenge of our work is how to efficiently find appropriate lag intervals over the O ( n candidates.
In this paper, we study the problem of finding appropriate lag intervals for temporal dependency analysis. The contri-bution of this paper is summarized as follows:
The rest of the paper is organized as follows: Section 2 summarizes the related work for temporal pattern mining and discusses the relationships with other existing temporal patterns. Section 3 defines the lag interval that we try to find. Section 4 presents several algorithms for finding ap-propriate lag intervals and analyzes the complexity of our problem. In Section 5, we present the experimental studies on synthetic and real data sets. Finally, Section 6 concludes our paper and discusses the future work.
Previous work of temporal dependency discovery can be categorized by the data set type. The first category is for market basket data, which is a collection of transactions [29] where each transaction is a sequence of items. The pur-pose of this type of temporal dependency discovery is to find frequent subsequences which are contained by a certain amount of transactions. Typical algorithms are GSP [28], FreeSpan[9], PrefixSpan[26], and SPAM[3]. The second cat-egory is for the time series data. A temporal dependency of this category is seen as a correlation on multiple time series variables [32] [5], which determines whether one time series is useful in forecasting another. Our work belongs to the third category, which is for temporal symbolic sequences. The input data is an item sequence and each item is asso-ciated with a time stamp. An item may represent an event or a behavior in history [18] [24] [23] [25][16]. The purpose is to find various temporal relationships among these events or behaviors. Many temporal patterns proposed in previous work can be considered as special cases of temporal depen-dencies with different lag intervals.
Table 1 lists several types of temporal patterns proposed in the literature and their corresponding temporal depen-dencies with lag intervals. A mutually dependent pattern ( m-pattern ) f A; B g , can be described as two temporal de-pendencies A ! [0 ; ] B and B ! [0 ; ] A . Items of A and B in an m-pattern appear almost together so that t 1 = 0 ; t 2 where is the time tolerance. A partially periodic pattern ( p-pattern ) [20] for a single item A , can be expressed as a temporal dependency A ! [ p  X  ;p + ] A , where p is the pe-riod. Frequent episodes A ! B ! C can be separated to A ! time window length [21]. [17] proposes loose temporal pat-tern and stringent temporal pattern . As shown in Table 1, the two types of temporal patterns can be explained by two temporal dependencies with particular constraints on the lag intervals. One common problem of these algorithms is how to set the precise parameter about the time window [21] [20] [4]. For example, for discovering partially periodic patterns, if is too small, the identification of partially periodic pat-terns would be too strict and no result can be found; if the is too large, many false results would be found. [15] [14] [22] directly find frequent episodes according to the occurrences of episodes in the data sequence. The discovered frequent episode may not have fixed lag intervals for the represented temporal dependency. Our method proposed in this paper does not require users to specify the parameters about the time window and is able to discover interleaved temporal dependencies.
Given an item sequence S = x 1 x 2 :::x N , x i denotes the type of the i -th item, and t ( x i ) denotes the time stamp of x , i = 1 ; 2 ; :::; N . Intuitively, if there is a temporal depen-dency A ! [ t 1 ;t 2 ] B in S , there must be a lot of A  X  X  that are followed by some B with a time lag in [ t 1 ; t 2 ]. Let n denote the observed number of A  X  X  in this situation. For instance, in Figure 1, every A is followed by a B with a time lag of 5 or 6 minutes, so n [5 ; 6] = 4. Only the second A is fol-lowed by a B with a time lag of 0 or 1 minute, so n [0 ; 1] Let r = [ t 1 ; t 2 ] be a lag interval. One question is that, what is the minimum required n r that we can utilize to identify the dependency of A and B with r . In this example, the minimum required n r cannot be greater than 4 since the sequence has at most 4 A  X  X . However, if let r = [0 ; + 1 we can easily have n r = 4. [20] proposes a chi-square test approach to determine the minimum required n r , where the chi-square statistic measures the degree of the independence by comparing the observed n r with the expected n r under the independent assumption. The null distribution of the s-tatistic is approximated by the chi-squared distribution with 1 degree of freedom. Let 2 r denote the chi-square statistic for n r . A high 2 r indicates the observed n r in the given se-quence cannot be explained by randomness. The chi-square statistic is defined as follows: where n A is the number of A  X  X  in the data sequence, P r probability of a B appearing in r from a random sequence. Hence, n A P r is the expected number of A  X  X  that are followed by some B with a time lag in r . n A P r (1 P r ) is the standard deviation. Note that the random sequence should have the same sampling rate for B as the given sequence S . The randomness is only for the positions of B items. It is known that a random sequence usually follows the Poisson process, which assumes the probability of an item appearing in an in terval is proportional to the length of the interval [27]. Therefore, where j r j is the length of r , j r j = t 2 t 1 + w B , w minimum time lag of two adjacent B  X  X , w B &gt; 0, and n B is the number of B  X  X  in S . For lag interval r , the absolute length is t 2 t 1 . w B is added to j r j because without w t = t 2 , j r j = 0, P r is always 0 no matter how large the n As a result, 2 r would be overestimated. In reality, the time stamps of items are discrete samples and w B is the observed sampling period for B items. Hence, the probability of a B appearing in t 2 t 1 time units is equal to the probability of a B appearing in t 2 t 1 + w B time units.
 The value of 2 r is defined in terms of a confidence level. For example, 95% confidence level corresponds to 2 r = 3 : 84. Based on Eq.(1), the observed n r should be greater than  X  3 : 84 n A P r (1 P r ) + n A P r . Note that we only care positive dependencies, so To ensure a discovered temporal dependency fits the entire data sequence, support [2] [28] [20] is used in our work. For A ! r B , the support supp A ( r ) (or supp B ( r )) is the number of A  X  X  (or B  X  X ) that satisfy A ! r B divided by the total number of items N . minsup is the minimum threshold for both supp A ( r ) and supp B ( r ) specified by the user [28] [20]. Based on the two minimum thresholds 2 c and minsup , Def-inition 1 defines the qualified lag interval that we try to find.
Definition 1. Given an item sequence S with two item types A and B , a lag interval r = [ t 1 ; t 2 ] is quali ed if and only if 2 r &gt; 2 c , supp A ( r ) &gt; minsup and supp minsup , where 2 c and minsup are two minimum thresholds speci ed by the user.
In this section, we first develop a straightforward algo-rithm for finding all qualified lag intervals, a brute-force al-gorithm. Then, STScan and STScan  X  algorithms are pro-posed which are much more efficient. We also present a lower bound of the time complexity for finding qualified lag intervals. Finally, we discuss how to incorporate the domain knowledge to speed up the algorithms.
To find all qualified lag intervals, a straightforward al-gorithm is to enumerate all possible lag intervals, compute their 2 r and supports, and then check whether they are qual-ified or not. This algorithm is called brute-force . Clearly, its time cost is very large. Let n be the number of distinct time stamps of S , r = [ t 1 ; t 2 ]. The numbers of possible t are O ( n 2 ), and then the number of possible r is O ( n each lag interval, there is at least O ( n ) cost to scan the entire sequence S to compute the 2 r and the supports. Therefore, the overall time cost of the brute-force algorithm is O ( n which is not affordable for large data sequences.
To avoid re-scanning the data sequence, we develop a sort-ed table based algorithm. A sorted table is a sorted linked list with a collection of sorted integer arrays. Each entry of the linked list is attached to two sorted integer arrays. Figure 2 shows an example of the sorted array. In our algo-rithm, we store every time lag t ( x j ) t ( x i ) into each entry of linked list, where x i = A , x j = B , i; j are integers from 1 to N . Two arrays attached to the entry t ( x j ) t ( x the collections of i and j . In other words, the two arrays are the indices of A  X  X  and B  X  X . Let E i denote the i -th entry of the linked list and v ( E i ) denote the time lag stored at E . IA i and IB i denote the indices of A  X  X  and B  X  X  that are attached to E i . For example in Figure 2, x 3 = A , x 5 = B , t ( x 5 ) t ( x 3 ) = 20. Since v ( E 2 ) = 20, IA 2 contains 3 and IB 2 contains 5. Any feasible lag interval can be represented as a subsegment of the linked list. For example in Figure 2, E E 3 E 4 represents the lag interval [20 ; 120].

To create the sorted table for a sequence S , each time lag between an A and a B is first inserted into a red-black tree. The key of the red-black tree node is the time lag, the value is the pair of indices of A and B . Once the tree is built, we tra verse the tree in ascending order to create the linked list of the sorted table. In the sequence S , the number A and B are both O ( N ), so the number of t ( x j ) t ( x i ) is O ( N time cost of creating the red-black tree is O ( N 2 log N O ( N 2 log N ). Traversing the tree costs O ( N 2 ). Hence, the overall time cost of creating a sorted table is O ( N 2 log N ), which is the known lower bound of sorting X + Y where X and Y are two variables [10]. The linked list has O ( N entries, and each attached integer array has O ( N ) elements, so it seems that the space cost of a sorted table is O ( N N ) = O ( N 3 ). However, Lemma 1 shows that the actual space cost of a sorted table is O ( N 2 ), which is same as the red-black tree.

Lemma 1. Given an item sequence S having N items, the space cost of its sorted table is O ( N 2 ) .

Proof. Since the numbers of A  X  X  and B  X  X  are both O ( N ), the number of pairs ( x i ; x j ) is O ( N 2 ), where x i x ; x j 2 S . Every pair associated with three entries in the sorted table: the time stamp distance, the index of an A and the index of a B . Therefore, each pair ( x i ; x j ) introduces 3 space cost. The total space cost of the sorted table is O (3 N 2 ) = O ( N 2 ).

Onc e the sorted table is created, finding all qualified lag intervals is scanning the subsegments of the linked list. How-ever, the number of entries in the linked list is O ( N 2 there are O ( N 4 ) distinct subsegments. Scanning all sub-segments is still time-consuming. Fortunately, based on the minimum thresholds on the chi-square statistic and the sup-port, the length of a qualified lag interval cannot be large.
Lemma 2. Given two minimum thresholds 2 c and minsup , the length of any quali ed lag interval is less than T N 1
Pr oof. Let r be a qualified lag interval. Based Eq.(1) and Inequality.(3), 2 r increases along with n r . Since n n , B y substituting Eq. 2 to the previous inequality, S ince n B &gt; N minsup , 2 c &gt; 0, we have
N is exactly the average period of items, which is deter-mined by the sampling rate of this sequence. For example, in system event sequences, the monitoring system checks the system status for every 30 seconds and records system events into the sequence. The average period of items is 30 seconds. Therefore, we consider T N as a constant. minsup is also a constant, so j r j max is a constant.

Algorithm STScan states the pseudocode for finding all qualified lag intervals. len ( ST ) denotes the number of en-tries of the linked list in sorted table ST . This algorithm sequentially scans all subsegments starting with E 1 , E 2 E len ( ST ) . Based on Lemma 2, it only scans the subsegment with j r j &lt; j r j max . To calculate the 2 r and the supports, Al gorithm 1 STScan ( S; A; B; ST; 2 c ; minsup ) 1: R  X  X  X  3: for i = 1 to len ( ST ) do 6: j  X  0 7: while i + j  X  len ( ST ) do 12: break 13: end if 16: j  X  j + 1 18: continue 19: end if 22: R  X  R  X  r 23: end if 24: end while 25: end for 26: return R for each subsegment, it cumulatively stores the aggregate indices of A  X  X  and B  X  X  and the corresponding lag interval r . For each subsegment, n r = j IA r j , supp A ( r ) = j supp B ( r ) = j IB r j =N .

Lemma 3. The time cost of STScan is O ( N 2 ) , where N is the number of items in the data sequence.

Proof. For each entry E i + j in the linked list, the time cost of merging IA i + j and IB i + j to IA r and IB r is j
IB i + j j by using a hash table. Let l i be the largest length of the scanned subsegments starting at E i . Let l max be the maximum l i , i = 1 ; :::; len ( ST ). The total time cost is:  X  gers in all integer arrays. Based on Lemma 1, j
IB i j ) = O ( N 2 ). Then T ( N ) = O ( l max N 2 ). Let E be the subsegment for a qualified lag interval, v ( E k + i 0, i = 0 ; :::; l . The length of this lag interval is j is not depending on N . Assume  X  E is the average v ( E k +1 v ( E k ), k = 1 ; :::; len ( ST ) 1, we obtain a tighter bound of l the overall time cost is T ( N ) = O ( N 2 ).
To reduce the space cost of STScan algorithm, we devel-op an improved algorithm STScan  X  which utilizes the incre-ment sorted table and sequence compression.
Lemma 1 shows the space cost of a complete sorted table is O ( N 2 ). Algorithm STScan sequentially scans the subseg-ments starting from E 1 to E len ( ST ) , so it does not need to access every entry at every time. Based on this observation, we develop an incremental sorted table based algorithm with an O ( N ) space cost. This algorithm incrementally creates the entries of the sorted table along with the subsegment scanning process.

The linked list of a sorted table can be created by merging all time lag lists of A  X  X  ( Figure 3), where A i and B j the i -th A and the j -th B , i; j = 1 ; 2 ; ::: . The j -th entry in are not necessary to be created in the memory because we only need to know t ( B j ) and t ( A j ). This can be done just with an indices arrays of all A  X  X  and all B  X  X  respectively. By using N -way merging algorithm, each entry of the linked list would be created sequentially. The indices of A  X  X  and B  X  X  attached to each entry are also recorded during the merging process. Base on Lemma 2, the length of a qualified lag interval is at most j r j max , therefore, we only keep track of the recent l max entries. The space cost for storing l max entries is at most O ( l max N ) = O ( N ). A heap used by the merging process costs O ( N ) space. Then, the overall space cost of the incremental sorted table is O ( N ). The time cost of merging O ( N ) lists with total O ( N 2 ) elements is still O ( N 2 log N ).
In many real-world applications, some items may share the same time stamp since they are sampled within the same sampling cycle. To save the time cost, we compress the original S to another compact sequence S  X  . At each time stamp t in S , if there are k items of type I , we create a To handle S  X  , the only needed change of our algorithm is that the j IA r j and j IB r j become the total cardinalities of triples in IA r and IB r respectively. Clearly, S  X  is more compact than S . S  X  has O ( n ) triples, where n is the number of distinct time stamps of S , n N . Creating S  X  costs an O ( N ) time complexity. By using S  X  , the time cost of STScan  X  becomes O ( N + n 2 log n ) and the space cost of the incremental sorted table becomes O ( n ).
For analyzing large sequences, an O ( n ) or O ( n log n ) algo-rithm is needed. However, we find that the time complexity of any algorithm for our problem is at least O ( n 2 ) (Lemma 4). The proof is to reduce the 3SUM  X  problem to our prob-lem, and the 3SUM  X  has no o ( n 2 ) solution [6]. To answer whether O ( n 2 ) is the tightest lower bound or not, a further study is needed.

Lemma 4. Finding a quali ed lag interval cannot be solved in o ( n 2 ) in the worst case, where n is the number of distinct time stamps of the given sequence.

Proof. Assume that an algorithm P can find a qual-ified lag interval in o ( n 2 ) in any case, we can construct an algorithm to solve the 3SUM  X  problem in o ( n 2 ) as fol-lows. Given three sets of integers X , Y , and Z such that j
X j + j Y j + j Z j = n , we construct a compressed sequence S of items which only has two item types A and B as follows: 1. For each x i in X , create an A at time stamp x i . 2. For each y i in Y , create a B at time stamp y i . 3. For each z i in Z , create n + 1 A  X  X  at time stamp ( i + Only the lag intervals created from z i have n r n + 1. If there are three integers y j 2 Y , x k 2 X , z i 2 Z such that y j x k = z i , the lag interval of z i must have n r n + 2. Then, we substitute n r = n + 2 into Eq. 1 to find the appropriate threshold 2 c , and call algorithm P to find all z that have n r n + 2. By filtering out the situations of y j y k = z i and x j x k = z i , we can obtain the desired three integers such that y j x k = z i if they exist. S  X  most 2 n distinct time stamps. The time cost of creating S O (2 n ) = O ( n ). P is an o ( n 2 ) algorithm. Filtering the result of P is O ( n ) since j Z j n . Therefore, the overall solution for the 3SUM  X  problem is O ( n ) + o ( n 2 ) + O ( n ) = o ( n However, it is believed that the 3SUM  X  problem has no o ( n solution [6]. Therefore, the algorithm P does not exist.
As discussed in Section 2, most existing temporal patterns can be described as temporal dependencies with some con-straints on the lag interval. In many real-world applications, the users have the domain knowledge or other requirements for desired lag intervals, which are helpful to speed up the algorithm. For example, in system management, the tem-poral dependencies of certain events can be used to identify false alarms [31]. However, SLA(Service Level Agreement) requires that any real system alarms must be acknowledged within K hours, and K is specified in the contract with cus-tomers. If a discovered lag interval is greater than K hours, the corresponding temporal dependency is trivial and can not be used for false alarm identification.

Generally, the constraints for a qualified lag interval [ t can be expressed as a set of inequalities: where m is the number of constraints, f i ( t 1 ; t 2 ) d straint functions that need to be satisfied. For example, the constraint for the partially periodic pattern is j t 1 t 2 Th e constraints for the predefined time window based tem-poral pattern are t 1 = 0, t 2 p , where p is the window length. To incorporate the constraints to our algorithm, a straightforward approach is to filter discovered qualified lag interval by the given constraints. However, this approach does not make use of the constraints to reduce the search space of the problem. On the other hand, since the con-straint function f i ( ; ) can be any complex function about t and t 2 , there is no generalized and optimal approach for using them. We only consider two typical cases: j t 1 t 2 and t 2 p . The first case can be utilized in the subsegment scanning. It provides a potential tighter bound than l max &lt; l max , but does not change the order of the overall time cost. The second case can be utilized to reduce the length of the linked list of the sorted table. When t 2 &lt; p , each time lag list of A i has at most O ( p=  X  E ) entries. Then, the overall time cost can be reduced to O ( n log n p=  X  E ) = O ( n log n ).
This section presents our empirical study of discovering lag intervals on both synthetic data sets and real data sets in terms of the effectiveness and efficiency.
All comparative algorithms are implemented in Java 1.6 platform. Table 2 summarizes our experimental environ-ment. At present, the most dedicated algorithm for finding la g intervals is the inter-arrival clustering method [17] [20], denoted by inter-arrival . For A ! B , an inter-arrival is the time lag of an A to its first following B . A dense cluster cre-ated from all inter-arrivals indicates its time lag frequent-ly appears in the sequence. Thus, a qualified lag interval is probably around this time lag. This algorithm is very efficient and only has a linear time cost, however, it does not consider the interleaved dependencies. We also imple-ment the four algorithms, brute-force , brute-force  X  , STScan and STScan  X  , to compare with in this experiment. brute-force  X  is the improved version of brute-force which utilizes the pruning strategy about j r j max mentioned in Lemma 2.
For each test, we enumerate all pairwise temporal depen-dencies for discovering qualified lag intervals.
The synthetic data consists of 7 data sequences. Each se-quence is first generated from a random item sequence with 8 item types, denoted by I 1 ,..., I 8 . The average sample period of items is 100. Three predefined temporal dependencies are randomly embedded into each random sequence and shown in Table 3. For each temporal dependency I i ! [ t 1 ;t 2 firs t randomly choose an item x i and an integer t 2 [ t and then let x i = I i and the item at t ( x i ) + t be I repeat this process until 2 [ t than the specified thresholds. Note that the time lags in these lag intervals are larger than the average sample period of items, so all three temporal dependencies are very likely to be interleaved dependencies.
The effectiveness of the algorithm result is validated by comparing the discovered results with the embedded lag in-tervals and measured by the recall [29]. We do not care the precision because every algorithm can achieve the 100% pre-cision if this algorithm is correct. We let 2 c = 10 : 83 which represents a 99 : 9% confidence level, minsup = 0 : 1. There is no surprise that all the algorithms proposed in this pa-per, brute-force , brute-force  X  , STScan and STScan  X  , find all the embedded lag intervals since they scan the entire space of the lag interval. Thus, the recalls of these methods are 1.0. The parameter of inter-arrival is varied from 1 to 2000. However, inter-arrival does not find any qualified lag interval in the synthetic data and its recall is 0. The reason is that, the qualified lag intervals are [400,500], [1000,1100] and [5500,5800], but most inter-arrivals in the sequence are close to the average sample period 100. Thus, inter-arrival can only probe the lag intervals around 100.
The empirical efficiency is evaluated by the CPU running time (Figure 4). inter-arrival is a linear algorithm, so it runs much faster than other algorithms. The running time of the brute-force algorithm increases extremely fast so that it can only handle very tiny data sets. By adding the pruning strat-egy about j r j max to brute-force , the brute-force  X  algorithm runs a little bit faster than the brute-force algorithm, but it still can only handle small data sets. STScan  X  compresses the sequence before the lag interval discovering, therefore, STScan  X  is a little bit more efficient than STScan .
STScan has not finish the tests for larger data sets be-cause it runs out of memory. Table 5 lists the approximate peak numbers of allocated objects in Java heap memory (not including the data sequence). It confirms Lemma 1 that the sorted table takes an O ( N 2 ) space cost. It also shows that, the space costs of STScan  X  , brute-force and brute-force all O ( N ) as mentioned in Section 4. Assuming each Java ob-ject only occupies an integer(8 bytes), STScan would cost X X X X o ver 10G bytes memory for 50 10 3 items. Hence, it runs out of memory when the data size becomes larger. However, by using the incremental sorted table, for the same data set, STScan  X  only costs 10M memory. inter-arrival only stores the clusters of all inter-arrivals, so its space cost is small.
Tw o real data sets are collected from IT outsourcing cen-ters by IBM Tivoli monitoring system [1] [30], denoted as Account1 and Account2. Each data set is a collection of system events from hundreds of application servers and da-ta server. These system events are mostly system alerts triggered by some monitoring situations (e.g. the CPU u-tilization is above a threshold). Table 6 shows the time frames and the sizes of the two real data sets. To discov-er the temporal dependencies with qualified lag intervals, we let 2 c = 6 : 64 which corresponds to the confidence level 99%, and minsup = 0 : 05. A constraint that t 2 1 hour is applied to this testing from the domain experts. of inter-arrival is varied from 1 to 2000.

Figures 6 and 7 show the running times of all algorithms on the two real data sets. As for STScan and STScan  X  , the running times grow slower than in Figure 4 because the constraint t 2 1 hour reduces their time complexities. Table 7 lists the peak numbers of allocated memory objects in JVM on Account2 data. The results on Account1 data is similar to this table.
 X X X X
T able 4 lists several discovered temporal dependencies with qualified lag intervals. inter-arrival only finds the first two temporal dependencies on Account2 data. The reason is that, only the two temporal dependencies have very small lag intervals which are just the inter-arrivals of the events. However, the lag intervals for other temporal dependencies are larger than most inter-arrivals, so inter-arrival fails. In Table 4, the first discovered temporal dependency for Account1 shows that M SG P lat AP P is a periodic pat-tern with a period of 1 hour. This pattern indicates this event M SG P lat AP P is a heartbeat signal from an appli-cation. The second and third discovered temporal depen-dencies can be viewed as a case study for event correlation [12]. Since most servers are Linux servers, so the alerts from processes must be also from Linux processes. Therefore, for Account1, process events and Linux process events can be automatically correlated. High CPU utilization alerts ( SM-P C PU ) can only be triggered by abnormal processes, so SMP CP U events can also be correlated with Linux Pr ocess events. In Account2, the first two temporal dependencies compose a mutual dependency pattern between TEC Er ror and Ticket R etry . It can be explained by a programming logic in IBM Tivoli monitoring system. When the mon-itoring system fails to generate the incident ticket to the ticketing system, it will report a TEC error and retry the ticket generation. Therefore, TEC Err or and Ticket R etry events are often raised together. The third and fourth dis-covered temporal dependencies for Account2 are related to a hardware error of an AIX server but with different lag in-tervals. This is caused by a polling monitoring situation. When an AIX server is down, the monitoring system con-tinuously receive AIX H W Er ror events when polling that AIX server. Thus, this AIX H W Er ror event exhibits a pe-riodic pattern. To validate the discovered results, we plot the temporal events into a graphical chart. Figure 5 is a screen shot of the plotting for Account2 data. The x-axis is the time stamp, the y-axis is the event type. As shown by this figure, TEC Err or and Ticket R etry exhibit a mutually dependency since they are always generated at the almost same time. AIX HW Er ror is a polling event.
To test the sensitivity of parameters, we vary 2 c and minsup and test the numbers of discovered temporal depen-dencies (Figures 8 and Figure 9) and the running time (Fig-ure 10 and Figure 11). When varying 2 c , minsup = 0 : 05; When varying minsup , 2 c = 6 : 64 (with 99% confidence lev-el). 2 c is not sensitive to the algorithm result because the associated confidence level is only from 95% to 99 : 99% al-though 2 c is varied from 3 : 84 to 100. By varying minsup , the number of discovered temporal dependencies exponen-tially decreases as shown in Figure 9. As mentioned in [20], the effective choice of minsup is 0 : 001 to 0 : 1.
In this paper, we study the problem of finding appropriate la g intervals for temporal dependencies over item sequences. We investigate the relationship between the temporal de-pendency with other existing temporal patterns. Two al-gorithms STScan and STScan  X  are proposed to efficiently discover the appropriate lag intervals. Extensive empirical evaluation on both synthetic and real data sets demonstrates the efficiency and effectiveness of our proposed algorithm in finding the temporal dependencies with lag intervals in se-quential data. As for the future work, we will continue to investigate more efficient algorithms that can handle large data sequences. We hope to find an O ( n 2 ) time complexity algorithm with a linear or constant space cost.
 The work is supported in part by NSF grants IIS-0546280 and HRD-0833093. [1] IBM Tivoli Monitoring. http://www-01.ibm.com/ [2] R. Agrawal and R. Srikant. Fast algorithms for mining [3] J. Ayres, J. Flannick, J. Gehrke, and T. Yiu.
 [4] K. Bouandas and A. Osmani. Mining association rules [5] A. Dhurandhar. Learning maximum lag for grouped [6] A. Gajentaan and M. H. Overmars. On a class of [7] L. Golab, H. J. Karloff, F. Korn, A. Saha, and [8] R. Gwadera, M. J. Atallah, and W. Szpankowski. [9] J. Han, J. Pei, B. Mortazavi-Asl, Q. Chen, U. Dayal, [10] A. Hernandez-Barrera. Finding an o ( n 2 log n ) [11] E. J. Keogh, S. Lonardi, and B. Y. chi Chiu. Finding [12] S. Kliger, S. Yemini, Y. Yemini, D. Ohsie, and S. J. [13] S. Laxman and P. S. SASTRY. A survey of temporal [14] S. Laxman, P. S. Sastry, and K. P. Unnikrishnan. [15] S. Laxman, P. S. Sastry, and K. P. Unnikrishnan. A [16] T. Li, F. Liang, S. Ma, and W. Peng. An integrated [17] T. Li and S. Ma. Mining temporal patterns without [18] Z. Li, B. Ding, J. Han, R. Kays, and P. Nye. Mining [19] S. Ma and J. L. Hellerstein. Mining mutually [20] S. Ma and J. L. Hellerstein. Mining partially periodic [21] H. Mannila, H. Toivonen, and A. I. Verkamo.
 [22] N. M  X eger and C. Rigotti. Constraint-based mining of [23] T. Mitsa. Temporal Data Mining . Chapman and [24] F. M  X  orchen. Algorithms for time series knowledge [25] F. M  X  orchen and D. Fradkin. Robust mining of time [26] J. Pei, J. Han, B. Mortazavi-Asl, H. Pinto, Q. Chen, [27] S. M. Ross. Stochastic Processes . Wiley, 1995. [28] R. Srikant and R. Agrawal. Mining sequential [29] P.-N. Tan, M. Steinbach, and V. Kumar. Introduction [30] L. Tang, T. Li, F. Pinel, L. Shwartz, and [31] W. Xu, L. Huang, A. Fox, D. A. Patterson, and M. I. [32] W.-X. Zhou and D. Sornette. Non-parametric
