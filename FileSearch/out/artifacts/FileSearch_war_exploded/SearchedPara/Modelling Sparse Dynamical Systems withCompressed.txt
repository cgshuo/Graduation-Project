 William L. Hamilton whamil3@cs.mcgill.ca Mahdi Milani Fard mmilan1@cs.mcgill.ca Joelle Pineau jpineau@cs.mcgill.ca Learning accurate models of complex domains is a fun-damental problem for developing rational autonomous agents. In the case of dynamical systems, the learned models can be used for a variety of tasks, such as tracking, prediction, resource allocation, planning, and much more. The problem of learning models of dynam-ical systems is particularly difficult in settings with large observation spaces and partial observability. Predictive state representations (PSRs) offer one model for discrete time finite action and observation systems, which represent system states as predictions about future events. Unlike other popular frame-works for modelling dynamic systems, such as Hid-den Markov Models (HMMs) for uncontrolled systems (Rabiner, 1990) and Partially Observable Markov De-cision Processes (POMDPs) (Kaelbling et al., 1998) for controlled systems, PSRs do not rely on hidden or latent states. Instead, PSR models are rooted directly in observable quantities. This allows PSRs to be con-structed without expectation maximization (EM) style algorithms, and thus allows for the efficient construc-tion of globally optimal models. Furthermore, PSRs, which are closely related to certain spectral learning algorithms for HMM X  X  (Hsu et al., 2008), are a more general model of stochastic dynamic systems that con-tain the latent state model as a special case (Singh et al., 2004).
 Despite the fact that there are many theoretical re-sults demonstrating the rich representational capacity of PSRs (Singh et al., 2004; Wiewiora, 2007), there is a lack of efficient algorithms for learning these represen-tations. A number of promising algorithms based on spectral learning have been proposed recently (Boots et al., 2009; Boots &amp; Gordon, 2011). These have been shown to perform well on some challenging tasks. However, they are still somewhat limited in large ob-servation spaces, since they typically consider a combi-natorial number of observation sequences. This can be avoided by assuming a functional representation of the observation space, but this requires additional knowl-edge from a human designer.
 The goal of this paper is to provide a sound agnos-tic general purpose algorithm for learning PSRs from large-dimensional batch data. The algorithm exploits a particular sparse structure that is present in many domains. This sparse structure is used to compress information using random projections, thus achieving efficient learning without requiring explicit structural information about the domain. The primary benefits of our approach are that it is algorithmically simple, it is applicable to a large variety of domains, and it provides guarantees on the fidelity of the learned com-pressed model.
 The current paper focuses exclusively on uncontrolled systems (i.e. observation-only systems, no actions), as our theoretical results pertain directly to the qual-ity of the learned model in that case. However, our algorithm is easily extended to include actions using techniques already developed for other PSR represen-tations (e.g. TPSRs). We present empirical results showing the good performance of our approach on two contrasting domains. This section outlines a number of useful technical con-cepts related to our approach. 2.1. Predictive State Representations Predictive State Representations (PSRs) (Singh et al., 2004) are designed to represent dynamical systems di-rectly with observable events. The dynamics are cap-tured through probability distributions over tests (se-quences of possible future observations, denoted  X  ) conditioned on histories (sequences of past observa-tions, denoted h ). Formally, a PSR in an uncontrolled partially observable system can be defined by four ele-ments {O ,Q, m 0 ,F } , where O is a set of observations, Q is a set of sufficient (core) tests , m 0 is a vector of prior probabilities (i.e. prediction vector conditioned on an empty history), and F is a function relating tests in Q to all possible tests.
 The primary goal of a PSR is to maintain probabilities of the form: P (  X  i | h j ) = P ( o 1 t +1 o 2 t +2 ...o for all i,j (superscripts label different observations and subscripts denote time). If we knew P (  X  i | h j )  X  i  X  j (i.e. all possible tests conditioned on all possible histories) then trivially we would have all the information nec-essary to characterize a system. Of course, obtaining estimates for all possible events (i.e. tests/histories of arbitrary length) is not feasible. This is where the set Q of sufficient tests comes into play.
 We say a set of tests Q is sufficient if and only if we can form a prediction vector of these tests p ( Q | h ) = [ P (  X  1 | h ) ,P (  X  2 | h ) ,....P (  X  | Q | , | h )] T tory and for all tests there is a projection function f  X  is sufficient if and only if all other tests can be repre-sented by some function of the tests in Q . Through-out this paper (as with much of the previous work on PSRs), we restrict our attention to linear projection functions. Thus the function f  X  can be expressed as a vector m  X  , and the expression above can be rewritten as: Once we have these projection functions, we need only maintain p ( Q | h ) for one particular history (i.e. the current history) at each time step. Thus, using time-dependent notation, we need to maintain only a single prediction vector m t = p ( Q | h ).
 We then define M o l to be a matrix with m o l  X  Q as rows, where m o l  X  m o l  X  i m t . In other words, M o l contains the projection functions for all tests that consist of the observation o appended to a core test  X  i  X  Q . Using this matrix, the prediction vector can be recursively updated after seeing observation o l by: where the normalizing factor m  X  satisfies m  X  m t = 1  X  t .
 The above update equation also reveals the full set of parameters which belong to F in our initial definition of PSR X  X . These parameters consist of the following: | O | matrices M o l of size | Q | X | Q | (one for each obser-vation) and the | Q | X  1 normalizing factor m  X  . These learned parameters, along with the prediction vector m t , provide a complete and sufficient model of a system. For any test  X  i /  X  Q , where  X  i consists of some observation sequence, for example o 1 t +1 ,o 2 t +2 ...o can compute m  X  i with: The PSR model can also be used to produce T -step predictions (i.e. the probability P ( o l t + T | h t ) of seeing an observation o l T -steps in the future) by: where M ? = P o i  X  X  M o l is a matrix that can be com-puted once and stored as a parameter for quick com-putation (Wiewiora, 2007).
 2.2. The TPSR Learning Algorithm Early results showed that a minimal PSR model of an uncontrolled partially observable system will be at least as concise as a corresponding HMM (Singh et al., 2004). However, they did not provide an efficient method for learning such a representation. Currently, the most successful learning method for PSRs, termed transformed PSRs (TPSRs), is based on spectral learn-ing algorithms (Rosencrantz et al., 2004; Boots et al., 2009). In this approach, a large set of tests is cho-sen (large enough so that it almost certainly contains a sufficient set as a subset), and empirical estimates are obtained for these tests. These estimates are then grouped into matrices, and the size of these matrices are reduced using spectral projection methods. The TPSR parameters can then be learned using regres-sion and these reduced estimates.
 Formally, one defines two observable matrices P T , H P
H , and |O| observable matrices P T ,o l , H (one for each observation). P T , H is a |T| X |H| matrix which contains the joint probabilities of all specified tests and possi-ble histories. P H is a |H| X  1 vector containing the marginal probabilities of each possible history. The P
T ,o l , H matrices are also of size |T|  X  |H| and con-tain the joint probabilities of observing each history, followed by a particular observation (corresponding to that matrix) and a test. The transpose of the thin SVD of P T , H , denoted U T , is then used to reduce the dimension of the observable matrices by left multiply-ing each observable matrix, excluding P H , by U T with some of the least significant singular vectors removed. The use of SVD also allows for the tuning of the dimen-sion of the representation by removing least significant vectors from U .
 The TPSR approach can also be extended to work with features of tests and histories (Boots et al., 2009; Boots &amp; Gordon, 2011). This is useful in cases where the observation space is too complex for standard tests to be used. When features of tests and histories are used, however, they are specified in a domain-specific manner, such as through kernel methods in continu-ous domains (Boots et al., 2009). Some authors have also used randomized Fourier methods to efficiently approximate kernel-based feature selection (Boots &amp; Gordon, 2011). These methods are quite successful in continuous domains. However, they still require domain-specific specification, and in some cases they also require an extremely large number of features in order to obtain high prediction quality (Boots &amp; Gor-don, 2011). The benefit of the algorithm presented here is that it implicitly performs general purpose fea-ture selection of tests using random compression. 2.3. Compressed Estimation Despite the fact that spectral algorithms can specify a small dimension for a transformed space, there are still a number of computational limitations. They re-quire that the |T| X |H| matrix P T , H be estimated in its entirety, and that the P T ,o l , H matrices be partially estimated as well. In many domains, such as the Poc-Man (Silver &amp; Veness, 2010) domain described below, these observable matrices can become far too large and cannot be manipulated directly. More importantly, these algorithms also require that spectral decompo-sition be performed on this large P T , H matrix, which can be prohibitively expensive. In order to circumvent these computational constraints, the CPSR algorithm we propose (in the next section) performs compressed estimation .
 This method is borrowed from the field of com-pressed sensing and works by projecting matrices down to spaces determined via randomly generated bases. More formally, a m  X  n matrix Y is compressed to a d  X  n matrix X (where d &lt; m ) by: where  X  is a d  X  m projection matrix composed of entries drawn from the gaussian distribution N (0 , 1 /d ) (Baraniuk &amp; Wakin, 2009).
 The fidelity of this technique depends only on what is called the sparsity of the matrix Y . Sparsity in this context refers to the maximum number of non-zero entries which occur in any column of Y . Formally, if we denote a column vector of Y by y i , we say that a matrix is k -sparse if: where || X || 0 denotes Donoho X  X  zero  X  X orm. X  This method of compression has a number of useful properties. It is computationally efficient, as it re-quires only the construction of the matrix X . The ma-trix multiplication above can, in fact, be avoided, and one can work in the compressed space directly. Fur-thermore, as we discuss later in the paper, the fidelity of the compression and the size of the compressed rep-resentation have only a logarithmic dependency on the original dimension ( m ), allowing for massive compres-sion in some cases.
 This compression technique is very well suited for ap-plication to PSRs. Informally, the sparsity condition is the requirement that for every history h i , only a subset of all tests have non-zero probabilities (a more formal definition appears in the theory section below). This seems realistic in many domains. For example, in the PocMan domain described below, we empirically found the average column sparsity of the matrices to be roughly 0.018% (i.e. approximately 0.018% of en-tries in a column were non-zero). Given the technical background outlined above, the compressed PSR (CPSR) algorithm is relatively straight-forward. It first constructs the random ma-trix  X . It then directly computes empirical estimates of the compressed matrices  X  P T , H and  X  P T ,o l , H from the batch of data, as well as the marginal probability of histories, P H .
 The  X   X  P T , H and  X   X  P T ,o l , H estimates are then used to construct C o l matrices for all o l  X  O , using linear re-gression. Intuitively, these C o l matrices are linear op-erators that encode, at any particular history, the joint probability of seeing that history and then the observa-tion o l . A c  X  vector is constructed in a similar manner but with  X  P H replacing the  X   X  P T ,o l , H estimates. This vector functions as a normalizer and is used to convert the joint probabilities computed with the C o l matrices to conditional ones. That is, c  X  and a C o l matrix are used together to compute the conditional probability of o l given a history. Lastly, a c 0 is constructed from the first column of  X   X  P T , H and simply defines an ini-tial probability distribution over tests. It is used as the initial prediction vector in the CPSR model of the system. The C o l matrices, the c  X  normalizer, and the initial prediction vector c 0 form a sufficient model and can be used with equations (1)-(4) to make predictions and track through a system.
 The algorithm generally assumes that data is provided in a batch. It is primarily designed to work with episodic domains where all events w i start at the same state. However, if this is not the case, one can sim-ply replace the equation 3-a of the CPSR algorithm with c  X  =  X   X  P T , H 1 d . In this situation, c  X  would no longer correspond to a start state and instead would correspond to a distribution over feasible states. Thus prediction is still possible but will be subject to greater error. This error should decrease as the model receives updates, as the updates allow the prediction vector to converge to a true model state over time. To simplify the analysis, assume that our test set is a core test set Q . Therefore, random projections are applied on  X  P Q , H and  X  P Q ,o, H matrices 1 . Define: Since Q is a core test set, the above is a TPSR repre-sentation (Boots et al., 2009; Rosencrantz et al., 2004). Assume we have enough histories in H such that ma-trices are full rank. Defining P Q ,h and P Q ,o,h to be the vectors containing the joint probabilities of all core tests and fixed history h , we have (by linearity of PSR): One can thus think of finding the B o and b  X  param-eters as regression problems, having the estimates of P
Q ,h  X  X  as noisy input features. We also have noisy observations of the outputs P Q ,o,h and P h . Since the sample set is noisy both on the input and output val-ues, direct regression in the original space might result in large estimation error. Therefore, we apply random projections to reduce the estimation error (variance) at the cost of a controlled approximation error (bias). Working in the compressed space also helps with the computation complexity of the algorithm.
 Note that there is an inherent difference between our work and the TPSR framework. In TPSR, one seeks to find concise linear transformations of the observa-tion matrices, whereas CPSR seeks to find good ap-proximations in a compressed space (which cannot be linearly transformed to the original model). The fol-lowing sections provide an analysis of the error in-duced by this compression and how the error prop-agates through the application of several compressed operators. 4.1. Error of One Step Regression There are several bounds on the excess risk of regres-sion in compressed spaces (Maillard &amp; Munos, 2009; Maillard et al., 2012; Fard et al., 2012). In this work, we assume the existence of a generic upper bound for the least squares regression. Assume we have a tar-get function f ( x ) = x T w where x is in a k -sparse D -dimensional space. We observe an i.i.d. sample set mean noise terms for which the maximum variance is bounded by  X  2  X  , and x i  X  X  are sampled from distribution  X  . Let  X  f d ( x ) be the compressed least squares solution on this sample with a random projection of size d . We assume the existence of a generic upper bound func-tion , such that with probability no less than 1  X   X  : k f ( x )  X   X  f d ( x ) k  X  ( x )  X  ( n,D,d, k w kk x k  X  ( x ) where k g ( x ) k  X  ( x ) = p E x  X   X  ( g ( x )) 2 is the weighted L norm under the sampling distribution.
 We make the following sparsity assumptions. For all h , P Q ,h and P Q ,o,h are k -sparse. Assuming that the empirical estimates of zero elements in these vectors are not noisy, for  X  x =  X  P Q ,h  X  X  Q ,h we have that  X  x k -sparse (similar argument for  X  y =  X  P Q ,o,h  X  X  Q ,o,h Finally, we assume that for all observations, B o  X  x and B o  X  y are k 0 -sparse.
 In order to simplify the analysis, in this section we define our C o matrices to be slightly different from the ones used in the described algorithm 2 . The results should only change very slightly if we use the original definitions.
 Let A i be the i th row of matrix A, and A  X  i be matrix A with i th row removed. We have the following: Theorem 1. Let H be a large collection of sampled histories according to  X  , and let  X  be a random pro-jection as described before. We observe noisy estimate  X  P of the output, where elements of  X  x and  X  y are in-dependent zero-mean random variables with maximum variance  X  2 x and  X  2 y respectively. For 1  X  i  X  d , define: Define C o to be a d  X  d matrix such that: Then with probability no less than 1  X   X  we have: where we define  X  2 o = max i,j ( X  ij ) 2 ( k X  2 y + k Proof. We have: Therefore we have a linear target and by definition u i is the COLS estimate with projection  X   X  i .
 First we analyze the effective noise variance in the sam-ple output. We have: And thus the (  X  P Q ,h ,  X  i  X  P Q ,o,h ) is the same as: Since  X  y is k -sparse and B o  X  x is k 0 -sparse, the effec-tive variance of the noise term is bounded by: Maximization over i gives the  X  2 o defined in the theo-rem and holds simultaneously for all i .
 We now apply the union bound to Equation 9: With probability no less than 1  X   X  , for all 1  X  i  X  d : Note that by our definition of C o we have that u ( X   X  i P Q ,h ) = ( C o ) i ( X  P Q ,h ), which immediately gives the theorem by combining the error bounds on each row.
 For large | Q | d , using the properties on the dis-tribution of the maximum of i.i.d. normal vari-ables, we have with high probability max i,j ( X  ij ) O ((log | Q | ) /d ) (Fisher &amp; Tippett, 1928). The norm of B o is largely problem dependent, but it is likely to be close to 1 in many cases. Assuming k 0 = k , we see that the effective variance term is a ( k log | Q | ) /d factor of the original variance. Thus, setting d = O ( k log | Q | ) should suffice to control the effective noise variance. The effectiveness of the compressed regression is largely dependent on how the L o term behaves com-pared to the norm of the target values. We refer the reader to the discussions in Maillard &amp; Munos (2009) and Maillard et al. (2012) on the k w kk x k  X  ( x ) term. If the target functions are smooth, then we expect an analysis similar to that of Fard et al. (2012) to prove that projections of size logarithmic in | Q | are enough to outperform the baseline predictor (constant output). A full discussion on such analysis is beyond the scope of this paper. 4.2. Error of The Compressed Normalizer The c  X  operator is the normalization operator for the compressed space. Therefore, for any history h , c  X   X  P Q ,h should equal P h . The following theorem provides a bound over the error of such prediction: Theorem 2. Let H be a large collection of sampled histories according to  X  . We observe noisy estimate  X  P output, where elements of  X  x and  X  z are independent zero-mean random variables with maximum variance  X  x and  X  Then with probability no less than 1  X   X  we have: where we define effective noise  X  2  X  =  X  2 z +  X  2 x Proof. Similar to Theorem 1, we have P h = b T  X  P Q ,h for all h . Therefore we have a linear target and by definition c  X  is the COLS estimate with projection  X . We have: Thus the effective variance is bounded by the  X  2  X  de-fined in the theorem. We complete the proof by an application of the bound in Equation 9. 4.3. Error Propagation Once we have the one step errors of compressed op-erators, we can analyze the propagation of errors as we concatenate the operators. Define o 1: t = o o 2 ...o t . We would like to bound the error between where c h =  X  P Q ,h . Since the theorems in the previ-ous sections were in terms of a fixed measure  X  , we have to make distributional assumptions to simplify the derivations. Assume that if we sample h from  X  , for all o , P Q ,o,h has the same distribution as P Q ,h For all t , define e h t such that C o t C o t  X  1 ... C P For a fixed t assume that k e h t k  X   X   X  t . After applying the ( t + 1)th compressed operator we have: Line 20 uses the distribution assumption discussed above. We can see that there is an additive error after each compressed operator, and also a multiplicative part that amplifies the error of the previous steps. As-suming that  X  is the bound of Theorem 2, one can apply a similar analysis to the compressed normaliza-tion operator to obtain an additive error of  X  and the amplification of the previous error by k c  X  k . We finish the analysis by assuming that the norm of all C o terms and the c  X  term is bounded by c , and that all t and the  X  term are bounded by . The total propagated error is thus bounded by ( c T  X  1) / ( c  X  1). To complete our analysis, we consider the empirical performance of the CPSR algorithm on two synthetic domains, called GridWorld and PocMan . Both do-mains were originally defined as POMDPs; we consider here the non-controllable version (i.e. only observa-tions). The goal therefore is to learn a good predictive representation of the domains, rather than attempt to plan using these representations. Throughout our experiments, the agents were given fixed exploration policies, and only the sequences of observations were recorded. The CPSR algorithm was then used to con-struct models, which produce probability distributions over observation sequences. 5.1. GridWorld The GridWorld domain is a 5  X  12 grid maze (see Figure 1) where the agent must navigate towards a goal state. The primary difficulty in this domain is that the agent receives aliased observations, designat-ing whether or not there is an adjacent wall in any of the four cardinal directions. The domain also has the added complication that state-to-state transitions are stochastic (0.2 transition noise probability). The primary purpose of this experiment is to illustrate the computational efficacy of the CPSR method compared to an uncompressed naive TPSR approach.
 Method and Evaluation: In all trials, the learning algorithm was given a sample of 1000 training runs to learn a model representation of the domain. We compare the model accuracy and algorithm runtime for building TPSR and CPSR models. In both the CPSR and TPSR cases, tests of length at most four were used and the final model dimension was set to 30. The quality of the models were evaluated according to their T -step prediction performance. That is, each model was asked to produce probability distributions for the terminal observation at each time step (up to the history bound). In other words, the models pro-duced must predict what observation would occur at each time-step (up to some bound) using only the ini-tial PSR state (i.e. without performing any updates). In all models, these predictions were computed using equation (3) and the prediction performance was eval-uated on 10 test sets. The model predictions  X  P ( o j k were then compared to Monte-Carlo rollout predic-tions  X  P ( o j k | h 0 ) (produced using knowledge of the un-derlying state dynamics) according to the prediction error k  X  P ( o j k | h 0 )  X   X  P ( o j k | h 0 ) k 2 . Results: As shown in Figure 2, the CPSR algorithm was able to produce competitive predictions, compared to the TPSR algorithm, showing that the compression does not have detrimental effects on model quality. Moreover, as shown in Figure 3, performing the es-timation in the compressed space greatly reduced the runtime of the algorithm. 5.2. PocMan The PocMan domain is a partially observable variant of the popular video game Pac-Man (Silver &amp; Veness, 2010). Like in the video game, the goal here is to col-lect randomly distributed food pellets while navigat-ing in a 17  X  19 maze and avoiding coming in contact with any of four ghosts. Unlike the video game, how-ever, the agent does not have knowledge of the full environment state and only has access to a set of lo-cal observations. This domain is especially interesting as its large state space ( | S |  X  10 56 ) and observation space ( |O| = 2 10 ) make it intractable for conventional EM style algorithms (Silver &amp; Veness, 2010). Exper-imentation in this domain illustrates how the CPSR method is able to produce higher quality models due to the fact that it performs estimation in the compressed space and can, therefore, include more information in its estimates.
 Method and Evaluation: The algorithms were once again given 1000 trials to learn a model repre-sentation. However, due to the extremely large obser-vation space, the CPSR method is able to include more information in its empirical estimates. Specifically, the CPSR algorithm is able to include tests of all lengths in its estimates, whereas the TPSR algorithm is only able to include tests of length 1 while not exceeding memory limits (8 GB in this case).
 We compared quality of models produced by a CPSR with all tests and a TPSR with tests of length 1. Again, the T -step prediction error was used as a mea-sure of quality.
 Results: As shown in Figure 4, the CPSR algorithm was able to learn a more accurate model due to its abil-ity to include longer tests. This effect will be strongest in domains, such as PocMan , that are strongly par-tially observable and that have very large observation spaces. Of course, a domain specific feature mapping technique could be used to reduce to memory load for the TPSR algorithm. However, such a feature map-ping would not be general and would require expert construction. The benefit of the CPSR approach is that the random projections are agnostic with respect to the domains characteristics.
 In this experiment, we did not directly compare em-pirical runtimes, since the algorithms did not use the same tests. However, for simplicity, we set the com-pressed dimension of the CPSR model to be equal to the number of tests, |T| , used by the TPSR algorithm. We also set this as our final model dimension (the av-erage final dimension was 140). Thus, by design, the runtime for the algorithms is asymptotically equal at O ( |O|| H || T | 2 ) and they use comparable resources. The CPSR algorithm provides a memory efficient tech-nique for learning compressed representations of dy-namic domains with large observation spaces using batch data. It provides theoretical guarantees for the fidelity of the compression and shows good empiri-cal performance. One particular advantage is that it relieves researchers of the burden of determining an appropriate compact representation. Selecting a compact latent state representation, in the case of HMMs/POMDPs, is a difficult problem; some recent work shows promise, but is much more expensive com-putationally than the methods we present here (Veness et al., 2011). Similarly, selecting a compact set of tests to use when learning PSR representations is a difficult issue, and currently, there are no principled approaches beyond enumerating observed tests with fixed bounds on test length, and applying spectral methods to re-duce the dimension. The benefit of the CPSR algo-rithm is that a much greater number of possible tests can be considered without affecting the space complex-ity of the learning process.
 It is worth noting that the CPSR algorithm does not reduce the dimension of histories. There is a trade-off here: we can reduce either the dimension of tests, or of histories; reducing both would likely alter the spar-sity of the matrices. Reducing the dimension of tests is probably preferable since in general, the space of all possible tests is greater than, or equal to, the space of all histories (in any domain with a defined start state it will be combinatorially larger) (Singh et al., 2004). Moreover, a number of methods already exist to reduce the memory burden induced by the number of histo-ries, such as the improved batch algorithm (Boots &amp; Gordon, 2011), and the use of large set sizes in in-dicative events (which are the sets of histories used in the estimation). Most importantly for CPSRs, the matrices representing the learned parameters are all of size d  X  d , where d is the reduced dimension of tests ( d = |T| if no compression is performed).
 Throughout this paper, we described the CPSR algo-rithm in the uncontrolled case (i.e. only observations, no actions) primarily for simplicity of exposure. It is worth noting that the CPSR approach is fully compat-ible with work on planning using TPSRs (Boots et al., 2009; Boots &amp; Gordon, 2011). One simply substitutes the CPSR states for the corresponding TPSR states. This is useful as planning algorithms can be developed independently of the type of PSR approach being used. In conclusion, the CPSR algorithm provides a novel lightweight algorithm for efficiently learning models of dynamic systems in large discrete observation spaces. We have used it to learn an effective representation in the PocMan domain, which has on the order of 10 56 states and 2 10 observations. We believe that the type of sparsity required for CPSR is present in a large num-ber of dynamic systems. We are now considering ex-tensions of the algorithm for continuous spaces. Acknowledgements The authors would like to thank Doina Precup, Yuri Grinberg and Sylvie Ong for helpful discussions on this work, and Joel Veness and David Silver for support on the PocMan domain. Financial support for this research was provided by the NSERC Discovery grant and USRA programs.
 Baraniuk, R. and Wakin, M. Random projections of smooth manifolds. Foundations of Computational Mathematics , 9:51 X 77, 2009.
 Boots, B. and Gordon, G. An online spectral learn-ing algorithm for partially observable dynamical sys-tems. In Association for the Advancement of Artifi-cial Intelligence , 2011.
 Boots, B., Siddiqi, S., and Gordon, G. Closing the learning-planning loop with predictive state repre-sentations. In Proceedings of Robotics: Science and Systems VI , 2009.
 Fard, M.M., Grinberg, Y., Pineau, J., and Precup,
D. Compressed least-squares regression on sparse spaces. In Association for the Advancement of Ar-tificial Intelligence , 2012.
 Fisher, R.A. and Tippett, L.H.C. Limiting forms of the frequency distribution of the largest or smallest member of a sample. In Mathematical Proceedings of the Cambridge Philosophical Society , volume 24. Cambridge Univ Press, 1928.
 Hsu, D., Kakade, S., and Zhang, T. A spectral algo-rithm for learning hidden markov models. In Con-ference on Learning Theory , 2008.
 Kaelbling, L., Littman, M., and Cassandra, A. Plan-ning and acting in partially observable stochastic domains. Artificial Intelligence , 101:99 X 134, 1998. Maillard, O.A. and Munos, R. Compressed least-squares regression. In Advances in Neural Informa-tion Processing Systems , 2009.
 Maillard, O.A., Munos, R., et al. Linear regres-sion with random projections. Journal of Machine Learning Research , 2012.
 Rabiner, Lawrence R. A tutorial on hidden markov models and selected applications in speech recogni-tion. In Waibel, Alex and Lee, Kai-Fu (eds.), Read-ings in speech recognition , pp. 267 X 296. 1990. Rosencrantz, M., Gordon, G., and Thrun, S. Learning low dimensional predictive representations. In Pro-ceedings of the twenty-first International Conference on Machine learning , 2004.
 Silver, D. and Veness, J. Monte-carlo planning in large pomdps. In Advances in Neural Information Pro-cessing Systems , 2010.
 Singh, S., James, M.., and Rudary, M. Predictive state representations: a new theory for modeling dynam-ical systems. In Proceedings of the 20th Conference on Uncertainty in Artificial Intelligence , 2004. Veness, J., Ng, K.S., Hutter, M., Uther, W., and Sil-ver, D. A monte-carlo AIXI approximation. Journal of Artificial Intelligence Research , 40, 2011. Wiewiora, E. Modeling probability distributions with predictive state representations . PhD thesis, Uni-
