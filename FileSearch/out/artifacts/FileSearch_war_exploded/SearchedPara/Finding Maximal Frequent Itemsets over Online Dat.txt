 very important to confine the memory usage of a data mining process regardless of the amount of information generated in the data stream. For this purpose, this paper proposes a CP-tree ( Compressed-prefix tree ) that can be effectively used in finding either frequent or maximal frequent itemsets over an online data stream. Unlike a prefix tree, a node of a CP-tree can maintain the information of several item-sets together. Based on this characteristic, the size of a CP-tree can be flexibly controlled by merging or splitt-ing nodes. In this paper, a mining method employing a CP-tree is proposed and an adaptive memory utiliza-tion scheme is also presented in order to maximize the mining accuracy of the proposed method for confined memory space at all times. Finally, the performance of the proposed method is analyzed by a series of experi-ments to identify its various characteristics. nology, the amount of information has been increasing faster than ever in various domains. Furthermore, depending on the characteristics of an application domain, its information is produced in diverse forms. A data stream is one of such forms and is a massive unbounded sequence of data elements continuously generated at a rapid rate. Due to this reason, it is impossible to maintain all the elements of a data stream. Consequently, on-line data stream processing should satisfy the following requirements [6]. First, each data element should be examined at most once to analyze a data stream. Second, memory usage for data stream analysis should be restricted finitely although new data elements are continuously generated in a data stream. Third, newly generated data elements should be pro-cessed as fast as possible to produce the up-to-date analysis result of a data stream, so that it can be instantly utilized upon request. To satisfy these requirements, data stream processing sacrifices the correctness of its analysis result by allowing some error.
 proposed to extract different types of knowledge em-bedded in a data stream. The sticky sampling method [11], the Lossy Counting algorithm [11] and the estDec method [4] focus on finding frequent itemsets over a data stream. In the Lossy Counting algorithm, to reduce the memory usage of a mining process, the counts of frequent itemsets can be kept in a secondary storage and only a buffer for the batch-processing of transactions is kept in main memory. As the buffer is enlarged, more number of newly generated transac-tions can be batch-processed together, so that the algorithm is more efficiently processed. When the number of frequent itemsets is large, accessing the information of frequent itemsets in a secondary disk needs more time. Due to this reason, this algorithm is not appropriate for an online data stream. estDec method [4] to minimize the number of itemsets to be monitored. In this method, an itemset whose support is greater than a predefined significant support S sig ( S sig  X  S min ) is regarded as a significant itemset where S min is a given minimum support. Each significant item-set in a data stream is represented by an individual node of a prefix tree. Consequently, the resulting set of frequent itemsets in a data stream can be found instantly at any moment. As the number of significant itemsets in a data stream is increased, the size of the prefix tree that represents these itemsets become larger. Consequently, the memory usage of the prefix tree is also increased. Once the size of a prefix tree becomes larger than the size of available memory space, no new significant itemset can be inserted to the prefix tree, so that the estDec method will not work properly any longer. memory usage of finding frequent itemsets in an incre-mentally enlarged data set. Unlike a prefix tree, a node of an itemset tree maintains the subset of items in an individual transaction. Given an itemset tree for a set of transactions, if there exists a node representing any subset of items in a newly added transaction T , the node is shared to represent the subset of the items in T . Only a node corresponding to the remaining items of T is newly inserted into the itemset tree. By sharing the common subsets of transactions in a data set, it is possible to reduce the required size of memory space. Consequently, the size of an itemset tree is smaller than that of a prefix tree for the same data set. However, like a prefix tree, an itemset tree has no mechanism to manipulate its size adaptively to confined memory space. structures, this paper proposes a CP-tree ( Compress-ed-Prefix tree ) to replace the role of a prefix tree in the estDec method. In addition, this paper also introduces the extended version of the estDec method, namely estDec + for a CP-tree. Unlike a prefix tree, two or more nodes of a prefix tree can be merged into a single node of a CP-tree as long as the support difference of their corresponding itemsets is within a predefined threshold called a merging gap threshold  X   X  (0,1). In such a node of a CP-tree, only the counts of two representative itemsets are maintained while those of the remaining itemsets are estimated based on the counts of the representative itemsets. By adaptively controlling the value of  X  , the number of nodes in a CP-tree can be changed. As the value of  X  is increased, more significant itemsets can be represented by a single node of a CP-tree. Consequently, the size of the CP-tree is reduced while the mining result of the estDec + method becomes less accurate. However, since the size of a CP-tree can be flexibly controlled by merging or splitting nodes, the estDec + method can fully utilize confined memory space at all times. This capability is valuable when the number of significant itemsets is fluctuated heavily. Section 2 reviews the estDec method. Section 3 pro-poses the structure and operations of a CP-tree in detail. Section 4 introduces the estDec + method which employs a CP-tree to find frequent or maximal fre-quent itemsets over an on-line data stream. In Section 5, the performance of the estDec + method is evaluated by a series of experiments. Finally, Section 6 concludes this paper. data stream one by one without any candidate generation and keeps track of the occurrence count of an itemset in the transactions generated so far by a monitoring tree whose structure is a prefix tree [1,3]. Given the current data stream D k , a prefix tree P the following characteristics: ii) Given a node n having an item i n  X  I in a prefix tree delayed-insertion and pruning operations. Monitoring the count of a new itemset is started only in the following two cases. The first case is when a new 1-itemset appears in a newly generated transaction T k . In this case, monitoring its count is instantly started by inserting it to the monitoring tree P k without any estimation. The second case is when an insignificant itemset just becomes a significant one due to its appearance of T k . Since it becomes an significant itemset, it should be inserted into P k for further monitoring. To find such an n -itemset e ( n  X  2), only when all of its ( n  X  1)-subsets are currently maintained in P k , the current support of the itemset e is estimated by those of its ( n  X  1)-subsets. If the estimated support is greater than a predefined insertion support S ins itemset e is inserted. Since the total number of the ( n  X  1)-subsets is n , let { c 1 , c 2 , ..., c n current counts of the ( n  X  1)-subsets monitored in P The estimated current count ) (  X  e C k of the itemset e is obtained by the largest one i.e. ) (  X  e C k = max ( c The upper bound of the estimation error for e is The above procedure is a delayed-insertion operation. The upper bound of this estimation error is proven to be ignorable when k becomes infinite [4]. In this paper, estimating the current count of such an insignificant itemset is called as inserting-count estimation .
 when the current support of an itemset maintained by P becomes less than a predefined pruning support S prn . The itemset is regarded as an insignificant itemset that cannot be a frequent itemset in the near future. Upon identifying such an itemset, the node representing such an itemset and all of its descendent nodes are pruned from P k based on the anti-monotonicity of a frequent itemset [4]. Since P k is located in main memory, its size should be kept smaller than the confined space of main memory at all times. However, its size totally depends on the density of significant itemsets in the current data stream D k with respect to S sig . Therefore, once the size of a prefix tree exceeds to the size of the confined memory space, it is impossible to monitor any new significant itemset by the delayed-insertion operation. Due to this reason, the mining accuracy of the estDec method can be degraded without any upper bound in this situation. represented by the prefix tree needs to be compressed. Two consecutive nodes by a prefix tree are merged in a CP-tree when the current support difference between their corresponding itemsets is less than or equal to a merging gap threshold  X   X  (0,1). Ultimately, a subtree of a prefix tree can be compressed into a node of a CP-tree.
 Definition 1. A mergeable subtree Suppose P k be a prefix tree and S be a subtree of P Let e v denote the itemset represented by the root of S and e j denote an itemset represented by a node of S . A leaf node of S is not necessarily to be a leaf node of P Given a merging gap threshold  X  , if all the nodes of the subtree S satisfy the following condition, the subtree S is a mergeable subtree and compressed into a node of a CP-tree Q k that is equivalent to P k . where | S | denotes the number of nodes in S .  X  The detailed structure of a node in a CP-tree is defined in Definition 2. Definition 2. CP-node structure Given a mergeable subtree S of a prefix tree P let a CP-tree Q k be equivalent to P k . To represent the following four entries m ( IJ ,  X  , c S , c L ) as follows: i) item-list IJ : The items of the nodes in each level of ii) parent-index list  X  :  X  maintains an entry of a form iii) largest count c L : the current count of the shortest iv) smallest count c S : if | S |=1, c S = c L . Otherwise, the CP-tree Q k . The subtree formed by the nodes n 1 and n 3 of P k are compressed into the node m ( IJ =&lt; a , b , c &gt;,  X  =&lt; m 0 .1, m 1 .1, m 1 .1&gt;, c is because the current support difference between the root node n 1 of the subtree and each of its child nodes n and n 3 is less than  X  . The root of the subtree represented by m 1 is IJ [1]= a which is corresponding to the node n 1 of P k . Its parent node  X  [1]= m 0 .1 is the node m of the CP-tree Q k . The fact that the node n parent of the node n 2 in P k can be inferred by m 1 and m 1 .  X  [2]= m 1 .1 which imply that the parent of the item b is m 1 . IJ [1] i.e. a . The shortest and longest itemsets of m 1 are a and ac respectively. CP-tree, let (1  X  j  X  n ). By the two counters c S and c L of the node, it is possible to trace the current supports of at most two itemsets i.e. the shortest and longest itemsets e as precisely as the estDec method does. Therefore, if more than three itemsets are compressed into a single node, the current counts of the remaining itemsets can be estimated by a formula where f ( m , j ) denotes a count estimation function that can model the count ) ( and c S of the shortest and longest itemsets e S and e function meaningful in an application domain can be employed to define the function f ( m , j ).
 defined in Section 2, the above estimation is called as merged-count estimation . When the current count of an itemset traced by a node of a CP-tree is estimated by the above mechanism, there must be an error count but the possible range of this error count is totally influenced by the value of  X  . threshold  X  , let Q k -1 denote a CP-tree at a data stream D k -1 . As in the estDec method, when a new transaction T is generated, those paths of Q k -1 that are induced by the items of T k are traversed respectively and the counts of all the nodes in the paths are updated. Traversing a CP-tree is virtually the same as traversing a prefix tree in [4]. The items of T k are lexicographical-ly ordered and matched with Q k  X  1 by a depth-first manner as in a prefix tree. Among the items in the an item i whose item-list index j does not appear in the where m . IJ [ j ]= i .
 its parent node and i p denote the last matched leaf-level compared with those remaining items of T k that are not yet matched. If the above condition is not met or the item m . IJ [1] is not matched, the search is terminated and return to the parent node of the node m . If m . IJ [1] is matched, the largest count c L of the node m is incremented by one. Let the item m . IJ [1] be the first common item ci 1 in the item-list m . IJ and the remaining items of T k . Among the remaining items of T k those items that are after the item ci 1 are considered to be matched further. Subsequently, find the second common item ci 2 in both the remaining items of IJ and those items in T k that are considered to be matched. Let the item-list indexes of the common items ci 1 and ci be j 1 and j 2 . Only when the parent of ci 2 is ci m .  X  [ j 2 ]= m . j 1 , let ci 2 be a new ci 1 and find a new ci the same manner until there is no such ci 2 in m . IJ . If the above recursive search in the node m is terminated by reaching one of the leaf-level items of the node m , the child nodes of the node m are searched continuously. When the last ci 2 item is not an leaf-level item, the next common item in the remaining items of the two lists is searched by the same way. This procedure is recursive-ly repeated until there is no item to be matched in either of the lists. Furthermore, only when the last item IJ [| IJ |] is matched as a leaf-level item, the smallest count m . c S is also increased. If none of the leaf-level items are matched, the search is terminated and returned to the parent of the node m . The traversing algorithm is presented in Section 4. operations: node-merge and node-split can be per-formed additionally. Let m denote the parent node of m . A node-merge operation is only invoked in the following two cases. One is when the current support difference between the shortest itemset of m and the longest itemset of the node m becomes less than or pens only when the difference between the two counts remains the same and only | D | k is increased. The other one is when a new significant itemset e is identified by the inserting-count estimation process, so that a new node for the itemset needs to be inserted as a child of the node m . If the current support difference of the estimated support of the new significant itemset and the largest itemset of the node m is less than or equal to  X  , the new node is merged into the node m . The detailed steps of a node-merging operation are described in Figure 2. On the other hand, a node m of a CP-tree is split into two different nodes when the support differ-ence between its shortest and longest itemsets becomes greater than  X  , i.e., ( m.c L  X  m.c &gt;  X  . The difference is enlarged when only m . c increased. When a node is split, each of the leaf-level items of the node m . IJ is separated as an individual node of a CP-tree. The detailed steps of a node-split operation are described in Figure 3. estDec method is proposed. The proposed method is basically based on the estDec method but the underly-ing memory structure of significant itemsets is changed from a prefix tree to a CP-tree. a data stream is differentiated over time by a decay mechanism [4], so that it can find recently frequent itemsets over the data stream [4]. To concentrate on developing a mining method based on a CP-tree over a data stream, this paper does not mention about the decay mechanism precisely. However, the same decay mechanism applied to a prefix tree in the estDec method can also be employed to a CP-tree in the estDec + method. Furthermore, the estDec+ method employs delayed-insertion and pruning operations to trace the current supports of only significant itemsets. However, the two thresholds: an insertion support S and a pruning support S prn used in the estDec method are denoted by a significant support S sig  X  (0, S this paper. In other words, delayed-insertion and pruning operations in the estDec + method are per-formed with respect to S sig .
 is allowed to be merged, an infrequent but significant quent itemsets. This can cause false positive or false negative errors in the course of merged-count estima-tion. To reduce these types of error, a node whose current support is less than a predefined threshold called a merging threshold S merge (  X  S min ) is not con-sidered as a candidate for a node-merge operation. Since a node of a CP-tree can represent multiple itemsets together, the current supports of all the itemsets induced by a node are estimated to find any maximal frequent itemset in the node. As the gap between S merge and S min is enlarged, the possibility that a node representing a maximal frequent itemset is not merged with any other node becomes high. Conse-quently, the counts of all the maximal frequent itemsets hardly include any estimation error caused by the merged-count estimation. consists of four phases: parameter updating, node restructuring, itemset insertion, and frequent itemset selection. When a new transaction T k in a data stream D k -1 is generated, these phases except the frequent itemset selection phase are performed in sequence. The frequent itemset selection phase is performed only when the up-to-date result set of frequent or maximal frequent itemsets is requested. Parameter updating phase: The total number of transactions in the current data stream D k is updated. Count updating &amp; node restructuring phase: This phase is performed by traversing Q k  X  1 according to the lexicographic order of the items in T k . For each visited node m , its smallest and largest counts m . c S and m . c may be incremented as described in Section 3.3. If the updated support of the shortest itemset m . e S becomes descendent nodes are pruned since all the itemsets represented by these nodes are turned out to be in-significant. If the updated support of the longest itemset m . e L is less than S merge or the support difference between the itemsets m . e S and m . e L becomes greater than  X  i.e. m . c S /| D | k &lt; S merge or ( m . c L node m is split. On the other hand, if the updated support of m . e L is greater than S merge and the support difference between m . e S and and m * . e L of its parent node m * is less than or equal to  X  i.e. m . c and ( m * . c L  X  m . c S )/| D | k  X   X  , these two nodes m and m merged. Itemset insertion phase : The itemset insertion phase is performed to insert any new significant itemset which has not been maintained in Q k  X  1 . As in the estDec method, every single item should be maintained by Q k  X  1 . Consequently, when T k contains any new item that is not in Q k  X  1 yet, a new node m for the item i  X  T is inserted as follows: Subsequently, any insignificant item whose current support is less than S sig is filtered out in the transaction T . Let the filtered transaction be denoted by k T . The monitoring tree Q k  X  1 is traversed for the filtered transaction k T once again to find out any new signifi-cant itemset induced by the items in k T . By the same way as in the estDec method, for each significant n -itemset e = i 1 i 2 ... i n ( n t 1) represented by a node m of Q every ( n+ 1)-itemset e which is k n T i e  X   X  1 examined. First of all, check whether all of its n -subsets of the itemset e are currently maintained in Q k  X  1 . If the above condition is satisfied, the current support of the itemset e is estimated as ) ( described in Section 2. If sig S e C t ) (  X  , a new node w corresponding to the itemset e is inserted to Q detailed description of this estimation process is presented in [4]. The entries of the new node w are initiated as follows: where q denotes the item-list index of the item i n in the node m .
 Maximal frequent itemset selection phase: This phase retrieves all the currently frequent or maximal frequent itemsets by traversing the monitoring tree Q k . As in the estDec method, all the nodes whose largest counts c L are less than | D | k * S sig can be pruned al-together by traversing the entire monitoring tree. It is called a force-pruning operation, and can be performed periodically. more likely to be changed over time, the number of currently significant itemsets is continuously varied. However, the size of memory space for a CP-tree is confined. In order to minimize the estimation error caused by the merged-count estimatioin, it is very important to keep the value of  X  as small as possible. The size of a CP-tree is inversely proportional to the value of  X  . In order to adaptively control the memory utilization of the estDec + method, the value of  X  should be dynamically changed in the parameter update phase of the estDec + method. over given confined memory space, the value of  X  is dynamically changed in the parameter updating phase of the estDec+ method. Let M U and M L denote the upper and lower bounds of desired memory usage respectively for given confined memory space M A . Whenever the current memory usage M C satisfies the following conditions, the new value  X  new of a merging gap threshold is adjusted adaptively as follows: where D denotes the step-wise increment of  X  for each adaptation and is defined by a user. As the values M
A  X  M U and M U  X  M L become larger, the value of  X  can also be larger. As long as the current memory usage M C of a CP-tree becomes greater than the upper bound M
U , the value of  X  is increased. As a result, more nodes can be merged and the size of the CP-tree is reduced. On the other hand, when M C becomes less than the lower bound M L , the value of  X  is decreased to enhance the mining accuracy of the CP-tree, so that the size of the CP-tree is increased. By setting the lower bound M high enough, the memory utilization of the estDec + method is kept high. On the other hand, by setting the upper bound M U low enough, the estDec + method can be executed without causing any memory overflow. method is analyzed by two data sets: T10.I4.D1000K and WebLog . The data set T10.I4.D1000K is generated by the same method as described in [2]. The data set WebLog is a real web-page access log data. The con-secutive web-pages accessed by a user are considered as a semantically atomic unit of activities, i.e., a transaction. The total number of items, i.e., the number of web-pages, is 545. The minimum, maximum, and average lengths of a transaction in the data set WebLog are 2, 30, and 5 respectively. In addition, the total number of transactions is 500,000. In all experiments, the transactions of a data set are looked up one by one in sequence to simulate the environment of an online data stream and a force-pruning operation is performed in every 1000 transactions. In addition, the value of S min is set to 0.001 and the count estimation function f ( m , j ) is defined as follows: All experiments are performed on a 1.8 GHz Pentium PC machine with 512MB main memory running on Linux 7.3 and all programs are implemented in C. method on the data set T10.I4.D1000K by varying  X  . The memory usage of the estDec + method is illustrated in Figure 5-(a) after the memory usage is stablized. To measure the accuracy of the estDec + method, a term average support error ASE ( R 2 | R 1 ) [4] is employed. As the value of ASE ( R 2 | R 1 ) gets smaller, the mining result R is more similar to R 1 . In Figure 5-(a), the memory usage of the estDec + method gets smaller as the value of  X  gets larger since more nodes are merged. The than the ASE ( R estDec+ |R Apriori ) in Figure 5-(b) since most of maximal frequent itemsets are more accurately monitored without merged-count estimation. As the value of S merge is set to be smaller for the same value of  X  , the ASE is increased but the memory usage is decreased. This is because more nodes are merged as the value of  X  is increased or the value of S decreased. Figure 5-(d) and 5-(e) shows that estDec + method is order-independent. For this experiment, T10.I4.D1000K_R is generated with the reversely ordered transactions of T10.I4.D1000K while T10.I4. D1000K_C is generated with two consecutive datasets, i.e., one with the transactions having odd number TID and the other with the transactions having even number TID . The value of S merge is set to 0.003. is closely compared with that of the estDec method on the data set T10.I4.D1000K . In this experiment, the value of  X  is fixed. For the same value of S memory usage of the estDec + method is always less than that of the estDec method. Figure 6-(b) shows the memory requirement of the estDec + method. The requirement is represented by the ratio of the size of memory space required by the estDec + method over that required by the estDec method to execute the same dataset. By varying the value of S sig , Figure 6-(c) and Figure 6-(d) illustrate the mining accuracy of finding frequent and maximal frequent itemsets respectively. When the value of S merge gets higher, the ASE of the estDec + method becomes closer to that of the estDec method since less nodes corresponding to maximal frequent itemsets are merged. In Figure 6-(e), the average processing time per transaction is compared. It is inversely proportional to the memory usage. This is mainly because the processing time to interpret the information of the itemsets in a node of a CP-tree becomes longer as either the value of  X  is larger or the value of S merge is smaller. likely to be changed over time [5]. Figure 7 shows how the estDec + method can adaptively maximize the utilization of confined memory space. In this experi-ment, the data set WebLog is used. The values of S min S sig , and S merge are set to 0.003, 0.1 u S min , and 0.003 respectively. Furthermore, the values of M U , M L , and M A are set to 95MB, 85MB, and 100MB respectively. The initial value of  X  is set to 0 and two different values of a user-defined increment  X  are used. The estDec method fails to be executed after the 1 u 10 transaction. This is because the size of its prefix tree becomes larger than that of the confined memory space. On the other hand, there is no problem to execute the estDec + method by adjusting the value of  X  adaptively for the same situation. Figure 7-(a) illustrates the trace of the value of  X  in this experiment. As shown in Figure 7-(b), the memory usage of the estDec + method is kept between M U and M L at all times. As expected, the value of  X  is more widely fluctuated for the larger value of  X  . Figure 7-(c) shows the ASE s of the the estDec + method in finding frequent and maximal frequent itemsets. The ASE of finding frequent itemsets is much higher than that of finding maximal frequent itemsets. For a given value of S min , the total number of frequent itemsets can be varied continuously over time without any upper bound. On the other hand, the up-to-date mining result of an on-line data stream should be traced in real-time and available at any moment. For this reason, the current counts of all the significant itemsets are kept in main memory by the estDec method. However, it is impossible to guarantee all of them to be maintained in confined memory space at all times. To cope with this problem, a CP-tree is proposed in this paper. Although the proposed estDec + method can be used to find either frequent itemsets or maximal frequent itemsets, it provides better accuracy for finding maximal frequent itemsets as illustrated in the experiments. By making the value of a merging threshold S merge large enough, the estDec + method can find the set of maximal frequent itemsets as accurately as the estDec method can do while the memory usage can be minimized. Although the average processing time of the estDec + method is slightly increased, the proposed method successfully provides a way to accommodate the unpredictable number of significant itemsets generated in the future of a data stream not in a secondary storage but in confined memory space. 
