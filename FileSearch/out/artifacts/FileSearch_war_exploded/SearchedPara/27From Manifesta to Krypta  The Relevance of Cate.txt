 RINO FALCONE, MICHELE PIUNTI, MATTEO VENANZI, and CRISTIANO CASTELFRANCHI , ISTC-CNR Starting from the artificial intelligence field, in particular from the multiagent systems (MAS) domain, the study of social phenomena like trust, delegation, and adoption ,is now increasing interest in the more general field of Information and Communication Technologies (ICT). The two main concepts behind this interest are: the autonomy that the new computational entities are developing in a very sophisticated way, and the most recent evolution of the interaction paradigm in computation. Pushing these two concepts of autonomy and interaction to their logical conclusions, we will have entities pursuing their own goals interacting with others that are at the same way pursuing their goals. In these situations, the primary need for an agent taking part in an intelligent interaction is to assess the trustworthiness of the interacting parts. In addition, we are going towards an interaction scenario in which artificial entities and humans are indistinguishable from each other. In this view, the probability that we have to interact or cooperate with entities we do not have any personal experience with will be growing, and the capacity of inferring how trustworthy an agent is will become a very relevant property of these systems. Many different approaches and models of trust were developed in the last 15 years [Marsh 1994; Jonker and Treur 1999; Barber and Kim 2001; Resnick and Zeckhauser 2002; Yu and Singh 2003; Sabater 2003; Huynh et al. 2006; Hang et al. 2009; Ziegler 2009]: they contributed to clarify many aspects and problems about trust and trustworthiness, although many issues still remain to be addressed. The main issue is to understand how trust really works, that is: which are its main sources and basis; how an entity can be considered trustworthy; how the social action of an artificial entity is mediated (in the case of a cognitive agent) by its mental ingredients of trust.

One of the main problems is to analyze the bases of trust: what are the reasons why an agent X has to trust an agent Y? We identify different kinds of trust and the nature of the basis for trusting other agents:  X  Direct experience (how Y performed in the past interactions with X);  X  Recommendations [Yolum and Singh 2003] (other individuals Z reporting their direct experience and evaluation about Y) or Reputation (the shared general opinion of others about Y);  X  Inferences/Reasoning (judgment about Y deriving from a rational reasoning of X not involving direct experience with, recommendation of, or reputation about the individual agent Y).
 In this article we propose a model inspired by the latter approach, focusing in partic-ular on a reasoning model based on an internal representation of general classes or categories of agents. Categories are defined on the basis of a set of specific constraints in which another yet unknown agent can be inserted. Assuming that an agent can be included in a class or category permits on the one side to  X  X eneralize X  from individuals to categories, to form general correlations and evaluations, and, on the other side, to transfer,  X  X nstantiate X , the attributes and features of that class to a given yet unknown agent. In other words, if there is a way to consider an unknown agent as belonging to a known category (for example, there are some signals of that agent reporting/referring an agent X  X  role, profession, but also an agent X  X  attitude, stable disposition, and so on), we can infer (or at least attribute) specific internal features (i.e., not directly observ-able) that would not be otherwise perceptible for such unknown agent. We are also considering the fact that there is a strict correlation between agent internal features and agent performances. This does not mean that every agent in the same category will perform exactly in the same way, but, in general, all the agents of the same cate-gory/class should ensure a good level of performance about the tasks referred to that category. In this sense we can recall the notions of  X  X rypta and manifesta X  introduced by Bacharach and Gambetta [2001], where the so-called manifesta of the agents are the signals of their krypta, a sort of internal properties ( X  X ualities X ,  X  X irtues X ,  X  X owers X ) able to predict/explain the agents X  behaviors on specific tasks, domains, and interac-tions. These notions do not pertain only to an individual agent: manifesta can be also signs of membership, and thus of qualities that in/for that class of agents those sig-nals mean. In fact, for trusting an agent we need to have a theory of its mind (in case of cognitive agent) or of its functioning (in case of a more simple tool, artifact, etc.) [Castelfranchi and Falcone 2010]. To do that, we need to identify a set of agent X  X  internal features in order to describe how that agent will perform a task in specific sit-uations. These internal features can be learned by direct experience, but also inferred by the class to which that agent belongs. A careful characterization of these categories and of their relevant features (in particular with respect to the classes of tasks) can lead to predict the performances for agents belonging to a given class when performing a certain task. This is true not only for tasks associated to their class (as generally happens), but also in the case in which agents perform a task relative to a different category. In practice, we have to understand: how can a trustor know if another agent is, for example, a baker, a surgeon, or a dentist? Which are the signs (the manifesta) of different categories? How does a category define the properties of individuals belonging to them (i.e., their krypta) ? And again: how is a dentist supposed to fulfill a surgeon X  X  task? And will a dentist do better or worse than a baker on that specific task?
This category-based analysis for trust is one of the more diffuse ways in which humans rely on and trust other unknown agents in daily life: we know how to rely on the waiter in a restaurant as waiter, on the driver of the bus as bus driver, on the policeman in the street of a stranger town as policeman, and so on. In this article we start from the analysis and results of the socio-cognitive model of trust [Castelfranchi and Falcone 1998, 2010; Falcone and Castelfranchi 2002]. We extend this model applying it to MAS where agents are able to exploit the knowledge about more or less formalized categories of agents, features, and tasks, and where the observable signals of an agent (manifesta) are assumed as clues of its internal properties (krypta). Accordingly, we introduce specific heuristics for:  X  X scribing categories to tasks as a crucial capability for identifying the best trustee on the basis of its potential categorization as expressed by its manifesta;  X  X ssessing trust towards a population of trustees in dynamic environment conditions, with different kind of tasks to fulfill;  X  X ssessing trust based on partial information about a heterogeneous population of agents: trustors only know few manifesta for each possible trustee.
 The article is structured as follows: Section 2 summarizes our socio-cognitive approach to trust and extends it with an inference model based on categorization abilities. Sec-tion 3 describes the computational model adopted for representing task over categories of agents and Section 4 presents the architecture implemented by cognitive agents able to assess trust based on ascribed categories and situated conditions. Finally, Section 5 evaluates the approach and presents experimental analysis and Section 6 concludes with the discussion of the obtained results and future developments. In this section we summarize the socio-cognitive model of trust and describe the ex-tension of this model for reasoning on categorial trust on the basis of a limited set of agent observable features. The socio-cognitive model of trust considers trust as a relational construct between the trustor (X) the trustee (Y) about a defined (more or less specialized) task ( where are also explicitly present both X X  X  goal ( g X , respect to which trust is activated) and the environment ( E ) where the relationship is going to take place.
 specific environmental conditions for any involved agents, as they are included in the general set of environmental settings ( E ). In fact, the trust relationship between X and Y aims at the achievement of the task  X  that will satisfy the goal g can be evaluated by the match between the results coming from the execution of the task (  X  ), with the goal of the agent X ( g X ). In general we have to consider a threshold over which the goal can be considered achieved (this threshold, on its turn, can be dependent from several parameters: the trustor X  X  personality, the relevance of the goal, and so on). The relational construct of trust can be analyzed in terms of the X X  X  mental ingredients of trust that are the goal g X and a set of main beliefs:  X  Bel(X Can Y (  X  )),  X  Bel(X Will Y (  X  )),  X  Bel(X ExtFact Y (  X  )), where the following hold.

Can Y (  X  ) . This means that Y is potentially able to fulfill the given conditions, is competent, has the internal powers, skills, know-how, etc); it represents what we call abilities .

Will Y (  X  )) . This means that, under the given conditions, Y potentially has the attribu-tions for being willing, persistent, available, etc., on fulfilling the task what we call dispositions .

ExtFact Y (  X  ) . This means that potentially there are a set of external conditions either favoring or hindering Y in realizing the task  X  ; it represents what we call opportunities and, in the specific case of (1), it coincides with the environmental conditions defined as E .

In our model we also consider that trust can be graded . In fact, each of the preceding beliefs can be quantified in terms of  X  X egree of credibility X  (about abilities, dispositions, and opportunities). Also for the goal we can consider a value of relevance. We can compose the several grades of credibility in a single degree of trust ( DoT Castelfranchi and Falcone [2010] for more details). In general, a trust relationship is established when DoT X , Y , X , E overcomes a threshold  X  . This threshold is also dependent on the value of the goal. So trivially X will trust Y about the task Given the previous analysis of the main components of the trust attitude ( g Can Y (  X  )), Bel(X Will Y (  X  )), Bel(X ExtFact Y (  X  ))), we can say that DoT turn, resultant from the several quantifications of these components. In what follows we describe a cognitive model allowing trustors to form such relevant beliefs, and in particular to infer the former beliefs (about Can Y (  X  )and Will categorization process. Let us now consider a MAS composed by many interacting agents ( ag characterized by a list of its own internal features determining the agent X  X  behavior in terms of (professional) abilities and dispositions . We assume that the list of external features of the agent defines its observable state, thus the potential perception of its functional abilities. Similarly to the approach provided in Bacharach and Gambetta [2001], we define an agent configuration based on the notions of krypta and manifesta .
Definition(Krypta). We define krypta as the internal features of an agent, represent-ing agent internal configuration and determining its behavior. We assume that agent X  X  krypta information is not observable by others.

Definition(Manifesta). We define manifesta as the external features of an agent, hence as the information which is observable by other agents.

In what follows we assume that manifesta do not determine the agent X  X  behavior in a direct way. Instead, we assume that manifesta are shaped on the internal configuration of the agent and recall its krypta. In other terms, we assume a relation between the agent X  X  krypta and its manifesta: namely, manifesta are the observable signs indicating with a certain approximation internal, unobservable krypta. In doing so, we do not consider the case in which the manifesta are deceptive or wrongly perceived: manifesta are always a hint, a clue of the agent X  X  krypta.

In the described configuration we will consider trustors and trustees as divided groups inside the MAS, thereby if an agent plays the role of trustor it cannot play the role of trustee. Agents playing the role of trustor (trust givers) have to identify the best trustee (trust taker) to which the task could be delegated for its fulfillment. We assume that trustors have a partial knowledge of the trustees population, and this knowledge is limited to personal experience of past interactions and to the analysis of the available trustee X  X  manifesta. We also assume that a trustor may assess trust by using its own computational model, that is, by exploiting statistical information, past experiences, cognitive heuristics, and so on. On such a basis the trustor will delegate the assigned task to the more trustworthy agent and will receive back the value of the trustee X  X  performance as reward. In a population of possible trustees, considering the external conditions E  X  E and the task  X  , a trustor X will trust the trustee Y for which the highest assessed degree of trust is assessed.

Definition(Tasks). We define a set of tasks (  X   X  T ), each task being identified by a couple ( action, goal ); where a specific goal (a state of the world to achieve or to maintain) can be reached by that specific (simple or complex) action .

Theoretically, the tasks are defined by a set of actions X  requirements identifying those agents X  internal features useful for successfully performing the actions, thus achieving the specified goal. These requirements are referred to as both the professional and dispositional features of the agents. In practice, the actions X  requirements of the tasks directly individuate the abilities and dispositions of the agents (or of classes/categories of them) needed to successfully realize those actions in order to achieve the specified goal. We also assume that external (environmental) conditions in which the task is realized could affect the performance of the delegated trustee.
 Definition(External Factors). We define the external factors ( tual conditions determining the situation in which the task is executed.

In fact, we assume two potential influences of the external environment on the trustees X  performances: on the one hand, different environmental conditions could lead to different results in the world, even starting from the same trustee X  X  actions (it depends on the different composition of the trustee X  X  actions with the environmental conditions); on the other hand, different environmental conditions could change the trustee X  X  actions themselves. In this case it results in different final trustee X  X  actions, rather than their composition with the environment. In the MAS described earlier, the problem to infer trust towards possible trustees is in anticipating their performances, Such a trust value can be used as a reliable indicator of the trustee X  X  performance on a given task. An available option for a trustor to do this is to ascribe a category to any possible trustee and, on such a basis, build a theory of that agent. We assume categories characterizing classes of agents in behavioral terms.

Definition(Categories). We define C at as the set of categories, each category being determined by a set of features X  X  constraints .

Members of a given category have their profile X  X  features bounded in a certain in-terval. In this characterization, a trustor can include a trustee in a given category by exploiting its manifesta. In doing so, a trustor can assume that the trustee has a range of features which is proper for the specific task requirements. Thereby, given a category, an agent may anticipate to some extent which performance the agent belonging to that category is going to realize.

We remark that, inside each category, the agent performances may belong to a range of values, varying from low to high effectiveness due to the actual grade of agents X  features. By knowing the category to which an agent belongs, a trustor knows just approximately the internal features of the agent: such a knowledge is given by the range of values (constraints) characterizing that category. Indeed, the actual skills and behaviors of the trustees are determined by a set of their internal features which, by definition, are not observable by others (krypta). It is worth to remark that even ascribing a category to an agent on the basis of its manifesta, a trustor continues to ignore the real values of the internal features of the trustee (that is, agent X  X  manifesta can just refer an approximate value of its krypta).

On this basis, we envisaged a cognitive architecture enabling agents to trust through categories as built on the following main functions.  X  Ascribe  X , cat . Given the description of the current task function calculates the degree of the match between the constraints of cat and the requirements of  X  (see Section 4.1).  X  Matches  X , cat , ag . Given the categories ascribed for each task manifesta owned by an agent ( ag ), this function allows to verify whether the trustee has the required internal features to fulfill the task or not (see Section 4.2).  X  TrustEval  X , ag , Bel , E . Given a task  X  , an environmental influence given the trustor belief base ( Bel ) storing the history of past interactions, this function allows the trustor to synthesize a trust value for ag . In concrete implementations, trust evaluation for the cognitive trustors is realized through a mechanism based on fuzzy cognitive maps (see Section 4.3).
 The details of these functions will be the matter of Section 4. It has to be remarked that this approach allows agents to reason in a twofold level, namely in a categorial and in a personal level: the former, ascribing categories to agents based on their manifesta, the latter, including the belief base of the agent to exploit the information about past personal experience. As said, the described cognitive heuristic also allows to evaluate external conditions and their influence on agents X  performances. The cognitive approach to trust assessment previously described allows trustors to com-bine different information sources. The task is ascribed to a list of suitable categories which drive the selection of possible trustees. In doing so, the cognitive trustor analyzes trustees X  manifesta, on the bases of these, extracts some measures of their professional and dispositional capabilities, also taking into account possible environmental influ-ences over the task execution. Before providing the details of the mechanisms at the basis of the cognitive architecture, in what follows we first describe the structures used by agents for reasoning in terms of categories and tasks.
 The set of categories C at models a shared explicit information inside the MAS. We consider professional and dispositional categories. They define, respectively, the com-mon abilities (or capabilities, skills) and dispositions (or personality traits, willingness, intentional attitudes) of their belonging agents.

Each category is defined by a set of features X  constraints , where each constraint bounds a certain agent feature to range within a minimum and a maximum value X  being bounds defined by the interval [0, 100]. To be fully comparable, these categories are designed on the same set of features; for example, the features of the professional categories are { manuality, specialization, expertise, problem solving tion refers to a specializing feature. Similarly, the dispositional categories are specified by { caution, attention, availability } .
 Professional categories are referred to the medical domain and are reported in Table I. Categorial features, requirement intervals, and constraints are not referred to experimental data, but they are inspired to a general common way of reasoning. This choice is aimed at showing the functioning and the efficacy of the categorization reasoning, regardless of the compliance of the real medical domain. As will be discussed in the model evaluation (Section 5), arbitrariness would compromise the results of our model only partially 2 .

As said, any professional category is characterized by a specializing feature, that is the feature professionalizing the category. For instance, in the Otorhinolaryngologist category, ent spec refers to otorhinolaryngology specialization is characterized by surgery spec , and so on (see Table I). On the basis of the profession-alizing feature, a taxonomy of categories exists. Each category is indeed divided into two subcategories, Low and High , meaning classes of agents with lower or higher skills for the same specialization. This allowses to better observe how the categorizer agent addresses trust to the most professionally specialized category for the given task.
Dispositional categories model a particular character profile of an agent. We consider six dispositional categories, as reported in Table II. As for the professional categories, also dispositional categories are designed on a basic set of features, that are attention, availability } . Notice that each dispositional category is designed to implic-itly promote a specific feature (e.g., category: Cautious dual category penalizes that feature (e.g., category: Impulsive This allows to better highlight the relation between the agent X  X  dispositions and task requirements in terms of behavioral attitudes. Internal dependencies among features are considered too. For example, the category cautious has a high value for the feature caution and a lower value for the feature availability (as we assume that the cautious agent will be lower in performing a task at the expense of his availability).
Having an agent member of a high professional category does not necessarily mean that it will perform better than any members of the respective low professional category. assume each agent belongs to exactly two categories, professional and dispositional ones. Thus, the evaluation of the agent X  X  performance on a task depends not only on his abilities ( features referred to the professional category) but also on his dispositional attitudes ( features referred to the dispositional category) in addition to the potential positive or negative influence of the environment. Maybe an agent presenting very high professional features could offer very low dispositional attitudes. Tasks are automatically provided to the agents by a system engine. A task is rep-resented in the agent X  X  knowledge as a set of requirements (both professional and dispositional) that should be satisfied by the performer X  X  features for successfully real-izing that task. A threshold value is associated to each of these features. The threshold value is the minimum value (for that feature) the trustee must supply in order to satisfy that specific feature.
 The tasks considered in our medical scenario are the ones described in Table III. As already said, task specification can include a specialization requirement which specializes the task over a specific professional category. For instance, the otitis task is characterized by an ent spec feature, which refers to otorhinolaryngology special-ization present in the Otorhinolaryngologist category. In this configuration, tasks and categories can be mapped each other on the basis of their specializing properties. Tasks can be executed only by agents playing the trustee role. A task is accomplished by a trustee with an action performed over the artifacts ( Ar ) representing the MAS environment. We define the value resulting from the task performance as a score computed by the actual features of the performer, that is by its krypta. In fact, a task is potentially well fulfilled only when the all the thresholds of its requirements are exceeded by the corresponding trustee X  X  features.

We use the FulfillTask function, showed in Algorithm 1, to quantify the value of fulfillment (score). This function is stateless, and it is implemented inside the envi-ronment artifacts ( Ar ), through which the actions are concretely executed and task achieved. The function provides a numerical score proportional to the matching value between task X  X  requirements R  X  and trustee X  X  features F i ities and dispositions (Algorithm 1, lines 1, 2). A second function ( featureMatching )is then used to provide the concrete matchmaking value between agent X  X  features and task requirements (Algorithm 1, line 10). Different techniques could be specified to define the matchmaking: featureMatching in Algorithm 1 utilizes a simple comparison that quantifies the overlap between each task requirement and the related agent X  X  features. Finally, the fulfillment value ( score ) is the sum of all the single overlaps be-tween agent X  X  features and task X  X  requirements, normalized to 100 and scaled over the number of missing features (lines 14, 15). In this section some of the relevant aspects characterizing the architecture of the cognitive agents are presented. In particular, the computational model implementing the functions defined in Section 2.2 is described. Ascribe  X , cat is the cognitive function used by the trustors for comparing the require-ments of the task  X  with the constraints characterizing the category cat . The ascribe mechanism is showed in Algorithm 2. First, the category constraints and the task re-quirements are retrieved using their representations (lines 1, 2). Then, every task re-quirement is compared with the constrains of cat . For each requirement r value is calculated (lines 4 X 11). If the task requirement meets in the category con-strains, a matchmaking value is calculated using the subfunction constrainMatching (line 9). Otherwise the requirement r k is considered as not satisfied, and the variable missing is incremented. As for the function FulfillTask , different techniques could be specified to define the matchmaking between category X  X  constraints and task X  X  require-ments: constrainMatching in Algorithm 2 utilizes a simple comparison to quantify the overlap between each task requirement and the related agent feature. The sum of all the partial overlaps is then normalized to 100 and scaled over the number of missing requirements (lines 13, 14).
 Given a task descriptor  X  , and given the manifesta exhibited by a trustee ag ,the Matches  X , cat , ag function defines whether or not the categories to which ag belongs are suitable to fulfill the task  X  . In doing so, this function checks whether the total of all the contributes provided by the categories owned by the agent ag allows a trustor to trust ag . The categories of the agent are derived from the its manifesta (line 3), and every single value ascribing the category to the task is used to increment a global match value (lines 6 X 8). Finally, the function returns true if this match value does overcome a given threshold  X  (line 9).

Notice that Matches satisfies the general statement of Eq. (2): the match value represents in this case an approximation of DoT computed on a categorial level. For simplicity, we just outline here the subfunction findCategory : concretely, given trustee X  X  manifesta ( mnf k  X  M ), this function retrieves the category to which the agent belongs using a set of predefined rules. In the adopted configuration, findCategory does not introduce further uncertainty, categories are directly mapped to manifesta and thus associated to agents with a rate 1:1. That is, in the concrete implementation of the MAS described in the next section, it is straightforward to retrieve categories from the corresponding manifesta. The possibility to have an uncertain attribution of categories is deemed for future work. It is worth noting that this function allows to focus on the discriminant requirements, thus narrowing the delegation search space only to those trustees exhibiting just the proper professional categories and avoiding inappropriate delegations to unsuitable trustee [Castelfranchi and Falcone 1997]. In order to compute trustworthiness of trustees belonging to Ag , cognitive trustors adopt the function TrustEval  X , ag , Bel , E . For each trustee filtered by the function Matches , this function combines the information inferred on the categories owned by the trustee with the situated environmental influences ( E  X  E ). The function realizes the com-putation of DoT X , Y , X , E , which is finally ranked to find the best trustee, as shown in Eq. (3).

TrustEval is assumed to merge all the contributions to trust, as they are identified in Section 2. For doing this, several options are available, ranging from linear, non-recursive functions up to nonlinear, recursive mechanisms as Neural Networks (NN). The architecture described here adopts the nonlinear mechanism of Fuzzy Cognitive Maps (FCM) [Kosko 1986]. The main advantage of using FCMs is to be a structure that offers a flexible computational design of the cognitive trust model, as well as it is suitable for different applications and domains. FCM is indeed a cognitive map fur-ther enriched with Fuzzy Logics [Kosko and Burgess 1998]. In general, cognitive maps model a causal process by identifying concepts and the causal relations , represented as a weighted graph . The causal effects can be determined by domain experts at design time by simply weighting the links. In this case the FCM has the layout shown in Figure 1, where the designer has defined the impacts for the internal factors given by the factor 1.0 for Experience and Abilities , and by the factor 0.5 for the Dispositions .
Benefit of FCMs are also their robustness and adaptability. In this case, the map is designed as a tree-like graph with Trust as root concept (see Figure 1). Following fuzzy reasoning rules, at each computation step the value of any concept (node) is updated by calculating the impact provided by the other concepts (i.e., the weighted sum of the incoming edges). Similarly to an NN, such a value is then squeezed using the node X  X  activation function, thereby introducing nonlinearity. The computation continues until the convergence is reached, that is until the updates do not significantly change the node values anymore. The use of particular FCM configurations allows to flexibly adopt different strategies of reasoning. Indeed, by inactivating or pruning some branches of the map, different kinds of trust evaluation can be straightforwardly performed. For instance, in the case of the simple cognitive agent which uses only categorial reasoning through manifesta information, the branch external factors is excluded from the computation. Dually, agents using the personal level, based on the direct experience only, may refer to the experience node, thus cutting off the categorial branches and the ones related to the external factors.

A further important property of the FCM is to maintain an unambiguous semantic for the involved structures. Differently from NN, the configuration of an FCM can be read, understood, and quantified at execution time in terms of concepts and concrete influences between concepts. FCM can be also used in conjunction with machine learn-ing techniques inspired either to unsupervised or supervised algorithms used by NN [Papageorgiou et al. 2006]. Learning is aimed at dynamically refining the weights of the causal relationships between concepts, introducing recursive loops between input and output nodes. FCM with learning features provides a fully adaptable decision making module. Our current works show that learning FCM techniques allows to better adhere to the problem domain, for instance, widely improving the accuracy of the model in as-sessing trust values which finely reflect the numerical anticipation of the delegation results.

In Figure 1, the map points out the two main contributions to trust that are external and internal factors (realized by the E-Factors and I-Factors nodes). By design choice, these factors affect the trust node with a fixed weight of 0.5 and 1.0 respectively. The map does not make use of feedback loops for learning, nor considers circular influences between concepts 4 Internal factors are all those elements depending on the internal characterization of the trustee, as believed by the trustor. The I-Factors node is linked to the node experience representing the knowledge of past direct interactions with the same trustee. I-Factors also has two further child nodes related to the specific categories considered in the trustor X  X  domain, thus summing up trustor X  X  beliefs about professional abilities and dispositions. They refer to the particular agent X  X  beliefs, which have been identified as Bel(X Can Y (  X  )), Bel(X Will Y ( two concepts is then respectively linked to a list of nodes indicating the professional and dispositional categories in C at (see Table I and Table II). The weight of the links reflects the impact of the category on the task requirements and is computed by the function Ascribe .

E-Factors node summarizes the trustor X  X  perceptions about the context conditions in which each trustee is assumed to execute the actions to fulfill the task. In concrete implementation of the system, we assume that the influence of these conditions on the performance can be positive, negative, or null. We also assume the trustor knowing the external factors E  X  E , for each available trustee and with no uncertainty. We also assume this contributes to being stored in the trustor X  X  belief base in terms of Bel(X ExtFact Y (  X  )), as identified in Section 2.1. In the special case where also direct experience (of the trustor with the same trustee) is considered, a further leaf node experience is linked to the internal factors.

The convergence on the root node is the output of the FCM and provides trustworthi-ness value for a given trustee. As trust values range within the interval [ configuration for the FCM is to adopt an hyperbolic tangent activation function [Bueno and Salmeron 2009]. In our architecture, the root node uses an hyperbolic tangent with scale factor  X  = 4, while all the internal nodes are provided with an identity activation function. By doing so, we do not lose dependencies between internal nodes and fur-thermore we make sure that no approximation error is computed and thus propagated by squeezing the values during the convergence process. As for trust values, we mean the negative subinterval [  X  1, 0] as mistrust , namely the case when agent distrusts to delegate the task to the trustee. The middle value 0 means neutral trust or absence of trust. Neutral trust may be possible either due to lack of information (leaves set to 0) or to divergent sources, namely, positive evaluation about professional categories opposite to negative evaluation of dispositional categories and/or environmental influences. The evaluation of our approach has been conducted through experiments while mea-suring the performance of our socio-cognitive model against an alternative statistical model commonly used for evaluating trust and reputation. This section describes the experimental setting, presents the obtained results, and discusses their significance. The scenario is designed as a time-stepped simulation in which participant agents playing the role of trustor and trustee have to cooperate to carry out a number of tasks in the medical domain. At the beginning of each round every trustor receives a task (  X   X  T ) from the simulation engine and it has the goal to achieve the highest pay off from performing the assigned task. Furthermore, trustors are assumed they are not able to autonomously fulfill the task but they need to find the best trustee to which to delegate the task execution. Experiments have been conducted using a population of 100 trustee agents. In the first set of experiments we consider three tasks: dental operation, appendicitis, otitis , as defined in Table III. We assume that trustees can accept more than one delegation coming from different trustors at every round. In addition, we make sure that at least 30% of the available trustees is guaranteed to belong to the professional category specialized for the task. For instance, when the task is otitis , there are at least 30 trustees belonging to the categories specialized with ent spec  X  99. The course of the experiments has been fixed to guarantee the agents to stabilize their scores, thus experiment length has been fixed in 200 rounds. The parameter  X  measures the influence of the environment on the task performance. This influence can vary between  X   X  %and +  X  % in the final score. A trustee ( ag to the context ( i ), in fulfilling the task (  X  ) is thus affected by positive, negative, or irrelevant context conditions, which influence the performance for a rate quantified by . For each environmental configuration, a series of 30 trials have been repeated. The results described shortly report the scores of the trustors averaged on the whole series.
We refer to cognitive trustors for indicating the agents exploiting the capabilities to assess trust based on the cognitive architecture described in Section 4. Globally, six strategies are compared for the trustors.
 In order to make the experimental results independent by the composition of the various population, the delegation effectiveness is measured in terms of absolute score . This metric is computed over the result of each delegation, and it is the ratio between the score actually obtained and the maximum available result achievable in the current population. In other words, a trustor obtains a score of 1.0 when it delegates the task to the trustee which is able to obtain the best performance among all the others.
The agents are implemented using Jason 1.3 [Bordini et al. 2007], while the sim-ulator is based on CArtAgO 2.0 [Ricci et al. 2010], a platform for programming MAS environments based on artifacts. This choice allowed us to design agents in terms of epistemic and motivational attitudes, namely beliefs and goals. It also allowed the implementation of agents as driven by internal events, according to the programming model based on AgentSpeak(L). Such a programming model lets us define the interac-tion between agents as based on messages, while the agent-environment interactions have been based on actions and perceptions, as defined in the JaCa programming model [Ricci et al. 2010] 5 . The configuration of the machine on which the experiments have been run is: Intel(R) Core(TM) i5 CPU x64, 2.67 MHz, 6MB RAM, equipped with Windows 7, Java 1.6. Results are presented for the four cases of study where  X  = are: dental operation, appendicitis, otitis . 5.2.1.  X  = 0 -No Influence. Table IV reports the mean scores obtained by the trustors when the environmental influence is null (i.e.,  X  = 0). The best performance is obtained by the cognitive trustors able to exploit experience of their past delegations: All and Exp (  X  0 . 98 points for any tasks). Stat totally gets a lower ranking ( its score is lowered by the extensive learning phase during the first 100 iterations, needed to test at least one time each trustee. The task otitis is taken as instance in Figure 2, showing the detail of the scores of the agents in each round. After a learning curve of only 25 iterations, Exp and All find the best performer in the trustees population and their scores stabilize on the maximum performance. Due to the cognitive attribution of trust based on categorization, the learning phase for these agents is limited to the exploration of only few trustees belonging to the most fitting categories for the task requirements. In a different way, the learning curve of the Stat agent requires a considerably larger number of iterations (100) before becoming stable on the maximum score. Cat picks up every trustee from the most fitting categories, though it is not able to further refine this choice not having any individual feedback from the delegated trustee. The score of this agent is  X  0 . 85 for dental operation and otitis ,and  X  0 . 90 points for appendicitis . This difference is due to the different matching between categories and the task requirements: being otitis is considered a very difficult task (see Table IV), the best available performance will be quite low and, in turn, the absolute score of categorizer agents will be proportionally higher. Ext performs the same as Cat because in absence of environment influence these two agents are in the same FCM configuration. Finally, Rand agents obtain the mean score ( the whole set of performers.

Trust delegation. It is also interesting to observe how the trustors distribute their delegations among the population of trustees: which trustee they delegate and how many times. The plots in Figure 3 show the distribution of the delegations in a single experiment. In this case, ag 12 is the best in performing the task dental operation ,that is the trustee obtaining the best performance in the actual population and thus the reference agent on which the absolute score is computed. Stat delegates at least one time each agent, before finding and stabilizing on the best performer (Figure 3(c)). Cat and Ext restrict their search to the only good and available dentists (Figure 3(b)), but they are not able to identify the best performer among those. All and Exp , combining together categorization and direct experience, quickly identify the best trustee in the group and delegate it throughout the simulation (Figure 3(a)). Finally, Rand delegates uniformly amongst the whole trustees population (Figure 3(d)). 5.2.2.  X  = 5 and  X  = 10 -Low and Medium Influence. For the sake of simplicity we focus here only on task dental operation , although similar analysis can be extended to the other tasks. Table V reports the scores for the same set of trustors with low ( and medium (  X  = 10) environmental influence. Strategies considering a richer set of information sources are expected to outperform more simple strategies. Compared to the case of  X  = 0, the standard deviation of the average results is sensibly increased (from 10  X  15 to 10  X  2 ) as a sign that the environmental noise sheds more uncertainty over the system. Increasing  X  , Ext raises its score up to 0 agents Exp and Cat lose around 3% and 4%. For  X  = 10, the environmental influence is strong enough to counter the direct experience and Exp and Ext equalize their scores on  X  0 . 91. The noise provoked by the environment on the performance is remarked by some irregularities on the curve of Exp , shown in Figure 4(b) and Figure 4(c). In this configuration, the trustor who delegates always to the same trustee will receive different outcomes from round to round, due to the environmental noise. Using the entire set of information sources, All builds its delegation choice on both experience and environmental factors. Curiously, when  X  = 5, All does worse than Exp (0.92 versus 0.96). To explain that, we have to remark that we could have e-factors overinfluencing the degree of trust and thus do not lead to the correct anticipation of the trustee X  X  performance. Different dynamics can be obtained refining the trade-off between the influences of experience and e-factors. In any case, All is able to maintain its score around 0 . 92 in both the environment configurations. Stat and Cat agents show a general decrease of their scores when  X  increases. Cat scores 0 . with medium influence. Stat steadies on the best trustee after having completed a full learning phase and gets the scores: 0 . 75 (low influence) and 0 Finally, Rand attains the worst performance, with a mean score around 0 5.2.3.  X  = 20 -High Influence. When the influence on task execution is high ( the noise of the environment undermines every direct experience (see Figure 4(d)). This fact fosters the capability of the agents to exploit the information of the external factors. Results show that All is again resistent to the environmental influences and keeps its score on 0 . 93. Ext , only following up the trustee with the most positive context (i.e., considering a much smaller trust sources set), performs nearly the same as All (0 . 92) and is now able to do much better than Exp (0 . 92 versus 0 Cat keep losing points because they are not able to anticipate environment influences. No differences are observed for the Rand agent, whose performance in fact does not depend on the environment conditions. So far we dealt with tasks featuring a specific professional category, that is, tasks containing one and only one discriminant requirement (e.g., dentistry spec for dental operation ). This assumption is justified by common knowledge or personal experience, suggesting that tasks are often a priori assumed to be concerned with some professional specialization. For instance, in our scenario the agents know that a dental operation can only be fulfilled by dentists, as well as appendicitis by surgeons and so forth. In the categorial reasoning, this discriminant requirement has a pivotal role, as it allows for immediately cutting off the professional categories which are considered to be unsuitable for a given task. We are now interested in deeper investigating the role of the specialization requirement in our computational model. In particular, we address the cases in which the specializing requirement might be overspecified or missing. For this purpose we consider two new tasks, cancer and infection : the former with double discriminant requirements, the latter without any discriminant requirements (Table VI).
 Cancer. Table VII shows the results of the six trustors playing on the task cancer . The double specialization requirement has the effect to extend the set of suitable professional categories to the oncologists and the radiotherapists. This increases the probability to find a good (but not the best) performer for strategies with random search such as Rand and Stat (the latter only in his learning phase). As a consequence, all the trustors improve their scores and the gap between categorizer agents and the other strategies is reduced. We can notice in Figure 5(a) that Ext and All are involved in a larger exploration of approximately 45 iterations. The structure of this task is also useful to understand the role of the function Matches (Algorithm 3) in the computational architecture of our model. Since we assume there are no categories having both the two specialization requirements specified by cancer , the matching values of any professional categories on this task computed by Ascribe will be lower. In other words, the analysis features-requirements so far performed is not able in this case to clearly point out the most suitable professional categories for this task to the eyes of the agent. As a consequence, the agents will need to use a lower value of pruning threshold in the function Matches in order to consider a sufficient number of professional categories in their search space.

Infection. For the task infection no specialization requirement is specified. Ideally, this task represents a sort of abstract task for which the agent does not know exactly the concerned doctor specialization to cope with it. The lack of the direct relation between task and a professional specialization opens up a number of alternatives in the agent X  X  choices: we might be in the opposite situations in which either many professional categories could be able to successfully carry out infection or nobody actually can perform well in the current population. Results in Table VII point out a global flattening in the performances of all the trustors scoring around 0 . This is due to the absence of a trustee who is able to outperform the current population on such a task, so statistical and the categorial strategies cannot do any better than to delegate some random trustees. Figure 5(b) also shows that Exp and All are forced to get some poor delegations up to 0.5 points as a consequence of their blind exploration. When the agent is not able to immediately refer the task to some specializations, the categorial reasoning does not add any substantial help to the search of the best trustee although still categorizer agents try (and in fact they do) to attribute a most suitable category to the given task. In the end, Cat and Ext are still able to maintain a slight advantage against Rand and Stat ,with0 . 90 against 0 . 84.

These examples allow to generalize the applicability of our approach. Overspecial-ized tasks like cancer , which present requirements drawn on several specializations, force the agent to explore a wide range of professional categories. Besides, if the task is nonspecialized, and if the task specification does not reflect the taxonomy of the cat-egories like in infection , then the categorization is not able to exercise any pruning on the population of trustees and agents need to try many delegation options. A relevant result can be analyzed in the trend of agents exploiting experience All and Exp .Having no environment influences (  X  = 0), the impact of external factors is inhibited in All ,and it exploits the same TrustEval function adopted by the Exp agent. In the cancer task, the learning phase is doubled with respect to the one done in the previous tasks. The exploration now reaches about 50 rounds, and can be explained by the fact that now All and Exp agents include the exploration of both radiotherapists and oncologists. In the infection task, the learning phase is tripled, it reaches 75 rounds and clearly includes the exploration of all the encountered categories. This can be explained since the fact that the infection task does not specify a diriment requirement to be matched with the professionalizing features of the categories. The exploration phase of All and Exp proceeds category by category. As shown in Figure 5, their scores undergo a stepped trend, each step representing the mean score provided by one single explored category. The experimentation has been extensive and has considered an heterogeneous sample of tasks, categories, and environmental conditions: more than 600 simulations were performed. The distinctive feature of the cognitive trustor is the capability to develop a reasoning over multiple levels: personal, categorial, contextual . Personal level takes into account the direct experience of a particular trustee. Categorial level considers abilities and dispositions of the potential trustee on the basis of the categories it belongs to. Finally the contextual level takes into account the specific environmental conditions in which the trustee is going to realize the task. The FCM structure is an image of such a hierarchical organization of the information sources.

Results pointed out an overall superior performance of the categorial agents against the mechanism of pure statistical trust. Statistical agent is forced to explore the whole population, thus requiring a huge (and computationally hard) amount of resources to find the best performer. Categorizing agents are able to ease the decision choices by pruning trustees belonging to the unsuitable categories. In doing this, the cognitive model bridges a gap of knowledge: it allows the trustor to infer the effective abilities of a trustee (krypta), namely forming an expectation about its possible performance, based on categorial analysis of observable knowledge (manifesta). The combination of categorial reasoning and direct experience allows for a search bounded to the only appropriate trustees and a consequent drastic reduction of the learning time. After the learning stage, both the strategies stabilize on the same performance.

Environmental conditions represent a further aspect to refine and enhance the cog-nitive trust reasoning. By considering not only the agent X  X  skills but also the influence of the environment on the task fulfillment, the cognitive agent Ext foresees situations of a poor outcome from an apparently good performer and instead fosters delegation to trustees not only skilled but also working in a favorable environment. By varying the parameter we observed the advantage of agent Ext compared with the other strategies (case  X  = 20). Nevertheless, in some cases an expected positive environmental influence could not be enough to find the optimal delegation, when the performance gap between agents holding the same category is high (case  X  = 10).

Finally, we discussed how the task specification directly affects the search domain of the categorizer trustor, with a special focus on the professionalizing features. Pro-fessionalizing features help the categorization process as they allow for an immediate cut of a part of unsuitable categories. In any case, categorization relies on a wider spectrum of features (see, for example, dispositions for which specializing features are not considered) and the performance of categorizer agents only partially depends on whether or not the specializing feature occurs. It has to be remarked that both the choices of task requirements and categorial intervals is made offline, and it is due to designer preferences. For instance, one could define caution for the Careful category in the interval [75, 95] instead of [80, 100]. As experiments show, this would compromise only partially the ability of cognitive agents to assess trustworthiness and find the best trustee. Categories are indeed evaluated with respect to the task. The role of the Ascribe function is crucial in centering the categories with the requirements to fulfill. Although the reasoning provides a slightly different set of possible trustees to choose from, it still allows agents to maintain similar results in terms of delegation effective-ness. Is worth nothing that the natural progress of a MAS, where agents are assumed to learn and continually enrich their knowledge, brings about the case in which the re-lation between tasks and specialized categories is known and can be suitably exploited for evaluating trust. This suggests an important scalability for the categorial approach: the model can be effectively applied in a wide class of domains, where it is feasible to associate specializing requirements to classes or groups of agents. In this work we started from the fundamental idea that there is a strong relationship between the uncertainty in trusting agents and the fact that part of the qualities of a possible trustee is unobservable. Based on this assumption, we provided a computational model by which cognitive agents succeed to assess trust upon a population of heterogeneous and possibly unknown trustees. As shown, the proposed approach enables a particular kind of reasoning based on direct experience of past interactions (personal dimension) on information about professional and dispositional abilities which can be assumed on generic and open population of agents. Conducted experiments clearly show the benefits of managing this twofold heuristic, thus effectively improving delegation strategies under uncertainty and ameliorating tasks fulfillment with respect to traditional strategies based on only direct experience.
As in Bacharach and Gambetta [2001], we realized this ability of dividing the in-formation and characterizing the system in  X  X rypta and manifesta X , thus enabling a special kind of inference allowing to explain agents X  internal qualities (krypta) with their observable signs (manifesta). In particular, we extended this relevant concept to the categories: an agent expressing the signs of a category inherits the qualifying properties of that category. Our results show that categories result as a pivotal piece of information for agents who are able to manage it. Indeed categorial reasoning allows to establish fruitful interactions with agents which have not been encountered yet. This aspect has a important significance in the context of open systems, characterized by heterogeneous societies of self-interested agents. Our model makes the MAS open to new agents that can enter and leave the application at any time, but not open to categories, that are in fact preexisting for the agents. Our future work will be aimed at addressing this limitation, by developing mechanisms to fully enable the categorial reasoning in open systems, for instance, letting categories to emerge on the basis of individual experience. A similar approach has been recently developed by Burnett et al. [2010], where the categories or class are not preexisting to the interactions, but the agents can generalize their experiences with known partners in previous contexts. This work shows that, by using data mining techniques, agents can form stereotypes that al-low to bootstrap trust evaluations about unknown agents in new contexts. By ascribing trust evaluations to learned classes of individuals as well as individuals themselves, agents can make use of both previous experiences and reputational opinions in contexts where this would not otherwise be possible.

Another limitation of our model is the naive statistical model that we introduced in order to benchmark and evaluate the approach. Among other weakness, the statistical approach that we implemented is not able to recognize environment influences. More in general, there are several interesting studies analyzing the role of the context in the trust relationships [Rehak et al. 2007; Tavakolifard et al. 2008. In these works the constraints introduced by the context and its various dimensions are formally and/or informally analyzed as a support for evaluating trust relationships. These studies can be considered as partially overlapping our approach, even if in our model we focus explicitly on categories (just eventually one of the constraints in those works) as a fundamental instrument for attributing features and properties to agents.

Finally, we have already implemented a fuzzy approach Falcone et al. [2003, 2004] of our socio-cognitive model of trust. This article revised and extended the conceptual analysis of that work in modeling the fuzzy cognitive maps used by the cognitive agents. The next steps in this direction will be in the development of a modular architecture, that is, able to configure the topology of the FCMs based on the relevant aspects characterizing particular situations. Future work will also account the possibility for agents to improve and refine the categories at runtime, thus based on the situated conditions of the system. A further step will account the possibility for agents to share such refined information, thus enabling different kinds of cooperation based on the communication of the categorial information characterizing the system. In any case, the aim of the present work was to verify the relevant role of the category-based analysis for trusting agents. On this basis we have adapted and updated the cognitive maps also introducing the role played by the categorial structures and by the experience.
