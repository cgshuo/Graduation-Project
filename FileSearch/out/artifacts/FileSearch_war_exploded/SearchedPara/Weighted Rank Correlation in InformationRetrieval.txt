 In Information Retrieval (IR), it is common practice to compare the rankings observed during an experiment with the rankings produced by (i) a competitor system, (ii) the same system but with different parameters or (iii) the system which correctly ranks all the items (e.g. a human) and is then considered the best. Examples of (i) regard the comparison of the algorithms for various techniques used in IR, such as query expansion, stemming, or graph link-based webpage ranking. An example of (ii) is the correlation between the webpage rankings computed by PageRank at different damping factors or numbers of iterations calculated through the power method. An example of (iii) is the comparison of the ranking of IR systems produced by usin g the relevance assessments collected by the human assessors with the ranking produced by using the relevance as-sessments collected through the manual runs. The comparisons aim at helping the experimenter to decide whether the co mpared rankings are  X  X pproximately X  the same or they are significantly different. The measurement of the degree to which two rankings are the same is called rank correlation in the literature of Statistics. Rank correlation is crucia l in IR because it helps decide the success of new models and techniques.

As in IR the rankings are often compared with a reference based on relevance assessments or preferences provided by human judges, this paper is focussed on the comparison between an observed rank ing and a reference ranking which puts the item in the correct order. Thus, it is assumed in this paper that the reference ranking is the best ordering of the items. Examples are the documents ranked by relevance assessments, the items ran ked by preferences, or the terms ranked by degree of synonymity  X  for the sake of simplicity, in the following,  X  X elevance X  refers to  X  X reference X ,  X  X mportance X ,  X  X sefulness X  and to similar terms.
Suppose a ranking of n  X  2 items, e.g. documents, is observed  X  this is called observed ranking. The items are conventionally numbered from 1 to n and thus item i is represented as the natural number i . For example, item 5 is ranked at the second position in the observed ranking (4 , 5 , 2 , 1 , 3). The ranking to which the observed ranking is compared is called reference ranking and is conventionally represented by the increasing sequence (1 , ... ,n ) which puts i at rank i .
The most used rank correlation coefficient (RCC) is Kendall X  X   X  . Kendall X  X   X  can be viewed as a function of the number of exchanges of two items necessary to transform the observed ranking to the reference ranking  X  the higher the num-ber of exchanges necessary to transform t he observed ranking to the reference ranking, the less correlated the two rankings are. Intuitively, the idea is similar to the bubble-sort algorithm. Formally, Kendall X  X   X  is defined as the ratio of the difference between the number of concordant pairs and the number of discordant pairs in the observed ranking with resp ect to the reference ra nking to the total number of pairs [1]. From this definition, it follows that where is the proportion of concordant items to the total number of pairs, which is n ( n  X  1) / 2, and C is the number of concordant pairs in the n -item observed ranking.

An important property of  X  is its limiting probability distribution. Under the null hypothesis of random, uniformly distributed rankings, and then of incor-relation,  X  is approximated by a Normal random variable with mean zero and known sampling variance, thus permitting the experimenter to infer about the significance of the RCCs by using the Normal probability distribution tables. The main advantage of  X  is the rapid convergence to normality even with small samples [1, 2]  X  however, this is only one of the reasons why this coefficient is largely used in IR, the others being the simple underlying idea, the sixty year-long history, and the wide availability of routines for calculating it in many statistical or mathematical software packages.

The problem is that the dis/concordan ces should be treated differently de-pending on the relevance of the items, the latter being an important issue in IR when some measure of relevance is often attributed to the items. In this regard, despite its simplicity, Kendall X  X   X  is inappropriate in discriminating the correla-tion involving the items on the top of the reference ranking from that involving the bottom ranked items. As a consequence, when the items are ranked, say, by relevance in the reference ranking,  X  is insensitive to the relevance of the items. Actually, in IR, the concordances or discordances involving the most relevant (or useful, interesting, important) items should often be considered more im-portant than the concordances involving the least relevant. The importance of the degree of relevance of the items is evident, for example, when non-binary relevance is recorded and document ran kings are compared  X  the concordances of the most relevant items are the most crucial and then the weights given to these concordances should be higher than those given to the oth er concordances. Therefore, the RCCs should weight the c oncordances differently depending on the ranks where the items occur in the re ference ranking. Since the reference ranking is often arranged by relevance, the treatment of dis/concordances de-pending on the item relevance means that the dis/coconcordances are treated differently depending on the ranks of the items in the reference ranking.
In this paper, a family of RCCs for IR, called  X   X  has been introduced to give different weights according to the rank of the items in the reference ranking. Each instance of  X   X  differs from the others for a series of n  X  1 weights used to give different importance to the ranks where the concordant pairs occur. The main contribution of this paper is the use of the gains [3] in order to provide a conceptual basis to the assignment of the weights of  X   X  . Thus, the definition of the weights of  X   X  is very simple, easy to use and intuitively understandable. The importance of the use of the gains is due to their role in estimating the probability that a relevant item is picked at random among those ranked before a fixed item, thus generalizing the notion used with  X  AP in which all the relevant items are treated equally.

The probability distribution for  X   X  has also been provided, thus permitting to decide if  X   X  computed using a given series of w eights is significantly different from zero, that is, if the observed ranking is different from the reference ranking and if the difference mostly affects the most relevant items  X  this is the second contribution of the paper. In this way, the experimenter can decide whether the use of a tested technique, model or method is significantly different from the technique, model or method used for another ranking, especially when the top ranked items are deemed the most crucial, thus grounding the comparison of experimental results on a sound infe rential statistical basis. Although  X  AP is more sensitive to the concordances at the top-ranks than  X  ,itisnotprovided with a probability distribution. However, in this paper, it is shown that, as  X  AP is an instance of  X   X  , and then it is approximatel y Normal with mean zero and known sampling variance.

As the paper is mainly theoretical, it provides the basis for the future ex-periments and applications. It is structured as follows. Section 2 briefly reviews the most relevant related work. Section 3 describes  X   X  . Section 4 illustrates the problem of weighting in rank correlation. In Section 5 the criterion to define the weights of  X   X  is presented. In [4] the use of weights giving different importance to the concordances or the discordances depending on the ranks of the items was considered. To this end, a RCC called  X  w was defined and the normality of the distribution probability was proved. Due to  X  w ,itcanbeshownthat  X   X  is a special case of  X  w and  X  is a special case of  X   X  .

The problem of giving more importance to the concordances occurring on the top was also addressed in [5] where a modified  X  , called  X  AP , was proposed. Those authors showed that  X  AP may be greater than  X  when the concordance between the reference ranking and the observe d ranking occurs at the top ranks, while  X 
AP may be less than  X  when the concordance betw een the reference ranking and the observed ranking occurs at the bottom ranks. In this paper, it has been shown that  X  AP is special case of  X   X  ,andthenof  X  w .

In [6], various rank correlation measures are investigated and classified. Us-ing a preference criterion, the authors suggested which RCC to use. Our work differs from that article since our aim is to generalize  X  and  X  AP , thus leveraging the known properties and advantages of these two coefficients and proposing a general coefficient which can be tailored to the needs of the evaluation of specific retrieval tasks. This paper, moreover, anchors  X   X  to the notion of gain as  X  AP has been anchored to the notion of Average Precision.
 Many are the papers which have used rank correlation, and in particular Kendall X  X   X  . The issue of giving more importance to the concordances at the top ranks raised in [7 X 11] as regards to ranking and advertising in the Web, in [12 X 21] as regards to the problem of evaluating IR systems, in [22, 23] as for distributed IR (the problem was t o select some of the best sources from a networked system), in [24] as for social search, and in [25 X 27] as for feature selection, indexing and crawling (the p roblem was to select the best features, the best indexed documents from a posting list or to crawl the best websites). In [5, 28], some research results on ra nk correlation and IR were surveyed. From the computation of  X  , one realizes that C is the sum of the number of concordant pairs computed over all the items where an item of the pair is fixed. That is, C = C (2) +  X  X  X  C ( n )where C ( i ) is the number of items less than i -th item in the observed ranking (see also [5]). For example, C (6) = 3 in (4 , 7 , 2 , 10 , 3 , 6 , 8 , 1 , 5 , 9).

It can be shown that where is the proportion of concordant items at rank i . The Average Precision (AP) correlation introduced in [5] was defined as where thus highlighting the fact that  X  and  X  AP belong to the same family of RCCs which is defined as where that is, a mixture of proportions of concordant items computed at every rank i =2 , ... ,n where the w i  X  X  form a series of mixture weights. 1
Suppose a reference ranking and an observed ranking are to be compared and consider the following experiment performed on the urn including all the items distributed according to the w i  X  X . First, pick at random an item i other than the top ranked from the reference ranking with probability w i . Second, pick at random with probability 1 i  X  1 an item ranked before i in the observed ranking. Finally, return 1 if the two pick ed items are ranked in accordance with the reference ranking. The exp ected value of this process is p  X  .

Note that, when using  X  AP , the probability that an item i other than the top ranked is picked at random from the reference ranking is uniform and equal to  X  1 . This view is derived from Average Precision which underlies  X  AP . Indeed, the picking of an item at random corresponds to the selection of a relevant document  X  as the relevant documents have the same degree of relevance (i.e., relevance is binary), the probability that an item is picked is uniform. On the contrary,  X   X  is based on a non-uniform probability (i.e., w i ) of picking an item, thus suggesting the idea that a non-binary or graded relevance underlies its definition  X  this is indeed the idea described in the following sections. Let us consider the following toy examples in order to intuitively illustrate the differences between the RCCs  X  of course, the example may seem a little con-trived, but it is a sort of counter-example to show that the RCCs do not provide the same result. Suppose (1 , ... 10) be the reference ranking and that three ob-served rankings differ from each oth er by the rank of the items affected by exchanges: At first sight x is very similar to the reference one, however, the two top ranked items are reversed. While the end user would appreciate the difference because the top ranked document in the observed ranking is not on the top,  X  =0 . 96 and so the two rankings are considered highly correlated.

Although y is a little more similar to the reference ranking  X  two middle ranked items are reversed while the top three items are unchanged,  X  =0 . 96 which again suggests concordance, thus indicating that the decision about concordance is insensitive to the rank of the reversed items  X  indeed,  X  does not change even for z . Let us compute  X  AP instead:  X  AP =0 . 78 for x while  X  AP =0 . 94 , 0 . 98 for y, z , respectively, thus confirming that this RCC is sensitive to the rank of the reversed items.

Let us now consider  X   X  and let the weights be, for example, thanks to the decreasing series of weights, the role played in  X   X  by the ranks of the reversed items is even more important than in  X  and  X  AP .Thishap-pens because the probability that a top ranked item is picked is higher than the probability of a bottom ranked item. Therefore, the discordances at the top ranks will be highly weighted as in x , while the discordance in z will be lit-tle weighted because the probability that the bottom ranked item is picked is low.

This is of course relevant to IR since the criteria used for assigning the weights to the number of concordant items at every rank determine the value of the RCC. Therefore, if  X  suggests that two rankings are equivalent, it might be that they agree at the bottom ranks rather than at the top ranks, the latter being a conclusion not always welcome when comparing rankings which are in contrast appreciated if they place the best items on the top.  X  AP reduces this drawback because it giv es equal weight to all the concor-dances. Indeed, a decreasing series of p ( i ) X  X  is sufficient to say that  X  AP &gt; X  . However, this condition is not necessary and  X  AP may fail to discriminate when this series is not decreasing. L et the observed rankings be u =(1 , 3 , 2 , 4 , 5) and v =(1 , 2 , 4 , 5 , 3). In terms of the number of exchanges, u is more corre-lated to the reference ranking than v . Indeed,  X  =0 . 80 for u and  X  =0 . 60 for v . Nevertheless,  X  AP provides the same value (i.e. 0 . 75) for both the observed rankings, thus not discriminating as  X  does. The reason lies in the proportion of concordant items. When these probabilities are computed, one obtains the 1 ,p (4) = 1 ,p (5) = 1 2 for v .

However, while  X  AP is based on the notion of Average Precision, thus making it more sound,  X   X  does in contrast still lack of such a basis. The next section provides this basis.
 The mixture weights thus play an important role in weighting rank correla-tion. At this point, there are two main methodological issues to which a great deal of attention should be paid. From the one hand, an issue is about how the mixture weights w i  X  X  should be defined in order to compare two rankings from a IR perspective. On the other hand, the probability distribution of the RCC family has to be defined in order to compare two rankings and to decide if they are significantly different from a st atistical point of view. To address these two methodological issues, in this paper, two methodological results are intro-duced, that is, the the notion of Cumulative Gain presented in [3] and weighted Kendall X  X   X  presented in [4]. 5.1 The Weighted Kendall X  X  Rank Correlation Coefficient The weighted kendall X  X   X  ,thatis,  X  w has been illustrated in [4] and is defined in this paper as where I is an indicator function such that I ij = 1 if items i, j are concordant (i.e. they are ranked in the observed ranking in the same order as the order in the reference ranking), I ij =  X  1ifitems i, j are discordant (i.e. they are ranked in the observed ranking in the opposite order as the order in the reference ranking) and v ij is the weight assigned to the concorda nce or discordance occurring between items i and j . This RCC assigns different weights depending on the ranks i, j . After a few passages, it can be shown that where the term multiplied by 2 resembles the p of  X  . Supposes that v ij = v ji , that is, the con/discordance weights are symmetric. In this case, Suppose, now, that the weights are constant for every i ,thatis, v ij = v i and then are independent of j  X  this means that the concordan ce (or discordance) between, say, the fifth item and the first item is equally treated as the concordance between the fifth item and the fourth item. This is actually what is assumed by many RCCs such as  X  and  X  AP . It follows that (when v ij = v i )
As C ( i )=( i  X  1) p ( i ), it is found that If one can easily see that  X  w =  X   X  .

It may be noted that, when v ij = 1, the weighted Kendall X  X   X  w turns into  X  , and when v ij = 1 i  X  1 , it turns into  X  AP .

Hence, the weighted Kendall X  X   X  w can be utilized as a basis to decide the mixture weights of  X   X  . Indeed, the definition of the v i  X  X  is sufficient to achieve the mixture weights of  X   X  . At this aim, one needs a basis to assign a value to the v i  X  X  before calculating the mixture weights. As the v i  X  X  need not to be normalized, that basis does only define the v i  X  X  as non-negative real values. In the next section, the basis proposed in this paper is illustrated. 5.2 Gains in Information Retrieval Evaluation The notion of gain and of cumulative gain for IR evaluation was proposed in [3]. In this section, this notion is briefly reviewed before illustrating how it has been exploited to define the basis for computing the mixture weights of  X   X  (and, in general, of  X  w ).

The value G( r i ) of the item ranked at i is the degree of relevance, interest or usefulness (in general, the  X  X ain X ) of the item to the user; for example, when graded relevance is used, G( r i ) may range between, say, 0 and 3. There are search scenario where, for example, the user s are asked to provide judgments from 0to7.

The notion of gain is useful in IR thanks to the cumulative gain (CG) of item ranked at i ,thatis,CG( r i ), which is the sum of the gains computed over relevance degrees of ten documents ranked by, say, similarity to a query. The degree of the fourth item is G( r 4 ) = 1, while its cumulative gain, that is, CG( r 4 ) is 2+3+0+1=6. 5.3 Weighted Rank Correlation Using Gain The selection of the mixture weights of  X   X  might somehow be arbitrary  X  an experimenter may choose a series of mixture weights different from that chosen by another experimenter and the evaluation results may hardly be comparable. This may turn out to be a danger whenever competitor observed rankings are compared with the reference ranking, especially if the details of the experiments are incomplete or imprecise. The problem is to define, in a principled way, the mixture weights so that the concordances, and the proportion of concordant items occurring at the top ranks are given higher mixture weight than those occurring at the bottom ranks. For making the choice of the mixture weights less arbitrary, the notions of gain and of cumulative gain for IR evaluation proposed in [3] and briefly reviewed in Section 5.2, have been utilized in this paper.
The basic idea underlying the utilization in this paper of the notions of gain and of cumulative gain for IR evaluation proposed in [3] has been that w i should measure the preference expressed by the user in picking the item at rank i which is then used to count the number of concordant items ranked before i .Themore relevant, useful or interesting the item is perceived, the higher the probability this item is considered for measuring the con cordance. In this way, the concordances with the items perceived more relevant t han others are weighted higher than the concordances with the least relevant items. This criterion is rendered as that is, the concordances with an item ranked at i will be weighted proportionally to the gain of the item. It follows that thus showing that the mixture weight depends on both the degree of relevance of r i and the rank of r i in the observed ranking.

Suppose that r i has been picked at random with probability w i .IfG( r i )is relatively high, then the dis/concordances will highly be weighted  X  the concor-dances will have a relatively high p ( i ) which is multiplied by w i . Suppose also that the reference ranking is based on G , that is, the items are ranked by G in the reference ranking so that the most relevant are on the top of the list. When the number C ( i ) of concordances at rank i with the reference ranking is high, many other items that are at least as relevant as the picked item are ranked on top of the observed ranking, thus indicating that the observed ranking is highly correlated with the reference ranking. The number of concordances between pairs of highly relevant items will be weight ed higher than number of concordances between pairs of less relevant items due to G( i )inEquation3.

Suppose, for example, that the items of the reference ranking (1 , 2 , 3 , 4 , 5) are 7 concordant pairs both in the observed ranking (1 , 2 , 5 , 4 , 3) and in the observed ranking (3 , 1 , 2 , 5 , 4). The value of  X   X  for the first observed ranking is ranking becomes 2( 3 7  X  0+ 3 7  X  1 2 + 1 7  X  3 3 + 1 7  X  3 4 )  X  1. 5.4 The Probability Distribution of the Family of Rank Correlation To judge the significance of an observed value of rank correlation with respect to a reference ranking, it is necessary to compare the observed ranking with that which would be observed if the ranking were formed randomly, i.e. it could be observed with uniform probability. Suppose that the null hypothesis of incorre-lation holds. In [4] it was shown that  X  w is approximately Normal. In particular, when v ij = v ji = v i ,itcanbeshownthat  X   X  is approximately Normal with mean zero and variance 4  X  2 v / 9 n  X  v where  X  v =( i v i ) /n and  X  2 v = i v 2 i /n .
As the v i  X  X  can easily defined using the G( r i ) X  X , the sampling distribution is readily available and the observed value of the  X   X  can be checked against the Normal distribution for testing the null hypothesis of non-correlation, that is,
After substituting v i with 1 i  X  1 , the limiting probability distribution of  X  AP can easily be obtained.

The relevance of the limiting convergence to the Normal distribution is that the experimenter can infer if an observed ranking, and then the algorithm which produced it, is significantly different from the reference ranking produced by an alternative algorithm. While rank correlation has extensively been studied in many different domains, it was rarely addressed by paying attention to the particular issues of IR. One of these issues is related to the importance of the items, the latter being an aspect often not considered in other domains because the rankings are relatively short or the items are not provided with a degre e of relevance. In IR, on the contrary, the items are often provided with a deg ree of relevance, thus making the error of placing a highly relevant item on the bottom worse than the error of placing a little relevant item.

The proposed RCC family can have an impact on evaluation since provides the experimenter with a measure to com pare rankings when the degree of rel-evance are non-binary and has to play a role in the comparison. However,  X   X  cannot always be applied. Indeed, there may be situations in which the degree of relevance is not available or does not make sense; for example, when compar-ing retrieval systems, it is difficult to say that a system is more important than another.

