 If unsupervised morphological segmenters could ap-proach the effectiveness of supervised ones, they would be a very attractive choice for improving ma-chine translation (MT) performance in low-resource inflected languages. An example of particular cur-rent interest is Arabic, whose various colloquial di-alects are sufficiently different from Modern Stan-dard Arabic (MSA) in lexicon, orthography, and morphology, as to be low-resource languages them-selves. An additional advantage of Arabic for study is the availability of high-quality supervised seg-menters for MSA, such as MADA (Habash and Rambow, 2005), for performance comparison. The MT gain for supervised MSA segmenters on dialect establishes a lower bound, which the unsupervised segmenter must exceed if it is to be useful for dialect. And comparing the gain for supervised and unsuper-vised segmenters on MSA tells us how useful the unsupervised segmenter is, relative to the ideal case in which a supervised segmenter is available.
In this paper, we show that an unsupervised seg-menter can in fact rival or surpass supervised MSA segmenters on MSA itself, while at the same time providing superior performance on dialect. Specifi-cally, we compare the state-of-the-art morphological analyzer of Lee et al. (2011) with two leading super-vised analyzers for MSA, MADA and Sakhr 1 , each serving as an alternative preprocessor for a state-of-the-art statistical MT system (Shen et al., 2008). We measure MSA performance on NIST MT-08 (NIST, 2010), and dialect performance on a Levantine di-alect web corpus (Zbib et al., 2012b).

To improve performance, we apply maximum marginal decoding (Johnson and Goldwater, 2009) (MM) to combine multiple runs of the Lee seg-menter, and show that this dramatically reduces the variance and noise in the segmenter output, while yielding an improved segmentation accuracy that exceeds the best published scores for unsupervised segmentation on Arabic Treebank (Naradowsky and Toutanova, 2011). We also show that it yields MT-08 BLEU scores that are higher than those obtained with MADA, a leading supervised MSA segmenter. For Levantine, the segmenter increases BLEU score by 18% over the unsegmented baseline. Machine translation systems that process highly in-flected languages often incorporate morphological analysis. Some of these approaches rely on mor-phological analysis for pre-and post-processing, while others modify the core of a translation system to incorporate morphological information (Habash, 2008; Luong et al., 2010; Nakov and Ng, 2011). For instance, factored translation Models (Koehn and Hoang, 2007; Yang and Kirchhoff, 2006; Avramidis and Koehn, 2008) parametrize translation probabili-ties as factors encoding morphological features.
The approach we have taken in this paper is an instance of a segmented MT model, which di-vides the input into morphemes and uses the de-rived morphemes as a unit of translation (Sadat and Habash, 2006; Badr et al., 2008; Clifton and Sarkar, 2011). This is a mainstream architecture that has been shown to be effective when translating from a morphologically rich language.

A number of recent approaches have explored the use of unsupervised morphological analyzers for MT (Virpioja et al., 2007; Creutz and Lagus, 2007; Clifton and Sarkar, 2011; Mermer and Ak X n, 2010; Mermer and Saraclar, 2011). Virpioja et al. (2007) apply the unsupervised morphological seg-menter Morfessor (Creutz and Lagus, 2007), and apply an existing MT system at the level of mor-phemes. The system does not outperform the word baseline partially due to the insufficient accuracy of the automatic morphological analyzer.

The work of Mermer and Ak X n (2010) and Mer-mer and Saraclar (2011) attempts to integrate mor-phology and MT more closely than we do, by in-corporating bilingual alignment probabilities into a Gibbs-sampled version of Morfessor for Turkish-to-English MT. However, the bilingual strategy shows no gain over the monolingual version, and nei-ther version is competitive for MT with a super-vised Turkish morphological segmenter (Oflazer, 1993). By contrast, the unsupervised analyzer we report on here yields MSA-to-English MT perfor-mance that equals or exceed the performance ob-tained with a leading supervised MSA segmenter, MADA (Habash and Rambow, 2005). The segmenter of Lee et al. (2011) is a probabilis-tic model operating at word-type level. It is di-vided into four sub-model levels. Model 1 prefers small affix lexicons, and assumes that morphemes are drawn independently. Model 2 generates a la-tent POS tag for each word type, conditioning the word X  X  affixes on the tag, thereby encouraging com-patible affixes to be generated together. Model 3 incorporates token-level contextual information, by generating word tokens with a type-level Hidden Markov Model (HMM). Finally, Model 4 models morphosyntactic agreement with a transition proba-bility distribution, encouraging adjacent tokens with the same endings to also have the same final suffix. Maximum marginal decoding (Johnson and Gold-water, 2009) (MM) is a technique which assigns to each latent variable the value with the high-est marginal probability, thereby maximizing the expected number of correct assignments (Rabiner, 1989). Johnson and Goldwater (2009) extend MM to Gibbs sampling by drawing a set of N indepen-dent Gibbs samples, and selecting for each word the most frequent segmentation found in them. They found that MM improved segmentation accuracy over the mean, consistent with its maximization cri-terion. However, for our setting, we find that MM provides several other crucial advantages as well.
First, MM dramatically reduces the output vari-ance of Gibbs sampling (GS). Table 1 documents the severity of this variance for the MT-08 lexicon, as measured by the average exact-match accuracy and segmentation F-measure between different runs. It shows that on average, 13% of the word tokens, and 25% of the word types, are segmented differently from run to run, which obviously makes the input to MT highly unstable. By contrast the  X  X M X  column of Table 1 shows that two different runs of MM, each derived by combining separate sets of 25 GS runs, agree on the segmentations of over 95% of the word token  X  a dramatic improvement in stability.
Second, MM reduces noise from the spurious af-fixes that the unsupervised segmenter induces for large lexicons. As Table 2 shows, the segmenter Decoding Level Rec Prec F1 Acc Gibbs Type 82.9 83.2 83.1 74.5 MM Type 95.9 95.8 95.9 93.9 induces 130 prefixes and 261 suffixes for MT-08 (statistics for Morfessor are similar). This phe-nomenon is fundamental to Bayesian nonparamet-ric models, which expand indefinitely to fit the data they are given (Wasserman, 2006). But MM helps to alleviate it, reducing unique prefixes and suffixes for MT-08 by 28% and 21%, respectively. It also re-duces the number of unique prefixes/suffixes which account for 95% of the prefix/suffix tokens ( Top-95 ).
Finally, we find that in our setting, MM increases accuracy not just over the mean, but over even the best -scoring of the runs. As shown in Table 3, MM increases segmentation F-measure from 86.2% to 88.2%. This exceeds the best published results on ATB (Naradowsky and Toutanova, 2011).

These results suggest that MM may be worth con-sidering for other GS applications, not only for the accuracy improvements pointed out by Johnson and Goldwater (2009), but also for its potential to pro-vide more stable and less noisy results.
 5.1 Experimental Design MT System . Our experiments were performed using a state-of-the-art, hierarchical string-to-dependency-tree MT system, described in Shen et al. (2008).
 Morphological Analyzers . We compare the Lee segmenter with the supervised MSA segmenter MADA, using its  X  X 3 X  scheme. We also compare with Sakhr, an intensively-engineered, supervised MSA segmenter which applies multiple NLP tech-nologies to the segmentation problem, and which has given the best results for our MT system in pre-vious work (Zbib et al., 2012a). We also compare with Morfessor.
 MT experiments . We apply the appropriate seg-menter to split words into morphemes, which we then treat as words for alignment and decoding. Fol-lowing Lee et al. (2011), we segment the test and training sets jointly, estimating separate translation models for each segmenter/dataset combination. Training and Test Corpora . Our  X  X ull MSA X  cor-pus is the NIST MT-08 Constrained Data Track Ara-bic training corpus (35M total, 336K unique words); our  X  X mall MSA X  corpus is a 1.3M-word subset. Both are tested on the MT-08 evaluation set. For dialect, we use a Levantine dialectal Arabic cor-pus collected from the web with 1.5M total, 160K unique words and 18K words held-out for test (Zbib et al., 2012b) Performance Metrics . We evaluate MT with BLEU score. To calculate statistical significance, we use the boot-strap resampling method of Koehn (2004). 5.2 Results and Discussion Table 4 summarizes the BLEU scores obtained from using various segmenters, for three training/test sets: Full MSA, Small MSA, and Levantine dialect. As expected, Sakhr gives the best results for MSA. Morfessor underperforms the other seg-menters, perhaps because of its lower accuracy on Arabic, as reported by Poon et al. (2009). The Lee segmenter gives the best results for Levantine, inducing valid Levantine affixes (e.g  X  X Al+ X  for MSA X  X   X  X *A-Al+ X , English  X  X his-the X ) and yielding an 18% relative gain over the unsegmented baseline.
What is more surprising is that the Lee segmenter compares favorably with the supervised MSA seg-menters on MSA itself. In particular, the Lee seg-menter with MM yields higher BLEU scores than does MADA, a leading supervised segmenter, while preserving almost the same performance as GS on dialect. On Small MSA, it recoups 93% of even Sakhr X  X  gain.

By contrast, the Lee segmenter recoups only 79% of Sakhr X  X  gain on Full MSA. This might result from the phenomenon alluded to in Section 4, where addi-tional data sometimes degrades performance for un-supervised analyzers. However, the Lee segmenter X  X  gain on Levantine (18%) is higher than its gain on Small MSA (13%), even though Levantine has more data (1.5M vs. 1.3M words). This might be be-cause dialect, being less standardized, has more or-thographic and morphological variability, which un-supervised segmentation helps to resolve.

These experiments also show that while Model 4 gives the best F-score, Model 3 gives the best MT scores. Comparison of Model 3 and 4 segmentations shows that Model 4 induces a much larger num-ber of inflectional suffixes, especially the feminine singular suffix  X -p X , which accounts for a plurality (16%) of the differences by token. While such suf-fixes improve F-measure on the segmentation refer-ences, they do not correspond to any English lexical unit, and thus do not help alignment.

An interesting question is how much performance might be gained from a supervised segmenter that was as intensively engineered for dialect as Sakhr was for MSA. Assuming a gain ratio of 0.93, similar to Small MSA, the estimated BLEU score would be 20.38, for a relative gain of just 5% over the unsuper-Lee GS Lee MM vised segmenter. Given the large engineering effort that would be required to achieve this gain, the un-supervised segmenter may be a more cost-effective choice for dialectal Arabic. We compare unsupervised vs. supervised morpho-logical segmentation for Arabic-to-English machine translation. We add maximum marginal decoding to the unsupervised segmenter, and show that it surpasses the state-of-the-art segmentation perfor-mance, purges the segmenter of noise and variabil-ity, yields BLEU scores on MSA competitive with those from supervised segmenters, and gives an 18% relative BLEU gain on Levantine dialectal Arabic. Acknowledgements This material is based upon work supported by DARPA under Contract Nos. HR0011-12-C00014 and HR0011-12-C00015, and by ONR MURI Con-tract No. W911NF-10-1-0533. Any opinions, find-ings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the US government. We thank Rabih Zbib for his help with interpreting Levantine Arabic segmentation output.
