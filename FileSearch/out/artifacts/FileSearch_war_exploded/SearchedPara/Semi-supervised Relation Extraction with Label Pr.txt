 Relation extraction is the task of finding relation-ships between two entities from text. For the task, many machine learning methods have been pro-posed, including supervised methods (Miller et al., 2000; Zelenko et al., 2002; Culotta and Soresen, 2004; Kambhatla, 2004; Zhou et al., 2005), semi-supervised methods (Brin, 1998; Agichtein and Gra-vano, 2000; Zhang, 2004), and unsupervised method (Hasegawa et al., 2004).

Supervised relation extraction achieves good per-formance, but it requires a large amount of manu-ally labeled relation instances. Unsupervised meth-ods do not need the definition of relation types and manually labeled data, but it is difficult to evaluate the clustering result since there is no relation type label for each instance in clusters. Therefore, semi-supervised learning has received attention, which can minimize corpus annotation requirement.

Current works on semi-supervised resolution for relation extraction task mostly use the bootstrap-ping algorithm, which is based on a local consis-tency assumption : examples close to labeled ex-amples within the same class will have the same labels. Such methods ignore considering the simi-larity between unlabeled examples and do not per-form classification from a global consistency view-point, which may fail to exploit appropriate mani-fold structure in data when training data is limited.
The objective of this paper is to present a label propagation based semi-supervised learning algo-rithm (LP algorithm) (Zhu and Ghahramani, 2002) for Relation Extraction task. This algorithm works by representing labeled and unlabeled examples as vertices in a connected graph, then propagating the label information from any vertex to nearby vertices through weighted edges iteratively, finally inferring the labels of unlabeled examples after the propaga-tion process converges. Through the label propaga-tion process, our method can make the best of the information of labeled and unlabeled examples to re-alize a global consistency assumption : similar ex-amples should have similar labels. In other words, the labels of unlabeled examples are determined by considering not only the similarity between labeled and unlabeled examples, but also the similarity be-tween unlabeled examples. 2.1 Problem Definition Let X = { x i } n of all entity pairs, where x i represents the contexts of the i -th occurrence, and n is the total number of occurrences of all entity pairs. The first l examples are labeled as y g ( y g  X  X  r j } R type and R is the total number of relation types). And the remaining u ( u = n  X  l ) examples are unla-beled.

Intuitively, if two occurrences of entity pairs have the similar contexts, they tend to hold the same re-lation type. Based on this assumption, we create a graph where the vertices are all the occurrences of entity pairs, both labeled and unlabeled. The edge between vertices represents their similarity. Then the task of relation extraction can be formulated as a form of propagation on a graph, where a vertex X  X  label propagates to neighboring vertices according to their proximity. Here, the graph is connected with the weights: W ij = exp (  X  s 2 ij ilarity between x i and x j calculated by some simi-larity measures. In this paper,two similarity mea-sures are investigated, i.e. Cosine similarity measure and Jensen-Shannon (JS) divergence (Lin, 1991). And we set  X  as the average similarity between la-beled examples from different classes. 2.2 Label Propagation Algorithm Given such a graph with labeled and unlabeled ver-tices, we investigate the label propagation algorithm (Zhu and Ghahramani, 2002) to help us propagate the label information of any vertex in the graph to nearby vertices through weighted edges until a global stable stage is achieved.
 Define a n  X  n probabilistic transition matrix T T ij = P ( j  X  i ) = ability to jump from vertex x j to vertex x i . Also de-fine a n  X  R label matrix Y , where Y ij representing the probabilities of vertex y i to have the label r j .
Then the label propagation algorithm consists the following main steps:
Step1: Initialization Firstly, set the iteration in-dex t = 0 . Then let Y 0 be the initial soft labels at-tached to each vertex and Y 0 which is consistent with the labeling in labeled data ( be the remaining u rows corresponding to unlabeled data points and its initialization can be arbitrary.
Step 2: Propagate the label by Y t +1 = TY t , where T is the row-normalized matrix of T , i.e. T probability interpretation.

Step 3: Clamp the labeled data , i.e., replace the top l row of Y t +1 with Y 0 data is clamped to replenish the label sources from these labeled data. Thus the labeled data act like sources to push out labels through unlabeled data. Step 4: Repeat from step 2 until Y converges.
Step 5: Assign x h ( l + 1  X  h  X  n ) with a label: y h = argmax j Y hj . 3.1 Data Our proposed graph-based method is evaluated on sources including broadcast, newswire, and news-paper. A break-down of the tagged data by different relation subtypes is given in Table 1. 3.2 Features We extract the following lexical and syntactic fea-tures from two entity mentions, and the contexts be-fore, between and after the entity pairs. Especially, we set the mid-context window as everything be-tween the two entities and the pre-and post-context as up to two words before and after the correspond-ing entity. Most of these features are computed from the parse trees derived from Charniak Parser (Char-Sabine Buchholz from Tilburg University.
Words: Surface tokens of the two entities and three context windows.

Entity Type: the entity type of both entity men-tions, which can be PERSON, ORGANIZATION, FACILITY, LOCATION and GPE.

POS: Part-Of-Speech tags corresponding to all tokens in the two entities and three context windows. Chunking features: Chunk tag information and Grammatical function of the two entities and three context windows. IOB-chains of the heads of the two entities are also considered. IOB-chain notes the syntactic categories of all the constituents on the path from the root node to this leaf node of tree.
We combine the above features with their position information in the context to form the context vec-tor. Before that, we filter out low frequency features which appeared only once in the entire set. 3.3 Experimental Evaluation 3.3.1 Relation Detection
We collect all entity mention pairs which co-occur in the same sentence from the training and devtest corpus into two set C 1 and C 2 respectively. The set C 1 includes annotated training data AC 1 and un-related data UC 1 . We randomly sample l examples from AC 1 as labeled data and add a  X  X ONE X  class into labeled data for the case where the two entity mentions are not related. The data of the  X  X ONE X  class is resulted by sampling l examples from UC 1 . Moreover, we combine the rest examples of C 1 and the whole set C 2 as unlabeled data .
 Given labeled and unlabeled data,we can perform LP algorithm to detect possible relations, which are those entity pairs that are not classified to the  X  X ONE X  class but to the other 24 subtype classes. In addition,we conduct experiments with different sampling set size l , including 1%  X  N train , 10%  X  N 100%  X  N train ( N train = | AC 1 | ). If any major subtype was absent from the sampled labeled set,we redo the sampling. For each size,we perform 20 tri-als and calculate an average of 20 random trials. 3.3.2 SVM vs. LP
Table 2 reports the performance of relation detec-tion by using SVM and LP with different sizes of labled data. For SVM, we use LIBSVM tool with beled data used in LP is used to train SVM mod-els. From Table 2, we see that both LP Cosine and LP JS achieve higher Recall than SVM. Especially, with small labeled dataset (percentage of labeled data  X  25% ), this merit is more distinct. When the percentage of labeled data increases from 50% to 100% , LP Cosine is still comparable to SVM in F-measure while LP JS achieves better F-measure than SVM. On the other hand, LP JS consistently outper-
Table 3 reports the performance of relation classi-fication, where the performance describes the aver-age values over major relation subtypes. From Table 3, we see that LP Cosine and LP JS outperform SVM by F-measure in almost all settings of labeled data, which is due to the increase of Recall . With smaller labeled dataset, the gap between LP and SVM is larger. On the other hand, LP JS divergence consis-tently outperforms LP Cosine . 3.3.3 LP vs. Bootstrapping
In (Zhang, 2004), they perform relation classifi-cation on ACE corpus with bootstrapping on top of SVM. To compare with their proposed Bootstrapped SVM algorithm, we use the same feature stream set-ting and randomly selected 100 instances from the training data as the size of initial labeled data.
Table 4 lists the performance on individual rela-tion type. We can find that LP algorithm achieves 6.8% performance improvement compared with the (Zhang, 2004) X  X  bootstrapped SVM algorithm aver-age on all five relation types. Notice that perfor-mance reported on relation type  X  X EAR X  is low, be-cause it occurs rarely in both training and test data. This paper approaches the task of semi-supervised relation extraction on Label Propagation algorithm. Our results demonstrate that, when only very few labeled examples are available, this manifold learn-ing based algorithm can achieve better performance than supervised learning method (SVM) and boot-strapping based method, which can contribute to minimize corpus annotation requirement. In the fu-ture we would like to investigate how to select more useful feature stream and whether feature selection method can improve the performance of our graph-based semi-supervised relation extraction.

