 1. Introduction large training set, which makes batch-mode global optimization algorithms inefficient or even impractical.  X  propose a new Life-Long Learning from Mistakes (3LM) algorithm that: 1. Learns to classify documents on a per-example basis and never stops learning, adapting to evolving data; 2. Uses negative feedback to reinforce learning (learning with a critic); (class means); 4. Provably converges for hyperplane-separable classes; 5. Experimentally demonstrates better accuracy than centroid-based document classification algorithms; 6. Demonstrates better performance than centroid-based, Na X ve Bayes, C4.5, AdaBoost, kNN, and SVM algorithms; back may be available, e.g., facebook/twitter feed classification.

The main contribution of the 3LM algorithm is in avoiding over-smoothing mar, Aseri, &amp; Patel, 2009 ) to denote various things not directly related to our use of it. 2. Related work 2.1. Related work on machine learning converge (see Section 3.3 ).

Document classification a number of methods were proposed for document classification. Examples of document clas-3LM X  X  superiority. We also show that 3LM outperforms AdaBoost and SVM-based classifiers. classes and class assignments over time.
 the users in the classification process. 2.2. Review of centroid-based algorithms clustering algorithms. In this section we overview their features relevant for the 3LM. 2.2.1. Batch-mode centroid-based classification each of the classes. That is, for each document class D k the centroids l k :
The document is then classified as belonging to the class of the highest ranking centroid: argmax et al., 2000 ). 2.2.2. Batch-mode K-means clustering using vector normalization ( Dhillon &amp; Modha, 2001 ) is one of the fastest document clustering algorithms. 2.2.3. Online K-means clustering of the K-means clustering try to minimize the mean-squared error: where N is the number of documents and k ( d ) = argmin k e {1, ... K } similarity between centroids and vectors: where k ( d ) = argmax k e {1, ... , K } [ cos ( l k , d )] is the index of the centroid l sification uses this same k ( d ) to determine document class assignment.
 2.2.4. Convergence of centroid-based algorithms depends on a decreasing learning rate. 2.2.5. Lifelong learning quires that every new document be supplied with the correct class label. 3. Lifelong learning for document classification of 3LM for hyper-plane-separable classes. 3.1. Intuition for learning from mistakes 3.1.1. Human-supervised classification classification. Thus, an algorithm relying on user feedback should learn from classification mistakes. 3.1.2. Learning from mistakes corresponding to the plus and minus classes are marked as #1.1 red based class assignments are shown with solid ovals, misclassifying two of the plus documents. 3.1.3. Centroids vs. clusterheads fit. We will make a clear distinction between centroids and clusterheads for the remainder of this paper. 3.1.4. Competitive balancing of clusterheads are diffused.
 will  X  X  X scillate X  X  between the misclassified documents, competing for dominance. how to deal with this (Sections 3.1.9, 3.1.10, and 3.1.11 ). 3.1.5. Comparing with centroid-based classifier heads is an example of competitive learning ( Biehl, Freking, &amp; Reents, 1997; King &amp; Lau, 1997 ). 3.1.6. Squared error vs. classification error solution to the problem of minimizing the error rate is NP-complete (Section 3.3 ). 3.1.7. Adapting to changes otherwise misclassified. Equally pulled in all directions, a clusterhead will come to a balanced state. 3.1.8. Over-fitting 3.1.9. Passing of the clusterheads the wrong labels. 3.1.10. Detecting clusterhead passing can then use the results of the classification and the reported errors to incrementally approximate the centroids. 3.1.11. Clusterheads on a leash errors. 3.2. The 3LM algorithm
We now describe the architecture of the 3LM classifier and present its training algorithm. 3.2.1. The description of the classifier on centroids, instead of clusterheads, results in higher misclassification rate. 3.2.2. Initialization
The 3LM algorithm maintains sets X ={ x 1 , ... , x K } and M = { l
K = 0, both X and M are empty. When a document d from a new, previously unseen class arrives, d is added to both X and M (and K is increased by 1). 3.2.3. Classification algorithm heads to classify them and the approximated centroids to prevent over-fitting: Algorithm classifyDocument Input: d : normalized document vector; a : learning rate of centroids; X ={ x 1 , ... , x K }: set of all normalized clusterheads;
M ={ l 1 , ... , l K }: set of all normalized approx. centroids; c argmax fixPassing({ l c }, X ) return c clusterhead is incrementally adjusted with a fixed learning rate a : l adjusting the clusterhead if the document is reported as misclassified. 3.2.4. Training algorithm Algorithm TrainClassifier
Input: d : normalized document vector; c : index of the correct class for document d ; M ={ l 1 , ... , l K }: a set of all normalized approximated centroids;
X ={ x 1 , ... , x K }: a set of all normalized clusterheads; a learning rate of centroids; b learning rate of clusterheads; e argmax if e = c then return c l c + a d , fixPassing({ l c }, X ) e x e b d , fixPassing( M ,{ x e }) c x c + b d , fixPassing( M ,{ x c }) given to all clusterheads found closer to the document than the correct clusterhead: x cos ( x c , d ). TrainClassifier formally describes the procedure. 3.2.5. Clusterheads on a leash accordingly: Algorithm fixPassing ( M , X ) Input: M ={ l 1 , ... , l n }: a set of relevant centroids;
X ={ x 1 , ... , x m }: a set of relevant clusterheads; for i 1tom:
The while loop of fixPassing works as follows: The equation cos ( x troids l i and l j ; the new position of the clusterhead is at the intersection of the segment x executed up to n times, in our experiments we never moved the clusterhead more than once. 3.2.6. Applying tf.idf testing the 3LM classifier with or without stop words has little effect on its overall accuracy. 3.3. Convergence of 3LM
We next prove the convergence of 3LM for hyper-plane separable classes and give a proof of NP-completeness for the algorithm minimizing the classification error.
 3.3.1. Convergence with negative rewards is the cosine similarity of the  X  X  X orst X  X  document in X , then after at most K =1/ t ing process would work if the documents of class N were not negated.

The clusterhead x i from one-class learning is the clusterhead of the positive class P ; denote it by P learning, the clusterhead of the original negative documents was simply w looks in terms of positive/negative rewards, let us restate the scheme as follows:
If a positive document x is misclassified, do P i +1 = P i do P i +1 = P i +( x ), N i +1 = P i +1 = N i + x , that is: and punish the clusterhead of the incorrect class.
 Let us now consider learning with positive reward only: normal to the plane, for all " x X k ,mx w k &gt; 0. Let t when negative rewards are also used. This motivated us to use negative rewards in our experiments. 3.3.2. Minimizing classification error is NP-hard ey &amp; Johnson, 1979 , p. 246). 4. Empirical evaluation ition and the theory presented in this paper. 4.1. Classification corpora three datasets widely used for testing single-class document classifiers: (1) Reuters21578 (2) OHSUMED 4  X  a collection of medical documents; and (3) TREC07p Spam selected a subset of single-topic documents, which we divided into two sets: 80% training and 20% testing. 7448 training and 1862 testing documents.

We chose a fully labeled subset of the TREC 2007 dataset, which contained 75,419 email messages. However, since we required frequent accuracy sampling for the experiments, we only picked a random subset of 10,000 email messages: 8031 spam and 1968 ham emails. These sets were divided into 8000 training and 2000 testing documents. 4.2. Experiments on a fixed dataset 4.2.1. Experimental setup
We did 5-fold cross-validation with 80% training and 20% testing documents performing 50 iterations on each of the 4.2.2. Summary of results removes possible bias of the results. 4.2.3. Batch centroid-based classifier showing less than 50% performance on the test part. 4.2.4. Online centroid-based classifier tor d k was used to incrementally adjust the position of the corresponding class-centroid ( l the training and testing subsets of the datasets. 4.2.5. 3LM classifier 9 . 4.2.6. Comparative analysis curves demonstrate how the 3LM algorithm fits the training data without over-fitting on the testing datasets. produce over-smoothed models, we believe that the degradation was due to the training data.
The online centroid-based classifier showed much worse over-fitting on the TREC07p spam corpus, losing to 3LM over ety of documents, including large attachments. 4.2.7. Other classifiers et al. (2009) .) 4.3. Life-long learning experiments 4.3.1. Training on the streaming data puted for every 10,000 documents.
 actual distribution of the news articles in the testing dataset. 4.3.2. Evolutionary experiment classes were hyper-plane separable, as discussed in Section 3 . 4.4. Robustness of the algorithm 4.4.1. Tolerance to random feedback errors do less than 20% mistakes. 4.4.2. Variation of the learning rate differing positive and negative rewards had almost no effect on the overall accuracy of the classifier. 4.4.3. Stop words overall accuracy of the 3LM classifier. 5. Significance and impact 5.1. Applications ing messages as spam, thus, giving negative feedback and allowing the spam filter to learn from its mistakes.
Torch, and LibSVM do not achieve high accuracy on the Reuters dataset. 5.2. Unique features leashing the clusterheads to the less agile centroids. 6. Conclusion and future work the standard Reuters, OHSUMED, and TREC07p datasets.
 (e.g., term stems, tf.idf weighted vectors), could be used in the classification. also in applications outside the document classification domain.
 Acknowledgment
We thank the anonymous reviewers for their many helpful comments which greatly improved the presentation. VP is funded by the Academy of Finland grant 138520.
 References
