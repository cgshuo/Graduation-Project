 The goal of combustion optimization of a coal-fired boiler is to improve its operating efficiency while reducing emissions at the same time. Being able to take measurements for key combustion ingredients, such as O2, CO, H2O is crucial for the feedback loop needed by this task. One state-of-the-art laser technique, namely, Tunable Diode Laser Absorption Spectroscopy (TDLAS) is able to measure the average value of gas concentration along a laser beam path. A active re-search direction in TDLAS is how to reconstruct gas concen-tration images based on these path averages. However, in reality the number of such paths is usually very limited, lead-ing to an extremely under-constrained estimation problem. Another overlooked aspect of the problem is that how can we arrange paths such that the reconstructed image is more accurate? We propose a Bayesian approach based on Gaus-sian process (GP) to address both image reconstruction and path arrangement problems, simultaneously. Specifically, we use the GP posterior mean as the reconstructed image, and average posterior pixel variance as our objective function to optimize the path arrangement. Our algorithms have been integrated in Siemens SPPA-P3000 control system that pro-vides real-time combustion optimization of boilers around the world.
 J.6 [ Computer Applications ]: COMPUTER-AIDED EN-GINEERING; I.4.5 [ Computing Methodologies ]: IM-AGE PROCESSING AND COMPUTER VISION X  Recon-struction Gaussian process; TDLAS; combustion optimization
The capability of reconstructing gas (e.g., of O2, CO) con-centration images inside the combustion zone is very useful c  X  Figure 1: Illustration of gas concentration recon-struction. The left plot shows the geometry of an op-erating coal-fired boiler. Our goal is to reconstruct 2D cross section gas concentration images (bottom right). To achieve this, TDLAS paths are installed on the wall of a boiler. Each path reads the average gas value along the path (top right). for visualizing, optimizing and monitoring the performance of a coal-fired boiler. The technique of tunable diode laser absorption spectroscopy (TDLAS) has received increasing interests due to its fast responsive speed, high sensitivity and non-invasiveness[7]. A single TDLAS setup consists of a laser transmitter sending laser beams over a path through the combustion region to a laser receiver. Each TDLAS path measures an average value of the gas concentrations along the path. Our goal is to reconstruct the 2D gas concentra-tion image based on multiple path averages (or projections), as illustrated in Fig.1.

There are two challenges for this task. First, given the paths, how can we accurately reconstruct the image? This concept is similar to that of computed tomography (CT) (Chapter 3 in [9]). However, most widely used CT algo-rithms such as filtered back-projection require a lot of pro-jections (multiple views and dense projections per view) to achieve a good resolution. In contrast, only a very small number of paths are typically set up on a boiler; for example, it is not uncommon that we only have five to 15 paths (pro-jections), which leads to an extremely under-constrained problem. Second, how do we best arrange paths such that the reconstructed image is even more precise? In reality, there are some constraints to consider. For example, a path may not be installed at a location or a direction (view) that we desire because of certain restrictions or mounting diffi-culties of a boiler. For the first estimation problem, many previous methods have been proposed, however, few of them have tackled the case with only about ten paths that we study here [12, 11, 1, 6, 20]. In addition, to the best of our knowledge, we haven X  X  seen an existing approach addressing the second optimization problem.
 In this paper, we present a Bayesian approach based on Gaussian process to tackle both estimation and optimization problems under the same framework. The 2D unknown im-age is modeled by a Gaussian process, a multivariate Gaus-sian distribution with pixel coordinates as its inputs. This naturally introduces long-range smoothness constraints such that neighboring pixels have similar values. Given the path projections, the image has a posterior Gaussian distribution with a posterior mean and covariance. We use the mean as the reconstructed image because it is optimal in terms of mean squared error. The posterior covariance indicates the uncertainty of the image. We propose to use the trace of this covariance matrix, or the sum of posterior variances for all pixels, as the objective function of a path arrange-ment. By minimizing this function, we become more cer-tain about our reconstruction and thus expect to get more accurate results. In addition, our objective function offers a fast and effective way to evaluate and compare existing path arrangements. Our algorithms have been integrated in Siemens SPPA-P3000 control system for real-time combus-tion optimization applications.

The rest of this paper is organized as follows. In Sect.2, we review previous work. In Sect.3, we define our reconstruc-tion problem. The proposed model is described in Sect.4. We present test results in Sect.5 and conclude this paper in Sect.6.
Tomographic techniques such as algebraic reconstruction technique (ART) have been proposed to handle the issue of a small number of projections [9, 20, 12]. However, ART updates the estimate only using one path in each iteration, which usually leads to a slow convergence and  X  X alt-and-pepper X  noise [6]. Extensions such as simultaneous iterative reconstructive technique (SIRT) [9], simultaneous algebraic reconstruction technique (SART) [9] and multiplicative al-gebraic reconstruction technique (MART) [6] can update es-timation using all paths in each iteration. Although proven to find an image complying to path projections, these ART-based approaches don X  X  offer a way to check if the recon-structed image is realistic or not.

Smoothness constraints among neighboring pixels are in-troduced as prior information to help addressing this under-constrained problem. Smoothness can be incorporated via smooth basis functions [15, 3]. [15, 3] also apply 1D smooth basis functions to multiple path averages under the same view. [1] correlates two pixels if they are both close to a path. However, such smoothness constraints are local and cannot capture long-range correlation among pixels.
Longer range smoothness can be achieved via the Tikhonov regularization (TR) [6]. This algorithm explicitly enforces a local smoothness constraint: every pixel value should be similar to the average of its neighbors X . Two pixels far apart are implicitly linked via all such local smoothness constraints Figure 2: Gas concentration reconstruction problem definition. Paths, available regions and region of in-terest (ROI) are denoted by blue lines, red lines and green boxes, respectively. The boiler cross section, as shown, has a width of 1 and a height of 1 . There are M = 5 paths. The image size is N = 10  X  10 = 100 . between them. The TR method can be viewed as a special case of Gaussian random fields [22], which assign weights to every pair of pixels in the image (instead of only neighboring pixels as done in the TR). Gaussian process is widely used in computer vision for applications such as super resolution [18, 17], which motivates our previous work [21]. It has been revealed that both Gaussian random fields and Gaus-sian process model long range smoothness via the covariance matrix of a Gaussian distribution, but they do this differ-ently. The former models the inverse of the covariance while the latter directly depicts the covariance [22].

Finally, all previous gas concentration approaches assume a fixed path arrangement. The most widely used configu-rations involve multiple views, each with multiple parallel paths [12, 11, 1, 6, 20]. These approaches may not be feasi-ble if there are mounting restrictions about where a path can or cannot be installed. In contrast, we present an optimiza-tion approach, taking these restrictions into consideration, to find the best path arrangement that can produce more accurate reconstruction results.
Our goal is to reconstruct an w  X  h gas concentration image v from M path averages (projections), denoted by an M -dimensional vector b . w and h are the width and height of the image, respectively. The projections b and image v have the following relation A is an M  X  N projection matrix . Once the paths are config-ured, A becomes a constant matrix. Typically, we represent the image v as a N -dimensional vector for easy algebraic manipulation, where N = w  X  h . To visualize the image, we then convert it into the matrix format. In the example shown in Fig.2, we have w = h = 10, M = 5 paths and we want to estimate the gas concentration at each of the N = 100 grid pixels. There are two tasks involved, recon-struction and path arrangement optimization.
If the paths are already configured, how can we recon-struct the image? We first introduce some terminology. The sum of the m -th row and the sum of the n -th column of A are respectively defined by A m, + = P N n =1 A m,n A + ,n = P M m =1 A m,n . A m -th pixel is termed as observed if there is at least one path crossing it or A + ,n &gt; 0. Otherwise, it is unobserved .
 We now describe how to determine a projection weight A m,n in the projection matrix A . One way is to treat each pixel as a small rectangle, and then compute the ratio of the length of the m -th path intercepted by the n -th pixel to the total length of the m -th path in the domain of interest [21, 6]. One drawback of this approach is that if a pixel doesn X  X  intersect with a path, it has no impact on the path average even if they are next to each other. We adopt a new strategy by treating each pixel as a point (as in Fig.2). We evenly place 1000 sample points along each path. For each sample point, we locate the closest four pixels (vertices of a small rectangle) and compute the bilinear weights of the four pixels regarding this sample point. Then the contribution of a pixel is the sum of its weights for all sample points. By doing this, we can get a smoother projection matrix because more pixels are involved. Finally, we normalize every row such that A m, + = 1, because path projection is a weighted average along the path.

Our reconstruction problem is essentially solving a linear equation (1) with both A and b known. If A is an invertible square matrix, where M = N , then we have v = A  X  1 b as done by [11]. If M &gt; N and A has full rank, based on linear least square we have However, our problem is very under-constrained because of M N . In such a case, we have multiple solutions satisfy-ing the same equation (1).

Simultaneous algebraic reconstruction technique (SART) is one of the most widely used ART algorithms [9]. It has the following iterative procedure v n denotes the current reconstructed image after the q -th iteration. ( Av ( q ) ) m indicates the estimated m -th projection from the current image. Note that in our problem A m, + = 1 and can be omitted from (3), but in general it has a non-zero value. (3) can be understood as follows. The residual be-tween the true projection b m and the estimated projection ( Av ( q ) ) m indicates in which direction v ( q +1) n from v ( q ) n to reduce this residual. The final direction is de-termined by the weighted average of all M projections, each with a weight of A m,n normalized by A + ,n . The magnitude of this movement is adjusted by a parameter  X  .

The SART algorithm is proven to converge to a solution of (1) if A + ,n 6 = 0 [8]. However, there is no guarantee whether the found solution, out of all possible solutions, is realistic or not. In addition, in our application, the path configu-ration can be arbitrary. It often happens that A + ,n for some columns so the n -th pixel is unobserved. In such cases, division-by-zero problem will happen and (3) will stop working.

Tikhonov regularization (TR) is another technique to reg-ularize linear equations [6]. TR adds another set of equations Lv = 0 to enforce smoothness constraint. L is a N  X  N reg-ularization matrix, where each row requires a pixel X  X  value to be identical to the average of its neighbors. Av = b and Lv = 0 are treated similarly in the objective function of ( Av  X  b ) T ( Av  X  b ) +  X  ( Lv ) T ( Lv ) (to be minimized).  X  is a parameter. It can be proved that the solution of TR is The only difference between (4) and (2) is due to the regu-larization term. We previously assume that paths are already configured. How can we arrange paths such that we can get better re-construction results. The boiler cross section is denoted by a rectangle. It has four walls with ID=1 , 2 , 3 , 4 as shown in Fig.2. For some applications, users may only focus on certain region of interest (ROI) (green boxes in Fig.2). By default, ROI is the whole cross section.

Ideally, for every path, it can be mounted between any of these wall pairs. However, under certain circumstances, some regions on a particular wall are not available and thus cannot be used to install a path. The red lines in Fig.2 indicates available regions that can be used for installation. In other words, every end point of a path must be located within an available region.

In either case, we have a combinatorial optimization prob-lem. Suppose that there are K available regions, leading to about of ( K  X  1) K/ 2 region pairs. Then there are about (( K  X  1) K/ 2) M possible arrangements just for assigning re-gion pairs to paths. This complexity has not included the efforts about where the end point of a path should be in a particular available region.

To the best of our knowledge, no prior work has addressed this path arrangement optimization problem. One possible solution is to randomly generate many path arrangements and evaluate each of them against a large number of tests to see which one produce the most accurate reconstruction re-sults. However, due to the aforementioned complexity, it is prohibitive for this approach to find the best path arrange-ment especially for a relatively large M .
In our previous study [1], we presented a Bayesian algo-rithm about how to reconstruct v from b . We model v as a multivariate Gaussian distribution where m and C are the N -dimensional mean vector and N  X  N covariance matrix, respectively. Because v represents a 2D image, its distribution is also referred to as a Gaussian process (GP) [14]. We assume that this GP is homogeneous since we don X  X  have a priori knowledge about the differences between different pixels. Thus, the cross-covariance C n between v i and v j in v , where 1  X  i,j  X  N , is defined as ( x ,y i ) and ( x j ,y j ) are the coordinates for pixels i and j , respectively. f and r are two parameters. (6) indicates that if neighboring pixels should have high correlation while far apart pixels should have low correlation. This global smoothness constraint aids us to solve our extremely under-constrained reconstruction problem.

We introduce noise to the projection model in (1) to make it probabilistic  X  2 is the noise variance and I is a M  X  M identity matrix. The projections b can thus be modeled as another multi-variate Gaussian distribution given the 2D image v
We can now write the joint probability between image v and projection b , P ( v , b ) = P ( v ) P ( b | v )
From (8), we can write the posterior distribution of v given b where the posterior mean and covariance are respectively.

In our previous work [21], we propose to use the posterior mean e m as the reconstructed image This is our solution to the reconstruction problem and is optimal in the sense of minimizing mean squared error. The complexity of calculating (10) is O ( MN 2 ) (assuming M &lt; N ). (10) can also be rewritten as If we set m = 0 and let C  X  1 = L T L , (13) has a identi-cal form to (4), the solution of TR. The difference is that we model the covariance C directly while TR models the inverse of covariance by L T L . In practice, we dynamically set each element of m equally to the average of all M path projections.

We note that one prior approach also models the image as a Gaussian distribution [13]. However instead of using para-metric covariance matrix as we do in (6), they propose to estimate the covariance via images simulated by computa-tional fluid dynamics (CFD). This demands a large number of training images, which can be expensive to obtain.
We have assumed that the path arrangements are already given and thus A is known. In this section, we describe how to find the best path arrangements or to determine the projection matrix A that can produce more accurate reconstruction.
We define the reconstruction uncertainty as the average posterior pixel variance F (  X  ) = 1 which is proportional to the trace of the posterior covariance in (11). Since posterior variance indicates the uncertainty of our prediction, minimizing such variance is expected to reduce uncertainty and thus improve our reconstruction re-sult. Here  X  = {  X  1 ,  X  2 ,...,  X  M } are path arrangement pa-rameters for all paths and determine projection matrix A . cating the coordinates of two end points for the m -th path. Note that because an end point is located on a wall so either x or y is a constant. Therefore, each  X  m only has two tun-able parameters. If we have a ROI smaller than the whole cross section, we simply process the pixels within that ROI (instead of applying the trace operator for the whole image).
Using the posterior covariance or variance of GP has been considered in other applications. For example, [5] propa-gates such uncertainty into multi-step ahead forecasting of time series. [10] performs clustering based the principle that highly populated area should have low uncertainty while less populated area should have high uncertainty.

We now describe how to compute F (  X  ). Because C is a constant, we just need to compute the projection matrix A . We have been using sample points and bilinear weights to compute the contributions of a pixel to a path and then determine A as noted in Sect.3.1. However, using the same method is not a good option here, because then we don X  X  have an analytical form to work with. Therefore, we propose the following approximation for computing A based on the distance between a pixel and the path.

The m -th path is a line and every point ( x,y ) on this line can be represented by the following equation
To compute the contribution of the n  X  th pixel ( x (a grid point in Fig.2), where n = 1 , 2 ,,N . to this path, we first compute the squared distance between the pixel to the line The contribution of this pixel to the path is defined as exp(  X   X d 2 m,n ), where  X  is a parameter. The rationale behind this is that the smaller the distance is, the higher impact the pixel has on the path. Finally, we define the m -th row of the projection matrix A m as A The normalization term in (17) is to make sure that the sum of this row is equal to one, because the projection is the weighted average of all pixel values on the path. Now the full projection matrix A is simply A = [ A T 1 ... A T
The largest advantage of using this approximated project matrix is that now our objective function F (  X  ) is differen-tiable with respective to parameter  X  . Thus, we can easily compute gradient and employ gradient-based algorithm such as interior point algorithm to solve the problem [2, 19]. This greatly speeds up the optimization process. The error intro-duced by this approximation is mainly due to pixels located at corners. When we compute the distance between such a pixel and a path, the projection of this pixel on the path can be located outside the cross section. Therefore, ideally, such a pixel should not have any impact on the path av-erage. However, our approximation method is not able to check this. Fortunately, the number of such pixels is very small and we don X  X  expect such error to be a big issue.
Note that our reconstruction uncertainty can be used to compare existing path arrangements and help selecting the best one. This is much faster and more effective than simu-lating and evaluating against a large number of test images as we show in Sect.5.4. We have introduced an unconstrained objective function F (  X  ). However, the end points of a path can only be lo-cated on a wall or certain regions of a wall and cannot go unbounded. We will add such constraints to our optimiza-tion problem.

Suppose that we have K available regions R 1 ,R 2 ,...,R K Each region is a line segment indicated by R k = [ wall k y k, 1 , x k, 2 , y k, 2 ]. wall k = 1, 2, 3, 4 denotes which wall this region is located on (see Fig.2). ( x k, 1 ,y k, 1 ) and ( x denote the starting and ending points of the region, respec-tively. They have a fixed order such that ( x k, 1  X  x k, 2 ( y because an available region must be located on one of the four walls.

For example, the available region on Wall 4 in Fig.2 is (4, 0, 0 . 2, 0, 0 . 5) indicating wall k = 4, x k, 1 0 . 2, x k, 2 = 0 and y k, 2 = 0 . 5. We will use k to exclusively indicate an available region, not to be confused with the path indicator m . So x k, 1 and x m, 1 are referring to locations on a region and a path differently even if k = m . The red lines on each wall of Fig.2 show such available regions. Every end point of all paths must be located within an available region.
We define region pair as a pair of available regions ( R k All region pairs are denoted by a set  X  = { ( R k 1 ,R k 2 wall k 1 } . We require that wall k 1 &lt; wall k 1 because ( R is the same as ( R k 2 ,R k 1 ) and only needs to be considered once. Conceptually, each path can span two regions to form a total of K ( K  X  1) / 2 possible region pairs. However, the number is usually smaller because we do not consider two regions on the same wall. We use |  X  | to indicate the cardi-nality of the set  X  .

The region pair where the m -th path is located is denoted by H m satisfying H m  X   X  . By considering region pairs, we define our final constrained optimization problem as follows LB ( . ) and UB ( . ) are lower bound and upper bound oper-ators, respectively. They ensure that end points of a path are located within an available region. If we denote H m ( R rameters in  X  m . Because the end points of both available regions and paths are located on a wall, two parameters in  X  m are actually constants and don X  X  need to be optimized over. If we let H = { H 1 ,H 2 ,...,H M } , we can write bounds in a more compact form by LB ( H )  X   X   X  UB ( H ).
The constrained optimization problem defined by (18) re-quires us to search for both M region pairs H 1 ,H 2 ,...,H and M path arrangement  X  1 ,  X  2 ,...,  X  M . This problem is challenging to solve because it is a combinatorial optimiza-tion problem. There are |  X  | M possible cases for region pair assignment H . For each assignment, the gradient-based search takes O ( MN 2 ). Therefore, the total complexity is O ( |  X  | M MN 2 ). This is prohibitive for slightly large M and K value.
 Therefore, we resort to stochastic optimization scheme [4]. It works as follows. For each iteration, we randomly perturb the current path arrangement by changing the region pair assignment and also initializing the end point positions of affected paths. Then we find the new best objective function in (18) by fixing the pair assignment. Next, we make a decision whether we keep this perturbation or switch back to the previous iteration result. The above process is then repeated until certain criterion is met. Different stochastic optimization methods differ in how we perturb and how we make a decision about the perturbation.

In this paper, we use simulated annealing (SA). For per-turbation, we randomly select a path, randomly assign a region pair to it and then randomly initialize its end point positions on this region pair. For the decision, suppose that the newly optimized objective function value is F new the previous objective function value is F old . We keep the new change if Here T 0 and 0 &lt; &lt; 1 are two constants. q is the current iteration number. 0  X   X   X  1 is a randomly generated num-ber during each iteration. The idea behind (19) is that if new object function F new is no more than F old (indicating a nice move) the left side is no less than 1. So no matter what the value  X  is, (19) is satisfied and we will keep the new perturbation. Otherwise, the left side of (19) will be a value between 0 and 1, so whether we keep the change is determined randomly on how large  X  is. The concept of annealing is to reduce the temperature term T 0 q gradually so the left side of (19) is less likely to be larger than  X  over time unless F new is surely no more than F old . We exit SA if the number of consecutive iterations without improvement exceeds 100.

By using the simulated annealing, we finally reduce the complexity from O ( |  X  | M MN 2 ) to O ( QMN 2 ), where Q is the maximum number of iterations needed and is typically smaller than 1000. This makes our algorithm practical. Al-ternatively, one can use Genetic algorithm to search for re-gion pair assignments [4]. Algorithm 1 shows the pseudo codes of the complete optimization process.
Simulated datasets. In order to evaluate our algo-rithms, we need to compare the reconstructed image with the ground truth image. However, it is difficult to mea-sure gas concentration inside the combustion region if not impossible. Thus, we resort to simulated tests. In all our tests, the resolution of an image is 200  X  200, representing a square boiler cross section with a width of 1 and a height of 1. Note that the proposed methodology can be applied to any rectangular cross section.
A ground-truth image is generated by summing L 2D smooth functions (similar to the covariance function in (6)). In particular, the n -th pixel value v n is produced as follows ( x n ,y n ) is the corresponding 2D coordinates of v n . The l -th smooth function is defined by h l exp(  X  ( x  X   X  xl ) where l = 1 , 2 ,...,L . There are four parameters for each function, h l , s l ,  X  xl and  X  yl , representing the peak, width and center locations of the function, respectively.
We fix L = 10 for all our tests. To produce a 2D image, we randomly create each of the L = 10 smooth functions by randomly selecting h l between 0 and 1, s l between 0.1 and 0.4,  X  xl and  X  yl between 0 and 1, respectively. Then all the L functions are summed to form the final ground-truth image v as in (20). The image created in this way is smooth, and usually multi-peaked and with an irregular shape, which resembles a realistic gas concentration image. We create a total of 100 images using this approach. One example is shown in Fig.6g.

Reconstruction algorithms We compare our GP algo-rithm with SART and TR. For our algorithm, we fix the GP parameters f = 1,  X  2 = 0 . 001 and r = 1 . 0. This set-ting gives us high enough signal-to-noise ratio f/ X  2 = 1000 and at the same time helps to avoid matrix singularity be-fore the matrix inverse in (10) and (11). Our algorithm is not sensitive to r when it is between 0 . 5 and 1 . 5. We set  X  = 300 used in projection matrix approximation such that only pixels right next to a path will have impact on its pro-jection. Parameters in simulated annealing are set as T 0 and = 0 . 95. For SART, we set its  X  = 1 in (3) and for TR, we set its  X  = 0 . 1 in (4). Both values produce the best results for these two algorithms. To further reduce compu-tation, for all three algorithms, we reconstruct images with a lower resolution of N = 10  X  10 and then apply bi-cubic interpolation to render the 200  X  200 image.

Path arrangement methods Before our study, most previous methods have been using view-based path arrange-ment scheme. In an orthogonal path arrangement, there are two views and a path is parallel to one of the four walls like top right plot in Fig.1. In a diagonal path arrangement, there are also two views and a path is parallel to one of the two diagonal directions (via rotating the orthogonal arrange-ment by 45 degrees). Siemens energy has mostly used these two simple methods to configure paths. We can combine these two schemes and form the multi-view path arrange-ment such that all paths will be arranged under four evenly spaced views. Note that these view-based approaches will not work in the case of mounting restrictions.

We also consider two additional baseline methods. The first one is to replace our objective function in (14) with a much simpler max N n =1 min M m =1 d 2 m,n . The rationale behind it is that each pixel should have at least one path nearby. We will refer to this method as  X  X ax min X . The second one is a random path arrangement by randomly selecting a region pair and randomly generating end point positions on the region pair for a path. We will compare our optimized path arrangement with all above five path arrangement schemes.
Evaluation Note that a reconstruction algorithm and a path arrangement method can be arbitrarily combined. For each such combination, we conduct 100 tests. For each test, we use one of the 100 simulated image as our ground truth. Based on the path arrangement, the projections are gener-ated. Then different reconstruction algorithm is applied to produce the reconstructed image. We compare this image e v with the ground truth image v using root mean squared error RMSE = average RMSE is used to judge the performance of this com-bination. All tests conducted in this paper are implemented in Matlab.
In this test, we focus on comparing the performances of three reconstruction algorithms based on the same path ar-rangement method (orthogonal, diagonal, multi-view, ran-dom or optimized). Fig.3 shows the average RMSE scores for different algorithms for different number of paths ( M from 5 to 100). More details about the optimized path ar-rangement will be given in the next section.

Our GP algorithm produces the lowest RMSE for all six tests. Note that due to the way we generate synthetic im-ages (Sect.5.1), a ground truth pixel value is usually between 0 and 3. Thus, RMSE=0 . 028 roughly means a relative error of 0 . 01(= 0 . 028 / 3). To check the statistical significance, we conduct the one-sided paired t-test of GP vs. TR which ap-pears to be the second performer. Table 1 shows the p value for all six tests for different number of paths. With a confi-dence level at 0 . 05, our results are significantly better than those of TR except five cases. SART performs worst for all Table 1: p-value of one-sided paired t-test on RMSE scores comparing our GP algorithm to TR. 0 . 000 in-dicates that p-value is smaller than 0 . 001 . A bold entry indicates a failed t-test with a confidence in-terval of 0 . 05 . Table 2: RMSE scores for three path arrangement methods using GP reconstruction algorithm. The best score for each column is highlighted in bold. cases. In addition, due to the previously noted division-by-zero problem SART often fails to produce scores. Therefore, using smoothness regularization like GP and TR helps to overcome this severely under-constrained situation.
If we look across all plots in Fig.3, it appears that the best path arrangement method is our optimization method, followed by random method and then multi-view method. The performance of the diagonal scheme does not improve after 20 paths. The orthogonal method (not shown) follows a similar trend but is worse than the diagonal method. The multi-view method also stops improving after 50 paths. This implies that when the number of paths increases, we should distribute them using more views. Therefore, when the num-ber of paths is more than 50, more than 4 views should help to further improve the multi-view approach. However, this is not the focus of this paper and is not explored here. The  X  X ax min X  method doesn X  X  perform well, most likely due to the fact that it only focuses on the closest path to a pixel by ignoring the others. Table 2 compares the performance of top three path arrangement methods using the same GP al-gorithm. Our path optimization method produces the best results for all cases, which also passes the t-test against both multi-view and random methods with a confidence interval of 0 . 05.
We now test the performance of our path arrangement optimization algorithm with different number of paths from 5 to 100. We assume that all walls are available for installing a path and the ROI is the whole cross section.

We initialize the simulated annealing by randomly assign-ing a region pair to a path and randomly selecting the path X  X  end points within the corresponding available region. Fig.4a shows the total time taken by our optimization algorithm to converge. When the number of paths is very small such as 5, the optimization time is only one and half minute. When the number of paths increases to 100, the time increases to 20 hours. The number of iterations needed ranges between 200 and 600. Fig.4b shows how the current lowest uncertainty (best objective function value) varies with the number of it-erations for the case of M = 10, which takes a total of 359 iterations. The uncertainty usually improves quick at the beginning, but improvement slows down gradually. Figure 4: Path arrangement optimization results. (a) shows the optimization time for different number of paths. (b) shows the evolution of objective func-tion value over number of iterations (in log scale) for the case of M = 10 paths.

Fig.5 shows the optimized path arrangements for M = 5 and M = 10 cases. It worthy noting that for both cases, cor-ner areas have more path presence than some center areas. We attribute this to the fact that it is harder to infer corner areas from other areas because they are less correlated with others. Therefore, dedicating some paths to corner areas help to reduce the overall uncertainty. Figure 5: Examples of optimized path arrange-ments.

By using the optimized path arrangements, we can also evaluate reconstruction algorithms as already shown in Fig.3e. Fig.6 visually shows how reconstruction improves with the increasing number of paths using GP. The ground truth im-age (Fig.6g) appears to have four peaks. When M is small such as 5 and 10, the algorithm is only able to recover two peaks due to limited projection information. When M in-creases to 50, three peaks are recovered. The reconstructed image with M = 100 closely resembles the ground truth image.
In this section, we consider a more realistic test case as shown in Fig.2. First, mounting restrictions exist. On the first wall, there are four available regions with a range of There is no available region on the second wall. The third fourth wall. In addition, ROI consists of two rectangles. The lower left corner and upper right corner of the first rectan-lower left corner and upper right corner of second rectangle objective function will only sum up the posterior variances for pixels within ROI. We only consider M = 5 , 10 , 15 paths, because these small numbers are of more practical use.
So far, we show that our optimized path arrangement is better than multi-view and random path arrangement. This is not so impressive considering that the latter two meth-ods are very simple and straightforward. Even if we don X  X  have other path arrangement algorithms to compare with, we seek the answer to the following question: how does our result compare with ground truth best path arrangement in terms of RMSE measure? Because such ground truth is never known to us, we may attempt to randomly sample paths in the hope that one of the randomly generated path arrangements might be close to the ground truth.

To be able to achieve this, we randomly generate 10000 path arrangements. For each arrangement, we apply a re-construction algorithm and compute the average RMSE. The random arrangement with the lowest RMSE is treated as the best random path arrangement. Fig.7 compares the RMSE of the best random path arrangement with that of our optimization result. Only TR and GP are used as the recon-struction algorithms, which leads to four RMSE curves. The GP based on optimized path arrangement (represented by  X  X ptimized+GP X ) produces the lowest RMSE. This is signif-icantly better than the second performer  X  X ptimized+TR X  with the highest p value at 0 . 002 for all cases.
Note that for this test, there are 19 region pairs. Even with M = 5, we have a total of 19 5  X  2 . 5  X  10 6 pair to path assignments. This hasn X  X  considered the end point locations of a path on an available region (continuous numbers). Therefore, the pool of 10000 random samples is too small to be able to include the ground truth best path arrangement. However, even with this  X  X mall X  pool size, it takes 16 hours to find the best random path arrangement in the case of M = 5. In contrast, our optimization algorithm takes about 1 minute, 2 minutes and 4 minutes to converge for M = 5, M = 10 and M = 15, respectively.

Fig.2 show the final optimized path arrangement in the case of M = 5 paths. Comparing Fig.2 with Fig.5a, the optimization result without restrictions, we can see that in Fig.5a, paths tend to cover wider regions. This is because Figure 7: Comparing our optimized path arrange-ment with best random path arrangement. the ROI for Fig.5a is the whole cross section while the ROI for Fig.2 is mostly upper left corner and center area. One may expect that in this case with such a small number of paths, all paths should cross the ROI area. Surprisingly, the 2-th path in Fig.2 doesn X  X  follow this intuition. This can be attributed to the fact that a good path arrangement should not only gain information about ROI but also remove ambiguity caused by non-ROI areas. Path 1, 3, 4 and 5 already have a good coverage over ROI, but their projection values are also influenced by pixels around lower left corner. Instead of using path 2 to gain additional information for ROI, our algorithm chooses to use it to gain information about those non-ROI pixels. This turns out to reduce the overall uncertainty even more.
Gas concentration reconstruction for coal-fired boiler is an important task in power industry. There are two aspects of this problem: how do we construct the image and how do we arrange paths. We propose to use Gaussian process to address both aspects under the same framework. We use the posterior mean as the reconstructed image and average posterior pixel variance as the objective function for path arrangement. A variety of tests are conducted to show the advantages of the proposed method.

Our algorithms have been implemented in Java and de-ployed in Siemens SPPA-P3000 control system as a impor-tant component in its combustion optimization module [16]. Combustion optimization is aimed at improving boiler effi-ciency and reducing emissions. A closed-loop optimization is achieved by manipulating fuel and air levels, with the help of our reconstructed image for key combustion compo-nents such as O2, CO, H2O and temperature. Fig.8a shows the work flow diagram of combustion optimization. Our al-gorithm is located in the block of  X  X istribution calculation based on CAT X  (CAT represents computer-aided tomogra-phy). Fig.8b shows that O2 distribution becomes better balanced with the closed loop control, which improves the boiler efficiency.

Fig.9 shows a separate user interface for path arrangement optimization, which mainly runs off-line. This software takes a boiler configuration file (with boiler geometry, number of paths, constraints and etc.) as input and exports the op-timized path arrangement in an output file. The user can then use the output to design the TDLAS layout plan.
Note that in our reconstruction algorithm, the reconstructed image is unbounded, which may cause a pixel value to be negative. This is against reality: a gas concentration cannot have negative values. We have improved this by convert-ing the Gaussian process posterior distribution in (9) into a quadratic loss function. After introducing user specified lower and upper bound (e.g, lower bound is zero), we form a quadratic programming problem, which can be easily solved. The details are omitted here.
 Figure 9: Path arrangement optimization user in-terface. [1] S. Angeli and E. Stiliaris. An accelerated algebraic [2] S. Boyd and L. Vandenberghe. Convex Optimization . [3] K. B. Chung, F. C. Gouldin, and G. J. Wolga.
 [4] D. Fouskakis and D. Draper. Stochastic optimization: [5] A. Girard, J. Candela, R. Murray-smith, and C. E. [6] A. Guha and I. Schoegl. Simulation of 2D [7] R. K. Hanson, P. A. Kuntz, and C. H. Kruger.
 [8] M. Jiang and G. Wang. Convergence of the [9] A. C. Kak and M. Slaney, editors. Principles of [10] H. Kim and J. Lee. Clustering based on Gaussian [11] C. Liu, L. Xu, Z. Cao, and H. McCann.
 (a) system work flow diagram. (b) combustion optimization example. [12] C. Liu, L. Xu, and Z.Cao. Measurement of [13] Z. Nadir, M. S. Brown, M. L. Comer, and C. A. [14] C. E. Rasmussen and C. K. I. Williams. Gaussian [15] M. Ravichandran and F. C. Gouldin. Reconstruction [16] S. Thavamani, M. Behmann, and T. Spaeth. Plant [17] J. Tian and K. Ma. A survey on super-resolution [18] M. E. Tipping and C. M. Bishop. Bayesian image [19] A. W  X  achter and L. T. Biegler. On the implementation [20] F. Wang, Q. Wu, Q. Huang, H. Zhang, J. Yan, and [21] C. Yuan. A Bayesian approach for gas concentration [22] X. Zhu, J. Lafferty, and Z. Ghahramani.

