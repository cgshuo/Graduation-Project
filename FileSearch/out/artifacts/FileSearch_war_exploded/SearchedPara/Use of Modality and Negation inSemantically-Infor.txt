 U.S. Department of Defense University of Maryland University of Maryland Johns Hopkins University Johns Hopkins University Johns Hopkins University Carnegie Mellon University
BB NTechnologies This article describes the resource-and system-building efforts of an 8-week Johns Hopkins
University Human Language Technology Center of Excellence Summer Camp for Applied Lan-guage Exploration (SCALE-2009) on Semantically Informed Machine Translation (SIMT). We
MN lexicon, and two automated MN taggers that we built using the annotation scheme and lexicon. Our annotation scheme isolates three components of modality and negation: a trigger (a word that conveys modality or negation), a target (an action associated with modality or negation), and a holder (an experiencer of modality). We describe how our MN lexicon was semi-automatically produced and we demonstrate that a structure-based MN tagger results in precision around 86% (depending on genre) for tagging of a standard LDC data set. framework that supports the inclusion of semantic annotations. Syntactic tags enriched with a process of tree grafting. Although the focus of our work is modality and negation, the tree
NIST 2009 Urdu X  X nglish test set. This finding supports the hypothesis that both syntactic and semantic information can improve translation quality. 1. Introduction This article describes the resource-and system-building efforts of an 8-week Johns
Hopkins Human Language Technology Center of Excellence Summer Camp for Ap-plied Language Exploration (SCALE-2009)onSemanticallyInformedMachineTranslation (SIMT) (Baker et al. 2010a, 2010b, 2010c, 2010d). Specifically, we describe our modal-ity/negation (MN) annotation scheme, a (publicly available) MN lexicon, and two automated M Ntaggers that were built using the lexicon and annotation scheme. trigger (a word that conveys modality or negation), a target (an action associated with modalityornegation),andaholder(anexperiencerofmodality).TwoexamplesofMN tagging are shown in Figure 1.
 modality tag is combined with  X  X OT X  to form the  X  X OTAble X  tag) and also that 412 M Ntags occur in pairs of triggers (e.g., TrigAble and Trig Negation) and targets (e.g., TargNOTAble).
 machinetranslationusingatechniquethatwecall tree grafting .Thistechniqueincorpo-ratessyntacticlabelsandsemanticannotationsinaunifiedandcoherentframeworkfor implementing semantically informed machine translation. Our framework is not lim-itedtothesemanticannotationsproducedbytheMNtaggersthatarethesubjectofthis article and we exploit this capability to additionally include named-entity annotations producedbyapre-existingtagger.Byaugmentinghierarchicalphrase-basedtranslation ruleswithsyntacticlabelsthatwereextractedfromaparsedparallelcorpus,andfurther augmenting the parse trees with markers for modality, negation, and entities (through thetreegraftingprocess),weproducedabettermodelfortranslatingUrduandEnglish.
The resulting system significantly outperformed the linguistically naive baseline Hiero model, and reached the highest scores yet reported on the NIST 2009 Urdu X  X nglish translation task.
 model, smaller (but significant) gains were achieved by injecting semantic knowledge into the syntactic paradigm. Verbal semantics (modality and negation) contributed slightly more gains than nominal semantics (named entities) and their combined gains were the sum of their individual contributions.
 tities) are only a small piece of the much larger semantic space, but demonstrating success on these semantic aspects of language, the combination of which has been unexplored by the statistical machine translation community, bodes well for (larger) improvements based on the incorporation of other semantic aspects (e.g., relations and temporal knowledge). Moreover, we believe this syntactic framework to be well suited forfurtherexplorationoftheimpactofmanydifferenttypesofsemanticsonthequality of machine-translation (MT) output. Indeed, it would not have been possible to initiate the current study without the foundational work that gave rise to a syntactic paradigm that could support these semantic enrichments.
 intheEnglishportionofaparalleltrainingcorpusandprojectedtothesourcelanguage (inourcase,Urdu)duringaprocessofsyntacticalignment.Thesesemanticelementsare subsequently used in the translation rules that are extracted from the parallel corpus.
The goal of adding them to the translation rules is to constrain the space of possible translations to more grammatical and more semantically coherent output. We explored whetherincludingsuchsemanticelementscouldimprovetranslationoutputintheface ofsparsetrainingdataandfewsourcelanguageannotations.Resultswereencouraging.
Translation quality, as measured by the Bleu metric (Papineni et al. 2002), improved when the training process for the Joshua machine translation system (Li et al. 2009) used in the SCALE workshop included M Nannotation.
 they can be used to characterize events in a variety of automated analytic processes.
Modalitiesandnegationcandistinguishrealizedeventsfromunrealizedevents,beliefs from certainties, and can distinguish positive and negative instances of entities and events. For example, the correct identification and retention of negation in a particular language X  X uch as a single instance of the word  X  X ot X  X  X s very important for a correct representation of events and likewise for translation.
 approach.Section4definesthetheoreticalframeworkforourMNlexiconandautomatic
MNtaggers. Section 5presents theMNannotation scheme usedbyour human annota-torsanddescribesthecreationofaMNlexiconbasedonthisscheme.Section6presents two types of M Ntaggers X  X ne that is string-based and one that is structure-based X  and evaluates the effectiveness of the structure-based tagger. Section 7 then presents implementation details of the semantically informed syntactic system and describes the results of its application. Finally, Section 8 presents conclusions and future work. 2. Related Work
The development of annotation schemes has become an area of computational lin-guistics development in its own right, often separate from machine learning applica-tions. Many projects began as strictly linguistic projects that were later adapted for computational linguistics. When an annotation scheme is consistent and well devel-oped, its subsequent application to NLP systems is most effective. For example, the syntactic annotation of parse trees in the Penn Treebank (Marcus, Marcinkiewicz, and
Santorini1993)hadatremendouseffectonparsingandonNaturalLanguageProcessing in general.

Although the labeling conventions may differ, a layer of modality annotation over verb role annotation, for example, can have a complementary effect of providing more information, rather than being viewed as a competing scheme. We review some of the major semantic annotation efforts here.
 argument structure over parse trees. First annotated as an overlay to the Penn
Treebank,Propbankannotationnowexistsforothercorpora.Propbankannotationaims to answer the question Who did what to whom? for individual predicates. It is tightly coupled with the behavior of individual verbs. FrameNet (Baker, Fillmore, and Lowe 1998), a frame-based lexical database that associates each word in the database with a semantic frame and semantic roles, is also associated with annotations at the lexical level.WordNet(Fellbaum1998)isaverywidelyusedonlinelexicaltaxonomywhichhas beendevelopedinnumerouslanguages.WordNetnouns,verbs,adjectives,andadverbs are organized into synonym sets. PropBank, FrameNet, and WordNet cover the word senses and argument-taking properties of many modal predicates.
 languages, with its roots in the Prague school of linguistics. Besides a morphological layer and an analytical layer, there is a Tectogrammatical layer. The Tectogrammatical layer includes functional relationships, dependency relations, and co-reference. The
PDT also integrates propositional and extra-propositional meanings in a single anno-tation framework.
 annotates discourse connectives and their arguments over a portion of the Penn
Treebank. Within this framework, senses are annotated for the discourse connectives in a hierarchical scheme. Relevant to the current work, one type of tag in the scheme is the Conditional tag, which includes hypothetical, general, unreal present, unreal past, factual present, and factual past arguments.
 lishing the importance of attributing a belief or assertion expressed in text to its agent (equivalenttothenotionof holder inourscheme).Theannotationschemeisdesignedto capture the expression of opinions and emotions. In the PDTB, each discourse relation 414 and its two arguments are annotated for attribution. The attribute features are the
Sourceoragent,theType(assertionpropositions,beliefpropositions,facts,andeventu-alities), scopal polarity, and determinacy. Scopal polarity is annotated on relations and their arguments to identify cases when verbs of attribution are negated on the surface but the negation takes scope over the embedded clause. An example is the sentence  X  X avingthedividendincreasesisasupportiveelementinthemarketoutlook but I don X  X  think it X  X  a main consideration . X  Here, the second argument (the clause following but )is annotated with a  X  X eg X  marker, meaning  X  X  think it X  X not a main consideration. X  preting polarity in the context of sentiment analysis, which is the task of identifying positive and negative opinions, emotions, and evaluations. The authors have estab-lishedasetoffeaturestodistinguishbetweenpositiveandnegativepolarityanddiscuss the importance of correctly analyzing the scope of the negation and the modality (e.g., whether the proposition is asserted to be real or not real).
 ification language, which has been developed in the context of reasoning for question answering (Saur  X   X , Verhagen, and Pustejovsky 2006). TimeML, which includes modality annotation on events, is the basis for creating the TimeBank and FactBank corpora (Pustejovsky et al. 2006; Saur  X   X  and Pustejovsky 2009). In FactBank, event mentions are marked with their degree of factuality.
 tainty and uncertainty. Rubin (2007) describes a scheme for five levels of certainty, referred to as Epistemic modality, in news texts. Annotators identify explicit certainty markers and also take into account Perspective, Focus, and Time. Focus separates certainty into facts and opinions, to include attitudes. In our scheme, Focus would be covered by want and belief modality. Also, separating focus and uncertainty can allow the annotation of both on one trigger word. Prabhakaran, Rambow, and Diab (2010) describe a scheme for automatic committed belief tagging. Committed belief indicates the writer believes the proposition. The authors use a previously annotated corpus of committedbelief,non-committedbelief,andnotapplicable(Diabetal.2009),andderive features for machine learning from parse trees. The authors desire to combine their work with FactBank annotation.
 for uncertainty and their scope. The task was described as  X  X edge detection, X  that is, finding statements which do not or cannot be backed up with facts. Auxiliary verbs such as may , might , can , and so forth, are one type of hedge cue. The training data for the shared task included the BioScope corpus (Szarvas et al. 2008), which is manually annotated with negation and speculation cues and their scope, and paragraphs from
Wikipedia possibly containing hedge information. Our scheme also identifies cues in the form of triggers, but our desired outcome is to cover the full range of modalities and not just certainty and uncertainty. To identify scope, we use syntactic parse trees, as was allowed in the CoNLL task.
 modalitiesisimportanttodeterminewhetheratextentailsahypothesis.Bar-Haimetal. (2007) include polarity based rules and negation and modality annotation rules. The polarity rules are based on an independent polarity lexicon (Nairn, Condorovdi, and
Karttunen2006).Theannotationrulesfornegationandmodalityofpredicatesarebased on identifying modal verbs, as well as conditional sentences and modal adverbials.
The authors read the modality off parse trees directly using simple structural rules for modifiers. chinetranslationincludesSigurdandGawr  X  onska(1994)andMurataetal.(2005).Sigurd and Gawr  X  onska (1994) write about rule based frameworks and how using alternate grammatical constructions such as the passive can improve the rendering of the modal in the target language. Murata et al. (2005) analyze the translation of Japanese into
English by several systems, showing they often render the present incorrectly as the progressive.Theauthorstrainedasupportvectormachinetospecificallyhandlemodal constructions, whereas our modal annotation approach is a part of a full translation system.

Our tree-grafting approach builds on a technique used for tree augmentation in Miller et al. (2000), where parse-tree nodes are augmented with semantic categories. In that earlier work, tree nodes were augmented with relations, whereas we augmented tree nodes with modality and negation. The parser is subsequently retrained for both semantic and syntactic processing. The semantic annotations were done manually by students who were provided a set of guidelines and then merged with the syntactic trees automatically. In our work we tagged our corpus with entities, modality, and negation automatically and then grafted them onto the syntactic trees automatically, forthepurposeoftrainingastatisticalmachinetranslationsystem.Anaddedbenefitof theextractedtranslationrulesisthattheyarecapableofproducingsemanticallytagged
Urdu parses, despite the fact that the training data were processed by only an English parser and tagger.
 a series of syntax rules are applied to a source language string to produce a target language phrase structure tree. The Penn English Treebank (Marcus, Marcinkiewicz, and Santorini 1993) is used as the source for the syntactic labels and syntax trees are relabeled to improve translation quality. In this work, node-internal and node-external information is used to relabel nodes, similar to earlier work where structural context was used to relabel nodes in the parsing domain (Klein and Manning 2003). Klein andManning X  X methodsincludelexicalizingdeterminersandpercentmarkers,making more fine-grained verb phrase (VP) categories, and marking the properties of sister nodes on nodes. All of these labels are derivable from the trees themselves and not from an auxiliary source. Wang et al. (2010) use this type of node splitting in machine translation and report a small increase in BLEU score.

Zollmann, and Vogel (2007) to induce synchronous grammar rules, a process which requires phrase alignments and syntactic parse trees. Venugopal, Zollmann, and Vogel (2007)usegenericnon-terminalcategorysymbols,asinChiang(2005),aswellasgram-matical categories from the Stanford parser (Klein and Manning 2003). Their method forruleinductiongeneralizestoanysetofnon-terminals.Wefurtherrefinethisprocess by adding semantic notations onto the syntactic non-terminals produced by a Penn Treebank trained parser, thus making the categories more informative.
 work. In their work, rule splitting and rule merging are applied to refine parse trees during machine learning. Hierarchical splitting leads to the creation of learned cate-goriesthathavelinguisticrelevance,suchasabreakdownofadeterminercategoryinto two subcategories of determiners by number, that is, this and that group together as do some and these . We augment parse trees by category insertion in cases where a semantic category is inserted as a node in a parse tree, after the English side of the corpus has been parsed by a statistical parser. 416 3. SIMT Motivation
As in many of the frameworks described herein, the aim of the SIMT effort was to provide a generalized framework for representing structured semantic information, suchasmodalityandnegation.Unlikemanyoftheprevioussemanticannotationefforts (where the emphasis tends to be on English), however, our approach is designed to be directly integrated into a translation engine, with the goal of translating highly divergent language pairs, such as Urdu and English. As such, our choice of annotation scheme X  X llustrated in the trigger-target example shown in Figure 1 X  X as based on a simplified structural representation that is general enough to accommodate divergent modality/negation phenomena, easy for language experts to follow, and straightfor-ward to integrate into a tree-grafting mechanism for MT. Our objective is to investigate whether incorporating this sort of information into machine translation systems could produce better translations, particularly in settings where only small parallel corpora are available.
 translating important semantic elements when working with a low-resource language pair. Figure 2 shows an example taken from the 2008 NIST Urdu X  X nglish translation task, and illustrates the translation quality of a state-of-the-art Urdu X  X nglish system (prior to the SIMT effort). The small amount of training data for this language pair (see
Table 1) results in significantly degraded translation quality compared, for example, to an Arabic X  X nglish system that has more than 100 times the amount of training data. the-art phrase-based MT system that by default does not incorporate any linguistic information (e.g., syntax or morphology or transliteration knowledge). As a result, wordsthatwerenotdirectlyobservedinthebilingualtrainingdatawereuntranslatable.
Names, in particular, are problematic. For example, the lack of translation for Nagaland and Nagas induces multiple omissions throughout the translated text, thus producing severalinstanceswherethe holder ofaclaim(or belief )ismissing.Thisisbecauseout-of-vocabulary words are deleted from the Moses output.
 rules used by the translation models. Generic symbols in translation rules (i.e., the non-terminalsymbol X  X  X )werereplacedwithstructuredinformationatmultiplelevels of abstraction, using a tree-grafting approach that we describe subsequently. Figure 3 418 illustrates the evolution of the translation rules that we used, first replacing  X  X  X  with grammatical categories and then with categories corresponding to semantic units. dications that a statement represents something that has/hasn X  X  taken place or is/isn X  X  a belief or an intention) and named entities (such as people or organizations). Other semanticunits,suchasrelationsbetweenentitiesandevents,werenotpartofthiseffort but we believe they could be similarly incorporated into the framework. We chose to examine semantic units that canonically exhibit two different syntactic types: verbal, in the case of modality and negation, and nominal, in the case of named entities. efforts in SIMT. Rather, we focused on the development of an annotation scheme for modality and negation and its use in MT, while relying on a pre-existing hidden Markov model (HMM)-based tagger derived from Identifinder (Bikel, Schwartz, and
Weischedel 1999) to produce entity tags. Thus, the remainder of this article will focus on our M Nannotation scheme, two M Ntaggers produced by the effort, and on the integration of semantics in the SIMT paradigm. 4. Modality and Negation
Modality is an extra-propositional component of meaning. In JohnmaygotoNY ,the basicpropositionis John go to NY andtheword may indicatesmodalityandiscalledthe trigger in our work. van der Auwera and Amman (2005) define core cases of modality: John must go to NY (epistemic necessity), John might go to NY (epistemic possibility),
John has to leave NY now (deontic necessity), and John may leave NY now (deontic pos-sibility). Larreya (2009) defines the core cases slightly differently as root and epistemic .
Root modality in Larreya X  X  taxonomy includes physical modality ( He had to stop. The road was blocked ) and deontic modality ( You have to stop ). Epistemic modality includes problematic modality ( You must be tired ) and implicative modality ( You have to be mad to do that ).Manysemanticists(Kratzer1991,vonFintelandIatridou2006)definemodality as quantification over possible worlds. John might leave NY means that there exist some possible worlds in which John leaves NY. Another view of modality relates more to a speaker X  X  attitude toward a proposition (McShane, Nirenburg, and Zacharski). using the term  X  X odality/negation (MN) X  to refer to our resources (lexicons) and processes(taggers).Weadopttheviewthatmodalityincludesseveraltypesofattitudes that a speaker might have (or not have) toward an event or state. From the point of view of the reader or listener, modality might indicate factivity, evidentiality, or senti-ment. Factivity is related to whether an event, state, or proposition happened or didn X  X  happen. It distinguishes things that happened from things that are desired, planned, or probable. Evidentiality deals with the source of information and may provide clues to the reliability of the information. Did the speaker have first-hand knowledge of what he or she is reporting, or was it hearsay or inferred from indirect evidence?
Sentiment deals with a speaker X  X  positive or negative feelings toward an event, state, or proposition.
 are related to factivity. Beyond the core cases of modality, however, we include some aspects of speaker attitude such as intent and desire. We included these because they are often not separable from the core cases of modality. For example, He had to go may includetheideasthatsomeonewantedhimtogo,thathemightnothavewantedtogo, that at some point after coercion he intended to go, and that at some point he was able to go (Larreya 2009).
 target of the triggering modality) and H is the holder (experiencer or cognizer of the modality). Some of the eight factivity-related modalities may overlap with sentiment or evidentiality. For example, want indicates that the proposition it scopes over may not be a fact (it may just be desired), but it also expresses positive sentiment toward the proposition it scopes over. We assume that sentiment and evidentiality are covered under separate coding schemes, and that words like want would have twotags, one for sentiment and one for factivity. 5. The Modality/Negation Annotation Scheme
The challenge of creating an M Nannotation scheme was to deal with the complex scopingofmodalitieswitheachotherandwithnegation,whileatthesametimecreating a simplified operational procedure that could be followed by language experts without special training. Here we describe our M Nannotation framework, including a set of linguistic simplifications, and then we present our methodology for creation of a publiclyavailableMNlexicon.Themodalityannotationschemeisfullydocumentedin asetofguidelinesthatwerewrittenwithEnglishexamplesentences(Bakeretal.2010c).
The guidelines can be used to derive hand-tagged evaluation data for English and they also include a section that contains a set of Urdu trigger-word examples. a small corpus of Urdu by hand, which we reserved for future work. The Urdu corpus could be useful as an evaluation corpus for automatically tagged Urdu, such as one derived from rule projection in the Urdu X  X nglish MT system, a method we describe furtherinSection7.Also,althoughwedidnotannotateaverylargeUrducorpus,more data could be manually annotated to train an automatic Urdu tagger in the future. 5.1 Anatomy of Modality/Negation in Sentences
Insentencesthatexpressmodality,weidentifythreecomponents:atrigger,atarget,and aholder.The trigger isthewordorstringofwordsthatexpressesmodalityornegation. The target is the event, state, or relation over which the modality scopes. The holder is 420 theexperiencerorcognizerofthemodality.Thetriggercanbeawordsuchas should , try , or negation is expressed without a lexical trigger. For a typical declarative sentence (e.g., John went to NY ), the default modality is strong belief when no lexical trigger is present.Modalitycanalsobeexpressedconstructionally.Forexample,Requirementcan be expressed in Urdu with a dative subject and infinitive verb followed by a verb that means to happen or befall. 5.2 Linguistic Simplifications for Efficient Operationalization
Six linguistic simplifications were made for the sake of efficient operationalization of the annotation task. The first linguistic simplification deals with the scope of modality and negation. The first given sentence indicates scope of modality over negation. The second sentence indicates scope of negation over modality: ily in the menu of 13 choices shown in Figure 5. First consider the case where negation scopes over modality. Four of the 13 choices are composites of negation scoping over modality. For example, the annotators can choose try or not try as two separate modali-ties. Five modalities (Require, Permit, Want, Firmly Believe, and Believe) do not have a negated form. For three of these modalities (Want, Firmly Believe, and Believe), this is becausetheyareoftentransparenttonegation.Forexample, I do not believe that he left NY sometimes means the same as I believe he didn X  X  leave NY . Merging the two is obviously a simplification, but it saves the annotators from having to make a difficult decision. require and permit . Not requiring P to be true is similar in meaning to permitting P to befalse.Thus,annotatorswereinstructedtolabel not require P to be true as Permit P to be false . Conversely, not Permit P to be true was labeled as Require P to be false . takesplaceasaseconddecision.Forexample,forthesentence John tried not to go to NY , the annotator first identifies go as the target of a modality and then chooses try as the modality. Finally, the annotator chooses false as the polarity of the target. have complex meanings that include components of more than one modality. For ex-ample, if one managed to do something, one tried to do it and one probably wanted to do it. Thus, annotators were provided a specificity-ordered modality list as in Figure 5, andwereaskedtochoosethefirstapplicablemodality.Wenotethatthislistcorresponds to two independent  X  X ntailment groupings, X  ordered by specificity: Inside the entailment groupings, the ordering corresponds to an entailment relation:
For example, succeeds can only occur if tries has occurred. Also, the entailment grouping is taken to be more specific than (ordered before) the ... } entailment grouping. Moreover, both entailment groupings are taken to be more specific than believes , which is not in an entailment relation with any of the other modalities.
 trigger word are tagged as firmly believes . This heuristic works reasonably well for the types of documents we were working with, although one could imagine genres such as fiction in which many sentences take place in an alternate possible world (imagined, conditional, or counterfactual) without explicit marking.
 nested modalities. For a sentence like He might be able to go to NY the target word go is marked as ability, but might is not annotated for Belief modality. This decision was based on time limits on the annotation task; there was not enough time for annotators to deal with syntactic scoping of modalities over other modalities.
 preparation. We felt that identifying the triggers and targets would be most beneficial in the context of machine translation. 5.3 The English Modality/Negation Lexicon Using the given framework, we created an M Nlexicon that was incorporated into an
M Ntagging scheme to be described in Section 6. Entries in the M Nlexicon consist of: (1) A string of one or more words: for example, should or have need of . (2) A part of speechforeachword:Thepartofspeechhelpsusavoidirrelevanthomophonessuchas the noun can . (3) An M Ndesignator: one of the 13 modality/negation cases described previously. (4) A head word (or trigger ): the primary phrasal constituent to cover cases where an entry is a multi-word unit (e.g., the word hope in hope for ). (5) One or more subcategorization codes derived from the Longman Dictionary of Contemporary
English (LDOCE). 422 small seed list of M Ntrigger words and phrases from our modality annotation manual (Baker et al. 2010c). Then, we expanded this small list of M Ntrigger words by running an on-line search for each of the words, specifically targeting free on-line thesauri (e.g., thesaurus.com ), to find both synonymous and antonymous words. From these we manually selected the words we thought triggered modality (or their corresponding negative variants) and filtered out words that we thought didn X  X  trigger modality. The resulting list of M Ntrigger words and phrases contained about 150 lemmas. negation constructions. For example, hunger (in the Want modality class) has a modal reading of  X  X esire X  when combined with the preposition for (as in she hungered for a promotion ), but we do not consider it to be modal when it is used in the somewhat archaic sentence He hungered , meaning that he did not have enough to eat. Thus the
LDOCEcode I associatedwiththeverb hunger washand-changedto I-FOR .Therewere 43 such cases. Once the LDOCE codes were hand-verified (and modified accordingly), the mapping to subcategorization codes was applied.

ModalityLexicon.txt . An example of an entry is given in Figure 6, for the verb need . 6. Automatic Modality/Negation Annotation
An M Ntagger produces text or structured text in which modality or negation triggers and/or targets are identified. Automatic identification of the holders of modalities was beyond the scope of our project because the holder is often not explicitly stated in the sentence in which the trigger and target occur. This section describes two types of MN taggers X  X ne that is string-based and one that is structure-based. 6.1 The String-Based English Modality/Negation Tagger
The string-based tagger operates on text that has been tagged with parts of speech by a Collins-style statistical parser (Miller et al. 1998). The tagger marks spans of words/phrases that exactly match M Ntrigger words in the M Nlexicon described previously, and that exactly match the same parts of speech. This tagger identifies the target of each modality/negation using the heuristic of tagging the next non-auxiliary verb to the right of the trigger. Spans of words can be tagged multiple times with different types of triggers and targets.
 of the sentence-level tags produced by our structure-based tagger, the results of which are described next. Although string-based tagging is fast and reasonably accurate in practice, we opted to focus on the indepth analysis of modality/negation of our SIMT results using the more accurate structure-based tagger. 6.2 The Structure-Based English Modality/Negation Tagger
The structure-based M Ntagger operates on text that has been parsed (Miller et al. 1998). We used a version of the parser that produces flattened trees. In particular, the flattenerdeletesVPnodesthatareimmediatelydominatedbyVPorSandnounphrase (NP) nodes that are immediately dominated by PP or NP. The parsed sentences are processed by TSurgeon rules. Each TSurgeon rule consists of a pattern and an action.
The pattern matches part of a parse tree and the action alters the parse tree. More specifically, the pattern finds an M Ntrigger word and its target and the action inserts tags such as TrigRequire and TargRequire for triggers and targets for the modality
Require. Figure 7 shows output from the structure-based M Ntagger. ( Note that the sentence is disfluent: Pakistan which could not reach semi-final, in a match against South
African team for the fifth position Pakistan defeated South Africa by 41 runs. ) The example shows that could is a trigger for the Ability modality and not is a trigger for negation.
Reach isatargetforbothAbilityandNegation,whichmeansthatitisinthecategoryof  X  X  is not able [to make P true/false] X  in our coding scheme. Reach is also a trigger for the Succeed modality and semi-final is its target.
 the M Nlexicon along with a set of 15 templates. Each template covers one situation such as the following: the target is the subject of the trigger; the target is the direct objectofthetrigger;thetargetheadsaninfinitivalcomplementofthetrigger;thetarget is a noun modified by an adjectival trigger, and so on. The verb class codes indicate 424 whichtemplatesareapplicableforeachtriggerword.Forexample,atriggerverbinthe transitive class may use two target templates, one in which the trigger is in active voice and the target is a direct object ( need tents ) and one in which the trigger is in passive voice and the target is a subject ( tents are needed ).
 mostcommontriggerwordsinordertoidentifyanddebugthemostbroadlyapplicable templates. We then used LDOCE toassign verb classes tothe remaining verbal triggers in the M Nlexicon, and we associated one or more debugged templates with each verb class. In this way, the initial corpus work on a limited number of trigger words was generalizedtoalongerlistoftriggerwords.BecausetheTSurgeonpatternsaretailored to the flattened structures produced by our parser, it is not easily ported to new parser outputs. The M Nlexicon itself is portable, however. Switching parsers would entail writing new TSurgeon templates, but the trigger words in the M Nlexicon would still be automatically assigned to templates based on their verb classes.
 sentence like They were required to provide tents . The pattern X  X ction pair is intended to beusedafterapre-processing stage inwhichlabelssuch as X  X oicePassive X  and X  X UX X  have been assigned.  X  X oicePassive X  is inserted by a pre-processing TSurgeon pattern because, in some cases, the target of a passive modality trigger word is in a different location from the target of the corresponding active modality trigger word.  X  X UX X  is inserted during pre-processing to distinguish auxiliary uses of have and be from their uses as main verbs. The pattern portion of the pattern X  X ction pair matches a node with label VB that is not already tagged as a trigger and that is passive and dominates the string X  X equired X .TheVBnodeisalsoasistertoanSnode,andtheSnodedominatesa
VBthatisnotanauxiliary( provide inthiscase).Theactionportionofthepattern X  X ction pair inserts the string  X  X argReq X  as the second daughter of the second VB and inserts the string  X  X rigReq X  as the second daughter of the first VB.
 thewholemodalitylexicon.Thespecificlexicalitem, required ,wasreplacedwithavari-able, as were the labels  X  X rigReq X  and  X  X argReq. X  The pattern was then given a name,
V3-passive-basic, where V3 is a verb class tag from LDOCE (described in Section 5.3) for verbs that take infinitive complements. We then looked up the LDOCE verb class labelsforalloftheverbsinthemodalitylexicon.Usingthisinformation,wecouldthen generate a set of new, verb-specific patterns for each V3 verb in the modality lexicon. 6.3 Evaluating the Effectiveness of Structure-Based MN Tagging
Weperformedamanualinspectionofthestructure-basedtaggingoutput.Wecalculated precision by examining 229 instances of modality triggers that were tagged by our tagger from the English side of the NIST 09 MTEval training sentences. We analyzed precision in two steps, first checking for the correct syntactic position of the target and then checking the semantic correctness of the trigger and target. For 192 of the 229 triggers (around 84%), the targets were tagged in the correct syntactic location.
Figure 8, the word must is a modality trigger word, and the correct target is the first non-auxiliaryverbheadingaverbphrasethatiscontainedinthesyntacticcomplement of must . The syntactic complement of must is the verb phrase be found to this problem .
Thesyntacticheadofthatverbphrase, be ,isskippedbecauseitisanauxiliaryverb.The correct (embedded) target found is the head of the syntactic complement of be . ticallycorrecttags.Inthisexample, must istaggedas TrigBelief ,wherethecorrecttag wouldbe TrigRequire .Also,becausetheMNlexiconwasusedwithoutrespecttoword sense, words were sometimes erroneously identified as triggers. This includes non-modal uses of work (work with refugees), reach (reach a destination), and attack (attack aphysical object),inconstrasttomodalusesofthesewords: work for peace (effort), reach a goal (succeed), and attack a problem (effort). Fully correct tagging of modality would need to include word sense disambiguation.
 tactic position. In 12 of 37 incorrectly tagged instances the targets are inside compound nouns or coordinate structures (NP or VP), which are not yet handled by the modality tagger.Theremaining25ofthe37incorrectlytaggedinstanceshadtargetsthatwerelost becausethetaggerdoesnotyethandleallcasesofnestedmodalities.Nestedmodalities occur in sentences like They did not want to succeed in winning where the target words want and succeed arealsomodalitytriggerwords.Propertreatmentofnestedmodalities requires consideration of scope and compositional semantics.
 triggerand/ortarget.In They did not want to succeed in winning , not ismarkedasatrigger for negation, want is marked as a target of negation and a trigger of wanting, succeed is markedasatriggerofsucceedingandatargetofwanting,and win ismarkedasatarget of succeeding. The second step in the treatment of nested modalities occurs during tree grafting, where the meanings of the nested modalities are composed. The tree grafting program correctly composes some cases of nested modalities. For example, the tag
TrigAble composedwith TrigNegation resultsinthetargettag TargNOTAble ,asshown in Figure 9. In other cases, where compositional semantics are not yet accommodated, the tree grafting program removed target labels from the trees, and those cases were counted as incorrect for the purpose of this evaluation.
 426 was the correct syntactic target, but not the correct semantic target. Decision would be a better target than taken in The decision should be taken on delayed cases on the basis of merit. We counted sentences with semantically light targets as correct in our evaluation because our goal was to identify the syntactic head of the target. The semantics of the targetisageneralissue,andweoftenfindlexico-syntacticfluffbetweenthetriggerand the most semantically salient target in sentences like We succeeded in our goal of winning the war where  X  X uccess in war X  is the salient meaning.
 noun phrases and prepositional phrases: There was no place to seek shelter ; The buildings should be reconstructed, not with RCC, but with the wood and steel sheets. More complex constructionalandphrasaltriggerswerealsomissed: President Pervaiz Musharraf has said some omissions from our M Nlexicon: It is not possible in the middle of winter to re-open the roads. Further annotation experiments are planned, which will be analyzed to close such gaps and update the lexicon as appropriate.

At best we could count instances of sentences containing trigger words that were not tagged. We are also aware of many cases of modality that were not covered such as the modal uses of the future tense auxiliary will as in That X  X l be John (conjecture), I X  X l do the dishes (volition), He won X  X  do it (non-volition), and It will accommodate five (ability) (Larreya 2009). Because of the complexity and subtlety of modality and negation, how-ever, it would be impractical to count every clause (such as the not rest unless clause above) that had a nuance of non-factivity. 7. Semantically Informed Syntactic MT This section describes the incorporation of our structured-based M Ntagging into an
Urdu X  X nglish machine-translation system using tree grafting for combining syntactic symbols with semantic categories (e.g., modality/negation). We note that a de facto
Urdu M Ntagger resulted from identifying the English M Ntrigger and target words in a parallel English X  X rdu corpus, and then projecting the trigger and target labels to the corresponding words in Urdu syntax trees. 7.1 Refinement of Translation Grammars with Semantic Categories
We used synchronous context-free grammars (SCFGs) as the underlying formalism for our statistical models of translation. SCFGs provide a convenient and theoretically grounded wayofincorporating linguistic information intostatistical models of transla-tion,byspecifyinggrammarruleswithsyntacticnon-terminalsinthesourceandtarget languages. We refine the set of non-terminal symbols so that they not only include syntactic categories, but also semantic categories.
 introduction of his hierarchical phrase-based machine translation system, Hiero. Hiero uses grammars with a single non-terminal symbol  X  X  X  rather than using linguistically informed non-terminal symbols. When moving to linguistic grammars, we use Syntax Augmented Machine Translation (SAMT) developed by Venugopal, Zollmann, and
Vogel (2007). In SAMT the  X  X  X  symbols in translation grammars are replaced with nonterminal categories derived from parse trees that label the English side of the
Urdu X  X nglish parallel corpus. 1 We refine the syntactic categories by combining them with semantic categories. Recall that this progression was illustrated in Figure 3. ties using an extraction procedure that requires parse trees for one side of the parallel corpus. Although it is assumed that these trees are labeled and bracketed in a syntac-tically motivated fashion, the framework places no specific requirement on the label inventory. We take advantage of this characteristic by providing the rule extraction algorithm with augmented parse trees containing syntactic labels that have semantic annotations grafted onto them so that they additionally express semantic information. 1. The English sentences in the parallel training data are parsed with a 2. The English sentences are MN-tagged by the system described herein and 3. The modality/negation and entity markers are grafted onto the syntactic although we focus the discussion here on the modality and negation, our framework isgeneralandwewereabletoincorporateothersemanticelements(specifically,named entities) into the SIMT effort.
 trees are presented, along with word alignments (produced by the Berkeley aligner), to the rule extraction software to extract synchronous grammar rules that are both 428 syntactically and semantically informed. These grammar rules are used by the decoder toproducetranslations.Inourexperiments,weusedtheJoshuadecoder(Lietal.2009), the SAMT grammar extraction software (Venugopal and Zollmann 2009), and special purpose-built tree-grafting software.
 phrase rules are augmented with modality and negation, taken from the semantic categories listed in Table 2. Because these get marked on the Urdu source as well as theEnglish translation, semantically enriched grammars alsoactasverysimplenamed entity or M Ntaggers for Urdu. Only entities, modality, and negation that occurred in the parallel training corpus are marked in the output, however. 7.2 Tree-Grafting Algorithm
Theoverall scheme ofourtree-graftingalgorithmistomatchsemantic tagstosyntactic categories. There are two inputs to the process. Each is derived from a common text file of sentences. The first input is a list of standoff annotations for the semantically taggedwordsequencesintheinputsentences,indexedbysentencenumber.Thesecond is a list of parse trees for the sentences in Penn Treebank format, indexed by sentence number.
 example,thesentence The students are able to swim istaggedas The students are TrigAble to TargAble swim . The distinction between  X  X egation X  and  X  X OT X  corresponds to the difference between negation that is inherently expressed in the triggering lexical item and negation that is expressed explicitly as a separate lexical item. Thus, Iachieved my goal is tagged  X  X ucceed X  and I did not achieve my goal is tagged as  X  X OTSucceed, X  but I failed to win is tagged as  X  X ucceedNegation, X  and I did not fail to win is tagged as  X  X OTSucceedNegation. X  iterate over the list of semantic tags. For each semantic tag, there is an associated word or sequence of words. For example, the modality tag TargAble may tag the word swim . ing syntactic parse tree that dominates that word. For a word sequence, we find and compare the parent nodes for all of the words. Each node in the syntax tree has a category label. The following tests are then made and tree grafts applied: 430 syntactictreenodeasthefinalresult.Thealgorithmkeepsthelasttagseenasthetagof precedence. In practice, we established a precedence ordering for modality/negation tags over named entity tags by grafting named entity tags first and modality/negation second.Ourintuitionwasthat,incaseofatie,finer-grainedverbalcategorieswouldbe more helpful to parsing than finer-grained nominal categories. wastaggedbothasaMNtargetandaMNtrigger,wegaveprecedencetothetargettag.

This is because, although M Ntargets vary, M Ntriggers are generally identifiable with lexical items. Finally, we used the simplified specificity ordering of M Ntags described inSection5.2toensureprecedenceofmorespecifictagsovermoregeneralones.Table2 liststhemodality/negationtypesfromhighest(Requiremodality)tolowest(Negation) precedence. 3 7.3 SIMT Results
We evaluated our tree grafting approach by performing a series of translation experi-ments.Eachversionofourtranslationsystemwastrainedonthesamebilingualtraining data. The bilingual parallel corpus that we used was distributed as part of the 2008
NIST Open Machine Translation Evaluation Workshop. 4 The training set contained 88,108 Urdu X  X nglish sentence pairs, and a bilingual dictionary with 113,911 entries.
For our development and test sets, we split the NIST MT-08 test set into two portions (with each document going into either test or dev, and preserving the genre split).
Our test set contained 883 Urdu sentences, each with four translations into English, and our dev set contained 981 Urdu sentences, each with four reference translations.
To extract a syntactically informed translation model, we parsed the English side of the training corpus using a Penn Treebank X  X rained parser (Miller et al. 1998). For the experiments that involved grafting named entities onto the parse trees, we tagged the English side of the training corpus with the Phoenix tagger (Richman and Schone 2008).Weword-alignedtheparallelcorpuswiththeBerkeleyaligner.Allmodelsuseda 5-gram language model trained on the English Gigaword corpus (v5) using the SRILM toolkit with modified K Nsmoothing. The Hiero translation grammar was extracted using the Joshua toolkit (Li et al. 2009). The other translation grammars were extracted using the SAMT toolkit (Venugopal and Zollmann 2009). effort. 5 Theexperimentsarebrokenintothreegroups:baselines,syntax,andsemantics.
To contextualize our results we experimented with a number of different baselines that were composed from two different approaches to statistical machine translation X  phrase-based and hierarchical phrase-based SMT X  X long with different combinations of language model sizes and word aligners. Our best-performing baseline was a Hiero model. The Bleu score for this baseline on the development set was 22.9 Bleu points. experiments on the effects of incorporating semantic elements (e.g., named entities and modality/negation)intothetranslationgrammars.Inourdevtestsetourtaggerstagged on average 3.5 named entities per sentence and 0.35 M Nmarkers per sentence. These wereincludedbygraftingmodality,negation,andnamed-entitymarkersontotheparse trees. Individually, each of these made modest improvements over the syntactically informedsystemalone.GraftingnamedentitiesontotheparsetreesimprovedtheBleu score by 0.2 points. Modality/negation improved it by 0.3 points. Doing both simulta-neouslyhadanadditiveeffectandresultedina0.5Bleuscoreimprovementoversyntax alone.Thisimprovementwasthelargestimprovementthatwegotfromanythingother than the move from linguistically naive models to syntactically informed models. statistically significant (Koehn 2004). All of the results were a significant improvement over Hiero (at p  X  0 . 01). The difference between the syntactic system and the syntactic system with named entities is not significant (p = 0 . 38). The differences between the 432 syntactic system and the syntactic system with MN, and between the syntactic system and the syntactic system with both M Nand named entities were both significant at (p  X  0 . 05).
 the pre-SIMT results and the translation produced by a human (reference). An error analysisofthisexampleoutputillustratesthatSIMTenhancementshaveresultedinthe elimination of misleading translation output in several cases: 1. pre-SIMT : China had the experience of Pakistan X  X  first nuclear bomb. 2. pre-SIMT : the nuclear bomb in 1998 that Pakistan may experience 3. pre-SIMT : He said that it is also present proof of that Dr. Abdul Qadeer
The article in question pertains to claims by Thomas Reid that China allowed Pakistan to detonate a nuclear weapon at its test site. In the first example, however, the reader is potentially misled by the pre-SIMT output to believe that Pakistan launched a nuclear bombonChina.TheSIMToutputleavesoutthementionofPakistan,butcorrectlycon-veysthefirmbeliefthatthebombeventisa test (closelyresemblingtheterm experiment inthehumanreference),notatruebombingevent.Thisisclearlyanimprovementover the misleading pre-SIMT output.

Pakistan is (or will be) attacked, through the use of the phrase may experience , where may is poorly placed. (We note here that this is a date translation error, i.e., the month of May should be next to the year 1998, further adding to the potential for confusion.)
Unfortunately, the SIMT output also uses the term experience (rather than experiment , which is in the human reference), but in this case the month is correctly positioned in theoutput,thuseliminatingthepotentialforconfusionwithrespecttothemodality.The lack of a modal appropriately neutralizes the statement so that it refers to an abstract event associated with the atom bomb, rather than an attack on the country. argued to be proof of the nuclear testing relationship between Pakistan and China, the first pre-SIMT output potentially leads the reader to believe that Dr. Abdul Qadeer is aftertheChinesedesign(notthatheactuallyusedit),whereastheSIMToutputconveys the firmbelief that the Chinese design has been used by Dr. Abdul Qadeer. This output very closely matches the human reference.
 coherent English output than that of the linguistically naive system. The figure also shows improvements due to transliteration, which are described in Irvine et al. (2010).
The scores reported in Figure 12 do not include transliteration improvements. 434 8. Conclusions and Future Work
We developed a modality/negation lexicon and a set of automatic M Ntaggers, one of which X  X he structure-based tagger X  X esults in 86% precision for tagging of a standard
LDC data set. The M Ntagger has been used to improve machine translation output by imposing semantic constraints on possible translations in the face of sparse training data. The tagger is also an important component of a language-understanding module for a related project.
 for low-resource languages. We have integrated linguistic knowledge into statistical machine translation in a unified and coherent framework. We demonstrated that augmenting hierarchical phrase-based translation rules with semantic labels (through  X  X rafting X ) resulted in a 0.5 Bleu score improvement over syntax alone.
 demonstrating success on the integration of semantic aspects of language bodes well for additional improvements based on the incorporation of other semantic aspects. For example, we hypothesize that incorporating relations and temporal knowledge into the translation rules would further improve translation quality. The syntactic grafting framework is well-suited to support the exploration of the impact of many different types of semantics on MT quality, though in this article we focused on exploring the impact of modality and negation.
 improvements in modality/negation identification are likely to lead to further gains in translation performance. Such a study would benefit from the inclusion of a more de-tailedmanualevaluationtodetermineifmodalityandnegationisadequatelyconveyed in the downstream translations. This work would be additionally enhanced through experimentation on other language pair(s) and larger corpora.
 of MT and semantics. Efforts underway in DARPA X  X  GALE program demonstrated the potential for combining MT and semantics (termed distillation ) to answer the informa-tion needs of monolingual speakers using multilingual sources. Proper recognition of modalities and negation is crucial for handling those information needs effectively.
In previous work, however, semantic processing proceeded largely independently of the MT system, operating only on the translated output. Our approach is significantly different in that it combines syntax, semantics, and MT into a single model, offering the potential advantages of joint modeling and joint decision-making. It would be interesting to explore whether the integration of MT with syntax and semantics can be extended to provide a single-model solution for tasks such as cross-language informa-tion extraction and question answering, and to evaluate our integrated approach (e.g., using GALE distillation metrics).
 Acknowledgments References 436
