 Spatial clustering is an active research area in the field of spatial data mining, which groups objects into meaningful subclasses based on their spatial and non-spatial attributes [1], [2]. In spatial data, spatial attributes, such as coordinates, describe the locations of objects. Non-spatial attributes include the non-spatial features of objects, such as oil saturation, population or species. Meanwhile, spatial correlation generally exists in spatial datasets, describing the dependent relationship on the non-spatial attributes across space.

Spatial clustering has previously been based on only the spatial attributes of the data. However, the non-spatial attributes may have a significant influence on the results of the clustering process. For example, in image processing, the general procedure for region-based segmentation compares a pixel with its im-mediate surrounding neighbors. Region growing is heavily based on not only on the location of pixels but also on the attributes of those pixels [3].
Meanwhile, spatial correlation is always considered important for spatial datasets. Spatial correlation always indicates the dependency between the spa-tial and non-spatial attributes, with the chance that some cause and effect lead to it. Of particular interest the higher degrees of spatial correlation [2].
In order to identify meaningful clusters from spatial datasets, spatial cluster-ing methods need to consider spatial attributes, non-spatial attributes and in-herent spatial correlations during the clustering process. We will illustrate these requirements using the following examples. Fig. 1 (a) includes two round shaped groups. The grey values of the left group change to darker consistently from the center, which shows strong spatial correlation. The grey values of the right group are randomly distributed, indicating weak or no spatial correlation mean-ing that this group should not be identified as a cluster. Similarly, we should be able to identify an arbitrary shaped cluster with spatial correlation such as the cluster shown in Fig. 1 (b). Fig. 1 (c) shows a raster data set with intensity as the non-spatial attributes. Since the dat a objects are evenly distributed (i.e. cell by cell), without considering the non-spatial attribute, the whole dataset might be clustered into one. However, the values of the non-spatial attribute form two spatially correlated clusters with the non-spatial attribute values differing sig-nificantly at the boundary. Thus, two spatial clusters should be identified from the spatial correlated area in this dataset.

However, most existing methods only focus on the spatial attributes or con-sider spatial and non-spatial independently. These methods are not suitable for those spatial datasets in which the non-spatial attributes and spatial correlation play important roles.

Spatial entropy is the extension of Shannon Entropy with the spatial con-figuration. It measures the distribution of a non-spatial attribute in the spatial domain [4]. In this paper, we propose to apply spatial entropy to measure local non-spatial attribute similarity and spatial correlation. A novel spatial entropy-based clustering method, called SEClu, is proposed to take into account spatial attributes, non-spatial attributes and spatial correlations.

Spatial clustering based on both non-spatial attributes and spatial correlation is a new research topic. To our best knowl edge, none of the previous methods are able to identify useful clusters directly from spatial correlation, hence the focus of this research. The main contributions of this paper are summarized below.
First, we establish that spatial entropy is an unbiased measure of local non-spatial attribute similarity and spatial correlation. Specifically, spatial entropy decreases for both local non-spatial attribute similarity and spatial correlation, thus a smaller spatial entropy value denotes that the corresponding spatial data is more likely to be grouped into a cluster.
Second, we propose a novel spatial clustering method named spatial entropy-based clustering, SEClu. SEClu discovers clusters that are not only dense spa-tially but that also have high spatial correlation based on their non-spatial at-tributes across that space.

Third, SEClu is demonstrated using both synthetic data and data from a real application. Results show that SEClu discovers more meaningful spatial clusters than methods considering spatial and non-spatial attributes independently.
The remainder of the paper is organized as follows. In Section 2, we present some related work. Section 3 introduces spatial entropy as the measure of spatial correlation and proposes a new density-based spatial clustering algorithm termed SECLu. Experiments on synthetic and rea l datasets are performed in Section 4. Section 5 summarizes the paper and dis cusses priorities for future work. In this section, we review some related spatial clustering methods.

DBSCAN is the first proposed density-based spatial clustering method. It starts from an arbitrary point q by performing a neighborhood query. If the neighborhood contains fewer than MinPts points, then point q is labeled as noise. Otherwise, a cluster is created and all points in q  X  X  neighborhood are placed in this cluster. Then the neighborhood of each of q  X  X  neighbors is examined to see if it can be added to the cluster. If so, the process is repeated for every point in this neighborhood, and so on. If a cluster cannot be expanded further, DBSCAN chooses another arbitrary unlabelled point and repeats the process. Although DBSCAN gives extremely good results and is efficient in many datasets, it is not suitable for cases where the non-spatial attributes play a role in determining the desired clusters since it does not take into consideration the non-spatial attributes in the dataset [1],[3].

Over the years, very few algorithms hav e been proposed for dealing with both spatial and non-spatial attributes during clustering process. One option is to handle non-spatial attributes and spatial attributes in two separate steps, as described in CLARANS [5]. The other option is to deal with the non-spatial at-tributes and spatial attributes together in the clustering process. The similarity functions for non-spatial attributes, and distance functions for spatial attributes, are handled simultaneously in order to define the overall similarity between ob-jects. Algorithms that have taken this approach include GDBSCAN [1], DBRS [3], and Clustering of Multi -represented Objects [6].

GDBSCAN [1] takes into account the non-spatial attributes of an object as a  X  X eight X  attribute, which is defined by the weighted cardinality of the singleton containing the object. The weight can be the size of the area of the cluster-ing object, or a calculated value from sev eral non-spatial attributes. DBRS [3] introduces the concept of  X  X urity X  to determine the categorical attributes of ob-jects in the neighborhood.  X  X urity X  is defined as the percentage of objects in the neighborhood, with the same characteristic for a particular non-spatial attribute as the center object. For non-spatial attributes, this can avoid creating clusters of points with different values, even though these points may be close to one other. However,  X  X urity X  is only defined for categorical non-spatial attributes. Clustering of Multi-represented Obj ects (CMRO) [6] extends DBSCAN by re-trieving information from one attribute to multiple attributes. Within a set of attributes, either spatial or non-spatial,  X  X ensity reachability X  is defined as the union or intersection of the selected attributes.

Even though all of the above methods consider the significance of non-spatial attributes, they ignore the spatial correlations between the spatial and non-spatial attributes. In this paper, we are interested in identifying arbitrary-shaped clusters based on spatial correlations. Since non-spatial attributes in a spatially correlated cluster usually change continuously, the values of non-spatial attributes might differ sig-nificantly for the whole cluster. Therefor e, in this research, we require similarity in a small area but not in the whole cluster.

In the following, we will first introduce spatial entropy and then justify that it is an unbiased measure in spatial clustering with respect to local non-spatial similarity and spatial correlation. 3.1 Spatial Entropy Spatial entropy is an information measure of non-spatial attributes that also takes into account the influence of spatial spaces. Various forms of spatial entropy have been developed for how to quantify the extent of the role played by space [4],[7]. In this paper, we select the one from [4] because it is simple and can handle both discrete and continuous non-spatial attributes. Given a dataset D with a non-spatial attribute prop in spatial spaces { S 1  X  X  X  S in category D i over the whole dataset D , i.e. p i = | D i | / | D | and p i =1.The intra-distance of D i , denoted by d int i is the average distance between objects in D i (shown in Eq. (1)). The extra-distance of D i , denoted by d ext i is the average distance of objects in D i to other partition classes of D (shown in Eq. (2)).
InEq.(1),when D i is empty or contains only one object, we assume its intra-distance is very small and a small constant  X  is assigned to d int i to avoid the influence of null values on the computation. In Eq. (2), when D i includes all of the objects in D , i.e. all objects have similar values of prop , we assume that the extra-distance d ext i is very large, and assign the extra-distance with a large constant  X  . dist ( j, k ) is the distance between objects j and k in spatial spaces. Definition 1. The spatial entropy of dataset D based on its partition { D 1 ,  X  X  X  , D ,  X  X  X  ,D n } is defined as (from [4]) : In this definition, a spatial configuration d int i /d ext i is added as a weight factor in the Shannon Entropy. The weight factor decreases when either the intra-distance decreases or the ex tra-distance increases, wh ich enables spatial entropy to measure the spatial distribution. Besides, given D and its partition, the spatial entropy is similar to Shannon Entropy in that it reaches the maximum value when p 1 =  X  X  X  p i  X  X  X  = p n . 3.2 Using Spatial Entropy in Spatial Clustering In this section, we demonstrate that spatial entropy is a monotonic decreasing function for local non-spatial attribute similarity and spatial correlation. Spatial Entropy vs. Local Non-Spatial Similarity. The non-spatial at-tribute prop of the spatial dataset D can be viewed as a random variable with its probability density function approximated using a histogram. If the non-spatial attribute prop is random, it follows an even distribution. As the local non-spatial similarity increases, prop tends to be more concentrated.
It has been shown that Shannon entropy of an even distribution reaches max-imum value and tends to decrease as the concentration of the distribution in-creases. Spatial Entropy H s is a special form of Shannon entropy and has a spatial configuration weight factor d int i /d ext i . Even though each object X  X  non-spatial attribute is correlated within the spatial spaces, the probability distri-does not influence the property of spatial entropy H s , which is a measure of ran-domness. Therefore, when prop follows an even distribution, its spatial entropy value reaches the maximum, otherwise the spatial entropy H s decreases as the concentration of the probability distribution increases.

In Fig. 2 (a), datasets 1 and 2 have the same spatial attributes, but points in dataset 2 have more similar non-spatial attributes than dataset 1. From the histograms, it is evident that more than 60% of points in dataset 2 have grey values between [150,200] while values in dataset 1 are random. Fig. 2 (b) shows that the spatial entropy value decreases from dataset 1 to dataset 2. Spatial Entropy vs. Spatial Correlation. Spatial entropy measures spatial correlation by quantifying spatial diversity. As in [8], the First Law of Geogra-phy states  X  everything is related to everything else, but near things are more related than distant things X . It implies not only the general existence of spatial correlation but also, as in [4], spatial diversity increases when either the distance between different objects decreases or the distance between similar entities in-creases. The intra-distance and the extra-distance are integrated into the spatial entropy using the form of d int i /d ext i , which keeps the spatial entropy decreasing when similar objects are close and divers e objects are far from each other. Spa-tial objects where similar non-spatial attribute values are close and where spatial objects with different non-spatial attributes are far from each other, d int i /d ext i de-creases. Therefore, spatia l entropy decreases when spa tial correlation increases.
In Fig. 2 (a), datasets 2 and 3 have the same spatial and non-spatial attributes, but different distributions for the non-spatial attribute. Here the spatial corre-lation increases from 2 to 3 (high value points centered and low value in the periphery), and the spatial entropy va lue decreases accordingly, as shown in Fig. 2 (b). 3.3 A Spatial Entropy-Based Spatial Clustering Method In this section, we propose a novel spatial clustering method, Spatial Entropy-based Clustering (SEClu). Given a spatial dataset SD with a non-spatial at-tribute prop , a symmetric distance function dist , and parameters Eps , MinNum and MaxSp , we introduce the following definitions for SEClu.
 Definition 2. The neighborhood of spatial object p, denoted by N Eps ( p ) ,is defined as N Eps ( p )= { q  X  SD | dist ( p, q )  X  Eps } (from [9]) . SEClu extends DBSCAN by applying spatial entropy to control the local non-spatial similarity and spatial correlation of N Eps ( p ). The previous discussion demonstrates that the spatial entropy value decreases for the local non-spatial attribute similarity and that spatial corre lation increases. Th erefore, SEClu in-troduces the maximum threshold of spatial entropy, denoted by MaxSp . In SEClu, a core object is an object whose neighborhood (1) has at least MinNum neighbors in spatial spaces, (2) has similar non-spatial attributes and high spatial correlation in its neighborhood satisfying H s ( N Eps ( p )) MaxSp . A border object is a neighbor object of a core object which is not a core object itself. Objects other than core objects or border objects are noise . Definition 3. A spatial object p is directly density-spEntropy-reachable to an object q w.r.t Eps, MinNum, MaxSp if (1) q  X  N Eps ( p ) ; (2) N Eps ( p )  X  MinNum ;and (3) H s ( N Eps ( p ))  X  MaxSp .
 In the above definition, the second conditi on examines the den sity of the neigh-borhood of p . The third condition examines non-spatial attribute of the neigh-borhood of p . A smaller value of spatial entropy H s implies objects in N Eps ( p ) have higher non-spatial similarity and spatial correlation.
 Definition 4. Spatial objects p and q are density-spEntropy reachable ( DSR-reachable ) w.r.t Eps, MinNum, MaxSp, denoted by DSR ( p,q ) ,ifthere is a chain of objects p 1  X  X  X  p n , p 1 = q , p n = p such that p i +1 is directly density-spEntropy reachable from p i .
 Definition 5. A density-spEntropy based cluster C is a non-empty subset of SD satisfying:  X  p, q  X  SD ,if p  X  C and DSR(p,q) holds, then q  X  C . It is obvious that for each pair of objects ( p, q )  X  C ,when C is a density-spEntropy based cluster, DSR ( p, q ) holds. Therefore, SEClu finds a cluster by identifying all objects that are density-spEntropy reachable.
 Algorithm 1. SEClu ( SD , Eps , MinNum , MaxSp )
As shown in Algorithm 1, SEClu starts by querying the neighborhood of an arbitrary object p in spatial space to see if it is dense enough N Eps ( p )  X  MinNum .Ifnot, p is labeled as noise, otherwise SEClu continues to check the non-spatial attribute. If the non-spatial attribute of p  X  X  neighborhood has a random pattern, i.e., it cannot satisfy H s ( N Eps ( p ))  X  MaxSp ,then p is labeled as noise. Otherwise, a new cluster C is created and all objects x  X  N Eps ( p )are placed in C . The neighborhood of each of p  X  X  neighbors is examined in the same way to see if it can be added to C . This process is repeated until all objects that are density-spEntropy reachable to p have been added to cluster C .Ifcluster C cannot be expanded further, SEClu chooses another unlabelled object and repeats this process until all objects hav e been assigned to a cluster or labeled as noise. The average complexity of SEClu is O ( n (log n + k 2 )), where n is the number of the objects in SD and k is the average number of objects in N Eps ( p i ). Calculating Spatial Entropy Efficiently. In SEClu, the spatial entropy H s is computed on the non-spatial attribute of N Eps ( p ). To be able to use H s to measure the spatial correlation, a partition process of N Eps ( p ) is generated in the first step. Given a spatial dataset D = N Eps ( p ) with the non-spatial attribute prop ,if prop is discrete it is binned into n slots with different values. If prop is continuous, it is binned into n contiguous slots (  X  1 ,  X  X  X  , X  i ,  X  X  X  , X  n )withthe interval of  X  . Then, each object in D is assigned to a unique slot based on its prop value, and a partition of D , denoted by { D 1 ,  X  X  X  ,D i ,  X  X  X  ,D n } , is generated.
The number of subsets n should be selected carefully. If n is too large, each subset may contain a very small number of data and also result in a high compu-tational cost. Sturges X  rule [10] is widely recommended for choosing a histogram interval since it provides a good approximation of the best n in capturing the distribution pattern. In this paper, we adopt the Sturges X  rule, and the subset number n is given by Eq. (4). Since SEClu is a density-based method, an effective way is to assign MinNum to N . In practice, spatial entropy H s is computed numerically . Since prior knowledge of the distribution of prop is always unknown, p i is estimated from the frequency p = | D i | / | D | . d int i and d ext i can be computed from Eqs. (1) and (2), respectively. Assume D i contains k objects, Eq. (1) calculates dist for k ( k  X  1) times, which computes the distance from each object to the other ( k  X  1) objects. To avoid the distance between each pair of objects in D i being computed twice, Eq. (1) can be substituted to a low computation cost formula Eq. (5) when dist is a symmetric function. Eq. (5) does not calculate duplicate distances, which computes dist for k ( k  X  1) / 2 times, half from Eq. (1).

Also, H s needs to be normalized in order to make a fair comparison. It has been demonstrated that d int i  X  2 d ext i [7]. Also, for a discrete random variable its Shannon entropy value satisfies 0  X  X  X  n i =1 p i log 2 ( p i )  X  log 2 n , then: Algorithm 2. Spatial Entropy H s ( D ) In the following, all spatial entropy values are normalized by H s / 2log 2 n  X  [0 , 1]. Algorithm 2 shows the pseudocode for the spatial entropy calculation. Spatial Entropy Parameter Maxsp . In SEClu, the parameters Eps and MinNum can be determined by using the heuristic method in [9]. Besides, given Eps and MinNum , MaxSp can be determined by the following rationale. Meet-ing the requirement of N Eps ( p )  X  MinNum , p should form a core object if it satisfies H s ( N Eps ( p ))  X  MaxSp .Thus,the MaxSp can be determined by seek-ing a threshold that makes the cluster the  X  X hinnest X . As in Fig. 3, when Eps and MinNum are fixed, the core object number is changing with respect to the MaxSp value. The MaxSp threshold is determined with the highest gradient, which appears as the first jump point in Fig. 3. Here all objects with the spatial entropy value higher than the threshold (above the line) are noise and the others are core objects.
 In this section, we evaluate SEClu by applying to both synthetic datasets and a real-world dataset. All experiments are performed on a 2.8GHz PC with 3G memory.
 Experiment one  X  spatial clustering of synthetic datasets This experiment shows the accuracy of SE Clu for identifying clusters with spa-tial correlation. Fig. 4 shows three sample datasets. Each dataset includes x, y coordinates as the spatial attribute and a grey/intensity value as the non-spatial attribute.

The three datasets have different shapes and follow different spatial correlation functions. Fig. 4 (a) includes three round shaped groups. The grey values of points in group 1 decrease as an exponential function with distance from the center. The grey values of group 2 are random. The grey values in group 3 increase linearly with distance to the center. Since both groups 1 and 3 have strong spatial correlation they should be identified as clusters. Group 2 does not form a cluster with spatial correlations and should be labeled as noise. Fig. 4 (b) shows three irregularly shaped groups. The S-shaped and new moon shaped groups have clusters with spatial correlation while the objects in the V-shaped group have random non-spatial attributes and should be identified as noise. Fig. 4 (c) shows a raster dataset (i.e. the obj ects are distributed cell by cell) with a spatial correlated non-spatial attribute. Three clusters exist in the dataset with the non-spatial attribute values varying significantly at the boundary of each cluster.

For SEClu, we set the parameters ( MinNum =18, Eps =0.017, MaxSp =0.29) for datasets (a) and (b) in Fig. 4. Since dataset (c) has evenly distributed spatial attributes, we apply a 5  X  5 window to decide the neighbor objects in Eps ( p i ), and MaxSp is set as 0.3. Fig. 5 shows the clustering results on three datasets. From the figure, it is evident that: first, SEClu discovers clusters with spatial correlations successfully. In Fig. 5 (a), data groups with either high value cen-ter correlation or low value center correlation are identified as clusters, while the random one is labeled as noise. Second, since SEClu is a density-based clustering method, it can discover clusters with irregular shapes, e.g., SEClu identifies the S-shaped and the new moon shaped spatial correlated clusters. Third, SEClu finds clusters with both spatial correlation and high local non-spatial similarity. For example, in Fig. 5 (c) three spatial correlated clusters locate very close to each other. Measuring the local non-spatial attribute similarity, SEClu success-fully separates the three clusters by detecting the significant dissimilarities in the non-spatial attribute.

We also compare SEClu with GDBSCAN [1]. In GDBSCAN, the non-spatial attribute is treated similar to the spatial attributes and has a  X  X eight X . In the experiments, for datasets (a) and (b), the grey value is linearly normalized to the range of the x coordinate and can be viewed as the third coordinate. The parameters to GDBSCAN are set as ( MinPts =18, Eps =0.017), which is simi-lar to the SEClu configuration. For dataset (c), the intensity value is linearly normalized into [0,1] and the non-spatial attribute weight function keeps the p i and p j are two arbitrary objects in the neighborhood. We also use a 5 window as the neighborhood.

Fig. 6 shows the clustering result of GDBSCAN. In datasets (a) and (b), con-sidering the non-spatial attribute as independent from spatial attributes GDB-SCAN incorrectly labels data with random distributed grey values as clusters. In dataset (c), even though spatial correlation exists in the three clusters, the non-spatial attribute changes. Since GDBSCAN only considers non-spatial at-tribute similarity, it is not suitable for identifying clusters in which the values of the non-spatial attribute are dissimilar but that still follow spatial correlations. Compared with the results of GDBSCAN, SEClu finds more meaningful clusters. A detailed accuracy comparison be tween SEClu and GDBSCAN is shown in Table 1. From the table, the accuracy of SEClu to the three datasets is 100% while GDBSCAN is around 66%, which demonstrates SEClu performs better than GDBSCAN in identifying clusters with spatial correlations.
 Experiment Two  X  real application to the census map of Alberta The second experiment is performed on the 2006 Census dataset of Alberta, Canada. In this experiment, our goal is to identify clusters containing strong spatial patterns between population and community locations. There are 5181 community records available in the data set. Each record is represented as a point, with the spatial attributes referring to the coordinates and the non-spatial attribute referring to the population.

We set ( Eps =0.13, MinNum =15, MaxSp =0.3) to SEClu, and the clustering results are shown in Fig. 7 overlaid on the map of the Province of Alberta. In Fig. 7, clusters identified by SEClu, exhibit meaningful spatial patterns. All 7 clusters are around major cities in Alberta, which are downtown centered and have a radial shape extending to the suburb area. Also, the clustered communi-ties close to city centers tend to have more population than those locating in the suburb, which reveals the phenomenon that many more people live in cities as compared to rural areas in Alberta. For example, the population in the cluster area reaches 2.56 million, which counts 76% of the total population in Alberta. This is consistent with records from Alberta Municipal Affairs that 81% of the Alberta population lives in urban cities and only 19% lives in rural area. In this paper, we first demonstrate that spatial entropy is a decreasing func-tion when spatial correlation and local non-spatial attribute similarity increase. Then, we propose a novel spatial cluster ing method, termed SEClu, that is based around the use of spatial entropy. SEClu considers spatial attributes, non-spatial attributes and spatial correlation during the clustering process and can identify arbitrary shaped clusters with spatial correlations. In our experiments, we apply SEClu to synthetic datasets and to a real-world application, and compare the clustering results with those of GDBSCAN. Results show that SEClu can dis-cover meaningful spatial clusters, and perform better than GDBSCAN at finding clusters with spatial correlations.
In the future, we will improve SEClu in terms of the following aspects. First, we will further evaluate SEClu with larger dataset and extend it to be able to deal with more spatial data types, such as polygons. Second, we will apply SEClu to real-world geological datasets, which usually have large amounts of data, complicated spatial correlations and have significance for real applications.
