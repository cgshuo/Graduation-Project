 MOOCs attract diverse users with varying habits. Identify-ing those patterns through clickstream analysis could enable more effective personalized support for student information seeking and learning in that online context. We propose a novel method to characterize types of sessions in MOOCs by mining the habitual behaviors of students within individual sessions. We model learning sessions as a distribution of ac-tivities and activity sequences with a topical N -gram model. The representation offers insights into what groupings of ha-bitual student behaviors are associated with higher or lower success in the course. We also investigate how context in-formation, such as time of day or a user X  X  demographic in-formation, is associated with the types of learning sessions. H.2.8 [ Database Management ]: Database Applications Massive Open Online Course; MOOCs; learning behavior patterns; sequence mining
Massive Open Online Courses (MOOCs) have recently garnered widespread public attention for their potential to make high quality education accessible to everyone. Re-searchers, educators, and the general public have become interested in understanding learning experiences in MOOCs. A major component of the learning experience is navigation through course content. The MOOC literature so far has focused on a summative view of user participation over ex-tended periods of time, such as over the whole course or over a whole week -trying to identify different groups of users based on aggregated statistics such as total number of lectures and assignments completed by the student [1]. We develop a more fine grained representation of MOOC clickstream data using topical N-gram models with single
Table 1: Statistics of the two Coursera MOOCs. sessions as the unit of analysis, with the goal of identifying habbits and strategies.

In a MOOC, each student X  X  complete interaction with the course materials is recorded as a clickstream, similar to other online environments. However, the different nature of the interaction provides new challenges for the community of researchers developing techniques for clickstream analysis. Understanding how students interact with MOOCs is a cru-cial issue because it affects how MOOC engineers and in-structors design future online courses. Effective analysis of clickstream data could enable dynamic interventions to im-prove success of students to achieve their information access goals. What makes the mining of learning behavior pat-terns hard is that learning sessions are typically composed of a range of loosely coordinated activities. The composition of a session is highly variable depending on factors such as learner engagement and time available. Previous behavior mining methods, such as those designed for search engine clicklog analysis, are not quite rich enough to capture these distinctions. We propose to leverage topical N -gram models to (1) capture the typical combination of learning activities and (2) identify frequent learning activity sequence which can suggest learning strategies. Thus we can characterize each session of MOOC interaction as a composition of such activities or activity sequence patterns. We find that there are typically a small number of latent session types across MOOCs we have studied. In this paper we present results that demonstrate that we can observe meaningful differences in student orientations towards course content. To under-stand how the learning sessions can be affected by context or individual user X  X  engagement level, we mine the associations between user session type and context information captured by system trace logs.
Our dataset consists of two Coursera 1 MOOCs, one is about virtual instruction(VI) and the other one is about personal financial planning(FP). They were both offered in 2013. Table 1 shows an overview of the data we extracted from the system trace logs. https://www.coursera.org/ Table 2: Number of students within each final grade level.

Pre-processing is the first part of Web Usage Mining which includes the domain dependent tasks such as data cleaning and session identification. In our case, a new session is con-sidered to begin when the time interval between two suc-cessive inter-transaction clicks adds up to 60 minutes. The visited or submitted contents during each session are con-sidered to be part of that session.

We extract 18 types of learning activities from the trace data. In particular, we distinguish between submitted quizzes, assignments, peer assessments and those that are attempted but not submitted. We also differentiate passive activities such as browsing and active activities such as publishing a post in the forums. Only the underlined activities are graded. We extract information for each session and each user. The contextual information associated with each session includes: (1) Time information, including Hour of the day , Day Pe-riod , Day of the week and Course week . (2) Device used dur-ing the current session. The device can be Desktop, Tablet or Mobile. (3) Length of the session. A Short session is shorter than 5 minutes. A Long session is longer than 30 minutes. Otherwise the session length is Medium.
 Information extracted for each user includes: Gender , Age , Country of Origin and Final Grade . Gender and Age are only known for the users who filled out the pre-course survey. Country of Origin is determined based on the IP address.
Peer assessment is the practice of classmates evaluating each other X  X  work.
In-video quizzes are quizzes that pop up during the lec-tures.
 As there are more than 100 different countries of origin, we group them into US and NON-US . As for achievement, we group the users into four groups according to their final grade. Students who successfully complete this class with a grade of around 60% -70% will receive a Statement of Accomplishment. Students who complete this course with a grade of 90% or better will receive a Statement of Accom-plishment with Distinction from Coursera. The statistics are shown in Table 2.
In this section, we describe how we model each learning session with a topical N -gram model and how we extract the typical context associated with different types of learning sessions.
A learning session can be characterized as a probabilis-tic combination of interaction and interaction sequence pat-terns. To motivate our work with intuitive examples, an intense learning session may be one that includes an as-signment submission. In the same session, the user may watch video lectures to prepare for the assignment or go to the discussion forums to find related discussions. Just as word order and phrases are often critical to capturing the meaning of text in many text mining tasks, the or-der of activities within sessions is important for capturing a user X  X  learning strategies. For example, a sequence,  X  X i-nalQuizBrowse Lecture FinalQuizSubmit X , implies the user tries to refer to the lecture during the final quiz. Activity sequences as the whole may carry more information than an unordered collection of its individual components.

A topical N -gram model is a topic model that discov-ers topics as well as topical phrases [10]. The probabilistic model generates words, or actions in our case, in their order of appearance. This is accomplished by iterating over words, and for each word, first sampling a topic, then sampling its status as a unigram or bigram, and then sampling the word from the selected topic-specific unigram or bigram distri-bution. Successive bigrams can form longer phrases. Thus the model can distinguish that  X  X hite house X  has a special meaning as a phrase in the  X  X olitics X  topic, but not in the  X  X eal estate X  topic. We apply topical N -gram models to our learning session modeling task where we treat each learning activity defined during pre-processing (Section 2) as a word and each session as a document. Then we can characterize learning sessions with topic proportions.
Intuitively, some learner behaviors are context-sensitive, that is, the occurrences of these behaviors are influenced by contextual factors like time and course schedule. For example, some users prefer to have an intense learning ses-sion, which involves doing assignments, on Sundays but only browse the course forums on weeknights. The associations between user interaction records and the corresponding con-texts, which can be referred to as behavior patterns, can be used to characterize user habits[2]. We are especially inter-ested in how students X  study habits influence their success. This is important because it may enable context sensitive support to be generated for students. Instead of traditional association rule mining, we use classification rule mining to forum threads consecutively discover a small set of rules in the context logs that predict session types generated by topic modeling[7]. Figure 1: Daily average topic distributions for four final grade groups in the Virtual Instruction MOOC. Figure 2: Daily average topic distributions for four final grade groups in the Financial Planning MOOC.
In this section, we first present the session topics gen-erated from the topical N -gram model. The visualization of average topic distribution on each course day shows dif-ferent engagement patterns of different final grade groups in our two MOOCs. Then we group each learning session based on its topic distributions. Interesting learning behav-ior patterns are mined from the context-rich log dataset.
We show the top ranking activities and activity sequences for each topic for the VI MOOC in Table 3 4 . The num-ber of topics is set to five. The topics generated by top-ical N-gram models capture both the typical combination of interactions and typical sequences of learning activities, such as  X  X rowseLecture BrowseLecture BrowseFinalQuiz X , which implies the user watches more than one video lectures before taking the final quiz.

Based on the topic distribution, we assign a session type to each session with the largest topic proportion. We set the session type as the variable to predict and use classification rule mining to mine learner behavior patters. Our defini-tions of Confidence and Support are similar to those in [2]. On a course level, all the behavior patterns with Confidence larger than 0.25 are mined. Then we select at most the top 20 behavior patterns for each session type instead of using all the mined behavior patterns. We manually check the mined behavior patterns. Table 4 shows some patterns mined from the VI course. These behavior patterns reflect some inter-esting learning habits of the students in this course. For example, on course week 3, students are likely to engage in an Assignment and Forum session.
We now investigate how a student X  X  final grade is related to her learning session distribution. Final grade can indicate student knowledge and also engagement. Here we think of the final grade as an independent variable; our goal is not to predict a student X  X  grade from her activity but rather to gain insight into how high-grade and low-grade students distribute their activities differently along the course weeks. On each course day, we compute the average session topic proportions over all the learning sessions that happened on that day. In Figures 1 and 2 we show trends for our two MOOCs. We find that the distribution patterns are qual-itatively similar. For example in both MOOCs, The None achievement users(Figure 1(a) and Figure 2(a)) are charac-terized with a flat distribution across the five learning session topics, which means they are insensitive to course schedules and deadlines. Since MOOCs have created space for these less performance-oriented types of learning, such as auditing or exploring a course, they have more purely Browsing ses-sions. The other three achievement groups reflect the course
The activities for the FP MOOC are very similar but slightly different. To save space, we do not show them here. schedule in different levels. In the VI course (Figure 1), the assignment is released on Monday of course week 3, users have more Assignment and Forum sessions to check out or do the assignment. Towards the assignment deadline, which is the end of week 3, an even higher proportion of the ses-sions are Assignment and Forum . Similar trends (bumps in the curve) can also be observed for peer-assessment(released and due in course week 4) and final quiz(week 5). It is inter-esting to compare the trends between Fail and Pass(Figure 1(b) vs. Figure 1(c); Figure 2(b) vs. Figure 2(c)), they have similar trends except that Fail users mostly do not have the clear Peer-Assessment bump in week 4. This may largely be due to the fact that they did not finish their own assign-ments so they cannot do peer-assessment. If we compare Pass and Distinction users(Figure 1(c) vs. Figure 1(d); Fig-ure 2(c) vs. Figure 2(d)), we can see that Pass users tend to  X  X rocrastinate X  towards a deadline, as much more of their Assignment or Final Quiz related sessions are in the later part of the week (deadlines are on Sunday nights). We leave deeper analysis of these behavior patterns, such as procras-tination, for future work.
Though there have been some quantitative, large-scale studies of student behavior in MOOCs to date, there is still much room for development of techniques that offer high resolution into student routines and habits at a fine grained level. Very few prior studies have utilized the full spectrum of rich information captured by activity trace data in an in-tegrated way. Recently, Anderson et al.[1] have developed a taxonomy of individual learner behaviors related specifically to assignments, designed to examine the different behavior patterns aggregated across a student X  X  entire experience in the course to distinguish high-and low-achieving students. Most commonly in prior studies, only one or two types or aspects of student interaction have been investigated at a time, for example, students navigating backwards [4], in-video dropouts[6], forum posting behaviors[11] and students X  time on specific tasks [3].

Since late 1990, web usage mining has been widely stud-ied. [9] surveyed the popular techniques in this field such as Association Rule Mining and Clustering. Sequential pat-tern discovery can characterize user episodes for the mining of traversal patterns on search engines, shopping sites, etc. A distinct property of the user interactions with MOOCs is that user navigation is less dependent on the linking struc-ture in the website and more related to their course goals. Thus typical sequential pattern mining algorithms may be less suitable for our task. Inspired by [5], which uses topic models to discover patterns in a user X  X  daily routine from sensor data, we adopt a form of topic model to extract lean-ing activity patterns.
In this paper, we propose a novel approach for characteriz-ing learning behavior patterns. The experiments show that learning sessions can be modeled as combinations of several session topics, which provides insights into how high-grade and low-grade students distribute their activities differently along the course weeks. Based on context information asso-ciated with each learning session, we mine learning behavior patterns and then observe how these patterns play out over a course. In the future, we want to mine individual learning behavior patterns to discover latent learner types [8].
This research was funded in part by NSF grants IIS-1320064 and OMA-0836012. [1] A. Anderson, D. Huttenlocher, J. Kleinberg, and [2] H. Cao, T. Bao, Q. Yang, E. Chen, and J. Tian. An [3] J. Champaign, K. F. Colvin, A. Liu, C. Fredericks, [4] P. J. Guo and K. Reinecke. Demographic differences in [5] T. Huynh, M. Fritz, and B. Schiele. Discovery of [6] J. Kim. Understanding in-video dropouts and [7] B. Liu, W. Hsu, and Y. Ma. Integrating classification [8] H. Ma, H. Cao, Q. Yang, E. Chen, and J. Tian. A [9] J. Srivastava, R. Cooley, M. Deshpande, and P.-N. [10] X. Wang, A. McCallum, and X. Wei. Topical n-grams: [11] M. Wen, D. Yang, and C. Ros  X  e . Linguistic reflections
