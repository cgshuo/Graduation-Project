 Developing statistical models for network data has been a growing research area in statistics and machine learning over the past decade ( Goldenberg et al. , 2009 ; Kolaczyk , 2009 ; Airoldi et al. , 2011 ). Among many models, the parametric families have been the major focus in the lit-erature because of their simplicity and analytic tractabil -ity. Popular examples of these parametric models in-clude the exponential random graph model ( Wasserman , 2005 ; Hunter &amp; Handcock , 2006 ), the stochastic block-model ( Nowicki &amp; Snijders , 2001 ), the mixed mem-2012 ) and many others. However, as the complexities of the networks increase, it becomes increasingly more chal-lenging to fit the data using a particular parametric model. 1.1. Non-parametric representation of a graph In this paper, we consider a non-parametric perspective of modeling network data using the exchangeable graph models (ExGM). The notion of exchangeability is due to de Finetti, later generalized by Aldous ( 1981 ), Hoover ( 1979 ) and Kallenberg ( 2005 ). A connection between pop-ular parametric models and exchangeable graph models has been recently made ( Hoff , 2008 ; Bickel &amp; Chen , 2009 ). The non-parametric (limit) object that characterizes an ExGM is often termed a graphon . As we will define for-mally in Section 2, a graphon is a 2 -dimensional continuous function on [0 , 1] 2  X  [0 , 1] that generates random graphs. Since a graphon is a model for network data, any model based inference, prediction and hypothesis testing can be performed using a graphon ( Lloyd et al. , 2012 ). For in-stance, when comparing networks that span different sam-ple sizes, graphons provide a natural solution: If two sam-ples of a network are generated from the same ExGM, they should have the same graphon, and hence, comparing two networks can be done by comparing two graphons.
 In this paper, we propose an efficient graphon estimator based on 2D histograms. The challenge of the problem is two-fold. First, since graphons are unique up to measure-preserving transformations, it is important to identify th e conditions under which graphons can be uniquely recov-ered (e.g., see Yang et al. , 2014 ). Second, it is desirable for a graphon estimator to be provably consistent. 1.2. Related work Previous methods of graphon estimation algorithms can be classified into two categories as follows.
 The first category is to perform graphon estimation con-ditioned on the node arrangement. When the node ar-rangement is conditioned on, we can bypass the dif-ficult problem of identifying a canonical representation of the graphon. For example, the universal singular value thresholding ( Chatterjee ) and the matrix comple-tion ( Keshavan et al. , 2010 ) seek low-rank structures of the adjacency matrix, whereas the stochastic blockmodel ap-proximation ( Airoldi et al. , 2013 ; Chan et al. , 2013 ) groups similar nodes to form community structures. However, since the estimations are conditioned on the node arrange-ment, the resulting graphons are not canonical.
 Different from the first category, the second category of methods estimate canonical graphons. In ( Bickel et al. , 2011 ), the authors proposed a method of moments which is theoretically consistent for that purpose. However, the method requires knowledge of all wheels of the net-work, and hence is computationally infeasible. Choi et lem by a clustering approach, but they stopped at the clus-tering step without actually estimating the graphon. In ( Lloyd et al. , 2012 ), Lloyd et al. considered a Bayesian ap-proach to estimate a graphon. However, the MCMC sam-pling process of the algorithm is computationally intensiv e. Moreover, there is no consistency guarantee of the esti-mator. More recently, other groups have begun exploring Latouche &amp; Robin , 2013 ; Olhede &amp; Wolfe ). Yet, none of these methods are both consistent and computationally ef-ficient. 1.3. Contributions In this paper, we propose a histogram approach to estimate graphons. Our method, called the Sorting-And-Smoothing (SAS) algorithm, consists of two steps. In the first step, we sort the empirical degrees and rearrange the nodes of the graph for a canonical ordering. In the second step, we compute the histogram of the sorted graph and smooth the histogram by a total variation minimization. Details of the SAS algorithm are presented in Section 3.
 The estimator returned by the SAS algorithm is consistent. The consistency proof leverages the sparsity concepts from compressed sensing. In particular, we show, in Theorem 3, that if the true graphon satisfies some Lipschitz condi-tions and has sparse gradients, then the mean squared error (MSE) of the estimator is O ((log n ) /n ) , where n is the size of the network. Discussion of the consistency is presented in Section 4.
 We test the SAS algorithm on both simulation data and real data (Section 5). The experiment of using the simulation data indicates that the SAS algorithm is superior to, both in terms of estimation quality and speed, several existing methods. Applying the SAS algorithm to real data, we es-timate graphons of two large-scale social networks and re-veal some structures. These results provide an alternative way of analyzing large-scale network data.
 For clarity of the presentation, details of the proofs can be found in a follow up report ( Chan &amp; Airoldi , 2014 ). The purpose of this section is to introduce the concepts of a graphon and discuss the conditions under which a graphon can be uniquely identified. 2.1. Definition of a graphon We let G be the adjacency matrix of a graph with the sized graph G , we say that G is exchangeable if it satisfies the following definition.
 Definition 1. An infinite random array G = ( G exchangeable if for any permutation  X  .
 Definition 1 is also known as the joint exchangeability, be-cause the permutation is applied to both rows and columns simultaneously ( Orbanz &amp; Roy ).
 We refer to all random graph models that satisfy exchange-ability as exchangeable graph models (ExGM). A use-ful characterization of an ExGM is given by the Aldous-Hoover theorem.
 Theorem 1 (Aldous-Hoover) . An infinite random array ( G measurable function F : [0 , 1] 3  X  X  0 , 1 } such that where ( U Uniform [0 , 1] random variables.
 The function F in Theorem 1 defines a graphon : Definition 2 (Graphon) . A graphon w is a symmetric mea-surable function w : [0 , 1] 2  X  [0 , 1] such that where ( U Uniform [0 , 1] random variables.
 Equivalently, ( 3 ) can be expressed as the following two-stage sampling scheme: Therefore, a finite sized network generated from a graphon can be regarded as a finite sample drawn according to ( 4 ). 2.2. Identifiability of a graphon To understand the identifiability issue of a graphon, it is important to discuss measure preserving transformations. Definition 3 (Measure Preserving Transformation) . A transformation  X  : [0 , 1]  X  [0 , 1] is measure-preserving w.r.t. a measure  X  if it is measurable, and for all A  X  [0 , 1] For example, if  X  is a measure preserving transformation and U  X  Uniform[0 , 1] , then  X  ( U ) is also distributed uni-formly on [0 , 1] . Similarly, if  X  is a measure preserving transformation, then the graphon defines the same ExGM as w because there exists a trans-formation such that w and w  X  are identical.
 The identifiability issue of a graphon arises because the converse of Definition 3 is not true in general: If w and w sure preserving transformation  X   X  such that w ( u, v ) = w ple, the functions w ( u, v ) = uv and w  X  ( u, v ) = (2 u mod 1)(2 v mod 1) define the same ExGM, but there is no  X   X  such that w ( u, v ) = w  X  (  X   X  ( u ) ,  X   X  ( v )) A formal statement of the above observation is given by the following theorem, which says that we need to find a pair of measure-preserving transformations  X  and  X   X  in order to show that w is unique.
 Theorem 2 (( Diaconis &amp; Janson , 2008 ), Thm. 7.1) . Let and w  X  be two graphons. Then  X  ( w, w  X  ) = 0 if and only if there exist measure-preserving transformations  X  and  X   X  : [0 , 1]  X  [0 , 1] such that where the distance  X  ( w, w  X  ) is the cut-norm defined by ( Lov  X  asz &amp; Szegedy , 2006 ).
 A consequence of Theorem 2 is the notion of twin-free: Definition 4 (Twin-free ( Borgs et al. , 2010 )) . A graphon is called twin-free if for any u w ( u 2 , v ) for almost all v  X  [0 , 1] .
 Essentially, the twin-free condition excludes the cases where two graphons can be made identical by row and col-umn permutations. For example, the pair shown in Figure 1 are twin, and hence they are not identifiable.
 The twin-free condition is necessary but not sufficient for identifying a unique graphon when we marginalize a graphon ( Orbanz &amp; Roy ): For example, if we consider w and w  X  in Figure 1 , and a graphon w  X  X  ( u, v ) = 1 / 2 , then w  X  X  is twin-free but g w The necessary and sufficient condition for a graphon to be identifiable is to require strict monotonicity of degrees ( Bickel &amp; Chen , 2009 ; Yang et al. , 2014 ). Condition 1 (Strict Monotonicity of Degree) . A graphon w has a unique representation if and only if there exists w is strictly increasing (or decreasing). The graphon w can is called the canonical representation of w .
 It is evident that the strict monotonicity condition im-plies twin-free, but not vice versa. In addition, if we let U  X  Uniform [0 , 1] , then strict monotonicity implies that g can ( U ) is absolutely continuous.
 In the rest of the paper we assume that all graphons of in-terests satisfy the strict monotonicity condition. For not a-tional simplicity, we drop the superscript (  X  ) can , and denote w as the canonical representation. 3.1. Overview The intuition of the proposed SAS algorithm is based on the following idea: As the size of a graph grows, the (sorted) empirical degree should converge to the ideal (canonical) degree distribution. Therefore, if we can sort the empirica l degree of a given graph, then by applying suitable smooth-ing algorithms we can find an estimate of the canonical graphon.
 Following this intuition, we propose a two-stage algorithm . In the first stage, we sort the rows and columns of G obtain a sorted graph b A according to the empirical degree. In the second stage, we compute a histogram b H of b A , and apply a total variation minimization to find an estimate b w An illustration of the SAS algorithm is shown in Figure 2 . 3.2. Stage 1: Sorting The purpose of the sorting step is to rearrange the observed graph G so that the rearranged empirical degrees are mono-tonically increasing. To this end, we compute the empirical degree and define a permutation b  X  such that d Then, we define a rearranged graph where an example is shown in Figure 2 .
 It is important to note that since the permutation b  X  is de-fined by the empirical degrees, it could be different from the true permutation that defines the canonical graphon ac-cording to the node arrangement. To differentiate the em-pirical permutation b  X  and the true permutation, we define  X  as the oracle permutation that sorts the node labels ( U such that U fine the oracle ordered graph as 3.3. Stage 2: Smoothing Network Histogram Estimation Once the graph is rearranged to have monotonically in-creasing degrees, the graphon estimation problem becomes finding a smooth surface that best fits ( b A we consider a simplified version of the stochastic block-model approximation ( Airoldi et al. , 2013 ) which approx-imates the continuous graphon using a piecewise constant function. More precisely, the stochastic blockmodel ap-proximation defines and correspondingly for some parameter h &gt; 0 denoting the size of each block. Equations ( 10 ) and ( 11 ) indicate that the stochastic block-model approximations ( b H of ( b A ues in the same block are identical, the effective degrees of freedom in ( b H where k =  X  n/h  X  is the number of blocks.
 Total Variation Minimization While the network histogram estimation step is consistent, the decay rate of the error can be further improved by in-troducing a total variation minimization step.
 The total variation minimization step is based on a sparsity assumption of the true graphon w . Analogous to natural images, we assume that graphons are sparse in the gradi-ents. Discretizing the continuous graphon w into a k  X  k grid, the assumption suggests that w needs to have a small total variation difference of w , respectively.
 Using the total variation concept, the refinement step can be posed as the following minimization problem: b w tv = argmin where k X k rameter that controls the fidelity between the total variati on solution b r and the histogram b H . To solve the minimization problem ( 13 ), we use the alternating direction method of multipliers (ADMM) ( Chan et al. , 2011 ).
 We remark that the size of b w tv is k  X  k . To ensure that the final estimate have the same size as the true graphon, we define the final estimate as where 1 notes the Kronecker product operator. Therefore, the final estimate b w 3.4. Complexity The complexity of the SAS algorithm can be analyzed by considering each step individually. In computing the em-pirical degree distribution, O ( n ) additions are used. The sorting procedure, in general, requires O ( n log n ) parisons. Therefore, the complexity for sorting is about O ( n log n ) multiplications plus O ( n ) additions. Next, for the histogram computation, computing each value of the bin requires O ( h 2 ) additions, and there are k 2 = ( n/h ) bins. Thus a total of O ( n 2 ) additions are needed. Finally, the total variation minimization is solved on a k  X  k array. Thus, the complexity of the ADMM step is O ( k 2 log k 2 ) (See ( Chan et al. , 2011 ) for discussions.) Combing these results we can show that the overall complexity of the SAS algorithm is O ( n log n + k 2 log k 2 ) multiplications plus O ( n 2 ) additions. In this section we discuss the statistical consistency of th e proposed SAS algorithm.
 Analyzing the consistency of the SAS algorithm is equiva-lent to determining an upper bound of the error = Before we proceed, we note that the second expectation in ( 15 ) is a classical result of approximating a continuous function by step functions. The bound is given in the fol-lowing Lemma.
 Lemma 1 (Piecewise Constant Function Approximation) . Then, Therefore, it remains to find an upper bound of k b w H Cauchy X  X  inequality.) In the following subsections, we dis -cuss how each step of the SAS algorithm contributes to this upper bound. 4.1. Consistency of empirical degree sorting To establish the consistency of the empirical degree sortin g, we must first establish the relationship between the oracle permutation (  X  ( i )) and the oracle degree ( d Lemma 2. Let  X  ( i ) be the oracle permutation such that U and assume that there exists constants L such that for any 0  X  x  X  1 and 0  X  y  X  1 . Then, the following result holds.
 Conversely, if ( 19 ) holds with probability at least 8 e The interpretation of Lemma 2 is as follows. First, ( 18 ) is the two-sided Lipschitz condition, with Lipschitz con-stants L gree distribution g ( u ) to be well-behaved so that there is no abrupt transition for both g and g  X  1 . Second, the for-ward statement suggests that if the oracle ordered indices have bounded differences, then correspondingly the empir-ical degrees should also have bounded differences. Con-versely, ( 20 ) suggests that if we can bound the difference in empirical degrees, then the difference in the true posi-tions should also be bounded.
 As an immediate consequence of Lemma 2 , we observe then the converse of Lemma 2 implies the following. Corollary 1. If d Therefore, if the error d ror between  X  ( i ) and b  X  ( i ) will also be small. 4.2. Consistency of the histogram estimator During the histogram estimation step, the error associated with the empirical degree sorting is translated to the error between the empirical histogram b H and the ideal histogram H . This is reflected in the following lemma.
 Lemma 3 (Bounds on k b H  X  H k truth graphon and assume that w is Lipschitz with constant respectively, then where C is a constant independent of n .
 We also establish the relationship between H and the step approximation H w .
 Lemma 4 (Bounds on k H  X  H w k function approximation of the graphon w and let H be the histogram defined as ( 11 ) . Then, 4.3. Consistency of total variation smoothing To analyze the total variation minimization step, we first observe that Therefore, if we consider H w as the desired function to be estimated, and consider  X  and  X  as perturbations added to H w , then b H can be regarded as a noisy observation of H w . Consequently, by applying total variation minimization to minimum total variation.
 To characterize the solution of the total variation minimiz a-tion problem, we first define the s -sparsity of the gradient of a function H w .
 Definition 5. A function H w  X  [0 , 1] k  X  k is s -sparse in gradient if its gradient  X  H w has at most s non-zero en-tries.
 With this definition, we apply the following result in com-pressed sensing.
 Lemma 5 (( Needell &amp; Ward ) Theorem A) . If b H = H w  X  +  X  with  X  2 = E [ k  X  +  X  k 2 2 ] , then the solution b w satisfies the condition where (  X  ) most significant non-zero entries of the argument. Lemma 5 indicates that the error k b w tv  X  H w k by the perturbation  X  and the sparse approximation error k X  H w  X  (  X  H w ) s k 1 . Since  X  2 = E [ k  X  +  X  k 2 2 and  X  are defined according to ( 23 ),  X  is upper bounded by ( 21 ) and ( 22 ). For the sparse approximation error term, in general k X  H w  X  (  X  H w ) essarily s -sparse in gradient. However, in practice, many real world networks are sparse ( i.e. number of edges are much fewer than number of nodes). Therefore, for practi-cal consideration it is often reasonable to assume that H is s -sparse in gradient and so k X  H w  X  (  X  H w ) s k 1 = 0 4.4. Overall consistency In summary, the overall consistency is given by the follow-ing theorem.
 Theorem 3 (Consistency of SAS algorithm) . Let w be the true graphon with the following properties: (i) w is Lip-schitz with constant L &gt; 0 ; (ii) g ( u ) = R 1 Lipschitz as defined in Lemma 2 ; (iii) H w is s -sparse in gradient. Then, the MSE of the SAS estimator satisfies and hence MSE  X  0 as n  X  X  X  and k/n  X  0 , where k is the number of blocks defined in ( 11 ) . After establishing the theoretical results, we now present simulation results of the proposed SAS algorithm. 5.1. Simulations The first experiment considers a number of graphons listed in Table 1 . The choices of these graphons are made to in-clude both low rank and high rank graphons, where the rank is measured numerically using a 1000  X  1000 discretization of the continuous graphons. Among the 10 graphons listed in Table 1 , we note that graphon no. 1 w ( u, v ) = uv is a special case of the eigenmodel ( Hoff , 2008 ), graphon no. 5 logistic model presented in ( Chatterjee ), and graphon no. 6 2002 ). Other graphons are chosen to demonstrate the ro-bustness of the SAS algorithm.

ID w ( u, v ) rank ( w ) 1 uv 1 6 | u  X  v | 1000 8 exp { X  max( u, v ) 3 / 4 } 1000 9 exp { X  1 10 log(1 + 0 . 5 max( u, v )) 1000 We compare the SAS algorithm with the universal sin-gular value thresholding (USVT) algorithm ( Chatterjee ) and the stochastic blockmodel approximation algorithm ( Airoldi et al. , 2013 ). These two algorithms are the exist-ing methods that have provable consistency and are numer-ically efficient. However, since both of these two methods do not have a sorting step, we apply the sorting step of the SAS algorithm prior to running the two algorithms. For the choice of binwidth h , we set h = log n for the SAS algo-rithm, and an oracle h that minimizes the MSE for the SBA algorithm ( i.e. , using the ground truth).
 The results of the experiment are shown in Table 2 , where we report the mean squared error (MSE) of the estimated graphons using the SAS algorithm, the USVT algorithm and the SBA algorithm. To reduce the random fluctuations caused by independent realizations of the random graphs, we average the MSE over 50 independent trials. Two cases of graph sizes are considered: n = 200 and n = 1000 . The results show that the SAS algorithm in general outper-forms the USVT algorithm and the SBA algorithm. Av-eraged over the 10 testing graphons, we see that the SAS algorithm achieves the lowest MSE among all three meth-ods.

SAS (Proposed) USVT SBA (a) 1 . 09  X  10  X  5 (b) 8 . 69  X  10  X  5 (c) 1 . 60  X  10  X  3 (d) 1 . 37  X  10  X  4 (e) 1 . 24  X  10  X  3 (f) 7 . 38  X  10  X  4 Figure 3 displays two examples of the estimated graphons. As shown in the figure, we see that while the USVT algo-rithm returns a reasonable estimate for graphon no.5 (which has a low rank), it returns a relatively worse estimate for graphon no. 10 (which has a high rank). Looking at the SBA algorithm, it is evident that using the oracle binwidth h , the average MSE is lower than that of USVT. However, the SBA algorithm tends to return a graphon with few com-munities. This is not favorable if the network has non-block structures. In contrast, the SAS algorithm returns results with lower MSE, and retains important features of the true graphons.
 In Figure 4 we show the runtime comparison between the SAS algorithm and the USVT algorithm. Both algorithms are implemented on an Intel 3.5GHz machine with 16GB RAM, Windows 7 / MATLAB R7.12.0 platform. The run-cantly lower complexity than the USVT algorithm. 5.2. Real data analysis As an application of the proposed SAS algorithm, we consider the problem of estimating graphons from real-world networks. For this purpose, we consider the col-laboration network of arXiv astro physics (ca-AstroPh) and the who-trusts-whom network of Epinions.com (soc-Epinions1) from Stanford Large Network Dataset Collec-consisting of 1 . 8  X  10 4 nodes and 3 . 9  X  10 5 edges, whereas the soc-Epinions-1 network is an unsymmetrical binary both networks, we randomly permute the rows and columns to simulate the raw data scenario where nodes are initially unordered.
 Figure 5 shows the results of the SAS algorithm. For the ca-AstroPh network, the graphon shows close collabora-tions among a group of people concentrated around the top left corner of the graphon. It also shows a number of small communities along the diagonal. For the soc-Epinions1 network, the graphon indicates that there are some influential nodes which consistently interact among themselves. These can be seen from the repeated patterns of the graphon.
 We remark that or the ca-AstroPh network ( n = 1 . 8  X  10 and the soc-Epinions-1 network ( n = 7 . 5  X  10 4 ), the esti-mations are completed in 20 seconds and 170 seconds, re-spectively, on a PC using an unoptimized MATLAB code. This provides a strong indication of the scalability of the SAS algorithm to larger networks. The Sorting-And-Smoothing (SAS) algorithm is a consis-tent and efficient graphon estimation algorithm. The SAS algorithm consists of two steps. In the first step, the ob-served graph is rearranged so that the degrees are mono-tonically increasing. In the second step, a histogram es-timation and a total variation minimization is applied to estimate a smooth surface that best fits the observed data. The SAS algorithm is evaluated on both simulation data and real network data. Our simulation results indicate that the SAS algorithm outperforms the universal singular value thresholding algorithm and the stochastic blockmodel ap-proximation algorithm. On large-scale real networks, the SAS algorithm returns consistent graphon estimates. Code . Available at: https://github.com/airoldilab/SAS Acknowledgments . The authors thank J. J. Yang and C. Q. Han for useful discussions. SHC is partially supported by a Croucher Foundation Postdoctoral Research Fellowship. EMA is partially supported by NSF CAREER award IIS-1149662, AROMURI award W911NF-11-1-0036, and an Alfred P. Sloan Research Fellowship.

