 In this paper, we tackle the problem of predicting what online memes will be popular in what locations. Specif-ically, we develop data-driven approaches building on the global footprint of 755 million geo-tagged hashtags spread via Twitter. Our proposed methods model the geo-spatial propagation of online information spread to identify which hashtags will become popular in specific locations. Con-cretely, we develop a novel reinforcement learning approach that incrementally updates the best geo-spatial model. In experiments, we find that the proposed method outperforms alternative linear regression based methods.
 H.3.4 [ Information Storage and Retrieval ]: Systems and Software X  Information networks social media; spatial impact; spatio-temporal analysis
The widespread adoption of GPS-enabled tagging of social media content provides new access to the fine-grained spatio-temporal logs of user activities. For example, the Foursquare location sharing service has enabled 2 billion  X  X heck-ins X  [10], whereby users can link their presence, notes, and pho-tographs to a particular venue. The mobile image shar-ing service Instagram allows users to selectively attach their latitude-longitude coordinates to each photograph; similar geo-tagged image sharing services are provided by Flickr and a host of other services. And the popular Twitter service sees 500 million Tweets per day, of which around 5 million are tagged with latitude-longitude coordinates.

With access to the worldwide geo-spatial footprints of so-cial media users, we focus on the problem of predicting what online memes will be popular in what locations , which has important implications for a variety of systems and appli-cations, including targeted advertising, location-based ser-vices, social media search, and content delivery networks. In particular, we focus our investigation on a sample of 755 million geo-tagged Tweets with precise latitude-longitude coordinates collected over the course of 18 months. Specifi-cally we consider the propagation of hashtags across Twitter, where a hashtag is a simple user-generated annotation pre-fixed with a #. Hashtags serve many purposes on Twitter, from associating Tweets with particular events (e.g., #rip-stevejobs and #fukushima) to sharing memes and conversa-tions (e.g., #bestsportsrivalry and #ifyouknowmeyouknow).
Our goal is to develop techniques based on Twitter hash-tag propagation which can be used to predict hashtags that will be popular at any location. For example, can we accu-rately predict which hashtags will be popular in San Fran-cisco over the next two hours? Can the same model also predict which hashtags will be popular in a small town like College Station, Texas? Can we identify which hashtags that have been popular in New York in the past two hours but will drop in interest? Building robust models that can accurately predict the spatio-temporal popularity of online memes like hashtags can aid in design of systems and ap-plications, including content delivery networks, social media search, location-based services like Google Now, and geo-targeted advertising.

Toward answering these questions, we develop in this pa-per a reinforcement learning-based approach that builds upon two competing hypotheses of information spread over geo-spatial networks.  X  Spatial Affinity: The first hypothesis, based on the To- X  Community Affinity: The second hypothesis is that
We investigate a series of features inspired by these two hypotheses for predicting which hashtags will be popular in a specific location at a specific time. Since the best fea-tures may vary for each location, we additionally propose a reinforcement-learning based method whereby the best model is determined is location specific. In our experimental evaluation over 755 million geo-tagged Tweets, we find that reinforcement learning algorithm that selects the single best feature function for a location performs the best. This model is able to predict close to 70% of future hashtags occurrences accurately.
The area of information diffusion is well studied with most work focussed on study of diffusion through social and in-formation networks, e.g., [11, 14, 15, 16, 18, 25]. But, our work in particular builds on two lines of research: Twitter analysis and geo-spatial analysis of social media. Twitter Analysis : Most papers studying Twitter have fo-cused on understudying its properties as a social network and had tried to analyze information diffusion as a effect of the underlying social network [12, 17, 18, 25]. Hence, similar models have been applied to study hashtag propagation on Twitter X  X  social network [21, 6]. In related research, people have studied approaches to predict the popularity of hash-tags in a given time frame in [24], sentiment detection on Twitter [8], topic tracking on twitter streams [19], and so forth.
 Geo-spatial Analysis of Social Media : The emergence of location-based social networks like Foursquare, Gowalla, Google Latitude, and so on, has motivated several studies related to large-scale geo-spatial analysis like [22, 20, 2, 3, 9, 13]. In a recent paper [4] authors dealt with the spa-tial analysis of Youtube videos, in which they observed the highly local nature of videos based on the propagation pat-terns of Youtube videos. On Twitter people have studied geo-spatial analysis in the context of inferring geographic in-formation from tweets like predicting user locations [5] and spatial modeling to geolocate objects [7].
For our analysis we collected data using the Twitter Stream-ing API. We used the API between February 1 and Novem-ber 30, 2011 to get a sample of around 755 million geo-tagged tweets which contains around 10 million unique hashtags. Every tweet is tagged with a latitude and longitude indicat-ing the location of the user at the time of the posting and the tuple &lt; hashtag , time , latitude , longitude &gt; corresponds to a particular hashtag occurrence.

To support location-based analysis, we divide the globe into square grids of equal area using Universal Transverse Mercator (UTM), a geographic coordinate system which uses a 2-dimensional Cartesian coordinate system to map loca-tions on the surface of the globe [1]. The issue with using an angular co-ordinate system like latitudes and longitudes is that distance covered by a degree of longitude differs as we move towards the pole. In addition, the distance covered by moving a degree in latitude and longitude is same only at the equator. Hence, it is hard to break globe into grids using this system. UTM on the other hand gives us a system of grids that closely matches distances in metric system mak-ing our analysis easier. While varying the choice of grid size can allow analysis at multiple levels (e.g., from state-sized cells to neighborhood-sized ones), we adopt a middle ground by dividing the globe into squares of 10km by 10km. Some grid cells will naturally be densely populated, others will be sparse. Let this set of distinct locations, each corresponding to a square, be represented by the set L .

To avoid sparsely represented hashtags, we consider only hashtags with at least 5 occurrences in a location and con-sider only hashtags with at least 250 total occurrences across all locations. Since some hashtags may have begun their Twitter life before the first day of our sample (February 1) while others may have continued on after the last day (November 30), we consider both February and November as buffer months. Hence, we capture the full lifecycle of hashtags starting on or after March 1 and ending by Oc-tober 31, which focuses our study to hashtags which have both their birth and death within the time of study (and as a result, removes cyclical hashtags like  X #ff X  and  X #no-follow X ). As illustrated in Figure 1, we additionally divide the set of all hashtags into two sets: a training set based on hashtags from March to August; and a test set based on September to October. Hashtags that start in training but continue into test are ignored. In this way, the training set contains 1466 complete hashtag propagations and the test set contains 515.
Let H be a set of hashtags and L the set of distinct lo-cations. Then for a hashtag h  X  H let o h l be the number of occurrences of the hashtag that have been observed in a location l  X  L , and let e h l be the number of occurrences of the hashtag that are expected in l . We now define the prob-lem of selecting top  X  k hashtags for a location as hashtag subset selection problem .
 Definition 4.1. (Hashtag Subset Selection Problem) : Given an integer k , hashtag subset selection problem for a location l is the task of determining set of top  X  k hashtags S  X  R such that the total number of expected hashtags for S is maximized, i.e., To understand the hashtag subset selection problem better, consider the example shown in Figure 2. It shows propaga-tion of two hashtags (pink and blue) in Dallas and Austin at time t . The number of observed and unobserved occurrences for these hashtags at a time t is indicated by the area below Figure 2: Example of trail propagation in two loca-tio ns shaded region with solid lines and a unshaded region with dotted lines respectively. Now, given that we only know the shaded regions under complete lines at t , the hashtag sub-set selection problem is the task of identifying k hashtags that will have maximum area under dotted lines. If k = 1, the solution to this problem would be S Dallas = { Blue } and S Feature Functions : If we know the area under dotted lines, i.e. e h l , then the solution to this problem is trivial. But, since we don X  X  have that information at t , we have to develop methods to estimate this value. Let  X  e h l be a score representing the value of e h l . Depending upon the method used to estimate this score, it could be anything -an integer predicting the number of expected occurrences or a value  X  [0 , 1]. The only condition is that a higher score for a loca-tion should indicate that this location sees more occurrences than a location with lower score. Then using (1), we redefine the hashtag subset S l in terms of  X  e h l as: Like mentioned earlier, the score,  X  e h l , for a location l and hashtag h , can be determined using several techniques. Let F be the set of feature functions used to estimate the value of e , where, f i  X  F is defined as f i : L  X  H  X  R . For example, a simple way to estimate expected hashtags in a location would be to use the notion that a hashtag that is popular in that location at current time will continue to be popular there during future. Like, lets say a hashtag (#redskins) about a football game in Washington D.C that is popular right now can be expected to remain popular next hour too. Concretely, calling this the greedy approach we can define the feature function corresponding to this, f greedy  X  F , as: where f greedy just gives the number of occurrences of h that have been observed in l .
 Learning Algorithms : Every feature function in F esti-mates a different value of  X  e h l , i.e., for a given location-hashtag pair we have | F | estimates for  X  e h l . But, for a given location-hashtag pair, we can only use one value of  X  e h l in (2). So, we formulate the task of determining a single value from a set of | F | values as a learning problem. In particular, we propose a set of learning algorithms, L , that use the set of feature functions F and a location-hashtag pair to estimate the value for  X  e h l . The learning algorithm can either combine all the estimated values in some ratio to get a new value of  X  e l or use some heuristic and select one of the values that it thinks is the best estimate. For example, we can estimate a new value for  X  e h l using linear regression as: where, w f i are regression coefficients and  X  is the error term.
In the following two sections we address two fundamental questions:  X  Feature Functions : What feature functions F do we  X  Learning Algorithms : What learning algorithms do
The feature functions to estimate the expected number of hashtag occurrences are guided by two major concepts of geo-spatial propagation: spatial affinity and community affinity. We first describe the feature functions based on spatial affinities where one function estimates local hash-tags more accurately while other estimates global hashtags more accurately. We then describe feature functions that use community affinities to learn relationship between locations.
In this section, we present feature functions that use spa-tial affinities between locations as described by the Tobler X  X  hypothesis [23] to estimate expected number of hashtags. Tobler X  X  hypothesis implies that the popularity of a hashtag in a location is dependent on the popularity of this hashtag in neighboring locations. So, we predict the future pop-ularity of a hashtag in a particular location as a function of the hashtag X  X  spatial distribution in other locations, such that the X  X ontribution X  X ade by the other location decreases exponentially as its distance from the particular location in-creases.

An advantage of using spatial affinities to estimate ex-pected hashtag occurrences is that this approach allows us to develop different feature functions depending on our pre-ferred hashtag type -local hashtag or global hashtag. Ex-amples of local and global hashtags are shown in Figure 3. It shows spatial distribution for two local hashtags -#black-parentsquotes (USA and England) and #missuniverso (Brazil), and one global hashtag -#usopen (entire world), which were popular on the evening of September 19, 2011. We can imag-ine applications (like localized advertising) where we would want to prefer one type of hashtag over other and the fea-ture function based on spatial affinities helps in such cases. In particular, we propose two feature functions: (i) global feature function which is suitable to estimate hashtags that are globally popular; and, (ii) local feature function which is suitable to estimate local hashtags.
 Global Feature Function : This function uses spatial dis-tribution of hashtags and estimates global hashtags more accurately than local. It is similar to the greedy feature in the sense that both these functions use hashtag X  X  observed occurrences to estimate expected hashtag occurrences. But, unlike greedy, this approach doesn X  X  use raw occurrence counts but shifted occurrence counts . Shifted occurrences are occur-rences that are contributed to a location from other locations using Tobler X  X  hypothesis, such that locations that are close by contribute greater number of occurrences to the location than locations that are far off. The global feature function is defined as: where, the sum calculates the total number of shifted foot-prints of h contributed by all locations to l . The exponen-tial function helps model Tobler X  X  hypothesis by decaying the contribution made by l i to l depending on the distance between the two locations. The parameter  X  controls the rate of decay and in our experiments we set  X  = 1 . 01. Local Feature Function : As mentioned earlier, this fea-ture function uses spatial distribution to estimate expected hashtag occurrences for local hashtags more accurately than global hashtags. But, instead of estimating expected count this feature function estimates a score in [0 , 1] that is an in-dicator of expected hashtag occurrences, such that, a higher score for a location indicates that more hashtags are ex-pected at that location than a location with lower score. But, before describing this function, we first define the prob-ability of observing a hashtag h in l , P r l , as: The score is calculated by applying Tobler X  X  hypothesis to the hashtag observing probability. So, we define the local feature function for a hashtag h in a location l as: wh ere, the numerator sums the shifted hashtag occurrence probability values from all locations to l . The exponential term is used to model Tobler X  X  hypothesis such that loca-tions that are closer to l contribute more to the score than locations that are far from l . Like before, in our experiments we set  X  = 1 . 01.

To illustrate differences between the two spatial affinity based feature functions described in this section, consider the spatial distributions of three hashtags shown in Figure 3. We use the global and location feature selection methods to predict the expected number of occurrences for each of these hashtags. Then we mark every location with color of Fig ure 4: Ranking trails using geospatial distribu-tion the hashtag that was most accurately estimated. The per-formance of these feature functions is shown in Figure 4. In these figures we observe the difference in approaches that the two feature functions take to estimate expected num-ber of occurrences for local and global hashtags. The global feature function as expected estimates hashtag occurrences for global hashtags more accurately as shown by the blue locations in Brazil and USA where other local hashtags ex-ist. The local feature function on the other hand, estimates the excepted occurrences of local hashtag pink #blackpar-entquotes (pink) and #missuniverso (green) hashtags more accurately.
The approaches proposed so far took into account only the geographical distances between two locations to estimate ex-pected hashtag occurrences. In this section, we move beyond geographical distances and look at an alternative approach that considers the impact of virtual communities that exist over Internet. In particular, we present feature functions that use community affinities between locations that may not necessarily be close in terms of geographical distance. In particular, we propose two feature functions that differ in the way community affinities between two locations is measured: (i) common hashtags feature function uses com-munity affinities measured based on the set of common hash-tags shared between locations; and, (ii) hashtag transmission feature function uses community affinities between locations measured based on the hashtags that a location might have transmitted to another.
 Both these approaches learn affinities between locations based on historical hashtag propagations. To do this we use the training set described in Section 3. Let H T be the set of all hashtags observed in the training set and H T l  X  R the set of hashtags observed in location l . Then, we define a prior probability of observing a hashtag in l as: We d efine C l i  X  l j  X  [0 , 1] as the measure of community affin-ity between locations l i and l j such that, C l i  X  l j = 1 . 0 in-dicates that a hashtag in l i will definitely occur in l j C  X  l j = 0 . 0 indicates that a hashtag in l i will not occur in l .
 Common Hashtags Feature Function : In this approach we measure community affinities between locations based on the information about common hashtags observed between a pair of locations. The intuition behind this approach is that if locations are connected by virtual communities then they must share common hashtags. Ex: techies in San Francisco and techies in Austin though geographically apart will share common hashtags. For the pair of locations l i and l j we define the common hashtag affinity C com l has occurred in l i , as: Not e that there might be cases where C com l the number of hashtags observed in these locations might be different ( | R l i | 6 = | R l j | ). We now define common hash-tag feature function using affinities learned from common hashtags observed in locations as: where, the sum calculates the total influence other locations have on l to make a hashtag h popular.
 Hashtag Transmission Feature Function : After look-ing at affinities based on common hashtags observed in lo-cations, we now look at affinities based on a set of hash-tags that a location might have transmitted to another. In particular, with this approach we are interested in learning affinities that can reflect temporal relationships between lo-cations. We define the affinity, C tran l hashtag transmission affinity and it indicates the chance that a hashtag observed in a particular location will be observed in another location in future. For example, in Figure 2, ob-serving pink hashtag that is popular in Dallas during the estimation window become popular in Austin during the prediction window, we can learn the temporal relationship between these two locations. We define C tran l whe re, t h l is the location l  X  X  traction time for h . The nu-merator in this definition is the size of set of hashtags that gained traction in l i before l j . Like in case of affinities based on common hashtags, there might be cases where C tion, the hashtag transmission feature function is defined as:
An example of how community affinities differs from spa-tial affinities is shown in Table 1. In this table we compare the community (common hashtag) and spatial affinities for Austin, Texas. We observe that though Austin is spatially closer to some of the other big cities in Texas, the hashtags observed there are more similar to the hashtags observed in Los Angeles, Washington D.C and New York.
In the previous sections we proposed five feature func-tions to estimate  X  e h l -first, the greedy feature function, next, two feature functions that used the hypothesis that distance between two locations played an important role in making hashtags popular, and finally two feature functions that used a contradictory hypothesis that is wasn X  X  distance but vir-tual communities on Internet that impact hashtag popular-ities.

The next task is to reduce | F | values of  X  e h l to a single value that can be used in (2). A simple approach now would be to evaluate which of these feature functions determines the value of  X  e h l most accurately and select it. In reality though, we might observe that a single feature function might not be suitable for all locations. Instead the demography of a place might dictate selection of a particular function that is best for this place. For example, metropolitan areas like those around Austin might prefer community feature func-tions, while smaller towns surrounding Dallas might prefer the spatial feature functions. In addition, it is possible that some locations might not prefer one feature function over the other but a combination of these feature functions in some ratio. Hence, in this section to deal with these issues we concentrate on two things: (i) introduce evaluation met-rics to measure the performance of feature functions for a location; and, (ii) describe algorithms that use these met-ric s to learn the best feature function or the best ratio for combining the feature functions for a location.
We now describe two evaluation metrics which we use in learning the best feature function or best combination of feature function for a given location. The value for each of these metrics is in the range [0 , 1] with 0 . 0 indicating the worst performance and 1 . 0 indicating the best performance. Given a location l , we denote the best set of top  X  k hashtags at this location as S l  X  and the set of top  X  k hashtags selected by our ranking models as S l (without the  X  on top). The two evaluation metrics are: Accuracy : This metric measures the similarity between S  X  and S l . This measure is similar to other set comparison metrics like the Jaccard index. It is defined as: suc h that, if the sets are identical accuracy is 1 . 0 and 0 . 0 if they are disjoint.
 Impact : While accuracy measures the similarity between the sets, it doesn X  X  measure the effect of selecting a particular set of hashtags over another. For example, it is possible that two disjoint sets of hashtags might observe same number of total hashtag occurrences after they are selected, resulting in the same performance. Hence, we define a metric called hashtag subset X  X  impact defined as: whi ch measures the ratio between the number of hashtag occurrences that were observed for hashtags in S l to those in S l  X  . The impact value 0.0 signifies no impact while 1.0 signifies best impact.
We next describe learning algorithms to determine a sin-gle value for  X  e h l from | F | values for it estimated using the feature functions. We build a different model for each lo-cation l  X  L and to build these models we use the training and test hashtag sets described in Section 3, which contains complete propagations for all hashtags. In particular, we present two learning algorithms depending on how the learn-ing algorithm assigns best feature function to a location: (i) linear regression algorithm which determines the weights for a linear combination of feature functions for a location; and, (ii) reinforcement learning algorithm which determines the single best feature function for a location.
 Learning with Regression : We first describe a learning algorithm using linear regression to determine a single value for  X  e h l , where a different model is built for each location l  X  L . To build these models we use the training and test hashtag sets described in Section 3. We know the complete propagation for a hashtag in the training and test sets. Con-sider the matrices X l and Y l : where, X l matrix has | H | rows, one for each hashtag in the training set. Every row contains 1 + | F | values each, ex-cept that for the first column, corresponding to the expected value for the hashtag calculated using the feature function corresponding to the column. The column matrix Y l has | H | rows with each value equal to the real expected value determined from the training set.

The values for the matrices is calculated using learning ( w l ) and prediction ( w p ) windows as shown in Figure 2. Note that, the expected value in Y l increases as we increase the prediction window, i.e. using a prediction window of 4 hours will have more hashtag occurrences than a window of 2 hours. Similarly, the observed hashtag occurrences used by feature functions to determine X l varies as the learning window is varied. The impact of varying these windows on the learning algorithms is evaluated later in the experiment section. Using these matrices, we define Y l as a linear func-tion of X l , where,  X  l is a column matrix called parameters matrix and E is the matrix of error terms. The parameters matrix con-tains the weights using which the various feature functions should be combined to determine  X  e h l from | F | estimates for it. The parameters matrix can be estimated by linear re-gression using the equation (3). We for a new hashtag h we can determine the expected occurrences for it using: Learning with Reinforcement : In the previous method we used linear regression to combine the values of expected hashtag occurrences estimated by all the feature functions. We now describe an approach that uses reinforcement learn-ing to determine this value. By reinforcement learning we mean that during every time interval the learning algorithm makes some prediction, then in the next time interval it updates its model based on its performance before making future predictions.

The learning algorithm is run independently for every lo-cation at regular time intervals. Let the weight W f l ( t ), for every location-feature function pair, represent the value that the learning algorithm uses to select a feature function for a given location at time t . During every time interval we select a feature function that we expect will perform best using W f l ( t ). We then evaluate the performance of all of all the feature functions using some metric (accuracy or im-pact) and update the W f l ( t ) accordingly. So, the idea is that after a few observations the algorithm learns which feature function is best suited for a location.
We describe two methods of reinforcement learning de-pen ding upon how W f l ( t ) is updated and used to select a feature function: (i) Deterministic method which selects the best feature function at any time; (ii) Randomized method which uses a probability to select a feature function. Deterministic Method : This method selects the single best feature function for a location. In this method the weight W f l ( t ) for every location-feature function represents the cumulative loss for the function until time t : then, for the next interval we select the feature function with the lowest cumulative loss until now, i.e. f = arg min f  X  F Randomized Method : Instead of picking a feature func-tion using cumulative loss as in the previous approach, in this method we select a feature function using a probabilis-tic approach. Let P f l ( t ), such that P f  X  F P f l ( t ) = 1, be the probability of choosing a feature function from F for lo-cation l at time t . We initialize these probabilities to The weight W f l ( t ) for every location-feature function is then used to determine probabilities for the next iteration. Like before, this weight is updated during every iteration as: where,  X   X  [0 , 1]. By using this function of  X  , as the accuracy for a feature function decreases the weight corresponding to that function decreases. The probability for choosing a feature function is then updated as:
We now evaluate the feature functions along with the learning algorithms described in this paper. In the first set of experiments we analyze performance of feature functions using accuracy and impact, and then the analyze the effect of varying various learning parameters. We then evaluate some characteristics of the learning algorithms. For the ex-periments we use the dataset described in Section 3.
In this section, we evaluate the performance of the feature functions and the learning algorithms using the metrics -ac-curacy and impact -described earlier in the paper. We start by evaluating the performance of the the feature functions and the learning algorithms on fixed parameters and then evaluate the performance of the learning algorithms by vary-ing parameters like number of top hashtags ( k ), the length of learning window and the length of prediction window.
An example of how the methods are evaluated, using eval-uation metrics, is shown in Table 2. In this example, we predicted the subset of hashtags for New York on Septem-ber 20, 2011. We predicted these hashtags at 20:00 UTC for the next 2 hours using a learning window of 6 hours. The first 3 columns show the prediction made by the 3 fea-ture functions -greedy, local spatial affinity and community affinity based on hashtag transmission. The last column shows the best set of hashtags or the gold set. The hashtags Table 3: Performance of various feature functions and learning algorithms in bold indicate that they were one of the correct hashtags predicted. In this example, we observe one of the drawbacks of greedy approach -it X  X  inability to predict hashtags which it hasn X  X  observed yet locally (in NY). The feature function using local spatial affinity does slightly better, in the sense it predicts mostly local hashtags, but misses out on hashtags that are popular globally like dudesthatsayno***, terrible-namesfor*** and so on. On the other hand, the feature function using community affinity based on hashtag trans-mission predicts 4 of the 5 hashtags correctly and performs the best. We also see that the performance of the feature function measured using the evaluation metrics we defined gives an indication of their actual performance.

We then evaluated the performance of all the feature func-tions and learning algorithms as shown in the example. We evaluated the methods using w p = 2 hours, w l = 6 hours and k = 10. The performance of the methods is shown in Table 2. Among the feature functions, we observe that the function that uses global spatial affinities performs the best. It has an accuracy and impact of 64%, implying that this method on average predicts 64% of hashtag occurrences for 2 hours in future correctly. In addition, as expected, the learning algorithms perform better than the individual feature func-tions with the method that uses reinforcement learning per-forming the best. The performance of this method could be attributed to the fact that it learns the best feature function for a location and uses that during predictions.
 Performance With Varying k : For this experiment, we evaluated the performance on various learning algorithms by varying the number of top hashtags ( k ). We set the learning window length w l = 6 hours, prediction window length w p 2 hour and then varied the value for k . The results of this experiment evaluated using accuracy and impact are shown in Figure 5(a) and Figure 5(d) respectively. The figures show the performance of the ranking algorithms as we vary the value of k from 1 to 25.

As described before, accuracy measures the similarity be-tween the set of hashtags selected by our algorithms and the best set of hashtags for that interval, while impact mea-sures how close we are to the best possible algorithm when it comes to the number of observed hashtag occurrences. We know that the distribution of hashtags at a location follows a zipfian distribution with few trails accounting for most oc-currences. Hence, the problem of selecting top  X  k hashtags becomes harder when k is small. The result of this distribu-tion is reflected in the performance of our ranking algorithms as well, where we observe that the performance of you al-20:00. gorithm improves as the value of k increases. The zipfian distribution also explains the flattening of the curve after around k = 10. The hashtags selected by the algorithms after this value of k don X  X  result in significant increase in im-pact as the observed occurrences of these hashtags is small, resulting in the flattening of the curve. Of the the learning algorithms, the algorithms that used reinforcement learning performed better than the algorithm that used linear regres-sion to estimate the value of expected hashtag occurrences. Performance With Varying w l : To evaluate the per-formance of our ranking algorithms for varying lengths of learning time window, we set the prediction time window w p = 2 hours and k = 10. We varied w l from 1 hour to 10 hours in 1 hour intervals. The results from this experiment using accuracy is shown in Figure 5(b) and using impact is shown in Figure 5(e).

We observe that the performance of the learning algo-rithms that use reinforcement is better than the algorithm that uses linear regression. But, there is no significant differ-ence between the two methods that use reinforcement learn-ing. Initially, as the length of learning window increases we see in improvement in accuracy (and impact) for all the al-gorithms. But accuracy beings to level out as the length of estimation window continues to increase. We believe the performance of the algorithms improves during initial in-crease in learning window because with a longer window they are able to analyze larger number of hashtag occur-rences which helps them make better decisions during pre-diction. But, as the window continues to increase they ob-serve older hashtags propagations, which results in evening out or even decreasing performance. The window that is best suitable for estimation might depend on the network on which the social network are propagating and the nature of hashtag themselves. In case of hashtag propagation on Twitter we found a window of 6 hours was best suited for hashtag prediction.
 Performance With Varying w p : We next evaluated the performance of our learning algorithms for varying lengths of prediction time window. We set the learning time win-dow w l = 6 hours and k = 10. We then varied w p from 1 hour to 10 hours in 1 hour intervals. The results from this experiment using accuracy is shown in Figure 5(c) and using impact is shown in Figure 5(f).

Like in earlier experiments we observe that learning algo-rithms that use reinforcement perform better than the lin-ear regression algorithm. In particular, we observe that the performance of the algorithms peaks when the prediction window is 2 hours and then decreases with the increase in length of prediction window. This result shows the sensitiv-ity of the prediction window, because unlike w l which had Figure 6: Distribution of preferred learning algo-rit hm in various locations by geographical areas (Im-pact). (a) Distribution of impact sco res Fig ure 7: Analysis of impact scores for various loca-tions. Using our learning algorithms we were able to achieve a impact of at least 60% for more than 80% of the locations. a region in which the performance didn X  X  change, in case of w p the performance of the model decreases almost linearly with time. In this section we analyze learning algorithms in detail. We first analyze the impact scores obtained using these al-gorithms and then analyze the rate at which the learning algorithms assign feature function to locations. We then an-alyze these algorithms further by defining a metric called flipping ratio which measures the uncertainty of a learning algorithm in assigning feature functions.
 Analysis of Impact Scores: We next analyze the impact scores for all the locations in our dataset. For this analysis we use impact scores obtained using the three algorithms that were compared in the previous section. Every location is assigned the best algorithm specific to it. We divided all the locations into 4 regions -United States (0 . 33%), Eu-rope (0 . 34%), South America (0 . 25%) and South-East Asia (0 . 08%). The number in bracket indicates the percentage of locations in the region. The distribution of the algorithms is shown in Figure 6. In spite of varying number of loca-tions in each region we observe that distribution of learning models is similar. All the regions have almost equal number of locations that prefer either deterministic or randomized algorithm and a small number of locations prefer linear re-gression.

The distribution of impact scores and its complementary cumulative distribution function is shown in Figure 7(a) and (a) Learning rate compari-son Figure 8: Deterministic algorithm learns faster than the randomized version and the hashtag density of a location impacts the rate at which it learns.
 Figure 7(b) respectively. As described earlier impact in a way measures how close the learning algorithm selected for a location is close to the ideal algorithm that can be designed for that location. So, a impact of 1 . 0 signifies the algorithm as good as the best algorithm. We observed that more than half of the locations, for which we made predictions, we were able to achieve an impact of at least 0 . 70.
 Analysis With Learning Rate: In this experiment we compare the rate at which the two reinforcement algorithms, we described in Section 6.2, learn feature function to be as-signed to a location. The result of this experiment is shown in Figure 8(a). In this figure, the learning time is shown in x-axis and the percentage of locations that flipped their decision in the current interval is shown in y-axis.
We observe that the deterministic algorithm is faster than the randomized algorithm. The flipping nature of these al-gorithms could be attributed to the way in which they select feature functions. The randomized algorithm selects a fea-ture function based upon probabilities estimated from the feature function weights while the deterministic algorithm is much simpler in the sense it makes a decision based upon the cumulative loss. These probabilities are non-zero for more than one feature function resulting in the algorithm flipping more. This issue is not observed in case of the deter-ministic algorithms making it much more stable and hence faster. In spite of the simple nature of deterministic algo-rithm we observe that its performance as better than that of the randomized algorithm. For hashtag propagation in Twitter we saw that we were able to assign feature function to locations using about a weeks data (flatting of red curve in Figure 8(a)).
 Analysis With Flipping ratio: We first describe flipping ratio and then analyze the learning algorithms using it. In our experiments test set is broken into time intervals of equal size. The learning algorithms select a feature function every interval. Then, flipping ratio measures the uncertainty of a learning algorithm by determining the number of times the algorithm changes its decision from that made in previous interval. It is defined as: whe re, an ideal learning algorithm with flipping ratio 0 . 0 will pick a feature function for a location in its first attempt, while the worst learning model with flipping ratio 1 . 0 will change its decision every interval.
We analyzed the correlation between the density of loca-tio n and its flipping ratio. Since, we can X  X  get the exact density for every location, we assume hashtag occurrences at a location as an indicator of the actual density. One of the issue with this assumption is that hashtag occurrence counts might not be a good indicator of actual density. For example, there could be dense locations with poor Inter-net connectivity resulting in low occurrences, while college towns with low density might have large number of occur-rences. But, this assumption doesn X  X  impact applications us-ing hashtag subset selection, because the hashtags selected by our models are still reflective of the user activity online and not the actual density. The correlation between density of a location and its flipping ratio is shown in Figure 8(b). We see that flipping ratio decreases with increase in density of a place. In other words, the ability of a learning algorithm to assign feature function to a location increases as the num-ber of hashtag occurrences at that location increases. This is an important result because, the earlier and more accu-rately we can assign feature function to a location with high density the better performance of our algorithm is.
In this paper, we proposed and evaluated approaches that predict where and when a online meme will be popular. In particular, we developed models based on the two competing hypotheses of information spread over geo-spatial networks -spatial affinity and community affinity. We then evalu-ated these models over a collection 755 million geo-tagged Tweets and found a model that can predict future hashtags occurrences with a 70% accuracy. In our future work, we are interested in analyzing how these approaches scale un-der large amount of data arriving at rapid rate. This work was supported in part by NSF grant IIS-1149383. Any opinions, findings and conclusions or recommendations expressed in this material are the author(s) and do not nec-essarily reflect those of the sponsors. [1] Universal transverse mercator coordinate system, [2] L. Backstrom, J. Kleinberg, R. Kumar, and J. Novak. [3] L. Backstrom, E. Sun, and C. Marlow. Find me if you [4] A. Brodersen, S. Scellato, and M. Wattenhofer. [5] Z. Cheng, J. Caverlee, and K. Lee. You are where you [6] E. Cunha, G. Magno, G. Comarela, V. Almeida, [7] N. Dalvi, R. Kumar, and B. Pang. Object matching in [8] D. Davidov, O. Tsur, and A. Rappoport. Enhanced [9] J. Ding, L. Gravano, and N. Shivakumar. Computing [10] Foursquare. About foursquare, April 2012. [11] M. Gomez Rodriguez, J. Leskovec, and A. Krause. [12] B. A. Huberman, D. M. Romero, and F. Wu. Social [13] K. Y. Kamath, J. Caverlee, Z. Cheng, and D. Z. Sui. [14] D. Kempe, J. Kleinberg, and E. Tardos. Maximizing [15] D. Kempe, J. Kleinberg, and  X  E. Tardos. Influential [16] G. Kossinets, J. Kleinberg, and D. Watts. The [17] H. Kwak, C. Lee, H. Park, and S. Moon. What is [18] K. Lerman and R. Ghosh. Information contagion: an [19] J. Lin, R. Snow, and W. Morgan. Smoothing [20] A. Noulas, S. Scellato, C. Mascolo, and M. Pontil. An [21] D. M. Romero, B. Meeder, and J. Kleinberg.
 [22] S. Scellato, A. Noulas, R. Lambiotte, and C. Mascolo. [23] W. Tobler. A computer movie simulating urban [24] O. Tsur and A. Rappoport. What X  X  in a hashtag?: [25] J. Yang and J. Leskovec. Modeling information
