 Recent advances in Web-based information extraction have allowed for the automatic construction of large, semantic knowledge bases, which are typically captured in RDF for-mat. The very nature of the applied extraction techniques however entails that the resulting RDF knowledge bases may face a significant amount of incorrect, incomplete, or even in-consistent (i.e., uncertain ) factual knowledge, which makes query answering over this kind of data a challenge. Our reasoner, coined URDF 1 , supports SPARQL queries along with rule-based, first-order predicate logic to infer new facts and to resolve data uncertainty over millions of RDF triplets directly at query time . We demonstrate a fully interactive reasoning engine, combining a Java-based reasoning back-end and a Flash-based visualization frontend in a dynamic client-server architecture. Our visualization frontend pro-vides interactive access to the reasoning backend, including tasks like exploring the knowledge base, rule-based and sta-tistical reasoning , faceted browsing of large query graphs, and explaining answers through lineage.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  search process Algorithms, Design, Management Uncertain RDF, Interactive Reasoning, Visualization A plethora of free semantic knowledge bases (including DBpedia and its inter-linked data sources, KnowItAll [8], ReadTheWeb [7] and YAGO [9, 19]) as well as commercial endeavors (including FreeBase.com, TrueKnowledge.com, Sig.ma, EntityCube, Wolfram Alpha, or Google Squared) http://urdf.mpi-inf.mpg.de reasoning. Soft rules can be employed in a deductive fash-ion to derive new facts from existing ones (including facts derived from other deduction steps), or to reinforce the con-fidence of existing base facts. Hard rules, on the other hand, enforce additional consistency constraints among both base and derived facts. The resulting logical dependencies among base and derived facts are captured via Boolean lineage for-mulas. Processing queries consists of two phases: 1) ground-ing the query against the rules and base facts contained in the knowledge base, and 2) a subsequent (propositional or probabilistic) consistency reasoning step. All reasoning-related computations X  X ncluding grounding and consistency reasoning X  X re handled by URDF at query time.
State-of-the-art RDF engines (see, e.g., [1, 11]) primar-ily focus on conjunctive queries on top of a relational en-coding of RDF data. These engines generally follow a de-terministic data and query processing model and do not have a notion of rule-based inference or uncertain reason-ing. Approaches for managing uncertainty in the context of probabilistic databases [3, 4, 5, 18, 17] focus on rela-tional data with fixed schemata and often employ strong independence assumptions among data objects (the  X  X ase tuples X ). ULDBs [4] provide a lineage-based representa-tion formalism for probabilistic data, which has been shown to be closed and complete under any combination of SQL operators and across arbitrary levels of materialized views. Here, the lineage (aka.  X  X istory X  in [18] or  X  X epair-key X  op-erator in [3]) of a derived tuple is captured as a Boolean formula, which recursively unrolls the logical dependencies from the derived tuple back to the base tuples. In probabilis-tic databases, SQL is employed for formulating queries and for defining views. SQL statements generally yield  X  X ard X  Boolean constraints among tuples, but lack the notion of  X  X oft X  dependencies among data items. Moreover, captur-ing correlated tuples [16] with probabilistic graphical models such as Bayesian Nets [6, 21] and Markov Random Fields [17] is finding increasing attention also in the database commu-nity. Also in the context of these graphical models, lineage remains the key for a closed representation model [10].
Statistical Relational Learning (SRL) has been gaining an increasing momentum in the machine learning, database, and knowledge management communities recently. Markov Logic Networks (MLNs) [14] are one of the most generic approaches for combining first-order logic and probabilis-tic graphical models. MLNs work by grounding a set of first-order logical rules against a knowledge base, and by sampling states ( X  X orlds X ) over a Markov network that rep-resents the grounded (i.e., propositional) formulas. Markov Logic however does not easily scale to very large knowledge bases. Even the most efficient, recent database approaches which adopt inference methods for probabilistic graphical networks, such as [21], [12] or [22], are designed for batch processing and are not well suited for interactive querying.
The reasoning backend is deployed under an Apache Tom-cat Web server and accesses a PostgreSQL database which captures the knowledge base. Our visualization frontend has been developed under Adobe Flex to run via Flash in almost any common Web browser, thus supporting a variety of oper-ating systems (e.g., Windows, Linux, Android) and clients Figure 2: Dependency graph for the query  X  X here does Bill Gates live, and where is this place located? X 
In contrast to soft rules, hard rules (i.e., consistency con-straints) have no intensional predicate as head literal and are not used for deriving new facts. Consistency constraints ei-ther have an arithmetic predicate (as above) or the constant false as head literal.

Lineage. The reasoner employs SLD resolution for ground-ing soft rules, while hard rules are not used for deduction and thus are grounded separately (see [20] for details on the grounding algorithm). Tracing lineage through SLD resolu-tion resolves to capturing the logical dependencies of derived facts back to the base facts. In analogy to [4, 17], we repre-sent lineage of derived facts as Boolean formulas.  X  Positive Lineage. SLD resolution with soft rules creates positive lineage. We obtain conjunctive lineage whenever we combine (ground) two or more positive literals that co-occur in the body of a rule. We obtain disjunctive lineage whenever two or more rules (including base facts) imply the same derived fact.  X  Negations. Hard rules offer a way to formulate negations in order to constrain the set of possible worlds. A special type of hard rules we consider in [20] partitions F into disjoint sets of mutually exclusive facts. In this case, each fact in such a  X  X ompetitor set X  may only be true if none of the facts it is in conflict with are true.

Propositional Reasoning. In propositional reasoning, we aim to find a truth assignment to facts in F that is con-sistent with all hard rules. In [20], we present a constrained and weighted MaxSAT solver that is specifically tailored to the combination of soft and hard rules we consider in our reasoning framework. It operates on a Boolean formula in conjunctive normal form (CNF), which is constructed as a conjunction of all clauses (including base facts, soft, and hard rules) that are grounded in response to a query.
Probabilistic Reasoning. In contrast to propositional reasoning, probabilistic reasoning does not consider only a single consistent truth assignment to facts (i.e., one possible world), but X  X t least conceptually X  all consistent worlds. In other words, the marginal probability of a derived fact f  X  F in is nothing else but the sum of probabilities of consistent worlds (i.e., those that do not violate any hard rule), for which the Boolean lineage formula of f evaluates to true. For general lineage formulas, probabilistic inference is known to explanation mode. In this mode, the graph granularity changes from an entity-relationship graph into a lineage graph, where the nodes represent entire facts, and the edges denote the logical dependencies among those facts. Additional con-junction (AND) and disjunction (OR) nodes group outgoing edges according to the logical dependencies among facts ob-tained from the deductive grounding steps. Lineage may not be cyclic, but it may form a DAG structure over the grounded facts. For better readability, lineage DAGs are flattened into trees, where a same fact may occur in mul-tiple branches of the tree. Fact nodes are again colored in green and red , according to the truth values assigned by the MaxSAT solver. An example explanation tree rooted at the fact livesIn(Bill Gates,Seattle, Washington) is shown in Fig-ure 4. The upper OR node indicates that several derivations for this fact exist. The second level of the expanded lineage branch has been obtained from the same soft rule as shown in Rule (1). Several sub-trees have been collapsed for better readability (as indicated by the dots).

Comparison Mode. Finally, the comparison feature al-lows for comparing the answers of any two subsequently ex-ecuted queries, including changes obtained from updating soft or hard rules. Nodes and edges, which are only con-tained in the first answer set, are colored in black borders; those contained in the second set are colored in white bor-ders; and those shared by both sets have yellow borders.
Our demo currently runs interactively on the latest ver-sion of the YAGO [9] knowledge base, consisting of more than 10 million entities and more than 80 million facts about these entities. To demonstrate all features of our inter-active reasoning framework, we have prepared more than 10 SPARQL queries, ranging from single-literal queries like  X  X ho is Woody Allen married to? X  to multi-join query pat-terns which require intricate reasoning steps. The demo will focus on queries and rules about people and locations (such as universities and people X  X  advisors or alma maters, merged with gazetteer data from geonames.org ), as these domains are particular strengths of YAGO. Following the scenario shown in Figures 1 X 4, we start by showing the difference be-tween results obtained from plain SPARQL-style query pro-cessing in comparison to rule-based reasoning. We then iter-atively explore the knowledge base around the initial result entities, thus constantly growing the graph. As the informa-tion displayed by the expanded graph becomes increasingly cluttered, we can take advantage of the faceted browsing fil-ter which provides a fine-grained control over the visualized information. We finally demonstrate how the explanation and comparison modes can be employed to effectively visu-alize how rule updates affect the query answers. At all steps of the demonstration, there will be ample opportunity for the audience to propose new queries, update rules, and try out different features of the reasoner.
