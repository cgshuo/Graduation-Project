 In applications such as Machine Translation (MT) and Dialogue Systems, sentence realisation is a ma-jor step. Sentence realisation involves generating a well-formed sentence from a bag of lexical items. These lexical items may be syntactically related to each other. The level of syntactic information at-tached to the lexical items might vary with applica-tion. In order to appeal to the wide range of applica-tions that use sentence realisation, our experiments assume only basic syntactic information, such as un-labeled dependency relationships between the lexi-cal items.

In this paper, we present different models for sen-tence realisation. These models consider a bag of words with unlabelled dependency relations as input and apply simple n-gram language modeling tech-niques to get a well-formed sentence.

We now present the role of a sentence realiser in the task of MT. In transfer-based approaches for first analyzed by a parser (a phrase-structure or a dependency-based parser). Then the source lexical items are transferred to the target language using a bi-lingual dictionary. The target language sentence is finally realised by applying transfer-rules that map the grammar of both the languages. Generally, these transfer rules make use of rich analysis on the source side such as dependency labels etc. The accuracy of having such rich analysis (dependency labeling ) is low and hence, might affect the performance of the sentence realiser. Also, the approach of manually constructing transfer rules is costly, especially for divergent language pairs such as English and Hindi or English and Japanese. Our models can be used in this scenario, providing a robust alternative to the transfer rules.

A sentence realiser can also be used in the frame-work of a two-step statistical machine translation. In the two-step framework, the semantic transfer and sentence realisation are decoupled into indepen-dent modules. This provides an opporunity to de-velop simple and efficient modules for each of the steps. The model for Global Lexical Selection and Sentence Re-construction (Bangalore et al., 2007) is one such approach. In this approach, discrimi-native techniques are used to first transfer semantic information of the source sentence by looking at the source sentence globally, this obtaining a accurate bag-of-words in the target language. The words in the bag might be attached with mild syntactic infor-mation (ie., the words they modify) (Venkatapathy and Bangalore, 2007). We propose models that take this information as input and produce the target sen-tence. We can also use our sentence realiser as an ordering module in other approaches such as (Quirk et al., 2005), where the goal is to order an unordered bag (of treelets in this case) with dependency links.
In Natural Language Generation applications such as Dialogue systems etc, the set of concepts and the dependencies between the concepts is ob-tained first which is known as text planning. These concepts are then realized into words resulting in a bag of words with syntactic relations (Bangalore and Rambow, 2000). This is known as sentence plan-ning. In the end, the surface string can be obtained by our models.

In this paper, we do not test our models with any of the applications mentioned above. However, we plan to test our models with these applications, es-pecially on the two-stage statistical MT approach using the bag-of-words obtained by Global Lexi-cal Selection (Bangalore et al., 2007),(Venkatapathy and Bangalore, 2007). Here, we test our models in-dependent of any application, by beginning with a given bag-of-words (with dependency links).

The structure of the paper is as follows. We give an overview of the related work in section 2. In sec-tion 3, we talk about the effect of dependency con-straints and gives details of the experimental setup in section 4. In section 5, we describe about the exper-iments that have been conducted. In section 6, our experimental results are presented. In section 7, we talk about the possible future work and we conclude with section 8. There have been approaches for sentence realisation such as FUF/SURGE (Elhadad, 1991), OpenCCG (White, 2004) and XLE (Crouch et al., 2007) that apply hand-crafted grammars based on partic-ular linguistic theories. These approaches expect rich syntactic information as input in order to re-alise the sentence. There are other approaches in which the generation grammars are extracted semi-automatically (Belz, 2007) or automatically (such as HPSG (Nakanishi and Miyao, 2005), LFG (Cahill and van Genabith, 2006; Hogan et al., 2007) and CCG (White et al., 2007)). The limitation of these approaches is that these cannot be incorporated into a wide range of applications as they rely on rich syntactic information for generation. On the con-trary, we use simple n-gram models to realise (or lin-earize) a bag-of-words where the only information available is the presence of various links between the words.

Our work is similar to a recently published work by Guo (Guo et al., 2008). They use n-gram models to realise sentences from the f-structures of HPSG (equivalent to labeled dependency structure). Their models rely heavily on the dependency relation la-bels (also called grammatical roles) available in HPSG. However, the dependency role information (of any dependency formalism) is either not read-ily available in a variety of applications in NLP. We propose to explore the realisation of a sentence us-ing minimal syntactic information. Apart from de-pendency links, we also make use of part-of-speech tags which are easily available and hence, our sen-tence realiser can be plugged much easily into var-ious applications. Guo (Guo et al., 2008) conduct their experiments by considering gold data as input. Apart from using gold data as input, we also con-duct experiments by assuming noisy input data to test the robustness of our models. The search al-gorithm used by both Guo and us is locally greedy i.e., we compute the best string at every node. Guo uses the Viterbi algorithm to get best string whereas we consider and score all permutations to obtain the best string.

There has been burgeoning interest in the prob-abilistic models for sentence realisation, especially for realisation ranking in a two stage sentence real-isation architecture where in the first stage a set of sentence realisations are generated and then a real-isation ranker will choose the best of them (Banga-lore and Rambow, 2000).

One major observation in our experiments was that the POS tags held immensely in the task of sen-tence realisation. There is a major advantage in using dependency constraints for sentence realisation. The search space reduces drastically when the constraints are applied. These constraints state that the realised sen-tences should be projective with respect to the de-pendency structure (unordered) of the input bag-of-words ie.., any word and its children in the depen-dency tree should project as a contiguous unit in the realised sentence. This is a safe assumption to make as the non-projectivity in English is only used to account for Long-Distance Dependencies and such cases are low in number (Guo et al., 2008). Figure 1: Bag of words with dependency constraints and head marked
We now present an example to show how the de-pendency constraints reduce the search space. For example, consider an unordered dependency tree in Figure 1, which has five words. If we don X  X  use the constraints provided by the dependency tree then the search space is 5! (120). But, if we use the con-straints provided by the dependency tree then the search space is 2! + 4! = 28. There is a huge reduc-tion in the search space if we use the constraints pro-vided by the dependency tree. Further, it has been shown in (Chang and Toutanova, 2007) that apply-ing the constraints also aids for the synthesis of bet-ter constructed sentences. For the experiments, we use the WSJ portion of the Penn tree bank (Marcus et al., 1993), using the stan-dard train/development/test splits, viz 39,832 sen-tences from 2-21 sections, 2416 sentences from sec-tion 23 for testing and 1,700 sentences from sec-tion 22 for development. The input to our sen-tence realiser are bag of words with dependency constraints which are automatically extracted from the Penn treebank using head percolation rules used in (Magerman, 1995), which do not contain any or-der information. We also use the provided part-of-speech tags in some experiments.

In a typical application, the input to the sentence realiser is noisy. To test the robustness of our models in such scenarios, we also conduct experiments with noisy input data. We parse the test data with an un-labelled projective dependency parser (Nivre et al., 2006) and drop the order information to obtain the input to our sentence realiser. However we still use the correct bag of words. We propose to test this as-pect in future by plugging our sentence realiser in Machine Translation.

Table 1 shows the number of nodes having a par-ticular number of children in the test data.
Children countNodes Children countNodes 0 30219 5 1017 1 13649 6 685 2 5887 7 269 3 3207 8 106 4 1526 &gt; 8 119 Table 1: The number of nodes having a particular number of children in the test data
From Table 1, we can see that more than 96% of the internal nodes of the trees contain five or less children. It means that for almost all the nodes, the reordering complexity is minimal. This makes this approach very feasible if the order of a sub-tree is computed after the order of the sub-trees of its chil-dren is fixed. Hence, the approaches that we present in the next section use bottom-up traversal of the tree. During the traversal, the appropriate order of every sub-tree is fixed. The task here is to realise a well formed sentence from a bag of words with dependency constraints (unordered dependency tree) for which we propose five models using n-gram based Language modeling techinque. We train the language models of order 3 using Good-Turning smoothing on the training data of Penn Treebank. 5.1 Model 1 : Sentential Language Model We traverse the tree in bottom up manner and find the best phrase at each subtree. The best phrase cor-responding to the subtree is assigned to the root node of the sub-tree during the traversal.

Let the node n have N children represented as c ( 1 &lt; i &lt; N ). During the bottom up traversal, the children c ing node n . Let the best phrases corresponding to the children be p ( c the node n is computed by exploring the permuta-tions of n and the best phrases p ( c to the children c that are explored are ( N +1)! . A sentential language model is applied on each of the candidate phrases to select the best phrase. p ( n ) = bestP hrase ( perm ( n,  X  i p ( c i )) o LM )
In Sentential Language Model, we used a LM that is trained on complete sentences of the training cor-pus to score the permutations. 5.2 Model 2 : Subtree-type based Language The major problem with model 1 is that we are us-ing a common sentential language model (trained on complete sentences) to score phrases corresponding to various sub-tree types. In this model, we build different LMs for phrases corresponding to different subtree-types.
 To build STLMs, the training data is parsed first. Each subtree in the parse structure is represented by the part-of-speech tag of its head. Different lan-guage models are created for each of the POS tags. We have 44 different language models each corre-sponding to a particular POS tag. For example, a IN language model contains phrases like in hour, of chaos, after crash, in futures, etc and VBD language model contains phrases like were criticized, never resumed while training.

So, in this model we realise a sentence from a unordered dependency tree by traversing the depen-dency tree in bottom-up manner as we did in model 1; but while scoring the permuted phrases we use different language models for subtrees headed by words of various pos tags. Here, LM associated with the part-of-speech of the node n . 5.3 Model 3 : Head-word STLM In the models presented earlier, a node and its chil-dren are ordered using the best phrases of the chil-dren. For example, the best phrase assigned to the node  X  X as X  is computed by taking of the permutation of  X  X as X  and its children  X  X he equity market X ,  X  X lliq-uid X  and  X . X  and then applying the language model. In model 3, instead of considering best phrases while ordering, the heads of the the children c ered. For example, the best phrase assigned to the node  X  X as X  is computed by first permuting the nodes  X  X as X ,  X  X arket X ,  X  X lliquid X  and  X . X  and then apply-ing the language models trained on the treelets (head and children) and not on entire sub-trees.

The major advantage of using this model is that order at a node is independent of the best phrases of its descendants and also any mistakes in computa-tion of best phrases of descendants doesn X  X  effect the choice of reordering decision at a particular node. 5.4 Model 4 : POS based STLM We now experiment by using Part-Of-Speech (POS) tags of words for ordering the nodes. In the previ-ous approaches, the language models were trained on the words which were then used to compute the best strings associated with various nodes. Here, we order the node and its children using a language model trained on POS tag sequences. The motiva-tion behind buliding such kind of Language models is that it deals with unseen words effectively. Hence, in this model, the best phrase corresponding to the node  X  X as X  is obtained by permuting the POS tags of the words  X  X as X ,  X  X arket X ,  X  X lliquid and  X . X  which are  X  X BZ X ,  X  X N X ,  X  X N X  and  X . X  respectively. As the best POS tag sequence might correspond to several orderings of the treelet, a word based STLM is ap-plied to choose the correct ordering.

The major advantages of this model is that it is more general and it deals with unseen words effec-tively. Also, it is much faster than earlier models as this model is a POS tag based model. 5.5 Model 5: Head-marked POS based STLM In POS based STLM, the head of a particular node isn X  X  marked while applying the language model. Hence, all the nodes of the treelet are treated equally while applying the LM. For example, in Figure 2, the structures of treelets is not taken into account while applying the head-POS based language model. Both are treated in the same manner while applying TLM. In this model, we experiment by marking the head information for the POS of the head word which treats the treelets in Figure 2 in a different manner to obtain the best phrase. As the best POS tag sequence might correspond to several orderings of the treelet, we test various word-based approaches to choose the best ordering among the many possibilities. The best approach was the one where head-word of the treelet had the POS tag attached to it.
 Figure 2: Two different treelets which would have same best POS tag sequence To evaluate our models, we compare the system gen-erated sentences with reference sentences and get the BLEU score. As mentioned in section 4, We evaluate our models on two different types of in-put. In the first input type, we have bag of words with dependency constraints extracted from tree-bank and in the second input type, the dependency constraints among the bag of words are extracted from the parser which are noisy. Table 2 shows the results of model 1-5.
 Model Treebank(gold) Parser(noisy) Model 1 0.5472 0.5514 Model 2 0.6886 0.6870 Model 3 0.7284 0.7227 Model 4 0.7890 0.7783 Model 5 0.8156 0.8027
We can observe that in model 1, BLEU score of the parser input is high when compared to Treebank input. This might be because, the parser input is pro-jective (as we used projective parsing) whereas the treebank input might contain some non-projective cases. In general, for all the models, the results with noisy dependency links are comparable to the cases where gold dependency links are used which is en-couraging.

We have taken the Table-3 from (Guo et al., 2008), which shows the BLEU scores of different Paper BLEU score Langkilde(2002) 0.757 Nakanishi(2005) 0.705 Cahill(2006) 0.6651 Hogan(2007) 0.6882 White(2007) 0.5768 Guo(2008) 0.7440 Our Model 0.8156 Table 3: Comparsion of results for English WSJ sec-tion 23 systems on section 23 of PTB. Its really difficult to compare sentence realisers as the information con-tained in the input vaires greatly between systems. But, we can clearly see that the our system performs better than all the systems. The main observations from the results are, (1) Searching the entire space of O(n!) helps, (2) Treelet LM capture characteristics of phrases headed by various POS tags, in contrast to sentential LM which is a general LM, (3) POS tags can play an important role in ordering nodes of a de-pendency structure, (4) The head models performed better than the models that used all the nodes of the sub-tree, and (5) Marking the head of a treelet pro-vides vital clues to the language model for reorder-ing. Although the results of the proposed models are much higher when compared to other methods, the major constraint with our models is the computa-tional complexity, which is O(n!). However, our ap-proach is still tractable because of the low values of n . We plan to reduce the search space complexity by using Viterbi search (Guo et al., 2008), and examine the drop in results because of that.

The models proposed in paper, consider only the locally best phrases (local to the sub-tree) at every step. In order to retain the globally best possibilities at every step, we plan to use beam search, where we retain K-best best phrases for every sub-tree.
Also, the goal is to test the approach for morphologically-rich languages such as Hindi. Also, it would require us to expand our features set. We also plan to test the factored models.

The most important experiment that we plan to perform is to test our system in the context of MT, where the input is more real and noisy.

To train more robust language models, we plan to use the much larger data on a web scale. In this paper, we had experimented with five ngram based models for sentence realisation from bag of words with dependency constraints. We have evalu-ated our models on two different types of input(gold and noisy). From the results, we can conclude that the model  X  X arked Head-POS based LM X  works best in both cases.
 The authors of this work were supported by ILMT grant 11(10)/2006-HCC(TDIL) and EILMT grant 11(9)/2006HCC(TDIL). We would also like to thank the four reviewers for their valuable reviews.
