 The research on image advertising is still in its infancy. Most previous approaches suggest ads by directly matching an ad to a query image, which lacks the power to identify ads from adjacent knowledge on adjacent markets from ads videos with a novel Multi-Modal Dirichlet Process Mixture Sets model, which is a unified model of (video frames) clustering and (ads) ranking. Our approach is not only capable of discovering relevant ads (e.g. car ads for a query car image), but also suggesting ads from adjacent proposed approach is fairly effective. I.5.4 [ Pattern Recognition ]: Applications  X  computer vision . G.3 [ Probability and Statistics ]: Nonparametric statistics . Algorithms, Performance. Image advertising, adjacent marketing, video retrieval. Though image has become an importa nt media in the Web, how to monetize web images is a seldom touched problem. Few research works have been published in the literature. Among them, most of the works suggest directly mapping an ad to an image [2]. They suffer from the vocabulary impedance problem so that if a term connections will be built between them. The approach of Wang et al. [4] improves this by leveraging the ODP ontology to bridge the vocabulary gap, but it is still limited by the available texts. Adjacent marketing means to develop additional items which compliment a customer X  X  needs in some manner, e.g. suggest insurance when one buys a car. The insurance package thus makes discover the potential adjacent market (e.g. insurance) of a certain product/object (e.g. car). In this paper we propose a solution of adjacent marketing for image advertising based on a large-scale ads video collection. It is motivated by the fact that generally a video ad contains two types Story frames in general provide the main concepts (e.g. cars) that imply certain human knowledge on the adjacent markets, e.g. showing tire ads on car images. A novel Multi-Modal Dirichlet Process Mixture Sets (MoM-DPM Sets) model is proposed as the key technique behind. Figure 2 shows the system overview. In the offline stage, we extract video keyframes and perform auto-tagging on them. The keyframes of ads videos given a query image (or query images). The texts come from three resources: image auto-tagging, OCR and surrounding texts; 2) search result expansion. Since the search the adjacent information between objects, we expand the retrieved frames with the rest frames in corresponding videos. For example, given the pizza image in Figure 2, the retrieved frames are generally about food, but by expa nding them with the rest frames from the same ads videos, we are able to retrieve those soft drink and restaurant video frames whic h suggest the adjacent markets; and 3) ads clustering and ranki ng. The disadvantage brought by scattered topics. We propose the MoM-DPM Sets model to automatically learn the key topics from the expanded search 
Figure 1. Key idea: the story frames (in red blocks) and ads frames (cyan blocks) of video ads suggest adjacent markets. ranked ads will be output. Therefore we find ads of Pepsi Cola and restaurants for the pizza image. The MoM-DPM Sets model addresses four challenges: 1) automatically determine the number of topics, 3) leverage both the visual and textual features to ensu re a better performance of topic discovery, and 4) unify the appr oaches of topic mining and ads ranking. features of a query image respectively. Let  X , X   X  concentration parameter and base distributions of visual and textual features respectively. Let  X   X   X ,  X  be model parameters and  X   X ,  X  frames labeled by the topic  X   X  respectively. The general form of is MoM-DPM Sets is given in Eq(1).  X   X   X   X   X  X  |  X   X  X  X   X ,  X   X ,  X   X ,  X   X ,  X   X   X   X   X   X   X   X   X   X   X   X  if  X  topic  X  .  X  is the normalization factor.  X  is the number of observed to solve the model, which genera lly converges in 30 iterations. MoM-DPM Sets has two key feat ures which make it different from previous multimodal DP Mixture processes [3]. Firstly, rather than to learn an optimal parameter set of  X  to figure out the membership of each video frame given the observed video frames  X   X  are known (  X   X  Such a set-based reasoning strategy [1] is more powerful in discovering analogical objects, e.g. given a frame set of Pepsi-cola does not rely on certain paramete r set, the clustering (topic mining) step and ranking step shar es the same model formulation. The ranking process is as Eq.(2).  X  X  X  X  X   X   X  X   X   X   X  X  X  X   X   X   X   X   X   X  X  |  X   X .. X   X ,  X   X ,  X   X  where  X   X .. X   X  X  X  X   X   X ,  X   X ,...,  X   X  defines the latent topic space. We crawled about 32k videos from Youtube.com initiated by 30 popular concepts for advertising. In total 327,889 key frames were extracted, which make up of the ads videos collection for frame search. We randomly selected 450 ads as a separate ads DB for the ranking purpose. 100 Flickr images were used as queries. approach compared with those of the baselines Argo [4] and direct outperforms the baselines. The ga p between the blue curve and relevant ads from potential adjacent market, which have little And the gap between the red curve and the green one indicates that Argo [4] also tackles the adjacent marketing problem to a certain extent but it is not effective enough. There are big gaps between our me thods and the baselines in top 3 may due to the limited size of our ads DB. Considering that generally a publisher such as Googl e shows less than five targeted ads, our method suggests a prom ising research direction for adjacent marketing. Web image is an uncovered gold mine. Our method is the first work to tackle the adjacent marketing problem for image advertising. It leverages the human intelligence embedded in novel Multi-Modal Dirichlet Pr ocess Mixture Sets model. [1] Z. Ghahramani, and K. A. He ller. Bayesian Sets. Neural [2] T. Mei, X.-S. Hua, and S.-P . Li. Contextual In-Image [3] A. Velivelli, and T.S. Huang. Automatic Video Annotation [4] X.-J. Wang, M. Yu, et al. Argo: Intelligent Advertising by 
