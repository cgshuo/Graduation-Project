 A key characteristic of a successful online market is the large participation of agents (producers and consumers) on both sides of the market. While there has been a long line of im-pressive work on understanding such markets in terms of rev-enue maximizing (also called max-sum) objectives, particu-larly in the context of allocating online impressions to inter-ested advertisers, fairness considerations have surprisingly not received much attention in online allocation algorithms. Allocations that are inherently fair to participating entities, we believe, will contribute significantly to retaining current participants and attracting new ones in the long run, thereby enhancing the performance of online markets. We give two generic online allocation algorithms to address this prob-lem. In the first algorithm, we address the max-min fairness objective which is defined as the minimum ratio among all advertisers of the actual revenue obtained by the allocation to given target revenues. The second algorithm considers a hybrid objective of max-sum with a revenue penalty for each advertiser who misses her revenue target. We consider a penalty that is linear in the difference between the target and the actual revenue. For both these objectives, we give online algorithms that achieve a competitive ratio of (1  X  for any &gt; 0 assuming an IID input.
As the internet achieves ubiquity and web-based services become an indispensable component of modern life, online systems have increasingly relied on efficient algorithms for allocating scarce resources to competing entities. While this problem has had a long history of algorithmic research which predates the modern-day internet by several decades, the emergence of the web has led to vigorous renewed activity, particularly in the context of online applications where the participating entities are substantially more dynamic and unpredictable than in traditional offline settings such as job scheduling. We describe such a setting as an online market where producers must be matched with consumers to meet specific demands that arrive over time. While this generic definition captures the essence of various real-world alloca-tion problems, we describe some key applications in the do-main of internet technologies that motivated our study.
In essence, any service that arbitrates among a set of avail-able choices in order to satisfy a demand that arrives online must meet the dual objectives of revenue and fairness in its arbitration protocol. In this paper, we consider the follow-ing general setting. A set of providers (such as advertisers, data providers, etc.), each constrained by a budget ,aregiven offline. A set of requests (such as advertising slots on web-pages, data queries, etc.) arrive online. Each request can be allocated to one among a subset of providers, and such an allocation generates a specified amount of revenue sub-ject to the constraint that the total revenue for a provider cannot exceed her budget. In the revenue-maximizing set-ting, the goal of the allocation algorithm is to maximize the revenue. However, to address the fairness objective, we in-troduce a new offline parameter called the target for every provider. Notionally, this represents the minimum revenue for a provider that gives her sufficient incentive to stay in the system. The online allocation algorithm must now en-sure that each provider meets her target, even if that comes at the cost of decreased revenue. Of course, among the al-locations that would meet the targets, the algorithm will continue to favor ones that generate greater revenue.
Our main contributions in this paper can be summarized as follows. 1. We formalize the generic online allocation problem and 2. We give efficient algorithms for the Max-Min and 3. Finally, we perform large-scale experiments on real-
For online ad markets, we consider the following setting: an advertiser comes to the market with a budget and a goal of maximizing her participation in the auctions subject to her budget. The goal of the market is to maximize revenue while improving advertiser satisfaction measured in terms of two natural fairness objectives: (1) the ratio of impressions won to impressions participated in and (2) the number of unique advertisers that won at least one impression.
In the information market setting, we consider a data mar-ket where e-commerce catalogs comprising product infor-mation are the information providers. Using targets derived from the quality of products in a provider X  X  catalog, we mea-sure the performance of our algorithms in terms of the ratio of actual queries served to the target as well as the total number of catalogs that get to serve some query.
There has been substantial research on understanding the trade-off between fairness and other objectives, particularly maximization objectives in resource allocation such as band-width maximization in networks (see, e.g., [9, 22]), maxi-mizing throughput and utilization of computing resources in scheduling (see, e.g., [2, 8]), etc. There has been some recent work on studying the trade-off between fairness and efficiency in display ad systems both for web applications as well other domains such as TV ads [19, 6, 15]. Of these, the closest to our work is [6], where the authors perform an experimental evaluation of the trade-off between efficiency and fairness. Instead, we give a concrete Hybrid formu-lation that simultaneously achieves fairness and efficiency, and in addition to experiments, we analytically show that our Hybrid algorithm is almost optimal for its objective function. Our Hybrid algorithm is based on a dual-based training algorithm for the Max-Sum problem due to De-vanur and Hayes [4]. There has been substantial research following up on this work applying similar technique to a more general suite of allocation problems and obtaining less restrictive versions of the so called  X  X arge budgets X  condi-tion [1, 6, 5, 17, 12]. The Max-Sum objective has been studied extensively over the last few years, particularly in the context of online ad allocation, both in the adversarial input model [16, 3] and also in stochastic input models such as the one considered in this paper [4, 10] (see also the re-cent survey by Mehta [14] and references contained therein). In addition to the Hybrid and Max-Sum objectives, we also have a formulation (the Max-Min problem) that solely focuses on the fairness objective. This formulation is similar to the diversification objective in [20], but whereas the goal in their work was to study the online selection problem, we study the online allocation problem.
As described in the introduction, we will formulate three versions of the resource allocation problem that correspond to the max-min, the max-sum, and a hybrid objective. Let D be a set of n providers .Let B i and T i be the budget and target respectively for provider i  X  D ,where T i  X  B Intuitively, the budget and target of a provider represent her maximum and minimum revenue respectively.

An input set Q of m requests arrives over time (online), where each request j  X  Q has a bid value b ij corresponding to each provider i  X  D . The bid value represents the revenue earned if the query j is assigned to provider i , subject to the budgetary limits of provider i . (Bid values are non-negative but can be 0.) On the arrival of request j , the algorithm allocates it to a provider (denoted d ( j )). Let Q ( i )betheset of requests that are allocated to provider i .The unrestricted revenue R i corresponding to provider i  X  D is given by j  X  Q ( i ) b ij , while the budgeted revenue (or simply revenue ) P i corresponding to provider i  X  D is given by min( R i ,B The fractional coverage c i for provider i  X  D is given by the
The three versions of this problem differ in the objectives that they seek to optimize.
We will analytically measure the quality of our algorithms by their competitive ratio , which is the minimum (over all input sequences) ratio of the objective of the algorithmic solution to that of the (offline) optimal solution. Unfortu-nately, the following theorems assert that in the adversarial setting (i.e., for the worst-case input sequence), the Max-Min and Hybrid problems have strong lower bounds. (The proofs of these theorems are deferred to the full version of the paper.)
Theorem 1. There is no randomized algorithm that ob-tains a competitive ratio better than 1 n for the Max-Min lem in the adversarial input model. On the other hand, a simple algorithm that assigns each request uniformly at ran-dom to one of the n providers has a competitive ratio of 1
Theorem 2. There is no randomized algorithm that ob-tains a non-zero competitive ratio for the Hybrid problem in the adversarial input model.
 In the online setting, the main algorithmic challenge is to provision for the future without knowing the future input. However, in practical scenarios such as internet advertising, the impressions arriving over time have a relatively consis-tent pattern though they may be subject to temporary fluc-tuations. We formally model this by assuming that the re-quests are independently and identically distributed (i.i.d.) according to some probability distribution that is not known to the algorithm. Note that the variance in the distribution automatically produces a certain degree of input fluctua-tion; however, the mere fact that the input must be drawn from some fixed (but unknown) distribution ensures that a certain level of consistency in the long run, which our al-gorithms exploit. It is important to note that the support of this distribution can be extremely large (e.g., exponential in the number of providers), and therefore, we cannot hope for strong concentration bounds in the actual bid values. However, the marginals of this distribution on the advertis-ers must be highly concentrated if the number of requests is large compared to the number of providers, which is typ-ically the case. Roughly speaking, this corresponds to the intuitive claim that the average (over large enough time in-tervals) of the bid values of a provider for the requests that arrive online remains fixed (or is subject to relatively small variations). This allows the following generic technique: ini-tially, estimate the marginal distribution of bid values for the providers from a small constant fraction of requests (say 1%) and then use these marginals to guide allocation deci-sions in the future.
Recall that in the Max-Min problem, the goal is to maxi-mize the minimum fractional coverage over all the providers, where the coverage of a provider is the ratio of her revenue to her target. For this problem, we will describe a simple and efficient algorithm (we call it the Max-Min algorithm) and theoretically verify that it is obtains a nearly optimal solution. Before describing the algorithm formally, let us give some intuition behind it.

First, note that in this problem, we can replace actual rev-enue (capped by budgets) by the corresponding unrestricted (i.e., uncapped) revenue for each provider. This is without loss of generality (w.l.o.g). Consider an algorithm that ob-tains a minimum coverage of c .If c  X  1, all targets are attained and the solution is optimal. So, we focus on c&lt; 1. In this case, a provider i attains a revenue of at least c But, note that T i  X  B i ;thus, Hence, the (capped) actual revenue attained by provider i is also at least c  X  T i . Therefore, we ignore budgets in the remainder of this section (for the Max-Min problem).
Perhaps the most obvious algorithm for the Max-Min prob-lem is one that greedily assigns each request to the provider who bids the maximum for it. However, this algorithm can be counter-productive in some scenarios, e.g., if there is a provider who bids large values but has a relatively small target and budget. In fact, consider the following scenario. Suppose at some stage of the input, the algorithm has sat-isfied the targets of all except one provider. Clearly, in all subsequent allocations, the algorithm must attempt to al-locate the arriving request to this lone provider since such an allocation would increase the minimum coverage. More generally, this suggests that the first few units of revenue generated by a provider are more important than the latter units of revenue. To capture this intuition, we introduce a reward function that encodes the importance of a unit of revenue based on the current revenue of a provider. The reward function decreases as the revenue of a provider in-creases. The reward earned by a particular allocation is the cumulative value of the reward function earned by the provider over the interval corresponding to her previous rev-enue to her new revenue. The algorithm simply assigns an arriving request to the provider who earns the maximum re-ward for it. Note that the na  X   X ve greedy algorithm described above is simply a version of our algorithm where the reward function is uniform over the entire range of revenue.
Let us now formally define algorithm Max-Min .Letthe expected optimal value of the objective function be denoted by c opt . We will assume that the algorithm knows (or has a good estimate of) the value of c opt . This assumption can be removed in exchange for a small loss in the competitive ratio of the algorithm. As described above, our algorithm uses a reward function  X  defined as where  X  is a constant that we will fix later. We also define At any stage of the algorithm, the remaining reward for provider i is  X   X  i =  X   X ( c i ), and the overall remaining reward is  X 
Let j be the current request. If the current allocation has fractional coverage c i for some provider i  X  D j , then the reward r ij of allocating request j to provider i is defined as the decrease in the value of  X   X  if request j is allocated to provider i , i.e., The Max-Min algorithm allocates the current request j to the provider i  X  D j that maximizes r ij . Assumption. Suppose that for some &gt; 0, we have the property where  X  indexes the support of the probability distribution from which are requests are drawn. Intuitively, this assump-tion ensures that none of the targets are too small compared to the maximum bid value. Note that this is true in practice in typical applications; e.g., in internet advertising, typical bids are in the range of a few cents, whereas advertising targets are millions of dollars.

With this assumption, we will now prove the next theo-rem.

Theorem 3. The competitive ratio of the above algorithm for the Max-Min problem is 1  X  .

Before giving a formal proof, let us sketch the main ideas that we will use in our analysis. Let  X  opt = c opt min i  X  D We will assume that for some constant  X  that we will fix later. We will show later that using a carefully chosen value of  X  ,theabove assumption on  X  opt holds as a consequence of our original assumption on the value of min i  X  D T i . Therefore, we are not introducing any new assumptions here.

Our main technical tool is the following lemma, which lower bounds the expected decrease in the value of the po-tential in every step of the algorithm.

Lemma 4. At any stage of the algorithm, the expected (over the input) decrease in  X   X  for the next item in the input stream is at least (1  X  1 / X  )  X  ln n m  X   X  . Figure 1: LP relaxation of the Max-Min problem.
 We will prove this lemma shortly, but first, let us show how this lemma leads to Theorem 3. The above lemma implies that the value of  X   X  decreases to at most since 1  X  x  X  e  X  x . Using this repeatedly over the m requests, and observing that the initial value of the potential is n ,we can upper bound the expected value of the potential at the end of the algorithm.

Corollary 5. The expected value of  X   X  when the algo-
We set  X  = c opt n ln n and  X  =1 / , which satisfies Eqn. (1) subject to our original assumption. Now, we are ready to complete the proof of Theorem 3.

Proof of Theorem 3. Suppose not, and let i min be the provider with the minimum fractional coverage at the end of the algorithm. Then, where the last equation follows from the choice of  X  and  X  . This violates Corollary 5.

We are left with proving Lemma 4. To prove this lemma, we use a linear programming (LP) relaxation of the Max-Min problem (Figure 1). Here,  X  indexes the support of the distribution from which requests are drawn, p (  X  ) denotes the probability of any request in the input stream having type  X  , and w i (  X  ) is the fraction to which such a request is allocated to provider i  X  D . The first constraint asserts that the ex-pected revenue for any provider is at least c opt  X  T i and the second constraint requires that each request be assigned to exactly one provider (in the fractional version, the sum of the fractional assignments for a provider is exactly 1). Since the expected optimal value of the objective is c opt ,theoptimal solution is feasible for this LP. It is important to note that we are using this LP only for analysis; the algorithm cannot use this LP since is does not know the distribution from which the input is drawn. Moreover, this LP can be exponential in size! We will compare the expected decrease of poten-tial in our algorithm to that by a hypothetical (fractional) algorithm (we call it the LP-based algorithm) that exactly follows the assignment given by the optimal fractional solu-tion for the above LP. Since our algorithm maximizes the decrease in potential in any step, any lower bound on the expected decrease of potential for the LP-based algorithm is also a lower bound for our algorithm. We can show such a lower bound of (1  X  1 / X  )  X  ln n m  X   X , thereby proving Lemma 4. The details of the proof are deferred to the full version of the paper.
Recall that in the Max-Sum problem, the goal is to max-imize the revenue subject to budgets, and there are no tar-gets. The algorithm for the Max-Sum problem is due to Devanur and Hayes [4]; we give the algorithm for complete-ness. Consider the LP relaxation of the Max-Sum problem given in Figure 3(a). Here, x ij is the fraction of request j that is assigned to provider i . The dual of this LP is given in Figure 3(b).

The algorithm has the following steps: 1. For the first fraction of the input, the algorithm solves 2. For every subsequent request j , the algorithm assigns The next theorem is due to Devanur and Hayes [4].
Theorem 6. The competitive ratio of the above algorithm for the Max-Sum problem is 1  X  O ( ) .
Recall that the Hybrid problem is a generalization of the Max-Sum problem where a penalty of  X   X   X  i is charged for missing target T i by a margin of  X  i . Our algorithm for the Hybrid problem is a generalization of the Max-Sum algorithm in the previous section. Consider the LP relaxation of the Hybrid problem given in Figure 3(a). Here, x ij is the fraction of request j that is allocated to provider i ,and  X   X   X  i is the penalty paid for failing to meet the minimum threshold T i for provider i . The dual of this LP is given in Figure 3(b).

Before describing the algorithm formally, let us give an intuitive sketch. This algorithm explicitly uses the first fraction of the requests (call this the initial portion of the input) to learn the input distribution. However, the input distribution might have exponential support, and therefore a constant fraction is not sufficient for learning the distribu-tion per se . Instead, the algorithm uses the initial portion of the input to learn the optimal dual variables. Once the initial portion of the input has arrived, the algorithm feeds it into the dual program and solves it. The key observation is that even though the initial portion is not a good repre-sentative of the overall input distribution, the dual variables obtained are approximately equal to the expected value of the optimal dual. Once the dual variables have been de-termined, the algorithm uses these dual variables to make assignment choices using a principle known as complemen-tary slackness . This translates to the following rule: assign each request to the provider who has the highest bid for it, where the bids are discounted by a parameter dependent on the optimal dual variables.

Formally, the Hybrid algorithm has the following steps: 1. For the first fraction of the input, the algorithm solves 2. For every subsequent request j , the algorithm assigns Assumption. We will assume that opt is large ; in partic-ular, that Note that in practice, opt and j  X  Q (max i  X  D b ij ) are orders of magnitude larger than all the other terms in the above expression. Therefore, the assumption essentially states that the square of the maximum revenue should dominate the sum of maximum bids. This clearly holds in practice because one would expect the optimal revenue to be comparable to the sum of maximum bids even without squaring.
It will be convenient to introduce a new notation  X  defined as Then, the assumption on the value of opt becomes With this assumption, we will now prove the next theorem.
Theorem 7. The competitive ratio of the above algorithm for the Hybrid problem is 1  X  O ( ) .

Let us first establish the notation that we will use in the analysis. Let So, x ij ( z,w ) is the indicator for whether request j will be assigned to provider i by the algorithm, if the dual variables are z and w .Let S denote the first fraction of the requests, and let S c = { 1 ,...,m }\ S .
 For the other notations, we use the following generic rule. Let R denote unrestricted revenue (i.e. not capped at the budgets), P and X denote the values of the primal and dual objectives, and  X  denote the penalty in the primal objective (before scaling by the penalty coefficient  X  ). A subscript of i for any of these notations denotes the corresponding parame-ter for provider i  X  D , whereas if there is no subscript, then we mean the sum of the parameter values over all i  X  D . Further, these parameters are functions of ( z,w,S )where z,w are the values of the dual variables and S is the set of requests over which the parameter is computed. If S = Q , we will drop it from the list of arguments. As examples of this notation scheme, X ( z,w,S )=(1  X  z i + w i )
The first lemma states that the unrestricted revenue for any particular provider estimated from the initial portion of the input is an accurate estimate of the overall unrestricted revenue scaled by . This formalizes the intuition that we described earlier about the initial portion of the input pro-viding good estimates of cumulative parameters even though it cannot help estimate the input probability distribution it-self. The lemma is a direct consequence of Chernoff bounds (see, e.g., [18]).

Lemma 8. Suppose b ij  X  1 for all i  X  D,j  X  Q .Foreach i  X  D and any z,w,t i ,
Next, we aggregate the concentration bounds obtained from the above lemma and claim that the sum of deviation of the revenue estimates obtained from the initial portion of the input for all the providers is a small fraction of the overall optimal revenue. (Due to space constraints, we omit the proof of this lemma.)
Lemma 9. There exists a set of values t i , i  X  D ,such that and with probability at least 1  X  ,
Note that Lemma 9 essentially says that if all the budgets were  X  and if there were no targets, then our algorithm is nearly optimal. We will now show that this claim about the restricted revenue can be extended to the budgeted rev-enue in the presence of penalties imposed by targets. Our main technical claim is to show that complementary slack-ness conditions are approximately satisfied by z  X  ,w  X  .Let a = t i / . Note that by weak duality, if we can show that then it implies that Therefore, it is sufficient to show Eqn. (4).
 We consider the two cases w  X  i =0and w  X  i &gt; 0 separately. Let us outline the case of w  X  i = 0. Note that the complemen-tary slackness conditions hold for the LP when restricted to the impressions in S since we solved this LP exactly when setting the dual variables. Therefore,  X   X  i = 0. This obser-vation now leads to a bound on  X  i since  X  i only depends on the unrestricted revenue and we have already shown that the overall unrestricted revenue R i has small deviation from R ( S ) / . Next, we use this observation about penalties and the complementary slackness conditions to obtain an upper bound on the gap between the solution obtained by the LP and a feasible dual solution, thereby proving Eqn. (4). The details of this proof are deferred to the full version of the paper.
In this section, we set out to validate the effectiveness of our allocation algorithms. Specifically, we employ the algorithms in two settings, viz. , online ad allocations and online information markets. We will describe each setting in more detail next.
One of the most common applications of online alloca-tion algorithms is in sponsored search. In this application, we map the producers to the advertisers who are interested in advertising slots associated with user queries which are the requests . The queries arrive in an online manner and the advertisers are typically budget constrained and specify their valuations (bids) for a set of keywords via a campaign which is run for a specified duration. We call a selected advertiser for a given ad slot as an impressed ad. An ad-vertiser continues to participate in the allocation process for different keywords specified by her campaign so long as her budget is not exhausted. An advertiser X  X  target is realized if her ad is shown in response to as many user queries as possible subject to her budget constraint. In addition to the three algorithms described in the paper, we also consider a natural greedy algorithm that assigns an ad slot to the advertiser who bids the highest for it, subject to the restric-tion that the bids placed by advertisers who have already Figure 4: The effect of the scaling factor  X  on rev-enue in online ad allocation exhausted their budget are ignored. We report the follow-ing measures of effectiveness of all the four algorithms  X  total revenue generated by all the advertisers; the fractional target realization for an advertiser, i.e., the ratio of budget spent to the overall budget for an advertiser; winning rate of an advertiser, i.e., the impression-to-participation ratio of an advertiser; and, the coverage of advertisers, i.e., number of unique advertisers that won at least one impression. The first measure focuses on the central performance objective of the algorithms, i.e., revenue maximization, while the other two measures focus on the fairness aspect of the algorithms.
In this experiment, we sampled 5 , 000 , 000 queries and the corresponding bids from the logs for a single day of a com-mercial ad delivery engine, each of which had at least 10 participating advertisers. (Note that the relative order of the sampled queries was retained in the online order.) The relative budgets of advertisers is computed as their expected cost over all their bids. This value is obtained by summing the product of the bid and the clickthrough rate (probability of the ad being clicked) over all the queries. The real bud-get of an advertiser is now obtained by scaling the relative budget using a scaling factor  X  that we vary over our exper-iments. For every impressed ad, we reduce an advertiser X  X  remaining budget by her expected cost, i.e, the product of her bid and the clickthrough rate of her impressed ad. We ran the Max-Min , Max-Sum , Greedy ,and Hybrid algo-rithms considering all participating advertisers for a given query and report the above three measures of effectiveness. In the case of the Hybrid algorithm, we chose a penalty coefficient  X  = 30.

In the first experiment, we measured the effect of the bud-get size on the revenue and fairness of the resulting alloca-tion from each algorithm. Clearly, as the scaling factor  X  increases, the amount of budget left for any advertiser to participate in an auction decreases and therefore becomes a critical factor for the allocation algorithm to consider. In this experiment, we varied  X  from 1 to 30 and measured the total expected revenue resulting from the allocation. We set the target at 20% of the budget for each advertiser. Fig-ure 4 illustrates the revenue derived from each allocation for different values of  X  .

Forsmallervaluesof  X  when the corresponding budgets are large, the other algorithms earn more revenue than Max-Min since they optimize revenue. However, somewhat sur-prisingly, as the budget decreases, i.e., at larger values of  X  , these algorithms start to underperform w.r.t. Max-Min We suspect this is so because the Max-Min algorithm is more egalitarian in its initial allocations and therefore, uses Figure 5: The effect of the scaling factor  X  on fair-ness (fractional target coverage) in online ad alloca-tion up the budgets on the advertisers in a uniform manner. On the other hand, the allocations in the Greedy , Max-Sum and Hybrid algorithms result in significant skew in budget utilization of the advertisers and some of the adver-tisers X  budgets are never used up.

Next, we measured the fairness of the resulting allocations for the same values of  X  . Our metric for fairness is the average, over the lowest k %forsome k , of the fractional coverage of the advertisers. Figure 5 shows the results of this experiment, where k =1.

Finally we note that increasing the penalty beyond 30 does not have significant impact since a moderate value of  X  used above already ensures that either Hybrid does not miss targets or it is maximizing the allocation for a provider whoisbelowhertarget.

Even when the budgets are large, Max-Min does a bet-ter job of allocating the ad slots to more advertisers than Greedy , Hybrid and Max-Sum . Now, as the budgets de-crease, Max-Min does a significantly better allocation in terms of fairness compared to the other two algorithms. In fact, in this range, it does better than the other two algo-rithms for both fairness and revenue objectives. When we increase k , this effect becomes more pronounced. This is illustrated in Figures 6(a) and 6(b) where we range k from 1 to 10. We used two values of the scaling parameter of  X  =5 and  X  = 15 in this experiment.

Recall that the number reported in this figure is the av-erage of fractional target achieved over all the advertisers in the lowest k %. As we increase k , the average levels off toward the average for the entire set of advertisers. Ini-tially, the increase in the fairness of the allocation from Max-Min is more pronounced. On the other hand, the increase in the allocations from Greedy , Max-Sum and Hybrid are more gradual and only realize around 15% of the possible target for k = 10 for both values of  X  .This behavior suggests that Max-Min uniformly increases the allocations to all the advertisers, while the other algorithms have a skewed allocation at the end. To verify this observa-tion, we fixed the scaling factor to 15 (i.e., use small budgets) to verify whether Max-Min would push all the advertisers toward realizing their targets. We bucketed the advertis-ers based on fraction of their targets realized with bucket 1 corresponding to 10% of the realized target and bucket 10 corresponding to the target being realized. Table 1 shows the resulting histogram validating our hypothesis.
Finally, we measured other indicators of performance of each algorithm. Specifically, we measured the winning rate
Bucket Greedy Max-Min Max-Sum Hybrid Table 1: Distribution of advertisers in terms of frac-tional target coverage in online ad allocation (  X  =15 ) Figure 7: The winning rates of advertisers in online ad allocation (  X  =15 ) of the advertisers as the ratio of the number of impressions to the number of non-zero bids. Figure 7 highlights the per-formance of the algorithms with respect to the advertisers in the lowest k % (ordered by the winning rate). Even though the difference is very small, we did find a consistent trend of the Max-Min algorithm improving the winning rates of the advertisers and is consistent with the other performance indicators.
Another important and emerging paradigm of online mar-kets are information markets wherein data providers can sell raw data or services utilizing the data. Two large scale ex-amples are the Google Custom Search 1 and the Bing Search Service 2 announced by Microsoft on its Azure marketplace Other examples include http://www.globalfinancialdata. com and http://www.elasticpath.com/products . To vali-date our algorithms in this setting, we implemented a scaled down version of such a service using data from three prin-cipal sources used in a commercial Shopping service, viz. , the commerce queries to the service, the taxonomy of the products in the commerce index, and the product catalog. Specifically, we considered the top 20 categories in the ser-vice X  X  Shopping taxonomy ranked by popularity in the user queries. Let us denote them by C . We then considered all products restricted to these categories from the catalog. We considered a sample of commerce queries received by the shopping service in a single day of October 2012. Restrict-ing the queries in Q to those that are associated with the important categories in C yielded us a set of around 200,000 queries Q . These queries served as requests in our experi-ment. Next, we describe how we instantiate the providers .
We created 1000 indexes in the backend to service the product queries. We proceeded with the index creation as follows. We randomly allocated the products to different indices. Thus, each index served as a proxy for a provider and was associated with a subset of commerce categories along with a subset of products in each of the associated categories. As a measure of the quality of each provider, we used some well-known measures of economic relevance [23, 21] of the products for all the associated categories. Specifi-cally, we used the review count , average review score , number of merchant offers , price index ,andthe product differenti-ating index i.e., how differentiating are the set of products it contains. Note that these are query independent features and can readily be computed by any provider. Further the associated data is very succinct and can readily be stored and used at query time by our algorithms. Table 2 summa-rizes a subset of the resulting set of providers.
Unlike the previous experiment, there are no explicit tar-gets associated with each provider. Instead we use the cat-egory specific quality score of each provider as a proxy for the fraction of queries it expects to serve. Since there is no specific auction in this setting either, we measured only the fraction of achieved target for each provider. We note that while the above assumptions result in allocations that do not satisfy the theoretical guarantees of our algorithms, https://www.google.com/cse/ http://datamarket.azure.com/dataset/bing/search https://datamarket.azure.com Table 2: A view into the indexes supporting dif-ferent subsets of categories with different scores for online information markets Figure 8: The effect of the scaling factor  X  on rev-enue in online information markets they admit allocations that clearly distinguish the relative performance of each algorithm. Specifically, for every query q , we compute the score of an index I as where the P ( . | . ) denotes the conditional probability of the respective events. We associated a target for each index I to be the q  X  X  v r ( q,I ) scaled by a factor  X  which we vary in the experiments to control the targets appropriately. We varied  X  from1to30instepsof5.

Finally, we note that since the Greedy algorithm did not perform significantly different from the Max-Sum algorithm as observed in the case of online ad allocations, we do not re-port any results of this algorithm in this set of experiments.
In the first experiment, we measured the effect of  X  on both the revenue and fairness resulting from the allocations. Figure 8 illustrates the change in revenue as the targets are reduced. While the Max-Min algorithm very slightly un-derperforms the Max-Sum and Hybrid algorithms for larger targets (i.e., smaller values of  X  ), it begins to out-perform Max-Sum for smaller targets. One interesting ob-servation here is that Hybrid exhibits similar performance as
Max-Min unlike in the previous experiments involving online ads. Also, unlike the previous case, none of the alloca-tions result in indexes reaching their targets. This is because the bid-to-budget ratio is much smaller in this setting.
Continuing with the experiment, we measured the fair-ness, viz. , the average value of the fractional targets achieved in the lowest k % of indexes. Figure 9 shows that both the Max-Min and Hybrid algorithms substantially outper-form Max-Sum , particularly for smaller targets.

Next, we measured the fairness of the allocations as k is increased from the bottom 1% to 10%. This was to observe Figure 9: The effect of the scaling factor  X  on fair-ness (fractional target coverage) in online informa-tion markets Figure 10: Fractional target coverage for the lowest k % of indexes in online information markets how the allocations changes as one goes up in the order. We used two values of the scaling parameter  X  to cover both small and large targets. As Figures 10(a) and 10(b) show, the Max-Min algorithm does a better job of trying to equal-ize the fractional realized targets across all indexes compared to the Max-Sum and Hybrid algorithms. For larger tar-gets, both Max-Sum and Hybrid do not make any progress toward balancing the allocations even for higher values of k .
Finally, we measure the winning rate of selection of in-dexes to answer user queries. Figure 11 shows that the Max-Min algorithm produces allocations in which the lowest 1% of indexes get selected, on average, almost 8% of the time they qualify for answering the user query, while the corre-sponding numbers for both Max-Sum and Hybrid are next to zero even as the percentage of indexes included increases from the lowest 1% to lowest 10%. In the same range, the performance of Max-Min improves from 8% to nearly 13%. Figure 11: The average winning rate of the indexes in online information markets (  X  =15 )
In this paper, we formulated three generic online alloca-tion problems Max-Min , Max-Sum ,and Hybrid that aim at a combination of fairness and revenue optimization objec-tives. We gave algorithms for these problem that we proved analytically are nearly optimal in their respective objectives. We compared the algorithms on fairness and revenue met-rics on two large real-world data sets corresponding online ad allocation and online information markets, and concluded that revenue-maximizing algorithms are consistently outper-formed by fairness-aware algorithms on multiple fairness ob-jectives. Moreover, the fairness-aware algorithms generate revenue that is comparable to (in some input ranges, even greater than) the revenue-maximizing algorithms. These ob-servations offer compelling proof of the importance of incor-porating fairness objectives in online allocation algorithms. Acknowledgement. Part of this work was done when the second author was at Microsoft Research, Redmond. The second author is supported in part by startup funds from Duke University. [1] Shipra Agrawal, Zizhuo Wang, and Yinyu Ye. A [2] Sanjoy K. Baruah, N. K. Cohen, C. Greg Plaxton, and [3] Niv Buchbinder, Kamal Jain, and Joseph Naor. Online [4] Nikhil R. Devanur and Thomas P. Hayes. The [5] Nikhil R. Devanur, Kamal Jain, Balasubramanian [6] Jon Feldman, Monika Henzinger, Nitish Korula, [7] Ali Ghodsi, Matei Zaharia, Benjamin Hindman, Andy [8] Ali Ghodsi, Matei Zaharia, Benjamin Hindman, Andy [9] Ashish Goel, Adam Meyerson, and Serge A. Plotkin. [10] Gagan Goel and Aranyak Mehta. Online budgeted [11] Carlee Joe-Wong, Soumya Sen, Tian Lan, and Mung [12] Thomas Kesselheim, Klaus Radke, Andreas T  X  onnis, [13] Jon Kleinberg, Yuval Rabani, and Eva Tardos. [14] Aranyak Mehta. Online matching and ad allocation. [15] Aranyak Mehta and Vahab Mirrokni. Online ad [16] Aranyak Mehta, Amin Saberi, Umesh V. Vazirani, and [17] Marco Molinaro and R. Ravi. Geometry of online [18] Rajeev Motwani and Prabhakar Raghavan.
 [19] Noam Nisan, Jason Bayer, Deepak Chandra, Tal [20] Debmalya Panigrahi, Atish Das Sarma, Gagan [21] J. Rowley. Product search in e-shopping: a review and [22] Saswati Sarkar and Kumar N. Sivarajan. Fairness in [23] W. R. Smith. Product differentiation and market
