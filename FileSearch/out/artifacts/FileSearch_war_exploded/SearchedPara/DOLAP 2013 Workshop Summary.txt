 The ACM DOLAP workshop presents research on data ware-housing and On-Line Analytical Processing (OLAP). The DOLAP 2013 program has three interesting sessions on De-sign and Exploitation of Social Data Warehouses, ETL and modeling and new trends, as well as a keynote talk on OLAP query processing and a panel on OLAP and Data Warehous-ing Technology in Big Data era.
 H.4.2 [ Information Systems Applications ]: Types of Systems X  X ecision support; H.2.7 [ Database Management ]: Database Administration Management Data Warehousing; OLAP
Data warehousing technology use has been growing over time and it is now a practical need in every major local and global organizations. A data warehouse integrates heteroge-neous and autonomous data sources (traditional databases, semi structured databases, text, blogs, and so on) into a sin-gle large database to enable advanced querying, analysis and recommendation. On-Line Analytical Processing (OLAP) is the most common type of analysis performed in a data ware-house, represented by exploratory queries, cube aggregations and business analytics. Data mining complements OLAP to explain trends, justify findings and compute statistical mod-els. Relational database systems for data warehousing rep-resent a mature technology, but the current growth of data, the spectacular development of data generated from social networks and the need of integrating end users in the life word search on a window of recent records. This solution is supported by a data structure, storage is column-based, a coding table (called dictionary) and processing are done in RAM. The basic contribution is to defer updates on the aux-iliary data structure as a fixed size window is continuously sliding. Experiments with social network data are given.
Session 2 presents papers on ETL and Evolution of data warehouse schemes. Paper [14] tackles an important prob-lem of inconsistent dimensions, when they are not strict and/or covering. To do so, the authors propose a tech-nique for cleaning them based on the use of extended di-mensions that replace the hierarchical relation defined on pairs of elements with a new relation defined over pairs of sets of elements. This new extended dimension allows an-swering approximate queries. Paper [8] brings a new concept related to slowly changing measures that parallel the well-known concept of slowly changing dimensions introduced in the literature. The authors motivates their proposal by a representative set of examples. The advantages and disad-vantages of the proposed solutions are discussed. Paper [11] proposes to use Reo, a specification language for automata for the specification of extract-transform-load (ETL) pat-terns, instead of Business Process Execution Language or Business Process Model and Notation. The authors have illustrated their approach by modeling two common tasks that are: surrogate key pipeline process and history main-tenance of slowly changing dimensions. Paper [1] presents an approach supported by their own software to prototype OLAP solutions via agile methods in special scenarios where data sources do not exist yet. A case study from the EDEN project aiming at providing ICT-based solutions to assess the energetic performance of farms is given.

In Session 3, we present papers on new trends and non-traditional approaches. Paper [5] proposes a window-based incremental K-Means algorithm to calculate clustered ag-gregations on a streaming fact table, relaxing a traditional GROUP BY clause in SQL. The input stream is a fact ta-ble with binary dimensions and numeric measure attributes, where the goal is to cluster records based on their binary dimensions and not on on the measures. From the algo-rithmic side, the paper proposes optimizations for sliding windows, sparse distance computation and incremental suf-ficient statistics. From the systems side, the paper analyzes the integration of the proposed algorithms into a a DBMS via user-defined aggregate functions, which enable parallel processing, multithreading and stream processing. Paper [2] proposes basic OLAP cube optimizations in SQL queries for solid state drives (SSD) and shows they produce a decent performance gain over hard disk drives. This work stresses SSDs are a promising technology for cube processing be-cause cube queries tend to be read intensive. The paper evaluates the impact of proposed optimizations in cube ma-terialization and cube exploration on the TPC-H benchmark database. This work shows SSDs may substitute hard disks in the future as their capacity increases and their cost de-creases. In contrast to most alternative works, paper [12] is a position paper defending the idea that DBMSs can be ex-ploited for big data analytics on tasks that involve structured data. The paper provides a comprehensive overview of big data analytics including storage/indexing, parallel compu-tation, programming mechanisms and algorithmic optimiza-tions. The paper categorizes computations into two broad groups: statistical models and patterns, where patterns sub-
