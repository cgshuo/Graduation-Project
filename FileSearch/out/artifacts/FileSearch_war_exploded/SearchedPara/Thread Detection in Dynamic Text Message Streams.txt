 } Text message stream is a newly emerging type of Web data which is produced in enormous quantities with the popu-larity of Instant Messaging and Internet Relay Chat. It is beneficial for detecting the threads contained in the text stream for various applications, including information re-trieval, expert recognition and even crime prevention. De-spite its importance, not much research has been conducted so far on this problem due to the characteristics of the data in which the messages are usually very short and incomplete. In this paper, we present a stringent definition of the thread detection task and our preliminary solution to it. We pro-pose three variations of a single-pass clustering algorithm for exploiting the temporal information in the streams. An algorithm based on linguistic features is also put forward to exploit the discourse structure information. We conducted several experiments to compare our approaches with some existing algorithms on a real dataset. The results show that all three variations of the single-pass algorithm outperform the basic single-pass algorithm. Our proposed algorithm based on linguistic features improves the performance rel-atively by 69.5% and 9.7% when compared with the basic single-pass algorithm and the best variation algorithm in termsofF1respectively.
 H.4.m [ Information Systems Application ]: Miscellaneous; I.5.4 [ Pattern Recognition ]: Applications X  Text process-ing Algorithms, Experimentation Text Stream, Thread Detection, Single-Pass Clustering, Lin-guistic Features Copyright 2006 ACM 1-59593-369-7/06/0008 ... $ 5.00. Dynamic text message streams are rapidly growing on the Internet. These data are produced in an enormous quantity with the popularity of Instant Messaging (IM), Internet Re-layChat(IRC)andonlinechatrooms. Asreportedin[6], IM is widely used among enterprises and other organizations as well as in personal communications. The number of users worldwide now exceeds 200 million on the major free ser-vices. An example of the dynamic text stream is found in an online chatting group in an intranet forum between pro-fessors and students. In this forum, professors and students discuss the problems which are not considered in class and students can share with others what they have learned. A part of this kind of message stream is given in Figure 1. Figure 1: An example of the text message stream.

It is true that most of the message streams produced through IM or IRC are casual chitchat which are neither meant to be searched nor analyzed. However, there is a remarkable category of streams containing valuable knowl-edge. The above educational example is a good example. If we can find out what problems are most bewildering for students from the online discussions between professors and students, the professors can schedule their class material and time more appropriately. For another example, many open-source projects have channels for developer and user support. Having this valuable information archived and an-alyzed with good search facilities can make them work more effectively. However, as shown in Figure 1, the messages from different participants on different topics are heavily in-terwoven. It is not appropriate to treat a message stream as a whole. Moreover, most messages in the stream are too short to be meaningful by themselves, as a single message can not convey a relatively rounded topic without consid-ering the context information. Therefore, it is necessary to detect the threads in a stream such that each thread is about a specific topic.

Besides the above motivation, some other scenarios also push us to detect threads from message streams. While most participants in chat rooms are engaged in legitimate infor-mation exchange, chat rooms can also be used as a forum for discussions of dangerous activities, such as the abduc-tion of children. Therefore, we need to monitor online con-versations to aid crime detection or even crime prevention. However, we can not rely on people to monitor the conversa-tions actively for a prolonged time. Since it is prohibitively expensive and usually hard for a person to keep track of all the topics in the text streams where the topics are di-verse and the participants change frequently. In addition, a person could easily lose track of the multiple threads in the conversations when the size of the data is large. What is more, users are reluctant to chat when the conversation is being monitored due to privacy concerns.

To detect the threads, we need to consider the characteris-tics of the message stream carefully which are double edged swords. On the one hand, the structure of message streams is totally different from written discourse because message streams do not contain linear discussions of any single topic, but rather contains partially threaded and interwoven topics that oscillate in short, incomplete messages. Therefore, we can not rely on the tools for traditional text mining tasks, such as the Topic Detection and Tracking (TDT) [1]. On the other hand, a dynamic text stream provides some lin-guistic features which are not available in other kinds of text. For example, the pairs such as  X  X ould you help me on ... X ,  X  X es, I could  X  are valuable hints for organizing the messages into threads and finding out the topic of each thread. How to make maximal use of such knowledge for thread detection is an important issue.

In the past, little work has been proposed to address the thread detection problem. An exception is [9], where the authors identified thread starts based on some patterns pro-vided by experts. In this paper, we choose the single-pass clustering algorithm which is popular in TDT as the baseline and then propose three variations of the single-pass cluster-ing algorithm to take the temporal information into con-sideration. An algorithm based on the linguistic features for text message analysis is also put forward. We compare our proposed methods with the baseline on a dataset col-lected from online discussions among professors, teaching assistants and students. The experimental results show that by taking temporal information into consideration, the three variants of the single-pass clustering method can improve the performance significantly; by leveraging the linguistic features, further improvement is achieved.

In Section 2, we discuss the related work followed by the stringent problem definition in Section 3. The algorithms for detecting threads are shown in Section 4. Section 5 presents the experimental results on a real dataset together with the discussions of the results. We give the conclusion and future work in Section 6.
Our work is closely related to topic detection and track-ing which is a longstanding problem [1, 20, 11]. TDT re-search develops algorithms for discovering and threading together topically related material in streams of data such as newswire and broadcast news in both English and Man-darin Chinese. However, our work is different from them in several aspects: (1) the basic element in TDT is a story about a certain topic in news streams while in our work it is a relatively short message which consists of one or several sentences conveying certain information. In our problem, it is hard to determine the topic from one single message. However TDT assumes that the content of each story is rich enough to reflect a specific topic. (2) in our work, there may be more than one thread at the same time, and the text of different threads intersects with each other. (3) the temporal information in our work plays an important role in detecting the thread. For example, the two messages  X  X ould you help me on ... X ,  X  X es. I could X  would likely come to-gether in a thread, with the former appearing ahead of the latter and not being far from each other. (4) the text stream produced by IM or IRC is highly dynamic and interactive. Two messages in a thread can be connected with each other not only through the semantic information they convey but also by some linguistic features. Our work is also related to text segmentation [7]. Text segmentation aims to iden-tify the boundaries of topic changes in long text documents and/or document streams, while in our problem, we aim to find the threads from streams consisting of short messages.
Some other papers work on the same type of data [2, 4, 16, 9]. Most of them focus on detecting the latent topics contained in the data. In [2], the authors developed a text classification system named ChatTrack. ChatTrack creates a concept-based profile that represents a summary of the topics discussed in a chat room or by an individual partic-ipant. It archives the contents of chat room discussions in XML format. Subsets of this data can be classified upon request to create profiles of particular sessions or particu-lar users. The classifier is pre-trained on more than 1,500 concepts, and it can also be extended to include concepts of interest to a particular analyst. However, the topics in chat rooms are very divergent and it is impossible to provide a universal classifier for all possible topics. In [4], Elnahrawy evaluated the text classification techniques (Na  X   X ve Bayes, k-nearest neighbor, and support vector machine) to find suit-able methods of chat log classification for automated crime detection.

In [3], the authors adopted complexity pursuit for the topic identification problem in chat lines and news sources. This algorithm separates interesting components from a time series of data and identifies some underlying hidden topics in streaming data. In [8], a topographical visualization tool was put forward for a dynamically evolving text stream, based on the hidden Marko vmodel (HMM). The system is based on the exploitation of the a priori domain knowledge, that is, there are relatively homogeneous temporal segments in a data stream. This system can be seen as a comple-mentary tool for topic detection and tracking applications. However, the state number of HMM is required beforehand. Furthermore, it is hard to extend the tool to work in an on-line fashion without learning the parameters of HMM from training data.

Another related work is dialog summarization [18], which performs automatic transcription, tracking, retrieval, and summarization of meetings. The difference is that they do not assume there are many threads at the same time.
In [9], Khan et al. realizing the importance of identifying the threads, made a preliminary attempt. However, their approach relies on some positive and negative patterns pro-vided by experts, which limits its application.

We also want to mention another group of work on data which are similar to the text message streams we exploit [10, 19]. The data they studied are produced by Newsgroups, BBS (Bulletin Board System) or other forums. Although their data appear as a stream consisting of messages, they are organized explicitly into thread trees. The root of the thread tree is the first message posted by someone seeking an answer to his/her question or a message posted by some-one who wants to initialize a discussion regarding a specific topic. The thread tree then expands as other people reply to this message and continue the discussion. Xi et al. studied the ranking functions for Newsgroup search in [19]. Their approach is based on some metadata, such as prior knowl-edge about the author of the message or the depth of the message. In [10], Kim et al. worked on the topic segmen-tation of hierarchical messages in Web discussion boards. Each thread tree is segmented into coherent units to facili-tate indexing and retrieval. However, the structure of thread trees is not available in our problem. It is our objective to discover the structures of the message stream.

In [5], Hatzivassiloglou et al. investigated two linguisti-cally motivated text features (noun phrase heads and proper names) in the context of document clustering. Their experi-mental results showed that linguistic features could improve the clustering performance. Some other early work also ver-ified the effectiveness of linguistic features in the context of information retrieval [13, 14]. In this paper, we exploit two kinds of linguistic features different from the above men-tioned ones. These features are more suitable for analyzing the discourse structure information in our problem.
For convenience of discussion, we first clarify the defini-tions of two concepts in our problem.
 Message : A message is an utterance which consists of Thread : a thread is a series of messages which starts with Figure 2: An illustration of the goal of thread de-tection in dynamic text stream.
As we have discussed, the basic and important step for processing the text stream data is to find out how many topics are being discussed and what they are. The detection task can be classified into two categories: off-line detection and on-line detection. The former focuses on the detection of topics in an accumulated collection, and the latter strives to identify the threads from online conversations. In this paper, we work on the off-line detection which is easily evaluated. In fact, most of the algorithms can be applied to on-line detection. In the following, we define the problem more precisely.
 Thread Detection : We assume that each thread contains
We make some assumptions for the thread detection task in this paper. Firstly, we assume that the author of each message is unknown. In fact, in most text messages streams, such information is available. We omit it for the follow-ing reasons: (1) some users may change their names during conversation; (2) a user can participate in several different threads at the same. In both cases, information about the authors may give us false leads for thread detection. There-fore, in our work, we only focus on the textual and temporal information in the text streams. However, it may be inter-esting to detect the true identity of the authors with multi-ple aliases in Internet chat rooms. We leave it to our future work. Another assumption is that we have no clue about the number of threads in a text message stream. This as-sumption is reasonable since the text message streams are of variable length and there is no prior knowledge about them.
Thread detection is in fact the task of grouping the mes-sages in the text stream into different groups and each group represents a topic. We employ the single-pass clustering al-gorithm (incremental clustering) which is tested in TDT [20] as the baseline algorithm. To cater to the characteristics of text stream, we propose three variations of the single-pass clustering algorithm. We also put forward a new algorithm which is similar to the single-pass algorithm where we also employ linguistic features in it. In this paper, we do not adopt the well studied K-means algorithm, since the num-bers of threads vary radically among different streams and are hard to be estimated.
To represent the semantic information of messages and threads (clusters of messages) in our detection algorithms, we employ the conventional vector-space model which uses the bag-of-terms representation [12]. A message is repre-sented using a vector of terms (words or phrases), which are weighted using the term frequency (TF) and the Inverse Document Frequency (IDF) in this paper and are appropri-ately normalized. The normalized sum of all vectors corre-sponding to the messages in a thread is used to represent the thread. This representation is called a prototype or a cen-troid of the thread. We use the standard cosine similarity, i.e., the cosine value between vectors of objects (messages or threads) to measure their similarity.

We also introduce two kinds of linguistic features to re-flect the discourse structure information of messages. One is the Sentence Type used in messages and another is the Personal Pronouns . English has four main sentence types: Declarative Sentences (to state an idea), Interrogative Sen-tences (to form questions), Imperative Sentences (to request or demand), and Conditional Sentences (to describe the con-sequences of a specific action, or the dependency between events or conditions). As to the personal pronouns, gram-marians have divided them into three categories: the first person (such as I, me, my, we, our, and so on); the second person (suchasyouandyour)andthe third person (such as he, she, they, their, his, hers, him, her, and so on). In this paper, we only consider the category of personal pro-nouns of the subject. If the subject is noun, it is classified as third person. Note that it is nontrivial to identify the sentence type and the subject for a sentence. For simplic-ity, we employ some heuristically designed automatons. For example, an interrogative sentence usually starts with an in-terrogative word and ends by a question mark; the subject appears at the beginning in a declarative sentence. The in-tuition to introduce linguistic features is that the messages in a thread are the conversational utterances between partic-ipants and they are highly interactive. The sentence types and personal pronouns used in neighboring messages are not random, but follow some hidden rules. In this paper, we try to discover these rules and apply them for thread detection. For each message M, we will record the Sentence Types of the first and the last sentences in this message using M.STF, M.STL, together with the category of personal pronouns in them using the notations of M.PPF and M.PPL. STF and PPF refer to Sentence Type of the First sentence and Per-son Pronouns in the First sentence respectively. STL and PPL can be explained similarly. If there is only one sentence in M, then M.STF equals to M.STL and M.PPF equals to M.PPL, which represent the Sentence Type and the cate-gory of person pronouns in the single sentence respectively.
In this section, we present the algorithms for the thread detection task. We first introduce our baseline algorithm: a single-pass clustering algorithm. Then we present three variations of the single-pass clustering algorithm as well as a novel algorithm which utilizes the linguistic features.
Given a text stream in which the messages are sorted ac-cording to the occurring time, the basic idea of a single-pass clustering algorithm is as follows. First, take the first mes-sage from the stream and use it to form a thread. Next, for each of the remaining message, say M, compute its sim-ilarity with each existing thread. Let T be the thread that has the maximum similarity with M. If sim ( M, T )isgreater than a threshold t sim , which is to be determined empirically, then add M to T; otherwise, form a new thread based on M. Function sim ( M, T ) is defined to be the similarity between M and the cluster T. The single-pass clustering algorithm is efficient as it considers each message once. We can not detect the number of threads in advance, but it is at most N where N is the number of messages. Therefore the time complexity is O ( N  X  N ). We denote the single-pass clustering algorithm as SP B .
 In SP B , whenever a new message M is added to a thread T, the centroid of T is updated as the normalized vector sum of messages in T. That is, all messages in a thread contribute to the centroid of the thread equally, no matter when it is added. However, by intuition, in the dynamic text stream, old messages in a thread should play less important roles than new messages. In fact, we can adjust the performance of SP B in two directions. By adjusting the threshold t sim we can obtain clusters at different levels of granularity. By changing the method for calculating centroids of the threads and the form of sim ( M, T ), we can emphasize different fac-tors which will affect the similarity measurement. We made much effort to exploit the dynamic nature of the text stream and the temporal properties of messages including time win-dow and discounting strategy. These efforts are described in the following variations of SP B .
 In these variants, we exploit the temporal information. For simplicity, we use the messages X  relative positions along the message stream to reflect the temporal information, in-stead of using the absolute occurring time. Besides the fol-lowing three variants, we can define many others. However, these three are representative enough in that they involve different attempts to exploit the effectiveness of the tempo-ral information. 1. SP with Weighted Centroid ( SP WC ) 2. SP Using Nearest Neighbor ( SP NN ) 3. SP Using Weighted Nearest Neighbor ( SP WNN )
As discussed above, the relationships between linguistic features in neighboring messages in a thread are not ran-dom, but follow some hidden rules. One way to describe these rules is by conditional probability . For simplicity, we assume the dependence satisfies the Marko vchain prop-erty. That is, the likelihood of a feature in message M j is entirely determined by the proceeding message M i in the same thread. Further, we assume that the linguistic fea-tures used in the first sentence of message M j are entirely determined by the last sentence in the proceeding message M i . For example, in Figure 2, if T 22 ends with an interroga-tive sentence which raises a question, it is supposed that T will begin with a declarative sentence to answer the ques-tion. What we are interested in is the likelihood of two messages being neighboring messages in a thread given the linguistic features describing them, that is, the probability P ( T ( M i ,M j ) | M i .ST L, M j .ST F )and P ( T ( M i M j .PPF ). Given two messages M i and M j , we can define a Boolean function T ( M i ,M j ) as follows to represent the event where M i and M j are the neighboring messages in a thread: T ( M i ,M j )= The probability P ( T ( M i ,M j ) | M i .ST L, M j .ST F )and P ( T ( M i ,M j ) | M i .PPL, M j .PPF ) can be estimated based the Bayes Rule according to equation (5) and (6): where the parameters on the right side of equations (5) and (6) can be estimated using Maximal Likelihood (ML) di-rectly from the training data. To combine the two different kinds of linguistic features, we use a simple way of calculat-ing P ( T ( M i ,M j )) as follows:
P ( T ( M i ,M j ) | Linguistic F eatures of M i and M j ) = 1 2 ( P ( T ( M i ,M j ) | M i .ST L, M j .ST F ) + P ( T ( M i ,M j ) | M i .PPL, M j .PPF )) Based on P ( T ( M i ,M j ) | Linguistic F eatures of M i we now present the linguistic features-based Single Pass Al-gorithm ( SP LF ). SP LF is similar to SP NN and SP WNN except that the similarity between messages is not only de-pendent on the semantic similarity but also the linguistic features, as shown in equation (8). An intuitive explanation of equation (8) is that the similarity between messages measured in terms of semantic informa-tion is adjusted according to the linguistic features of these messages.
We have described the single-pass clustering algorithm for our problem, as well as three variations of it and a new al-gorithm based on linguistic features. In this section, we empirically compare these algorithms. We introduce the ex-perimental data set, our evaluation metrics and present the experimental results based on those metrics. The possible reasons for the different methods X  performances are also ex-plained.
The data set used in this paper consists of real text streams produced in online conversations among professors, teaching assistants and students in 16 different classes. The thread information is provided by the authors of the messages. For simplicity, we use the numbers 1 to 16 to represent the 16 text streams. The statistical information of the three largest and three smallest streams measured by the number of mes-sages is shown in Table 1 and Table 2. The average number of messages, threads and participants among the 16 streams are 102.8, 23.3 and 26.6 respectively.

For SP LF , we need the training data to estimate condi-tional likelihood parameters. Therefore a 3-fold cross val-idation procedure is applied in the experiments. That is, we randomly split the 16 streams into 3 folds (with one fold containing 6 streams and the other two containing 5 streams each) and at each time, we use two folds as training data and another fold as test data. Though all other thread de-tection algorithms do not need the training data, they are also tested on the same test data used by SP LF for compar-ison purposes.
The precision, recall and F measure are commonly used metrics in information retrieval to evaluate the retrieval re-sults [17]. They have been adapted to evaluate the perfor-mance of clustering [15]. Here, we explain these metrics in the context of the thread detection problem. For each de-tected thread, we calculate its precision and recall against each real thread. The F measure is defined by combining the precision and recall together. Specifically, for the detected thread j and the real thread i , the metrics can be calculated as follows: where n ij is the number of messages of the real thread i in the detected thread j , n i is the number of messages in the real thread i , n j is the number of messages in the detected thread j and F(i, j) is the F measure of the detected thread j and the real thread i .

The whole F measure of the detection result in a stream is defined as a weighted sum over all threads as follow: where the max is taken over all detected threads and n is the total number of messages. The results we report in the next section are in terms of the average F value among all the test streams.
We compared our proposed algorithm based on linguistic features and the 3 variations of the single-pass algorithm with the basic single-pass algorithm. The results are shown in the tables from Table 3 to Table 10. The results are ob-tained through three-fold cross validation procedure. The number in boldface is the highest F-value which can be achieved by the corresponding algorithm when tuning the parameters. In the next section, we give a detailed anal-ysis of the parameters tuning procedure and explain why different algorithms reach peak performance under different parameter settings.

Table 3: Performance of SP B when t sim changes
Table 4: Performance of SP WC when t sim changes
From the results shown in from Table 3 to Table 10, we can order the different algorithms based on the performance: SP LF &gt;SP NN &gt;SP WNN &gt;SP WC &gt;SP B . In the following part, we give an explanation for the performance differences among them.

It is easy to see that the 3 variations of the single-pass algorithm can achieve obvious improvement over the basic single-pass algorithm. This observation validates the effect of the temporal information. When taking the temporal information into consideration, the variations can remove the impact of the distant messages whose thread is not active any more. Then it is possible for them to assign the right thread label to the currently processed messages. Table 5: Performance of SP NN when the similarity threshold is fixed as 0.53 ( m means the window size) Table 6: Performance of SP NN when the window size is fixed at 7 Table 7: Performance of SP WNN when the similarity threshold is fixed at 0.42 ( m means the window size) Table 8: Performance of SP WNN when the window size is fixed at 30 Table 9: Performance of SP LF when the similarity threshold is fixed at 0.19 ( m means the window size) Table 10: Performance of SP LF when the window size is fixed at 8
SP NN increases the performance relatively by 41.3% in terms of F-value compared with SP WC . The reason for the improvement is explained as follows. There are two ma-jor differences between SP NN and SP WC . The first one is that SP NN only considers the messages within a win-dow with size m ; the second is that SP NN determines the thread of the target message based on each single message in each existing thread instead of the centroid of each thread. These differences both contribute to the better performance of SP NN . Due to the dynamic nature of a text stream, that is, some active topics may become inactive when the conversation moves, it is proper to neglect the impact of the old messages in the stream. Therefore, using a sliding window is better than the discounting strategy adopted by SP WC . To get the centroid of a cluster, we need to com-bine the messages belonging to the cluster. However, after mixing up the messages, it may become harder for us to distinguish two topics if they share some common words. Then, it is better to record all the messages in the exist-ing clusters and determine the similarity between the target message and a thread by computing the similarity between the target message and each distinct message in that thread, which is another reason for SP NN  X  X  better performance.
SP WNN is similar to SP NN except that the former dis-counts the similarity between the target message and the message in a window according to the distance between the two messages. In fact, in the text stream, one message might not always reply to its nearest neighbor. For example, in Figure 2, T 25 replies to T 22 instead of T 24 .Soifwediscount the similarity between T 25 and T 22 , the similarity may fall below the predefined threshold and they would not be clus-tered together which leads to an error. This explains why SP WNN is not as good as SP NN .

From Table 9 and Table 10 we can see that SP LF is the best one among the several algorithms including basic single-pass algorithm, and the three variations of basic single-pass algorithm. SP LF improves the performance relatively by 69.5% and 9.7% when compared with the basic single-pass algorithm and the best variation respectively. In fact, SP is modified on the basis of SP NN and it takes the advantage of SP NN as shown before. Besides that, SP LF takes the linguistic features into consideration. In fact, in the text stream generated by conversations, the linguistic features play an important role in connecting the messages within a thread. That is why SP LF outperforms SP NN .
The parameter for SP B and SP WC is the similarity thresh-old ( t sim ) which is easy to tune since the performance of the algorithms depends solely on it. However, for SP NN , SP WNN and SP LF , there are two parameters for each al-gorithm to tune at the same time. That is the size of the window ( m ) and the similarity threshold ( t sim ). It is hard to search over all the parameter space to reach the peak perfor-mance for each algorithm. So we adopt a greedy approach by tuning the two parameters alternatively and repeatedly until the performance converges. That is, we first fix m and then tune t sim to find out the best value of t sim . After that, we fix t sim as the best value we just obtained and tune m to get its best value. We repeat this process until the per-formance of the algorithm does not change any more. The tables from Table 5 to Table 10 show the last two steps for SP NN , SP WNN and SP LF respectively.

From the results shown in Table 5 to Table 10, we can observe that the best values of the window size and the sim-ilarity threshold for different algorithms are quite different. We illustrate the observation by the window size. The win-dow size means the reliable range within which we calculate the similarity between messages. If one message is out of the window, we can not rely on it to decide the thread of the target message even if the similarity between them is high. Therefore, it is reasonable that the best window size for SP WNN is much larger than that for SP NN since the for-mer is guaranteed by the discounting strategy. Since SP LF also takes a discounting strategy, based on linguistic fea-tures instead of the time distance, the best window size for it is larger than that for SP NN but not as large as that for
In this paper, we explored the issue of thread detection in dynamic text message streams, which is considered as a newly emerging kind of data on the Internet. After in-troducing the stringent definition of the task, we proposed three variations of the single-pass clustering algorithm and a novel algorithm based on linguistic features. The variations take the temporal information into consideration and im-prove the performance by at most 54.6% when compared with the basic single-pass algorithm. The linguistic fea-tures in this paper include Sentence Type and the Personal Pronouns used in messages. By modeling the relationship between neighboring messages in a thread in terms of de-pendent probability distribution of linguistic features in the messages, our proposed method outperforms the best vari-ation of the single-pass clustering algorithm by 9.7%.
Although we obtained promising results compared to the baseline through our proposed solutions, there is much room for improvement. Firstly, the linguistic features in this pa-per are relatively simple and the way to identify the features are heuristic. We need to find out more advanced linguistic features which can indicate the relationships between mes-sages more accurately. Secondly, we will try some other sophisticated approaches to combine different linguistic fea-tures. Thirdly, the way we utilize temporal information is straightforward which may limit the performance of some algorithms such as SP WC . We will try other approaches in the future. Fourthly, though we mentioned the importance of the end message in a thread, we did not study it explic-itly. We will design some specific methods for discovering it. Finally, to validate our proposed algorithms, we will test them on some much larger data sets in our future work. Dou Shen and Qiang Yang are supported by a grant from NEC (NECLC05/06.EG01). We thank the anonymous re-viewers for their useful comments. [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and [2] J. Bengel, S. Gauch, E. Mittur, and [3]E.Bingham,A.Kab  X  a n, and M. Girolami. Topic [4] E. Elnahrawy. Log-based chat room monitoring using [5] V. Hatzivassiloglou, L. Gravano, and A. Maganti. An [6] http://www3.gartner.com/3 consulting services/ [7] X. Ji and H. Zha. Domain-independent text [8] A. Kab  X  a n and M. A. Girolami. A dynamic [9]F.M.Khan,T.A.Fisher,L.Shuler,T.Wu,and [10] J. W. Kim, K. S. Candan, and M. E. D  X  onderler. Topic [11] G. Kumaran and J. Allan. Text classification and [12] G. Salton. Automatic text processing: the [13] G. Salton and M. Smith. On the application of [14] A. F. Smeaton. Progress in the application of natural [15] K. G. Steinbach, M. and V. Kumar. A comparison of [16] V. H. Tuulos and H. Tirri. Combining topic models [17] R. C. van. Information Retrieval . Butterworths, [18] A. Waibel, M. Bett, M. Finke, and R. Stiefelhagen. [19] W. Xi, J. Lind, and E. Brill. Learning effective [20] Y. Yang, T. Pierce, and J. Carbonell. A study of
