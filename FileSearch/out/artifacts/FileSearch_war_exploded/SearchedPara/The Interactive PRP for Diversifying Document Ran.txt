 The assumptions underlying the Probability Ranking Prin-ciple (PRP) have led to a number of alternative approaches that cater or compensate for the PRP X  X  limitations. In this poster we focus on the Interactive PRP (iPRP), which re-jects the assumption of independence between documents made by the PRP. Although the theoretical framework of the iPRP is appealing, no instantiation has been proposed and investigated. In this poster, we propose a possible in-stantiation of the principle, performing the first empirical comparison of the iPRP against the PRP. For document di-versification, our results show that the iPRP is significantly better than the PRP, and comparable to or better than other methods such as Modern Portfolio Theory.
 Categories and Subject Descriptors: H.3.3 [Informa-tion Storage and Retrieval] -Information Search and Re-trieval -Retrieval Models General Terms: Algorithms, Theory. The PRP has played a central role in the development of Information Retrieval (IR): in the context of ad-hoc retrieval the PRP has underpinned the development of most formal models. This is because, if a system upholds the PRP then its response is guaranteed theoretically to be optimal given the query. In practice, this principle has largely stood the test of time, but it relies on a number of key assumptions which have been called into question [3, 5, 6]. In particular, the PRP has been criticised because of the independence assumption , which assumes only document and query are sufficient to determine whether a document is relevant, ig-noring the influence of other documents in the ranking [3].
In non-traditional evaluation contexts such as subtopic retrieval, where dependencies between documents are con-sidered, a number of ranking principles and strategies alter-native to the PRP have been proposed. These include Max-imal Marginal Relevance (MMR) [1] and Modern Portfolio Theory (MPT) [5], along with the recently proposed Quan-tum PRP (qPRP) [6], as well as the untested iPRP [2]. The latter provides a theoretical framework for extending the PRP to the context of interactive IR. However, the iPRP has not been empirically tested or validated; so it is un- X  clear whether it performs better than other approaches, or not. In this poster, we compare the rankings that the iPRP would initially deliver to the user in the first pass of retrieval , against the rankings based on other approaches (and leave the interaction to future work).
In [2], Fuhr proposes a theoretical framework for extend-ing the PRP to the context of interactive IR. In this frame-work, the independence assumption is rejected since rele-vance is assumed to depend upon the documents the user has previously examined. Search is then modelled as situa-tion, called a list of choices, that are presented to the user. The user moves between situations by accepting one of the choices. Once a choice has been accepted, the retrieval sys-tem is required to produce a new list of choices depending upon the previous choice. The ranking principle strives to provide the optimum ordering of the choices presented in each situation, such that for each rank position i , documents under the iPRP are ranked as follows: where Q ( . ) is the probability 1 that the user does not revise their choice of selecting document d ; e is the effort of ex-amining document d ; g is the additional effort required for correction if the user judges a viewed document as irrelevant; and b d,i is the benefit of ranking document d if relevant.
The iPRP assumes that the user would examine each doc-ument in turn. Thus at each rank, the previous documents would influence the relevance of the subsequent documents. In order to obtain the ranking for the first pass of retrieval (i.e. before any actual user interaction has transpired), we can ignore the costs associated with the user or assume them constant. So both e and g are set to zero in the first pass. The probability Q ( . ) of a user not revising their choice can be treated as constant for all the documents, and thus it is dropped for rank equivalence reasons.

This leaves one final choice to be made about the benefit of ranking a document d at rank i . Since this is depen-dent upon the documents that have been previously ranked, then a reasonable approximation of the benefit would be to determine how dissimilar the considered document is to all previous documents. This can be achieved through a sum-mation over all previously ranked documents of a measure of dissimilarity or anti-correlation, i.e. we assume the possi-ble benefit comes from novel information. If document d is similar to the previous documents, then the correlation will be low, or negative, leading to a low total benefit. Similar documents are then demoted in the ranking, while docu-ments that are more diverse are promoted, giving rise to the following objective function: Under the iPRP dependencies between documents are incor-porated through multiplication, providing a completely dif-ferent approach to alternative strategies. In contrast, MPT, MMR and qPRP combine relevance with diversity in an ad-ditive fashion.
In this paper we conducted an empirical study in the con-text of subtopic retrieval, with the aim of comparing the iPRP with previously proposed principles and strategies. In particular, we compare the empirical effectiveness of iPRP against those of PRP, MMR, MPT, and qPRP. We refer to [1, 5, 6] for the formulation of these approaches.
For this study, we employed the TREC 6-8 Interactive subtopic collection and the TREC 18 on the Clueweb09 (part B) dataset. Rankings are evaluated using IA-P 2 , NRBP, and  X  -NDCG (with  X  = 0 . 5). All approaches were imple-mented using Lemur 3 . Each collection was indexed where common stop-words were removed and Porter stemmer was applied. For each alternative ranking approach, re-ranking of the top 4 100, 200, 500 and 1000 documents was per-formed. The Pearson X  X  correlation between pairs of docu-ments X  term vectors was used to estimate dependencies be-tween documents. Approaches were instantiated as follows. PRP. The PRP is implemented employing Okapi BM25 scoring schema, where the model X  X  parameters are set to standard values. Scores obtained by this method are used to generate the relevance estimates required by the other approaches, thus serving as baseline.
 MMR. We investigated the effect on retrieval performances of MMR X  X  parameter  X  , varying  X  in [0 , 1] with steps of 0 . 1. MPT. No variance is associated with the relevance scores of Okapi BM25, and thus we resort to treat variance as adjunc-tive parameter, setting a constant variance value amongst documents. We investigated the optimal value of the vari-ance  X  2 d in the range [10  X  10 , 10  X  1 ] and combine it with the value of the parameter b , ranging in [  X  10 , 10]. qPRP. The implementation of the qPRP does not require extensive parameter tuning procedures. Without a method to estimate complex probability amplitudes, we resort to an approximation of phases by using Pearson X  X  correlation be-tween the two documents X  term vectors, as suggested in [6].
Regarding parameters settings, here we present the per-formances of those runs that delivered the highest value of  X  -NDCG@10 over the whole topic set.
 Results. The results of our empirical investigation are re-ported in Table 1. The best value of  X  -NDCG@10 on the TREC 6-8 for MPT is obtained when  X  2 d  X  10  X  7 , regard-less of the value of b , and the obtained ranking is equivalent to that of PRP. This suggests that MPT X  X  ranking formula reduces to the PRP one, when parameters are tuned so as to optimise  X  -NDCG@10 on the whole set of query topics for this collection. This is not the case however for TREC 18. The best performing model depends on the collection employed. For example, iPRP delivers the most effective ranking, with respect to  X  -NDCG@10, on the TREC 6-8 subtopics collection, while MPT delivers the best on TREC 18. Further analysis and testing are required to determine whether the differences depend upon the types of docu-ments, needs, or number of subtopics.
In this poster, we have provided an initial attempt at in-stantiating the iPRP to provide the initial ranking of doc-uments. This was evaluated in the context of subtopic re-trieval. These findings suggest that the iPRP can be ef-fective; significantly outperforming the PRP and providing comparable or better performance over other diversity ap-proaches. While we have only considered one possible inter-pretation of the iPRP, further work will explore other pos-sible instantiations, and in particular what happens when there is interaction.
