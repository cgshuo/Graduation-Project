 Automatic website topic recognition hel ps to improve the accuracy and efficiency of specific resource discovery and application. One of the most difficult problems for recognition is how to represent websi te topic features. Vector space model (VSM) is an effective text-based feature description method. The similarity de-gree of page topics is judged through vector distances. Many factors are also considered into topic analysis of web page, such as anchor text[1], page title and keyword[2], feature selection[3], ontology[4], categorized model[5], etc. tions among pages are complicated as well.The analysis scale of website topic is completely different from web page. Ester et al.[6] summarize all pages within a site into one single feature vector based on VSM. Kriegel et al.[7] take topic frequency vector represent the number of pages about particular topic within the site. Moreover, the internal link str ucture of website is often viewed as a hiberarchy with tree or graph structure[6, 8, 9]. These methods require compli-cated statistics and computations. Facing the rapid growth of network size, the suitability remains to be improved.
 sites, our solution is to utilize hybrid vector space model (HVSM) representing websie topic feature. In this paper, we i ntroduce this model and briefly describe its relevant proof tests abo ut specific site recognition.
 2.1 Multi-feature Model for Topic Description The contents of same topic sites are similar in general, and the internal link structure also exist similarities obviously. Anchor texts of navigation toolbars or menus in homepages are indicative for the structure information. Different topic sites have respective structure feature t erms represented by anchor texts, some examples as shown below.  X  Manufacturing: profile, production, sale, after service, news, . . .  X  Media portal: news, entertainment, health, sports, economy, . . .  X  Government department: organization, policy, program, statistics, news, . . . We adopt hybrid vector space model to denote website topic feature. Its vector elements are composed of structure elements w i and content ones w j ,which are weighting values of structure feature term t i and content feature term t j respectively. T 1 represents a structure term set about anchor texts indicating link structure information; T 2 is a content term set about keywords representing text content. The topic feature term set is the union of two sets as T = T 1  X  T 2 . The feature terms are mapped to vector elements as  X  : T  X  V , and website topic feature can be den oted as a vector, that is Here n is the total dimension of vector space, i and j is the dimension of structure and content feature respectively.
 elements represent different semantic inf ormation and strengthen topic feature description. Traditional VSM can be regarded as simplified HVSM, namely vec-tor elements only include T 2 . 2.2 Weighting Selection The weight of structure elements w i is boolean function to reflect structure information. This approach is to let w i present 1 if feature term t i occurs in pages and 0 otherwise. Content element w j is assigned by TF-IDF weighting. The value of w i is 0 or 1 and its dimension is relatively small. To increase the analysis ability of w i ,we take normalization TF-IDF weighting the number of samples which contain t j , m is the total amount of samples. 2.3 Feature Selection The structure feature terms are mainly extracted from anchor texts in home-pages. Different expression habits cause the synonymous term phenomenon of same semantic links(e.g. X  aboutus  X  X nd  X  profile  X ), and that requires to be de-noted by exclusive terms. We have built a synonymous structure term library through sample statistics.
 formation method (MI). Statistic samples are constituted of topic samples and negative ones. This method firstly chooses a quantity of preliminary terms of specialized field from the Chinese thesaurus, and then computes mutual infor-mation values of samples in different classes .
 Here P ( t | C ) is occurrence probability of feature term t in class C , P ( t )is occurrence probability of t in all samples. All terms are ranked according to their mutual information. To select a subset of j feature terms, the j terms with highest MI values are chosen. 2.4 Object Page Search The principles of object page search include: (1) the page priority grade is spec-(2) The maximum search depth of URL is limited to 2 levels of website link hier-archy ; (3) the total size of pages downloaded are defined. These can guarantee the relevant degree between object page s and website topic, and alleviate the network load and processing capacity.
 is adopted. Anchor texts and sitemaps help to determine the search routes in-side sites. Moreover, the instance-base d library of search path is set up through statistical analysis of URL expression ways of certain amounts of sample sites. The heuristic search via different routes is used to access the sites. 2.5 Classification Algorithm Manufacturing site recognition can be typically regarded as the binary classifi-cation or filtering problem. The topics of non-manufacturing sites are compara-tively dispersed and very difficult for unified description. Actually topic analysis only considers manufacturing-related feature terms. The centroid-based classifi-cation algorithm is exploited[10].
 vector set { V 1 , ..., V m } , the arithmetic mean of this vector set is taken as the center vector V c that represents topic template set.
 To a new website with its feature vector V , the similarity degree between V and center vector V c is commonly measured using the cosine function, given by Whether the website topic is coincident with the required topic can be deter-mined by pre-defined similarity threshold. 3.1 Experiment Process To verify the recognition capability of HVSM, the recognition objects are defined as mechanical manufacturing sites. Firstly relevant pages are collected from spe-cific sites as training samples. The feature term library is set up through page parsing and selection. Meanwhile, the feature vectors of topic templates are built. The classifier trains repeatedly to decide the suitable categorized threshold value and the size of feature dimension. Secondly, Web spiders extract new URLs from website external links, traverse inside the site and gather pages. Finally the cor-responding feature vector is set up after parsing pages and matching feature terms, the site topic is judged through the classifier and predefined threshold. 3.2 Contrast Experiment We divide the data set into 1,000 training samples and 2,100 test ones. The former are used to build the feature term library and adjust the classification threshold during the training phase. The latter contains 1,460 manufacturing-topic samples, and the other non-topic ones include government sites, media sites and etc.
 separately. The topics of test samples are determined by classification threshold T i . The total feature dimension n is 50 and the structure dimension is 15. The indexes of classification performance are specified in[11]. Fig.1 and Fig.2 indicate the similarity distribution of test samples based on HVSM and VSM, and T i are 0.15 and 0.1 respectively. The X-axis in the illustrations stands for cosine similar values between test samples and the center vector of topic template. The HVSM-based average similar value of topic samples is approximately 0.3  X  0.4, while that of non-topic samples is approximately 0. 03  X  0.05. recall , precision , F for HVSM is 0.84, 0.93, 0.88 separatively. The average similar values between topic sites and contrast ones are obvious in order of magnitude. F measure of VSM declines 10.2% compared with HVS M. The recognition performance to non-topic samples is better under HVSM. 3.3 Website Recognition in Actual Internet To assess the adaptability of HVSM in real network, 50 URLs of manufacturing-topic sites are chosen as the initial URLs for web search. New sites are found from website external links and relevant pages are downloaded. Website topic analysis is according to HVSM and VSM s eparately. In case new one is judged as manufacturing topic, its external links inside are extracted as new URLs for web search. Meanwhile, every site is identified by manual judgment as objective criteria. Finally, we count approximately 5,000 samples. The contrast variation curves of F measure based on two models are shown as Fig.3. Table 1 is a group of HVSM-based statistics results along the search process 1 .
 HVSM achieves higher classification accuracy . The structure characteristics added in topic feature make for improving the r ecognition performan ce of specific sites. This paper presents a new exploratory research on domain-specific website recog-nition based on hybrid vector space model. Our main contribution is HVSM-based feature description combining structure and content feature through text information. This way of feature presentation is succinct and prominent. It avoids the complexity of link structure analysis. Meanwhile, its algorithm complexity and system expense are smaller. The experimental results indicate that this model and relevant techniques contribute to improve the accuracy of topic-specific website classification, and have broad application in domain-specific re-source discovery.
 route regular library. In addition, our current research is confined to manufact-uring-topic website recognition. Further researches need to be conducted about multi-class websites classification other than manufacturing sites .

