 A lot of redundant or low-quality information is intermixed with useful information on the web, which brings the major problem to the development of modern search engines. Henzinger (et al) suggested that it should be extremely helpful for web search engines which has been one of the search engines X  challenges at this time [7]. high-quality page more usually offers many useful links to other high-quality information by just one click. That is the main difference between a high-quality page regarding a certain topic is called  X  X opic distillation X  [4], which has been adopted as a major task in TREC Web Track for several years. Previous techniques [1][3][4][6] for the task were mostly carried out on the whole data collection, mainly to perform result analysis. Improvements were achieved but results might have been hurt due to the noise caused by low-quality documents. High-quality pages take up only a small proportion greatly improved. In this paper, a topic-independent method of high-quality page selection is proposed. The selection of high-quality pages could be considered as a dividing process, which partitions all documents into high-quality pages and common ones. This process has to be treated with independent of topics because high-quality pages selected are used to before retrieval. In this case, contents of documents should not be added in as features because it is topic-concerned. 
Previous research indicated that some non-content features could be used to carry high-quality pages and common ones gather together respectively. 
The remaining part of this paper is constructed as follows: Section 2 sets out non-content features. The method of high-quality page selection based on K-means selection and retrieval experiments, followed by discussions and conclusions. Statistical characteristics of non-content features, namely in-degree, document length, calculated, as shown in Fig. 1 below. 
It is difficult to get a good sample of pages [7], so estimation is made to obtain a statistics shown in Fig. 1 is composed of qrels of TREC11 X  X  topic distillation task, and we adopt .GOV corpus which includes about 19GB (document size) pages from .GOV domain as the common page set shown in Fig. 1. The .GOV corpus is a crawl of about 1,250,000 Web pages from .GOV domain. It is used in TREC web track task from TREC11 to TREC13. 
In Fig. 1, in-site out-link is defined as the out-link pointing to another page at the in-site out-link anchor text rate is defined as follows [12]: 
URL-types include ROOT, SUBROOT, PATH and FILE [8]. Different types are presented different values in the statistics as follows: ROOT=4, SUBROOT=3, PATH=2, FILE=1. The average type value of high-quality pages is 1.93, which tends to be a PATH value; though the value of common pages is 1.15, near to a FILE value. doing clustering which separates high-quality ones from common pages. The K-means clustering algorithm is a popular clusteri ng method that minimizes the clustering error [11] and is widely used in statistical analysis because of its simplicity and flexibility [13]. 
In order to perform K-means clustering, every page in the document set is represented with a five-dimension vector, each dimension of which indicates a feature discussed in the previous section. Vectors are divided by their variance as a normalization to avoid the influence brought by numerical differences of dimensions. 
K is set to 2 in our K-means clustering if we would like to get a high-quality page cluster and a common page cluster. A puzzled problem in the clustering is how to select conditions [5]. Statistical results in section 2 are utilized to help to select good mean vectors of two classes. Firstly, mean vector of the high-quality page set mentioned in section 2 is used as the initial mean vector of the high-quality cluster. Secondly, we get mean vector of the common page set mentioned in section 2 divided by a constant C (set to 2 in our experiments) as the initial mean vector of the common cluster. High-quality page selection experiments are introduced in this section. The K-means high-quality page set and a common page set, and metrics are brought to evaluate the result set. 4.1 Training and Testing Set section 3. They are all high-quality pages. 
The testing set and the training set share no pages in common. 4.2 Evaluation Metrics Traditional Recall metric can be presented to estimate how many high-quality pages the result set would cover. Recall can be calculated by: 4.3 High-Quality Page Selection Result Carry out high-quality page selection using K-means clustering. 
The result is laid out in Fig. 2 below, which shows the process of K-means clustering 16.7% of all pages covers nearly 70% of all testing high-quality pages. The clustering composed of 44.7% of all pages and covers 90% of all testing high-quality pages. This means that the clustering divides the whole document set into two page sets: one is the Horizontal axis: percentage of all pages in .GOV page set Vertical axis: coverage of testing set contains all useful pages in the whole set; the other is the common page set, which is mainly composed of useless pages. high-quality pages on a certain topic as its re trieval target. Retrieval results are shown in Table 1. All experiments are performed on our IR system named TMiner with BM2500 term weighting [2]. 
As shown in Table 1, high-quality page set, which contains only half of all pages and promotion of 72% in Precision@10, 45% in R-precision, compared with the whole set result. This is because the high-quality page set has excluded a lot of low-quality pages which are actually noises for topic distillation task. It is easier and more effective to do the task upon such a small and high-quality page set. 
Compared with TREC12 X  X  best result [4], the high-quality page set X  X  result has the same Precision@10 and higher R-precision. 
Results show that this topic-independent high-quality page selection gets rid of noises in a big page set, finds high-quality pages and obtains a smaller but better page set for information retrieve. Though K-means clustering is a converging process that costs a few hours to complete, it matters little since selection of high-quality pages is performed before retrieval topic-independently. This method improves both performance and efficiency of retrieval tasks. This paper introduces a topic-independent method of high-quality page selection using non-content features to improve performance and efficiency of web information retrieval. The selection of high-quality pages is considered as a clustering process in this paper, which divides all documents into high-quality pages and common ones. Non-content features are used to do the clustering, and K-means clustering algorithm is adopted. 
Following conclusions can be made: Firstly, non-content features are helpful for finding high-quality pages topic-independently. Second, K-means clustering process converges and brings to us a high-quality page set that contains only half of the whole generated high-quality page set has a big promotion in precision, compared with that on the whole collection of .GOV data in TREC12 web track. 
The success brings us more problems to think about, and more and deeper research can be done in the future: Are there any other non-content features that can be used to perform the clustering? Can supervised learning be brought in to help separate high-quality pages from common ones? How will the performance, efficiency and result become if supervised learning is utilized? 
