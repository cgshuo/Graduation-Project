 Matrix factorization models, as one of the most powerful Collabo-rative Filtering approaches, have greatly advanced the recommen-dation tasks. However, few of them are able to explicitly consid-er structured constraint for modeling user interests. To solve this problem, we propose a novel matrix factorization model with adap-tive graph regularization framework, which can automatically dis-cover latent user communities jointly with learning latent user rep-resentations, to enhance the discriminative power for recommenda-tion. Experiments on real-world datasets demonstrate the effective-ness of the proposed method.
 H.3.3 [ Information Search and Retrieval ]: Information filtering Algorithms, Design, Experimentation Collaborative Filtering, Structured Constraint, Recommendation
Recommender systems play an important role in our daily life, especially in this era of Big Data, which help users to find the infor-mation that they are rarely aware but really interested in. With the ability to make recommendations without clear content description-s of items, Collaborative Filtering (CF) algorithms have been wide-ly applied in various recommender systems. As one of the most powerful CF approaches, Matrix Factorization (MF) models have become popular and achieves the state-of-the-art performance [11]. However, MF approaches have also encountered some problems. Consider music recommendation as example. Different users may have different preferences on music genres, and they can be divided into different communities according to their interests. Therefore, Corresponding author c  X  an ideal recommendation system should take this structured prop-erty into consideration. To achieve this goal, most existing methods are mainly based on side information, such as social network and item content. In fact, a more fundamental solution is also need-ed. Recently, directly exploiting structured property for learning matrix factorization has gained much attention [10, 9]. Along this novel direction, we focus on how to incorporate structured prior into matrix factorization models for improving CF performance.
There are two main approaches for explicitly exploiting struc-tured property for recommendation tasks. The first one is from permutation view, based on graph partitioning theories. Typically, [10] first transforms a sparse rating matrix into a bordered block-diagonal structure, and then uses the extracted denser submatrices for rating prediction separately. However, it is a pipeline frame-work which is independent of specific matrix factorization models. Though it can be used as a black box efficiently, this transforming process may not incorporate task specific information. The sec-ond one is from feature selection view, based on the regularization techniques [4]. In this category, [9] considers multiple user inter-ests, and factorizes the rating matrices into latent factor spaces for each with group sparsity regularization. This approach assumes users X  interests are determined by different sets of factors, and then could use a subset of the latent factors. The limitation is that the subgroups need to be pre-partitioned. In fact, how to find a reason-able partition is also a problem, which might propagate errors by the inappropriate grouping, into subsequent learning process.
Different from the above approaches, in this paper, we seek to enhance the performance of matrix factorization models through proposing an adaptive graph regularization on latent users, which is learnt automatically from data. The motivation behind the idea is to improve the discriminative power of latent user representations. It is achieved by incorporating structured prior, such that the points within the same communities become more similar, and those with-in different communities become less similar, in the latent factor space. Therefore, the proposed method can take structured prop-erty into consideration jointly with the recommendation task ori-ented objective, and can benefit from community induced discrim-inative power with the ability of automatically grouping without pre-partition.
As shown in Definition 1, our goal is to predict the missing val-ues in R , by computing the predicted values r ij = u T i matrix factorization models also have a nice probabilistic interpre-tation with Gaussian noise [6], in this paper, we mainly focus on how to exploit structured constraint from algebra view.
 a sparse rating matrix R = [ r ij ] , where the observed r the rating of user i on item j , matrix factorization models aim to factorize R = UV T , where U and V are low rank matrices with rows as latent users u T i and latent items v T j respectively. To consider structured influence on modeling user preference, the most popular way is to incorporate side information, such as social network [5] and topic structure of item content [1]. This structured information has proven to be useful for building more accurate rec-ommendation models. For the above approaches, the underlying assumption is that additional auxiliary resources with high quality are available in advance besides user rating information. In con-trast, we consider a more fundamental case, only using rating ma-trix without side information. It could be easily extended to the scenarios of the above modeling approaches.
In this section, we introduce the recently proposed structured constraint [2], i.e., Laplacian constraint, to recommendation tasks, for explicitly capturing the latent user community structures while learning matrix factorization. The motivation could also be roughly explained from overlapping denoising perspective. As a toy exam-ple, a middle-school student buys a T-shirt and a pencil. A worker buys a T-shirt and a hammer. The hammer may be recommend-ed to the student due to the overlapping T-shirt. Such noisy over-lapping pattern often accounts for the fundamental reason why CF performance is highly sensitive to data in practice, which is sel-dom addressed explicitly in previous work. To consider this issue, we propose to constrain the overlapping patterns within different latent communities, as hidden structured constraint on global over-lapping patterns for CF. In the following, we first show the defini-tion of Laplacian matrix, and then present its connection with the structure of the affinity matrix.

D EFINITION 2 (L APLACIAN M ATIRX ). Consider an affinity matrix W  X  R n  X  n of n samples with weights W ( i,i 0 ) . The Lapla-cian matrix L W  X  R n  X  n is defined as: L W = D  X  W , where D = diag ( d 1 ,...,d n ) and d n =  X  i 0 W ( i,i 0 ) . The normalized The following well known theorem relates the rank of the Laplacian matrix to the number of blocks in W .

T HEOREM 1 ([7]). Let W be an affinity matrix. The multi-plicity k of the eigenvalue 0 of the corresponding Laplacian L equals the number of connected components (blocks) in W .
Based on the above theorem, we can enforce a general square matrix to be k-block-diagonal to represent different latent commu-nities. For the hidden graph constructed by latent users u construct an affinity matrix W ( j,j 0 ) using Gaussian kernel. Then we can define a set of k-block-diagonal matrix (k-BDMS) as the constraint term for optimization in Eq. (2), where k . k 2 2 denotes the ` 2 norm, and  X  2 denotes the deviation. Ide-ally, the degree of overlapping constraint is expected to be flexibly controlled, which is considered in the proposed framework.
To incorporate the structured constraint, the straightforward ap-plying Laplacian constraint on reconstructed rating matrix is not suitable, because this may violate the Nearly Isometric Proper-ty (NIP) as mentioned in [11] to undermine the performance. In addition, we expect to flexibly control the overlapping constrain-t. Therefore, we propose an adaptive hidden graph regularization framework, which is similar to [5], but our graph used for regular-ization is learnt automatically with block-diagonal prior, rather than a pre-defined one based on side information. We can automatically discover latent user communities jointly with learning latent user representations, to enhance the discriminative power. To achieve the goal, we have the following optimization objective: min where k X k F is the Frobenius norm. In Eq.(2), the first term ensures that latent users U and items V can well approximate the observed ratings, where c ij is a confidence parameter [8] for rating r b . If c ij is large, we trust r ij more, c ij = ond term in Eq. (2) is the graph regularization term, where c the confidence parameter for modeling w ii 0 = exp (  X  k u  X  W that measures the similarity between latent users. The simi-larity weight w ii 0 in hidden graph W is automatically learnt from data with Laplacian constraint, i.e., rank ( L W sys ) = n  X  k for pur-suing k -block-diagonal structure as discussed in Section 2.1. This constraint W  X  X  in Eq. (1) is imposed on the Laplacian matrix of latent users through Gaussian kernel. Thus it can be directly opti-mized jointly with latent user representations, and then can improve their discriminative power. The remaining terms are used to avoid over-fitting, the parameters  X  U ,  X  v and  X  S control the strength of each regularization term respectively. It is noted that the degree of overlapping constraint can not only be controlled by the parameter  X 
W but also the number of latent groups flexibly.
We employ an alternating optimization method to solve the prob-lem, by updating U , V , S , W iteratively and alternatingly.
The following update rules are obtained by setting the derivative of L with respect to u i , v j , and s k to zero. u where I is an identity matrix of the same dimension as that of latent space. S is a matrix with rows as social factor-specific latent feature vectors for the learnt hidden graph W . R i is a column vector with rating values [ r i 1 ,...,r iJ ] T . Similarly, R j = [ r For the hidden graph W , W i = [ w i 1 ,...,w iI N ] T [ w 1 i 0 ,...,w I N i 0 ] T , I N and J are the total number of users and items respectively. D c i is a diagonal matrix with values diag ( c ...,c iJ ) and D c j = diag ( c 1 j ,...,c I N j ) . D w i similarly defined with diagonal elements c w i,. and c w .,i tively. In addition, c w ii 0 is the confidence parameters for w high confidence value a is set to the learnt user relations within the same communities, and the low confidence value b is set to those within different communities, where a &gt; b &gt; 0 .
After learning U , V , S , we can obtain the hidden graph W ing Gaussian kernel as shown in Eq. (1). However, this variable matrix W 0 may move out of the hidden structured constraint set, and no longer guarantees a k-block-diagonal structure. Thus, we need to project it back to the k-BDMS constraint set. The projec-tion essentially finds a matrix W in K as defined in Eq. (1) which is closest to W 0 in terms of the Euclidean distance. The involved optimization problem can be explicitly written as follows via Aug-mented Lagrangian Multiplier (ALM) method: where J is the Lagrangian multiplier and  X  is an increasing weight parameter for the term of enforcing the auxiliary variable L
W sys . Thus the two constraints are decoupled and we can al-ternatively optimize W and  X  Z . The solution to Eq. (6) is similar to that in [2], and we omit it here due to limited space. The difference is that our W is constructed from latent user representations using Gaussian kernel, with normalized Laplacian constraint.
 Input: Number of latent factors k , a sparse rating matrix R , stan-Output: U , V , S , W . 1: while t &lt; T do 2: Update each u t i with Eq. (3); 3: Update each v t j with Eq. (4); 4: Update each s t i 0 with Eq. (5); 5: Update W t by solving the problem in (6); 6: t = t + 1 ; 7: end while 8: Return U , V , S , W ; The naive calculation of V T D c i V , S T D w i S , U U K is dimension of the latent space. Inspired by [3], e.g., we can rewrite V T D c i V = V T ( D c i  X  bI ) V + bV T V , where I is the corresponding identity matrix. Then we can pre-compute bV Since D c i  X  bI has only N user non-zeros where N user N this sparsity can significantly speed up computation [5].
The experiments were conducted on two public real-world dataset-s : LastFM and Delicious,with binary ratings, as shown in Table 1. Data available at http://grouplens.org/datasets/hetrec-2011/ Dataset #User #Item Sparsity #Ratings #Avg. R LastFM 1892 18745 0.28% 92834 49 Delicious 1867 69223 0.08% 104799 56 For easier comparison with previous proposed methods, we use Root Mean Square Error (RMSE) to measure the prediction accu-racy in this work. For N rating-prediction pairs, i.e., the predicted r
The experimental setting is as follows. Following [5, 9], we randomly select 90% of the data for training and the rest for test-ing. The random selection was carried out 5 times independently, and we report the average results. For all datasets, we set kernel  X  = 50 ; a = 1 , b = 0 . 01 in PMF and HGMF;  X  = 1 ,  X  = 0 . 1 ,  X  = 0 . 01 and K pre = 200 in GSMF-K. The max iteration num-ber is 200 , and the number of latent factors k = 200 . For two different datasets, LastFM :  X  V = 0 . 1 in PMF. b  X  = 0 . 005 in LMF.  X  U = 0 . 1 ,  X  V = 100 in GSMF and HGMF. Delicious :  X  U = 0 . 01 ,  X  V = 0 . 1 in PMF, GSMF and HGMF. b  X  = 0 . 0016 in LMF. The remaining parameters vary for our evaluation.
Table 2 shows that, on the extremely sparse dataset, Delicious, our method can achieve considerable improvement compared PM-F and other structured aware modeling approaches. This could be explained that in extremely sparse case, the common ratings for users are not sufficiently overlap such that the collaborative mod-eling fails due to the lack of co-occurrence pattern information. Therefore, considering structured property is important for mod-eling users, which can make the points within the same communi-ties more similar to distinguish dissimilar patterns. Although PMF-LMF, GSMF and GSMF-K take the structured property into con-sideration from different perspectives, the results of these methods still perform worse than our method. This could be explained that PMF-LMF is a pipeline approach which may not well extract sub-denser matrices without task objective, especially when original da-ta is not relatively dense enough. In contrast, our HGMF explores overlapping constraint in the more denser latent subspace. GSMF is limited to the pre-partitioned groups without adaptive grouping for task objective. Moreover, Figure 1 further validates the effec-tiveness of the proposed method in terms of Top-N performance.
The parameter  X  W is introduced to control the contribution from hidden graph regularization for CF. Therefore, we investigate how our algorithm HGMF is influenced by the graph weight parame-and Figure 2 show that in general, with the increase of  X  performance in different datasets shows similar patterns: first in-creasing, reaching its highest value and then decreasing, obviously for Delicious. In particular, for the extremely sparse dataset, De-licious, lower value suggests good performance. For other more denser datasets, relatively higher value will improve the evaluation results. It could be explained that in the extremely sparse case, each latent user may rely on more latent neighbours. Thus, if we restrict its group membership tightly, the performance will decrease. For denser case, the rating matrix may introduces more noisy patterns. Thus, the larger regularization will separate the latent user from the noisy relevant users in the different latent communities.
Different from traditional regularization approaches, our method can naturally bridge different latent spaces with different dimen-sions, within the proposed adaptive hidden graph regularization framework. Therefore, we further investigate how our algorithm #hidden group k 100 200 300 400 500 LastFM 0.5665 0.5565 0.5413 0.5395 0.5335 Delicious 0.8522 0.8474 0.8319 0.8205 0.8234 HGMF is influenced by the number of hidden groups ( k in Eq. (6)), i.e., the approximate dimension of the learnt hidden graph space. It is noted that the dimension of latent factor space is 200 . We vary Table 4 and Figure 3 show that fixing the optimal parameter  X  setting larger number of hidden groups will achieve better results in terms of RMSE and Recall. Empirically, we find this parameter is dependent on the parameter  X  W . Thus we can first fix this parame-ter and then change  X  W , or vise versa. Both cases can achieve the similar results. Intuitively, fixing  X  W , slightly enlarging the num-ber of hidden groups will narrow the range of visible neighbours. It will make the learnt latent user representation more discriminative.
In this paper, we proposed a novel solution to explicitly exploit-ing structured property for collaborative filtering, without relying on side information. It could be seen as a principled way of con-straining the potentially noisy overlapping patterns locally, while learning the global matrix factorization. This method benefits from the community induced discriminative power for recommendation, jointly with the ability of automatically grouping without preparti-tion. Experiments on two real-world datasets exhibit the promising performance, compared with some state-of-the-art methods.
