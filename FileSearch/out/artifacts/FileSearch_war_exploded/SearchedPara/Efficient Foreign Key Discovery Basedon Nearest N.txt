 Schema is the basis to comprehend a database, which is of great significance in data modeling, query optimization, schema matching and indexing, etc. Pri-mary/foreign key relationships play an important role in the schema of relational database. However, many reasons will lead to incompletion of foreign key con-straints in a database. For example, the database lacks support for checking foreign key constraints, the designers ignore to check foreign keys on purpose for performance consideration, or some relationships are not known to design-ers but are inherent in the data. All these reasons are quite frequent met in databases. The absence of foreign keys will lead to poor data quality and thus influence data analysis. When it happens in a database, which contains hundreds of tables, thousands of attributes, countless tuples and lacks of documentation in addition, it is extremely difficult to identify the foreign keys even for an expert. work focuses on detecting INclusion Dependencies(INDs) [ 1 ][ 3 ]. An IND A  X  B demands tuples in attribute A should appear in attribute B. Obviously, it is not sufficient to identify foreign keys. In light of this, some researchers try to Figure 1 shows an overview of our algorithm. Similar to previous work, we Since the choice of features has significant influence on the achievable perfor- X  Distinct Tuples(DT): The number of distinct tuple in an attribute. For-eign key values often cover a wide range of primary key values.  X  Attribute Name(N): This feature is used to measure the distance of two attribute names, which reflect the similarity of names.  X  Average(A): The average of all distinct tuples for a numerical attribute.
The averages of a foreign key and its primary key are often very close.  X  Variance(V): The variance of all distinct tuples for a numerical attribute.
The variances are often close between a foreign key and its primary key.  X  Average Length(AL): The average length of all tuples for a sting attribute. The average lengths should be similar when the values of a foreign key form a non-bias sample of the primary key.
  X  Median(M): The median tuple of all distinct tuples for an attribute. The the value similarity is considered during IND detection. All these features should be normalized and then we use l 2 to measure two attributes X  distance: where DT P ,N P ,A P ,V P ,AL P ,M P ; DT F ,N F ,A F ,V F ,AL F ,M F are the features of attribute P and F. We compute all distances of each IND pair. There is a big jump between foreign keys and other INDs for foreign key and primary key have underlying sematic relationship. Our algorithm can detect this big jump point automatically and unitize it as threshold to separate foreign keys from INDs. We evaluate our algorithm on two benchmark synthetic databases(TPC-E and TPC-H), a sample database of MySQL(sakila), as well as an information man-agement system database(EMIS). The characteristics of them are shown in table 1 , where T is the number of non-empty tables, Avg(C) and Max(C) are the average and maximum number of columns per table, Avg(R) and Max(R) are the average and maximum number of rows per table, SC and MC are numbers of single column and multi-column foreign keys.
 Intel Core i7-2600 3.40GHz with 8GB RAM running SQL Server 2008. We eval-uate Precision, Recall and F-measure. The schemas of the databases are the ground truth. Table 2 shows our algorithm X  X  effectiveness for different data sets, where  X  X P NO. X  means the big jump point. It is easy to see our algorithm can obtain a good precision and recall.
 as shown in table 3 . The effectiveness of the two method is close. However, we avoid high complexity attribute distance computation.
 1MB, 10MB, 100MB, 1GB and 10GB. The running times for each of two phases and the total time are shown in figure 2 . Phase 1 stands for IND detection,
