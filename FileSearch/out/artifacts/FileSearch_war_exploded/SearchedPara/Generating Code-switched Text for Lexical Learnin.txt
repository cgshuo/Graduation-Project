 Today, an adult trying to learn a new language is likely to embrace an age-old and widely accepted practice of learning vocabulary through curated word lists and rote memorization. Yet, it is not uncommon to find yourself surrounded by speak-ers of a foreign language and instinctively pick up words and phrases without ever seeing the defini-tion in your native tongue. Hearing  X  X ass le sale please X  at the dinner table from your in-laws vis-iting from abroad, is unlikely to make you think twice about passing the salt. Humans are extraor-dinarily good at inferring meaning from context, whether this context is your physical surround-ing, or the surrounding text in the paragraph of the word that you don X  X  yet understand.

Recently, a novel method of L2 language teach-ing had been shown effective in improving adult nique relies on a phenomenon that elicits a nat-ural simulation of L1-like vocabulary learning in adults  X  significantly closer to L1 learning for L2 learners than any model studied previously. By in-fusing foreign words into text in the learner X  X  na-tive tongue into low-surprisal contexts, the lexi-cal acquisition process is facilitated naturally and non-obtrusively. Incidentally, this phenomenon occurs  X  X n the wild X  and is termed code-switching or code-mixing , and refers to the linguistic pattern of bilingual speakers swapping words and phrases between two languages during speech. While this phenomenon had received significant attention from both a socio-linguistic (Milroy and Muysken, 1995) and theoretical linguistic perspectives (Be-lazi et al., 1994; Bhatt, 1997) (including some computational studies), only recently has it been hypothesizes that  X  X ode-switching X  is a marking of bilingual proficiency, rather than deficiency (Genesee, 2001).

Until recently it was widely believed that inci-dental lexical acquisition through reading can only occur for words that occur at sufficient density in a single text, so as to elicit the  X  X oticing X  ef-fect needed for lexical acquisition to occur (Cobb, 2007). Recent neurophysiological findings, how-ever, indicate that even a single incidental expo-sure to a novel word in a sufficiently constrained context is sufficient to trigger an early integra-tion of the word in the brain X  X  semantic network (Borovsky et al., 2012).

An approach explored in this paper, and moti-vated by the above findings, exploits  X  X onstrain-ing X  contexts in text to introduce novel words. A state-of-the-art approach for generating such text is based on an expert annotator whose job is to decide which words to  X  X witch out X  with novel foreign words (from hereon we will refer to the  X  X witched out X  word as the source word and to the  X  X witched in X  word as the target word). Conse-quently the process is labor-intensive and leads to a  X  X ne size fits all solution X  that is insensitive to the learner X  X  skill level or vocabulary proficiency. This limitation is also cited in literature as a sig-nificant roadblock to the widespread adaptation of graded reading series (Hill, 2008). A reading-based tool that follows the same principle, i.e. by systematic exposure of a learner to an incremen-tally more challenging text, will result in more ef-fective learning (Lantolf and Appel, 1994).
To address the above limitation, we develop an approach for automatically generating such  X  X ode-switched X  text with an explicit goal of maximizing the lexical acquisition rate in adults. Our method is based on a global optimization approach that incorporates a  X  X nowledge model X  of a user with the content of the text, to generate a sequence of lexical  X  X witches X . To facilitate the selection of  X  X witch points X , we learn a discriminative model for predicting switch point locations on a corpus that we collect for this purpose (and release to the community). Below is a high-level outline of this paper.  X  We formalize our approach within a prob- X  We compare this global method to sev- X  We analyze the operating range in which Our proposed approach to the computational gen-eration of code-switched text, for the purpose of L2 pedagogy, is influenced by a number of fields that studied aspects of this phenomenon from dis-tinct perspectives. In this section, we briefly de-scribe a motivation from the areas of socio-and psycho-linguistics and language pedagogy re-search that indicate the promise of this approach. 2.1 Code-switching as a natural phenomenon Code-switching (or code-mixing) is a widely stud-ied phenomenon that received significant attention over the course of the last three decades, across the disciplines of sociolinguistics, theoretical and psycholinguistics and even literary and cultural studies (predominantly in the domain of Spanish-English code-switching) (Lipski, 2005).

Code-switching that occurs naturally in bilin-gual populations, and especially in children, has for a long time been considered a marking of incompetency in the second language. A more recent view on this phenomenon, however, sug-gests that due to the underlying syntactic com-plexity of code-switching, code-switching is ac-tually a marking of bilingual fluency (Genesee, 2001). More recently, the idea of employing code-switching in the classroom, in a form of conversation-based exercises, has attracted the attention of multiple researchers and educators (Moodley, 2010; Macaro, 2005), yielding promis-ing results in an elementary school study in South-Africa. 2.2 Computational Approaches to Additionally, there has been a limited number of studies of the computational approaches to code-switching, and in particular code-switched text generation. Solorio and Liu (2008), record and transcribe a corpus of Spanish-English code-mixed conversation to train a generative model (Naive Bayes) for the task of predicting code-switch points in conversation. Additionally they test their trained model in its ability to generate code-switched text with convincing results. Build-ing on their work, (Adel et al., 2012) employ ad-ditional features and a recurrent network language model for modeling code-switching in conversa-tional speech. Adel and collegues (2011) propose a statistical machine translation-based approach for generating code-switched text. We note, how-ever, that the primary goal of these methods is in the faithful modeling of the natural phenomenon of code-switching in bilingual populations, and not as a tool for language teaching. While useful in generating coherent, syntactically constrained code-switched texts in its own right, none of these methods explicitly consider code-switching as a vehicle for teaching language, and thus do not take on an optimization-based view with an ob-jective of improving lexical acquisition through the reading of the generated text. More recently, and concurrently with our work, Google X  X  Lan-guage Immersion app employs the principle of code-switching for language pedagogy, by gener-ating code-switched web content, and allowing its users to tune it to their skill level. It does not, how-ever, seem to model the user explicitly, nor is it clear if it performs any optimization in generating the text, as no studies have been published to date. 2.3 Computational Approaches to Sentence Although not explicitly for teaching language, computational approaches that facilitate accessi-bility to texts that might otherwise be too difficult for its readers, either due to physical or learning disabilities, or language barriers, are relevant. In the recent work of (Kauchak, 2013), for example demonstrates an approach to increasing readability of texts by learning from unsimplified texts. Ap-proaches in this area span methods for simplify-ing lexis (Yatskar et al., 2010; Biran et al., 2011), syntax (Siddharthan, 2006; Siddharthan et al., 2004), discourse properties (Hutchinson, 2005), and making technical terminology more accessible to non-experts (Elhadad and Sutaria, 2007). While the resulting texts are of great potential aid to lan-guage learners and may implicitly improve upon a reader X  X  language proficiency, they do not explic-itly attempt to promote learning as an objective in generating the simplified text. 2.4 Recent Neurophysiological findings Evidence for the potential effectiveness of code-switching for language acquisition, stem from the recent findings of (Borovsky et al., 2012), who have shown that even a single exposure to a novel word in a constrained context, results in the inte-gration of the word within your existing semantic base, as indicated by a change in the N400 elec-trophysiological response recorded from the sub-jects X  scalps. N400 ERP marker has been found to correlate with the semantic  X  X xpectedness X  of a word (Kutas and Hillyard, 1984), and is believed to be an early indicator of word learning. Further-more, recent work of (Frank et al., 2013), show that word surprisal predicts N400, providing con-crete motivation for artificial manipulation of text to explicitly elicit word learning through natural reading, directly motivating our approach. Prior to the above findings, it was widely believed that for evoking  X  X ncidental X  word learning through read-ing alone, the word must appear with sufficiently high frequency within the text, such as to elicit the  X  X oticing X  effect  X  a prerequisite to lexical acqui-sition (Schmidt and Schmidt, 1995; Cobb, 2007). 3.1 Overview The formulation of our model is primarily moti-vated by two hypotheses that have been validated experimentally in the cognitive science literature. We re-state these hypotheses in the language of  X  X urprisal X : 1. Inserting a target word into a low surprisal 2. Multiple exposures to the word in low sur-
Hypothesis 1 is supported by evidence from (Borovsky et al., 2012; Frank et al., 2013), and hy-pothesis 2 is supported by evidence from (Schmidt and Schmidt, 1995). We adopt the term  X  X ow-surprisal X  context to identify contexts (e.g. n-grams) that are highly predictive of the target word (e.g. trailing word in the n-gram). The motiva-tion stems from the recent evidence (Frank et al., 2013) that low-surprisal contexts affect the N400 response and thus correlate with word acquisi-tion. To realize a  X  X ode-switched X  mixture that adheres maximally to the above postulates, it is self-evident that a non-trivial optimization prob-lem must be solved. For example, naively select-ing a few words that appear in low-surprisal con-texts may facilitate their acquisition, but at the ex-pense of other words within the same context that may appear in a larger number of low-surprisal contexts further in the text.

To address this problem, we approach it with a formulation of a factor graph that takes global structure of the text into account. Factor graph for-malism allows us to capture local features of indi-vidual contexts, such as lexical and syntactic sur-prisal, while inducing dependencies between con-sequent  X  X witching decisions X  in the text. Max-imizing likelihood of the joint probability under the factorization of this graph yields an optimal sequence of these  X  X witching decisions X  in the en-tirety of the text. Maximizing joint likelihood, as we will show in the next section, is a surrogate to maximizing the probability of the learner acquir-ing novel words through the process of reading the generated text. 3.2 Language Learner Model A simplified model of the learner, that we shall term a Probabilistic Learner Model (PLM) serves as a basis for our approach. PLM is a model of a learner X  X  lexical knowledge at any given time. PLM models the learner as a vector of indepen-dent Bernoulli distributions, where each compo-nent represents a probability of the learner know-ing the corresponding word. We motivate a proba-bilistic approach by taking the perspective of mea-suring our belief in the learner X  X  knowledge of any given word, rather than the learner X  X  uncertainty in own knowledge. Formally, we can fully specify this model for learner i as follows: where V is the vocabulary set  X  identical across all users, and  X  i j is our degree of belief in the learner i  X  X  knowledge of a target word w j  X  V . Statistical estimation techniques exist for estimat-ing an individual X  X  vocabulary size, such as (Bhat and Sproat, 2009; Beglar, 2010), and can be di-rectly employed for estimating the parameters of this model as our prior belief about user i  X  X  knowl-edge.

The primary motivation behind a probabilistic user model, is to provide a mechanism for up-dating these probabilities as the user progresses through her reading. Maximizing the parameters of the PLM under a given finite span of code-switched text, thus, provides a handle for generat-ing optimal code-switched content. Additionally, a probabilistic approach allows for a natural inte-gration of the user model with the uncertainty in other components of the system, such as uncer-tainty in determining the degree of constraint im-posed by the context, and in bitext alignment. 3.3 Model overview At the high level, as illustrated in Figure 1, our ap-proach integrates the model of the learner (PLM) with the local contextual features to update the PLM parameters incrementally as the learner pro-gresses through the text. The fundamental as-sumption behind our approach is that the learner X  X  knowledge of a given word after observing it in a sentence is a function of 1) the learner X  X  previ-ous knowledge of the word, prior to observing it in a given sentence and 2) a degree of constraint that a given context imposes on the meaning of the novel word, and is directly related to the surprisal of novel word in that context. Broadly, as the learner progresses from one sentence to the next, exposing herself to more novel words, the updated parameters of the language model in turn guide the selection of new  X  X witch-points X  for replac-ing source words with the target foreign words. In practice, however, this process is carried out im-plicitly and off-line by optimizing the estimated progress of the learner X  X  PLM, without dynamic feedback. Next, we describe the model in detail. 3.4 Switching Factor Graph Model To aid in the specification of the factor graph struc-ture, we introduce new terminology. Because the PLM is updated progressively, we will refer to the parameters of the PLM for a given word w i after observing its k th appearance (instance) in the text, as the learner X  X  state of knowledge of that word, P ( z i k = 1) =
Without explicit testing of the user, this variable is hidden. We can view the prior learning model as the parameters of the vector of random variables
The key to our approach is in how the param-eters of these hidden variables are updated from repeated exposures to words in various contexts. a context (this may be an n-gram, an entire sen-tence or paragraph containing w i , but we will re-strict our attention to fixed-length n-grams). In-depend on how  X  X onstrained X  the meaning of w i is in the given context. We will refer to it as the  X  X earnability X , denoted by L k i , of word w i on its will define  X  X earnability X  as follows: prise the context window of w i , not including w i , words in w \ i . P ( constrained ( w i ) = 1 | w ) is a real value (scaled between 0 and 1) that represents the degree of constraint imposed on the meaning of word w i by its context. This value comes from a binary prediction model trained to predict the  X  X redictability X  of a word in its context, and is based on the dataset that we collected (described later in the paper). Generally, this value may come directly from the surprisal quantity given by a language model, or may incorporate additional features that are found informative in predicting the constraint on the word. Finally, the quantity is weighted by the parameters of the state vari-ables corresponding to the words other than w i contained in the context. This encodes an intu-ition that a degree of predictability of a given word given its context is related to the learner X  X  knowl-edge of the other words in that context. If, for ex-ample, in the sentence  X  X ass me the salt and pep-per, please X , both  X  X alt X  and  X  X epper X  are substi-tuted with their foreign translations that the learner is unlikely to know, it X  X  equally unlikely that she will learn them after being exposed to this con-text, as the context itself will not offer sufficient information for both words to be inferred simulta-neously. On the other hand, substituting  X  X alt X  and  X  X epper X  individually, is likely to make it much easier to infer the meaning of the other. Figure 2: A noisy-OR combination of the learner X  X  the word X  X   X  X earnability X  in the observed context
A noisy-OR-based CPD provides a convenient and tractable approximation in capturing the in-tended intuition: updated state of knowledge of a given word will increase if the word is observed in a  X  X ood X  context, or if the learner already knows the word.

Combining Equation 2 for each word in the con-text using the noisy-OR, the updated state for word w cause of the dependence of each z in the context on all other hidden variables in that context, we can capture the dependence using a single factor per context, with all of the z variables taking part in a clique, whose dimension is the size of the con-text.

We will now introduce a dual interpretation of the z variables: as  X  X witching X  variables that de-cide whether a given word will be replaced with its translation in the foreign language. If, for exam-ple, all of the words have high probability of be-ing known by a learner, than maximizing the joint likelihood of the model will result in most of the words  X  X witched-out X   X  a desired result. For an arbitrary prior PLM and the input text, maximiz-ing joint likelihood will result in the selection of  X  X witched-out X  words that have the highest final probability of being  X  X nown X  by the learner. 3.5 Inference The problem of selecting  X  X witch-points X  reduces to the problem of inference in the resulting factor graph. Unfortunately, without a fairly strong con-straint on the collocation of switched words, the resulting graph will contain loops, requiring tech-niques of approximate inference. To find the opti-mal settings of the z variables, we apply the loopy max-sum algorithm. While variants of loopy be-lief propagation, in general, are not guaranteed to converge, we found that the convergence does in-deed occur in our experiments. 3.6 Predicting  X  X redictable X  words We carried out experiments to determine which words are likely to be inferred from their context. The collected data-set is then used to train a logis-tic regression classifier to predict which words are likely to be easily inferred from their context. We believe that this dataset may also be useful to re-searchers in studying related phenomena, and thus make it publicly available.

For this task, we focus only on the following context features for predicting the  X  X redictability X  of words: n-gram probability, vector-space simi-larity score, coreferring mentions. N-gram prob-computed within a fixed-size window of the word (trigrams using Microsoft N-gram service). Coref-erence feature is a binary feature which indicates whether the word has a co-referring mention in a 3-sentence window preceding a given context (ob-tained using Stanford X  X  CoreNLP package). We train L2-regularized logistic regression to predict a binary label L  X  { Constrained , Unconstrained } using a crowd-sourced corpus described below. 3.7 Corpus Construction For collecting data about which words are likely to be  X  X redicted X  given their content, we devel-oped an Amazon Mechanical Turk task that pre-sented turkers with excerpts of a short story (En-glish translation of  X  X he Man who Repented X  by word occurs.
 Ana Maria Matute), with some sentences contain-ing a blank in place of a word. Only content words were considered for the task. Turkers were re-quired to type in their best guess, and the num-ber of semantically similar guesses were counted by an average number of 6 other turkers. A ra-tio of the median of semantically similar guesses to the total number of guesses was then taken as the score representing  X  X redictability X  of the word being guessed in the given context. All words cor-responding to blanks whose scores were equal to and above 0.6 were than taken as a positive la-bel (Constrained) and scores below 0.6 were taken as a negative label (Unconstrained). Turkers that judged the semantic similarity of the guesses of other turkers achieved an average Cohen X  X  kappa agreement of 0.44, indicating fair to poor agree-ment. We carried out experiments on the effectiveness of our approach using the Amazon Mechanical Turk platform. Our experimental procedure was as follows: 162 turkers were partitioned into four groups, each corresponding to a treatment con-dition: OPT (N=34), HF (N=41), RANDOM (N=43), MAN (N=44). Each condition corre-Figure 4: Visualization of the most  X  X redictable X  words in an excerpt from the  X  X he Man who Re-pented X  by Ana Maria Matute (English transla-tion). Font-size correlates with the score given by judge turkers in evaluating guesses of other turk-ers that were presented with the same text, but the word replaced with a blank. Snippet of the dataset that we release publicly. sponded to a model used to generate the presented code-switched text. For all experiments, the text used was a short story  X  X ottery X  by Shirley Jack-son, and a total number of replaced words was controlled (34). Target vocabulary consisted of words from an artificial language, generated stat-ically by a mix of words from several languages. Below we describe the individual treatment condi-tions:
RANDOM (Baseline): words for switching are selected at random from content only words.
HF ( High Frequency ) Baseline: words for switching are selected at random from a ranked list of words that occur most frequently in the pre-sented text.

MAN ( Manual ) Baseline: words for switch-ing are selected manually by the author, based on the intuition of which words are most likely to be guessed in context.

OPT ( Optimization-based ): factor graph-based model proposed in this paper is used for generat-ing code-switched content. The total number of switched words generated by this method is used as a constant for all baselines.

Turkers were solicited to participate in a study that involved  X  X eading a short story with a twist X  (title of HIT). Not the title, nor the description gave away the purpose of the study, nor that it would be followed by a quiz. Time was not con-trolled for this study, but on average turkers took 27 minutes to complete the reading. Upon com-pleting the reading portion of the task, turkers were presented with novel sentences that featured the words observed during reading, where only one of the sentences used the word in a semanti-cally correct way. Turkers were asked to select the sentence that  X  X ade the most sense X . An example of the sentences presented during the test:
A  X  X ecall X  metric was computed for each turker, defined as the ratio of correctly selected sentences to the total number of sentences presented. The  X  X rand-average recall X  across all turkers was then computed and reported here. We perform a one-way ANOVA across the four groups listed above, with the resulting F = 11 . 38 and p = 9 . 7 e  X  7 . Consequently, multiple pairwise comparison of the models was performed with the Bonferroni-corrected pairwise t-test, yielding the only significantly different recall means between HF  X  MAN ( p = 0 . 00018) , RANDOM  X  MAN ( p = 2 . 8 e  X  6) , RANDOM  X  OPT ( p = 0 . 00587) . The results indicate that, while none of the automated methods ( RANDOM , HF , OPT ) outperform manually generated code-switched text, OPT outperforms the RANDOM baseline (no decisive conclusion can be drawn with respect to the HF  X  RANDOM pair).
 Additionally, we note, that for words with fre-quency less than 4, OPT produces recall that is on average higher than the HF baseline (p=0.043, Welch X  X  t-test), but at the expense of higher fre-quency words. Figure 5: Results presented for 4 groups, sub-jected to 4 treatment conditions: RANDOM , HF , MAN , OPT . Recall performance for each group corresponds to the average ratio of selected sentences that correctly utilize code-switched words in novel contexts, across all turk-ers. We observe from our experiments that the optimization-based approach does not in general outperform the HF baseline. The strength of the Figure 6: Subset of the results for 2 of the 4 treat-ment conditions: HF and OPT that correspond to recall only for words with item frequency in the presented text below 4. frequency-based baseline is attributed to a well-known phenomenon that item frequency promotes the  X  X oticing X  effect during reading, critical for triggering incidental lexical acquisition. Gener-ating code-switched text by replacing high fre-quency content words, thus, in general is a sim-ple and viable approach for generating effective reading-based L2 curriculum aids. However, this method is fundamentally less flexible than the optimization-based method proposed in this paper, for several reasons:  X  The optimization-based method explicitly  X  An optimization-based approach is able to In this work we demonstrated a pilot implemen-tation of a model-based, optimization-based ap-proach to content generation for assisting in the reading-based L2 language acquisition. Our ap-proach is based on static optimization, and while it would, in theory progress in difficulty with more reading, its open-loop nature precludes it from maintaining an accurate model of the learner in the long-term. For generating effecting L2 con-tent, it is important that the user be kept in a  X  X one of proximal development X   X  a tight region where the level of the taught content is at just the right difficulty. Maintaining an accurate internal model of the learner is the single most important require-ment for achieving this functionality. Closed-loop learning, with active user feedback is, thus, going to be functionally critical component of any sys-tem of this type that is designed to function in the long-term.

Additionally, our approach is currently a proof-of-concept of an automated method for generat-ing content for assisted L2 acquisition, and is lim-ited to artificial language and only isolated lexi-cal items. The next step would be to integrate bitext alignment across texts in two natural lan-guages, inevitably introducing another stochas-tic component into the pipeline. Extending this method to larger units, like chunks and simple grammar is another important avenue along which we are taking this work. Early results from concur-rent research indicate that  X  X ode-switched based X  method proposed here is also effective in eliciting acquisition of multi-word chunks.

