
Toobtainhighqualitytranslations,humantransla-tors usually have to modify the results generated by a machine translation (MT) system (called post edit-ing, PE). In many cases, PE needs a lot of modifica-tions, which is time-consuming (Plitt and Masselot, 2010). To speed up the process, interactive ma-chine translation (IMT) is proposed which instantly update the translation result after every human ac-tion (Langlais et al., 2000; Foster et al., 2002; Bar-rachina et al., 2009; Koehn, 2009; Gonz X lez-Rubio et al., 2013; Alabau et al., 2014). Because the trans-lation quality could be improved after every update, IMT is expected to generate high quality transla-tions with less human actions (Sanchis-Trilles et al., 2014).

Typical IMT systems usually use a left-to-right sentence completing framework pioneered by Langlais et al (2000), in which the users process the translation from the beginning of the sentence and interact with the system at the left-most error. By assuming the translation from the beginning to the modified part (called "prefix") to be correct, the sys-tem generates new translations after the given pre-fix (Koehn, 2009; Barrachina et al., 2009; Ortiz, 2011; Alabau et al., 2014).

Despite the success of this left-to-right frame-work, one potential weakness is that it is difficult to modify critical translation errors at the end of a sen-tence. Critical translation errors are those errors that has large impact on the translation of other words or phrases. When a translation ambiguity occurs at the end of a sentence while it causes translation errors at thebeginning,modifyingthiscriticalerrorsfirstmay bring great positive effects on previous parts of the translation, which may reduce human efforts in an IMTprocess. Modifyingfromlefttorightwilldelay the modification of the ambiguity point and lowers the interaction efficiency.

Critical errors are often caused by the inheren-t difficulty of translating source phrases. Mohit et al. (2007) proposed a classifier to identify the difficult-to-translatephrases(DTPs),whichwereex-tracted from syntactic trees. They demonstrated that askinghumantotranslatetheseDTPscanbringasig-nificant gain to the overall translation quality com-pared to translating other phrases. However, to our best knowledge, there is no practice in integrating these DTPs into an IMT framework.

In this paper, we propose a Pick-Revise IMT framework (PRIMT) to explicitly split the modifi-cation of a translation result into two very simple actions. Firstly, a wrongly-translated phrase is se-lected from the whole sentence ( Pick ); secondly, the correcttranslationisselectedfromthetranslationta-ble (or manually added) to replace the original one ( Revise ). Our system then re-translates the sentence and searches for the best translation using previous modifications as constraints (Section 2). Further-more, we propose two automatic suggestion models thatcouldpredictthewrongly-translatedphrasesand select the revised translation, respectively (Section 3). With the suggestion models, users only perform one of the actions (picking or revising) and let the suggestion models complete the other one. In this case, the interactions could be further simplified to be only one of the actions, which is as simple as one mouse click.

Experiment results show that by performing on-ly one mouse click, the translation quality could be significantly improved (around +2 BLEU points in one PR cycle). Performing both two actions multi-ple times will bring greater gain in translation qual-ity (+17 BLEU) with a relatively low Keystroke and Mouse-action Ratio (KSMR) (Barrachina et al., 2009) (3.3% KSMR). 2.1 PRIMT System We first explain the difference between Pick-Revise (PR) framework and left-to-right frame-work (Foster et al., 2002) with an example (in Ta-ble 1). For the given input source sentence, the MT system firstly generates a baseline translation. In the left-to-right framework human translator modi-fiestheleft-mosterrorfrom"todiscuss"to"discuss". But this modification may not bring any positive ef-fects on the other part of the translation. So more interactions are needed to further improve the trans-lation quality.

In our pick-revise framework, the human trans-lator picks the phrase "  X   X  " which was consid-eredthemostcriticaltranslationerror, andrevisethe translation from "the" to "anti-terrorism" according to phrase table. After a PR cycle, our constrained decoder re-translates the sentence. It not only gen-erates the correct translation for the pick-revise pair (PRP), but also improves the translation around the PRP (bold parts).

Compared to left-to-right framework, our frame-workcanmodifythemostcriticalerroratfirst,which brings larger improvements on translation quality and improves the efficiency of human interactions. Figure 1 shows an overview of our framework. For a source sentence s 1 ...s n , our framework iter-atively generates the translation using a constrained decoder. The constraints come from previous pick-ingandrevisingprocesses. Thepickingandrevising results can also be collected for model adaptation. The whole process continues until the translation is considered acceptable by the users. We explain the key components of our framework below. 2.2 Picking
In the picking step, the users pick the wrongly-translated phrase, ( s j i , t ) 1 , to be revised. The picking process aims at finding critical errors in the transla-tion, caused by errors in the translation table or in-herent translation ambiguities. The more critical the error is, the larger translation quality improvement can be achieved by correcting the error (Mohit and Hwa, 2007). Critical errors might have a large influ-ence to the translation of their context.

To make the picking step easier to be integrated into MT system, we limit the selection of transla-tion errors to be those phrases in the previous PR-cycle output. If it's the first PR-cycle, then those er-rors come from phrases used to generate the base-line translation. For more convenient user interac-tions, in our PRIMT system, critical errors can be pickedfromboththesourceandtargetsidebysimply a mouse click on it. The correspondence/alignment between source and target phrases are visualized for easier human observation.

Green et al. (2014) demonstrated that perform-ing post-editing, i.e. directly editing the translation errors, could get acceptable translations faster than performing left-to-right IMT. Such result also indi-cates that identifying critical translation errors is not a difficult task for human to perform. 2.3 Revising
Intherevisingstep,theusersrevisethetranslation of s j i by selecting the correct translation t  X  from the translation table, or manually add one if there is no correct translation in the translation table. Whether toperformselectionoraddingdependsonthequality of the translation table. When the translation system istrainedwithlargeenoughparalleldata, thequality ofthetranslationtableisusuallyhighenoughtooffer the correct translation.

For a picked phrase, the translation options in the phrase table could be presented to the users as a list. Theusersjustneedtoclickonthecorrecttranslation to complete the revising step. The users could also typeanewtranslationthroughaseparatedinputarea. 2.4 Decoder and Model Adaptation
A pick-revise pair (PRP), ( s j i , t  X  ), is obtained af-ter a PR cycle for a source sentence. We use a con-strained decoder to search for the best translation with the previous PRPs as constraints. The con-strained search algorithm is similar to the algorithm inatypicalphrase-basedmachinetranslation(Koehn et al., 2003). The only exception is that it makes anextracomparisonbetweeneachtranslationoption and previous PR pairs, which ignores all the phras-es that overlap with the source side of a PRP. As a result, a lot of translation options are ignored, which makes the search space much smaller than standard decoding. In this way, we could guarantee that all the PRPs are correctly translated and the whole pro-cess can be carried out in real-time.

The system could collect all PRPs and adapt the models using methods described in Germann (2014) or Marie (2015). In our current implementation, we mainly focus on the picking and revising step and leave model adaptation as future work.
To further reduce the human actions, we propose to use automatic suggestion models for the picking and revising step, respectively. Such models can of-fer suggestions to users in both picking and revising steps. Because both picking and revising actions are performing selections from multiple candidates, we use classifier-based approaches to model these two steps. In the following subsections, we will intro-duce how we define the picking and revising tasks asclassificationtasksandhowwechoosefeaturesto model the tasks. Note that these automatic sugges-tion models could be interpreted as simplified confi-dence measurements. 3.1 The Picking Suggestion Model (PSM) 3.1.1 PSM Training
The picking process aims at selecting critical er-rorswhichhashugeimpactonthetranslationquality of their context. The goal of PSM is to automatical-ly recognize those phrases that might be wrongly-translated, and suggest users to pick these phrases. In real world systems, the users can either accept or refuse the suggestion.

Within all the phrases of a source sentence, we need to separate the wrongly-translated phrases and correctly-translated phrases. Because translation er-rors often cause low translation quality, we use the translation quality gain after the revising action as a measurement. We treat those phrases that achieve translation quality improvement after revising as wrongly-translated phrases; those lead to translation quality deterioration as correctly-translated phrases.
We select phrases that lead to a BLEU improve-ment/deterioration greater than a threshold as posi-tive/negative instances. In this paper, the threshold is set as 10% of the BLEU score of the baseline sen-tence. 3.1.2 PSM Features
Modeling the picking process needs two aspects ofinformation. Oneofthemistodeterminewhether the phrase is difficult-to-translate; the other is to de-terminewhetherthecurrenttranslationoptioniscor-rect. We use features from translation models (TM-s), language models (LMs), lexical reordering mod-els (LRMs), as well as counting and lexical features in Table 2. These features cover information of the source side, target side, translation ambiguity, and context, etc. 3.2 The Revising Suggestion Model (RSM) 3.2.1 RSM Training
The revising process aims at selecting a correc-t translation for a given phrase under the given con-text. The goal of RSM is to predict the correct trans-lation and suggest users to replace the wrong trans-lation with the predicted one. The users can either accept it or use another translation.

Translation table has multiple translation option-s for one phrase. Within the translation option set of a source phrase, we need to separate the correc-t and wrong translation options. Instead of asking human translators to label these translations, we use two criteria to distinguish correct translation options from wrong translation options.

Firstly, the correct translation option should be a substring of the references, which ensures the cor-rectness of the options itself. Secondly, the correc-t translation option should be consistent with pre-trained word alignment on the translated sentence pair 2 . This is to ensure that the translation option does not get credit for words that are not translations of the source side phrase. The remaining options are considered wrong translations.

Withtheabovecriteria,weselectallcorrecttrans-lation options as positive instances for the revis-ing step, and randomly sample the same number of wrong translation options to be negative instances. Specifically, translation options that are used by the baseline system are included as negative instances. 3.2.2 RSM Features Thefeatures usedfor RSMare showedin Table3. For translations of a given source phrase, there is no need to compare their source-side information be-causethesetranslationoptionssharethesamesource phrase and context. So these features mainly focus onestimatingthetranslationqualityofagiventrans-lation option. As a result, features for RSM only in-cludingthescoresforTM,LMandLRM,etc, which are simpler compared to PSM.
 4.1 Experiment Settings 4.1.1 Translation Settings
Through out the experiments, we use an in-house implementation of the phrase-based machine trans-lation system (Koehn et al., 2003) and incorpo-rate our PRIMT framework into the translation sys-tem. The parallel data for training the translation model includes 8.2 million sentences pairs from LDC2002E18, LDC2003E14, LDC2004E12, LD-C2004T08, LDC2005T10, LDC2007T09. A 5-gram language model is trained with MKN smooth-ing (Chen and Goodman, 1999) on Xinhua portion of Gigaword which contains 14.6 million sentences. We use a combination of NIST02 and NIST03 to tune the MT system parameters and train the sug-gestion models. We test the system on NIST04 and NIST05 data. The translation results are evaluated with case insensitive 4-gram BLEU (Papineni et al., 2002). Our baseline phrase-based MT system has comparableperformancewiththeopensourcetoolk-it Moses (Koehn et al., 2003). 4.1.2 Classification Settings
We use three classification models to model the automaticsuggestionmodels: themaximumentropy model,theSVMmodelandtheneuralnetworkmod-el. Weuseamaximumentropymodel(Zhang,2004) with 30 iterations of L-BFGS. We use the LibSVM implementation (Chang and Lin, 2011) with RBF k-ernel and L2 regularization ( c = 128 ,  X  = 0 . 5 ). We use a feedforward neural network with the CNTK implementation (Agarwal et al., 2014). The neural network has one hidden layer of 80 nodes, with sig-moid function as the activation function.

We use one-hot representation for the source and target word features when using the maximum en-tropyandSVMmodel,andusepre-trainedwordem-beddings(Mikolovetal.,2013)fortheneuralmodel. 4.2 Methodology 4.2.1 Simulated Human Interaction
Becausereal-worldhumaninteractionsareexpen-sive and time-consuming to obtain, we use simulat-edhumaninteractionsforpickingandrevisinginthe experiment.

Directly identifying critical errors in the transla-tion is not an easy task without human annotation. Instead, we find critical errors by judging the in-fluence of a given error to the translation of their context. We try picking every phrase in a baseline translation result and revising it using the simulated revising strategy (described below). The influence of the phrase is measured by the translation quali-ty improvement after re-translation with the current phraseberevised. Thephrasewiththehighesttrans-lation quality improvement is picked to be the simu-lated human picking result.

Given the phrase to be revised, the simulated revising action is straightforward. Among all the translation options that are considered correct (Sec. 3.2.1),wechoosethelongestonetobethesimulated human revising result.

With the above simulated actions, one PR cy-cle takes exactly two mouse clicks and none key-stroke. For fair comparison, we use the same simu-lated revising action for the left-to-right framework. Each cycle of left-to-right framework also takes t-wo mouse clicks. We also compare the post editing method which selects the most critical error and ed-its it to be the simulated revising translation. The key-stroke count for each editing is the number of characters of the correct phrase translation. 4.3 Translation Quality Improvement in Ideal
Our first experiment is to test the PRIMT perfor-mance in an ideal environment. We conduct experi-ments on sentences for which the reference could be generatedbyourcurrentMTsystemusingforcedde-coding. Forced decoding forces the decoder to gen-erate translations exactly the same as the references. A reference translation could be generated by forced decoding means that it won't be necessary to input newwordstogenerateacorrecttranslation. Because weonlysimulatehumanrevisingactionsasselecting thebesttranslationoptionfromphrasetable(without adding new options), such a setting guarantees that the phrase table contains the correct translation for every phrase.

Table 4 shows that picking and revising the most critical error (PR*1) can bring +18 and +13 BLEU improvements in the two data sets, respectively. Re-vising the left-most error (L2R*1) only achieves an improvement around +5 BLEU. This result demon-strates that picking the critical error to be revised is critical in our PR framework. Compared to the left-to-right method, our framework has the advantage of correcting the critical errors in a high priority. By correctingsucherrors,theBLEUgainismuchlarger than left-to-right correction.

Post-editing the most critical error (PE*1) uses 8% KSMR, but only brings +5 BLEU improvement. Compared to post-editing, which just edits the criti-cal error without affecting other parts of the transla-tion,ourPRIMTframeworkcanre-decodeforbetter translations with less human interactions.
 In 8 PR-cycles (PR*8) (around 17% KSMR), the PRIMTachievesveryhighqualitytranslationresult-s with a BLEU score higher than 75 (around +35 BLEU to baseline). These results demonstrate the efficiency of PRIMT in multiple interactions. 4.4 Translation Quality Improvement in
We also validate the improvements of translation quality in a general environment. We perform simi-lar experiments on all NIST04 and NIST05 data. In someofthesentences,thetranslationtablemightnot contain the correct translation for source phrase, due to the limitation of the training of our current MT system.
 The results are listed in Table 5. Although the BLEU score in general environment are lower than those in ideal environment, the results show basi-cally the same trends as in the previous experiment. The third row (PR*1) in Table 5 shows that picking and revising the most critical error can bring around +11 BLEU improvements in both data sets. The im-provements in L2R*1 (+3.2) and PE*1 (+2.5) are muchless. ThreePR-cycles(around3.3KSMR)can achieve +17 BLEU improvements (PR*3). Com-pared to left-to-right and PE methods, our frame-work still has a significant advantage in the general environment. 4.5 Using Automatic Suggestion Models
We validate the effectiveness of our automat-ic suggestion models by both classification perfor-mance and translation performance.

Table 6 shows the classification performances of the PSM and the RSM, with different models. The precision and recall are calculated on positive in-stances in the test set, because only those instances that are predicted as positive will be used in the IMT system. Because it is harder to automatically iden-tify the correct translation, we keep the translation unchanged when the RSM classifies all translation options to be negative.

The performance of the three classifiers are sim-ilar. Feedforward neural network has a moderate advantage. In general, the PSM could recognize the critical translation errors with an F-score around 0.67. The RSM achieves about 0.65 F-score for rec-ognizing the correct translation. The F-scores are all in the range between 60 and 70, which is reasonable considering the difficulty of the tasks themselves.
We also evaluate the translation improvements when automatic suggestion models are used in the PR framework (Table 7). If the picking action per-forms a random pick of phrase (RandomPicking), there is barely no improvement in the translation quality, even with the simulated revising action. For comparison, using PSM could achieve a significant BLEUimprovementofaround2BLEU,onbothtest sets. It suggests that the BLEU gain does not come from the long reference translation match in the re-vising step. Picking critical errors is crucial in our framework.

Choosing the most critical error and performing a randomrevisingaction(RandomRevising)bringsno improvementinBLEUeither. UsingourRSMcould still improve the translation quality by 1.5 BLEU.
In general, using one of our PSM and RSM could still achieve significant improvement in translation quality. But the uses only need to perform one type of actions, which might be more suitable to be per-formed by a single human translator. However, the improvement is relatively small compared to fully simulated results, suggesting that human involve-ment is still critical for improve the translation qual-ity. Better modeling or training with larger data may alsoimprovementtheperformanceofautomaticsug-gestions.
WefurtheranalyzetheperformanceofourPRIMT systembyexamples. Table8showsthe PRIMTpro-cedureof improving translation quality for three dif-ferent sentences.
 In the first sentence, two PR cycles (4.7% KSM-R) lead to a perfect translation. In the first PR cy-cle (PR*1), revising the translation of "  X  X  " from "the" to "the 6th" improves the neighboring transla-tion. The translation of "  X  X  X  " change from "con-firms" to "confirm", which is a positive effect. In PR*2, revising the translation of "  X  X  X  " from "cas-es" to "case" also changes the neighborhood transla-tion(thetranslationof"  X  X  X  X  X  X  X  X  X  X  "changes to "death case from the bird flu"). After two PR cy-cles, the reference translation is obtained.
In our current settings, the reference translation couldnotalwaysbeobtained. Themaximumachiev-able BLEU is around 60-70 in general environment. The next two examples shows some possible expla-nations.

In the second sentence in Table 8, "  X  X  X  X  X  " is picked in the first PR cycle. Revising the translation from "a" to "need a certain" makes the translation of "  X  X  X  " changing from "is" to "usually". In the nex-t PR cycle, revising the translation of "  X  X  X  " from "process" to "course" makes the neighboring trans-lation changing from "," to ", and". Meanwhile, the positionof"course"movestotherightplace(infront of","). InthelastPRcycle,thetranslationof"  X  X  X  " is revised from "it" to "it cannot be". After three PR cycles, the translation quality improves significant-ly. However,thetranslationisstilldifferentfromthe reference. This is because "  X  X  X  X  X  " should be translated into "accomplished in one action" instead of "accomplished". But there is no suitable trans-lation options for it in the current phrase table. So thesystemcannotgenerateaperfecttranslation. The problemswillbelesssignificantwhenreal-worldhu-man translators are involved. Human translator in-puts the correct translation "accomplished in one ac-tion", the system will generate the reference transla-tion after constrained decoding (Human).

In the last sentence in Table 8, "  X  X  X  " is picked as the critical error. Revising the translation from "to the" to "failed to", leads to an improvement on neighboring phrase (the translation of "  X  X  X  X  X  " to "fully clear"). In the second PR cycle, "  X  X  X  X   X  " is picked. Revising the translation from "the is-raeli" to "israel 's", makes the translation of "  X  X  X  " change from "response" to "reply", which is also a positive effect. However, after two PR cycles, all phrase translations are correct, but the translation is still different from the reference. This is because the language model and lexical reordering model prefer the wrong phrase ordering, which put "the us" at the endofthewholesentence. Thisproblemraisesfrom the MT system itself, which may not be solved di-rectly in our current framework.

Ifmoreinteractionsareallowed,forexample,per-forming reordering operations, the above problems could be solved. But the interactions become more complex, andmaynotbeacceptabletohumantrans-lators. Other solutions includes using better statisti-cal models such as neural language models (Bengio etal.,2003). Thisisaninterestingissuewewilllook into. We introduced a pick-revise IMT framework, PRIMT, where the users could pick critical transla-tion errors anywhere in the sentence and revise the translation. By correcting the critical error instead of the left most one, our framework could improve thetranslationqualityinaquickerandmoreefficien-t way. By using automatic suggestion models, we could reduce human interaction to a single type, ei-ther picking or revising. It is also possible to let dif-ferent human translators to perform different action-s. In this case every translator will focus on a single action, which might be easier to train and may have higher efficiency.

On the other hand, the performance of curren-tframeworkisstillrelatedtotheunderlyingMTsys-tem. Furtherimprovementcouldbeachievedbysup-porting other type of interactions, such as reordering operations, or building the system with stronger sta-tistical models. We will also conduct real-world ex-perimentstoseehowthisnewIMTframeworkwork-s when human translators are actually involved.
The authors would like to thank the anonymous reviewers for their valuable comments. This work is supported by the National Natural Science Founda-tion of China (No. 61300158, 61472183), the Jiang-su Provincial Research Foundation for Basic Re-search (No. BK20130580). This research is partial-ly supported by the Collaborative Innovation Cen-ter of Novel Software Technology and Industrializa-tion, Nanjing University. Shujian Huang is the cor-responding author.

