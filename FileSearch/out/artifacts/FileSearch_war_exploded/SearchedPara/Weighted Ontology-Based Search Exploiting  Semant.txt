 well-defined meaning, better enabling computers and people to work in cooperation [1]. In recent years, semantic web has made significant progress. And several systems have been developed for semantic search [2, 3, 4 and 5]. 
However, semantic search does not seem to be so successful. One of the biggest problems is that most of these systems view semantic search as a problem of conven-tional keyword based search. In keyword based search, when a user types a query, the system returns a list of ranked documents that contain the query keywords. 
In semantic web, there are usually two kinds of data: ontology and instances. By semantic search in this paper, we mean searching for instances from the semantic web. Keyword based search can serve current web well. However, the method seems really want may not contain the query keywords. posal is to make use of relations and instance similarities for improving the semantic useful for search. We also assume that similarities between instances can be leveraged the assumption. 
Specifically, we first employ keyword based search method to retrieve instances query keywords but  X  X onnect X  to instances containing the keywords by some kind of instance that is what the user wants, instances similar to the instance can also be what the user wants. Furthermore, we use weighted ontology as the underlying data model to make the search processing more effective. We have implemented the proposed methods as a new feature in Semantic Web Aiding Rich Mining Service (SWARMS) project [7] (http://keg.cs.tsinghua.edu.cn /project/pswmp.htm). In SWARMS, we use OWL [8], one of the most popular ontol-ogy languages, as the knowledge representation language. We applied the system to given query. Our empirical experiments indicate that the proposed methods signifi-cantly outperform the keyword based methods for semantic search. 
The rest of the paper is organized as follows. In section 2, we introduce the related stance similarity measure and in section 5 we describe our search approach. Section 6 gives the experimental results. We make concluding remarks in section 7. In [5] authors describe an interesting approach for ranking query results using seman-tic information. The approach is oriented towards determination of the link relevance and reflects the semantic link-based nature of the Semantic Web. And the approach combines the characteristics of the inferencing process and the content of the informa-which uses rules from the domain ontology, i.e. the query process includes ontology-instances not keywords. A very interesting approach for querying Semantic Associations on the Semantic Web is presented in [3]. Semantic Associations capture complex relationships be-tween entities involving sequences of predicates, and sets of predicate sequences that interact in complex ways. A Semantic Association Query (SAQ) is a pair of entity stance using a measure that is similar to the notion of relation importance proposed in ranking of the complex path connecting entities. 
Significant efforts have been devoted to hybrid search engines which integrate se-mantic search and traditional search techniques [4, 9, 10 and 11]. The work presented in [4] describes a framework that combines traditional search engine techniques to-gether with ontology based information retrieval. A  X  X ocument X  that represents an Whereas, we give different weights to text content in the values of different properties similarity, all captured associations are derived from the explicit information existing in knowledge base. On the other side, the strength of our approach lies in exploiting implicit similarity knowledge. 
Another semantic searcher [2] which is built on Semantic Web infrastructure is de-signed to improve traditional web searching. They implemented two semantic search systems which, based on the denotation of the search query, augment traditional navigating through the instances graph is also used in our work. tion, we summarize their major primitives and introduce some shorthand notations. The main components of an ontology are concepts, relations, and axioms [6]. 
A concept represents a set or class of entities or  X  X hings X  within a domain. The con-concepts or properties of concepts. Axioms are used to constrain values for concepts ontology with associated instances is what is known as a knowledge base. 
In semantic search, we have found that different concepts or different relations We then extend the ontology definition so as to support the definition of importance. A core ontology can be defined as: Definition 1. A core ontology is a structure: consisting of (i) two disjoi nt sets C and R whose elemen ts are called concept identifi-ers and relation identifiers, resp., (ii) a partial order  X  C on C, called concept hierar-chy or taxonomy, (iii) a function  X  : R C or C  X  C called signature, and (iv) a partial order  X  R on R, called relation hierarchy. Relation can be defined as: Definition 2. For a relation r R with |  X  (r)| = 2, its domain and range are defined by domain(r) := the first element of  X h X q X h X tr X  ):= the second element of  X 
So far, the ontology definition can not ex press the importance of concept. We ex-tend the definition, and define the relation and concept importance as follows: importance to its domain and its range by imp(r 2 , domain(r 2 )) [0, 1] and imp(r 2 , range(r 2 )) [0, 1]. And for a concept c C and a relation r R with c  X  C domain(r), imp(r , c) = imp(r , domain(r)). Definition 4. For a concept c C, we define its importance by imp(c) [0, 1], and for c i , c j q C, c i  X  C c j , imp(c i )  X  imp(c j ). 
Value of imp ( c ) captures how important c is to this domain. Concepts or relations with higher importance contribute more in the search results. Users may care more for the instances of concept with higher importance. 
Ontology designers conducted the importance assignment for the relations and concepts according to their domain backgroun d knowledge. When conflicts occur, we use the average value as the importance. 
The importance can be assigned manually or can be learned automatically. The process of manual assignment is complex, time-consuming, and error-prone. Auto-matic assignment seems more feasible and more accurate. However, in this paper, we confine ourselves to the search processing. We will leave this to future work. The notion of similarity is used in many contexts to identify objects having common between instances. In our method, ontology structures of both hierarchical concepts and non-hierarchical relations are exploited to estimate the instance similarity. 4.1 Measures Exploi ting Concept Hierarchy Let us start the illustration from an example (shown in figure 1). The example shows chy. By unbalanced hierarchy, we mean sibling nodes with different numbers of pro-
The depth based measure is defined as [12]: 
For example, sim ( f 1 , pdf 1 ) = 2*1/(4+3)=2/7. 
Allowing for the numbers of concept instances, we define another similarity meas-urement. For two instances i 1 and i 2 , we define that is sim c ( i 1 , i 2 ) = sim c ( i 2 , i 1 ). And it is in range [0, 1). 
Table 1 shows the similarity values calculated by the depth based measure and the new measure. 
The new measure makes use of the instance population in addition to schema hierarchy. This similarity measure seems more accurate than the previous one in unbalanced hierarchy. 4.2 Measures Exploiting Property Similarity Usually, instances of the same concepts may have common properties. We define property similarity between instances based on the similarity scores of their property value-pairs: Properties can have different types. We calculate the similarity in terms of following rules: (i) If the range of property r is numeric, the similarity is computed as: where v r ( i ) represents the value of instance i on property r . This measure is only ap-plicable for positive numbers. (ii) If the range of property r is textual, we employ VSM (Vector Space Model) [13] to compute the Cosine Similarity between the two strings. For computing the Cosine Similarity, we extract bag of words from a string and construct a vector accordingly, finally compute the similarity by cosine similarity method. (iii) If the range of property r is a semantic concept c , the problem can be transformed into bag similarity computing. (See [12, 14 and 15] for details of bag similarity.) We exploit the Jaccard X  X  Coefficient here: 4.3 Combining Concept and Property Similarity After that, we combine sim c and sim p by using linear interpolation: where  X  is an experience parameter. At present, we determine it empirically as 0.4. 
The instance similarities are computed allowing for the weighted ontology. We explore other more effective ways to combine these two kinds of similarity. 5.1 The General Architecture We perform semantic search in three stages of processing: keyword based search, semantic feedback, and semantic data search. Figure 2 shows the flow. 
The input is a query containing one or several keywords (here the query is the same as that in the keyword based search). Using the keyword based search, we re-trieve the instances that contain the query keywords. The retrieved instances are weighted ontology. In semantic feedback, we prompt the top ranked instances (top larities to re-retrieve the instances that do not contain the query keywords. 5.2 Keyword Search and Semantic Feedback In keyword search, we developed our keyword based search engine by making use of VSM (Vector Space Model). We extract a bag of words for each instance and con-struct a vector accordingly. We next compute the value of each element in the vector by tf/idf measure [16 and 17]. Allowing for the weight ontology, we make some change to the measure: belongs to. Notation tf r ( i , t ) is the frequency of word t in instance i . In semantic feedback, we hope to capture user X  X  information needs more accurately. We adopt the strategy of feedback. Then the essential task is to provide a friendly inter-action between users and semantic data. We return the initial result instances by human readable text. Two approaches can be used here. The first is that we use the web docu-method is inapplicable since some instances are not annotated from a single page. 
Therefore, we propose a new technique to present instances in the form of natural language. For example, in Figure 3, the instance &amp; d 3 can be described as the follow-ing piece of text:
Currently, a template based method is applied to this work. A template is designed template for generating the natural language expression. 
In this way, users can easily understand what the instance is about. And then give their feedbacks to the system. We give three options for each top ranked result: rele-vant , barely relevant and irrelevant . And the relevant scores are adjusted according to user selection: scores of instances indicated relevant are adjusted to 1, barely relevant to 0.4 and irrelevant to 0. 5.3 Semantic Data Search may be  X  X elevant X  to the query through relations and instance similarities. Spread Activation technique is a processing framework designed for semantic networks and ontologies in AI area and has been successfu lly used in semantic data processing [4, 18, 19 and 20]. We employ Spread Activation in our semantic search stage. 
We first explore the knowledge base by using relations between instances. To re-most one time. Instance n i can spread to n j in this way: stance, if n i is the object of r and n j is the subject of r , it is defined as: tions of this specificity have been used in [4] and [5]. The higher the specificity is, the more valuable the relation instance is. path connecting them: 
By making use of instance similarities for spreading, we choose the top ranked in-stances to spread the weight to other instances. Instance n i spreads to n j in this way: experiment, the relevant scores of the ten most similar instances to n i will be updated. may occur due to their high similarity. 6.1 Software Domain We implemented the weighted ontology-based semantic search engine as a compo-nent of SWARMS and tested it in a software domain application. We defined the software ontology corresponding to the knowledge schema on SourceForge (http://sourceforge.net). Figure 4 shows part of the ontology. We downloaded 9796 projects from the web site and organized th em into the instance base. Now there are around 112,098 node instances together with 166,320 relation instances. 
In the SourceForge website there are 19 main software topics (e.g. Internet, Multi-media, etc). Most of them have sub-topi cs, for example, the Multimedia topic has various sub-topics such as Graphics, Audio and Video. Each project has one or more several developers and one developer also may be involved in several projects. 6.2 Experiment Setup and Measure Starting from the annotated data from SourceForge website, we developed a search test involving ten people in the evaluation. Each of the evaluator is given five queries (as shown in Table 2). 
For each query, we performed the comparison of four types of searches: a-rw , b-rsw , c-rsf and d-rswf . Table 3 shows the experimental search types. The first type of techniques proposed in this paper. 
In evaluation, we proposed a measure that takes into account both relevance and rank position. We define the measure as: pute the R measure. Because users tend to only care about the few top ranked results, here we set N as 30. 6.3 Results and Discussion Each score is the average of scores from the ten evaluators. The four bars from left to stance similarity are, on average, able to provide more relevant results and give better ranking of the retrieved results than search engine (type a ) that only use relations. 
These empirical results deserve several comments. First, we can see that type b search is 18% better than type a search, which means instance similarity method used in spreading process boosts the performance. Naturally we are interested in why type b search works so well. So we interviewed three evaluators to try to answer that ques-tion. Their explanation is that the improvement mainly comes from the augmentation of relevant retrieved instances. Some relevant instances retrieved in type b search are not included in type a search results. They usually contain no or few query keywords similarity with the top ranked instances. 
Nevertheless, type c searches do not improve much in the comparison to type a unweighted ontology is inaccurate, which hurts the final performance. We see that the stance similarities are computed using weighted ontology, the relevant scores are much better. The intuition behind this is that the weighted ontology makes the in-stance similarity more accurate. Accurate similarity can reduce the irrelevant entities introduced into the spreading process. 
Note that, in general, the performance of feedback is correlated with the initial per-feedback does not affect the final performance very much, because users can not search. But in the second query, with the bad initial results, the improvement is only provide any improvement. In this paper, we have investigated the problem of semantic search. We have extended the ontology definition so as to support importance of concept and relation. We have proposed an approach to the task of semantic search by using instance similarities and semantic feedback technique. Experiment results show that the proposed methods are effective and can improve retrieval performance significantly. 
As future work, we plan to make further improvement on the accuracy of semantic its effectiveness, such as book, news or paper searching. 
