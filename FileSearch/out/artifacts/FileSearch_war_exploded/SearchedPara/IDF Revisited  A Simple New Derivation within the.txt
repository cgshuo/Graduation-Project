 There have been a number of prior attempts to theoretically justify the effectiveness of the inverse document frequency (IDF). Those that take as their starting point Robertson and Sp  X arck Jones X  X  probabilistic model are based on strong or complex assumptions. We show that a more intuitively plausible assumption suffices. Moreover, the new assump-tion, while conceptually very simple, provides a solution to an estimation problem that had been deemed intractable by Robertson and Walker (1997).
 Categories and Subject Descriptors: H.3.3 [Informa-tion Search and Retrieval]: Retrieval models General Terms: Theory, Algorithms Keywords: inverse document frequency, IDF, probabilistic model, term weighting
The inverse document frequency (IDF) [12] has been  X  X n-corporated in (probably) all information retrieval systems X  ([6], pg. 77). Attempts to theoretically explain its empirical successes abound ([2, 14, 1, 11, 5, 8, 4, 3], inter alia ). Our focus here is on explanations based on Robertson and Sp  X arck Jones X  X  probabilistic-model (RSJ-PM) paradigm of informa-tion retrieval [10], not because of any prejudice against other paradigms, but because a certain RSJ-PM-based justifica-tion of the IDF in the absence of relevance information has been promulgated by several influential authors [2, 9, 7]. RSJ-PM-based accounts use either an assumption due to Croft and Harper [2] that is mathematically convenient but not plausible in real settings, or a complex assumption due to Robertson and Walker [11]. We show that the IDF can be derived within the RSJ-PM framework via a new assump-tion that directly instantiates a highly intuitive notion, and that, while conceptually simple, solves an estimation prob-lem deemed intractable by Robertson and Walker [11].
In the (binary-independence version of the) RSJ-PM, the i th term is assigned weight wher e p i def = P ( X i = 1 | R = y ), q i def = P ( X i X i is an indicator variable for the presence of the i th term, and R is a relevance random variable. Croft and Harper [2] proposed the use of two assumptions to estimate p i and q in the absence of relevance information. CH-1 , which is unobjectionable, simply states that most of the documents in the corpus are not relevant to the query. This allows us to set d q CH i def = n i N , where n i is the number of documents in the corpus that contain the i th term, and N is the num-ber of documents in the corpus. The second assumption, CH-2 , is that all query terms share the same probability  X  of occurring in a relevant document 1 . Under CH-2, one sets d where  X  0 = log (  X / (1  X   X  )) is constant (and is 0 if  X  = . 5). Quantity (2) is essentially the IDF.

CH-2 is an ingenious device for pushing the derivation above through. However, intuition suggests that the oc-currence probability of query terms in relevant documents should be at least somewhat correlated with their occur-rence probability in arbitrary documents within the corpus, and hence not constant. For example, a very frequent term can be expected to occur in a noticeably large fraction of any particular subset of the corpus, including the relevant documents. Contrariwise, a query term might be relatively infrequent overall due to having a more commonly used syn-onym; such a term would still occur relatively infrequently even within the set of (truly) relevant documents. 2
Robertson and Walker (RW) [11] also object to CH-2, on the grounds that for query terms with very large document frequencies, weight (2) can be negative. This anomaly, they show, arises precisely because d p CH i is constant. They then propose the following alternative: where  X  is the Croft-Harper constant, but reinterpreted as the estimate for p i just when n i = 0. One can check that
This can be relaxed to apply to just the query terms in the document in question. Indeed, one study [5] did find p i increasing with n i . d i  X  [  X , 1] slopes up hyperbolically in n i . Applying d p RW and d q CH i to the term-weight scheme (1) yields (which is positive as long as  X   X  . 5).
The estimate d p RW i increases monotonically in n i , which is a desirable property, as we have argued above. However, its exact functional form does not seem particularly intuitive. RW motivate it simply as an approximation to a linear form; approximation is necessary, they claim, because Despite this claim, we show here that there exists a highly intuitive linear estimate that leads to a term weight varying inversely with document frequency.

There are two main principles that motivate our new es-timate. First, as already stated, any estimate of p i should be positively correlated with n i . The second and key insight is that query terms should have a higher occurrence proba-bility within relevant documents than within the document collection as a whole . Thus, if the i th term appears in the query, we should  X  X ift X  its estimated occurrence probability in relevant documents above n i /N , which is its estimated occurrence probability in general documents. This leads us to the following intuitive estimate, which is reminiscent of  X  X dd-one smoothing X  used in language modeling (more on this below): Here the L &gt; 0 in the numerator 4 is a  X  X ift X  or  X  X oost X  constant. 5 Plugging b p i and d q CH i into (1) yields the term weight which varies inversely in n i , as desired.

Furthermore, as hinted at above, selecting L  X  X  value is equivalent to selecting b p i  X  X  value for query terms whose doc-ument frequency is 0. That is, L/ ( N + L ) is directly analo-gous to  X  in RW X  X  derivation. Indeed, choosing L = N is just like choosing  X  = 0 . 5, which is commonly done in presen-tations of the Croft-Harper derivation in order to eliminate the leading constant  X  0 in (2); doing so in our case yields the following term weight, which is the  X  X sual X  form of the IDF ([13], pg. 184):
The fact that RW X  X  Figure 2 depicts the linear scenario graphically appears to have led to some mistaken impres-sions (e.g., [5], pg. 18, coincidentally) that this is the math-ematical model that RW actually employed.
The L in the denominator ensures that b p i  X  1.
Since the RSJ-PM document-scoring function only accu-mulates weights for terms appearing in the query, it is fine to compute the b p i  X  X  offline, that is, before the query is seen. Finally, note that b p i is linear in n i ; we have thus contradicted the assertion quoted above that developing a  X  X traight-line X  model is  X  X ntractable X  [11].
An interesting direction for future work is to consider lift functions L ( n i ) that depend on n i . It can be shown that different choices of L ( n i ) allow one to model non-linear de-pendencies of p i on n i that occur in real data, such as the approximately logarithmic dependence observed in TREC corpora by Greiff [5]. Importantly, seemingly similar choices of L ( n i ) yield strikingly different term-weighting schemes; it would be interesting to empirically compare these new schemes against the classic IDF.
 Acknowledgments . We thank Jon Kleinberg and the anony-mous reviewers for helpful comments. This paper is based upon work supported in part by the National Science Foun-dation under grant no. IIS-0329064, a Yahoo! Research Alliance gift, and an Alfred P. Sloan Research Fellowship. Any opinions, findings, and conclusions or recommendations expressed are those of the author and do not necessarily re-flect the views or official policies, either expressed or implied, of any sponsoring institutions, the U.S. government, or any other entity.
