 question RS (recommender system), the Enlister project, for the biggest Chinese Q&amp;A (Questions and Answers) website and evaluate its performance on massive data from this real-world practice. recommendation algorithms and optimization methods. To enhance recommendation accuracy and handling time-sensitive questions, we propose a large s cale real-time RS based on the combination of machine learning algorithms and the stream computing technology. Consideri ng of algorithm flexibility and performance, we use the maxi mum entropy model as the fundamental model design in the CTR (click-through rate) prediction of recommendation items. In the perspective of the Enlister system architecture, we illustrate how we divide and conquer massive data processing problem with a novel stream computing design which reduces th e data process latency down to seconds. concept by achieving a series of significant improvements. H3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval Algorithms, Performance Machine Learning, Maximum entropy, Stream computing Baidu Inc. is a leading internet service provider in China. As of January 2012, it ranked 5th in the Alexa global rankings and the 1 in China. One of Baidu X  X  most popular services is the Baidu Knows, which offers a Q&amp;A plat form to its users for knowledge and experience sharing. Today, there are over 400 million questions on the Baidu Knows website, of which more than 170 million questions were answered by users. Around 100 million users search for answers every day and over 12 new questions are posted online every second. 
As the biggest Q&amp;A website in China, the Baidu Knows create an eco-system of knowledge shari ng between the website X  X  users. As shown in Figure 1, typical common users just search in the Baidu Knows for answers with so me related keywords. Some of these users will become the Aske rs to post new questions on the website. Then the users who know the answers to these questions post their answers back and become answerers in this community. As more questions have been answered, the search result quality of common users will be improved. Therefore, the fundamental concept of keeping this community healthy is stimulating the growth of answered questions. 
As for the answerers, searching for unsolved questions is often too time-consuming. That X  X  why a question RS is introduced to solve this problem by automatically presenting questions to potential answerers. We build an intelligent RS to pr ovide the Baidu Knows users with questions that they may be willi ng to answer. This RS is also capable of tracking down the shor t-term variation of a user X  X  intention. 
After submitting a new answer to an unsolved question, a user will be redirected to a new we b page where we put the question recommendation list there. The user could either click through one question to answer it or just leave this page if not interested. The quantitative analysis of the user reactions and recommender performance will be presented in Section 5. 
Our Contributions can be summarized as follows:  X  We bring a large scale question RS, which is based on the  X  We illustrate that the stream computing technology could  X  Inspired by the modern search engine ranking technology, 
For your convenience, we organize the remainder of this paper as follows. In Section 2, relate d work is introduced. The user model and the recommender algorith ms are described in Section architecture. All the evaluations are placed in Section 5. Finally, we have a brief conclusion in Section 6. 
The previous question RS of Ba idu Knows is a typical content-based RS [1]. It models the relevance between a user and a question as the cosine similarity degree of the user X  X  preference vector and the term vector extr acted from the question. However, objective and wild computational complexity. 
As in many other information re trieval [2] and search engine advertising application [3] [4], CTR prediction is introduced to improve the performance of the Q&amp;A RSs [5] [6]. Compared with other RS that had applied CTR prediction, the Enlister has pushed the CTR predic tion to the edge of real-time massive-data processing and has pr oven to be very successful in the real-time RS design. In our new version of RS, known as the Enlister system, the CTR metric is introduced to characterize the correlation between users and questions. It presents a closer view to the users X  experience than the relevance score we used before. 
In order to make more accurate predictions, delicate user models are constructed based on the data we collected from the users. On one hand, we expect thes e models to disclose the nature of our users X  choices of answer ing questions. On the other hand, the models have to be simple enough to accommodate massive calculation and industria l adoption. Based on the user models, the click prediction models are trai ned according to the user click history and certain features from th e user models. With the trained click model, we can easily predict the probability of a specific user clicking on a particular question. After we aggregate probability prediction results an d generate a new recommendation list, diversity adjustments are introduced to avoid the potential monotonous problem of the question recommendation and pursue some limited but pragmatic novelty. 
In the Enlister system, user model is built on both long-term status of user attributes and short-term variation of user interest. 
Some user attributes are the basic information of a user, such as age, gender, education, expertise and other tags that one labeled on himself. User interest is essential in the user model data structure. In the Enlister system, three aspects of interest descriptions are generated from three different semantic abstractions: 1) Interest Term Vector 2) Related Questions 3) Abstract Interest Vector 
In the Enlister system, the click model that we created is a kind of probabilistic classification model. It is a binary classification model to calculate the probability of a sample belonging to a class.
We will introduce more details a bout the click prediction in the following sections, including: 1) Sample Collection; 2) Feature Selection; 3) Classifier Algorithm. 
The samples are collected from the real online log of the original version RS. The positive samples are the questions that the user had examined and c licked. However, the negative samples are not questions that are unvisited by the user, but the questions we randomly choose fr om the question pool. As besides having no interest, there are many reasons may explain why questionnaire investigation shows that most people did not click on a recommended question because they just did not notice it. Thus the probability that the ran domly chosen questions coincide with the user X  X  interest can be negligible, considering the huge size of our question pool. 
From our previous investigations , two factors are essential in the user X  X  decision of following a question. One is the user X  X  attributes. The other is the corr elation degree between the user interest and a question. 
As has been mentioned in Section 3.2.1, user attributes suggest the user X  X  preference in the Q&amp;A community. The basic user attributes contribute to many low level features in our model. For example, a woman who is over 30 with a PhD degree may have a tendency to receive more questi on recommendations than others who don X  X  have any expertise. Othe r features from the statistics are also useful in prediction, such as the participation history of a user in the Q&amp;A community. We have observed that the more active a user is, the more likely he will accept the recommended questions. 
The major purpose of the user in terest model, which we have described in Section 3.2.2, is to support the calculation of sematic correlation degree between user inte rest description and an input question. The correlation degree is a combined similarity degree of many natural language aspects consist to the user interest model. For the utilization of the interest term vector, we calculate the number of matched terms, cosi ne similarity and bm25 between the user interest term vectors and question vectors. Then the matched terms and the semantic similarity are measured between the input question and the related questions in a user X  X  model from both the term angle and the topic angle. 
In the Enlister design, two principles are crucial in the classifier selection. First, the classifier should be capable of performing a probabilistic classification, as we need not only the class label, but also the confidence degrees. Second, it needs to be a (generalized) linear classifier, which meets the requirement of online system response latency. Based on th ese two principles, we choose click the question q can be calculated as follows: 
With 
The global optimization solution is maximizing a logarithmic posteriori against the training se t by some optimization methods, such as limited-memory Broyden-Fletcher-Goldfarb-Shanno (L-BFGS) and Stochastic Gradient Descent (SGD). We have tried these two methods in our experiment respectively. The result shows that the L-BFGS optimizati on is slightly better in this application scenario. After the m odel training process, we apply precision, recall etc. More details will be discussed in section 5. 
Based on previous user research and eye-ball tests, we found from the users. 
In the Enlister, we use different filter algorithms for the head and the tail. For the head part, we apply a loose filtering algorithm, which only deletes some apparent duplication in the list. While for questions that have noticeable semantic level similarity to each appearance. 
The most important concept in the Enlister system design is real-time CTR prediction. The major data process can be described as follows. 
As shown in the Figure 2, the whole process is divided into 3 stages. The first stage includes 2 sections, one of which is used to extract the features of input questions and the other is used to generate user model from user actions in Baidu Knows online service system. The second stage is the CTR prediction where the user-action features, the input question features and the pre-trained click model are arranged together. With all the input parameters, we can calculate the probability of the user being re-rank section. This is where the functionality of the list padding and diversity adjustment algorith m occurs in the whole data process. 
For building the data processing flow, we construct multiple logic queues between processing nodes. The processing nodes are grouped into several node groups. Each group represents a simple the prediction section. If any group shows sign of lacking processing ability, we could just add nodes to that node group to solve the scalability problem [8]. 
To evaluate the CTR model, we apply standard metrics in our experiments, such as precision, recall and accuracy. 
As for a real online RS, users X  reaction to the recommendation is a more convincing metric. 100,000 questions that had been viewed and clicked by users are selected from users X  logs as positive sample, which involves 10 thousands users with 10 records per user on average. The negative samples could be built with two different types of data sources, the weak negative or the random negative. The weak negative samples are questions from real recommendation lists that are never clicked by users. The random negative samples are questions that chosen randomly from a large question pool. The data in Table 2 gives us the evaluation of different ways of negative samples selection. It is clear that using the random negative samples in training m odel is better in this case. 
The ratio of the positive and negative samples proportion is another issue to be settled. To find the proper ratio, we trained the model on datasets with different sample proportion settings. The results in Table 3 indicate that while the proportion ratio of positive and negative samples is 50% to 50%, a better classifier performance is produced. 
As referred in Section 3, SGD and LBFGS algorithms are considered as the optimization algorithm in the maximum entropy model training. The data in Table 4 shows LBFGS is slightly better than SGD in this applica tion. As a result, we choose the LBFGS algorithms for the online evaluation. Enlister was released to the Baidu Knows users and an online evaluation was conducted from Feb. 11 th , 2012. 
In Table 5, the number of cl icks/answers to recommended questions is given. As can be se en from the table, the total number increased by a big margin compared with the previous RS. 
Figure 6: Trend of the active answerers after Enlister was 
Essentially, as shown in Figure 6, the promotion of the active answerer number suggests a much favorable user experience, where the active answerer is defined as one who answered at least one question in the past 30 days. In the Enlister project, we have successfully built a real-time RS that serves millions of users every day. The evaluation data shows that the algorithm and system design fit the recommendation scenario quite well. Great impr ovement had been made on the accuracy and time-sensitive issues. The number of active users had grown substantially after the sy stem was officially launched. 
The result data just illustrates the efficiency and performance of our current solution. Still, there are a lot of other recommendation algorithms and optimization methods to be considered in our future improvement. Two potenti al aspects are the timing of recommendation and the utilization of relationships between users. 
Finally, we hope our work will inspire and encourage more people to build large scale recomm ender systems for helping users retrieve useful information. The authors would like to thank all the colleagues in Baidu Inc. who contributed to the Enlister pr oject in various ways, especially Hao Tian, Jian Xian, Junyu Cai, Kai Chai, Xin Sun. 
The authors are grateful to Dr. Evan Xiang for his comments on the early draft of this paper. [1] Michael J. Pazzani and Daniel Billsus. 2007. Collaborative Filtering [2] Olivier Chapelle , Ya Zhang, A dynamic bayesian network click [3] M. Regelson and D. Fain. Predicting click-through rate using [4] Matthew Richardson , Ewa Dominowska , Robert Ragno, Predicting [5] Xin Jin, Yanzan Zhou , Bamshad Mobasher. A maximum entropy [6] Yutaka Kabutoya, Tomoharu Iwata, Hisako Shiohara, Ko Fujimura. [7] Thomas Hofmann. Probabilistic latent semantic indexing . [8] M. Stonebraker, U. Cetintemel, and S. Zdonik: The 8 requirements 
