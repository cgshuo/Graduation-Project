 ORIGINAL PAPER Lipika Dey  X  Sk. Mirajul Haque Abstract The proliferation of Internet has not only led to the generation of huge volumes of unstructured information in the form of web documents, but a large amount of text is also generated in the form of emails, blogs, and feed-backs, etc. The data generated from online communication acts as potential gold mines for discovering knowledge, par-ticularly for market researchers. Text analytics has matured and is being successfully employed to mine important infor-mation from unstructured text documents. The chief bottle-neck for designing text mining systems for handling blogs arise from the fact that online communication text data are often noisy. These texts are informally written. They suffer from spelling mistakes, grammatical errors, improper punc-tuation and irrational capitalization. This paper focuses on opinion extraction from noisy text data. It is aimed at extract-ing and consolidating opinions of customers from blogs and feedbacks, at multiple levels of granularity. We have pro-posed a framework in which these texts are first cleaned using domain knowledge and then subjected to mining. Ours is a semi-automated approach, in which the system aids in the process of knowledge assimilation for knowledge-base building and also performs the analytics. Domain experts ratify the knowledge base and also provide training sam-ples for the system to automatically gather more instances for ratification. The system identifies opinion expressions as phrases containing opinion words, opinionated features and also opinion modifiers. These expressions are categorized as positive or negative with membership values varying from zero to one. Opinion expressions are identified and catego-rized using localized linguistic techniques. Opinions can be aggregated at any desired level of specificity i.e. feature level or product level, user level or site level, etc. We have devel-oped a system based on this approach, which provides the user with a platform to analyze opinion expressions crawled from a set of pre-defined blogs.
 Keywords Noisy text  X  Context-dependent cleaning  X  Opinion mining  X  Wo r d N e t  X  Text analytics for market knowledge discovery 1 Introduction The increased use of Web as a medium of communication has led to the generation of a huge quantity of unstructured data in the form of blogs, chats, emails, reviews, feedbacks, news, etc. Since Internet is a crucial driving force in today X  X  world, these texts are rich pointers to the collective opinion of the global population on almost every topic. Thus these texts are considered as rich sources for raw inputs to market research and knowledge discovery. Given the volume and growth rate of these sources, efficient mechanisms are required to aggre-gate, assimilate and interpret all the information with mini-mal human intervention. Opinion mining refers to the task of opinion extraction and sentiment analysis from unstructured text documents. The key components of opinion mining are opinion extraction and structurization that can help in aggre-gation and analysis of opinions about pre-defined subjects. Opinion extraction involves identification of opinion holder, the subject being reviewed, the part or the feature of the sub-ject that is being evaluated, and finally classifying the opin-ion as either positive or negative or some other pre-defined opinion category. Structurization involves transformation of the extracted opinion expressions into structures suitable for assimilation and analysis.

In this paper, we present the design and analysis of a system that has been designed to mine opinions mainly from blogs, though the principles are generic and work for other documents also. The quality of texts encountered in blogs and chats is extremely noisy. Noisy text data typically comprises spelling errors, ad-hoc abbreviations and improper casing, incorrect punctuation and malformed sentences. Though an array of systems has been developed in the recent past to ana-lyze sentiments and mine opinions from text, most of them assume that the underlying texts are linguistically correct. Compared to the volume of work dedicated to sentiment anal-ysis which identifies whether a sentence expresses positive or negative emotion, fewer attempts have been made toward structuring and mining the content extracted from noisy data sources. In Sect. 2 we provide a detailed review of the related work in this field.

This paper presents the framework for a generic web-based opinion finder system. It can be customized to get a summarized view of all relevant opinions expressed about chosen products. It is a semi-automated system which extracts and organizes information according to analysts X  needs, and also acts as an aid to analysts to validate new knowledge to update the knowledge base. Of particular inter-est to market analysts are dedicated blogs where users post their opinions and exchange views on product-related issues. This system is therefore designed to learn and extract all prod-uct-related features and concepts that are being discussed and opinionated about. The system provides facilities for mining the data and viewing the results at desired levels of specificity.
The opinion mining framework comprises two core mod-ules: Data acquisition and pre-processing to reduce noise in the text  X  X ata acquisition is done using site-specific crawlers. The acquired data are stored along with as much associated information as is available. Associated data often contains useful information about blogger, time, product name, etc. Since the system is primarily designed to analyze opinions from blog data, one of the core tasks is to reduce as much noise as possible. Pre-processing itself comprises various sub-tasks like identifying meaningful segments of text, spell-ing correction, etc. It may be noted that the focus of the system is not to correct all the errors in text. Rather these methods have been designed to focus on minimizing error in opinion mining and are customizable to adapt to different domains. Though a number of systems have been proposed earlier for extracting opinions from product reviews, most of these have assumed linguistically correct sentences as inputs. Opinion extraction and mining  X  X pinion extraction identi-fies fragments within a sentence that express opinions about a relevant subject and stores them in pre-defined templates. These templates are subjected to different analytics for gen-erating collective opinions.

The distinguishing features of the proposed approach are: (i) The system employs a linguistic approach which (ii) A new approach is proposed to deal with adverbial (iii) The extracted opinions are stored as structured tem-(iv) Based on the proposed framework, opinion mining 2 Related research As the Web gains power as a social media, the task of extract-ing and analyzing meaningful content from these noisy sources is attracting a fair deal of attention from the research-ers. Initiated by Hatzivassiloglou and McKeown [ 11 ], opinion mining gained momentum only recently. While a section of research is dedicated toward identifying opinion-ated expressions and their orientation, there has been a lot of interest in mining the web for extraction of user generated product reviews and their classification. Another class of sys-tems is dedicated to track opinions about people or events from news sources. We have provided an in-depth review of the first class of systems since they are functionally more similar to ours than the others.

Traditional sources of noisy text included (a) text obtained from automatic transcription of speech data and (b) text obtained by using OCRs on text images. More recent sources of noisy text include user generated content available on the Web in the form of Blogs, Online chats, messages, Wiki, etc. These texts not only contain involuntary spelling errors, but also contain abbreviations, acronyms, specialized vocabulary and show significant use of mixed languages.

Two approaches have been reported in the literature for performing noisy text analytics. The first approach is a two-step process. It proposes the elimination of noise from text and then proceeds with analysis on cleaned text. The sec-ond approach processes the noisy text directly using machine learning techniques which can learn patterns from the under-lying text. The techniques adopted usually depend on the ulti-mate information extraction task. We have adopted the first approach since that is most suitable to the task at hand. In Sect. 2.1 , we review some of the important works reported for pre-processing of noisy text. In Sect. 2.2 ,wehavereviewed related work on sentiment analysis and opinion mining. 2.1 Preprocessing noisy text Pre-processing of noisy text to produce clean text which can be used for information extraction thereafter relies on iden-tification of spelling errors and correcting them, eliminating arbitrary sequences of white spaces between words, detecting sentence boundaries, eliminate arbitrary use of punctuation marks and capitalization. These tasks are usually executed in a pipeline.

Kernighan et al. [ 15 ] in a seminal paper introduced the use of a noisy channel model to perform spelling correc-tion. The idea here is to find the most likely sequence of words that could have given rise to the observed sequence of tokens, assuming an underlying language model. This work was extended by Brill and Moore [ 2 ] who uses a more sophisticated error model to get substantial improvements. These works were, however, primarily concerned with errors in post-edited text, and do not work correctly for free web content. None of these works, however, consider a word as an error if it is a dictionary word, though obviously wrong in the given context.

Several researchers have worked on Information Extrac-tion from noisy text. Chieu and Ng [ 4 ] presented a maximum entropy-based method to extract information components from semi-structured text like seminar announcements. Though these texts do not contain spelling errors, non-exis-tence of sentence barriers and high degree of capitaliza-tion complicate the task of information extraction from such documents. This work demonstrated the feasibility of using machine-learning for multi-slot Information Extraction from semi-structured text.

Mikheev [ 20 ] addressed the problems of sentence bound-ary disambiguation, disambiguation of capitalized words and identification of abbreviations with minimal use of pre-built resources. The resources used included a list of common words, a compiled list of most frequently used words in start-ing positions, a list of proper names expected in mandatory positions and a list of abbreviations obtained from the Inter-net. A collection of strategies are thereafter employed to learn the characteristics of the noisy document and disambigu-ate correctly. However, this work was evaluated on Brown Corpus and not noisy text with irrational use of characters.
Clark [ 5 ] presents a machine learning methodology using generative models and a noisy channel method for pre-processing of very noisy text. It assumes that the text may contain unbounded vocabulary, varying amounts of white spaces, random degrees of capitalization of words, spelling errors, etc. In this work, language modeling is done at the character level rather than at the word level, using an n-gram word model. A sequence of characters is assumed to consist of a sequence of tokens interspersed by white space which can be of zero length. The approach is to model the process as having a sequence of levels of description for tokens, rang-ing from abstract to the observed strings, together with a set of models that govern the production of the more specific level from the more abstract. The abstract models consist of the erroneous or irrationally capitalized versions of correct strings.

Wong et al. [ 30 ] presented an integrated scoring model for preprocessing noisy text. Their system called ISSAC corrects spelling errors, expands ad-hoc abbreviations and restores cases. ISSAC makes use of six weights based on differ-ent information sources, namely original rank suggested by spellchecker program Aspell reuse factor, abbreviation fac-tor, normalized edit distance, domain significance and gen-eral significance. An enhancement of ISSAC was proposed in [ 31 ]where the left and right neighbors of a word were also taken into account to derive the scores.

Sentence boundary detection for speech transcripts is a well studied problem [ 10 , 16 , 18 ]. Most of these systems employ Hidden Markov Models (HMM) along with a set of lexical and prosodic features, learnt from a manually tagged training set.

Nasukawa et al. [ 22 ] presented a system which analyzes automatic speech recognition (ASR) data. ASR data are quite different in nature from blog text. The key challenge there was to detect sentence boundaries since punctuation sym-bols were missing. Identifying phonetic variants of words was also another challenge for this data. This work reported techniques to identify sentence boundaries using the pause information. The language model is built using opening and closing n-gram sequences of sentence units identified using the silence information in training data. Since this system is employed to extract typical noun phrases and verb objects, the aim of boundary detection was to improve the accuracy of POS tagging.

As is obvious from the above discussion, most of the work in pre-processing noisy text excepting the ones by Chieu and Ng [ 4 ] and Nasukawa et al. [ 22 ], has been done without tak-ing into account the application for which it is cleaned. None of these were evaluated for noisy text generated on the web, which poses its own challenge. The proposed system dif-fers significantly from the earlier works. The pre-processing methodology here is designed specifically targeted toward generating clean text suitable for opinion mining. 2.2 Sentiment analysis and opinion mining Opinion mining, which is at the crossroads of information retrieval and computational linguistics, aims at identifying opinions expressed within a document and also classify them. Classification could be aimed at identifying the opinion expressed as either positive or negative. Alternatively, the focus may be to identify the finer nuances of sentiment expressed like anger or hatred as opposed to simply clas-sifying it as negative.

Hatzivassiloglou and McKeown [ 11 ] proposed the use of a supervised learning algorithm to infer the semantic orien-tation of adjectives from constraints on conjunctions. They used a list of seed words to determine whether a sentence con-tains positive or negative sentiments. Turney [ 28 ] suggested an approach to extend this list using value phrases composed of six syntactic patterns. Similar to these two approaches, Yi and Nasukawa (2005) built a dictionary of polarity lexicons to extract sentiments from a sentence. Turney and Littman [ 29 ] hypothesized that terms with similar orientation tend to co-occur in documents. It proposed that the semantic orientation of a term can be estimated by combining a point-wise mutual information (PMI) measure of the term against some paradigmatic terms. Thus the semantic orientation of a phrase can be calculated as the mutual information between the given phrase and the word  X  X xcellent X  minus the mutual information between the given phrase and the word  X  X oor X . The mutual information is estimated by issuing queries to a search engine and noting the number of hits. Pavel [ 23 ] proposed the use of WordNet for opinion mining. Esuli and Sebastiani [ 8 ] proposed SentiWordNet, a lexical resource that assigns to each synset of WordNet three sentiment scores: positivity, negativity and objectivity.

Pang and Lee [ 24 ] proposed the use of SVM to classify subjective sentences by using distance measures between sentences as additional features. Dave et al. [ 6 ] proposed a machine learning-based technique for mining opinion from the web. The system is trained on structured reviews like those available on amazon.com to identify appropriate prod-uct features and also learn scoring methods for judging opin-ion orientations. The classifier is then used to identify and classify review sentences from the web. The system was thus applicable only to products for which structured reviews were available for training.

Hu and Liu [ 12 ], presented a more generic method for mining customer reviews for opinions on products. In this work, opinion mining was integrated with search. The task was to mine opinion and perform feature-based opinion sum-marization for a product from user-generated content or user-generated media on the Web. Product features were identified using a linguistic approach, where nouns and noun phrases were initially selected as candidate features. The candidate feature list is then subjected to association-rule mining to identify the frequently occurring features. The frequently occurring feature list is further pruned using compactness pruning. Opinion words are thereafter extracted by locating the nearby adjectives. The set of adjectives identified as opin-ion words are later used to identify infrequent but interest-ing features. This work was further extended in [ 13 ], where the opinions are presented in a summarized fashion along with their classification into positive or negative categories. The classification was done by utilizing the adjective syno-nym set and antonym set in WordNet to predict the semantic orientations of adjectives. The summarization task was dif-ferent from traditional text summarization and the aim was to only present an aggregate of features of the product on which the customers have expressed their opinions and indi-cate whether the opinions are positive or negative. In [ 19 ] Opinion Observer was proposed as a system for analyzing and mining comparative opinions from the web. This system was equipped with a visualizer that presented comparisons of multiple products in terms of summarized opinions on features of the products.

Popescu and Etzioni [ 25 ] presented OPINE, an unsuper-vised information extraction system which mines reviews in order to build a model of important product features, their evaluation by reviewers, and their relative quality across products. OPINE extracts opinion phrases , which are adjec-tive, noun, verb or adverb phrases representing customer opinions. Opinions could be positive or negative and vary in strength. The distinctive features of OPINE were its use of pointwise mutual information(PMI) function for feature assessment and incorporation of Web PMI statistics in addi-tion to review data in its assessment. OPINE used relaxation labeling to find the orientation of opinion words in a context-dependent manner. This system was claimed to have a higher precision on extracting and classifying opinion expressions though with a minor fall on recall value.

In [ 14 ], a method for identifying comparative sentences was presented. A comparative sentence usually expresses an ordering relation between two sets of entities with respect to some common features, and uses different language con-structs. The main mining task here was to identify com-parative sentences from texts and then extract comparative relations from them. This work is based on mining of fre-quently occurring sequential patterns from parts-of-speech (POS) tagged sentences. Two types of sequential rules were learnt. Class sequential rules (CSR) could identify sequences for classifying sentences, while label sequential rules (LSR) were learnt for feature extraction. Ding and Liu [ 7 ] propose a new opinion aggregate function which can classify opinion expressions within a sentence in a context-dependent manner. It proposes the use of intra-sentence and inter-sentence con-junction rules along with synonyms and antonyms to decide the opinion orientation of each expression.

Benamara et al. [ 1 ] proposed the use of adverb X  X djective combines (AAC) for sentiment mining from news articles. Adverbs were classified into five categories. Based on this classification, a set of general axioms were defined that were to be satisfied by all adverb scoring techniques. Scoring was based on axiomatic treatment of AACs based on the linguistic classification of adverbs. It was shown that sentiment min-ing using AACs correlate better with human judgment than adjective priority scoring.

Sentiment or opinion analysis has also been engaged for a host of other applications. OASYS, designed by Cesarano et al. [ 3 ], is one such system which provides a tool to accu-rately and quickly analyze opinion intensity on a particular topic from news sites on the web. In addition to finding a quantitative and qualitative rating, it shows how the level of opinion intensity changes over time and geographic loca-tion. Mei et al. [ 21 ] presented a computational approach to mine sentiments from social networking sites. Ghose et al. [ 9 ] proposed an altogether different methodology to measure the strength and polarity of an opinion. The idea here was to use the economic context in which the opinion is evaluated, instead of using human annotators or linguistic resources. The underlying assumption is that a product with more pos-itive opinions sells at a higher price than a product with neg-ative opinions. Thus the actual price of a product is used to assign opinion orientations.

Use of dependency grammars for extracting opinion from noisy text in Chinese Language was proposed by Qiu et al. [ 26 , 27 ]. This is a rule-based system, which performs topic extraction from opinion sentences through syntactic parsing of the sentences using the dependency grammar. It is stated that this technique outperforms machine learning techniques in high-level sentiment classification. Noise elimination for topic extraction is also discussed. The rules are designed to do contextual analysis based on sentiment words. However these rules do not take care of enhancing and reducing mod-ifiers that can alter the polarity or strength of opinion. The only modifiers considered are the negation modifiers.
It is obvious from the review that opinion mining and sentiment analysis has gained a huge momentum due to the proliferation of opinionated content on the web. A number of machine learning-based approaches have been proposed for the task, as also a wide array of techniques based on Nat-ural Language Processing. The works most similar to our approach are those reported by Qiu et al. [ 26 , 27 ] for Chinese text. However, they have not discussed the applicability of the rules for noisy text in English. The framework also did not take care of modifiers which are equally important for sentiment strength identification as the sentiment words themselves. Moreover, most of the earlier works on opinion mining have not addressed the issue of mining sentiment-related information from noisy text sources which contain errors of unprecedented types. Looking for known opinion words in such a text will not work if there are spelling errors. Grammatical errors, which are aplenty, can cause both dis-tance-feature-based machine learning algorithms and Natu-ral Language Processing techniques to fail. Most of these errors have to be corrected in a context-dependent manner in order to get meaningful results from these sources. Our work attempts to address this issue by looking at an inte-grated framework for opinion mining from noisy text, which first cleans the text in a context-dependent fashion, helps in building a domain-specific knowledge-base and then finally extract opinion words and opinionated features from them. Our work also stands out as a system which offers the facil-ity to expand the domain knowledge-base by extracting new phrases that satisfy known linguistic patterns as possible can-didates for inclusion into the domain dictionary. 3 Proposed framework for opinion extraction and mining from noisy text In this section, we present an overview of the various func-tional components of the proposed opinion mining system that can identify, evaluate and aggregate opinions from noisy text sources on the web. Figure 1 presents high-level software architecture of the proposed system.

The functionalities of each module are briefly described here.
 Data acquisition module  X  X  set of pre-defined web sites are crawled and the contents are stored using a pre-defined schema. Each individual blog entry is stored as a separate data element. All associated meta-data like author X  X  name, product name or brand name, if available, are also stored. A uniform structure is assumed for all blogs, with provi-sion for storing NULL values in various fields, since blogs are highly divergent in their structure. It is assumed that all blogs will contain content relevant to a particular domain. Creating knowledge-base for opinion mining  X  X pinion min-ing is a highly domain sensitive task. Though there are cer-tain generic principles that can work across domains, each domain may also have a collection of unique words and phrases used for expressing product features or opinions. For example, blockbuster is an opinion expression typically defining popularity and therefore positivity for movies, though rarely encountered in the same context for other dom-ains. Opinion orientation of a word may be context-sensitive. For example, in the context of vehicles, low price can indi-cate a positive opinion, while low performance indicates a negative opinion. Therefore, opinion mining systems need to be appropriately trained for a domain.

Keeping the above in mind, the proposed framework uses a knowledge-based approach where creation of the knowl-edge-base is human-assisted. The system is initially seeded with a set of generic words which is thereafter expanded with more words using WordNet. The system also learns patterns which are likely to be opinion expressions from the texts themselves. The system aids the knowledge-engineer by pro-actively presenting new information extracted from the content for validation. Once validated, the knowledge base stores opinion expression structures that contain opinion words and features learnt. Relevant linguistic information is extracted and stored as frequently occurring sequential paths of dependency relations in the knowledge base.
 Pre-processor for cleaning noisy text  X  X oisy text is pre-processed to identify sentence boundaries, correct improper casing, and correct spelling errors with effective utilization of domain knowledge. The cleaned text is stored along with the collected meta-data for each blog entry.
 Opinion expression identification and extraction  X  X he cleaned text is subjected to part of speech (POS) tagging, phrase structure extraction and dependency analysis. The phrase structure tree and the dependency relations are used to analyze the opinions. Opinion extraction and analysis is a knowledge-based activity. The system looks for frequently occurring knowledge-base patterns in the new data. During this process, the system also finds patterns that are similar but not a part of the knowledge-base and presents to the domain expert for validation, as described earlier.
 Opinion assimilation and aggregation  X  X uring this phase, the system employs domain ontology to assimilate extracted opinions and aggregate the information at multiple levels of specificity. This allows various functionalities like slice-and-dice and comparing of information.

The remaining sections present the functional details of these components in more details. 4 Preprocessing noisy text Due to the lack of any regulation on blog sites, users often do not use the formal structure of language while generating content. Spelling errors are abundant. Use of homonyms or similar sounding words is very common. Spelling errors, par-ticularly using the phonetic equivalent of a word is common. Arbitrary use of symbols is also very common. Natural lan-guage processing tools like parser and tagger fail to perform with high accuracy in the presence of these errors.
Based on these observations, the key pre-processing tasks identified are: Symbol cleaning X  X here irrational use of punctuation marks are removed. Sentence boundary detection X  X dentify logical breaks within text and introduce physical breaks Context-based spelling corrections X  X dentify erroneous words and replace them with most probable correct word. Figure 2 presents the high-level architecture of the pre-pro-cessing module. The operational details of each sub-module are discussed in the following sections. 4.1 Symbol cleaning Symbol cleaning identifies and removes irrational use of punctuation marks to ensure better parsing result. This also includes removal of symbols which appear due to encoding incompatibilities. Symbol cleaning is a two step process. For repetitive symbols as shown in the noisy sentence in Table 1 , the repetitions are removed using a rule base. If a symbol represents a valid punctuation mark like  X ? X ,  X : X , etc. in English language, only one instance of it is retained pro-vided it is not at the beginning of the sentence, else all such symbols are removed. Symbols which are not a part of the regular alphabet set or punctuation marks are removed. Users can create their own symbol dictionary based on inputs from the site. For example, the sentence in Table 1 has some sym-bols like  X = =20 X  that have crept in due to encoding problems while crawling this particular site. The system removes these symbols.

After removing repeated symbols, it also does a dictio-nary look up to see whether the two segments of characters immediately before and after these symbols are dictionary words or not. If not, then it is checked whether they together make up a word. If so, then the two fragments are merged, else the symbols are replaced by a blank space. 4.2 Sentence boundary identification Sentence boundaries are not obvious in noisy texts. Even when punctuation marks are used, incorrect usage like absence of a space after the  X  X eriod X  mark fuses two words before and after it to create one possibly non-dictionary entry. Consequently, multiple sentences get fused into one very big sentence ultimately causing a parser error. Simple loca-tion of punctuation marks like full-stop obviously does not work, since it is also overloaded as a decimal point or as an abbreviation indicator. Other punctuation symbols like ?, !, etc. are easier to use. Sometimes a single sentence is split over multiple lines and in this case the boundary identifier has to first merge the various fragments of the sentences before inserting the boundary.

We have implemented a Rule-based system to identify log-ical sentences and introduce sentence boundaries. The rules used are stated below: Splitting : The presence of the symbol  X . X  is treated as a sen-tence boundary provided it is not preceded by a pre-defined set of words like {Prof., Org., Pvt., Ltd., Gov.}, etc. To tackle arbitrary abbreviations, a list of valid  X  X mall words X  like {at, in, on, ok}, etc. is also maintained. Dictionary words of two or fewer characters are considered as valid small words. This allows the system to recognize unknown abbreviations cor-rectly and ignore the  X . X  that appears as a part of these abbre-viations. It is also ignored if it appears within or immediately after digits and does not follow space characters. In all other cases, the symbol  X . X  is used as a sentence boundary identifier and a space is inserted between the two sentences.
 Merging : Since sentences are expected to start with upper case letters, capitalization provides the most important cue for sentence breaks. If a line starts with a lower case alphabet and the previous line does not end with a valid punctuation symbol then the two lines are considered as candidates to be merged. Merging is followed by one of the two actions listed below Mergerule1 : When a new line starts with a lower-case non-dictionary word fragment, it is checked whether merging it with the last word of the last sentence creates a dictionary word or not. If it does then these two words are merged into a single word and the contents of the two lines are merged to create a sentence.
 Merge rule 2 : When a new line starts with a dictionary word, the two lines are merged with a blank inserted between them. Noisy texts are prone toward erroneous character cases. Sometimes the entire text is written using only upper or lower case. In this case, the system ensures that only known entity names and the first character of a sentence are in upper case. Remaining text is re-written in lower case. 4.3 Context-based spelling correction Opinion mining to a large extent depends on locating opin-ion words and analyzing their relationship to the surrounding text. Erroneous spellings are the biggest hindrance to mining opinions correctly from text. If an opinion word is errone-ously spelt then it may be missed by the opinion extraction module. On the other hand, if an opinion feature is erro-neously spelt then it may lead to incorrect aggregation and compilation.

Several applications use basic spell suggester library for spelling correction. We observed that context-based spell-ing correction works best for an application such as opinion mining, since additional information about the domain can provide better suggestions. This is explained through the fol-lowing examples. Consider the three sentences given below: The car is a real beuty .
 I haven X  X  had any problem with the vehicle suspension so far and still loocin good The car is very bed .
 In the first sentence, the word  X  X eauty X  is mis-spelt and an opinion extractor without a spell correction facility will fail to recognize it correctly. While spell suggester correctly rec-ognizes this, it fails to recognize the work  X  X ooking X  correctly in the second sentence. Spell suggester suggests  X  X oin X  as the replacement word, since it uses a generic distance measure based on number of transformations required to reach a cor-rect dictionary word and not the context. The word that can be reached with the minimum number of transformations is ranked one and is suggested as the best alternative for the wrongly spelt word. The other problem that Spell Suggester cannot deal with is erroneous use of word as shown in the third sentence. Since  X  X ed X  is a dictionary word it is not iden-tified as an error.

We propose an enhancement of Spell Suggester, where the best suggestion for an erroneous word is picked up after con-sidering the neighboring words as its context. The proposed methodology uses a weighted approach, where the Spell Sug-gester ranks are used in conjunction with the occurrence probability of the suggested word within its two neighbors. The occurrence probabilities of the words, bigrams and tri-grams are computed using a-priori probabilities from training samples. Training samples are selected from regulated text like newspaper reports, journals and magazines. All com-mon words like the stop words, which usually have very high frequencies, are set to have the same high frequency (MAX_FREQ).

Using the proposed methodology, each word is verified for correctness, even if it is a dictionary word. For each word w t in the text, its left and right neighbors termed as LEFT_WORD and RIGHT_WORD respectively, are extracted. A dictionary word w d is thereafter considered as a replacement for w t based on the probability of the trigram (LEFT_WORD, w d , RIGHT_WORD) and the similarity between w t and w d . For each application, a list of proper nouns is also used, if available. This ensures that non-dictionary words which represent entities in a domain are not changed to dictionary words.

Figure 3 presents the proposed algorithm for spelling cor-rection. Let us explain the algorithm with the sentence  X  X he car is very bed X . The two grams obtained for the above sen-tence are {the car, car is, is very, very bed} and the three grams are {the car is, car is very, is very bed}. For each word R obtained from the text, the system first obtains the spell suggester suggestions as a list of probable dictionary words and their ranks. For a dictionary word, the word itself would be at the highest rank. The system now considers the possi-bility of each of these words by replacing the original word in the bigrams and trigrams by the suggested word and looking up for their domain frequencies. These weights are combined in step 6. The word for which the highest weight is attained is returned as the correct word. For the word though  X  X ed X  itself is initially the highest ranked word, based on a priori probabilities extracted from training data, the probability of  X  X ery bed X  is much lower than  X  X ery bad X , thereby leading to the right correction. 5 Creating opinion knowledge base using a semi-automated approach The knowledge base contains knowledge about opinion words and their orientation with respect to a domain. It also contains information about entities, brands, features and any other relevant domain attributes that may be required for opinion assimilation and aggregation. The system is initially provided with a seed list of opinion words extracted from tagged training texts. This list is then enhanced automatically using relevant dictionaries. During training, the system also learns linguistic structures which typify opinion expressions. The acquired knowledge is stored as a collection of rules that encode linguistic patterns of interest within a domain. These rules help in identifying new opinion words and fea-tures from both training and test data. The new opinion words are validated by experts for enhancement of the knowledge base. Domain-specific entities and features are stored using domain ontology. 5.1 Learning opinion words Opinion words are usually categorized into positive and neg-ative categories. However, rather than identifying all opinion words as uniformly positive or negative, we associate weights to these words, such that the weights reflect their degree of positivity or negativity. One of the unique aspects of this work is to also include in the framework a category of words that modify the strength of opinion when associated with an opin-ion word. For example, consider the following sentences:  X  X his is a good car X   X  X  am absolutely satisfied with the machine. X  Clearly, while the first sentence states a positive opinion about a product, the second sentence conveys a larger degree of positivity about a product.

In order to capture this aspect, we have identified two categories of words that are important to opinion mining X  opinion words and modifiers. Modifiers can be further cate-gorized into three categories X  X nhancers, reduces and nega-tion modifiers. All the four classes are defined below: Opinion words  X  X ords that can independently express some opinion. These words are associated with two weights that describe their memberships to the categories positive and negative.
 Enhancers  X  X hese words appear within a text in conjunction with an opinion word and increase the positive or negative membership of the opinion word. Sample words belonging to this category are extremely , very , etc. Thus the phrase  X  very happy with the car  X  will indicate a larger degree of positive opinion than  X  happy with the car  X , and the phrase  X  extremely poor performance  X  would convey a larger degree of negative opinion than  X  poor performance  X .
 Reducers  X  X educers constitute a class of words that reduce the impact of the opinion expressed by an opinion word. Words in this category include  X  only  X ,  X  slightly  X , etc. Thus the negative strength expressed by  X  slightly bad taste  X  is less than that of  X  bad taste  X , while the positivity of  X  slightly better performance  X  is also less than that of  X  better perfor-mance  X .
 Negation words  X  These words reverse the opinion polar-ity altogether.  X  Not  X  and its variants fall under this category. Recognizing negation words is a crucial task since failing to recognize these words would obtain results that are opposite to the opinion expressed. For example, the sentence  X  X his car is hassle free X  expresses a positive opinion, though the word  X  X assle X  is a negative opinion word. The system has acquired a set of words like  X  free , remove , never  X , etc. under this category.

The role of a word in a sentence can be disambiguated only from the context. For every opinion word encountered, the algorithm checks for all related modifiers recursively. For every opinion word, the longest chain of dependency rela-tions involving modifiers is considered for opinion scoring. This ensures that when a word has potential to be either an opinion word or a modifier, its role is verified in the context of the sentence before opinion assignment.

The proposed system stands out from the earlier works in providing a formal framework for handling the enhancers and reducers. We have used a framework similar to hedge algebra used in fuzzy logic for computing the strengths of opinion words in association to modifiers. Although [ 1 ] had considered a similar framework for adjectives and adverbs, it may be noted that in our framework, opinion words and modifiers are not restricted to be adjectives and adverbs only. The proposed framework can address a wider range of mod-ifications and thereby assign correct opinion orientation.
It is also observed that each domain usually has some opinion phrases that occur with high frequency. Since these are usually domain-specific, the system also extracts all fre-quently occurring bigrams and trigrams and incorporates them into the knowledge base after human supervision. This enables the system to learn typical phrases like  X  worth the money  X  X r X  over the top  X , etc.

The next section presents how an expanded knowledge base is built starting with a small training set. 5.2 Word expansion algorithm The system is bootstrapped with a small set of words in each of the four categories described above. These words are selected from among a set of most frequently occurring words in the training set. To select a good initial seed set, we have used words extracted from both clean text sources like expert reviews and noisy text sources like user blogs.
The root opinion words are expanded to identify a larger set of opinion words, using Princeton Wordnet 2.0 1 .Anew algorithm has been developed for this purpose. An intelligent implementation has been done to extract a large set of opinion words efficiently, with both time and memory requirements optimized.

The algorithm includes new words in an iterative fash-ion. At each step the new words are chosen from among the synonyms of already included words. For each seed word, the probability of its synonyms to be also included into the seed list is computed. Wordnet can identify different senses of the same word. Accordingly, it can determine synonyms of a given word in various senses. A sense S of a given word is a collection of its synonyms used in that sense. The proba-bility of a new synonym belonging to a particular category is dependent on the number of senses in which it overlaps with the total set of words found in that category.

For each word p in the initial seed set A , its synonyms are obtained using WordNet. Let n denote the total number of senses in which the word p is used. Let S i , denote the set of synonyms obtained for sense i , where i varies from 1 to n . The entire set of words in S i is included in the expanded list, if a pre-defined fraction of S i is already part of the seed set A . While computing the overlap between S i and A ,aword w belonging to S i is assumed to be a member of A , if either or a pre-defined fraction of its synonyms are already included in A . The initial word set A is updated to A  X  S i . Figure 4 explains the rationale of the algorithm.

Since a single word may belong to multiple senses, the overall weight of a word to a category is computed as fol-lows: Prob (w) := ( no. of matched senses of w / total no. of Expansion of list of enhancers, reducers and negation words also follow same principle, but are assigned only one weight. This weight is used in conjunction with weights of the opin-ion words when they co-occur with them.

In spite of the human efforts and dictionary-based expan-sion, new words are regularly encountered in any applica-tion, which are either opinion words or opinion modifiers, but whose opinion orientation are not known a priori. Such words are recognized by the system due to the similarity in linguistic constructs within which they are observed in the text. When any new word appears frequently enough within the text, it is selected as a candidate for inclusion into the knowledge-base. Since these words are selected based on their linguistic properties, each word is considered to belong to either of the two broad categories X  opinions or opinion modifiers . To find the right sub-category of a word, the same expansion algorithm is now applied though in a reverse direc-tion. All synonyms of the candidate word are obtained from the Wordnet. The degree of overlap of the synonym set with the existing sets of words in each category is used to deter-mine its strength of opinion orientation.

Since documents may also contain words in different forms, WordNet is also used to derive alternate morpholog-ical forms of the word. For example, when the word  X  X at-isfied X  is encountered by WordNet as an opinion word, its alternate forms like  X  satisfied, satisfactory, satisfactorily  X  X re also included in the knowledge base. The above procedure is applied repeatedly to the enhanced set till a certain depth of the Wordnet dictionary is traversed. Figure 5 states the algorithm.

The system has an option for the final knowledge base to be verified by a domain specialist. We present a few inter-esting cases which convinced us to take this semi-automated approach. Using a sample set of generic opinion words like  X  good, great  X , etc. the expansion algorithm had learnt the word nifty with some amounts of positive and negative ori-entations. However, when the system was applied for Indian Stock Market News Analysis, the word had to be eliminated from the knowledge base since NIFTY is the name of an index in this domain. Another word that had to be eliminated through manual inspection was due, which was included as a result of expanding the word outstanding . A word that could not be found through expansion and had to be added manu-ally was blockbuster . Certain phrases like  X  flying colors  X , etc. were also added to the knowledge base. Domain-dependent tuning is also possible through this interface. For example, the word hit as a verb, has negative orientation. However, as a noun, it has a positive orientation. 6 Identifying opinion expressions and opinionated features using typed dependencies Opinion mining consists of three sub-tasks (a) identification and extraction of opinion expressions from text (b) analyz-ing opinion expressions to extract opinionated features and (c) determine orientation of opinion expressions. The most difficult among these is the task of identifying the features that are being opinionated about. The difficulties arise due to the fact that the opinion and the opinionated feature may be related by complex linguistic relationships. As stated ear-lier, simple distance-based analytics like looking for features within a specified neighborhood of the opinion word fail to identify the features correctly. The challenge is therefore to learn the complex linguistic patterns that characterize rela-tionships between opinion words and opinionated features.
In the proposed framework, opinion expressions are first extracted from within text using a mix of key-word spot-ting and linguistic techniques. Linguistic analysis is directed toward associating opinion words with opinionated features. Though opinion is primarily expressed through key-words, locating the key-word is not enough. A correct orientation of an opinion expression can only be established after a com-plete relationship analysis of the related concepts in the sen-tence. The aim of the system is to output three-tuples of the form &lt; feature, opinion, orientation &gt;.

Let us consider the following sample sentence extracted from a blog which carries user reviews of cars X  X  X EAG-TIVES Very few X . After cleaning, the opinion word identified is NEGATIVE, which would tend to assign a negative orien-tation to the sentence. However, it is obvious that the overall orientation should be positive, since the opinion expression states that there are few negatives. The correct output in this case should be reduced negativity.

To achieve this, opinion, in the current framework com-prises two parts X &lt; opinion words, opinion modifiers &gt;. Modifiers can be enhancers, reducers or negation words, as explained in the earlier section. The overall opinion orien-tation is done using dependency analysis between opinion words and their modifiers in a sentence. For example, in the above citation,  X  X EGATIVE, very few X  X  X ependency anal-ysis yields that NEGATIVE is the key opinion word, which is modified by the word  X  X ew X  which is further modified by the word  X  X ery X . The overall opinion orientation computation for this proceeds as follows: Step 1 : NEGATIVE  X  Structure is negative with strength N = 1 in this case.
 Step 2 : Operator few is a reducer that operates on NEG-ATIVE, thereby reducing the strength N . N is reduced to N F (say).
 Step 3 : Operator very is an enhancer that operates on few , so enhances effect of few . Thus N F is further reduced to N Result : Overall negativity is less than 1.
 The relationship between opinion words and their modifi-ers are learnt as linguistic rules through frequent sequen-tial pattern mining . The frequent patterns are mined over dependency trees output by a Natural Language Parser , and stored as linguistic rules. A natural language parser is a program that works out the grammatical structure of sen-tences, and identifies groups of words that go together as phrases . It can also identify with reasonable accuracy the subject or object of a verb. Probabilistic parsers use knowl-edge of language gained from hand-parsed sentences to try to produce the most likely analysis of new sentences. In this project, we have used the Stanford Parser version 1.6.1 which is available at ( http://nlp.stanford.edu/software/lex-parser.shtml ). The Stanford Parser takes plain text documents as input and produces three types of output for each sentence  X  X he tagged text in which every word of a sentence is tagged with its POS tag, the phrase structure tree that groups the words of the sentence that should be interpreted together, and a set of dependency relations which are binary in nature and specifies grammatical relationship between two words in the sentence. Dependency relations given by Stanford Parser are in the format rel(governor, dependant) where rel is a known dependency relation. There are altogether 48 relations that are output by Stanford Parser [ 17 ]. Typed dependencies are produced from dependency relations and the phrase struc-ture tree using rules or patterns. In case of Stanford Parser, these rules have been learnt using the Penn Tree Bank, and does reasonably well for imperative sentences. The typed dependencies define a tree structure over the sentence as shown in Fig. 6 , which shows sample outputs obtained for a sentence.
Opinion expression identification and analysis is a four-step process as explained below.
 Step 1 : Sentence processing  X  X ach cleaned sentence is tagged and parsed using the Stanford Parser.
 Step 2 : Find opinion words  X  X pinion words are located using key-word spotting. Key-word spotting refers to the task of locating known opinion words within input text.
 Step 3 : Opinion expression identification  X  X n appropriate phrase that subsumes the opinion key-words is identified. An appropriate phrase could be a nested or non-nested grammat-ical phrase output by the phrase structure tree. Since we work pre-dominantly with noisy text, we cannot assume perfectly correct text inputs. Thus the system is trained to work with only those structures that are most likely to be found even within noisy text. The most relevant structure in this context is found to be the nested and non-nested Adjective Phrases containing noun phrases and adverbs. The second most com-monly encountered phrase structure is the Verb Phrase. The choice of the most appropriate phrase is guided by rules. Using phrases for opinion expressions rather than sentences improves the accuracy of opinion mining from blogs, which often contain improperly constructed sentences.
 Step 4 : Opinion feature identification  X  X pinionated features are finally identified using dependency analysis. It is found that local dependencies of words are identified with more accuracy by the parser than a complete structural analysis for probable sentences. Given a training corpus with annotated opinion expressions, the system learns the most frequently occurring sequential patterns of dependency relations bet-ween opinion words and opinion features by analyzing the typed dependencies. A pattern in this case refers to a series of dependency relations that can be traced between the opinion word and the opinionated feature within an annotated text. The types of dependencies important for opinion analysis are mod and ccomp relations along with their descendants. The neg relation is a descendent of the mod relation. It spe-cifically indicates the presence of a negation modifier. The most frequently repeated patterns are learnt as rules. The rules extracted can be at multiple levels of specificity. These rules are learnt using a Decision Tree. Figure 7 shows the rules that have been learnt for associating opinion features to opinion adjectives, and also extraction of opinion features from adjective and verb phrases. For adjective phrases, the dependencies considered mostly involve analysis of the mod-ifier relation. When opinions are expressed using verbs, the key task is to find the subject or the object of the verb, which is the required feature. The class of the verb dictates whether the subject or the object is to be extracted. In the current framework, verb classes and their relationships to subject and object have been extracted using VerbNet. 2 If the gover-nor is an opinion verb, the dependent represents the desired feature. The dependency relations used to identify the depen-dent on the governing opinion verb, are also given in Fig. 7 , along with examples.
 Step 5 : Opinion strength assignment  X  X ach opinion expres-sion is assigned opinion strength. The combined strength of all opinion expressions is assigned to the sentence. Assum-ing that an opinion expression E contains an opinion word w , which is linked to a modifier word m , the positive and negative scores for this opinion expression is computed as follows.

Let us suppose positive score of w is P W and negative score is N W .

If the modifier word m is an enhancer then positive score of expression E is given by P W ( 1 + W m ) and negative score of E is given by N W ( 1 + W m ) , where W m is the weight of the modifier word.

If the modifier word m is a reducer then positive score of expression E is given by P W /( 1 + W m ) and negative score of E is given by N W /( 1 + W m ) , where W m is the weight of the modifier word.

If the modifier word m is a negation word then positive score of expression E is given by N W  X  W m .

Figure 8 describes the entire process of opinion expression extraction and opinion strength computation. 7 Aggregation and assimilation of opinion For any real application, listing the opinionated features and opinion strengths is not enough. Given the multitude of blog sites where users are posting their opinion about products, marketing researchers need to assimilate and analyze opin-ions collected from these sites. We now present a mechanism to aggregate opinions about features and products at multiple levels of specificity.

It may be observed that a feature can be mentioned in different ways within free form text. For example, in the domain of vehicles, opinionated features like  X  good mileage , high fuel efficiency , gives good average  X , etc. all refer to the basic feature  X  mileage  X . Our system is capable of integrating a domain-specific ontology to aggregate feature level opin-ions. For any given application domain, this ontology can be crafted by domain experts or learnt through text mining.
At present, the ontology is built through WordNet-based expansion for a seed set. The seed set is expanded to include synonyms, hypernyms, hyponyms, meronyms and co-ordinate terms of seed words. The ontology is stored in OWL. 3 The ontology specifies part-whole, attribute-value and class X  X ubclass relationships among domain components. The leaf level nodes of the ontology contain dictionary words that are mapped to the higher level feature nodes.
The proposed opinion mining system has been developed in JAVA as a web application. The system can be tuned to work on different products with appropriate domain ontology plugged in. The system crawl documents from pre-defined web sites. This can fetch the actual review or feedback text from some widely used websites. Opinionated features and opinions are then extracted at different levels of granular-ity. Sample features identified from the corpus are [happy owner], [good mileage], [hard gear], [heavy braking], [good pickup], [worse interiors], etc. Summarization at the level of a product is similarly obtained by aggregating opinions about all features. Summarization at brand level, repository level, or site levels are also done in a similar way.

Table 2 shows some sample feature expressions that were collected from blogs on cars. The weights indicate normalized collective positive and negative opinion about each feature. It also shows how to aggregate these features to a core set of three features. The opinion orientations are also suitably summarized.

Producing results is not enough, unless these can be visu-alized effectively. Users interact with the system through a Graphical User Interface. Figures 9 , 10 and 11 illustrate some screen shots to depict how the opinion mining system is being used for analyzing user views on cars. Figure 12 shows the same system being implemented for analyzing user views on movies. As is obvious, the underlying principles of the system remain same, though visual interface changes based on the product, features and usage. 8 Evaluation We now provide results that highlight the system X  X  perfor-mance in terms of the following capabilities:  X  Identifying opinion words and their orientations using  X  Domain-dependent cleaning of noisy text  X  Identifying opinion expression including opinion words,  X  Opinion orientation assignment.

All scores presented for noisy text are based on manual evaluation of the corpus done by a team of researchers not involved with this work. This was done to ensure unbiased evaluation.

Table 3 presents the performance of the Word Expansion algorithm employed to build the opinion knowledge base. The knowledge base was initialized with a seed set of 25 words. Each seed word belonged to exactly one category positive or negative, with membership 1. The seed set was then expanded using WordNet and a total of 583 words were identified as opinion words, of which 552 were found to be accurate. After expansion, a word may have both positive and negative weights.

Performance of the Context-based Spelling Correction module for noisy text cleaning is presented in Table 4 . Performance evaluation has been done over 3,250 sentences collected from movie and car blogs. After symbol cleaning, sentence merging the system initially identified 1,049 tri-grams as possibly erroneous. These were the ones which had a non-dictionary word at middle. The context-based spell checker identified 770 of these words as domain entities, which resulted in an accuracy of 97%. In the remaining 279 trigrams, 236 words were replaced correctly by the top-most suggestion made by the system in a context dependent way. The total number of trigrams which could not be treated cor-rectly is 69, thereby incurring an error of 6.5%. Table 4 sum-marizes these results.

We now present results to evaluate the performance, the opinion extraction and mining algorithms. Results are pre-sented for two different collections. The first set comprises blog content of 134 customer feedbacks taken from http://www.indiacar.com for 10 models of car. Human eval-uators identified a total of 1,043 opinion expressions within 516 sentences in these blogs. Among 134 feedbacks 88 were judged by human evaluators as overall positive, 39 were tagged as overall negative and 7 were labeled as neutral.
Our aim was to evaluate the capability of the system to cor-rectly recognize opinion sentences and also assess the over-all positivity or negativity of opinion. Tables 5 and 6 present the confusion matrices for opinion orientation assignment at sentence and feedback levels, respectively. It is observed that the accuracy of opinion orientation at blog level is much higher compared to that at sentence levels. A closer look reveals that while the system performs quite well in recogniz-ing positive and negative sentences, most of the errors involve neutral sentences. This is possible since the system was not trained to recognize neutral expressions. Since all blogs def-initely contain more opinionated sentences than neutral sen-tences, this error is not reflected at the blog level. It was also observed that recognizing negative opinion was com-paratively tougher. Table 7 presents summarized results for accuracy of opinion extraction at various levels (sentence, feedback) considering only positive and negative sentences.
Table 8 presents the performance of the proposed system for opinion assignment on customer review data set available at the website http://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html . This data set has been used by various ear-lier works for reporting their system performances. It can be seen from Table 8 that our approach shows higher accuracy in both opinionated sentence identification and sentence ori-entation assignment. These data were comparatively cleaner to the data that we had collected from the blog sites.
Table 9 presents the results for feature extraction for the two datasets presented earlier. In the customer review data set, a sentence is tagged with the features about which opinion has been expressed in the sentence along with an intensity value indicated by number of plus or minus signs associ-ated with it. We have not used the intensity values directly for comparison. For the customer review dataset the features extracted by the system cannot be always matched directly with those in the dataset, since some features are implicit. In order to compare the results, the system had to employ addi-tional reasoning. Some features are automatically identified and matched with manually tagged features. Some needed anaphora resolution, while some features could be matched after normalizing words (morphing), synonym mapping or ontology-based resolution. Popescu and Etzioni [ 25 ] had reported overall precision and recalls of 0.79 and 0.80 for opinion phrase extraction for a sub-set of 550 sentences from this dataset. A detailed comparison is not possible with this work since the sentences used are not known. Table 9 shows that in general our system performs better.

It may be noted that the performance of the proposed sys-tem is better for the car domain, since our system has been trained with high volumes of car blog data, all of which was not used for evaluation though due to difficulty of human tagging. 9 Conclusion In this paper, we have presented an opinion mining system that can extract opinions about products and features from noisy texts like blogs, emails, online customer feedback, etc. The key challenge to mine opinion from blogs is posed by the fact that the text is noisy. We have proposed a text pre-processing mechanism which exploits domain knowledge to clean the text. The cleaned text is then processed by Natural Language Processing tools. We have also proposed an iter-ative approach to integrate new knowledge into the system. The system is designed to operate in a semi-automated fash-ion where it presents new information related to the domain pro-actively to the knowledge engineer for validation. It can be thus tuned easily for different domains. The system uses a plugged -in domain ontology to aggregate opinions at differ-ent levels of specificity from pre-defined web sites. Opinions can be also viewed at multiple levels of granularity based on user requirement.

We have presented novel algorithms to determine orien-tation of opinion words using Wordnet. We are currently working toward increasing the scope of opinion expression identification. We are also enhancing our system to learn con-text-dependent opinion orientations from a training set. For example, a word like  X  comfortable  X  can always be judged as having positive orientation independent of domain or context. However, words like  X  big, small, etc.  X , cannot be classified as  X  X ositive X  or  X  X egative X  in a context independent way. In a sentence like  X  the screen is small for the camera  X , small should be interpreted to have a negative connotation. How-ever, when it is mentioned  X  the camera is small enough to fit into the pocket  X , it should be interpreted to have a positive connotation. This can be done provided the system learns that  X  big  X  is desirable for  X  screen  X  X ut X  small  X  is desirable for  X  size  X , when it comes to the domain of camera. Rein-forcement learning principles are being incorporated into the framework to learn such modifiers.

The natural extension of opinion mining is to mine percep-tions or implicit moods from the text. This has a lot to do with identifying contradictions, sarcasms, comparisons and so on. We are exploring incorporation of advanced techniques for combined analysis of perceptions from multiple related blog entries.
 References
