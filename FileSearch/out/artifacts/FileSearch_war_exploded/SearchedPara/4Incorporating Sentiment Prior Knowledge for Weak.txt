 Sentiment analysis aims to understand subjective information such as opinions, atti-tudes, and feelings expressed in text. It has become a hot topic in recent years be-cause of the explosion in availability of people X  X  attitudes and opinions expressed in social media including blogs, discussion forums, tweets, etc. Sentiment analysis found its way into a wide range of applications for tracking companies reputations, finding customers opinions about products/services and competitors, monitoring positive or negative trends in social media, etc.

The rapid evolution of user-generated content demands sentiment analysis tools that can easily adapt to new domains with minimum supervision. Most prior work [Blitzer et al. 2007; Choi et al. 2005; Kim and Hovy 2004; Narayanan et al. 2009; Pang and Lee 2004; Pang et al. 2002; Zhao et al. 2008] views sentiment classification as a text classification problem where an annotated corpus with documents labeled with their sentiment orientation is required to train classifiers. As such, they lack portability across different domains.

Instead of using labeled documents for sentiment classifier training, there has been growing interest in exploring labeled words or labeled features as supervision informa-tion to classifier learning. For example, the word  X  X xcellent X  typically conveys positive sentiment. In recent years, much effort has been devoted to incorporate prior belief of word-sentiment associations from a sentiment lexicon into classifier learning by com-bining such lexical knowledge with a small set of labeled documents [Andreevskaia and Bergler 2008; Li et al. 2009; Melville et al. 2009].

This article proposes weakly-supervised approaches based on latent Dirichlet al-location (LDA) [Blei et al. 2003] for sentiment classification by incorporating lexical knowledge obtained from available sentiment lexicons 1 .Weproposetwopossibleways in incorporating sentiment prior knowledge into LDA model learning, one is by modify-ing the Dirichlet prior for topic-word distribution (LDA-DP), the other is by augment-ing the model objective function through adding terms which express preferences on expectations of sentiment labels of the lexicon words using generalized expectation cri-teria [McCallum et al. 2007] (LDA-GE). The proposed approaches perform sentiment analysis without the use of labeled documents. In addition, it is simple and compu-tationally efficient; rendering them more suitable for online and real-time sentiment classification on the Web.

The major contribution of this work is twofold.  X  We proposed two principled approaches in incorporating prior knowledge into LDA model learning, LDA-DP and LDA-GE, and derived efficient training and inference procedures for LDA-DP based on Gibbs sampling, and for LDA-GE based on varia-tional Bayes. While this article mainly focuses on exploring sentiment prior knowl-edge, the proposed approaches can be used in more general settings where prior classes of certain terms are known.  X  We compared the performance of LDA-DP and LDA-GE extensively on both English and Chinese review data, including English movie review, multi-domain sentiment dataset, and Chinese product reviews on mobile phones, digital cameras, MP3 play-ers, and monitors. The results show that our methods attain comparable or better performance than other previously proposed weakly-supervised or semi-supervised methods for sentiment classification despite using no labeled documents. In addi-tion, we observed that LDA-GE is more effective than LDA-DP, suggesting that it should be preferred when incorporating prior knowledge into the topic model.
The rest of the article is structured as follows. Related work on weakly super-vised and semi-supervised sentiment classification are discussed in Section 2. The LDA model is introduced in Section 3. The proposed LDA-DP and LDA-GE are presented in Section 4 and 5 respectively, followed by a toy example illustrated in Section 6. The experimental setup and results are discussed in Section 7 and 8. Finally, Section 9 concludes the article and outlines directions for future research. Turney [2002] first proposed a sentiment classification approach that does not require labeled data. He calculated the semantic orientations of phrases in documents that contain adjectives or adverb as the pointwise mutual information (PMI) with a positive prototype  X  X xcellent X  minus the PMI with a negative prototype  X  X oor X . His approach achieved an accuracy of 84% for automobile reviews and 66% for movie reviews. While Turney only used one polarity prototype for each class ( X  X xcellent X  and  X  X oor X ), Read and Carroll [2009] chose seven polarity prototypes which were obtained from Roget X  X  Thesaurus and WordNet and selected based on their respective frequency in the Giga-word corpus. They then measure the similari ty between words and polarity prototypes in three different ways, lexical association (using PMI), semantic spaces, and distribu-tional similarity. Still the best result was achieved using PMI with 69.1% accuracy obtained on the movie review data.

Weakly supervised sentiment classification approaches do not require labeled docu-ments, instead, they use supervision information either from sentiment lexicons con-taining a list of words marked as positive or negative, or from user feedbacks. Lin and He [2009] proposed a joint sentiment-topic (JST) model to model both sentiment and topics from text and they incorporate sentiment prior information by modifying condi-tional probabilities used in Gibbs sampling during JST model learning. Dasgupta and Ng [2009] utilized user feedbacks in the spectral clustering process to ensure that text are clustered along the sentiment dimension. Features induced for each dimension of spectral clustering can be considered as sentiment-oriented topics.

Other weakly supervised sentiment classification approaches typically adopt the self-training strategy. Zagibalov and Carroll [2008a, 2008b] start with a one-word sentiment seed vocabulary and use iterative training to gradually enlarge the seed vocabulary by adding more sentiment-bearing lexical items based on their relative frequency in both the positive and negative parts of the current training data. Sentiment direction of a document is then determined by the sum of sentiment scores of all the sentiment-bearing lexical items found in the document. Instead of using a one-word seed dictionary as in Zagibalov and Carroll [2008b], Qiu et al. [2009] proposed to start with a much larger HowNet Chinese sentiment dictionary 2 as the initial lexicon. Documents classified by the first phase are taken as the training set to train the SVMs which are subsequently used to revise the results produced by the first phase. Tan et al. [2008] proposed a combination of lexicon-based and corpus-based approaches that first labels some examples from a given domain using a sentiment lexicon and then trains a supervised classifier based on the labeled ones from the first stage.

There have also been work combining labeled documents with lexical prior knowl-edge obtained from sentiment lexicons. For example, Andreevskaia and Bergler [2008] integrate a corpus-based classifier trained on a small set of annotated in-domain data and a lexicon-based system trained on WordNet for sentence-level sentiment annota-tion across different domains. Li et al. [2009] employ lexical prior knowledge for semi-supervised sentiment classification based on non-negative matrix tri-factorization, where the domain-independent prior knowledge was incorporated in conjunction with domain-dependent unlabeled data and a few labeled documents. Melville et al. [2009] also combine lexical information from a sentiment lexicon with labeled documents where word-class probabilities in Na  X   X ve Bayes classifier learning are calculated as a weighted combination of word-class distributions estimated from the sentiment lexi-con and labeled documents respectively.

Outside sentiment classification, much recent work has been conducted to explore labeled features in model learning without labeled instances. For example, some approaches use human annotated labeled features to generate pseudo-labeled ex-amples that are subsequently used in standard supervised learning [Schapire et al. 2002; Wu and Srihari 2004]. Druck et al. [2008] proposed training discriminative probabilistic models with labeled features and unlabeled instances using generalized expectation (GE) criteria. Labeled features can come from human annotations or through unsupervised feature clustering with latent Dirichlet allocation (LDA). For LDA-generated features, the feature labels are generated by an oracle which assumes the availability of labeled instances. These soft constraints are then expressed as GE criteria.

Incorporating supervised information into LDA model learning has been studied in Blei and McAuliffe [2008], Mimno and McCallum [2008], Lacoste-Julien et al. [2008], and Ramage et al. [2009]. Blei and McAuliffe [2008] proposed supervised LDA (sLDA) which uses the empirical topic frequencies as a covariant for a regres-sion on document labels such as movie ratings. Mimno and McCallum [2008] proposed a Dirichlet-multinomial regression which uses a log-linear prior on document-topic distributions that is a function of observed features of the document, such as author, publication venue, references, and dates. DiscLDA [Lacoste-Julien et al. 2008] and Labeled LDA [Ramage et al. 2009] assume the availability of document class labels and utilize a transformation matrix to modify Dirichlet priors. DiscLDA introduces a class-dependent linear tra nsformation to project a K -dimensional ( K latent topics) document-topic distribution into a L -dimensional space ( L document labels), while Labeled LDA simply defines a one-to-one correspondence between LDA X  X  latent topics and document labels.

In contrast to the aforementioned methods, our proposed approaches incorporate sentiment prior knowledge by either modifying the Dirichlet prior for topic-word dis-tributions or augmenting the LDA objective function through adding the generalized expectation criteria terms, and essentially create an informed prior distribution for the sentiment labels. Latent Dirichlet Allocation (LDA) [Blei et al. 2003] is a generative probabilistic model which is widely used in document analysis. It models the semantic relationships be-tween words based on their co-occurrences in documents. It is based on a Bayesian model where each document is modeled as a mixture of latent topics, and a topic is a discrete probability distribution that defines how likely each word is to appear in a given topic. For example, an LDA model might have topics that can be clas-sified as A CADEMIC and G AME . We would expect the A CADEMIC topic has higher probabilities of generating words such as university, research, professor etc. And the G
AME topic more likely generates words such as play, score, points etc. Words with-out special relevance, such as computer , will have roughly even probability between classes.

LDA can be illustrated with the graphical model as shown in Figure 1(a). We use plate notations here where the boxes are  X  X lates X  representing replicates. The outer plate represents documents where M denotes the number of documents. The inner plate represents the repeated choice of topics and words within a document where N d the number of words in document d . Shaded nodes denote observed variables and unshaded nodes denote hidden variables.

Assuming that we have a total number of S topics; a corpus with a collection of M of N d words denoted by d =( w 1 , w 2 , ..., w N vectors, and each word in the document is an item from a vocabulary index with V distinct terms denoted by { 1 , 2 , ..., V } , the generative process is:  X  For each topic s  X  X  1 , ..., S }  X  Choose a distribution  X  s  X  Dir(  X  ).  X  For each document d  X  [1 , M ]  X  Choose document length N d  X  Poisson(  X  ).  X  Choose a distribution  X  d  X  Dir(  X  ).  X  For each of the N d word position w t , Here,  X  d is the topic distribution for document d ,  X  s is the word distribution for topic s ,  X  is the parameter of the uniform Dirichlet prior on  X  uniform Dirichlet prior on  X  s . Existing sentiment classification approaches fall into three main categories: lexicon-based, corpus-based, or a combination of both. Lexicon-based approaches make use of a sentiment lexicon to classify a document as positive or negative by aggregating sentiment scores of the words it contains, while corpus-based approaches typically learn a classification model from a labeled corpus. Contrary to existing approaches, we view sentiment classification as a generative problem that when an author writes a review document, he/she first decides on the overall sentiment or polarity (positive, negative, or neutral) of a document, then for each sentiment, decides on the words to be used. The LDA model, as shown in Figure 1(a), can be used to model a mixture of only three sentiment labels, that is, positive, negative and neutral.

We can incorporate sentiment prior knowledge into the LDA model by modify-ing the Dirichlet priors of word-topic distributions as shown in Figure 1(b) which wetermedasLDA-DP.Herewehaveatotalnumberof S sentiment labels S = { neutral , positi v e , negati v e } . The generative process is as follows:  X  For each sentiment label s  X  X  1 , ..., S }  X  X raw  X  s  X  Dir(  X  s  X   X  T s ).  X  For each document d  X  [1 , M ]  X  Choose document length N d  X  Poisson(  X  ).  X  Choose a distribution  X  d  X  Dir(  X  ).  X  For each of the N d word position w t ,
Compared to the original LDA model, we add an additional dependency link of  X  on the matrix  X  of size S  X  V which we use to encode word prior sentiment information. For each sentiment label s and each word w ,  X  s w encodes the word prior polarity probability. Intuitively,  X  is initialized as an identity matrix with all the elements taking a value of 1. Given a sentiment lexicon, for each word w  X  X  1 , ..., V } ,if w is found in the sentiment lexicon, for each s  X  X  1 , ..., S } , the element  X  s w is updated as follows: where the function S ( w ) returns the prior sentiment label of w in a sentiment lexicon and takes a value 0 if neutral, 1 if positive, and 2 if negative.
 The matrix  X  can be considered as a transformation matrix which modifies the Dirichlet priors  X  so that the word prior sentiment polarity can be captured. For ex-ample, the word  X  excellent  X  has a positive sentiment pola rity. The corresponding row ative prior polarity. Thus, the word has much higher probability to be drawn from the positive topic word distribution.
 The total probability of the model is
We use collapsed Gibbs sampling [Griffiths and Steyvers 2004] to approximate the posterior. Gibbs sampling is a Markov chain Monte Carlo method which allows us repeatedly sample from a Markov chain whose stationary distribution is the posterior of interest, s d , t here, from the distribution over th at variable given the current values of all other variables and the data. Such samples can be used to empirically estimate the target distribution. Letting the index x =( d , t ) denote t th word in document d and the subscript  X  x denote a quantity that excludes data from t th word position, the conditional posterior for s x is: where N j ,w the the number of times words in the corpus assigned to sentiment label j ; N d , j is the number of times sentiment label j has been assigned to some word tokens in document d ; N d is the total number of words in the document collection. Sentiment prior knowledge can also be incorporated into the LDA model by aug-menting the model objective function by adding terms which express preferences on expectations of sentiment labels of the lexicon words using generalized expectation criteria [McCallum et al. 2007], which we called LDA-GE.

Letting = {  X ,  X  } , we obtain the marginal distribution of a document w by integrat-ing over  X  and  X  and summing over s :
Taking the product of marginal probabilities of documents in a corpus gives us the probability of the corpus.

Assume we have some labeled features where words are given with their prior sen-timent orientation, we could construct a set of real-valued features of the observation to expresses some characteristic of the empirical distribution of the training data that should also hold of the model distribution. where  X  ( x ) is an indicator function which takes a value of 1 if x is true, 0 otherwise. Equation (4) calculates how often feature k and sentiment label j co-occur in the corpus.
 We define the expectation of the features as where  X  P ( w ) is the empirical distribution of w in document corpus D ,and P ( w | s ; )isa conditional model distri bution parameterized at .
 bels and K is the total number of features or constraints used in model learning. The jk th entry denotes the expected number of times that feature k is assigned with label j .
 tation becomes the predicted feature distribution on the label j ,thatis,
We define a criterion that minimizes the KL divergence of the expected feature dis-tribution and a target expectation  X  f , which is essentially an instance of generalized expectation criteria that penalizes the divergence of a specific model expectation from a target value.
 We can use the target expectation  X  f to encode human or task prior knowledge. For ex-ample, the word  X  X xcellent X  typically represent a positive orientation. We would expect that this word more likely appears in positive documents. In our implementation, we adopted a simple heuristic approach [Druck et al. 2008; Schapire et al. 2002] that a majority of the probability mass for a feature is distributed uniformly among its asso-ciated labels, and the remaining probability mass is distributed uniformly among the other non-associated label(s). As we only have three sentiment labels here, the target expectation of a feature having its prior polarity (or associated sentiment label) is 0.9 and 0.05 for its non-associated sentiment labels.

The above encodes word sentiment prior knowledge in the form of  X  P ( s | w ). However, the actual target expectation used in our approach is  X  P ( w | s ). We could perform the following simple transformation: by assuming that the prior probability of w can be obtained from the empirical dis-tribution of w in document corpus D , and the prior probability of the three sentiment labels are uniformly distributed in the corpus.

We augment the likelihood maximization by adding the generalized expectation cri-teria objective function terms.
 where  X  is a penalized parameter which controls the relative influence of the prior knowledge. This parameter is empirically set to 100 for all the datasets. For brevity, we omit  X  in the subsequent derivations.

The learning of the LDA-GE model is to maximize the objective function in Equa-tion (8). Exact inference on LDA-GE is intractable. We use the variational methods to approximate the posterior distribution over the latent variables. The variational distribution which is assumed to be fully factorized is and s dt  X  Multinomial(  X   X  ).
 We can bound the objective function in Equation (8) in the following way. By letting L ( ; ) denote the RHS of the preceding equation, we have By maximizing the lower bound L ( ; )withrespectto is the same as minimizing the KL distance between the variational posterior probability and the true posterior probability.
 Expanding the lower bound by using the factorizations of P and q ,wehave
We define (  X  )  X  log K k =1  X  k  X  K k =1 log (  X  k )where is Gamma function, each of the eight terms in the above equation can be expressed as: where (  X  ) is the digamma function, the first derivative of the log (  X  ) function.
The first seven terms are the same as in the LDA model. We show how to compute the last term in the above equation. For a sentiment label j
E q [ G ( E [ f ( w, j )])] = E q
We then employ a variational expectation-maximization (EM) algorithm to estimate the variational parameters and the model parameters .

The update rules are  X  (M-step). To estimate the model parameters, we maximize the lower bound on the log likelihood with respect to the parameters = {  X ,  X  } . There are no closed form so-lutions for  X  and  X  and an iterative searching algorithm is used to find the maximal values. In this section, we illustrate the differences among LDA, LDA-DP, and LDA-GE by running a toy example with vocabulary size 10, 3 sentiment labels, and a sentiment lexicon containing only 5 words, out of which 3 are positive and 2 are negative. Figure 2 depicts the multinomial distributions P ( w | s ) under LDA, LDA-DP, and LDA-GE. It can be observed that LDA has difficulties in modeling words X  polarities. For example, the positive words, Words 8 and 10, have roughly even probability to be generated from either positive and neutral sentiment labels. On the contrary, both LDA-DP and LDA-GE are able to capture words X  prior polarities that Words 1 and 2 have much higher probabilities to be generated from the negative sentiment label. Likewise, Words 8, 9, and 10 are more likely to be generated from the positive sentiment label. For other words which do not have prior polarities, their sentiment labels are inferred by the co-occurrences with those words with prior polarities. We evaluated our proposed methods on both English and Chinese corpora. The English corpora comprises of the Movie review data 3 and the multi-domain sentiment (MDS) dataset 4 . The Movie review data consists of 1,000 positive and 1,000 negative movie reviews downloaded from the IMDB movie archive. The MDS dataset contains four different types of product reviews extracted from Amazon.com including Books, DVDs, Electronics, and Kitchen appliances, with 1,000 positive and 1,000 negative reviews for each domain.

The four Chinese corpora 5 were derived from product reviews harvested from the website IT168 6 with each corresponding to different types of product reviews including mobile phones, digital cameras, MP3 players, and monitors [Zagibalov and Carroll 2008a]. All the reviews were tagged by their authors as either positive or negative overall.

It can be seen that the Movie review data appears to be the largest dataset, nearly double the corpus size compared to that of Books and DVDs. The Electronics and Kitchen datasets are smaller with their vocabulary size being only half of that of Books and DVDs. The size of Chinese corpora are much smaller compared to the English datasets.

The English MPQA subjectivity lexicon 7 and the Chinese NTU Sentiment Dictio-nary (NTUSD) 8 [Ku and Chen 2007] were used to extract sentiment prior knowledge for English and Chinese datasets respectively. It should be noted that both lexicons are domain-independent and do not bear any domain-specific information about the corpora used here. Preprocessing was performed on English datasets by first remov-ing punctuation, numbers, non-alphabet characters and stopwords, and then stem-ming words to their root form. Chinese word segmentation was performed on the four Chinese corpora using the conditional random fields based Chinese Word Segmenter 9 [Tseng et al. 2005].

Summary statistics of the datasets after preprocessing and the total number of matched polarity words (words can be found in the corresponding sentiment lexicon) for each dataset are shown in Table I. The prior polarity words coverage in each corpus is also listed in the last column of the table. This section presents the experimental results obtained using the LDA-DP and LDA-GE models tested on both the English and Chinese corpora. The results are averaged over five runs with different random initialization. We compare our proposed approaches with the two baseline methods as described in the following.  X  Lexicon labeling . We implemented a baseline model which simply assigns a score +1 and  X  1 to any matched positive and negative word respectively based on a sen-timent lexicon. A review document is then classified as either positive or negative according to the aggregated sentiment score. Thus, in this baseline model, a docu-ment is classified as positive if there are more positive words than negative words in the document and vice versa.  X  LDA . We evaluated sentiment classification performance with the LDA model where the number of topics were set to 3 corresponding to the 3 sentiment labels.
Table II shows the classification accuracy results on both the English and Chinese corpora. It can be observed that Lexicon labeling achieves an accuracy in the range of 53 X 76% with the best accuracy obtained using the Chinese NTUSD lexicon on the Chi-nese MP3 corpus. LDA model without incorporating any sentiment prior information performs quite poorly with its accuracy being only slightly better than random classi-fication. A significant improvement is observed when the prior sentiment knowledge is incorporated. In general, LDA-GE performs better than all the other models on the English corpora except Electronics with t he best accuracy of 72.67% being achieved on the Movie review data. As for the Chinese corpora, LDA-DP appears better than all the other models with the best accuracy of 83.36% being achieved on the Monitor corpus. We have performed significance tests and found that while both LDA-DP and LDA-GE perform significantly better than LDA at the 0.01 significance level, there is no statistically significant difference between LDA-DP and LDA-GE. We thus conducted another set of experiments to further investigate the impact of the prior information on model learning. We compare LDA-DP and LDA-GE under two different settings. One is with random initialization. That is, the word prior sentiment information is only incorporated by transforming the Dirichlet prior for topic-word distribution in LDA-DP or used to modify the LDA objective function in LDA-GE. The other is initial-ization with prior information. That is, the word prior polarity information obtained from a sentiment lexicon is incorporated during the initialization stage of LDA model learning. Each word token in the corpus is compared against the words in a sentiment lexicon. The matched word token get assigned its prior sentiment label. Otherwise, it is assigned with a randomly selected sentiment label. The results under these two settings for LDA-DP and LDA-GE on both English and Chinese corpora are reported in Table III.

It can be observed that with random initialization, LDA-DP only gives mediocre results with most of the accuracies being only slightly better than random classifica-tion. LDA-GE appears better than LDA-DP with an average of 63% achieved across both English and Chinese corpora. Initializing the models with word sentiment prior information, both LDA-DP and LDA-GE improve dramatically with an average of sen-timent classification accuracy 70% being ach ieved for the English corpora and nearly 80% for the Chinese corpora.

We also plot classification accuracies versus training iterations for both LDA-DP and LDA-GE on the English and Chinese corpora as shown in Figures 3 and 4 re-spectively. It can be observed from the figures that with random initialization, the performance of both LDA-DP and LDA-GE improves with the increase of training iter-ations. For LDA-DP, the improvement on the English corpora is in the range of 2 X 4% which is less significant compared to the Chinese corpora where an increase of 13 X 20% is observed. LDA-GE improves over the initial classification results by 10 X 16% on the English corpora and 5 X 12% on the Chinese corpora.
 When initialized with prior polarity information, the accuracies obtained using LDA-DP appear to be the best at the beginning and either fluctuate in a small range of 1 X 2% or drop slightly before stabilizing again such as on the English book corpus or the Chinese MP3 corpus. It seems that when LDA-DP is initialized with word sentiment prior information, the effect of transforming the Dirichlet prior of topic-word distribu-tion appears to diminish. Yet for LDA-GE initialized with prior information, a similar trend is observed as with random initialization that the performance improves with the increasing number of EM iterations and converges at about 6th iteration for most of the corpora. We also notice that for some of the Chinese corpora, the performance of LDA-GE goes through a peak, then dipped slightly before convergence. This is because the variational Bayes procedure does not maximize the classification accuracy directly, instead, it maximizes the log-likelihood of the data and the convergence is monitored based on the changes of a loss function, rather than accuracy.
In general, LDA-GE employing variational Bayes algorithm exhibits faster conver-gence rate compared to LDA-DP which used collapsed Gibbs sampling. This is the same as what have been observed by other researchers that the stochastic nature of collapsed Gibbs sampling causes it to converge more slowly than the deterministic algorithms [Asuncion et al. 2009].
 We also compare the run time of LDA-DP and LDA-GE versus LDA. For LDA and LDA-DP, we ran 2,000 Gibbs sampling iterations on all the datasets. The Dirichlet prior on the per-document topic distributions,  X  , was initially set to L  X  0 . 05 / S ,where L is the average document length and S is the total number of sentiment labels, and was re-estimated from data using maximum-likelihood estimation [Minka 2003] every 40 Gibbs sampling iterations. For LDA-GE, the model runs until convergence in the EM procedure or until it reaches a maximum of 200 EM iterations. For all the datasets tested here, LDA-GE converges in less than 30 EM iterations. Figure 5 shows the aver-age run time over five different runs for each model on each dataset using a computer with a duo core CPU 2.8GHz and 2G memory. It can be observed that LDA-DP and LDA have roughly the same processing time. But LDA-GE runs significantly faster that it only uses in average less than half of the run time compared to both LDA and LDA-DP.

The above results suggest that incorporating sentiment prior knowledge by aug-menting the model objective function through adding generalized expectation criteria terms is more effective than modifying the Dirichlet prior for topic-word distribution. Thus, LDA-GE should be preferred over LDA-DP when considering employing the topic model for sentiment analysis. Li et al. [2009] employed lexical prior knowledge extracted from a sentiment lex-icon that was developed in the IBM India Research Labs [Ramakrishnan et al. 2003] for semi-supervised sentiment classification based on non-negative matrix tri-factorization. Such domain-independent prior knowledge was incorporated in conjunction with domain-dependent unlabeled data and a few labeled documents for model learning. With 10% of labeled documents for training, the non-negative matrix tri-factorization approach performed much worse than our approach with a difference of 7% X 11% for LDA-DP and 10% X 13% for LDA-GE on both the movie review data and MDS. With 40% labeled documents, their approach gives a similar result on the movie review data as LDA-GE which uses no labeled documents.

Lin et al. [2010] incorporated sentiment prior information extracted from both the MPQA subjectivity lexicon and the appraisal lexicon 10 by modifying conditional probabilities used in Gibbs sampling during LDA model learning. The best sentiment classification results obtained are 74.1% on the movie review data and 69.3% on MDS. Our LDA-GE performs slightly worse than theirs on the movie review data, but gives a better result on MDS.

Dasgupta and Ng [2009] proposed a weakly supervised sentiment classification al-gorithm where user feedbacks are provided on the spectral clustering process in an interactive manner to ensure that text are clustered along the sentiment dimension. Users are allowed to specify the dimension along which she wants the data points to be clustered via inspecting a small number of words. They removed words that occur in only a single review and the top 1.5% words after sorting the vocabulary by docu-ment frequency. And we did not perform such preprocessing. Their proposed approach achieved 70.9% classification accuracy on the movie review data and an average of 68.95% on the MDS dataset. Both of our LDA-DP and LDA-GE give slightly better performance on both datasets. While a generic sentiment lexicon provides useful prior knowledge for sentiment anal-ysis, the contextual polarity of a word may be quite different from its prior polarity. Positive words may appear in sentences describing negative sentiment, and vice versa. Also, the same word might have different po larity in different domain. For example, the word  X  X mall X  is positive when used to describe a mobile phone, but it is negative if it is used to describe a SUV. Thus, it is worthwhile to automatically distinguish between prior and contextual polarity. Our proposed approach starts with a generic sentiment lexicon and incorporate the word sentiment prior knowledge into model learning. It is able to learn the sentiment-word probabilities from a particular domain and thereby reflect a domain-specific sentiment polarity for each word.

Table IV lists some extra polarity words extracted by LDA-GE which are not found in either the MPQA subjectivity lexicon for the English corpora or the NTUSD sen-timent lexicon for the Chinese corpora. We can see that LDA-GE is able to identify domain-specific polarity words. For example, oscar for movie reviews, plai for Books, classic for DVDs, cordless for Electronics, and stainless and drip for Kitchen.
From the Chinese corpora, example domain-specific words include (compact) for mobile phones, (telephoto) for digital cameras, (metallic) and (noise) for MP3, (flat screen) and (distortion) for monitors.

The iterative approach proposed in Zagibalov and Carroll [2008a] can also automat-ically acquire polarity words from data. However, it appears that only positive words were identified by their approach. Our proposed LDA-GE model can extract both pos-itive and negative words and most of them are highly domain-salient as can be seen from Table IV. This article has proposed two different ways for incorporating sentiment prior knowl-edge into the topic model for weakly-supervised sentiment analysis where sentiment labels are considered as topics. Prior information from sentiment lexicons are either incorporated by modifying the Dirichlet prior for topic-word distribution (LDA-DP), or by augmenting the model objective function through adding terms that express preferences on expectations of sentiment labels of the lexicon words using generalized expectation criteria (LDA-GE ). Experimental results on both the English and Chinese corpora show that our approaches attain comparable or better performance than exiting weakly supervised sentiment classification methods despite using no labeled documents. Moreover, the proposed approaches are simple and robust and do not require careful parameter tuning. We also found that LDA-GE appears to be more effective than LDA-DP and thus should be preferred when considering employing the topic model for sentiment analysis. Although this article primarily studies sentiment analysis, the proposed approach is applicable to any text classification task where some relevant prior knowledge is available.

One issue relating to the proposed approach is that it still depends on the existence of a language-specific sentiment lexicon and thus cannot be applied to other less stud-ied languages where no sentiment-related resources are available. A possible way to alleviate this problem is to construct a language-specific sentiment lexicon automati-cally from data and use it as the prior inform ation source to be inco rporated into model learning.

Another promising direction for future wo rk is to incorporate ontology engineering into weakly supervised model learning. By incorporating domain-independent knowl-edge from a sentiment lexicon as well as domain knowledge from ontologies, we are hoping to reveal both topics and sentiment labels of a document simultaneously.
