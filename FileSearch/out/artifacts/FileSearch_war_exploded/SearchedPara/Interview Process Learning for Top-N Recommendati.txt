 In the field of recommendation system research, a key challenge is how to effectively recommend items for new users, a problem gen-erally known as cold-start recommendation. In order to alleviate cold-start problem, recently systems try to get the users X  interests by progressively querying users X  preference on predefined items. Constructing the query process via machine learning based tech-niques becomes an important direction to solve cold-start problem. In this paper, we propose a novel interview process learning algo-rithm. Different from previous approaches which focus on rate pre-diction, our model is able to handle wide ranges of loss functions and can be used in collaborative ranking task. Experimental results on three real world recommendation dataset demonstrate that our proposed method outperforms several baseline methods.
 H.3.3 [ Information Search and Retrieval ]: Information filtering; I.2.6 [ Artificial Intelligence ]: Learning Algorithms, Performance, Experimentation Recommender System; Cold-start problem; Ranking; Decision tree; Functional matrix factorization
With the development of Internet, recommendation systems have become a significant component in the domain of data mining. However, a key challenge for building an effective recommender system is the well-known cold-start problem, which is to recom-mend items to new users. While existing collaborative filtering al-gorithms can obtain high performance under warm-start condition, they will fail to recommend items for fresh users since the recom-mender system rarely knows the interests of those users. Recently cold-start problem has attracted much attention from researchers, which becomes a hot topic in the field of recommendation.
An intuitive approach to solving the cold-start problem is to mod-el new users X  preferences by querying their responses adaptively in an interview process [1, 3, 4]. While there has been researches on the interview process learning, existing literatures focus learn-ing models that optimizing root mean squared error (RMSE) for rate prediction task. While collaborative ranking is equally impor-tant as rate prediction, interview process learning for collaborative ranking is not explored.

In this paper, we propose a novel learning algorithm to learn interview questions for collaborative ranking task. The proposed method is based on factorization of the sparse user-item rating ma-trix, but we define the user latent factor to be the output of a func-tion in the form of a decision tree, whose input is the users X  answers to the interview queries. The learning task is effectively carried out with the coordinate descent based update algorithm and a estima-tion method for general loss function reduction beyond square loss. The contribution of the paper is listed as follows. (1) We propose a general framework of interview decision tree which can handle ranking task. (2) We empirically demonstrate the effectiveness of the proposed method on three real-world datasets.

Outline: In Section 2, we briefly present existing research works for cold-start collaborative filtering. In Section 3, we first introduce basic matrix factorization algorithm for collaborative filtering, then we present our method which models users X  preference by con-structing the interview process in the form of decision tree. Then, we test our proposed method X  X  performance on three datasets and prove that our model can outperform other baselines in Section 4. Finally we conclude our work and discuss about several future di-rections in Section 5.
In this section, we describe our method for cold-start collabo-rative filtering which incorporate interview process into the matrix factorization model. The key contribution is that we propose a gen-eral framework of interview decision tree which can handle ranking task.
Before describing our method, we first introduce basic matrix factorization algorithm for collaborative filtering. Let r the rating of user i for item j , where i = 1 ; 2 ; : : : ; N and j = 1 ; 2 ; : : : M . We generally use matrix R to present the whole rating matrix. We define observed rating set O = { ( i; j ) | r ij The goal of collaborative filtering is to predict the unknown ratings in R . One method for collaborative filtering is matrix factorization. Specifically, we assign a d -dimension vector u i  X  R d for each user i and v j  X  R d for each item j . The rating r ij of user i for item j can be estimated by inner production of u i and v j , i.e.  X  r
W e can also rewrite the expression above in matrix format, i.e.  X  R = U T V . Our object is to estimate the parameters U and V fitting the training data by solving the following optimization prob-lem: where L is a loss function that measuring the difference between the prediction  X  R and the target R . Reg ( U; V ) is the regularization term. For the loss function L , it can be square loss, logistic loss, pairwise rank loss, etc.
In the basic matrix factorization model described in Section 3.1, the user latent factor u i is learned by optimizing the loss on the observed data. However, in order to model the new user X  X  latent factor, we propose to search a function which can map the new user X  X  responses into latent space. Specifically, assume we would like to ask users k interview questions, i.e. show k items to users in proper order to ask for their ratings. We also assume an answer to a question can be positive value presenting the rating or zero which means "Unknown". Furthermore, let x i denote the k -dimension vector representing the answer of user i to the k questions. And we associate x i with u i by assuming u i = f ( x i ) , where f is a function which maps the answer vector x i  X  R k to the user latent vector u i  X  R d . Then we can rewrite the rating estimation the user i give for item j as  X  r ij = v T j f ( x i ) .

Our goal is to learn both f and v j from the training data. By substituting u i = f ( x i ) into 1, we have the following optimization problem: factors mapped from their response vectors. And F is the func-tion space from which f ( x ) is selected and the second term is the regularization term in which  X  X  X  X  represent Frobenius norm.  X ( f ) defines the complexity of the function f .

Furthermore, our system should query adaptively, that is follow-up questions should be selected based on the user X  X  response to the previous questions. What X  X  more, since we allow the user to answer "Unknown", our system need to be capable with this situ-ation. Following prior works [2, 4, 5], we use a decision tree to represent function f ( x ) , i.e. the function space F is decision tree space. Specifically, each node of the decision tree represents an interview question, and it has three branches which mean "higher than threshold", "lower than threshold" and "Unknown", respec-tively. After the user answer a series of questions, we can obtain a path from the root node to the leaf node according to the user X  X  responses.

We further utilize the decision tree structure to encourage the latent factors of each nodes close to their parents. To achieve this, we assign a preference vector to each node in the decision tree, and define the latent factor of each node to be the sum of all the vectors along the path to the root. This can be formally expressed by following equation where path ( x i ) gives the node on the path that corresponds to an-swers x i in the tree. We use symbol  X  u s to emphasize that each parameter is the difference between current nodes X  latent factor to its parent X  X  latent factor. We further define the  X ( f ) as This allows the optimization step to encourage the latent factor of each node to be close to its parent. We call our model layer-wise functional matrix factorization model. Figure (1) gives the outline of our methods.
The objective function defined in 2 can be optimized through an alternating minimization process. Specifically, we can partition all parameters in Equation (2) into two parts and then optimize them separately between the following two steps: 1. Fix f ( x ) , we can update v j by regularized coordinate descent. According to the objective function 2, we update one parameter p among all parameters V for each iteration: 2. Fix v j , we try to learn a function f formed in decision tree s.t.
The most significant problem now is how to find the optimal de-cision tree from a large function space. Since it is computationally impossible for us to find out the global optimal function, we pro-pose a layer-wise additive update with an efficient greedy update algorithm to find a approximate solution instead.
In our work, the objective function is defined in Equation (2), and we now describe a greedy algorithm to construct a decision tree which fit the training data approximately best. Specifically, at each node, we select a best interview question(i.e. a best item to rate) and a best rating threshold by optimizing the loss function Equation (2); then the tree will split the user set into three parts. We repeat this procedure recursively until the tree reaches the redefined depth limit. In our experiments, the depth limit is usually set to a small number between 3 and 10.
F ormally, starting from the root node, once the interview ques-tion q and the rating threshold t are fixed, we can divide the set of users at current node into three disjoint subsets C l ( q; t ) , C and C m ( q; t ) as mentioned above. For any subset C , we would like to find out the optimal increment on the user factor,  X  u best = argmin Here R | C means that constrain R on the user set C , and ( u  X  u; : : : ; u P +  X  u ) represents that make | C | copies for the latent factor u P +  X  u . The vector u P means the user latent factor ob-tained by parent node where C l  X  C r  X  C m belongs to. Our method adds a leaf node for each subset, and thus add a  X  u to latent factors of each subset.

It is time consuming to directly calculate the  X  u best for general loss, we use a more effective approximated solution instead. The first part of the objective function can be approximated by Taylor expansion as:  X  X  ( R | C; ( u P ; : : : ; u P ) T V ) +  X  u T (  X  X  + 2 u = e L ( X  u ) Here  X  X  means gradient of loss function L and H means the Hes-sian matrix of L which is formally defined as: We use e L ( X  u ) to find the best user latent factor  X  u  X  X  + 2 u  X  u and e H = H + 2 u , and we can rewrite e L as: Mathematically , the optimal  X  u has a closed-form solution given by  X  u best =  X  e H 1 g . Substituting the equation into 9, we can get the result that Ha ving above approximate expression for the optimal value of loss function, we can decide which partition strategy is the best one. However, it is also time consuming to calculate the inverse matrix, so we use the diagonal approximation of of e H . Since the inverse matrix of a diagonal matrix is easy to get, we would use the diago-nal matrix to estimate  X  u best . Denote D as the diagonal matrix of e H , and Equation (10) can be simplified as
W e can use Equation (12) to find the optimal interview question q and the best threshold t . Note since there are approximations in the derivations, we only use it to find the interview question. After the question is found, we use coordinate descent to obtain optimal  X  u . The update process will enumerate every dimension of  X  u i and fix other dimensions to optimize  X  u i . After the root node is constructed, its children can be constructed in a similar way recursively until the depth of the tree reaches the depth limit.
In this section, we design a set of experiments on three bench-mark datasets to make comparison between our method and other baselines.
Firstly, we describe our three datasets which are used in experi-ments.
We test the ranking performance in our experiments. The perfor-mance of ranking task can be measured by mean average precision (MAP), which is defined as follows where U represents the set of all users included in test set, the observed item set of user i and rank i ( j ) calculates the rank of item j in the ranking list of user i . Furthermore, P @ n calculates the fraction of top n recommended items that are positive.
Our experiment setting is as same as that in Zhou et al. [5]. For each dataset, we split the users into two disjoint subsets, the train-ing set and the test set. The ratings of each user in the test set are partitioned into two sets: the first set is used to generate the user responses while the second set is used to evaluate the performance. For ranking task, our experimental setting here is to sample nega-tive instances for training data and test data separately. For test da-ta, to simulate users X  rank list, we randomly sample negative items 10 times as positive items for each user as test data.

The algorithms tested in our experiments are summarized as fol-lows,
In this section, we test the ranking performance of our algorithm on three datasets. Firstly, we evaluate the MAP for EIP, FixQ and Warm-MF on MovieLens since fMF cannot handle the logistic loss. We test four sets of results by setting number of interview questions at 3, 5, 8, 10 respectively. The detailed MAP results of three algorithms are shown in Figure (2(a)). From the MAP results of each of the al-gorithm, we can get some basic observations. Firstly, we find that our proposed approach EIP do outperforms FixQ in this rank task. And MAP of EIP is higher than FixQ by 2% averagely. Second-ly, Warm-MF works better than EIP. And the gap between these two algorithm is quite large, which is about 6%. That is, on this dataset, the advantage of warm-start situation is obvious. Finally, the improvement of MAP caused by the increment of the number of interview question is quite notable. In this section, we report the performance of three algorithms on Netflix. We give the comparison of our method against other two in Figure (2(b)). And here we also set the number of interview ques-tions at 3, 5, 8, 10, which is similar to that in previous sections. It is evident that EIP achieves a significant improvement over FixQ. Here the MAP of EIP is still higher than that of EIP by about 2%. The warm-start situation also has obvious advantage, which out-perform EIP by 5% approximately. Furthermore, the effect of the increment of the number of interview questions is still evident here.
Finally, experiments are conducted on Yahoo! Music dataset, the largest dataset mentioned in this paper. Different from previous sections, we set the number of interview questions at 3, 4, 5, 6 to make the training time shorter because of the scale of the dataset. We present MAP results of three algorithm as Figure (2(c)). Fig-ure (2(c)) gives us an abstract impression that EIP outperform FixQ obviously. The gap between EIP and FixQ reaches about 7% aver-agely. And another bright spot in Figure (2(c)) is that EIP outper-forms Warm-MF by a bit less than 3%, which means our method almost reaches the rank performance of warm-start situation in this dataset. Last but not the least, the improvement caused by the depth of the decision tree is not as evident as above. Even when the depth reaches 6, the MAP begins to decrease, which means our model becomes overfitting.
In this subsection, we show more experimental results of our algorithm on prediction tasks and we use widely used metric RMSE as evaluate the performance of each algorithm.

We compare the prediction performance on MovieLens. We also involve fMF here to make a comparison with other two algorithm-s. As Figure (2(d)) shows, our method outperforms fMF and FixQ. However, we can also find that the RMSE performance of cold-start algorithms is far worse than that of Warm-MF, which is not similar to MAP performance. Furthermore, when the depth becomes deep-er, the results of fMF and EIP show signs of deterioration. We think that this phenomenon is caused by overfitting since the skewness of small dataset.
The main focus of this paper is on the cold-start problem in rec-ommender systems. We have proposed a framework for effectively learning a decision tree to handle different kinds of tasks including ranking task. We can simulate interview process to model the laten-t factors for new-come users. Furthermore, our framework is able to handle different types of loss function; even they do not have closed form solution of the optimal point. We have established learning algorithm based on alternating optimization. At last, we have demonstrated the effectiveness of our method on real-world recommendation benchmarks and compared our method with other baselines.

The current model make the use of Taylor expansion and some inequality estimation to speed our method up and it may cause the harm to the performance. For future work, we plan to investigate how to make the update rules used in coordinate descent more pre-cise, as well as the expected optimal value of loss function. More-over, we also plan to apply more kinds of loss function for different tasks. [1] N. Golbandi, Y. Koren, and R. Lempel. On bootstrapping [2] N. Golbandi, Y. Koren, and R. Lempel. Adaptive [3] A. M. Rashid, I. Albert, D. Cosley, S. K. Lam, S. M. McNee, [4] A. M. Rashid, G. Karypis, and J. Riedl. Learning preferences [5] K. Zhou, S.-H. Yang, and H. Zha. Functional matrix
