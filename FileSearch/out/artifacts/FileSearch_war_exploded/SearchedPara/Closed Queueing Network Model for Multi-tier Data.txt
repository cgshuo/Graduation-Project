 Recent years have witnessed significant growth of data stream applications, such as large volume of streaming data are collected from dispersed networks, and processed online in some data processing centers. To meet the requirement of high throughput of data processing and to achieve high availability, data stream processing centers (abbr. DSPC) are increasingly hosted on high performance computing utility, which is usually composed of cluster of computers [1,5] . 
This paper focuses on performance modeling of a particular kind of middleware-based pipe-filter-like data stream applications which are hosted on high performance We use tier to represent a cluster of symmetrical filters, which share the data streams down the pipe. Analytically modeling the performance of data stream processing center is important. However, prior research work on performance of data stream stream processing utilities are increasingly hosted on HPC clusters, the impacts of structure of DSPC on the system performance will be crucial. This paper aims at investigating these impacts by establishing a closed queueing network model for DSPC. 
Our basic approach is to model each filter server in processing pipes with a queue where streaming data request waits in the queue before getting serviced and leaving queuing network. Closed queueing network is preferred to open network, for it well models the synchronization processing behaviors between filter servers, and fits the session-oriented characteristics of data stream applications, where each session comprises a sequence of requests with think-times in between. The paper is structured as follows. We describe our model and analysis method in Sections 2. Section 3 presents experimental validation of the model. Finally, section 4 concludes the paper. 2.1 Network Monitoring Data Processing Application Before presenting the performance model, we first describe a network monitoring data processing application, which is hosted on a cluster of symmetrical multi-processor (SMP) machines to filter and analyze monitoring data streams. This application is used as the background example to derive the performance model, and to monitor and notify the abnormal network behavior for a very-large telecom network by collecting streams of network monitoring data from dispersed interception points. These monitoring data are pushed to a central processing center with a multi-tier pipe-and-filter architecture (see Fig 1). As entries of the data center, proxy servers buffer monitoring data items before issuing packaged data requests to the tier 1 filter servers. There are two kinds filter servers in the system: filter 1 and filter 2, each of which is equipped with some rule-based abnormal behavior definition addressing different facets of security. A data request from a proxy session flows down the tiered filters and concludes processing before next request of the session starts. A dispatcher stands before each filter server tier to distribute request sessions among filters when a new session comes. Now we are working on such network monitoring data processing system based on StarBus+ [7] , a CORBA middleware. 2.2 The Queuing Model for DSPC From the background application, we derive a general DSPC system (depicted in Fig1-b) equipped with N processing tiers denoted by Tier 1 to Tier N. Each tier consists of a cluster of symmetrical filter server components. M proxies, as entries of the DSPC, collect streams of data and continuously issue data processing requests into DSPC. We assume that streaming data load is equally distributed among filter servers of each tier and each filter server runs on a dedicated machine. 
To accurately analyzing the behavior of each filter server, we employ a generalized network of multi-server queues to model a filter server and the underlying machine queueing network for multi-tier data stream processing center (shown in Fig 2).We model M proxies of a data center with infinite server (IS) queues, called session queues , which have infinite processing capability and plays as the delay servers with constant think time T . We use Tier 0 to denote M session. 
Each tier of the filter server cluster is modeled with multiple parallel sub-queueing 1  X  X  X  ). We use Q filter server replications in each tier, we use in the r th replication of i Filter . 
Let Tier j ( 0, ij N  X  X  X  ). Note that ,0 N p =1 and 0,1 p =1, which means all requests stream from Tier N will come to Tier 0 (session queues) and all requests will go through Tier 1 filter servers. Let inside the sub-network for Filter l in Tier l ( 0, that a request begins its processing in Filter l directly from queue , lj Q . the probability of a request finishing Filter l processing when leaving queue , lj Q . As the streaming data processing is data-intensive applications, the impacts of network transportation on the whole system performance can not be neglected in most cases. We use a single-server queue to model the network effects in our analysis, which forms a particular filter server, called network filter queue . We employ the Mean-Value Analysis (MVA) algorithm [6] to analyze the closed queueing network presented 
KRL notations will be used in model analysis: 1 / of Q k . 3.1 Concrete Queueing Model fo r the Experimental Application The network monitoring data processing application described in section 2.1 is used as the model validation application. In our experiments, the application is hosted on a SMP cluster consisted of 8 four-way symmetric multiprocessor machines connected with 1000 Mb Ethernet. Each machine has four Itanium 1.7 GHz processors and 48 GB RAM. All machines run Red Hat Enterprise Linux AS 3 with kernel 2.4.21-4.EL and StarBus+ runtime. Two dedicated machin es are used to host the multi-threaded proxy servers with one thread for a data stream request session. The left 6 machines are allocated among two filter server tiers. We conduct experiments under three system configurations: Config-1(two machines for tier 1), Config-2(three machines we derive a concrete close queueing netw ork model(see Fig 3) from the general model presented in section 2.2. 
We conduct system profiling and measuremen ts to approximate the service time of CPU queue to disk-I/O queue is assumed 1:1 in filter 2 servers, which means each data request will visit disks once after CPU access inside filter 2 server. Now we have the following model parameters for three experimental configurations (see Table 1): 3.2 Experimental Results Figure 4-(a)(b)(c) respectively plot the predicted throughput and average response time vs. the observed performance under three configurations. Figure 4-(d) shows the CPU utilization under the Config-1 setup. From these experiments, we see the proposed concrete queueing model can well capture the performance for the monitoring data processing system, and the difference between the observed performance and model predictions are less than 15% when the proxy sessions are less than 30. As shown, both throughput and average response time of the application are accurately predicted when proxy sessions are less than 20. In general, system throughput predictions more approximate the observed values than the predicted average response time. However, under heavy load conditions (more than 30 proxy sessions), the deviation of average respon se time predictions increases obviously. Several factors may have effect on the model accuracy. First, some assumptions, such as the one that the visit ratio of disk-I/O is equal to the CPU access in filter 2 server tier may not hold. Secondly, the error of model parameter estimation may incur performance deviation. Thirdly, software contentions, which are not captured in our model, may severely affect the system response time under heavy load conditions. In this paper, we present an analytical model for middleware-based multi-tier DSPC hosted on high performance SMP cluster. Based on a closed queueing network with multi-server queue supports, our model is general enough to capture system behavior results show that the model nicely captures the applications performance for a number of workloads and configurations. 
