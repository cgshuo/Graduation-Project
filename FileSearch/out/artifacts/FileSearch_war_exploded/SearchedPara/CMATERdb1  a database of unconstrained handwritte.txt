 ORIGINAL PAPER Ram Sarkar  X  Nibaran Das  X  Subhadip Basu  X  Mahantapas Kundu  X  Mita Nasipuri  X  Dipak Kumar Basu Abstract In this paper, we have described the preparation of a benchmark database for research on off-line Optical Character Recognition (OCR) of document images of hand-written Bangla text and Bangla text mixed with English words. This is the first handwritten database in this area, as mentioned above, available as an open source document. As India is a multi-lingual country and has a colonial past, so multi-script document pages are very much common. The database contains 150 handwritten document pages, among which 100 pages are written purely in Bangla script and rests of the 50 pages are written in Bangla text mixed with Eng-lish words. This database for off-line-handwritten scripts is collected from different data sources. After collecting the document pages, all the documents have been preprocessed and distributed into two groups, i.e., CMATERdb 1.1.1, con-taining document pages written in Bangla script only, and CMATERdb 1.2.1, containing document pages written in Bangla text mixed with English words. Finally, we have also provided the useful ground truth images for the line seg-mentation purpose. To generate the ground truth images, we have first labeled each line in a document page automatically by applying one of our previously developed line extraction techniques [Khandelwal et al., PReMI 2009, pp. 369 X 374] and then corrected any possible error by using our developed tool GT Gen 1.1. Line extraction accuracies of 90.6 and 92.38%areachievedonthetwodatabases,respectively,using our algorithm. Both the databases along with the ground truth annotations and the ground truth generating tool are available freely at http://code.google.com/p/cmaterdb .
 Keywords Unconstrained handwritten document image database  X  Text line extraction  X  Ground truth preparation OCR of multi-script document 1 Introduction OCR involves computer recognition of characters from dig-itized images of optically scanned document pages. The characters thus recognized from document pages are coded with American Standard Code for Information Interchange (ASCII) or some other standard code for storing in a file, which can be edited as any other file created with some word processing software or some editor. A scanner with OCR facility allows editing the contents of document pages after scanning them optically.

Identification of text lines is the first and most important step in the process of OCR of handwritten/printed document images. If text line identification is not accurate, then none of the words and characters in the constituent text lines can be identified correctly. Such errors are unacceptable for large-scale recognition of documents.

The problem of text line identification for handwritten documents is more difficult than the printed documents. For example, all the text lines in a handwritten document may be skewed with respect to the horizontal axis, or individual lines may be non-parallel to one another. A text line may also be curvy or written close to one another, making the line segmentation difficult. Adjacent text lines may even touch one another at multiple points. All such cases make the line segmentation from handwritten digitized documents a chal-lenging research problem.

The next step in an OCR system for handwritten docu-ments is that of word identification. Words in a text line must be identified accurately for the constituent characters to make grammatical sense. Word identification poses its own set of problems. In many of the techniques developed for word extraction so far, words are identified after identification of the text lines. So, the performance of the word extraction technique is completely dependent on that of the text line identification technique. Word identification also becomes very difficult in case of text lines with varying skewness or slant.

Despite the importance of the line segmentation for the successful development of any OCR system, especially for handwritten text, an acceptable degree of accuracy has not yet been achieved for unconstrained handwritten document, and hence, it still remains as an open problem for research.
Researches on extraction/segmentation of unconstrained handwritten text lines from digitized document pages are limited in the literature [ 7 , 10  X  17 , 21 ]. In one of our ear-lier works [ 7 ], we had reviewed contemporary research contributions related to extraction of handwritten/printed text lines from digitized document pages. Current research contributions related to extraction of unconstrained hand-written text lines from digitized document pages may be classified into several categories viz. Hough Transformation based techniques [ 10 , 11 , 16 ], Statistical approaches using Minimal spanning tree, Probability Distribution Function (PDF) etc. [ 12  X  14 , 17 ] and typical morphological approaches using run length encoding, water flow technique, analysis of neighborhood components etc [ 15 , 7 , 21 ]. Some of word extraction methodologies are described in [ 10 , 16 , 24 , 25 ]. 1.1 Need for standardization of experimental data Handwritten OCR is a challenging and open problem in Pat-tern Recognition, which started in early 1960s. Generally, majority of the researchers in this field prepared their own databases for their respective experiments, making uniform assessment of any methodology a difficult task. At present, limitedpublicdomaindatabasesareavailableforhandwritten OCR. Most popularly used databases in this field are NIST [ 1 ], IAM-DB [ 2 ], CENPARMI [ 3 ], CEDAR [ 26 ]etc.Most of these databases [ 1 , 26 ] are not freely available. IAM-DB database [ 2 ] consists of handwritten English script. CEDAR database [ 26 ] consists of city names, state names, ZIP codes, and alphanumeric characters. Moreover, some handwritten numerals X  databases [ 1 ] aim at specialized applications, such as recognition of postal code. In addition to the English dat-abases, there are databases of other languages [ 4 , 5 ]. Korean and JIS Chinese scripts were used for the databases in [ 4 ] and [ 5 ], respectively. Databases are also available for Ara-bic script [ 27 ] and Japanese script [ 28 ]. The ICDAR 2009 Handwriting Segmentation Contest [ 6 ] also provided a set of handwritten document pages written in Latin script for Eng-lish, Greek, French, and German languages. A database is also available in [ 9 ] for some of the handwritten Indic scripts viz., Bangla, Devanagri, and Oriya. But in [ 9 ], only data-base for isolated digit, characters, modifiers, or compound characters is available. Authors of [ 23 ] also provided two databases for handwritten numerals for two Indian scripts, viz., Devanagri and Bangla.

However, there is no public domain database available for unconstrained handwritten document pages written in any of the popular Indic scripts. It may be worth mentioning at this point that for Indic, Arabic, and Chinese scripts, special techniques are required to implement handwritten OCR algo-rithms, on digitized document pages of such scripts. Another typical attribute of Indic script document is the presence of Latin script words in many unconstrained documents, mak-ing the OCR process more complex. More than 960million people use Indic scripts [ 19 ] worldwide, and that large pop-ulation itself is a motivating factor in developing benchmark datasets for such scripts. Previous researches on Indic script recognition systems were reported on the basis of databases collected in the laboratory. But, future research in this domain requires standard databases fulfilling certain criteria depend-ing on the application domain.

Therefore, for the aforementioned reasons, we have been motivated to prepare two handwritten document databases. The first one contains only Bangla words, and the other containing both Bangla and English words. The second cat-egory of document pages is more popular and difficult to segment and recognize due to the presence of two contrast-ing types of scripts in it. The following section discusses the origin of mixed script documents in India and some basic characteristics of Bangla script. The line/word extraction techniques for both these categories of documents may argu-ably perform in similar fashion (despite sharp differences in writing styles of the two scripts under consideration), but character segmentation from Matra -based (A Matra is a hor-izontal line, touching the upper part of a basic or compound character) Bangla word images is different from that of Latin word images. Therefore, intelligent classification techniques are required to distinguish words of two different scripts in a mixed script document. In one of our earlier works [ 30 ], an effort was made in such direction. However, benchmark databases of mixed script document images are required to extend research initiatives in that direction. This has been one of our primary motivations behind inclusion of the mixed script document image dataset (along with the Bangla script document image dataset) in our current work. 1.2 Origin of mixed script documents in India With nearly 207million total speakers [ 18 ], Bangla is one of the most spoken languages (ranking 5th or 6th) [ 19 ]in the world. Bangla, official language of Bangladesh, is the primary language spoken in Bangladesh and is the second most spoken language in India. In India, Bangla is mostly used in West Bengal, Tripura, and Assam. Moreover, Ban-gla script is also used for other two Indian languages, viz., Assamese and Manipuri.

In any Indic script, including Bangla, region-specific minor variations in the shape of the scripts written by indi-viduals are sometimes observed. Another interesting point regarding handwritten documents in Indic scripts is that peo-ple often write one or more words in English. The reasons for this possibly are a. India is a multi-lingual country. b. India has colonial past. c. English is very much used in official purpose. d. English is usually taught in schools. e. Most of the books followed in higher studies are either
We observed that while writing scientific or technical information (such as subjects like physics, chemistry, math-ematics, computer science, etc.) in an Indic script, the writer might casually enter one or more English words, generating a mixed script document. 1.3 Characteristics of Bangla script Characters of Bangla script can be grouped into five cate-gories of characters, viz., vowel, consonant, modified shape, compound character, and punctuation symbol. Out of these characters, vowels and consonants, which constitute Bangla alphabet, are called basic characters . There are 11 vowels and 39 consonants in Bangla alphabet. There is no concept of upper and lower case characters in Bangla script. Charac-ters in Bangla script are written from left to right. A vowel following a consonant in a word takes a modified shape in Bangla script. Such shapes of all vowels are termed as mod-ified shapes . It is noteworthy that some modified shapes attached with a consonant have two isolated parts appearing in two opposite sides of the consonant. Some modified shapes may appear just below the consonant, and some may reach its top from one of its sides with a curved or partly curved seg-ment. So, characters in Bangla script may not always appear in non-overlapping consecutive positions. Depending on the mode of pronunciation, a Bangla consonant followed by one or two consonants takes a complex shape, which is called a compound character . There are in all 280 compound characters in Bangla script. Apart from the basic characters, the modified shapes, and the compound characters, Bangla script also constitutes 10 digit patterns. An important feature of Bangla characters is Matra or head line. Excepting a few, all basic and compound characters of Bangla script have this feature.. The width of a Matra is nearly same as the width of the character it touches. All the Matras of consecutive characters appearing in a Bangla word are joined to form a common Matra of the characters appearing in the word.
Rest of the paper describes the database nomencla-ture, data collection methodology, data processing tech-niques employed and the detail composition of the database. Description and availability of the database and the ground truth generating software, developed by us, are also discussed in this paper along with the detailed reports of the bench-mark performances of our line extraction methodology on the newly developed database. 2 Detailed dataset description We have named our developed database as CMATERdb 1, where CMATER stands for Center for Microprocessor Appli-cation for Training Education and Research, a research lab-oratory at Computer Science and Engineering department of Jadavpur University, India, where the current research activity took place. db stands for database , and the numeric value 1 represents handwritten line segmentation database prepared for the current work. Currently, we have devel-oped two variations of CMATERdb 1, viz., CMATERdb 1.1 representing a database of handwritten document pages con-taining Bangla words only and CMATERdb 1.2 representing a database of handwritten document pages containing both Bangla and English words. The first version of both these dat-abases is released as CMATERdb 1.1.1 and CMATERdb 1.2.1, respectively. Database is available freely in the CMATER website ( www.cmaterju.org ) and at http://code.google.com/ p/cmaterdb . 2.1 Data collection methodologies The materials of the handwritten document pages for the proposed databases have been collected from three different types of sources, viz., class notes of students of different age-groups, handwritten manuscripts of a popular Bangla monthly magazine  X  Computer Jagat  X  X  29 ], and the docu-ment pages written by different persons, on request, under our supervision.

The document pages written under our supervision were collected from various persons with textual contents col-lectedfromnewspaperarticlesandBanglatextbookscontain-ing both Bangla and English vocabulary. The writers were asked to use a black or blue ink pen and write inside the A-4 size pages. They were imposed no other restrictions regard-ing the kind of pen they used or the style of writing chosen. Specialattentionwaspaidtoensuredatacollectionfromwrit-ers of different age-groups and educational levels. Moreover, we collected the pages from different places (home, office, school, etc.) in order to include different styles of writing. In total, 25 men and 15 women participated in this data col-lection drive. The main characteristics of our database are as follows:  X  95% of the writers were native Bengali.  X  Places of Data Collection: 40% in schools/colleges, 40%  X  Educational level of the writers: 20% 10th standard  X  Writers X  age: 40% between 15 and 25years, 30% between 2.2 Data processing techniques All the document pages were scanned using a flatbed scanner with 300 dpi gray scale image resolution. Each page, meant for the databases CMATERdb 1.1.1 and CMA-TERdb 1.2.1, is stored in bitmap file format with the nam-ing convention B###.bmp and BE###.bmp, respectively. ### is a unique integer number given to the file name to maintain sequence, and B or BE refers to the document type, i . e ., Bangla or Bangla X  X nglish, respectively. Some sample images from both these databases are shown in Fig. 1 (a-b).

After scanning, the documents were binarized by sim-ple adaptive thresholding technique, where the thresh-old was chosen as the mean of the maximum and minimum gray level values in each document image. All the binarized images were archived in DAT format, where the foreground and background pixels were represented as  X 0 X  and  X 1 X , respectively. Then, the documents were pre-processed in order to remove all the remaining salt and pepper noises like long lines in the border zone(s). To remove discontinuity in the pixel level, we have used erosion and dilation [ 8 ], two popularly used morphological oper-ators in image processing. Figure 2 b shows output of the preprocessing technique for a sample image, as shown in Fig. 2 a, taken from the database. All the binarized images are finally used to prepare the ground truth annotations for the database. 2.3 Composition of the database CMATERdb 1.1, the Bangla script handwritten document database contains 100 pages in its first version. CMA-TERdb 1.2 contains 50 handwritten document pages contain-ing both Bangla and English words. Each of the document pages of the databases are described with the help of attri-butes like page dimensions, i.e., height, width and aspect ratio, counts of number of lines and words, and statistical esti-mations of the horizontal and vertical stroke widths. Detailed descriptions of all the document pages of the two databases are uploaded as supplementary files in the database website [ http://code.google.com/p/cmaterdb ]. Descriptions of some of the sample pages and the averages and standard deviations of all the attributes of all the document pages from the two databases are shown in Tables 1 and 2 , respectively.
Document attributes related to page dimensions are actu-ally based on the scanned region of the images. In most cases, we have attempted to preserve the original/physical page dimensions, but in some cases, they may get compromised because of misalignment due to scanning or cropping of torn out page boundaries (especially relevant in cases of manuscripts collected from external sources). Counting of number of lines and words in the document images is done manually at the CMATER research laboratory. These attributes are necessary for designing effective line/word extraction algorithms. They give an estimate of the aver-age line/word spacing in document images. These count-features are also essential for performance evaluation of line/word extraction techniques. The stroke width in any binarized document image is estimated as the run of black pixels in any given direction (horizontal/vertical). Unlike the other features, these two features are computed pro-grammatically and are particularly useful in estimating an important writers X  characteristic, that is, the connectedness in writing style. These writers X  characteristics play key roles in line/word segmentation algorithms. Popularly used run-length-based features are specifically sensitive to the stroke width of any unconstrained handwritten document image. Run-length-based horizontalness and verticalness attributes in document/word images are widely used for character seg-mentation [ 31  X  34 ] from document images. To get the average horizontal stroke width, we have estimated the mean of all the continuous run of black pixels along the rows. The average vertical stroke width is computed in the similar fashion over the mean column-wise runs of black pixels. The computa-tion process of these two features is pictorially illustrated in Fig. 3 . To show the variability in writing styles of indi-viduals, in each document page, we have also provided the standard deviations of horizontal and vertical stroke widths (in respective pages) both in the supplementary material [ http://code.google.com/p/cmaterdb ] and in the Tables 1 and 2 .

The orientation/skew of text lines is estimated as the hypo-thetical angle the handwritten text lines make with the hori-zontal axis. Presence of multi-oriented text is also considered as an important characteristic of unconstrained handwritten document images. Since the objective of the current work is to accommodate normal writing styles from variety of users, extreme multi-oriented writing is not included in the current dataset collection. Some of the document pages, taken from our dataset, with limited multi-oriented characteristics of the text lines are shown in Fig. 4 a, b. 3 Ground truth of our databases Generation of appropriate ground truth data has always been a challenging and tiresome task for the kind of problem under consideration. Availability of ground truth information, how-ever, makes any database more useful, enabling proper eval-uation of one X  X  technique by comparing their output with the ground truth of the same. In this work, we have prepared ground truth images for all the images of our databases, viz., CMATERdb 1.1.1 and CMATERdb 1.2.1 for line segmentation application. For each of the two handwritten databases, we have generated the ground truth information, which has been archived as CMATERgt 1.1.1 and CMATERgt 1.2.1, respec-tively. We have prepared these ground truth images of the databases in a semi-automatic way. More specifically, we have employed our previously developed [ 22 ] technique to identify individual line segments from any document image. The possible error that might have been generated in the automated line extraction is corrected using a software tool called GT Gen version 1.1, which we have developed for this project. Basically, we have used GT Gen to recolor some lines or part of the lines, which were erroneously labeled by our technique developed in [ 22 ]. It may be noted that all the ground truth images are stored in bitmap (bmp) file format, where the background is labeled in white and individual text lines are marked in different colors. All the files in CMATERgt 1.1.1 and CMATERgt 1.2.1 are named as GTB###.bmp and GTBE###.bmp, respectively. Figure 5 a, b shows sample ground truth images from the two databases, respectively, prepared for the line extraction application. 3.1 GTGen: the ground truth generating software GT Gen version 1.1 is a software tool, developed in Visual Basic dot net technology at the CMATER research labora-tory that can label text in any chosen color. GT Gen reads images of document pages with white background. One can select any color from a color panel and use that to recolor the text by selecting the intended region with a mouse. Using this technique, we can easily correct errors in our line extrac-tion algorithm [ 22 ] to generate ground truth data. We can even use this tool to label text lines from beginning (without assistance from [ 22 ]) or even generate ground truths for word and character segmentation algorithms. This software setup is available freely and can be downloaded from http://code. google.com/p/cmaterdb . A screenshot of the developed GT Gen 1.1 software is shown in Fig. 6 . 4 Benchmark evaluation of the databases by our line extraction technique Our previously published works in this area may be found in [ 7 , 21 , 22 ]. We also participated in ICDAR-2009 Handwriting Segmentation Contest [ 20 ]. The line extraction algorithm as discussed in [ 22 ] is applied on both of the databases prepared for the current work. The brief description of the algorithm and results achieved on both the databases are described in the subsequent subsections. 4.1 Line extraction algorithm used In one of our earlier works [ 22 ], an effective technique for identifying text lines in digitized handwritten document images has been presented. Two terminologies, a component or a segment , have been used interchangeably to represent an 8-connected set of black pixels in any binarized digi-tal document page. A connected component-labeling (CCL) algorithm [ 8 ] is implemented to identify the basic segments in the text document as unique objects. During preprocess-ing, the components are categorized in one of the 4 types, viz., Type #1, Type #2, Type #3, and Type #4 according to their respective dimensional characteristics (related to their heights and widths). Type #1 components are the small dot -like segments , Type #2 components are the long lines, Type #3 components consist of large segments, which may or may not be connected, and Type #4 components comprise of the rest of the segments.

Type# 1 and Type #2 components are considered as noise and are therefore ignored. Type #3 components may be generated as a result of overlap of two or more words belong-ing to adjacent text lines or character(s) that may have lig-ature(s) or elongated portion(s) in upper or lower directions due to writing style of individual. Such components are also ignored during the initial phase of identification of text lines. Our algorithm therefore considers only Type #4 components, during the first phase of the processing.
Different dimensional features of these Type #4 compo-nents are used to identify individual text line. The post-processing step includes possible reconsideration of the Type #1 components, ignored in the first phase. Some of these might have actually been small handwritten parts of texts, and such components are allocated to suitable text lines. Finally, there might have been few cases in which some words of adjacent text lines get merged (Type #3 components). Such touching text components are carefully selected and split to form the actual text lines. Other type of Type #3 components is included in the text line with which they have maximum overlap. Illustration of the 4 different types of components is shown on a sample document image in Fig. 7 . 4.2 Results of the line extraction algorithm Performance evaluation of the line extraction algorithm is done by visually observing the identified lines carefully on the set of handwritten documents, as we have not any tool for estimating performance evaluation automatically. For manual estimation of the success rate of text line extraction technique,wehaveconsideredtwotypesoferrors,viz.under-segmented text line and over-segmented text line. If two or more text lines are identified as a single text line, then it is considered as under-segmentation error and both/all the extracted text lines are treated as wrongly extracted text lines. Similarly, if single text line components are errone-ously allocated to two or more text lines, then this text line is also considered as wrongly extracted text line due to over-segmentation. The total number of under-segmented and over-segmented text lines is reflected in the estimation of the success rate (SR) of the text line extraction technique. More specifically, SR = ( T  X  ( U + O ))/ T , (1) where,
U = number of under-segmented text lines
O = number of over-segmented text lines
T = number of actual text lines present in the document page
By applying equation ( 1 ), the percentages SRs achieved on the databases CMATERdb 1.1.1 and CMATERdb 1.2.1 are 90.60 and 92.38%, respectively. Table 3 illustrates the performance of the line extraction technique [ 22 ] on both the databases. Figure 8 a, b shows line extraction results on two sample document images, taken from the two databases underconsideration.Figure 9 showsresultsofdifferentissues of present line extraction technique. Figure 9 a shows out-put image, illustrating cases of under-segmentation and over-segmentation, and Fig. 9 b shows output image of successful touching text line separation. 5 Conclusion In this paper, we have discussed the steps involved in gener-ating a benchmark database for unconstrained, handwritten document pages containing both Bangla and Bangla X  X nglish mixed script words. This database is first of its kind in this domain of application, i.e., OCR of handwritten Indic script. Each document contains characters, text, digits, and other symbols written by different writers. In the current database, the document pages written under our supervision were col-lected from 40 writers of different age-groups, sexes, and educational levels. As an extension of the current project, more handwritten samples will be collected (under our super-vision) from a broader section of the society to incorporate a wider variation in handwriting styles. Also, we plan to collect more number of unconstrained handwritten document pages, analyze both the supervised and unconstrained documents, prepare the ground truth and make the benchmark results ready for the next database release. As discussed before, Bangla is a complex Indic script and used by more than 207million people in this world. Unlike English, Bangla script uses more than 300 character shapes, many modifiers, and 10 digit patterns. Therefore, extraction of text lines from such documents is a challenging task. Despite many research efforts on this problem domain, availability of standard data-set is limited for Bangla script. The current CMATERdb 1 database is the first effort to develop one such repository not only for unconstrained handwritten document pages contain-ing Bangla script but also for mixed script document pages containing both Bangla and English words. In future releases of our database, we may include newer scripts like Devan-agri and collect document pages containing both Devanagri and Latin script words. Extreme variations in writing styles having slants in words, and multi-oriented text lines may also be incorporated as a future work. Such databases would enable to test versatility of any line/word/character segmen-tation algorithms to their limits. It may also be noted that all the current document pages are digitized using a flatbed scanner with a given resolution. Camera captured document image analysis is also gaining popularity and may open up a new research dimension. We have already reserved our CMA-TERdb4 release for such images that till now includes only camera-captured business card images [ http://code.google. com/p/cmaterdb ]. Such images often suffer from uneven illu-mination, perspective distortion, improper focus, shadow, etc. Extending CMATERdb4 release for camera captured handwritten/printed document images is another future scope of this work.

We have also generated the ground truth images for both the databases for evaluation of line extraction algorithm and also made the ground truth generating software GT Gen 1.1 available freely in public domain. Benchmark text line extraction accuracies on these handwritten pages are also reported in the current work. In future, our aim is to increase the size of the database and to generate unconstrained hand-written page databases for other Indic scripts. We are also working at present to generate word-level and character-level databases for handwritten Bangla word images. Improve-ment of the ground truth generation software by includ-ing the line extraction routines and performance evaluation metrics are also in our future plans of research in this domain.
In a nutshell, we have attempted to provide a benchmark evaluation database for researchers interested in a challeng-ing problem domain, related to OCR of unconstrained hand-writtendocumentpagescontainingBanglaandBanglamixed with English words.
 References
 ORIGINAL PAPER Ram Sarkar  X  Nibaran Das  X  Subhadip Basu  X  Mahantapas Kundu  X  Mita Nasipuri  X  Dipak Kumar Basu Abstract In this paper, we have described the preparation of a benchmark database for research on off-line Optical Character Recognition (OCR) of document images of hand-written Bangla text and Bangla text mixed with English words. This is the first handwritten database in this area, as mentioned above, available as an open source document. As India is a multi-lingual country and has a colonial past, so multi-script document pages are very much common. The database contains 150 handwritten document pages, among which 100 pages are written purely in Bangla script and rests of the 50 pages are written in Bangla text mixed with Eng-lish words. This database for off-line-handwritten scripts is collected from different data sources. After collecting the document pages, all the documents have been preprocessed and distributed into two groups, i.e., CMATERdb 1.1.1, con-taining document pages written in Bangla script only, and CMATERdb 1.2.1, containing document pages written in Bangla text mixed with English words. Finally, we have also provided the useful ground truth images for the line seg-mentation purpose. To generate the ground truth images, we have first labeled each line in a document page automatically by applying one of our previously developed line extraction techniques [Khandelwal et al., PReMI 2009, pp. 369 X 374] and then corrected any possible error by using our developed tool GT Gen 1.1. Line extraction accuracies of 90.6 and 92.38%areachievedonthetwodatabases,respectively,using our algorithm. Both the databases along with the ground truth annotations and the ground truth generating tool are available freely at http://code.google.com/p/cmaterdb .
 Keywords Unconstrained handwritten document image database  X  Text line extraction  X  Ground truth preparation OCR of multi-script document 1 Introduction OCR involves computer recognition of characters from dig-itized images of optically scanned document pages. The characters thus recognized from document pages are coded with American Standard Code for Information Interchange (ASCII) or some other standard code for storing in a file, which can be edited as any other file created with some word processing software or some editor. A scanner with OCR facility allows editing the contents of document pages after scanning them optically.

Identification of text lines is the first and most important step in the process of OCR of handwritten/printed document images. If text line identification is not accurate, then none of the words and characters in the constituent text lines can be identified correctly. Such errors are unacceptable for large-scale recognition of documents.

The problem of text line identification for handwritten documents is more difficult than the printed documents. For example, all the text lines in a handwritten document may be skewed with respect to the horizontal axis, or individual lines may be non-parallel to one another. A text line may also be curvy or written close to one another, making the line segmentation difficult. Adjacent text lines may even touch one another at multiple points. All such cases make the line segmentation from handwritten digitized documents a chal-lenging research problem.

The next step in an OCR system for handwritten docu-ments is that of word identification. Words in a text line must be identified accurately for the constituent characters to make grammatical sense. Word identification poses its own set of problems. In many of the techniques developed for word extraction so far, words are identified after identification of the text lines. So, the performance of the word extraction technique is completely dependent on that of the text line identification technique. Word identification also becomes very difficult in case of text lines with varying skewness or slant.

Despite the importance of the line segmentation for the successful development of any OCR system, especially for handwritten text, an acceptable degree of accuracy has not yet been achieved for unconstrained handwritten document, and hence, it still remains as an open problem for research.
Researches on extraction/segmentation of unconstrained handwritten text lines from digitized document pages are limited in the literature [ 7 , 10  X  17 , 21 ]. In one of our ear-lier works [ 7 ], we had reviewed contemporary research contributions related to extraction of handwritten/printed text lines from digitized document pages. Current research contributions related to extraction of unconstrained hand-written text lines from digitized document pages may be classified into several categories viz. Hough Transformation based techniques [ 10 , 11 , 16 ], Statistical approaches using Minimal spanning tree, Probability Distribution Function (PDF) etc. [ 12  X  14 , 17 ] and typical morphological approaches using run length encoding, water flow technique, analysis of neighborhood components etc [ 15 , 7 , 21 ]. Some of word extraction methodologies are described in [ 10 , 16 , 24 , 25 ]. 1.1 Need for standardization of experimental data Handwritten OCR is a challenging and open problem in Pat-tern Recognition, which started in early 1960s. Generally, majority of the researchers in this field prepared their own databases for their respective experiments, making uniform assessment of any methodology a difficult task. At present, limitedpublicdomaindatabasesareavailableforhandwritten OCR. Most popularly used databases in this field are NIST [ 1 ], IAM-DB [ 2 ], CENPARMI [ 3 ], CEDAR [ 26 ]etc.Most of these databases [ 1 , 26 ] are not freely available. IAM-DB database [ 2 ] consists of handwritten English script. CEDAR database [ 26 ] consists of city names, state names, ZIP codes, and alphanumeric characters. Moreover, some handwritten numerals X  databases [ 1 ] aim at specialized applications, such as recognition of postal code. In addition to the English dat-abases, there are databases of other languages [ 4 , 5 ]. Korean and JIS Chinese scripts were used for the databases in [ 4 ] and [ 5 ], respectively. Databases are also available for Ara-bic script [ 27 ] and Japanese script [ 28 ]. The ICDAR 2009 Handwriting Segmentation Contest [ 6 ] also provided a set of handwritten document pages written in Latin script for Eng-lish, Greek, French, and German languages. A database is also available in [ 9 ] for some of the handwritten Indic scripts viz., Bangla, Devanagri, and Oriya. But in [ 9 ], only data-base for isolated digit, characters, modifiers, or compound characters is available. Authors of [ 23 ] also provided two databases for handwritten numerals for two Indian scripts, viz., Devanagri and Bangla.

However, there is no public domain database available for unconstrained handwritten document pages written in any of the popular Indic scripts. It may be worth mentioning at this point that for Indic, Arabic, and Chinese scripts, special techniques are required to implement handwritten OCR algo-rithms, on digitized document pages of such scripts. Another typical attribute of Indic script document is the presence of Latin script words in many unconstrained documents, mak-ing the OCR process more complex. More than 960million people use Indic scripts [ 19 ] worldwide, and that large pop-ulation itself is a motivating factor in developing benchmark datasets for such scripts. Previous researches on Indic script recognition systems were reported on the basis of databases collected in the laboratory. But, future research in this domain requires standard databases fulfilling certain criteria depend-ing on the application domain.

Therefore, for the aforementioned reasons, we have been motivated to prepare two handwritten document databases. The first one contains only Bangla words, and the other containing both Bangla and English words. The second cat-egory of document pages is more popular and difficult to segment and recognize due to the presence of two contrast-ing types of scripts in it. The following section discusses the origin of mixed script documents in India and some basic characteristics of Bangla script. The line/word extraction techniques for both these categories of documents may argu-ably perform in similar fashion (despite sharp differences in writing styles of the two scripts under consideration), but character segmentation from Matra -based (A Matra is a hor-izontal line, touching the upper part of a basic or compound character) Bangla word images is different from that of Latin word images. Therefore, intelligent classification techniques are required to distinguish words of two different scripts in a mixed script document. In one of our earlier works [ 30 ], an effort was made in such direction. However, benchmark databases of mixed script document images are required to extend research initiatives in that direction. This has been one of our primary motivations behind inclusion of the mixed script document image dataset (along with the Bangla script document image dataset) in our current work. 1.2 Origin of mixed script documents in India With nearly 207million total speakers [ 18 ], Bangla is one of the most spoken languages (ranking 5th or 6th) [ 19 ]in the world. Bangla, official language of Bangladesh, is the primary language spoken in Bangladesh and is the second most spoken language in India. In India, Bangla is mostly used in West Bengal, Tripura, and Assam. Moreover, Ban-gla script is also used for other two Indian languages, viz., Assamese and Manipuri.

In any Indic script, including Bangla, region-specific minor variations in the shape of the scripts written by indi-viduals are sometimes observed. Another interesting point regarding handwritten documents in Indic scripts is that peo-ple often write one or more words in English. The reasons for this possibly are a. India is a multi-lingual country. b. India has colonial past. c. English is very much used in official purpose. d. English is usually taught in schools. e. Most of the books followed in higher studies are either
We observed that while writing scientific or technical information (such as subjects like physics, chemistry, math-ematics, computer science, etc.) in an Indic script, the writer might casually enter one or more English words, generating a mixed script document. 1.3 Characteristics of Bangla script Characters of Bangla script can be grouped into five cate-gories of characters, viz., vowel, consonant, modified shape, compound character, and punctuation symbol. Out of these characters, vowels and consonants, which constitute Bangla alphabet, are called basic characters . There are 11 vowels and 39 consonants in Bangla alphabet. There is no concept of upper and lower case characters in Bangla script. Charac-ters in Bangla script are written from left to right. A vowel following a consonant in a word takes a modified shape in Bangla script. Such shapes of all vowels are termed as mod-ified shapes . It is noteworthy that some modified shapes attached with a consonant have two isolated parts appearing in two opposite sides of the consonant. Some modified shapes may appear just below the consonant, and some may reach its top from one of its sides with a curved or partly curved seg-ment. So, characters in Bangla script may not always appear in non-overlapping consecutive positions. Depending on the mode of pronunciation, a Bangla consonant followed by one or two consonants takes a complex shape, which is called a compound character . There are in all 280 compound characters in Bangla script. Apart from the basic characters, the modified shapes, and the compound characters, Bangla script also constitutes 10 digit patterns. An important feature of Bangla characters is Matra or head line. Excepting a few, all basic and compound characters of Bangla script have this feature.. The width of a Matra is nearly same as the width of the character it touches. All the Matras of consecutive characters appearing in a Bangla word are joined to form a common Matra of the characters appearing in the word.
Rest of the paper describes the database nomencla-ture, data collection methodology, data processing tech-niques employed and the detail composition of the database. Description and availability of the database and the ground truth generating software, developed by us, are also discussed in this paper along with the detailed reports of the bench-mark performances of our line extraction methodology on the newly developed database. 2 Detailed dataset description We have named our developed database as CMATERdb 1, where CMATER stands for Center for Microprocessor Appli-cation for Training Education and Research, a research lab-oratory at Computer Science and Engineering department of Jadavpur University, India, where the current research activity took place. db stands for database , and the numeric value 1 represents handwritten line segmentation database prepared for the current work. Currently, we have devel-oped two variations of CMATERdb 1, viz., CMATERdb 1.1 representing a database of handwritten document pages con-taining Bangla words only and CMATERdb 1.2 representing a database of handwritten document pages containing both Bangla and English words. The first version of both these dat-abases is released as CMATERdb 1.1.1 and CMATERdb 1.2.1, respectively. Database is available freely in the CMATER website ( www.cmaterju.org ) and at http://code.google.com/ p/cmaterdb . 2.1 Data collection methodologies The materials of the handwritten document pages for the proposed databases have been collected from three different types of sources, viz., class notes of students of different age-groups, handwritten manuscripts of a popular Bangla monthly magazine  X  Computer Jagat  X  X  29 ], and the docu-ment pages written by different persons, on request, under our supervision.

The document pages written under our supervision were collected from various persons with textual contents col-lectedfromnewspaperarticlesandBanglatextbookscontain-ing both Bangla and English vocabulary. The writers were asked to use a black or blue ink pen and write inside the A-4 size pages. They were imposed no other restrictions regard-ing the kind of pen they used or the style of writing chosen. Specialattentionwaspaidtoensuredatacollectionfromwrit-ers of different age-groups and educational levels. Moreover, we collected the pages from different places (home, office, school, etc.) in order to include different styles of writing. In total, 25 men and 15 women participated in this data col-lection drive. The main characteristics of our database are as follows:  X  95% of the writers were native Bengali.  X  Places of Data Collection: 40% in schools/colleges, 40%  X  Educational level of the writers: 20% 10th standard  X  Writers X  age: 40% between 15 and 25years, 30% between 2.2 Data processing techniques All the document pages were scanned using a flatbed scanner with 300 dpi gray scale image resolution. Each page, meant for the databases CMATERdb 1.1.1 and CMA-TERdb 1.2.1, is stored in bitmap file format with the nam-ing convention B###.bmp and BE###.bmp, respectively. ### is a unique integer number given to the file name to maintain sequence, and B or BE refers to the document type, i . e ., Bangla or Bangla X  X nglish, respectively. Some sample images from both these databases are shown in Fig. 1 (a-b).

After scanning, the documents were binarized by sim-ple adaptive thresholding technique, where the thresh-old was chosen as the mean of the maximum and minimum gray level values in each document image. All the binarized images were archived in DAT format, where the foreground and background pixels were represented as  X 0 X  and  X 1 X , respectively. Then, the documents were pre-processed in order to remove all the remaining salt and pepper noises like long lines in the border zone(s). To remove discontinuity in the pixel level, we have used erosion and dilation [ 8 ], two popularly used morphological oper-ators in image processing. Figure 2 b shows output of the preprocessing technique for a sample image, as shown in Fig. 2 a, taken from the database. All the binarized images are finally used to prepare the ground truth annotations for the database. 2.3 Composition of the database CMATERdb 1.1, the Bangla script handwritten document database contains 100 pages in its first version. CMA-TERdb 1.2 contains 50 handwritten document pages contain-ing both Bangla and English words. Each of the document pages of the databases are described with the help of attri-butes like page dimensions, i.e., height, width and aspect ratio, counts of number of lines and words, and statistical esti-mations of the horizontal and vertical stroke widths. Detailed descriptions of all the document pages of the two databases are uploaded as supplementary files in the database website [ http://code.google.com/p/cmaterdb ]. Descriptions of some of the sample pages and the averages and standard deviations of all the attributes of all the document pages from the two databases are shown in Tables 1 and 2 , respectively.
Document attributes related to page dimensions are actu-ally based on the scanned region of the images. In most cases, we have attempted to preserve the original/physical page dimensions, but in some cases, they may get compromised because of misalignment due to scanning or cropping of torn out page boundaries (especially relevant in cases of manuscripts collected from external sources). Counting of number of lines and words in the document images is done manually at the CMATER research laboratory. These attributes are necessary for designing effective line/word extraction algorithms. They give an estimate of the aver-age line/word spacing in document images. These count-features are also essential for performance evaluation of line/word extraction techniques. The stroke width in any binarized document image is estimated as the run of black pixels in any given direction (horizontal/vertical). Unlike the other features, these two features are computed pro-grammatically and are particularly useful in estimating an important writers X  characteristic, that is, the connectedness in writing style. These writers X  characteristics play key roles in line/word segmentation algorithms. Popularly used run-length-based features are specifically sensitive to the stroke width of any unconstrained handwritten document image. Run-length-based horizontalness and verticalness attributes in document/word images are widely used for character seg-mentation [ 31  X  34 ] from document images. To get the average horizontal stroke width, we have estimated the mean of all the continuous run of black pixels along the rows. The average vertical stroke width is computed in the similar fashion over the mean column-wise runs of black pixels. The computa-tion process of these two features is pictorially illustrated in Fig. 3 . To show the variability in writing styles of indi-viduals, in each document page, we have also provided the standard deviations of horizontal and vertical stroke widths (in respective pages) both in the supplementary material [ http://code.google.com/p/cmaterdb ] and in the Tables 1 and 2 .

The orientation/skew of text lines is estimated as the hypo-thetical angle the handwritten text lines make with the hori-zontal axis. Presence of multi-oriented text is also considered as an important characteristic of unconstrained handwritten document images. Since the objective of the current work is to accommodate normal writing styles from variety of users, extreme multi-oriented writing is not included in the current dataset collection. Some of the document pages, taken from our dataset, with limited multi-oriented characteristics of the text lines are shown in Fig. 4 a, b. 3 Ground truth of our databases Generation of appropriate ground truth data has always been a challenging and tiresome task for the kind of problem under consideration. Availability of ground truth information, how-ever, makes any database more useful, enabling proper eval-uation of one X  X  technique by comparing their output with the ground truth of the same. In this work, we have prepared ground truth images for all the images of our databases, viz., CMATERdb 1.1.1 and CMATERdb 1.2.1 for line segmentation application. For each of the two handwritten databases, we have generated the ground truth information, which has been archived as CMATERgt 1.1.1 and CMATERgt 1.2.1, respec-tively. We have prepared these ground truth images of the databases in a semi-automatic way. More specifically, we have employed our previously developed [ 22 ] technique to identify individual line segments from any document image. The possible error that might have been generated in the automated line extraction is corrected using a software tool called GT Gen version 1.1, which we have developed for this project. Basically, we have used GT Gen to recolor some lines or part of the lines, which were erroneously labeled by our technique developed in [ 22 ]. It may be noted that all the ground truth images are stored in bitmap (bmp) file format, where the background is labeled in white and individual text lines are marked in different colors. All the files in CMATERgt 1.1.1 and CMATERgt 1.2.1 are named as GTB###.bmp and GTBE###.bmp, respectively. Figure 5 a, b shows sample ground truth images from the two databases, respectively, prepared for the line extraction application. 3.1 GTGen: the ground truth generating software GT Gen version 1.1 is a software tool, developed in Visual Basic dot net technology at the CMATER research labora-tory that can label text in any chosen color. GT Gen reads images of document pages with white background. One can select any color from a color panel and use that to recolor the text by selecting the intended region with a mouse. Using this technique, we can easily correct errors in our line extrac-tion algorithm [ 22 ] to generate ground truth data. We can even use this tool to label text lines from beginning (without assistance from [ 22 ]) or even generate ground truths for word and character segmentation algorithms. This software setup is available freely and can be downloaded from http://code. google.com/p/cmaterdb . A screenshot of the developed GT Gen 1.1 software is shown in Fig. 6 . 4 Benchmark evaluation of the databases by our line extraction technique Our previously published works in this area may be found in [ 7 , 21 , 22 ]. We also participated in ICDAR-2009 Handwriting Segmentation Contest [ 20 ]. The line extraction algorithm as discussed in [ 22 ] is applied on both of the databases prepared for the current work. The brief description of the algorithm and results achieved on both the databases are described in the subsequent subsections. 4.1 Line extraction algorithm used In one of our earlier works [ 22 ], an effective technique for identifying text lines in digitized handwritten document images has been presented. Two terminologies, a component or a segment , have been used interchangeably to represent an 8-connected set of black pixels in any binarized digi-tal document page. A connected component-labeling (CCL) algorithm [ 8 ] is implemented to identify the basic segments in the text document as unique objects. During preprocess-ing, the components are categorized in one of the 4 types, viz., Type #1, Type #2, Type #3, and Type #4 according to their respective dimensional characteristics (related to their heights and widths). Type #1 components are the small dot -like segments , Type #2 components are the long lines, Type #3 components consist of large segments, which may or may not be connected, and Type #4 components comprise of the rest of the segments.

Type# 1 and Type #2 components are considered as noise and are therefore ignored. Type #3 components may be generated as a result of overlap of two or more words belong-ing to adjacent text lines or character(s) that may have lig-ature(s) or elongated portion(s) in upper or lower directions due to writing style of individual. Such components are also ignored during the initial phase of identification of text lines. Our algorithm therefore considers only Type #4 components, during the first phase of the processing.
Different dimensional features of these Type #4 compo-nents are used to identify individual text line. The post-processing step includes possible reconsideration of the Type #1 components, ignored in the first phase. Some of these might have actually been small handwritten parts of texts, and such components are allocated to suitable text lines. Finally, there might have been few cases in which some words of adjacent text lines get merged (Type #3 components). Such touching text components are carefully selected and split to form the actual text lines. Other type of Type #3 components is included in the text line with which they have maximum overlap. Illustration of the 4 different types of components is shown on a sample document image in Fig. 7 . 4.2 Results of the line extraction algorithm Performance evaluation of the line extraction algorithm is done by visually observing the identified lines carefully on the set of handwritten documents, as we have not any tool for estimating performance evaluation automatically. For manual estimation of the success rate of text line extraction technique,wehaveconsideredtwotypesoferrors,viz.under-segmented text line and over-segmented text line. If two or more text lines are identified as a single text line, then it is considered as under-segmentation error and both/all the extracted text lines are treated as wrongly extracted text lines. Similarly, if single text line components are errone-ously allocated to two or more text lines, then this text line is also considered as wrongly extracted text line due to over-segmentation. The total number of under-segmented and over-segmented text lines is reflected in the estimation of the success rate (SR) of the text line extraction technique. More specifically, SR = ( T  X  ( U + O ))/ T , (1) where,
U = number of under-segmented text lines
O = number of over-segmented text lines
T = number of actual text lines present in the document page
By applying equation ( 1 ), the percentages SRs achieved on the databases CMATERdb 1.1.1 and CMATERdb 1.2.1 are 90.60 and 92.38%, respectively. Table 3 illustrates the performance of the line extraction technique [ 22 ] on both the databases. Figure 8 a, b shows line extraction results on two sample document images, taken from the two databases underconsideration.Figure 9 showsresultsofdifferentissues of present line extraction technique. Figure 9 a shows out-put image, illustrating cases of under-segmentation and over-segmentation, and Fig. 9 b shows output image of successful touching text line separation. 5 Conclusion In this paper, we have discussed the steps involved in gener-ating a benchmark database for unconstrained, handwritten document pages containing both Bangla and Bangla X  X nglish mixed script words. This database is first of its kind in this domain of application, i.e., OCR of handwritten Indic script. Each document contains characters, text, digits, and other symbols written by different writers. In the current database, the document pages written under our supervision were col-lected from 40 writers of different age-groups, sexes, and educational levels. As an extension of the current project, more handwritten samples will be collected (under our super-vision) from a broader section of the society to incorporate a wider variation in handwriting styles. Also, we plan to collect more number of unconstrained handwritten document pages, analyze both the supervised and unconstrained documents, prepare the ground truth and make the benchmark results ready for the next database release. As discussed before, Bangla is a complex Indic script and used by more than 207million people in this world. Unlike English, Bangla script uses more than 300 character shapes, many modifiers, and 10 digit patterns. Therefore, extraction of text lines from such documents is a challenging task. Despite many research efforts on this problem domain, availability of standard data-set is limited for Bangla script. The current CMATERdb 1 database is the first effort to develop one such repository not only for unconstrained handwritten document pages contain-ing Bangla script but also for mixed script document pages containing both Bangla and English words. In future releases of our database, we may include newer scripts like Devan-agri and collect document pages containing both Devanagri and Latin script words. Extreme variations in writing styles having slants in words, and multi-oriented text lines may also be incorporated as a future work. Such databases would enable to test versatility of any line/word/character segmen-tation algorithms to their limits. It may also be noted that all the current document pages are digitized using a flatbed scanner with a given resolution. Camera captured document image analysis is also gaining popularity and may open up a new research dimension. We have already reserved our CMA-TERdb4 release for such images that till now includes only camera-captured business card images [ http://code.google. com/p/cmaterdb ]. Such images often suffer from uneven illu-mination, perspective distortion, improper focus, shadow, etc. Extending CMATERdb4 release for camera captured handwritten/printed document images is another future scope of this work.

We have also generated the ground truth images for both the databases for evaluation of line extraction algorithm and also made the ground truth generating software GT Gen 1.1 available freely in public domain. Benchmark text line extraction accuracies on these handwritten pages are also reported in the current work. In future, our aim is to increase the size of the database and to generate unconstrained hand-written page databases for other Indic scripts. We are also working at present to generate word-level and character-level databases for handwritten Bangla word images. Improve-ment of the ground truth generation software by includ-ing the line extraction routines and performance evaluation metrics are also in our future plans of research in this domain.
In a nutshell, we have attempted to provide a benchmark evaluation database for researchers interested in a challeng-ing problem domain, related to OCR of unconstrained hand-writtendocumentpagescontainingBanglaandBanglamixed with English words.
 References
