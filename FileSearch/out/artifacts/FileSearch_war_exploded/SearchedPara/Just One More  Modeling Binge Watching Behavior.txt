 Easy accessibility can often lead to over-consumption, as seen in food and alcohol habits. On video on-demand (VOD) services, this has recently been referred to as  X  X inge watching X , where poten-tially entire seasons of TV shows are consumed in a single viewing session. While a user viewership model may reveal this binging behavior, creating an accurate model has several challenges, in-cluding censored data, deviations in the population, and the need to consider external influences on consumption habits. In this pa-per, we introduce a novel statistical mixture model that incorpo-rates these factors and presents a  X  X irst of its kind X  characterization of viewer consumption behavior using a real-world dataset that in-cludes playback data from a VOD service. From our modeling, we tackle various predictive tasks to infer the consumption decisions of a user in a viewing session, including estimating the number of episodes they watch and classifying if they continue watching an-other episode. Using these insights, we then identify binge watch-ing sessions based on deviation from normal viewing behavior. We observe different types of binging behavior, that binge watchers of-ten view certain content out-of-order, and that binge watching is not a consistent behavior among our users. These insights and our find-ings have application in VOD revenue generation, consumer health applications, and customer retention analysis.
 Binge Watching, Censored Poisson Regression, Mixture Model
In recent years, the ability to record user behavior has given rise to datasets containing consumption patterns of individuals for ac-tivities as diverse as alcohol consumption [1] and gambling [2]. Of course, not all users consume at the same rate, with some users specifically over-consuming during a single session. This is a com-pelling problem, as the ability to identify the over consumption of food, alcohol, or gambling behavior has applications in public health [18]. The focus of this paper is on modeling and inferring  X  This work was completed while at Technicolor Research.
 the user consumption behavior in order to identify abnormal over-consumption, or  X  X inging X  behavior from real-world consumption data. Specifically, we focus on user binging of video content, or  X  X inge watching X .

For years television episodes were consumed in a standard net-work broadcast format, where each new episode was released once a week and then consumed one-at-a-time. In recent years, with the advent of video on-demand (VOD) services, consumers now have the ability to access full seasons of television episodes at once. This has led to the rise of binge watching, where multiple TV episodes, and potentially entire seasons, are consumed in a single viewing session. Recent market research studies have shown that over of consumers binge watch on a regular basis [17]. This change in watching habits, and consumers demands to continue binge watch-ing, has resulted in modified viewership numbers, content release schedules, and consumer expectations.

Unfortunately, the precise modeling of user binge watching be-havior is difficult. While the popular press usually defines binge watching with respect to a specific number of episodes consumed for all scenarios ( e.g., between two and six episodes in one sit-ting [3]), this ignores factors such as behavior changes due to the type of content or the day of the week. To create an accurate view-ership model from real-world VOD playback data, several factors must be considered. The first factor is incorporating when the user has consumed all their available items, resulting in  X  X ensored X  data, where the user cannot possibly consume more but may desire to. The second is the lack of homogeneous behavior among all users, where the binge users may behave considerably different than those that consume only a handful of episodes. Finally, external factors, such as the time of day, or details about the specific object being consumed  X  such as, what specific show is being watched  X  can determine different behavioral patterns.

In this paper, we model, characterize, and infer consumption be-havior of users by accommodating all the factors mentioned above using real-world playback observations. We reject a one-size-fits-all approach and create a statistical mixture model that adapts to the many sub-populations of the observed user base. Additionally, we account for the possibility of censored data and learn the contri-bution of covariates ( i.e., external factors) on the number of items consumed. The result is framing our user viewership problem as censored Poisson regression with latent factors . To estimate the relevant parameters of this model, we derive a novel Expectation-Maximization (EM) algorithm that incorporates these features.
Given our model, we infer various aspects of the user consump-tion behavior. This includes predicting the total number of episodes a user will consume from the start of a viewing session. Our tech-nique results in an improvement of 4% in RMSE and 9% in MAE over other tested techniques. Additionally, we show how this model can predict if the user will continue watching another episode dur-ing the session. For this application, our model results in classi-fication AUC over 7% better than off-the-shelf techniques. These consistent improvements demonstrate the accuracy of our viewing model.

Finally, we demonstrate how this model can be used to detect binge watching sessions. We determine what constitutes  X  X inge watching X , identify sessions that involve binge watching, and show how behavior of users in such sessions deviates from normal be-havior. We describe the particular television show titles and genres that cause binge watching, with the observation that comedies (like  X  X he Big Bang Theory X  and  X  X ow I Met Your Mother X ) result in more and longer binge watching sessions than dramatic shows (like  X  X omeland X  and  X  X he Walking Dead X ). We also discover that users binge differently dependent on the content. On story-driven televi-sion shows (such as many dramas or  X  X ow I Met Your Mother X ), a vast majority of users binge the episodes sequentially, allowing them to complete, or catch-up on, episodes quickly. On shows without a dominant storyline across episodes (such as  X  X he Big Bang Theory X  or  X  X odern Family X ), almost half the binge sessions view episodes out-of-order, possibly as a background activity. Our insights demonstrate how binge watching is a distinctly different activity compared with regular viewing behavior.
Characterizing aggregate traffic on Video On-Demand (VOD) services has been a well studied area. Prior work often focused on detailing the traffic patterns from a specific service, such as Telia-Sonera [4], China Telecom [22], or YouTube [7]. These specific papers focused on content popularity and viewing trends for the purposes of service improvements. This has direct application on content caching and availability, but is separate from our focus on individual user sessions. The modeling of individual user sessions in VOD was the focus of [6]. This study analyzed content popu-larity and how it changes as a result of individual user behavior. To the best of our knowledge, no prior VOD study targets viewer consumption patterns with the consideration of the application of binge-watching characterization and inference. To this date, the primary source of binge watching characterization has come from explicit market research surveys.

Netflix conducted a survey on the binge watching behavior of 3,078 adults aged 18 and older, of whom 1,496 people ( 48 . 6% respondents) stream TV shows at least once a week [3]. Among these participants, 61% reported they binge watch regularly, where binge watching is defined as watching two to three episodes of a single TV series in one session. More recently, TiVo conducted a similar survey on a group of 15,196 users [17]. They define binge watching as watching 3 or more episodes in one day. The results of this survey indicate that 91% of users report binge watching as a common behavior, of whom 40% and 69% reporting they had at least one binge watching session within a week and within a month of the survey, respectively. According to the responses from both surveys, factors driving binge watching include catching up on TV shows and compensating for the delay in learning about a show since the first time it was aired. We note that all of these prior research has focused on qualitative user responses, and not on actual user playback information.

Our focus on modeling user episode playback takes the form of building regression models on event counts. Parametric regression models, such as Poisson regression model and its variants [15], have been extensively used for modeling event data. Extensions, such as censored Poisson regression model in medical and bio-logical studies [21], and mixtures of Poisson regression has also been applied in various fields [10, 11, 16]. These extensions can be viewed as a limited case of our proposed model of censored Poisson regression with latent factors. Recently Karlis et al. [13] proposed a censored mixture Poisson regression model which is similar to our model. In contrast, we focus on session dependent censorship while this prior work considered the traditional setting where censorship threshold is fixed for all observations. Additionally, Karlis et al. simplifies their model parameter estimation, whereas our algorithm optimizes the exact likelihood. Finally, our regression model is a more general form of survival analysis, which has been commonly used in various other time-to-event domains, such as user engage-ment modeling and churn prediction [12], patient treatment stud-ies [14], and auction price inference [20].
We received a sampled set of anonymized users from a US-based streaming video on-demand service across a timespan of 16 months from January 2014 to April 2015. This service is pay-per-content and consists of user interactions ( e.g., content play actions, pause actions, etc.) from TV, tablet, and phone devices. Our focus throughout the remainder of the paper is on modeling television consumption habits via this dataset, specifically with assessing ab-normal binge consumption patterns. In order to assess viewing con-sumption patterns, we must first define a discrete television viewing session. Informed by prior work, we use the following definition,
D EFINITION 1. A watching session consists of all interactions of a user containing watching at least one episode of television and with less than an hour between interactions.
 As a result, we created user viewing sessions over our sample of VOD data. We then removed the least popular shows and kept tele-vision series that have been watched in more than 100 sessions. In order to filter out infrequent users, we only kept sessions of users who purchased five or more episodes. The resulting dataset contains 65 popular television titles, 3,488 users, and 26,404 total viewing sessions across these users, with each session lasting an average of 91 . 8 minutes and a median of 62 . 0 minutes.
Considering just the number of episodes consumed in each ses-sion, the histogram can be seen in Figure 1a presented in log scale. As expected, we find a majority of users consume only a handful of episodes during each session. We also find that this distribu-tion has a relatively heavy tail, indictating potential abnormal over-consumption behavior in some sessions.

Using this actual VOD playback dataset, we find that viewing be-havior is not a consistent phenomenon. For example, in Figure 1b, we show the average number of episodes viewed per session given the day of the week. This plot indicates that viewers have shorter viewing sessions on weekdays compared with the weekend ( i.e., Friday, Saturday, and Sunday). Additionally, we show the average number of episodes consumed relative to the start hour of the ses-sion in Figure 1c for both weekday and weekend. Again, we find that the time context changes user behavior. In particular, there are more viewing activities during weekend nights as opposed to week-end days, and the difference between weekend and weekday views appears to be higher later in the day. Finally, our dataset also re-veals different behaviors relative to the mechanism the viewer uses to consume content. We find that on mobile devices users con-sume on-average 1 . 58 episodes per session, while on televisions they consume 2 . 00 episodes on average.

In addition to the user context of time and device, viewing be-havior is also modified by the content itself. We find that TV shows generally fall in two categories in terms of the length of their individual episodes; with episodes commonly either 22 minutes or 44 minutes in length, such that with commercials the episodes would be either a half-hour or one hour in length, respectively. In our VOD data, the average number of episodes per session is re-ported to be 1 . 79 for longer episodes whereas it is 2 . 54 episodes.

In Table 1, we also show the average number of episodes con-sumed for specific television shows. We find that this changes dra-matically between different titles and different genres. For exam-ple, genres of drama/horror/action tended to have fewer episodes viewed per session compared with television shows in the comedy genre. Additionally, we find that even shows in the same genre can have different behavior, such as the more narrative driven comedy show  X  X ow I Met Your Mother X  resulting in viewers watching on-average half an episode more per session compared with the less story-focused comedy of  X  X he Big Bang Theory X .
 Table 1: Average Number of episodes consumed per session for given television shows.

We also need to consider the availability of content for partic-ular television shows. For example, consider there are only three episodes of a particular television series available for the user, and the user consumes all three episodes. This is censoring behavior. In our dataset, we find that 20 . 9% of all sessions are censored, in-dicating that the termination of a session may not have been by user choice. We find this phenomena is not uniformly distributed across television shows, with 41 . 1% of  X  X he Walking Dead X  sessions cen-sored, only 6 . 04% of  X  X he Big Bang Theory X  censored, and of  X  X ow I Met Your Mother X  sessions censored.

Our observations from this dataset indicate considerable differ-ences in viewing behavior due to user context ( e.g., time of the day, day of the week) and the television show content. In addition, the frequent occurrence of session censorship indicates that many of the session terminations may be forced by content availability. These insights indicate the need to consider these multitude of fac-tors in order to accurately model user viewing behavior.
The characterization of our playback dataset indicates pre-dictable patterns in user behavior. We find that certain timing, content, and metadata all result in distinct differences in viewing patterns. This points to the ability to model user behavior by incor-porating these factors. An accurate viewing model allows for user behavior inference, such as, prediction of consumption, estimation of session length, and the extraction of binge watching events.
In this section, we present the assumptions and details of the pro-posed model of the consumption behavior of users. As mentioned earlier, a key point in our model is to account for the possibility of censorship for sessions where the user cannot consume more episodes but may, in fact, desire to. We also consider the impact of external factors, such as content and context features, on user consumption behavior. Finally, to account for the variability of be-havior among user population, the proposed model consists of a mixture of components. A novel Expectation-Maximization (EM) algorithm is proposed to estimate the parameters that correspond to these factors.
Let v i denote the number of episode views in the session As defined previously, a session is the unit of interaction time of the user with the VOD in a single sitting, and the number of views is the discrete value of interest on which our model focuses. An initial assumption is that this value follows a Poisson distribution with parameter , whose probability mass function is, We choose the Poisson distribution for this purpose mainly because it is suitable to express the probability of counting events, such as the number of episodes viewed. While different discrete distribu-tions could be used here, such as a geometric distribution, we later find in Section 5 that this offers no improvements.
In the VOD domain of our interest, we consider censorship to occur if the last episode watched in a session is the latest episode of the corresponding television series that is aired and available on sorship in our setting varies and depends on the current status of the show at the time of a session. For ease of notation, we introduce 1 For ease of notation, we consider v i to be the number of episodes consumed in session i , minus one ( e.g., viewing one episode would result in v i =0 .) used in media content which is known as the act of suppressing unwanted parts from the content. the value h i to denote the number of episodes available to the user during session i . This censorship threshold depends on the content that is viewed in the session; hence, it is session dependent. This is different from the standard censorship setting in which a fixed censorship threshold across all observations is induced by, for in-stance, the ending of a clinical trial [14] or user inactivity after a certain point on the study [9].
We now define our consumption model that incorporates (1) -session censorship, (2) -the contribution of user context in the form of covariates, and (3) -the heterogeneous nature of the user population.
 Censorship  X  We define c i = I ( v i = h i ) as a binary variable consumed the latest available episodes in the session. By assuming independence across N observed sessions, the likelihood of single Poisson distribution with censorship is obtained as: Note that in Equation (2), the likelihood of viewership for a cen-sored observation is considered as Pr( v i h i ) to take into ac-count the chance that the user could continue watching any further episode(s) of the series, had the episode(s) been available for view-ing at the time.
 External Factors  X  Each session i can be represented by a group of external factors, such as the viewing device used, the time of day, etc. These constitute the vector of d covariates ( x sessions (as in Eq. (1) and (2)), a session dependent parameter introduced to capture the dependency of consumption rate on these factors as discussed in Section 3. We use the log-linear function commonly used as the link function in Poisson regressions, This facilitates the derivation of our EM algorithm presented later. Mixture Components  X  Finally, to account for the variability in the behavior of the user population, we consider a mixture of Pois-son distributions to model the heterogeneous consumption behavior between sessions.

Let K denote the number of mixture components, and k 2 { 1 ...K } denote the index of each component. The probability mass for v i can be written as follows: Pr( v i ; ,  X  )= where  X  k is the weight of the mixture component k ,  X  k 0 P at least h i episodes in the session according to component mixture model. Finally, the likelihood of all N sessions is: Pr( v ; ,  X  )=
Note that, the session dependent Poisson parameter and the co-efficient vector, respectively denoted by i,k and k , both depend on the component k . In other words, the heterogeneity of the user population results in various behavioral patterns that are captured by different variants of these parameters. Similar to Equation (3), the log-linear relation holds between these two parameters in each component k : log( i,k )= x &gt; i k . It is noted that the censored likelihood Pr k ( v i h i ) is calculated using the session dependent consumption rate k,i , hence, it is also a function of k . A sum-mary of notations is provided in Table 2.
We consider Maximum Likelihood Estimation (MLE) for the model parameters  X  = { k ,  X  k } K k =1 given N observed sessions, their covariates, and the session dependent censorship thresholds.
A closed-form MLE is intractable in our mixture model, hence we instead use an Expectation-Maximization (EM) based approxi-mation [5, 8]. We note that the introduction of covariates and ses-sion dependent censorship requires the derivation of a specific EM algorithm for our model.

Let z i 2 { 1 ,...,K } be the mixture assignment of session Our goal is to lower bound the data likelihood function by, and maximize this lower-bound. In the E-Step of the iteration iteration and maximize the lower-bound with respect to all distri-butions q ( z ) ; in the M-Step, we fix q ( z ) and find the optimum that maximizes the lower-bound. The E-Step and M-Step are con-ducted alternatively.
 E-Step: By Jensen X  X  inequality, the optimal solution for q ( z ) iteration. This can be calculated explicitly,  X  i,k := Pr( z i = k | v i ;  X  posterior probability of the session i being sampled from mixture component k .
 M-Step: Using Eq (7), the lower-bound in Eq. (6) after E-Step can be written as: Now we optimize  X  ( t ) = arg max Q (  X  ;  X  ( t 1) ) . For where is the Lagrange multiplier to take into account the con-straint that  X  j values must sum to one. For k , we numerically solve the following problem: The detailed derivations can be found in Appendix.
 Algorithm 1 Censored EM Algorithm: EM-fit
Input: Session covariates { x i } , consumption observations censorship thresholds { h i } , number of iterations T , number of components K .

Initialize parameters  X  (0) =(  X  (0) , (0) ) for t 2 1 ...T do end for
Output: Estimated parameter values, b  X  =(  X  ( T ) , ( T ) We present the pseudocode of the estimation algorithm, called EM-fit , in Algorithm 1. EM-fit receives three session depen-dent inputs: covariates x i , episode counts v i , and the corresponding censorship criterion h i for sessions i =1 ,...,N , and the number of components K . EM-fit iterates over the E-Step and M-Step for T steps, where T is the index of the step in which the con-vergence criterion is satisfied. We use the common convergence criterion that the algorithm is deemed to have converged when the change in the data log-likelihood falls below some threshold, which we specify in Section 5.
In this section, we present results on the real-world VOD view-ership dataset described in Section 3. We first show that our model can fit better than simpler models and that each of our factors con-tribute to a more accurate fit to our observed data. We then show that our model can be used to predict user behaviors in two applica-tion scenarios: inferring the number of episodes viewed in a session and classifying if the user will continue to watch the next episode.
To infer our model parameters, we run Algorithm 1. For the specific choice of covariates, x i , we consider the following:
All these features are binarized and concatenated, resulting in a feature vector for each session of dimension 104 .

We run Algorithm 1 until the change of the log-likelihood on training data is below 0 . 01% . For updating the coefficient vectors, , we use gradient descent and stop when the frobenius norm of gradient is below 0 . 01 . Parameter vector (0) simplex. To avoid local minimas, we use 10 random initialization for Algorithm 1. Finally, all results in this section are presented with respect to 5-fold cross validation. First the hypothesis of using the Poisson distribution is tested. We compare the Poisson distribution against another candidate, ge-ometric distribution. The estimation for geometric distribution with covariates, censorship, and latent factors can be similarly derived as we performed for the Poisson case in Section 4. Figure 2 compares the empirical probabilities of the observed number of episodes per session with the fitted models for a single Poisson, single geomet-ric distribution, mixture Poisson ( K =3 ) and mixture geometric ( K =3 ). We find the average log-likelihood to be 1 . 30 for single Geometric, 1 . 34 for single Poisson, 1 . 27 for mixture of Geo-metric, and 1 . 12 for mixture of Poisson. We find that although a single geometric distribution can fit better than a single Poisson distribution, the mixture of Poisson can fit best to the data. The figure demonstrates that this is especially true with respect to the tail of the distribution. It is also known that mixture of Poisson distributions often have thick tails which make them suitable for long-tailed data [19]. This reinforces our decision to use the Pois-son distribution in our model. Figure 2: The learned model for single Poisson/Geometric (upper), and
Next, we consider the choice of the number of mixture com-ponents K . The predictive log-likelihood is used as a performance metric and evaluated using 5 -fold cross-validation. Specifically, we estimate the model parameters { k ,  X  k } K k =1 from the training set and then evaluate the log-likelihood of the hold-out validation set for various values of K . We also normalize the log-likelihood by the number of sessions in the validation set.

The average predictive log-likelihood across 5 -fold cross-validation as well as the standard deviation of this value are de-picted in Figure 3. We observe that K =3 is the knee point of the curve: by increasing K =1 to K =3 the likelihood improves by a large margin. Meanwhile, for K&gt; 3 there is no significant change in likelihood. This suggests that K =3 is a good candidate. As a result, we fix K =3 for the rest of the paper.
We next compare the performance of our proposed model against multiple baselines in fitting to the real-world data. These baselines can be viewed as different combinations of the three key factors -mixture , censorship , and covariates . They are summarized in Ta-Table 3: Settings of the proposed model and various baselines.  X  X  X  repre-Figure 4: Predictive log-likelihood of the proposed model comparing to ble 3. For instance, the censored Poisson regression model (F) is a special case of our model when K =1 . As a consequence, we can understand the importance and significance of these components of our model. We note that EM-based estimation algorithms can similarly be derived for these models.

We use predictive log-likelihood on 5 -fold cross-validation as the performance metric to evaluate the robustness of different set-tings as adding modeling complexity does not necessarily improve the predictive likelihood. The results are shown in Figure 4. The log-likelihoods are normalized by the number of sessions in each validation set and the standard deviations over 5-folds are reported.
Overall, our model achieves the best predictive accuracy com-pared to all the baselines. We find that introduction of latent factors, the censorship, and the covariates all contribute significantly to im-proving modeling accuracy. One can compare the proposed model (H) against the model without mixtures (F) and observe that adding these mixture components can improve the modeling accuracy by a large margin. Additionally, the improvement of our model (H) ver-sus one without censoring (D) shows that incorporating censorship knowledge also significantly enhances the modeling accuracy.
We consider predicting the number of episodes a user will watch given information available at the beginning of a session. Noting that we observe the covariates x i and the censorship threshold when session starts, we predict the number of episodes a user will watch  X  v i as, where E ( v ; k )= P h i 1 is the censored expectation of a single Poisson distribution, with i,k =exp( x &gt; i k ) as the session dependent Poisson rates and the parameters k and  X  k are learned from the training set.
We predict the number of episodes viewed in a session as the expectation based on the session dependent covariates and censor-ship threshold. It is noted that Eq. (11) guarantees that prediction using our censored model.
 Table 4: The predictive root-mean-square-error (Pred.RMSE) and the pre-
The problem of predicting v i when a session starts can be viewed as a regression problem where the response variable is v i regression features are x i and h i . Therefore, we compare our al-gorithm against standard linear regression, ` 1 regularized linear re-gression (Lasso), and Poisson regression (log-linear regression, the setting  X  X  X  as in Table 3). Additionally, we perform a version of lin-ear regression that considers the censorship threshold h i for linear coefficients , the inferred value is b v i =min h we refer to this as Thresholded Linear Regression .

As evaluation metrics, we compute the predictive root mean square error ( RMSE ) and mean absolute error ( MAE ) on the val-idation set using 5 -fold cross-validation. We compare our model against the statistical baselines in Section 5.2 and the regression baselines, using the same setting id as in Table 3 for consistency. The mean and standard deviation across 5 -fold cross-validation for Predictive RMSE and MAE are summarized in Table 4.

As it is observed in the table, the proposed model ( X  X  X ) outper-forms the regression baselines (linear regression, Lasso, Poisson regression) in both RMSE and MAE metrics. We note that all lin-ear regression methods directly minimize the square error as train-ing objective, hence they are given the advantage in term of RMSE metric. Therefore the improvement is not expected to be signifi-cant. Our model, however, outperforms these baselines in predic-tion while not explicitly optimizing RMSE or MAE. This suggests that our model can better predict the user behavior given the ex-ternal factors. We note that the censored Poisson Regression ( X  X  X ) can predict as accurate as our model, due to the fact the we use the expectation in Eq. (11) and the latent mixture assignment is marginalized.
Another application of our viewership model is to predict the continuation of a viewing session. Specifically, given the number of episodes a user has already watched in the middle of a session v , we would like to predict if they will continue to watch the next episode. Given our model, we use Pr( v&gt;v c | v c ; ,  X  ) probability of continuation, where ,  X  are learned from the train-ing set. This conditional probability can be calculated as, Pr( v&gt;v c | v c ; ,  X  )= where p ( z | v c ; ,  X  ) is the posterior likelihood of component membership given the current watched episodes as in Eq. (7).
We then predict the event of continuation by thresholding this conditional probability. Note that this prediction problem is a stan-dard binary classification problem where class labels are user continued to watch or 0 if the user stopped. Therefore, we compare our model against the standard classification algorithms using logistic regression and support vector machines (SVMs). Table 5: The Area Under Curve (AUC) and Cross Entropy of the proposed
For each session i with v i television episodes, we can construct v training or testing samples at the end of each episode. We first create 5 -fold cross-validation on the sessions and further convert each session in training and validation sets into continuation data. We consider a collection of performance metrics: the Area Under Curve (AUC), the predictive cross entropy, and the correct classifi-cation rate evaluated on validation sets. The cross entropy can be computed as P aged over all test samples, where y j is the label of continuation and p
Table 5 summarizes the prediction result for our model against the statistical baselines summarized in Section 5.2 and the classi-fication baselines. The mean and standard deviation across the folds are reported. We observe that in Table 5, the proposed model outperforms the compared approaches in all performance metrics. Figure 5: Classification rates on validation set when considering the cur-
We also investigate how the prediction accuracy changes as the user watches more episodes. Specifically, we design the exper-iment to only predict the continuation when v c is above a cer-tain threshold. Figure 5 summarizes the results for our model and standard classification algorithms. Note that the number of training/validation samples are smaller and more biased when the threshold for v c increases. Therefore, we also include the simple majority votes rules as baselines. For simple majority vote, we predict a user would continue after watching v episodes if most training samples at the end of v episodes continued. As we can see in Figure 5, the prediction accuracy increases as the threshold on v increases. This matches the intuition that the event of contin-uation is easier to predict if we have more observation history in a single session. However, our algorithm consistently outperforms the baselines. This shows that our model can accurately infer the behavior type of a session and make predictions as we gather more observations in a session.
The experimental study in Section 5 validates that our proposed model both fits to the data and also has applications in inferring user viewing behavior. We can also use this model to segment particular behaviors automatically from our model inference algorithm. In this section, we discuss how our model can be used to categorize and interpret distinct types of viewing behavior. In particular, we focus on the over-conusumption of content, or  X  X inge watching X  behavior.
We begin by considering the real-world implications of our learned mixture model. Given K =3 mixture components, Fig-ure 6 depicts the distribution of each component of the learned model for the three most popular television series in the dataset,  X  X alking Dead X ,  X  X omeland X , and  X  X he Big Bang Theory X .

We find that the learned mixture components reveal three distinct behaviors that are consistent across the dataset. (1) The component with the smallest captures the sessions where the user watches a few ( i.e., one or two) episodes in a session. (2) The component with the value in between those of the other two corresponds to the sessions in which user consumes an above average number of episodes ( i.e., 3 to 7) as indicated by the green curves in Fig-ure 6. (3) The third component with the largest consumption rate (the red curves in Figure 6) represents users who watch an extreme number of episodes in a session.

We find these different types of behavior to be consistent not only across the examples in Figure 6 but also hold for all data sam-ples. This is validated by Figure 7 in which we plot the distri-butions for the learned Poisson parameters i,k for each compo-nent ( k =1 , 2 , 3 ) and across all viewing sessions 3 . Overall, the consumption rates for the three components are distinct. The av-erage consumption rate for the second component is 2 . 9 episodes per session and is 6 . 8 for the third component. These two compo-nents are in accordance with the  X  binge watching  X  in prior studies [3, 17]. This motivates us to define these two component as the binge-watching components. Figure 7: Box-plot of the distribution of i,k +1 across the three com-A Data-Driven Binge Watching Definition -Given the two com-ponents associated with binge watching behavior, we then iden-tify a binge-watching session by calculating Pr( z i = k | v according to (7), the posterior mixture assignment of session component k . Formally, we define a session to be a binge-watching session if k =2 or k =3 is the most likely mixture assignment of the session. This provides a fully data-driven approach to define and infer binge-watching behavior.
 Different Types of Binge Watching -While existing studies char-acterize binge-watching as a single type of viewing behavior [3, 17], our model reveals that there are in fact two sub-classes of binge-watching. Specifically, the component k =3 captures the sessions in which a significantly large number of episodes is con-sumed. This is a rather extreme behavior than the component 2 . Therefore, we define the component k =3 as  X  X yper-binge X  watching and corresponding sessions as  X  X yper-binge X  watching sessions. We believe this gives a finer-grain analysis of binge-watching behavior. Similarly, we refer to sessions corresponding to component k =2 as the  X  X inge X  watching sessions, and the ones corresponding to component k =1 as the  X  X egular X  sessions.
Using this definition, we find that 22 . 2% of all watching ses-sions fall in one category of binge watching, i.e., binge watching sessions or hyper-binge watching sessions. To be more explicit, 20 . 1% of sessions are binging sessions and 2 . 1% of sessions are hyper-binging sessions. This indicates that  X  X yper-binging X  is a rare yet extreme viewing behavior. 3 Noting that we subtract 1 from v i to simplify the model derivation, we plot +1 .
 Content and Context-Aware Binge Watching Definition -Our model learns differences between the viewing behavior for different types of shows, days of the week, and devices used for watching. These are summarized in Figures 8, 9, and 10. In these figures, the distributions of i,k across the three components are shown.
Recall that in most binge-watching studies so far, a one-size-fits-all definition of binging is used [17]. However, Figure 8 shows that binge-watching in our model is adapted to the content of spe-cific watching sessions. For example, in Figure 8, a binge watch-ing session ( k =2 ) for the 20-minutes-long comedy  X  X ow I Met Your Mother X  has on average more than five episodes while the 1-hour long action drama  X  X omeland X  has on average only two episodes when binging. Similarly, a hyper-binge watching session ( k =3 ) for  X  X ow I Met Your Mother X  has on average more than 10 episodes per session while that of  X  X omeland X  reveals only four episodes. We can also observe that the less story-focused com-edy,  X  X he Big Bang Theory X , is binge-watched and hyper-binge watched with a smaller consumption rate than  X  X ow I Met Your Mother X , which is narrative-driven ( i.e., the episodes are connected by a common storyline).

Figures 9 and 10 demonstrate that our binge watching definition is context-aware. We observe that binge and hyper-binge watch-ing sessions on Friday, Saturday, and Sunday have more episodes viewed compared to that of weekdays. Similarly, the dominance of using TV devices ( i.e., tv and blu-ray) over mobile ( i.e., iPad, and iPhone) appears to be more significance for binge watching and hyper-binge watching sessions compared to regular sessions.
Finally, we consistently observe the distinction between the hyper-binge component k =3 and the binge component k =2 in terms of consumption rate across different contents and context in Figures 8, 9, and 10. In addition, we note that the consumption rates for the first component are between one and two episodes per session. This suggests that the regular component k =1 captures a uniform behavior across all sessions.
A characterization of binge watching behavior is presented here in terms of (1) binge watching behavior across individual users, (2) difference in viewing patterns between binging and non-binging sessions, and (3) the transition patterns among different viewing behavior types.
 User Characterization -Given the most likely component assign-ment for all sessions of a particular user, we calculate the fraction of sessions that correspond to one of the three components. For each component, we sort the fraction of users in ascending order and summarize the results in Figure 11. We note that the points on different curves with the same x-value may not correspond to the same user. Figure 11 indicates that binge-watching is not a uniform behavior across the user-population. We find that 64% of users in our dataset binge-watched at least once while 11% of users hyper-tire collections of television episodes has led to the rise of binge watching behavior. In this paper, we offered a  X  X irst of its kind X  study of viewer binge watching habits from real-world video on-demand records. We characterized the real-world observations to determine relevant context covariates and limitations  X  such as data censorship. Using these insights, we constructed a statistical view-ership model and validated that it fits better to the data than all other tested models. We then showed how this viewership model can be used to infer features of the user viewing session, such as the number of episodes viewed and whether the user will continue watching. Finally, we exploit the properties of this model to intro-duce a methodology that automatically extracts attributes of binge watching behavior. Our characterization reveals different types of binging behavior, the prevalence of binge watchers viewing con-tent out-of-order, and that binge watching is not a consistent be-havior among our users. Next steps include modeling user-level behavior, examination of mechanisms to influence binge watching behavior, analysis of binge consumption of other types of products ( e.g., video games, gambling, etc.) and how it differs from televi-sion binge watching. [1] Alcohol Research Group Datasets. [2] The Transparency Project. [3] Netflix declares binge watching is the new normal. [4] H. Abrahamsson and M. Nordmark. Program popularity and [5] C. M. Bishop. Pattern Recognition and Machine Learning . [6] L. Carlinet, T. Huynh, B. Kauffmann, F. Mathieu, L. Noirie, [7] M. Cha, H. Kwak, P. Rodriguez, Y.-Y. Ahn, and S. Moon. [8] A. Dempster, N. Laird, and D. Rubin. Maximum likelihood [9] G. Dupret and M. Lalmas. Absence time and user [10] L. A. Hannah, D. M. Blei, and W. B. Powell. Dirichlet [11] Y. He and K. Wang. Inferring search behaviors using [12] K. Kapoor, M. Sun, J. Srivastava, and T. Ye. A hazard based [13] D. Karlis, P. Papatla, and S. Roy. Finite mixtures of censored [14] R. Kay. Proportional hazard regression models and the [15] C. McCulloch and S. Searle. Generalized linear and mixed [16] S. Nagano, Y. Ichikawa, N. Takaya, T. Uchiyama, and [17] TiVO. Viewers X  New TV Reality: A  X  X eason X  = One Day. [18] R. A. Volberg. The prevalence and demographics of [19] G. Willmot. Mixed compound Poisson distributions. Astin [20] W. C.-H. Wu, M.-Y. Yeh, and M.-S. Chen. Predicting [21] H. Yeh, B. Gajewski, P. Mukhopadhyay, and F. Behbod. The [22] H. Yu, D. Zheng, B. Y. Zhao, and W. Zheng. Understanding We present the details of derivation for Algorithm 1 for parameter estimation in M-step. Recall that the overall objective is,  X  subject to P forward to show  X  ( t ) max where i,k =exp( x &gt; i k ) and Pr k  X  X  also depend on k this optimization numerically using gradient descent. We first cal-culate r r k log(Pr k ( v i h i )) = 1 = 1 Pr k ( v i h i ) Pr k ( v i h i ) On the other hand, r all, we have, r k l (  X  ) =
