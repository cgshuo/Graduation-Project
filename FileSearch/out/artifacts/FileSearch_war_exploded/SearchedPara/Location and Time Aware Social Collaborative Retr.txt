 In location-based social networks (LBSNs), new successive point-of-interest (POI) recommendation is a newly formu-lated task which tries to regard the POI a user currently visits as his POI-related query and recommend new POIs the user has not visited before. While carefully designed methods are proposed to solve this problem, they ignore the essence of the task which involves retrieval and recommen-dation problem simultaneously and fail to employ the social relations or temporal information adequately to improve the results.

In order to solve this problem, we propose a new model called location and time aware social collaborative retrieval model (LTSCR), which has two distinct advantages: (1) it models the location, time, and social information simulta-neously for the successive POI recommendation task; (2) it efficiently utilizes the merits of the collaborative retrieval model which leverages weighted approximately ranked pair-wise (WARP) loss for achieving better top-n ranking results, just as the new successive POI recommendation task needs. We conducted some comprehensive experiments on publicly available datasets and demonstrate the power of the pro-posed method, with 46.6% growth in Precision@5 and 47.3% improvement in Recall@5 over the best previous method. H.3.3 [ Information Storage and Retrieval ]: Informa-tion Search and Retrieval X  Information Filtering, Retrieval Models Algorithms, Experimentation Collaborative Retrieval, Location based Social Networks, Successive Location Recommendation c  X  With the popularity of location-based social networks (LB-SNs) allowing users to share their location-embedded in-formation or attend location-aware activities at given time, more and more researchers pay attention to research tasks in this field, such as event-related recommendation [14, 27, 26], location prediction [12, 1], and location-aware information retrieval [21], etc.

In these studies, successive POI recommendation [4] is a newly emerging task which tries to treat users X  current POIs as POI-related queries and recommend new POIs users have not visited before. Hence, it can be regarded as a hybrid task involving both retrieval and recommendation. It is important for real-time location-aware recommender systems. For example, it is extremely common that when a user visited one location just now, he may not be clear where to go next. The recommender system can treat the current location of the user as his location-aware query and automatically recommend new POIs, which is beneficial for both users and businesses.

Compared with traditional POI recommendation task which also tries to recommend new POIs for users [3, 25, 13, 7, 10, 9], the essential difference is that the performance of succes-sive POI recommendation task is largely influenced by users X  current visiting locations. To be more specific, the location which a user will visit next is usually near his current vis-iting POI. Besides, the shift from one specified location to another specific location may be very common. One exam-ple is the popular travel route in a tourist city, in which the transition from one POI to another is usually fixed. With-out explicitly modeling the users X  current visiting POIs, the approaches of traditional POI recommendation cannot cap-ture the localization of successive visiting and the frequent shift patterns. Thus, it will result in poor performance by directly applying the models designed for traditional POI recommendation to successive POI recommendation task.
Existing approaches for successive POI recommendation task [17, 4] consider users X  current locations to generate rec-ommendation results. Nevertheless, they ignore to utilize the social relations between users or temporal information of visiting adequately, which can influence users X  final decisions to a certain extent. On the one hand, social relations indi-cate that users may visit locations their friends have been to, which is reasonable as friends have similar interests. On the other hand, users and locations both have their own tempo-ral characteristics. Different users may have various visiting patterns in the same period which are determined by their own habits. POIs also have different probability of being visited in different time periods. For example, restaurants are more likely to be visited in lunch and dinner time. In later data analysis, we verify that check-in patterns of users and POIs over timelines are indeed diverse through correla-tion analysis. Besides, the characteristic of hybrid retrieval and recommendation involved in this task still needs to be studied, especially when modeling the top-k ranking results of recommendations which is significant for successive POI recommendation, as for each user the number of successive POIs visited for specific location-aware query is small.
To tackle the above issues, we propose a new model called location and time aware social collaborative retrieval model (LTSCR) . It is a natural extension of the recently proposed collaborative retrieval model (CRM) [20] which models query, user, and item in a unified model and first employs the loss function called weighted approximate rank pairwise (WARP) loss [18, 19] in collaborative filtering to gain better top k rec-ommendation results and is more suitable for bybrid task in-volving retrieval and recommendation task simultaneously, which is similar to our successive POI recommendation task. In order to better model the users X  successive check-in be-haviors in LBSNs, LTSCR considers users X  current visiting locations, visiting time, and user himself as implicit queries. Each candidate location is composed of three types of la-tent factors: (1) the first kind of factor captures transition patterns between successive check-in POIs, (2) the second models preference between users and locations, (3) and the third reveals locations X  popularity over time. Besides, so-cial relations are utilized to regularize the degree of interest similarity between friends, and the localization property is employed to constrain candidate POIs to be within the near regions of the query POI.

In summary, our major contributions in this paper are summarized as follows:
The rest of the paper is organized as follows: we first discuss the related works in Section 2. Section 3 gives nec-essary preliminaries for successive modeling. In Section 4, we formulate our model in detail. Section 5 presents the experimental results and analysis. Finally, we conclude this paper in Section 6.
In this section, we briefly introduce three lines of researches related to our task: (a) traditional POI recommendation; (b) successive POI recommendation; and (c) collaborative retrieval.
 Traditional POI Recommendation . Traditional POI recommendation task has been extensively studied in the last several years. Many researches hold a central assump-tion that nearer locations will be more likely to be visited by users. Based on this, a series of works incorporate dis-tance influence factor into diverse traditional recommenda-tion models [23, 3, 11]. Ye et al. [23] first combined dis-tance influence factor with user-based collaborative filtering method. Then Cheng et al. [3] blended probabilistic matrix factorization with a gaussian mixture model to capture the influence of distance. More recently, Kurashima [11] pro-posed a geo topic model to integrate distance factor with latent Dirichlet allocation [2]. Another research direction is to utilize temporal information check-ins to improve loca-tion recommendation results [25, 7, 10]. Similar to the evo-lutional trend of researches for integrating distance factor, they also incorporate temporal information into user-based collaborative filtering, matrix factorization and topic model successively. The above works demonstrate the advantages of considering location distance information and temporal information in traditional POI recommendation, which can motivate the research in successive POI recommendation. Successive POI Recommendation . Lately, a few suc-cessive POI recommendation works [17, 4] have been con-ducted. Snag et al. [17] proposed a probabilistic model to integrate category transition probability and POI popular-ity to solve this problem. However, their method relies on categories of POIs and user attributes such as gender and residence information, which might not be easy to get due to privacy concern. Thus their method cannot be directly used in this paper. Cheng et al. [4] extended the state-of-the-art context-aware recommendation method, i.e., factor-ized personalized Markov chain (FPMC) [15], to provide a new model called FPMC with localized region constraint for successive POI recommendation. They divided the geo-graphical space into grids, and the candidate recommenda-tion locations for a user should be within the grid the user currently stays in or its surrounding eight grids. This condi-tion is called localized region constraint. The experimental results indicated the effectiveness of their method. As they ignore to utilize the social relations between users and tem-poral information of visiting, our works first propose two extensions based on their model to incorporate these useful information and then we propose a new model called LTSCR to combine the extensions with the standard collaborative model, which makes our works largely different from theirs. Two recent works [5, 22] try to predict the next user move-ment based on users X  previous sequential movements. Yet our problem is obviously different from theirs in two aspects. First, they consider which place users will move to and when they will reach while we concentrate on recommending new POIs which users have not visited before. Second, they need to utilize multiple recent check-ins of each user to construct sequential model for location transfer and time information prediction while we only regard each user X  X  current visiting location as a query for collaborative retrieval. Besides, Yin et. al. [24] proposed a location-content-aware recommender system which recommends items given a query location from users. However, their problem setting is different from ours as the query locations in theirs are regions (e.g. cities) and they want to recommend spatial items within those regions while our queries include all locations and we try to recom-mend POIs near those query locations. Figure 1: Basic Overview of Location-based Social Network.
 Collaborative Retrieval . Collaborative retrieval task was first proposed by Weston et al. [20]. It blends traditional in-formation retrieval and personalized recommendation tasks. In order to solve this problem, they proposed a latent collab-orative retrieval model, which could be roughly divided into two parts. The first part modeles the relation among query, user, and item for solving retrieval problem. The second part captured the relation between user and item for deal-ing with the recommendation problem. Besides, the model adoptes the WARP loss function to train the model in or-der to gain better top k results. Upon this model, Hsiao et al. [9] incorporated social relation information to regularize user latent factors and achieved better results. More details about collaborative retrieval model can be referred in the next section. In this paper, we propose a new model called LTSCR based on the standard collaborative model to solve our problem.
In this section, we first analyze properties of the datasets from LBSNs. Then we formulate the successive POI recom-mendation problem in our setting. After that, the standard method for this task is presented. Finally, the collaborative retrieval model is introduced at last as the cornerstone of the subject of the next section.
Location-based social networks are common in current so-cial networks. Almost all LBSNs and their variations share the following basic data attributes: user set U , POI set P , social relation set S , and temporal information set T . Their primary relations are shown in Figure 1. Basically, for a user u , when he visits a POI p at time t , he can share this check-in record with others, such as his friend set S ( u ). In this work, we adopt two publicly available datasets published by [6] to test our proposed models. The first one was crawled from Brightkite and the other was from Gowalla. Thus, we denominate the first data set as Brightkite and the second as Gowalla for convenience.

In order to compute the distance distribution of successive check-in pairs, we first mine the successive check-in pairs. Inspired by the methods mentioned in [20, 4], we determine a maximal time interval T max . For any two successive check-in POIs from the same user, the check-in time difference can not exceed T max . After we collect enough consecutive check-in pairs, we calculate the cumulative distribution of distance between successive check-in locations. Figure 2 shows that in Gowalla dataset, 90.1% check-in pairs lie within 5 miles and only less than 6% pairs X  distances surpass 10 miles. This phenomenon about localization of successive check-ins is less Figure 2: Distance Between Successive Check-in POIs. visible in Brightkite dataset. However, there are still more than half check-in pairs X  distances within 5 miles and more than eighty percents pairs X  distances less than 20 miles. In summary, users X  next POI choices are constrained in local regions near their current visiting POIs.

Besides, we also want to check whether temporal informa-tion may influence the successive POI recommendation re-sults. It is intuitive that for different users, their own habits may cause very different visiting patterns as time goes on. And for specific POI, its check-in patterns should be differ-ent from other POIs belonging to different categories. For example, parks are usually visited by users in daytime, while restaurants are preferred by users at dinner time. To verify this, we utilize Pearson correlation to measure the correla-tion of users X  temporal check-in patterns in the same location region to ensure the local time consistency and the same as for POIs. More specifically, we first filter users or locations with few check-in records. We use a 24 dimensional vec-tor to represent the temporal check-in pattern of each user or item, with each dimension corresponding to an hour and each value denoting the total check-in count belonging to that hour. Then for users (or POIs) in the same geographi-cal region, we calculate their Pearson correlation in pair and average the results finally for all pairs in all regions. The re-sults for both datasets are shown in Figure 3. We can see that all of them lies in the interval [+0 . 22 , +0 . 32], which means the temporal check-in patterns have low positive cor-relation. Another phenomenon is that the correlation of locations X  temporal check-in patterns is a little lower than users X  on both datasets. In all, the check-in patterns of users and POIs over time are indeed diverse. The above analysis suggests us to utilize the temporal information of visiting to help successive POI recommendation.
Based on the above data analysis, we formulate the succes-sive POI recommendation task below. Given a user u ( u  X  U ), his already visited POI set P ( u ), his current visiting POI i ( i  X  P ), and the corresponding visiting timestamp t ( t  X  X  ), the task is to recommend a new POI c ( c /  X  P ( u )) for user to visit successively. Generally, top k new POIs are delivered to user u which are ranked according the score gotten from a defined score function f ( u,t,i,c ).
In the collaborative retrieval setting, i and t can be consid-ered as a location and time aware query of user u . The user wants to know which successive POI he can visit in the near Figure 3: Average Correlation of Temporal Check-in Patterns of Users/POIs. future. Hence, the above task can be regarded as one kind of collaborative retrieval task. However, there is no need to consider all POIs as candidate results as the works [20, 9] do because of the localization property of successive check-ins. Thus, we only need to search near POIs according to i to determine the final results, which is supported by the previous data analysis.
The central idea of collaborative retrieval is to capture the relation among users, queries, and items in a unified model to calculate the possibility score f ( u,q,i ) of user u preferring item i under the query q . Assume I and Q denote the item set and query set, respectively. K is the dimension of latent factors, U  X  R K X |U| are user factors, V  X  R K X |I| are item factors, Q  X  R K X |Q| are query factors, U u  X  R K is the latent factor of user u , V i  X  R K is the latent factor of item i , and Q given a query q ( q  X  Q ) and an item i , the score function is formally expressed as follows, where T u  X  R K X K is a user dependent transform matrix. We can see that the first part of the equation is to capture the relation among query, user, and item, while the second part is to model the relation between user and item. Thus, the first part corresponds to the retrieval model and the second part corresponds to the recommendation model.
The collaborative retrieval model utilizes weighted ap-proximate rank pairwise (WARP) [18] loss to complement traditional pairwise loss functions. Unlike previous pair-wise loss functions which treat all training pairs equally, the WARP loss actively learns more from training pairs where positive items have high ranking positions and thus can achieve better top k ranking results (see [19] for more explanations). The rank for each positive item i is defined as below, where I (  X  ) is an indicator function. It is clear that if f ( u,q,i ) gets larger value, less items will satisfy (1 + f ( u,q,j )) &gt; f ( u,q,i ) and item i should get lower rank.

Computing the scores of all items to get ranks is not ef-ficient. Hence, an approximate method is proposed. For a given positive item i , it draws a negative item j with-out replacement and terminates until item j satisfies the margin-based comparison 1 + f ( u,q,j ) &gt; f ( u,q,i ). Suppose the number of sampling step to get j for i is N i . Then the approximate rank is calculated below, where b X c means the floor function, |I| is the total number of items.

After getting the approximate rank, the rank loss for the positive item i is defined as follows, where  X  n is the weight of position n in the ranked list and often defined to be 1 /n .

To optimize the loss function, efficient learning algorithms such as stochastic gradient descent (SGD) require that it is derivable for model parameters. Following the idea from [19], the margin function max(0 , 1 + f ( u,q,j )  X  f ( u,q,i )) can be added to meet the requirement. During the learning process, all the training pairs are weighed in every iteration according to the above two equations.

In summary, the collaborative retrieval model has two main characteristics: (1) it computes both query depen-dent and independent preference score through the retrieval model and recommendation model respectively, and jointly learn query, user, and item factors in a unified model; (2) it utilizes WARP loss function for optimization to get bet-ter top-k ranking recommendation results. Inspired by the above two ideas, we design our model for better modeling users X  successive check-in behaviors and further achieve su-perior recommendation results.
In this section, we first discuss the method to handle social relations and temporal information. Based on this, we then introduce the integrated new model we proposed and the corresponding model parameter learning approach.
Social relations are basic elements in social networks, which cover friendship, following relationship, trust relationship, etc. These relations could be one-way or two-way relation. Usually, users with social relations tend to have similar pref-erences and affect each other in some activities. Intuitively, these are also suitable for successive POI recommendation task, since users have more possibility of visiting the POIs their friends have visited.

Social regularization is an elegant approach to integrat-ing social relations with the latent factor model (Ma et al. 2011). It encourages users who are socially connected to have similar latent factors. Assume the original objective function is L o , the objective function of social regulariza-tion corresponds to L s , then the hybrid objective function becomes their blending, i.e., L o +  X  L s with a relative weight  X  .

We define the objective function of social regularization as follows, where S ( u ) means the friend set of user u ,  X  u,u 0 is the simi-larity value of user u and his friend u 0 , || X || 2 is the L2-norm. Thus, the central problem becomes how to compute the sim-ilarity value  X  u,u f . Using binary social relation directly can-not capture the different degrees of similarity between user u and his different friends. To address this issue, we define the following formula to compute the similarity degree, where S u,i equals 1 if user u and i are friends. We only keep their friends who rank within top k by the similarity degree to save computation cost for later parameter learning in Equation 9. In the experiments, we set k to be 10.
To model temporal information of users X  check-ins, we first segment the continuous temporal space into fixed-sized time periods. For example, we can just treat one hour of a day as one time period, which means the number of time peri-ods |T| is 24. Then for any timestamp, it will belong to one time period uniquely. This could be easily determined by the hour value of the timestamp. In addition to con-structing time periods based on hours, we can also consider weekday, month, and season information. There is a trade-off between time granularity and model complexity. In other words, too many periods will result in the overfitting prob-lem, and further influence the final results. In this paper, we find that dividing 24 hours of each day into 6 time periods and meanwhile differentiating weekdays and weekends can get a little better results. Thus the number of time periods is set to be 12 ( |T| = 2  X  6) in experiments.

Based on previous data analysis, incorporating the time period information into the new model for both users and POIs is promising. To reflect the diverse preference of users in different time periods, we extend the user latent factor U u  X  R K to the user temporal latent matrix U u  X  R K X |T| , where U u,t  X  R K denotes the temporal latent factor in time period t for user u . Besides, in order to reveal the popu-larity of each location changed over time periods, we add a temporal popularity factor T i  X  R |T| for each POI i .
One concern for the operations is that the user temporal matrix U u has K X |T| parameters to be learned. Thus it is more likely to suffer from overfitting than without con-sidering temporal information. To overcome this issue, we can further add temporal regularization term to the objec-tive function to control user temporal matrix in addition to social regularization term. In this work, we suppose that the change of factors of near time periods may be smooth. We calculate the similarity degree between near time peri-ods based on the check-in behaviors of each user through cosine similarity. For each time period t , there are two near time periods, i.e., t  X  1 and t +1 . The first time period is near to the last due to periodicity. We denote the two similarity values as A t,t  X  1 and A t,t +1 , respectively. Assume P ( u,t ) denotes the POI set user u has visited in time period t , then the similarity degree A t,t  X  1 can be computed as follows, Analogously, A t,t +1 can be calculated in the same way.
Inspired by the above results and the collaborative re-trieval model introduced in Section 3.3, we formulate our new model (LTSCR). For a user u , U u,t  X  R K denotes his temporal latent factor. For a POI i , it has three types of latent factors: 1) P i  X  R K captures the transition patterns between successive check-in POIs. It can be regarded as the retrieval part in the collaborative retrieval model. Adding additional user dependent transformation matrix like CRM for this task does not improve the final results significantly and increase the computation cost through our experiments. Thus we leave them out in our approach; 2) V i  X  R K models the preference between users and locations. It can be con-sidered as the recommendation part in CRM; 3) T i  X  R |T| denotes the popularity of the location changed over time periods.

Given the above statement, the recommendation ranking score can be calculated as follows. For a user u , assume the current POI he is visiting is i and the corresponding time period is t , which means the input query of user u is constituted by a POI-time pair ( i,t ). The preference to the next candidate POI c he may visit is measured by the following score function, where  X  and  X  control the relative strength of each part above and should meet the constraints:  X   X  R + ,  X   X  R + , and  X  +  X   X  1. The setting of these two parameters will be discussed in Section 5.4.2. We should emphasize that we adopt P T i P c instead of P T i V c in the above equation as it can achieve better experimental results. This may be explained by the fact that the first one can directly learn the transition patterns from data.

In order to utilize the localized region constraint, we con-strain the candidate recommendation location c should be within the grid the user currently stays in (the grid i be-longs to) or its surrounding eight grids, which is the same as (Cheng et al. 2013). More details about the grid size setting can be referred in the later dataset preprocessing section.
We incorporate the social regularization term and the temporal regularization term mentioned before into our new model for learning from users X  real check-in behaviors by ex-panding the standard WARP loss function. Given a user u and his current visiting POI i , we denote his true suc-cessive visiting POI as c . The learning process should first sample one negative POI c 0 to construct the training pair ( u,t,i,c,c 0 ). Under the localized region constraint, all the negative POIs should also be within the grid covering i or its surrounding eight grids. We use  X  tr ( u ) to denote all the training pairs related to user u . With this spirit, LTSCR solves the following learning problem, min +  X  +  X  +  X  where the sampled negative POI c 0 for query POI i with positive POI c in LTSCR should satisfy the margin-based comparison 1 + f ( u,t,i,c ) &gt; f ( u,t,i,c 0 ). The last terms of the above optimization target are regularization terms which control the overfitting problem and are often employed in latent facor models. The number of sampling step for finding the adequate negative POI determines the approximate rank e r ( c ) according to Equation 3.  X  ,  X  , and  X  are regularization parameters for the model which can be tuned on validation datasets.

The SGD algorithm is leveraged to optimize the above objective function. The central idea of SGD is to randomly scan all training pairs and update parameters though the gradient descent direction of the target function for each training pair. Each update is done by the following equation, where  X  corresponds to the learning rate.  X  denotes all model parameters, and Obj denotes the objective function shown in Equation 9.

Given a training pair ( u,t,i,c,c 0 ) from the whole training data, the key gradients of all related parameters are com-puted as follows, We only list the gradients related to the positive location c . However, it is easy to derivate the similar gradients related to the negative location c 0 . After the gradients are calcu-lated, we can update the parameters through Equation 10 uniformly. In summary, the complete learning algorithm for LTSCR is described in Algorithm 1.
To demonstrate the effectiveness and efficiency of our pro-posed models, we conducted experiments on two real datasets. We first describe the data preprocessing procedure in Sec-tion 5.1 and then give a simple introduction to the evaluation metrics we used in this task. We explain all the methods we compare in the experiments in Section 5.3. Lastly, we com-pare the results of all methods and analyze the possible rea-sons. All the algorithms were implemented using C++ and we conducted all the experiments on a server (four 3.00GHz CPU cores, 20GB memory) with 64-bit Linux system. In this paper, we exploit the same ordinary data structures for all the algorithms and do not consider any parallel compu-tation.
 Algorithm 1: The Learning Algorithm 1 tt=0; 2 Initialize hyper-parameters; 3 Randomly initialize U , P , V , T ; 4 while Obj ( U , P , V , T ) not converged and tt  X  T max 5 Randomly shuffle the training records TR ; 6 Get ( u,t,i,c ) from record k; 7 Sampling desirable negative POI c 0 ; 8 Compute all gradients through Equation 11; 9 Update model parameters by Equation 10; 10 tt = tt + 1;
We employ two public datasets, i.e., Brightkite and Gowalla in the experiments, just as mentioned in Section 3.1. As stated in Section 3.2, we address the problem of successive POI recommendation problem. When a user specifies a POI and its corresponding visiting time, the algorithms should recommend new POIs the user prefers to visit in the near future. In order to evaluate the results of all methods, we should extract reasonable successive check-in records from the same user to simulate the process. In the experiments, we regard two successive check-ins within T = 2 ( hour ) as a valid successive check-in pair. This strategy is similar to [20, 4]. To filter noisy data, we further select users who have at least 10 records and POIs which have at least 5 records in all check-in pairs gotten from the previous step. After fin-ishing the preprocessing, we gain the ultimate experimental datasets. The details of the two datasets are shown in Ta-ble 1.
 Table 1: Basic Statistics of Location-based Social Network Data.

In order to utilize the localized region constraint moti-vated by the data analysis in Section 3.1, we divide the geographical space into nearly equally-sized grids whose ar-eas are 0 . 05( longitude )  X  0 . 05( latitude ), which can include most successive check-in pairs. We randomly divide the two datasets into training, validation, and test datasets accord-ing to the ratio 7 : 1 : 2, meanwhile, assure that each user and POI occur at least one time in the training data. All the models are trained on the training datasets and all the hyper-parameters are tuned on the validation datasets. Fi-nally, we compare all the models on the test datasets.
To evaluate the successive POI recommendation results, we adopt two types of standard evaluation metrics: (1) Pre-(a) Precision@5 in Brightkite. (c) Precision@5 in Gowalla. cision@n (Precision at Position n) and Recall@n (Recall at Position n), and (2) MRR(Mean Reciprocal Rank).

Precision and recall are mainly used in previous recom-mendation tasks [20, 4] which relate to our work. Generally, it is computed by the following formula, where N tr denotes the number of truly recommended items, and N t represents the number of total true items.

We should emphasize that for each query POI, the num-ber of true recommendation results is small for collaborative retrieval task. Therefore, the precision of results may be relative low as long as k is not small. That X  X  also why the works [20, 9] do not use metric Precision@n. As a comple-mentary, we adopt MRR metric that concentrates on mea-suring positions of the first correct recommendation results. In our problem setting, MRR is calculated as where | Q u | is the number of implicit location queries each user u has and rank i specifies the position of the first correct successive POI the user will visit based on the query i . We adopt the following five methods in the experiments. Among them, the first two are popularity based methods and the middle two are model based methods. The main targets of the experiments are to demonstrate that our proposed method outperforms these methods.
Besides, it is also necessary to verify the effectiveness of the main components of LTSCR. To achieve this, we adopt the strategy similar to the forward selection method which is frequently employed in feature selection task [8]. Specif-ically, starting from the basic model (FPMC+LR), we add one more component that we intend to test each time and compare them in an incremental fashion. Here, we conclude the two partial methods to be adopted in later comparison as follows,
Based on the results of the above partial methods of LTSCR, we can also demonstrate the advantage of utilizing the mer-its of CRM by comparing LTSCR with FPMC+LR+ST.
In this part, we mainly describe the hyper-parameters we tuned for LTSCR on the validation datasets. The other adopted comparison methods are also tuned to ensure to achieve their good results.
There is a tradeoff between learning speed and conver-gence guarantee for learning rate setting. Without specific mention, we set learning rate  X  to be 0 . 01 for all models. The dimension of all latent factors are set to be 20 for Brightkite dataset and 40 for Gowalla in our most experiments. This is inspired by the analysis of dimension influence on recom-mendation performance in Section 5.5.3.
As shown in Equation 8,  X  and  X  control the relative in-fluence of different parts on preference score computation. Here, we determine them based on the performances of Pre-cision@5 and Recall@5 on validation datasets which coincide with the recommendation objective. Specifically, we employ the grid search method to get optimal setting by configur-ing  X  and  X  with different combinations. As Figure 4 shows, temporal factors of POIs play a minor role in optimal results compared with the other two parts. The optimal parame-ter configurations are pointed out in both figures and it is evident that the variations of results near the optimal point are relatively smooth. Without loss of generality, we set  X  = 0 . 2 , X  = 0 . 1 for Brightkite data and  X  = 0 . 4 , X  = 0 for Gowalla data, respectively.
The regularization terms  X  for all latent factors are set to be 0 . 1 across all the models based on the results on vali-dation dataset after several trials on { 10  X  3 , 10  X  2 ,  X  X  X  , 10 It is intuitive that  X  and  X  should be larger than  X  as they capture additional knowledge to constrain the latent factors. We experimented many combinations for  X  and  X  . Exper-imentally, we find that the results continue to grow slowly with increase of  X  and  X  as long as they are larger than 1 and not too large. Empirically, we set them to be 10 which can ensure good results. We start with discussing the results reported in Figure 5. Firstly, we compare the two POI popularity based meth-ods, i.e., POP with POP+LR. From the table, we can see that POP+LR performs consistently better than POP in both datasets. The phenomenon is rational since POP+LR utilizes the localization property of successive check-ins and ranks POIs only in local regions.

Then we analyze the results of the basic model based ap-proach PMF+LR. Actually, we find the results of PMF+LR shows no improvements over POP+LR X  X , except the result corresponding to MRR metric in Gowalla dataset. Knowl-edge gotten from the above comparison is two-folds. It re-flects that PMF+LR is not very suited for the successive POI recommendation task. Besides, popularity based method is not very robust when the size of candidate POIs is large as their performance drops significantly in the large Gowalla dataset. By comparing FPMC+LR with the above meth-ods, we can conclude that the incorporation of users X  current visiting locations is crucial for the successive POI recommen-dation task. This can be explained by that the current loca-tion each user stays in can be regarded as an implicit query which is an indicative for his successive check-in choice.
Finally, we contrast LTSCR with all other models. As the results show, LTSCR behaves vastly superior to both PMF+LR and FPMC+LR, which reveals that our proposed approach improves the state-of-the-art results significantly. The analysis of the key components of LTSCR is introduced subsequently. As we mentioned before, for each location and time aware query, the number of true recommendation results is small for successive POI recommendation task. Therefore, the precision of results may be relative low as long as n in Precision@n is not small. However, the rela-tive improvements on Precision@n are significant. For ex-ample, LTSCR achieves 38.3% and 54.9% relative improve-ments over FPMC+LR on metric Precision@5 for datasets Brightkite and Gowalla, respectively.
We verify the effectiveness of utilizing social relation, tem-poral information, and collaborative retrieval framework in LTSCR through an incremental comparison strategy using the results shown in Figure 6.
First, FPMC+LR+S consistently outperforms FPMC+LR in the two datasets notably. This indicates the effectiveness of using social relation for our task. Based on FPMC+LR+S, FPMC+LR+ST is further provided which is a direct exten-sion of FPMC+LR+S by incorporating temporal informa-tion in the model, just as we mentioned in Section 5.3. The comparison between FPMC+LR+ST and FPMC+LR+S fits in with our expectation, as FPMC+LR+ST achieves better results. Thus, considering temporal information can bene-fit the task. Finally, to demonstrate the superiority of col-laborative retrieval framework, we make a comparison be-tween LTSCR and FPMC+LR+ST. As expected, LTSCR behaves the best among all the methods and outperforms FPMC+LR+ST.

In summary, through the above incremental comparisons, we can conclude that the main components we utilized are suited for the successive POI recommendation task.
In this section, we will briefly discuss how the dimension of latent factors influences the results. We conduct experi-ments on Precision@5 and Recall@5 on two datasets sepa-rately with different dimension setting changing from 5 to 100. The results are reported in Figure 8.

Clearly, the variation trend of the results on Brightkite dataset is not very stable. Although almost all the meth-ods increase monotonously before reaching dimension 10, PMF+LR encounters an inflection point at this dimension. Purely increasing the dimension of latent factors may cause the overfitting problem, especially on the Brightkite dataset which is not very large. From a whole perspective, setting dimension to be 20 for Brightkite is an acceptable choice.
On the other hand, the curves drawn in Figure 8(c) and 8(d) are much clearer to reflect how the change of the di-mension influences the results on Gowalla dataset. When the dimension is small, i.e., less than 30, the growth rate is fast. Then they start to converge after the dimension surpass 30 and retain pretty stable after 40.

From the two figures, we can also conclude that our pro-posed method consistently outperforms the other two model-based approaches, no matter how large the dimension is.
Under the SGD learning framework, the total time of learning for LTSCR is mainly dominated by the cost of each learning iteration and the number of iterations. (a) Change of Time Cost
In each iteration, the time cost depends on the size of training instances and learning speed for each instance. As we introduced in Section 3.3, the sampling process for WARP loss could only be terminated when a sampled item satisfies the margin-based comparison. Thus, At the beginning of learning, the time cost for each instance is small as it is rapid to sample a negative item which satisfies the require-ment. As the optimization process proceeds, the time cost will increase. Theoretically, the maximal number of sam-pling step for a training pair is |P| X  1. However, when the optimization converges, the time cost of sampling will also be bounded. We tested the LTSCR X  X  learning time cost of each iteration on the large Gowalla dataset, which has nearly one million training pairs. As shown in Figure 7(a), when the time cost reaches a stable state, it is only slightly over 2 times as large as the time cost of the beginning, which is acceptable for model learning. (a) Precision@5 of Brightkite. (c) Precision@5 of Gowalla.
Besides, we tested how the data size affects the time cost of the learning of LTSCR on the large Gowalla dataset. From the results shown in Figure 7(b), we can estimate the average time cost of one iteration grows about linearly with the size of the dataset.
In this paper, we have proposed a new latent factor model called LTSCR for successive POI recommendation task. The new model not only considers users X  current visiting loca-tions, temporal information of visiting, social relations, and the localization of successive check-ins simultaneously, but also utilizes the merits of collaborative retrieval model. We validate the model on two real datasets. The experimental results have shown that 1) social and temporal information are indeed beneficial for this task, and 2) LTSCR outper-forms the several other methods.
 We thank the anonymous reviewers for their valuable and constructive comments. This work was supported in part by National Basic Research Program of China (973 Program) under Grant No. 2011CB302206, National Natural Science Foundation of China under Grant No. 61272088, and Ts-inghua University Initiative Scientific Research Program.
