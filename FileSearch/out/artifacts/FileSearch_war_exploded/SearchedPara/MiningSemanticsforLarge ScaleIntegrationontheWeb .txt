 The Web has been rapidly  X  X eepened X  X  with myriad searchable databases online, where data are hidden behind query interf aces. Toward lar ge scale inte gration over this  X  X eep Web,  X  we are facing a new challenge X  With its dynamic and ad-hoc nature, such lar ge scale inte gration mandates dynamic semantics disco very . That is, we must on-the-fly cope with  X  X emantics X  of dynamically disco v-ered sources without pre-configured source-specific kno wledge. To tackle this challenge, our initial works hinge on the insight that the lar ge scale is itself also a unique opportunity: We observ e that the desired  X  X emantics X  often connects to surf ace presentation char -acteristics, through some hidden regularities over man y sources. Such regularities can be essentially leveraged in enabling seman-tics disco very . In particular , we report our evidences in three initial tasks for inte grating the deep Web: interf ace extraction , schema matching , and query translation . Generalizing these specific ev-idences, we thus propose our  X  X nified insight X  of  X  X ining X  se-mantics for lar ge scale inte gration by exploiting hidden regularities across holistic sources. Further , to fulfill the promise of such holis-tic mining, we discuss challenges toward its realization for dynamic semantics disco very . As our initial works as well as several related efforts have witnessed, we belie ve our unified insight, holistic min-ing for semantics disco very , is a promising methodology toward enabling lar ge scale inte gration. Recently , the Web has been rapidly deepened with the pre valence of databases on the Internet. As Figure 1 conceptually illustrates, on this so-called  X  X eep Web,  X  numerous online databases pro vide dynamic query-based data access through their query interf aces, in-stead of static URL links. A July 2000 study [1] estimated 43,000-96,000 such search sites (and 550 billion content pages) on the Web. Our recent surv ey [2] in April 2004 estimated 450,000 online databases. As current cra wlers cannot effecti vely query databases, such data are invisible to search engines, and thus remain lar gely hidden from users.
 Ho we ver, while there are myriad useful databases online, users of-ten have dif ficulties in first finding the right sources and then query-ing over them. Consider user Amy , who is mo ving to a new town. To start with, dif ferent queries need dif ferent sources to answer: Where can she look for real estate listings? ( e.g. , realtor .com .) Studying for a new car? ( car s.com .) Looking for a job? ( mon-ster .com .) Further , dif ferent sources support dif ferent query capa-bilities: After source hunting, Amy must then learn the grueling details of querying each source.
 To enable effecti ve access to databases on the Web, it is critical to inte grate these lar ge scale deep Web sources. Such deep Web inte-gration brings a new challenge of on-the-fly disco vering inte gration-related semantics ( e.g. , source query capabilities, semantic cor -respondences of attrib utes) without pre-configured source-specific kno wledge. To tackle this challenge, our  X  X hesis X  of solutions builds upon the observ ation that databases on the Web are not arbitrarily comple x X  There seem to be some  X  X on vergence X  or  X  X e gularity X  naturally emer ging across man y sources. This  X  X oncerted com-ple xity X  sheds light on pursuing a  X  X olistic mining X  paradigm for disco vering semantics dynamically . This paper presents evidences, insights and challenges of such semantics mining for lar ge scale inte gration X  as learned from our initial experience in building a  X  X etaQuerier X  1 for exploring and inte grating the deep Web. In particular , toward lar ge-scale inte gration, we are facing new chal-lenges. For coping with the lar ge scale : The deep Web is a lar ge collection of queryable databases (well on the order of , as men-tioned earlier). As the lar ge scale mandates, first, such inte gration is dynamic : Since sources are proliferating and evolving on the Web, the y cannot be statically configured for inte gration and conse-quently must be dynamically disco vered for inte gration. Second, it is ad-hoc : Since queries are submitted by users for dif ferent needs, the y will each interact with dif ferent sources X  e.g. , in Amy X  s case: those of real estates, automobiles, and jobs. As queries are ad-hoc, we must mediate them on-the-fly for rele vant sources, with no pre-configured source-specific kno wledge.
 While the need is tantalizing X  for effecti vely accessing the deep Web X  the order is also tall. The challenge arises from the man-date of on-the-fly semantics disco very : Given the dynamically-disco vered sources, to achie ve on-the-fly query mediation, we must cope with various  X  X emantics.  X  To name a few: What are the query capabilities of a sour ce ? (So as to characterize a source and query it.) How to matc h between query interfaces ? (So as to mediate metaquerier .cs.uiuc.edu queries.) While the challenge of semantics is not new to any infor -mation inte gration effort, for smaller and static scenarios, automatic semantics disco very is often an option to reduce human labor , as an aid to manually configured semantics ( e.g. , source descriptions and translation rules). In contrast, for lar ge scale scenarios, semantics disco very is simply a mandate , since sources are collected dynam-ically and queried on-the-fly .
 As our critical insight, while the lar ge scale presents new chal-lenges, we belie ve it also reveals itself as novel opportunities. In particular , we conducted a surv ey of the deep Web [2] by exploring about 500 sources in eight domains, e.g. , Books, Airf ares. The sur -vey revealed some inspiring observ ations: Databases on the Web are not arbitrarily comple x; there seem to be some  X  X on vergence X  and  X  X e gularity X  natur ally emer ging across man y sources. This  X  X oncerted comple xity X  sheds light on the challenge of dynamic semantics disco very . (So, it is perhaps hopeful to achie ve lar ge scale metaquerying.) In hindsight, such beha vior is indeed natural at a lar ge scale: As sources proliferate, the y tend to be influenced by peers X  which we intuiti vely understand as the Amazon effect . 2 To begin with, as moti vating evidences, our initial works for inte-grating the deep Web have essentially built upon this very insight (Section 2). First, interf ace extraction : For solving the problem of automatically extracting attrib utes from a query interf ace in HTML format, we introduce a par sing paradigm by hypothesizing the ex-istence of hidden syntax , which describes the layout and seman-tics across query interf aces [20]. Second, schema matching : To disco ver semantic correspondences among attrib utes, we propose a holistic matching approach by matching all the schemas at the same time with the hypothesis of a hidden schema model , which guides the generation of schemas[7; 8]. Third, query translation : To trans-late queries between two query interf aces, we develop a type-based sear ch-driven translation frame work by observing the existence of hidden localities among query patterns [19].
 To generalize, as a unified insight, and as the main thesis of this paper , we propose a new  X  X hilosophy X  as a generic approach for inte gration at a lar ge scale: Holistic mining for semantics disco v-ery , as Figure 2 conceptually sho ws. Consider an inte gration task that requires disco very of semantics. To begin with, our philoso-phy builds upon two hypotheses: First, shallow observable clues : The desired  X  X nderlying X  semantics often connects (Figure 2, top  X   X ) to the  X  X bserv able X  presentations, or shallo w clues. Second, holistic hidden regularities : Such connections often follo w some implicit properties, or hidden regularities (Figure 2, middle  X   X ), which will reveal holistically across man y sources.
 Therefore, our inte gration task, or the disco very of the desired se-mantics, is naturally the inver se of this semantics-to-presentations connection: We thus propose to tackle with lar ge scale inte gration by developing such  X  X e verse analysis X  (Figure 2, bottom) which holistically  X  X ines X  the shallo w clues, as guided by the hidden reg-ularity , to disco ver the desired semantics. As Section 3 will discuss, our three initial evidences in Section 2 can all be vie wed as materi-alizations of this holistic mining frame work.
 In our development, we also observ e some challenges in pursuing such a mining approach for dynamic semantics disco very . In par -ticular , what are the new  X  X eta-mining X  and  X  X ining X  issues arisen in holistic inte gration? Ho w to deal with noises in input data, i.e. ,  X  X resentation clues,  X  to be mined? What if the (often-hypothetical) hidden regularity cannot precisely capture the characteristics of ob-serv ations? Be yond exploring hidden regularities with a mining approach, are there other ways to exploit  X  X ar ge scale X  in holistic
Online bookstores seem to follo w Amazon.com as a de facto stan-dard.
 Figure 2: Unified insight: Holistic mining for semantics disco very . inte gration? Section 4 discusses these further challenges toward realizing holistic mining for lar ge scale inte gration.
 We start with Section 2 for our evidences of exploiting  X  X idden reg-ularity X  for coping with semantics. We next, in Section 3, present our unified insight of the  X  X olistic mining X  paradigm for seman-tics disco very toward lar ge scale inte gration. Section 4 raises some challenges and issues in pursuing such a mining approach. Sec-tion 5 revie ws related work and Section 6 concludes. We now report three initial tasks, interf ace extraction , schema match-ing and query translation , as the key components for realizing lar ge scale inte gration of the deep Web. For each task, we briefly sum-marize its functionality , moti vate the essential insights, and present the specific approach. As we will see, these tasks, while dif ferent in their specific problems and solutions, are themselv es  X  X vidences X  of exploiting certain hidden regularities for semantics disco very . For inte grating Web databases, as the very first step, we studied the problem of interf ace extraction [20] -to  X  X ecognize X  the basic condition templates presented in query interf aces.
 A query interf ace essentially represent query capabilities that a source supports through its interf ace, as templates of specifiable query conditions. For instance, amazon.com (Figure 3(a)) supports a set of five condition templates (on author , title , , pub lisher ). Such query condition templates establish the tar get semantics un-derlying a Web query interf ace that our task seeks to disco ver. Such form extraction essentially requires both grouping elements hierarchically ( e.g. , the condition template about author in ama-zon.com is a group of 8 elements: a text "author" , a textbox , three radio buttons and their associated text  X  X ) and tagging their semantic roles ( e.g. , "author" has the role of an attrib ute and the textbox an input domain .) The tasks are challenging  X  it seems to be rather  X  X euristic X  in nature with no clear criteria but only a few fuzzy heuristics , as well as exceptions . First , grouping is hard, because a condition is generally -ary , with various numbers of elements nested in dif ferent ways. ([ heuristics ]: Pair closest el-ements by spatial proximity . [ exception ]: Grouping is often not pairwise.) Second , tagging is also hard X  There is no semantic la-belling in HTML forms. ([ heuristics ]: A text element closest to a textbox field is its attrib ute. [ exception ]: Such an element can instead be an operator of this or next field.) Finally , with various form designs, their extraction can be inherently confusing. Insight: We observ e that query interf aces, although presented dif-ferently , often share similar or common query patterns. For in-stance, as Figure 3 sho ws, amazon.com has five condition templates (on author , title , etc. ) and aa.com nine (on from , to , etc. ). These condition templates seem to share some common  X  X atterns X : Those template patterns present condition templates in certain visual ar-rangement (or layout) X  Figure 3(c) sho ws several examples. For instance, pattern 1 represents a common format for condition tem-plates of the form [ attr ibute ; contain ; text] , by arranging attr ibute to be follo wed by a textbox. Such condition templates represent key-word search (by an implicit contain operator) on a textual attrib ute ( e.g. , author ).
 To understand the  X  X omple xity X  of such template patterns, we con-ducted a surv ey (with more details available at [2]). In particular , we explore 150 deep Web sources in three domains -Books, Auto-mobiles, and Airf ares -from the TEL-8 dataset at The UIUC Web Inte gration Repository[3]. (TEL-8 dataset contains about 500 deep Web sources on eight domains.) Our surv ey finds that the template patterns in those query interf aces reveal some concerted structure. We find only 25 template patterns overall X  which is surprisingly small as a vocab ulary for online queries. As just mentioned, Fig-ure 3(c) sho ws several frequently-used patterns. The distrib ution is extremely non-uniform: Figure 4(b) ranks the patterns according to their frequencies (and omits 4 rare attrib utes in the tail, which occur only once in 150 sources), for each domain and overall. We observ e a characteristic Zipf-distrib ution, which confirms that a small set of top-rank ed patterns will dominate.
 We also observ e the con vergence beha vior , both within and across domains. Figure 4(a) summarizes the occurrences of patterns. (To simplify , it similarly omits the rare  X  X nly-once X  patterns.): The fig-ure marks sources are seen (along the -axis), the gro wth (along ) slo ws down and thus the curv e flattens rapidly . Further , we observ e that the con vergence generally spans across dif ferent domains, which indicates that most template patterns are quite generic and not do-main specific.
 Such observ ation moti vates us to hypothesize the existence of a hidden syntax across holistic sources. That is, we rationalize the concerted structure by asserting the creation of query interf aces as guided by some hypothetical syntax: The hypothetical syntax guides a syntactic composition process from condition templates to their visual patterns. This hypothesis effecti vely transforms the problem into a new paradigm: We can vie w query interf aces as a vi-sual langua ge [13], whose composition conforms to a hidden, i.e. , non-pr escribed , grammar . The extraction of their semantics, as the reverse, is thus a par sing problem.
 Appr oach: We thus introduce a par sing paradigm by hypothesiz-ing that there exists hidden syntax to describe the layout and seman-tic of query interf aces [20]. Specifically , we develop the interf ace extractor as a visual language parser , as Figure 5 sho ws. Given a query interf ace in HTML format, the interf ace extractor tok enizes the page, parses the tok ens, and then mer ges potentially multiple parse trees, to finally generate the query capability . At its heart, we develop a 2P grammar and a best-ef fort par ser .
 First, by examining man y interf aces, a human expert summarizes and encodes two complementary types of presentation con ventions as the 2P grammar . On one hand, we need to write productions to capture con ventionally deplo yed hidden patterns. On the other hand, howe ver, by capturing man y patterns, some will conflict, and thus we also need to capture their con ventional precedence (or  X  X ri-orities X ) as prefer ences .
 Second, to work with a hypothetical syntax, we develop our parser to perform  X  X est-ef fort.  X  As a non-prescribed grammar is inher -ently ambiguous and incomplete, we need a  X  X oft parsing X  semantic X  The parser will assemble parse trees that may be multiple (because of ambiguities) and partial (because of incompleteness), instead of insisting on a single perfect parse. On one hand, it will prune am-biguities, as much as possible, by emplo ying preferences (as in the 2P grammar). On the other hand, it will recognize the structure (by applying productions) of the input form, as much as possible, by maximizing partial results.
 When there are multiple parse trees for the same query interf ace, we need an error handling mechanism to generate the final out-put. While the parser frame work is rather generic, error handling is often application specific. As our  X  X ase X  implementation, our  X  X er ger X  (Figure 5) simply mer ges all query condition templates covered in all parse trees, to enhance the  X  X ecall X  (or coverage) of extraction. To enable query translation across dif ferent sources, we studied the schema matching problem [7; 8] -to disco ver semantic correspon-dences of attrib utes across Web interf aces.
 Schema matching is critical for mediating queries among deep Web sources. For instance, in Books domain, we may find subject is the synon ym of categor y , i.e. , subject = categor y . In particular , we generally consider to disco ver comple x matchings. In contrast to simple 1:1 matching, comple x matching matches a set of at-trib utes to another set of attrib utes, which is thus also called : matc hing . For instance, in Books domain, author = first name , last name ; in Airf ares domain, passengers = adults , se-niors , children , infants .
 While schema matching has been a central issue in data inte gration, the lar ge scale sets new requirements on the matching task. Tra-ditional schema matching works ( e.g. , [16; 12; 5]) are developed for small scale and static inte gration scenarios, in which automatic matching technique is often an option to reduce human labor , as an aid to manually configured semantics. Schema matching under such scenarios is abstracted as finding pairwise attrib ute correspon-dences between two sources and thus cannot scale well. In con-trast, in lar ge scale data inte gration scenarios, the matching process needs to be as automatic as possible and scalable to lar ge quantities of sources, as the lar ge scale mandates.
 Insight: We observ e that the aggre gate vocab ulary of attrib utes in the same domain are not arbitrarily lar ge -the y tends to con-verge at relati vely small size. To understand the comple xity of such  X  X chema vocab ulary , X  we once again conduct a surv ey using the TEL-8 dataset as we used for interf ace extraction . (More details about the surv ey can be found at [2].) In particular , we surv eyed all 400+ sources in eight domains. Figure 6(a) analyzes the gro wth of frequency-weighted vocab ulary size for each domain. In particu-lar , we weight the vocab ulary gro wth by the  X  X mportance X  of a new attrib ute X  For the purpose of inte gration, an attrib ute that occurs in man y sources will be more important. To quantify , let the fre-quency of an attrib ute be the number of sources in which it occurs. When counting the vocab ulary size, each attrib ute is now weighted by its frequenc y in the corresponding domain. We see a very rapid con vergence X  In other words, as sources proliferate, their vocab u-laries will tend to stabilize. Note that the sources are sorted in the same order as the y were collected without any bias.
 In fact, the vocab ularies will con verge more rapidly , if we exclude  X  X are X  attrib utes. To quantify , let the frequenc y of an attrib ute be the number of sources in which it occurs. Figure 6(b) orders these frequencies for all the attrib utes over their ranks. It is interesting but perhaps not surprising to observ e that the distrib ution obe ys the Zipf  X  X  law: The frequencies are inversely proportional to their ranks. Man y low-rank ed attrib utes thus rarely occur; in fact, (203/422) attrib utes occur in only one source. Further , frequent at-trib utes dominate: we observ e that the top-20 attrib utes, or (20/422) attrib utes, constitute (1291/2992) of all the occur -rences. What are the most  X  X opular X  attrib utes across all these sources? The top 5 frequent attrib utes are, in this order , title , key-word , price , mak e , and artist .
 Appr oach: To tackle the challenge of lar ge scale matching, as well as to tak e adv antage of its new opportunity , we propose a new ap-proach, holistic schema matc hing , to match man y schemas at the same time and find all the matchings at once. Such a holistic vie w enables us to explore the conte xt information across all schemas, which are not available when the y are matched only in pairs. In particular , we started by developing the MGS matching approach with the assumption of the existence of a hidden generati ve schema model, which generates query interf aces from a finite vocab ulary of attrib utes [7]. Specifically , the observ ations of con verging attrib ute vocab ularies lead us to hypothesize the existence of a hidden gener -ative model, which probabilistically generates, from a finite vocab-ulary , the schemas we observ ed. Intuiti vely , such a model gives the statistical properties that constrains how synon ym attrib utes may co-occur across interf aces. The hidden generati ve model guides a statistic generation process from attrib ute correspondences (among the vocab ulary) to their occurrences in interf aces. Given a set of query schemas as statistical  X  X bserv ations,  X  schema matching is thus the disco very of such a hidden statistical model, which em-beds attrib utes correspondence relationships.
 To realize such hidden model disco very , we have proposed a gen-eral abstract frame work, MGS , with three steps: (1) Hypothesis modeling : We first specify a parameterized structure of the hypo-thetical hidden models. Such models should capture the specific  X  X ynon ym X  semantics we want to disco ver. (2) Hypothesis gener a-tion : We then generate all  X  X onsistent X  models that instantiate the observ ed schemas with non-zero probabilities. (3) Hypothesis se-lection : Finally , we select hypotheses that are consistent with the observ ed schemas with suf ficient statistical significance. In our further study , and in our current implementation, we explore the co-occurrence patterns of attrib utes to disco ver comple x match-ings [8]. For instance, we may observ e that last name and first name have a high probability to co-occur in schemas, while the y together rarely co-occur with author . More generally , we observ e that grouping attrib utes ( i.e. , attrib utes in one group of a matching e.g. , last name , first name ) tend to be co-present and thus pos-itively correlated across sources. In contrast, synonym attrib utes ( i.e. , attrib ute groups in a matching) are negati vely correlated be-cause the y rarely co-occur in schemas.
 This observ ation moti vates us to abstract the schema matching prob-lem as correlation mining [8]. Specifically , we develop the DCM approach for mining comple x matchings, consisting of automatic data preparation and correlation mining. As preprocessing, the data preparation step cleans the extracted query capabilities to prepare  X  X chema transactions X  for mining. Then the correlation mining step disco vers comple x matchings with d ual c orrelation m ining of pos-itive and negati ve correlations. At the core of on-the-fly information inte gration, we studied the query translation problem [19] -to map a source query (which may be issued from a dynamically constructed unified query interf ace) to a tar get query form on-the-fly , i.e. , without manually crafted per -source kno wledge pre-configured for indi vidual sources. As sources present dif ferent query capabilities, query translation, in essence, is to match and express queries in terms of such capa-bilities. As discussed in interf ace extraction , in general, query ca-pability of a source presents templates of queries acceptable to the back-end database. To translate a query is thus to instantiate the tar -get query template -by populating the parameters in the template with concrete values -into a tar get query which is semantically close to the source query .
 As comple x queries are built upon atomic conditions, translation eventually resorts to mapping between semantically related condi-tions, as disco vered by schema matching . As Figure 7 indicates, given a specific sour ce condition ( e.g. , [ price range ; between ; 5,35] ), with respect to a matching tar get template ( e.g. , = [ price ; ] ), what is the closest mapping? In this case, condition map-ping is to instantiate into = [ price ; ; 35] (assuming we want the tar get condition to minimally subsume the source condition), which best matches , i.e. , with respect to . Figure 7 sho ws some example mappings.
 With interf ace extraction syntactically recognizing the conditions, to enable query translation, the essential challenge is to really un-derstand what a condition  X  X eans,  X  i.e. , the subset of values, or re-sult rang e , restricted by the condition. For instance, for condition [ price ; between ; 5,35] , its semantic meaning is to constrain the value of price in a range of ( ) . Similarly , [ price ; ; 35] constrained the value to ( ) . If we are able to understand such semantic meaning of each condition, we can compare the closeness of a tar -get condition with the source condition in terms of the result ranges constrained by these two conditions. Therefore, query translation naturally becomes a search problem, i.e. , among all possible instan-tiations of the tar get condition template, query translation is to find the one which is semantically closest to the source condition. Insight: We observ e that while conditions are presented dif ferently in query interf aces, for expressing a particular semantic meaning on a concept, e.g. , a range of price ( ) , there are concerted ways across dif ferent interf aces. For instance, to express range ( ) , an interf ace may use template to form a condition [ price ; between ; 0,35] , while another interf ace may use to form [ price ; ; 35] . Ho we ver, when looking at man y interf aces collecti vely , we find that the  X  X lternati ve X  templates for expressing such semantics are rather limited.
 To understand possible alternati ves of expressing certain seman-tics, we conduct a surv ey on condition templates using the same dataset as we used for interf ace extraction , i.e. , query interf aces from Books, Airf ares and Automobiles domains in the TEL-8 dataset. We notice that a condition template can be an alternati ve of another template only if there exist a concept (which may correspond to multiple semantically corresponding, i.e. , matching, attrib utes) that is expressed alternati vely using the two templates in two dif ferent interf aces. For example, the two templates and are used to express the conditions on the same concept of book price (with pos-sibly dif ferent attrib ute names such as price range and price ), and thus the y can be alternati ves. We study the alternative corr espon-dences between any two condition templates we collected in the surv ey. We use a corr espondence matrix to report for any two condition templates , whether the y have such alternati ve cor -respondence. In particular , denotes the number of con-cepts that are expressed using both templates and in dif ferent sources. Figure 8 sho ws our surv ey result ( i.e. , the correspondence matrix), where the value of is illustrated as the degree of grayness at each cell .  X From Figure 8, we observ e that alternati ve templates form certain clusters or  X  X ocalities X  X  That is, templates in a locality are often alternati ves to each other , while templates across dif ferent local-ities cannot be used as alternati ves to express the same semantic meaning. Further , we find that such correspondence localities are consistent with the notion of  X  X ata types.  X  That is, while the condi-tion templates in a locality are used by various concepts, those con-cepts often share the same data type. In particular , the first locality in Figure 8 corresponds to templates usually used by concepts of datetime type ( e.g. , concept depar ture date , drop-off time ), the second one by concepts of numeric type ( e.g. , concept price , mileage ) and the third one by concepts of text type ( e.g. , concept author , title ).
 The observ ations of localities and their consistenc y with data types indicate that: For expressing a constrained subset of values, e.g. , price in range ( ) , there are only limited ways of presentation in query interf aces. The possible variations are restricted by the lo-calities of alternati ves or data types. For instance, to express price range ( ) , since it is of numeric type, we thus will use tem-plates e.g. , or , in the corresponding  X  X umeric locality . X  As we further observ e, data type pro vides a platform (which is not specific to any source) for simulating the  X  X f fects X  of conditions by encoding the semantics, as constrained subset, of dif ferent opera-tors with respect to the platform. For example, for numeric type condition, a line of real numbers is such a platform for simulating the semantics. Upon this numeric line, we can encode the meaning of operators, e.g. , between , or as partitioned ranges on the nu-meric line. For example, operator between ( ) is encoded as a range from to on the numeric line. To understand a condition, e.g. , [ price ; between ; 0,35] , is simply to apply the encoded kno wl-edge to simulate the result against the platform. Therefore, data type gives us a source-generic platform for encoding the semantic kno wledge needed for query translation. Based on such kno wledge, we are able to translate queries for those unseen sources, as long as it reuses the templates in the type-based template localities. Appr oach: To translate a condition, we develop a search-dri ven approach. That is, among all possible instantiations of the tar get template, we search for the one, which is closest to the source con-dition. Figure 9 gives an overvie w of the condition mapping ma-chinery . It tak es a source condition and a matching tar get condi-tion template as input, and outputs the closest tar get translation for . Specifically , starting from source condition and tar get condition template , the type reco gnizer first recognizes the type of the two conditions by exploiting their syntactic features ( e.g. , the from-to pattern for numeric type, the operator , the values in the tar get template domain, etc. ). It then further dispatches the condi-tions accordingly to the type handler . The type handler encodes our type-specific kno wledge for understanding the semantics of query conditions. Based on such understanding, it performs search in all possible instantiations of to find the closest mapping as the output of the translation. Toward building the MetaQuerier system, we are inspired to ob-serv e that there seem to emer ge common insight across several in-tegration tasks. While we have developed these tasks (Section 2) separately , each with its specific techniques, as we put them to-gether , the y seem to share the same methodology , which reveals a common insight that conceptually unifies the seemingly dif ferent approaches. This section discusses this methodolo gy ,  X  X olistic in-tegration,  X  and its underlying unified insight ,  X  X ining for semantic disco very . X  To begin with, as Section 1 moti vated, we note that any inte gra-tion task is, to a lar ge extent, about semantics disco very  X  to dis-cover certain tar get semantics : e.g. , for task interf ace extraction :  X  X xtracting X  query conditions; for schema matching :  X  X atching X  these query conditions across dif ferent interf aces; for query trans-lation :  X  X nderstanding X  each condition. The major barrier for lar ge scale inte gration, with its dynamic and on-the-fly nature, is exactly such semantics disco very , for the lack of pre-configured per -source kno wledge.
 As a shared  X  X ethodology , X  for such lar ge scale inte gration, to tackle the very challenge of semantics disco very , our solutions have essentially assumed the same holistic inte gration frame work. By holistic inte gration , we tak e a holistic vie w to account for many sources together in inte gration, by globally exploiting  X  X lues X  across all sources for resolving the  X  X emantics X  of interest X  To our sur -prise, although not obvious by their own, when put together , man y of our inte gration tasks implicitly share the same holistic-inte gration frame work X  which thus conceptually  X  X nifies X  our various tech-niques.
 As a hindsight, we thus  X  X ropose X  holistic inte gration as a con-ceptually unified methodology for lar ge scale inte gration. As evi-dent from our experience (albeit limited), we belie ve such holistic-inte gration is promising: It is intriguing to observ e, as we are in-spired, that the  X  X hallenge X  of lar ge scale can lend itself as a unique  X  X pportunity X  to solv e inte gration tasks X  The essence of holistic in-tegration hinges on seeing not only the  X  X ree X  of each source indi-vidually but also the  X  X orest X  of man y sources as a whole. That is, it will explore holistic clues (as we will see) across man y sources as a  X  X ommunity X  to tak e adv antage of the lar ge scale (with suf ficient  X  X amples X ). Such  X  X olistic X  approaches will lik ely be essential for lar ge scale inte gration tasks.
 In particular , such holistic inte gration, as a common methodology , reveals several interesting  X  X nderlying principles,  X  for enabling se-mantics disco very . In particular , in its materializations for vari-ous tasks, we have observ ed that holistic inte gration can resort to, among others, hidden regularity  X  as an enabling principle of the so-lutions. (As a related note, while not a focus of this paper , we have also observ ed the use of  X  X eer majority , X  as we report in [4].) Intu-itively , holistic inte gration can leverage  X  X idden regularity X  across man y sources, to disco ver the desired semantics X  For our vari-ous inte gration tasks, interf ace extraction exploits hidden  X  X yntax,  X  schema matching hidden  X  X chema model,  X  and query translation hidden condition  X  X ocalities,  X  as we will explain.
 Thus, as the main thesis of this paper , by holistic inte gration, we propose to explore  X  X idden regularity X  existing across sources X  which leads to a unified insight of  X  X ining X  as a main resort for seman-tics disco very . As just discussed, any inte gration task is essentially the disco very of certain tar get semantics X  but, we can only observ e some  X  X urf ace X  presentations . As a unified principle, several of our tasks X  in particular , interf ace extraction , schema matching , and query translation as Section 2 reported X  have exploited hidden reg-ularities of surf ace presentations for semantics disco very . In retro-spect, as Figure 2 conceptually illustrates, we observ e that, under the same holistic-inte gration spirit, these tasks have built upon two common hypotheses, which relate underlying semantics to observ-able presentations, across man y sources. ( ) Shallow observable clues: The  X  X nderlying X  semantics often relates to the  X  X bserv able X  presentations, or shallo w clues, in some way of connection . Thus, we can often identify certain observ able clues, which reflect the underlying semantics. ( ) Holistic hidden regularity: Such connections often follo w some implicit properties, which will reveal holistically across sources.
Thus, by observing man y sources, we can often identify certain hidden regularity that guides how the semantics connects to the presentations.
 These hypotheses shed light for dynamic semantics disco very X  To tackle this main challenge in lar ge scale inte gration, we tak e the approach of holistic mining of shallo w presentations across man y sources to unco ver underlying semantics: By identifying the holis-tic regularity , our inte gration task, to disco ver the desired seman-tics, is thus the  X  X n verse X  of this semantics-to-presentations connec-tion. Our  X  X olistic inte gration X  frame work can then develop some rever se analysis , which holistically analyzes the shallo w clues, as guided by the hidden regularity , to disco ver the desired semantics X  Ov erall, holistic inte gration is thus translated to holistic  X  X ining X  of observ able presentations for underlying semantics.
 While a unified insight, as we will see, such holistic mining can materialize into dif ferent concrete solutions, depending on the spe-cific inte gration task at hands. That is, to specifically realize such holistic mining, as the dual hypotheses dictate, our holistic mining frame work must address two  X  X nabling X  questions for making the frame work possible: connection, what is the hidden regularity? (Does it even exist?)
Such regularity , if identified, will guide the reverse analysis for mining the semantics. tified, what is the rever se analysis? That is, what reverse analysis shall serv e as our  X  X ining X  technique? With this conceptual frame work (Figure 2), Section 3.1 will next present how it  X  X nifies X  our example tasks with their specific tech-niques, and Section 3.2 then discusses if this insight can generalize beyond our initial task studies. This general  X  X olistic mining X  frame work, as Figure 2 sketches, conceptually unifies our approaches for several tasks as its spe-cific realizations. We now demonstrate with interf ace extraction , schema matching , and query translation  X  As Figure 10 contrasts, while addressing dif ferent problems with dif ferent techniques, these tasks are consistently unified under the same conceptual frame work of holistic mining for semantics disco very .
 First, consider interf ace extraction : As Section 2 introduced, the observ ation of condition  X  X atterns X  moti vated us to hypothesize the existence of hidden syntax  X  In our term now, this con verging syn-tactical structure is the hidden regularity , which we identify across holistic sources. We thus rationalize the common condition lay-out patterns by asserting query-form creation, although at various autonomous sources, as guided by some hypothetical syntax: As Figure 10(a) sho ws, the hypothetical syntax (as hidden regularity ) guides an interf ace composition process (as connection ) from query conditions (as semantics ) to their visual patterns (as presentations ). That is, in terms of our holistic inte gration frame work, there ex-ists a compositional connection (Hypothesis ), and such connec-tions at various sources share the same syntactical grammar as the regularity (Hypothesis ). This syntactical interf ace composition beha vior constrains how conditions may be arranged visually in interf aces X  e.g. , attrib utes may be aligned with their input fields in certain ways. This hidden syntax effecti vely transforms the prob-lem: The rever se analysis to find query conditions is thus the  X  X in-ing X  of syntactically connected components and thus, since we vie w query interf aces as a  X  X isual language,  X  a visual-langua ge par sing approach.
 Second, consider schema matching . As Section 2 introduced, we hypothesize a hidden generati ve beha vior , which probabilistically generates, from a finite vocab ulary , the schemas we observ ed X  In our term now, this consistent generati ve beha vior is the hidden reg-ularity , which we identify across holistic sources. We thus rational-ize the common attrib ute occurrence patterns by asserting query-schema creation, although at various autonomous sources, as guided by some hypothetical generati ve beha vior . As Figure 10(b) sho ws, the hypothetical generati ve beha vior (as hidden regularity ) guides a schema generation process (as connection ) from the matchings of attrib utes (as semantics ) to their occurrences in schemas (as pre-sentations ).
 That is, in terms of our holistic inte gration frame work, there ex-ists a generati ve connection (Hypothesis ), and such connections at various sources share the same statistical beha vior as the regu-larity (Hypothesis ). This statistical schema generati ve beha vior constrains how attrib utes may occur in schemas X  e.g. , grouping at-trib utes tend to positi vely co-occur while synon ym attrib utes neg-atively . This hidden generati ve model effecti vely transforms the problem: The rever se analysis to find attrib ute matchings is thus the  X  X ining X  of statistical correlated attrib utes, and thus a corr ela-tion mining approach.
 Third, consider query translation : As Section 2 introduced, the main challenge in on-the-fly query translation lies in condition un-der standing  X  the automatic  X  X nderstanding X  of a condition (as an instantiation of a condition template at the tar get query interf ace) for what it  X  X eans X  X  The  X  X emantics X  to disco ver is thus, for a given query condition , what is the subset of values, or the result rang e , that the condition constrains.
 The observ ation of condition-correspondence  X  X lusters X  moti vated us to hypothesize the existence of hidden localities , each of which consists of a small set of alternati ve condition templates for certain data type X  In our term now, this type-based condition clustering is the hidden regularity , which we identify across holistic sources. We thus rationalize the common condition-correspondence patterns by asserting the expression of queries on a certain concept, although at various autonomous sources, as guided by some hypothetical con-dition locality: As Figure 10(c) sho ws, the hypothetical condition locality (as hidden regularity ) guides a query expression process (as connection ) from a result range (as semantics ) to its query con-dition (as presentations ).
 That is, in terms of our holistic inte gration frame work, there ex-ists an expressional connection (Hypothesis ), and such connec-tions at various sources share the same localities of templates as the regularity (Hypothesis ). This type-based query expression beha vior constrains what templates may be used to construct query conditions X  e.g. , numeric attrib utes may be constructed with , , or range selections. This hidden locality effecti vely transforms the problem: The rever se analysis to find the semantics of a query con-dition is thus the  X  X ining X  of its result range. Since we vie w a con-dition as constructed within a generic locality (which is not source specific), this understanding becomes a type-based simulation of the condition X  s effect on the intended type of data X  i.e. , recogniz-ing the right type and simulating within its understood scope of the locality .
 Putting together , we have seen that these semantics disco very tasks, while with rather dif ferent techniques, are conceptually unified in the same holistic mining frame work (Figure 2). Ho we ver, these concrete approaches have demonstrated dif ferent realizations of the two  X  X nabling X  questions: First, for , we observ ed that the hidden regularities between semantics and presentations, although of the same nature, can tak e rather dif ferent forms. Ev en in our limited examples, in clear con-trast, the spectrum ranges from syntactical regularities (of hidden grammar for interf ace composition and locality for query expres-sion) on one hand to statistical ones (of hidden generati ve beha v-ior for schema generation) on the other hand. Ho we ver, the y are of essentially the same nature X  as a  X  X reation X  process connecting semantics to presentations X  for our three tasks, that of creating in-terf aces, schemas, and queries respecti vely .
 Second, for , we observ ed that the reverse analysis or the  X  X in-ing techniques,  X  although naturally implied by the forw ard con-nection, can resort to rather dif ferent  X  X ining X  techniques: In our examples, in clear contrast, the spectrum ranges from more  X  X tan-dard X  corr elation mining techniques to the less traditional approaches of visual par sing and simulation . Ne vertheless, the y are all natu-rally implied as the appropriate  X  X n verse X  of their respecti ve for -ward connections. While we have  X  X nified X  from our three initial tasks, as a hindsight, the conceptual  X  X olistic mining X  frame work for semantics disco v-ery , will the same insight  X  X eneralize X  to other tasks? As the heart of our unification, the dual hypotheses underpin the feasibility of the conceptual frame work. In this section, we attempt to qualita-tively argue that these hypotheses (and thus the desired generaliza-tion) are lik ely to hold, as the nature of Web presentations dictates. While our conjecture is informal at best, we hope to highlight intu-itively the promise of holistic mining for lar ge scale inte gration. Thus, we ask X  As the basis of our approach, are the dual hypothe-ses valid? First, for Hypothesis , are there certain presentation patterns as observ able  X  X lues X  that connect to and reflect the de-sired underlying semantics? If such patterns emer ge, this hypothe-sis will stand to guide our semantics disco very , by analyzing such clues. Further , for Hypothesis , even if such patterns exist, can we observ e them consistently as a  X  X e gularity X  across a lar ge scale? If such patterns are indeed  X  X olistic,  X  this hypothesis can guide us to exercise the lar ge scale of the Web to identify the regularity , which will then guide the reverse analysis.
 Patterns are likely to emer ge: First, we observ e that such presen-tation patterns will often naturally emer ge, for presenting certain underlying semantics.
 As the nature of the Web dictates, to con vey information to human users, its presentations will naturally sho w the follo wing character -istics: One one hand, the presentations will be  X  X eaningful X  X  to naturally bear the implications of the underlying semantics. In our examples, e.g. , for schema matching : As Section 2 discussed, at-trib ute occurrences indeed connect to the  X  X emantics X  X  The match-ings (or the lack of) between attrib utes ( e.g. , author and name ) imply if the y are mutually redundant, leading to their occurrences in a schema as observ able clues. On the other hand, to be friendly to users, the presentations will be  X  X ntuiti ve X  X  to naturally appeal to users consumption of information. For instance, for interf ace extraction : To mak e query interf aces easy to use, query condi-tions (the underlying semantics) are often arranged in a table-lik e appearance X  Thus the visual layout serv es as such an observ able clue. Ov erall, to bridge underlying semantics to users, as both ends demand, Web presentations are lik ely to exhibit meaningful and intuiti ve patterns.
 Patterns are likely to con ver ge: Further , we belie ve such patterns can often be consistently observ ed across man y sources and thus surf ace as holistic patterns.
 As the nature of the Web dictates, there are man y good reasons for this conjecture: To begin with, first, the same  X  X eaningful-ness X  upon which a pattern may emer ge (as just mentioned) at a single source will hold true at every source (thus, for schema matching , author and name will not co-occur in general). Sec-ond, for  X  X ntuiti veness X  X  Since the Web has become our  X  X ltimate information source,  X  the need of Web usability 3 naturally adv o-cates common design patterns that man y sources will lik ely follo w. For instance, for interf ace extraction : The analogy to ill-designed  X  X orms X  ( e.g. , the inf amous Florida  X  X utterfly X  ballots in US Elec-tion 2000) has generated discussions 4 on Web-form designs. More-over, as the Web is a hea vily interlink ed community , as in any social netw ork,  X  X eer influence X  will naturally for ge the con vergence of con ventions. For instance, most personal homepages follo w sim-ilar format or adopt uniform templates. In fact, on the Web, au-tonomous sources may even con verge to de facto standards X  e.g. , online bookstores seem to follo w Amazon.com as a standard inter -face.
 Ov erall, with the nature of the Web, we belie ve that presentation patterns will not only emer ge (thus Hypothesis ) but also con verge (thus Hypothesis ) across man y sources holistically . For our ex-ample tasks, we have observ ed the hidden syntax, the generati ve beha vior , and the condition localities X  We stress that, although al-most tak en for granted now, these regularities were not obvious (as the y were  X  X idden X ) to begin with; the y were only revealed as we surv eyed real Web sources, as Section 2 reported. We belie ve simi-lar observ ations will surf ace in other tasks. We note that, as further evidences, several research efforts have also emer ged recently to leverage such  X  X olistic mining X  insight for inte gration, as Section 5 will discuss. In our development of the holistic mining insight for semantics dis-covery , we also observ ed some open issues that warrant further re-search. These issues can be cate gorized into three aspects: the re-alization of the mining frame work, the rob ustness of mining tech-niques, and the exploration of holistic insight.
 The Realization of the Holistic Mining Framew ork: As Section 3 discussed, to realize the holistic mining for semantics disco very (Figure 2), we need to address two enabling questions ( i.e. , and as Section 3 discussed): Meta-mining for dis-covering the hidden regularity and mining for the semantics. Our evidences sho w that, for various inte gration tasks, the meta-mining phase may cover a wide range of dif ferent hidden regularities and consequently the mining phase may exploit dif ferent mining tech-niques, including non-traditional ones.
 First, as key to the frame work, meta-mining is dif ficult to automate X  It is unclear how we can automatically disco ver the hidden regu-larity with respect to a specific inte gration task. In our evidences (Section 2), we, as human experts, observ e the regularities of hid-den syntax (for interf ace extraction ), hidden generati ve model (for schema matching ) and hidden locality (for query translation ). It seems that, with current techniques, it is very dif ficult to automate such an  X  X bserv ation X  stage.
 While hard to automate, as we learned from our experience, such  X  X eta-mining X  suggests a more profound lesson X  To see  X  X idden opportunities,  X  it is imperati ve that we get to kno w the real data, by surv eys and experiments, to gather a good grasp of the charac-teristics of our problems. In particular , as we decided to  X  X et our hands dirty X  early on, our surv ey [2] of the deep Web  X  X rontier X  essentially guided us in shaping our  X  X eta-mining X  insight. Second, as our evidences sho w, the mining techniques for seman-tics disco very may exploit non-traditional approaches. To begin with, such inte gration tasks, as novel applications for data mining, may raise new issues even for existing techniques. For instance, in schema matching , our DCM approach translates finding com-ple x matchings into correlation mining, a well-studied problem in data mining. Ho we ver, in our scenario, we are more interested in negati ve correlations, which reflect the  X  X ynon ym X  attrib utes. As existing correlation mining works mostly focus on positi ve corre-lations, we need to address the new issue of developing a rob ust measure for negati ve correlations. Further , for man y tasks, their mining techniques can go beyond existing mining abstractions X  and are not even always  X  X tatistical.  X  We have witnessed several such non-standard techniques: For schema matching : our MGS approach exploits hidden model disco very with hypothesis testing; for interf ace extraction , we resort to visual parsing as the mining technique X  a syntactical rather than statistical approach. The Rob ustness of Mining Techniques: An essential dif ference between our mining for semantics and tra-ditional data mining is the interpretation of the mining result. Tra-ditional data mining does not require a strong connection between semantics and presentations, and consequently , the interpretation of mining result is rather subjecti ve since there is no clear ground truth to measure the  X  X ccurac y X  of the result ( e.g. , when do we consider an association rule accurate?) In contrast, for inte gration scenarios, the mining result has clear semantic meaning and thus the accurac y matters ( e.g. , whether an extracted query capability or disco vered matching is correct). Thus, this demand of accurac y sets a  X  X eman-tic X  metric for measuring mining techniques. In particular , as our hidden regularity is often hypothetical in nature ( e.g. , the hidden grammar for interf ace extraction is at best imaginary), the mining techniques must be rob ust against potential inconsistenc y between the actual observ ations and our hypotheses.
 First, such inconsistenc y can result from noises in the observ ations. Such noises may be collected from source containing erroneous information or generated by a preceding inte gration task. For in-stance, the input of schema matching is in fact a set of extracted interf aces outputted by interf ace extraction . As an automatic pro-cess, interf ace extraction ine vitably incurs errors, which mak e the input of schema matching noisy . It is thus critical to develop ro-bust mining approaches that can sustain noisy observ ations. In [4], we propose an ensemble frame work as a sample technique to cope with this noisy data problem.
 Second, such inconsistenc y can also result from over-simplified modeling of a hidden regularity . Hypothetical in nature, the hid-den regularity may not capture full data characteristics and thus the mining approach may be working under an  X  X nconsistent X  assump-tion. We can remo ve such an inconsistenc y by more complete mod-eling of the hidden regularity X  For instance, for interf ace extraction , the visual grammar (as the  X  X e gularity X ) consists of not only pro-duction rules but also prefer ences  X  without which the parser cannot arbitrate between conflicting patterns, which will naturally arise as the syntax is only hypothetical.
 Further Exploration of Holistic Insight : In this paper , we propose a mining vie w to disco ver semantics by exploring holistic sources across the deep Web. We belie ve there are other ways to exploit this holistic insight. In particular , in [4], we propose peer majority as a new approach for  X  X rror correction,  X  based on the same insight X  In short, we can exploit the majority of peers for correcting errors made by relati ve few . Thus, while this hidden regularity-based mining approach is promising, as our experience extrapolates, we belie ve there are lik ely more novel op-portunities for leveraging holistic sources as a principled solution for enabling inte gration. Our study of lar ge scale information inte gration has a distinct focus in terms of both the problem and the solutions. On one hand, as the problem, moti vated by enabling lar ge scale inte gration, our goal is to dynamically inte grate numerous sources on the deep Web. On the other hand, as the solutions, our observ ations of hidden regular -ities lead to a  X  X ining X  paradigm for semantics disco very . To begin with, information inte gration has traditionally focused on relati vely small-scaled pre-configured systems [6; 17] ( e.g. , Infor -mation Manifold [10], TSIMMIS [15], Clio [14]). In contrast, we are facing a  X  X ynamic X  and  X  X d-hoc X  scenario (Section 1) of in-tegrating at a lar ge scale, for databases on the Web. Such a lar ge scale inte gration imposes dif ferent requirements and thus faces its own challenges. In particular , to deal with this lar ge scale, man y tasks have to be automated as much as possible, unlik e inte gration in a small scale where sources can be manually prepared. These challenges essentially boil down to the requirement of on-the-fly semantics disco very .
 Further , to enable such semantics disco very , as our main thesis, we propose to exploit the  X  X idden regularities X  revealed by holistic sources, which leads to a mining paradigm for semantics disco v-ery . While the idea of leveraging the regularities for semantics dis-covery has also been observ ed in other research works, especially wrapper induction [11], their regularities are explicit  X  X ssertions X  rather than implicit  X  X ypotheses.  X  The focus of those works is thus to  X  X nduce X  such regularities from repetiti ve examples: e.g. , dy-namically generated Web pages from an underlying  X  X emplate.  X  In a sense, we generalize the inducti ve spirit to lar ge scale scenarios, where myriad sources, albeit heter ogeneous and autonomous , ex-hibit certain hidden regularities. We thus propose the dual hypothe-ses ( and ; Section 3), upon which we develop holistic mining as a conceptually unified frame work for lar ge scale inte gration. Toward such semantics disco very with hidden regularities, several research efforts, which also emer ged recently , essentially share sim-ilar insights X  but specifically for the schema matching task, which we have also studied in our conte xt [7; 8] (as Section 2 reported). In particular , references [18; 9] exploit clustering for holistically matching man y schemas. Reference [11] proposes a  X  X orpus-based X  idea, which uses a separately-b uilt schema corpus as a holistic  X  X no wl-edge base X  for assisting matching of unseen sources.
 While sharing similar holistic frame works, in contrast to these ef-forts, we have developed our holistic mining insight to generally tackle with  X  X emantics disco very X  common in man y lar ge scale in-tegration tasks, which we belie ve will generalize well beyond the specific task of schema matching ( e.g. , interf ace extraction and query translation ), as Section 3 discussed. Further , we belie ve, besides  X  X tatistical X  analysis (which most other works have based upon), there are a wide range of applicable techniques ( e.g. , syn-tactical parsing [20] for interf ace extraction ) to generally explore holistic hidden regularities for semantics disco very . Toward lar ge scale inte gration on the Web, where the disco very of inte gration-related semantics is dynamic and thus necessarily on-the-fly , this paper proposes our  X  X hilosophy X  of holistic min-ing for semantics disco very as a general approach. Moti vated by the concerted-comple xity observ ations of Web sources, our insights hinge on the hypotheses that the tar get semantics to be disco vered often connects to certain shallo w observ able clues, in a way guided by some holistic hidden regularities across man y sources. Inte gra-tion is thus a reverse analysis, which holistically mines the shallo w clues to disco ver the underlying semantics.
 As concrete evidences, we have studied three dif ferent deep Web inte gration tasks, interf ace extraction [20], schema matching [7; 8], and query translation [19], each of which materializes holistic min-ing with syntactical or statistical approaches. Our experience indi-cates the promise of such techniques: For interf ace extraction , our experiment sho ws that the parsing approach achie ves abo ve 85% accurac y for extracting query conditions across randomly selected deep Web sources. For schema matching , our experiment in eight popular domains sho ws that both the MGS and DCM frame works can achie ve about 80-100% accurac y. For query translation , our ex-periment in three domains sho ws that the type-base search-dri ven translation frame work can achie ve about 90% accurac y.
 Thus, as our experience (although limited) clearly suggests, such holistic approaches are well suited for the new frontier of lar ge-scale netw ork ed databases in general and our focus of the deep Web in particular . As our key insight, in these settings, as sources proliferate, their aggre gate comple xity does not gro w indefinitely X  Instead, holistic hidden regularities often naturally emer ge across sources. We thus propose  X  X olistic mining for semantics disco v-ery X  as a general approach for leveraging the lar ge scale challenge as an opportunity for new inte gration techniques. [1] M. K. Ber gman. The deep web: Surf acing hidden value. Tech-[2] K. C.-C. Chang, B. He, C. Li, M. Patel, and Z. Zhang. Struc-[3] K. C.-C. Chang, B. He, C. Li, and Z. Zhang. The [4] K. C.-C. Chang, B. He, and Z. Zhang. Toward lar ge scale in-[5] A. Doan, P. Domingos, and A. Y. Hale vy. Reconciling [6] D. Florescu, A. Y. Le vy, and A. O. Mendelzon. Database tech-[7] B. He and K. C.-C. Chang. Statistical schema matching across [8] B. He, K. C.-C. Chang, and J. Han. Disco vering comple x [9] H. He, W. Meng, C. T. Yu, and Z. Wu. Wise-inte grator: An [10] A. Y. Le vy, A. Rajaraman, and J. J. Ordille. Querying het-[11] J. Madha van, P. A. Bernstein, A. Doan, and A. Hale vy. [12] J. Madha van, P. A. Bernstein, and E. Rahm. Generic schema [13] K. Marriott. Constraint multiset grammars. In Proceedings of [14] R. J. Miller , M. A. Hern  X  andez, L. M. Haas, L. Yan, C. T. [15] Y. Papak onstantinou, H. Garc  X  X a-Molina, and J. Ullman. Med-[16] E. Rahm and P. A. Bernstein. A surv ey of approaches to [17] J. D. Ullman. Information inte gration using logical vie ws. In [18] W. Wu, C. T. Yu, A. Doan, and W. Meng. An interacti ve [19] Z. Zhang, B. He, and K. C.-C. Chang. On-the-fly constraint [20] Z. Zhang, B. He, and K. C.-C. Chang. Understanding web
