 freely-defined tags, hence the ternary relation of formed. This system must interpret the observed and non-observed entries in tagging item using certain tags. The non-observed entries can reveal two types of information: values that indicate users might be interested in them in the future and they need to be set of  X   X  X  X  X  X  X  X  X , X  X  X  X , X  X  X  X  X  X  X  X   X  for a tuple of  X   X  X  X , X  X  X  X , X  X  X  X   X  list of recommended items is ordered in descending order based on the predicted pre-ference score. Users usually show more interest to the fewer items at the top of the list than the ones further down the list [3]. The order of items in the recommendation list generating the list. A  X  X earning-to-rank X  approach optimizes the recommendation model with respect to the evaluation measure such that it can generate a quality top-recommendation list [3-5]. 
The measures widely used to evaluate the performance of a ranking model are Dis-counted Cumulative Gain (DCG), Mean Average Precision (MAP), and Mean Reci-procal Rank (MRR) [6]. Compared to other two measures, DCG is more widely used influence on the score than the lower positions. DCG consists of two functions: (1) a discount function which makes items lower down in the ranked list contribute less to ing the recommendation task which generates a quality top-In this paper, we propose an efficient and novel learning-to-rank method, called as This method generates an optimal list of recommended items from the DCG perspec-learning-to-rank model. This interpretation scheme has shown good performance when implemented on a pair-wise ranking model [1, 2, 8], i.e. the objective function of the model is formed based on the pairs of items on each user-tag set. In this paper, the objective function only based on the list of all items on each user-tag set. Experi-mental results on real-world datasets show that Do-Rank is scalable and outperforms state-of-the-art recommendation methods in recommendation quality. It ascertains that optimizing DCG while building the learning-to-rank recommendation model improves the recommendation performance. Recent works have proposed the optimized recommendation models based on MAP [9] and MRR [10], dealing with binary relevance data. Since the tag-based rec-Weimer et.al [11] have proposed a recommendation method by optimizing the Nor-systems use tags as implicit feedback. A recommendation system with explicit rating data builds its model by collecting the ratings which represent the preference level of ranking the predicted preference scores inferred from the unobserved relations [7, 11]. In contrast, a tag-based recommendation system builds its model by using the user tagging history as data entries. The key challenges it faces are modeling mendation list needs to be generated by ranking the predicted preference scores of list of items under all tags which may be interest to a user. model can be used as a predictor function which maps the relationship inherent in tagging data to a predicted preference score, and enables op-timization of the evaluation measure [14] such as DCG. 
The proposed item recommendation method Do-Rank comes closest to the tag rec-ommendation method PITF [8] that implements tensor approach and applies the or-dinal relevance set labelling to build a learning-to-rank model. Do-Rank has four sig-model , whereas PITF employs a pair-wise ranking model . PITF focuses on getting the the entire items recommendation list as in Do-Rank . Secondly, the objective function mistakes done at the top or bottom positions in the recommendation list [9]. Thirdly, PITF infers the negative values of non-observed tagging data from all items that have not been annotated by the user using a tag, whereas, Do-Rank implements an efficient tated by the user using any other tags. Lastly, PITF is a tag recommendation method and Do-Rank is an item recommendation method. The tag and item recommendations are two distinct tasks. Tag recommendations are generated with two specified dimen-users only and, therefore, the item predicted preference scores must be calculated for the whole available tags before being sorted as a list of top-
To the best of our knowledge, this is the first work on tag-based item recommenda-tion system that directly optimizes the ranking evaluation measure. Our contributions can be summarized as follows: (1) We propose a novel tag-based item recommenda-method with ordinal relevance set tagging data, and (3) We propose a fast learning-to-rank algorithm that implements an efficient tagging data interpretation scheme. 
The remainder of this paper is organized as follows. Section 2 details the Do-Rank learning method. Section 3 presents the experimental results based on real-world da-tasets. Section 4 concludes the paper. Let  X  X  X  X  X   X   X ,  X   X ,  X   X ,...,  X   X  be the set of  X  users,  X  X   X   X  items, and  X  X   X   X   X   X ,  X   X ,  X   X ,...,  X   X  be the set of denoted as  X  X  X  X  X  X  X  , where a vector of  X  X  X  X , X , X  X  tagging activity of user  X  using tag  X  to annotate item 2.1 Tensor Based Recommendation Prediction Model observed tagging data,  X  X  X   X  X  X  X  X  X  X  where  X  X   X   X   X   X , the user tag usage for an item. The latent relationship between users, items, and tags can be inferred after decomposition. We use CP [15] as the predictor function in our model since Tucker, the other well-known decomposition technique, is more expen-sive in both memory and time [15]. As illustrated in Figure 2, CP factorizes a third-order tensor  X  X  X   X  X  X  X  X  X  X  into three factor matrices  X   X   X  X   X  X  X  X  ponding reduced factor matrices. The predicted preference score is calculated as: A predicted score reflects the preference level of a user in choosing an item for a tag. produce quality recommendation [13]. Assuming that users show interest to a few top recommended items only [3], a recommendation model can be optimized with respect to the evaluation measure during the learning procedure [4] in order to generate quali-ty recommendation by ranking the tensor entries most effectively. 
The task now becomes to recommend an optimal (from the DCG perspective) item list to users using the latent factor matrices after decomposing input tensor model. In DCG, the correct order of higher ranked items is more important than that of the low-er ranked items and, therefore, the higher positions have more influence on the score. and numerator in Equation (2) [4, 7]. The discount function makes items lower down in the ranked list contribute less to DCG score while the gain function gives weight to the items based on their relevance label. The DCG score for a user under tag  X  can be defined as: relevance set of  X   X  X  X  X  X  X  X  X , X  X  X  X , X  X  X  X  X  X  X  X   X  (or  X   X 1,0,1  X  model. The  X   X , X , X  is the ranking position of item  X  for user The DCG score of all users over all items under all tags can be defined as: The item recommended list is generated for user  X  cending order of the computed preference scores over all items under all tags. 2.2 Smoothed DCG and Optimization It can be seen from Equation (3) that DCG is dependent on the ranking positions. The rankings change in a non-smooth way with respect to predicted relevance scores cal-culated based on the model parameters (i.e. factor matrices). The non-smooth function proaches [4]. In this paper, we solve this problem by approximating the ranking posi-tion  X   X , X , X  by a smoothed function with respect to the model parameters. approximate  X   X , X , X  by the following smoothing function: where  X  X  X  X  X  is the logistic function  X   X  X  X  X   X  X  X  , and the smoothed approximation of DCG: The resulted objective function can now be formulated as: where  X   X  is the regularization coefficient corresponding to that controls overfitting. Note that the constant coefficient ( descent to optimize the objective func tion in Equation (6). Given a case respect to the model parameters  X  X   X   X   X ,  X   X   X ,  X   X   X  , the gradient of  X   X  X  X  X  By substituting  X   X   X  X   X   X  with  X  we get: Based on Equation (9), we can see that we only have to compute the model parameters to implement the  X  X  X  X  optimization. However, we can also see tags. Therefore, in the next subsection, we propose a fast learning algorithm that im- X  X   X  of all users is only required on observed or positive items across all tags. 2.3 Fast Learning The basic idea of the fast learning algorithm is to optimize by calculating only the predicted relevance score difference have observed to show user interest and items which are not of user interest, i.e. posi-tive and negative items, respectively. The key challenge here is to efficiently infer the positive and negative items from the tagging data, on each the observed and non-observed tagging data and labels each entry as one of element in the ordinal relevance set of  X   X  X  X  X  X  X  X  X , X  X  X  X , X  X  X  X  X  X  X  X   X  pair-wise ranking model. In this paper, we propose to approximate using the  X  X  X  scheme that is implemented on a list-wise ranking model . User-Tag Set ( UTS ) Scheme. The UTS scheme, based on positive and negative entries amongst items. The items of positive entries are derived from the observed data, while the items of negative entries are interpreted from items that have not been annotated by user  X  using any other tags [1]. As illustrated in Fig-ure 3(a) and (b), the positive entries show that  X   X  has used items  X   X   X   X ,  X   X  ,  X   X  for  X   X   X   X  , and  X   X  for and negative entries are  X   X   X   X ,  X   X  and  X   X   X   X ,  X   X  ing the scheme, the input set consists of a list of tag assignment corresponding relevance score  X   X , X , X  using the following rules: negative items on each  X   X , X   X   X  X  and defines them as: (1) tive items derived from the observed data, and (2) items derived from the items that have not been tagged by resultant objective function can be formulated by: where  X  X   X  X  X  X   X   X , X , X   X  X   X   X , X , X  . The gradient of  X  X  X  X  to the model parameter  X  X  X  X   X   X   X ,  X   X   X ,  X   X   X ,  X   X   X  is given by Equation (11).  X  X   X  where  X  denotes element-wise product. From Equation (11), we can see that for op-timizing  X  X  X  X  across all users and under all tags, we only need to compute each  X  X  that is less computationally expensive than computing |  X  X  |  X  X  . The Do-Rank learning algorithm is outlined in Figure 4. 2.4 Complexity Analysis and Convergence implemented, the Do-Rank complexity (illustrated in Figure 4), becomes  X  X  X  X  X   X  X   X   X   X  , where  X   X  and  X   X  denote the average number of Since  X   X , X   X  X  X  , the Do-Rank complexity now becomes  X  X  X  |  X  | X   X  X  X  X  X  X  X  X   X   X 
The objective function of Do-Rank is optimizing iterated DCG scores during the optimization process as the termination criterion [9], declining. posed tag-based item recommendation method Do-Rank . Adapting standard practice  X  -core technique, i.e. selecting users, items, and tags that have occurred in at least number posts. Post is the set of distinct user-item sets in the observed tagging data. into a training set  X   X  X  X  X  X  X  (80%) and a test set user-item combination in the training set if a triplet The recommendation task is to predict and rank the Top- X  in  X   X  X  X  X  X  according to DCG. The evaluation metr ics [4] used to measure the recom-mendation performance are (1) NDCG, Normalized DCG score, presented at various top- X  positions, and (2) MAP, Mean Average Precision (AP). 
Following the initialization approach proposed for a ranking model [7], we ran-parameters in Do-Rank , we randomly selected 25% of all the observed data available in  X  rate parameter  X 0.01  X  and regularization parameter  X  X 1 X   X  X  X  as the size of latent factor matrix. 3.1 Scalability of Do-Rank : Impact of Fast Learning Approach We first investigated the impact of implementing the fast learning approach on opti-mizing  X  X  X  X  as defined in Equation (10), by measuring the running time for learning the model on a single iteration at different scales, i.e. 10% to 100% of 5(a) and 5(b) show that the learning time of  X  X ast learning X  approach, on the LastFM the size of items  X  . The  X  X egular X  approach, i.e. optimizing ing fast learning approach requires more learning time as the computational complexi-ty is determined by  X   X  , as previously described in Section 2.4. These results confirm that the User-Tag Set (  X  X  X  ) scheme employed in this algorithm efficiently interprets the tagging data and, the pair-wise difference between the positive and negative item entries is sufficient for determining effective ranking instead of calculating difference between all pair of items in the dataset. 3.2 Effectiveness of Co nvergence Criterion Figures 6(a) and 6(b) show the evolution of DCG@10 across iterations on the training and test sets respectively. DCG increases through early iterations on both sets, before the performance is declined. It ascertains that Do-Rank is able to effectively optimize DCG. We can notice that the DCG measure drops after a few iterations (less than 15) proach in order to avoid the model to overfit [9]. 3.3 Performance Comparison The performance of Do-Rank is compared with the following methods.  X 
PITF [8] . We have adapted PITF [8] to generate item recommendations based on the pair-wise ranking model on each user-item set. The tuned parameters are  X 0.01  X  ,  X  X 5 X   X  X  X  , and  X 128  X  .  X 
CP-TRPR [13]. A probabilistic ranking tensor-based method that ranks the pre-dicted preference scores, calculated from the decomposed models, by utilizing the t  X  X 1  X  X  X  X  X  X  X  X   X  X  X  ,  X 0 X  ,  X 20  X  X  X  X _ X  X  X  , and  X 128  X  .  X 
CTS [17]. The state-of-the-art matrix-based method that ranks the recommenda-tuned parameters are  X 50  X  X  X  X _ X  X  X  X  X  X  X  X  X  X  X  and  X 20  X  X  X  X _ X  X  X  X  X  The recommendation performance comparisons of the proposed Do-Rank and the benchmarking methods on LastFM and MovieLens datasets are listed in Table 2 and methods in terms of NDCG (at any top- X  positions) on both datasets. It can be noted that the higher the top- X  position, the less the NDCG score is. In terms of MAP, Do-Rank is still able to outperform other methods on the LastFM dataset. 
Compared to PITF, an AUC-based optimi zation approach which gives equal penal-hances the top- X  recommendation performance by optimizing the top-biased measure building the learning model will improve the recommendation performance. Addi-lists, i.e. list-wise measure. 
Both Do-Rank and CP-TRPR utilize the users past tagging history to correctly rank the order of items that might interest users. However, CP-TRPR interprets the tagging considers the observed entries as  X 1 X  and overfits the negative and null values inferred impacts the recommendation performance [2]. Moreover, the model was designed to Finally, Do-Rank outperformance towards CTS is again proving that three-dimensional characteristic of tagging data must be captured so that the many-to-many three-dimension into two-dimensions [12]. directly optimizes the (smoothed) DCG in building the learning model for generating an ordered list of items that might interest the user. Entries in the tensor-based model are generated from the ordinal relevance set tagging data. We presented a fast learn-ing approach that implements the User-Tag Set (  X  X  X  scheme, and enables efficient execution of Do-Rank . The experimental results on real datasets show that Do-Rank is scalable and outperforms all benchmarking methods on model improves the recommendation performance. For the future work, we are plan-ning to investigate the implementation of DCG optimization on other ranking models and the potential of optimizing other measures for tag-based item recommendation as different measures possibly yield different recommendation performances. 
