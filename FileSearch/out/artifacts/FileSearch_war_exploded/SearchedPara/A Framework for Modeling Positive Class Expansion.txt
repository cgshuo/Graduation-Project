 In conventional machine learning and data mining research, it is assumed, explicitly or [4,14]. However, in many real-world applications, we may encounter problems with varying target concept. The f ollowing are two examples.

In these examples, a common difficulty is that the training data is collected at an earlier time point but the predictions are t o be made later, meanwhile the coverage of the target concept at different time points may be quite different. For example, in the above Example 1, suppose there were only 10 customers who had already turned to the new product (i.e., 10 positive examples ) at the time when the data were collected; but when the model is used to make prediction, 20 more customers have already turned to the new product. Thus, if we only consider the original 10 positive examples, maybe the model we build for predicting who will turn to the new product could not meet our demand.

A possible solution to the above problem is to wait for a long period to collect a can be considered. However, this may be infeasible in most cases since waiting for a long period will cause, for example, great loss of benefits in the above Example 1 and loss of human lives in the above Example 2. Moreover, data used in data mining tasks miner could not collect more data. So, the varying target concept problem has to be addressed when there is only a single snapshot data set instead of a series of data sets taken at different time points.

In this paper, we propose a framework to deal with the positive class expansion prob-lem, which has been illustrated in the above examples, with a single snapshot data set. Our framework has two elements. The first element is the utilization of the observation that the instances that are currently positive become positive ahead of the instances that are currently negative , which leads to an AUC optimization problem. The second element is the incorporation of domain knowledge expressed by user preferences of pairs of instances. These two elements are unified as an optimization problem, which is solved by the SGBDota (Stochastic Gradient Boosting with Double Target) approach. The SGBDota approach achieves success in e xperiments, which validate the useful-ness of our framework for dealing with positive class expansion problem with single snapshot.
 Section 3 reviews some related work. Section 4 proposes our framework. Section 5 reports on experiments. Finally, Section 6 concludes. instance is associated with a random variable y called class, which is determined by p ( y | x ) . In conventional classification problem, a learning algorithm outputs a function  X  f (  X  ; D, p ( y | x )) that minimizes the error of a loss function L : where we call the training set as a snapshot and the time point as training time .After trained on the snapshot, a classifier is used to make predictions at a later time point, while D keeps steady. The evaluation of  X  f is therefore changed tively. The formalization of positive class expansion consists of two constraints: which means there are only two classes, positive and negative, and the positive class is in expanding. The positive class expansion problem appears to have some relationship with PU-Learning [12,17], concept drift [9,10], and covariate shift [8,1]. But in fact it is very different from these tasks.

In PU-Learning, i.e., learning with positive and unlabeled data, it is required to dis-criminate positive instances from negative i nstances, while only positive instances are available in training data. A large part of works addressing PU-Learning follow two steps, e.g. [12,17]. First, strong negative instances are discovered from the unlabeled
In concept drift, an online learning envir onment is considered, where instances are coming sequentially batch by batch, and the target concept may change in the coming batch. A desired approach for concept drift problem is the one that correctly detects and fast adapts to the drift, e.g. [9,10].

In covariate shift problem (or sample selection bias [13]) , training and test instances are drawn from different distributions, while the a posteriori probability is unchanged. Using the notations in the previous section, it minimizes the error: proaches (e.g. [8,1]) addressing this problem try to correct the bias in the training in-stances, such that minimizing error on the training instances corresponds to minimizing error on the test instances.

The positive class expansion problem is apparently different from the above prob-lems. In PU-Learning problem, most works make an assumption that the positive in-stances in the training set are representat ive of the positive class concept. But in our problem, the positive class is in expanding thus are not representative. We have noticed a recent work of PU-Learning considers differe nt training and test distributions [11]. However, that work gears heavily to text mini ng by using specialized mechanisms, i.e., it tries to synthesize samples by using additional keywords. In concept drift, it expects a series of data sets with information for drift detection, but in our problem, there is assumes the a posteriori probability is unchanged from the training time to the testing time. On the contrary, the a posteriori changes in our problem.

The approach, we proposed to solve the optimization problem in our framework, is derived from Gradient Boosting [5,6]. Gradient boosting is a greedy optimization approach that avoids solving complex equations by iteratively fitting residuals of the objective function. In order to minimize an arbitrary loss function L , minimization problem, where  X  t is the parameter of h ,  X  t and  X  t are decided by where F t = F t  X  1 +  X  t h (;  X  t ) and F = F T . To avoid dealing with the complex loss function L ,itfirstsolves  X  t by fitting pseudo-residuals least-squarely according to and then it solves  X  t according to Since the positive class is in expanding, it is reasonable to assume that the instances that are currently positive become positive ahead of the instances that are currently the negative instances, which is exactly expressed by the AUC ( area under ROC curve ) [3] criterion. This assumption may imply the total information that we can obtain from the data set per se. Thus, we use 1 minus the AUC value as the loss function to evaluate how the information provided by the training data is utilized: where D + and D  X  are subsets of D that contains all of the positive and negative in-stances, respectively, and I ( a ) gets 1 if a  X  0 and 0 otherwise.

Since the training data is not sufficient to build a good model in our problem, we indicate pairwise preferences on some inst ances. For example, pairs of instances can be randomly drawn from the training set, and then the user is asked to judge which instance would become positive earlier in his/er opinion. Another possibility is to apply apriori rules to decide which instance would become positive earlier, such as people of Mongoloid race may be easier to got SARS than people of Caucasoid race .Let k (  X  ,  X  ) denotes the user X  X  pairwise preferences, such that where  X  x a is preferred X  means that the user thought that x a would become positive earlier than x b . We then fit these preferences by the loss function:
Our final objective function combines Eq.1 and 2 by aprior weight  X  :
As mentioned before, we realize our framework based on Gradient Boosting [5,6]. In the original Gradient Boosting algorithm, each instance x is associated to a target label y . However, in Eq. 3, each instance x is associated to two targets, one is y x while the learners in each iteration, h 1 and h 2 ,as: where h 1 and h 2 fit the residuals of L auc and L pref , respectively.
 loss functions are rewritten as: The residual of L auc for each positive instance x  X  D + is and for each negative instance x  X  D  X  is  X  The residuals of L pref is:  X  k x =  X  Then, fitting to the residuals least-squarely, we have  X  Next, defining  X  To do the minimization, we solve by the Newton-Raphson iteration with one step: set as the initial guess of  X  .After  X  1 and  X  2 have been solved, we have
Before forming the approach, There are two important issues to be dealt with. One is different behaviors between Eq.1 and Eq.4. Consider two instances x a and x b with y a =+1 and f ( x a and x b are equal or very close 1 according to the user X  X  preference, the objective function will still pay much attention on ranking x a before x b , which makes the built model over complex. We handle this issue by removing a part of negative instances that model for AUC residuals.

The other issue is that some instances have either y values or preferences, but not both. We fit the model of AUC on instances where y values are available, fit the model bination weights of the two models on the intersection of the instances.
Table 1 presents the SGBDota (Stochastic Gradient Boosting with Double Target) where y values and preferences are both available. But since D b isonlyusedtodeter-especially when this effect will be further reduced by shrinkage parameter in line 12. [6]. In line 12, the shrinkage is used to prevent from overfitting.

SGBDota have several parameters.  X  can be set according to the user X  X  confidence of the domain knowledge,  X  could be set as 0.01 [6]. We eliminate p by a simple strategy: we run SGBDota with different p , and choose the value with which the preference is best fitted, i.e., the minimum L pref that SGBDota reaches. Here L auc is not involved in choosing of p because it contains no information about the expansion. 5.1 Experimental Setting In order to visualize the behavior of the proposed approach, we generate a 2-dimensional synthetic data set, by sampling 1,000 instances from four Gaussian models. In order to evaluate the performance of the proposed approach on real-world data sets, we derive four data sets from the UCI Machine Learning Repository [2].
 segment contains seven classes of outdoor images, i.e., brickface , sky , cement , win-dow , path , foliage ,and grass .Weset grass as the positive class at training time, and grass + foliage + path as the positive class at testing time. veteran is the veteran X  X  administration lung can cer trial data. We set instances with time within 48 hours as positive at testing time. pcb is the data recorded from the Mayo Clinic trial in primary biliary cirrhosis, of the liver conducted between 1974 and 1984. We set instances with living time within 365 days and 1460 days as positive at training and testing time, respectively.
On data sets postoperative, veteran, segment and pcb , we randomly split 2/3 of the using AUC criterion. The split is repeated 20 times to obtain an average performance.
We try three assumptions of  X  X omain knowledge X  for experiment. The first one as-sumes that the positive class expands from dense positive area to spares positive area, the second one assumes the positive class expands from dense positive area to spares random space splits and counting instances in the local region. The third one assumes the positive class expands along with the neighborhoods using linear neighborhoods propagation [15] (positive label is +1 and negative label is zero). We name the SGBDota with the three assumptions as SGBDota-1, SG BDota-2, and SGBDota-3. Nevertheless, it is expected to incorporate real domain knowledge in real world applications.
The default parameter setting of SGBDota is: T =50 ,  X  =0 . 01 approximately be on training set by the search strategy mentioned before, where p =1 means only the negative instances with the lowest preference are kept undeleted for minimizing L auc . Approaches compared to SGBDota include Random Forests, PU-SVM [17], SG-BAUC and Random. Random Forests includes 100 trees. PU-SVM uses RBF kernel. SGBAUC is AUC optimization by stochastic gradient boosting with shrinkage 0.01 and 50 iterations. Random is the random guess approach, which serves as a lower bound. All the other default parameters are taken from WEKA [16]. 5.2 Comparison with Other Methods First, we visualize the behavior of our approach by the synthetic data set. The data dom Forests, PU-SVM, SGBAUC, and SGBDota-1, are trained on the data set. Then, ( x and displayed in Fig.1(b), (c), (d), and (e), using histogram equalization.
In Fig.1(a), since the expansion is from regions of high positive density to low posi-tive density, we expect that there are two expanding paths, one is from the right cluster bottom cluster. From Fig.1(b), it is observed that Random Forests does not find the expanding path from the right cluster to the bottom cluster. From Fig.1(c), PU-SVM SGBAUC ignores the path from the left cluster to the bottom cluster. Finally, SGBDota concerns all the expanding paths, as shown in Fig.1(e).
 Results of comparisons between SGBDota and the other methods are presented in Table 2. Since each approach is tested 20 times on each data set, for two approaches in comparison, we employ a pairwise two-tail t -test with significance level at 0.05 to test if they have significant differences. A win/loss is counted SGBDota is significantly Table3 lists the counts. It can be found that SGBDota-1 and SGBDota-2 never lose, and are better than all the other approaches on segment . SGBDota-2 is moreover better than all the other approaches on pbc . This indicates that, with eff ective domain knowledge, our approach can exceed the-stat-of-t he-arts learning approaches. 5.3 Influence of Parameters We study the influence of the parameter p . The performances of SGBDota with p = { 1 Forests, PU-SVM, SGBAUC, and Random are also plotted.

On segment and pbc , there is a large flat area where SGBDota-1 and SGBDota-2 have the best performance. On postoperative and veteran , SGBDota-1 and SGBDota-2 have less chance to be the best, which may be because the domain knowledge we used here is not strong. We also note that postoperative is a hard data set, where Random Forests is worse than Random, and SGBAUC can only achieve equal performance with Random, but SGBDota-1 and SGBDota-2 have a significant chance to exceed Random.
Then, we study how the parameter  X  affects the performance of SGBDota. Here we use SGBDota-1 as a representative of the SGBDota approach. We test it by varying p in of SGBDota on the four UCI data sets.

From Fig.3, it can be observed that  X  =1 is better than smaller value, which is rea-sonable because if the used domain knowledge is useful, it should be heavily weighted, otherwise the knowledge is probably fake. While it is hard to choose a good fixed value of p , because when the domain knowledge is strong, p needs to be large to reduce the it is convenient to let  X  =1 ,andset p according to user X  X  confidence about the domain knowledge or leaving p be determined by the search strategy. In this paper, we propose a framework to deal with positive class expansion problem with single snapshot. Our framework includes two elements, i.e., the utilization of the observation that the instances that are currently positive become positive ahead of the instances that are currently negative , and the incorporation of domain knowledge ex-pressed as user preferences of pairs of instances. We formulate the problem as an opti-mization problem, and propose the SGBDota (Stochastic Gradient Boosting with Dou-ble Target) approach which achieves success in experiments.

In our future work we will try to apply our approach to some real-world tasks which suffer from the positive class expansion problem. We will also try to extend the pro-posed framework to other varying target con cept problems, such as the positive class shrinking problem. This research was supported by the National Science Foundation of China (60635030, 60721002), the National High Technology Research and Development Program of China (2007-AA01Z169), and the Foundation for the Author of National Excellent Doctoral Dissertation of China (200343).

