 Conformity is a type of social influence involving a change in opin-ion or behavior in order to fit in with a group. Employing several social networks as the source for our experimental data, we study how the effect of conformity plays a role in changing users X  online behavior. We formally define several major types of conformity in individual, peer, and group levels. We propose Confluence model to formalize the effects of social conformity into a probabilistic model. Confluence can distinguish and quantify the effects of the different types of conformities. To scale up to large social net-works, we propose a distributed learning method that can construct the Confluence model efficiently with near-linear speedup.
Our experimental results on four different types of large so-cial networks, i.e., Flickr, Gowalla, Weibo and Co-Author, ver-ify the existence of the conformity phenomena. Leveraging the conformity information, Confluence can accurately predict actions of users. Our experiments show that Confluence significantly im-proves the prediction accuracy by up to 5-10% compared with sev-eral alternative methods.
 J.4 [ Social and Behavioral Sciences ]: Miscellaneous; H.3.3 [ Information Search and Retrieval ]: Text Mining Algorithms, Experimentation Conformity; Social influence; Social network
Conformity is the act of matching attitudes, beliefs, and behav-iors to group norms [8]. The phenomenon of conformity could occur in small groups or the whole society, as a resultant of peer in-fluence or group pressure. Conformity can have either good or bad effect depending on the situation. For example, it helps form and maintain the social norms, and helps prevent acts that are percep-tually dangerous. Conformity can be influenced by various factors such as individual status, peer influence and group pressure. There-fore there is a clear need for qua ntitative methods for measuring conformity from different aspects, so as to understand the complex dynamics in social networks.

Conformity was first studied by psychologists through inter-views with small groups of participants [17]. In economics, Bern-heim [3] found that sometimes pe ople are willing to conform sim-ply because they recognize that departure from the social norm may impair their status. Bernheim further proposed a theory of social conformity and presented a model to describe the conformity pro-cess. However, due to the lack of real data, he only studied the model from the theoretical aspect. With the rapid proliferation of online social networks such as Facebook, Twitter, and Flickr, it becomes feasible and also very necessary to conduct an in-depth investigation of the conformity problem on real large social net-works. In practice, the effect of conformity has been also observed in online social networks. For example, Bond et al. [4] reported results from a randomized controlle d trial of political mobilization messages delivered to 61 millio n Facebook users. They found that when one is aware that their friends have made the political votes, their likelihood to vote will significantly increase. Bakshy et al. [2] also found that when their friends click an ad, they will be more likely to click the same ad.

From a broader viewpoint, conformity can be seen as a special type of social influence. There are a bulk of studies on social in-fluence analysis. These studies can be roughly classified into three categories: influence testing [1, 9, 20], influence quantification [12, 13, 23, 32], and influence maximization models [6, 18]. However, most of the works focus on qualitative study of social influence. With an exception, Tang et al. [32] presented a Topical Affinity Propagation (TAP) approach to quantify the topic-level social in-fluence in large networks. However, they do not distinguish the effect of peer influence and group conformity.

There are several challenges for the conformity influence analy-sis. First, how to formally define and differentiate different types of conformities? Unlike peer influence, which mainly considers how two connected friends influence each other, conformity occurs in different situations and exists with different forms. Second, how to construct a computational model to learn the different conformity factors? Third, how to validate the proposed model in real large networks.

To address the above challenges, we formally define the problem of conformity influence analysis in social networks and categorize conformity into individual conformity, peer conformity, and group conformity. We propose an Confluence method to formalize the ef-fects of social conformity into a probabilistic factor graph model. Figure 1: Action prediction accuracy (AUC) of different meth-ods by considering the effect of conformity in four networks. The Confluence method can distinguish and quantify the effect of the different types of conformities. We test the proposed method on four social networks, i.e., Flickr, Gowalla, Weibo 1 , and Co-Author. Our experimental analysis verifies the existence of conformity in all the four social networks. We further apply the Confluence method to model and predict users X  online behavior. To scale up to large social networks, we propose a distributed learning version of Con-fluence that can leverage parallel computing to significantly reduce the computational time to nearly linear speedup (  X  9  X  with 16 computer cores). Figure 1 shows the prediction accuracy in terms of Area Under Curve (AUC) on the four networks. It can be clearly seen that by incorporating the conformity factors, the prediction performance can be significantly improved up to 5-10% compared to various baseline methods.
 Organization Section 2 formulates the problem; Section 3 ex-plains the proposed model and describes the algorithm for learning the model; Section 4 presents the experimental results; finally, Sec-tion 5 discusses related work and Section 6 concludes the work.
Let G =( V,E ) denote the social network, where V is a set of |
V | = N users and E  X  V  X  V is a set of relationships between users. A user X  X  behavior is time dependent. Specifically, we use the triple ( a, v i ,t ) to represent user v i performed action a t ,where A is the set of possible actions. For example, on Flickr, the action can be defined as adding comment to a specific picture. We further assume that users in a network form m groups and use an N  X  m matrix C to represent users X  group memberships. Specif-ically, each binary-valued element c ik  X  C represents whether user v belongs to the k th group. We use C k to represent the k th The group can be formed through user participation. For example, users on Flickr can build and join different groups. If a network does not have the explicit group information, we use a community detection algorithm (e.g., [27]) to automatically detect groups from the network structure. In addition, each user v i is associated with a
Weibo.com, the most popular microblogging service in China with more than 400 million users.
 set of d numeric attributes x i . The attributes can be defined based on users X  profile (e.g., interest or posted tweets). Given this, we can define the input of our problem as follows. (Table 1 summarizes the notations used throughout this paper.) Input: The input of our problem consists of two components, i.e., an attribute augmented network G =( V,E, C , X ) and action history A = { ( a, v i ,t ) } a,i,t ,where X denotes an N matrix with an element x ij indicating the j th attribute of user v
Our goal is to study how a user X  X  behavior conforms to her peer friends and the commun ities (groups) tha t she belongs to. In this work, we define three levels of conformities respectively from the aspect of individual, peer relationship, and group. The individual conformity represents how easily user v  X  X  behavior conforms to her friends. Formally, we have
Definition 1. Individual conformity: The individual confor-mity is defined as the ratio between the number of actions for which we have evidence that the user v conforms to one of her friends v , over the total number of actions performed by user v .Morepre-cisely we define: where A v  X  A denotes the action history of user v and is a threshold of difference between the time when the two users v and v performed the same action a ,and | X | denotes the cardinality over aset.

We also define peer conformity to represent how likely the user v  X  X  behavior is influenced by one particular friend v .
Definition 2. Peer conformity: The peer conformity is defined as the ratio between the number of actions for which we have evi-dence that the user v conforms to her friend v , over the total num-ber of actions performed by the friend v ,thatis: where A v  X  A denotes the action history of user v .

We further define group conformity to represent the conformity of user v  X  X  behavior to groups that the user belongs to. In a group, there might be a large number of actions performed by its users. However many actions may be performed by only one single user. To begin with, we first define the  X  -group action as the action that was performed by more than a percentage  X  of all users in the com-munity (group) C k . Given this, we define the group conformity as follows:
Definition 3. Group conformity: The group conformity is then defined as the ratio between the number of actions for which we have evidence that the user v conforms to the group, over the total number of  X  -group actions performed by users in the group C where A  X  C k  X  A denotes actions performed by more than a per-centage  X  of all users in the group C k ; I [ c ik ] is an indicator func-tion, which returns true if the value of c ik is 1 and false otherwise.
Please note that a user may be involved into more than one groups, thus has different conformity degrees in the different groups. The above definitions quantify the conformity from differ-ent levels (individual, peer relationship, and group). Further, given the action history A = { ( a, v i ,t ) } a,i,t ,weusevariable y indicate whether user v i performs the an action a and use the col-of all users at time t . Next, we define the problem of conformity influence analysis.

Problem: Given 1) an attribute augmented network G = ( V,E, C , X ) and 2) action history A = { ( a, v i ,t ) } quantify the importance of the different types of conformities for each user? This is formalized as finding a model parameters  X  of different conformities to maximiz e the following conditional prob-ability, i.e.,  X  =argmax  X  P  X  ( Y t | G, A ) . The second problem is how to incorporate the defined conformities and the learned model parameters into a unified model to predict users X  future action in the social network, i.e., Y =argmax Y t +1 P  X  ( Y t +1 |
Our goal is to design a unified model to capture users X  action dy-namics and model conformities from different levels. We propose Confluence, a conformity-aware factor graph model. To handle real large networks, we develop a distributed model learning algorithm.
In the Confluence model, we attempt to maximize the con-ditional probability of user actions given their corresponding at-tributes and the input network, i.e., P  X  ( Y t | G, A ) . More precisely, for each action ( a, v i ,t )  X  A , we construct a training instance. Then learning the model becomes how to find a configuration of parameters  X  to maximize the joint conditional probability for all users X  actions. When applying the learned model parameters to predict users X  future actions, it tries to find a setting of action la-bels Y t +1 at time t +1 to maximize the conditional probability P ( Y t +1 | G, A ) based on the learned parameters.

Directly maximizing the conditional probability P ( Y | G, A ) is often intractable. Factor graph provides a method to factorize the  X  X lobal X  probability as a product of  X  X ocal X  f actor functions, each of which depends on a subset of the variables in the graph [19]. In the proposed Confluence model, we try to capture two kinds of information, i.e., the attributes associated with each user and three types of conformities we defined in  X  2. Specifically, we use three factor functions to represent the individual conformity, peer conformity, and group conformity, respectively. Figure 2: Graphical representation of the Confluence model.
In the above definitions, without ambiguity, we omit the time stamp t (e.g., simplifying y t i to y i ) and use the superscript (e.g., simplifying y t i to y i ) to indicate a variable at time stamp t .
The different factors quantify how different levels of conformi-ties finally determine user v  X  X  actions. According to the defined cor-relations, we can construct the graphical structure in the Confluence model. An example is illustrated i n Figure 2. In the input network, structed factor graph, its corresponding latent variable y 1 is con-User v 1 has four friends in the input network, thus four peer confor-mity factors in the factor graph model. We also define an individual conformity factor for each user. B esides the conformity factors, we use factor function f ( y i ,x ij ) to capture the correlation between the user X  X  attribute x ij and user X  X  action. By integrating all the fac-tor functions together, and according to the Hammersley-Clifford theorem [15] we can obtain the following log-likelihood objective function, where I [ y j ] is an indicator function to indicate whether user v formed the same action immediately before user v i , more precisely, [  X  ( a, v j ,t )  X   X  t  X  t  X  0] and I [ c ik ] indicates whether user v belongs to the group C k ;  X  ,  X  ,  X  ,and  X  are respectively weights of the different factor functions;  X  =( {  X  } , {  X  } , { rameter configuration estimated from the training data; and Z is a normalization factor to ensure that the distribution is normalized so that the sum of the probabilities equals to 1.

In practice, choosing a good threshold for defining the confor-mity factors is challenging. Instead, we use a decay factor  X  in each conformity function. A large  X  means a slow-decay effect. Accordingly, the peer conformity factor is defined as: where t corresponds to the latest past time when v j performed the same action as v i in the training data set. The decay factor decays the peer conformity exponentially over time, with the half-life,  X  , serving as a tunable parameter. The basic idea is that friend X  X  recent actions have higher influence on one X  X  action. The group confor-mity factor is defined as: where t represents the latest past time when some user in group C k performed the same action as user v i in the training data set; and  X  is empirically set as 0.25. Please note that a user may belong to multiple groups and accordingl y we could incorporate multiple different group community factors into the objective function. Sim-ilarly, the individual conformity factor is defined as: where I [ y j  X  e ij  X  E ] represents whether some friend v performed the same action a k  X  A v i immediately before user v Implementation note. In our experiments, we empirically set the parameters within the factor functions as follows:  X  =2 , =1 , and  X  =0 . 25 . We did try different parameter values. For example, for  X  , we fixed all the other parameters and varied  X  from 1 to 10 with an interval 1. We varied between [1 , 5] .For  X  ,wevaried between [0 . 0 , 1 . 0] with an interval 0.05. We tested the model accu-racy (in terms of F1-score) for each parameter value and found that the performance was relatively stable across different settings. As for the community detection, we tried different algorithms such as local spectral partitioning (LSP) , METIS, and Newman. We found that the prediction performance is also not very sensitive to the choice of the community detection algorithm. Finally, we use the Newman algorithm (e.g., [27]) due to its wide adoption.
Besides the conformity features, we also define other features for modeling users X  actions in the networks. The first type of features are based on users X  attributes including the number of friends and users X  interests. More specifically, to make the defined features as general as possible, we simply consider four attribute features, i.e., the number of friends, the number of new friends in the recent three time stamps, the number of total groups that the user joined, and the number of groups the user joined in recent three time stamps. The proposed model is also general and can incorporate other social theory-based features. Thus, the s econd type of features are defined based on some other social theories. Specifically,
Opinion leader: the feature is defined to represent whether the user is an opinion leader or not. We use the InfluenceRank [29], a PageRank-like algorithm, to rank and select opinion leaders in a network.

Structure hole: the feature is defined as whether the user is a structural hole spanner 2 . We use the algorithm proposed in [24] to detect whether a user spans structural holes.

The above two features are defined as node-specific features and are recorded in the f ( y i ,x ij ) , except that here x ij the status of the user. In addition, we also define another two cor-relation features.

Social ties: a (binary) feature is defined to represent whether a tie between two users is a strong tie or weak tie [14]. Moreover, we quantify the tie strength according to the communication frequency (e.g., message sent) between users. Then, a new (real-valued) fea-tures is defined to represent the number of common neighbors be-tween two users.

Social balance: social balance theory [11] suggests that people in a social network tend to form balanced (triad) structures (like  X  X y friend X  X  friend is also my friend X ). For a undirected network, there are four types of (un)balanced triads. A binary feature is de-fined for each of the triad structure. The similar feature definition wasalsousedin[31].

These two correlation features are incorporated into our model in a similar way as that of the peer conformity factor g ( y i ,y j ,pcf ( v i ,v j )) .
Learning the Confluence model is to find a configuration for the likelihood objective function O (  X  ) . As real social networks may contain thousands or millions of nodes, we have developed a dis-tributed learning algorithm to scale up our model to handle large networks. The distributed learning algorithm was developed based on MPI (Message Passing Interface). In general, the model learn-ing algorithm can be viewed as two steps: 1) compute the gradient for each parameter; 2) optimize all parameters with the gradient descents. The most expensive part is the first step of calculating the gradient. Thus we develop a distributed algorithm to speed up the first step and perform the second step on a single (master) machine.
Roughly speaking, a person is said to span a structural hole in a social network if he or she is linked to people in parts of the network that are otherwise not well connected to one another [5].
We first introduce how we calculate the gradient for each param-eter. As the network structure in the social network can be arbitrary (may contain cycles), it is intractable to obtain exact solution of the objective function using methods such as Junction Tree [34]. We use Loopy Belief Propagation (LBP) [26] to approximate the so-lution. Specifically, we first approximate the marginal distribution P ( y i | . ) using LBP. With the marginal probabilities, the gradient can be obtained by summing over all factor functions. Theoret-ically, the LBP algorithm does not guarantee a convergence and may result in local maximum, but in practice its performance is good. We empirically compare the effectiveness and efficiency of the algorithm in Section 4. After obtained the marginal distribution P ( y i | . ) , we use a gradient descent method (or a Newton-Raphson method) to solve the objective function (Eq. 1). We use  X  as the example to explain how we learn the parameters. Specifically, we first write the gradient of each unknown parameter  X  with regard to the objective function: where E [ f ( y i ,x ij )] is the expectation of the local factor func-tion f ( y i ,x ij ) given the data distribution in the input network and E bution learned by the model, i.e., P ( y i | G, A ) . Similar gradients can be derived for parameter  X  i ,  X  ij ,and  X  ik .

Now we explain how we use distributed learning to approxi-mate the marginal probability. We use a master-slave architec-ture, i.e., one master machine is responsible for optimizing param-eters, and the other slave machines are responsible for calculating the marginal probabilities. At the beginning of the algorithm, the graphical model of Confluence is partitioned into M roughly equal subgraphs, where M is the number of slave processors. The par-tition can be done by any graph cut software. After the partition, the subgraphs are then distributed over slave processors. Then each slave processor calculates the  X  X ocal X  belief (the marginal probabil-ity) on the subgraph G l according to the following equations (again we use P ( y i | G, A ) as the example in the explanation): where  X  denotes a normalization constant; m l ij ( y i ) is the  X  X elief X  propagated from node y j to node y i ; NB ( i ) \ j denotes all nodes neighboring node y i in the subgraph G l , except y j ;  X  all defined factor functions related to y i in the subgraph G calculated by  X  l i ( y i )=exp( d k =1 f ( y i ,x ik )+  X  in the subgraph; notation b l i ( y i ) denotes the unnormalized  X  X ocal X  belief collected from each subgraph, and finally by combining them together we obtain the marginal probability P ( y i | . ) .
However, inevitably there will be some correlation factors de-fined over nodes that are partitioned into different subgraphs. These correlation factors cannot be calculated due to the high communi-cation cost. Simply eliminating those correlation factors may hurt the learning performance. To alleviate this problem, we present a virtual node based method. In particular, suppose three nodes ( y 1 ,y 2 ,y 3 ) in the Confluence model are associated with a group conformity factor g ( . ) . If the partition assi gns two nodes (e.g., y 1 and y 2 ) into one subgraph G 1 and the rest one (i.e., y 3 ) into another so that the group conformity factor can be still calculated in the sub-graph. For the virtual node, we do not calculate the local attribute factors f ( . ) . The distributed learning algorithm is summarized in Algorithm 1.
 Model inference. The learned model parameters  X  can be used to infer users X  future actions. In particular, given the network G and the action history A , we aim to predict users action labels Y time t +1 . This can be done by performing the model inference on the network to maximize the conditional probability, i.e.,
Again, we use the distributed loopy belief propagation algorithm to compute the marginal probability P  X  ( y t +1 i | . ) andthenpredict the action of each user at time t +1 as the label that has the largest marginal probability. For each user, we define the individ-ual conformity factor according to the estimated individual confor-mity from the training data. For defining the peer conformity factor time t when v j performed the corresponding action y j , and calcu-late the factor according to Eq. 2. The group conformity factor can be similarly defined.
We conduct various experiments to evaluate the Confluence method. The datasets and codes are publicly available. 3 Data sets. We evaluate the proposed method on four different genres of networks: Flickr, Gowalla, Weibo, and Co-Author. Table 2 lists statistics of the four networks.

Flickr is a photo sharing network. Users on the site can share photos and add comments to other photos. Flickr users can also create and join different groups. The data set spans the period from Apr. 1st, 2012 to Jun. 16th, 2012. We define the action as adding a comment to a specific photo. Thus the action space includes all photos on Flickr. To avoid the sparsity problem, we remove those photos with less than 5 comments. This results in 144,627 unique actions. We try to study how users X  commenting actions conform to the other users in the network.

Gowalla is a location-based social network, where users share their locations by checking-in. The data was from [7] and all check-ins of these users over the period of Jul. 10th, 2010 -Jul. 29th, 2010. The action in this data set is defined as whether a user checks in some location (indicated by hashtag or location ID). Thus the dimension of the action space is the number of available locations. We also remove those locations with less than five check-ins and finally obtain 218,811 unique actions. Our goal is to study whether the users will conform to their friends X  check-in behavior.
Weibo is the most popular microblogging service in China. We collected a complete network between 1,700,000 users and all the tweets posted by those users between Sep. 28th, 2012 and Oct. 29th, 2012. The action is defined as whether a user posts a message on a specific topic (indicated by hashtag). We choose the ten most popular topics in 2012 and study how users conform to each other in the network on discussing those topics. We aim to study how users conform to each other on discussing those topics. http://arnetminer.org/conformity/
Dataset Flickr Gowalla Weibo Co-Author #nodes 1,991,509 196,591 1,776,950 737,690 #edges 208,118,719 950,327 308,489,739 2,416,472 #groups 460,888 N/A N/A 60 #actions 3,531,801 6,442,890 6,761,186 1,974,466
Co-Author is a network of authors. The data set, crawled by Arnetminer.org [33], is comprised of 737,690 CS authors and 2,416,472 co-authorships over 1975 -2012. Based on the publica-tion venues, authors are categorized into different domains such as Data Mining, Artificial Intelligence, Computer Graphics, etc. action is defined as whether an author will publish a paper in a spe-cific domain. Thus, in total we have 200 unique actions. Our goal is to study how an author conforms to the other authors on choosing the publication venue.
 Evaluation metrics. To quantitatively evaluate the proposed model, we consider the following performance metrics:
All codes are implemented in C++ and JAVA, and all the evalua-tions are performed on an x64 machine with E7520 1.87GHz Intel Xeon CPU (with 16 cores) and 192GB RAM. The operation system is Microsoft Windows Server 2008 R2 Enterprise. The proposed distributed learning algorithm has a good convergence property. On average, it converges within 100 iterations.
 Comparison methods. Given the input network G and the action history A , we can construct a training data set { ( x i ,y where n = | A | ; x i is the feature vector associated with user v and y i = a indicates whether user v i performs the corresponding action a . In this way, we can use existing methods such as Sup-port Vector Machines (SVMs) or Logistic Regression (LR) to train a classification model and then apply the trained model to predict users X  future actions. The difference from our proposed Confluence model is that the classification model does not consider the corre-lation between users X  actions. We also compare with Conditional Random Fields (CRFs) [21].

SVM: it uses all defined features associated with each user to train a classification model and then apply it to predict users X  ac-tions in the test data. For SVM, we use SVM-light. 5
LR: it uses logistic regression (LR) to train the classification model with the same features as those in the SVM method. We also compare with the results of Naive Bayes (NB) and Gaussian Radial Basis Function Neural Network (RBF). For all the three methods, we employ Weka. 6
CRF: it is a graphical model based on Conditional Random Field (CRF). Comparing with CRFs, the factor graph model provides a
Refer to http://arnetminer.org/topic-browser for a list of domains. http://svmlight.joachims.org/ http://www.cs.waikato.ac.nz/ml/weka/ Figure 3: Factor contribution analysis. Confluence base stands more explicit explanation for the factorization of the underlying probability distribution [19]. In addition, it is not easy to incor-porate the group conformity factors into the CRF model, as users X  group memberships could be arbitrary and one user can belong to multiple groups. Thus in the CRF method, we use attribute-based features, the social-based features, and individual conformity fea-tures, but do not use the group conformity features. For CRF, we use Mallet [25].
 In all the comparison methods, we try to use the same features. The attribute based features are used in all the methods. The so-cial features defined on social ties and social balance are used in CRF and Confluence only, as SVM and LR cannot capture the cor-relations. As for the conformity features, individual conformity is defined for each user, and is used in all methods; peer conformity is defined for peer friends and is used in CRF and Confluence; group conformity is defined for groups and is used only in Confluence.
On all the four data sets, we use the historic users X  actions as the training data in different methods and use the learned model to pre-dict users X  action in the next time stamp. Specifically on Flickr each week is a time stamp (which results in 11 time stamps in total), on Gowalla and Weibo each day a time stamp (which result in 20 and 32 time stamps respectively), and on Co-Author each year is a time stamp (which results in 38 time stamps). We perform the prediction for each time stamp and finally report the average performance. Prediction performance. Table 3 lists the action predic-tion performance of the different methods on the four data sets. Our method Confluence consistently achieves better performance than the comparison methods. In terms of F1-score, Confluence achieves a 1-17% improvement compared with the SVM, LR, NB, and RBF methods that do not consider the correlation features. CRF also considers some correlation features (such as social tie and social balance based features), thus improves the prediction performance. However it cannot incorporate the group conformity feature, thus still underperforms our method by 0.5-10.5% in terms of F1-score. We produced sign tests for each result, which con-firms that all the improvements of our proposed models over the five methods are statistically significant ( p 0 . 01 ). Factor contribution analysis. In the Confluence model, we de-fine basic features based on the user-associated attributes, and five standard deviation.
  X  0.0031) 0.5802 (  X  0.0012) 0.6473 (  X  0.0004)  X  0.0057) 0.5770 (  X  0.0018) 0.6510 (  X  0.0008)  X  0.0083) 0.5920 (  X  0.0031) 0.6520 (  X  0.0019)  X  0.0010) 0.5720 (  X  0.0024) 0.6700 (  X  0.0010)  X  0.0009) 0.6239 (  X  0.0016) 0.6722 (  X  0.0010)  X  0.0010) 0.6342 (  X  0.0010) 0.7383 (  X  0.0006)  X  0.0121) 0.9295 (  X  0.0105) 0.9280 (  X  0.0042)  X  0.0234) 0.9310 (  X  0.0155) 0.9500 (  X  0.0054)  X  0.0335) 0.9300 (  X  0.0223) 0.9520 (  X  0.0030)  X  0.0284) 0.9300 (  X  0.0182) 0.9540 (  X  0.0022)  X  0.0291) 0.9330 (  X  0.0164) 0.9610 (  X  0.0019)  X  0.0173) 0.9352 (  X  0.0101) 0.9644 (  X  0.0140)  X  0.0181) 0.5060 (  X  0.0157) 0.5070 (  X  0.0053)  X  0.0104) 0.5750 (  X  0.0281) 0.5390 (  X  0.0133)  X  0.0085) 0.5810 (  X  0.0165) 0.5390 (  X  0.0132)  X  0.0098) 0.5460 (  X  0.0159) 0.5450 (  X  0.0103)  X  0.0121) 0.5720 (  X  0.0209) 0.6320 (  X  0.0139)  X  0.0085) 0.6816 (  X  0.0156) 0.7572 (  X  0.0077)  X  0.0145) 0.8256 (  X  0.0129) 0.8562 (  X  0.0115)  X  0.0346) 0.8140 (  X  0.0221) 0.8500 (  X  0.0030)  X  0.0185) 0.8050 (  X  0.0048) 0.8720 (  X  0.0074)  X  0.0191) 0.8240 (  X  0.0145) 0.8790 (  X  0.0031)  X  0.0249) 0.8360 (  X  0.0087) 0.9025 (  X  0.0025)  X  0.0130) 0.8818 (  X  0.0084) 0.9579 (  X  0.0022) types of social features: social balance (SB), structure hole (SH), opinion leader (OL), strong tie/weak tie (STWT), and conformity (CF). Here we examine the contributions of the different social fac-tors defined in our model. Specifically, first we use the basic fea-tures to train a model (referred to as Confluence base ). Then we incrementally add one of the five social features and evaluate its improvement on the prediction performance over that using only basic features. Figure 3 shows the Area Under Curve (AUC) score on the different data sets. We see that different social factors con-tribute differently in the different networks. For example, the opin-ion leader based features are very useful in the Gowalla network, but less useful in the Co-Author network. On the other hand, the conformity based features consistently improve the prediction per-formance on all the networks. In terms of the AUC score, the im-provements by adding conformity features range from 2% to 20% in the four networks. This analysis confirms the importance of the conformity phenomena in social networks.
 Effects of conformity. We further present an in-depth analysis of how different levels of conformities affect the performance of action prediction. Figure 4 shows the prediction performance (in terms of AUC) of the proposed Confluence by considering differ-ent levels of conformities. Confluence base stands for the Conflu-ence method by considering only basic features (i.e., ignoring all conformity factors). It can be clearly seen that without the confor-mity based factors, the prediction performance drop significantly. Co-Author network is most predictable because the co-authorships are stable and predictable in general. Weibo and Flickr are the most difficult to predict because the user behavior is fairly au-tonomous and independent. Conformity has most significant pre-diction impact on Gowalla, which suggests conformity plays an important role in geospatial and mobile applications in social net-works. By incorporating the conformity features, significant im-provements (+20-30%) over the prediction performance can be ob-Figure 4: Effect of conformity. Confluence base stands for the Con-tained on Gowalla. Confluence base +I (or +P or +G) respectively indicates that we respectively add individual conformity features (or peer conformity features or group conformity features) into the Confluence base method. By incorporating each type of con-formity factors, we observe clear improvement compared to the Confluence base method. We can also see that on all the four data sets, the group conformity is more important than the other two types of conformities. This makes sense, as in most cases confor-mity is a group phenomenon rather than an individual behavior.
We now evaluate the scalability performance of the distributed learning algorithm on the four networks. In our experiments, we Table 4: Running time of the proposed algorithm (hour).
 Confluence (single) 19.637 2.395 11.229 6.464 use METIS [16] to partitio n the graph into mu ltiple subgraphs (one for each core). Figure 5 shows the speedup of the distributed algo-rithm with different number of computer nodes (2, 3, 6, 8, 10, 12, 14, 16 cores) used. The speedup curve is close to the perfect line at the beginning. Though the speedup inevitably decreases due to the increase of the communication cost between the different computer nodes, the distributed learni ng algorithm can still achieve speedup with 16 cores. It is noticeable that the speedup curves on different networks present a bit different patterns. This is due to the difference of the network properties (such as densities). Table 4 further gives the running time for learning the proposed Confluence model over 16 computer cores and single compute on different data sets.

Another thing worth noting is that the distributed learning is es-sentially an approximation of the original learning algorithm on a single machine. We used METIS to partition the graph into multiple subgraphs and distribut e the subgraphs onto slave ma-chines. We also evaluate the prediction performance by the dis-tributed learning algorithm. On average, the prediction accuracy by the distributed learning over 16 cores only drops slightly (rang-ing from 0.5-1.68%), which further demonstrates the effectiveness of the distributed learning algorithm.
Now we use a case study from Flickr to further demonstrate the effectiveness of the proposed model. Figure 6 shows an exam-ple extracted from Flickr. User A joined three groups (denoted as Group 1, 2, 3 respectively). On 03/10/2012, user A added one com-ment respectively to Picture 1 and Picture 2. The Action 1 (adding comment to Picture 1) was mainly performed in Group 1 and the Action 2 (adding comment to Picture 2) was mainly performed in Group 2. After modeling with the proposed Confluence method, the modeling results suggest that, for performing Action 1, user A has a strong conformity to user B, but very weak conformity to user D and C. By taking a closer look at the data, we found that Group 1 is a loosely connected group and members have very few connec-tions in the group, and the comments to the same photo are very controversial (such as the comments of B and D to Picture 1). Thus the influence between users are mainly at the peer level. For Ac-Figure 6: Case Study. User A joined three groups (Group 1, 2, 3). tion 2, the modeling result suggests that user A has a strong group conformity to Group 2. By checking the data, we found that Group 2 is a tourist group, where people posted their photos taken in the trip. Thus it is very likely that many users added comments to some popular photos together.
Conformity was first studied by psychologist through interviews with small groups of participants. Kelman [17] identified three ma-jor types of conformity. However, the categorization is mainly from subject and cannot easily be detected by a computational model. In economics, Bernheim [3] proposed the social conformity the-ory and presented a model for modeling the conformity process. However, due to the lack of real data, he mainly focused on the theoretical aspect of the model.

Considerable work has been conducted for studying the effects of social influence. For example, Bakshy et al. [2] conducted ran-domized controlled trials to identify the effect of social influence on consumer responses to advertising, and Bond et al. [4] used a randomized controlled trial to verify the social infl uence on politi-cal voting behavior. Anagnostopoulos et al. [1] proposed a shuffle test to examine the existence of social influence. However, most of the methods focus on qualitatively study the existence of social influence in different networks. Tang et al. [32] presented a Topi-cal Affinity Propagation (TAP) approach to quantify the topic-level social influence in large networks. Goyal et al. [13] presented a method to learn the influence probabilitie s by counting the num-ber of correlated social actions. Tan et a. [30] proposed a model to learn and distinguish the effects of influence, correlation, and uses X  action dependency. However, all the aforementioned works mainly consider the peer influence between users and ignore the group conformity effect. Zhang et al. [35] proposed the concept of social influence locality and use d a large microblogging network to study how users X  behavior is influenced by close friends in their ego networks. Li et al. [22] tried to study the interplay between influence and individual conformity. However, they do not con-sider the group conformity. Quite a few studies have been done for maximizing the influence spread in social network. Domingos and Richardson [10, 28] formally defined influence maximization as an algorithmic problem and prove its NP-hardness. Chen et al. [6] further developed efficient algorithms to approximately solve the influence maximization problem. While, influence maximization is in nature different from the conformity analysis problem. To the best of our knowledge, this is the first attempt to formally define the problem of conformity influence analysis and to address this problem with a principled method.
In this paper, we study a novel problem of conformity influence analysis in large social networks. We formally define three major types of conformities, precisely formulate the problem of confor-mity influence analysis, and propose a Confluence model to model users X  actions and conformity. Three factor functions are defined to capture the different levels of conformities. A distributed learn-ing algorithm is presented to efficiently learn the proposed model. We validate the effectiveness and efficiency of the proposed model on four networks. Our experimental results show that the proposed method significantly outperforms several alternative methods. We also present a case study to further demonstrate the effectiveness of the method.

Understanding the fundamental mechanism of social conformity is very important for social network analysis and represents a new and interesting research direction. As for the future work, it would be intriguing to connect the conformity phenomenon with some other social theories such as social status and structural holes so as to understand the formation and dynamic change of the network structure. It is also interesting to design some other model, for example a game theory based model, to model the conformity phe-nomenon. As for the proposed Confluence model itself, it has many parameters. We also consider adding regularization to control the sparsity of those parameters.
 Acknowledgements. The work is supported by the Natural Science Foundation of China (No. 61222212, No. 61073073, No. 61170061), Chinese National Key Foundation Research (No. 60933013, No.61035004), and a fund for Fast Sharing of Science PaperinNetErabyCSTD.
