 In this work, we explore the use of error-correcting output codes (ECOC) to enhance the performance of centroid text classifier. The framework is to decompose one multi-class problem into multiple binary problems and then learn the individual binary classification problems by centroid classifier. However, this kind of decomposition incurs considerable bias for centroid classifier, which results in noticeable degradation of performance. To address this issue, we use Model-Refinement to adjust this so-called bias. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval-search process Algorithms; Performance; Experimentation Error-Correcting Output Codes (ECOC); Text Categorization; Information Retrieval 
In recent years, Error-Correcting Output Codes (ECOC) has been applied to boost the na X ve bayes, decision tree and SVM this work, we explore the use of ECOC to enhance the performance of centroid classifier [1]. To the best of our knowledge, no previous work has been conducted on exactly this problem. The framework we adopted is to decompose one multi-class problem into multiple binary problems and then use centroid classifier to learn the individual binary classification problems. 
However, this kind of decompos ition incurs considerable bias [6] for centroid classifier. In substance, the decision rule of centroid classifier is based on a straightforward assumption that the documents in one category should share some similarities with each other. However, this hypothesis is often violated by ECOC on the grounds that it ignores the similarities of original classes when disassembling one multi-class problem into multiple binary problems. 
In order to attack this problem, we use Model-Refinement [5] to reduce this so-called bias. The basic idea is to take advantage of misclassified examples in the training data to iteratively refine and adjust the centroids. The empirical evaluation [5] shows that Model-Refinement can dramatically reduce the bias. 
ECOC works by converting a multi-class supervised learning problem into a large number (L) of two-class supervised learning problems [3]. Any learning algorithm can be used to learn each of these L problems. L can then be thought of as the length of the codewords with one bit in each codeword for each classifier. The ECOC algorithm is outlined in Figure 1. 
The basic idea of centroid classifier is to construct a centroid C for each class c i using formula (1) where d denotes one document centroid classifier makes a simple decision rule (formula (2)) that a given document should be assigne d a particular class if the similarity (or distance) of this document to the centroid of the straightforward assumption: the documents in one category should share some similarities with each other. 
For example, the single-topic doc uments involved with  X  X port X  or  X  X ducation X  can meet with the presumption; whereas the hybrid documents involved with  X  X port X  as well as  X  X ducation X  break this supposition. 
As such, ECOC based centroid classifier also break this hypothesis. This is because ECOC ignores the similarities of original classes when producing binary problems. In this scenario, many different classes are often merged into one category. For example, the class  X  X port X  and  X  X  ducation X  may be assembled into one class. As a result, the assu mption will inevitably be broken. 
Let X  X  take a simple multi-cla ss classification task with 12 classes. After coding the original classes, we obtain the dataset as Figure 2. Class 0 consists of 6 original categories, and class 1 contains another 6 categories. Then we calculate the centroids of merged class 0 and merged class 1 using formula (1), and draw a Middle Line that is the perpendicular bisector of the line between the two centroids. 
According to the decision rule (formula (2)) of centroid classifier, the examples of class 0 on the right of the Middle Line will be misclassified into class 1. This is the mechanism why ECOC can bring bias for centroid classifier. In other words, the ECOC method conflicts with the assumption of centroid classifier to some degree. 
To decrease this kind of bias, we employ the Model-Refinement approach to adjust the class repr esentative, i.e., the centroids. The basic idea of Model-Refinement is to make use of training errors gradually, and then the training-set error rate can also be reduced gradually. 
For example, if document d of class 0 is misclassified into class 1, both centroids C 0 and C 1 should be moved right by the following formulas (3-4) respectively, where  X  (0&lt;  X  &lt; 1) is the Learning Rate which controls the step-size of updating operation. With this so-called move operation, C C are both moving right gradually. At the end of this kind of move operation (see Figure 3), no exam ple of class 0 locates at the right of Middle Line so no example will be misclassified. More details can be found in [5].

In this subsection, we pres ent the outline (Figure 4) of combining ECOC and Model-Refine ment for centroid classifier. In substance, the improved ECOC combines the strengths of ECOC and Model-Refinement. ECOC research in ensemble learning techniques has shown that it is well suited for classification tasks with a large num ber of categories. On the other hand, Model-Refinement has proved to be an effective approach to reduce the bias of base classifier, that is to say, it can dramatically boost the perform ance of base classifier. 
In our experiment, we use two corpora: 20NewsGroup Industry Sector 2 . For 20NewsGroup, we use a subset consisting of total categories and 19,446 documents ; for Industry Sector, we use a subset called as Sector-48 cons isting of 48 categories and in all 4,581 documents. 
For experiments involving SV M we employed SVMTorch. ( www.idiap.ch/~bengio/projects/SVMTorch.html ). We use Information Gain [7] to select 10,000 features. For simplicity, we use MR to stand for Model-Refinement. For ECOC, we use 63-bit BCH coding [3]. Model-Refinement (MR) iterates over the total training set 8 times. 
From table 1, we can observe that ECOC indeed brings considerable decrease in accuracy . Especially on sector-48, the bias reduces the accuracy of centroid classifier from 0.7985 to 0.6422. On the other hand, the combination of ECOC and Model-Refinement makes a significan t performance improvement over centroid classifier. On Newsgroup, it beats centroid classifier by 4 percents; on Sector-48, it beats centroid classifier by 11 percents. More encouraging, it yields better performance than SVM, especially on Sector-48. This im provement also indicates that Model-Refinement can effectively reduce the bias incurred by ECOC. 
In this work, we examine th e use of ECOC for improving centroid text classifier. The experimental results indicate that the combination of ECOC with M odel-Refinement makes a wide margin performance improvement over traditional centroid classifier, and even performs comparably with SVM classifier. 
