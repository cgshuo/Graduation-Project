 Online micro-blogging services have revolutionized the way people discover, share, and distribute infor-mation. Twitter is perhaps the most popular such service with over 140 million active users as of 2012. 1 Twitter enables users to send and read text-based posts of up to 140 characters, known as tweets . Twitter users follow others or are followed. Being a follower on Twitter means that the user receives all the tweets from those she follows. Common prac-tice of responding to a tweet has evolved into a well-defined markup culture (e.g., RT stands for retweet,  X  X  X  followed by an identifier indicates the user). The strict limit of 140 characters allows for quick and immediate communication in real time, whilst enforcing brevity. Moreover, the retweet mecha-nism empowers users to spread information of their choice beyond the reach of their original followers.
Twitter has become a prominent broadcast-ing medium, taking priority over traditional news sources (Teevan et al., 2011). Shared information through this channel spreads faster than would have been possible with conventional news sites or RSS feeds and can reach a far wider population base. However, the proliferation of user-generated con-tent comes at a price. Over 340 millions of tweets are being generated daily amounting to thousands of tweets per second! 2 Twitter X  X  own search en-gine handles more than 1.6 billion search queries per day. 3 This enormous amount of data renders it in-feasible to browse the entire Twitter network; even if this was possible, it would be extremely difficult for users to find information they are interested in. A hypothetical tweet recommendation system could alleviate this acute information overload, e.g., by limiting the stream of tweets to those of interest to the user, or by discovering intriguing content outside the user X  X  following network.

The tweet recommendation task is challenging for several reasons. Firstly, Twitter does not merely consist of a set of tweets. Rather, it contains many latent networks including the following relationships among users and the retweeting linkage (which in-dicates information diffusion). Secondly, the rec-ommendations ought to be of interest to the user and likely to to attract user response (e.g., to be retweeted). Thirdly, recommendations should be personalized (Cho and Schonfeld, 2007; Yan et al., 2011), avoid redundancy, and demonstrate diversity. In this paper we present a graph-theoretic approach to tweet recommendation that attempts to address these challenges.

Our recommender operates over a heterogeneous network that connects the users (or authors) and the tweets they produce. The user network represents links among authors based on their following be-havior, whereas the tweet network connects tweets based on content similarity. A third bipartite graph ties the two together. Tweet and author entities in this network are ranked simultaneously following a co-ranking algorithm (Zhou et al., 2007). The main intuition behind co-ranking is that there is a mu-tually reinforcing relationship between authors and tweets that could be reflected in the rankings. Tweets are important if they are related to other important tweets and authored by important users who in turn are related to other important users. The model ex-ploits this mutually reinforcing relationship between tweets and their authors and couples two random walks, one on the tweet graph and one on the author graph, into a combined one. Rather than creating a global ranking over all tweets in a collection, we ex-tend this framework to individual users and produce personalized recommendations. Moreover, we in-corporate diversity by allowing the random walk on the tweet graph to be time-variant (Mei et al., 2010).
Experimental results on a real-world dataset con-sisting of 364,287,744 tweets from 9,449,542 users show that the co-ranking approach substantially im-proves performance over the state of the art. We ob-tain a relative improvement of 18.3% (in nDCG) and 7.8% (in MAP) over the best comparison system. Tweet Search Given the large amount of tweets being posted daily, ranking strategies have be-come extremely important for retrieving information quickly. Many websites currently offer a real-time search service which returns ranked lists of Twit-ter posts or shared links according to user queries. Ranking methods used by these sites employ three criteria, namely recency, popularity and content rel-evance (Dong et al., 2010). State-of-art tweet re-trieval methods include a linear regression model bi-ased towards text quality with a regularization factor inspired by the hypothesis that documents similar in content may have similar quality (Huang et al., 2011). Duan et al. (2010) learn a ranking model us-ing SVMs and features based on tweet content, the relations among users, and tweet specific character-istics (e.g., urls, number of retweets).
 Tweet Recommendation Previous work has also focused on tweet recommendation systems, assum-ing no explicit query is provided by the users. Collaborative filtering is perhaps the most obvious method for recommending tweets (Hannon et al., 2010). Chen et al. (2010) investigate how to se-lect interesting URLs linked from Twitter and rec-ommend the top ranked ones to users. Their rec-ommender takes three dimensions into account: the source, the content topic, and social voting. Sim-ilarly, Abel et al. (2011a; 2011b; 2011c) recom-mend external websites linked to Twitter. Their method incorporates user profile modeling and tem-poral recency, but they do not utilize the social networks among users. R. et al. (2009) propose a diffusion-based recommendation framework es-pecially for tweets representing critical events by constructing a diffusion graph. Hong et al. (2011) recommend tweets based on popularity related fea-tures. Ramage et al. (2010) investigate which topics users are interested in following a Labeled-LDA ap-proach, by deciding whether a user is in the followee list of a given user or not. Uysal and Croft (2011) es-timate the likelihood of a tweet being reposted from a user-centric perspective.

Our work also develops a tweet recommendation system. Our model exploits the information pro-vided by the tweets and the underlying social net-works in a unified co-ranking framework. Although these sources have been previously used to search or recommend tweets, our model considers them simultaneously and produces a ranking that is in-formed by both. Furthermore, we argue that the graph-theoretic framework upon which co-ranking operates is beneficial as it allows to incorporate per-sonalization (we provide user-specific rankings) and diversity (the ranking is optimized so as to avoid re-dundancy). The co-ranking framework has been ini-tially developed for measuring scientific impact and modeling the relationship between authors and their publications (Zhou et al., 2007). However, the adap-tation of this framework to the tweet recommenda-tion task is novel to our knowledge. Our method operates over a heterogeneous network that connects three graphs representing the tweets, their authors and the relationships between them. Let G denote the heterogeneous graph with nodes V and edges E , and G = ( V , E ) = ( V M  X  V U , E M  X  E U E
MU ) . G is divided into three subgraphs, G M , G U and G MU . G M = ( V M , E M ) is a weighted undirected graph representing the tweets and their relationships. Let V M = { m i | m i  X  V M } denote a collection of | V M tweets and E M the set of links representing relation-ships between them. The latter are established by measuring how semantically similar any two tweets are (see Section 3.4 for details). G U = ( V U , E U ) is an unweighted directed graph representing the so-cial ties among Twitter users. V U = { u i | u i  X  V U } is the set of users with size | V U | . Links E U among users are established by observing their following behavior. G MU = ( V MU , E MU ) is an unweighted bi-partite graph that ties G M and G U together and repre-sents tweet-author relationships. The graph consists of nodes V MU = V M  X  V U and edges E MU connect-ing each tweet with all of its authors. Typically, a tweet m is written by only one author u . However, because of retweeting we treat all users involved in reposting a tweet as  X  X o-authors X . The three subnet-works are illustrated in Figure 1.

The framework includes three random walks, one on G M , one on G U and one on G MU . A random walk on a graph is a Markov chain, its states being the vertices of the graph. It can be described by a square n  X  n matrix M , where n is the number of vertices in the graph. M is a stochastic matrix prescribing the transition probabilities from one vertex to the next. The framework couples the two random walks on G M , and G U that rank tweets and theirs authors in isolation. and allows to obtain a more global rank-ing by taking into account their mutual dependence. In the following sections we first describe how we obtain the rankings on G M and G U , and then move on to discuss how the two are coupled. 3.1 Ranking the Tweet Graph Popularity We rank the tweet network follow-ing the PageRank paradigm (Brin and Page, 1998). Consider a random walk on G M and let M be the transition matrix (defined in Section 3.4). Fix some damping factor  X  and say that at each time step with probability (1- X  ) we stick to random walking and with probability  X  we do not make a usual random walk step, but instead jump to any vertex, chosen uniformly at random: Here, vector m contains the ranking scores for the vertices in G M . The fact that there exists a unique so-lution to (1) follows from the random walk M being ergodic (  X  &gt; 0 guarantees irreducibility, because we can jump to any vertex). M T is the transpose of M . 1 is the vector of | V M | entries, each being equal to one. Let m  X  R V M , || m || 1 = 1 be the only solution. Personalization The standard PageRank algo-rithm performs a random walk, starting from any node, then randomly selects a link from that node to follow considering the weighted matrix M , or jumps to a random node with equal probability. It pro-duces a global ranking over all tweets in the col-lection without taking specific users into account. As there are billions of tweets available on Twit-ter covering many diverse topics, it is reasonable to assume that an average user will only be inter-ested in a small subset (Qiu and Cho, 2006). We operationalize a user X  X  topic preference as a vec-ber of topics, and t i represents the degree of prefer-ence for topic i . The vector t is normalized such that  X  n i = 1 t i = 1. Intuitively, such vectors will be different for different users. Note that user prefer-ences can be also defined at the tweet (rather than topic ) level. Although tweets can illustrate user in-terests more directly, in most cases a user will only respond to a small fraction of tweets. This means that most tweets will not provide any information relating to a user X  X  interests. The topic preference vector allows to propagate such information (based on whether a tweet has been reposted or not) to other tweets within the same topic cluster.

Given n topics, we obtain a topic distribution ma-trix D using Latent Dirichlet Allocation (Blei et al., 2003). Let D i j denote the probability of tweet m i to belong to topic t j . Consider a user with a topic pref-erence vector t and topic distribution matrix D . We calculate the response probability r for all tweets for this user as: where r =[ r 1 , r 2 , . . . , r V sponse probability vector and r i the probability for a user to respond to tweet m i . We normalize r so that  X  for a given user and the topic distribution ma-trix D , our task is estimate the topic preference vector t . We do this using maximum-likelihood estimation. Assuming a user has responded to w tweets, we approximate t so as to maximize the ob-served response probability. Let r ( t ) = t D T . As-suming all responses are independent, the probabil-ity for w tweets r 1 , r 2 , . . . , r w is then  X  w i = 1 a given t . The value of t is chosen when the proba-bility is maximized:
In a simple random walk, it is assumed that all nodes in the matrix M are equi-probable before the walk. In contrast, we use the topic preference vector as a prior on M . Let Diag ( r ) denote a diagonal ma-trix whose eigenvalue is vector r . Then m becomes: Diversity We would also like our output to be diverse without redundant information. Unfortu-nately, equation (4) will have the opposite effect, as it assigns high scores to closely connected node communities. A greedy algorithm such as Maxi-mum Marginal Relevance (Carbonell and Goldstein, 1998; Wan et al., 2007; Wan et al., 2010) may achieve diversity by iteratively selecting the most prestigious or popular vertex and then penalizing the vertices  X  X overed X  by those that have been already selected. Rather than adopting a greedy vertex selec-tion method, we follow DivRank (Mei et al., 2010) a recently proposed algorithm that balances popular-ity and diversity in ranking, based on a time-variant random walk. In contrast to PageRank, DivRank as-sumes that the transition probabilities change over time. Moreover, it is assumed that the transition probability from one state to another is reinforced by the number of previous visits to that state. At each step, the algorithm creates a dynamic transition ma-trix M ( . ) . After z iterations, the matrix becomes: and hence, m can be calculated as:
Equation (5) increases the probability for nodes with higher popularity. Nodes with high weights are likely to  X  X bsorb X  the weights of their neighbors di-rectly, and the weights of their neighbors X  neighbors indirectly. The process iteratively adjusts the ma-trix M according to m and then updates m according to the changed M . Essentially, the algorithm favors nodes with high popularity and as time goes by there emerges a rich-gets-richer effect (Mei et al., 2010). 3.2 Ranking the Author Graph As mentioned earlier, we build a graph of au-thors (and obtain the affinity U ) using the follow-ing linkage. We rank the author network using PageRank analogously to equation (1). Besides popularity, we also take personalization into ac-count. Intuitively, users are likely to be interested in their friends even if these are relatively unpopu-lar. Therefore, for each author, we include a vec-tor p = [ p 1 , p 2 , . . . , p | V ence for other authors. The preference factor for au-thor u toward other authors u i is defined as: which represents the proportion of tweets inherited from user u i . A large p u i means that u is more likely to respond to u i  X  X  tweets.

In theory, we could also apply DivRank on the au-thor graph. However, as the authors are unique, we assume that they are sufficiently distinct and there is no need to promote diversity. 3.3 The Co-Ranking Algorithm So far we have described how we rank the network of tweets G M and their authors G U independently following the PageRank paradigm. The co-ranking framework includes a random walk on G M , G U , and G MU . The latter is a bipartite graph representing which tweets are authored by which users. The ran-dom walks on G M and G U are intra-class random walks, because take place either within the tweets X  or the users X  networks. The third (combined) ran-dom walk on G MU is an inter-class random walk. It is sufficient to describe it by a matrix MU | V and a matrix UM | V One intra-class step changes the probability distribu-while one inter-class step changes the probability distribution from ( m , u ) to (UM T u , MU T m ). The design of M , U , MU and UM is detailed in Sec-tion 3.4.

The two intra-class random walks are coupled using the inter-class random walk on the bipartite graph. The coupling is regulated by  X  , a parameter quantifying the importance of G MU versus G M and G
U . In the extreme case, if  X  is set to 0, there is no coupling. This amounts to separately ranking tweets and authors by PageRank. In general,  X  represents the extent to which the ranking of tweets and their authors depend on each other.

There are two intuitions behind the co-ranking al-gorithm: (1) a tweet is important if it associates to other important tweets, and is authored by impor-tant users and (2) a user is important if they asso-ciate to other important users, and they write impor-tant tweets. We formulate these intuitions using the following iterative procedure: Step 1 Compute tweet saliency scores: m m Step 2 Compute author saliency scores: u u Here, m ( z ) and u ( z ) are the ranking vectors for tweets and authors for the z -th iteration. To guarantee con-vergence, m and u are normalized after each itera-tion. Note that the tweet transition matrix M is dy-namic due to the computation of diversity while the author transition matrix U is static. The algorithm typically converges when the difference between the scores computed at two successive iterations for any tweet/author falls below a threshold  X  (set to 0.001 in this study). 3.4 Affinity Matrices The co-ranking framework is controlled by four affinity matrices: M , U , MU and UM . In this section we explain how these matrices are defined in more detail.

The tweet graph is an undirected weighted graph, where an edge between two tweets m i and m j repre-sents their cosine similarity. An adjacency matrix M describes the tweet graph where each entry corre-sponds to the weight of a link in the graph: M where F ( . ) is the cosine similarity and ~ m is a term vector corresponding to tweet m . We treat a tweet as a short document and weight each term with tf.idf (Salton and Buckley, 1988), where tf is the term fre-quency and idf is the inverse document frequency.
The author graph is a directed graph based on the following linkage. When u i follows u j , we add a link from u i to u j . Let the indicator function I ( u i , u j note whether u i follows u j . The adjacency matrix U is then defined as: U
In the bipartite tweet-author graph G MU , the entry E MU ( i , j ) is an indicator function denoting whether tweet m i is authored by user u j : Through E MU we define MU and UM , using the weight matrices MU = [  X  W ij ] and UM= [  X  W ji ], con-taining the conditional probabilities of transitioning from m i to u j and vice versa: Data We crawled Twitter data from 23 seed users (who were later invited to manually evaluate the output of our system). In addition, we collected the data of their followees and followers by travers-ing the following edges, and exploring all newly included users in the same way until no new users were added. This procedure resulted in a relatively large dataset consisting of 9,449,542 users, 364,287,744 tweets, 596,777,491 links, and 55,526,494 retweets. The crawler monitored the data from 3/25/2011 to 5/30/2011. We used approx-imately one month of this data for training and the rest for testing.

Before building the graphs (i.e., the tweet graph, the author graph, and the tweet-author graph), the dataset was preprocessed as follows. We removed tweets of low linguistic quality and subsequently discarded users without any linkage to the remain-ing tweets. We measured linguistic quality follow-ing the evaluation framework put forward in Pitler et al. (2010). For instance, we measured the out-of-vocabulary word ratio (as a way of gauging spelling errors), entity coherence, fluency, and so on. We fur-ther removed stopwords and performed stemming. Parameter Settings We ran LDA with 500 itera-tions of Gibbs sampling. The number of topics n was set to 100 which upon inspection seemed gen-erally coherent and meaningful. We set the damp-ing factor  X  to 0.15 following the standard PageRank paradigm. We opted for more or less generic param-eter values as we did not want to tune our frame-work to the specific dataset at hand. We examined the parameter  X  which controls the balance of the tweet-author graph in more detail. We experimented with values ranging from 0 to 0.9, with a step size of 0.1. Small  X  values place little emphasis on the tweet graph, whereas larger values rely more heav-ily on the author graph. Mid-range values take both graphs into account. Overall, we observed better performance with values larger than 0.4. This sug-gests that both sources of information  X  the content of the tweets and their authors  X  are important for the recommendation task. All our experiments used the same  X  value which was set to 0.6.
 System Comparison We compared our approach against three naive baselines and three state-of-the-art systems recently proposed in the literature. All comparison systems were subject to the same fil-tering and preprocessing procedures as our own al-gorithm. Our first baseline ranks tweets randomly (Random). Our second baseline ranks tweets ac-cording to token length: longer tweets are ranked higher (Length). The third baseline ranks tweets by the number of times they are reposted assum-ing that more reposting is better (RTnum). We also compared our method against Duan et al. (2010). Their model (RSVM) ranks tweets based on tweet content features and tweet authority features using the RankSVM algorithm (Joachims, 1999). Our fifth comparison system (DTC) was Uysal and Croft (2011) who use a decision tree classifier to judge how likely it is for a tweet to be reposted by a spe-cific user. This scenario is similar to ours when rank-ing tweets by retweet likelihood. Finally, we com-pared against Huang et al. (2011) who use weighted linear combination (WLC) to grade the relevance of a tweet given a query. We implemented their model without any query-related features as in our setting we do not discriminate tweets depending on their relevance to specific queries.
 Evaluation We evaluated system output in two ways, i.e., automatically and in a user study. Specif-ically, we assume that if a tweet is retweeted it is rel-evant and is thus ranked higher over tweets that have not been reposted. We used our algorithm to predict a ranking for the tweets in the test data which we then compared against a goldstandard ranking based on whether a tweet has been retweeted or not. We measured ranking performance using the normalized Discounted Cumulative Gain (nDCG; J  X  arvelin and Kek  X  al  X  ainen (2002)): nDCG ( k , V U ) = where V U denotes users, k indicates the top-k posi-tions in a ranked list, and Z u is a normalization factor obtained from a perfect ranking for a particular user. r i is the relevance score (i.e., 1: retweeted, 0: not retweeted) for the i -th tweet in the ranking list for user u .
 We also evaluated system output in terms of Mean Average Precision (MAP), under the assumption that retweeted tweets are relevant and the rest irrele-vant: where N u is the number of reposted tweets for user u , and P u i is the precision at i -th position for user u (Manning et al., 2008).

The automatic evaluation sketched above does not assess the full potential of our recommendation sys-tem. For instance, it is possible for the algorithm to recommend tweets to users with no linkage to their publishers. Such tweets may be of potential interest, however our goldstandard data can only provide in-formation for tweets and users with following links. We therefore asked the 23 users whose Twitter data formed the basis of our corpus to judge the tweets ranked by our algorithm and comparison systems. The users were asked to read the systems X  recom-mendations and decide for every tweet presented to them whether they would retweet it or not, under the assumption that retweeting takes place when users find the tweet interesting.

In both automatic and human-based evaluations we ranked all tweets in the test data. Then for each date and user we selected the top 50 ones. Our nDCG and MAP results are averages over users and dates. Our results are summarized in Tables 1 and 2. Ta-ble 1 reports results when model performance is evaluated against the gold standard ranking obtained from the Twitter network. In Table 2 model per-formance is compared against rankings elicited by users.

As can be seen, the Random method performs worst. This is hardly surprising as it recommends tweets without any notion of their importance or user interest. Length performs considerably better than Random. This might be due to the fact that infor-mativeness is related to tweet length. Using merely the number of retweets does not seem to capture the tweet importance as well as Length. This suggests that highly retweeted posts are not necessarily in-formative. For example, in our data, the most fre-quently reposted tweet is a commercial advertise-ment calling for reposting! The supervised systems (RSVM, DTC, and WLC) greatly improve performance over the naive baselines. These methods employ standard machine learning algorithms (such as SVMs, decision trees and linear regression) on a large feature space. Aside from the learning algorithm, their main difference lies in the selection of the feature space, e.g., the way content is represented and whether authority is taken into account. DTC performs best on most evalua-tion criteria. However, neither DTC nor RSVM, or WLC take personalization into account. They gen-erate the same recommendation lists for all users. Our co-ranking algorithm models user interest with respect to the content of the tweets and their pub-lishers. Moreover, it attempts to create diverse out-put and has an explicit mechanism for minimizing redundancy. In all instances, using both DCG and MAP, it outperforms the comparison systems. Inter-estingly, the performance of CoRank is better when measured against human judgments. This indicates that users are interested in tweets that fall outside the scope of their followers and that recommenda-tion can improve user experience.

We further examined the contribution of the in-dividual components of our system to the tweet recommendation task. Tables 3 and 4 show how the performance of our co-ranking algorithm varies when considering only tweet popularity using the standard PageRank algorithm, personalization (Per-sRank), and diversity (DivRank). Note that DivRank is only applied to the tweet graph. The PageR-ank algorithm on its own makes good recommenda-tions, while incorporating personalization improves the performance substantially, which indicates that individual users show preferences to specific topics or other users. Diversity on its own does not seem to make a difference, however it improves perfor-mance when combined with personalization. Intu-itively, users are more likely to repost tweets from their followees, or tweets closely related to those retweeted previously. We presented a co-ranking framework for a tweet recommendation system that takes popularity, per-sonalization and diversity into account. Central to our approach is the representation of tweets and their users in a heterogeneous network and the abil-ity to produce a global ranking that takes both in-formation sources into account. Our model obtains substantial performance gains over competitive ap-proaches on a large real-world dataset (it improves by 18.3% in DCG and 7.8% in MAP over the best baseline). Our experiments suggest that improve-ments are due to the synergy of the two information sources (i.e., tweets and their authors). The adopted graph-theoretic framework is advantageous in that it allows to produce user-specific recommendations and incorporate diversity in a unified model. Evalua-tion with actual Twitter users shows that our recom-mender can indeed identify interesting information that lies outside the the user X  X  immediate following network. In the future, we plan to extend the co-ranking framework so as to incorporate information credibility and temporal recency.
 Acknowledgments This work was partially funded by the Natural Science Foundation of China under grant 60933004, and the Open Fund of the State Key Laboratory of Software Development Environment under grant SKLSDE-2010KF-03. Rui Yan was supported by a MediaTek Fellowship.
