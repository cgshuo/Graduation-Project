 Query length has generally been regarded as a query-specific constant that does not affect document ranking. In this pa-per, we reveal that query length actually interacts with term frequency (TF) normalization, a key component of all ef-fective retrieval models. Specifically, the longer the query is, the smaller the TF decay speed should be. In order to study the impact of query length, we present a desirable for-mal constraint to capture the heuristic of query length for retrieval. Our constraint analysis shows that current state-of-the-art retrieval functions, including BM25 and language models, fail to satisfy the constraint, and that, in order to solve this problem, the TF normalization component in a retrieval function should be adapted to query length. As an application, we develop a simple regression algorithm to adapt BM25 to query length, and demonstrate its effective-ness on several representative TREC collections.
 H.3.3 [ Information Search and Retrieval ]: Retrieval models Algorithms, Theory Query length, term frequency normalization, constraints
Optimization of retrieval models is a fundamental research problem in information retrieval. Although many studies have attempted to improve retrieval models from various perspectives, e.g., [10, 11, 3, 6], they mainly focused on ei-ther document properties (e.g., term frequency and docu-ment length) or the estimation of term statistics from the corpus (e.g., IDF and background model), while little atten-tion has been paid to the query length (i.e., the count of terms in a query). In fact, query length has largely been regarded as a query-specific constant that does not affect document ranking.

In this paper, we reveal that query length actually plays a role in retrieval models through influencing term frequency (TF) normalization. It is widely recognized that TF should be normalized to properly weaken the contribution of re-peated term occurrences (as compared to the first occur-rence) of a term, based on the intuition that the first oc-currence of the term often brings more relevance evidence. However, we argue that the first occurrence of a term may not be that important when the query is long, as the terms of a longer query generally tends to be more semantically redundant (i.e., one query term may be semantically over-lapping with other query terms), and the relative importance of the first occurrence of a new query term (as compared to its repeated occurrences) in a document from a longer query may not be as high as that from a shorter query. We thus hypothesize that the longer the query is, the less penaliza-tion the repeated term occurrences should receive. In other words, a document that mis-matches a query term from a longer query should not be penalized as much as that of another document that mis-matches the query term from a shorter query.

We propose a formal constraint to model the interaction between query-length and TF normalization mathematically, so that it is possible to apply it to not only diagnose a retrieval function analytically and but also guide us to fix the problem. We then use constraint analysis to examine BM25 [8, 9] and language models [11], and find that nei-ther of them satisfies the constraint. More specifically, for BM25, the proposed constraint is equivalent to a require-ment that its parameter k 1 should increase monotonically with the query length; for the language modeling approach with Dirichlet prior smoothing [11], the constraint requires that the Dirichlet prior  X  should increase monotonically with the query length. In other words, the optimal k 1 and  X  val-ues for a longer query should generally be larger than that for a shorter query; as a result, a query-independent parameter setting would not be optimal for all queries. This has also been confirmed by the empirical evidences in Section 3.2.
Motivated by this understanding, we propose a simple methodology for adapting retrieval models to query length using a linear regression method, which incurs almost no additional computational cost. As an application, we apply the proposed method to estimate a query-length aware k 1 for BM25. Our experimental results on multiple representative TREC collections demonstrate its effectiveness.
In our previous works [5, 7], we explored how to adapt TF normalization to the global distribution of individual terms in the whole corpus. Although related, those works are or-thogonal to the current work, as they only used global term statistics but did not explore query length. We emphasize that our major contributions in this paper are the query length heuristics and constraints, which are novel. Never-theless, we have compared the proposed method with our previous work [5] in the experiments.

The interaction between query length and document length normalization has been studied [1, 2]. Chung et al. [1] have incorporated the query length into the pivoted document length normalization in the vector space model (rather than BM25), but they did not reach any conclusive results; Cum-mins and Riordan X  X  recent work [2] examined a similar heuris-tic, and formalized a constraint to describe the heuristic, but their method only performs comparably to the baseline re-trieval models. Moreover, both works focused only on docu-ment length normalization, but did not pay attention to the effect of query length in TF normalization.

Constraint analysis has been explored in information re-trieval to diagnostically evaluate existing retrieval models [3], introduce novel retrieval signals into existing retrieval mod-els [6, 2], and guide the development of new retrieval models [4]. Our constraint analysis is inspired by these previous works, but the proposed constraint QLN-TFC is novel.
How can we regulate the interactions between TF nor-malization and query length as discussed in Section 1 so that we can adapt a retrieval function to different queries? To answer this question, we first propose a desirable formal constraint, namely QLN-TFC, that any reasonable retrieval function should satisfy.

QLN-TFC: Let Q = { q 1 , q 2 } be a query with two terms q and q 2 . Assume D 1 and D 2 are two documents such that | D 1 | = | D 2 | , c ( q 1 , D 1 ) = n &gt; 1, c ( q 2 , D 1 c ( q 2 , D 2 ) = 1, and the document relevance scores S ( Q, D S ( Q, D 2 ). If we reformulate the query Q  X  = Q  X  { q 3 adding another term q 3 /  X  Q into the query, where c ( q c ( q 3 , D 2 ) = 1, then S ( Q  X  , D 1 ) &gt; S ( Q  X  , D 2 ).
This constraint ensures that the relative importance of the first occurrence of a new query term (as compared to its repeated occurrences) in a longer query should not be as high as that in a shorter query. To illustrate, a document, say D 1 , that mis-matches a query term q 2 from a longer query Q  X  should not be penalized as much as that D 1 mis-matches the query term q 2 from a shorter query Q .
We now diagnose retrieval models using the proposed con-straint QLN-TFC. We use the widely accepted BM25 [8, 9] as an example. The BM25 formula, as presented in [3], scores a document D with respect to query Q as follows: where c ( q, Q )/ c ( q, D ) represents the frequency of term q in Q / D , df ( q ) is the number of documents containing term q , N is the total number of documents in the collection, and dtf ( q, D ) is the key component of BM25 contributing to its success, i.e., the sub-linear TF normalization formula, which prevents the contribution of repeated occurrences of a term from growing too large: where is the pivoted normalization method [10] for document length normalization, in which, | D | is the length of document D , and avdl is the average document length. There are two im-portant parameters: (1) k 1 is used to control the shape of this TF normalization component, and a larger k 1 penalizes the repeated term occurrences less; (2) b  X  [0 , 1] is the slope parameter. Both k 1 and b are usually set independently on query length.

Let X  X  look at the QLN-TFC constraint. Consider the av-erage case when | D 1 | = | D 2 | = avdl . It can be shown that the S ( Q, D 1 ) = S ( Q, D 2 ) implies the following equality: And after query reformulation, the constraint S ( Q  X  , D S ( Q  X  , D 2 ) requires With some basic mathematical derivations, the constraint QLN-TFC is equivalent to the following inequality: which clearly cannot be satisfied by the standard BM25, given that k 1 is independent on query length | Q | . To satisfy the constraint, it is required that the parameter k 1 should increase monotonically with the query length | Q | .
Similarly, we also analyze another representative retrieval function, the language modeling approach with Dirichlet prior smoothing method [11], for which the constraint QLN-TFC is equivalent to the following inequality: Figure 2: Plots of optimal  X  w.r.t. the query length. where  X  is the Dirichlet prior, and p ( q i | C ) is the probabil-ity of q i estimated using the whole collection. This shows that in order for the language modeling approach to satisfy the constraint, an adaptive Dirichlet prior  X  that increases monotonically with the query length | Q | is desired.
Our above analysis has shown that, analytically, query length interacts with TF normalization. Now we turn to seeking empirical evidence to see if this is a common behavior of modern information retrieval models.

We first plot the optimal k 1 1 in BM25 for each query w.r.t. the query length on different TREC collections in Fig-ure 1. We do a binning analysis, where we rank all queries according to their lengths and then group every 10 contin-uous queries into a bin. The  X  X uery length X  of a bin is the average length of all queries in the bin, and the  X  k 1  X  of the bin is the median of all k 1 values in the bin. We can see there is indeed clear correlation between the query length and the optimal k 1 value, especially on Robust04 and Ter-abyte, probably because Robust04 and Terabyte consist of more query topics (498 and 298 respectively) than WT10G (only 198). Anyway, this confirms our intuition that TF normalization interacts with query length, and thus a query length independent k 1 would not be optimal for all queries.
In addition, we also analyze the optimal Dirichlet prior  X  in the language modeling approach w.r.t. the query length in a similar way based on Robust04, as shown in Figure 2, and find  X  also has a positive correlation with query length. In order to improve current retrieval models to satisfy QLN-TFC, we need to make their TF normalization compo-nents dependent on query-length. However, we do not want that the addition of this new constraint changes the imple-mentations of other existing retrieval heuristics in these re-trieval functions that have been shown to work quite well [3]. We propose a heuristic approach to achieve this goal by mak-ing the corresponding parameters in the TF normalization component aware of query-length using a simple regression method. Specifically, k 1 = f ( | Q | ) in BM25 and the Dirichlet prior  X  = g ( | Q | ) in the language modeling approach, where f (  X  ) and g (  X  ) are functions to be estimated. In this paper, we focus only on the improvement of BM25 due to the space reason. With k 1 = f ( | Q | ), the Inequality 2 is equivalent to: queries 451-550 701-850 301-450, 601-700 #qry(with qrel) 198 298 498 mean(ql) 7 . 93 7 . 34 9 . 10 std(ql) 5 . 44 5 . 16 8 . 53 max(ql) 30 24 62 #total qrel 5 , 981 28 , 640 17 , 412 #documents 1692 k 25205 k 528 k Table 1: Characteristics of document and query sets suggesting that a monotonically increasing function f (  X  ) will make BM25 satisfy QLN-TFC unconditionally. And inter-estingly, this is consistent with the data analysis results in Figure 1, confirming empirically that QLN-TFC is a desir-able retrieval constraint. Observing the sublinear curves of k 1 w.r.t. the query length in Figure 1, a heuristic approxi-mation of f (  X  ) is thus obtained as follows: where  X  and  X  are two free parameters. The logarithm func-tion in f (  X  ) intuitively makes sense: k 1 = f ( | Q | ) should in-crease more when the query length increases from 3 to 4 than when the query length increases from 10 to 11.

As we have already collected the optimal k 1 value for each training query, we can use the standard curve-fitting tech-nique and the least square method to fit f (  X  ) to the ground truth to estimate both  X  and  X  . Finally, substituting Equa-tion 5 into 1, we get the following retrieval function,
In addition, we also revisit the heuristic of query length in-teracting with document length normalization. This heuris-tic is not entirely novel, as a previous work [1] has reported that a larger b value is often needed for longer queries in the vector space model based on analyzing several small docu-ment collections. We revisit this heuristic on BM25 using several larger TREC collections. We first do a similar bin-ning analysis, and plot the optimal b values w.r.t. the corre-sponding query lengths using BM25, which shows that the optimal b correlates with the query length well (and the opti-mal b also increases sub-linearly with the query length). We also apply the same linear regression method to compute a query-length aware b =  X   X  log | Q | +  X   X  . We use three representative TREC collections: WT10G, Terabyte and Robust04, which represent different sizes and genre of text collections. WT10G and Terabyte are medium and large Web collections respectively. Robust04 is a rep-resentative news dataset. Our queries are taken from both the title and the description fields of the TREC topics. For all the datasets, the preprocessing of documents and queries is minimum, involving only Porter X  X  stemming. We do not remove any stopwords. An overview of the involved query topics and document collections are shown in Table 1.
The top-ranked 1000 documents for each run are compared in terms of their mean average precisions (MAP), which also serves as the objective function for parameter training. In addition, the precision at top-10 documents (P@10) is also considered.
We first employ a two-fold cross-validation for parame-ter tuning, where the query topics are split into even and odd numbered topics as the two folds. We compare the pro-posed query-length aware BM25 (labeled as X  X M25QL X ) with two baselines: (1) a standard BM25 for which both b and k 1 are trained (labeled as  X  X M25 X ), and (2) a query-length specific BM25 (labeled as  X  X M25 Q  X ) that does a two-fold cross-validation among queries of the same length (if any), and degenerates to  X  X M25 X  if there is no other query of the same length. The comparison results are summarized in Ta-ble 2. We can see that BM25QL outperforms both BM25 and BM25 Q significantly in terms of MAP. BM25 Q is some-times even worse than BM25. These observations suggest that a  X  X ard X  way to train a query-length specific retrieval model (like BM25 Q ) may not work well due to the reduction of training data, but a  X  X oft X  X ay, like BM25QL, that uses all the training data to train a query-length aware retrieval func-tion, works effectively. In addition, we can see that although BM25QL improves MAP significantly over the baselines, its P@10 scores are similar to those baselines without any sig-nificant differences, probably because BM25QL is trained to optimize MAP rather than P@10.

We also compare BM25QL with our previous work on adaptive BM25, namely BM25-adpt [5], on WT10G and Ro-adpt [5], where we add a free parameter  X  into the objective function of BM25-adpt to control the range of k 1 , formally Obviously, the new object function takes the original one [5] as its special case when  X  = 1. In our work,  X  is also opti-mized using cross validation. We can see that the proposed BM25QL works better. One possible reason is that, although BM25-adpt works well on short keyword queries [5], it does not work effectively on verbose queries that are being used in this work. But the proposed method works better to adapt to different query lengths.

To understand the performance of query-length aware k 1 and query-length aware b separately, we train two retrieval functions  X  X M25QL ( k 1 ) X  and  X  X M25QL ( b ) X , respectively. We use a query-length aware k 1 and a query-length unaware b 3 in the former, while using a query-length aware b and a query-length unaware k 1 in the latter. We can see that both methods work more effectively than BM25 and BM25 Q in terms of MAP, suggesting that both parts contribute to the performance of BM25QL.
In this paper, we revealed that query length affects TF normalization, and explored an idea of query-length aware retrieval models. Specifically, we proposed a desirable formal constraint to capture the heuristic of query length in retrieval functions, diagnosed BM25 and other retrieval functions to show that they cannot satisfy the constraint, and developed a query-length aware TF normalization methodology. We applied the proposed techniques on BM25, which was shown to improve the standard BM25 significantly.
I thank Dr. ChengXiang Zhai for his helpful discussions, and three anonymous reviewers for their useful comments. [1] T. L. Chung, R. W. P. Luk, K. F. Wong, K. L. Kwok, [2] R. Cummins and C. O X  X iordan. A constraint to [3] H. Fang, T. Tao, and C. Zhai. A formal study of [4] H. Fang and C. Zhai. An exploration of axiomatic [5] Y. Lv and C. Zhai. Adaptive term frequency [6] Y. Lv and C. Zhai. Lower-bounding term frequency [7] Y. Lv and C. Zhai. A log-logistic model-based [8] S. E. Robertson and S. Walker. Some simple effective [9] S. E. Robertson, S. Walker, S. Jones, [10] A. Singhal, C. Buckley, and M. Mitra. Pivoted [11] C. Zhai and J. D. Lafferty. A study of smoothing
