 Carnegie-Mellon University siddiqi@cs.cmu.edu Many problems in machine learning involve sequences of real-valued multivariate observations. To model the statistical properties of such data, it is often sensible to assume each observation to be sequence. In the case where the state is real-valued and the noise terms are assumed to be Gaussian, the resulting model is called a linear dynamical system (LDS), also known as a Kalman Filter [3]. LDSs are an important tool for modeling time series in engineering, controls and economics as well as the physical and social sciences.
 Let {  X  i ( M ) } n nitude, {  X  i ( M ) } n  X  ( M )  X  |  X  1 ( M ) | . An LDS with dynamics matrix A is stable if all of A  X  X  eigenvalues have mag-nitude at most 1 , i.e.,  X  ( A )  X  1 . Standard algorithms for learning LDS parameters do not enforce this stability criterion, learning locally optimal values for LDS parameters by gradient descent [4], Expectation Maximization (EM) [5] or least squares on a state sequence estimate obtained by sub-space identification methods, as described in Section 3.1. However, when learning from finite data samples, the least squares solution may be unstable even if the system is stable [6]. The drawback of ignoring stability is most apparent when simulating long sequences from the system in order to generate representative data or infer stretches of missing values.
 We propose a convex optimization algorithm for learning the dynamics matrix while guaranteeing stability. An estimate of the underlying state sequence is first obtained using subspace identifica-tion. We then formulate the least-squares problem for the dynamics matrix as a quadratic program (QP) [7], initially without constraints. When this QP is solved, the estimate  X  A obtained may be unstable. However, any unstable solution allows us to derive a linear constraint which we then add to our original QP and re-solve. The above two steps are iterated until we reach a stable solution, which is then refined by a simple interpolation to obtain the best possible stable estimate. Our method can be viewed as constraint generation for an underlying convex program with a feasi-we terminate before reaching feasibility in the convex program, by checking for matrix stability after each new constraint. This makes our algorithm less conservative than previous methods for enforc-ing stability since it chooses the best of a larger set of stable dynamics matrices. The difference in the resulting stable systems is noticeable when simulating data. The constraint generation approach also achieves much greater efficiency than previous methods in our experiments.
 One application of LDSs in computer vision is learning dynamic textures from video data [8]. An advantage of learning dynamic textures is the ability to play back a realistic-looking generated se-models can quickly degenerate because of instability in the underlying LDS. In contrast, sequences generated from dynamic textures learned by our method remain  X  X ane X  even after arbitrarily long durations. We also apply our algorithm to learning baseline dynamic models of over-the-counter (OTC) drug sales for biosurveillance, and sunspot numbers from the UCR archive [9]. Comparison to the best alternative methods [1, 2] on these problems yields positive results. Linear system identification is a well-studied subject [4]. Within this area, subspace identification methods [10] have been very successful. These techniques first estimate the model dimensionality and the underlying state sequence, and then derive parameter estimates using least squares. Within subspace methods, techniques have been developed to enforce stability by augmenting the extended observability matrix with zeros [6] or adding a regularization term to the least squares objective [11]. All previous methods were outperformed by Lacy and Bernstein [1], henceforth referred to as LB-1. They formulate the problem as a semidefinite program (SDP) whose objective minimizes the state sequence reconstruction error, and whose constraint bounds the largest singular value by 1 . This convex constraint is obtained by rewriting the nonlinear matrix inequality I n  X  AA T  X  0 as a linear matrix inequality [12], where I n is the n  X  n identity matrix. Here,  X  0 (  X  0 ) denotes positive (semi-) definiteness. The existence of this constraint also proves the convexity of the  X  1  X  1 region. A follow-up to this work by the same authors [2], which we will call LB-2, attempts to overcome the conservativeness of LB-1 by approximating the Lyapunov inequalities P  X  APA T  X  0 , P  X  0 with radius is less than 1 . However, the approximation is achieved only at the cost of inducing a nonlinear distortion of the objective function by a problem-dependent reweighting matrix involving P , which is a variable to be optimized. In our experiments, this causes LB-2 to perform worse than LB-1 (for any  X  ) in terms of the state sequence reconstruction error, even while obtaining solutions outside the feasible region of LB-1. Consequently, we focus on LB-1 in our conceptual and qualitative comparisons as it is the strongest baseline available. However, LB-2 is more scalable than LB-1, so quantitative results are presented for both.
 To summarize the distinction between constraint generation, LB-1 and LB-2: it is hard to have both matrices). LB-1 optimizes the right objective but over the wrong feasible region (the set of matrices with  X  1  X  1 ). LB-2 has a feasible region close to the right one, but at the cost of distorting its objective function to an extent that it fares worse than LB-1 in nearly all cases. In contrast, our method optimizes the right objective over a less conservative feasible region than that of any previous algorithm with the right objective, and this combination is shown to work the best in practice. The evolution of a linear dynamical system can be described by the following two equations: tions in R m , and w t and v t are zero-mean normally distributed state and observation noise variables. Figure 1: A. Sunspot data, sampled monthly for 200 years. Each curve is a month, the x -axis is over years. B. First two principal components of a 1 -observation Hankel matrix. C. First two principal components of a 12 -observation Hankel matrix, which better reflect temporal patterns in the data. Assume some initial state x 0 . The parameters of the system are the dynamics matrix A  X  R n  X  n , the observation model C  X  R m  X  n , and the noise covariance matrices Q and R . Note that we are learn-ing uncontrolled linear dynamical systems, though, as in previous work, control inputs can easily be incorporated into the objective function and convex program.
 Linear dynamical systems can also be viewed as probabilistic graphical models. The standard LDS filtering and smoothing inference algorithms [3, 13] are instantiations of the junction tree algorithm for Bayesian Networks (see, for example, [14]).
 We follow the subspace identification literature in estimating all parameters other than the dynamics matrix. A clear and concise exposition of the required techniques is presented in Soatto et al. [8], which we summarize below. We use subspace identification methods in our experiments for unifor-mity with previous work we are building on (in the control systems literature) and with work we are comparing to ([8] on the dynamic textures data). 3.1 Learning Model Parameters by Subspace Methods Subspace methods calculate LDS parameters by first decomposing a matrix of observations to yield an estimate of the underlying state sequence. The most straightforward such technique is used here, which relies on the singular value decomposition (SVD) [15]. See [10] for variations.
 observations which is the input to SVD. One typical choice for D is D = Y 1:  X  ; we will discuss others below. SVD yields D  X  U  X  V T where U  X  R m  X  n and V  X  R  X   X  n have orthonormal columns { u i } determined by keeping all singular values of D above a threshold. We obtain estimates of C and X : See [8] for an explanation of why these estimates satisfy certain canonical model assumptions.  X  X is referred to as the extended observability matrix in the control systems literature; the t th column of  X 
X represents an estimate of the state of our LDS at time t . The least squares estimate of A is: where k X k F denotes the Frobenius norm and  X  denotes the Moore-Penrose inverse. Eq. (3) asks  X  A to minimize the error in predicting the state at time t + 1 from the state at time t . Given the above estimates  X  A and  X  C , the covariance matrices  X  Q and  X  R can be estimated directly from residuals. 3.2 Designing the Observation Matrix In the decomposition above, we chose each column of D to be the observation vector for a single time step. Suppose that instead we set D to be a matrix of the form A matrix of this form, with each block of rows equal to the previous block but shifted by a con-stant number of columns, is called a block Hankel matrix [4]. We say  X  d -observation Hankel matrix of size  X   X  to mean the data matrix D  X  R md  X   X  with d length-m observation vectors per column. Stacking observations causes each state to incorporate more information about the future, since  X  x t generated constraint A. B.
 Figure 2: (A): Conceptual depiction of the space of n  X  n matrices. The region of stability ( S  X  ) is non-convex while the smaller region of matrices with  X  1  X  1 ( S  X  ) is convex. The elliptical contours case) leads to a stable solution A  X  . The final step of our algorithm improves on this solution by interpolating A  X  with the previous solution (in this case,  X  A ) to obtain A  X  Constraint generation is able to learn a nearly optimal model from a noisy state sequence of length 7 simulated from E 0 , 10 , with better state reconstruction error than either LB-1 or LB-2. now represents coefficients reconstructing y t as well as other observations in the future. However the observation model estimate must now be  X  C = U ( : , 1: m ) , i.e., the submatrix consisting of the vation. Having multiple observations per column in D is particularly helpful when the underlying dynamical system is known to have periodicity. For example, see Figure 1(A). See [12] for details. The estimation procedure in Section 3.1 does not enforce stability in  X  A . To account for stability, we first formulate the dynamics matrix learning problem as a quadratic program with a feasible set that includes the set of stable dynamics matrices. Then we demonstrate how instability in its solutions can be used to generate constraints that restrict this feasible set appropriately. As a final step, the solution is refined to be as close as possible to the least-squares estimate while remaining stable. The overall algorithm is illustrated in Figure 2(A). We now explain the algorithm in more detail. 4.1 Formulating the Objective The least squares problem in Eq. (3) can be written as follows (see [12] for the derivation): I n is the n  X  n identity matrix and  X  denotes the Kronecker product. Note that P is a symmetric nonnegative-definite matrix. The objective function in (4) is a quadratic function of a . 4.2 Generating Constraints The quadratic objective function above is equivalent to the least squares problem of Eq. (3). Its feasible set is the space of all n  X  n matrices, regardless of their stability. When its solution yields use  X  A to calculate a convex constraint on the spectral radius. However, consider the class of 2  X  2 We turn instead to the largest singular value , which is a closely related quantity since Therefore every unstable matrix has a singular value greater than one, but the converse is not neces-sarily true. Moreover, the set of matrices with  X  1  X  1 is convex. Figure 2(A) conceptually depicts the non-convex region of stability S  X  and the convex region S  X  with  X  1  X  1 in the space of all n  X  n matrices for some fixed n . The difference between S  X  and S  X  can be significant. Figure 2(B) at the edges of the figure. While results for this class of matrices vary, the constraint generation algorithm described below is able to learn a nearly optimal model from a noisy state sequence of  X  = 7 simulated from E 0 , 10 , with better state reconstruction error than LB-1 and LB-2. Let  X  A =  X  U  X   X   X  V T by SVD, where  X  U = [  X  u i ] n
Therefore, instability of  X  A implies that: Here g = vec (  X  u 1  X  v T separating  X  a from the space of matrices with  X  1  X  1 . We use the negation of Eq. (7) as a constraint: 4.3 Computing the Solution The overall quadratic program can be stated as: with a , P , q and r as defined in Eqs. (5). { G, h } define the set of constraints, and are initially empty. The QP is invoked repeatedly until the stable region, i.e. S  X  , is reached. At each iteration, we calculate a linear constraint of the form in Eq. (8), add the corresponding g T as a row in G , and augment h with 1 . Note that we will almost always stop before reaching the feasible region S  X  . caused our solution to cross the boundary of S  X  , so we interpolate between the last solution and the order to obtain a better objective value while remaining stable. An interpolation could be attempted between the least squares solution and any stable solution. However, the stable region can be highly complex, and there may be several folds and boundaries of the stable region in the interpolated area. In our experiments (not shown), interpolating from the LB-1 solution yielded worse results. quadprog ), LB-1 [1] and LB-2 [2] (using CVX with SeDuMi ) in Matlab on a 3 . 2 GHz Pen-tium with 2 GB RAM. Note that these algorithms give a different result from the basic least-squares system identification algorithm only in situations where the least-squares model is unstable. How-ever, least-squares LDSs trained in scarce-data scenarios are unstable for almost any domain, and some domains lead to unstable models up to the limit of available data (e.g. the steam dynamic textures in Section 5.1). The goals of our experiments are to: (1) examine the state evolution and simulated observations of models learned using our method, and compare them to previous work; and (2) compare the algorithms in terms of reconstruction error and efficiency. The error metric used for the quantitative experiments when evaluating matrix A  X  is i.e. percent increase in squared reconstruction error compared to least squares, with J (  X  ) as defined in Eq. (4). We apply these algorithms to learning dynamic textures from the vision domain (Sec-tion 5.1), as well as OTC drug sales counts and sunspot numbers (Section 5.2). A.
 B.

C.  X 2 0 2  X 1 0 1 Figure 3: Dynamic textures. A. Samples from the original steam sequence and the fountain sequence. B. State evolution of synthesized sequences over 1000 frames ( steam top, fountain bottom). The least squares solutions display instability as time progresses. The solutions obtained using LB-1 remain stable for the full 1000 frame image sequence. The constraint generation solu-tions, however, yield state sequences that are stable over the full 1000 frame image sequence without significant damping. C. Samples drawn from a least squares synthesized sequences (top), and sam-ples drawn from a constraint generation synthesized sequence (bottom). Images for LB-1 are not shown. The constraint generation synthesized steam sequence is qualitatively better looking than the steam sequence generated by LB-1, although there is little qualitative difference between the two synthesized fountain sequences.
 Table 1: Quantitative results on the dynamic textures data for different numbers of states n . CG is our algorithm by generating constraints until we reach S  X  , since LB-1 failed for n &gt; 10 due to memory limits. e x is percent difference in squared reconstruction error as defined in Eq. (10). Constraint generation, in all cases, has lower error and faster runtime. 5.1 Stable Dynamic Textures exhibit some form of low-dimensional structure and recurrent (though not necessarily repeating) characteristics, e.g. fixed-background videos of rising smoke or flowing water. Treating each frame of a video as an observation vector of pixel values y t , we learned dynamic texture models of two video sequences: the steam sequence, composed of 120  X  170 pixel images, and the fountain sequence, composed of 150  X  90 pixel images, both of which originated from the MIT temporal texture database (Figure 3(A)). We use parameters  X  = 80 , n = 15 , and d = 10 . Note that the state sequence we learn has no a priori interpretation.
 An LDS model of a dynamic texture may synthesize an  X  X nfinitely X  long sequence of images by driving the model with zero mean Gaussian noise. Each of our two models uses an 80 frame training sequence to generate 1000 sequential images in this way. To better visualize the difference between image sequences generated by least-squares, LB-1, and constraint generation, the evolution of each method X  X  state is plotted over the course of the synthesized sequences (Figure 3(B)). Sequences generated by the least squares models appear to be unstable, and this was in fact the case; both the steam and the fountain sequences resulted in unstable dynamics matrices. Conversely, the constrained subspace identification algorithms all produced well-behaved sequences of states and stable dynamics matrices (Table 1), although constraint generation demonstrates the fastest runtime, best scalability, and lowest error of any stability-enforcing approach.
 ure 3(C)) indicates the effect of instability in synthesized sequences generated from dynamic texture models. While the unstable least-squares model demonstrates a dramatic increase in image contrast over time, the constraint generation model continues to generate qualitatively reasonable images. Qualitative comparisons between constraint generation and LB-1 indicate that constraint generation Table 1 demonstrates that constraint generation always has the lowest error as well as the fastest runtime. The running time of constraint generation depends on the number of constraints needed to reach a stable solution. Note that LB-1 is more efficient and scalable when simulated using constraint generation (by adding constraints until S  X  is reached) than it is in its original SDP formulation. 5.2 Stable Baseline Models for Biosurveillance We examine daily counts of OTC drug sales in pharmacies, obtained from the National Data Retail Monitor (NDRM) collection [17]. The counts are divided into 23 different categories and are tracked separately for each zipcode in the country. We focus on zipcodes from a particular American city. The data exhibits 7 -day periodicity due to differential buying patterns during the week. We isolate a 60 -day subsequence where the data dynamics remain relatively stationary, and attempt to learn LDS parameters to be able to simulate sequences of baseline values for use in detecting anomalies. We perform two experiments on different aggregations of the OTC data, with parameter values n = 7 , d = 7 and  X  = 14 . Figure 4(A) plots 22 different drug categories aggregated over all zipcodes, and Figure 4(B) plots a single drug category (cough/cold) in 29 different zipcodes separately. In both the periodicity in the data, while the least squares model is unstable and its predictions diverge over time. LB-1 learns a model that is stable but overconstrained, and the simulated observations quickly drift from the correct magnitudes. We also tested the algorithms on the sunspots data (Figure 2(C)) with parameters n = 7 , d = 18 and  X  = 50 , with similar results. Quantitative results on both these domains exhibit similar trends as those in Table 1. We have introduced a novel method for learning stable linear dynamical systems. Our constraint larger set of stable matrices with a suitable objective function. The constraint generation approach also has the benefit of being faster than previous methods in nearly all of our experiments. One possible extension is to modify the EM algorithm for LDSs to incorporate constraint generation into the M-step in order to learn stable systems that locally maximize the observed data likelihood. Stability could also be of advantage in planning applications.
Tra ining Data Constraint Generation Least Squares LB-1 Figure 4: (A): 60 days of data for 22 drug categories aggregated over all zipcodes in the city. (B): 60 days of data for a single drug category (cough/cold) for all 29 zipcodes in the city. (C): Sunspot numbers for 200 years separately for each of the 12 months. The training data (top), simulated output from constraint generation, output from the unstable least squares model, and output from the over-damped LB-1 model (bottom).
 Acknowledgements This paper is based on work supported by DARPA under the Computer Science Study Panel program (authors GJG and BEB), the NSF under Grant Nos. EEC-0540865 (author BEB) and IIS-0325581 (author SMS), and the CDC under award 8-R01-HK000020-02,  X  X fficient, scalable multisource surveillance algorithms for Biosense X  (author SMS).

