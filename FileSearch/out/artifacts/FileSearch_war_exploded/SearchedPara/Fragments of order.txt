 High-dimensional collections of 0-1 data occur in many ap-plications. The attributes in such data sets are typically considered to be unordered. However, in many cases there is a natural total or partial order  X  underlying the variables of the data set. Examples of variables for which such or-ders exist include terms in documents, courses in enrollmen t data, and paleontological sites in fossil data collections . The observations in such applications are flat, unordered sets; however, the data sets respect the underlying ordering of the variables. By this we mean that if A  X  B  X  C are three variables respecting the underlying ordering  X  , and both of variables A and C appear in an observation, then, up to noise levels, variable B also appears in this observa-tion. Similarly, if A 1  X  A 2  X   X  X  X   X  A l  X  1  X  A l is a longer sequence of variables, we do not expect to see many obser-vations for which there are indices i &lt; j &lt; k such that A and A k occur in the observation but A j does not.
In this paper we study the problem of discovering frag-ments of orders of variables implicit in collections of un-ordered observations. We define measures that capture how well a given order agrees with the observed data. We de-scribe a simple and efficient algorithm for finding all the fragments that satisfy certain conditions. We also discuss the sometimes necessary postprocessing for selecting only the best fragments of order. Also, we relate our method with a sequencing approach that uses a spectral algorithm, and with the consecutive ones problem. We present experimen-tal results on some real data sets (author lists of database papers, exam results data, and paleontological data).  X 
Supported by a Microsoft Research Fellowship. Part of this work was done while the author was visiting the HIIT Basic Research Unit, Department of Computer Science, University of Helsinki, Finland.
 H.2.8 [ Database management ]: Database applications X  Data mining ; F.2.2 [ Analysis of algorithms and prob-lem complexity ]: Nonnumerical algorithms and problems Novel data mining algorithms, discovering hidden ordering s, spectral analysis of data, consecutive ones property
High-dimensional collections of 0-1 data occur in many applications, such as in market basket analysis, telecommu -nications networks, information retrieval, computationa l bi-ology, and ecology. The attributes in such data sets are typ-ically considered to be unordered. However, in many cases there are ordering dependencies among the attributes. Con-sider, for example, technical articles about database man-agement systems, and the terms  X  X atabase system X ,  X  X uery X , and  X  X electivity estimation X . A document can contain one of them, all of them, or just the first two or last two. How-ever, a document containing the terms  X  X atabase X  and  X  X e-lectivity estimation X  but not  X  X uery optimization X  seems somewhat strange.

Indeed, searches on Citeseer 1 using Google give the fol-lowing numbers of hits: We indeed see that one particular pattern of occurrences of terms is very rarely represented. Note that we are not look-ing at the ordering of terms in individual documents. For each document, we only look at whether the terms occur in it or not. We aim at using this data to obtain informa-tion about the ordering relationships between the attribut es (variables).

The reason for the asymmetry between the three terms in the above example is that there is an underlying direc-tionality in the terms. The term  X  X electivity estimation X  in the context of  X  X atabase systems X  is dependent on the http://citeseer.nj.nec.com concept of  X  X uery X : selectivity estimation cannot be dis-cussed without mentioning (sooner or later) queries. The chain of concepts could be longer: for example,  X  X istogram technique X  would probably fit to the end of the above chain.
What makes the above ordering  X  X atabase system X   X   X  X uery X   X   X  X electivity estimation X  interesting is that there are enough observations that con-tain at least two of the terms (the fragment has high fre-quency) and few observations have the first and last but do not have the second one (the fragment has few violations). We make these criteria specific in the next section.
In this paper we study the problem of discovering this type of fragments of order from unordered 0-1 data. Such orderings between smaller or larger sets of variables occur in various types of data sets. For example, consider a data set where the variables represent courses at a department and rows represent students; a 1 indicates that the student has passed the course. The prerequisites of courses show up in fragments of order: if course A i is needed for course A i +1 for i = 1 , . . . , l  X  1, we assume that no student has passed two courses A i and A k but not A j for some i &lt; j &lt; k . Some examples of observations conforming and violating the orde r A  X  B  X  C  X  D are given in the next table.
 Note that if an observation violates some order, it also vio-lates the order obtained by reversing the direction of all th e precedence relationships.

As a third example, consider paleontological data about fossil remains of animals. The variables are different sites (in different locations) from which fossils have been found, and the observations represent the taxa (species or genera) . If variable A is set for observation t , this means that taxon t has been found at site A . Each site represents fossils from a relatively brief interval in geological time. The goal for t his type of data is to find the order corresponding to the ages of the sites. For a fragment of order A  X  B  X  C relating three sites, an observation t that violates this order corresponds to the so-called Lazarus phenomenon: a taxon that is extant at A , extinct for B , and reappears at C .

The rest of this paper is organized as follows. In Section 2 we review work related with the problem we consider here. In Section 3 we describe the formal definitions of fragments of order and give the problem statement for finding all frag-ments from a dataset. We focus on finding fragments of order, and not total orders, as the real-life data sets seldo m allow for nice orderings of attributes that would be compat-ible with most of the data. Section 4 describes a simple A priori-like algorithm for finding the fragments, and it show s how we can do some postprocessing to select the best frag-ments. Section 5 is a quick introduction to spectral cluster -ing, a method that can be used to yield total orderings of all the attributes minimizing some stretch measures. Sec-tion 6 gives the empirical results, and Section 7 is a short conclusion.
We are not aware of a lot of related work. Our work is of course heavily influenced by the work on association rules [1]: the idea of looking at all possible patterns from a con-cept class that satisfy certain frequency counts has proved to be very useful (e.g., sequential patterns [2, 15]). Here, however, the concepts are slightly less straightforward: a n observation with all 1s does not contribute to all patterns, as it does for normal frequent pattern type of concepts.
Some of the approaches of postprocessing association rules (see, e.g., [10, 19]) aim at finding graphs of attributes from 0-1 data. However, the semantics there typically are quite different from ours. Mannila and Meek [14] provide an algo-rithm for finding a partial order for the full set of variables in an dataset consisting of observation in each of which the variables are ordered ; in our setting, the observations are sets, not sequences. The work of Popescul et al. [17] has somewhat similar goals to ours, but in their paper they con-sider the context of linked documents. In computational biology, e.g., in sequence assembly (see [8]), one encounte rs the task of totally ordering a set of variables so that so sort of breaks are minimized. This is fairly closely related to the method of spectral clustering. Again, our emphasis is on finding fragments of order, not a single best order, and hence many of the techniques from computational biology are not directly applicable. Our problem is also related to the consecutive ones property [4]; we will discuss the rela-tionship in Section 5.
In this section we introduce some notation and define more formally the problem of discovering the fragments of order. Let R = { A 1 , . . . , A n } be the set of 0-1 attributes of the dataset. A dataset D = { r 1 , . . . , r m } consists of m observa-tions each of which is a subset of attributes from R . Equiv-alently, an observation can be viewed as a record with n attributes { A 1 , . . . , A n } taking values in { 0 , 1 } . This gives rise to the common data representation as a 0/1 matrix with m rows corresponding to observations and n columns corre-sponding to attributes.

We are interested in cases where there is an underlying ordering of a subset of the attributes of R . We denote such an ordering using the symbol  X  , and we write A i  X  A j to say that A i precedes A j in the ordering. A sequence of at-tributes F =  X  A 1 , . . . , A l  X  defines a fragment of order , or just a fragment , if the attributes of F form a chain with respect to the ordering  X  , i.e., if it is the case that A 1  X  . . .  X  A We say that fragment F is of length l . We sometimes write F =  X  A 1 , . . . , A l  X  and in other cases we use the notation A 1  X  X  X  X  X  X  A l .

Orderings on the data attributes like the above can be implicitly induced by a hidden variable associated with the attributes, or by a semantic interpretation of the attribut es.
The central observation in our paper is that there is enough information in the data to recover the underlying ordering of the attributes, or at least to obtain some clues regarding this ordering. This is accomplished by noticing that, given an ordering, certain observations respect it and some viola te it.

As an example, consider a potential fragment F =  X  A i , A of length 3, i.e., the ordering A i  X  A j  X  A k . We say that an observation t violates F if t [ A i ] = t [ A k ] = 1 and t [ A An observation t violates a potential fragment F of length l &gt; 3, if it violates any fragment F 0 of length exactly 3 which is subsequence of F , i.e., there are three attributes A i and A k in the ordering such that and we have t [ A i ] = t [ A k ] = 1 and t [ A j ] = 0. We say that an observation respects a potential fragment if it does not violate it.

Given a fragment F =  X  A 1 , . . . , A l  X  , with l  X  2, the fre-quency f ( F, D ) of F on dataset D is the fraction of rows r in D in which at least two attributes of F appear, i.e., for some i and j with i 6 = j we have r [ A i ] = r [ A j ] = 1. We de-note by R ( F, D ) the collection of rows that have the above property; thus f ( F, D ) = |R ( F, D ) | . If fragment F mutation of F , then F and F 0 have the same frequency. The violation fraction v ( F, D ) of F on D is the fraction of rows r of R ( F, D ) that violate F . For a fragment F of length 2 we define v ( F, D ) = 0 for all D . Note that the frequency of F is the fraction from all rows, while the violation frac-tion is the fraction of violating rows from the R ( F, D ) rows contributing to f ( F, D ).

We want to search for orders that are good in the sense that they have few violations. This condition, however, is not sufficient for the ordering to be interesting. A database in which all observations are empty (i.e., there are no 1s) has violation fraction of 0 for all orderings. This, obvious ly, is not what we want: we want to also have positive evidence that the attributes occurring in the order are used. As an example, consider the dataset All the rows in this table contribute to the frequency of the ordering A  X  B  X  C  X  D , and this ordering has no violations The same is true for the reverse ordering D  X  C  X  B  X  A . All the other 22 orderings of the four attributes have also frequency 1, but each has at least one violation.
A frequency threshold  X  is used in combination with the violation threshold  X  in order to obtain fragments that ap-pear frequently in the dataset and have a small number of violations. In particular, given thresholds  X ,  X   X  [0 , 1] we define the set T 0 ( D,  X ,  X  ) to consist of the fragments that are  X  -frequent and not  X  -violated, i.e., T ( D ,  X ,  X  ) = { F fragment of R| f ( F, D )  X   X , v ( F, D )  X   X  } . Note, however, that this definition does not require that all attributes contribute to the frequency of the fragment. Consider the dataset The frequency of the ordering A  X  B  X  C  X  D is 1 and there are no violations. Obviously, D is not contributing to the order. Thus we augment our definition by requiring that all subfragments of F also have to belong to the collection:
T ( D ,  X ,  X  ) = { F | f ( F, D )  X   X , v ( F, D )  X   X , According to this definition, the fragment A  X  B  X  C  X  D does not belong to T ( D ,  X ,  X  ) for any  X  &gt; 0, as the frequency of, e.g., fragment A  X  D is 0.

One can worry whether our criteria for interesting frag-ments is too weak. Consider the following data set. Every ordering of the four attributes has frequency 1 and vi-olation fraction 0, so they would belong to the set T ( D ,  X ,  X  ) for all choices of  X  and  X  . In Section 4.2 we show how we se-lect between the orderings among the same set of attributes. Basically, the strategy is to look at the number of violation s: if there is an ordering F that has clearly less violations than the other orderings then that implies that F is more infor-mative than other orderings among the same attributes.
In Section 4 we describe an efficient algorithm to compute the set T ( D,  X ,  X  ), and we show how the best orderings can be found in the case where there are several permutations of the same subset of variables in the collection T ( D,  X ,  X  ).
In this section we describe an algorithm for computing the set T ( D ,  X ,  X  ) for given D ,  X  and  X  .

The algorithm consists of two phases. The first is a fairly standard levelwise computation of the set T ( D ,  X ,  X  ). This can be done efficiently in fashion similar to A priori algo-rithm, since the collection T ( D ,  X ,  X  ) is downward closed by definition.

One characteristic of the set T ( D ,  X ,  X  ) is that it might be possible (and indeed this is typically the case) to contai n many fragments of the same subset of attributes. First, for it is true that the reverse fragment  X  A l , . . . , A 1  X  belongs in the set, as well. This is true because the two fragments have exactly the same frequency and violation fraction. In other words, the data D is oblivious with respect to the direction of attribute orderings.

In addition to reversed fragments, it is possible that many more permutations of the same subset of attributes belong in the set T ( D ,  X ,  X  ). Imagine, for example, a dataset D for which there is a subset S of attributes such that in each row of D either all of the attributes of S appear together or none. In this case, it is feasible that all fragments that are derived as permutations of S are members of T ( D ,  X ,  X  ).
This motivates the second phase of our algorithm, which is a peer selection phase. We would like to distinguish between fragments that correspond to a true ordering of attributes, versus fragments that appear in T ( D ,  X ,  X  ) just because they are frequent itemsets . The intuition of the algorithm for discovering true ordering is to test how a fragment stands out among its peers , where peer is any other fragment which is a permutation of the same attributes. This is explained in detail in Section 4.2
As we mentioned in the previous section, the algorithm for computing the set T ( D ,  X ,  X  ) is an A priori type method based on the monotonicity property of the collection T ( D ,  X ,  X  ). Note that the frequency of a fragment is not monotonic with respect to subsequences: the frequency of  X  A, B, C, D  X  can be higher than the frequency of  X  A, B, C  X  .

The algorithm starts by forming all fragments consisting of exactly two attributes from R . These are marked as can-didate fragments of length 2. At the k -th step, candidate fragments of length k have been formed. The algorithm proceeds by dropping all fragments that do not satisfy the frequency and violation fraction thresholds, and by formin g candidate fragments of length k +1. The inbuilt monotonic-ity of T ( D ,  X ,  X  ) guarantees that no fragment will be missed.
The next three functions provide a detailed description of the levelwise algorithm.
 LevelWise ( D ,  X  ,  X  ) Candidates ( L ) Evaluate ( D ,  X  ,  X  , C )
The complexity of the algorithm is O ( mn ( |T| + C )), where m is the number of observations in the data, n is the number of variables, and C is the number of candidate fragments considered which turn out not to belong to T . Thus the method is linear in the size of the data and scales nicely to large data sets.

The frequency and violation fraction for a fragment or a set of fragments can be computed from the data by sim-ple sequential scan. The counts can also be written by us-ing the inclusion-exclusion principle in the form f ( F, D ) = P i c i fr ( X i , D ), where the sets X i are subsets of the frag-ment, fr ( X i , D ) is the frequency of the set X i in the asso-ciation rule sense [1], and c i is a positive or negative inte-ger. However, these expressions can be exponentially large in the number of elements in F , so we in our experiments compute the frequencies directly from the data. However, the use of expressions of the above form gives the possibilit y of taking advantage of the wealth of fast association rules algorithms [10] for our problem, as well.
The second phase of the algorithm for discovering the best fragments of order is to test whether a fragment is a true order that stands by its own. As we mentioned before, if a set of attributes occur always together we do not want to take a single or all permutations of this set as a result. In this case we would probably like to say that the trivial partial order is the right answer.

Suppose that a fragment F belongs to T ( D ,  X ,  X  ). This means that the ordering of attributes given by F is not vi-olated too often. We still have to test that the actual order is significantly different from other possible orders of the attributes occurring in F .

If, for example, for three attributes A , B , and C we have that the association rules AB  X  C , AC  X  B , and BC  X  A all have accuracy 1 in the data, then all 6 permutations of ABC have the same frequency and violation fraction. (Note the similarity to concepts such as closed sets.)
Next we describe a simple probabilistic model for estimat-ing the likelihood of orders (somewhat in the spirit of [14]) . The model gives in the end the expected result: the best ordering is the one that has the fewest violations.
Given a fragment F =  X  A 1 , . . . , A l  X  , consider the set of all possible permutations of the attributes of F , that is
For a fragment F , the likelihood L ( D| F ) expresses the probability that the dataset D comes from a model where F is a true order on the attributes. We assume that i.e., the logarithm of the likelihood is proportional to the violation fraction. The reason for this assumption can be obtained, e.g., from MDL type of arguments.

Assume that L ( D| Z ) is computed for all Z  X  S ( F ), and furthermore assume that the fragments in S ( F ) is the com-plete set of models for which we are interested in distinguis h-ing the likelihood of the data. Then, by applying Bayes X  rule we can write P r ( F |D ) = P r ( Z ) L ( D| Z ) We are assuming that P r ( Z ) = 1 |S ( F ) | for all Z  X  S ( F ), since we have no reason to favor a particular permutation. For the choice of L ( Z |D ) as specified in Equation (1) we have
One should immediately observe that the denominator in the above formula does not depend on the permutation Z , thus, for selecting the best permutation, we only have to consider the term exp (  X  v ( Z, D )). The log of the latter is proportional to v ( Z, D ), i.e., the number of violations of fragment Z in the dataset D .

Motivated by the above discussion, we suggest that the selection among peers (say,  X  ABC  X  and all permutations of it) should be based on the number of violations for each per-mutation. We consider the number of violations just as a (e.g., binomially distributed) random variable. Given suc h a set of random variables we select the (one or several) per-mutations with the less number of violations as candidate best fragments. To decide if these candidates are indeed bes t fragments we need to verify that the values of their violatio n fractions cannot be attributed to randomness and noise in the data. This can be done easily with a standard anova test. The selection phase algorithm is summarized below. SelectAmongPeers ( T )
We assume that the violation fractions v ( F, D ) are known since they have been computed in the previous phase of the algorithm. The complexity of the selection phase is O ( |T| log |T| ). This is because the most expensive step  X  partitioning T into groups of peers  X  can be accomplished by lexicographic sorting of all fragments in T .
In this section, we describe an ordering algorithm based on spectral methods. Spectral algorithms are important tools for solving graph partitioning problems, and they have been used in a wide range of applications, such as solving linear systems [18], domain decomposition [6], scientific numeric al algorithms [20], and clustering problems [16]. Spectral al go-rithms have also been used for ordering vertices in a graph, and in particular for the linear arrangement problem, as dis -cussed in [13].

The spectral algorithm we discuss in this section is at-tractive because of its simplicity and its intuitive appeal . However, one should note that formally the spectral algo-rithm does not correspond to the same problem that we defined in Section 3. The main difference is that the spec-tral algorithm provides a single total ordering, instead of many, perhaps overlapping, fragments of order. Similarly, the concepts of frequency and violation fraction threshold s are not used by the algorithm. In the rest of the section, we give some background for the spectral method in general and then we describe our spectral ordering algorithm.
Consider an undirected graph G = ( V, E ) where each ( i, j )  X  E has weight w ij . Let A be a matrix whose ( i, j )-th entry is equal to w ij if ( i, j )  X  E and 0 otherwise. The Laplacian of graph G is defined to be the symmetric and zero-sum matrix L = D  X  A , where D is a diagonal ma-trix whose ( i, i )-th entry is d i = P ( i,j )  X  E w ij . Let v be the eigenvector of L that corresponds to the second smallest eigenvalue. One can show (e.g., [7]) that v is the vector that minimizes the quadratic form Vector v is also known in the literature as the Fiedler vector . It can be viewed as a mapping from a node i  X  V to the value v i , that is, as an embedding from graph nodes to the 1-dimensional line. If we use Equation (2) to define a  X  X tretch X  energy function associated with this embedding, then the Fiedler vector has the property that it minimizes this energ y function.

This has clearly an ordering interpretation. However, it goes beyond simple ordering since it also assigns real num-ber values to nodes and therefore distances between them. If one is looking for an ordering it is more natural to search for a bijection  X  : V  X  { 1 , . . . , n } that minimizes the ar-rangement cost This NP -hard problem is studied in [13] and various heuris-tics are proposed. In this paper, we use such a heuristic to obtain an approximate total orderings on the dataset at-tributes. This is done as follows: We consider each attribute A  X  X  to be a node in a graph G
D . For each pair of attributes ( A i , A j ), we consider the weight of this edge in G D to be the frequency of the itemset { A i , A j } . The Laplacian matrix of G D is formed and the Fiedler vector is computed. Then, the algorithm outputs all the attributes in order of ascending (or descending) value o f their Fiedler coordinates.

The spectral algorithms have interesting connections to the consequtive ones property. A matrix of 0s and 1s has the consequtive ones property, if there is a way of permuting the attributes so that for each row all the 1s are consequtive . Testing whether a matrix has the consequtive ones property can be done in linear time using PQ-trees [4, 5, 11]. The relationship of spectral methods and the consequtive ones property is studied in more detail in [3].

The relationship between spectral clustering and finding fragments of order is interesting. Consider the case when the input data has the consequtive ones property. Then by the results of [3] the spectral method (used for the Lapla-cian matrix of G D ) produces an ordering which satisfies the consequtive ones property. Furthermore, in this case this o r-dering has in our terms frequency 1 and no violations. Thus in the case of consequtive ones property the output from our method would be of exponential size, as all subsequences of the order would qualify. Thus one can see our technique as more applicable to situations in which the underlying order does not have long paths.
In this section we briefly describe some of the experiments we have done on real data using the fragment discovery al-gorithm.

We report some results from a students exam results data set, from author lists of database papers, from titles of database papers, and from paleontological databases.
We also ran experiments on generated data, by generating random orderings of subsets of the set of attributes and gen-erating data by selecting consequtive attributes from thes e orderings. The data was corrupted by adding noise. The results on these data sets showed that the method was able to find the generating orderings up to a fairly high level of noise, and that the number of superfluous fragments re-mained small. We omit the details. (in %) (in %) (in %) (in %) Table 1: Results on the exam results data.  X  : the frequency threshold;  X  : the violation fraction threshold. Max l is the maximum length of a frag-ment in the result. |T| is the total number of frag-ments found.  X  ,  X  : see text.
We considered a data set from the Department of Com-puter Science at the University of Helsinki. The data set has 2953 observations (corresponding to students), 5684 vari-ables (corresponding to courses), and 72395 exam results. The average number of 1s per row is 24.5, with a minimum of 1 and maximum of 131.

For this data, we ran experiments on the fragment find-ing algorithm. In this case, we have two ways of relating the resulting fragments to the data. First, we know the rec-ommended ordering among the courses; see Figure 1 for a partial view of this. Second, we have in the original data set information about the times in which the students have taken each course. So we can compare how well the discov-ered fragments correspond with official policy and with the real data.

Table 1 gives some results on how the fragments are re-lated to the actual known order in which each student has passed the courses. To compare how well the fragments cor-respond with the actual order of courses, we computed two coefficients. The score  X  is computed by looking at each fragment and each observation that contains at least all the variables occurring in that fragment. We test whether the order of the courses in the observations is the same (or re-verse) from that in the fragment;  X  is the fraction of cases in which this happens. The score  X  is computed by looking at each fragment and each observation containing at least 2 courses appearing in the fragment, and by checking whether the order in the observation corresponds to the order in the fragment (or its reverse);  X  is the fraction of cases in which this happens. (Note that  X  has the bias that no observation with at most 2 courses can cause a violation.)
Visual comparison of the discovered fragments against the ordering shown in Figure 1 shows that the correspondence is good, especially for small thresholds of the violation frac tion. When up to 40 % of violations are allowed, one sees also fragments that are not compatible with the partial ordering in the figure.

As a single example, we found the fragment Programming Databases Programming Data Structures Figure 1: Recommended ordering among 9 courses in the exam results data.
 which had frequency 1361, and violation fraction 3.2%. Ther e were 464 students who had attended all these 5 courses, and 278 had passed them in exactly the above order. When the course Computer Organization took away from the above order, the frequency was 1222 and violation fraction 0.9%. The same 464 students who had attended all those 4 courses, but 439 (94.6%) had passed them in exactly the above order.
The results show that the fragment discovery algorithm manages to capture a surprising amount of the order actu-ally existing in the data. In [14] an algorithm was given that reconstructed a partial order for the courses, given th e ordered observations; what we show here is that the frag-ments describing the same ordering to a high degree can be reconstructed from unordered data. We studied the bibliographies of VLDB, SIGMOD, and PODS available at the Collection of Computer Science Bib-liographies 2 , and extracted the lists of authors from each paper. A selection of the papers with at least 2 authors yielded 3109 rows (papers) with a total of 9538 authors, i.e., 3.1 authors per paper. There are 3398 authors in total. The numbers of orderings obtained for various thresholds are shown in Table 2.

From the results in Table 2 we note that the number of elements in the answer set increases rapidly with decreas-ing frequency threshold  X  and increasing violation fraction threshold  X  . One should observe, however, that it is easy to find values of  X  and  X  that produce outputs of desired size.
Recall that for each fragment also the reverse fragment has the same frequency and violation fraction. Thus the algorithm for finding fragments find produces all fragments basically twice. The column N in Table 2 shows how many distinct subsets there are. We discussed previously the cas e http://liinwww.ira.uka.de/bibliography/ Table 2: Number of elements in T ( D ,  X ,  X  ) for var-ious values of  X  and  X  for the authors of database papers data set. Max l is the maximum length of a fragment in the result. |T| is the total number of fragments found. N is the number of different sub-sets of attributes present in the output, and P is the number of subsets for which more than two different orderings belong to T . of a tightly connected set of attributes. This case occurs fairly rarely in the database. One nice example is the triple which satisfies the above condition! 3
A converse case is observed for the triplet which has a frequency of 15. This ordering has no violations, while the other orderings have either 1 or 4 violations. Thus we can say that the above ordering is the best among these three authors.

As an example of a long fragment, we have which has a frequency of 3.3 %: at least two of these au-thors are authors in 104 papers, while there are 18 violation s (17 %). Many of the long fragments, as the one above, are very intuitive for readers of the database literature.
We also tested the spectral clustering method on this data set. The technique cannot be applied to the whole data set, as there are several disconnected components in the under-lying graph, i.e., authors who have no chain of coauthorship connections with the other authors. Thus we had to limit the data set by taking the 20 most common authors and including all papers in which at least one of them was an author. The spectral ordering for the top 20 authors pro-duced was
The authors are joint authors in 5 papers in the database, but there is no paper in which only two of them would be authors. There are lots of papers in which one of them is an author, of course.
 One of the longer orders produced by the fragment finding algorithm is It has a frequency of 3.2 % (99 observations) and only 3 violations (3%). We see close similarity between the above fragment and the spectral clustering result.

We also tested the similarity of the discovered fragments against the spectral ordering. The results show, as expecte d, that the fragments mostly capture the same type of order-ing information as the spectral method. However, there are many cases in which the fragments yield a more intuitive collection of orders against the forced single order of the spectral method. We omit the details.

We also used the algorithm to find fragments from the titles of the papers in the bibliography. An example frag-ment is which has a frequency of 116, and 3 violations.
In the paleontological dataset (see [12]) the variables are different sites (in different locations) from which fossils h ave been found; there are 674 of these. As observations, we used the presence or absence of genera, of which there are about 300. The sites have been classified into so-called MN classes ; the MN class of a site corresponds roughly to the age of the site. We ran the fragment discovery algorithm to see (1) how well are the fragments compatible with the MN classifi-cation, and (2) whether any exceptions can be found. Again, we found that the fragments correspond relatively well with the existing order of the variables. Of the approximately 2000 triplets found with  X  = 0 . 01 and  X  = 0 . 2, about 1800 where compatible with the MN classes, about 200 had a dif-ference of 1 (e.g., the fragment was A  X  B  X  C , but the MN classes were 7,8, and 7, respectively). One triplet had a difference of 2: for the fragment A  X  B  X  C the MN classes were 15, 17, and 15. The existence of the fragment indicates, e.g., that no genera was present in A and C but absent in B, and thus the assignment of MN class 17 to B is suspect. This was confirmed by an investigation of the background for the assignment [9].
We have defined the concept of a fragment of order. Such a fragment is an ordering of a subset of variables in a 0-1 dataset. We described the criteria, frequency and violatio n fraction, to be used for finding potentially interesting fra g-ments of order. We gave a simple A priori-like algorithm for discovering all fragments of order that satisfy the thresho lds, and describe how further pruning can be done by selection among peers, if necessary.
 We gave preliminary empirical results on several datasets. The results on the course enrollment data set showed that the method is able to find large fractions of the underlying structure of the curriculum. The results on the bibliograph ic database demonstrated that the method also yields intu-itively appealing results in the case where there is no known underlying order. We also studied briefly the relationship of the fragments to an ordering of the variables obtained by spectral methods. Even the first results on paleontological data were strong enough to lead to the discovery of an error in the original data set.

Obviously, a lot remains to be done. We are currently conducting a much larger set of experiments, and also de-vising methods for estimating the recall and precision of a set of fragments with respect to a known partial order.
A possible extension of the above framework is to con-sider the discovery of partial orders. This leads to interes t-ing issues. Consider for example a partial order in which A  X  B, A  X  C, B  X  D and C  X  D . What constitutes a violation of this order? If we see A and D in an observation, do we require that both or at least one of B and C is also seen? The first interpretation is conjunctive, and it yields a fairly well behaving concept class, which has several mono-tonicity properties. The second, disjunctive interpretat ion, on the other hand, gives a concept class which fails many monotonicity test both in theory and practice. Finding a well-behaving class of partial orders would be of interest. [1] R. Agrawal, T. Imielinski, and A. Swami. Mining [2] R. Agrawal and R. Srikant. Mining sequential [3] J. E. Atkins, E. G. Boman, and B. Hendrickson. A [4] K. S. Booth and G. S. Lueker. Linear algorithms to [5] K. S. Booth and G. S. Lueker. Testing for the [6] T. F. Chan and D. C. Resasco. A framework for the [7] F. R. K. Chung. Spectral Graph Theory . CBMS [8] R. Durbin, S. Eddy, A. Krogh, and G. Mitchison. [9] M. Fortelius. Private communication. 2003. [10] J. Han and M. Kamber. Data Mining: Concepts and [11] Hsu. A simple test for the consecutive ones property. [12] J. Jernvall and M. Fortelius. Common mammals drive [13] Y. Koren and D. Harel. Multi-scale algorithm for the [14] H. Mannila and C. Meek. Global partial orders from [15] H. Mannila, H. Toivonen, and A. I. Verkamo.
 [16] A. Ng, M. Jordan, and Y. Weiss. On spectral [17] A. Popescul, G. W. Flake, S. Lawrence, L. H. Ungar, [18] A. Pothen, H. Simon, and L. Wang. Spectral nested [19] R. Ramakrishnan and J. Gehrke. Database [20] H. D. Simon. Partitioning of unstructured mesh
