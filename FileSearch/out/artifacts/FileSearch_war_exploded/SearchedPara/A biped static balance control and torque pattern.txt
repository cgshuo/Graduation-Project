 1. Introduction
A kind of intelligent motor behaviors of animals is observed in a learning of motion patterns by adapting to unknown environ-ment. Even my pet dog, for instance, not only walks in my cluttered house without tripping but also changes his walking or running pattern according to the situation. Such behaviors are not easy to achieve as robot behaviors, because, in conventional robot controls, the motion patterns are programmed in advance by assuming environmental conditions. The programmed robot behaviors are not assured in unknown or variable environments.
Two types of abilities are found in the above dog behavior. One steady environmental condition (walking is switched to running). The other is to stabilize the posture or movement to deal with a rapid disturbance from the environment (walking in the cluttered house where foot placement may be slightly different at each step). This paper treats a scheme of motor control and learning from these two points of view.

To make the problem as simple as possible, the balancing problem as shown in Fig. 1 is considered as an example. In this situation, a human stands on a floor where the slope changes Normally, humans can adjust their standing position with respect to the slope of the ground by changing the sway angle, in other words, the joint angle of the ankle. This balancing method is especially called ankle strategy ( Horak and Nashner, 1986 ), although some other strategies, mechanisms or control methods are proposed in the human standing ( Winter, 1995; Alexandrov et al., 1998; Rietdyk et al., 1999; Van Ooteghem et al., 2008 )or biomechanical/robotic model ( Gorce and Vanel, 1997; Hof, 2007; long time, humans can learn the operation of the ankle as a periodic motion pattern based on this periodicity. The object of machines like robots rather than to elucidate a neuronal mechanism whereby humans accomplish such a n adaptive behavior, although the problem originates from a consideration of a control/learning mechanism in the behaviors of biological systems.

Balance control methods are often discussed in the field of robotics, especially for walking robots. Here, the main issue is rather motion generation based on the zero moment point (ZMP) ( Vukobratovic et al., 1990 ), a point on the ground around which the moment of inertial force and gravity are balanced. In this gravity (CoG) are calculated in advance as a motion pattern so that the ZMP is kept beneath the foot support. Then the trajectories are reproduced by position control during actual ( Huang et al., 2000; Wollherr and Buss, 2004; Lee et al., 2005; Prahlad et al., 2007 ) of the trajectories have been proposed to adapt to changes in environmental conditions. However, the discussions of periodic pattern learning are not yet sufficiently advanced to support the development of walking robots. As for static balance, the stability of the upright posture is analyzed ( Napoleon and Sampei, 2002 ). The acquisition of biped dynamics is described with a neurophysiological model ( Nakayama and Kimura, 2004 ). Reinforcement learning is applied ( Borghese and task ( Morimoto and Doya, 2001 ). Human static balance is measured to clarify its adaptive characteristics ( Nashner, 1976;
Priplata et al., 2002; Lockhart and Ting, 2007 ). Regarding to the periodic motion learning, a method based on the controllers 1999; Ishiguro et al., 2003; Ijspeert, 2008; Endo et al., 2008 ).
However, control and pattern learning schemes of periodic motion based on the on-line balance have not been sufficiently discussed.

Thus, this paper deals with a problem such as that in Fig. 1 that contains both control and learning factors. We have already proposed a control and learning method for a special case where the period of an environmental alternation is given beforehand of the period is required. After the concept of our control scheme is explained in Section 2, a control and learning method including period estimation is formulated in Section 3. In Section 4, the effects of our scheme are confirmed by simulations, and it is applied to the motion control of actual robot in Section 5. In
Section 6, concepts and assumptions in this paper are recon-sidered and its advantages as well as remained problems are discussed. Finally, this paper is concluded in Section 7. 2. Control and learning scheme for static balance 2.1. Strategy
One of our future goals is to apply the balancing and learning method to the locomotion pattern learning. The walking is periodic motion and thus the balance disturbances caused by the inertial force of walking also become periodic. Thus, motion compatible to the locomotion pattern learning and is applicable to the design of the desired trajectories in the locomotion pattern.
Then, an irregular environment, such as seen in a cluttered house, produces non-periodic disturbances. Under the plan in this paper, such non-periodic disturbance is compensated by the feedback control based on ground reaction forces. Simultaneously, an adequate motion pattern is learned into the motion pattern generator to automatically cope with the periodic forces from walking motions. As the first step toward this goal, we consider here the static balance control and the motion pattern learning with respect to periodic external forces.

In the human balance control, ankle strategy is typically observed for small disturbance, in which balance is kept by ankle joint operation without moving any other joints such as knee and short time. Thus, it is reasonable to assume an ankle strategy to consider a control and learning scheme in biped balance control.
As mentioned in Section 1, adaptability should enable the adjustment of motion to environmental changes on different a temporary external force as a short-term fluctuation and to an ongoing, here periodic, external force as a long-term transition.
These two kinds of external force cause a contradiction in motion pattern generation: In the former case, the motion pattern should be unchanged (i.e., stabilized), because the external force is regarded as the disturbance. In the latter case, the motion patterns should sometimes be changed, i.e., restructured or switched, to be appropriate to the new environment.

To cope with this contradiction, the following two character-istics are introduced to a control and learning scheme: feedback information regarding the ground reaction force and a feedfor-ward controller as the motion pattern generator. This scheme is ground reaction force is informative for balance. The center of action of all the ground reaction forces is called the center of pressure (CoP) and coincides with the ZMP ( Goswami, 1999 ).
Thus, balance control against the temporary external force is constructed based on the feedback information regarding ground reaction force, as shown in Fig. 2 (a). Now, assume that the the action of the balancing motion also becomes periodic. Based on this periodicity the motion pattern is being stored in memory during the learning process. Here, the torque trajectories are of learning is balance maintenance without information on the ground reaction forces, which generally provide significant feedback for balancing. This process is illustrated in Fig. 2 (b). 2.2. Static balance model
To achieve the scenario in the above section, a simple link model, as shown in Fig. 3 (a) is considered. The ankle joint acts mainly against the small disturbance, which is called ankle strategy ( Horak and Nashner, 1986 ). From this point of view, an inverted pendulum with small foot support is introduced with the following assumptions: the motion is restricted within the sagittal plane. The ankle joint can generate torque t and its only at two points, where the vertical component of the ground the center of the foot and enough low position.
 The dynamics of the inverted pendulum is given by I  X  y  X  MLg sin y  X  F x L cos y F y L sin y  X  t  X  F A L sin  X  y y the distance from the joint to the center of mass (CoM), g is the gravity acceleration, F x and F y are unknown external forces. F y are given as follows: F  X  tan y f  X  F x Mg F The foot support, on the other hand, never move when the balance is maintained, implying that the moment balance equations are obtained instead of the motion equation. They are given as F  X  F  X  f is an interacting force from the inverted pendulum. 2.3. Methods
The scheme is realized using the concept of feedforward and feedback control. Here, feedback means that the system uses the signal from the ground reaction force, and feedforward means that it does not contains its sensory feedback.

In the next section, the control law is first constructed for the ankle joint torque, t fb . For periodic external forces, t becomes periodic. Based on this periodicity, the torque pattern is learned; i.e., the trajectories of t fb are memorized during its repetitive generation. The motion pattern generator, acting as a feedforward controller, stores this pattern. The output torque of the feedforward controller is denoted by t ff .

The total torque t is the sum of t ff and t fb : the t fb component. As t ff is being learned, t fb is gradually decreasing. Finally, t fb is copied to t ff , i.e., replaced by t next section, this process is formulated using the static balance model in Section 2.2. 3. Formulation 3.1. Adaptive balance maintenance
Not only to keep F T and F H positive but also to make them equal is a reasonable description of the control purpose for balance Then, the stability margin ( McGhee and Frank, 1968 )ismaximum, implying that this posture is maintainable against any external  X  K d _ y K p y  X  K f Proposition. Define the control law as (7), i.e ., t  X  t fb dynamical system (1), (4) and (5). At the stationary state , y  X  y well as F T  X  F H hold for constants F x and F y .
 Proof. At first, a new variable t f is defined as  X  Then, the control law (7) becomes  X  K d _ y K p y  X  K f t f :  X  9  X  the following equation is obtained: _ t  X  obtained by setting the differential term zero. It is given as  X  y , _ y , t f  X  X  y f , 0 , K p K F the controllability of the linearized dynamics around this point ( Ito and Kawasaki, 2005 ). &amp; posture, the moment of the external force and gravity is balanced. Namely, no torque is required at the ankle joint and thus the effective posture maintenance is achieved. Furthermore, the dependence of the stationary state y f on F x and F y that the posture adaptively change with the external forces. The local stability is the same as the actual human motion: humans certainly tumble if they are pushed by a large force. 3.2. Learning of periodic pattern
This section treats the learning of periodic motion pattern as torque trajectory, when the periodic external force is exerted. Here, the period of the external force T e is assumed to be known. The case in which its period is unknown will be discussed in the next section.

In the static balance model with ankle strategy, the ankle joint motion pattern generator followed by the method in Section 2.3. Namely, a control and learning law is defined as follows:
The control law t is defined as the summation of the feedforward torque t ff and feedback torque t fb :  X  t ff  X  t fb :  X  12  X  ff is calculated by the next equation: ff  X  Y r ^ f :  X  13  X  Here,
Y  X  X   X  y r , S , S 0 C , C 0 C , S 0 S , C 0 S , ... , S n C , C where  X  y r is calculated from the derivative of _ y r defined as _ y  X  and S k  X  sin k o e t , C k  X  cos k o e t , o e  X  2 p = T control and learning method. ^ f is, on the other hand, an estimate of the unknown parameter vector f defined as f  X  K I s ,  X  16  X  where K  X  and ^ f is updated in the next learning rule.

The learning of the feedforward torque t ff is described by the update of ^ f as _ ^ f  X  G Y T r s :  X  19  X  Here, G is a positive diagonal matrix.

For the feedback torque t fb , the definition (7) is utilized: fb  X  K d _ y K p y  X  K f s  X  _ y _ y r K f K
Proposition. Assume that the period of the external force T known. If a control and learning law is given as (12) and (19), t constructed , in other words , ^ f is learned , so that t
Proof. Because of the periodicity, the external forces F x expanded to the Fourier series as follows:
F  X 
F  X  Substituting them into (1), the next equation is obtained:
I  X  y MLgS Using the definition of Y r , i.e., (14)
I  X  y MLgS is obtained. Subtract (25) from (24), we obtain
I  X   X  y  X  y r  X  X  t Y r s :  X  26  X  Furthermore, from (10), we also get
IK
K _ t Subtract (27) from (26),
I  X  y  X  i.e., IK _ s  X  t Y r f  X  29  X 
V  X  1  X  K I Is 2  X  f T G 1 f  X  ,  X  30  X  where f  X  ^ f f :  X  31  X 
Note that _ f  X  _ ^ f since f is constant. Then, _ V  X  K
I Is _ s  X   X  X  t Y r f  X  s  X  _ ^ f T G 1 f  X  X  Yr ^ f K d s Y r f  X  s  X  X  G Y  X  K d s 2  X  Yr f s s T Y r f  X  K d s 2 r 0  X  32  X  and  X  V  X  2 K d s _ s :  X  33  X  the boundedness of the s and f . Next, the boundedness of s implies the boundedness of y and _ y , while the boundedness of f is bounded since the left-hand side of (29) is bounded. Accord-
The boundedness of  X  V ensures that _ V -0 when t -1 based on the Lyapunov-like lemma ( Slotine et al., 1991 ). This implies s
Accordingly, the update of ^ f leads t fb to zero. &amp; 3.3. Period estimation of external force
The formulation of the previous section requires that the period of the external force is known. However, the period is generally unknown beforehand or varies with the situation. Thus, its the observation of the ankle joint motion: the ankle joint moves with the same period as that of the periodic external force if the balance is maintained. Because the period is uniquely determined
For this estimation, the effect of low pass filter was utilized in our previous paper ( Ito et al., 2005 ). However, the generated sinusoidal function was somewhat deformed, which does not always lead to the good learning result. This is why the other method based on the local autocorrelation is introduced.
The angular frequency is estimated by the following steps. 1. The trajectory of the ankle joint angle is stored back in time during the interval T s from t 0 . This trajectory is put to y y  X  t , t 0  X  X  y  X  t 0  X  t  X  X  T s r t r 0  X  :  X  34  X  r  X  t  X  X 
Here, / a  X  t  X  , b  X  t  X  S T s  X  3. This r ( t ) should be nearly equal to 1 with every interval T because of its periodicity. Thus, the time t max ( k ) which gives the local maximal value beyond a threshold r 0  X  o 1  X  is memorized. Here, k is an integer denoting the order of the maximal value. 4. ^
T e is calculated by averaging some t max  X  k  X  t max  X  k 1  X  with every time interval T p . Then, the estimated value of the angular frequency ^ o e is obtained by the following equation: ^ o e  X  2 p = ^ T e :  X  37  X  5. The basic angular frequency in Fourier expansion o is adjusted as the dynamics with the first order lag _ o  X  k o  X  o ^ o e  X  X  38  X  to avoid the discontinuous changes of the angular frequency.
When the basic angular frequency is estimated, its higher harmonics are obtained by the following recurrence equation: cos n o t sin n o t  X 
Here, let us reconsider the construction of Y r in (14). S are directly related to the periodic external force: the basis functions of the expansion of the periodic external force. Y contains such variables as y , _ y that are not directly related.
However, y and _ y result in periodic if the balance is maintained under the periodic external force. This fact allows the left-hand side of (24) to be wholly expressed as the Fourier series with the basic angular frequency o e . Namely, Y r is reconstructed as
Y  X  X  sin o t , cos o t , ... , sin n o t , cos n o t  X  40  X  and the left-hand side of (13) is expressed using (40) as well as that consists of the Fourier coefficients. These definitions are adopted in the following simulations and experiments. 4. Simulation 4.1. Period estimation and torque pattern learning 4.1.1. Purpose
The first simulation investigates the efficiency of the period estimation method based on the local autocorrelation, and examine whether the torque trajectory is certainly stored to the feedforward controller as the motion pattern generator. 4.1.2. Conditions
The adaptive posture change as well as the torque pattern learning was simulated for the static balance model that is mentioned in Section 2.2. The link parameters are M  X  0.50kg, L  X  0.2m,  X   X  0 : 05m, I  X  0.025kgm 2 . Three controllers are com-pared. They are applied to the same control law (12) and learning law (19), but differ in the period estimation algorithm, i.e., controller with (i) no period estimation. o is fixed to 1Hz; (ii) period estimation based on the low-pass filter (proposed in (iii) period estimation using local autocorrelation (proposed in
In each controller, the same values are set to the following Learning starts at 5s. The external force is imposed by the following equation: F  X  Mg sin a ,  X  41  X  F  X  Mg  X  1 cos a  X  ,  X  42  X  gradient a . a is set in the following three manners: (a) a  X  A sin2 p f , A  X  5 1 , f  X  0.5Hz. (b) a  X  A sin2 p f , A  X  5 1 , f  X  1Hz. (c) a  X  A 1 sin2 p f 1  X  A 2 sin2 p f 2 , A 1  X  A 2  X  3 1 , f The 4th-order Runge Kutta method is used with the step size 1ms. 4.1.3. Results
The torque trajectory t with its feedforward and feedback components t ff and t f b are depicted in Figs. 4, 5 and 6 , top. For the controller (iii), the estimated angular frequency is shown in the bottom.

The controller (i) without the period estimation can learn the torque trajectories only if the external force has the same period trajectories cannot be copied to the feedforward controller completely, as shown in Fig. 4 (b) and (c).

The controller (ii) can learn simple periodic trajectories with various period, as shown in Fig. 5 (a) and (b). However, complex periodic trajectory that contains multiple frequency components cannot learn completely, as shown in Fig. 5 (c).
On the contrary, the controller (iii) that is proposed in this paper can learn even complex periodic trajectories, as shown greatest common divisor of f 1  X  0.5Hz and f 2  X  0.75Hz. 4.2. Feedback effect of ground reaction force 4.2.1. Purpose
A remarkable feature of our control and learning method is to make an effective use of the ground reaction force feedback, though many conventional methods, typically a well-known PD control, usually contain only the feedback of the joint angle deviations/velocities. Here, our method is compared to the PD control by setting zero or non-zero value to the parameter K an advantage of our method is demonstrated. 4.2.2. Conditions
A case where our method shows a noticeable advantage is that the periodic external force contains the bias component. Thus, the set as  X  A sin  X  2 p ft  X  A bias , A  X  0 : 1rad , f  X  1Hz , A bias
The controller (iii) using the local autocorrelation to the period
K  X  0.3 as our proposed feedback controller. The upright posture
Any other parameters are the same as the previous section. 4.2.3. Results
The PD control is designed to keep the ankle joint angle
And, the ankle joint torque is certainly learned: Feedback torque becomes zero, while the total torque is wholly composed of the feedforward component, as shown in Fig. 7 (c). However, the they must be always positive, but FT sometimes takes negative values in Fig. 7 (b). It implies that the robot tumbles by the PD control in the actual experiment.

The controller containing the ground reaction force feedback, on the other hand, drives the ankle joint periodically around forward slanted position. This motion is confirmed as a sinusoi-torque learning is completed as shown in Fig. 8 (c).
In conclusion, our control law brings the robustness to the biped balance against the external forces. See also Ito and
Kawasaki (2005) . 5. Experiments 5.1. Apparatus
A simple robot, as shown in Fig. 9 (a), is used to confirm the has only 1 1 of freedom of motion at the base joint. The length of the upper link is 0.5m, the base link is 0.1m. The weight is 0.52kg. The base joint at the center of the base is 0.046m height from the ground. Four small loadcells (force sensors) are attached components of the ground reaction forces are measured. The installed in the motor that drives base joint.

To impose the periodic disturbance, the slope stand as shown in Fig. 9 (b) is utilized. The robot is made to balance on this periodically moving slope stand in the experiment.

The angle of the base joint as well as the slope stand is detected by the signal from the rotary encoder of the motor. This signal is input to the personal computer as the controller through from the loadcells are also input through the AD converters via strain gage amplifier. And the motors are driven by the signal from the DA converter through the motor driver. The control signal is generated in every 2ms. 5.2. Conditions
Three cases are examined. In the case (a), the period of the external force is given correctly and thus its estimation is not necessary. The external force is generated using slope stand. The slope angle a controlled using PD controller whose reference is given by the sinusoidal function  X  A sin2 p f ,  X  44  X  where A  X  0.12rad and f  X  0.1Hz. The case (b) requires the period estimation. The slope angle is changed followed by the reference adding up two sinusoidal waves:  X  A 1 sin2 p f 1  X  A 2 sin2 p f 2 ,  X  45  X  where A 1  X  0.072rad (  X  2.5 1 ), A 2  X  0.105rad (  X  6 1 ), f f  X  0.2Hz. The gains of the PD controller are 6.6 for proportional gain and 0.3 for the derivative gain.

The control law (12) and the learning law (19) are adopted to the controller with the following gain settings. K d  X  3.5, K K the period estimation is unnecessary for the case (a). 5.3. Results and discussions The results of the above three conditions are shown in Fig. 10 . is gradually replacing the feedback torque is observed as expected. However, the feedback torque does not completely a mechanical problem: the robot as well as the slope stand has small backlash in gears of motor. This backlash prevents the robot from repeating exactly the same motion, although it can be easily achieved in the simulations. The mechanical strain around the base joint may be another problem.

In the cases (b) and (c), based on the period estimation of the external force, the learning progresses so that the feedback component decreases and is gradually being replaced by the feedforward component. However, this also does not completely converge to zero. The remaining vibrations are of the same magnitude as the case (a), implying that results better than case (a) are not expected in this robot system. Accordingly, we can conclude that the torque is surely learned to the motion pattern generator, and that torque pattern generation become less dependent on the feedback signal of the ground reaction forces. 6. Discussion
This paper addresses adaptive aspects of animal motion from the viewpoint of control and learning by taking static balance as an example. The timescale in patterns of motion is focused on. stabilized against sudden disturbances like environmental fluc-tuations. On the other hand, the motion pattern should be variable, i.e., be adjusted with respect to long-term variations the former is expressed as a temporary external force, while the latter occurs as a rather permanent environmental change, such as a change of the ground slope with the standing position.
To cope with external forces with different timescales, a is stabilized by the control scheme prepared for the temporary external force, while a new pattern is stored to the motion generator as a torque pattern by the learning scheme in response to the periodic disturbance. Here, information on the ground balancing situation. This is why balance is maintained based on feedback about the ground reaction forces in our control scheme. However, in the stationary condition where a periodic distur-bance is exerted, the torque trajectory is learned as a motion pattern. After learning, the feedback information on the ground reaction force is no longer required: The balance can be maintained by the adaptively acquired torque trajectory in a feedforward manner. This is equivalent to a sensorless control. To achieve the sensorless control, the information on the controlled object or environment should be acquired in the controller. robots.

When non-periodic external force is exerted, the feedback controller handles them. However, stationary balancing motion never emerge from such non-periodic external force: a constant motion pattern that achieves the balance maintenance is not able to be acquired since such pattern cannot be embedded in advance in the controller if the external force is not predictable. The experimental result in Section 5 states it well: unpredictable mechanical vibration and slippage due to static frictions and disturbances with low repeatability. Although such non-periodic component is compensated by the feedback controller, it cannot be learned, which is shown as fine fluctuations of the feedback component in Fig. 10 . In summary, our control method is constructed by combining the motion pattern generator coping with periodic excitement with a feedback controller to handle non-periodic disturbances. This dual control strategy allows us to simultaneously processes the following two tasks; the balance maintenance with respect to not only periodic but also non-periodic disturbances, and the learning of the periodic component of the control torque.

Extending a problem in our previous work ( Ito et al., 2005 ), this paper treats the uncertainty of the period of the external tion is introduced. This method requires a high-performance feedback controller that produces stable response to the periodic external forces, because the period is estimated from the periodic the period estimate becomes unstable or fluctuated, which resets the learning of the motion pattern described as Fourier coeffi-cients expanded by sinusoidal function with this estimated period. In such a case, the learning does not converge for quite a while. The high-performance feedback controller is also needed to the learning of an adequate motion pattern, since the motion pattern to be learned is a copy of the output of the feedback controller. To enhance the performance of the feedback controller, we introduced here the information of the ground reaction forces, which provides the robustness to the biped balance as shown by simulations in Section 4.2. In addition to the enhanced feedback controller, our approach brings advantages compared to the sole feedback controller in the point that the feedforward controller automatically generates an adequate motion pattern, i.e., torque trajectory independent of the sensory feedback. Furthermore, such a motion pattern is adjusted on-line collaborated with the feedback controller, although this process requires sensory information.

Finally, the ankle strategy should be discussed. The ankle strategy is well-described by an inverted pendulum model. Because of its typicality and simplicity, many studies on the human posture control adopt an inverted pendulum model from so on, Gatev et al., 1999; Masani et al., 2006; Qu et al., 2007 ). Focusing on the ground reaction forces, we also assume the ankle strategy in this paper, because disturbances by external forces so rapid in a problem example shown in Fig. 1 . Actually, the frequency of the external force in experiments is not more than 0.2Hz (Max. 8.5 1 ). In a study of human motion measure-ment, the disturbances applied to the human upright posture by the moving platform is 0.5Hz (Max. 15cm) ( Van Ooteghem et al., 2008 ), where the strategy gradually shifted from the ankle strategy to the multi-segment control. Thus, the ankle strategy is a valid assumption in the condition of this paper. However, transition among the strategy by learning is reported to actual human static balance. To extend our study, the discussions on the control and learning will be required beyond the framework of the ankle strategy. 7. Conclusion
This paper treated a biped balance control and learning when an unknown periodic external force is exerted. In this case, a human learns a motion pattern by which the biped balance is maintained with performing the stabilization task.

The above process is formulated with dynamical equations using an inverted pendulum model based on the ankle strategy. Thanks to the feedback controller based on the ground reaction force, the stationary posture adaptively changes with the external force. To store the feedback torque trajectory of this controller when a periodic external force is imposed, the motion generator is prepared in parallel. Then, the dynamics of the balancing motion is expanded to a Fourier series. The local autocorrelation of the frequency of the Fourier expansion. Next, Fourier coefficients are learned in the motion generator to replace the feedback torque trajectory by the feedforward one. In this learning, the decrement of the feedback component in the total torque output is ensured based on a Lyapunov-like lemma.

In a computer simulation, the acquisition of the torque trajectories is confirmed against unknown periodic external forces with various periods. A similar tendency toward acquiring the torque trajectories is also observed as an actual physical phenomenon using a robot. However, the torque pattern is not learning, due to some mechanical problems.

The periodicity assumption in the external forces is expected to be extended to the control of locomotion. Because stationary locomotion is regarded as periodic activity, forces disturbing the to the motion planning or pattern generation of locomotion is considered as our future works.
 Acknowledgements
This work was partially supported by the Ministry of Educa-tion, Culture, Sports, Science and Technology-Japan, Grant-in-Aid (22500173).
 References
