 Question-and-answer (Q&amp;A) websites, such as Yahoo! An-swers, Stack Overflow and Quora, have become a popular and powerful platform for Web users to share knowledge on a wide range of subjects. This has led to a rapidly grow-ing volume of information and the consequent challenge of readily identifying high quality objects (questions, answers and users) in Q&amp;A sites. Exploring the interdependent re-lationships among different types of objects can help find high quality objects in Q&amp;A sites more accurately. In this paper, we specifically focus on the ranking problem of co-ranking questions, answers and users in a Q&amp;A website. By studying the tightly connected relationships between Q&amp;A objects, we can gain useful insights toward solving the co-ranking problem. However, co-ranking multiple objects in Q&amp;A sites is a challenging task: a) With the large volumes of data in Q&amp;A sites, it is important to design a model that can scale well; b) The large-scale Q&amp;A data makes ex-tracting supervised information very expensive. In order to address these issues, we propose an unsupervised N etwork-based C o-R anking framework (NCR) to rank multiple ob-jects in Q&amp;A sites. Empirical studies on real-world Yahoo! Answers datasets demonstrate the effectiveness and the ef-ficiency of the proposed NCR method.
 H.2.8 [ Database management ]: Database applications-Data mining Q&amp;A Networks; Unsupervise; Co-Ranking; Interrelation-ships
Over the past few years, question-and-answer (Q&amp;A) sites, such as Yahoo! Answers, Stack Overflow and Quora, have provided a new way for Web users to share knowledge on a wide range of subjects. Individuals can conveniently ad-dress specific needs to the public and get first-hand replies. These Q&amp;A sites have exploded in popularity. Yahoo! An-swers, the first and largest Q&amp;A site, had 7,000 new ques-tions and 21,000 new answers posted per hour in July, 2012 [18]; Stack Overflow, a Q&amp;A site for computer program-mers, had over 1.9 million registered users and more than 5.5 million questions in August, 2013. These repositories of valuable knowledge provide a gold mine for information retrieval and automatic question answering.

Since the Q&amp;A site allows anyone to contribute knowledge on the Web, the quality of its objects (questions, answers and users) varies dramatically. On Yahoo! Answers, the answers provided by experts are detailed and useful, while others, provided by non-experts, may even contain spam and junk information. This is true for other types of objects as well. Some questions become popular in a short period of time and they get thousands of answers. In contrast, some questions are ridiculous and fail to get any answers. Distin-guishing high quality objects from low quality ones can help improve the service offered by Q&amp;A websites. Therefore, the problem of object ranking in Q&amp;A sites has received considerable attention in the last few years [13, 10, 29].
Most conventional approaches of object ranking in Q&amp;A sites focus on a single type of object. For instance, the works in [2, 13] investigated how to evaluate or predict the quality of questions, and [29, 23] aim to find high quality answers. In reality, the multiple types of objects are interrelated, e.g., good questions often attract high quality answers from com-petent users. Exploring the interrelationships among differ-ent types of objects can help identify high quality objects in Q&amp;A sites more effectively.

In this paper, we specifically focus on the ranking prob-lem of co-ranking questions, answers and users in a Q&amp;A website. Studying the co-ranking problem has many ben-efits to real-world applications. With high quality objects, Q&amp;A websites can recommend the most trendy information to users. In addition, the top objects under a certain topic or over all the topics can help improve user engagements because individuals can have a quick tour over popular in-formation in the community. Furthermore, the co-ranking performance can be considered as an important signal for answer vertical search and web search. Integrated with such query independent signal, we can better rank the relevant questions, answers and users for a certain query. By study-ing the tightly connected relationships among different types of objects, we can gain useful insights toward solving the co-ranking problem. However, this is a challenging task due to the following reasons:
In order to address these issues, we model a Q&amp;A site as a heterogeneous network, and capture the interdependent re-lationships to infer the popularity of questions , interesting-ness of answers and contributions of users simultaneously. Take the ranking of questions for example, Yahoo! Answers simply ranks the questions according to the number of an-swers they have. However, we observe in Section 3 that the popularity of a question does not depend on how many an-swers it attracts but on the interestingness of those answers, which is a common heuristic similar to the PageRank [7] principle. For instance, a question ( X  Is 1+1=2?  X ) attract-ing 100 boring answers ( X  Yes  X  or  X  No  X ) is much less popu-lar than a question ( X  Why do cats act like monkeys?  X ) attracting 10 interesting answers. We consider such interde-pendencies in our co-ranking model.

In summary, our contributions can be summarized as fol-lows:
In this section, we first introduce several related concepts and notations. Then, we will formally define the problem of co-ranking multiple types of objects in Q&amp;A networks.
Definition 1. Heterogeneous Q&amp;A Network : A het-erogeneous Q&amp;A network is a special kind of information network, which is represented as a graph G = ( V, E ). V is the set of nodes (objects), including t types of objects T 1 = { v 11 , ..., v 1 n 1 } , ..., T t = { v t 1 , ..., v the set of links (relations) between the nodes in V , which involves multiple types of links. The network of Yahoo! An-swers is shown in Figure 1. It involves three types of objects, i.e., users (U), questions (Q) and answers (A), and three types of links, i.e., askedBy , answeredBy and givenBy .
In heterogeneous Q&amp;A networks, each type of link repre-sents an unique binary relation R from node type i to node type j , where R ( v ip , v jq ) holds iff object v ip and v lated by relation R . R  X  1 denotes the inverted relation of R , which holds naturally for R  X  1 ( v jq , v ip ). Let dom ( R ) = T denote the domain of relation R , range ( R ) = T j denotes its range. For example, in Figure 1, the link type  X  askedBy  X  can be written as a relation R between question nodes and user nodes. R ( v ip , v jq ) holds iff question v ip is asked by user v jq . Given a Q&amp;A network, we can define different adjacent matrices according to the different types of links as follows:
Definition 2. L QA matrix : E QA  X  Q  X  A  X  E is the set of answeredBy links between questions and answers. The corresponding adjacent matrix can be denoted as L QA , where L QA ( q, a ) = 1 if a question q  X  Q has an answer a  X  A , and L
QA ( q, a ) = 0 otherwise. Q and A have the relationship of 1 : n , i.e., a question may have n answers ( n  X  1) but an answer is only for a certain question.

Definition 3. L AU matrix : E AU  X  A  X  U  X  E is the set of givenBy links between answers and users. The corre-sponding adjacent matrix can be represented as L AU , where L
AU ( a, u ) = 1 if an answer a  X  A is posted by a user u  X  U , and L AU ( a, u ) = 0 otherwise. A and U have the relationship of n : 1, i.e., an answer is only from a certain user but a user may provide n answers ( n  X  1) to different questions.
Definition 4. L QU matrix : E QU  X  Q  X  U  X  E is the set of askedBy links between questions and users. The corre-sponding adjacent matrix is L QU , where L QU ( q, u ) = 1 if a question q  X  Q is asked by a user u  X  U , and L QU ( q, u ) = 0 Figure 1: The heterogeneous network in Yahoo! An-swers. Each shape represents one type of object in the network, and each arrowed line represents one type of link. otherwise. Q and U have the relationship of n : 1, i.e., a question is only asked by a certain user but a user may post n questions ( n  X  1) on Q&amp;A websites.

Given a Q&amp;A network, our goal is to rank different types of nodes simultaneously. So we define variables that quantify the qualities of questions, answers and users more precisely:
Definition 5. Popularity of questions : The popularity of a question q  X  Q  X  V (denoted by P ( q )) is a score of how popular the question q is. It indicates the question q  X  X  ability to attract hot debates or discussions. For ease of understanding and computations, we limit the range of P ( q ) to (0, 1).

For example,  X  X hy do cats act like monkeys? X  is a popular question because everyone can be involved to show diverse answers from different viewpoints.

Definition 6. Interestingness of answers : The inter-estingness of an answer a  X  A  X  V (denoted by I ( a )) is a score of how interesting the answer a is. The interestingness represents the answer a  X  X  strength to impress users. I ( a ) is within the range (0, 1).

We still take the question  X  X hy do cats act like monkeys? X  as an example, an answer  X  X hey are scared little cats and hiding from the big dogs. X  is more interesting than another answer  X  X ait.....what? X .

Definition 7. Contribution of users : The contribution of a user u  X  U  X  V (denoted by C ( u )) is a score of how the user u contributes to the Q&amp;A community. It indicates the user u  X  X  ability to ask popular questions and give interesting answers. C ( u ) is also within the range (0, 1).

For instance, a user asking 10 popular questions contributes more than one who asks 100 questions with nobody answer-ing them. Similarly, a user providing many interesting an-swers also contributes a lot to the Q&amp;A system.
Based on the node and relation types in Q&amp;A networks, the input of the co-ranking task consists of a heterogeneous Table 1: Statistics of Yahoo! Answers datasets network G = ( V, E ). V includes three types of nodes Q , A and U . E involves three types of links E QA , E AU and E Our goal is to build a general framework to simultaneously recognize high quality questions, answers and users under an unsupervised setting. In order to solve this problem, we need to address the following challenges: 1. How can one capture the interdependent relationships among a question X  X  popularity, an answer X  X  interestingness and a user X  X  contribution? 2. Based upon the interdependent relationships, how can one simultaneously rank the questions, answers and users in an unsupervised way? 3. As the network is getting larger, how can one scale up the ranking algorithm to the growth of Q&amp;A sites?
For the first challenge, we explore some observations on the real Yahoo! Answers data. Based on them, we present the interdependent relationships among the three different types of nodes in Section 3. For the second challenge, we introduce how to iteratively rank the three types of nodes based on the interrelationships in Section 4. For the third challenge, we implement the framework in a parallelized en-vironment and show the time efficiency in Section 5.
A motivation for this work is that a question X  X  popularity, an answer X  X  interestingness, and a user X  X  contribution could be strongly correlated with each other in Q&amp;A websites. Before proceeding, we first introduce real-world data used in this work and investigate whether the observations sup-port the assumption of interdependent relationships among questions, answers and users.
Yahoo! Answers is a popular Q&amp;A website where people ask and answer questions on any topic. Each question has a lifecycle. After it is posted by an asker, it stays in an  X  X pen X  state where it receives answers. Then at some point (decided by the asker, or by an automatic timeout on the website), the question is considered  X  X losed X  and can receive no further answers. At this stage, a  X  X est answer X  is selected either by the asker or through a voting procedure from other users; once a best answer is chosen, the question is  X  X esolved X . A question can also be awarded a  X  X tar X  by any user at any time, marking it as an interesting question.

We collect 169,103 resolved questions posted in April, 2013. Each of these questions has at least 5 answers and the  X  X est answer X  is selected according to the votes of other users. We also randomly select 4 subcategories and take the questions, answers and users under each subcategory as a small dataset. The data is publicly available on Yahoo! Answers and the basis statistics are shown in Table 1.
In this section, we conduct a data analysis on questions, answers and users under the subcategory of Religion &amp; Spir-ituality. We investigate some of the basic principles that Figure 2: Distributions of question stars, answer votes and user points on Yahoo! Answers. Ques-tion stars reflect the popularity of questions, answer votes show the interestingness of answers, and user points indicate the contribution of users to some ex-tent. reveal the potential interdependent relationships among the three types of nodes in the heterogeneous Q&amp;A network.
On Yahoo! Answers, a user can award a question a  X  X tar X , marking it as an interesting question. The number of stars can reflect the popularity of a question. The red bars in Figure 2 indicate that about 97% of the questions have at most 5 stars. A user can also vote an answer as a  X  X est answer X . The number of votes can reveal the interestingness of an answer. The blue bars in Figure 2 show that around 98% of the answers have at most 3 votes. A user can be awarded more points if s/he provides more answers. The number of points can reflect the contribution of a user to some extent. We can observe that around 60% of the users get points less than 3000 from the green bars in Figure 2.
Based on these statistics, we first conduct a data analysis on questions. Figure 3 (a) reveals the influences of answers and users on questions. It can be observed that if a ques-tion has more stars, its answers will have more votes and the asker will also have more points. This phenomenon il-lustrates that (1) Popular questions often attract more interesting an-swers than those questions with little popularity. (2) Popu-lar questions are likely to be asked by those high contribution users.

Then we analyze the influences of questions and users on answers. Figure 3 (b) shows the analysis. If an answer has more votes, the corresponding question usually has more stars and the user who provides the answer often has more points. This observation shows that interesting answers are usually given to those popular questions and they are often provided by those high contribution users.

We also do some analysis on the users with no more than 3000 points. Figure 3 (c) reveals the influences of questions and answers on users. If a user has more points, his/her questions often have more stars and his/her answers often have more votes. It illustrates that high contribution users would like to ask popular questions and post interesting an-swers.

The relationship between answers and users we observed is consistent with that in [3]. Furthermore, we additionally capture the relationships between a question and its asker. Based on these observations, we propose the following prin-ciples to solve the co-ranking problem in Q&amp;A networks: 1. We can identify the interestingness of an answer given the popularity of the corresponding question, plus the con-tribution of the user who posted the answer. 2. For a question, if we have the interestingness scores of its answers and the contribution score of its asker, we can infer its popularity, because a question is more popular if it attracts more interesting answers and the asker has more contribution to the system. 3. Now we go back to indicate a user X  X  contribution. Intu-itively, a user contributes more to the community if s/he asks more popular questions and gives more interesting answers. In contrast, one contributes less if one has few popular ques-tions and interesting answers.

With these observations and principles, we next introduce how to model the qualities of different types of nodes in the network-based co-ranking framework.
In this section, we propose an unsupervised N etwork-based C o-R anking model ( NCR ) and introduce the iter-ative computation algorithm for NCR. The above observa-tions and principles serve as the base of the proposed model. NCR is designed in a divide-and-conquer way to decompose the co-ranking problem into three separate types of sub-modules (as shown in Figure 4) for questions, answers and users. The interdependencies are captured through itera-tive computations to help identify high quality objects in heterogeneous Q&amp;A networks. Given a question q , we denote the set of answers for q as S ( q ) = { a i |  X  a i , L QA ( q, a i ) = 1 } . The influence of S on the popularity of q is defined as the summation of the interestingnesses of all the answers in S a ( q ), where | S a ( q ) | is the number of answers q has. We use N aq to normalize I a ( q ) on the entire question set Q so their squares sum to 1: P q  X  Q ( I a ( q )) 2 = 1.

Similarly, the set of users for q can be denoted as S u ( q ) = { u i |  X  u i , L QU ( q, u i ) = 1 } . Since each question can only be asked by a certain user, we can denote the only element as u . The influence of u q on the popularity of q can be defined in a similar way as follows: where N uq = P q  X  Q ( I u ( q )) 2 is a normalization factor on the entire question set Q so their squares sum to 1.

Depending on the influences of answers and users, we can compute the popularity of q as follows: where N q = P q  X  Q ( P ( q )) 2 is a normalization factor on the entire question set Q so their squares sum to 1. In Equation 3, we add I a ( q ) and I u ( q ) together instead of multiplying them. The reason is that if a question is newly posted with-out any answers, its popularity can still be predicted by its asker X  X  contribution. However, if we multiply I a ( q ) and I ( q ) together, the popularity becomes 0, which will cause shows the trend of influence one type of object on another type. inaccurate rankings for new questions on Q&amp;A sites. Figure 4 (a) summaries the entire process of computing the popu-larity score of a question q according to the influences of its answers and user.

In order to calculate P ( q ), we need the interestingness values of q  X  X  answers, which we define next.
To decide the interestingness of an answer, we have similar intuitions to the calculation of question popularity. Given an answer a , the answerer u belongs to U ( u  X  U ) and L
AU ( a, u ) = 1. Similarly, the corresponding question q be-longs to Q ( q  X  Q ) and L QA ( q, a ) = 1. We denote the in-fluences of u and q on the interestingness of a as I u ( a ) and I ( a ), respectively. According to Figure 3 (b), the interest-ingness of an answer is highly influenced by its question X  X  popularity and its user X  X  contribution. Figure 4 (b) repre-sents how to obtain the interestingness of a via the influences of q and u .
 I u ( a ), I q ( a ) and I ( a ) can be formulated in a similar way. where N ua , N qa and N a are three normalization factors to ensure the scale to be within the range (0, 1).
How do we judge a user? We usually consider two things when we look at a user. The first one is the answers the user provides. If the answers are very interesting and most of them are selected as  X  X est answers X , the user tend to con-tribute much to the Q&amp;A community. In contrast, if the answers are always boring (like  X  X es X ,  X  X o X  or  X  X hat? X ), we may doubt the contribution of the user. The second fac-tor is the questions the user asks. Those users are likely to contribute more if their questions are popular with lots of interesting answers. Based on these observations, we model a user X  X  contribution by considering both his/her answers and questions. Figure 4 (c) shows how to calculate the con-tribution score of a user via the influence of his/her answers and questions.
 Given a user u , we denote the set of answers u gives as S ( u ) = { a i |  X  a i , L AU ( a i , u ) = 1 } . We formulate the influ-ence of S a ( u ) on the contribution of u as the summation of the interestingness scores of all answers in S a ( u ), where | S a ( u ) | is the number of answers u provides. We use N au to normalize I a ( u ) on the entire user set U so their squares sum to 1: P u  X  U ( I a ( u )) 2 = 1.
 Similarly, the set of questions u asks can be denoted as S ( u ) = { q i |  X  q i , L QU ( q i , u ) = 1 } , and the influence of S ( u ) on the contribution of u is the summation of the pop-Algorithm 1 The NCR algorithm Input: A heterogeneous Q&amp;A network G = ( V, E ), maxi-Output: The set of popularity P , interestingness I and 1: // Initialization step 2: while NOT converged or #iteration &lt; = M ax It do 3: Update P using (1), (2) and (3) 4: Update I using (4), (5) and (6) 5: Update C using (7), (8) and (9) 6: end while ularity scores of all questions in S q ( u ), where | S q ( u ) | is the number of questions u asks. N qu P set U so their squares sum to 1.

Depending on the influences of answers and questions, we can compute the contribution score of u as follows: where N u = P u  X  U ( C ( u )) 2 is a normalization factor on the entire user set U .
Integrating all the information of the heterogeneous Q&amp;A network together, NCR adopts an iterative method to com-pute question popularity, answer interestingness and user contribution, by exploring the interdependent relationships among them. The iterative computation framework is sum-marized in Algorithm 1. The time complexity of the NCR algorithm is O ( t | E | ), where t is the iteration number and | E | is the number of links in the Q&amp;A network. Through our experiments, the algorithm converges after 3 rounds in most cases.
The proposed NCR model computes the quality of each object in Q&amp;A sites according to the quality of its linked objects. The very design of NCR makes the entire network naturally splittable when NCR calculates the qualify of ob-jects. As shown in Figure 4, the ranking results for ques-tions, answers and users can be computed in parallel at each iteration. Therefore, by extending NCR to a distributed version, we can reduce the runtime significantly. In the ex-periments, we choose to implement the distributed version of NCR on Apache Hadoop Platform using Pig Latin 1 . Pig Latin is a high-level programming language. It allows the de-veloper to specify how the algorithm is performed, while the Pig complier transforms the specifications into Map-Reduce programs. The runtime of the Map-Reduce jobs depends on how the data is split and stored on the cluster [20]. In this paper, we test the scalability of the distributed NCR algorithm by generating various numbers of data splits.
In this section, we conduct extensive experiments to eval-uate the proposed NCR framework. After introducing the experiment settings and the evaluation metric, we compare different ranking methods. Furthermore, we also study the efficiency of NCR on the large-scale network.
We test the effectiveness of the proposed NCR model on datasets showed in Table 1. In order to evaluate the per-formance, we have to generate ranking lists for questions, answers and users respectively from real Yahoo! Answers datasets. Since [13] considers stars as one metric for ques-tion quality, we use stars as the ground truth for question popularities. Wang et al. [29] use  X  X est answer X  labels to evaluate the quality of answers. However, only one  X  X est an-swer X  is selected for a question and all the other answers have the same labels. It will be biased to evaluate our ranking results using such labels. Since a  X  X est answer X  is selected through a voting procedure from other users, we use vote numbers as the ground truth for answer interestingness in our experiments. For users, we generate the ground truth of a user by considering both the stars of questions s/he asked and the votes of answers s/he provided because they reflect the contribution of users in [11]. With such rich  X  X uman labelings X  on Yahoo! Answers, we average these values and then convert them into integers in a scale from level 1 (the lowest quality) to level 4 (the highest quality) as in [13].
We set up the evaluation criterion using normalized dis-counted cumulative gain (nDCG) [9]. nDCG is a popular measure in information retrieval tasks, and it focuses on correct rankings of high quality nodes. We compare the re-sult of NCR with the ground truth for each type of node. For questions and users, we can obtain a single ranking list with the entire participating nodes and then calculate the nDCG values. However, it is different for the answers, since an answer is only useful to its corresponding question. If we rank all the answers together, it would be meaningless. So for each question, we rank its answers and calculate the nDCG value. Then we use the average nDCG value as the final evaluation of answer quality.
In order to demonstrate the effectiveness of our NCR ap-proach, we compare the following methods: All these baseline methods ignore the interdependent re-lationships in the heterogeneous Q&amp;A network (e.g., PR, CSR, etc.) or only consider incomplete relationships (e.g., HITS(UQ)).
In this subsection, we study the effectiveness of the pro-posed NCR method. Table 2 presents the comparison results for question popularity, answer interestingness and user con-tribution under the subcategory of Religion &amp; Spirituality. Due to space limit, we only show the performances of ques-tion popularity and user contribution from top 10% to 50% in Table 2 (a) and (c). Since each question has at least 5 answers, we report the average nDCG value from top 1 to top 5 for interestingness of answers in Table 2 (b). It can be observed that NCR consistently outperforms other baseline methods on the rankings of all the three types of nodes. In particular, compared with the three baseline methods PR, HITS (A) and HITS (H), all of which are focusing on the homogeneous network of users, NCR can achieve the best performance as shown in Table 2 (c). It illustrates that the interdependent relationships among questions, answers and users can help improve the ranking result of users. Moreover, although PR and HITS (A) can identify high contribution users with good results, NCR can still perform better than these two baseline methods with an improvement of at least 3.5%. Furthermore, the performance of NCR is significantly better than that of HITS (H) with an improvement of at most 24%.

Compared with the baseline method HITS (UQ) consid-ering the heterogeneous network with two types of nodes (questions and users), NCR can still have better perfor-mances on both questions and users as shown in Table 2 (a) and (c). It reveals that questions, answers and users are tightly interconnected with each other and ignoring ei-ther one type of object would weaken the co-ranking perfor-mance.

Compared with the other baseline methods RAT, RCS and RAD, which do not consider the network structure in the ranking task, NCR still achieves the best results. It shows that the interdependent relationships in the heteroge-neous network are more powerful and helpful than the time information (used in RAT) and the text information (used in RCS and RAD) in detecting high quality nodes. More-over, extracting meaningful features from text information is challenging and time-consuming. With large volumes of new questions and answers, making use of text information efficiently becomes more and more difficult.

We further show the performances of the proposed NCR model under another three subcategories in Tables 3, 4 and 5. We can observe that the performances of NCR are the best under all these subcategories except that of user contri-bution under the subcategory of Dogs. Though NCR does not perform well for user contribution, it still achieves the best results for question popularity and answer interesting-ness. Moreover, Table 4 (a) shows that NCR can achieve an improvement of at most 140% on question quality under the subcategory of Baby Names. We also present the result on the entire Yahoo! Answers data in Table 6. It reveals that NCR is robust and stable regardless of any category information.

In summary, with the help of interdependent relationships among questions, answers and users, NCR always outper-forms the baseline methods. In the next subsection, we in-vestigate more details about the efficiency of the proposed NCR framework.
In this subsection, we evaluate the runtime efficiency of two versions of NCR: single-NCR runs in Python on a sin-gle node Server (Intel Xeon TM Quad-Core CPUs of 2.26GHz and 36GB RAM) and parallel-NCR runs on a multi-node Hadoop cluster (Intel Xeon TM 2  X  Quad-Core CPUs of 2.50GHz and 16GB RAM) in Pig Latin. Parallel-NCR algorithm is complied into Map-Reduce jobs and executed over Hadoop in a distributed fashion. We use the entire dataset with ques-tions from all categories and report the runtime of these two versions in Table 7. Since the ranking results are the same no matter we run NCR in local or in parallel, we only present the runtime (in seconds) in Table 7. It can be observed that with 8-node Hadoop cluster, parallel-NCR is 6.5 times faster than single-NCR. performance. performance.
We also test the scalability of parallel-NCR with differ-ent mappers. We set the data split size (mega byte) to be 6 different numbers from 5 to 30, with an interval of 5. The smaller the data split size is, the larger the num-ber of mappers is. Figure 5 summarizes the performance of mapping time with different numbers of mappers. It can be seen that with more mappers, the mapping process becomes much more efficient. For example, if 70 mappers are used to run parallel-NCR, the mapping procedure costs 324 seconds. If we use more mappers such as 129 mappers, the mapping Figure 5: The mapping time with different number of mappers. time is reduced to 252 seconds. However, the communica-tion time will increase if we use more mappers. So in our experiment, we set the data split size as 10Mb. The total number of mappers are 129.

In summary, as the network gets larger, parallel-NCR can efficiently scale up the proposed framework to the growth of Q&amp;A sites.
User communities in online Q&amp;A websites have already been investigated from several perspectives. The first is the study of user X  X  interests and motivations for contribution [1, 21, 4, 27] in the community. These studies model the au-thority, reputation and expertise of users in social networks and communities [8, 16, 15]. The second is the study of user quality in Q&amp;A sites by developing several link-based rank-ing algorithms [11, 19, 30, 32]. For example, Zhang et al. [32] focus on the data from Java forum and construct a post-reply network, in which the nodes correspond to users and the links represent interactions between askers and answer-ers. Both ExpertiseRank (a PageRank-like algorithm) and HITS are applied in [32] to identify users with high expertise. Jurczyk and Agichtein [11] also apply the HITS algorithm to user communities and they aim to discover authoritative users in topical categories. However, all these studies fo-cus on ranking only users by extracting a homogeneous user network from Q&amp;A sites. Our study is different from them since we model the Q&amp;A site as a heterogeneous network and co-rank questions, answers and users in this network.
The study of content quality in Q&amp;A websites is also re-lated to our work. It can be categorized into two branches. The first branch investigates how to evaluate or predict the question quality [2, 13, 14]. Agichtein et al. [2] analyze the essential features related to questions and propose a su-pervised method to identify high quality content in Q&amp;A sites. [13] evaluates the question quality using a mutual reinforcement-based label propagation algorithm. [14] pre-dicts the subjectivity of questions based on a co-training model. The other branch aims to find high quality answers [10, 5, 29, 26]. Jeon et al. [10] extract non-textual features to predict the quality of answers. Sekai et al. [22] apply the graded-relevance metrics to evaluate the answer qual-ity. Bian et al. [5] introduce a ranking algorithm to retrieve high quality answers according to the user interaction and the answer relevance. Wang et al. [29] model the question-answer relationships via analogical reasoning and develop an answer ranking method. Suryanto et al. [26] aim to find good answers for newly-arrived questions by considering the answerer expertise. However, all these works do not study the quality of users. In addition, some of them [2, 13, 29, 14] require substantial amounts of manual supervision.
There are also a few research studies on the link-based ranking within heterogeneous networks. Studies in [33, 25] focus on the bibliographic data with three different types of objects, authors, publications and conferences. Zhou et al. [33] uses the heterogeneous network of authors and publica-tions to co-rank these two types of objects while [25] ranks authors and conferences by constructing another heteroge-nous network. Yin et al. [31] create a heterogeneous network of facts and websites to help discover truth in multiple con-flicting sources on the Web. Wang et al. [28] detect review spammers based on a heterogeneous online store review net-work. However, the network representations in these stud-ies are very different from that of the Q&amp;A site, therefore their techniques are not applicable to our work. Bian et al. [6] utilize the relationships among questions, answers and users to estimate the quality of these three types of objects. It is most related to our work. However, [6] uses a semi-supervised method while our work aims to rank the differ-ent types of objects in a totally unsupervised way. Another difference is that [6] separates the contribution of users into two groups, the contribution of askers and those of the an-swerers. But this separation is not realistically reasonable. User contributions should be considered as integrations of their question asking and answering behaviors. In our work, we quantify the contribution of users according to both their asking and answering activities.
In this paper, we study the problem of estimating the quality of questions, answers and users simultaneously in heterogeneous Q&amp;A networks. First we analyze real-world Yahoo! Answers datasets to demonstrate the interdepen-dent relationships among questions, answers and users. The NCR framework is then introduced to co-rank different types of objects by capturing their interrelationships in an unsu-pervised way. Extensive experiments are conducted to eval-uate the proposed NCR framework on datasets under dif-ferent topic categories. The effectiveness of the proposed model shows that interdependent relationships play impor-tant roles in ranking objects (questions, answers and users) in a heterogeneous Q&amp;A network. Furthermore, we also im-plement the NCR framework in a distributed version to test its scalability.
 There are several interesting directions for future work. In current work, we recognize high quality questions, an-swers and users based on the interdependent relationships in heterogeneous Q&amp;A networks. Since questions and an-swers have contents, one direction of our future work is to combine the content information with the interconnections to better rank different types of objects. Some previous studies demonstrate that the community activity plays an important role in Q&amp;A sites. Therefore, another direction of our future work is to add the community information into the proposed framework. Since ranking is an important sig-nal for search, we can also incorporate the co-ranking results into answer vertical search.
 This work is supported in part by NSF through grants CNS-1115234 and OISE-1129076, US Department of Army through grant W911NF-12-1-0066, and Yahoo! Labs Faculty Re-search and Engagement Program (FREP). [1] L. Adamic, J. Zhang, E. Bakshy, and M. Ackerman. [2] E. Agichtein, C. Castillo, D. Donato, A. Gionis, and [3] A. Anderson, D. Huttenlocher, J. Kleinberg, and [4] C. Aperjis, B. Huberman, and F. Wu. Human [5] J. Bian, Y. Liu, E. Agichtein, and H. Zha. Finding the [6] J. Bian, Y. Liu, D. Zhou, E. Agichtein, and H. Zha. [7] S. Brin and L. Page. The anatomy of a large-scale [8] G. Dror, D. Pelleg, O. Rokhlenko, and I. Szpektor. [9] K. Jarvelin and J. Kekalainen. Cumulated gain-based [10] J. Jeon, W. Croft, J. Lee, and S. Park. A framework [11] P. Jurczyk and E. Agichtein. Discovering authorities [12] J.M. Kleinberg. Authoritative sources in a hyperlinked [13] B. Li, T. Jin, M. Lyu, I. King, and B. Mak. Analyzing [14] B. Li, Y. Liu, and E. Agichtein. Cocqa: co-training [15] Q. Liu, E. Agichtein, G. Dror, E. Gabrilovich, [16] Q. Liu, E. Agichtein, G. Dror, Y. Maarek, and [17] M. McGee. Yahoo answers hits one billion answers. [18] M. McGee. Yahoo answers hits 300 million questions, [19] K. Nam, M. Ackerman, and L. Adamic. Questions in, [20] C. Olston, B. Reed, U. Srivastava, R. Kumar, and [21] J. Preece, B. Nonnecke, and D. Andrews. The top five [22] T. Sakai, D. Ishikawa, N. Kando, Y. Seki, [23] C. Shah and J. Pomerantz. Evaluating and predicting [24] X. Si, E. Y. Chang, Z. Gy  X  ongyi, and M. Sun. [25] Y. Sun, J. Han, P. Zhao, Z. Yin, H. Cheng, and [26] M. Suryanto, E. Lim, A. Sun, and R. Chiang.
 [27] G. Wang, K. Gill, M. Mohanlal, H. Zheng, and [28] G. Wang, S. Xie, B. Liu, and P. Yu. Review graph [29] X. J. Wang, X. Tu, D. Feng, and L. Zhang. Ranking [30] J. Yang, L. Adamic, and M. Ackerman.
 [31] X. Yin, J. Han, and P. Yu. Truth discovery with [32] J. Zhang, M. Ackerman, and L. Adamic. Expertise [33] D. Zhou, S. Orshanskiy, H. Zha, and L. Giles.
