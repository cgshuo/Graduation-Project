 Spectral clustering is one of the most popular methods for analyzing the cluster struc-ture of networks. In comparison with other classical clustering algorithms such as k-works [1]. The key reason is that, the exponential increment of time consumption and space occupation restricts the scalability of spectral clustering, especially facing up to matrix approximating algorithms for spectral clustering have been proposed. 
The Nystr X m method is a widely used and efficient low-rank matrix approximat-ing technique to speed up spectral clustering, which is able to reduce the computing and memory burdens enormously [2]. Lots of sampling techniques such as uniform sampling [3], weighted sampling [4], random walking sampling [5], k-means sam-clustering as much as possible. In common, these techniques select the interpolation points for Nystr X m method with some probabilities, which are computed in view of similarity between pairwise nodes in the networks, and the similarity computation by a metric is time-consuming. Even though based on node degrees, there is no valuable information for the judicious selection of columns and rows for a low-rank approx-simply, as well lack of enough useful information for the construction of affinity ma-to generate a low-rank matrix, which is used for the approximation of spectral cluster-ing efficiently to mine the cluster property of social networks with large scale nodes. 
Apart from link relations, if there is no other resource such as the attribute or fea-available information to motivate the approximate computing of Nystr X m method for spectral clustering? As is known to us, the triangle has a strong cluster property due to its any two vertices X  connection [7]. If we traverse the triangles in social networks and shrink the encountered triangle into a sing le node (multi-node), the accumulated edge smaller and smaller, the basic cluster structure of original networks has still been kept rithm for large-scale social networks via a pre-coarsening sampling based Nystr X m method, which embeds a new triangle-based coarsening process to make the low-rank matrix approximation of spectral clustering much more efficient and targeted. Due to the outstanding capability of identifying the objective clusters in the sampling sults [8], spectral clustering has been widely applied to many research fields such as and group the similar points into one cluster [9]. Both the procedures of the construc-are complex, which induces spectral clustering unsuitable for the problems with large data sets. Thus, a number of heuristic methods and approximation algorithms are designed to alleviate the computational burdens of spectral clustering. 
Yan et al. [10] utilized a distortion-minimizing local transformation of data to speed up the approximating process of spectral clustering. However, the clustering results are prone to the local optimum and se nsitive to the original selection because of k-means, or not steady because of RP tree. Mall et al. [11] employed a primal-dual metric is simplified to the angular cosine between pairwise data points, too much time is cost to compute the affinity matrix. 
Inspired by the original application in numerical approximate solution of integral equations [12], the Nystr X m method is introduced to generate a low-rank matrix ap-proximation for the eigen-decomposition of spectral clustering, making spectral clus-tend the computing results to the whole data set. However, the adopted sampling technique has not improved the computational accuracy. Zhang et al. [6] employed a k-means based sampling scheme to reduce the approximation error of Nystr X m me-scheme time-consuming. Belabbas et al. [14] proposed that the probability of choos-ing interpolation points for Nystr X m method was in proportion to the determinant of similarity matrix, and the Schur complement was used to analyze the Nystr X m recon-struction error. While the bigger the determinant is, the smaller the error is. 
Unfortunately, the existing spectral clustering algorithms based on the Nystr X m reasons. Firstly, no matter what sampling scheme is adopted for the Nystr X m method, most low-rank matrix approximation algorithms for spectral clustering are based on an affinity matrix, which is too time-consuming to construct due to the high com-plexity of similarity computing. Secondly, the social networks are often built on link rithm for large-scale social networks via a pre-coarsening sampling based Nystr X m method, which avoids the time-consuming pairwise similarity computation and im-proves the performance of spectral clustering. 3.1 Background The Nystr X m method is originally used to find the numerical approximations to ei-genfunction problems, which are expressed by integral equations of the form [15] as: where  X   X   X   X  denotes the probability density function, tion,  X  and  X   X   X   X  denote the eigenvalue and eigenvector of the kernel the integral equation respectively. To approximate the integral on the left of Equation (1), sample  X  interpolation points  X  X   X   X ,  X   X ,..., imate result by the empirical average is as follows: where  X   X   X   X   X  approximates  X  X  X  X  X  in Equation (1). In addition, choose from  X  X   X   X ,  X   X ,...,  X   X  as well to generate an eigen-decomposition notes the positive semi-definite matrix with elements denotes the eigenvector matrix of  X   X  and  X   X   X   X  X   X  X  X  X  is a diagonal matrix whose non-zero elements are the eigenvalue of eigenvector  X   X   X  X  X  X  and eigenvalue  X   X  in Equation (1) can be estimated by 
The eigenvector of any point  X  can be approximated by the eigenvectors of inter-polation points in  X  X   X   X ,  X   X ,...,  X   X  , because the k-th eigenvector at an unsampled point  X  can be computed by: 
As is shown above, different interpolation points to be selected will lead to differ-ent approximating results. 
How to extend the Nystr X m method to spectral clustering? Consider a trix  X  , which is partitioned as follows: by the intersection of  X  columns and  X  rows sampled in some manner,  X   X  X  denotes the submatrix consisting of elements with a sampled column label (ex-clusive) or sampled row label, respectively, and  X  submatrix consisting of the remaining elements of  X  . Suppose the eigen-decomposition of  X   X  X  is  X   X  X   X  X   X  can be extended to the original matrix  X  , and the estimation of the corresponding approximate eigenvectors are  X   X   X  X  X  X   X 
In addition, some details on the normalization of eigenvectors, the transformation which can be referred to [16] for further studies. 3.2 A Pre-Coarsening Sampling Based Nystr  X  m Method quitously, which is the most direct resource for studying social networks. Without any help of other information like attribute or feature of nodes to serve for similarity com-puting in social networks, is it possible that the task of low-rank matrix approximation based on the Nystr  X  m method for spectral clustering can proceed? At least impossible for weighted sampling, random walking sampling or k-means sampling based Nystr  X  m methods, because there is no appropriate affinity matrix to match with them. Even though an endeavor is made to search for such a matrix, it is time-consuming to compute the matrix by some similarity metrics like Cosine [17]. 
How to mine some available information from the link structure of social networks lenge to our work. Let X  X  start from an example in Figure 1. Figure 1(a) shows a link relation based network which contains many triangles. If we execute operations as network will be transformed into a smaller weighted network gradually as is shown in Figure 1(b). During the transforming process, the edges adjacent to the shrunk vertic-es in a triangle are accumulated, thus the unit edge-weight values of original network become numerical values after transformation, which can be utilized as the foundation network keeps the basic cluster topology structure of the original network. 
As is familiar to us, the three vertices of a triangle are bound to belong to the same weighted network by shrinking the traversed triangles into multi-nodes will not break work appear after transformation, which reflect the joint strength of any two nodes. In addition, some connections between nodes in the transformed network are the indirect transformation of link relation based network, which is able to be utilized for the fur-ther sampling of Nystr X m method explicitly. 
Extending the principle to the social networks, where triangles are the basic struc-tural elements, we propose a pre-coarsening sampling based Nystr first give the formulized definition of the novel triangle-based coarsening problem: Definition 1. (Triangle-based Coarsening Problem) Input: undirected, link relation based social network nodes of  X  ,  X  X  X  denote edges,  X  denote triangles, edge weight Output: undirected, coarsened weighted network  X   X   X   X   X   X   X ,  X   X ,  X   X   X   X   X  X   X  of  X   X  denote is similar to  X  ,  X   X   X  X   X  are numerical. Process: traverse  X  of  X  in an order (ascending or descending) of node degrees, { shrink it into a single multi-node  X   X  X  X  X  X  X  X  X  X  X  X  X  X   X  ; accumulate the edges adjacent to shrunk nodes  X   X  X  X  X  X  X  X  X  and reweight the corresponding remained edges
The certain order of node degrees in Definition 1 is a necessary condition, which is used to avoid the indeterminacy of generated network by coarsening the random tra-versed triangles. And if traversing and shrinking triangles in the network without any constraint, the coarsening will make the original cluster structure disappear some-times, thus to prevent this phenomenon from happening, another condition as  X  to be a multi-node just only one time  X  must be added. Figure 2 shows an example of the gen-eration of a smaller weighted network by triangle-based coarsening. We put the triangle-based coarsening as the preprocessing for sampling of Nystr Method, so the proposed pre-coarsening sampling based Nystr Definition 2. (Pre-Coarsening Sampling based Nystr  X  m Method) Input: weight matrix  X   X  constructed on the weighted network which is generated by the triangle-based coarsening.
 Output: low-rank approximating matrix  X   X  . Process: in view of  X   X  and the probability distribution  X  rows and  X  columns to generate a low-rank approximating matrix 3.3 Spectral Clustering for Larg e-Scale Social Networks sample nodes. Depending on the obtained low-rank approximating matrix eigen-decomposition of  X   X  is able to extended to the out-of-samples in approximation of spectral clustering more efficient for large-scale social networks built on link relations. We define the out-of-sample extension problem as follows: Definition 3. (Out-of-Sample Extension Problem) Input: low-rank approximating matrix  X   X  .
 Output: approximate eigenvector matrix  X   X  . Process: compute the eigenvector matrix  X   X  by  X   X   X  X  approximate  X   X  by  X   X   X  X  X  X   X   X ;  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X   X   X   X   X   X  X  In contrast to the process of pre-coarsening sampling of Nystr for the extension of eigenvectors in  X   X  , it is necessary to use k-means to group all of large-scale social networks. The implementa tion of integral process of coarsening, sampling and clustering of our spectral clustering is depicted in Algorithm 1. Algorithm 1. Spectral clustering 
Output: k clusters of  X  . 1 Begin 2  X   X  = weight matrix generated from  X  by the triangle-based coarsening; 3 S =indices of m columns sampled by probability  X   X  4  X   X   X  X   X   X  X  X  X : ; 5  X   X   X  X   X   X   X   X   X   X  ; 6  X   X   X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X   X   X  X , ; 7  X   X  X   X   X   X / X   X  X   X   X   X   X 1 ; //  X   X  X  is the approximating eigenvectors of out-of-sample 8  X   X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X   X   X   X ,  X  X   X  ; 9  X   X   X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  ; // group the approximate eigenvector matrix into k 10  X  X  X  X  X  X  X  X  X   X  X  X  X  X  X  X  X  X   X   X   X  X  by reference to  X   X  ; 11 End 3.4 Performance Analysis By virtue of the triangle-based coarsening, valuable prior information about cluster is sampling of Nystr X m method. What X  X  more, due to the intrinsic strong cluster proper-ty of triangle, the basic cluster structure of original network is maintained after coar-sening preprocessing. Therefore, via the pre-coarsening sampling based Nystr X m computational accuracy of the low-rank matrix approximation of spectral clustering can be promoted greatly. Lemma 1 (Running Time). The worst case time complexity of our algorithm is less than  X  X  X   X  X   X   X   X  X   X   X   X   X   X  X  X  X  X  X   X   X  X  X  X  X  X  X  X  X  X  , and the worst case space complexity is  X  X  X  X  X  X  , where e denotes the number of edges in network  X  of columns in matrix  X   X  ,  X  denotes the number of sampled columns from denotes the number of clusters,  X  denotes the iteration times of k-means. Proof. The process of traversing all of the triangles in the network takes cessary to do the traversing, because the triangles adjacent to the shrunk nodes become unavailable, so the time complexity of generating matrix Algorithm 1, the consuming time is  X   X   X   X   X   X  X  X  X  X  X   X   X  on  X  only needs  X  X  X  X  X  X  X  operations (neglect the time of normalizing the time complexity of our algorithm is less than  X  X  X  X  X  X  X  in the worst case. In the process of approximate computing of spectral cluster-stored is  X  X  X  , so the memory usage of our algorithm is 4.1 Dataset and Experiment Setup Our experiments are designed on the dataset of large-scale social networks which are collected from Stanford University X  X  SNAP networks [19]. The details of each social network are listed in Table 1. Our spectral clustering algorithm for large-scale social networks is realized by a pre-coarsening sampling based Nystr X m method. To test our algorithm X  X  performance, we compare the pre-coarsening sampling with uniform sampling [20], weighted sampling [21], k-means sampling [6] and incremental sampling [22]. Our pre-coarsening sampling can proceed explicitly based on the link relations of social networks, but the weighted sampling, k-means sampling and approaches to compute the similarity matrices firstly. Therefore, we design two sub-computations for the latter three sampling techniques. normalized mutual information (NMI) [23] to evaluate the clustering performance of Nystr X m methods. In general, the larger NMI is, the better the clustering results are. 
We perform all the experiments on a Linux machine with 4Core 2.6GHz CPU and 8G main memory. The implementations of all algorithms are in Java. Moreover, we repeat to run each algorithm 30 times to obt ain an average result of NMI, making the analytical results more accurate. 4.2 Experimental Results and Analysis The spectral clustering results corresponding to different social networks are dis-played in Figure 3, along with the running time of different algorithms in Figure 4. 
From Figure 3(a) we can observe that, our spectral clustering algorithm outper-based on the weighted sampling, k-means sampling, and incremental sampling. 
By contrast, we analyze the clustering results in Figure 3(b). There is no doubt that the accuracy of clustering results of our algorithm is superior to the others. And with the weighted sampling, k-means sampling, and incremental sampling excel the ones of the uniform sampling based algorithm. Besides, when the sampling probabilities of different columns of matrix are identical, the temporarily adopted uniform random sampling among these columns will degrade the performance of our algorithm, so some exceptions appear in LiveJournal, Twitter and Friendster of Figure 3(b). 
Subsequently, let us compare the running time between different algorithms (note that we just do comparison in the case of adding similarity matrices). It is obvious that in Figure 4, the algorithm based on the k-means sampling technique spends much more consists in the inherent iterative computing complexity of k-means as an unsupervised method. Because of the relative easier sampling technique, the time consuming of the other algorithms is so small to be neglected in contrast to the k-means sampling based algorithms except for the uniform sampling based algorithm. This is because that much are based on the weighted sampling and incremental sampling. This paper proposes a spectral clustering al gorithm for large-scale social networks via a pre-coarsening sampling based Nystr X m method. By virtue of a new triangle-based link relation based social network, which reveals some useful prior information about cluster, and then executes an efficient sampling for the Nystr X m method to generate a low-rank matrix approximation for the eigen-decomposition of spectral clustering. Due to the cluster property of triangle, the process of coarsening maintains the origi-nal cluster topology structure. Moreover, the pre-coarsening sampling based Nystr X m method makes spectral clustering capable to analyze the social networks explicitly without any other available information except for link relations, promoting the com-demonstrate that our algorithm outperforms the state-of-the-art spectral clustering algorithms, which are based on other sampling techniques for the Nystr X m method. 
