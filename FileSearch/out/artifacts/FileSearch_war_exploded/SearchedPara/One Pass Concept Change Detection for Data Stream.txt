 Data stream mining has been the subject of extensive research over the last decade or so. The well known CVFDT [1] algorithm is a good example of an early algorithm that proposed an incremental approach to building and maintaining a decision tree in the face of changes or concept drift that occur i n a data stream environment. Since then there has been a multitude of refinements to CVFDT (such as [2]) and to other methods [3] [4] that perform other types of mining such as a clustering and association rule mining.

The fundamental issue with data stream mining is to manage the sheer volume of data which grows continuously over time. A standard method of coping with this issue is to use a fixed size window of width w , where only the most recent w instances are used to update the model built [5]. While this method is conceptually appealing, the major limitation is that concept change can occur at intervals that are quite distinct from the window boundaries. If rapid changes o ccur within a window, then these multiple changes will be undetected by the mining algorithm thus reducing the effectiveness of the model generated. Ideally a data stream algorithm should use long periods of stability to build a more detailed model whereas in time of rapid change the window needs to be shrunk at each change, the data representing the old concept be purged and the model updated with the new concept. Concept change detection with variable-sized adaptive windows has received very little attention compared to the well established area of algorithm development for data stream mining.

The methods proposed for concept change detection with adaptive windows all suf-fer from limitations with respect to one or more key performance factors such as high computational complexity, poor sensitivity to gradual change or drift, or the opposite problem of high false positive rate. In this research we propose a novel concept change detection method called OnePassSampler and compare it with the state-of-the-art con-cept change detector, ADWIN2 [6]. Our empi rical results show that OnePassSampler has a lower false positive rate and significantly lower computational overheads than ADWIN2. OnePassSampler, as its name suggests makes only a single pass through its memory buffer and employs a simple and efficient array structure to maintain data about the current window. With ADWIN2 every new data block that arrives triggers a reassessment of candidate cut points previously visited, thus making it a multi-pass algorithm with respect to its internal memory buffer.

The major contributions made by this research are: a robust one pass algorithm for concept drift detection that has low memory and run time overheads while offering a rigorous guarantee on the false positive rate. The rest of the paper is as follows. Section 2 reviews the major research relating to concept drift detection. In Section 3 we describe our novel approach to drift detection with the formulation of a model, the derivation of a test statistic and the one pass algorithmic approach that is the key to low overheads. Section 4 presents a concep tual comparison between OnePassSampler and ADWIN2. Section 5 presents our empirical results and we conclude in Section 6 with a summary of the research achievements and some thoughts on further work in the area of concept change detection. The concept drift detection problem has a classic statistical interpretation: given a sam-ple of data, does this sample represent a single homogeneous distribution or is there some point in the data (i.e the concept change point) at which the data distribution has undergone a significant shift from a statistical point of view? All concept change de-tection approaches in the literature formulate the problem from this viewpoint but the models and the algorithms used to solve this problem differ greatly in their detail.
Sebastiao and Gama [7] present a concise survey on change detection methods. They point out that methods used fall into four basic categories: Statistical Process Control (SPC), Adaptive Windowing, Fixed Cumulative Windowing Schemes and finally other classic statistical change detection methods. Early Drift Detection Method (EDDM) [8] works on the same basic principle as the authors earlier work but uses different statistics to detect change. More recently Bifet et al [6] proposed an adaptive windowing scheme called ADWIN that is based on the use of the Hoeffding bound to detect concept change. The ADWIN algorithm was shown to outperfo rm the SPC approach and has the attrac-tive property of providing rigorous guarantees on false positive and false negative rates. ADWIN maintains a window ( W ) of instances at a given time and compares the mean difference of any two sub windows ( W 0 of older instances and W 1 of recent instances) from W . If the mean difference is statistica lly significant, then ADWIN removes all instances of W 0 considered to represent the old concept and only carries W 1 forward to the next test.

An improved version of ADWIN called ADWIN2[6] was also proposed by the same author which used a variation of exponential histograms and a memory parameter, to limit the number of hypothesis tests done on a given window. ADWIN2 was shown to be superior to Gama X  X  method and fixed size window with flushing [9] on perfor-mance measures such as the false positive rate, false negative rate and sensitivity to slow gradual changes [6]. Despite the improvements made in ADWIN2, some issues remain namely, the fact that multiple passes on data are made in the current window and an improvement in the false positive rate for noisy data environments. We start by defining in formal terms the problem that we address in this research. We then describe some generic principles that govern our change detector model. A test statistic is then derived that will be used in the change detector algorithms that we pro-pose. We present a memory management strategy that supports incremental sampling with the use of a fixed size buffer in the form of a reservoir. 3.1 Change Detection Problem Definition Concept Chang e Detection. Let S 1 =( x 1 ,x 2 ,...,x m ) and S 2 =( x m +1 ,...,x n ) with 0 &lt;m&lt;n represent two samples of instances from a stream with population means  X  1 and  X  2 respectively. Then the change detection problem can be expressed as testing the null hypothesis H 0 that  X  1 =  X  2 that the two samples are drawn from the same distribution versus the alternate hypothesis H 1 that they arrive from different distributions with  X  1 =  X  2 . In practice the underlying data distribution is unknown and a test statistic based on the sample means needs to be constructed by the change detector. If the null hypothesis is accepted incorrectly when a change has occurred then a false negative is said to have taken place. On the other hand if H 1 is accepted when no change has occurred in the data distribution then a false positive is said to have occurred. Since the population mean of the underlying distribution is unknown, sample means need to be used to perform the above hypothesis tests. The hypothesis tests can be restated as: Accept hypothesis H 1 whenever Pr ( |  X   X  S 1  X   X   X  S 2 | )  X  ) &gt; X  ,where  X  lies in the interval (0 , 1) and is a parameter that controls the maximum allowable false positive rate, while is a function of  X  and the test statistic used to model the difference between the sample means.
 Detection Delay. Due to the use of sample data to infer changes in the population, detection delay is inevitable in any concept change detector and is thus an important performance measure. Detectio n Delay is the distance between ( m +1) and m ,where m is the instance at which change is detected . In other words, detection delay equals: m  X  ( m +1) . 3.2 OnePassSampler Conceptual Change Detection Model Our change detector is designed to widen its applicability to streams with different char-acteristics while yielding comparable pe rformance, accuracy and robustness to methods such as ADWIN2. OnePassSampler has the following properties, as illustrated in our experimentation: (1) is oblivious to the unde rlying data distribution, and (2) is inexpen-sive in terms of computational cost and memory.
 Core Algorithm Overview. We first provide a basic sketch of our algorithm before discussing details of hypothesis testing. We use a simple example to illustrate the work-ing of the algorithm. OnePassSampler accumula tes data instances into blocks of size b. When attached to a classifier that uses OnePassSampler to detect change points, input data instances consists of a binary sequenc e of bits where binary 1 denotes a misclassi-fication error and binary 0 denotes a correct classification decision. We use a block of data instances as the basic unit instead of in stances as it would both be very inefficient and unnecessary from a statistical point of view to test for concept changes at the arrival of every instance.

Suppose that at time t 1 blocks B 1 and B 2 have arrived. OnePassSampler then checks whether a concept change has occurred at the B 1 | B 2 boundary by testing H 1 above. If H 1 is rejected then blocks B 1 and B 2 are concatenated into one single block B 12 and H 1 is next tested on the B 12 | B 3 boundary. In this check the sample mean of sub-window B 12 is computed by taking the average value of a random sample of size b from the sub-window of size 2 b . This sample mean is then co mpared with the sample mean computed from block B 3 , also of size b. This process continues until H 1 is ac-cepted, at which point a concept change is declared; instances in the left sub-window are removed and the instances in the right sub-window are transferred to the left. At all testing points equal sized samples are used to compare the sample means from the two sides of the window. The use of random sampling accelerates the process of the computation of the sample mean while maintaining robustness. The use of the aver-aging function as we shall see from our experimentation helps to smooth variation in the data and makes OnePassSampler more robust to noise than ADWIN2. In essence, OnePassSampler does a single forward scan through its memory buffer without the use of expensive backtracking as employed ADWIN2. While the use of random sampling ensures that sample means can be computed efficiently, a memory management strategy is required to ensure efficient use of memory as the left sub-window has the potential to grow indefinitely during periods of long stability in the stream.
 Use of Bernstein Bound. Our approach relies on well established bounds for the differ-ence between the true population and sample mean. A number of such bounds exist that do not assume a particular data distribution. Among them are the Hoeffding , Chebyshev , Chernoff and Bernstein inequalities [10]. The Hoeffding inequality has been widely used in the context of machine learning but has been found to be too conservative [6], over estimating the probability of large deviations for distributions of small variance. In contrast , the Bernstein inequality prov ides a tighter bound and is thus adopted in our work.
 The Bernstein inequality states the following: where X 1 ,...,X n are independent random variables, E [ X ] is the expected value or population mean, X i  X  [ a,c ] and  X   X  is the sample variance.
 Memory Management in OnePassSampler. As OnePassSampler never re-examines previous candidate cut points it does not need to maintain a history of such cut-points and thus does not need to store memory synopses in the form of exponential histograms as ADWIN2 does. Instead, OnePassSampler only requires the means of its left and right sub-windows. In order to efficiently support the computation of sample averages a random sampling strategy is employed.

In addition to improving efficiency, random sampling is also necessary to satisfy the independence requirement for data used i n the computation of the Bernstein bound. In a data stream environment independence between data instances in the same locality may not always be true as changes in the underlying data causes instances arriving after such a change to have very similar data characteristics, thus violating the independence property. One simple and effective method of addressing this dependence effect is to perform random sampling.

Our memory management strategy is based on the use of arrays to store blocks of data. An array enables fast access to specific data blocks that are sampled via the use of random sampling. The array is used to capture data in OnePassSampler X  X  memory buffer. The memory buffer is divided into a left sub-window and a right sub-window, each of which uses an array for storage. When a new data block arrives, the block is temporarily inserted into the right sub-window and the sample means from the two sub-windows are compared to check for statistically significant differences. If no such difference exists, data in the right sub-window is copied into the left sub-window and is then removed from the right sub-window. Essentially this means that the left sub-window consists of a set of largely homogeneous blocks. In this context, it is more efficient from a memory point of view to slide the oldest w b block from the sub-window, where w is the width of the window and b is the data block size.
 In certain circumstances the right sub-window may hold more than one data block. This happens when OnePassSampler enters a w arning state after which newly arriving data blocks are added to the right sub-window instead of the left sub-window. A warn-ing state is triggered when the mean of the data block in the right sub-window is not significantly different from the mean in the left sub-window on the basis of the drift confidence value 1  X   X  drift but is significantly different with respect to a warning con-fidence value 1  X   X  warning . In cases when a warning state is entered a sliding window scheme is used for the right sub-window as well.

Given the OnePassSampler X  X  worst case memory requirements are bounded above by 2 w as two memory buffers are allocated of size w for each of the two sub-windows. We experimented with different values of w and show that the quality of change detection (false positive rate, false negative rate and detection delay) is largely insensitive to the size of w , provided that w exceeds the block size b . 3.3 Computation of Cut Point Threshold We now establish the value of the cut threshold against a null hypothesis that the data in the left and right sub-windows are drawn from the same population. Our null hypothesis is expressed as: H 0 is H 0 :  X  l =  X  r =  X  and the alternate hypothesis as H 1 :  X  l =  X  r .Let S l = a random sample which comprise the m blocks in the left sub-window and let S r = a random sam-ple { z 1 ,z 2 ,...,z r } of size r from { x m +1 ,x m +2 ,...,x n } which comprises the (n-m) blocks in the right sub-window. With the application of the union bound on expression (1), we derive the following for every real number k  X  (0 , 1) : Applying the Bernstein inequality on the R.H.S of Equation 1, we get: In the classification context, the bounds a and c for the Bernstein bound take values a =0 , c =1 . Substituting this in (2) we get: The probability Pr [ |  X   X  l  X   X   X  r | X  ] represents the false positive rate  X  and hence we have: We now need to minimize the RHS of (4) in order to minimize the upper bound  X  for the false positive rate. Given the two exponential terms, the RHS of (4) can be minimized when: The variable k above represents the proportion of instances among the left and right sub-windows. OnePassSampler uses equal sized samples across the sub-windows, giving k = 1 2 . We note that k = 1 2 satisfies (5) above. Substituting k = 1 2 in (4) gives: Solving (6) to find gives: where p = ln 4  X  .If |  X   X  l  X   X   X  r | X  , concept change is declared at instance ( m +1) and S l , S r can be considered to be from different distributions with probability (1  X   X  ) , otherwise, hypothesis H 0 is accepted that there is no concept change in the window of instances S n .

A change detection algorithm by its very nature needs to test multiple cut points be-fore an actual change point is detected. Each test involves a hypothesis test applied at a certain confidence level. The effect of multiple tests is to reduce the confidence from  X  to  X  which represents the effective (overall) confidence after n successive hypothesis tests have been carried. However, we note that the hypothesis tests in the change de-tection scenario are not independent of each other as the probability of a false positive (i.e incorrectly accepting hypothesis H1 that the means across the left and and right sub-windows are different) at a particular test has an influence on whether a false posi-tive occurs at subsequent tests and hence methods such as Bonferroni do not apply. We use our own error correction factor,  X  =2  X  to space constraints. Thus, in our model the change and warning significance levels,  X  positive probability. We observe that the the correction factor above converges to 2  X  for large values of n . 3.4 OnePassSampler Change Detection Algorithms This section presents the core algorithms used in our change detector system. S r and S l denote the right and left sub windows. Algorithm (1) decides the change type given the mean values  X   X  r and  X   X  l of S r and S l respectively, change (the threshold mean differ-ence for  X  change )and warning (the warning threshold mean difference for  X  warning ). change and warning are calculated using the equation (7). Though OnePassSampler detects drifts in any variation in the mean, algorithm (1) only reports the change when mean increases (  X   X  r &gt;  X   X  l ). In the event of a concept change Algorithm (2) transfers the contents of the right sub-window into the left. When a warning state is triggered it increases the sample size, in e xpectation of a subsequent concept change. This increase has the effect of increasing precision in sampling and the algorithm may become more sensitive to slow gradual change.
 Two major design differences exist between the two change detectors. The first lies in the policy used in determining cuts. When new data arrives, ADWIN2 creates a new bucket and adds it to its memory buffer. It then searches through all buckets currently stored in its memory buffer for a possible cut point. A cut point in ADWIN2 lies on the boundary between buckets. With N buckets currently in storage, ADWIN2 will ex-amine a total of ( N  X  1) possible cut points. Furthermore, as each new bucket arrives previous bucket boundaries that were examined before will be re-examined for possi-ble cuts. Effectively, ADWIN2 makes multiple passes through its memory buffer. In contrast, OnePassSampler never re-examines previous block (equivalent of ADWIN2 X  X  bucket) boundaries for cuts and only examines the boundary between the newly arrived block and the collection of blocks that arrived previously for a possible cut. In this sense, OnePassSampler can be said to do a single pass through its memory buffer when searching for cuts, and hence its name.

The second major difference lies in the estimation strategy for assessing means of data segments. ADWIN2 relies on exponential histograms for estimating mean values, whereas OnePassSampler uses random sampling base on an efficient array structure to estimate means. The problem with exponential histograms is that some of the buckets, typically the more recent ones may be too sma ll in size to yield accurate estimations for mean values. This is due to the fact that in ADWIN2 a bucket is created whenever a 1 appears in the stream, and when data has high variation bucket size will vary widely. For buckets that are too small in size to support accurate estimation, ADWIN2 will end up overestimating the true mean and false positives may then result. Our empirical study had two broad objectives. Firstly, we conducted a comparative study of OnePassSampler with ADWIN2 on key performance criteria such as the true positive rate, the false positive rate, the time delay in detecting changes and the exe-cution time overheads involved in change detection. We used Bernoulli distribution in all experiments to simulate classifier outputs though OnePassSampler is a general drift detector for any distribution.

In the second part of our experimentation we conducted a sensitivity analysis of the effects of block size, warning level and sliding window size on the delay detection time for OnePassSampler. 5.1 Comparative Performance Study One first experiment was designed to test OnePassSampler X  X  false positive rate vis-a-vis ADWIN2. We used a stationary Bernoulli distribution for this and tested the effect of various combinations of mean values (  X  ) and confidence values (  X  ) as shown in Table 1. For this experiment the block size for OnePassSampler was set to its default value of 100 and ADWIN2 X  X  internal parameter M was also set to its default value. We conducted a total of 100 trials for each combination of  X  and  X  and the average false positive rate for each combinatio n was recorded.

Table 1 shows that both OnePassSampler and ADWIN2 have good false positive rates that are substantially lower than the confidence level set. However, we observe that as the variance in the data increases with the increase in the  X  value (for a Bernoulli dis-tribution, the variance is  X   X  (1  X   X  ) ) that ADWIN2 starts to register false positives. The ADWIN2 false positive rate increases progre ssively with the increase in the variance as well as the lowering of confidence (ie higher  X  values). On the other hand OnePass-Sampler retains a virtually zero false positive rate except when the confidence is low at 0.3 when it registers a rate of 0 . 01% , compared to the ADWIN2 rate of 1 . 28% at  X  =0 . 5 and  X  =0 . 3 . As the confidence becomes lower the value decreases and this results in an increase in the false positive rate for ADWIN2. However, OnePassSampler is virtually insensitive to the decrease in due to the fact that the mean value can be estimated more accurately through the com bined use of random sampling and the use of the aggregated running average mechanism.
 The second experiment was designed to test the true positive (detection) rates of OnePassSampler and ADWIN2 over data tha t was also generated from a Bernoulli dis-tribution. We generated four different data streams of length L =10 , 000 , 50,000, 100,000 and 1,000,000 bits from a Bernoulli distribution. The data generated was sta-tionary with mean 0 . 01 in the first L  X  2300 time steps and we then varied the distribu-tion in a linear fashion with different gradients in the last 2300 time steps. A total of 100 trials were conducted for each combination of data length and slope values. We tracked key performance indicators such as the true detection rate, average execution time and the detection delay time. Both OnePassS ampler and ADWIN2 managed to achieve a true detection rate of 100 % for all combinations of data length and change gradients. Figure 1 also illustrates that ADWIN2 was much slower in stream processing than OnePassSampler. Furthermore, the gap b etween the two processing times becomes wider as the length of the stable segment of the stream becomes longer. This was ex-pected as ADWIN2 spends much time doing repeated scans through the histogram and examines every possible combination of cut s defined by the buckets. OnePassSampler, on the other hand does a single pass through the window segment and at each block of data it assesses whether the newly arrived block is sufficiently different from the previous blocks in its memory buffer.

However, it is clear from Figure 1 that ADWIN2 has better mean detection delay when compared to OnePassSampler. OnePassS ampler needs a relatively larger window segment before it can decide whether a newl y arrived block is sufficiently different due to the sampling strategy that it uses. As expected, the delay times reduced with increasing gradient of change, although we observe that OnePassSampler reduces at a faster rate than ADWIN2 with the gap between the two closing for higher gradients of change. Section 5.2 shows that OnePassSampler X  X  detection delay can be reduced with proper use of warning level and particularly block size on which it is most sensitive with respect to delay.
 The final part of our experimentation involved an investigation of the sensitivity of OnePassSampler X  X  key parameters on detec tion delay time. From previous experimen-tation with Bernoulli data it was observed that OnePassSampler had a higher detection delay time than ADWIN2 and thus the motivation was to determine parameter settings that minimize OnePassSampl er X  X  detection delay time. 5.2 Sensitivity Analysis on OnePassSampler In the first experiment we investigated the effect of block size on Bernoulli data streams with different gradients. Section 5.1. Figur e 2 shows that as block size increases, delay time initially decreases, reaches a minimum value and then starts to rise once again. In order to detect changes in data distribution a sample of sufficient size is required, which in turn is determined by the block size. If the size of the block (sample size) is too low, then in common with other statistical tests of significance, a statistical difference cannot be determined until a greater change occurs with time, thus delaying the detection. On the other hand, if the block size is too large then the probability increases that a change occurs too late within a given block for the change to be detected and so the change will go undetected until at least a new block arrives, thus giving rise to an increased detection delay. A block size of 200 appears to be optimal across a range of different change gradients, except when the change is very gradual , in which case 500 gives a slightly lower delay.

We next checked the effect of warning level on delay. Figure 2 shows that warning level has a much smaller effect on delay than block size. With a slope of 1 . 00 E  X  04 the warning level setting has a negligible effect on delay and thus a pragmatic setting that is twice the significance level should suffice in most cases to reduce the delay.
Next, we assessed the effect of sample size in crement. Whenever the warning level is triggered the sample size is incremented in the hope of trapping an impending change earlier. We investigated a range of increments and as Figure 3 shows, a doubling of sample size produces optimal results across t he entire spectrum. As with the warning level, too large an increase results in an increase in the detection delay.
Overall, it appears that block size is of prime importance in minimizing delay time; a block size of 200 works well for a range of datasets with different change dynamics. The other two parameters have a much smaller effect in general but can also contribute to smaller delay times with settings that we discussed above, especially in the case of slowly varying data.

Finally, we assessed the effects of the sliding window size on true positive rate, false positive rate and delay time. We varied the sliding window size in the range 500 to 10,000. For each window size, 30 trials were conducted on data from a Bernoulli distribution and the average for each of the p erformance measures were recorded. Due to space constraints we show the detection delay for the smallest change gradient of 1 . 00 E  X  4 ; the results for the other change gradients followed very similar trends. As Table 2 shows, the detection delay is largely insensitive to window size. In addition, all window sizes recorded a true positive rate of 100% . The false positive rate was in line with the other two measures, virtually no change in rate was observed across the entire range of window sizes used. Once again space constrains prevent us from showing the entire set of results; we only show the case with mean value 0 . 3 and delta 0 . 3 . All other combinations of mean and delta returned virtually identical results. These results indicate that window size when set at a reasonable multiple of block size has no significant effect on key factors such as the true positive rate and delay time. These results are to be expected as data that is slid out of the window consists of a set of homogeneous instances from OnePassSampler X  X  left sub-window.
 This research has shown that a concept change detector based on a sequential hypothe-sis testing strategy based on use of the Bernstein bound as a test statistic yields excellent performance in terms of false positive rate, true positive rate and processing time. Our comparative study with ADWIN2 clearly shows that a single pass strategy can pro-duce competitive false positive and true positive rates to ADWIN2, with much lower computational overheads.

The use of sequential hypothesis testing combined with an efficient incremental strat-egy that updates statistics on the memory buffer were the two major factors behind the greatly reduced computational overheads over ADWIN2. Despite lower computational overheads, OnePassSampler has a higher det ection delay time in certain cases and our future work will focus on improving this aspect. By means of a mechanism that moni-tors change in the running average of data arriving in the window an alternate candidate cut point can be defined at a point further downstream than the current block boundary. The system would then check both the current block boundary as well as the alternate point. This modification would result in trading off computational overhead with an improvement in detection delay for dat asets with small gradients of change.
