 One of the goals in recommender systems is to recommend those items to each user that maximize the user X  X  utility. In this study, we propose new approaches which, in conjunction with any existing recommendation technique, can improve the top-N item selection by taking into account rating variance. We empirically demonstrate how these approaches work with several recommendation techniques, increasing the accuracy of recommendations. We also show how these approaches can generate more personalized reco mmendations, as measured by the diversity metric. As a result, user s can be given a better control to choose whether to receive recommendations with higher accuracy or higher diversity. H.3.3 [ Information Search and Retrieval ]: Information filtering, Retrieval models, Selection process.
 Keywords: Rating Variance, Recommendation Filtering, Recommendation Ranking, Accuracy, Diversity. The most common formulation of the recommendation problem relies on the notion of ratings, i. e., recommender systems estimate ratings of items that are yet to be consumed by the users, based on the ratings of items already c onsumed. Recommendations to users are typically made based on the value of the predicted ratings, i.e., the items with the highest predicted ratings are the ones being recommended. Accordingly, there have been many studies on developing new algorithms that can help to correctly estimate the ratings of items not consumed. Ho wever, relying on the predicted rating value alone may not be e nough to find the best items for each user. There may exist other f actors that can affect the quality of recommendations. In particular , this paper aims to find new recommendation approaches that can take into account rating variance of an item in selecting recommendations. For instance, in a traditional collaborative filtering recommendation technique, some item could be predicted relatively high based on other users X  ratings (e.g., by averaging the ratings of all users who rate d this item). However, all users may not agree to rate it with the same exact high rating. Some users may rate the item extremely high and some may rate it extremely low, and this could potentially lead to different results in terms of the quality of recommendations from when all users rate the item with the same rating value. This paper starts from the premise that recommender systems can be improved by considering the difference in tw o cases (i.e., different rating variance), and it is conformed by empirical results. We used the pre-processed MovieLens data (775,176 movie ratings including 2,830 users a nd 1,919 movies, available at grouplens.org) to demonstrate the relationship between rating variance and accuracy of recommendations. The ratings used here are integers between 1 and 5, inclusive, where higher value represents a better movie. 60% of the ratings were randomly chosen for training and the rest of the ratings are predicted as a test dataset. Since we want to know if the relationship between rating variance and accuracy is similar across different recommendation techniques, we us e one memory-based and two model-based techniques for rati ng prediction (i.e., a memory-based collaborative filtering techni que which uses cosine-based similarity and adjusted weighted sum, a na X ve Bayesian model, and a flexible mixture model). Rating variance of each movie is calculated based on the ratings of a ll the movies that a user rated in the training dataset. The accuracy of recommendations is measured with mean absolute error (MAE) that is the average of the differences between predicted and actual ratings in the test dataset. As Figure 1 shows, there exists a regular relationship between rating variance of a given item and the accuracy of recommendations involving that specific item. The accuracy monotonically decreases (i.e., the mean absolute error increases) different recommendation technique s. As a result, we have learned that, if we recommend to users only those items whose rating variance is small, the accuracy of recommendations could be improved. Therefore, we propose several new recommendation approaches that use standard devi ation of ratings (i.e., the positive square root of rating variance) to restrict the recommendations to only top-N items with relatively smaller rating variances. Recommender systems are usually classified into three categories based on their approach to r ecommendation: content-based, collaborative, and hybrid approaches [2]. Content-based recommender systems recommend items similar to the ones the user preferred in the past. Collaborative filtering recommender systems recommend items that users with similar preferences have liked in the past. Finally, hybrid approaches can combine content-based and collaborative met hods in several different ways [1]. Furthermore, recommender systems can also be classified based on the nature of their algorithmic technique into memory and model-based approaches [3 ]. Memory-based techniques usually represent heuristics that calculate recommendations  X  X n the fly X  based directly on the previous user activities. One of the commonly used memory-based techniques is to find users that have similar tastes, using cosine -or correlation-based similarity measures. In contrast, model-base d techniques use previous user activities to first learn a predictive model, typically using some statistical or machine-learning me thods, which is then used to make recommendations. Examples of such techniques include the na X ve Bayesian and flexible mixture models [6, 7]. Our proposed approaches focus on collaborative filtering techniques which use only rati ng data, but both memory-and model-based techniques are empirically tested. One goal of a typical collaborative filtering technique is to correctly estimate the ratings of unrated items ba sed on the given ratings; another goal is to find items that maximize the user X  X  utility. Memory-or model-based collaborative filtering techniques help us to estimate the unknown ratings (i.e., the firs t goal). Our new approaches determine the top-N items that can result in higher accuracy of recommendations (i.e., the second goal). As discussed above, the accuracy of recommendations could potentially be improved if we take into account rating variance in choosing top-N items. This motivation of using variance for similar purposes is shared in the decision science literature; for example, when a decision maker is provided with multiple opinions and needs to aggregate them, the variance of the individuals X  opinions is often used as a convenient proxy of decision maker X  X  confidence in their opinion [8]. A similar approach in the recommender systems literature was used in [5], where the variance in rating patte rns among the users with similar interests was captured using a  X  X ecoupled X  model. That is, they developed a new model-based t echnique to account for rating patterns, while our approaches can be used in conjunction with any existing recommendation technique as a post-processing step. We can simply employ our new rating-variance-based recommendation approaches to the predictions already obtained from any existing technique, resulting in the improved recommendation accuracy. However, while our proposed approaches can improve the accuracy of recommendations, the accuracy alone may not be enough in evaluating the performance of recommender systems; e.g., it is easy to obtain higher precision by recommending only very popular items that most users are likely to rate highly. If we recommend items based only on their popularity, then the level of personalization is arguably lowe r, and the recommender systems will be of little use. It has often been suggested that recommender systems must be not only accurate, but also useful [4]. Thus, various usefulness measures can be used, e.g., to make sure that the recommendations have a sufficient diversity of items. Our proposed recommendation approaches will also be evaluated using a diversity measure (in addition to accuracy), and we will discuss the flexibility of recommendations by developing new approaches which would give user the control over the quality of recommendations. Once a recommender system is able to predict unknown items, top-N items for each user can be obtained based on the predicted ratings in two steps (filtering and ranking): filtering the predicted ratings greater than the pre-defined acceptable threshold (e.g., we use 3.5 out of 5), and then choosing N items above the threshold with the highest predicted ratings. In our simple filtering approach, in addition to the acceptable rating threshold ( T ), we also filter out the recommendations according to some user-specified rating standard deviation threshold. In our experiments, we varied the rating standard de viation threshold from 0.7 to 1.2 in increments of 0.05. For instance, in the case of 0.9, we recommended to users only items w ith a rating standard deviation of less than 0.9 (and, of course , where the predicted rating was above 3.5). With this simple filtering approach, only the  X  X ighly-ranked X  items with  X  X ow rating variance X  will be recommended to users and, in turn, we expect that the more the rating variance threshold restricted the recommended items, the better the accuracy of the recommendations would be in terms of the standard precision-in-top-N metric. However, as mentioned above, while important, accuracy is not the only factor to consider. Recommender systems must be not only accurate but also useful [6]. As a measure of usefulness, we use the diversity metric by computing the total number of distinct items recommended across all users. This diversity metric is a personalization realized by the system; i.e., the diversity metric will show whether all users are recommended the same top-N items or every user is given his/her own unique top-N items (or something in-between). The rating standard deviation threshold places a limit on which items can be recommended. In other words, with a smaller recommendations, in which case the diversity would clearly suffer. Therefore, it is important to maintain a balance between accuracy and diversity. To address this issue, we propose three new recommendation approaches that can increase the diversity of recommendations while maintaining a relatively high precision-in-top-N , by adjusting filtering or/and ranking conditions in the top-N recommendation process. Our proposed adjusted ranking, adjusted filtering , and combined approaches directly use rating standard deviation of each item in selecting recommendations by adjusting either filtering or ranking condition (or both). In the adjusted filtering approach, when predicting the rating of item i for a given user u , we take the predicted rating generated by an y traditional recommender system and subtract a portion of one st andard deviation of all known ratings of item i (from the training dataset).This way we try to model a worst case scenario  X  i.e., how low the actual rating could be, if the prediction by the traditional recommender system is not very accurate. We then recommend the item if this newly computed predicted rating is greater than the acceptable rating threshold (i.e., 3.5). More specifi cally, we tested various portions of one standard deviation in the range of 0.1 to 1 in increments of predicted rating by ( k * one standard deviation of ratings) and check to see whether or not th is adjusted value can still be considered as  X  X ighly-ranked. X  If so, we recommend N items, according to the order of the original (not adjusted) predicted ratings. In other words, we rank the top-N items based on the average case scenario, but make sure that we recommend only those items that would be above the acceptable threshold in the worst case scenario. The adjusted ranking approach is the opposite of the adjusted filtering approach in filtering and ranking conditions. In the adjusted ranking approach, we rank top-N items based on the adjusted predicted ratings, but do not use the rating standard deviation in the filtering condition. The combined approach has the most conservative condition in both filtering and ranking. Namely, after subtracting one standard deviation from the predicted ratings, we rank top-N items based on the newly adjusted ratings (i.e., worst case s cenario) instead of the originally predicted ones (i.e., average case scenario), as long as this adjusted value is considered as  X  X ighly-ranked. X  Therefore, the combined approach would be expected to result in more accurate recommendations than the adjusted ranking and adjusted filtering approach, while its dive rsity measure should be lower than that of the adjusted ranking and adjusted filtering approach because items are ranked by considering both rating value and rating standard deviation together and, in turn, there is less flexibility to recommend different items to each user. Lastly, we also tested the standard recommendation approach, i.e., without any rating standard devia tion constraint in both filtering and ranking conditions, in order to compare it with our proposed approaches. Standard approach a nd three proposed approaches are summarized in Table 1, and are presented formally in Figure 2. Table 1. Classification of New Variance-Based Approaches Ranking Condition Simple filtering , adjusted ranking , adjusted filtering , combined and standard approaches are evaluated using both the precision-in-top-N metric and diversity metric, as shown in Figure 3. The proposed approaches are applied to the predicted ratings obtained by using three different r ecommendation techniques, as mentioned in Section 1. Here , one standard deviation ( k =1) is used in adjusted filtering and ranking conditions. The results clearly show a trade-off between accuracy and diversity in a simple filtering approach (first row in Figure 3). The combined approach among three proposed recommendation approaches performed best in accuracy, while sacrificing the diversity. The adjusted ranking approach obtained the highest diversity since there is no rating variance constraint in filtering and provided more accurate recommendations than adjusted filtering approach in the model-based techniques (i.e ., na X ve Bayesian and flexible mixture model). This can be explained by the fact that the predicted rating values acquired from the model-based technique are discrete, not continuous. That is, many predictions will have identical values (e.g., rated as  X 5 X ), and the top-N items are chosen randomly from this list of highest-rated items for each user. Therefore, it is more impor tant to change the order of recommendations (ranking condition) than filtering condition since the adjusted ratings might still be higher than acceptable rating threshold. We also tested various portions of one standard deviation in the range of 0 to 1 in increments of 0.1 in filtering and ranking conditions of adjusted ranking , adjusted filtering , and combined approaches. If k =0, the proposed approaches become the standard approach. The results in Figure 4 show that, as the portion of one recommendations improves, but the diversity deteriorates in all proposed approaches. Specifically, the trade-off between accuracy and diversity is less pronounced in the adjusted ranking approach, and the accuracy increase is the largest in the combined approach. Figure 2. New Top-N Recommendation Approaches using Standard Deviation of Ratings In conclusion, one can choose simple filtering, adjusted ranking, adjusted filtering , or combined approach, according to how much accuracy or diversity of recommendations we want to obtain. The adjusted ranking , adjusted filtering , and combined approaches have a more balanced performance in their precision and diversity metrics, as compared to the simple filtering approach. In this study, using a simple filtering approach we have demonstrated that the accuracy of recommendations can be significantly improved by filtering out recommendations above a minimum rating standard deviation threshold. However, there was also a corresponding decrease in the diversity of recommendations. We thus proposed the adjusted ranking , adjusted filtering and combined approaches which adjust filtering or/and ranking conditions in selecting top-N items. These approaches are especially useful, since a user can control the balance between the accuracy and diversity of recommendations. Also, note that, while this paper focuses on choosing top-N items for each user, our proposed approach es can be applied to choosing top-N users for each item in a straightforward manner. Furthermore, this study provide s some interesting opportunities for future work. In particular, the rating variance can be considered in selecting the training data for unknown rating prediction, which is typically referred to as an active learning problem. If we can choose ratings with potentially high accuracy (e.g., ratings with a low average of user rating variance and item rating variance) among all the known ratings, we may arguably reach the desired accuracy level faster (i.e., with less training data) than when we choose the data randomly. Our preliminary results show that such active learning approach (which uses only a fraction of available ratings, i.e., the ones with lower variance) increases the performance in accuracy metrics such as mean absolute error, precision, and recall in the early training stages. [1] G. Adomavicius and A. Tuzhilin, Toward the Next [2] M. Balabanovic and Y. Shoha m, Fab: Content-Based, [3] S. Breese, D. Heckerman, and C. Kadie, Empirical Analysis [4] J.L. Herlocker, J.A. Konstan, L.G. Terveen, and J. Riedl, [5] R. Jin, L. Si, C.X. Zhai, a nd J.Callan, Collaborative Filtering [6] L. Si and R. Jin, Flexible Mixture Model for Collaborative [7] X. Su and T. M. Khoshgoftaar, Collaborative Filtering for [8] D.V. Budescu, A.K. Rantilla, H.T. Yu, and T.M. Karelitz, 
