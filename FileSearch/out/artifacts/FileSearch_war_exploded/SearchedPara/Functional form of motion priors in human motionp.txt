 Imagine that you are traveling in a moving car and observe a wa lker through a fence full of punch holes. Your visual system can readily perceive the walking p erson against the apparently moving background using only the motion signals visible through th ese holes. But this task is far from trivial due to the inherent local ambiguity of motion stimuli, often referred to as the aperture problem . More precisely, if you view a line segment through an aperture the n you can easily estimate the motion component normal to the line but it is impossible to estimate the tangential component. So there are an infinite number of possible interpretations of the local m otion signal.
 One way to overcome this local ambiguity is to integrate loca l motion measurements across space to infer the  X  X rue X  motion field. Physiological studies have shown that direction-selective neurons in primary visual cortex perform local measurements of moti on. Then the visual system integrates these local motion measurements to form global motion perce ption [4, 5]. Psychophysicists have identified a variety of phenomena, such as motion capture and motion cooperativity, which appear to be consequences of motion spatial integration [1, 2, 3]. F rom the computational perspective, a number of Bayesian models have been proposed to explain the se effects by hypothesizing prior assumptions about the motion fields that occur in natural env ironments. In particular, it has been shown that a prior which is biased to slow-and-smooth motion can account for a range of experi-mental results [6, 7, 8, 9, 10].
 But although evidence from physiology and psychophysics su pports the existence of an integration stage, it remains unclear exactly what motion priors are use d to resolve the measurement ambigui-ties. In the walking example described above (see figure 1), t he visual system needs to integrate the local measurements in the two regions within the red boxes in order to perceive a coherently moving background. This integration must be performed over large d istances, because the regions are widely separated, but this integration cannot be extended to inclu de the walker region highlighted in the blue box, because this would interfere with accurate estimation of the walker X  X  movements. Hence the motion priors used by the human visual system must have a func tional form which enables flexible and robust integration.
 We aim to determine the functional form of the motion priors w hich underly human perception, and to validate how well these priors can influence human perc eption in various motion tasks. Our approach is to combine parametric modeling of the motion pri ors with psychophysical experiments to estimate the model parameters that provide the best fit to h uman performance across a range of stimulus conditions. To provide further validation, we t hen use the estimated model to predict human performance in several different experimental setup s. In this paper, we first introduce the two functional forms which we consider and review related li terature in Section 2. Then in Section 3 we present our computational theory and implementation de tails. In Section 4 we test the theory by comparing its predictions with human performance in a ran ge of psychophysical experiments. Figure 1: Observing a walker with a moving camera. Left panel , two example frames. The visual system needs to integrate motion measurements from the two r egions in the red boxes in order to perceive the motion of the background. But this integration should not be extended to the walker region highlighted in the blue box. Right panel, the integra tion task is made harder by observing the scene through a set of punch holes. The experimental stimuli in our psychophysical experiments are designed to mimic these observation conditions. Many models have proposed that the human visual system uses p rior knowledge of probable mo-tions, but the functional form for this prior remains unclea r. For example, several well-established computational models employ Gaussian priors to encode the b ias towards slow and spatially smooth motion fields. But the choice of Gaussian distributions has l argely been based on computational convenience [6, 8], because they enable us to derive analyti c solutions.
 However, some evidence suggests that different distributi on forms may be used by the human visual system. Researchers have used motion sequences in real scen es to measure the spatial and temporal statistics of motion fields [11, 12]. These natural statisti cs show that the magnitude of the motion (speed) falls off in a manner similar to a Laplacian distribu tion ( L1-norm regularization), which has heavier tails than Gaussian distributions (see the left plo t in figure 2). These heavy tails indicates that while slow motions are very common, fast motions are sti ll occur fairly frequently in natural environments. A similar distribution pattern was also foun d for spatial derivatives of the motion flow, showing that non-smooth motion fields can also happen in natu ral environments. This statistical finding is not surprising since motion discontinuities can a rise in the natural environment due to the relative motion of objects, foreground/background segmen tation, and occlusion.
 Stocker and Simoncelli [10] conducted a pioneering study to infer the functional form of the slow-ness motion prior. More specifically, they used human subjec t responses in a speed discrimination task to infer the shape of the slowness prior distribution. T heir inferred slowness prior showed sig-nificantly heavier tails than a Gaussian distribution. They showed that a motion model using this inferred prior provided an adequate fit to human data for a wid e range of stimuli.
 Finally, the robustness of the L1-norm has also been demonst rated in many statistical applications (e.g., regression and feature selection). In the simplest c ase of linear regression, suppose we want to find the intercept with the constraint of zero slope. The re gression with L1-norm regularization estimates the intercept based on the sample median, whereas the L2-norm regression estimates the intercept based on the sample mean. A single outlier has very little effect on the median but can alter the mean significantly. Accordingly, the L1-norm regu larization is less sensitive to outliers than is the L2-norm. We illustrate this for motion estimatio n by the example in the right panel of figure 2. If there is a motion boundary in the true motion fiel d, then a model using L2-norm fields which blurs the motion across discontinuity. But the m odel with an L1-norm (Laplace prior) preserves the motion discontinuity and gives smooth motion flow on both sides of it.
 Figure 2: Left plot, the Gaussian distribution (L2-norm reg ularization) and the Laplace distribution (L1-norm regularization). Right plot, an illustration of o ver-smoothing caused by using Gaussian priors. The input data is specified by local motion measurements ~r set of positions ~r ~v defined at all positions ~r in the image domain, estimated from the local motion measure ments. The motion field ~v can be thought of as an interpolation of the data which obeys a slowness and smoothness prior and which agrees approximately with the lo cal motion measurements. Recall that the visual system can only observe the local motion in the dir ections ~n component motion) because of the aperture problem. Hence ap proximate agreement with local measurements reduces to the constraints: As illustrated in figure 3, we consider three motion prior ter ms which quantify the preference for slowness, first-order smoothness and second-order smoothn ess respectively. Let  X  denote the image domain  X  i.e. the set of points ~r = ( r energy function of form: where  X ,  X ,  X ,  X ,  X ,  X  are positive parameters and second-order smoothness The (negative log) likelihood function for grating stimuli imposes the measurement constraints and is of form: The combined energy function to be minimized is: This energy is a convex function provided the exponents sati sfy  X ,  X ,  X , p  X  1 . Therefore the energy Lagrange equations). Below we computer these Euler-Lagran ge partial differential equations in  X ,  X ,  X  6 = 2 , the Euler-Lagrange equations are non-linear partial diff erential equations (PDEs) and explicit solutions cannot be found (if  X ,  X ,  X  = 2 the Euler-Lagrange equations will be linear and so can be solved by Fourier transforms or Green X  X  functions, as previously done in [6]). To solve these non-linear PDEs we discretize them by finite differences and use iterative gradient descent (i.e. we ~v ( ~r, 0) at random, and solve the update equation for t &gt; 0 : where k = 1 , 2 ,  X  2 ,  X   X  2 become negative when the positive exponents  X ,  X , ... take value 1 , we include a small algorithm stops when the difference between two consecutiv e energy estimates is close to zero (i.e. the stopping criterion is based on thresholding the energy c hange).
 the time-step, and ( i, j ) denotes space discretization with h = 4 r Then the above PDE X  X  can be discretized as where F id v We compared two possible functional forms for the motion pri or: (1) the Laplace distribution with L1-norm regularization, with  X  =  X  =  X  = 1 , (2) the Gaussian distribution with L2-norm regular-ization, with  X  =  X  =  X  = 2 . Since the main goal of this work is to discover motion priors , we employed the same likelihood term with p = 2 for both models. We used the performance of human subjects in the first experimental session to estimate the we ights of the three prior terms,  X ,  X ,  X  , for each functional form. We then validated the predictions of the model by comparing them with human performance in a second experimental session which us es different stimulus parameters. 4.1 Stimulus We used a multiple-aperture stimulus [13] which consists of 12 by 12 drifting sine-wave gratings grating of 5.6 cycles/deg spatial frequency, which was with in a stationary Gaussian window. The contrast of the elements was 0.2. The motion stimulus includ ed 20 time frames which were presented within 267 ms. The global motion stimulus was generated as fo llows. First, the orientation of each local grating element was randomly determined. Second, a gl obal motion (also called 2D motion, with the speed of 1 deg/sec) direction was chosen. Third, a ce rtain proportion of elements (signal elements) were assigned with the predetermined 2D motion , w hile each of the remaining elements (noise elements) was assigned a random 2D motion. Finally, w ith its orientation and 2D motion velocity, the drifting speed for each element was computed s o that the local (or component) drifting motion strength was controlled by varying the proportion of signal elements in the stimulus (i.e., the coherence ratio). Stimuli with high ratio exhibited more co herent motion, and stimuli with low ratio exhibited more random motion.
 In all the experiments reported in this paper, each particip ant completed two experiment sessions with different stimulus parameters. The goal of session 1 wa s parameter estimation: to estimate the weights of the three prior terms  X  slowness, first-order smoo thness and second-order smoothness,  X  for each model. Session 2 was for model validation: using the weights estimated from session 1 to predict subject performance for different experimental co nditions.
 Figure 4: Stimulus illustration. Multiple-aperture stimu li with coherence ratio of 0, 0.4, 0.8 and 1 from left to right. the blue and green arrows indicate the 2D m otion directions assigned for signal and noise elements, respectively. 4.2 Experiment 1 4.2.1 Procedure were presented with two motion patterns, one after another. The first one was the reference motion pattern, which always moved upward (0 degree), and the secon d one was the test motion pattern, whose global motion direction was either tilted towards the left or the right relative to the reference pattern. Both patterns lasted for 267 ms with 500 ms inter-st imulus interval. The observer X  X  task was to determine whether the global motion direction of the t est pattern was more towards the left or right relative to the reference pattern. In order to make s ure observers understood the task and were able to perceive the global motion, before the beginnin g of the first session, observers passed a test session in which they achieved 90% accuracy in 40 consec utive trials with 80% coherence and 20 (or 45) degrees of angular difference. To allow observers to familiarize themselves with the task, before each experimental session observers went through a p ractice session with 10 blocks of 25 trials.
 The first session consisted of 20 blocks of 50 trials. the cohe rence ratio was constant within each block. The observer X  X  discrimination performance was meas ured for ten coherence ratios (0, 0.1, 0.2, .. , 0.9) in the first session. The angular difference between th e reference and test motion was fixed for each observer in the entire session (2 degrees for ob servers AL, MW and AE; 45 degrees for OQ and CC). The second session was identical to the first on e, except that the coherence ratio was fixed at 0.7, and the angular difference between the globa l motion directions of the reference and the test patterns was varied across blocks (ten angular d ifferences: 1, 5, 10, .. , 45 degrees). 4.2.2 Results We implemented motion models with the Laplace prior distrib ution (termed  X  X 1 model X ) and the Gaussian prior (termed  X  X 2 model X ). As the first step, exhaus tive search was conducted to find a set of weights for the prior terms that provided the best fit to the human psychometric performance in experimental session 1. Table 1 reports the estimated par ameters for each individual subject us-ing the L1 and L2 models. There was clear individual differen ce for the estimated weight values. However, across all five subjects, large weight values were f ound for the second-order smoothness terms, indicating the contribution from higher-order smoo thness preference is important in perceiv-ing global motion from multiple-aperture stimulus.
 Figure 5 shows the results from each individual participant and best-fitting model performance. The results clearly show the L1 model provided the better fit to hu man data when compared to the L2 model. In general,humans appear to be sensitive to the inclu sion of noise elements, and perform Table 1: Estimated weights  X ,  X ,  X  of slowness, first-order smoothness and second-order smoot hness prior terms, for L1 and L2-norm model worse than the L2 model, which tends to strongly encourage sm oothness over the entire display window.
 In experimental session 2, the two models predicted perform ance as a function of angular difference between the reference motion and the test motion. As shown in figure 7, the L1 model yielded less error in fitting human performance than did the L2 model. This result illustrates the power of the L1 model in predicting human performance in motion tasks diffe rent from the tasks used for estimating model parameters. Figure 5: Comparison between human performance and model pr edictions in session 1. Left two plots, accuracy as a function of coherence ratio for two representative subjects. Blue solid lines indicate human performance. Red and green dashed lines indi cate L1 and L2 model predictions with the best fitted parameters. Right plot, model error for a ll five subjects. The model error was computed as the mean absolute difference between human perf ormance and model predictions. L1 model consistently fits human performance better than L2 mod el for all subjects Figure 6: Comparison between human performance and model pr edictions in session 1. Left two plots, accuracy as a function of angular difference between the reference and the test motio n for two representative subjects. Blue solid lines indicate human p erformance. Red and Green dashed lines indicate L1 and L2 model predictions. Right plot, model erro r for all five subjects. Less errors from L1 model indicate that L1 model consistently fits human perfo rmance better than L2 model for all subjects 4.3 Experiment 2 The results of Experiment 1 clearly support the conclusion t hat the motion model with Laplace prior (L1-norm regularization) fits human performance better tha n does the model with Gaussian prior (L2 model). In Experiment 2, we compared human motion judgme nt with predictions of the L1 model on each trial, rather than using the average performan ce as in Experiment 1. Such a detailed comparison can provide quantitative measures of how well th e L1 model is able to predict human motion judgment for specific stimuli.
 In Experiment 2, the first session was identical to that in Exp eriment 1, in which angular difference in the two global motion directions were fixed (45 degrees for all observers) while the coherence ratio was varied. In the second session, observers were pres ented with one motion stimulus on each trial. The global motion direction of the pattern was random ly selected from 24 possible directions (with a 15-degree difference between two adjacent directio ns). Observers reported their perceived global motion directions by rotating a line after the motion stimulus disappeared from the screen. A two-pass design was used to let each observer run the identi cal session twice in order to measure the reliability of the observer X  X  judgments.
 We used human performance in session 1 to estimate model para meters: weights  X ,  X ,  X  for slow-ness, first-order smoothness and second-order smoothness p rior terms for each individual partici-pant. Since identical stimuli were used in the two runs of ses sion 2, we can quantify the reliability of the observer X  X  judgment by computing the response correl ation across trials in these two runs. As shown in the left plot of figure 7, human observers X  responses were significantly correlated in the two runs, even in the condition of random motion (coherence ratio is close to 0). The correlated responses in these subthreshold conditions suggest that hu man observers are able to provide con-sistent interpretation of motion flow, even when the motion i s random. The right plot of figure 7 shows the trial-by-trial correlation between human motion judgments with model-predicted global motion direction. The model-human correlations were compa rable to human self-correlations. Even in the random motion condition (where the coherence ratio is 0), the correlation between the model and human judgments is greater than 0.5, indicating the pred ictive power of the model. We also noticed that the correlation between human and L2 model was a round 8 percent worse than the hu-man self-correlation and the correlation between the L1 mod el and humans. This finding further demonstrated that the L1 model provided a better fit to human d ata than did the L2 model. Figure 7: Comparison between human performance and model pr edictions using trial-by-trial corre-lation. Left plot, human self correlation between two runs o f identical experimental sessions. Right plot, correlation between human motion judgement and model predicted global motion direction. The significant correlation between human and the model indi cates the L1 model is able to predict human motion judgment for specific stimuli, even in the rando m display, i.e., coherence ratio close to 0. We found that a motion prior in the form of the Laplace distrib ution with L1-norm regularization provided significantly better agreement with human perform ance than did Gaussian priors with L2-norm. We also showed that humans weighted second-order moti on smoothness much higher than first-order smoothness and slowness. Furthermore, model pr edictions using this Laplace prior were consistent with human perception of coherent motion, even f or random displays. Overall our results suggest that human motion perception for these types of stim uli can be well modeled using Laplace priors.
 Acknowledgments This research was supported by NSF grants IIS-613563 to AY an d BCS-0843880 to HL. [1] R. Sekuler, S.N.J. Watamaniuk and R. Blake. Perception o f Visual Motion. In Steven X  X  Hand-[2] L. Welch. The perception of moving plaids revewals two pr ocessing stages. Nature ,337,734-[3] P. Schrater, D. Knill and E. Simoncelli. Mechanisms of vi sual motion detection. Nature Neu-[5] N. C. Rust, V. Mante, E. P. Simoncelli and J. A. Movshon. Ho w MT cells analyze the motion [6] A.L. Yuille and N.M. Grzywacz. A computational theory fo r the perception of coherent visual [7] A.L. Yuille and N.M. Grzywacz. A Mathematical Analysis o f the Motion Coherence Theory. [8] Y. Weiss, E.P. Simoncelli, and E.H. Adelson. Motion illu sions as optimal percepts. Nature [9] H. Lu and A.L. Yuille. Ideal Observers for Detecting Moti on: Correspondence Noise. Ad-[10] A.A. Stocker and E.P. Simoncelli. Noise characteristi cs and prior expectations in human visual [12] C. Liu, W. T. Freeman, E. H. Adelson and Y. Weiss. IEEE Conference on Computer Vision and [13] Amano, K., Edwards, M., Badcock, D. R. and Nishida, S. Ad aptive pooling of visual motion
