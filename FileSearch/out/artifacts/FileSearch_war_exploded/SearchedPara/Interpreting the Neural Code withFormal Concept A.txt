 Mammalian brains consist of billions of neurons, each capable of independent electrical activity. From an information-theoretic perspective, the patterns of activation of these neurons can be un-derstood as the codewords comprising the neural code. The neural code describes which pattern of activity corresponds to what information item. We are interested in the (high-level) visual system, where such items may indicate the presence of a stimulus object or the value of some stimulus at-tribute, assuming that each time this item is represented the neural activity pattern will be the same or at least similar. Neural decoding is the attempt to reconstruct the stimulus from the observed pat-tern of activation in a given population of neurons [1, 2, 3, 4]. Popular decoding quality measures, such as Fisher X  X  linear discriminant [5] or mutual information [6] capture how accurately a stimu-lus can be determined from a neural activity pattern (e.g., [4]). While these measures are certainly useful, they tell us little about the structure of the neural code, which is what we are concerned with here. Furthermore, we would also like to elucidate how this structure relates to the represented information items, i.e. we are interested in the semantic aspects of the neural code.
 To explore the relationship between the representations of related items, F  X  oldi  X  ak [7] demonstrated that a sparse neural code can be interpreted as a graph (a kind of  X  X emantic net X ). In this inter-pretation, the neural responses are assumed to be binary (active/inactive). Each codeword can then be represented as a set of active units (a subset of all units). The codewords can now be partially ordered under set inclusion: codeword A  X  codeword B iff the set of active neurons of A is a sub-set of the active neurons of B. This ordering relation is capable of capturing semantic relationships between the represented information items. There is a duality between the information items and the sets representing them: a more general class corresponds to a smaller subset of active neurons, and more specific items are represented by larger sets [7]. Additionally, storing codewords as sets is especially efficient for sparse codes. The resulting graphs (lattices) are an interesting representation of the relationships implicit in the code.
 We would also like to be able to represent how the relationship between sets of active neurons trans-lates into the corresponding relationship between the encoded stimuli. These observations can be formalized by the well developed branch of mathematical order theory called Formal Concept Anal-ysis (FCA) [8, 9]. In FCA, data from a binary relation (or formal context ) is represented as a concept lattice. Each concept has a set of formal objects as an extent and a set of formal attributes as an in-tent. In our application, the stimuli are the formal objects, and the neurons are the formal attributes. The FCA approach exploits the duality of extensional and intensional descriptions and allows to visually explore the data in lattice diagrams. FCA has shown to be useful for data exploration and knowledge discovery in numerous applications in a variety of fields [10, 11].
 We give a short introduction to FCA in section 2 and demonstrate how the sparseness (or denseness) of the neural code affects the structure of the concept lattice in section 3. Section 4 describes the generative classifier model which we use to build the formal context from the responses of neurons in the high-level visual cortex of monkeys. Finally, we discuss the concept lattices so obtained in section 5. Central to FCA[9] is the notion of the formal context K := ( G, M, I ) , which is comprised of a set of formal objects G , a set of formal attributes M and a binary relation I  X  G  X  M between members of G and M . In our application, the members of G are visual stimuli, whereas the members of M are the neurons. If neuron m  X  M responds when stimulus g  X  G is presented, then we write ( g, m )  X  I or gIm . It is customary to represent the context as a cross table, where the row(column) headings are the object(attribute) names. For each pair ( g, m )  X  I , the corresponding cell in the cross table has an  X  X  X . Table 1, left, shows a simple example context. monkeyHand  X  Table 1: Left : a simple example context, represented as a cross-table. The objects (rows) are 4 visual stimuli, the attributes (columns) are 3 (hypothetical) neurons n1,n2,n3. An  X  X  X  in a cell indicates that a stimulus elicited a response from the corresponding neuron. Right : the concepts of this context. Concepts are lectically ordered [9]. Colors correspond to fig.1.
 Define the prime operator for subsets A  X  G as A 0 = { m  X  M | X  g  X  A : gIm } i.e. A 0 is the set of all attributes shared by the objects in A . Likewise, for B  X  M define B 0 = { g  X  G | X  m  X  B : gIm } i.e. B 0 is the set of all objects having all attributes in B .
 Definition 2.1 [9] A formal concept of the context K is a pair ( A, B ) with A  X  G , B  X  M such that A 0 = B and B 0 = A . A is called the extent and B is the intent of the concept ( A, B ) . IB ( K ) denotes the set of all concepts of the context K .
 In other words, given the relation I , ( A, B ) is a concept if A determines B and vice versa. A and B are sometimes called closed subsets of G and M with respect to I . Table 1, right, lists all concepts of the context in table 1, left. One can visualize the defining property of a concept as follows: if ( A, B ) is a concept, reorder the rows and columns of the cross table such that all objects in A are in adjacent rows, and all attributes in B are in adjacent columns. The cells corresponding to all g  X  A and m  X  B then form a rectangular block of  X  X  X  X  with no empty spaces in between. In the example above, this can be seen (without reordering rows and columns) for concepts 1,3,4. For a graphical representation of the relationships between concepts, one defines an order IB ( K ) : ( A 2 , B 2 ) if A 1  X  A 2 (which is equivalent to B 1  X  B 2 ). In this case, ( A 2 , B 2 ) is a superconcept of ( A 1 , B 1 ) and we write ( A 1 , B 1 )  X  ( A 2 , B 2 ) . The relation  X  is called the order of the concepts. It can be shown [8, 9] that IB ( K ) and the concept order form a complete lattice. The concept lattice of the context in table 1, with full and reduced labeling, is shown in fig.1. Full labeling means that a concept node is depicted with its full extent and intent. A reduced labeled concept lattice shows an object only in the smallest (w.r.t. the concept order of definition 2.2) concept of whose extent the object is a member. This concept is called the object concept , or the concept that introduces the object. Likewise, an attribute is shown only in the largest concept of whose intent the attribute is a member, the attribute concept , which introduces the attribute. The closedness of extents and intents has an important consequence for neuroscientific applications. Adding attributes to M (e.g. responses of additional neurons) will very probably grow IB ( K ) . However, the original concepts will be embedded as a substructure in the larger lattice, with their ordering relationships preserved. Figure 1: Concept lattice computed from the context in table 1. Each node is a concept, arrows represent superconcept relation, i.e. an arrow from X to Y reads: X is a superconcept of Y . Colors correspond to table 1, right. The number in the leftmost compartment is the concept number. Middle compartment contains the extent, rightmost compartment the intent. Left : fully labeled concepts, i.e. all members of extents and intents are listed in each concept node. Right : reduced labeling. An object/attribute is only listed in the extent/intent of the smallest/largest concept that contains it. Reduced labeling is very useful for drawing large concept lattices.
 The lattice diagrams make the ordering relationship between the concepts graphically explicit: con-cept 3 contains all  X  X onkey-related X  stimuli, concept 2 encompasses all  X  X aces X . They have a com-mon child, concept 4, which is the  X  X onkeyFace X  concept. The  X  X pider X  concept (concept 1) is incomparable to any other concept except the top and the bottom of the lattice. Note that these re-lationships arise as a consequence of the (here hypothetical) response behavior of the neurons. We will show (section 5) that the response patterns of real neurons can lead to similarly interpretable structures.
 From a decoding perspective, a fully labeled concept shows those stimuli that have activated at least the set of neurons in the intent. In contrast, the stimuli associated with a concept in reduced labeling will activate the set of neurons in the intent, but no others. The fully labeled concepts show stimuli encoded by activity of the active neurons of the concept without knowledge of the firing state of the other neurons. Reduced labels, on the other hand show those stimuli that elicited a response only from the neurons in the intent. One feature of neural codes which has attracted a considerable amount of interest is its sparseness . In the case of a binary neural code, the sparseness of a codeword is inversely related to the fraction of active neurons. The average sparseness across all codewords is the sparseness of the code [12, 13]. Sparse codes, i.e. codes where this fraction is low, are found interesting for a variety of reasons: they offer a good compromise between encoding capacity, ease of decoding and robustness [14], they seem to be employed in the mammalian visual processing system [15] and they are well suited to representing the visual environment we live in [15, 16]. It is also possible to define sparseness for graded or even continuous-valued responses (see e.g. [17, 4, 13]). To study what structural effects different levels of sparseness would have on a neural code, we generated random codes, i.e. each of 10 stimuli was associated with randomly drawn responses of 10 neurons, subject to the constraints that the code be perfectly decodable and that the sparseness of each codeword was equal to the sparseness of the code. Fig.2 shows the contexts (represented as cross-tables) and the concept lattices of a local code (activity ratio 0.1), a sparse code (activity ratio 0.2) and a dense code (activity ratio 0.5). Figure 2: Contexts (represented as cross-tables) and concept lattices for a local, sparse and dense random neural code. Each context was built out of the responses of 10 (hypothetical) neurons to 10 stimuli. Each node represents a concept, the left(right) compartment contains the number of introduced stimuli(neurons). In a local code, the response patters to different stimuli have no overlapping activations, hence the lattice representing this code is an antichain with top and bottom element added. Each concept in the antichain introduces (at least) one stimulus and (at least) one neuron. In contrast, a dense code results in a lot of concepts which introduce neither a stimulus nor a neuron. The lattice of the dense code is also substantially longer than that of the sparse and local codes.
 The most obvious differences between the lattices is the total number of concepts. A dense code, even for a small number of stimuli, will give rise to a lot of concepts, because the neuron sets repre-senting the stimuli are very probably going to have non-empty intersections. These intersections are potentially the intents of concepts which are larger than those concepts that introduce the stimuli. Hence, the latter are found towards the bottom of the lattice. This implies that they have large intents, which is of course a consequence of the density of the code. Determining these intents thus requires the observation of a large number of neurons, which is unappealing from a decoding perspective. The local code does not have this drawback, but is hampered by a small encoding capacity (maximal number of concepts with non-empty extents): the concept lattice in fig.2 is the largest one which can be constructed for a local code comprised of 10 binary neurons. Which of the above structures is most appropriate depends on the conceptual structure of environment to be encoded. To explore whether FCA is a suitable tool for interpreting real neural codes, we constructed formal contexts from the responses of high-level visual cortical cells in area STSa (part of the temporal lobe) of monkeys. Characterizing the responses of these cells is a difficult task. They exhibit complex nonlinearities and invariances which make it impossible to apply linear techniques, such as reverse correlation [18, 19, 20]. The concept lattice obtained by FCA might enable us to display and browse these invariances: if the response of a subset of cells indicates the presence of an invariant feature in a stimulus, then all stimuli having this feature should form the extent of a concept whose intent is given by the responding cells, much like the  X  X onkey X  and  X  X ace X  concepts in the example in section 2. 4.1 Physiological data The data were obtained through [21], where the experimental details can be found. Briefly, spike trains were obtained from neurons within the upper and lower banks of the superior temporal sulcus (STSa) via standard extracellular recording techniques [22] from an awake and behaving monkey ( Macaca mulatta ) performing a fixation task. This area contains cells which are responsive to faces. The recorded firing patters were turned into distinct samples, each of which contained the spikes from  X  300 ms before to 600 ms after the stimulus onset with a temporal resolution of 1 ms. The stimulus set consisted of 1704 images, containing color and black and white views of human and monkey head and body, animals, fruits, natural outdoor scenes, abstract drawings and cartoons. Stimuli were presented for 55ms each without inter-stimulus gaps in random sequences. While this rapid serial visual presentation (RSVP) paradigm complicates the task of extracting stimulus-related information from the spiketrains, it has the advantage of allowing for the testing of a large number of stimuli. A given cell was tested on a subset of 600 or 1200 of these stimuli, each stimulus was presented between 1-15 times. 4.2 Bayesian thresholding Before we can apply FCA, we need to extract a binary attribute from the raw spiketrains. While FCA can also deal with many-valued attributes, see [23, 9], we will employ binary thresholding as a starting point. Moreover, when time windows are limited (e.g. in the RSVP condition) it is usually impossible to extract more than 1 bit of stimulus identity-related information from a spiketrain per stimulus [24]. We do not suggest that real neurons have a binary activation function. We are merely concerned with finding a maximally informative response binarization, to allow for the construction of meaningful concepts. We do this by Bayesian thresholding, as detailed in appendix A. This procedure also avails us of a null hypothesis H 0 =  X  X he responses contain no information about the stimuli X . 4.3 Cell selection The experimental data consisted of recordings from 26 cells. To minimize the risk that the com-puted neural responses were a result of random fluctuations, we excluded a cell if 1.) H 0 was more probable than 10  X  6 or 2.) the posterior standard deviations of the counting window parameters were larger than 20 ms , indicating large uncertainties about the response timing. Cells which did not respond above the threshold included all cells excluded by the above criteria (except one). Fur-thermore, since not all cells were tested on all stimuli, we also had to select pairs of subsets of cells and stimuli such that all cells in a pair were tested on all stimuli. Incidentally, this selection can also be accomplished with FCA, by determining the concepts of a context with gJm =  X  X timulus g was tested on cell m  X  and selecting those with a large number of stimuli  X  number of cells. Two of these cell and stimulus subset pairs ( X  X  X , containing 364 stimuli and 13 cells, and  X  X  X , containing 600 stimuli, 12 cells) were selected for further analysis. To analyze the neural code, the thresholded neural resposes were used to build stimulus-by-cell-response contexts. We performed FCA on these with C OLIBRI C ONCEPTS 1 , created stimulus image montages and plotted the lattices 2 . The complete concept lattices were too large to display on a page. Graphs of lattices A and B with reduced labeling on the stimuli are included in the supplementary Figure 3: A : a subgraph of lattice A with reduced labeling on the stimuli, i.e. stimuli are only shown in their object concepts. The  X  indicates that an extent is the intersection of its superconcepts X  extents, i.e. no new stimuli were introduced by this concept. All cells forming this part of the concept lattice were responsive to faces. B : a subgraph of lattice B, fully labeled. The concepts on the right side are not exclusively  X  X ace X  concepts, but most members of their extents have something  X  X oundish X  about them. material (files latticeA neuroFCA.pdf and latticeB neuroFCA.pdf ). In these graphs, the top of the frame around each concept image contains the concept number and the list of cells in the intent.
 Fig.3, A shows a subgraph from lattice A, which exclusively contained  X  X ace X  concepts. faceSubgraphLatticeA neuroFCA.pdf ). The top concepts introduce human and cartoon faces, i.e. their extents are consist of general  X  X ace X  images, while their intents are small (3 cells). In contrast, the lower concepts introduce mostly single monkey faces, with the bottom concepts having an intent of 7 cells. We may interpret this as an indication that the neural code has a higher  X  X esolution X  for faces of conspecifics than for faces in general, i.e. other monkeys are represented in greater detail in a monkey X  X  brain than humans or cartoons. This feature can be observed in most lattices we generated.
 Fig.3, B shows a subgraph from lattice B with full labeling. The concepts in the left half of the graph are face concepts, whereas the extents of the concepts in the right half also contain a number of non-face stimuli. Most of the latter have something  X  X oundish X  about them. The bottom concept, being subordinate to both the  X  X ound X  and the  X  X ace X  concepts, encompasses stimuli with both char-acteristics, which points towards a product-of-experts encoding [25]. This example also highlights another advantage of FCA over standard hierarchical analysis techniques, e.g. hierarchical cluster-ing: it does not impose a tree structure when the data do not support it (a shortcoming of the analysis in [26]).
 For preliminary validation, we experimented with stimulus shuffling (i.e. randomly assigning stimuli to the recorded responses) to determine whether the found concepts are indeed meaningful. This procedure leaves the lattice structure intact, but mixes up the extents. A  X  X aive X  observer was then concept stability was obtained by trying different binarization thresholds: as stated in appendix A, we used a threshold probability of 0.5. This threshold can be raised up to 0.7 without losing any of the conceptual structures described in fig.3, although some of the stimuli migrate upwards in the lattice. We demonstrated the potential usefulness of FCA for the exploration and interpretation of neural codes. This technique is feasible even for high-level visual codes, where linear decoding methods [19, 20] fail, and it provides qualitative information about the structure of the code which goes beyond stimulus label decoding [4]. Clearly, this application of FCA is still in its infancy. It would be very interesting to repeat the analysis presented here on data obtained from simultaneous multi-cell recordings, to elucidate whether the conceptual structures derived by FCA are used for decoding by real brains. On a larger scale than single neurons, FCA could also be employed to study the relationships in fMRI data [27].
 Acknowledgment D. Endres was supported by MRC fellowship G0501319.
 [1] A. P. Georgopoulos, A. B. Schwartz, and R. E. Kettner. Neuronal population coding of move-[2] P F  X  oldi  X  ak. The  X  X deal Homunculus X : Decoding neural population responses by Bayesian infer-[3] MW Oram, P F  X  oldi  X  ak, DI Perrett, and F Sengpiel. The  X  X deal Homunculus X : decoding neural [4] R. Q. Quiroga, L. Reddy, C. Koch, and I. Fried. Decoding Visual Inputs From Multiple Neu-[5] OR Duda, PE Hart, and DG Stork. Pattern classification . John Wiley &amp; Sons, New York, [6] T. M. Cover and J. A. Thomas. Elements of Information Theory . John Wiley &amp; Sons, New [7] P F  X  oldi  X  ak. Sparse neural representation for semantic indexing. In XIII Conference [8] R. Wille. Restructuring lattice theory: an approach based on hierarchies of concepts. In I. Rival, [9] Bernhard Ganter and Rudolf Wille. Formal Concept Analysis: Mathematical foundations . [10] B. Ganter, G. Stumme, and R. Wille, editors. Formal Concept Analysis, Foundations and [11] U. Priss. Formal concept analysis in information science. Annual Review of Information [12] P F  X  oldi  X  ak. Sparse coding in the primate cortex. In Michael A Arbib, editor, The Handbook of [13] P F  X  oldi  X  ak and D Endres. Sparse coding. Scholarpedia , 3(1):2984, 2008. [14] P F  X  oldi  X  ak. Forming sparse representations by local anti-Hebbian learning. Biological Cyber-[15] B. A Olshausen, D. J Field, and A Pelah. Sparse coding with an overcomplete basis set: a [16] Eero P Simoncelli and Bruno A Olshausen. Natural image statistics and neural representation. [17] ET Rolls and A Treves. The relative advantages of sparse versus distributed encoding for [18] P Dayan and LF Abbott. Theoretical Neuroscience . MIT Press, London, Cambridge, 2001. [19] J.P. Jones and L. A. Palmer. An evaluation of the two-dimensional Gabor filter model of simple [20] D. L. Ringach. Spatial structure and symmetry of simple-cell receptive fields in macaque [21] P F  X  oldi  X  ak, D Xiao, C Keysers, R Edwards, and DI Perrett. Rapid serial visual presentation [22] M. W. Oram and D. I. Perrett. Time course of neural responses discriminating different views [23] R. Wille and F. Lehmann. A triadic approach to formal concept analysis. In G. Ellis, R. Levin-[24] D. Endres. Bayesian and Information-Theoretic Tools for Neuroscience . PhD thesis, School [25] GE Hinton. Products of experts. In Ninth International Conference on Artificial Neural Net-[26] R Kiani, H Esteky, K Mirpour, and K Tanaka. Object category structure in response pat-[27] K. N. Kay, T. Naselaris, R. J. Prenger, and J. L. Gallant. Identifying natural images from [28] D. Endres and P. F  X  oldi  X  ak. Exact Bayesian bin classification: a fast alternative to bayesian A standard way of obtaining binary responses from neurons is thresholding the spike count within a certain time window. This is a relatively straightforward task, if the stimuli are presented well separated in time and a lot of trials per stimulus are available. Then latencies and response offsets are often clearly discernible and thus choosing the time window is not too difficult. However, under RSVP conditions with few trials per stimulus, response separation becomes more tricky, as the responses to subsequent stimuli will tend to follow each other without an intermediate return to baseline activity. Moreover, neural resposes tend to be rather noisy. We will therefore employ a simplified version of the generative Bayesian Bin classification algorithm (BBCa) [28], which was shown to perform well on RSVP data [24].
 BBCa was designed for the purpose of inferring stimulus labels g from a continuous-valued, scalar measure z of a neural response. The range of z is divided into a number of contiguous bins. Within each bin, the observation model for the g is a Bernoulli scheme with a Dirichlet prior over its param-eters. It is shown in [28] that one can iterate/integrate over all possible bin boundary configurations efficiently, thus making exact Bayesian inference feasible. We make two simplifications to BBCa: 1) z is discrete, because we are counting spikes and 2) we use models with only 1 bin boundary in the range of z . The bin membership of a given neural response can then serve as the binary attribute required for FCA, since BBCa weighs bin configurations by their classification (i.e. stimulus label decoding) performance. We proceed in a straight Bayesian fashion: since the bin membership is the only variable we are interested in, all other parameters (counting window size and position, class membership probabilities, bin boundaries) are marginalized. This minimizes the risk of spurious re-sults due to  X  X ontrived X  information (i.e. choices of parameters) made at some stage of the inference process. Afterwards, the probability that the response belongs to the upper bin is thresholded at a probability of 0.5. BBCa can also be used for model comparison. Running the algorithm with no bin boundaries in the range of z effectively yields the probability of the data given the  X  X ull hypothesis X  H 0 : z does not contain any information about g . We can then compare it against the alternative hypothesis described above (i.e. the information which bin z is in tells us something about g ) to
