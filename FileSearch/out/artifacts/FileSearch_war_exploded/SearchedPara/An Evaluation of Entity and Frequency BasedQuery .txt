 We present a semantic approach to suggesting query com-pletions which leverages entity and type information. When compared to a frequency-based approach, we show that such information mostly helps rare queries.
 H.3.3 [ Information Search and Retrieval ]: Query For-mulation Algorithms, Experimentation, Measurement Query Completion, Query Log Analysis, Web Search
From the days of boolean search on library catalogues, users have reformulated their queries after an inspection of initial search results. Traditional information retrieval stud-ies this in frameworks such as query expansion, relevance feedback, interactive retrieval, etc. These methods mostly exploit document contents because that is typically all in-formation that is available. The situation is very different in web search engines because of the large amounts of users whose queries are collected in query logs . Query logs reflect how large numbers of users express their queries and can be a rich source of information when optimizing search results [3] or determining query suggestions [1, 4, 5].

In this paper we study a special case of query sugges-tion: query completion, which aims to help users complete their queries. In particular, we are interested in comparing a commonly adopted frequency-based approach with meth-ods that exploit an understanding of the type of entities in queries. Our intuition is that completion for rare queries can be improved by understanding the type of entity being sought. For example, if we know that  X  X X354 X  is a kind of digital camera, we can generate sensible completions by choosing them from the set of completions used with other digital cameras. Besides suggesting queries, the obtained completions can also function as facets for faceted brows-ing or as input for ontology engineering since they represent query refinements common to a class of entities. In this paper, we address the following questions: (i) How can we recognize entities and their types in queries? (ii) How can we rank possible completions given an entity type? (iii) How can our methods be evaluated and how do they per-form? To address (iii), we propose a novel method which evaluates the prediction of real web queries. We show that a purely frequency-based approach without any entity type information works quite well for more frequent queries, but is surpassed by type-based methods for rare queries.
In this section we introduce our notations and proposed type-based methods. We assume queries can be decomposed in an entity part e and a completion part f and that entities can be assigned a type T . Table 1 shows some examples. In case the query contains both a prefix and suffix, we treat it as two separate queries. Given a set of such queries, we determine the matrix N = ( n ef ) e,f , where n ef is the number of times we see f with e . By grouping all entities of a certain type we can, for example, compute n Tf := P e  X  T n ef which is the number of times we see completion f with an entity of type T . Using N, we can readily estimate probabilities such as P ( f ), P ( f | e ), P ( f | T ), and P ( e | f,T ). Imagine that a user is typing a query and we recognize what she has typed so far as an entity with a corresponding type. The most naive approach (and the one taken by most search engines) would be to suggest the most frequent completions for the entity ( M0 ): score M 0 ( f,e ) = P ( f | e ) . Given an in-finite amount of data this should suffice. However, it will probably fail for rare entities since we will have no or very few completions for these. Thus, we turn to the type and smooth the entity distribution with the type distribution.
M1 looks at the most likely completion for the current type: score M 1 ( f,T ) = P ( f | T ) . Another desirable property a completion should have, is being rare over all types. M2 rewards such completions: score M 2 ( f,T ) = P ( f | T ) intuition is that completions which are frequent as well as evenly distributed among the entities in the type should be rewarded ( M3 ): score M 3 ( f,T ) = G ( f | T ) = ` Q e  X  T The final method ( M4 ) only considers the distribution of completions within the type: score M 4 ( f,T ) = H (  X  f | T H is the entropy of the multinomial  X  f | T = ( P ( e | f,T ))
To detect entities in queries, we use a dictionary (i.e. a list of all the entities of each type) and match the largest sub-string common to the query and the dictionary. Dictionaries can be built from taxonomies which list entities of different types. We derive a taxonomy from Wikipedia categories and assume that every category constitutes a type (e.g. for the entity  X  X adonna X : American actor-singers, American + side effects Anti-inflammatory drugs  X  how to take Anti-inflammatory drugs + video American film actors dancers, etc.). Further, every article listed in a category constitutes an entity of that type 1 . Wikipedia is very large with a broad coverage and it defines many possible enti-ties (our version has 1,970,637 entities and 269,393 types). Wikipedia entries can belong to many categories (e.g. 34 for  X  X adonna X ). So, we need a method to choose the best entity type. This is a challenging research question in itself; trivial methods such as choosing the most frequent or rarest type did not work well. Instead, we apply M1 on the training data and evaluate the performance of all possible types of each entity. We then choose the type that led to the best performance on the training set. For entities not present in the training set we select the type with the most entities.
For evaluation, we compare the highest scoring comple-tions of the various methods with the actual observed re-mainder of the queries in the test set. We use 6 consecutive days of query logs which we split equally into a training and a test set. We analyze each query and if it contains an entity we keep it. This results in 1,681,753 queries for training and 1,644,033 for testing. For each query, we compute the top K = 10 completions predicted by each method. The cor-rect completion for that query is the one typed by the user. We are interested in two evaluation measures: (i) Success Rate @ K (SR), i.e. whether the completion is correctly predicted and (ii) Mean Reciprocal Rank @ K (MRR), i.e. the mean of the inverse of the ranks at which the comple-tion was found, up to K . Table 2 shows the results over all test queries. As is clear from the low absolute scores, the task of suggesting the correct completion is a difficult one. The highest obtained MRR is 0.178 for M0 with queries that occur around 1000 times. M0 outperforms the type-based methods on almost all queries and measures. However, as
We remove any disambiguation part in the entry title. This has the adverse effect of introducing noise, e.g. collapsing Madonna (art) and Madonna (entertainer). Disambiguating such queries is beyond the scope of the current work but could, e.g., be achieved by leveraging a user X  X  history [2]. indicated by Figure 1, the type-based methods M1 and M3 perform slightly better than M0 for less frequent queries (oc-curring 40 times or less and making up 12.7% of the total query volume). For other queries, M0 outperforms all other methods although the difference with M1 is usually small. The reason for the drop in performance for frequently oc-curring queries is that these mostly consist of entities such as  X  X n X ,  X  X o X , and  X  X he X  (which are Wikipedia entries, but do not seem sensible entities).
We have presented a semantic approach to suggesting query completions, which leverages entity and type information. We evaluate various methods and compare them to a purely frequency-based approach. The results show that type-based information mostly helps queries which do not occur fre-quently. Our current work is only the first step towards a thorough evaluation methodology for this task. Future work includes performing a user study to obtain an indication of the usability of the type-based suggestions. We also intend to look at different ways of defining entity types and the mapping of entities to types.
