 Grapheme-to-phoneme conversion (G2P), in which the aim is to convert the orthography of a word to its pronunciation (phonetic transcription), plays an im-portant role in speech synthesis and understanding. Names, which comprise over 75% of unseen words (Black et al., 1998), present a particular challenge to G2P systems because of their high pronunciation variability. Guessing the correct pronunciation of a name is often difficult, especially if they are of for-eign origin; this is attested by the ad hoc transcrip-tions which sometimes accompany new names intro-duced in news articles, especially for international stories with many foreign names.

Transliterations provide a way of disambiguating the pronunciation of names. They are more abun-dant than phonetic transcriptions, for example when news items of international or global significance are reported in multiple languages. In addition, writing scripts such as Arabic, Korean, or Hindi are more consistent and easier to identify than various pho-netic transcription schemes. The process of translit-eration, also called phonetic translation (Li et al., 2009b), involves  X  X ounding out X  a name and then finding the closest possible representation of the sounds in another writing script. Thus, the correct pronunciation of a name is partially encoded in the form of the transliteration. For example, given the ambiguous letter-to-phoneme mapping of the En-glish letter g , the initial phoneme of the name Gersh-win may be predicted by a G2P system to be ei-ther /g/ (as in Gertrude ) or / X / (as in Gerald ). The transliterations of the name in other scripts provide support for the former (correct) alternative.
Although it seems evident that transliterations should be helpful in determining the correct pronun-ciation of a name, designing a system that takes ad-vantage of this insight is not trivial. The main source of the difficulty stems from the differences between the phonologies of distinct languages. The mappings between phonemic inventories are often complex and context-dependent. For example, because Hindi has no /w/ sound, the transliteration of Gershwin instead uses a symbol that represents the phoneme /V/ , similar to the /v/ phoneme in English. In ad-dition, converting transliterations into phonemes is often non-trivial; although few orthographies are as inconsistent as that of English, this is effectively the G2P task for the particular language in question.
In this paper, we demonstrate that leveraging transliterations can, in fact, improve the grapheme-to-phoneme conversion of names. We propose a novel system based on discriminative re-ranking that is capable of incorporating multiple transliterations. We show that simplistic approaches to the problem fail to achieve the same goal, and that translitera-tions from multiple languages are more helpful than from a single language. Our approach can be com-bined with any G2P system that produces n -best lists instead of single outputs. The experiments that we perform demonstrate significant error reduction for three very different G2P base systems. 2.1 Problem definition In both G2P and machine transliteration, we are in-terested in learning a function that, given an input sequence x , produces an output sequence y . In the G2P task, x is composed of graphemes and y is composed of phonemes; in transliteration, both se-quences consist of graphemes but they represent dif-ferent writing scripts. Unlike in machine translation, the monotonicity constraint is enforced; i.e., we as-sume that x and y can be aligned without the align-ment links crossing each other (Jiampojamarn and Kondrak, 2010). We assume that we have available a base G2P system that produces an n -best list of out-puts with a corresponding list of confidence scores. The goal is to improve the base system X  X  perfor-mance by applying existing transliterations of the in-put x to re-rank the system X  X  n -best output list. 2.2 Similarity-based methods A simple and intuitive approach to improving G2P with transliterations is to select from the n -best list the output sequence that is most similar to the cor-responding transliteration. For example, the Hindi transliteration in Figure 1 is arguably closest in per-ceptual terms to the phonetic transcription of the second output in the n -best list, as compared to the other outputs. One obvious problem with this method is that it ignores the relative ordering of the n -best lists and their corresponding scores produced by the base system.

A better approach is to combine the similarity score with the output score from the base system, al-lowing it to contribute an estimate of confidence in its output. For this purpose, we apply a linear combi-nation of the two scores, where a single parameter  X  , ranging between zero and one, determines the rela-tive weight of the scores. The exact value of  X  can be optimized on a training set. This approach is similar to the method used by Finch and Sumita (2010) to combine the scores of two different machine translit-eration systems. 2.3 Measuring similarity The approaches presented in the previous section crucially depend on a method for computing the similarity between various symbol sequences that represent the same word. If we have a method of converting transliterations to phonetic represen-tations, the similarity between two sequences of phonemes can be computed with a simple method such as normalized edit distance or the longest com-mon subsequence ratio, which take into account the number and position of identical phonemes. Alter-natively, we could apply a more complex approach, such as ALINE (Kondrak, 2000), which computes the distance between pairs of phonemes. However, the implementation of a conversion program would require ample training data or language-specific ex-pertise.

A more general approach is to skip the tran-scription step and compute the similarity between phonemes and graphemes directly. For example, the edit distance function can be learned from a training set of transliterations and their phonetic transcrip-tions (Ristad and Yianilos, 1998). In this paper, we apply M2M-A LIGNER (Jiampojamarn et al., 2007), an unsupervised aligner, which is a many-to-many generalization of the learned edit distance algorithm. M2M-A LIGNER was originally designed to align graphemes and phonemes, but can be applied to dis-cover the alignment between any sets of symbols (given training data). The logarithm of the probabil-ity assigned to the optimal alignment can then be interpreted as a similarity measure between the two sequences. 2.4 Discriminative re-ranking The methods described in Section 2.2, which are based on the similarity between outputs and translit-erations, are difficult to generalize when multiple transliterations of a single name are available. A lin-ear combination is still possible but in this case opti-mizing the parameters would no longer be straight-forward. Also, we are interested in utilizing other features besides sequence similarity.

The SVM re-ranking paradigm offers a solution to the problem. Our re-ranking system is informed by a large number of features, which are based on scores and n -grams. The scores are of three types: 1. The scores produced by the base system for 2. The similarity scores between the outputs and 3. The differences between scores in the n -best
Our set of binary n -gram features includes those used for D IREC TL+ (Jiampojamarn et al., 2010). They can be divided into four types: 1. The context features combine output symbols 2. The transition features are bigrams on the out-3. The linear chain features combine the context 4. The joint n -gram features are n -grams contain-We apply the features in a new way: instead of be-ing applied strictly to a given input-output set, we expand their use across many languages and use all of them simultaneously. We apply the n -gram fea-tures across all transliteration-transcription pairs in addition to the usual input-output pairs correspond-ing to the n -best lists. Figure 1 illustrates the set of pairs used for feature generation.

In this paper, we augment the n -gram features by a set of reverse features. Unlike a traditional G2P generator, our re-ranker has access to the outputs produced by the base system. By swapping the input and the output side, we can add reverse context and linear-chain features. Since the n -gram features are also applied to transliteration-transcription pairs, the reverse features enable us to include features which bind a variety of n -grams in the transliteration string with a single corresponding phoneme.

The construction of n -gram features presupposes a fixed alignment between the input and output se-quences. If the base G2P system does not provide input-output alignments, we use M2M-A LIGNER for this purpose. The transliteration-transcription pairs are also aligned by M2M-A LIGNER , which at the same time produces the corresponding similarity scores. (We set a lower limit of -100 on the M2M-A
LIGNER scores.) If M2M-A LIGNER is unable to produce an alignment, we indicate this with a binary feature that is included with the n -gram features. We perform several experiments to evaluate our transliteration-informed approaches. We test simple similarity-based approaches on single-transliteration data, and evaluate our SVM re-ranking approach against this as well. We then test our approach us-ing all available transliterations. Relevant code and scripts required to reproduce our experimental re-sults are available online 1 . 3.1 Data &amp; setup For pronunciation data, we extracted all names from the Combilex corpus (Richmond et al., 2009). We discarded all diacritics, duplicates and multi-word names, which yielded 10,084 unique names. Both the similarity and SVM methods require transliter-ations for identifying the best candidates in the n -best lists. They are therefore trained and evaluated on the subset of the G2P corpus for which transliter-ations available. Naturally, allowing transliterations from all languages results in a larger corpus than the one obtained by the intersection with transliterations from a single language.

For our experiments, we split the data into 10% for testing, 10% for development, and 80% for training. The development set was used for initial tests and experiments, and then for our final results the training and development sets were combined into one set for final system training. For SVM re-ranking, during both development and testing we split the training set into 10 folds; this is necessary when training the re-ranker as it must have system output scores that are representative of the scores on unseen data. We ensured that there was never any overlap between the training and testing data for all trained systems.

Our transliteration data come from the shared tasks on transliteration at the 2009 and 2010 Named Entities Workshops (Li et al., 2009a; Li et al., 2010). We use all of the 2010 English-source data plus the English-to-Russian data from 2009, which makes nine languages in total. In cases where the data provide alternative transliterations for a given in-put, we keep only one; our preliminary experiments indicated that including alternative transliterations did not improve performance. It should be noted that these transliteration corpora are noisy: Jiampo-jamarn et al. (2009) note a significant increase in English-to-Hindi transliteration performance with a simple cleaning of the data.

Our tests involving transliterations from multiple languages are performed on the set of names for which we have both the pronunciation and translit-eration data. There are 7,423 names in the G2P cor-pus for which at least one transliteration is available. Table 1 lists the total size of the transliteration cor-pora as well as the amount of overlap with the G2P data. Note that the base G2P systems are trained us-ing all 10,084 names in the corpus as opposed to only the 7,423 names for which there are transliter-ations available. This ensures that the G2P systems have more training data to provide the best possible base performance.

For our single-language experiments, we normal-ize the various scores when tuning the linear com-bination parameter  X  so that we can compare values across different experimental conditions. For SVM re-ranking, we directly implement the method of Joachims (2002) to convert the re-ranking problem into a classification problem, and then use the very fast LIBLINEAR (Fan et al., 2008) to build the SVM models. Optimal hyperparameter values were deter-mined during development.

We evaluate using word accuracy, the percentage of words for which the pronunciations are correctly predicted. This measure marks pronunciations that are even slightly different from the correct one as in-correct, so even a small change in pronunciation that might be acceptable or even unnoticeable to humans would count against the system X  X  performance. 3.2 Base systems It is important to test multiple base systems in order to ensure that any gain in performance applies to the task in general and not just to a particular system. We use three G2P systems in our tests: 1. F ESTIVAL (F EST ), a popular speech synthe-2. S EQUITUR (S EQ ), a generative system based 3. D IREC TL+ (DTL), the discriminative system All systems are capable of providing n -best output lists along with scores for each output, although for F
ESTIVAL they had to be constructed from the list of output probabilities for each input character.
We run D IREC TL+ with all of the features de-scribed in (Jiampojamarn et al., 2010) (i.e., context features, transition features, linear chain features, and joint n -gram features). System parameters, such as maximum number of iterations, were determined during development. For S EQUITUR , we keep de-fault options except for the enabling of the 10 best outputs and we convert the probabilities assigned to the outputs to log-probabilities. We set S EQUITUR  X  X  joint n -gram order to 6 (this was also determined during development).

Note that the three base systems differ slightly in terms of the alignment information that they pro-vide in their outputs. F ESTIVAL operates letter-by-letter, so we use the single-letter inputs with the phoneme outputs as the aligned units. D IREC TL+ specifies many-to-many alignments in its output. For S
EQUITUR , however, since it provides no informa-tion regarding the output structure, we use M2M-A
LIGNER to induce alignments for n -gram feature generation. 3.3 Transliterations from a single language The goal of the first experiment is to compare sev-eral similarity-based methods, and to determine how they compare to our re-ranking approach. In order to find the similarity between phonetic transcriptions, we use the two different methods described in Sec-tion 2.2: A LINE and M2M-A LIGNER . We further test the use of a linear combination of the similar-ity scores with the base system X  X  score so that its confidence information can be taken into account; the linear combination weight is determined from the training set. These methods are referred to as A
LINE +B ASE and M2M+B ASE . For these experi-ments, our training and testing sets are obtained by intersecting our G2P training and testing sets respec-tively with the Hindi transliteration corpus, yielding 1,950 names for training and 229 names for testing.
Since the similarity-based methods are designed to incorporate homogeneous same-script translitera-tions, we can only run this experiment on one lan-guage at a time. Furthermore, ALINE operates on phoneme sequences, so we first need to convert the transliterations to phonemes. An alternative would be to train a proper G2P system, but this would re-quire a large set of word-pronunciation pairs. For this experiment, we choose Hindi, for which we constructed a rule-based G2P converter. Aside from simple one-to-one mapping (romanization) rules, the converter has about ten rules to adjust for con-text.

For these experiments, we apply our SVM re-ranking method in two ways: 1. Using only Hindi transliterations (referred to as 2. Using all available languages (referred to as In both cases, the test set is restricted to the same 229 names, in order to provide a valid comparison.
Table 2 presents the results. Regardless of the choice of the similarity function, the simplest ap-proaches fail in a spectacular manner, significantly reducing the accuracy with respect to the base sys-tem. The linear combination methods give mixed re-sults, improving the accuracy for F ESTIVAL but not for S EQUITUR or D IREC TL+ (although the differ-ences are not statistically significant). However, they perform much better than the methods based on sim-ilarity scores alone as they are able to take advan-tage of the base system X  X  output scores. If we look at the values of  X  that provide the best performance on the training set, we find that they are higher for the stronger base systems, indicating more reliance on the base system output scores. For example, for A LINE +B ASE the F ESTIVAL -based system has  X  = 0 . 58 whereas the D IREC TL+-based system has  X  = 0 . 81 . Counter-intuitively, the A LINE +B ASE and M2M+B ASE methods are unable to improve upon S EQUITUR or D IREC TL+. We would expect to achieve at least the base system X  X  performance, but disparities between the training and testing sets prevent this.

The two SVM-based methods achieve much bet-ter results. SVM-A LL produces impressive accu-racy gains for all three base systems, while SVM-H
INDI yields smaller (but still statistically signifi-cant) improvements for F ESTIVAL and S EQUITUR . These results suggest that our re-ranking method provides a bigger boost to systems built with dif-ferent design principles than to D IREC TL+ which utilizes a similar set of features. On the other hand, the results also show that the information obtained by consulting a single transliteration may be insuf-ficient to improve an already high-performing G2P converter. 3.4 Transliterations from multiple languages Our second experiment expands upon the first; we use all available transliterations instead of being re-stricted to one language. This rules out the sim-ple similarity-based approaches, but allows us to test our re-ranking approach in a way that fully uti-lizes the available data. We test three variants of our transliteration-informed SVM re-ranking approach, which differ with respect to the set of included fea-tures: 1. SVM-S CORE includes only the three types of 2. SVM-N -GRAM uses only the n -gram features. 3. SVM-A LL is the full system that combines the The objective is to determine the degree to which each of the feature classes contributes to the overall results. Because we are using all available transliter-ations, we achieve much greater coverage over our G2P data than in the previous experiment; in this case, our training set consists of 6,660 names while the test set has 763 names.

Table 3 presents the results. Note that the base-line accuracies are somewhat lower than in Table 2 because of the different test set. We find that, when using all features, the SVM re-ranker can provide a very impressive error reduction over F ESTIVAL (26.7%) and S EQUITUR (20.7%) and a smaller but still significant ( p &lt; 0 . 01 with the McNemar test) error reduction over D IREC TL+ (12.1%).

When we consider our results using only the score and n -gram features, we can see that, interestingly, the n -gram features are most important. We draw a further conclusion from our results: consider the large disparity in improvements over the base sys-tems. This indicates that F ESTIVAL and S EQUITUR are benefiting from the D IREC TL+-style features used in the re-ranking. Without the n -gram fea-tures, however, there is still a significant improve-ment over F ESTIVAL , demonstrating that the scores do provide useful information. In this case there is no way for D IREC TL+-style information to make its way into the re-ranking; the process is based purely on the transliterations and their similarities with the transcriptions in the output lists, indicat-ing that the system is capable of extracting use-ful information directly from transliterations. In the case of D IREC TL+, the transliterations help through the n -gram features rather than the score features; this is probably because the crucial feature that signals the inability of M2M-A LIGNER to align a given transliteration-transcription pair belongs to the set of the n -gram features. Both the n -gram fea-tures and score features are dependent on the align-ments, but they differ in that the n -gram features allow weights to be learned for local n -gram pairs whereas the score features are based on global infor-mation, providing only a single feature for a given transliteration-transcription pair. The two therefore overlap to some degree, although the score fea-tures still provide useful information via probabili-ties learned during the alignment training process.
A closer look at the results provides additional insight into the operation of our re-ranking system. For example, consider the name Bacchus , which D I -REC TL+ incorrectly converts into /b X k X @s/ . The most likely reason why our re-ranker selects instead the correct pronunciation /b X k@s/ is that M2M-A
LIGNER fails to align three of the five available transliterations with /b X k X @s/ . Such alignment fail-ures are caused by a lack of evidence for the map-ping of the grapheme representing the sound /k/ in the transliteration training data with the phoneme / X / . In addition, the lack of alignments prevents any n -gram features from being enabled.

Considering the difficulty of the task, the top ac-curacy of almost 75% is quite impressive. In fact, many instances of human transliterations in our cor-pora are clearly incorrect. For example, the Hindi transliteration of Bacchus contains the / X / conso-nant instead of the correct /k/ . Moreover, our strict evaluation based on word accuracy counts all sys-tem outputs that fail to exactly match the dictio-nary data as errors. The differences are often very minor and may reflect an alternative pronunciation. The phoneme accuracy 2 of our best result is 93.1%, which provides some idea of how similar the pre-dicted pronunciation is to the correct one. 3.5 Effect of multiple transliterations One motivating factor for the use of SVM re-ranking was the ability to incorporate multiple transliteration languages. But how important is it to use more than one language? To examine this question, we look particularly at the sets of names having at most k transliterations available. Table 4 shows the results with D IREC TL+ as the base system. Note that the number of names with more than five transliterations was small. Importantly, we see that the increase in performance when only one transliteration is avail-able is so small as to be insignificant. From this, we can conclude that obtaining improvement on the ba-sis of a single transliteration is difficult in general. This corroborates the results of the experiment de-scribed in Section 3.3, where we used only Hindi transliterations. There are three lines of research that are relevant to our work: (1) G2P in general; (2) G2P on names; and (3) combining diverse data sources and/or systems.
The two leading approaches to G2P are repre-sented by S EQUITUR (Bisani and Ney, 2008) and D
IREC TL+ (Jiampojamarn et al., 2010). Recent comparisons suggests that the former obtains some-what higher accuracy, especially when it includes joint n -gram features (Jiampojamarn et al., 2010). Systems based on decision trees are far behind. Our results confirm this ranking.

Names can present a particular challenge to G2P systems. Kienappel and Kneser (2001) reported a higher error rate for German names than for general words, while on the other hand Black et al. (1998) report similar accuracy on names as for other types of English words. Yang et al. (2006) and van den Heuvel et al. (2007) post-process the output of a general G2P system with name-specific phoneme-to-phoneme (P2P) systems. They find significant im-provement using this method on data sets consisting of Dutch first names, family names, and geograph-ical names. However, it is unclear whether such an approach would be able to improve the performance of the current state-of-the-art G2P systems. In addi-tion, the P2P approach works only on single outputs, whereas our re-ranking approach is designed to han-dle n -best output lists.

Although our approach is (to the best of our knowledge) the first to use different tasks (G2P and transliteration) to inform each other, this is concep-tually similar to model and system combination ap-proaches. In statistical machine translation (SMT), methods that incorporate translations from other lan-guages (Cohn and Lapata, 2007) have proven effec-tive in low-resource situations: when phrase trans-lations are unavailable for a certain language, one can look at other languages where the translation is available and then translate from that language. A similar pivoting approach has also been applied to machine transliteration (Zhang et al., 2010). No-tably, the focus of these works have been on cases in which there are less data available; they also modify the generation process directly, rather than operating on existing outputs as we do. Ultimately, a combina-tion of the two approaches is likely to give the best results.

Finch and Sumita (2010) combine two very dif-ferent approaches to transliteration using simple lin-ear interpolation: they use S EQUITUR  X  X  n -best out-puts and re-rank them using a linear combination of the original S EQUITUR score and the score for that output of a phrased-based SMT system. The lin-ear weights are hand-tuned. We similarly use linear combinations, but with many more scores and other features, necessitating the use of SVMs to determine the weights. Importantly, we combine different data types where they combine different systems . In this paper, we explored the application of translit-erations to G2P. We demonstrated that transliter-ations have the potential for helping choose be-tween n -best output lists provided by standard G2P systems. Simple approaches based solely on sim-ilarity do not work when tested using a single transliteration language (Hindi), necessitating the use of smarter methods that can incorporate mul-tiple transliteration languages. We apply SVM re-ranking to this task, enabling us to use a variety of features based not only on similarity scores but on n -grams as well. Our method shows impressive error reductions over the popular F ESTIVAL sys-tem and the generative joint n -gram S EQUITUR sys-tem. We also find significant error reduction using the state-of-the-art D IREC TL+ system. Our analy-sis demonstrated that it is essential to provide the re-ranking system with transliterations from multi-ple languages in order to mitigate the differences between phonological inventories and smooth out noise in the transliterations.

In the future, we plan to generalize our approach so that it can be applied to the task of generating transliterations, and to combine data from distinct G2P dictionaries. The latter task is related to the no-tion of domain adaptation. We would also like to ap-ply our approach to web data; we have shown that it is possible to use noisy transliteration data, so it may be possible to leverage the noisy ad hoc pronuncia-tion data as well. Finally, we plan to investigate ear-lier integration of such external information into the G2P process for single systems; while we noted that re-ranking provides a general approach applicable to any system that can generate n -best lists, there is a limit as to what re-ranking can do, as it relies on the correct output existing in the n -best list. Modifying existing systems would provide greater potential for improving results even though the changes would be necessarily system-specific.
 We are grateful to Sittichai Jiampojamarn and Shane Bergsma for the very helpful discussions. This re-search was supported by the Natural Sciences and Engineering Research Council of Canada.
