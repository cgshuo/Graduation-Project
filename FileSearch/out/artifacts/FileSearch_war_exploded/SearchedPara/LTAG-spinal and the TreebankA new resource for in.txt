 Libin Shen  X  Lucas Champollion  X  Aravind K. Joshi Abstract We introduce LTAG-spinal, a novel variant of traditional Lexicalized Tree Adjoining Grammar (LTAG) with desirable linguistic, computational and statistical properties. Unlike in traditional LTAG, subcategorization frames and the argument X  X djunct distinction are left underspecified in LTAG-spinal. LTAG-spinal with adjunction constraints is weakly equivalent to LTAG. The LTAG-spinal for-malism is used to extract an LTAG-spinal Treebank from the Penn Treebank with Propbank annotation. Based on Propbank annotation, predicate coordination and LTAG adjunction structures are successfully extracted. The LTAG-spinal Treebank makes explicit semantic relations that are implicit or absent from the original PTB. LTAG-spinal provides a very desirable resource for statistical LTAG parsing, incremental parsing, dependency parsing, and semantic parsing. This treebank has been successfully used to train an incremental LTAG-spinal parser and a bidirec-tional LTAG dependency parser.
 Keywords Tree Adjoining Grammar LTAG-spinal Treebank Dependency parsing Abbreviation LTAG Lexicalized Tree Adjoining Grammar 1 Introduction Lexicalized Tree Adjoining Grammar (LTAG) (Joshi and Schabes 1997 ) has attractive properties from the point of view of Natural Language Processing (NLP). LTAG has appropriate generative capacity (LTAG languages belong to the class of mildly context-sensitive languages) and a strong linguistic foundation.

In this article, we introduce LTAG-spinal, a variant of LTAG with very desirable linguistic, computational, and statistical properties. LTAG-spinal with adjunction constraints is weakly equivalent to traditional LTAG.

We first provide a brief introduction of LTAG in Sect. 1.1 . In Sect. 1.2 ,we describe the motivation for the LTAG-spinal formalism. In Sect. 2 , we introduce the definition of LTAG-spinal. Then we describe the process of extracting an LTAG-spinal Treebank from the Penn Treebank (PTB) (Marcus et al. 1994 ), together with Propbank annotation (Palmer et al. 2005 ) in Sect. 3 . We illustrate the extracted LTAG-spinal Treebank and its treatment of certain syntactic phenomena of linguistic interest in Sect. 4 . We also present the statistical properties of the LTAG-spinal Treebank in Sect. 5 , especially the compatibility with the Propbank. We discuss our conclusions and future work in Sect. 6 . 1.1 Lexicalized Tree Adjoining Grammar Tree Adjoining Grammar (TAG) was first introduced in (Joshi et al. 1975 ). A recent review of TAG is given in (Abeille  X  and Rambow 2001 ), which provides a detailed description of TAG with respect to linguistic, formal, and computational properties (see also Frank 2002 ). In this section, we briefly describe the TAG formalism and its relation to linguistics.

In traditional lexicalized TAG, each word is associated with a set of elementary trees , or e-trees for short. Each e-tree represents a possible tree structure for the word.
There are two kinds of e-trees, initial trees and auxiliary trees . A derivation always starts with an initial tree. Auxiliary trees must have a foot node , a leaf node whose label is identical to the label of the root. E-trees can be combined through two operations, substitution and adjunction . Substitution is used to attach an initial tree a into a substitution slot of a host tree a 0 . Substitution slots are specially marked leaf nodes whose label must be identical with the root of a . Adjunction is used to attach an auxiliary tree a to a node n of a host tree a 0 . n must carry the same label as the root and foot nodes of a . Adjunction is carried out by replacing the node n with the entire tree a . The foot node of a is then replaced by the subtree under n .
The tree resulting from the combination of e-trees is called a derived tree .We can record the history of a derivation by building a derivation tree , in which every e-tree used in the derivation is represented by a single node and every operation by a single arc, whose parent is the host tree of the operation. 1.2 Motivation for LTAG-spinal For the purpose of statistical processing, we need a large scale LTAG style treebank. As far as automatic treebank extraction and statistical processing is concerned, a variant of traditional LTAG, namely LTAG-spinal, turns out to be more attractive. We now illustrate these two aspects in turn. 1.2.1 LTAG Treebank Extraction LTAG encodes the subcategorization frames of predicates explicitly by modeling each predicate as an e-tree that contains substitution slots for (obligatory) arguments but not for (optional) adjuncts. Predicates with more than one subcategorization frame are represented with multiple e-trees.

In previous work of LTAG treebank extraction (Xia 2001 ; Chen et al. 2006 ), heuristic rules were used to distinguish arguments from adjuncts. However, e-trees extracted in this way are different from the e-trees of a handcrafted LTAG grammar, e.g., the XTAG English grammar (XTAG-Group 2001 ). It turns out to be a non-trivial task to map the automatically generated templates to those in the XTAG grammar. One extracted e-tree can be mapped to several XTAG e-trees which differ in their feature structures. It is difficult to obtain this information from the original resources.

Therefore, we desire a framework in which the representations for arguments and adjuncts are similar. In this way, we can encode the ambiguity with a single structure, and leave the disambiguation for further processing.

Our solution is a sister adjunction like operation. Sister adjunction was previously proposed to represent adjuncts in Chiang ( 2000 ) for Tree Insertion Grammars (TIG) (Schabes and Waters 1995 ), as well as in D-Tree substitution grammars (Rambow et al. 2001 ). We call our operation attachment (see below for a definition). We use attachment both for arguments and for non-predicate adjuncts, 1 thereby encoding argument X  X djunct ambiguity.

The extended domain of locality (EDL) (Joshi and Schabes 1997 ) of LTAG is still retained in the sense that syntactically dependent arguments are directly attached to the predicate. By domain of locality, we mean a domain over which various kinds of syntactic dependencies can be specified. In traditional LTAG, EDL extended projections of lexical items. In our presentation, EDL is expressed in terms of soft constraints, in particular in terms of the distributions of argument and adjunct attachment operations.

As a result, our e-trees are in the so-called spinal form since arguments do not appear in the e-tree of the predicate. 1.2.2 Statistical processing The complexity of using automatically extracted LTAG templates in parsing is greatly increased due to increased local ambiguity (i.e., the average number of e-trees per word). According to the coarse to fine approach (Charniak and Johnson 2005 ), it is attractive to use some structure to encode these templates, so as to make the search space more tractable at each step of parsing.

The LTAG-spinal formalism, which we formally introduce in the next section, substantially reduces the local ambiguity. For example, the e-tree of a transitive verb and the e-tree of a ditransitive verb have identical spines from the S node to the V node. In parsing, when we encounter a predicate of a given sentence, we do not need to guess its subcategorization frame immediately. Instead, we use the spinal form to represent a verb without its subcategorization frame. We defer identifying the correct subcategorization frames to a later stage in the processing chain, when enough contextual information becomes available, in a way similar to Charniak ( 1997 ) and Collins ( 1999 ).

To sum up, the key reasons that lead us to adopt the LTAG-spinal framework are these: Unlike traditional LTAG, LTAG-spinal does not encode the argument X  adjunct distinction explicitly, which makes it easier to automatically convert the PTB to LTAG-spinal format. LTAG-spinal trees generalize over predicates with different subcategorization frames, which follows the coarse to fine spirit and alleviates the sparse data problem for parsing. In particular, the parser is not forced to make a decision on subcategorization without enough contextual information. 2 Formalism In LTAG-spinal, just as in traditional LTAG, we have two kinds of e-trees, initial trees and auxiliary trees (see Fig. 1 ). What makes LTAG-spinal novel is that e-trees are in the spinal form. A spinal initial tree is composed of a lexical spine from the root to the anchor, and nothing else. A spinal auxiliary tree is composed of a lexical spine and a recursive spine from the root to the foot node. For example, in Fig. 1 , B , ..., B i , ..., B 1 * .
 There are two operations in LTAG-spinal, namely, adjunction and attachment . Adjunction in LTAG-spinal is the same as in traditional LTAG (see Sect. 1.1 ). To attach an initial tree a to a node n of another tree a 0 , we add the root of a to n as a new child. Unlike in the substitution operation, a 0 need not have a substitution slot that subcategorizes for the root of a . Attachment applies to initial trees only, and adjunction applies to auxiliary trees only.

Attachment can be modeled as a special case of adjunction. We can add artificial attachment of an initial tree by a (non-wrapping) adjunction of the artificial auxiliary tree, as in TIG. On the other hand, attachment is similar to substitution in that, unlike adjunction, it can not generate any non-projective dependencies.
However, the flexibility of attachment can be constrained by null (NA), obligatory (OA) and selective (SA) attachment constraints analogous to adjunction constraints in traditional LTAG (Joshi and Schabes 1997 ). With these constraints, LTAG-spinal is weakly equivalent to traditional LTAG. A detailed proof is given in (Shen 2006 ).

As for the LTAG-spinal Treebank described in this article, we do not use the three hard constraints described above, which means that the predicate e-trees do not contain slots for their arguments. In our data oriented approach, the constraints are represented in a soft way via statistics. In other words, even ungrammatical sentences receive a (low probability) parse. However, this does not represent a theoretical commitment on our part. As the weak equivalence with LTAG shows, it is perfectly possible to write an LTAG-spinal grammar that assigns no structure to ungrammatical sentences.

An example of LTAG-spinal derivation trees is shown in Fig. 2 . Each arc is associated with a label which represents the type of operation. We use att for attach and adj for adjoin.

In Fig. 2 , seems adjoins to new as a wrapping adjunction , which means that the leaf nodes of the adjunct subtree appear on both sides of the anchor of the main e-tree in the resulting derived tree. Here, seems is to the left of new and to me is to the right of new . Wrapping adjunction allows us to describe non-projective dependencies. In this case, the dependency between to and seems is non-projective. It should be noted that attachment/sister adjunction does not allow wrapping structures like this one. 3 Extracting an LTAG-spinal Treebank 3.1 Previous work For the purpose of statistical processing, many attempts have been made for automatic construction of LTAG treebanks. Joshi and Srinivas ( 1994 ) presented a supertag corpus extracted from the Penn Treebank with heuristic rules. However, due to certain limitations of the supertag extraction algorithm, the extracted supertags of the words in a sentence cannot always be successfully put together. Xia ( 2001 ) and Chen et al. ( 2006 ) described deterministic systems that extract LTAG-style grammars from the PTB. In their systems, a head table in Magerman X  X  style ( 1995 ) and the PTB functional tags were used to resolve ambiguities in extraction. Chiang ( 2000 ) reported a similar method of extracting an LTAG treebank from the PTB, and used it in a statistical parser for Tree Insertion Grammar. 3.2 Our approach We automatically extracted an LTAG-spinal Treebank from the PTB together with Propbank annotation. The following two properties make our extracted treebank different from previous work: incorporation of Propbank information and treatment of coordination. In this section, we discuss each of these properties in turn and then describe our extraction algorithm. 3.2.1 Propbank guided extraction Propbank provides annotation of predicate X  X rgument structures and semantic roles on the Penn Treebank, and was unavailable to most of the previous LTAG treebank extraction systems. 2 There is an obvious connection between Propbank argument sets and e-trees in LTAG. Therefore, one of the goals of our work is to incorporate Propbank annotation into the extracted LTAG-spinal Treebank. In this way, the extracted e-trees for each lexical anchor (predicate) will become semantically relevant. At the same time, as explained below, Propbank provides syntactic information that helps us successfully extract various structures of interest.

In Chen and Rambow ( 2003 ), in a procedure called head filtering , a head table was used as a first step to recognize the head constituent for each phrase. Propbank annotation was then used to distinguish arguments from adjuncts, the second step of the extraction procedure. We employ Propbank annotation as early as the head filtering step. This turns out to be helpful for recognizing structures that are hard to discover with a head table. For example, Propbank annotation on discontinuous arguments helps us recognize auxiliary trees.
 Example 1 (the market could) arg1.1 (continue) Pred (to soften) arg1.2 in the months ahead.

Example 1 illustrates raising. The Propbank annotation tells us that the market could ... to soften is ARG1 of continue . Unlike Propbank, the PTB does not distinguish raising from control. Based on the Propbank information, we can avoid mistakenly taking the market by itself as an argument of continue , as we would want to do if this was a control structure. (The extracted tree is shown in Fig. 5 .) 3.2.2 Treatment of predicate coordination Predicate coordination structures such as VP coordination and Right Node Raising can be seen as predicates either sharing or dropping some of their arguments. Traditional LTAG X  X  notion of locality requires each predicate to carry its complete subcategorization frame with it  X  X  X ard-coded X  X  as a part of its elementary tree. For this reason, an account of coordination cannot easily be given in traditional LTAG. Previous work has suggested contracting shared substitution slots (Sarkar and Joshi 1996 ). That approach extends the notion of a derivation tree to an acyclic derivation conjuncts (e.g., the right conjunct in VP coordination) into auxiliary e-trees lacking some arguments.

LTAG-spinal does not share traditional LTAG X  X  notion of fixed constituency, so representing predicate coordination becomes much easier. Predicate e-trees do not contain slots for their arguments, so we do not have to transform them.

In the LTAG-spinal Treebank, predicate coordination is represented with a special structure. We conjoin two spinal e-trees, which are of the same category, as shown in Fig. 3 . We conjoin interesting onto new , and obtain a coordination structure, which is represented as a box in the figure. Here conjoining is a special operation to build predicate coordination structures incrementally. 3 This method is more flexible than the well-known treatment of coordination in Combinatory Categorial Grammar (CCG) (Steedman 2000 ) and the CCG treebank (Hockenmaier and Steedman 2002 ). In CCG, the conjuncts of the same category are combined first, and then combined with the shared arguments. In our approach, we do not need to combine the conjuncts first as in CCG.

In Sturt and Lombardo ( 2005 ), it is shown that a combination order other than that of CCG X  X  is more preferable from the viewpoint of psycholinguistics and incremental parsing. In their order, a complete sentence structure is first built using the first conjunct, and then the second conjunct is introduced into the derivation. Our formalism is flexible enough to accommodate either order. For example, in Fig. 3 , we could either conjoin interesting to new first as in CCG, or attach new to parser first as in Sturt and Lombardo ( 2005 ). The order of operations for predicate coordination is flexible in LTAG-spinal.

In traditional LTAG, constituency is fixed once the e-trees are defined. Any continuous string generated in LTAG always has a semantic type, which can be read constituent dominating just that string. As for LTAG-spinal, e-trees are in the spinal form, so that we could easily employ underspecification of argument sharing. In this way, representation of predicate coordination becomes even simpler.
 The example in Fig. 3 illustrates adjective coordination. In the treebank, S and VP coordination and right node raising are represented in a similar way. As for gapping, we have not pursued the question of how to represent it in LTAG-spinal, mainly because the traces of the gapped predicates are not annotated in PTB and so we could not extract this information. 3.2.3 Extraction algorithm We now describe the algorithm that we have used to extract the LTAG-spinal Treebank from the PTB with Propbank annotation. We use a rule-based method for treebank extraction. We take a PTB tree as an LTAG derived tree. The algorithm is implemented in several rounds of tree traversal. Each round is implemented with a recursive function over trees. Therefore, whenever possible, we try to divide different operations into different rounds so as to simplify the implementation. The following is a list of the steps for extraction. 1. We first automatically generate the annotation for be , since the latest release of 2. Then we reconcile PTB and Propbank by tree transformations on PTB trees to 3. We recognize LTAG predicate adjunction and predicate coordination in the 4. Then we extract LTAG e-trees from the transformed PTB subtrees recursively, 5. At the end, we map all of the e-trees into a small set of normalized e-trees, as
We map a non-predicate auxiliary tree to an initial tree by removing its foot (three for verbs and three for non-verbs) and four different kinds of full auxiliary trees. In Fig. 4 , VBX represents a verbal POS tag, and X represents a non-verbal POS tag. 4 The LTAG-spinal Treebank In this section, we focus on linguistic phenomena of special interest to us. Some are difficult to represent with CFG, but are easy with TAG thanks to the use of adjunction, such as raising verbs (i.e., continue, begin, etc.), Exceptional Case Marking (ECM) verbs (i.e., expect, believe, etc.), and parentheticals. Some are important in order to make the parsing output useful, such as the treatment of relative clauses as well as predicative nominals and adjectives. 5
The figures used in this section were generated with the graphical interface of our treebank API (see Sect. 6 ). In the figures, solid lines are used within e-tree spines, and dotted arrows are used between e-trees. Auxiliary trees are recognizable by their footnodes, which are marked with an asterisk. Empty elements (*-1, *t*-48, etc.) are carried over from the PTB into the LTAG-spinal Treebank. 6 For convenience, the root node of every e-tree is annotated with the span that this tree and its descendants cover in the string. 4.1 Raising verbs and passive ECM verbs In the LTAG-spinal Treebank, raising verbs and passive ECM verbs are associated with an auxiliary tree. For example, in Fig. 5 , the e-tree for continue adjoins onto the S node of the e-tree for soften . Furthermore, in attaches to continue . Since soften dependency. We use the adjoining operation to distinguish raising verbs from control verbs. 4.2 Relative clauses In the LTAG-spinal Treebank, a relative clause is represented by attaching the predicate of the clause to the head of the phrase that it modifies. For example, in Fig. 6 , the predicate of the relative clause is shown . which attaches onto shown , and shown attaches onto earnings . 4.3 Parentheticals In the LTAG-spinal treebank, parentheticals containing a predicate, such as  X  X  X r. Green testified X  X , are treated using adjunction. This predicate adjoins into the verb of the clause that contains the parenthetical. The argument structure of that clause is not disrupted by the presence of the parenthetical. For example, in Fig. 7 , testified adjoins into began from left. Arguments and adjuncts of began are attached directly to began , even when they are separated from it by the parenthetical, as is the case with eventually . 4.4 Predicative trees In the current version of the LTAG-spinal Treebank, most of the predicate nominals example, in Fig. 8 , writer attaches to is .

We are aware that, in the XTAG English grammar, predicate nominals and adjectives are regarded as the head. Our differing treatment is due to the difficulty in finding the head of a noun phrase. In the PTB, NP representation is flat (Vadas and automatically. For example, the NP those workers and managers and the NP the US sales and marketing arm are both represented as flat NPs.

Furthermore, appositives and NP lists are represented in the same way. The problem of distinguishing NP coordination from coordination within an NP results in the difficulty of choosing the head of NPs. 4.5 Extraposition Extraposition is a class of dependencies that cannot be represented with traditional LTAG. 7 It is also a problem for the LTAG-spinal formalism. For the sentence in Fig. 9 , more than three times the expected number should modify 28 . However, in the LTAG-spinal Treebank, number , the head of the NP, attaches to the predicate died instead.
 5 Properties of the LTAG-spinal Treebank In this section, we describe the LTAG-spinal Treebank in numbers, and argue that LTAG-spinal as an annotation format represents an improvement on the PTB since it facilitates the recovery of semantic dependencies.

We ran the extraction algorithm on 49,208 sentences in the PTB. However, 454 sentences, or less than 1% of the total, were skipped. About 314 of these 454 sentences have gapping structures. Since the PTB does not annotate the trace of deleted predicates, additional manual annotation would be required to handle these sentences. For the rest of the 140 sentences, abnormal structures are generated due to tagging errors. 5.1 Statistics In the LTAG-spinal Treebank extracted from the remaining 48,754 sentences in the PTB, there are 1,159,198 tokens, of which 2,365 are auxiliary trees and 8,467 are coordination structures. Five percent of all sentences contain at least one adjunction and 17% at least one coordination.

In the grammar extracted from 48,754 sentences in the PTB using steps 1 X 4 of the algorithm described in Sect. 3.2.3 , there are 1,224 different types of spinal e-trees, and 507 of them appear only once in the LTAG-spinal Treebank. This result is compatible with the long tail of the distribution observed in Xia ( 2001 ) and Chen et al. ( 2006 ). Many of these e-trees are just noise. On the other hand, after executing step 5 (normalization), there remain only 135 different normalized spinal e-trees, and only seven of them appear only once in the treebank. We also avoid the sparse data problem by using normalized e-trees. 5.2 Compatibility with Propbank This section shows that our treebank maintains a high level of compatibility with Propbank predicate X  X rgument relationships.

Propbank arguments are represented as word spans, not subtrees. So the first question is whether they correspond to subtrees in the LTAG-spinal derivation tree. We say that an argument is well-formed in the LTAG-spinal Treebank if it can be generated by a subtree some of whose direct children trees may be cut away. For example, and the stocks is generated by a sub-derivation tree anchored on stocks , while and and the attach to the tree for stocks . Then we say that the argument the stocks is well-formed because we can get it by cutting the and tree, a direct child of the stocks tree.
 As shown in Table 1 , we have 295,852 pairs 8 of predicate X  X rgument structures. Only 1,661 arguments, 0.6% of all of the arguments, are not well-formed. Most of these cases are extraposition structures.

For the remaining 294,191 arguments, we now ask how easy it is to recover the argument from a given subtree containing it. By using a few heuristic rules, for example, removing the subtrees for the punctuation marks at the beginning and at the end, we can easily recover 288,056, or 97.4% of all the arguments. For the remaining 6,135 arguments, more contextual information is required to recover the argument. For example, we have a phrase NP PP SBAR ( a book in the library that has never been checked out ), where both PP and SBAR attach to the NP as modifiers. Here NP , instead of NP PP , is an argument of the main verb of SBAR in the Propbank. In order to handle cases like these, learning methods should be used. However, we have a baseline of 97.4% for this task, which is obtained by just ignoring these difficult cases.

The next question is how to find the subtree of an argument if we are given a predicate. We evaluate the LTAG-spinal Treebank by studying the pattern of the path from the predicate to the argument for all the predicate X  X rgument pairs in the treebank. Table 1 shows the distribution of the distances between the predicate and the argument in derivation trees. Distance = 1 means the predicate and the argument are directly connected.

The following is a list of the most frequent patterns of the path from the predicate to the argument. P represents a predicate, A represents an argument, V represents a modifying verb, and Coord represents predicate coordination. Arrows point from the parent to the child. The number of arrows is the distance between the predicate and argument, except for the case of a conjunct and its parent, which are considered directly connected although there is an artificial Coord node in between. Conjuncts are regarded as two steps apart from each other. We use A x , P x and P y to represent other arguments or predicates appearing in the sentence. 1. P ? A 2. P / A (relative clause, predicate adjunction) 3. P / Px ? A (subject and object controls, Fig. 10 a) 4. P / Coord ? Px ? A (shared arguments) 5. V / A 6. P / Ax / Py ? A (Fig. 10 b) 7. P / Coord / Px ? A (control + coordination) 8. P / Px / Py ? A (chained controls, Fig. 10 c)
These eight patterns account for 95.5% of the total 295,852 pred X  X rg pairs in the treebank. Table 2 shows the frequency of these patterns. Patterns 1, 2 and 5 account for all the directly connected pred X  X rg pairs in Table 1 .
 We take this result to provide empirical justification for LTAG X  X  notion of EDL. In addition, this result shows that the LTAG-spinal derivation tree provides support for automatically identifying predicate X  X rgument relationships in a way that PTB annotation by itself does not. 5.3 Unlabeled argument identification For the purpose of showing the compatibility of the LTAG-spinal Treebank with the Propbank, here we present a preliminary experiment on unlabeled argument identification, a task which is used to generate all the argument candidates for an argument classification system. We compare the performance of a rule-based approach for extracting unlabeled Propbank arguments from the LTAG-spinal Treebank with a SVM-based approach (Pradhan et al. 2005 ) for extracting the same information from the PTB. The point of this section is to evaluate how easily Propbank information can be recovered from LTAG-spinal annotation. The comparison with Pradhan et al. ( 2005 ) (see Table 3 ) is given for informational purposes only since we used Propbank information in the process of creating the LTAG-spinal Treebank (including the LTAG-spinal test data).

In Chen and Rambow ( 2003 ), pattern 1 is used to recognize arguments. However, it is not enough, since it only accounts for 82.4% of the total data. We have implemented a simple rule-based system for unlabeled argument identification by employing patterns 1 X 5 as follows. For each verbal predicate, we first collect all the previous section. If there is no argument candidate in subject position, we look for the subject by collecting sub-derivation trees according to patterns 3 and 4. Then we transform these sub-derivation trees into phrases with a few simple rules as described in the previous section. We achieved an F -score of 91.3% for unlabeled non-trace argument identification on Section 23 of this treebank, 9 and 91.6% on the whole treebank.

This illustrates that the LTAG-spinal Treebank makes explicit semantic the LTAG-spinal Treebank appears to be a very interesting alternative approach toward semantic role labeling, one in which syntax and semantics are tightly connected. 6 Conclusions and future work In this article, we have introduced LTAG-spinal, a novel variant of traditional LTAG with desirable linguistic, computational and statistical properties. Unlike in traditional LTAG, subcategorization frames and the argument X  X djunct distinction are left underspecified in LTAG-spinal. LTAG-spinal with adjunction constraints is weakly equivalent to traditional LTAG.

The LTAG-spinal formalism is used to extract an LTAG-spinal Treebank from the Penn Treebank with Propbank annotation. Based on Propbank annotation, predicate coordination, and LTAG adjunction are successfully extracted. The LTAG-spinal Treebank makes explicit semantic relations that are implicit or absent from the original PTB. It provides a very desirable resource for statistical LTAG parsing, incremental parsing, dependency parsing, and shallow semantic parsing.
In Shen and Joshi ( 2005 ), the LTAG-spinal Treebank was used to train and evaluate an incremental parser for LTAG-spinal. In Shen and Joshi ( 2007 ), an efficient LTAG dependency parser was trained and evaluated on this treebank, and it achieved an F -score of 90.5% on dependencies on Section 23 of this treebank. In the future, we will extend our work to semantic parsing based on this treebank.
The corpus is freely available for research purposes. The homepage of this resource is http://www.cis.upenn.edu/ * xtag/spinal . The two parsers described above are also available for download at that page. We plan to release this resource through LDC in the future, at which time we will be able to include the mapping to the Propbank annotation.
 We have created a comprehensive Java API that provides full access to the LTAG-spinal Treebank, the output of our parsers, and the special format of the postprocessing the parser output and producing graphical representations as in the illustrations. The API will be available under the link given above.
 We hope this resource will promote research in statistical LTAG parsing, as the Penn Treebank did for CFG parsing. In the future, we also plan to build a standard LTAG treebank based on this LTAG-spinal Treebank.
 References
