 Advances in wireless communication, mobile computing, and positioning technolo-gies have made it possible to manipulate (e.g., model, index, query, etc.) moving object trajectories in practice. A number of interesting applications are being devel-oped based on the analysis of trajectories. For instance, zoologists can figure out the living habits and the migration patterns of wild animals by analyzing their motion trajectories. An important type of query thereinto is the so-called k -Nearest Neighbor ( k NN) search, which retrieves from a dataset within a predefined time interval, the k ( k  X  1) objects that are closest to a given query object. Assume that the trajectories of animals are known in advance, the zoologists may pose the following query: find which k animal's trajectories are nearest either to a given stationary point (e.g., food source, lab, etc.) or to a predefined animal's one at any time instance of the time pe-historical continuous k NN (HC k NN). 
Given a set S of trajectories, a query object (point or trajectory) q , and a temporal neighbors (NNs) of q at any time instance of T . The result lists contain a set of tuples the NN of q . As an example, Figure 1 shows two HC2NN queries, labeled as Q 1 and Q positions, and one for time). Then, the 1-NN list for Q 1 (that takes a point f and a time [ t
Even though much work on continuous k NN (C k NN) search for spatial and spatio-work on HC k NN queries for moving object trajectories has been left largely un-touched to the best of our knowledge. Recently, Frentzos et al. [4] studied the HC k NN retrieval for historical trajectories of moving objects. However, they follow traversal induces a backtracking operation, resulting in reaccessing some nodes that were visited before. Thus, the I/O cost (i.e., number of node accesses) and CPU time incurred in the algorithms are rather high. 
In our earlier work [19], we have studied k NN search on static or moving object trajectories with respect to non-continuous history, and developed two algorithms called BFP k NN and BFT k NN which are shown to be superior to the algorithms of PointkNNSearch and TrajectorykNNSearch proposed by Frentzos et al. [4]. In this paper, we move on to study, with respect to continuous history, k NN search on static or moving object trajectories through R-tree-like structures [7] storing historical in-formation about trajectories. Specifically, we present two algorithms, called HC P -k NN query point and the moving query trajectory, respectively. The core of our solution employs the best-first traversal paradigm [5] and enables effective update strategies to number of node accesses and accelerate the execution of the algorithms (i.e., lead to less running time). Finally, we conduct extensive experiments by using real and syn-thetic datasets, the results of which confirm that our proposed algorithms outperform their competitors (including ContPointNNSearch and ContTrajectoryNNSearch algorithms [5]) significantly in terms of efficiency and scalability. 
The rest of the paper is organized as follows. Section 2 surveys the previous work and 5 describe the HC P -k NN and HC T -k NN algorithms, respectively. Section 6 experimentally evaluates the performance of the algorithms under various settings. Section 7 concludes the paper with a few directions for future work. One area of related work concerns indexing of moving object trajectories. The trajec-Tr length of Tr , with Tr i being a position vector sampled at timestamp t i . Therefore, tra-jectories can describe the motion of objects in 2-or 3-dimensional space, in addition to be considered as 2-or 3-dimensional time series data. Although our proposed aims at strict trajectory preservation . 
Another area of related work is C k NN queries in spatial and spatio-temporal data-bases. Song et al. [12] utilized a periodical sampling technique to process C k NN underlying data structure. Benetis et al. [3] developed an algorithm to answer NN retrieval for continuously moving points. Tao et al. [14] presented a technique, termed as time-parameterized queries , which can be applied with mobile queries, mobile objects or both, given an appropriate indexing structure. Iwerks et al. [6] investigated the problem of C k NN queries for continuously moving points, assuming that the up-dates that change the functions describing the motions of the points are allowed. Cur-17, 18] or distributed [9] environment. All work mentioned above, nevertheless, does not cover the C k NN query on moving object trajectories. Recently, Frentzos et al. [4] explored the issue of HC k NN query processing over historical trajectories of moving objects, by proposing two algorithms called ContPointNNSearch and ContTrajec-toryNNSearch which can handle, respectively, such a query w.r.t. a static query point and a moving query trajectory. Unfortunately, the I/O cost and CPU cost of their algorithms are expensive because they use the DF traversal paradigm. In this section, we discuss how to maintain as the final result of a HC k NN query the k nearest lists (denoted by kNearestLists ). Figure 2 shows the procedure of our Update k Nearests algorithm, in which arguments M and kNearestLists are taken as the input. Note that the structure M retains the parameters of the distance function includ-ing a , b , and c (computed using the method described in [4]), the associated minimum Dmin and maximum Dmax of the function during the lifetime, a time period, and the actual entry in order to report it as the answer instantly. To avoid adding unnecessary elements to kNearestLists , we maintain a set PruneDist of thresholds, to keep track of the maximum among each nearest list. In fact, the set PruneDist is an array which is list, then we can easily derive the following relationship: PruneDist (1) &lt; PruneDist (2) distances. Initially, Update k Nearests compares M.Dmin with PruneDist ( k ). If M.Dmin  X  distance is larger than all the ones enclosed in kNearestLists , and the algorithm terminates. Otherwise, M is added to the structure UpdateList which stores the checked elements (line 3). Next, Update k Nearests recur-sively inserts every element in UpdateList into appropriate nearest list (lines 5-17). Note that in line 12, a sub-procedure UpdateNearest is invoked to update a single nearest list, de-noted by NearestList . 
Figure 3 shows the pseudo-code of the UpdateNearest algo-rithm, which outputs the list NextUpdateList storing the ele-ments that need to be checked later. Initially, UpdateNearest examines whether M overlaps with some elements in Neares-tList w.r.t. time extent. If not, it adds M to NearestList directly, returns NextUpdateList , and terminates (lines 3). Otherwise, it takes various cases into con-sideration in updating Neares-tList (lines 5-19). Specifically, UpdateNearest first determines whether the time interval of T (storing the element already in NearestList ), denoted by [ T.T s , T.T e ], intersects with that of M (i.e., [ M.T s , M.T e ]). If so, it cal-culates the temporal overlapping (denoted by [ T s , T e ]) between T and M (line 10). Subsequently, UpdateNearest updates Neares-tList by analyzing all the relationships between the distance functions of T and M , as leading to the addition of the partial M having the time interval [ M.T s , T s ), denoted as Figures 4a and 4c graphically represent the cases of lines 12, 15, and 19 in Figure 3, and M , producing nT and nM having the same time interval [ T s , T e ]; and then it con-siders all the relationships between nT and nM in order to determine whether nT is to immediately below. both nT and nM are parabolas in the following discussion. However, similar conclu-sions also hold if they are lines. maximum of nT (i.e., nT.Dmax ) is completely smaller than the minimum of nM (i.e., nM.Dmin ). Then, nT is still stored in NearestList , but nM is added to NextUpdateList . four cases to process the update (cf. Figure 5). identical. Then, nT is stored in NearestList and nM is added to NextUpdateList . nM only have the different offset in the dist ance axis. In this case, we need to check their maximum in order to determine whether nT is replaced by nM . have the different offsets both in the distance and time axes. After computing the Root example, we must split the parabolas into different parts and determine the part of nT to be replaced by that of nM because the timestamp of the Root (i.e., T 3 ), denoted by space limitation. Case 4. This case (Figures 5d-5f) happens when a  X  a' . This implies that nT and nM not the difference between the distance functions of nT and nM , and then distinguish among the following sub-cases: (i) D &lt; 0 (Figure 5d), meaning that the distance functions of nT and nM are asymptotic and do not intersect. Then, we check only their minimum to determine the global minimum. (ii) D = 0 (Figure 5e), namely, the distance functions of nT and nM osculate in their common minimum. Then, we have to examine their maxi-mum to determine the global minimum. Note that the processing method of the sub-case and nM intersect in two points (specified as Root 1 and Root 2 , respectively). In the sub-and nM . These situations are omitted here for the sake of conciseness. Employing the BF traversal paradigm, HC P -k NN processes the HC k NN retrieval with storing all candidate entries together with their smallest distances w.r.t. a given query metric. Furthermore, the procedure Update k Nearests (described in Section 3) is called to update the k nearest lists (i.e., kNearestLists ). Figure 6 shows the pseudo-code of our HC P -k NN algorithm. It takes as input a NN k , and returns kNearestLists . The details of the HC P -k NN algorithm are as follows. By starting from the root tree R (line 2), it traverses recursively the tree in a best-first fashion (lines 3-23). Specifically, HC P -k NN first de-heaps the top entry E from hp (line 4). If E.Dmin  X  PruneDist ( k ) holds, that is, the smallest distance between E and Q is no smaller than the maximal distance among the k -th nearest list, then it reports kNear-prevent the non-qualifying entries that do not contribute to the result from en-heaping HC P -k NN only inserts those entries in E into hp (lines 11-19) if their time period over-an intermediate (i.e., a non-leaf) node, HC P -k NN also only en-heaps those child entries in E if their time intervals are across T and their distances to Q are smaller than Prun-the same way as [4]. Again by adopting the BF traversal paradigm, HC T -k NN aims at handling the HC k NN algorithm, in which a TB-tree R , a predefined query trajectory Q , a query time extent T and the number of NN k are taken as the input, and k NNs of Q as the output at any best-first traversal, by starting with the root of R and proceeding down the tree. 
First, HC T -k NN initializes some auxiliary structures involving hp , kNearestLists , and PruneDist (line 1), gets the set QT of actual query trajectory segments whose time heap hp (line 3). Subsequently, HC T -k NN recursively finds the answer that is stored in kNearestLists (lines 4-33). In each iteration, HC T -k NN first de-heaps the top entry E from hp (line 5). As with HC P -k NN, if E.Dmin  X  PruneDist ( k ) holds, then it returns kNearestLists and terminates since the final result has been discovered (line 7). Oth-erwise, HC T -k NN deals with either an actual entry of trajectory segment (line 10) or a if e has the time period across T , e  X  X  time interval overlaps with that of each entry qe adds all the necessary entries in E to hp when E is an intermediate node. It is impor-tant to note that the operation concerned in line 15 is necessary because the temporal extent of some qe in QT may not intersect with that of e in E (therefore it needs not be visited). Also note that, the computation of the Mindist_Trajectory_Rectangle metric included in line 29 uses the method proposed in [4]. In this section, we experimentally evaluate the efficiency and scalability of our proposed using real and synthetic datasets. Since the work of [4] is most related to ours, we evalu-algorithms proposed in [4]. All algorithms used in the experiments were implemented in Visual Basic, running on a PC with 3.0 GHz Pentium 4 processor and 1 GB memory. 6.1 Experimental Settings and a fleet of school buses containing 145 trajectories. We also deploy several syn-thetic datasets generated by a GSTD data generator [15] to examine the scalability of the algorithms. Specifically, the synthetic data sets correspond to 100, 200, 400, 800, and 1600 moving objects, with the position of each object being sampled approxi-mately 1500 times. Furthermore, the initial distribution of moving objects is Gaussian while their movement is ruled by a random distribution. Table 1 summarizes the sta-tistics of both real and synthetic datasets. 
Each dataset is indexed by a TB-tree [10], using a page size of 4 KB and a (vari-able size) buffer fitting 10% of the tree size with the maximal capacity of 1000 pages. The experiments study three factors, involving k , temporal extent (TE), and the num-ber of moving objects (#MO), which can affect the performance of the algorithms. The parameters used in the experiments are described in Table 2, in which the values while the others are fixed to their default values. Performance is measured by execut-ing workloads, each comprising of 100 HC k NN queries. For each experimental in-stance, the reported results are the mean cost per query for a workload with the same settings. In addition, the query points used in the HC P -k NN algorithm utilize random random parts of random trajectories belonging to the school bus dataset as the query trajectory collection; while in the case of GSTD datasets, the query sets of trajectories are created by the GSTD data generator. 6.2 Experimental Results on HC P -k NN Algorithm The first set of experiments investigates the effect of k . Figure 8 shows the number of node accesses and CPU time (in seconds) of the algorithms as a function of k . Obviously, HC P -k NN outperforms its competitor (i.e., ContPointNNSearch of [4]) significantly, and the difference increases with k . As expected, the query overhead of each algorithm grows with k , due to the increase in the update cost of k nearest lists. Next, Figure 9 compares the performance of the two algorithms with respect to TE. Also, HC P -k NN is evidently superior to ContPointNNSearch in all cases. Overall, the CPU time of each algorithm increases linearly as TE grows, which is caused by the growth of temporal overlapping. 
Finally, Figure 10 plots the performance of the two algorithms with respect to #MO using the synthetic dataset. HC P -k NN again wins, and is several orders of mag-nitude faster than ContPointNNSearch in terms of CPU time. 6.3 Experimental Results on HC T -k NN Algorithm Having confirmed the superiority of HC P -k NN for the HC k NN retrieval w.r.t. the static query point, we proceed to evaluate the performance of HC T -k NN for the HC k NN query w.r.t. the moving query trajectory. Figure 11 shows the efficiency of diagrams in Figure 8, HC T -k NN is clearly better than its competitor (i.e., ContTrajec-toryNNSearch of [4]) significantly, and the difference increases with k . Subsequently, Figure 12 compares the cost of the two algorithms by varying TE. The diagrams and their explanations are similar to those of Figure 9. As with the settings of Figure 10, the last set of experiments (Figure 13) shows the performance of the two algorithms versus #MO, which exhibits a similar pattern as that of Figure 10. Although C k NN queries for spatial and spatiotemporal objects have been well-studied trajectories. In this paper, we have developed two efficient algorithms to process HC k NN search on R-tree-like structures storing historical information about trajectories. traversal paradigm hence incurs expensive I/O and CPU cost, our solution uses the best-algorithms outperform their competitors significantly in both efficiency and scalability. k -closest pair queries [3]) for moving object trajectories. For instance,  X  X ind the k pairs of trajectories that have the k smallest distances among all possible pairs during a pre-defined time period X  . Another challenging issue is to develop a cost model to estimate the execution time of the k NN retrieval over trajectories, so as to facilitate query optimi-zation and reveal new problem characteristics that could lead to even faster algorithms. Acknowledgment. We would like to thank the authors for sharing the implementation of their proposed algorithms in [4].

