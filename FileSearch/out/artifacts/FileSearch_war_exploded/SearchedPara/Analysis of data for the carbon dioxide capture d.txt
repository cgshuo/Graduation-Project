 Yuxiang Wu, Christine W. Chan n ) capture technology is commonly adopted for reducing industrial CO 1. Introduction
The large amounts of carbon dioxide (CO 2 ) emitted from the combustion of carbon-based fuels in power generation and other industrial processes, such as cement manufacture and hydrogen production, had made it one of the most important greenhouse gases (GHG). In fact, CO 2 is responsible for about 70% of the enhanced greenhouse effect and global warming, which is likely to result in serious climate changes, a rising global sea level, flooding of coastal cities, severe drought conditions in many inland regions, and endangerment of various animal species in the affected regions.

Due to public concern about environmental pollution and climate change, the post combustion CO 2 capture technology is commonly adopted for reducing industrial CO 2 emissions, from for example, power generation plants. Research on the CO 2 capture technology is currently ongoing at the International Test Centre for CO 2 Capture (ITC) located in Regina, Saskatchewan of Canada. The process of amine-based CO 2 capture implemented at
ITC can be briefly described as follows: the pre-treated industrial flue gas reacts with the amine solvent in the absorber column. With the high temperature steam, the amine solvent selectively absorbs CO 2 from the flue gas. Then, the rich amine solvent that is carrying CO 2 is passed through a regeneration column. There CO is extracted from the amine solvent and the lean amine solvent is regenerated. The regenerated amine solvent returns to the process for further CO 2 absorption. The CO 2 stream is post-treated and can be stored or used for other industrial purposes. The research objective in the area of post combustion CO 2 is to improve the efficiency of the CO 2 capture process while reducing specific operating problems such as solvent degradation and corrosion. This objective requires a good understanding of the intricate relationships among parameters involved in the CO capture process. A review of the relevant literature has identified the most significant parameters in the process to include heat duty, circulation rate of the solvent, CO 2 lean loading, and solvent concentration. The data which provided the basis of our modeling study were collected from the amine-based post combustion CO capture process at ITC.

The objective of our research is to understand the nature of relationships among the key parameters that influence the production rate of carbon dioxide capture from the process. The set of operational data collected from ITC from year 2003 to 2006 was used, and the analysis process involves using artificial neural networks (ANN) for modeling the relationship among the parameters, and sensitivity analysis (SA) for clarifying the relative significance of the parameters. After applying the combined approach of ANN and SA to the operational data, the results generated were validated by the domain experts. The triangula-tion of the modeling results against expert opinions constitutes a technical novelty of our study.

The paper is organized as follows: Section 2 presents the background literature relevant to the technologies of CO 2 artificial neural networks, and sensitivity analysis. Section 3 describes the process of neural network modeling. Section 4 describes the process of sensitivity analysis. Section 5 presents the findings from validation of the developed models and some refined model results. Section 6 gives a conclusion and some directions of our future work. 2. Background 2.1. Application problem domain  X  amine-based CO 2 capture process
The process of amine-based CO 2 capture at the ITC is illustrated in Fig. 1 and briefly described as follows. Prior to CO removal, the flue gas is cooled and particulates and other impurities such as SO x and NO x are removed as much as possible.
The pre-treated flue gas contacts the lean amine solution counter currently in the absorber column and the amine selectively absorbs CO 2 from the flue gas. The amine solution carrying CO enters the stripper column, where the CO 2 is extracted from the amine solvent and the original amine solvent is regenerated. The amine solvent is returned to the absorber column and used in the
CO 2 removal process again. The CO 2 stream produced is essentially pure and can be pressurized and transported to a suitable site for geological storage.

Extensive review of the relevant literature and knowledge acquisition with the chief engineer of ITC revealed that the performance indicators crucial for evaluating the performance and efficiency of the CO 2 capture process include: CO 2 production rate, heat duty, lean loading, and absorption efficiency. These four indicators are called the key dependent variables, which are discussed as follows: from the flue gas and the amine solvent. Heat duty refers to the amount of heat required for amine solvent regeneration. The higher heat duty reflects higher energy consumption and higher operation cost. CO 2 absorption efficiency refers to the amount of the CO 2 extracted from the flue gas in the absorption phase.
A higher CO 2 absorption efficiency indicates a better absorber performance. Lean loading refers to the amount of CO 2 contained in the regenerated amine solvent. The leaner CO 2 loading in the regenerated amine solvent indicates a greater amount of CO be captured in the absorber.
 eight control variables of absorber in gas actual flow (the tag name is FI200ACT), input absorber fluid CO 2 gas (AIT-203), absorber TK440 off gas flow (FI901), lean amine to absorber flow rate (FT600), reboiler pressure (PT660), pressure of steam entered reboiler (PT103A), steam from reboiler flow rate (FT103C), and amine concentration (molarity). The objective of the data analysis study is to identify the relationships among these 8 control or input and the 4 dependent variables. 2.2. Artificial neural network the operation mechanism of biological neural networks. In engineering, neural networks serve two important functions: as pattern classifiers and as nonlinear adaptive filters ( Dorf, 1997 ). As a data processing system, an artificial neural network accepts inputs and exports outputs. An ANN consists of a group of artificial neurons as basic data processing elements. Information is processed inside the neurons and transmitted over their connec-tions. This was inspired by the structure of biological nervous systems in which biological neurons are the basic signaling units of the nervous system and each neuron is a discrete cell ( McCulloch and Pitts, 1943 ). The neurons communicate with each other via connections called dendrites, which branch out to send and receive signals from other neurons. Artificial neurons are often organized in usually no less than three layers in an artificial neural network: an input layer, an output layer, and one or more hidden layer.

The requirements for setting up ANN systems include data on the past performance of the studied system and a selected set of neural-network models ( Kalogirou, 2001 ). Kreider and Wang (1995) applied ANNs to predict the rates of energy use in commercial buildings for determining the energy use of chillers by employing hourly averaged data collected from the system, and their results have satisfactory prediction accuracy. Anderson et al. (1996) used simulated performance values to train an ANN to predict the steady-state output of a proportional-integral (PI) controller, and the study was able to improve performance with respect to tracking the temperature set-point of a simulated heating-coil. In Christo et al. (1995) , an ANN was successfully applied to model the chemical reactions in turbulent combustion simulations, and the results showed that the ANNs could describe the general behavior of the chemical reactions with high accuracy.
Some relevant works on applying ANN modeling combined with sensitivity analysis (SA) have been conducted in the domains of business and engineering ( Baker et al., 1999; Cullen and Frey, 1999; Embrechts et al., 2001; Poh et al., 1998; Fraedrich and
Goldberg, 2000; Kleijnen, 1995 ). Nguyen and Chan (2005) also presented an ANN model inpredicting oil well productions. 2.3. Sensitivity analysis
Sensitivity analysis (SA) is the study of how the variation or uncertainty in the output of a mathematical model can be apportioned, qualitatively or quantitatively, to different sources of variation in the input of a model ( Cacuci et al., 2005 ). Generally, sensitivity analysis introduces a formalized procedure which identifies how  X  X  X ensitive X  X  the model output is to changes in various model components. According to this definition, sensitiv-ity analysis can involve the model structure, model state variables, environmental variables, and initial conditions. In our research work, sensitivity analysis on the input parameters was performed in our attempt to unravel the precise relationships among the conditional or input parameters and the consequent outputs. The sensitivity analysis will inform us on which input parameter(s) is/are more important in predicting accurate output values ( Yao, 2003 ).

The sensitivity analysis (SA) approach is used for tackling two problems in data modeling and analysis. First, the model builder often cannot determine which parameters to include in a predictive model. Second, it is often difficult to accurately measure or quantify the input parameters X  impacts on the dependent variables. Therefore, sensitivity analysis can help model builders explicate the precise influence of the input parameters, thereby enhancing understanding about the studied system X  X  behavior.

Sensitivity analysis helps unravel the more precise influence of the input parameters. The approach can help model builders study the uncertainties associated with the model parameters so that more optimal selection of the input parameters can result.
This is especially applicable when the domain process is not well understood; in which case combining sensitivity analysis with the
ANN approach can extract useful information about the relation-ships among the model inputs and outputs ( Hodouin et al., 1991 ).
Such information is essential for model validation and for process optimization ( Hashem, 1992 ).

Although the method of sensitivity analysis originated from mathematical modeling, it has been widely applied in diverse domains, including business, engineering, medicine, and indus-trial areas. For example, Baker et al. (1999) concluded that sensitivity analysis is one of the principal quantitative techniques in risk management. This conclusion is drawn from a survey of risk management in major U.K. companies. Cullen and Frey (1999) used sensitivity analysis as an aid in identifying the important uncertainties in order to prioritize additional data collection and research. In addition, Embrechts et al. (2001) presented a new approach to sensitivity analysis for feature selection using multiple ensemble neural networks in a bootstrapping mode with bagging. The methodology was applied to in-silico drug design with Quantitative Structural Activity Relationship (QSAR), which is notoriously challenging for machine learning. Poh et al. (1998) combined the neural networks and sensitivity analysis technologies for analyzing the effects of advertising and promo-tion on sales. Combining sensitivity analysis and neural networks can potentially single out important input variables. This is useful for identifying the priority of the input parameters in a complex process, as well as building the correct ANN models. In addition, recent research shows that sensitivity analysis can be very important in model verification and validation either during the processes of development or refinement of the model ( Kleijnen, 1995; Fraedrich and Goldberg, 2000 ). 3. Neural network modeling 3.1. Data filtering
The data set contains 147 columns of operational data generated from the CO 2 capture system of ITC from 2003 to 2006. Some sample data are shown in Fig. 2 .

To enhance the accuracy and reliability of the models, the data were examined and filtered in the following three steps so that only stable data remained and were used for our modeling study:
Step 1 . During some days, the data were collected during very short time frames, such as, half an hour. These data were considered insufficient to reflect the changing trend of the operations at the plant and hence removed.

Step 2 . Typically, the plant does not operate in a stable manner in the morning and during the hour before shut down, and the data collected during these periods of time were considered unreliable. Therefore, the data before 12:30 pm and after 3:30 pm were removed.

Step 3 . After examination of the data set, it was found that some of the parameters behaved in an erratic manner. For example, the steam pressure increases 20 KPa in 10 min. These data exhibit abnormal performance, and are deemed unreliable; hence, they are removed.

The data that remained after these three filtering steps appeared to be stable and reflect noticeable trends on a daily basis. This indicates that the data describes normal and reliable plant performance, and they can be used as inputs for our modeling study. 3.2. Data modeling procedure
A survey of relevant literature suggested that four among over a hundred parameters are determining factors for evaluating the efficiency and performance of the CO 2 capture process system; they are CO 2 production rate, heat duty, CO 2 absorption efficiency, and lean amine loading. However, little research has been done on how these factors were influenced by other observable process control variables. Recently, Zhou et al. (2008) used a statistical regression modeling method to study the relationships among these parameters. Although it has been suggested that the eight independent variables mentioned above affect these 4 perfor-mance indicator parameters, the precise relationships among these parameters are unknown. An assumption made in our study is that an explication of the relationships among these key parameters will shed light on ways of enhancing efficiency of the
CO 2 capture process and enable more optimal control of the operational conditions of the process.

While conventional mathematical modeling can possibly simulate the relationships, the method requires analysis of a vast amount of data and consumes much time in implementation. The alternative approach of combining neural network and sensitivity analysis was adopted to develop an analytical model that relates the 8 control input variables with the 4 dependent outputs, which are also the performance indicators of the CO 2 process system.
The data analysis process involves the following steps: (1) construct the artificial neural network models based on the dataset, (2) conduct sensitivity analysis on the modeling results, (3) validate the results with experts, and (4) reformulate and reapply the neural network model and generate results. The data modeling process is shown in Fig. 3 . The Weka version 3.4.12 (trademark of Weka) software tool kit was used for implementa-tion. Weka is data mining software in Java, which includes a collection of machine learning algorithms for data mining. Since the sensitivity analysis procedure was not included in the Weka library, an additional program module was implemented to perform the task.

The combination of ANN and SA for modeling the set of operational data is adopted because while ANN can generate good models of the data, the models are not explicable. Adopting SA on the modeling results helps to reveal the relative significances among the input variables, which were subsequently validated by the process experts. The results generated from this modeling and validation process are more credible and can enhance our understanding of the carbon dioxide capture process system.
The careful triangulation of the modeling results against expert opinions, and the insights generated in the interaction process, constitute technical innovations of the investigation. The details of the modeling process are discussed as follows. 3.3. Building the neural network models
A three-layered artificial neural network model is one of the simplest and most popular type of neural network model. This network architecture is adopted in this study. The model typically consists of three layers, which are the input layer, output layer, and middle layer. The input layer is responsible for accepting input signals. The output layer is used for exporting the output data. The middle layer is usually called the hidden layer because it is only visible internally and has no direct contact with the outside.
 the number of known inputs, and the number of the output layer units is decided by the desired outputs. But no clear rule exists for determining the number of hidden layer units. One suggestion is to define the number of hidden units as half of the sum of the inputs and output units ( Poh et al., 1998 ). The number of hidden layers needs to be determined for a specific application because an overly complex model would lead to over learning of the network.
 predictive results and the network configurations ( Han and
Kamber, 2006 ); hence the configuration of network has to be determined before importing the data. It has been suggested that a back-propagation neural network is an efficient function approximator, given the network includes sufficient number of hidden nodes with sigmoid output functions ( Poh et al., 1998 ). In our study, a feed-forward back-propagation neural network was adopted for its simplicity and maturity. The number of hidden layers was set to 1 to simplify the model building process since a one hidden layer network is typically sufficient for modeling industrial tasks. The outputs are the predicted variables while the inputs are the conditional variables that influence the outputs and for which data are available.
 parameters: Number of inputs 8 Number of outputs 4 Number of hidden layers 1 Number of hidden layer units 4 Learning rate 0.3 Momentum 0.2 Activation function Sigmoid function Number of epochs 500
The back-propagation network searches for an optimal con-figuration, which refers to the best choices of the weights for all neurons, to fit the network to the provided data. The procedure generally consists of two steps: First step, when the inputs are transmitted to a neuron, the activation values are propagated to the output units, and the actual network output is compared with the desired output values. An error is found in each of the output units. The total error is calculated using a formula called the error function or cost function as follows ( Poh et al., 1998 ):
E  X  1 2 where O ip represents the actual value from the i th output unit in the p th training samples, while t ip is for the desired output.
In the second step, the errors calculated in the first step are passed back from the outputs to the inputs via the hidden layer(s).
Each unit X  X  output error can be calculated from the total error from the first step based on the weights in the unit. This is why the method is called back-propagation. Since the errors from each unit X  X  output is known, the network updates the weights from the output unit back to all the hidden units that are connected to it until it reaches the input units, in order to minimize the error ( Poh et al., 1998 ) w  X  w k Z r E  X  2  X  where Z is the learning rate set by the researcher and r E is an estimate of the gradient of E with respect to w k in the k th iteration.

After the weights are adjusted, step one is repeated to check if the result can satisfy the preset condition. If not, these two steps will be repeated recursively until the total error converges. 3.4. Model validation method
Model validation involves estimating accuracy of the classifier or predictor model. In this study, model validation is performed using cross-validation. Cross-validation, which is also known as rotation estimation, is a statistical practice that partitions a sample of data into subsets for training and verifying a model X  X  purposes ( Han and Kamber, 2006 ). Particularly, K -fold cross-validation method is adopted in this study.

In K -fold cross-validation, the original data sample is parti-tioned into K subsets. A single subset is retained for testing the trained model, while the other K 1 subsets are used in the training. This process, which is called a folding process, is repeated K times. The result of the K -fold evaluations will be averaged to produce an overall estimation. This is a commonly adopted method because it makes use of the dataset repeatedly such that each subset is used in training as well as validation ( Han and Kamber, 2006 ). In our study, tenfold cross-validation is adopted to verify our modeling results. The careful validation conducted within the ANN modeling process is important and contributes to the understanding about the CO 2 capture process system. 3.5. Back propagation results for the ANN
As discussed in Section 3.2, the study began with constructing the ANN models, and then sensitivity analysis was conducted on the modeling results. The models were constructed using Weka version 3.4.12 (trademark of Weka). The ANN models involve all 8 independent input parameters of absorber in gas actual flow (FI200ACT), input absorber fluid CO 2 gas (AIT-203), absorber TK440 off gas flow (FI901), lean amine to absorber flow rate (FT600), reboiler pressure (PT660), pressure of steam entered reboiler (PT103A), steam from reboiler flow rate (FT103C), and amine concentration (molarity). Four different prediction models were developed for each predicted or dependent variables of CO production rate, heat duty, CO 2 absorption efficiency, and lean loading.

A summary of the four different prediction models developed for each of the four target outputs is shown in Table 1 . The correlation-coefficient ( R ) represents the amount of variation in the consequent variable that is accounted for by the model ( Field, 2000 ); it is a measure of how well the model performs in predicting the dependent variable ( Einspruch, 1998 ). The R value for the ANN prediction model for CO 2 production rate is 99%, while the other 3 prediction models for heat duty, absorption efficiency and lean loading all approximate or are over 90%. It can be observed from the prediction results that the models are simulating the relationships between the 8 independent variables and the 4 dependent variables with high accuracy.

Some observations on the modeling process are discussed as follows. Trainings of the ANN models for 500, 1000, and 2000 iterations have been conducted during the model building process, but it was observed that there is no significant difference among the accuracies of the generated models. Hence we adopted 500 iterations as a reasonable limit and this was also adopted in the model rebuild process to be discussed later. The results listed in Table 1 are taken from the models trained with 500 iterations.
It is hypothesized that not all the independent parameters contribute significant influences on the target dependent outputs. Hence, it is further hypothesized that some independent para-meters can be removed without reducing the predictive power of the model. To analyze the contribution of each input variable as well as enhance the predictive and explanatory power of the models, sensitivity analysis on all the input parameters was conducted. This will be discussed in the next section. 4. Sensitivity analysis 4.1. Introduction
An explicit prediction model can be made more efficient by reducing the number of variables through a weight sensitivity analysis. The impact of each independent variable on the dependent variables can also be found from the sensitivity analysis ( Poh et al., 1998 ). The experts for this project included the CO 2 capture process engineers and researchers at ITC, who initially selected the predictive parameters based on their experiences and knowledge. However, even experts could not specify each parameter X  X  precise and measurable influence on the outputs. The sensitivity analysis approach can explicate the input parameters X  precise influences on the outputs when values of the inputs change, thereby enhancing understanding about the uncertainties associated with the model parameters. Two sensi-tivity analysis methods were adopted in this study, namely the equation method and the variable perturbation method. 4.2. Equation method
Hashem (1992) introduced the equation method of calculating output sensitivities to inputs X  variations for feedforward ANN. His sensitivity calculation method was based on research results of
Hornik et al.(1990) , who stated that the function to be approximated by the ANN need not be differentiable in the classical sense as long as it possesses a generalized derivative, as is the case for certain piecewise differentiable functions. As shown in Sherif X  X  theory, the derivative of the ANN model X  X  output parameter with respect to the independent inputs can reveal the influence of the input variables, as the sensitivities of the outputs. In this section, the method formulas will be discussed.
Hashem (1992) made two assumptions for the deduction process, which were: (1) the ANN activation functions are differentiable and (2) there is no bypassing connection in the network. To simplify illustration of the process, we assume that all the layers in the ANN share the same activation function in our analysis. The activation function we used in the ANN is the logistic sigmoid function f ( x )  X  1/(1+ e x ), which has the property of being similar to the step function but with uncertainty in some region; this uncertainty can suitably simulate the relationships between biological neurons. The sigmoid functions are typically chosen in many ANN implementations because their derivatives are easy to calculate, making it easier to estimate the weight changes in some training algorithms ( Hashem, 1992 ).

A feedforward ANN usually consists of: an input layer, N hidden layers, and one output layer. Output sensitivities, which are represented by the derivatives with respect to the input variables, are calculated by applying the backward chaining partial differentiation rule. The process is briefly shown as follows ( Hashem, 1992 ):
S  X  @ O @ I @ h @ I i  X  @ h @ I
In the input layer, the weight is defined as follows: @ h @ I where O is the value of output node; h n k the input sum value of the ( n 1)th layer to the k th node in the n th layer; V n j the output value of j th node in n th layer after applying activation equation to the sum value from the previous layer; I i the i th input to the network; w n jk the connection weight between the j th node in layer n 1 and the k th node in layer n. S i the sensitivity result to the i th input. the sensitivity calculation equation can be simplified to the following formula when it is adopted in our study:
S i  X  @ O where the notation is the same as in the previous equations. output parameter. The value is directly proportional to its influence. The ranking of the S i reveals the priority in which the input parameters influence the output variable. 4.3. Variable perturbation method
Klimasauskas (1991 ). He used first order sensitivity analysis, based on the perturbation of one input variable at a time and monitoring the outputs X  variations ( Hashem, 1992 ). Yao (2003) suggested two forms of the variable perturbation, which are
I n  X  I n  X  d  X  8  X  or
I n  X  I n d  X  9  X  where I n represents the n th input and d is the change that is introduced to the input variable I n . This method is more intuitive and straightforward compared to the equation methods. It adjusts one input value by d while keeping the other inputs unchanged and monitors the output variations. This procedure is applied recursively to every data point for that particular observed input variable. Then output changes are gathered from each run and an averaged value is calculated. The average value can indicate the influence of the observed input to the output. This step is repeated on each input parameter until all of their sensitivities are obtained.
 methods calculate the sensitivities in different ways; hence the two methods are incomparable because of the different units used. However, each method generates a ranking of the sensitivity calculation results for the input variables, and from the ranking, different influences among the inputs is revealed. Therefore, the two methods were run individually and two significance rankings of the input variables were generated. 4.4. Sensitivity analysis results analysis were implemented by adding a small module into Weka version 3.4.12 (trademark of Weka). Since Weka is open source software, customized code can be added to enhance the capability of the software. The enhanced system, which includes the two methods for calculating the sensitivities as discussed in Sections 4.2 and 4.3, was applied to each of the four ANN models presented in Section 3.5. In the prediction model for CO 2 production rate (FI-700), the model contains 9 independent parameters, which include (1) absorber in gas actual flow (FI200ACT), (2) input absorber fluid CO 2 gas (AIT-203), (3) absorber TK440 off gas flow (FI901), (4) lean amine to absorber flow rate (FT600), (5) reboiler pressure (PT660), (6) pressure of steam entered reboiler (PT103A), (7) steam from reboiler flow rate (FT103C), (8) amine concentration (molarity), and (9) the amount of energy used for solvent regeneration (heat duty). Sensitivity analysis was conducted on these 9 independent or input parameters and the influences of each parameter to the production rate are listed in Table 2 .Itisnoted that while heat duty is a dependent variable, it also can act as an independent variable because according to the experts X  knowledge, it might have significant influence on the production rate. Hence it is added as an independent or input variable in this model.
As we can see from Table 2 , steam from reboiler flow rate (FT103C) has the greatest influence on the production rate based on the equation method of sensitivity analysis. On the other hand, the results from applying the variable perturbation method show that not only steam from reboiler flow rate (FT103C), but also amine concentration (molarity) contribute significantly to the production rate. The reason for the different results is that the two methods use different mechanisms. The first method calculates the sensitivity layer by layer recursively, which means it can identify the hidden connections between the input and the output inside the hidden layer(s). The second method is more intuitive because it basically adjusts one input at a time while keeping the others unchanged, and then evaluates the change caused by the changed input on the output variable.

While it cannot be determined from the results which method is more accurate, it is possible to identify which parameter(s) are not useful to this model. From Table 2 it can be seen that both methods reveal that absorber in gas actual flow (FI200ACT), input absorber fluid CO 2 gas (AIT-203), absorber TK440 off gas flow (FI901), lean amine to absorber flow rate (FT600), and reboiler pressure (PT660) have very low sensitivities compared to the other independent or input parameters. In other words, changes in these parameters would not affect the target outputs. By eliminating the insignificant variables from the model, we can simplify the model.

Similar analysis can be done on the other 3 models whose target outputs are heat duty; lean loading and absorption efficiency (see Tables 3 X 5 ).

For the heat duty model ( Table 3 ), it is observed that the equation method results are very different from the variable perturbation method. But in either case, the amine concentration (molarity) and absorption efficiency both show relatively low sensitivities to the heat duty compared to the other inputs. Hence, the two input parameters can be eliminated.

In the lean loading model ( Table 4 ), it can be observed that all the parameters show some influence to the output and no input variables need to be eliminated. The next step is to obtain expert validations on our observations, which will be discussed in the next section.

Table 5 describes the model for absorption efficiency predic-tion. It can be observed that the sensitivity analysis results from the two SA calculation methods are very similar. Based on our observation, only the parameter of lean loading can be removed from the inputs. Again, this has to be validated by the experts. 5. Expert validation and model reformulation
The results generated from the SA were shown to the experts during an interview. Their observations are discussed as follows. In the prediction model for production rate (FI700) ( Table 6 ), the
SA results suggest that the parameters of (1) reboiler pressure (PT660), (2) pressure of steam entered reboiler (PT103A), (3) steam from reboiler flow rate (FT103C), (4) amine concentration (molarity), and (5) the amount of energy used for solvent regeneration (heat duty) highly contribute to the output of production rate of CO 2 capture. While the experts agreed that these parameters have significant influences on the production rate, they also considered in addition to the above that the following parameters are important input variables for predicting
CO 2 production rate (FI700): (a) absorber in gas actual flow (FI200ACT) and (b) lean amine to absorber flow rate (FT600). The divergence of their opinion from the modeling results can be explained by the range of values of the modeled data. While the latter group of two parameters are not so important within the range of the training data, they should be included as key factors for predicting CO 2 production rate in general.

Based on the SA results, the CO 2 production rate model was refined and the two parameters of input absorber fluid CO (AIT-203) and absorber TK440 off gas flow (FI901) were removed from the model to reduce its complexity. Table 6 (last column) shows the newly formulated ANN model for production rate prediction. The parameters used in the model are marked by  X  X  X . It is noted from the last row of Table 6 that the R of the new model (0.999) is almost the same as the previous R value (0.999). In other words, the new model is able to predict CO 2 production as well as the original model even though two input parameters were eliminated.

Similar validations were conducted for the other three prediction models, which are discussed as follows.

For the heat duty model ( Table 7 ), the SA results showed that the amine concentration (molarity) and absorption efficiency parameters contribute little influence to the heat duty output.
However, the experts insisted that the two parameters are useful based on their knowledge. Moreover, they suggested that the parameters of absorber in gas actual flow (the tag name is
FI200ACT), absorber TK440 off gas flow (FI901), and reboiler pressure (PT660) can be removed from the model. Although this suggestion does not agree with our observations from the SA, the model was refined according to the experts X  suggestions because we believe that the experts X  experiences are more valuable. The R value in the refined model is 0.9018, which is about 2% less than the former model X  X  R value of 0.929. Hence, we conclude that the elimination of the three parameters was acceptable.
 different methods were not consistent. During the validation process, we found the experts X  opinions were more aligned with the results from the perturbation method. Hence, the experts X  opinions were combined with the perturbation method results and we concluded that input absorber fluid CO 2 gas (AIT-203), absorber
TK440 off gas flow (FI901), and heat duty can be removed from this model. The R value of the refined model is 0.851 and compared to the R value of the original model of 0.884, this is only a 3% decrease. Therefore, the elimination of the three variables was acceptable.
For the absorption efficiency model ( Table 9 ), the SA results suggested that the lean loading parameter can be eliminated. The experts validated the SA results and as a result, the lean loading parameter is removed from this model. Compared to the original model X  X  R value of 0.9475, the refined model X  X  R value is 0.9233.
The decline of about 2% in the R value indicates that the elimination of the parameter of lean loading was acceptable.
It can be observed from the R values for the three prediction models for heat duty, lean loading, and absorption efficiency that the refined models can still predict the target outputs with relatively high accuracy. The reductions in the refined models X  R values have been limited to within 3 percentage points. The predictive power of the refined models is considered acceptable and the models with fewer input parameters also have the advantage that less training time is required. 6. Conclusion
The combined approach of ANN and SA has been applied to the dataset on the carbon dioxide capture process system of ITC, and four prediction models for the dependent parameters of CO production rate, heat duty, CO 2 absorption efficiency, and lean loading have been generated. The results from this study indicate that (1) this combined approach is able to capture the nonlinear or linear relationships among parameters in the CO 2 capture process and (2) the prediction models can predict the target output with relatively high accuracy as indicated by the associated R values, which are all around 90%.

Using the ANN approach in modeling an industrial process has the advantage that the modeling process takes less time than the mathematical modeling process. Most of the development time was spent on incorporating the equation method into the ANN modeling program of Weka version 3.4.12 (Trademark of Weka). Since there is no existing software library that focuses on this task, the program implementation consumes the majority of the development time. After the implementation step was completed, the model training time was less than 1 min in our experiment even though the data set contains over 10,000 rows of data. We believe validation by experts is a crucial step for verifying and refining the models developed. This was also the most time consuming and effort intensive portion of the research. From our study, it can be seen that the reformulated models based on sensitivity analysis combined with expertise knowledge have fewer input parameters but still demonstrate good predictive power. The refined models are also more comprehensible and reliable than the models generated only using ANN. The careful triangulation of results generated by the combined approach against expert opinions also means that the results are more credible and can contribute to our enhanced understanding of the carbon dioxide capture process system.

A major weakness of the ANN approach is that the models generated are implicit and cannot provide explicit descriptions of the inter-relationships among the variables. This weakness is partially compensated for by adopting SA methods, which can reveal the relative significances among the variables. In the sensitivity analysis process, it is found that the variable perturbation method tends to generate results more congruent with the expert X  X  knowledge. The equation method addresses the first order and higher order output sensitivities when variations in the input variables exist in the multilayer feed forward ANNs with differentiable activation ( Hashem, 1992 ). On the other hand, the perturbation method directly measures the influences of the inputs on the output by adjusting one input value and keeping the others unchanged at one time. The latter method is more intuitive and reflects more directly the influences of individual input variables on the outputs. It is possible that this is a more suitable method than the equation method for conducting SA in the CO capture domain. We believe the procedure of conducting ANN modeling, SA, then expert validation is generalizable for modeling other industrial processes. In the future, the modeling results will be compared to data analysis results generated using other artificial intelligence approaches such as neural-fuzzy modeling. Acknowledgements The authors are grateful for the generous support of the Canada Research Chair Program and Natural Sciences and Engineering Research Council of Canada. We would also like to acknowledge the help and contributions of Dr. Paitoon Tontiwachwuthikul, Dr. Raphael Idem, Don Gelowitz, and Qing Zhou.
 Reference
