 Hierarchical classification has been shown to have superior perfor-mance than flat classification. It is typically performed on hierar-chies created by and for humans rather than for classification per-formance. As a result, classification based on such hierarchies often yields suboptimal results. In this paper, we propose a novel genetic algorithm-based method on hierarchy adaptation for improved clas-sification. Our approach customizes the typical GA to optimize classification hierarchies. In several text classification tasks, our approach produced hierarchies that significantly improved upon the accuracy of the original hierarchy as well as hierarchies generated by state-of-the-art methods.
 I.5.2 [ Pattern Recognition ]: Design Methodology X  Classifier de-sign and evaluation ; H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Information filtering Algorithms, Performance Topical categorization, Hierarchical classification, SVM
Classification can be performed based on a flat set of categories, or on categories organized as a hierarchy. In flat classification, a single classifier learns to classify instances into one of the target categories. In hierarchical classification, a separate classifier is trained for each non-leaf node in the hierarchy. During training, each classifier is trained to categorize the instances that belong to any of the descendants of the current node into its direct subcate-gories. When deployed, an instance is first classified by the root classifier, and then passed to one of the first level categories with the highest probability. This process is repeated iteratively from top to bottom, invoking one classifier at each level, until reaching a leaf node. Prior work has shown that hierarchical classification has performance superior to that of flat classification (e.g., [3, 5, 1]).
Hierarchical classification is typically performed utilizing human-defined hierarchies, reflecting a human view of the domain. However, these hierarchies are usually created without considera-tion for automated classification. As a result, hierarchical classifi-cation based on such hierarchies is unlikely to yield optimal perfor-mance.

In this paper, we propose a new method based on genetic algo-rithms to create hierarchies better suited for automatic classifica-tion. In our approach, each hierar chy is considered to be an indi-vidual. Starting from a group of randomly generated seed hierar-chies, genetic operators are randomly applied to each hierarchy to slightly reorganize the categories. The newly generated hierarchies are evaluated and a subset that are better fitted for classification are kept, eliminating hierarchies with poor classification performance from the population. This process is repeated until no significant progress can be made. In our experiments on several text classifi-cation tasks, our algorithm significantly improved the classification accuracy compared to the original hierarchy and also outperformed state-of-the-art adaptation approaches. Our contributions include:
The basic idea of generating/adapting hierarchies for better clas-sification is not new. Li et al. [4] proposed a method of using linear discriminant projection to generate hierarchies. In this approach, all the documents within the hierarchy are first projected onto a lower dimensional space. Then, the leaf categories are clustered using hierarchical agglomerative clustering to generate the hierar-chy. Tang et al. [8] proposed a method for hierarchy adaptation by iteratively checking each node in the hierarchy, and making slight modifications locally. This approach can also be used to model dy-namic change of taxonomies [7]. A dditional related work may be found in our full report [6].

There are at least two main differences that separate our ap-proach from previous work:
As introduced previously, hierarchical classification can often perform better than flat classification. However, this is not al-ways true.It depends on the choice of hierarchy. In order to further motivate this work using real-world data, we randomly selected 7 leaf categories containing 227 documents from LSHTC dataset (see Section 3.1 for details), exhaustively generated all the possible hi-erarchies based on the selected categories, and tested the classifica-tion performance for every hierarchy. In total, 39,208 hierarchies were generated, out of which 48.2% perform worse than flat clas-sification in terms of accuracy. This verifies our intuition that im-proving hierarchical classification needs a well-chosen hierarchy. In the following, we will describe how to adapt genetic algorithms to search for a better hierarchy.
A genetic algorithm (GA) is a search/optimization method that resembles the evolution process of organisms in nature. Like any other search method, it searches through the solution space of a problem, looking for an optimal solution. In our problem, we con-sider each possible hierarchy to be a solution (or an individual in GA, specifically). As illustrated by the small example above, our solution space is often too large to perform an exhaustive search except for very small datasets.

A typical GA usually starts with an initial population of individ-uals, then iteratively repeats the following search procedure until the stopping criterion is satisfied. In each iteration, a subset of individuals is selected for reproduction by applying mutation and crossover operations on them. Then the fitness of each new individ-ual is evaluated, and low-fitness individuals are dropped, leaving a better fitted population as the start of next iteration. In our ap-proach, we will leave the high level procedure of GAs as described above unchanged, while adapting representation method and repro-duction operators to make them fit the hierarchical classification problem. We chose a GA instead of other generic search methods for at least two reasons. First, it intrinsically supports large popula-tions rather than greedy, single path optimization. Second, we can adapt its reproduction operators to allow significant changes to the solutions without changing the high level search procedure.
In our work, each hierarchy is represented as a sequence of nu-meric IDs and parentheses, in which each ID corresponds to a leaf category, and each pair of parentheses represents a more generic category consisting of the categories in between them. Multiple levels in the hierarchy are reflected using nested parentheses.
More formally, we represent a h ierarchy using the following rules: 1. Each leaf node is represented by its numeric id; 2. Each non-leaf node is represented by a list of all its children 3. The hierarchy is represented recursively using Rule 1 and 2. 4. The outermost pair of parentheses is omitted.
 Figure 1 illustrates a small example, which will be represented as (125)((36)4) .

The hierarchy representation method above serializes a hierar-chical tree into a sequence of tokens. However, different repre-sentations may correspond to the same hierarchy. For example, (125)((36)4) and (215)((63)4) define the same hierarchy. We detect duplicate hierarchies using a two-step canonicalization. We first remove unnecessary parentheses, then sort siblings according to the minimal class id in its subtree (refer to our report [6] for details).
In typical GA, mutation is performed by switching a random bit in the chromosome string. However, this operation is not as straightforward in the hierarchical setting. We design three muta-tion methods that are suitable for hierarchy evolution: promotion, grouping, and switching.

The promotion operator randomly selects a node n (which can be either a leaf or non-leaf node), and promote n as a child of its grand-parent, i.e., n becomes a sibling of its parent node. The grouping operator randomly selects two sibling nodes and groups them to-gether. If a non-leaf node n has k children, C = { c i | i =1 ..k } where k  X  2 . We randomly select two nodes c x and c y from through c k , and remove them from C . Then we add a new node into C so that c z becomes a child node of n . Finally, we make and c y children of c z .The switching operator randomly selects two nodes m and n (and the subtrees rooted at those locations) in the whole hierarchy, and switches their positions.
In a typical GA, crossover is performed by swapping segments of the chromosome string between the parents. In the hierarchi-cal setting, however, directly swapping parts of the hierarchy rep-resentation will generate invalid hierarchies. Therefore, we need crossover methods customized for hierarchy evolution.

We used two types of methods: swap crossover and structural crossover. The two parents are noted as h p 1 and h p 2 , the children h c 1 and h c 2 .In swap crossover , a child h c 1 is generated using the following steps. First a split point p is randomly chosen in note the the part starting from the beginning of the representation string to the split point p as h p 1 . We remove the segment after from h p 1 and only consider h p 1 . Then right parentheses are added at the end to balance with the existing left parentheses. Suppose S is the set of leaf nodes that appear in h p 1 ; we go through and remove all the nodes n if n  X  S . This removal transforms h p 2 into h p 2 . Finally, h p 1 and h p 2 are concatenated to form The other child h c 2 is generated by switching h p 1 and applying the above procedure. Figure 2 illustrates the process of swap crossover.

For our second approach, we note that a hierarchy can be seen as an integration of two independent characteristics: the tree struc-ture and the placement of leaf nodes. At a high level, structural crossover aims to  X  X ix and match X  these two factors. A child hi-erarchy inherits the structural information from one parent, and placement of leaf nodes from the other. In our implementation, h c 1 is generated using the following method. First, every leaf node in h p 1  X  X  representation is replaced with a blank space. Then these blank spaces are filled with the leaf nodes in h p 2 using the order that they appear in h p 2 . h c 2 is generated by switching Figure 3 illustrates the process of structural crossover. A GA requires a fitness function for evaluating new individuals. We define the fitness of a hierarchy as the classification accuracy using this hierarchy evaluated on validation data. A GA also needs a stopping criterion to terminate the iterative evolution process. In our algorithm, we keep a watch list of the top N watch best hier-archies. If the performance of the top hierarchies does not change between two consecutive iterations, the algorithm terminates. In the following experiments, we set N watch to 5.
We used three public datasets to test our algorithm. The first two datasets are from the first Large Scale Hierarchical Text Classifica-tion (LSHTC) challenge 1 held in 2009. We selected a toy dataset from Task 1 with 36 leaf categories and 333 documents, which will be referred to as LSHTC-a. We also used the dry-run dataset from Task 1, which has 1,139 leaf categories and 8,181 documents. We will refer to this dataset as LSHTC-b. Both datasets are partitioned into three subsets: a training set used to train classifiers during the training process, a validation set used to estimate the fitness score of each generated hierarchy, and a test set to evaluate the final output hierarchy. The third dataset is WebKB 2 , containing 7 leaf categories and 8,282 documents. We performed four-fold cross-validation on WebKB. LibSVM [2] is used as the base classifier to implement the standard hierarchical SVM. We used all the default settings in LibSVM, including the radial basis function kernel as it yields better performance than the linear kernel on the datasets we used. In our algorithm, we set the population size to 100 on LSHTC-a and WebKB, 500 on LSHTC-b.

We compared our approach (Evolution) with two existing state-of-the-art approaches: a hierarchy adaptation approach called Hier-archy Adjusting Algorithm (HAA) [8], and a hierarchy generation http://lshtc.iit.demokritos.gr/node/1 http://www.cs.cmu.edu/afs/cs/project/theo-20/www/data/ Figure 4: Accuracy on LSHTC datasets compared across dif-ferent methods. approach called Linear Projection (LP) [4]. We implemented HAA according to the algorithm outlined in Figure 12 and 13 of [8]. All three search methods were implemented. In our implementation of HAA, we set the stopping criterion to 0.001. That is, when the im-provement between two consecutive iterations is less than 0.001, the algorithm terminates. We also compared our algorithm with Linear Projection on WebKB dataset. Instead of re-implementing the LP algorithm, we directly used the automatically generated hi-erarchy on WebKB reported in the Linear Projection paper, and performed the four-fold cross-validation based on that hierarchy.
On LSHTC-a, our algorithm converged after seven iterations, improving the performance on the test set from 70% to 79.5% (av-eraged across three runs using different random seeds). HAA con-verged after two iterations with the accuracy improved to 71.9%. On LSHTC-b, it took 49 iterations for our algorithm to converge, and 18 iterations for HAA. HAA improved upon the baseline X  X  ac-curacy of 49.6% to 54.0% , while our algorithm X  X  final output hier-archies have an average accuracy of 56.5% across three runs using different random seeds. The results are shown in Figure 4. On WebKB, we compared our algorithm with flat classification, HAA, and Linear Projection. The flat classification has an accu-racy of 70.3% averaged across the four folds. Linear Projection and HAA improve the accuracy to 74.6% and 75.4%, respectively. Our algorithm further improves to 76.4%, a 21% reduction in error rate compared with flat classification. Figure 5 shows the average performance and standard deviation for each method. Two-tailed t-tests showed the improvement of our algorithm over other algo-rithms is statistically significant.
As we pointed out previously, our approach differs from ex-isting hierarchy adaptation approaches from at least two aspects: making significant changes to hierarchies and a larger population size to maintain population var iety. Now we analyze quantitatively whether these differences make our approach outperform existing methods. The following analysis is performed on LSHTC-b.
In order to evaluate the effectiveness of the genetic operators, we calculate the improvement that each type of operator brings to a hierarchy. Figure 6 shows the average improvement in terms of accuracy. On average, all the five operators have a negative im-pact on the accuracy. For example, the  X  X wap crossover X  even decreases accuracy by 0.018 when averaged across all evolution Figure 5: Accuracy on WebKB dataset compared across differ-ent methods.
 Figure 6: Improvement compared across different genetic op-erators. operations. That is, on average, every time a  X  X wap crossover X  is applied on a hierarchy, the newly generated hierarchy has an ac-curacy lowered by 0.018. Fortunately, the genetic algorithm only keeps the best hierarchies in the population, and discards the rest. Therefore, the degradation is counter-balanced by such a selection process, making an overall increasing trend (as we showed pre-viously in experimental results). We also calculated the standard deviation of the improvement, as well as minimal and maximal improvement. The error bars in Figure 6 show the minimal and maximal improvement. The standard deviation of the operators are 0.0004, 0.0005, 0.0009, 0.0100, 0.0028, respectively. This indi-cates that the mutation operators only have slight impact on the accuracy while changes made by crossover are more significant. In the best case,  X  X wap crossover X  improved accuracy by 0.026,  X  X tructural crossover X  improved 0.029, while all the mutation op-erators can only improve no more than 0.002 at their best. These statistics match our intuition that more significant changes can po-tentially bring better improvements than local modifications.
Unlike previous approaches that only carry the best hierarchy into the next iteration, we keep hundreds of hierarchies in the pop-ulation. This raises a reasonable concern about our approach: is the large population necessary? To answer this question, we first identified the top-N hierarchies at each iteration, then back-traced their parents from the previous iteration, and finally found out the ranks for their parents. The results are plotted in Figure 7. The x-axis shows the range of the parents X  ranking. For example, range 1 corresponds to rank 1 through 50. Range 10 corresponds to rank 451 through 500. We can see that most parents rank above 300, while still leaving a significant portion between 300 and 500. From another point of view, if we were to keep only 50 hierarchies, we would have lost approximately 88% of the top 1 hierarchies at each iteration, 84% of the top 5 and top 10. Although we could probably shrink the population size by 20% without significant degradation in accuracy, this supports the idea that the comparatively large pop-ulation is necessary.
In this paper, we proposed a hierarchy adaptation approach us-ing the standard mechanisms of a genetic algorithm along with spe-cial genetic operators customized for hierarchies. Unlike previous approaches which only keep the best hierarchy in the search pro-cess and modify the hierarchy locally at each step, our approach maintains population variety by allowing simultaneous evolution of a much larger population, and enables significant changes dur-ing evolution. Experiments on multiple classification tasks showed that the proposed algorithm can significantly improve automatic classification, outperforming existing state-of-the-art approaches. Our analysis showed that the variety in population and customized reproduction operators are important to improvement in classifica-tion.
 We thank Dr. Hector Munoz-Avila for discussions that inspired the use of genetic algorithms, and Liangjie Hong and Na Dai for help-ful discussions. This material is based upon work supported by the National Science Foundation under Grant Number IIS-0545875.
