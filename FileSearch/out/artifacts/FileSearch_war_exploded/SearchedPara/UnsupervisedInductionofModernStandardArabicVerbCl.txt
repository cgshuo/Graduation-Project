 The creation of the Arabic T reebank (A TB) f a-cilitates corpus based studies of man y interesting linguistic phenomena in Modern Standard Arabic (MSA). 1 The A TB comprises manually annotated morphological and syntactic analyses of ne wswire te xt from dif ferent Arabic sources. W e e xpl o i t the A TB for the no v el task of automatically creating le x-ical semantic v erb classes for MSA. W e are inter -ested in the problem of classifying v erbs in MSA into groups that share semantic elements of mean-ing as the y e xhibit similar syntactic beha vior . This manner of classifying v erbs in a language is mainly adv ocated by Le vin (1993). The Le vin Hypothesis (LH) contends that v erbs that e xhibit similar syn-tactic beha vior share element(s) of meaning. There e xists a relati v ely e xtensi v e classification of English v erbs according to dif ferent syntactic alternations, and numerous linguistic studies of other languages illustrate that LH holds cross linguistically , in spite of v ariations in the v erb class assignment (Guerssel et al., 1985).

F or MSA, the only test of LH has been the w ork of Mahmoud (1991), ar guing for Middle and Unac-cusati v e alternations in Arabic. T o date, no general study of MSA v erbs and alternations e xists. W e ad-dress this problem by automatically inducing such classes, e xploiting e xplicit syntactic and morpholog-ical information in the A TB.

Inducing such classes automatica lly allo ws for a lar ge-scale study of dif ferent linguistic phenom-ena within the MSA v erb system, as well as cross-linguistic comparison with their English counter -parts. Moreo v er , dra wing on generalizations yielded by such a classification could potentially be useful in se v eral NLP problems such as Information Ex-traction, Ev ent Detection, Information Retrie v al and W ord Sense Disambiguation, not to mention the f a-cilitation of le xical resource creati o n such as MSA W ordNets and ontologies. Based on the Le vin classes, man y researchers at-tempt to induce such c lasses automatically (Merlo and Ste v enson, 2001; Schulte im W alde, 2000) . No-tably , in the w ork of Merlo and Ste v enson , the y at-tempt to induce three main English v erb classes on a lar ge scale from parsed corpora, the class of Uner g a-ti v e, Unaccusati v e, and Object-drop v erbs. The y re-port results of 69 . 8% accurac y on a task whose base-line is 34% , and whose e xpert-based upper bound is 86 . 5% . In a task similar to ours e xcept for its use of English, Schulte im W alde clusters English v erbs semantically by using their alternation beha v-ior , using frames from a statistical parser combined with W ordNet classes. She e v aluates ag ainst the published Le vin classes, and reports that 61% of all v erbs are clustered into correct classes, with a base-line of 5% . W e emplo y both soft and hard clustering techniques to induce the v erb classes, usi n g the clustering algo-rithms implemented in the library cluster (Kaufman and Rousseeuw , 1990) in the R statistical comput-ing language. The soft clustering algorithm, called F
A N N Y , is a type of fuzzy clustering, where each ob-serv ation is  X  X pread out X  o v er v arious clusters. Thus, the output is a members h i p function P ( x i , c ) , the membership of element x i to cluster c . The mem-berships are nonne g ati v e and sum to 1 for each fix ed observ ation. The algorithm tak es k , the number of clusters, as a parameter and uses a Euclidean dis-tance measure.

The hard clustering used is a type of k -means clus-tering The canonical k -means algorithm proceeds by iterati v ely assigning elements to a cluster whose center (centroid) is closest in Euclidian distance. F or both clustering techniques, we e xplore three dif-ferent sets of features. The features are cast as the column dimensions of a matrix with the MSA lem-matized v erbs constituting the ro w entries. Inf ormation content of frames This is the main feature set used in the clustering algorithm. These are the syntactic frames in which the v erbs occur . The syntactic frames are defined as the sister con-stituents of t h e v erb in a V erb Phrase (VP) con-stituent.

W e v ary the type of information resulting from the syntactic frames as input to our clustering algo-rithms. W e in v estig ate the impact of dif ferent le v-els of granularity of frame information on the clus-tering of the v erbs. W e create four dif ferent data sets based on the syntactic frame information reflect-ing four le v els of frame information: FRAME1 in-cludes all frames with all head information for PPs and SB ARs, FRAME2 includes only head informa-tion for PPs b ut no head information for SB ARs, FRAME3 includes no head information for neither PPs nor SB ARs, and FRAME4 is constructed with all head information, b ut no constituent ordering in-formation. F or all four frame information sets, the elements in the matrix are the co-occurrence fre-quencies of a v erb with a gi v en column heading. V erb patter n The A TB includes morphological analyses for each v erb resulting from the Buckw al-ter 2 analyzer . Semitic languages such as Arabic ha v e a rich templatic morphology , and this analy-sis includes the root and pattern information of each v erb . This feature is of particular scientific interest because it is unique to the Semitic languages, and has an interesting potential correlation with ar gu-ment structure.
 Subject animacy In an attempt to allo w the clus-tering algorithm to use information closer to actual ar gument structure than mere syntactic frames, we add a feature that indicates whether a v erb requires an animate subject. F ollo wing a technique suggested by Merlo and Ste v enson , we tak e adv antage of this tendenc y by adding a feature that is the number of times each v erb occurs with each NP types as sub-ject, including when the subject is pronominal or pro-dropped. 5.1 Data Pr eparation The data used is obtained from the A TB. The A TB is a collection of 1800 stories of ne wswire te xt from three dif fe rent press agencies, comprising a total of 800 , 000 Arabic tok ens after clitic se gmentation. The domain of the corpus co v ers mostly politics, economics and sports journalism. Each acti v e v erb is e xtracted from the lemmatized treebank along with its sister constituents under the VP . The ele-ments of the matrix are the frequenc y of the ro w v erb co-occuring with a feature column entry . There are 2074 v erb types and 321 frame types, corresponding to 54954 total v erb frame tok ens. Subject animac y information is e xtracted and represented as four fea-ture columns in our matrix, corresponding to the four subject NP types. The morphological pattern associated with each v erb is e xtracted by looking up the lemma in the output of the morphological ana-lyzer , which is included with the treebank release. 5.2 Gold Standard Data The gold standard data is created automatically by taking the English translations corresponding to the MSA v erb entries pro vided with the A TB distrib u-tions. W e use these English translations to locate the lemmatized MSA v erbs in the Le vin English classes represented in the Le vin V erb Inde x. Thereby creat-ing an approximated MSA set of v erb classes corre-sponding to the English Le vin clas ses. Admittedly , this is a crude manner to create a gold standard set. Gi v en the l ack of a pre-e xisting classification for MSA v erbs, and the no v elty of the task, we consider it a first approximation step to w ards the creation of a real gold standard classification set in the near fu-ture. 5.3 Ev aluation Metric The e v aluation metric used here is a v ariation on an F -score deri v ed for hard clustering (Rijsber -gen, 1979). The result is an F  X  measure, where  X  is the coef ficient of the relati v e strengths of pre-cision and recall.  X  = 1 for all results we re-port. The score measures the maximum o v erlap be-tween a h ypothesized cluster (HYP) and a corre-sponding gold standard cluster (GOLD), and com-putes a weighted a v erage across all the HYP clus-ters: F  X  =
Here A is the set of HYP clusters, C is the set of GOLD clusters, and V to t = number of v erbs that were clustered into the HYP set. This can be lar ger than the number of v erbs to be clustered because v erbs can be members of more than one cluster . 5.4 Results T o determine the best clustering of the e xtracted v erbs, we run tests comparing fi v e dif ferent pa-rameters of the model, in a 6 x 2 x 3 x 3 x 3 design. F or the first parameter , we e xamine six dif ferent frame dimensional conditions, FRAME1+ SUB-J Animac y + V erbP att,FRAME2 + SUBJ Animac y + V erbP att,FRAME3 + SUBJ Animac y + V erbP att, FRAME4 + SUBJ Animac y + V erbP att, FRAME1 + V erbP att only; and finally , FRAME1+ SUBJ An-imac y only . The second parameter is hard vs. soft clustering. The last three conditions are the num-ber of v erbs clustered, the number of clusters, and the threshold v alues used to obtain discrete clusters from the soft clustering probability distrib ution. W e compare our best results to a random baseline. In the baseline, v erbs are randomly assigned to clus-ters where a random cluster size is on a v erage the same size as each other and as GOLD. 3 The highest o v erall scored F  X  =1 is 0 . 501 and it results from us-ing FRAME1+SUBJ Animac y+V erbP att, 125 v erbs, 61 clusters, and a threshold of 0 . 09 in the s oft clus-tering condition. The a v erage cluster size is 3 , be-cause this is a soft clustering. The random baseline achie v es a n o v erall F  X  =1 of 0 . 37 with comparable settings of 125 v erbs randomly assigned to 61 clus-ters of approximately equal size. A representati v e mean F  X  =1 score is 0 . 31 , and the w orst F  X  =1 score obtained is 0 . 188 . This indicates that the cluster -ing tak es adv antage of the structure in the data. T o support this observ ation, a statistical analysis of the clustering e xperiments is undertak en in the ne xt sec-tion. F or further quantitati v e error analysis of the data, we perform ANO V As to test the significance of the dif ferences among the v arious parameter settings of the clustering algorithm. W e find that informa-tion type is highly significant ( p &lt; . 001 ). W ithin v arying le v els of the frame information parameter , FRAME2 and FRAME3 are significantly w orse than using FRAME1 information ( p &lt; . 02 ). The ef fects of SUBJ Animac y , V erbP att, and FRAME4 are not significantly dif ferent from using FRAME1 alone as a baseline, which indicates that these features do not independently contrib ute to impro v e clustering, i.e. FRAME1 implicitly encodes the information in V erbP att and SUBJ Animac y . Also, algorithm type (soft or hard) is found to be significant ( p &lt; . 01 ), with soft clustering being better than hard clustering, while controlling for other f actors. Among the con-trol f actors, v erb number is significant ( p &lt; . 001 ), with 125 v erbs being better than both 276 and 407 v erbs. The number of clusters is also significant ( p &lt; . 001 ), with more clusters being better than fe wer .

As e vident from the results of the statistical anal-ysis, the v arious informational f actors ha v e an inter -esting ef fect on the quality of the clusters. Includ-ing le xical head informati o n in the frames signifi-cantly impro v es clustering, confirmi ng the intuition that such information is a necessary part of the alter -nations that define v erb classes. Ho we v er , as long as head information is included, configurational infor -mation about the frames does not appear to help the clustering, i.e. ordering of constituents is not signif-icant. It seems that rich Arabic morphology plays a role in rendering order insignificant. Nonetheless, this is an interesting result from a linguistic perspec-ti v e that be gs further in v estig ation. Also interesting is the f act that SUBJ Animac y and the V erbP att do not help impro v e clustering. The non-significance of SUBJ Animac y is indeed surprising, gi v en its sig-nificant impact on English clusterings. Perhaps the cues utilized in our study require more fine tuning. The lack of significance of the pattern information could indicate that the role played by the patterns is already encoded in the subcate gorization frame, therefore pattern information is superfluous.
The score of the best parameter settings with re-spect to the baseline is considerable gi v en the no v-elty of the task and lack of good quality resources for e v aluation. Moreo v er , there is no reason to e x-pect that there w ould be perfect alignment between the Arabic clusters and the corresponding translated Le vin clusters, primarily because of the quality of the translation, b u t also because there is unlik ely to be an isomorphism between English and Arabic le x-ical semantics, as assumed here as a means of ap-proximating the problem.

In an atte mpt at a qualitati v e analysis of the re-sulting clusters, we manually e xamine se v eral HYP clusters. As an e xample, one includes the v erbs &gt; aloqaY [meet], $ ahid [vie w], &gt; ajor aY [run an in-tervie w], { isotaqobal [r eceive a guest], Eaqad [hold a confer ence], &gt; aSodar [ issue] . W e note that the y all share the concept of con v ening, or formal meet-ings. The v erbs are clearly related in terms of their e v ent structure (the y are all acti vities, without an as-sociated change of stat e) yet are not semantically similar . Therefore, our clustering approach yields a classification that is on par with the Le vin classes in the coarseness of the cluster membership granular -ity . In summary , we observ e v ery interesting clusters of v erbs which indeed require more in depth le xical semantic study as MSA v erbs in their o wn right. W e successfully perform the no v el task of apply-ing clustering techniques to v erb frame information acquired from the A TB to induce le xical semantic classes for MSA v erbs. In doing this, we find that the quality of the clusters is sensiti v e to the inclu-sion of information about le xical heads of the con-stituents in the syntactic frames, as well as param-eters of the clustering algorithm. Our classification performs well with respect to a gold standard clus-ters produced by noisy translations of English v erbs in the Le vin classes. Our best clustering condition when we use all frame information and the most fre-quent v erbs in the A TB and a high number of clusters outperforms a random baseline by F  X  =1 dif ference of 0 . 13 . This analysis leads us to conclude that the clusters are induced from the structure in the data
Our results are reported with a ca v eat on the gold standard data. W e are in the process of manually cleaning the English trans lations corresponding to the MSA v erbs.

