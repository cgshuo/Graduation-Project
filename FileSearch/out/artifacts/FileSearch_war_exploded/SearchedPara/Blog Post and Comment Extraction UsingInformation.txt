 As we know, blog is one of the core applications of web 2.0. It is composed by blogrolls, permalinks, comments, trackbacks and posts. With the development of blogosphere, searching information from blog pages becomes more and more important. However, blog pages inevitably include some noises which affect the precision of the information retrieval system. In order to improve the perfor-mance of information retrieval system, it is necessary to acquire the post and comment from blog page.

There are some state-of-the-art methods in information extraction. One of the most common methods is link/text removal ratio [2,3]. This method is use-ful in removing useless links in news page. From the experiment in [2,3], this method shows a good performance in ext racting news from news page. However, this method isn X  X  good at differentiating other useless texts from news texts. Besides the research in text extraction, there are a lot of research in extracting data record from the web page. Handcrafted rules, like NLP based, wrapper [1,4,5,6,7,13] and Html-aware [12], are useful in locating the special data record in web page, such as author name, publish time, etc. In [6], Bing Liu uses MDR (Mining Data Region) to automatically find the data record. This method is use-ful in mining both contiguous and noncontiguous data records. A Partial Tree Alignment based method is presented in [12]. This method is used to align sim-ilar data items from multiple data fields. In some specific web sites, the above methods achieve a high precision. How ever, these methods need to write some polished rules by hand. These rules aren X  X  easy to achieve and they are language sensitive. We have to write rules for each kind of nature language. Although there are some kinds of methods to automatically acquire rules from the corpus, all these methods require a well-formed corpus annotation which needs a great effort.

Because the characters of the post and comment are different, it is necessary to separate the post and comment. This work is similar to the topic segmen-tation. Some papers were published in this field. Reynar provides an exten-sive discussion of algorithms for topic segmentation [10]. Yan Qi introduces a CUrvature-Based segmentation method [8]. Although the above topic segmen-tation methods achieve very good performance in identifying boundaries in text streams, the topics of the post and comment are often the same.

In this condition, it is necessary to do some research in blog extraction. In this paper, we try to use html format information of blog page from the perspective of information theory. Therefore, we propose a two-stage method which computes the information quantity of the html format information to extract the post and comment in blog page. The main contributions of this paper are as follows. 1. We transform the problem of detecting the boundary between the post and 2. We combine the advantage of the vision information and the effective text
The structure of this paper is as follows. We discuss the framework of our two-stage extractor in section 2. Section 3 describes the algorithm of locating main text and presents an example. Finding separator between the post and comment will be detailed in section 4. The results of experiments will be shown in section 5. A typical function of web page extraction is to locate some useful texts and filter the noises. Here, in blog page, we call these useful texts  X  main text  X . Main text is some of object texts which represent the theme of the web page. The main text of blog page includes two parts of text. The first part is the post which is written by the author. The second part is the comment which is written by the reader who is interested in the post. A ex ample of main text is shown in Figure 1. In this figure, all of the texts in cell C 2 are the main text of the example blog page. Both of these two parts are important in representing the main idea of the document and they have different priority. If we want to find the opinion of the author, it is obvious that the post is the first thing to be concerned. Based on this consideration, we have to separate the post and comment. The separating result of example page is shown in Figure 2.
With the above discussion, the framework of our blog extraction includes two stages, locating the main text and finding separator between the post and comment. Because the format of html can form a DOM (Document Object Model) tree and the main text exists in one of the subtree, in the DOM model, the object of locating the main text is equal to find the minimal subtree which contains the main text. After the locating main text stage, the html format information is used in finding separator between the post and comment. Because of different html format distribution in the post and comment, the object of finding separator is to make a suitable division which can partition the different format of the post and comment.
 Based on the DOM tree structure, our task of locating main text is to find the minimal subtree which contains the main text. We call this minimal subtree  X  minimal main text subtree  X . Because the main text of the blog page only includes the post and comment, the minimal main text subtree is the minimal subtree which contains the post and comment. Here, any other texts and links except the main text are treated as noises. There are three kinds of noises in blog pages. The first kind of noise is some advertisements which have no contribution to the information retrieval system. The second kind of noise is some useful links. Such as the blogrolls which contain a list of other weblogs that the author reads regularly. These links are useful in link analysis, but they are useless in text analysis. The third kind of noise is some routine texts which represent some status of the blog. Such as  X  X opyright X  text and  X  X bout author X  text. For example, in Figure 1, there are some  X  X bout author X  texts in cell C 3. Although link/text removal ratio is useful in removing the useless links in news page, there are two limitations when it is used in blog page. First, some authors write some useful links in the post. Second, it is difficult to distinguish the routine text and the main text because they are natural language expressions appearing in text. Based on our experiments, we find two important features of the main text. The first feature is that most of the main texts of blogs hold the largest vision space in comparing with their siblings in the DOM tree. we call this vision space  X  vision information  X . Vision information refers to the visual position of each html block, such as width, height, etc. But in this paper, we only use the width in vision information. In [11], it shows that the vision information is useful in differentiating segments in the web page. The second feature is that most of the main texts of blogs contain more words than other routine texts. Therefore, for the first feature, we use css (Cascading Style Sheets) style in html to acquire vision information, for the second feature, we calculate the effective text information in each node of the DOM tree. We use the following formula to calculate theeffectivetextinformation .
 Where W e is the number of words without links in the text, W a is the number of words in the text. W e W how much effective text information each word of the text has.

With the above consideration, we build the effective text information based locating main text algorithm which is described as follows.
 Locating main text algorithm 1. Build an html DOM tree. 2. Calculate the effective text information of each node. 3. Use the css style to get the visual width of each node. 4. From the root of html DOM tree, do the following steps. 5. Use the range of chosen subtree as the range of main text.

In this algorithm, we define the concept of loss ratio. The main text and other parts of blog page have different distribution of effective text information ratio. If loss ratio changes greatly, it is in a great possibility that we have located the boundary of main text. The value of loss ratio threshold is difficult to set because the value of loss ratio threshold would be different for different blog pages. Therefore, we use the average loss ratio as the value of loss ratio threshold.
According to our algorithm, we divide page into cells and it is easy to find the correct cell C 2. First, we compare two cells ( F 1and F 2). We will find that the width of F 2 is equal to the width of F 1. Then we compare the effective text information and choose cell F 2 as root. Second, we co mpare three cells ( C 1, C 2 and C 3). It is easy to find that C 1 has the longest width, but the number of its words is fewer than the threshold. Although the effective text information of C 3 is bigger than C 2, we select C 2 because the width of C 2 is bigger than C 3. So we select C 2 as root. And we will find that loss ratio is out of the range of threshold. This is because from cell F 2tocell C 2, the distribution of effective text information ratio changes greatly. As a result, we stop here and choose cell C 2 as the range of main text. 4.1 Theory Analysis In tree structure, suppose that the ma in text is correctly located and the web format information of post and comment exists. We can partition the html tree of main text into three parts. The first part contains a part of the post and the last part contains a part of the comment. Therefore, the problem of finding the separator between the post and comment is to find which part the middle part is similar to. From this purpose, we have to compare two trees to compute their similarity [9]. This kind of method greatly depends on the formula of computing similarity. It is difficult to define a suitable formula.

From another point of view, computing the similarity of tree structure is to detect the redundancy of html format. If a block is redundant to the post (or the comment), it will be similar to the format of the post (or the comment). From data compression and information communication, the information theory shows a great power in detecting the redundancy of information. In the information theory philosophy, for three strings (A, B and C), if C is more similar to A than B, then the increment of information quantity of adding C to A will be smaller than the increment of information quantity of adding C to B. Based on this consideration, the html tag sequence is mapped into string to compute the redundancy of format information.

Without loss of generality, we assume that there are two possible separators (
S 1 and The whole html tag sequence is separated into three parts ( M 1 , M 2 , M 3 ). This is shown in Figure 3. We treat the html tags in M 3 as a whole block which is named as D . p 1 is the probability of D in M 1 . p 2 is the probability of D in M 2 .If p information quantity increment of combining the M 1 and M 3 is  X  log 2 ( p 1 )and the information quantity increment of combining the M 2 and M 3 is  X  log 2 ( p 2 ). It is obvious that the format in M 3 is more close to the format in M 1 than in M 2 , and we should choose possible separators, we can compare each pair of separators to find which one is the best.
 In the above discussion, we treat the html tags in M 3 as a whole block. In unigram model, we consider each html tag as an independent block. Assume that there are m kinds of html tags in blog page. Because each possible separator divides the html tag sequence into two parts (post and comment), we define the information quantity of separator as follows.
 Where j is the j th part which is divided by the separator. For the i th kind of tag in the j th part, its probability is p ji and its number is n ji . We can use this equation to find the suitable separator. For example, in Figure 3, assume that p M j i is the probability of the i th kind of tag in M j .And the number of the i th kind of tags in M j is n M j i . The information quantity of M 1 and M 2 ) will increase the information quantity. If we choose (adding M 3 to M 2 ), the information quantity will increase  X  1 .Ifwechoose S 2 as the right separator (adding M 3 to M 1 ), the information quantity will increase  X  2 . Then we can get the following result.
 Where p M separator. p M is separator. IS i is the information quantity of S i .

From the above equation, we can find that the separator which has the min-imal increment will also be the separator which has the minimal information quantity. So our target becomes to find the separator which has the minimal information quantity. 4.2 Basic Algorithm Because all the nodes in unigram model are equal, we use the preorder traversal method to map the tree structure into a linear structure. Then we calculate the information quantity of separator to find the suitable separator. The algorithm is shown as follows.
 Finding separator algorithm 1. Build an html DOM tree in the range of the main text. 2. Eliminate all the non-tag nodes in DOM tree and build an html tag tree. 3. For each immediate child node of the root, do the following steps. 4. Choose the separator which has the minimal information quantity.
In this algorithm, we only check the immediate child node of the root node of minimal main text subtree. This is because the post node and comment node exist in the different immediate child node, otherwise the root node won X  X  be the root node of the minimal main text subtree which contains the post and comment. So if we locate wrong minimal main text subtree, the chosen separator in this algorithm will be wrong.
 5.1 Corpus Processing The goal of our experiment is to test the performance of our information quantity based extracting algorithm. We use the standard blog corpus which comes from the blog track in TREC2006. According to our algorithm, we process the corpus in the following steps. First, we choose all the permalinks from the data which were crawled in December 7, 2005. Second, according to the domain name of each blog page, we count the number of pages in each domain and select the blog pages in the top 100 domains as test data. Third, because our algorithm uses css style to acquire the visual width of each html tag, we download css style file of each page. At last, after eliminating the pages without css style, we get 25910 blog pages and label them in manual. The status of these pages are shown in Table 1. Because a lot of domain names of blog pages are from the same blog site, the final 25910 blog pages are distributed in 9 blog sites. We manually label these pages and the annotation of the corpus denotes the root node of the minimal main text subtree and immediate child node which contains the comment in the minimal main text subtree. Labelling blog page one by one isn X  X  an easy work. Fortunately, although there are hundreds of format styles in these pages, we find that the blog site builders like to use some comprehensible words in html tag to identify the main text and comment. Such as  X  X ain X ,  X  X ost X ,  X  X omment X ,  X  X eply X , etc. So we use some heuristic words in html tag to group these 25910 pages and get 84 groups. These groups were checked one by one. In each group, we use these heuristic words to manually label the root node of the minimal main text subtree and immediate child node which contains the comment. Finally, we write only 84 templates instead of 25910 labelled pages. 5.2 Experiment Result Experiment evaluation For the performance evaluation, we define four kinds of precisions as follows. P recision ( MainText )= NL P recision ( P ostComment )= NS P recision ( P ostComment | MainText )= NSL P recision ( MainText + P ostComment )= NSL Where NL is the number of pages which is correct in locating main text. NCorpus is the number of pages in corpus. NS is the number of pages which is correct in finding separator. NSL is the number of pages which is both correct in locating main text and finding separator.
 Performance test In our experiment, the overall performance of our algorithm and the performance of each stage is tested. The results of our algorithm are shown in Table 2. In Table 2, we can see that both Precision(MainText) and Precision(Post Comment | MainText) are high. It shows that our algorithm can locate main text and find separator precisely. We can also see that Precision(PostComment) and Precision(MainText+PostComment ) are so close. As we have mentioned in section 4.2, if the minimal main text subtree is wrong, the chosen separator will be wrong in a great probability. In other words, its contrapositive, if the post and comment is separated correctly (Precision(PostComment)), then the minimal main text subtree is correct in a great probability (Precision(MainText+Post Comment)).

Because our extracting framework includes two stages, we have to test the performance of each stage. In the following experiments, we first compare our locating main text algorithm with other two methods, then we show the perfor-mance of finding separator in all kinds of post/comment ratio.

In Figure 4, we compare the performance of three kinds of locating meth-ods, our effective text information based method, link/text removal ratio based method and text based method. The x axis is the MainText/WebText ratio, and the y axis is Precision(MainText). Because we consider that other texts and links except the main text as noises, the x axis shows the sequence of ratio of main text and noise in blog page. If the MainText/WebText ratio is small, there will be a lot of noises in blog page. Three curves in this figure show the performance trend of three methods. It is clear that our effective text informa-tion based method outperforms other two methods. The link/text removal ratio isn X  X  easy to precisely locate the main t ext. The text based method achieves a good performance when the MainText/WebText ratio is over 7 / 10. But the text based method isn X  X  easy to differentiate the main text and other texts when they have the similar number of bytes.

Some blog pages contain few comments (or no comments). Our finding sep-arator algorithm is based on the condition that the web format information of post and comment exists. In our corpus processing, we treat the message text  X 0 comments X  as a part of comment text. For example, in Figure 2, although there are 0 comment, we treat the message text  X 0 comments X  and the web format framework of comments as the comment part. In this condition, the length of post text will be bigger than the length of comment text. It is important to exam the performance of our information quantity based finding separator method in all kinds of post/comment ratio. The result is shown in Figure 5. The x axis is the post/comment ratio, and the y axis is Precision(PostComment | MainText). In the result, our method achieves a high precision (over 90%) when the length of comment text is bigger than the length of post text. When the length of post text becomes bigger than the length of comment text, the precision decreases slightly. This is because there are more redundant html formats in the comment than in the post. Our finding separator algorithm is easy to detect the similar (or redundant) html tag node. The trend of curve shows that even in the condition of few comments, our algorithm also achieves a good precision (over 78%). Blog search test Based on our blog extraction method, we can extract the post and comment from blog to improve the performance of blog search. In order to test the contri-bution of our extraction method, we use the 88.8G blog corpus and 50 topics in TREC2006 blog track to retrieval the relevant blog pages. The retrieval model is the classical language model with Dirichlet smoothing. Retrieval results are shown in Table 3. The results show that our extraction method improves all four metrics and our results even better than the best results in TREC2006 blog track in three metrics. Extracting the information from the web page is one of the challenging works in information retrieval. In order to acquire the blog post and comment, we build a two-stage method. First, we use the effective text information based method to locate the main text. This method combines the advantage of effective text information and vision information. Second, in finding the separator between the post and comment, we choose the separator which has the minimal information quantity. Both in the theory analysis and experiment, we find this method is very useful. From the results of experiments , our method achieves a good performance.
Although our two-stage method achieves a good performance, there are still some spaces to improve. In finding separator, we only use the unigram model to calculate the information quantity. Compare with bigram and trigram model, unigram model is more simple in representing the information. In fact, there are some relations between the html tags, especially the hiberarchy structure relation between the html tags.
 The work is supported by the National Fundamental Research Program of China (Project No 2004CB318109). And we would like to thank to Yan Guo, Gang Zhang, Yu Wang and Ruijie Guo for their contributions to the related research work and preparation of this paper.

