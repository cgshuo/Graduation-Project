 1. Introduction explains its constituent graphics. Thus information graphics are an important knowledge source that should not be ignored. graphic such as the graphic's caption, axis labels, etc.

To do this, we must first disambiguate the words in the query and expand the query with related words. Words have multiple words? And lastly, one has the issue of which approach to take, ranging from supervised approaches that learn from labeled training sets to unsupervised methods which use unlabelled corpora [28].

A vexing problem for information retrieval is the term mismatch problem more successfully matched with relevant documents. As with disambiguation, query expansion requires a knowledge source and set of terms for inclusion in the expanded query.

Although disambiguation and query expansion are common issues in text processing and information retrieval, our problem is (including words provided by the graphic's hypothesized intended message) is small compared with that of typical text require large amounts of context terms or focus exclusively on named entities [4,11,27,31] . been extended to query expansion. By a short query, we mean one with fewer than 15 words, of which typically a third are exactly the same terms as those appearing in the query. Third, microblog retrieval is an important search domain. With the increasing usage of Twitter, users have urgent needs to make sense and make use of the information hidden in the tweets. However, since this is a new search problem, it has not yet been well-studied.

Our approach both to disambiguation and query expansion utilizes the huge information resource provided by Wikipedia, the disambiguation by providing a semantic web of hyperlinks and Wikipedia and results in an up-to-date knowledge source.
 our knowledge are the shortest yet. Second, our method can determine when a sequence of words should be disambiguated as a more generally for information systems that must semantically process short text. 2. Related work
Bunescu and Pasca are generally credited with being the first to use Wikipedia as a resource for disambiguation [4]. They developed a more general system that linked all  X  interesting with the more difficult problem of disambiguating all salient terms in the query indiscriminately. However, short strings do not reliably contain trivial terms.

Ferragina and Scaiella [15] addressed this problem by employing a voting system that resolved all ambiguous terms to a maximum of 15 terms in length. The average query length in our test set is just 8.9 words, including stop words.
Ratinov et al. define a local disambiguation method to be one that disambiguates each term independently, and a global limited to named entities, our performance seems to be best when combining our own local and global approaches as well. sequences of words from short texts.

More recently, Meij et al. studied the problem of linking search queries and tweets to Wikipedia concepts [21 our study is that we do not require any training data.
 global query expansion and relevance feedback [20]. Global query expansion extracts synonyms of query terms from a source results in more effective document retrieval. Our work falls into the category of global query expansion. based on how often they linked to one of the K most relevant articles. The highest ranked anchor phrases were then used to from the top-ranked documents, categories and titles as well as from WordNet synsets. These methods rely on anchor phrases documents via short queries.

Milne et al. [26] implemented query expansion via user interaction by using Wikipedia to automatically generate a corpus-short queries and applying our methods to the retrieval of objects that contain only relatively short text. 3. Overview of paper
The remainder of this paper presents our research on Wikimantic which uses Wikipedia as the knowledge source for formally, let s =( t 1 , t 2 , ... , t | s | ) be a sequence of | s | terms. For every term t mapping t j  X  C i where C i is the Wikipedia article that best defines the concept t
Jobs resigns from Apple  X  , an acceptable mapping would link
CEO of Apple.  X  resigns  X  would be mapped to the article Resignation, and Mapping  X  apple  X  to the article for the actual apple fruit would be unacceptable in that context. then use that summary to choose the most probable mapping of terms to concepts. To summarize s , we construct a possible meanings of the terms in s .

Once we have the weighted set (the MixtureConcept), the individual terms in the sequence s can be disambiguated. This Wikimantic approach to disambiguation.
 methodology for extending Wikimantic to query expansion, applies it to microblog retrieval, and presents results that and suggestions for future work. 4. Methodology for constructing topic models use terms like  X  computer  X  ,  X  iPhone  X  ,  X  Steve  X  ,or  X  know that the writer means the Apple Corporation and not the fruit when they just say Our generative model makes the simplifying assumption that it is the Concepts themselves that generate terms in a text. When a writer wishes to write a document or formulate a query about the Apple Corporation, we say that the Concept of from Wikipedia. 4.1. AtomicConcept is a one to one mapping between articles and the AtomicConcepts that generate them. that an article's subject (its AtomicConcept) will be talked about.
 is: occurring in the English language. 2 4.2. MixtureConcept the one selected to generate, and all weights necessarily sum to 1. Like all Concepts, a MixtureConcept M has an a priori probability P ( M ) of being the topic, and probabilities P ( t | M ) of generating a given term t. may look something like:
To find the likelihood of the term  X  iPhone  X  in any term sequence with M the content of a concept's article to estimate w i and then a second method that uses references between concepts. 4.3. Content-based topic modeling with AtomicConcepts and then weight the AtomicConcepts. Recall that there is a 1 article to estimate the concept's weight in the MixtureConcept.

To construct the elements of the set of AtomicConcepts comprising the MixtureConcept, we look at every subsequence of
Finally, all articles that share a disambiguation page with an article already in the set are added. resigns  X  : Steve  X  Matches title of disambiguation page Steve . Add all articles disambiguated by that page. ( disambiguation ) link to.
 ( disambiguation ) link to.
 Steve Jobs  X  Matches the title of the article Steve _ Jobs .
 Jobs Resigns  X  Matches nothing, so no articles added.

Steve Jobs Resigns  X  Matches nothing, so no articles added.
Once our unweighted set M is populated, it will contain a large number of candidate AtomicConcepts of varying degrees of relevance, and we rely on weights to mitigate the impact of spurious concepts. We weight each AtomicConcept A probability that every term in s was generated by that AtomicConcept, ignoring stop words. sequence. A Concept like Jobs _( Role ) may have a high probability of generating will penalize it significantly. We can expect the Concept Steve_ Jobs to generate which would give it a much larger weight than Jobs _( Role ) would get. 4.4. ReferenceRank topic modeling: M R
Our second method, ReferenceRank, uses references between AtomicConcepts to estimate the weights w generate a given term in s .
 Consider the following example where M might be misleading if it is weighted by probability of generating. all concepts that are likely to generate the term  X  apple Concepts generate references to other concepts as well as terms.

Given that AtomicConcept A 1 generated a reference to another concept, the probability that the referenced concept is A estimated as the probability that clicking a random link in A The probability that a MixtureConcept M will generate a reference to a Concept C (denoted R of the AtomicConcepts in M generating a reference to C: where w i = the weight of A i in M (Eq. (2)) For a TermSequence s , we compute the special MixtureConcept M their probability of being referenced.
 proportional to the weighting of that AtomicConcept in M . 5. Disambiguation its probability of being the correct mapping for a term in s . In the case of topic model M adjusted to reflect its probability of describing the sense of a term in s.

However, reliance on the topic model M R by itself is problematic due to Wikipedia's relatively sparse link structure. This means that neither will receive a vote and therefore their weights in M it must be supplemented with information from M . For this reason, the mixture P ( A | s )=(1 optimal value of d is determined experimentally.

Another issue is the need to handle sequences of words that should be treated as a single concept. In many disambiguation disambiguation considerably more difficult. Does  X  Life Saver these graphs.

Thus we need a more robust method of disambiguation. Our approach is to consider every possible sequence of words as a term for disambiguation. Thus if a problematic sequence of terms like breakdown of the sequence is disambiguated. Each breakdown yields a unique candidate set of disambiguations that is scored method, as described in the following subsections. 5.1. Product method depicts the four candidate sets that are considered when the string  X  new  X  .
 as n disambiguations of the entity, 5 as shown by the fourth row in Fig. 1 , where the score for the sequence
P ( Concept New _ York _ City | s ) to the third power. 5.2. Averaging method
Concepts in the set; once again, n adjacent terms that were disambiguated as referring to a single entity are counted as n disambiguations. For example, the fourth line of Fig. 2 shows the sequence the sequence). 5.3. Evaluation Our system, named Wikimantic, includes four alternative methods for disambiguation: the product and averaging methods with
MixtureConcept M as the topic model for the term sequence s and the product and averaging methods with (1 the topic model. Each method was evaluated using 70 queries from the Trec 2007 QA track and 26 queries collected for our to ambiguous phrasing of the queries). About 110 words were content words that were not nouns. We present results for disambiguating just nouns and for disambiguating all non-function words.

Table 1 displays some short queries and a few interesting terms disambiguated by Wikimantic, along with the Wikipedia animals , and price of oil which are multi-word terms that are not named entities. For example, airport code is correctly disambiguated by Wikimantic as a single concept but which could have been erroneously interpreted as two separate concepts with multiple possible interpretations for code .
 noun-equivalent article. For example, it would be acceptable to annotate the term
Tables 2 and 3 present statistics on precision and recall for the four methods. Precision is equal to the number of terms nouns and 59.25 overall. 5.4. Discussion matches between alternate conjugations of the same verb.

For each of the two methods described in Section 5.1 , we evaluated Wikimantic using the combination (1 with varying values of d . Improved performance occurred for small values of d (d the ReferenceRank votes from completely overriding the initial scores from M .

Our results show that our system Wikimantic has very good success at disambiguating terms in short queries, even without capitalization or a priori identification of multi-word strings that should be mapped to a single concept. 6. Extending Wikimantic to query expansion
Wikimantic would map the query  X  superbowl commercials  X  to the Wikipedia concept query with terms from this concept, such as  X  advertising ones mentioning  X  superbowl  X  and  X  advertising  X  but not query expansion.
 methods use Wikimantic results for query expansion while the last one uses it to adjust the weight of query terms. 6.1. Baseline method for microblog retrieval timestamp, and only relevant tweets that were posted before the timestamp of the query should be retrieved. following: is referred to as BL .

Note that we have conducted preliminary experiments using the collection from Microblog Track 2011 [29], and found that
The next sections describe our efforts in leveraging Wikimantic results to improve retrieval performance. 6.2. Query expansion via Wikimantic
Query expansion is a commonly used strategy in IR to improve retrieval performance since it is effective in bridging the example, given the query  X  car costs  X  , if we could expand the query with related terms such as we would be able to retrieve relevant documents mentioning
The challenge is how to select expansion terms and appropriately assign weights to them so that they exert the appropriate influence in evaluating candidate documents for retrieval. Recall that the proposed Wikimantic system can construct a MixtureConcept that represents a topic and that the the information from the MixtureConcept to identify terms that are highly relevant to those in the original query.
Formally, given a query Q , we first use Wikimantic to construct the MixtureConcept M ( Q )={( w of AtomicConcepts (Wikipedia articles) and their associated weights. We can then use a term weighting method to select expansion terms from these Wikipedia articles and expand the original query with the weighted expansion terms. In particular, we propose the following term weighting method to select expansion terms t. where P ( t | A i ) is the likelihood of generating term t from the AtomicConcept A ln df t  X  X  represents the importance of a term and is computed using the IDF weighting [17].
AtomicConcept A i ; (2) the likelihood that AtomicConcept A retrieving relevant documents.
 newly added expansion terms would be controlled by a parameter for query Q . Thus, the retrieval function based on query expansion can be written as: where  X  controls how much we trust the expansion terms. When larger, we put more trust on the expansion terms.
 (1) the original MixtureConcept, which is constructed using the methods described in Section 4 ; and (2) the subset of the AtomicConcepts that have been selected as the disambiguation of a term in the query Q. The expansion methods cor-responding to these two scenarios are referred to as QE-ALL and QE-DIS respectively. 6.3. Concept-based query term weighting
Our third strategy uses Wikimantic results to adjust the term weighting based on the relations among query terms. Previous now explore how to use these disambiguated concepts to adjust the term weighting.
 among query terms and may favor documents that are relevant to a subset of query concepts. For example, given a query staff cut  X  , traditional retrieval models may incorrectly assign a higher relevance score to documents covering a single concept in the query than to those covering  X  BBC to favor documents covering more query concepts.
 to use the query concepts information to adjust the term weighting.
 number of more important terms from the same concept that have been covered in the same document as follows: weighting can be written as: where Q  X  denotes a set of query terms that are not associated with any AtomicConcepts, Q favor documents covering all the query concepts through reducing the weights of query terms whose corresponding concepts have been covered by more important terms. The method is referred to as CW. Once again, placed on the expansion terms versus the terms in the original query. 6.4. Experiments
We conducted experiments over two TREC collections to examine whether using Wikimantic results can improve retrieval performance. 6.4.1. Experiment design by NIST assessors. The judgments were made using a three-point scale: documents). All measures are computed with both  X  minimally relevant 6.4.2. Effectiveness of the proposed methods
We evaluated the effectiveness of the proposed methods and compared them with two baseline methods: (1) BL , which is the expansion method that expands a query with synonyms of query terms. The performance results are summarized in Table 4 . the performance.
 [36], their reported performance (0.3014 measured with P@30) is much worse than ours. superbowl commercials which are multi-word terms that are not named entities. In addition, the query assange nobel peace 6.4.3. Parameter sensitivity
Our best query expansion methods have two parameters: (1) of  X  improve performance, precision does not change markedly for the different values of performance is robust with respect to both parameters. 6.4.4. Discussions
To better understand the performance of the proposed methods, we further analyze their performance and make the following interesting observations.

First, the disambiguation results of Wikimantic enable better query understanding. For example, consider the query
Both query terms are common words, so traditional keyword matching methods would return many non-relevant documents able to connect query terms with Wikipedia concepts such as the performance to 0.87 measured by P@30. Similar observations can be made for other queries with common words, such as of The Rite  X  .

Second, the expansion terms from the constructed MixtureConcept are effective in bridging vocabulary gaps, especially for those with named entities. For example, for the query  X  Hugo Chavez  X  leader  X  . Similar queries are  X  Steve Job's health  X  ,  X  should be grouped together and associated with a single concept from which related terms are identified.
Third, query expansion may hurt performance for queries when the concepts contributing expansion terms are not the only important ones in the query. For example, the expansion terms for the query  X  may over-favor tweets mentioning Facebook instead of the privacy concern. Other similar queries are  X  Chicago Blizzard  X  .
 is  X  NCIS TV series  X  as opposed to other concepts such as  X 
Solution  X  . However, for the query  X  Saleh Yemen overthrow  X 
Yemen  X  is only part of the query and cannot cover information about method can help queries withmultiple-term concepts but does not help queries withsingle term concepts. Consider thequery immigrant laws  X  as an example; the baseline method would return many non-relevant documents covering the proposed concept weighting method CW would improve the performance by returning relevant documents covering both  X 
British Government cut  X  ,  X  horse race betting  X  and  X  Keith Olermann new job queries with single-term concepts, such as  X  Yemen Saleh overthrow retrieval performance for a subset of queries and the computational cost is as cheap as the baseline method. 7. Optimization of Wikimantic node graph is small and read speeds are important.
 that comprised less than t % of the total terms. Ignoring unimportant terms has the additional very important advantage of speeding up disambiguation, since insignificant entries will not be read from the disk later. so recently used nodes in RAM, which lets us quickly create links between nodes we have recently used.
After compilation, Wikimantic uses the node graph to compute probability values which are used to compute the weights when speed matters.
 to the larger English Wikipedia. This technique was extremely useful for prototyping new ideas and finding bugs, and is recommended to anyone who is thinking of building a system which processes a lot of information from Wikipedia dump files. 8. Conclusion
This paper has presented Wikimantic and its disambiguation and expansion methods that utilize Wikipedia and work with not limited to nouns, does not rely on correct capitalization, and can determine when a sequence of words should be experimental results show the success of the methodology. Our query expansion methods use the topic concepts produced by Wikimantic for a query and produce very good results for short text documents such as tweets. There are several aspects of future work. Our experimental results showed that a combination of M and M has the potential to improve disambiguation results, but that disproportionate weighting of MixtureConcepts causes the top
AtomicConcept to have too much voting power. We plan to explore a smoother method of weighting MixtureConcepts to overcome this problem. We also plan to explore how to selectively use the concept-based query term weighting strategy to
Consider the query  X  Which technology company has the greatest revenue over the last decade ? selection of this graph as part of the candidate set that will be further evaluated. Acknowledgments
This work uses Microsoft Web N-gram Services and was supported by the National Science Foundation under grants III-1016916 the paper.

References
