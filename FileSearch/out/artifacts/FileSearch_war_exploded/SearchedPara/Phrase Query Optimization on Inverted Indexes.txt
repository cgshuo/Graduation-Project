 Phrase queries are a key functionality of modern search engines. Beyond that, they increasingly serve as an important building block for applications such as entity-oriented search, text analytics, and plagiarism detection. Processing phrase queries is costly, though, since positional information has to be kept in the index and all words, including stopwords, need to be considered.

We consider an augmented inverted index that indexes selected variable-length multi-word sequences in addition to single words. We study how arbitrary phrase queries can be processed efficiently on such an augmented inverted index. We show that the under-lying optimization problem is NP -hard in the general case and describe an exact exponential algorithm and an approximation al-gorithm to its solution. Experiments on ClueWeb09 and The New York Times with different real-world query workloads examine the practical performance of our methods.

Phrase queries are supported by all modern search engines and one of their advanced features most popular with human users, ac-counting for up to 5% of query volume [10]. Even when unknown to users, phrase queries can still be implicitly invoked, for instance, by means of query-segmentation methods [6]. Beyond their use in search engines, phrase queries increasingly serve as a building block for other applications such as (a) entity-oriented search and analytics (e.g., to identify documents that refer to a specific entity using one of its known labels), (b) plagiarism detection (e.g., to identify documents that contain a highly discriminative fragment from the suspicious document), (c) culturomics (e.g., to identify documents that contain a specific n -gram and compute a time-series from their timestamps). Our focus in this work is on sup-porting phrase queries more efficiently.

Positional information about where words occur in documents has to be maintained to support phrase queries, which leads to in-dexes that are larger (e.g., [3] report a factor of about 4  X  for the inverted index) than those required for keyword queries. Also, all words need to be considered in the case of phrase queries, as opposed to keyword queries for which stopwords can be ignored. Consequently, phrase queries are substantially more expensive to process, since more data has to be obtained from the index.
The problem of substring matching, which is at the core of phrase queries, has been studied extensively by the String Processing com-munity. However, the solutions developed (e.g., suffix arrays [8] and permuterm indexes [5]) are designed for main memory and cannot cope with large-scale document collections. Solutions de-veloped by the Information Retrieval community [11, 13] build on the inverted index, extending it to index selected multi-word se-quences, so-called phrases , in addition to single words.
In this work, we follow the general approach of augmenting the inverted index with selected multi-word phrases. Given such an index, we focus on the problem of phrase-query optimization , that is, determining for a given phrase query an optimal set of terms to process it. Consider, as a concrete example, the phrase query  X  X e are the champions X  and assume that all bigrams have been indexed alongside single words. Here, the space of possible solutions includes among others { we , are , the , champions } and { we are , are the , champions } . Identifying a cost-minimal set of indexed terms is the problem addressed in this work. Existing work [13] has addressed this problem only using heuristics. In con-trast, we study its hardness and devise an exact exponential algo-rithm and an approximation algorithm to its solution.

Contributions that we make in this work thus include (1) we study the problem of phrase-query optimization , establish its NP -hardness, and describe an exact exponential algorithm as well as an O (log n ) -approximation algorithm to its solution; (2) an experi-mental evaluation on ClueWeb09 and a corpus from The New York Times, as two real-world document collections and different work-loads denoting the three kinds of tasks where phrase queries are applicable, comparing our approach against state-of-the-art com-petitor and establishing its efficiency and effectiveness. Organization. The rest of this paper is organized as follows. Section 2 introduces our formal model and our augmented-index framework. Section 3 deals with optimizing phrase queries. Sec-tion 4 describes our experimental evaluation. Finally, we relate our work to existing prior work in Section 5.
We let V denote the vocabulary of all words. The set of all non-empty sequences of words from this vocabulary is denoted V Given a word sequence s =  X  s 1 , . . . , s n  X   X  V + , we let | s | = n denote its length. We use s [ i ] to refer to the word s th position of s , and s [ i..j ] ( i  X  j ) to refer to the word subse-quence  X  s i , . . . , s j  X  . Given two word sequences r and s , we let pos ( r , s ) denote the set of positions at which r occurs in s , for-mally pos ( r , s ) = { 1  X  i  X | s || X  1  X  j  X | r | : s [ i + j  X  1] = r [ j ] } . For r =  X  ab  X  and s =  X  cabcab  X  , as a concrete example, we have pos ( r , s ) = { 2 , 5 } . We say that s contains r if pos ( r , s ) 6 =  X  . To ease notation, we treat single words from V also as word sequences when convenient. This allows us, for instance, to write pos ( w, s ) to refer to the positions at which w occurs in s .

We let the bag of word sequences C denote our document col-lection . Each document d  X  C is a word sequence from V + ing our notation, we now define document frequency as common in Information Retrieval. Let S be a bag of word sequences (e.g., the document collection), we define the document frequency of the word sequence r , as the total number of word sequences from S containing it df ( r , S ) = |{ s  X  X | pos ( r , s ) 6 =  X  X | .
Framework We build on the popular inverted index for our phrase query processing task. To support arbitrary phrase queries, an inverted index has to contain all words from the vocabulary in its dictionary (i.e., V  X  X  ) and record positional information in its posting lists. We denote each posting as ( id ( d ) , pos ( w, d ) ) for word w and document d and the positions pos ( w, d ) at which the word occurs. We augment the inverted index by adding multi-word sequences, so-called phrases , to the set of terms. The dictionary D of such an augmented inverted index thus consists of individual words alongside phrases (i.e., D  X  V + ) as terms. To process a given phrase query q , a set of terms is selected from the dictionary D , and the corresponding posting lists are intersected to identify documents that contain the phrase.

Several authors [4, 11, 13] have exploited the high selectivity of word sequences and proposed phrase-augmented indexes. How-ever, the approaches for query-optimization problem , determining the set of terms that should be used to process a given phrase query, are based on heuristics. We take a principled approach to address the problem, including its formalization and a study of its hardness as described in Section 3.
We now describe how a phrase query q can be processed using a given augmented inverted index with a concrete dictionary D . Our objective is thus to determine, at query-processing time , a subset P  X  X  of terms, further referred to as query plan , that can be used to process q .

To formulate the problem, we first need to capture when a query plan P can be used to process a phrase query q . Intuitively, each word must be covered by at least one term from P . We capture whether P covers q using the predicate covers ( P , q ) =  X  1  X  i  X | q | :  X  t  X  X  :  X  j  X  pos ( q [ i ] , t ) : The phrase query q =  X  abc  X  , as a concrete example, can thus be processed using { X  ab  X  ,  X  bc  X  X  but not { X  ab  X  ,  X  cd  X  X  . Second, we need to quantify the cost of processing a phrase query using a specific query plan.

Intersecting of posting lists can be done using term-at-a-time (T AA T) or document-at-a-time query processing (D AA T).

For both, in the worst case the cost of processing a phrase query depends on the sizes of posting lists read and thus the set of terms selected to process the query.

We model the cost of a query plan P as the total number of post-ings that has to be read c ( P ) = P t  X  X  df ( t, C ) . While sizes of positional postings are not uniform (e.g., due to varying numbers of contained positions), suggesting collection frequency as a possi-bly more accurate cost measure, we found little difference in prac-tice. The sum of document frequencies closely correlates with the response times of our system.

Assembling the above definitions of coverage and cost, we now formally define the problem of finding a cost-minimal query plan P for a phrase query q and dictionary D as the following NP -hard optimization problem T HEOREM 1. P HRASE -Q UERY O PTIMIZATION is NP -hard.
 Proofs of all theorems and corollaries are omitted but are available accompanying technical report [1].
If an optimal query plan P  X  exists, so that every term therein oc-curs exactly once in the query, we can determine an optimal query plan using dynamic programming based on the recurrence O
PT ( i )= in time O ( n 2 ) and space O ( n ) where | q | = n . O PT the cost of an optimal solution to the prefix subproblem q [1 ..i ]  X  once the dynamic-programming table has been populated, an opti-mal query plan can be constructed by means of backtracking. In the first case, the prefix subproblem can be covered using a single term. In the second case, the optimal solution combines an optimal solution to a smaller prefix subproblem, which is the optimal sub-structure inherent to dynamic programming, with a single term that covers the remaining suffix.

T HEOREM 2. If an optimal query plan P  X  for a phrase query q exists such that  X  t  X  X   X  : | pos ( t , q ) | = 1 , then c ( P O
PT ( | q | ) , that is, an optimal solution can be determined using the recurrence O PT .

It entails that we can efficiently determine optimal query plans for phrase queries with no repeated words.

C OROLLARY 1. We can compute an optimal query plan for a phrase query q in polynomial time and space, if  X  1  X  i  X | q | : | pos ( q [ i ] , q ) | = 1 .
 In practice this special case is important, since a large fraction of phrases queries in typical workloads do not contain repeated words.
Otherwise, when there is no optimal query plan P  X  according to Theorem 2, dynamic programming can not be directly applied, since there is no optimal substructure. Consider, as a concrete problem instance, the phrase query q =  X  abxayb  X  with dictio-nary D = { X  a  X  ,  X  b  X  ,  X  x  X  ,  X  y  X  ,  X  ab  X  X  and assume df ( t , C ) &gt; 1 for t  X  { X  a  X  ,  X  b  X  ,  X  x  X  ,  X  y  X  X  and df (  X  ab  X  , C ) = 1 . Here, the optimal solution P  X  = { X  a  X  ,  X  b  X  ,  X  x  X  ,  X  y  X  X  does not contain an optimal solution to any prefix subproblem q [1 ..i ] ( 1 &lt; i &lt; | q | ), which all contain the term  X  ab  X  .

However, as we describe next, an optimal query plan can be com-puted, in the general case, using a combination of exhaustive search over sets of repeated terms and a variant of our above recurrence.
For a phrase query q let the set of repeated terms be formally defined as R = { t  X  X  | | pos ( t , q ) | &gt; 1 } . Let further F  X  R denote a subset of repeated terms. We now define a modified document frequency that is zero for terms from F , formally and denote by O PT 0 the variant of our above recurrence that uses this modified document frequency.

Algorithm 1 considers all subsets of repeated terms and, for each of them, extends it into a query plan for q by means of the recur-rence O PT 0 . The algorithm keeps track of the best solution seen and eventually returns it. Its correctness directly follows from the following theorem.

T HEOREM 3. Let P  X  denote an optimal query plan for the phrase query q and F = { t  X  X   X  | | pos ( t , q ) | &gt; 1 } be the set of re-peated terms therein, then c ( F ) + O PT 0 ( | q | )  X  c ( P
The cost of Algorithm 1 depends on the number of repeated terms |R| , which is small in practice and can be bounded in terms of the number of positions in q occupied by a repeated word r = |{ 0  X  i  X | q | | | pos ( q [ i ] , q ) | &gt; 1 }| . For our above example phrase query q =  X  abxayb  X  we obtain r = 4 . Note that | R |  X  2 holds. Algorithm 1 thus has time complexity O (2 and space complexity O ( n 2 ) where | q | = n .
Computing an optimal query plan can be computationally ex-pensive in the worst case, as just shown. It turns out, however, that we can efficiently compute an O (log n ) -approximation, reusing results for S ET C OVER [12].

To this end, we convert an instance of our problem, consisting of a phrase query q and a dictionary D with associated costs, into a S
ET C OVER instance. Let the universe of items U = { 1 , . . . , | q |} correspond to positions in the phrase query. For each term t  X  D , we define a subset S t  X  X  of covered positions as S t = { 1  X  i  X | q | |  X  j  X  pos ( t , q ) : j  X  i &lt; j + | t |} . The collection of subsets of U is then defined as S = { S and we define cost ( S t ) = df ( t , C ) as a cost function. For our concrete problem instance from above, we obtain the instance U = { 1 , . . . , 6 } and S = {{ 1 , 4 } , { 2 , 6 } , { 3 } , { 5 } , { 1 }} .
We can now use the greedy algorithm that selects sets from S based on their benefit-cost ratio, which is known to be a O (log n ) -approximation algorithm [12]. This can be implemented in O ( n time and O ( n 2 ) space where | q | = n .

Note that, as a key difference to the greedy algorithm described in [13], which to the best of our knowledge does not give an ap-proximation guarantee, our greedy algorithm selects subsets (corre-sponding to terms from the dictionary) taking into account the num-ber of additional items covered and the coverage already achieved by selected subsets.
We now describe our experimental evaluation. We begin with the description of the datasets, followed by a comparison of the query-optimization methods from Section 3.
Document Collections. We use two real-world document col-lections: (1) ClueWeb09-B (CW) with more than 50 million En-glish web documents crawled in 2009; and (2) The New York Times Annotated Corpus (NYT) with more than 1.8 million articles pub-lished by The New York Times between 1987 and 2007.

Workloads. To reflect different use cases including web search, entity-oriented search, and plagiarism detection, we consider four different workloads for our experimental evaluation: (1) MSN is a query workload made available for research by a commercial web search engine in 2009. It contains queries routed to the U.S. Microsoft search site and sampled during May 2006. (2) MSNP as the subset of explicit phrase queries from the aforementioned query workload, i.e., queries enclosed in quotes (e.g.,  X  X ational pandemic influenza response plan X  ). (3) YAGO is a work-load of entity labels from the YAGO2 knowledge base [7]. In its rdfs:label relation, it collects strings that may refer to a spe-cific entity, which are mined from anchor texts in Wikipedia. For the entity Bob_Dylan , as a concrete example, it includes among others the entity labels  X  X ob dylan, X   X  X ob allen zimmerman, X  and  X  X obert allen zimmerman. X  (4) NYTS/CWS as workloads con-sisting of 1,000,000 sentences randomly sampled from the NYT and CW document collection, respectively.
 Note that we excluded single-word queries from all workloads. Interestingly, queries are on average shorter in the YAGO work-load (2.45 words) than in the web search query workloads. By de-sign, the NYTS and CWS workloads consist of substantially longer phrase queries. We use document frequency as a cost measure for all our experiments. As mentioned earlier, one could use collection frequency instead. In practice, though, the two measures are highly correlated and we did not observe big differences. Also, as a one-time pre-processing performed using Hadoop and made available to all methods, we compute n -gram statistics for the workload and document collection using the method described in [2].
The experiment examines the effect that the choice of query-optimization method can have on query-processing performance. We consider three query-optimization methods for this experiment: the greedy algorithm (GRD) from [13], our greedy algorithm (APX) that comes with an approximation guarantee, and our exponential exact algorithm (OPT). GRD considers terms in increasing order of their document frequency, thus based on their selectivity, and chooses a term if it covers any yet-uncovered portion of the phrase query. Originally designed to deal with bigrams only, we extend GRD to break ties based on term length, and thus favor the longer term, if two terms have the same document frequency.

To compare the query-optimization methods, we built augmented inverted indexes whose dictionaries include all phrases up to a spe-cific maximum length l  X  X  2 , 3 , 4 , 5 } . Thus, for l = 5 , all phrases of length five or less are indexed. This allows us to study the behav-ior of the methods as more terms to choose from become available.
Table 1 reports average query-processing costs, corresponding to the number of postings read, for all sensible combinations of our document collections and workloads for different choices of l . When studying the behavior of the different query-optimization methods on an augmented inverted index obtained for a specific choice of l , we exclude queries from all workloads that consist of fewer than l words. This is reasonable, since those queries can simply be processed by looking up the corresponding n -gram and there is nothing to optimize.

As we can see from the table, the approximate solutions (GRD and APX) work well, and their costs are close to the ones obtained with the optimal algorithm (OPT). As expected, the performance of APX, our approximation algorithm, is closer to optimal than the performance of the heuristic GRD. This difference is more pro-nounced on the NYTS and CWS workloads consisting, by con-struction, of verbose queries.

Also, as expected, we observe that with increasing l , the number of posting read per query decreases for all query optimizers. The improvements are drastic when considering sentence workloads for all optimizers. For shorter queries there is less room for query opti-mization, as observed in the YAGO and MSNP workloads. For longer queries, in contrast, there is more room for query optimi-zation and thus an opportunity for OPT and APX to make better choices, as observed on the NYTS/CWS workloads consisting of verbose queries. This is even more noticeable for larger choices of l , as can be seen from the results obtained for l = 4 on CWS where OPT processes less than 50% of postings than GRD.

We also observe that a majority of queries does not contain re-peated words. Even otherwise the number of repetitions is typically small. This has a favorable impact on the execution time of OPT. We observe that all query-optimization methods perform similarly in terms of execution time. Our optimization methods are thus ro-bust and achieve superior performance to GRD.
Williams et al. [13] put forward the combined index to support phrase queries efficiently. It assembles three levels of indexing: (i) a first-word index as a positional inverted index, (ii) a next-word index that indexes all bigrams containing a stopword, and (iii) a phrase index with popular phrases from a query log. Its in-memory dictionary is kept compact by exploiting common first words be-tween bigrams. Query processing escalates through these indexes  X  first it consults the phrase index and, if the phrase query is not found therein, processes it using bigrams and unigrams from the other indexes. Transier and Sanders [11] select bigrams to index based only on characteristics of the document collection. Select-ing bigrams makes sense in settings where phrase queries are is-sued by human users and tend to be short  X  as observed for web search by Spink et al. [10]. Variable-length multi-word sequences have previously been considered by Chang and Poon [4] in their common phrase index , which builds on [13], but indexes variable-length phrases common in the workload.
In this work, we studied the problem of phrase-query optimi-zation on augmented inverted indexes. We established its NP -hardness and put forward an exact exponential algorithm as well as an O (log n ) -approximation algorithm to its solution. Our experi-ments on different document collections and workloads established that real-world instances are well-behaved, so that the approximate algorithms almost always get close to the optimum. [1] A. Anand, I. Mele, S. Bedathur, and K. Berberich. Phrase [2] K. Berberich and S. Bedathur. Computing n-Gram Statistics in [3] S. B X ttcher and C. Clarke. Information Retrieval . 2010. [4] M. Chang and C. K. Poon. Efficient phrase querying with [5] P. Ferragina and R. Venturini. The compressed permuterm [6] M. Hagen, M. Potthast, A. Beyer, and B. Stein. Towards [7] J. Hoffart, F. Suchanek, K. Berberich, and G. Weikum. Yago2: [8] U. Manber and E. W. Myers. Suffix arrays: A new method for [9] J. Neraud. Elementariness of a finite set of words is [10] A. Spink, D. Wolfram, B. J. Jansen, and T. Saracevic. [11] F. Transier and P. Sanders. Out of the box phrase indexing. [12] V. V. Vazirani. Approximation algorithms . 2001. [13] H. E. Williams, J. Zobel, and D. Bahle. Fast phrase querying
