 The Drosophila gene expression pattern images document the spatial and temporal dynamics of gene expression and they are valuable tools for explicating the gene functions, interaction, and networks during Drosophila embryogene-sis. To provide text-based pattern searching, the images in the Berkeley Drosophila Genome Project (BDGP) study are annotated with ontology terms manually by human cu-rators. We present a systematic approach for automating this task, because the number of images needing text de-scriptions is now rapidly increasing. We consider both im-proved feature representation and novel learning formulation to boost the annotation performance. For feature represen-tation, we adapt the bag-of-words scheme commonly used in visual recognition problems so that the image group in-formation in the BDGP study is retained. Moreover, im-ages from multiple views can be integrated naturally in this representation. To reduce the quantization error caused by the bag-of-words representation, we propose an improved feature representation scheme based on the sparse learning technique. In the design of learning formulation, we pro-pose a local regularization framework that can incorporate the correlations among terms explicitly. We further show that the resulting optimization problem admits an analyti-cal solution. Experimental results show that the representa-tion based on sparse learning outperforms the bag-of-words representation significantly. Results also show that incorpo-ration of the term-term correlations improves the annotation performance consistently.
 H.2.8 [ Database Management ]: Database Applications -Data Mining Algorithms gene expression pattern, image annotation, bag-of-words, sparse learning, regularization
Gene expression in a developing embryo is modulated in particular cells in a time-specific manner. This leads to the development of an embryo from an initially undifferentiated state to increasingly complex and differentiated form. The patterning of the model organism Drosophila melanogaster along the anterior-posterior and dorsal-ventral axes repre-sents one of the best understood examples of a complex cascade of transcriptional regulation during development. Systematic understanding of the regulatory networks gov-erning the patterning is facilitated by the atlas of patterns of gene expression, which has been produced by the in situ hybridization technique and documented as digital images [24, 10]. Such images capture the spatial and temporal pat-terns of gene expression at the cellular level and provide valuable resources for explicating the gene functions, inter-actions, and networks during Drosophila embryogenesis [12, 4]. To provide text-based pattern searching, the gene ex-pression pattern images in the Berkeley Drosophila Genome Project (BDGP) high-throughput study are annotated with anatomical and developmental ontology terms using a con-trolled vocabulary (CV) [24, 25] (Figure 1). Currently, the annotation is performed manually by human curators. How-ever, the number of available images is now rapidly increas-ing [11, 6, 27, 26]. It is therefore important to design com-putational methods to automate this task [8].

The gene expression pattern annotation problem can be formulated as an image annotation problem, which has been studied in computer vision and machine learning in the case of natural images. Although certain ideas from natural im-age annotation can be employed to solve this problem, sig-nificant challenges remain. Specifically, the gene expression pattern images are currently annotated collectively in small groups based on genes and developmental stages (time) us-ing a variable number of terms in the original BDGP study (Figure 1). Since not all terms assigned to a group of im-ages apply to every image in the group, we need to develop approaches that can retain the original group information of images. It has been shown that the annotation perfor-mance can be adversely affected if such groups are ignored, i.e. , assuming that all terms are associated with all images in a group [8, 7, 13]. Moreover, images in the same group may share certain anatomical and developmental structures, Figure 1: Sample image groups and the associated terms in the BDGP database for the gene engrailed in stage ranges 7-8 (top) and 9-10 (bottom). hence, the terms in the CV are correlated. It is thus desir-able to exploit this correlation information in the annotation process. In addition, the Drosophila embryos are 3D objects, and they are documented as 2D images taken from multiple views. Since certain embryonic structures can only be seen in specific two-dimensional projections (views), it is bene-ficial to integrate images with different views to make the final annotation.

In this paper, we present a systematic approach for an-notating gene expression pattern images. We consider both improved feature representation and novel learning formula-tion to boost the performance of this annotation task. The proposed feature representation scheme is motivated from the bag-of-words scheme commonly used in visual recogni-tion problems. In this approach, features are extracted from local patches on the images, and they are quantized to form the bag-of-words representation based on a pre-computed codebook. In our approach, visual features are extracted from local patches on each image in a group, so that the group information of images is retained as in the BDGP study. To integrate images with multiple views, we pro-pose to construct a separate codebook for images with the same view and represent each image group as multiple bags. One major limitation of the bag-of-words approach is that each feature vector is only quantized to the closest code-book word, resulting in quanti zation errors. To overcome this limitation, we propose to encode each feature vector using multiple codebook words simultaneously. Specifically, we propose to determine the number of codebook words and their weights used to represent each feature vector automat-ically using the sparse learning framework.

In the design of learning schemes for the annotation task, we consider formulations that can incorporate the correla-tions among terms explicitly. Since not all terms are cor-related and the degrees of correlation for different pairs of terms vary, we propose a regularization framework that im-poses local constraints on the models so that only models for correlated terms are const rained to be similar. We fur-ther show that the resulting optimization problem admits an analytical solution. Experimental results on the images from the FlyExpress database (www.flyexpress.net) show that the representation based on sparse learning outper-forms the bag-of-words representation significantly. Results also show that incorporation of the term-term correlations improves the annotation performance consistently.
The images in the FlyExpress database [10] have been standardized semi-automatically, including alignment. We propose to use local features extracted from local patches on the images for the annotation task, since such features are more robust than global features [16]. The methods for localizing patches on images can be categorized into three classes including affine-region-detector-based methods [17], sampling-based methods [19], and regular-patch-based methods [3]. We extract dense features on regular patches on the images, since such features are commonly used for aligned images. Due to the limitations of the image pro-cessing techniques, local variations may exist on the images. Thus, we extract invariant fea tures from each regular patch. In this paper, we apply the SIFT descriptor [14] to extract local visual features, since it has been applied successfully to other image-related applications [16]. Specifically, each fea-ture vector is computed as a set of orientation histograms on 4  X  4 pixel neighborhoods, and each histogram contains 8 bins. This leads to a SIFT feature vector with 128 (4  X  4 dimensions on each patch. Note that although the invari-ance to scale and orientation no longer exists since we do not apply the SIFT interest point detector, the SIFT descriptor is still robust against the variance of position, illumination and viewpoint.
The images in the BDGP high-throughput study are an-notated collectively in small groups based on the genes and the developmental stages. We propose to encode each image group as a feature vector based on the bag-of-words and the sparse coding representations. Both of these two schemes are based on a pre-computed codebook, which consists of representative local visual features computed on the images. The codebook is usually obtained by applying a clustering algorithm on a subset of the local features, and the cluster centers are then used as the visual words of the codebook.
The 3D nature of the embryos and the 2D layout of the im-ages determine that certain body parts can only be captured by images taken from certain views. We propose to con-struct a separate codebook for images with the same view. In particular, we consider images taken from the lateral and the dorsal views, since the number of images from other views is small. For each stage range, we build a separate codebook for images with each view. Since the visual words of the codebooks are expected to represent the embryonic structures, the images used to build the codebooks should contain all the embryonic structures that the system is ex-pected to annotate. Hence, we extract codebook images in a way so that each embryonic structure appears in at least 10 and 5 images for lateral and dorsal views, respectively, basedonthetotalnumberofimageswitheachview. The SIFT features computed from regular patches on the code-book images are then clustered using the k -means algorithm. Since this algorithm depends on the initial centers, we repeat the algorithm with ten random initializations from which the one resulting in the smallest summed within-cluster distance is selected. The number of clusters (i.e., the codebook size) is set to 2000 and 1000 for lateral and dorsal images in the experiments, respectively.
The proposed image group representation scheme is mo-tivated from the bag-of-words approach commonly used in image and video analysis problems [21, 18]. In this approach, invariant features are extracted from local patches on images or videos, and each feature in a test image or video is then quantized based on a pre-computed codebook. Hence, an entire image or video is represented as a global histogram counting the number of occurrences of each word in the code-book. To integrate images taken from multiple views of the 3D embryos, we propose to extract local visual features from each image in a group and represent the images in the same group with the same view as a bag of visual words. Groups that contain images with multiple views can thus be repre-sented as multiple bags of visual words, one for each view. The bags for multiple views can then be concatenated to annotate the image groups collectively. One limitation of the bag-of-words approach is that features are only quan-tized to the closest visual words, which may cause quanti-zation errors. We thus propose to enhance the bag-of-words approach using sparse coding techniques. Experiments in Section 5 show that such technique improves the annotation performance consistently.
After the codebooks for both views are constructed, the images in each group are quantized separately for each view. In particular, features computed on regular patches on im-ages with a certain view are compared with the visual words in the corresponding codebook, and the word closest to the feature in terms of Euclidean distance is used to represent it. Then the entire image group is represented as multiple bags of words, one for each view. Since the order of the words in the bag is irrelevant as long as it is fixed, the bag can be represented as a vector counting the number of occurrences of each word in the image group.

Let a 1 ,  X  X  X  ,a d  X  R r be the d cluster centers (codebook words) and let u 1 ,  X  X  X  ,u s  X  R r be the s features extracted from images in a group with the same view, where r is the di-mensionality of the local features ( r = 128 for SIFT). Then the bag-of-words vector x is d -dimensional, and the i -th com-ponent x i of x is computed as where  X  ( a, b )=1if a = b , and 0 otherwise, and || X || denotes the vector 2-norm. Note that m i =1 x i = s, since each feature is assigned to exactly one word.

Based on this construction, the vector representation for each view can be concatenated so that the images in a group with different views are integrated. Let x l and x d be the bag-of-words vector for images in a group with lateral and dorsal views, respectively. Then the bag-of-words vector x for the entire image group can be represented as The length of the final vector representing an image group is 3000 (2000+1000) in our implementation. To account for the variability in the number of images in each group, we normalize the bag-of-words vector to unit length.
One major limitation of the bag-of-words approach is that the representation is obtained by the hard assignment ap-proach in which a local feature vector is only assigned to its closest visual word. It could be the case that a feature vector is very close to multiple words in the codebook, and it is thus desirable to represent this feature vector using all of them. Indeed, a recent study has shown [20] that the soft assignment approach that assigns each feature vector to multiple visual words based on their distances usually results in improved performance. However, there is no principled way to determine the number of visual words to which a feature vector should be assigned. In the following, we pro-pose to address this issue by relying on the sparse learning framework.

Let A =[ a 1 ,  X  X  X  ,a d ]  X  R r  X  d denote the codebook matrix in which { a i } d i =1 are the visual words. Given a feature vec-tor u , the traditional bag-of-words approach assigns u to the closest visual words and represents u as a d -dimensional vec-tor x in which the entry corresponding to the closest visual word is one, and all other entries are zero. This reduces to computing x by solving the following optimization problem: subject to the constraint that only one entry in x is one, and all other entries are zero. A natural extension of this hard assignment approach is to remove the constraint on x . This, however, may yield x that is not sparse at all, i.e. ,the local feature u is mapped to a large number of visual words simultaneously.

To achieve a compromise between these two extreme cases, we propose to compute x by solving the following optimiza-tion problem: where  X &gt; 0 is a tunable parameter and || x || 1 = d i =1 denotes the vector 1-norm. The problem in Eq. (2) is the -regularized regression problem called  X  X asso X  [22] with the additional nonnegativity constrain. It is well-known the so-lution to this problem is sparse in the sense that many en-tries in x will be set to zero. Recently, many algorithms for solving the lasso problem have been proposed such as the coordinate descent algorithm [5].
Given the bag-of-words and the sparse coding represen-tations of image groups, we develop a framework for anno-tating the gene expression pattern images in this section. The proposed framework can inc orporate the correlations among different terms by constraining the models for corre-lated terms to be similar. We further derive an analytical solution to the resulting problem.
Let X =[ x T 1 ,  X  X  X  ,x T n ]  X  R n  X  d be the data matrix derived from the bag-of-words or the sparse coding representations, where x i  X  R d is the representation for the i th image group (sample), and let Y  X  R n  X  k be the label indicator matrix Figure 2: The Pearson X  X  correlation coefficients com-puted on the columns of the label indicator matrix using two data sets from stage ranges 11-12 (left fig-ure) and 13-16 (right figure) with 50 and 60 terms, respectively. defined as
Y ij = 1ifthe i -th sample has the j th label  X  1otherwise , where n is the number of training samples, d is the data dimensionality, and k is the number of terms. Given a pre-scribed loss function (  X  ,  X  ), we propose to build k models { f i } k i =1 by minimizing the following regularized empirical risk function: where f { f i } k i =1 , X (  X  ) is some regularization functional, and  X &gt; 0 is the regularization parameter. Many multi-task learning formulations constrain the multiple models by employing different forms of regularization on f [2, 1].
We build a model for each term in the one-against-rest manner. Since certain groups of terms from the CV are highly correlated, it is desirable to constrain the models for correlated terms to be similar. In this paper, we use the Pearson X  X  correlation coefficient computed on columns of the label indicator matrix Y as our measure of term correlation. Figure 2 shows the Pearson X  X  correlation coefficients com-puted on two data sets from stage ranges 11-12 and 13-16 with 50 and 60 terms, respectively. It can be observed that a significant number of terms show different degrees of correla-tion. To visualize the correlation graph, we show in Figure 3 one of the connected components in the correlation graph in stage range 13-16 after removing correlations below 0.3. We can observe that all terms in this graph are related to the sensory system. Based on these observations, we propose a particular form of regularization that can constrain the models for correlated terms to be similar.

In the following, we consider linear models: which is parameterized by the weight vector w i  X  R d and the bias b i  X  R .Let C  X  R k  X  k be the term-term correlation matrix in which C pq measures the correlation between the p th and the q th term. Note that the proposed formulation is independent of the methods used to measure the corre-lations among terms, and any other methods can be used for this purpose. Since terms can be positively or negatively related, the entries in C can be either positive or negative. Figure 3: The term-term interaction graph com-puted using the Pearson X  X  correlation coefficient for terms in stage range 13-16. The vertices represent terms and edges represented the correlations be-tween terms. The graph shown in this figure is one of the connected components after the correlation coefficients are thresholded at 0.3.
 To capture the correlations among terms encoded into C , we propose to solve the following optimization problem: where W =[ w 1 ,  X  X  X  ,w k ]  X  R d  X  k , G denotes the index set with the magnitudes of the corresponding entries in C above a pre-specified threshold  X  , i.e., G = { ( p, q ): | C pq || X || two regularization parameters, and g ( C pq )istheweightfor the regularization on terms p and q . In this paper, we set g ( C pq )= C 2 pq . In this model, the weight vectors for mod-els corresponding to correlated terms are constrained to be similar, weighted by the strength of the correlation. More-over, negatively-related terms are also taken into account by considering the sign of the correlation coefficient.
In the following, we consider the least squares loss for the formulation in Eq. (5). This leads to the following optimization problem: Note that we have assumed that both X and Y are centered in terms of rows, and thus the bias term can be ignored. We show in the following that the optimal W admits an analytical solution, which only involves the singular value decomposition (SVD) and matrix and vector operations.
Note that C 2 pq  X || w p  X  sign( C pq ) w q || 2 = ||| C pq To reformulate the problem in Eq. (6) into a compact ma-trix form, we need to introduce an additional variable. For the m th constraint in G , which encodes the correlation be-tween the p th and the q th terms, define h m  X  R k as a vector whose p th and q th entries are nonzero, and all other entries are zero as: h m =(  X  X  X  , 0 ,  X  X  X  , | C pq | Based on this definition, it is easy to verify that the problem in Eq. (6) can be expressed equivalently as: where H =( h 1 ,  X  X  X  ,h g )  X  R k  X  g and g = | G | is the size of the set G .
We show that the problem in Eq. (8) admits an analytical solution. Taking the derivative of the objective function in Eq. (8) with respect to W and setting it to zero, we obtain that Let X = U 1  X  1 V T 1 and H = U 2  X  2 V T 2 be the SVD of X and H , respectively, where U 1  X  R n  X  n , V 1  X  R d  X  d  X  2  X  R k  X  g are diagonal. Then the equality in Eq. (9) can be expressed as Multiplying V T 1 and U 2 from the left and right, respectively, on both sides of Eq. (10), we obtain that Denote Then Eq. (11) can be expressed as Note that  X   X  1 is positive definite, and hence  X  ( i ) 1 i . It follows that  X  W can be obtained as After  X  W is computed, the original weight matrix W can be recovered as W = V 1  X  WU T 2 . This leads to the main algorithm in Algorithm 1 for computing the optimal W .
 Algorithm 1 The main algorithm Input: X , Y , H ,  X  1 ,and  X  2 Output: W 1. Compute SVD as X = U 1  X  1 V T 1 and H = U 2  X  2 V T 2 2.  X   X  1 = X  T 1  X  1 +  X  1 I = diag(  X  (1) 1 ,  X  X  X  , X  ( d 3.  X   X  2 =  X  2  X  2  X  T 2 = diag(  X  (1) 2 ,  X  X  X  , X  ( k ) 2 4. D = V T 1 X T YU 2 6. W = V 1  X  WU T 2 In Algorithm 1, the dominant computational cost is the SVD X  X  of X and H . The two regularization parameters  X  1 and  X  2 can be tuned using double cross-validation. Note that for different values of  X  1 and  X  2 , the SVD X  X  of X and H need to be computed only once. Thus, the overall procedure for parameter tuning is efficient.
The proposed formulation is related to the fused lasso [23], which encourages the sparsity of the difference between co-efficients in single-response regression problems. In partic-ular, the sum of the absolute values of differences between consecutive coefficients are regularized in fused lasso. Moti-vated by fused lasso, the graph-guided fused lasso (GFlasso) was proposed in [9] to constrain the weight vectors of cor-related tasks in multiple-response regression problems. A key difference between our formulation and those based on fused lasso is that we regularize the two norm of the dif-ferences between the weight vectors for related tasks, while those based on the fused lasso use the one norm regular-ization. This leads to different procedures for solving the resulting problem. In particular, it has been shown [9] that the GFlasso formulation involves a quadratic programming problem, which is computationally expensive for problems such as the annotation of gene expression patterns. In con-trast, our formulation results in an analytical solution, and the parameter tuning is efficient, since the computationally dominant part needs to be performed only once for different values of the regularization parameters.
In this section, we report and analyze the annotation re-sults obtained by applying the proposed approach to images in the FlyExpress database (http://www.flyexpress.net/).
The size of images in the FlyExpress database is stan-dardized to 128  X  320 pixels, and the radius and spacing of the regular patches to extract local features are set to 16 pixels in the experiments. The non-negative lasso prob-lem in Eq. (2) is solved by adapting the coordinate descent algorithm [5] to incorporate the non-negativity constraint. The continuous process of Drosophila embryogenesis is di-vided into 16 stages, which are then grouped into 6 stage ranges (1-3, 4-6, 7-8, 9-10, 11-12, and 13-16) [24, 25]. Since most of the CV terms are stage-range specific, we anno-tate the image groups according to their stage ranges sep-arately. The first stage range contains only 2 terms, and we do not report the performance in this stage range. For other stage ranges, we begin with the 10 terms that appear in the largest number of image groups, and then we add ad-ditional terms in the order of their frequencies with a step size of 10. This results in different numbers of data sets in each stage range, depending on the number of CV terms in that stage range. The extracted data sets are randomly partitioned into training and test sets using the ratio 1:1 for each term. For each data set, we randomly generate 30 training/test partitions, and the average performance is re-ported. WeusetheAUCandF1scoreastheperformance measures. To assess the performance across multiple terms, we report both the macro-averaged and the micro-averaged F1 scores. The threshold value  X  for the correlation coeffi-cient is tuned empirically, and it is fixed to 0.3 in the exper-representation. PMK star ,PMK clique ,andPMK kcca denote the three methods based on pyramid match 0.68 77.67  X  0.82 76.97  X  0.91 77.47  X  0.80 0.52 77.44  X  0.75 76.84  X  0.71 77.46  X  0.72 1.47 74.18  X  0.86 73.40  X  0.90 74.71  X  0.84 0.91 71.78  X  0.97 72.41  X  0.84 72.27  X  0.78 2.56 69.28  X  1.17 69.01  X  1.22 69.79  X  1.18 0.74 71.90  X  0.80 72.38  X  0.79 72.28  X  0.72 1.03 72.10  X  0.94 71.61  X  1.18 72.75  X  0.99 0.48 78.55  X  0.63 78.54  X  0.57 78.64  X  0.57 0.31 76.62  X  0.68 76.39  X  0.68 76.97  X  0.67 0.55 71.94  X  0.60 71.36  X  0.51 72.90  X  0.63 0.63 71.16  X  0.65 70.28  X  0.68 72.12  X  0.64 0.77 69.64  X  0.86 68.24  X  0.64 70.73  X  0.83 0.35 82.22  X  0.42 82.58  X  0.64 81.87  X  0.76 0.36 76.74  X  0.33 77.36  X  0.54 77.03  X  0.52 0.38 73.80  X  0.48 74.07  X  0.53 74.05  X  0.68 0.38 71.02  X  0.56 71.19  X  0.50 71.49  X  0.45 0.51 68.74  X  0.51 68.92  X  0.57 69.15  X  0.73 0.60 67.33  X  0.57 67.34  X  0.63 68.24  X  0.48 iments. The regulari zation parameters  X  1 and  X  2 are tuned using double cross-validation. Note that for different values of  X  1 and  X  2 , the SVD of X and H need to be computed only once. The code for the proposed formulation is available at http://www.public.asu.edu/~sji03/annotation/ .
We assess the performance of the proposed local regu-larization formulation on 18 data sets from 5 stage ranges. We evaluate the effectiveness of the bag-of-words and the sparse feature representations in the following subsection, which shows that the sparse feature representation yields significantly higher performance in all cases. Hence, we use the sparse feature representation in this experiment. To demonstrate the effectiveness of this formulation, we report the results obtained by applying linear support vector ma-chines (SVM) separately for each term in the one-against-rest manner. To compare the performance achieved by the proposed formulation based on the sparse feature representa-tion with existing approaches, we report the performance of the methods in [8] based on pyramid match kernels (PMK). All three formulations proposed in [8], denoted as PMK star PMK clique and PMK kcca are reported. All the model pa-rameters are tuned using cross-validation. The performance in terms of AUC, macro F1 and micro F1 for the five meth-odsisreportedinTables1,2and3,respectively.

We can observe from the results that among the five meth-ods, LR soft outperforms the other four methods in all cases. In particular, LR soft outperforms SVM soft significantly in al-most all cases. Since both of these methods are based on the sparse feature representation, this shows that the proposed local regularization formulation is effective in exploiting the correlations among terms. Both LR soft and SVM soft out-perform the three methods based on pyramid match kernels. This demonstrates that the sparse feature representation is more effective than the pyramid match kernel method.
To assess the relative performance of LR soft and SVM soft on individual terms, we show the differences of AUC achieved by these two methods for each term on two data sets from stage ranges 11-12 and 13-16 in Figure 4. In these two fig-ures, the reported performance is the average values over 30 random trials, and positive bar values show that LR soft outperforms SVM soft , while negative bar values show that SVM soft outperforms LR soft . We can observe that among the 100 terms reported, LR soft outperforms SVM soft on 99 terms except for the term procephalon primordium .Ade-tailed analysis on this term shows that this term is not re-lated to any other terms after the correlations are thresh-olded. Thus, no local regularization is imposed on this term.
We compare the performance obtained by the bag-of-words and the sparse learning representations on three data sets from stage range 4-6 with 10, 20 and 30 terms, respectively. For each data set, we report the performance of the local reg-ularization formulation based on the bag-of-words (LR hard and the sparse learning (LR soft ) representations in Table 4. We can observe that the propose d sparse feature represen-tation outperforms the bag-of-words scheme significantly on all three data sets. We observe a similar trend in other data sets. This shows that the soft assignment approach based on the sparse learning formulation can potentially reduce the quantization error of the bag-of-words scheme.
To assess the effectiveness of the local regularization in constraining the models for correlated terms, we visualize the weight matrices on a data set in stage range 13-16 with 60 terms as the regula rization parameter  X  2 increases grad-ually in Figure 5. When  X  2 = 0, the models for different terms are decoupled, and thus no regularity is observed in the weight matrix. As  X  2 increases, the weight vectors for of Table 1 for explanations.
 1.13 33.68  X  1.41 38.94  X  1.57 30.23  X  1.55 1.23 22.76  X  0.84 24.79  X  1.37 22.79  X  1.34 1.27 17.80  X  1.02 17.05  X  1.13 16.92  X  1.23 1.55 40.43  X  1.24 42.15  X  1.33 32.94  X  1.32 1.24 22.83  X  1.04 23.13  X  0.93 19.91  X  1.16 1.41 42.00  X  1.06 41.84  X  0.96 33.96  X  0.98 1.43 25.57  X  0.97 24.38  X  0.97 21.79  X  1.11 0.91 47.93  X  0.87 50.21  X  1.27 35.85  X  0.88 0.88 28.97  X  0.84 31.92  X  1.29 22.42  X  0.98 0.82 19.69  X  0.61 22.12  X  0.89 16.34  X  0.47 0.85 15.15  X  0.55 16.73  X  0.69 12.48  X  0.51 0.94 12.27  X  0.42 13.52  X  0.65 10.49  X  0.47 0.81 55.03  X  0.94 55.34  X  1.09 38.84  X  0.86 0.87 34.42  X  1.00 34.20  X  0.82 24.94  X  1.29 0.78 25.92  X  0.75 25.73  X  0.90 19.53  X  0.92 0.80 19.84  X  0.42 19.38  X  0.73 14.85  X  0.76 0.64 16.35  X  0.46 15.55  X  0.61 12.85  X  0.61 0.76 14.05  X  0.41 13.20  X  0.46 11.44  X  0.49 of Table 1 for explanations.
 1.07 44.06  X  1.20 45.21  X  1.18 36.57  X  1.36 1.10 37.31  X  0.91 36.06  X  1.12 30.43  X  1.16 4.02 36.14  X  1.27 34.20  X  1.18 32.77  X  1.41 1.44 52.42  X  1.11 52.84  X  1.13 48.66  X  1.06 6.09 49.04  X  1.07 48.73  X  1.05 46.66  X  1.05 1.26 54.21  X  0.74 54.72  X  0.79 51.33  X  0.89 2.51 49.68  X  0.82 49.00  X  1.15 47.39  X  1.00 1.00 60.95  X  0.58 60.73  X  0.80 55.21  X  0.97 0.94 51.72  X  0.69 51.68  X  0.87 46.05  X  0.78 1.73 47.49  X  0.72 46.58  X  0.66 43.30  X  0.79 2.24 45.90  X  0.75 45.24  X  0.78 42.26  X  0.90 2.98 45.17  X  0.58 44.70  X  0.68 43.55  X  0.93 0.68 61.12  X  0.71 61.21  X  0.89 52.38  X  0.72 0.89 48.31  X  0.57 48.56  X  0.60 41.04  X  0.69 0.94 43.87  X  0.64 43.17  X  0.62 36.55  X  0.67 0.89 40.89  X  0.73 40.09  X  0.86 33.86  X  0.80 2.31 39.54  X  0.61 38.65  X  0.65 33.63  X  0.96 2.67 38.55  X  0.69 37.57  X  0.67 34.57  X  1.05 correlated models are increasingly constrained to be similar. This can be observed from the increasingly similar patterns in certain columns of the weight matrix. This demonstrates that the local regularization formulation is effective in con-straining the models for correlated terms to be similar.
In this paper, we propose a systematic approach for an-notating Drosophila gene expression pattern images. For the feature representation, we propose to reduce the quanti-zation error associated with the bag-of-words scheme using the sparse learning technique. Based on this improved fea-ture representation, we propose a classification formulation using a local regularization, which accounts for the correla-tions among different CV terms. We further show that the resulting regularized formulation admits an analytical solu-tion. The effectiveness of the feature representation and the local regularization formulation is evaluated using images from the FlyExpress database.

The codebooks used in this paper are constructed by un-supervised methods. Recent studies have shown [18, 15] that incorporation of the label information in constructing the codebook usually results i n improved performance. We will explore the supervised codebook construction in the fu-ture. In the current work, we only consider the least squares loss in the local regularization formulation. We will explore other loss functions, such as the hinge loss, in the future. LR soft outperforms SVM soft , while negative bar values show that SVM Table 4: Comparison of the performance achieved by the proposed formulation based on the bag-of-words (LR hard ) and the sparse learning feature represen-tations (LR soft ) on three data sets from the stage range 4-6 with 10, 20, and 30 terms. The reported performance is the average value obtained from 30 random trials.
 10 81.06 82.86 47.61 50.93 50.71 52.87 20 82.54 84.20 40.02 43.21 44.42 47.11 30 79.99 81.63 30.07 32.63 42.13 44.63 We thank Ms. Kristi Garboushian for editorial support. This work is supported in part by the National Institutes of Health grant No. HG002516, the N ational Sci ence Founda-tion grant No. IIS-0612069, the N ational Sci ence Founda-tion of China grant Nos. 60635030 and 60721002, and the Jiangsu Science Founda tion grant No. BK2008018. [1] A. Argyriou, T. Evgeniou, and M. Pontil. Convex [2] T. Evgeniou and M. Pontil. Regularized multi-task [3] L. Fei-Fei and P. Perona. A Bayesian hierarchical [4] C. C. Fowlkes and et al. A quantitative spatiotemporal [5] J. Friedman, T. Hastie, H. H  X  ofling, and R. Tibshirani. [6] R. Gurunathan and et al. Identifying spatially similar of size. [7] S. Ji, Y.-X. Li, Z.-H. Zhou, S. Kumar, and J. Ye. A [8] S. Ji, L. Sun, R. Jin, S. Kumar, and J. Ye. Automated [9] S. Kim, K.-A. Sohn, and E. P. Xing. A multivariate [10] S. Kumar and FlyExpress Consortium. A [11] S. Kumar and et al. BEST: a novel computational [12] E. L  X  ecuyer and et al. Global analysis of mRNA [13] Y.-X. Li, S. Ji, S. Kumar, J. Ye, and Z.-H. Zhou. [14] D. G. Lowe. Distinctive image features from [15] J. Mairal, F. Bach, J. Ponce, G. Sapiro, and [16] K. Mikolajczyk and C. Schmid. A performance [17] K. Mikolajczyk, T. Tuytelaars, C. Schmid, [18] F. Moosmann, E. Nowak, and F. Jurie. Randomized [19] E. Nowak, F. Jurie, and B. Triggs. Sampling strategies [20] J. Philbin, O. Chum, M. Isard, J. Sivic, and [21] J. Sivic and A. Zisserman. Efficient visual search for [22] R. Tibshirani. Regression shrinkage and selection via [23] R. Tibshirani, M. Saunders, S. Rosset, J. Zhu, and [24] P. Tomancak and et al. Systematic determination of [25] P. Tomancak and et al. Global analysis of patterns of [26] J. Ye, J. Chen, R. Janardan, and S. Kumar.
 [27] J. Ye, J. Chen, Q. Li, and S. Kumar. Classification of
