 S  X oren Laue soeren.laue@uni-jena.de Friedrich-Schiller-University Jena, Germany We consider the following unconstrained semidefinite optimization problem: where f ( X ) : R n  X  n  X  R is a convex and differentiable function over the cone of positive semidefinite matri-ces. Many machine learning problems can be cast as a semidefinite optimization problem. Prominent exam-ples include sparse PCA (d X  X spremont et al., 2007), distance metric learning (Xing et al., 2002), nonlin-ear dimensionality reduction (Weinberger et al., 2006), multiple kernel learning (Lanckriet et al., 2004), mul-titask learning (Obozinski et al., 2010), and matrix completion (Srebro et al., 2004).
 We provide an algorithm that solves general large-scale unconstrained semidefinite optimization problems ef-ficiently. The idea to our algorithm is a hybrid ap-proach: we combine the algorithm of Hazan (2008) with a standard quasi-Newton algorithm. The algo-rithm achieves convergence to the global optimum with very good running time. It can be readily used for a variety of machine learning problems and we demon-strate its efficiency on three different tasks: matrix completion, metric learning, and sparse PCA. Another advantage of the algorithm is its simplicity, as it can be implemented in less than 30 lines of Matlab code. 1.1. Related Work A constrained version of Problem 1 is called a semidef-inite program (SDP) if function f as well as the con-straints are linear. Semidefinite programs have gained a lot of attention in recent years, since many NP-hard problems can be relaxed into SDPs and many machine learning problems can be modeled as SDPs.
 The most widely known implementations of SDP solvers are interior point methods. They provide high-accuracy solutions in polynomial time. However, since the running time is a low-order polynomial in the di-mension n they do not scale well to medium and large problems that often occur in machine learning. On the other hand, the high accuracy of their solutions is typically not needed as the input data is often noisy. Among other methods, proximal methods have been employed to solve SDPs in order to circumvent the large running time of interior point methods. They achieve better running times at the expense of less ac-curate solutions. Examples include (Nesterov, 2007; Nemirovski, 2004) and (Arora et al., 2005) where the multiplicative weights update rule is employed. The algorithm of (Arora et al., 2005) has been random-ized by (Garber &amp; Hazan, 2011) based on the same idea as in (Grigoriadis &amp; Khachiyan, 1995) to achieve sublinear running time. Another randomized algo-rithm has appeared in (Kleiner et al., 2010). Further-more, alternating direction methods have been pro-posed to solve SDPs (Wen et al., 2010).
 Another line of algorithms for solving SDPs are Frank-Wolfe type algorithms such as (Hazan, 2008). This ap-proach is also known as sparse greedy approximation and these algorithms have the advantage that they produce sparse solutions (Clarkson, 2008) which, for SDPs, corresponds to low-rank solutions. Low-rank solutions are very appealing since they can drastically reduce the computational effort. Instead of storing a low-rank positive semidefinite matrix X  X  R n  X  n one just stores a matrix V  X  R n  X  k where X = V V T , with k being the rank of X . Matrix-vector multiplications, for instance, can be done in O ( nk ) instead of O ( n 2 ). There have also been nonlinear approaches to linear SDPs, however, without general convergence guaran-tees (Burer &amp; Monteiro, 2003). In some special cases (matrix completion problems where it is assumed that the data is indeed generated by a low rank matrix and the restricted isometry property holds) convergence guarantees have been shown. In general, the prob-lem of solving an SDP with a low-rank constraint is NP-hard (Goemans &amp; Williamson, 1995).
 Organization of the Paper Section 2 describes our algorithm while in Section 3 we provide experimen-tal results on three different machine learning prob-lems. We compare our algorithm against a standard interior point method and against algorithms that are specifically designed for each of the individual prob-lems. Section 4 provides theoretical guarantees for the running time and for the convergence to the global optimal solution. Our algorithm is summarized in pseudo-code in Algo-rithm 1.
 Algorithm 1 Hybrid Algorithm Input: Smooth, convex function f : R n  X  n  X  R Output: Approximate solution of Problem 1
Initialize X 0 = 0, V 0 = 0 repeat until Approximation guarantee has been reached The notation [ V i ,v i ] used in Algorithm 1 stands for the horizontal concatenation of matrix V i and col-umn vector v i . The function ApproxEV returns an approximate eigenvector to the largest eigenvalue: given a square matrix M it returns a vector v i = ApproxEV( M,  X   X  ) of unit length that satisfies v T i Mv  X  max ( M )  X   X   X  , where  X  max ( M ) denotes the largest eigenvector of matrix M .
 Our algorithm runs in iterations. Each iteration con-sists of two steps: a rank-1 update and a subse-quent nonlinear improvement of the current solution. The rank-1 update step follows a Frank-Wolfe type approach. A linear approximation to function f at the current iterate X i is minimized over the cone of semidefinite matrices. The minimum is attained at v v T i where v i =  X  max (  X  X  X  f ( X i )) is the vector to the largest eigenvalue of  X  X  X  f ( X i ). Then the next iter-ate X i +1 is a linear combination of the current iterate X i = V i V T i and v i v T i such that it minimizes f . In the second step, the nonlinear update step, the cur-rent solution X i +1 = V i +1 V T i +1 is further improved by minimizing function f ( V V T ) with respect to V . Note that this function is no longer convex with respect to V . Hence, we can only expect to find a local minimum. Our analysis however shows, that this is sufficient to still converge to the global optimal solution of Prob-lem 1. In fact, it is even not necessary to find a local minimum, any improvement will work.
 In Section 4 we will prove that after at most O ( many iterations Algorithm 1 will return a solution that is  X  -close to the global optimal solution. We have implemented our hybrid algorithm in Matlab exactly as described in Algorithm 1. For the nonlin-ear update we use minFunc (Schmidt) which imple-ments the limited memory BFGS algorithm. The two-variable optimization problem in the rank-1 update is also solved using minFunc . We use the default settings of minFunc . The approximate eigenvector computa-tion is done using the Matlab function eigs . We ran all experiments in single-thread mode on a 2.50GHz CPU. 3.1. Matrix Completion In this section we consider the matrix completion prob-lem used for collaborative filtering. Given a matrix Y where only a few entries have been observed the goal is to complete this matrix by finding a low-complexity matrix X which approximates the given entries of Y as good as possible. Low complexity can be achieved for instance by a low rank or by small trace norm. Also different error norms can be considered depending on the specific application. For instance, the l1-norm in combination with the trace-norm regularization leads to the robust PCA approach for matrix completion with low rank (Cand`es et al., 2011). Here, we use the l2-norm and the rank constraint as a measure of complexity. Hence, the matrix completion problem becomes the following optimization problem: where  X  is the set of all given entries of Y . Note that Problem (2) is NP-hard (Gillis &amp; Glineur, 2011). However, we can still attempt to find a good solution to it by using our hybrid algorithm. Problem (2) can be transformed into the following equivalent semidefinite optimization problem: where and  X  X is a positive semidefinite matrix. V and W are suitable symmetric matrices. Hence, the matrix completion Problem (2) for an input matrix Y  X  R m  X  n can be cast into a semidefinite optimization problem We compare our algorithm to a state-of-the-art solver GECO (Shalev-Shwartz et al., 2011) which was specifi-cally designed for solving large-scale matrix minimiza-tion problems with a low-rank constraint. We fol-low the experimental setting of (Shalev-Shwartz et al., 2011). We use three standard matrix completion datasets: MovieLens100k, MovieLens1M, and Movie-Lens10M. The dimensions of the three datasets are 943  X  1682, 6040  X  3706, and 69878  X  10677 respec-tively and they contain 10 5 , 10 6 , and 10 7 movie ratings from 1 to 5. The task is to predict a movie rating for user i and movie j . We used the datasets without any normalization 1 and split them randomly such that for each user 80% of the ratings went into training data and 20% into test data.
 Our algorithm minimizes the training error much faster than GECO and at the same time also needs a much smaller rank. As a result we also achieve an optimal test error much faster and with a smaller rank than GECO. Table 1 reports the test root-mean-square error (RMSE) as well as the rank where it was achieved and the running times. Both rows for GECO in Ta-ble 1 reflect the same runs. The first row shows the statistics where the test error reaches the minimum. However, since GECO slows down a lot with the rank we also added intermediate results when the test error is approaching the minimum. As it can be observed our algorithm achieves the same or better test error by requiring only a fraction of the time needed by GECO. Both algorithms need quasi-linear time in the number of ratings and hence can be used to solve large scale matrix factorization problems. Note however, that for our algorithm the runtime per iteration scales linearly with the rank k whereas GECO needs O ( k 6 ). This behavior slows down GECO considerably, which can be seen in Figure 1. 3.2. Metric Learning The second problem we approach is the metric learning problem. We are given a labeled dataset X = ( x i ,y i ) Let S be a set containing all pairs of indices ( i,j ) whose data points x i and x j are similar to each other, i.e. its labels y i and y j are equal; let the set  X  S con-tain all indices of data points that are dissimilar to each other. For a given semidefinite matrix A , the Mahalanobis distance between x i and x j is defined as d ( i,j ) = p ( x i  X  x j ) T A ( x i  X  x j ). The metric learn-ing problem is that of finding a positive semidefinite matrix A , such that under the induced Mahalanobis distance, points that are similar are close to each other and points that are dissimilar are far apart. This prob-lem can be cast as a semidefinite optimization prob-lem(Xing et al., 2002): Note that the 1 in the inequality constraint in Prob-lem (4) can be changed to any arbitrary positive con-stant. This constraint is just to ensure that not all points are mapped onto the same point. Prob-lem (4) does not fit into our framework. However, we can transform it into the following equivalent un-constrained semidefinite problem: Problem (5) is just the Lagrangian of Problem (4). Since the 1 in the inequality constrained was chosen arbitrary we can also choose any positive constant for  X  . In our experiments we set it to 1.
 We follow the experimental setting of (Kleiner et al., 2010). We compared our approach against an interior point method implemented in SeDuMi (Sturm, 1999) (via CVX (Grant &amp; Boyd, 2011)) and the algorithm of (Xing et al., 2002) which is a projected gradient ap-proach and was specifically designed to solve the above SDP. We could not directly compare our algorithm to that of (Kleiner et al., 2010) as the code was not available. However, the authors show that it performs similarly to (Xing et al., 2002).
 As a measure of quality for a given solution A we de-fine:
Q ( A ) = where 1[ . ] is the indicator function and  X  = P essence Q captures how many points with the same la-bel are mapped closer to each other than points with different labels.
 We initially apply metric learning to the UCI iono-sphere dataset which contains 351 labeled data points in dimension 34. The results of this experiment are shown in Figure 2. As it can be seen, our hybrid al-gorithm achieves the optimal value almost instantly. The projected gradient descent algorithm (PG) needs about 20 times as long to achieve a solution of com-parable quality. Since the interior point method (IP) scales very badly with the number of data points, we only ran it on a sub-sample of size 4*34=136. On this dataset, our method achieves the same function value as IP: 5.47e-05, while requiring only 0.28 seconds as opposed to 1513 seconds that IP needs. PG achieves a function value of 5.50e-05 in 88 seconds. Following (Kleiner et al., 2010), we ran a second set of experiments on synthetic data in order to mea-sure the dependence on the dimension d . We sam-pled points from R d as follows: We define two sets of cluster centers C 1 = { (  X  1 , 1) , (  X  1 ,  X  1) } and C { (1 ,  X  1) , (1 , 1) } and apply a random rotation to both sets. We then sample each data point from a uniform Gaussian distribution N (0 ,I d ). The first two coordi-nates of each data point are replaced by one of the cluster centers and the label of this data point is set accordingly to either 1 or 2. Finally, a small pertur-bation drawn from N (0 , 0 . 25 I 2 ) is added to the first two coordinates. The results are depicted in Table 2, which shows the running times for the various algo-rithms until a quality measure of Q &gt; 0 . 99 has been reached.
 Our algorithm achieves the same optimal function val-ues as the interior point method, while requiring less time than the PG method. For larger dimensions we plot the results in Figure 3. As it can be observed, our algorithm is considerably faster than PG on these larger dimensions. We omit the IP method here, as this scales badly with increased dimension. 3.3. Sparse PCA As a third problem we consider the sparse principal component analysis problem (sparse PCA). For a given covariance matrix A  X  R n  X  n , sparse PCA tries to find a sparse vector x that maximizes x T Ax , i.e. a sparse principal component of A . This problem can be relaxed into the following SDP (d X  X spremont et al., 2007): where A  X  X denotes Tr( A T X ). In a subsequent round-ing step the largest eigenvector of the solution to Prob-lem (6) is returned as the solution vector x . The pa-rameter  X  controls the tradeoff between the sparsity of x and the explained variance x T Ax .
 Problem (6) is not in form (1). However, one can easily transform it into an unconstrained semidefinite problem by defining the functions g ( X ) = X Tr( X ) and f ( X ) =  X  P ( i,j ) | X ij | X  A  X  X . Hence, Problem (6) is equivalent to Note that f ( g ( X )) is again a convex function over the set of semidefinite matrices without the zero ma-trix. However, f ( g ( X )) is not smooth. Smoothness of f ( g ( X )) can be achieved either by implicitly smooth-ing it, e.g. using Nesterov X  X  smoothing technique (Nes-terov, 2005) or by explicitly smoothing it and replac-ing the absolute function | . | with the scaled Huber-loss H M . The Huber-loss is defined as: By appropriate scaling one can achieve an arbitrary small difference between | x | and H M ( x ). We obtain a smooth, convex function f H M by replacing the ab-solute function with the Huber-loss in function f . In our experiments we set M = 10  X  6 such that functions f M and f differ only marginally from each other. We again follow the experimental setting of (Kleiner et al., 2010) and we compare to an interior point method and to a state-of-the-art algorithm, the DSPCA algorithm (d X  X spremont et al., 2007) which is specifically designed to solve Problem (6). We used the colon cancer data set which contains 2000 microar-ray readings from 62 subjects. We randomly sampled readings in order to vary the dimension d . As standard with this task, we normalized the data to mean 0 and standard deviation 1. We set  X  = 0 . 2 in Problem (6) to obtain sparse solutions for all d .
 Table 3 reports the running time, the function value at convergence, the sparsity of the solution and the captured variance for these data sets. As mentioned above, we ran our algorithm on the function f H M , how-ever we report the function value f ( X ) for the original formulation (6). The solutions of our algorithm are ba-sically identical to those of the interior point method. However, it needs only a fraction of the time spent by the interior point method. The DSPCA algorithm pro-vides accurate solutions within short time even with increasing dimension, however our algorithm is still considerably faster, especially for large dimensions. 4.1. The Duality Gap In this section we provide a duality gap for Problem (1) and analyze the running time of Algorithm 1. Let Problem (1) have finite optimal solution denoted by f  X  obtained at X  X  . Let t be an upper bound on the trace norm Tr( X  X  ). Such a trace bound always exists if f  X  &gt;  X  X  X  . Then the optimization Problem (1) is equivalent to: In order to simplify some technicalities in the proof we change Problem (8) into: Problems (8) and Problem (9) are equivalent if we de-fine where and t 0 = t  X  Tr( X )  X  0. Note that  X  X is positive semidefinite whenever X is positive semidefinite. This transformation is only done here for simplifying the analysis of Algorithm 1. It does not alter Algorithm 1. We denote by S t := { X  X  R n  X  n | X 0 , Tr( X ) = t } the set of all positive semidefinite matrices with trace constraint t .
 Hence, we have that Problem (1) is equivalent to By convexity of f , we have the following linearization, for any X,Y  X  S t : This allows us to define the Wolfe-dual of (10) for any fixed matrix X  X  S t as follows, and the duality gap as By the definition of the objective function f , the gra-dient  X  f ( X ) is always a symmetric matrix and there-fore has real eigenvalues, which will be important in the following.
 Lemma 1. The duality gap can be written as Proof. We will prove the claim by showing that for any symmetric matrix G  X  R n  X  n , one can equiv-alently reformulate the linear optimization problem max Y  X  S t G  X  Y as follows: where the latter maximization is taken over unit vec-tors u i  X  R n , k u i k = 1, for 1  X  i  X  n , and real coefficients  X  i  X  0, with P n i =1  X  i = t .
 For Y  X  S t let Y = U T U be its Cholesky factoriza-tion. Let  X  i be the squared norms of the rows of U , and let u i be the row vectors of U , scaled to unit length. From the observation Tr( Y ) = Tr( U T U ) = Tr( UU T ) = P i  X  i = t it follows that any Y  X  S t can be written as a convex combination of rank-1 matrices Y = P n i =1  X  i u i u T i with unit vectors u i  X  R n . It follows where the last equality is the variational characteriza-tion of the largest eigenvalue.
 Finally, both claims follow by plugging in  X  X  X  f ( X ) for G .
 By construction the duality gap g ( X ) is always an up-per bound on the primal error h ( X ) = f ( X )  X  f ( X  X  This can also be used as a stopping criterion in Algo-rithm 1. If g ( X )  X   X  then f ( X ) is an  X  -approximation to the optimal solution. 4.2. Runtime and Convergence Analysis In this section we will show that after at most O ( 1  X  ) iterations Algorithm 1 returns a solution that is an  X  -approximation to the global optimal solution. The proof is along the lines of (Clarkson, 2008) and (Hazan, 2008). However, we improve by lowering the needed accuracy for the eigenvector computation from O (  X  2 ) to O (  X  ). This in turn lowers the computational effort for a eigenvector computation from O ( 1  X  ) to O ( 1  X   X  iteration when using the Lanczos method.
 Let the curvature constant C f be defined as follows: C The curvature constant is a measure of how much the function f ( X ) deviates from a linear approximation in X , and hence can be seen as an upper bound on the relative Bregman divergence induced by f . Now we can prove the following theorem.
 Theorem 2. For each i  X  1 , the iterate X i of Algo-rithm 1 satisfies f ( X i )  X  f ( X  X  )  X   X  , where f ( X the optimal value for the minimization Problem (1), Proof. We have X i = V i V T i . Let the sequence  X  i = i +2 . For each iteration of Hazan X  X  rank-1 update, we have that where the first inequality follows from choosing  X  = 1  X   X  i and  X  =  X  i  X  t and the last inequality follows from the definition of the curvature constant C f . Fur-thermore, The last inequality follows from setting  X   X  to a value at most  X  i  X  C f t within Algorithm 1. Hence, Inequality (11) evaluates to Subtracting f ( X  X  ) on both sides of Inequality (12), and denoting the current primal error by h ( X i ) = f ( X i )  X  f ( X  X  ), we get which by using the fact that the duality gap g ( X i ) is always an upper bound on the primal error h ( X i ) gives The claim of this theorem is that the primal error large number of iterations. Indeed, we will show by ( i = 0), we know from (14) that the claim holds, be-cause of the choice of  X  0 = 1.
 Assume now that h ( X i )  X  8 C f i +2 holds. Using  X  i +2 in Inequality (14) we can now bound h ( X i +1 ) as follows: So far we only considered the progress made by Al-gorithm 1 trough the rank-1 update. Running the nonlinear improvement on f ( V i V T i ) in each iteration only improves the primal error h ( X i ) in each iteration. Hence, the claim of the theorem follows.
 We can set  X   X  =  X  4 t throughout Algorithm 1. This will ensure  X   X   X   X  i  X  C f t as needed by the analysis of the al-gorithm.
 We have provided an algorithm that optimizes convex, smooth functions over the cone of positive semidef-inite matrices. It can be readily used for a variety of machine learning problems, as many of these fall into this framework or can be equivalently transformed into such a problem. In this paper we have performed experiments on three of such problems and we have shown that our algorithm significantly outperformes state-of-the-art solvers without the need of tuning it to any of the specific tasks. Additionally, the algorithm proposed has the advantage of being very simple, and it comes with the guarantee to always converge to the global optimal solution. In the future, we plan to im-plement our algorithm in C++ for further speedups. Acknowledgements The author would like to thank Georgiana Dinu and Joachim Giesen for useful discussions on the topic. This work was supported by the Deutsche Forschungs-gemeinschaft (DFG) under grant GI-711/3-2.

