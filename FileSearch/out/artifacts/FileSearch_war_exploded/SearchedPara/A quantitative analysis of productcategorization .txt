 REGULAR PAPER Martin Hepp  X  Joerg Leukel  X  Volker Schmitz Abstract Many e-business scenarios require the integration of product-related data into target applications or target documents at the recipient X  X  side. Such tasks can be automated much better if the textual descriptions are augmented by a machine-feasible representation of the product semantics. For this purpose, categorization standards for products and services, like UNSPSC, eCl@ss, the ECCMA Open Technical Dictionary (eOTD), or the RosettaNet Technical Dic-tionary (RNTD) are available, but they vary in terms of structural properties and content. In this paper, we present metrics for assessing the content quality and maturity of such standards and apply these metrics to eCl@ss, UNSPSC, eOTD, and RNTD. Our analysis shows that (1) the amount of content is very unevenly spread over top-level categories, which contradicts the promise of a broad scope implicitly made by the existence of a large number of top-level categories, and that (2) more expressive structural features exist only for parts of these standards. Additionally, we (3) measure the amount of maintenance in the various top-level categories, which helps identify the activelymaintained subject areas as compared to those which ones are rather dead branches. Finally, we show how our approach can be used (4) by enterprises for selecting an appropriate standard, and (5) by standards bodies for monitoring the maintenance of a standard as a whole. Keywords Products and services classification  X  Metrics  X  UNSPSC  X  eCl@ss  X  RosettaNet  X  Ontologies  X  Electronic commerce  X  Electronic catalogs 1 Introduction Data and content management in an e-business environment consists to a signif-icant extent of content integration tasks, where content integration is, following the definition by Stonebraker and Hellerstein , the  X  X ntegration of operational in-formation across enterprises X , which is highly volatile, and large in data volume and number of transactions [23]. Two very common examples are the integration of product descriptions from multiple suppliers into one consistent, multi-vendor catalog or the aggregation of itemized invoicing data into a financial target hier-archy for analytical purposes like spend analysis. The mere number of such tasks on one hand and the limited amount of time available on the other hand make a high degree of mechanization of any such tasks highly desirable. As mechanized integration solely based on natural language analysis of unstructured data has so far not achieved a sufficient level of precision, the common approach is tagging individual data sets with references to entries in a standardized vocabulary of prod-ucts and services terminology, such as UNSPSC. 1 These vocabularies are usually built around a hierarchy of categories, e.g.  X  X ffice supplies X  with  X  X encils X  and  X  X ulers X  as subclasses. Within this paper, we refer to such standardized vocabular-ies for products and services terminology as Products and Services Categorization Standards (PSCS) . For several years now, multiple standards bodies have been de-veloping and providing such standards, and businesses have tried to make use of them for the mechanization of product-related data processing. However, the cur-rent situation is unsatisfying for the following reasons: 1. The initial enrichment of unstructured data with such machine-readable se-2. While the structure and characteristics of the standards are known in advance 3. Products and services categories undergo continuous change due to innova-4. The actual content quality of a categorization standard cannot be derived from a strong need for measuring the actual content quality of products and services categorization standards, because they must select the most suitable standard prior to investing in the annotation of unstructured data, but have currently no methods or tools at hand that can be used for this purpose.
 allow evaluating the maturity, specificity, and coverage of products and services categorization standards, and apply them to the current and multiple past releases of the three most prominent horizontal (i.e. cross-industry) standards UNSPSC, eCl@ss, and eOTD, and one vertical (i.e. industry-specific) standard, namely the RosettaNet Technical Dictionary (RNTD). For those standards that are partitioned in top-level categories spanning well-defined scopes, we also do a sectoral analysis that makes visible the differences between top-level categories with regard to these measures. 1.1 Categorization standards for products and services There are countless approaches for the classification of goods, ranging from rather coarse taxonomies, created for customs purposes and statistics of economic activ-ities, like the North American Industry Classification System (NAICS) and its predecessor SIC (see U.S. Census Bureau [24]), to expressive descriptive lan-guages for products and services, like eCl@ss, eOTD, or the RNTD. The UN-SPSC, widely cited as an example of a product ontology, is in the middle be-tween those two extremes, providing an industry-neutral taxonomy of products and services categories, but no standardized properties for the detailed description of products. It is out of the scope of this paper to list and compare all available stan-dards in this area, but one can say that UNSPSC, eCl@ss, and eOTD are currently the most important horizontal standards (i.e. covering a broad range of industries), and RNTD should be included in the analysis because of its high degree of detail, albeit limited to a narrow segment of products.
 nents:
Product Classes : All PSCS are based on a set of product categories that aim at
Hierarchy of Classes : Most PSCS arrange the classes in hierarchical order. It is
Dictionary of Properties : More sophisticated PSCS include a dictionary of stan-
Enumerated Property Values : For properties where a standard datatype is not suf-
Class X  X roperty Relation : Most PSCS with a dictionary of properties include a
Keywords : Sets of keywords and relations between such words and classes or are a work in progress with often multiple releases per year. 1.2 Related work Collections of consensual concepts for the communication about products and services have been subject to much research in diverse research communities, e.g. under the label  X  X ntologies X  in the knowledge representation and data manage-ment field [20], with specific focus on catalog data integration [3, 5, 6, 21], and as  X  X roduct classification standards X  (PCS) [17, 22], or  X  X roduct schema X  [25] in the e-commerce arena. Also,  X  X escriptive languages for products and services X  has been proposed as an alternative term [10]. Many researchers have worked on the task of integrating two standards by finding similar concepts and establishing mappings between them, e.g. [22] or [2].
 of such categorization standards for granted and treats the most prominent ap-proaches eCl@ss, UNSPSC, eOTD, or the RNTD as an externally given solution to the non-trivial requirement of sufficient coverage and detail. Except for our earlier works [9, 10, 12, 13], we do not know of any in-depth analysis of the con-tent quality of PSCS. The empirical study by Fairchild and de Vuyst analyzes the concepts of standardized PSCS, but describes only some characteristics of UN-SPSC on a high level of abstraction [4]. Li [18] has analyzed XML grammars for electronic commerce regarding their content, but only on the basis of very simple metrics.
 propose metrics for the structural properties of RDF-S schemas for the Semantic Web, but include only one product-related schema in their analysis of 28 schemas. Also, in the course of deriving an OWL ontology from UNSPSC and eCl@ss, there have been findings on the actual semantics of the taxonomic relationships in these standards [11, 15].
 but the common approaches have to our knowledge not been applied to business vocabularies as some form of software.
 of the art in agent-based electronic commerce, and to [1], which introduces an agent-based electronic market architecture that uses ontologies for representing the various views on products. 1.3 Our contribution In this paper, we (1) present a framework of metrics that can be used to assess the quality and maturity of products and services categorization standards and tax-onomic standards in other domains (e.g. medical informatics or library science) and (2) apply these metrics to the current and multiple past releases of eCl@ss, UNSPSC, eOTD, and the RNTD. Based on this, we (3) reveal that most of those standards, though advertised as industry-neutral undertakings, are fully developed in only a few selected branches. Also, we can (4) clearly show which of these standards are actually maintained and updated, and which others are rather inac-tive, dead collections. Also, we present a sectoral analysis that breaks down the aggregated results to the respective top-level categories.
 that reflect the dimensions of content, domain coverage, and maintenance. Sec-tion 3 describes our experiences and the resulting data of applying our metrics to multiple releases of eCl@ss, UNSPSC, eOTD, and the RNTD, and demonstrates how our metrics can additionally support decision-making in typical use case sce-narios. In Sect. 4, we discuss the findings. In Sect. 5, we summarize the work and highlight its implications for both e-business participants and standards bodies. 2 Methodology and metrics We define a set of metrics that aim at reflecting dimensions relevant for judging the content quality, domain coverage, and amount of maintenance of products and services categorization standards. The general approach is to determine the amount of structural elements and relationships between such elements. We want to answer the following questions: (1) To which degree do the elements supported by the skeleton of any given PSCS (2) If the respective elements exist, to which degree are they specific? (3) Is the degree of completeness and detail consistent throughout all top-level cat-(4) How much maintenance work and updating is actually done by the standards (5) Is maintenance taking place in all branches of the standard, or are there just propose suitable metrics. 2.1 Relevant dimensions The proposed metrics target four aspects of the respective PSCS: (1) The absolute amount of content, i.e. the number of categories, properties, and (2) the degree of balance along the hierarchy (especially the distribution of content (3) the specificity of property assignment in class-wise property lists, and (4) the absolute growth and the amount of maintenance over time, both for the
Amount of Content : The metrics in this section reflect the absolute number of
Metrics for Hierarchical Order and Balance of Scope : Most PSCS include a
Quality of Class-Specific Property Sets : Many PSCS contain a property X  X lass of this paper, a property is considered a generic property when it is contained in more than 75% of the property lists, and a property list is considered specific as soon as it holds one single specific (i.e. not generic) property. The cut-off point of 75% was selected because it is compatible with the implicit design decisions of all common PSCS and also does not count inconsistencies in the assignment of generic properties to the favor of the respective standards, which would have been the case if a cut-off point near 100% was chosen.

Growth and Maintenance : The metrics in this section reflect the pace of growth 2.2 Proposed metrics In this section, we define the individual metrics for the relevant dimensions as identified in Sect. 2.1. 2.2.1 Number of classes, properties, and enumerative values For this dimension, we just count the absolute number of elements. These metrics are very basic and often easily available. They are also often used by standards bodies to promote their work, but it can be shown later that they are useful only in combination with other metrics. 2.2.1.1 Number of products and services classes
Definition of the metric : For each release of a specific PSCS, we count the overall
Rationale : This metric reflects the vocabulary size, i.e. the number of generic 2.2.1.2 Number of properties
Definition of the metric : For each release of a given PSCS, we count the total
Rationale : The size of the property library reflects the number of concepts for 2.2.1.3 Number of enumerative data types Product properties (e.g.  X  X isk diam-combination with a unit of measurement (e.g.  X  X nches X ), or to a set of symbols reflecting valid concepts. The second form of data typing is usually referred to as enumerative data types, because the lexical space is an explicit set or list of a limited amount of items.

Definition of the metric : We count all properties in the property library that are
Rationale : It is highly desirable to have properly defined lexical spaces for all 2.2.2 Metrics for hierarchical order and balance of scope All of the standards in our analysis (except for the RNTD) are horizontal standards that aim at covering categories across industries. However, the breadth of top-level categories may falsely indicate an equal coverage and quality in all of those segments. The metrics defined in this section help to reveal whether a given standard is equally well developed across its hierarchy, or whether the breadth of scope found at the top-level is just an unfulfilled promise. 2.2.2.1 Number of classes per top-level category
Definition of the metric : For each release of a given PSCS, we determine the
Rationale : Many PSCS were created by merging existing standards from specific 2.2.2.2 Services vs. products Categorization standards can contain concepts for products, for services, or both. The mere existence of services categories, however, does not reveal the actual number of services categories as compared to products.
Definition of the metric : We count the total number of services concepts (on all
Rationale : The services domain differs from the representation of tangible prod-2.2.2.3 Distribution properties of the number of classes per top-level category
Definition of the metric : We determine the distribution parameters for the data
Rationale : These metrics show how the distribution of classes along the cate-2.2.2.4 Percentage of content in the most populated top-level categories In many PSCS, we find a few huge top-level categories, often reflecting bulk con-tributions from previous industry-specific efforts. The following metric sheds light on this issue.

Definition of the metric : For the current release of a given PSCS and based on
Rationale : For horizontal products and services standards, this reveals whether 2.2.2.5 Size of the most populated category vs. median of all top-level categories It is not only worthwhile to know the percentage of concepts in the biggest category, but also the order of magnitude of the imbalance between the biggest category and the median.

Definition of the metric : For the most recent version of a PSCS, we divide the
Rationale : This metric reveals the order of magnitude of the number of concepts 2.2.2.6 Number of descendents per superordinate category Besides the distribu-tion of categories among the top-level sections, it is useful to see how the degree of detail varies among the various levels of the hierarchy.

Definition of the metric : For each level of the hierarchy individually, we count
Rationale : This metric reveals how the degree of detail (i.e., the number sub-2.2.3 Quality of class-specific property sets tle use unless the standard includes a mechanism that helps maintain consensus among standards users about which properties are to be used in combination with which category. Otherwise, individual participants will fail to use compatible sets of properties for the same classes, which would make processing the property val-ues very difficult. The common mechanism for this is providing a list of property recommendations per class. view, it is very hard to implement and maintain for standards bodies, since it re-quires industry consensus on a very detailed level. Also, product properties are often the distinguishing aspect of competing offerings; thus, manufacturers, if in-volved in the standardization process, are very keen on seeing properties included that reflect the advantageous dimensions of their products, while they have little incentive to agree to the addition of a property that only helps their competitors to describe advantageous dimensions of their own products in more detail. Also, the need for maintenance on the level of properties can be assumed to be higher than on the level of categories, since they are more closely coupled to technical innovation (e.g. the category  X  X V sets X  has been needed for many decades now while the property  X  X upport for digital TV X  is a recent requirement).
 property sets for products and services classes and at quantifying the degree of specificity. They can also be applied on the level of top-level categories in order to show the distribution of specific property sets over the scope of a given standard. 2.2.3.1 Specific property lists ratio A certain amount of the properties from the property library is usually assigned to either all or the vast majority of all classes. Since these properties add little specificity to the description at the class level, we need a metric that removes such mechanically generated property sets from the total number of property sets.

Definition of the metric : We count all products and services categories that con-
Rationale : Only the number of specific property assignments indicates the 2.2.3.2 Distribution of specific property sets per top-level categories While the overall percentage of categories with specific property sets is already a good in-dicator for applications that use the entire scope of the standard, there are many situations where the amount of specific property sets broken down to top-level categories is interesting.

Definition of the metric : We apply the metric 2.2.3.1. individually to each top-
Rationale : This metric helps identify those top-level categories that actually 2.2.3.3 Property usage in property lists If users want to assess the amount of labor for creating product descriptions and data conversion etc., they should know the number of properties per category. The following metric reflects this aspect.

Definition of the metric : For each concept that has a specific property list, we
Rationale : Property lists should contain all necessary properties, but not a wild 2.2.3.4 Semantic Weight and Semantic Value oped in our earlier works [10, 12, 13] and are motivated and defined as fol-property lists, based on the fundamental idea that a property being used very frequently is generally less specific than a property assigned to only a few categories.
 list is either considered specific, as soon as it contains a single property that is used in not more than 75% of all property lists, or generic, if it contains only properties assigned to at least 75% of the classes or no properties. One should note that none of the popular standards uses inheritance for properties; therefore, we can simply count the explicit property assignments in the standard.
 steps: First, the Semantic Weight for each property in the property library is deter-mined. In a second step, the Semantic Value for each single property list is com-puted by adding the Semantic Weights of all properties contained. The Semantic Value for classes without a property list is by definition equal to zero. in the property library, we count the number of entries in the class X  X roperty rela-tion. This yields the number of occurrences of property P i . Then, each property P i in the property library receives a Semantic Weight SW i that is equal to the reciprocal value of its usage frequency in a given release of the PSCS (this idea resembles basic concepts in information and communication theory): It is important to note that this is not a characteristic of the respective property alone, but reflects its usage in a given PSCS. The uneven distribution of classes and the fact that node specific property lists do not yet exist for a big share of the classes influence the absolute semantic weights. A base property will have a semantic weight of with 1  X   X   X  0 . 75.
 base property. Its range results from the definition of a non-specific property as in Sect. 2.1. A very specific property used only in one single property list has a Semantic Weight of 1. Properties in the property library that are not used in any property list should be simply ignored, because no meaningful value can be determined.
 in the PSCS having a property set S j , we sum up the Semantic Weights of all contained properties. This yields the Semantic Value SV j for each class C j with j = 1 ,..., number of classes specificity of the property list for the class, but very frequently used properties add less semantics than specific properties. SV j is an indicator for the semantic specificity of the class C j . The higher SV j , the more distinct is the respective property list from that of any other class.
 ment, because it is influenced by the size and structure of the property library. For example, a badly structured property library with duplicate entries for identi-cal properties will increase the Semantic Values. The major gain is not the value itself, but its distribution properties with regard to the PSCS as a whole. overly big property collections with lots of redundant entries, the raw value SV j should be divided by the number of properties.
 for measuring the distribution of specificity of property sets in PSCS, they can likely be applied to other domains, e.g. the usage of properties for describing in-stances in OWL ontologies (since OWL properties have a global scope) or weigh-ing the specificity of references in scholarly work. These additional usages are, however, outside the scope of this paper. 2.2.4 Growth and maintenance Due to the ongoing innovation in the products and services domain, standards bodies have to keep on creating new categories for new types of goods. The actual amount of new categories is constrained by at least two limitations: The amount of input received from the market side and the speed of processing such input. The amount of innovation dynamics likely varies across industries (e.g. IT components will have more new concepts per time than office supplies), but it can be assumed that some innovation dynamics exists in all domains covered by popular PSCS. This assumption is confirmed by simulation experiments described in [9]. cator for the seriousness of maintenance, and it is also of importance for users of the standards in order to implement a suitable strategy for coping with release changes. This is because modified elements in the standard often require manual checking whether the class assignments and properties for existing data are still valid, and many enterprise resource planning (ERP) systems store only one single category per item, which limits the amount of time available for migrating from one PSCS version to the next.
 ments are the most actively maintained ones. 2.2.4.1 Number of new classes per month
Definition of the metric : For each release change of a given PSCS, we determine
Rationale : For a good coverage of concepts needed in the domain, any PSCS 2.2.4.2 Number of new and modified classes per top-level category
Definition of the metric : For each top-level category of a given PSCS, we deter-
Rationale : While the metric 2.2.4.1. can identify standards that undergo no seri-3 Application to eCl@ss, UNSPSC, eOTD, and the RosettaNet Technical Dictionary In a comprehensive analysis, we determined the metrics defined above for the most recent releases of the four standards eCl@ss, UNSPSC, eOTD, and RNTD. This section describes our experiences and presents the resulting data. 3.1 Data extraction and applicability As a first step, we tried to download the most recent release and previous releases of all four standards. While the RNTD is available freely, all others require reg-istration and, in the case of eOTD and UNSPSC, even a membership fee. The membership fee and registration is only necessary if someone wants to download the complete standard. Browser-based search is not subject to these limitations. all four standards come in different formats. eCl@ss is delivered as a set of CSV files that are well documented, but required time-consuming manual import into our RDBMS. eOTD comes as a set of MS Access files, UNSPSC as one MS Excel file per release, and RNTD is packed into a proprietary XML syntax. The situa-tion is even more complicated as the individual schemas used for the storage of the standards have often changed over time. We also observed multiple inconsis-tencies, e.g. that explicit flags are not always set correctly. Whenever possible, we corrected those inconsistencies. The result was one huge set of relations in one RDBMS, which we then analyzed using SQL queries.
 metrics are not applicable to UNSPSC since the official release does not contain properties. Those metrics based on the hierarchical structure cannot be used for RNTD, as there is no hierarchy in this standard; they can also be applied to eOTD only in part, as the classifying identifier EGIC is not a fully-fledged hierarchical order. The eOTD files summarize all releases in one huge audit file, so that we had to derive the valid concepts at a given point in time based on the addition and deletion dates in that file. When official release dates were not easily available, we used file dates or date entries in the data bases as an approximation. of samples. The main reason for this was that a properly gained sample would have required at least similar effort. As a consequence of this approach, respective statistical parameters (i.e. the standard deviation and the coefficient of variation) must be determined as defined for population data and not as defined for a sample. This especially affects the computation of the variance and standard deviation. present the most interesting ones. 3.2 Results Our analysis shows surprising results in all four types of metrics that go beyond the total number of elements, i.e. with regard to  X  the hierarchical order and balance of content,  X  the property library,  X  the quality of class-specific property sets, and  X  the growth and amount of maintenance work.
 sion about the adoption of a particular standard by an e-business participant. 3.2.1 Absolute size Ta b l e 1 shows the total number of categories, properties, and values as the most obvious metrics for all four PSCS. These numbers, especially the total number of classes, are often used by standards bodies when promoting their standards. All values given in here are based on the actual data in the respective standards and not simply taken from marketing materials. eCl@ss and UNSPSC. The fact that RNTD is substantially smaller is no sur-prise, since the scope of it is limited to a narrow segment. It must also be said that the total number of enumerative data values in RNTD cannot be di-rectly compared to the other standards, since the respective structural element in RNTD is more of a  X  X erm Definition X  which holds not only data values but also other entries for useful concepts. Thus it is given in parentheses in the table. 3.2.2 Hierarchical order and balance of content For horizontal products and services standards, the hierarchical order and the bal-ance of content reveals whether the standard is a true horizontal approach or hor-izontal just with regard to the existence of segments, but in reality focused quite vertically at the more detailed level. A true horizontal standard requires quite nat-urally not only the existence of segments for a broad range of concepts but also actual entries in the deeper branches of all segments. Table 2 shows the percent-age of concepts contained in the largest and the three largest top-level sections, and relates the size of the largest category to the median. This metric reveals the order of magnitude of the number of concepts in the most populated segment as compared to the median (i.e. the size of the top-level category in the middle of the distribution). The bigger this ratio, the more is the content of the standard domi-nated by one single segment.
 of categories stems from a very few branches. In eCl@ss, eOTD, and UNSPSC sections. Especially when compared to the median size of all categories, the degree of imbalance is obvious. The largest segment in eOTD is more than 52 times as big as the median, which can be traced back to the bulk import of classes from past standards. In eCl@ss, the largest top-level category is still seven times as big as the median, and in UNSPSC it is eleven times as big.
 vided by the mean) of the number of classes per top-level category for eOTD is about twice the value for both UNSPSC and eCl@ss, pointing to very diverse top-level sizes. The smallest ( X  X ractors X ) contains just seven descendents, the biggest ( X  X edical, dental, veterinary, ...  X ) two-thousand times as much (14,189 of 58,970 categories).
 obvious when the size of the individual top-level categories is visualized in a bar chart, see Fig. 1 (UNSPSC 7.0901), Fig. 2 (eOTD August 1, 2004), and Fig. 3 (eCl@ss 5.1de).

UNSPSC : eOTD : eCl@ss : lease change from version 4.1 to 5.0, where the ratio of the largest category vs. the median was reduced from 814% down to 731%, there is no significant change in the dominance of a few classes measurable.
 fined in Sect. 2.2.1. are insufficient indicators when comparing alternative stan-dards. For example, eCl@ss contains 1,992 categories in the top-level category  X  X ffice supplies, furniture, equipment, and papeterie X  (segment 24), while UN-SPSC offers only 576 categories in the respective subject area (353 in segment 44,  X  X ffice Equipment and Accessories and Supplies X , and 223 in segment 56,  X  X ur-niture and Furnishings X ), and eOTD only 1020 (593 in  X  X ffice Supplies and De-vices X , 316 in  X  X urniture X , and 111 in  X  X ffice Machines, Text Processing Systems, and Visible Record Equipment X ). The scope covered by the respective categories will likely not be completely the same, but since the order of magnitude is so sub-stantial, we can assume that the coverage of this topic is much better in eCl@ss than in UNSPSC and eOTD, despite the fact that eOTD contains more than twice as many categories in total. This is an important finding, because exactly this range of products is of paramount relevance for e-procurement, since respective projects often target the sourcing of everyday office supplies. Unfortunately, the size of a top-level category is not immediately visible for a decision maker, since it re-quires importing the standard into an RDBMS and the subsequent execution of nested SQL queries.
 pare distributions with a different mean; it is thus a good indicator for the com-parison of multiple PSCS with regard to the degree of balance. Table 3 shows the coefficient of variation and other distribution parameters of the number of classes per top-level category for eCl@ss, eOTD, and UNSPSC. One can see that eCl@ss and UNSPSC vary only half as much with regard to the degree of bal-ance than eOTD. This matches what is obvious from the numbers and diagrams; eOTD has extremely small segments (e.g.  X  X ractors X  with just seven categories) and extremely big ones, like the ones names above, with up to 14,189 categories. top-level category which is between the 25% smallest categories and the remain-ing bigger ones. The median is the size of a category that is exactly in the middle of the population, i.e. the one which has the same number of smaller categories below itself than bigger ones above. Q3 (third quartile) reflects the size of that top-level category which separates the 75% smallest categories from the remain-ing bigger ones. (When there is no single element that holds exactly the position defined for the quartiles and the median, the respective value is the mean of the two adjacent values; this explains the values ending  X .5 X ).
 tributed, i.e. how many descendents exist per parent node. This reflects whether a specific PSCS is evenly developed at all levels, or whether only some branches are completed down to the leaf level, while others end at a higher level. standards having a hierarchical order. As per the definition of the metric in Sect. 2.2.2.2., this does not include services hidden in the deeper levels of the hierarchy. Services differ from tangible products, e.g. because the fulfillment is bound to properties of the service customer, especially with regard to location and time. Also, there might be industries where, due to their high volume, services are of special interest for spend analysis. It thus makes sense to determine the percentage of services classes.
 3.2.3 Property library eCl@ss, eOTD, and RNTD include a library of properties that can be used to de-scribe product or services in more detail, while UNSPSC does not. The net size of this library indicates the amount of concepts for properties in the given stan-dard. However, it can be suspected that redundancy is a big problem with regard to properties, because the often distributed development of PSCS makes it very likely that redundant properties are created when the existence of an equivalent property is not realized, e.g. due to different terminological conventions. In addition, enu-merative data types for such properties that cannot be unambiguously represented using standard data types are highly desirable. However, we can often observe that such property definitions are incomplete (e.g. defined as any alphanumeric sequence of less than 30 characters), which impedes the automated interpretation of property values.
 and the amount of properties with enumerative data typing. The latter is a good indicator for the specificity of properties, since it requires a lot of domain knowl-edge and community consensus to define enumerative data types for product prop-erties. One can see that eOTD has the biggest amount of properties but the lowest absolute number of enumerative data types. Since nearly a quarter of the 28,025 properties in eOTD is not included in any property set, we counted only the 21,129 properties that are assigned to at least one category. 3.2.4 Quality of class-specific property sets Property lists tell a standards user which properties should be used to describe a product or service in detail. These recommendations are part of many PSCS and should contain all necessary properties, but not a wild collection of any usable property, because this makes automated processing of product data difficult, as elements of the same type might be described using different properties. Creat-ing and maintaining such property sets per each category is a tremendous task, because it requires consensus on a very detailed level. The provision of proper-ties is often regarded as an important discriminator between PSCS, but has so far been just regarded on the structural level, i.e. whether the data model of the PSCS supports properties, and not whether the PSCS actually contains specific property assignments. The metrics in this section reveal the degree to which the various PSCS actually implement property sets. Also, only the amount of specific prop-erty assignments indicates the amount of progress in the creation of fully-fledged products and services concepts.
 tain at least one property that is not assigned to more than 75% of all classes. Ta b l e 10 illustrates how the number of properties per class varies between the var-ious PSCS. The median and coefficient of variation is surprisingly consistent. In general, a high variation in the number of properties indicates only partial progress in the development of property assignments. As an extension, this metric can be applied to each segment in order to identify those segments that actually contain a high amount of specific property lists.
 specific property lists. Since eOTD does not contain a fully-fledged hierarchy, RNTD contains no hierarchy, and UNSPSC does not include properties at all, we did this analysis for eCl@ss 5.1de only.
 the existence of a specific property set. There is a very small difference to the actual number (our analysis of the actual data base returns 10,930 specific property sets, while the flag is set for 10,933). This, however, can be neglected. The results of this analysis are shown in Table 11 . We computed the percentage both based on the total number of categories and based on the leaf level, since eCl@ss does currently not attach properties to any category on the 1st, 2nd, and 3rd level of the hierarchy. One can see that only six of 25 top-level categories have specific property sets for at least 40% of their entries. 14 top-level categories have such for less than 5% of their entries, which means that in the respective subject areas, eCl@ss does not really offer any competitive advantage over UNSPSC, which lacks properties at all. Also, the property assignments in top-level categories 38 and 39 (inorganic and organic chemicals) are specific only in the sense that they include properties not used in other top-level categories, but are otherwise almost identical for all 6353 entries.
 mantic Value can help measure the specificity of property sets. We applied this metric to eCl@ss, eOTD, and RNTD. Tables 12 and 13 show the resulting distri-bution properties of the Semantic Weights and Semantic Values. The median of 0.5 for the Semantic Weights of eCl@ss and eOTD indicates that half of the prop-erties are used in no more than two property sets, and the respective value of 1 for RNTD says that half of the properties are used in only one or no property set at all. The coefficient of variation in Table 12 shows how much the frequency of inclu-sion of properties in property sets varies across the property library, and the same column in Table 13 shows how much the specificity of property sets varies over the whole standard. For a detailed discussion of the implications of these values see Sect. 4. 3.2.5 Growth and maintenance We have already pointed out that the products and services domain is subject to substantial conceptual dynamics due to product innovation (see also [9]), and this on the level of categories, properties, and enumerated data values. This alone makes the amount of maintenance work in a given standard an important indi-cator. Since we could also show with the previous metrics that current PSCS are far from complete, the amount of additions becomes additionally interesting, since it might help us extrapolate whether there is reason to believe that subject areas that are currently incomplete but important for a given business application will improve in the foreseeable future. In order to achieve a good coverage of concepts needed in the domain, any PSCS requires (1) timely and complete feedback about missing entries from the user community, and (2) a streamlined standardization process that adds respective new elements in a timely manner.
 tant findings for decision makers in business and standards bodies. We can show that RNTD and eOTD are rather dead collections than actively maintained stan-dards, while eCl@ss and UNSPSC are continuously updated. A breakdown by top-level categories, however, shows that even in eCl@ss and UNSPSC this is true for only a very limited part of their scope. Also, it must be noted that the number of new elements per month has decreased in UNSPSC.
 eOTD, UNSPSC, and the RNTD. Table 15 relates the number of new and modified classes for the most recent releases to the amount of time passed in between re-leases. We can observe that eOTD as the largest set of concepts (58,970 classes in the latest release) and RNTD as a comparatively small set (789 classes) have both almost no growth with regard to their content. In contrast, eCl@ss has been, on average, growing by as much as 280 and UNSPSC by about 230 new classes per 30 days, and both also show significant maintenance of existing entries. It must be stressed, though, that the amount of update work found in UNSPSC per month has decreased substantially in the most recent releases. The comparatively high mean value can be traced back mainly to the releases 6.0315 and 6.0501.
 SPSC is not evenly distributed over the respective standards, but instead restricted to a limited number of top-level categories. In order to analyze this in detail, we measured the amount of change in size per each top-level category of eCl@ss and UNSPSC. Since eOTD underwent almost no maintenance and RNTD has no hierarchical order, we did not perform this analysis for these two standards. We started our analysis with version 4.0, so the values for this first version are not available. One can see that there is maintenance work in almost all top-level categories, including consolidation work that reduced the size of a category. There are minimal discrepancies between the total amount of change between Tables 14 and 16 , since we used a slightly different approach for counting new and modified entries; however, the order of magnitude of this is negligible. Table 17 shows the same data as a relative percentage over the size of this category in the previous release. Categories 17, 18, and 19 were newly introduced in version 5.0 and have thus no respective value in Table 17 .
 sion. The segments  X  X ffice supplies, furniture, equipment, and papeterie X  (24 with 1493 new classes),  X  X uxiliary supplies, additives, formulations X  (30 with 1,061 new classes) and  X  X rganic Chemicals X  (39 with 1709 new classes) accounted for almost half (44%) of the additions in this release change. However, one has to say that eCl@ss is being maintained in almost all subject areas.
 one major release change (6.0315) in which almost all top-level categories were extended. This was the version in which the two competing branches of UNSPSC, one maintained by the UNDP 4 and one maintained by ECCMA 5 were consol-idated and thus much of the user input from ECCMA X  X  online system for user feedback was incorporated. Apart from that one-time event, substantial additions have occurred only in three segments: 41 ( X  X aboratory and Measuring and Ob-serving and Testing Equipment X ), 42 ( X  X edical Equipment and Accessories and Supplies X ), and 51 ( X  X rugs and Pharmaceutical Products X ). Segment 60 ( X  X usical Instruments and Games and Toys and Arts and Crafts and Educational Equipment and Materials and Accessories and Supplies X ) grew by as many as 1187 cate-gories in that 6.0315 release change but is without any observable maintenance ever since.
 the three other segments can be observed very well in the visualization shown in Fig. 4 .
 property lists. Table 19 shows how the share of specific (see above for a definition) property lists has developed in eCl@ss per each top-level category. One can see that the top-level categories 17, 18, 20, 26, 28. 30, 31, 33, 34, 36, 37, 40, and 41 have no or almost no specific property lists in the most current version. Only categories 24, 25, 38, and 39 have specific property lists for more than 50% of their entries. The table indicates, however, that there is active development of specific property lists in 17 of 25 top-level categories. To our surprise, specific property lists in the top-level category  X  X ndustrial piping X  (37) have been removed in release 5.1. This is in line with consolidation work on the class level in this subject area. We suppose that eCl@ss is restructuring this area completely. 3.3 Application to use case scenarios While the application of our metrics as described above has already returned im-portant results that document the content quality of all relevant PSCS, the metrics can also be used by individual market participants for decision making in more specific use cases. The following are examples of such scenarios. 3.3.1 Scenario 1: Maintenance strategy and maintenance efforts The data models of most ERP packages support the storage of categories and sometimes also respective property values for products and services. However, this is often a 1:1 relationship between a product or purchased item and a respective description based on a PSCS. In other words, it is not possible to handle entries migration from one PSCS release to another should take place in one turn, since the master data is inconsistent in the meantime. The metrics that quantify the amount of change in categories and property sets can be used to assess the amount of product entries that require manual updates. In combination with estimates for the amount of time needed per item to be checked, both the need for staffing and the duration of the update can be approximated. Especially the breakdown per top-level categories can be used to check whether the most relevant subject areas are currently actively maintained. 3.3.2 Scenario 2: Steering the development of a standard The organizations coordinating the maintenance of such standards have a strong need to monitor the total content quality, the amount of progress, strengths and weaknesses in the covered subject areas, for they must distribute limited resources for the maintenance in the most effective way. Also, they may want to iden-tify weak parts of their standard in order to launch extra activities for their im-provement, e.g. motivating lead market participants to submit proposals for new content.
 amount of labor and other resources necessary to add the content necessary to fill the gaps, and probably to quantify the need for public funding, given that the overall economic benefit of such a lingua franca of e-business can be communicated.
 dependent groups of market participants. In this case, our metrics can be used to monitor the structural consistency of the work done by the respective group (e.g. number of properties per property set, etc.). 3.3.3 Scenario 3: Comparing the specificity of competing standards We can assume that a vendor of products wants to select the most specific standard prior to beginning to augment existing product data with PSCS-based descriptions. This often makes sense, since the more specific the annotation is, the more likely it becomes that future content operations can achieve a high degree of automation. An example is the automated generation of catalogs for special interest groups based on the execution of rules over properties, e.g. the creation of a catalog of camping-related products that is to contain all products that operate on 12 V and weigh less than 5 kg. If there are two competing standards available, the decision can be made using our metrics as follows: (1) Take a random sample of products from the actual range of products (e.g. n = (2) Identify the most suitable product category for each of these products in the (3) Compute the Semantic Value for the property lists for each of these products. (4) Repeat steps 2 and 3 for any alternative standard.
 category exists plus (2) the number of properties per class and (3) the degree of specificity. Note that the mean of a sample (e.g. the percentage of products in the sample that has a suitable category) is a very reliable estimate for mean of the full population, even if the sample size is comparatively small in comparison to the size of the population. If necessary, the sample size can be chosen so that the likelihood that the mean of the sample deviates not more than a given amount from the mean of the population is guaranteed to be below a given probability. additionally constrained by decisions of other parties in the value chain. 4 Discussion In this section, we compare our results with the underlying research questions as defined in Sect. 2. 4.1 Degree of completeness and balance of content All three horizontal standards contain an impressing number of categories for products and services, but the categories are quite unevenly distributed among the various top-level segments. The labels and number of top-level categories promise a very broad, industry-neutral scope, which is an unfulfilled claim in the current stage of the standards. Especially the impressive number of categories in eOTD (58,970) obscures that most entries (24%) are in one single branch ( X  X edical, dental, and veterinary equipment and supplies X ). Compared to the mean of all seg-ments, this branch is 52 times as big. UNSPSC and eCl@ss are much more evenly populated, but still have 7 times (eCl@ss) respectively 11 times (UNSPSC) as many entries in their biggest category. All three have more than 30% of all entries in three large sections and thus only a small partition of their 25 (eCl@ss), 55 (UNSPSC), or 79 (eOTD) top-level categories.
 can see that the degree of completeness decreases in eCl@ss from top to down; the coefficient of variation increases from 61% (top-level- X  2nd level) to 156% (3rd level  X  4th level), whereas it is much more consistent in UNSPSC (74% compared to 100%). In both standards, however, the population at the leaf level varies greatly, with a minimum of just one leaf and a maximum of 85 (eCl@ss) or 92 (UNSPSC). This metric cannot be determined for eOTD because it lacks a fully-fledged hierarchy. entries, but this objection does not justify the order or magnitude found in cur-rent PSCS. As a summary, the total number of classes obscure that many of the branches are still very much incomplete, and potential users are advised to check the coverage of entries in their domain prior to adopting a PSCS. 4.2 Specificity The degree of specificity can be evaluated best by looking at class-specific prop-erty assignments. RNTD has specific property lists for all of its classes, as com-pared to only 43% (eCl@ss) and 35% (eOTD). In other words, more than 2/3 of all eOTD classes and more than half of all eCl@ss classes are currently without specific property lists. On the other hand, all PSCS with properties contain many properties that are used with only one or two classes. This can point either to re-dundancy, to the  X  X rbitrary X  creation of property lists on demand, or a combination of both.
 mantic Value, one can see that both eCl@ss and eOTD show an enormous spread. The coefficient of variation is as high as 523% (eCl@ss) and 432% (eOTD), while RNTD shows only 155%. Also, RNTD has a mean about 33 (eCl@ss) to 100 times (eOTD) of the size of the others. Those orders of magnitude are compati-ble with our manual observations. In absolute values, RNTD has the highest me-dian of 6.41E-04 as compared to 6.16E-07 (eCl@ss) and 6.52E-09 (eOTD). In other words, the property lists (in the middle of the population) of RNTD are a thousand times more specific than the property lists in eCl@ss, and the property assignment in eOTD is hundred times less specific as compared to eCl@ss. This very well reflects our observation that both have huge differences in the quality of the property assignment. The big difference between RNTD and the two other can be traced back to the fact that RNTD is a very narrow, specific PSCS and can thus achieve coherence much easier, but the gap between eCl@ss and eOTD seems for us mainly a matter of performance. It also correlates with the maintenance activities (see below). 4.3 Maintenance Both eCl@ss and UNSPSC undergo sustained improvement with an average of more than 200 new classes per month, even though the number of new and mod-ified classes in UNSPSC is declining significantly over time. On the other hand, eOTD had less than one new class per month in 2004, and this despite its wide coverage. It is hardly possible that there is no need for new classes in 79 seg-ments. RNTD has also received only minimal additions with a mean of 1.3 new classes per month for the last five releases. For us, this points to either lack of user feedback, lack of users, insufficient maintenance procedures, or any combination of these. Any of the three causes are very disadvantageous for a business user of the respective standards, for he or she cannot hope for a timely addition of missing categories. UNSPSC has received substantial additions in only three segments: 41 ( X  X ab-oratory and Measuring and Observing and Testing Equipment X ), 42 ( X  X edical Equipment and Accessories and Supplies X ), and 51 ( X  X rugs and Pharmaceutical Products X ). The rest of the standard has not been actively maintained since March 15, 2003 until September 2004. This is surprising, since UNSPSC is otherwise more balanced in its content than eCl@ss and eOTD.
 seems to be that user involvement in eCl@ss is organized in a more effective way. From talks with this standards body, we know that several major enterprises dedi-cate substantial staff resources to improving the content quality. The fact that there are also classes removed from time to time seems to indicate that also significant consolidation work is taking place.
 bitious goal of eCl@ss is by far not fulfilled, since a majority of classes does not yet have specific property sets. However, one can see from Table 19 that there is progress in most top-level categories.
 too tedious and time-consuming and the standards bodies add new content only with significant delay. The maintenance and evolution of the standards seems to be too much detached from its users. In previous work, we proposed (already in 2003) that intelligent Web front-ends are necessary which can be employed by standards users to report missing categories or submit change requests easily, and that do pre-classify such requests using simple rule-based mechanisms [9]. UN-SPSC underwent the most substantial amount of additions when the content from the ECCMA variant, which included a Web-based system for suggesting new en-tries, was integrated into the official version. This makes us believe that lowering the barriers for users X  participation in the evolution of such standards is crucial. In another stream of work [14, 16], we have recently shown that Wikipedia com-munities are able to yield a vast amount of consensual concepts without central coordination, just based on clever community control, which also supports this assumption. 5 Conclusions In this paper, we have provided a wealth of quantitative data about one of the core application domains of representation in business information systems: Products and services. Apart from our direct findings, we hope that many other researchers can use our data for additional work, e.g. cost/benefit analysis or various types of correlation analysis. The direct implications of our work are as follows. 5.1 Theoretical implications We have presented a comprehensive framework of metrics for analyzing the con-tent quality of all structural elements of popular categorization schemes. This in-cludes a novel pair of metrics called  X  X emantic Weight X  and  X  X emantic Value X  that allow quantifying the specificity of property assignment in such scenarios. While the metrics were designed specially for the purpose of the analysis pre-sented in this paper, we hope that they can be applied to measuring problems in other domains with similar structural characteristics. 5.2 Implications for standards bodies Our metrics revealed weaknesses and shortcomings in all of the four PSCS. The metrics indicate quite clearly the type of action needed and also point to the weak branches of hierarchical categorization standards. They can also be used to moni-tor the development of content quality from a management perspective if the main-tenance of branches is organized in a distributed manner. 5.3 Implications for standards users Our results show that neither the provided structural components and the data model of a given PSCS nor the general scope as indicated by the top-level cat-number of actual entries in the branches of interest, the specificity of property assignment, the consistency and specificity of the property library, and the se-riousness of maintenance activities should be closely regarded. The metrics we presented in this paper can easily be applied to only a segment of interest in order to evaluate the content quality in the branches relevant to the decision maker. of maintenance work for their industry segments among multiple PSCS. This will prevent investment into such standards that neither cover existing representational needs nor show convincing efforts of improvement.
 References Author Biographies
