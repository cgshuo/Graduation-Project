 parameters for some s  X  p . The method of  X  (e.g., [1, 19, 10]).
 ingly, a natural extension is the non-parametric regressio n model y = f  X  ( x additively as a sum f  X  ( x models are the sparse additive models , studied by Ravikumar et. al [12], in which where S  X  X  1 , 2 , . . . , p } is some unknown subset of cardinality | S | = s . functions of this form. Just as  X  parametric models, similar  X  back-fitting algorithm to recover the component functions h consistency in empirical L 2 ( P an  X  s s inference problems [16, 11].
 We discuss and summarize the main consequences in Section 5. observations of the form functions f : R p  X  R that have an additive decomposition: Given some integer s  X  { 1 , . . . , p } , we define the function class F subspaces of F , given by The minimax rate of estimation over F functions of the observations { ( y ( i ) , X ( i ) ) } n minimax rate. 2.1 Inner products and norms Given a univariate function h may assume for all h assumption that the covariate vector X = ( X on F has the additive decomposition h f, f  X  i assumed the L 2 ( P ) inner product over F would involve cross-terms.) 2.2 Kullback-Leibler divergence Y | f ( X )  X  X  ( f ( X ) ,  X  2 I n  X  n ) and Y | e f ( X )  X  X  ( e f ( X ) ,  X  2 I n  X  n ) , by the functions f and e f respectively. Therefore we have the relation 2.3 Metric entropy for function classes metric entropy of F  X  : S X S  X  R + . The covering and packing entropy (denoted by log N In this paper, we are interested in packing (and covering) su bsets of the function class F some concrete examples here: (i) Consider the class H = { h k h  X  k H = |  X  | tions on [0 , 1] with the norm k h k In our analysis, we require that the metric entropy of B Assumption 1. Using log M (  X  ; H ) to denote the packing entropy of the unit ball B assume that there exists some  X   X  (0 , 1) such that Corollary 2). that covers the function class F Consider the observation model (2) where the covariate vect ors have i.i.d. elements X function f  X   X  X  Under these conditions, we have the following result: norm is lower bounded as where, for a fixed constant c , the quantity  X  log M (  X  ; H ) =  X (  X   X  1 /m ) , we have for some C &gt; 0 . 3.1 Some consequences In this section, we discuss some consequences of our results . multiplied by s .
 functions (see Example (i)).
 by Bickel et al. [1], the rate achieved by  X  covariates X .
 entropy of F in the next point.
 in the process of conducting a thorough comparison with the a bove-mentioned  X  function class F the generalized Fano method X  X  technique based on Fano X  X  ineq uality X  X o the set T lower bounds over a second set T of bound on the mutual information developed by Yang and Barron [17]. Before procedding, we first note that for any T  X  X  Moreover, for any subsets T in equations (10) and (11). 4.1 Bounding the complexity of subset selection some parameter space, we let d be a metric on it.
 Lemma 1. (Generalized Fano Method) For a given integer r  X  2 , consider a collection M of r probability distributions such that and the pairwise KL divergence satisfies Then the minimax risk over the family is lower bounded as by the set of distributions M M Let g be an arbitrary function in H such that k g k T of the set T The construction of A is as follows: Lemma 2. There exists a subset A  X  T (i) log | A | X  1 2 s log( p/s ) , (ii) k f  X  f  X  k 2 (iii) D ( f k f  X  )  X  1 constructed, see K  X  uhn [8]. For s log p with Lemma 2 yields the bound 4.2 Bounding the complexity of s -dimensional estimation an arbitrary subset of s integers in { 1 , 2 , .., p } , and define the set F Clearly F We use a technique used in Yang and Barron [17] to lower bound t he minimax rate over F construct a maximal  X  version for details). Following these steps yields the foll owing result: Lemma 3. F packing and covering entropies respectively: have the bounds that these are  X  -packing and coverings sets in F inequality Now we choose  X  and then require that s log M ( c X  n  X  be re-expressed as log M ( c e  X  equation (12) yields the desired rate thereby completing the proof. derived in Theorem 1 are minimax optimal for many function cl asses. analysis was that the covariates X lower bounds on the minimax rate derived in this paper.

