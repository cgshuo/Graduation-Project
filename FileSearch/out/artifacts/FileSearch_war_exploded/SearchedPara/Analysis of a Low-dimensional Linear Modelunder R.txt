 Collaborative filtering techniques have become popular in the past decade as an effective way to help people deal with information overload. Recent research has identified sig-nificant vulnerabilities in collaborative filtering techniques. Shilling attacks, in which attackers introduce biased rat-ings to influence recommendation systems, have been shown to be effective against memory-based collaborative filtering algorithms. We examine the effectiveness of two popular shilling attacks (the random attack and the average attack) on a model-based algorithm that uses Singular Value De-composition (SVD) to learn a low-dimensional linear model. Our results show that the SVD-based algorithm is much more resistant to shilling attacks than memory-based algo-rithms. Furthermore, we develop an attack detection method directly built on the SVD-based algorithm and show that this method detects random shilling attacks with high de-tection rates and very low false alarm rates.
 H.3.5 [ Information Storage and Retrieval ]: Online In-formation Services X  Commercial services ; K.4.4 [ Comput-ers and Society ]: Electronic Commerce X  Security Experimentation, Security Collaborative filtering, recommender systems, shilling at-tacks, anomaly detection
Recommendation systems help people deal with informa-tion overload by recommending products or services from a large number of candidates. Collaborative Filtering (CF) is one popularly used recommendation technique. It recom-mends to a user the items that people with similar tastes Copyright 2006 ACM 1-59593-369-7/06/0008 ... $ 5.00. and preferences liked in the past. Generally, CF techniques can be divided into two categories: memory-based algo-rithms and model-based algorithms. Memory-based algo-rithms , which are either user-based or item-based, first iden-tify the top k users or items most similar to the active user or item and then combine those ratings together to com-pute predictions. In contrast to memory-based algorithms, model-based algorithms learn a predictive model from rating profiles and use that model to generate predictions.
While CF techniques are beneficial to users, they might be vulnerable to recommendation attacks because they are de-pendent on external sources of information. In these attacks (which have been termed shilling attacks [10]), attackers in-fluence a recommendation system in a manner advantageous to them by introducing biased rating profiles. Because rec-ommendation systems are widely used in the realm of e-commerce, there is a natural motivation for producers of items (manufacturers, authors, etc. ) to use these shilling attacks so that their items are recommended to users more often. Therefore, recommendation system operators should be concerned about these attacks when they design and im-plement systems.

Recent research [4, 10, 12, 13] has identified and examined the vulnerabilities of memory-based CF techniques in the face of recommendation attacks. O X  X ahony et al. [13] first performed empirical studies of a user-based CF algorithm under shilling attacks and showed that attacks are success-ful at affecting predictions. Lam and Riedl [10] further eval-uated the impact of attacks by including an item-based CF algorithm, and their study suggested that the item-based ap-proach is much less affected by these attacks. More recently, Burke et al. [4] and Mobasher et al. [12] proposed several new attack models that need little knowledge of the specific system being targeted to have a strong likelihood of success in attacks on both user-based and item-based algorithms.
To the best of our knowledge, all previous work consid-ered only memory-based CF algorithms when exploring vul-nerabilities of recommendation systems, and no empirical study has been conducted on model-based algorithms. Since model-based algorithms have different mechanisms, it is im-portant to know how well the attacks that are effective against memory-based algorithms can affect model-based al-gorithms. In this paper, we focus on a popular model-based algorithm, a Singular Value Decomposition (SVD) based CF algorithm used in [1, 2, 5, 6, 16, 19, 20], which assumes that the rating matrix can be well described by a low-dimensional linear model and then computes the best model that maxi-mizes the log-likelihood of ratings.
We perform a series of experiments to quantitatively eval-uate the effect of two popular recommendation attacks (the random attack and the average attack) on the SVD-based al-gorithm, and compare that with effects of attacks on memory-based algorithms. Our results demonstrate that the SVD-based algorithm is much less affected by attacks. We further propose a method built on the SVD-based algorithm to de-tect recommendation attacks. Our results demonstrate that this method is effective at detecting random attacks (though not average attacks) with high detection rates and low false alarm rates.
In this section, we examine how well the common shilling attacks that are effective against memory-based algorithms operate with the SVD-based algorithm. We compare the impact of recommendation attacks on the SVD-based algo-rithm and two memory-based (user-based [8] and item-based [17]) algorithms.
We now give more details on the three tested CF algo-rithms.
The user-based CF algorithm [8, 15] first computes the correlations between users using a mean-adjusted Pearson correlation, and then combines a weighted average of the k nearest neighbors X  ratings to produce a prediction. More precisely, a predicted rating P i,j for user i on item j is com-puted by where A u,j is user u  X  X  rating on item j , A i is user i rating, and w i,u is the correlation between users i and u
We use an optimized version suggested in [8]. We set k to 20 and use n/ 50 significance weighting. 1 A similarity threshold of 0.1 is used, so only positive similarities are con-sidered. This parameterization is exactly the same as that in [10].
The item-based algorithm [17] computes and uses similar-ities between items rather than users. The formula used to compute a prediction is: Here, s v,j is the similarity between items v and j .Our implementation uses the adjusted cosine method to compute similarities. The number of neighbors is set to 20 and only positive similarities are considered. The parameterization of this version is also the same as that in [10].
SVD was first introduced into recommendation systems in [2] and [16]. The underlying assumption of applying SVD
If two users have fewer than 50 commonly rated items, a significance weight of n/ 50 is used, where n is the number of co-rated items. Otherwise, the significance weight is 1. to a rating matrix is that observed ratings A i,j are combi-nations of ratings from a low-dimensional linear model (de-noted as X ) and Gaussian noise (with zero mean). That is,
Since the rating matrix in the real world is incomplete and sparse, Srebro and Jaakkola [19] proposed an Expectation-Maximization (EM) algorithm to maximize the log-likelihood of all observed ratings A o ,thatislogPr( A o | X ). In this pa-per, we use this SVD-based algorithm in which the EM al-gorithm is incorporated. The details of the derivation of this EM algorithm can be found in [19, 20]; an overview is given below.

In the Expectation step of the t th iteration, a filled-in ma-trix A ( t ) is formed where unobserved entries A ( t ) i,j to the corresponding values of the computed linear model unchanged from A .Thatis, In the following Maximization step, we perform SVD on this filled-in matrix A ( t ) to get A ( t ) = USV T . The updated linear model X ( t ) is computed as where U k , S k ,and V k are matrices composed of the top singular vectors, singular values, and right singular vectors, respectively.

The above EM procedure is ensured to converge, which means that the log-likelihood of all observed ratings given the current model estimate is always nondecreasing. After the EM procedure finishes, a prediction is computed as the corresponding entry in the final computed model, i.e. ,
In this paper, the rank of linear model X issetto10and the number of iterations in the EM algorithm is set to 10. Taking into account the differences in rating scale between different users, we initially normalize each entry for user a rating matrix by first subtracting user i  X  X  rating average from it and then dividing the difference by the standard deviation of user i  X  X  ratings. In the first iteration of the EM procedure, unrated entries are replaced with zero. Finally, predictions are denormalized to the original rating range.
Our experimental design builds on the previous work in [10]. The recommendation attacks considered are shill at-tacks where the attackers introduce a new set of shill users and a set of ratings made by those shill users to the rec-ommendation system. The two intents of attacks that are considered are to  X  X ush X  a set of items so that they are rec-ommended to more users, and to  X  X uke X  a set of items so that they are recommended to fewer users.

A MovieLens data set consisting of about 1 million rat-ings on 3706 items by 6040 users is used in all experiments. Each user gives ratings to at least 20 items. Ratings are discrete-valued between 1 and 5. The number of new shill users introduced to the data set is varied between 20 and 200. To maximize the number of items in common between shill users and real users, each shill user gives ratings to all movies. We manually selected 20 movies for our target set (see Table 1); this selection of items represents a wide range of popularity (number of ratings) and likability (mean rating).

Two common attack models, random attack and average attack, are used in our experiments. In the random attack model, each shill user gives random values from a normal distribution to items not in the target set and rates items in the target set with a value equal to either the maximum or minimum allowed rating depending on its intention (push or nuke, respectively). A normal distribution with mean 3 and standard deviation 1 . 1 is used because these two values represent the ratings distribution in the original data set. Note that randomly generated values are always rounded to allowed ratings. The average attack model used here is similar, but the ratings for items not in the target set are set randomly from a normal distribution with mean equal to the average rating of the item being rated and standard deviation 1 . 1. The intuition of the average attack model is to make inserted bots more similar to existing users and thus have a stronger attacking effect.
To measure how effective an attack is in accomplishing its goal, we use two metrics proposed in [10] and [13]: Predic-tion Shift and Expected Top-N Occupancy (ExpTopN). Pre-diction shift is defined as the average change in prediction toward some target values (the maximum or the minimum allowed rating, respectively, for a push or nuke attack) over all users and target items. ExpTopN is defined as the ex-pected number of occurrences of all target items in a top-recommendation list, measured over all users, assuming that the displayed ordering of items tied at any particular rank is random. As indicated in [10], the median recommenda-tion search by MovieLens users ends with at most the first 40 items displayed. Therefore, we use ExpTop40 to reflect actual MovieLens usage.
A total of 48 experiments were performed in a 3  X  2  X  2  X  4 test matrix. The algorithm (user-based, item-based, or SVD-based), intent (push or nuke), attack model (random or average), and the number of shill users/bots (20, 50, 100, 200) were varied in each experiment. Twenty trials were tested for each experiment and mean values are reported.
Table 2 lists the obtained results measured by PredShift and the percentage change in ExpTop40. The original Exp-Top40 values (without attacks) for these three CF algo-rithms are 0 . 4012 (user-based), 0 . 2647 (item-based), and 0 . 5536 (SVD-based). Compared with the results in [10], the results obtained from the user-based and the item-based al-gorithms have similar patterns. The former responds very strongly to all attacks while the latter responds less strongly. The SVD-based algorithm has the smallest change in both PredShift and ExpTop40 for all attacks. The largest change in PredShift is no more than 0 . 003 and the largest percent-age change in ExpTop40 is no more than 4%. It is easy to see that the SVD-based algorithm also has much smaller absolute changes in ExpTop40 if we multiply the percentage changes by the original ExpTop40 values (without attack). Overall, the above results demonstrate that the SVD-based CF algorithm is much more resistant to the random and average shilling attacks than the memory-based CF algo-rithms.
For the item-based algorithm, there are two noteworthy points. First, random nuke attacks can actually push target items in both metrics. This unexpected observation was also reported in [10]. Second, average push attacks may nuke target items slightly in ExpTop40, although the item ratings are shifted greatly toward the maximum rating in PredShift. The inconsistency of the results in these two metrics implies that average push attacks may unintentionally push items not in the target set.

We suppose that the above two unexpected observations might be caused by the experimental design and the char-acteristics of the item-based algorithm. Note that in the item-based algorithm, the prediction results corresponding to an item will be changed only when the nearest neighbor items of this item become different. In the current design, all 20 target items are pushed or nuked in each added bot. It is likely that two or more target items go into (or go out of) the nearest neighbors of a certain item (no matter it is in the target set or not). Since likabilities (mean ratings) of the target items range widely, the predictions for this item may change unintentionally. Taking into account this assumption, we propose a slightly different experimental de-sign. In each experiment, only one target item is chosen and then pushed or nuked in the injected bots; the mean predic-tion and ExpTop40 occupancy corresponding to this target item is recorded. After conducting 20 experiments, one for each target item, we compute PredShift and the percentage change in ExpTop40.

Listed in Table 3 are the results of the item-based algo-rithm using this new experimental design. Obtained results for the item-based algorithm are significantly different from what is listed in Table 2 except for the group of average nuke attacks. Although it is hard to tell which experimental de-sign is more objective, the inconsistency of the results from them suggests that the effect of attacks on the item-based al-gorithm is highly dependent on the number of target items in attacking bots. We note that the results for the user-based algorithm and the SVD-based algorithm in this new experiment (not shown) comply with the results in Table 2 very well.
One important question regarding shilling attacks in rec-ommendation systems is whether attacks can be detected. In this section, we propose an attack detection method that exploits the low-dimensional linear model computed from the SVD-based CF algorithm and verify its effectiveness in MovieLens. are 0 . 4012 (user-based), 0 . 2647 (item-based), and 0 . . 004 5% 0 . 002 4% . 006 6% 0 . 001 3% . 032 30% 0 . 000 2% . 062 91% 0 . 000 1% . 307 1% 0 . 002 4% . 432  X  9% 0 . 002 4% . 508  X  8% 0 . 001 3% . 559  X  8% 0 . 001 1%  X  0 . 028 3% 0 . 001 3%  X  0 . 041 17% 0 . 002 2%  X  0 . 070 61% 0 . 002 1%  X  0 . 104 161% 0 . 003 0% . 459  X  7% 0 . 001 2% . 586  X  34% 0 . 001 2% . 612  X  63% 0 . 002 1% . 630  X  80% 0 . 003 0% Table 3: Effect of attacks on the item-based CF al-gorithm when a single target item is chosen in each experiment.

Assume that we have a rating matrix A (users-by-items), and denote X as a model that describes this rating matrix. We first measure how likely it is that a rating is real by defining the degree of belief in a rating:
Definition 1. The degree of belief in a rating A i,j is de-fined as the log-likelihood of this rating given the model that is log Pr( A i,j | X ) .
 We then measure how likely it is that a user X  X  rating profile is real by defining the degree of belief in a user X  X  rating profile:
Definition 2. The degree of belief in user i  X  X  rating pro-items user i has rated and j l is the index of the l th rated item.

In this paper, the considered model is a low-dimensional linear model. It is argued in [5] that such a model is well able to describe user preferences, which explains why this model has been popular for CF algorithms.

A low-dimensional model X can be computed from all observed ratings (including real ratings and biased ratings) using the SVD-based algorithm in Section 2.1.3. 2 Recall that the SVD-based algorithm used computes an X that maximizes the log-likelihood of all observed ratings. There-fore, the computed model X is actually the linear model that maximizes the sum of the degrees of belief in all observed ratings. After X is computed, we can compute the degree of belief in any observed rating and any user X  X  rating profile. in a rating, log Pr( A i,j | X ), can be derived as follows: log Pr( A i,j | X )=logPr( A i,j | X i,j )=  X  1 where C is a constant. Subsequently, the degree of belief in user i  X  X  rating profile follows as 1 of the squared differences between entries in the i th row of
A and entries in the i th row of X if rated entries have weight one and unrated entries have weight zero. For ease of expression, we define this term as the belief divergence (
D ( A i || X i )): According to the previous equation, user i  X  X  rating profile has a higher degree of belief if its belief divergence is smaller,
As noted previously, each rated entry in A is initially nor-malized. belief divergence D(A ||X ) real profiles belief divergence D(A ||X ) real profiles profiles (right of the line). The value of mean ( D ( A j )) + 2  X  std ( D ( A j || X j )) is shown as a dashed line. Most attacks are easy to distinguish using this line. and vice versa. Therefore, D ( A i || X i ) is used as a metric to tell whether a rating profile is real or manipulated. We consider user i  X  X  rating profile to be normal if where the mean and the standard deviation are computed over all rating profiles. If the belief divergences D ( A of real rating profiles can be well described by a Normal distribution, 3 the right side in the above inequality is the threshold for D ( A i || X i ) at a confidence level of the Normal cumulative distribution function of the value c .Weset c to 2 in this paper, which corresponds to the 97 . 7% confidence level in a Normal distribution.

In Figure 1 we illustrate the effectiveness of this approach in MovieLens when a random attack model is used. Each subfigure shows plots of the belief divergence D ( A i || X each rating profile. The first 6040 rating profiles (on the left of the vertical line) are real rating profiles and the last 100 profiles (on the right) are inserted bots. All inserted bots push or nuke one target item and give random ratings (  X  N (3 . 6 , 1 . 1 2 )) to another 2000 items. This number is chosen because the maximum number of ratings given by a user in MovieLens is 2314. The value of the threshold for D ( A i || X i ) is shown graphically as a dashed line.
Figure 1 shows how sharply the belief divergence is able to separate random attacks from real rating profiles. It also gives some insight into why (as we will show in the next sub-section) our method yields such high detection rates com-bined with low false alarm rates. As seen in the plots, al-most all inserted attack profiles result in values of D ( greater than the threshold, while very few of the real rating profiles yield D ( A j || X j ) greater than that.
We use the experimental design introduced in Section 2.2 to evaluate the proposed SVD-based detection method. Our
By the central limit theorem, if h i is the same for all i then D ( A i || X i ) is asymptotically Normal as h i increases. validation is focused on answering two questions: (1) how well can this method detect attack bots? and (2) how does the context of attacks affect the performance of the method?
Three metrics that are used are the detection rate , false alarm rate , and Receiver Operating Characteristic (ROC) curve . The detection rate is defined as the number of de-tected attack bots divided by the number of attack bots. The false alarm rate is defined as the number of normal pro-files that are predicted as attacks divided by the number of normal profiles. Note that we assume that all the original 6040 profiles in MovieLens are normal profiles. The ROC curve attempts to measure the extent to which an infor-mation filtering system can successfully distinguish between signal and noise (attacks and normal profiles in this case). The ROC area, which measures the area under the ROC curve, is used in our experiments.

We first show how well the SVD-based method detects random attack bots. We performed 2  X  4 experiments, in each of which the attack intent (push or nuke) and the num-ber of bots (20, 50, 100, or 200) were varied. For each exper-iment, there were 20 trials corresponding to 20 target items (one target item in each trial); averages were computed over them for all metrics. Each inserted bot pushes or nukes one target item and also gives ratings to another randomly chosen 2000 items.
 Table 4 reports detailed results from our experiments. The ROC area is always larger than or equal to 0 . 9998. The SVD-based method detects at least 90% of the attack bots with a false alarm rate smaller than 0 . 25%. The table con-firms quantitatively that our method is very accurate and precise for random attacks. Note that both the detection rate and the false alram rate drop slightly when the num-ber of bots increases. This is because the mean and the standard deviation of D ( A i || X i ) increases (and as a result the threshold increases) when more bots are injected. How-ever, the stable result in ROC area demonstrates that it is still possible to separate the injected bots from the normal profiles in this case. Detection can be done accurately.
 . 25%  X  1 . 83% 0 . 22%  X  0 . 01% . 80%  X  1 . 82% 0 . 14%  X  0 . 02% . 95%  X  1 . 73% 0 . 07%  X  0 . 01% . 20%  X  1 . 41% 0 . 02%  X  0 . 01% . 25%  X  1 . 83% 0 . 22%  X  0 . 01% . 00%  X  1 . 72% 0 . 15%  X  0 . 02% . 75%  X  1 . 12% 0 . 06%  X  0 . 01% . 55%  X  1 . 86% 0 . 02%  X  0 . 01% Table 5: Results of random push attacks (with 100 bots) for SVD-based detection method when the number of rated items in each bot varies. Detec-tion is essentially perfect (ROC &gt; 0 . 999 ) when bots rate a large number (  X  500 ) of items. #rated ROC Detection False Alarm
To answer the second question about how this method works when the attack setting changes, we first vary the number of rated items (filler items) in attack bots. We use a random push attack model with 100 bots in which a single target item is attacked. Results are presented in Table 5, which shows that the ROC area is larger than 0 . 999 when the number of rated items is larger than or equal to 500. It also shows that injected bots having fewer rated items are harder to detect. An intuitive explanation of this finding is that the chance to observe the inconsistency among ratings becomes smaller at that time. However, when the number of rated items is 50, our method can still get a 46 . 35% detection rate with a 0 . 10% false alarm rate. Note that the median and mean numbers of rated items in normal rating profiles are 96 and 165 . 6, respectively. These two observations verify an important property of our approach: that it depends very little on the number of rated items in normal profiles or attack bots.

We next change the number of targets in each bot to de-termine the effect on the performance of our method. The experimental setting is similar to the above one, except that the number of targets in one experiment varies from 1 to 20. Results are listed in Table 6, which shows that the detection rate drops when more items are targeted. This implies that the belief divergences D ( A i || X i ) of injected bots generally become smaller at that time.

We finally show the performance of the detection method when the standard deviation of Gaussian distribution used for generating random ratings is changed. Table 7 shows that both the detection rate and the false alarm rate re-main fairly constant when the standard deviation becomes smaller. Note that when a small standard deviation is used, almost all random ratings are valued 3 or 4 on the MovieLens Table 6: Results of random push attacks (with 100 bots) for SVD-based detection method when the number of target items varies. Table 7: Results of random push attacks (with 100 bots) for SVD-based detection method when the standard deviation of random ratings varies. De-tection performance is nearly constant.
 5 point scale. In that case, our method can still separate random attacks from normal profiles very well.

While the proposed method is effective at detecting ran-dom attacks, we observe that it has a much smaller power to detect average attacks. Table 8 lists the detection re-sults when an average attack model is used with 100 injected bots in which the number of rated items varies. When the number of rated items is around 50, the method still has limited success at separating average attacks from normal profiles. However, when this number is larger, the SVD-based method becomes completely ineffective. We also ob-serve that the detection performance for average attacks can be enhanced if a higher rank of the linear model is chosen. These findings suggest that average attacks are more simi-lar to normal rating patterns and they have more subtle in-consistency among their ratings in a low-dimensional linear projection. Although average attacks are harder to detect, there is a higher knowledge cost of mounting them relative to random attacks because the attacker needs to know rating averages for items in the targeted system.

To summarize, our results above demonstrate that for a broad range of settings in random attacks, the SVD-based method has high detection rates and low false alarm rates.
An advantage of the proposed detection method is that it is directly built on the SVD-based CF algorithm. There-fore, it requires little extra cost ( O ( mn )where m and Table 8: Results of average push attacks (with 100 bots) for SVD-based detection method when the number of rated items in each bot varies. The method has a small power of detecting average at-tacks when the number of rated items in each bot is around 50 and it becomes completely ineffective when this number becomes larger. #rated ROC Detection False Alarm the number of users and items, respectively) to compute be-lief divergence if the SVD-based algorithm is already incor-porated in a recommendation system. The computational cost of the SVD-based CF algorithm is O ( l  X  ( m 2 n + mn 2 if a deterministic SVD computation method is used and is O ( l  X  kmn log( mn )) if a Lanczos approximation method is used to compute the top k singular vectors [7], where l is the number of iterations in the EM procedure. Several fast SVD approximation methods have been applied to recom-mendation systems, and interested readers can refer to [3, 20].

Based on the performance of our detection method on ran-dom attacks, we suppose it might be effective for detecting other attack models in which random ratings are used, e.g. , the bandwagon attack in [12]. If that is true, attackers will need to incur a higher cost for mounting successful attacks by either using item average ratings instead of random ones or injecting more bots in each of which many fewer random ratings are used.
In this paper, we empirically show that an SVD-based algorithm [19] is much more resistant to random and aver-age shilling attacks than two representative memory-based algorithms [8, 17]. Moreover, a detection method built on the SVD-based algorithm is demonstrated to be effective in detecting random attacks. Previous papers [5, 16, 19] have shown that the SVD-based algorithm has the same or better recommendation performance than memory-based algorithms. Our study suggests one more reason for recom-mendation system operators to prefer this algorithm.
Since research on shilling attacks in recommendation sys-tems is relatively new in the literature, there are a few re-search directions available for future work. One is to ex-periment with other model-based CF algorithms ( e.g. ,[9] and [11]) and hybrid CF algorithms ( e.g. , [14] and [18]) to examine how effective shilling attacks are against them. A second is to explore whether there are specific attack mod-els that have a larger likelihood of success in attacking the SVD-based algorithm and other model-based algorithms. A third possibility is to find new detection methods that can effectively detect average attacks.
 This material is based in part upon work supported by the National Science Foundation under award number IDM 0308229. Any opinions, findings, and conclusions or recom-mendations expressed in this publication are those of the au-thors and do not necessarily reflect the views of the National Science Foundation. We thank the anonymous reviewers for their comments, which helped us improve the quality of the paper. [1] Y. Azar, A. Fiat, A. Karlin, F. McSherry, and J. Saia. [2] D. Billsus and M. J. Pazzani. Learning collaborative [3] M. Brand. Fast online SVD revisions for lightweight [4] R.Burke,B.Mobasher,R.Bhaumik,and [5] J. Canny. Collaborative filtering with privacy via [6] K. Goldberg, T. Roeder, D. Gupta, and C. Perkins. [7] G. Golub and C. V. Loan. Matrix Computations (3rd [8] J.L.Herlocker,J.A.Konstan,A.Borchers,and [9] T. Hofmann. Latent semantic models for collaborative [10] S. K. Lam and J. Riedl. Shilling recommender systems [11] B. Marlin. Modeling user rating profiles for [12] B. Mobasher, R. Burke, R. Bhaumik, and [13] M. O X  X ahony, N. Hurley, N. Kushmerick, and [14] D. M. Pennock, E. Horvitz, S. Lawrence, and C. L. [15] P. Resnick, N. Iacovou, M. Suchak, P. Bergstorm, and [16] B. M. Sarwar, G. Karypis, J. A. Konstan, and [17] B. M. Sarwar, G. Karypis, J. A. Konstan, and [18] A. I. Schein, A. Popescul, L. H. Ungar, and D. M. [19] N. Srebro and T. Jaakkola. Weighted low rank [20] S. Zhang, W. Wang, J. Ford, F. Makedon, and
