 task of Entity Resolution is to find similar record pairs based on a specified similarity similarity function for these two records is above a given threshold. Similarity join [2, 3, 4] is one of effective approaches to implement ER over one or two datasets of in-terest. Generally, similarity joins take as input two datasets, and identifies all pairs of dataset, i.e., employ (self) similarity join on the same dataset, we can perform a clus-join. Web document clustering [5] and replicated web collections [6] can be achieved by clustering web documents based on their similarity, community discovery in a social network site can be achieved by mining graph data based on the similarity be-tween nodes[7], and large dense graphs can be obtained by similarities[8]. 
With the rapid development of data mining applications and ever-growing scale of social networking services as an example. The data increment of Facebook has reached up to 500TB per day, producing 27 million times Like Button clicks. Moreo-formed in an efficient and scalable fashion. If we compute every pair of records, the cost, traditional centralize approaches have the obvious limitation on the performance paper, we aim to address the performance issue by exploiting the power of distributed computing. 
In recent years, the works of similarity join for ER have received growing research momentum. These works typically adopt a two-phase approach: (i) generate candidate pairs and (ii) verify candidate pairs [4]. In the candidate generation phase, the goal is to filter record pairs that can't be matched, in order to minimize the amount of candi-On the other hand, the verification phase calculates the similarity of candidate pair to conventional approaches. Recently, several techniques have been proposed for the similarity join based on the MapReduce framework which provides the ability of for distributed processing. However, the performance surfers from the data skew which caused deteriorated performance in distributed processing. processing framework for ER , which provides high performance on computing similarity of objects pairs and clustering objects. Many similarity functions have been similarity, and edit distance similarity. Note that each of these similarity functions has been specially designed with some specific kinds of data in mind. This paper aims to token-based algorithms, e.g., Jaccard algorithm. To facilitate parallel similarity joins, we use MapReduce as the framework of distributed processing. In our ER framework, we propose similarity join algorithms based on multiple filtering techniques to reduce tween them. The contributions of this paper are as follows:  X  candidate pairs for efficient Entity Resolution in distributed processing.  X  based on the connection in their similarity graph.  X 
We propose an ER framework based on MapReduce, which integrates the algo-rithm of similarity join and Disjoint Set to support efficiently clustering objects in a distributed environment.  X  paper and to evaluate the efficiency of proposed techniques. 
The rest of the paper is organized as follows: Section 2 introduces the related works. The ER framework based on MapReduce is presented in Section 3.Section 4 rithms integrate multiple filter principles to execute in MapReduce, and the clustering 5. Section 6 concludes the paper. Entity Resolution has been widely studied for data mining applications [6, 9, 10]. Ex-isting research works on ER mainly focus on algorithms for similarity join. Similarity Join is defined as follows: Given two datasets R and S, for a entity-pair (r, s) where r in R and s in S, if similarity measure Sim(r, s) is higher than the given threshold, then the pair (r, s) is returned as the results. Several similarity join techniques [3, 11] have been proposed for processing in-memory and external memory data. There are also techniques [4] which make use of database operators to address similarity join. ment of a string as a bag of words (tokens). Thus, some existing works on the similari-similarity function. There are two popular methods in solving the problem of filtering shold for the exact case. The technique has been proposed in [14] to reduce the amount filter and prefix hash algorithm have also been proposed in [15] for the same purpose. In addition, the position information of prefix introduced in [13] filters the unqualified candidate pairs that have passed the length-filter. The algorithm proposed in [16] gene-rates characters for different types of strings based on the adaptive selection of prefix length. However, it took much time in selecting the length of prefix. tributed processing. MapReduce framework [17] has been applied to improve the effi-ciency of finding all similar pairs from terabytes of data. The basic idea is to partition problem of set-similarity join that runs multiple MapReduce steps to find similar pairs on set-based data. MRSimJoin [19], implemented on Hadoop, focuses on distributing processed in a single node. However, MRSimJoin requires its dataset to lie in a metric space. The work in [20] focuses on analyzing cost to pick the optimal algorithm when using MapReduce. A MapReduce implementation of set similarity proposed in [21] includes three stages, computing data statistics, outputting RID pairs of similar records, vestigated the virtual node method. In this section, we first describe the proposed Entity Resolution framework for cluster-ing, based on the MapReduce model, to improve the efficiency by exploiting distri-steps: 1) matching similar objects based on similarity join, 2) clustering objects based on the graph of similarities, i.e., each connected sub-graph is regarded as a cluster. In each step, we propose a set of MapReduce base d algorithms to partition large datasets and distribute them into multiple nodes. The architecture of our framework for ER is shown in Figure 2. 
In the architecture, we use the Hadoop distributed file system (HDFS) to store data that includes original datasets, similar object pairs generated with similarity joins, and even clustering results. To achieve high performance on massive data, we make use of job is divided into multiple Map tasks and Reduce tasks to execute on multiple nodes. priate nodes. In this architecture, we design two functional components to handle the nent executes a self similarity join on the given dataset, and returns all matched pairs Cluster component cluster objects into clusters based on similar pairs such that mem-bers of a cluster are in similar to each other. In summary, we regard a connected sub graph as a basic cluster of objects. In both phases of similarity join and clustering, algorithms require multiple candidate pairs, it first uses one MapReduce loop to sort elements of objects based on their frequency for selecting objects X  features. Then, in an additional MapReduce loop, Graph Cluster is based on the Disjoin Set algorithm which requires merge groups with iterative function. Thus, we design an algorithm with multiple MapReduce loop for clustering in next section. Section 4.1. Then in Section 4.2, we propose the improved prefix filter algorithms for clustering objects with similarities. 4.1 Preliminaries Given two objects r and s , we use a similarity function, denoted by sim(r, s) , to meas-ure their similarity. In this paper, we focus on the Jaccard similarity on sets or strings which are widely used in data mining and textual applications. Let r and s be two token sets, the Jaccard similarity of r and s is given by Eq. (1): dataset. When the scale of dataset is increasing, the cost of join becomes quite expen-sive. Thus, we propose a prefix filtering technique to address the performance issue in similarity join. The basic idea of prefix filtering is to prune object pairs that cannot be shold is high, the cost of similarity join with prefix filtering will reduce significantly. model, we map objects into distributed nodes based on their prefix elements. This can ensure s and r are mapped into at least one common bucket. r =(CBDF) , where their elements are ordered based on global frequency in the dataset, and the threshold is specified as  X  = 0.7 . The prefix size of each object is computed by ( r , r 3 ) and ( r 2 , r 3 ) since they had no common prefix elements. in the prefix(r) . Thus, the position information is further used to improve filtering per-and s , the maximum number of their common elements is min(p, q) . Thus, the size of element intersection is at most |i-j|+min(p, q) , and the size of elements union is at least max(L s , L r ) . We use SimP(r, s) to denote the maximum value of estimate similarity for fication. So the value of SimP(r, s) must satisfy Eq. (2). fective to prune the number of the candidate pairs. Therefore we can propose a proper filter performance. 4.2 The All Prefix Filter for Similarity Join Considering the cases where two objects may have more than one common prefix, an efficient way is to compute them in one bucket based on one common element and As the prefix B must have been dealt in the B bucket, so the computation in the bucket A is redundant and thus can be avoid. 
To filter the candidate pairs, existing works have proposed the position filter prin-and whether the estimated size of the intersections (r, s) is close to the real length. As a result, a larger number of candidate pairs may still need to be verified. SimE(r, s) is defined by Eq. (3) below: elements in prefixes that do not exist in both objects, so we can get c+min(p',q')&lt;|i-SimJ(s,r), the appjoin filter can more efficient filter candidate pairs for verification. 4.3 Clustering Objects with Similarities larities. We regard the similar relationship between objects as a graph data, and each connected sub graph is a cluster. Therefore, the problem of finding clusters of objects path between x and y . Algorithm 1. The MapReduce-based Disjoint Sets algorithm 1. MAP (key= unused ,value= text ) 2. key =r; value = ( min ( HashNO,r,s ) ,&lt;r,s,sim&gt; ); output(key , value); 3. REDUCE (key= item ,values= iterator ) 4. while iterator .hasnext() 5. HashNo=listMerger (results, it.next()); count++; 6. if count ==1 7. counter .increment(1) 8. while resultList 9. output( record , HashNO ); 10. MAP (key= unused , value= text ) 11. output(value+key , value); 12. REDUCE (key= item , values= iterator ) 13. while 14. minHashNo =min( minHashNo ,values.next); 15. output(key, HashNo ); 
Since we use MapReduce model to execute the similarity join with our appjoin algorithm, all similar pairs are stored in distributed nodes. We need combine objects of sub graphs as a cluster. To achieve this problem, we use the algorithm based on Disjoint Sets . We first annotate each object in dataset with a unique ID. Then in each MapReduce node, all similar pairs are sorted based on the smaller object IDs in them. Therefore, the similari ty graph is transformed into a directed graph in which each edge always directs from an object node with larger ID to an object node with smaller ID. Finally, we execute multiple MapReduce tasks to merge connected graphs with algorithm based on Disjoint Sets . The algorithm of algorithm is all connected sub graphs that are mapping to clustering groups. 
However, the Disjoint Set algorithm may include too many MapReduce loops if the graph contains long paths between nodes. To reduce the number of Ma-pReduce loops, we further propose a cache-based algorithm. The algorithm ject ID of each similar pair. Then a merge operation is executed on two hash pairs with their cluster ID. The detail of algorithm is shown in Algorithm 2. 
Algorithm 2. The Cache Merge Algorithm 1. Intiliztion (rtable, ntable) 2. Map(key= unused , value= text ) 3. record =parser(text); 4. if rtable.size  X  c 5. output(rtable); 6. rtable .clean(); ntable .clean(); 7. rtable .add(value); 8. ntable .update(record. s ); ntable .update(record. r ); 9. Close() 10. output( table ); 5.1 Experimental Setup techniques, and conduct an experimental evaluation. The framework is deployed on a memory and 3.1GHz four Core i3-2100 Processor with Gigabit Ethernet. The operat-ing system of each node is Red Hat Enterprise Linux 6.1(Santiago). 
In our experiments, we use the real world datasets collected from DBLP and Cite-seerX. The DBLP dataset consists of almost 1.2 million records which include informa-tion about conference papers, conferences, journals, authors and so on. Our experiments mainly use conference papers. The CiteseerX data includes more than 1.5 million ments, we execute similarity join algorithms to achieve entity evaluation task. 5.2 Experimental Results 1) The performance on different data size rithms with different scale of data. We use various sizes of experimental data to com-pare the performances of our appjoin method with ppjoin method (which serves as the range from 5 to 25 million objects. scale data. From the results, we find that our appjoin method has better performance on a large data set. With the scale of data increasing, appjoin method can achieve a better performance than the ppjoin method. In our experiments, we also measure the number of filtered record pairs before the verification stage of entity resolution. As shown the large data set generates much more pairs and our filter method is more efficient to filter unqualified candidate pairs as data size increases. 2) The performance on different threshold We also evaluate the performances of different methods under different values of simi-larity thresholds, varied from 0.65 to 0.95. The evaluation is performed using a dataset outperforms the ppjoin method, especially when the threshold has a lower value. 
As shown in Figure 8, the differences between the compared two methods are sig-thod can filter more candidate pairs than ppjoin . 3) The performance on cache-based algorithm We further evaluate the performances of our cache-based algorithm for clustering under setting with 100 million cached similar pairs. Figure 9 shows the number of MapReduce loops of no-cache and cache-based method for the Disjoint Set under different thresholds. This experimental result proves that the cache-based algorithm achieves a higher perfor-This is because connected sub graphs hold a larger scale when the threshold is low. In this paper, we have studied the problem of using Entity Resolution to support effi-MapReduce model was proposed for achieving clustering tasks with the similarity fore verify stage and propose a new appjoin algorithm for similarity join to improve have implemented our method and compared with a state-of-the-art method, i.e., ppjoin . Experimental results on real-world datasets show that our method achieves high performance for similarity join, especially when a lower value of similarity thre-shold is setup for large-scale data clustering. Acknowledgement. Project supported by the National Basic Research Program of China (973 Program) under grant No. 2012CB316201, the National Natural Science Foundation of China (Grant No. 61003060), the Fundamental Research Funds for the Central Universities (Grant No. N110404010), and the 863 High Technology Founda-tion of China (Grant No. 2012AA010704). 
