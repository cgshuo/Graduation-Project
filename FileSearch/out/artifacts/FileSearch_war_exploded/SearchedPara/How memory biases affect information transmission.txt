 Most of the facts that we know about the world are not learned t hrough first-hand experience, but are the result of information being passed from one person to another. This raises a natural question: how are such processes of information transmission affecte d by the capacities of the agents involved? Decades of memory research have charted the ways in which our memories distort reality, changing the details of experiences and introducing events that neve r occurred (see [1] for an overview). We might thus expect that these memory biases would affect the t ransmission of information, since such a process relies on each person remembering a fact accuratel y.
 The question of how memory biases affect information transm ission was first investigated in detail as showing that people were biased by their own culture when t hey reconstruct information from memory, and that this bias became exaggerated through seria l reproduction. Serial reproduction has become one of the standard methods used to simulate the pr ocess of cultural transmission, and several subsequent studies have used this paradigm (e.g., [ 3, 4]). However, this phenomenon has not been systematically and formally analyzed, and most of thes e studies have used complex stimuli that how information is changed by serial reproduction and how th is process relates to memory biases. how information should change when passed along a chain of ra tional agents.
 Biased reconstructions are found in many tasks. For example , people are biased by their knowledge of the structure of categories when they reconstruct simple stimuli from memory. One common effect of this kind is that people judge stimuli that cross bo undaries of two different categories to be further apart than those within the same category, althou gh the distances between the stimuli are the same in the two situations [6]. However, biases need n ot reflect suboptimal performance. If we assume that memory is solving the problem of extracting and storing information from the noisy signal presented to our senses, we can analyze the proc ess of reconstruction from memory as a Bayesian inference. Under this view, reconstructions sho uld combine prior knowledge about the world with the information provided by noisy stimuli. Use of prior knowledge will result in biases, but these biases ultimately make memory more accurate [7].
 If this account of reconstruction from memory is true, we wou ld expect the same inference process to occur at every step of serial reproduction. The effects of memory biases should thus be accumu-lated. Assuming all participants share the same prior knowl edge about the world, serial reproduction should ultimately reveal the nature of this knowledge. Draw ing on recent work exploring other pro-cesses of information transmission [8, 9], we show that a rat ional analysis of serial reproduction makes exactly this prediction. To test the predictions of th is account, we explore the special case where the task is to reconstruct a one-dimensional stimulus using the information that it is drawn from a fixed Gaussian distribution. In this case we can precis ely characterize behavior at every step AR(1), process, allowing us to draw on a variety of results ch aracterizing such processes. We use these predictions to test the Bayesian models of serial repr oduction in two laboratory experiments and show that the predictions hold serial reproduction both between-and within-subjects. The plan of the paper is as follows. Section 2 lays out the Baye sian account of serial reproduction. In Section 3 we show how this Bayesian account corresponds to the AR(1) process. Sections 4 and 5 present two experiments testing the model X  X  prediction th at serial reproduction reveals memory biases. Section 6 concludes the paper. We will outline our Bayesian approach to serial reproductio n by first considering the problem of reconstruction from memory, and then asking what happens wh en the solution to this problem is repeated many times, as in serial reproduction. 2.1 Reconstruction from memory Our goal is to give a rational account of reconstruction from memory, considering the underlying computational problem and finding the optimal solution to th at problem. We will formulate the problem of reconstruction from memory as a problem of inferr ing and storing accurate information about the world from noisy sensory data. Given a noisy stimul us x , we seek to recover the true state of the world  X  that generated that stimulus, storing an estimate  X   X  in memory. The optimal solution to this problem is provided by Bayesian statistics. Previou s experience provides a  X  X rior X  distri-distribution p (  X  | x ) by applying Bayes X  rule to store. Perhaps the simplest such scheme is sampling from t he posterior, with  X   X   X  p (  X  | x ) . This analysis provides a general schema for modeling recons truction from memory, applicable for any form of x and  X  . A simple example is the special case where x and  X  vary along a single continuous dimension. In the experiment presented later in the paper we take this dimension to be the width of a fish, showing people a fish and asking them to reco nstruct its width from memory, but the dimension of interest could be any subjective quantity s uch as the perceived length, loudness, Gaussian distribution, with  X   X  N (  X  distribution centered on  X  , x |  X   X  N (  X ,  X  2 being N (  X x + (1  X   X  )  X  should be a compromise between the observed value x and the mean of the prior  X  of the compromise being set by the ratio of the noise in the dat a  X  2 This model thus predicts a systematic bias in reconstructio n that is not a consequence of an error of memory, but the optimal solution to the problem of extractin g information from a noisy stimulus. Huttenlocher and colleagues [7] have conducted several exp eriments testing this account of memory biases, showing that people X  X  reconstructions interpolat e between observed stimuli and the mean of a trained distribution as predicted. Using a similar notion of recosntruction from memory, Hemmer and Steyvers [11] have conducted experiments to show that pe ople formed appropriate Bayesian reconstructions for realistic stimuli such as images of fru it, and seemed capable of drawing on prior knowledge at multiple levels of abstraction in doing so. 2.2 Serial reproduction With a model of how people might approach the problem of recon struction from memory in hand, we are now in a position to analyze what happens in serial repr oduction, where the stimuli that sees a stimulus x stores a sample  X   X  from this distribution in memory. When asked to produce a reco nstruction, the participant generates a new value x distribution, substituting  X   X  for  X  . This value of x Viewed from this perspective, serial reproduction defines a stochastic process: a sequence of random variables evolving over time. In particular, it is a Markov c hain, since the reconstruction produced transition probabilities of this Markov chain are being the probability that x tending to  X  ( x Identifying this distribution will help us understand the c onsequences of serial reproduction. The transition probabilities given in Equation 2 have a spec ial form, being the result of sampling a value from the posterior distribution p (  X  | x [8, 9]. The stationary distribution of this Markov chain is t he prior predictive distribution being the probability of observing the stimulus x when  X  is sampled from the prior. This happens reproduction: after many reproductions, the stimuli being produced will be sampled from the prior distribution assumed by the participants. Convergence to t he prior predictive distribution provides those biases would be reflected in the prior.
 distribution. Applying Equation 2 using the results summar ized in the previous section, we have x 3 indicates that the stationary distribution is N (  X  is slow since  X  faster. Since  X  = 1 / (1 +  X  2 perceptual noise and the variance of the prior distribution ,  X  2 faster convergence, since the specific value of x results in slower convergence, since x The special case of serial reproduction of one-dimensional stimuli can also give us further insight into the consequences of modifying our assumptions about st orage and reconstruction from mem-autoregressive process, abbreviated to AR(1). The general form of an AR(1) process is where  X  each variable is being predicted from that which precedes it in sequence. AR(1) models are widely used to model timeseries data, being one of the simplest mode ls for capturing temporal dependency. Just as showing that a stochastic process is a Markov chain pr ovides information about its dynamics and asymptotic behavior, showing that it reduces to an AR(1) process provides access to a number distribution that is Gaussian with mean c/ (1  X   X  ) and variance  X  2 a lag of n is  X  n  X  2 to its stationary distribution at a rate determined by  X  .
 It is straightforward to show that the stochastic process de fined by serial reproduction where a sam-ple from the posterior distribution on  X  is stored in memory and a new value x is sampled from the where  X  = 1 / (1 +  X  2 with c = (1  X   X  )  X  find the stationary distribution by substituting these valu es into the expressions given above. Identifying serial reproduction for single-dimensional s timuli as an AR(1) process allows us to relax our assumptions about the way that people are storing and rec onstructing information. The AR(1) model can accommodate different assumptions about memory s torage and reconstruction. 1 All these ways of characterizing serial reproduction lead to the same basic prediction: that repeatedly recon-structing stimuli from memory will result in convergence to a distribution whose mean corresponds to the mean of the prior. In the remainder of the paper we test t his prediction.
 In the following sections, we present two serial reproducti on experiments conducted with stimuli that vary along only one dimension (width of fish). The first ex periment follows previous research for the next. The second experiment uses a within-subjects d esign in which each person reconstructs the memory biases of individuals. dimensional quantity  X  the width of a schematic fish  X  that wou ld serve as a prior for reconstructing similar stimuli from memory. The two distributions differe d in their means, allowing us to examine whether the mean of the distribution produced by serial repr oduction is affected by the prior. 4.1 Method The experiment followed the same basic procedure as Bartlet t X  X  classic experiments [2]. Participants were 46 members of the university community. Stimuli were th e same as those used in [7]: fish with the fish, ranging from 2.63cm to 5.76cm. The stimuli were pres ented on an Apple iMac computer by a Matlab script using PsychToolBox extensions [13, 14].
 Participants were first trained to discriminate fish-farm an d ocean fish. The width of the fish-farm fish was normally distributed and that of the ocean fish was uni formly distributed between 2 . 63 and 5 . 75 cm. Two groups of participants were trained on one of the two d istributions of fish-farm fish (prior distributions A and B), with different means and same standard deviations. In condition A,  X  0 = 3 . 66 presented at the center of a computer monitor and participan ts tried to predict which type of fish it was by pressing one of the keys on the keyboard and they receiv ed feedback about the correctness of fish. The procedure was the same as the training block except t here was no feedback. The training-testing loop was repeated until the participants reached 80 % correct in using the optimal decision strategy. If a participant could not pass the test after five i terations, the experiment halted. farm. On each trial, a fish stimulus was flashed at the center of the screen for 500ms and then disappeared. Another fish of random size appeared at one of fo ur possible positions near the center of screen and the participants used the up and down arrow keys to adjust the width of the fish until The first participant tried to memorize these random samples and then gave the reconstructions. Each subsequent participant in each condition was then pres ented with the data generated by the previous participant and they again tried to reconstruct th ose fish widths. Thus, each participant X  X  data constitute one slice of time in 120 serial reproduction chains.
 distributions had drifted. Ten participants X  data were exc luded from the chains based on three cri-teria: 1) final testing score was less than 80% of optimal perf ormance; 2) the difference between the reproduced value and stimulus shown was greater than the difference between the largest and the smallest stimuli in the training distribution on any tri al; 3) there were no adjustments from the starting value of the fish width for more than half of the trial s. 4.2 Results and Discussion plots for the two conditions. The mean reconstructed fish wid ths produced by the first participants in conditions A and B, although the overall size of the differ ence is reduced and the means of the stationary distributions were lower than those of the distr ibutions used in training. exactly what we see in Figure 1. The correlation between the s timulus x is the correlation between the AR(1) model X  X  predictions an d the data, and this correlation was high we examined whether the Markov assumption underlying our an alysis was valid, by computing the plot for x correlation between x conditions, being 0.04 and 0.01 in conditions A and B respect ively (both p &lt; 0 . 05 ). The between-subjects design allows us to reproduce the proc ess of information transmission, but our analysis suggests that serial reproduction might also h ave promise as a method for investigating the memory biases of individuals. To explore the potential o f this method, we tested the model with a within-subjects design, in which a participant X  X  rep roduction in the current trial became the iment thus produced a chain of reproductions. Each particip ant produced three such chains, starting from widely separated initial values. Control trials and ca reful instructions were used so that the participants would not realize that some of the stimuli were their own reproductions. 5.1 Method Forty-six undergraduates from the university research par ticipation pool participated the experiment. The basic procedure was the same as Experiment 1, except in th e reproduction phase. Each partici-participants saw were their own reproductions in the previo us trials in the same chain. To prevent participants from realizing this fact, chain order was rand omized and the Markov chain trials were intermixed with 40 control trials in which widths were drawn from the prior distribution. 5.2 Results and Discussion Participants X  data were excluded based on the same criteria as used in Experiment 1, with a lower testing score of 70% of optimal performance and one addition al criterion relevant to the within-for convergence being that the lower and upper chains must cr oss the middle chain. After these screening procedures, 40 participants X  data were accepted , with 21 in condition A and 19 in condi-the chains (trials 21-40) were analyzed further.
 The locations of the stationary distributions were measure d by computing the means of the repro-Figure 2: Stimuli, training distributions and stationary d istributions for Experiment 2. Each data the 95% confidence interval around the mean for each conditio n. Figure 3: Chains and stationary distributions for individu al participants from the two conditions. participant X  X  data. (d) Autoregression for the last 20 iter ations of each participant X  X  data. 2 shows the mean values for these two conditions. The basic pr ediction of the model was borne exposed to data suggesting a different prior. However, the m eans were in general lower than those Figure 3 shows the chains, training distributions, the Gaus sian fits and the autoregression for the second half of the Markov chains for two participants in the t wo conditions. Correlation analysis showed that the AR(1) model X  X  predictions are highly correl ated with the data generated by each participant, with mean correlations being 0.90 and 0.81 for conditions A and B respectively. The correlations are significant for all participants. The mean partial correlation between x given x participant in condition B. We have presented a Bayesian account of serial reproduction , and tested the basic predictions of this account using two strictly controlled laboratory experime nts. The results of these experiments are consistent with the predictions of our account, with serial reproduction converging to a distribution that is influenced by the prior distribution established thr ough training. Our analysis connects the biases revealed by serial reproduction with the more genera l Bayesian strategy of combining prior knowledge with noisy data to achieve higher accuracy [7]. It also shows that serial reproduction can be analyzed using Markov chains and first-order autoregress ive models, providing the opportunity to draw on a rich body of work on the dynamics and asymptotic be havior of such processes. These connections allows us to provide a formal justification for t he idea that serial reproduction changes in storage and reconstruction from memory.
 Acknowledgments This work was supported by grant number 0704034 from the Nati onal Science Foundation.
