 We pro vide a summary of the Workshop on Data Mining Us-ing Matrices and Tensors (DMMT'08) held in conjunction with ACM SIGKDD 2008, on August 24th in Las Vegas, USA. Ab out 100 people attended the workshop. We rep ort in detail about the researc h issues addressed in the talks at the workshop. More information about the workshop can be found at http://www.cs.fiu.edu/~taoli/kd d08-workshop . The eld of pattern recognition, data mining and mac hine learning increasingly adapt metho ds and algorithms from adv anced matrix computations, graph theory and optimiza-tion. Prominen t examples are spectral clustering, non-negativ e matrix factorization, Principal comp onen t analysis (PCA) and Singular Value Decomp osition (SVD) related clustering and dimension reduction, tensor analysis suc h as 2DSVD and high order SVD, L-1 regularization, etc. Compared to probabilistic and information theoretic approac hes, matrix-based metho ds are fast, easy to understand and implemen t; they are esp ecially suitable for parallel and distributed-memory computers to solv e large scale challenging problems suc h as searc hing and extracting patterns from the entire Web. Hence the area of data mining using matrices and tensors is a popular and gro wing area of researc h activities. This workshop presen ts recen t adv ances in algorithms and metho ds using matrix and scien ti c computing/applied math-ematics for mo deling and analyzing massiv e, high-dimensional, and nonlinear-structured data. One main goal of the work-shop is to bring together leading researc hers on man y topic areas (e.g., computer scien tists, computational and applied mathematicians) to assess the state-of-the-art, share ideas and form collab orations. We also wish to attract practition-ers who seek novel ideals for applications. In summary , this workshop striv es to emphasize the follo wing asp ects: The Topic areas for the workshop include (but are not lim-ited to) the follo wing: Metho ds and algorithms: Application areas: The 2008 Workshop on Data Mining using Matri-ces and Tensors (DMMT'08) is the rst workshop on this theme held ann ually with the SIGKDD Conference. Through the workshop, we exp ect to bring together leading researc hers on man y topic areas (e.g., computer scien tists, computational and applied mathematicians) to assess the state-of-the-art, share ideas and form collab orations. We also wish to attract practitioners who seek novel ideals for applications.
 The program of the workshop included a keynote talk by Prof. Mic hael I. Jordan from Univ ersit y of California at Berk eley , three invited talks by Prof. Christos Faloutsos from Carnegie Mellon Univ ersit y, Prof. Haesun Park from Georgia Institute of Technology , and Prof. Lenore R. Mullin from NSF CISE CCF Theoretical Foundations Clusters. There are also sev en researc h pap er presen tations. Ab out 100 peo-ple attended the workshop. The on-line pro ceedings of the workshop is available at http://www.cs.fiu.edu/~taoli /kdd08-workshop/ . The workshop program is started by a keynote talk entitled "sucien t dimension reduction" by Prof. Mic hael I. Jordan from Univ ersit y of California at Berk eley . The problem of "sucien t dimension reduction" (SDR) is that of nding a subspace S suc h that the pro jection of the covariate vector X onto S captures the statistical dep endency of the resp onse Y on X . Prof. Jordan rst presen ted a general overview of the SDR problem, focusing on the form ulation of SDR in terms of conditional indep endence. He also discussed some of the popular algorithmic approac hes to SDR, particularly those based on inverse regression. Finally , He describ ed a new metho dology for SDR whic h is based on the character-ization of conditional indep endence in terms of conditional covariance operators on repro ducing kernel Hilb ert spaces (a general characterization of conditional indep endence that is of indep enden t interest). The workshop program also included three invited talks by Prof. Christos Faloutsos from Carnegie Mellon Univ ersit y, Prof. Haesun Park from Georgia Institute of Technology , and Prof. Lenore R. Mullin from NSF CISE CCF Theoret-ical Foundations Clusters.
 Prof. Christos Faloutsos's talk is about surprising patterns in large graphs. He review ed some 'laws' for static as well as evolving graphs (e.g., how do graphs look like? How do they evolve over time? How can we generate realistic-looking graphs?). He then pro vided some recen t disco veries on blogs and in uence propagation and describ ed some tools to help us analyze large graphs (e.g., The 'Kronec ker' gener-ators, The Cen terPiece subgraphs to spot cen tral nodes in a comm unit y, and incremen tal tensor analysis to spot anoma-lies in Internet trac data). Finally , he discussed emerging map/reduce approac h and its impact on large graph mining. Prof. Haesun Park talk ed about linear discriminan t analysis (LD A) and its generalizations. Linear Discriminan t Analy-sis (LD A) has been utilized as a metho d of choice for di-mension reduction of clustered data. Prof. Park presen ted Linear Discriminan t Analysis (LD A) has been utilized as a metho d of choice for dimension reduction of clustered data. The LD A/GSVD can be nonlinearized by using kernel func-tions. Some exp erimen tal results are presen ted in text clas-si cation, facial recognition, and ngerprin t classi cation, to demonstrate the e ectiv eness of the prop osed metho ds. Prof. Lenore R. Mullin of National Science Foundation gave a full presen tation about the new NSF/CISE initiativ es in numerical computation, optimization, high performance computing. She esp ecially emphasized tensor analysis as the rise of multi-linear arra ys in data mining. Audience ask ed Dr. Mullin man y questions about NSF funding opp ortuni-ties. The workshop program included sev eral researc h presen ta-tions.
 Chris Ding from UT Arlington presen ted some recen t the-oretical progress in tensor clustering and error Bounds. He and his colleagues recen tly dev elop ed theoretical pro of to sho w that the widely used ParaF ac and HOSVD tensor de-comp ositions are in fact performing sim ultaneous K-means data clustering and subspace factorization. This work ex-tends the earlier dev elopmen t on the equiv alence between K-means clustering and principal comp onen t analysis (PCA), and the equiv alence between K-means clustering and non-negativ e matrix factorization (NMF). They also presen ted lower and upp er bounds on the tensor reconstruction er-rors, similar to the Eckart-Y oung error form ulation for Sin-gular Value decomp osition (SVD). Exp erimen ts on 3 image datasets are presen ted.
 Evrim Acar from Sandia National Lab oratories introduced their work on understanding Epilepsy seizure structure us-ing tensor analysis. She introduced mathematical mo dels based on multi-mo dal data construction and analysis with a goal of understanding epilepsy seizure dynamics and de-veloping automated and objectiv e approac hes for the anal-ysis of large amoun ts of scalp electro encephalogram (EEG) data. Seizure recognition aims to automatically di eren tiate between seizure and non-seizure perio ds. In their work, the multi-c hannel EEG signals were rst rearranged as a third-order tensor with mo des: time epochs, features and chan-nels. Then a multilinear regression mo del, i.e., Multilinear Partial Least Squares (N-PLS), whic h is the generalization of Partial Least Squares (PLS) regression to higher-order datasets, was used to mo del the tensor. The two-step ap-proac h facilitates EEG data analysis from multiple channels represen ted by sev eral features from di eren t domains. She sho wed that their approac h gave promising results in terms of iden tifying seizure origins as well as marking seizure pe-riods.
 In their pap er, S.K. Tasoulis (Univ ersit y of Patras) and D.K. Tasoulis (Imp erial College London) prop osed an impro ve-men t of the Principal Direction Divisiv e Partitioning algo-rithm from three persp ectiv es: (1) how to split a cluster, (2)whic h cluster to split, and (3) stopping criterion. Their prop osed algorithm merges concepts from densit y estimation and pro jection-based metho ds towards a fast and ecien t clustering algorithm, capable of dealing with high dimen-sional data. Exp erimen tal results sho wed impro ved parti-tioning performance compared to other popular metho ds. They also explored the problem of automatically determin-ing the num ber of clusters.
 Vacla v Snasel (Technical Univ ersit y of Ostra va) et al. pro-posed two metho ds for boolean matrix factorization: an ar-ti cial neural net work based boolean factorization and a ge-netic algorithm for boolean matrix factorization. The neu-ral net work boolean factorization is based on the Hop eld-like neural net work mo del while the genetic algorithm based boolean factorization mak es use of a constructiv e algorithm for suggesting base vectors. Exp erimen ts were also con-ducted to evaluate the two prop osed algorithms.
 Motiv ated by the observ ation that simple reform ulation of Gaussian pro cesses can lead to much faster execution times on graphs, Thomas Gartner and Shank ar Vembu from Fraun-hofer Institute IAIS, German y presen ted sev eral strategies for ecien t implemen tations of kernel metho ds with graph kernels. In particular, regularized least squares and supp ort vector mac hine were discussed in detail to illustrate these strategies. The authors also sho wed how to com bine these strategies with other popular algorithms for graphs, includ-ing graph ranking algorithms and low dimensional embed-ding algorithms. A toolkit is implemen ted in python for regularized least squares and supp ort vector mac hine. In their work, Ship eng Yu (Siemens Medical Solutions), Jinbo Bi (Siemens Medical Solutions) and Jieping Ye (Arizona State Univ ersit y) introduced the probabilistic higher-order PCA (PHOPCA), a family of probabilistic mo dels for 2D (and higher-order) data. They sho wed that PHOPCA re-covers the optimal solutions of sev eral PCA-st yle algorithms under mild conditions. Ecien t EM-t ype algorithms were deriv ed for learning, with less time complexit y than the non-probabilistic coun terparts. Sev eral extensions of PHOPCA were also discussed. Some empirical results were presen ted using face images, USPS handwritten digits and a real ap-plication in cardiac view recognition of echocardiogram. It has been sho wn that man y SVM mo dels can be form u-lated into quadratic programming while the path-tracing for SVMs (e.g., the task of tracing the regularized piecewise lin-ear solution path for SVMs) can be attac ked by parametric quadratic programming (PQP). Zhili Wu (Hong Kong Bap-tist Univ ersit y) et al. considered the relation between path-tracing for SVMs and the generalized mean-v ariance port-folio optimization from a PQP view. The relation allo ws the path-tracing task to be handled by tailoring the critical line algorithm (CLA) originally prop osed for mean-v ariance portfolio optimization. The CLA algorithm systematically utilizes the equalit y and bounding constrain ts in the PQP form ulation and leads to a robust one-p er-iteration approac h based on Karush-Kuhn-T ucker conditions. Work General Chair Hongyuan Zha, Georgia Institute of Technology Work Co-c hairs Chris Ding, Univ ersit y of Texas at Arlington Tao Li, Florida International Univ ersit y Shengh uo Zhu, NEC Lab oratories America Committee Mem bers Tamm y Kolda, Sandia National Labs Jesse Barlo w, Penn State Univ ersit y Mic hael Berry , Univ ersit y of Tennessee Yun Chi, NEC Lab oratories America Lars Elden, Linkping Univ ersit y, Sweden Christos Faloutsos, Carnegie Mellon Univ ersit y Estratis Gallop oulos, Univ ersit y of Patras Joydeep Ghosh, Univ ersit y of Texas at Austin Ming Gu, Univ ersit y of California, Berk eley Mic hael Jordan, Univ ersit y of California, Berk eley Yuanqing Lin, Univ ersit y of Pennsylv ania Huan Liu, Arizona State Univ ersit y Mic hael Ng, Hong Kong Baptist Univ ersit y Haesun Park, Georgia Tech Wei Peng, Xero x Researc h Rob ert Plemmons, Wake Forest Alex Pothen, Old Domino Univ ersit y Yousef Saad, Univ ersit y of Minnesota Horst Simon, Lawrence Berk eley National Lab oratory Fei Wang, Florida International Univ ersit y Jieping Ye, Arizona State Univ ersit y Kai Yu, NEC Lab oratories America Hongyuan Zha, Georgia Tech Zhongyuan Zhang, Chinese Academ y of Sciences Most submissions were review ed and discussed by two re-view ers and workshop co-c hairs. We are very indebted to all program committee mem bers who help ed us organize the workshop and review ed the pap ers very carefully . We would also like to thank all the authors who submitted their pap ers to the workshop; they pro vided us with an excellen t workshop program. More information about the workshop can be found at http://www.cs.fiu.edu/~taoli/ kdd08-workshop/ .

