 With the ongoing growth of the World Wide Web and the expanding use of different lan-guages, the need for cross-language models that retrieve relevant documents becomes more pressing than ever. Cross-language information retrieval deals with the retrieval of documents written in a language different from the language of the user X  X  query. At the time of retrieval the query in the source language is typically translated into the target language of the documents with the help of a machine-readable dictionary or machine translation system. Translation dictionaries do not exist for every language pair, and they are usually trained on large parallel corpora, where each document has an exact translation in the other language, or are hand-built. Parallel corpora are not available for each language pair. In contrast , comparable corpora in which documents in the source and the target language contain similar content, are usually available in abundance. In this paper we address the question whether suitable cross-language re-trieval models can be built based on the interlingual topic representations learned from comparable corpora. We accomplish this goa l by means of a cross-language generative model, i.e., bilingual Latent Dirichlet Allocation (BiLDA), trained on a comparable cor-pus such as one composed of Wikipedia articles. The resulting probabilistic translation model is incorporated in a statistical language model for information retrieval. The lan-guage models for retrieval have a sound statistical foundation and can easily incorporate probabilistic evidence in or der to optimize the cross-language retrieval process.
The contributions of the paper are as follows. Firstly, we show the validity and the potential of training a bilingual LDA model o n bilingual comparabl e corpora. Secondly, we successfully integrate the topic distrib utions resulting from training the bilingual LDA model in several variant retrieval mode ls and perform a full-fledged evaluation of the retrieval models on the standard CLEF test collections. We show that the results obtained by our retrieval models, which do not exploit any linguistic knowledge from a translation dictionary, are competitive with dictionary-based models. Our work makes cross-language information retrieval portable to many different language pairs. Probabilistic topic models such as probabilistic Latent Semantic Indexing [9] and Latent Dirichlet Allocation [1] are both popular means to represent the content of a document. Although designed as generative models for t he monolingual setting, their extension to multilingual domains follows naturally. Cimiano et al. [6] use standard LDA trained on concatenated parallel and comparable docum ents in a document comparison task. Roth and Klakow [23] try to use the standard LDA model trained on concatenated Wikipedia articles for cross-language information ret rieval, but they do not obtain decent results without the additional usage of a machine translation system.

Recently, the bilingual or multilingual LDA model was independently proposed by different authors ([17,14,7,2]) who identify interlingual topics of different languages. These authors train the bilingual LDA model on a parallel corpus. Jagarlamudi and Daum  X  e III [10] extract interlingual topics from c omparable corpora, but use additional translation dictionary information. None of these works apply the bilingual LDA model in a cross-lingual information retrieval setting.

Cross-language information retrieval is a well-studied research topic (e.g., [8,19,24,18]). As mentioned, existing methods rely on a translation dictionary to bridge documents of different languages. In some cases interlingual information is learned based on parallel corpora and correlations found in the paired documents [13], or are based on Latent Semantic Analysis (LSA) applied on a parallel corpus. In the latter case, a singular value decomposition is applie d on the term-by-document matrix, where a document is composed of the concatenated text in the two languages, and after rank re-duction, document and query are projected in a lower dimensional space ([3,15,5,29]). Our work follows this line of thinking, but uses generative probabilistic approaches. In addition, the models are trained on the individual documents in the different lan-guages, but paired by their joint interli ngual topics. Cross-language relevance models [12] have also been applied for the task, but they still require either a parallel corpus or a translation dictionary. LDA-based monolingual retrieval has been described by Wei and Croft [28].

Transfer learning techniques, where knowledge is transfered from one source to an-other, are also used in the frame of cross-language text classification and clustering. Transfer learning bridged by probabilis tic topics obtained via pLSA was proposed by Xue et al. [29] for the task of cross-domain t ext categorization. Recently, knowledge transfer for cross-domain learning to rank the answer list of a retrieval task was de-scribed by Chen et al. [4]. Takasu [26] proposes cross-language keyword recommenda-tion using latent topics. Except for Wang et al. [27], where the evaluation is vague and unsatisfactory (the same dataset is used for training and testing), and relies solely on 30 documents and 7 queries, none of the above works use LDA-based interlingual topics in cross-language retrieval. The topic model we use is a bilingual extension of a standard LDA model, called bilin-gual LDA (BiLDA) ([17,14,7,2]).

As the name suggests, it is an extension of the basic LDA model, taking into account bilingualism and initially designed for paralle l document pairs. We test its performance on a collection of comparable texts where r elated documents are paired, and therefore share their topics to some extent. BiLDA takes advantage of the document alignment by using a single variable that contains the topic distribution  X  . This variable is language-independent, because it is shared by each of th e paired bilingual comparable documents. Algorithm 3.1 summarizes the generative story, while Figure 1 shows the plate model.
Having one common  X  for both of the related documents implies parallelism between the texts, which might not always be the case. Still, we later show that the BiLDA model can provide satisfactory results when traine d on a comparable corpus such as Wikipedia.
The described BiLDA model serves as a framework for modeling our retrieval mod-els. After the training using Gibbs sampling ([25]), two sets of probability distributions are obtained for each of the languages. One s et consists of per-topic word probability distributions, calculated as P ( w i | z k )=  X  S k,i = n notes the total number of times that the topic z k is assigned to the word w i from the vocabulary W S . The formula for a set of per-topic word probability distributions  X  for the target side of a corpus is computed in an analogical manner.

The second set consists of per-document topic probability distributions, calculated as P ( z k | D J )=  X  J,k = n denotes the number of times a word in the document D J is assigned to the topic z k . This section provides a theoretical insight to cross-language retrieval models relying on per-topic word distributions and per-document word distributions. 4.1 LDA-only CLIR Model Given the set { D 1 ,D 2 ,...,D L } of documents in a target language T , and a query Q in a source language S , the task is to rank the documents according to their relevance to the query. We follow the basic approach for using language models in monolingual information retrieval [28]. The probability P ( Q | D J ) that the query Q is generated from the document model D J , is calculated based on the unigram language model:
The main difference between monolingual IR and CLIR is that documents are not in the same language as the query. Thus, one needs to find a way to efficiently bridge the gap between languages. The common approach is to apply translation dictionaries, translate the query and perform monolingual retrieval on the translated query. If a trans-lation resource is absent, one needs to find another solution. We propose to use sets of per-topic word distributions and per-document topic distributions, assuming the shared space of latent topics. We calculate the right-hand side of equation (1) as by using the two BiLDA-related probability distributions  X  S k,i and  X  T J,k . The parameter  X  is an interpolation parameter, while P ( q i | Ref ) is the maximum likelihood estimate of the query word q i in a monolingual source language reference collection Ref .Itgives a non-zero probability for words unobserved during the training of the topic model in case it occurs in the query. Here, we use the observation that latent topics constitute a language-independent space shared between the languages.

The per-topic word distributions for the source language are used to predict the prob-ability that the word q i from the query Q will be sampled from the topic z S k ,andthe per-document topic distributions for the ta rget language to predict the probability that thesametopic z T k (but now in the other language 1 )isassignedtoatokeninthetarget document D J . As LDA is a generative model, we may infer the source or target lan-guage part of a pre-trained bilingual model o n any monolingual collection in the source We can now merge all the steps into one coherent process to calculate the probability P ( Q = q 1 ,q 2 ,...,q m | D J ) ,where Q denotes a query in the source language, and D J denotes a document in the target language. We name this model the LDA-only model : 1. Infer the trained model on a test corpus in the target language to learn P ( z T k | D J ) 2. For each word q 1 ...q m in the query, do: 3. Compute the whole probability score for the given query and the current document This gives the score for one target language document D J . Finally, documents are wish to reverse the language of queries and the language of documents, the retrieval is performed in an analogical manner after the model is inferred on a desired corpus. 4.2 LDA-Unigram CLIR Model The LDA-only CLIR model from Subsection 4.1 can be efficiently combined with other models for estimating P ( w | D ) . If we assume that a certain amount of words from the query does not change across languages (e.g. some personal names) and thus could be used as an evidence for cross-la nguage retrieval, the probability P ( q i | D J ) from (1) may be specified by a document model with the Dirichlet smoothing. We adopt smoothing techniques according to evaluations and fi ndings from [30]. The D irichlet smoothing acts as a length normalization parameter an d penalizes long documents. The model is then: where P mle ( q i | D J ) denotes the maximum likelihood estimate of the word q i in the document D J , P mle ( q i | Coll ) the maximum likelihood estimate in the entire collection Coll ,  X  is the Dirichlet prior, and N d the number of words in the document D J .  X  2 is another interpolation parameter, and P ( q i | Ref ) is the background probability of q i , calculated over the large corpus Ref . It gives a non-zero proba bility for words that have zero occurrences in test collections. We name this model the simple unigram model .
We can now combine this document model with the LDA-only model using linear interpolation and the Jelinek-Mercer smoothing: where P lda is the LDA-only model given by (2), P lex the simple unigram model given by (4), and  X  is the interpolation parameter. We call this model the LDA-unigram model .

The combined model presented here is straightforward, since it directly uses words shared across a language pair. One might also use cognates (orthographically similar words) identified, for instance, with the edit distance ([16]) instead of the shared words only. However, both approaches improve retrieval results only for closely related lan-guage pairs, where enough shared words and cognates are observed. We believe that a more advanced  X  X on-LDA X  part 2 of the document model may result in even higher scores, since knowledge from other translation resources may be used to model the probability P lex ( q i | D J ) . 5.1 Training Collections The data used for training of the models is collected from various sources and varies strongly in theme, style and its  X  X omparableness X . The only constraint on the training data is the need for document alignment, and it is the only assumption our BiLDA model utilizes during training.

The first subset of our training data is the Europarl corpus [11], extracted from pro-ceedings of the European Parliament and c onsisting of 6, 206 parallel documents in English and Dutch. We use only the evidence of document alignment during the train-ing and do not benefit from the  X  X arallelness X  of the sentences in the corpus.
Another training subset is collected from Wikipedia dumps 3 and consists of paired documents in English and Dutch. Since the articles are written independently and by different authors, rather than being direct translations of each other, there is a con-siderable amount of divergence between ali gned documents. Our Wikipedia training sub-corpus consists of 7, 612 documents which vary in length, theme and style 4 .
As a preprocessing step we remove stop words, and our final vocabularies consist of 76, 555 words in English, and 71, 168 words in Dutch. 5.2 Test Collections Our experiments have been conducted on three data sets taken from the CLEF 2001-2003 CLIR campaigns: the LA Times 1994 ( LAT ), the LA Times 1994 and Glasgow Herald 1995 ( LAT+GH ) in English, and the NRC Handelsblad 94-95 and the Algemeen Dagblad 94-95 ( NC+AD ) in Dutch. Statistics of the collections are given in Table 1.
Queries are extracted from the title and description fields of CLEF topics for each year. Stop words have been removed from queries and documents. Table 1(b) shows the queries used for the test collections.

Parameters  X  and  X  for the BiLDA training are set to values 50 /K and 0.01 respec-tively, where K denotes the number of topics following [25]. The Dirichlet parameter  X  in the LDA-unigram retrieval model is set to 1000. The parameters  X  1 and  X  2 are set to negligible values 5 , while we set  X  =0 . 3 , which gives more weight to the topic model. This section reports our experimental results for both English-Dutch CLIR and Dutch-English CLIR. The cross-language topic mode l is trained just once on a large bilingual training corpus. After training, it can be used for both retrieval directions, after we infer it on the appropriate test collection. We have carried out the following experi-ments: (1) we compare our LDA-only model to several baselines that have also tried to exploit latent concept spaces for cross-la nguage information retrieval, such as cross-language Latent Semantic Indexing (cLSI) and standard LDA trained on concatenated paired documents. We want to prove the soundness and the usefulness of the basic LDA-only model and, consequently, other models that might later build upon the foundation established by the LDA-only model. (2) We provide an extensive evaluation over all CLEF test collections with all our retrieval models, and provide a comparison of the best scoring LDA-unigram model with some of the best CLIR systems from the CLEF 2001-2003 campaigns. We have trained our BiLDA model with a different number of topics (400, 1000 and 2200) on the combined EP+Wiki corpus. The main evaluation measure we use for all experiments is the mean average precision (MAP). For several experiments, we additionally pr ovide precision-recall curves. 6.1 Comparison with Baseline Systems The LDA-only model serves as the backbone of other, more advanced BiLDA-based document models. Since we want to make sure that the LDA-only model constructs a firm and sound language-independent foundatio n for building more complex retrieval models, we compare it to state-of-the-art systems which try to build a CLIR system based around the idea of latent concept sp aces: (i) the cross-language Latent Semantic Indexing (cLSI) as described by [3], which constructs a reduced (latent) vector space trained on concatenated paired documents in two languages, and (ii) the standard LDA model trained on the merged document pairs [23].
 We have trained the cLSI model and the standard LDA model on the combined EP+Wiki corpus with 400 and 1000 dimensions (topics) and compared the retrieval scores with our LDA-only model which uses the BiLDA model with the same number of topics. The LDA-only model outscores the other two models by a huge margin. The MAP scores for cLSI and standard LDA are similar and very low, and vary between the MAP of 0.01 and 0.03 for all experiments, which is significantly worse than the results of the LDA-only model. The MAP scores of the LDA-only model for NL 2001, NL 2002, and NL 2003 for K=1000 are 0.1969, 0.1396, and 0.1227, respectively, while the MAP scores for EN 2001, EN 2002, and EN 2003 for K=1000 are 0.1453, 0.1374, and 0.1713, respectively.
 One reason for such a huge difference in scores might be the ability to infer the BiLDA model on a new test collection (due to its fully generative semantics) more accurately. Cross-language LSI for CLIR reported in the literature always uses the same corpus (or subsets of the same corpus) for training and testing, while this setting asks for inferring on a test corpus which is not by any means content-related to a training corpus. BiLDA has a better statistical foundation by defining the common per-document topic distribution  X  , which allows inference on new documents based on the previously trained model and also avoids the problem of overfitting inherent to the pLSI model and, consequently, the cLSI model. Anot her problem with the baseline methods might be the concatenation of document pairs, since one language might dominate the merged document. On the other hand, BiLDA keeps the structure of the original document space intact. 6.2 Comparison of Our CLIR Models Using a Fixed Number of Topics (K=1000) In this subsection, the LDA-only model, the simple unigram model and the combined LDA-unigram model have been evaluated on all test collections, with the number of topics initially fixed to 1000. Table 2 con-tains MAP scores for the LDA-unigram mode l, Figure 2(a) shows the precision-recall values obtained by applying all three models to the English test collections and the Dutch queries, while Figure 2(b) shows the p recision-recall values for the Dutch test collections and the English queries.
 Varying the Number of Topics. The main goal of the next set of experiments was to test the performance of our models if we vary the number of topics set for BiLDA train-ing. We have carried out experiments with the CLIR models relying on BiLDA trained with different numbers of topics (400, 1000 and 2200). Figure 3 shows the precision-recall values of the LDA-only and the LDA-unigram model, while the associated MAP scores of the best scoring LDA-unigram model are presented in Table 2.
 Discussion. As the corresponding figures show, the LDA-only model seems to be too coarse to be used as the only component of an IR model (e.g., due to its limited number of topics, words in queries unobserved during training). However, the combination of the LDA-only and the simple unigram model, which allows retrieving relevant docu-ments based on shared words across the languages (e.g. personal names), leads to much better scores which are competitive even w ith models which utilize cross-lingual dic-tionaries or machine translation systems. For instance, our LDA-unigram model would have been placed among the top 5 retrieval systems for the CLEF 2002 Bilingual to Dutch task, would have been placed among the top 3 retrieval systems for the CLEF 2001 Bilingual to Dutch task, and outperform s the only participating system in the CLEF 2002 Dutch to English task (MAP: 0.1495) [20,21]. All these state-of-the-art CLEF systems operated in a similar settings as ours and constructed queries from title and description or title , description and narrative fields from the CLEF topics. They, however, rely on translation resources which were hand-built or trained on parallel cor-pora. We obtain competitive results by using the BiLDA model trained on comparable corpora. We believe that our results could still improve by training the BiLDA model on a corpus which is topically related with the corpus on which we perform the retrieval. We have proposed a novel language-independe nt and dictionary-free framework for cross-language information retrieval that does not use any type of a cross-lingual dictio-nary or translation system. The framework is built upon the idea of cross-language topic models obtained by applying a bilingual Latent Dirichlet Allocation model (BiLDA), where the only prerequisite is the availability of abundant training data consisting of comparable document-aligned documents.

We have thoroughly evaluated this cross-language retrieval model using standard test collections from the CLEF 2001-2003 CLIR campaigns and have shown that our combined model, which fuses evidence from the BiLDA model and the unigram model, is competitive with the current top CLIR systems that use translation resources that are hand-built or are trained on parallel corpora.

In future work, we will accumulate more co mparable document-aligned data, ex-ploiting Wikipedia and other sources. We also plan to construct other models that will combine topical knowledge with other evidences (for instance, using cognates instead of exactly the same words shared across languages). Additionally, we plan to expand the standard BiLDA to fit more divergent comparable training datasets. In addition, the cross-language knowledge transfer based on the proposed generative topic models that are trained on comparable corpora might be useful in many other m ultilingual informa-tion management tasks including cat egorization and summarization.

