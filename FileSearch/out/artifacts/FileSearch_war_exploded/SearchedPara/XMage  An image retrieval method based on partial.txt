 1. Introduction
Content-based image retrieval systems search for images that are similar to a query image from a given image database. An efficient image retrieval technology is necessary in diverse applications, such as medical analysis, weather prediction, image searches on the internet, and electronic commerce. Since the use of image data has been widely spread across many application domains, an efficient search on voluminous and complex information, which is the intrinsic characteristic of multimedia data, is becoming increasingly important. Initial systems tackled the content-based image retrieval problem by using color, texture, and shape features. As a result, two images can be seen as similar only because they have similar color distri-to partial similarity because they use features of the entire image.

The results of recent research show that the usage of the region is better than that of the entire image for the granularity of comparison, producing more accurate results ( Jing, Mingjing, Zhang, &amp; Zhang, 2002; more segmented regions are usually not sufficient to address semantic object representation. Moreover, re-gion matching is indispensable for computing partial similarity between two images in region-based image retrieval. It causes severe overhead and deteriorates the performance of query processing. In addressing these problems mentioned above, the image-to-image similarity measure for partial similarity is of special importance in retrieving similar images.

Coupled with the inaccuracy of automatic segmentation, the retrieved results, in general, do not always match user  X  s intuition, or understanding of the images. Typically, a user  X  s semantic understanding of an image is at a higher level than region representation and an object is composed of multiple segments with varying color and texture patterns. The accuracy of automatic segmentation is an open problem in vision application. We have focused on development a filtering function for region matching using color distribu-tion on the assumption that an image is accurately segmented into a set of regions.

Mathematically, defining a partial similarity measure is equivalent to defining the distance between sets of points in a high-dimensional space, i.e., the feature space. Every point in the space corresponds to the feature vector or the descriptor of a region. Although the distance between two points in a feature space can be easily defined by various measures, such as the Euclidean distance, it is not obvious how to define a distance between two sets of feature points for searching two partially similar sets. Since two images may be segmented into different numbers of regions, they cannot be represented in one high-dimensional space.
Therefore, the traditional dimension reduction method, such as DFT and Wavelet transformation, cannot be used.

It is straightforward to define distance mathematically between two sets of points in various ways. One common method is to compute the minimum distance between any two points in the two sets and consider that as the distance between the two sets. But the minimum distance between any two points cannot detect partial similarity between two images because they are considered to be partially similar if they are similar in a large portion and different only in certain regions.

This is the motivation for our research. The development of a distance function between two sets of fea-ture points is addressed. The proposed distance function is image-to-image partial similarity measure and is used as a filtering function for a fast partial similarity search of image database. Fig. 2 shows the proposed query processing, a brief sketch of which is as follows. It is further explained in Section 4.
The R *-tree and the CXHistogram Construction: An appropriate segmentation algorithm generates a set of regions from a raw target image. The R *-tree and the CXHistogram are constructed by using the extracted multi-attribute feature vector of each region. In our experiments, a 16 color value (RGB) is extracted as a feature vector. The XHistogram is a bar graph of the region intensities. It is pro-posed for solving the  X  boundary value problem  X  (refer to Section 3.1). The CXHistogram is built by sim-ply clustering the XHistogram using an equalized quantization method. The R *-tree and the
CXHistogram are stored into a database for later processing. The CXHistogram is a representation for each image.

Query processing: A query image is also segmented into a set of regions and the CXHistogtram of the query image is generated by using the same method mentioned above. After the R *-tree traversal, all target images contained at least one region similar to a region of query image are retrieved. Then, the proposed similarity measure, CXSim(), compares the partial similarity between the query image and the retrieved target images by comparing the two CXHistograms. The use of the CXSim() minimizes
 X  false hits  X  while guaranteeing  X  no false dismissals.  X  The measure selects candidate target images from a database, each of which falls under a given threshold.
 The contributions and advantages of this work are summarized as follows:
The CXSim() is developed as an image-to-image similarity measure between two images for a partial similarity image search. It achieves the effect of comparing regions of two images by simply comparing the two images.

The CXSim() is a location-independent and noise-tolerant similarity measure. The former means that two images are examined regardless of the location of objects, and the latter means two images are deter-mined to be similar if they are similar except for some regions.

The CXSim() does not depend on the number of regions of an image because the proposed method can detect the partial similarity of two images. This is achieved through Histogram Intersection , which drops dissimilar portions of two images.

XMage achieves up to 5.9-fold speed up in search over the R *-tree search followed by sequential scanning.

The rest of this paper is organized as follows: Section 2 provides a survey of related works with a dis-cussion of the partial similarity search for image data. In Section 3, we propose a new image representation and an image-to-image partial similarity measure, the CXHistogram and the CXSim(), respectively, for re-gion-based image retrieval including formal definitions and mathematical proofs. Section 4 explains in detail the CXHistogram construction and a multi-step query processing with a partial similarity search algorithm. Extensive experiments are conducted in Section 5 in order to measure the effectiveness and effi-ciency of our proposed method, XMage. The conclusion is given in Section 6, along with the planned future works. 2. Related work
The annotation of images is given by domain experts and needs an enormous amount of time for large image datasets. Moreover, it may be different from the view of an end user because a domain expert can take a subjective view of an image. Therefore, there has been active research on automatic parsing in which the extracted features of each image map to a multi-dimensional point. The shorter the distance between two points is, the more similar two images are. The typical systems for content-based image retrieval in-clude QBIC ( Faloutsos et al., 1994; Flickner, Sawhney, Niblack, &amp; Ashley, 1995; Niblack et al., 1993 ),
Virage ( Gupta &amp; Jain, 1997 ), and Photobook ( Pentland, Picard, &amp; Sclaroff, 1995; Picard &amp; Kabir, 1993 ), and WBIIS ( Wang, Wiederhold, Firschein, &amp; Wei, 1998 ). The similarity of two images is defined as the Euclidean distance between two feature vectors of images ( Flickner et al., 1995; Jacobs, Finkelstein, vector of the entire image is sensitive to object extension/reduction and object location. Two images can be considered similar by feature vectors although they are different visually.

The fundamental reasons for the problems of previous research are that the number of features in query processing is insufficient and they are extracted from the entire image. Kastenmuller et al. developed a joint joint histogram is composed of various features and generated by the Cartesian product of features. They have shown by various experiments that the joint histogram can obtain more effective results than the color histogram.

The use of regions can override the limitations of the feature extraction from the entire image ( Natsev ularity of comparison, and it produces more accurate results ( Jing, Mingjing, et al., 2002, 2002; Natsev et al., 2003; Smith &amp; Li, 1999; Wang et al., 2001 ). Guibas considered a quadtree partitioning of an image where only windows with uniformly consistent features are preserved and other windows are discarded as containing multiple region information ( Guibas, Rogoff, &amp; Tomasi, 1995 ). For each window a Fourier sig-nature is computed and compared to that of neighboring windows to determine if they are sufficiently alike.
The drawbacks of this approach are that two images can be seen as different even though they are similar and thus it will not be able to efficiently handle scaling and translation of objects. In Smith and Chang (1999) and Smith and Li (1999) , authors proposed a similarity measure based on a variable-sized window. However, this was location-dependent because the spatial information of objects was used.
To provide users with a simple querying interface and to reduce the influence of inaccurate segmentation, several image-to-image similarity measures combining information from all of the regions have been pro-and therefore relieve the users of selecting regions. Many efforts have been made to reduce the query pro-cessing time. These can be classified into two categories: the use of the traditional tree structures ( Gong,
Zhang, Chuan, &amp; Sakauchi, 1994; Natsev et al., 2003; Thomas, Carson, &amp; Hellerstein, 2000 ), such as image similarity measure that allows partial image matching is described in Rubner, Thomasi, and Guibas (1998) . They proposed the earth mover  X  s distance (EMD) using liner programming for matching histograms.

Recently, Natsev et al. considered the similarity model WALRUS that is a robust model for scaling and translation of objects within an image ( Natsev et al., 2003 ). Each image is first decomposed into regions.
The similarity measure between two images is then defined as the fraction of the area of the two images covered by matching regions. However, WALRUS focuses on the development of a fast and effective seg-mentation method instead of an image-to-image similarity measure. Consequently, region matching should be necessary before image matching. The authors proposed a greedy heuristic for computing the similar region pair set with the maximum area. The basic idea is to iteratively choose the best pair of matching regions that maximizes the area covered by the regions. The time complexity of the above greedy algorithm ple of region matching by using a greedy method. In Natsev et al. (2003) , authors adopted 0.085 as a nor-malized region similarity threshold. In this paper, the region similarity threshold is assumed to be 2.21, which was generated 0.085 times the longest distance of the 16 color space.

Example 1. Let R ( A ) be a representation for a region of an image, where R and A denote region intensity and its area, respectively. Let a target image t and the query image q be { t { q 1 , q 2 , q 3 } = {3(3),2(4),1(2)}, respectively. Two regions are selected as a matching pair if the distance between them is less than or equal to the given region similarity threshold, {( t are matching pairs. The similar region pair set with the maximum area is then {( t covered by which is 7 + 5 = 12.

Time-series analysis is the most similar application to partial similarity image retrieval. If an image is partitioned into n regions and the feature vector of each region is m -dimensional, a region can be mapped to a point in an m -dimensional space and then an image is multi-dimensional time-series data according to the region visiting order. The number of regions is proportional to image complexity. Therefore, the prob-lem of region-based image retrieval can be transformed into the subsequence matching of multi-dimen-sional time-series data.
 The previous work of time-series analysis is mostly similarity search for one-dimensional data ( Agrawal, (1995) , Berchtold, Keim, and Kriegel (1997) and Faloutsos, Ranganathan, and Manolopoulos (1994) . But previous research on the partial similarity search was made for one-dimensional time series data. Recently, data ( Lee, Chun, Kim, Lee, &amp; Chung, 2000 ). They used a continuous summation of distance of two cor-are different at some locations, or with a small amount of noise at all locations. Other research areas of partial similarity search involve categorical attribute clustering ( Guha, Rastogi, &amp; Shim, 1999 ), and
CAD ( Berchtold et al., 1997 ), etc. The partial similarity measure using continuous distance summation can be formulated as Eq. (1) and may be quite sensitive to a few noises.

Example 2. Let t , q be a target sequence and a query sequence, respectively, t =  X  (1,2),(3,5),(2,3),(4,5), (5,5),(2,2)  X  , q =  X  (2,3),(4,5),(1,1),(2,2)  X  . We can obtain the definition of D min ( t , q ), the similarity value between t and q is (5,5),(2,2)  X  and  X  (2,3),(4,5),(1,1),(2,2)  X  .

We developed an image-to-image similarity measure as a filtering function of a partial similarity measure for region-based image retrieval in order to reduce the overall query time in a large image database. Much previous research on the content-based image retrieval was focused on the development of a filtering func-tion. But, to our knowledge, there has been no approach that is designed to reduce the overall query time in a region-based image search. Measures developed in the time-series area have no noise-tolerant properties even though they can measure the partial similarity of multi-dimensional time-series. 3. Partial similarity model
In this section, we define problems to be tackled in region-based image retrieval and propose a partial similarity measure to solve them. An image is segmented into a set of regions, the features of which are extracted by an appropriate algorithm. Table 1 gives the symbols and their corresponding meanings used in this paper. 3.1. Problem definition
If two images are similar in a large portion, and different only in certain regions, they should be consid-ered to be similar (referred to as noise-tolerant similar).

Noise problem : Noise is defined as the regions of an image that are not similar to any region in the other image. Most similarity measures of traditional approaches are via the Euclidean distance between two feature vectors, which may not detect partially dissimilar images if they compute similarity at the gran-ularity of the entire image. This problem is referred to as the noise problem.

For this, the granularity for the comparison of two images should be done by regions rather than the entire image. Only the similar region or regions of the two images are counted in computing the partial sim-ilarity. The following summarize the problems to be tackled.

Different length problem : The number of regions generally increases with the image complexity. Thus, the number of regions of two images may be different. This problem is defined as the different length problem. If a single feature vector is computed for each region, several high-dimensional points may rep-resent an image. Region-based image retrieval techniques, therefore, cannot use traditional compression techniques that are popular as dimension reduction methods. To count the common regions disregarding their locations, the elements of two region sets should be compared in a sequential method, that is, pair-wise way. A pair of regions is considered to be similar if the Euclidean distance between two regions is less than or equal to the given region similarity threshold, s and Seq () is defined as a sequential search measure in Definition 1.

Definition 1 ( Image similarity ). Let t i , a m be regions of target image t and q ( t
R _ Seq () be region similarity measure of Seq (). Two images t and q are said to be similar if there exists a similar region pair set A ={( a 1 , b 1 ),( a 2 , b 2 ), ... ,( a Seq () is the same as the image similarity measure adopted in Natsev et al. (2003) . In the above definition,
Area  X [ l i  X  1 b i  X  is the number of pixels in the query image q covered by regions b are considered to be similar if the fraction of matched area compared to the total area of the two images is above the user-specified threshold, f .

Boundary value problem : Two regions can be seen as dissimilar if they are mapped into different bins of a histogram even though they are similar by a distance-based measure. For example, adopting 2.21 as a threshold for similarity, two regions  X  0,0,1  X  and  X  0,1,0  X  are determined as similar by the Euclidean dis-tance measure. However, they may be located in different bins such as b and c, and two dissimilar regions may be located in the same bin such as a and b. Then a and b are determined as similar, whereas b and c are not as shown in Fig. 3 . This problem is defined as the boundary value problem.

Noise problem and different length problem are remedied by HS histogram with histogram intersection (refer to Lemma 1), while boundary value problem are remedied by the XHistogram approach. The follow-ing example illustrates the region and noise. An image is partitioned into many regions, each feature vector of which is extracted from a raw image.
 of two sets represents a region feature vector. The number of regions of the target image is 6 while the
 X  2,2,1  X  . 3.2. Partial similarity based on histogram intersection
The image histogram is a valuable tool used to view the intensity profile of an image. It is a bar graph of the pixel intensities. The pixel intensities are plotted along the x -axis and the numbers of pixels for each intensity along the y -axis. The histogram represents the occurrences of intensity of an image. We define a new histogram for a region-based image search named region-based histogram, which is a bar graph of along the y -axis. A region area is defined as the number of pixels within the region. One-dimensional region intensity is considered; however, it can be easily extended to a multi-dimensional region intensity.
Example 4. Let R ( A ) be a representation for a region of an image, where R and A denote region intensity 1(2)} as in Example 1 and the domain of the bins be [1,9]. The region-based histogram, H ( t ) and H ( q ) for the image t and q are built as follows: H ( t )=  X  0,0,1,4,0,0,2,5,0  X  , H ( q )=  X  2,4,3,0,0,0,0,0,0  X  .
In Swain and Ballard (1991) , the authors proposed a new histogram for computing similarity between two images, whose number of pixels for each intensity is computed by a histogram intersection method.
Let the histograms of a target image t and the query image q be H ( t )=  X  t and is defined as follows:
 X  min( t 1 , q 1 ), min( t 2 , q 2 ), ... ,min( t n , q n
We introduce the Histogram Summation (HS) histogram, which is generated by histogram intersection for the partial similarity comparison of two images. HS function has two histogram sets as its domain and range, respectively.
 Definition 2 ( HS histogram ). Let histograms of a target image t and the query image q be H ( t )=
 X  t , t 2 , t 3 , ... , t n  X  and H ( q )=  X  q 1 , q 2 , q 3 , ... , q defined as where Example 5. This shows a case in which histograms are  X  0,0,1,4,0,0,2,5,0  X  and  X  2,4,3,0,0,0,0,0,0  X  ,asin
Example 4. From Definition 2, the HS histogram of two images is  X  0,0,4,0,0,0,0,0,0  X  . It could be seen that the HS function disregards the dissimilar regions by the histogram intersection.

The following definition gives a partial similarity measure based on histogram intersection. Let Area 2() be a function for the summation of all frequencies of a histogram. If the histogram of an image is H ( t )=  X  t 1 , t 2 , t 3 , ... , t n  X  , then Area 2  X  H  X  t  X  X   X  query image q is defined as follows. Sim () can have two regions as its parameters because a region is a subimage of an image: Lemma 1. Sim() removes noises via the histogram intersection.

Proof. Let histograms of a target image t and the query image q be H ( t )=  X  t
H ( q )=  X  q 1 , q 2 , q 3 , ... , q n  X  , respectively. Let an HS histogram be HS ( H ( t ), H ( q )) =  X  a
Definition 2, when t i = 0, noises of the query image are removed, and then a a target image are removed by the same method. Therefore, Sim () removes noises via the histogram inter-section, consequently Sim () solves the different length problem. h
The more similar a target image is to the query image, the more likely Sim () approaches 1. Sim () = 0 means that a target image and the query image are absolutely different. The following example shows the meanings of Sim ().
 Example 6. In the case of Examples 5 and 1, Sim () and Seq () are 0.19 and 0.43, respectively. because a similarity measure based on the histogram intersection is an exact match rather than a similar match since it computes the summation value of two corresponding bins. A new histogram, the CXHisto-gram, is proposed to overcome the problem mentioned above. 3.3. CXHistogram and CXSim()
The CXHistogram is introduced as a new image representation, and the CXSim() as a correct and effi-cient image-to-image similarity measure that aims at pruning irrelevant target images from a database.
However, they can be located in different bins and then Sim ( t inition 3, they are determined to be dissimilar. The following Example 7 is considered for solving this prob-lem: We assume that the region similarity threshold is 2.21 and a region feature vector is one-dimensional and its domain is [1,9]. All domains of each dimension are extended by two times of the flooring value of s on both the right and left sides. For example, if s = 2.21, all domains are extended by four. Correspond-ingly, if the domain of the bins is [1,9], it is extended to [ 3,13]. Our design objective is that Sim () have 1 as its value in the case that two images are similar in the vector space. Based on the above design objec-tive, we can adopt an alternative value for the dimension extension. From the several experiments, we can discover that two times of the ceiling value of s cannot satisfy the design objective but three times of the flooring value of s 2 is good at alternative value.

Example 7. Let the two images be 4(4) and 2(4). The histograms of the two images are modified as follows and named as XH 2 and XH . XH 2 is constructed by distributing the area of a region not only in the corresponding bin but also among the following nearby bins. The bins fall less than or equal to twice the the flooring value of s is applied. The area of the region is put in a parenthesis at its original intensity. XH 2( t )=  X  0,0,0,4,4,4,4,(4),4,4,4,4,0,0,0,0,0  X  ; XH ( t )=  X  0,0,0,0,0,4,4,(4),4,4,0,0,0,0,0,0,0  X  ;
XH ( q )=  X  0,0,0,4,4,(4),4,4,0,0,0,0,0,0,0,0,0  X  . Then, Example 7 can be summarized in the following.

Observation. The histograms of two images are extended. The area of each regions of a target image is not only plotted in the corresponding bin but is also distributed among all nearby bins of that bin, which fall less than or equal to twice the flooring value of the given region similarity threshold, s , both on the right side and left side of the corresponding bin. For a query image, 1 time the flooring value of s is applied.
In Example 7, the cause of applying the HS function to XH 2( t ) and XH ( q ) is as follows: Let two regions be t i = a (4) and q j = b (3). If the region similarity threshold is 2.21, the flooring value of the given region as the same purpose measure. In the case that two regions are similar in the vector space (i.e., the Euclidean less than 1, the two regions are considered as dissimilar. From Fig. 4 , numerators of Sim ( t ( K +1)  X  7 = 21, ( K +2)  X  7 = 28, ... ,(2  X  K +1)  X  7 = 35, whereas the value of the denominator is 35. Con-sequently, although t i and q j are similar when D ( t i , q and 28 35 , respectively, which are less than 1. If HS function is applied to XH 2( t
XH 2( q j ) as shown in Fig. 5 , then Sim ( t i , q j ) has 1 as its value when D ( t ping bins is 2  X  K +1.

The XHistogram and the XSim () are introduced as a new image representation and a new similarity mea-sure, respectively. 2K-neighbors and K-neighbors of a bin are defined as a set of all nearby bins whose dis-tance from that bin is less than or equal to 2  X  K and equal to K , respectively. For example, if the region similarity threshold is 2.21, 2 K -neighbors of 0 is 0,1,2,3,4.
Definition 4 ( XHistogram, XSim ()). The XHistogram is a region-based histogram. The area of each region is distributed among all the elements of its 2 K -neighbors or K -neighbors. A partial similarity measure on the XHistogram, XSim (), for a target image t and the query image q is defined as follows: 2 K -neighbors has a limitation (the same for K -neighbors). The number of elements of each 2 K -neighbors may be different. Let the region similarity threshold and the domain of bins be 2.21 and [1,9], respectively. 2 K -neighbors of 1 is {1,2,3,4,5}, whereas 2 K -neighbors of 5 is {1,2,3,4,5,6,7,8,9}. In solving this prob-lem, the domain of bins is extended from [1,9] into [ 3,13]. All domains of each dimension should extend to two times the K value on both the right and left sides.

Example 8 (XHistogram). Let a target image t and the query image q be t = {4(4), 7(2), 8(5), 3(1)}, q = {3(3), 2(4), 1(2)}, where a region similarity threshold is 2.21 and the domain of the bins [ 3,13]. Fig. 6 is the XHistogram for the target image t and can be rewritten in the following simple form: XH 2( t )=  X  0,0,1,5,5,5,7,12,12,12,12,11,7,7,7,5,0  X  .
 The XHistogram of XH ( q ), XH ( t ) can be built in the same way: XH ( q )=  X  0,0,2,6,9,9,9,7,3,0,0,0,0,0,0,0,0  X  ; XH ( t )=  X  0,0,0,0,1,5,5,5,7,11,7,7,7,5,0,0,0  X  .
 From the above XH 2( t ), and XH ( q ), the HS histogram, can be computed: HS ( HX 2( t ), XH ( q )) =  X  0,0,3,11,14,14,16,19,15,0,0,0,0,0,0,0,0  X  .
 Therefore, the similarity of the two images is The following theorem indicates that the XSim () is a necessary condition of Seq ().
 Theorem 1. The XSim() is a no false dismissals measure of Seq().
 f ) XSim ( t , q ) P f " ( t i , q j ) 2 R , R :set of region pairs. Let ( a and A  X  R .Let R _ XSim ()beregionsimilaritymeasureof XSim ()and R _ Seq ()and Seq ()isdefinedinDefinition1. (a) D ( t i , q j ) 6 s and ( t i , q j ) 2 A , (b) otherwise, From (a) and (b) XSim ( t , q )= ) Seq ( t , q ) P f ) XSim ( t , q ) P f . h
However, the XHistogram has a large number of bins and thus takes a very large space. For example, the number of bins of an image whose color model is RGB and whose resolution is 24, is 13,824 (that is, 24 ). The CXHistogram is used for solving the above limitation.

Definition 5 ( CXHistogram, CXSim() ). The CXHistograms are, denoted by CXH 2() and CXH (), regions-based histograms and are constructed by simply clustering the XHistograms, XH 2() and XH (), respectively.
The XHistogram is clustered by the equalized quantization which combines the same number of adjacent bins into one bin. CXSim ( t , q ) is the similarity measure of two images based on the CXHistogram and is defined as
The CXHistogram of XH 2( t ) in Example 8 is  X  1,15,31,35,21,5  X  if three adjacent bins are clustered into 1 bin.
 Theorem 2. The CXSim() is a no false dismissals measure of the XSim().
 Proof. We show that XSim ( t , q ) P ) CXSim ( t , q ) P f , where f : image similarity threshold. Let
XH ( q )) be the sum of i th and j th value of HS histogram for XH 2( t ) and XH ( q ). Let XH 2( t )=  X  t
XH ( q )=  X  q i , q 2 , ... , q m  X  , CXH 2( t )=  X  T 1 , T of generality, we assume that T k = t i + t j , Q k = q i (i) t i = q i = t j = q j 6  X  0, K _ HS ( CXH 2( t ), CXH ( q )) = t (ii) t i =0, K _ HS ( CXH 2( t ), CXH ( q )) = t j + q i + q (iii) t j =0, K _ HS ( CXH 2( t ), CXH ( q )) = t i + q i (iv) q i =0, K _ HS ( CXH 2( t ), CXH ( q )) = t i + t j + q (v) q j =0, K _ HS ( CXH 2( t ), CXH ( q )) = t i + t j + q (vi) Area 2( CXH ( q )) = Area 2( XH ( q )), Area 2( CXH ( t )) = Area 2( XH ( t )) from (i) to (v). ) XSim ( t , q ) P f ) CXSim(t,q) P f . h Corollary 1. The CXSim() is a no false dismissals measure of Seq().
 Proof. From Theorems 1 and 2, the CXSim() is a no false dismissals measure of Seq (). h
Corollary 1 means that the CXSim() can be used as a filtering function for Seq () and its performance is measured in Section 5. 4. XMage query processing()
This section presents the overall process of XMage which consists of the R *-tree filtering, CXSim() fil-tering, and refinement step. The query processing of XMage is a range query based on image similarity threshold and pre-processing for image segmentation and building of the CXHistogram should be made for all target images for later processing ( Fig. 7 ):
Image parsing : We use the sliding windows for obtaining a set of regions of an image ( Faloutsos, Ranga-nathan, et al., 1994; Natsev et al., 2003 ). Some sliding windows are clustered into a region using the mod-feature vectors of two sliding windows exceeds a threshold, a new region is generated. The similar regions are clustered afterwards. The region detection algorithm is different from the shot detection algorithm with respect to spatial connectivity. For example, the window, (left, top, right, bottom) = (0,0,9,9), may be clustered into a region with the window (2,4,11,13). That is, all windows connected spatially are considered to be neighboring. The average of RGB color values and areas of regions for all target images are saved into databases. An image parsing for the query image is executed in query time.
Color space : A color space is a way of representing colors and their relationship to each other. Different image processing systems use different color models for different reasons. The color picture publishing industry uses the CMY color model. Color CRT monitors and most computer graphics systems use the
RGB color model. Systems that must manipulate hue, saturation, and intensity separately use the HIS color model. Human perception of color is a function of the response of three types of cones. Because of that, color systems are based on three numbers (called tristimulus values). It is well-known that RGB space is not perceptually uniform, i.e., perceptually small visual color differences do not always corre-spond to small RGB color distance. There exist color spaces that are much more perceptually uniform such as the CIE L * a * b / L * u * v spaces, which are known to improve the perceptual non-uniformity of spaces is better than that of the RGB space, producing more accurate results.

Color clustering : Most color-based image retrieval systems adopt the color histogram as the representa-tion of the distribution of color in the image. One of the most important steps in these systems is to reduce histogram dimensions with the least loss in color content ( Wang et al., 1997 ). In this paper, we perform the equalized quantization to the RGB color space in order to change color levels from 256 to 16 in each axis.

Determine the K value : The K value is region similarity threshold and used for building the CXHisto-gram. It is determined via an experimental analysis by a domain expert. In our experiments, 2.21 was adopted as the K value. In Natsev et al. (2003) , authors adopted 0.085 as a normalized region similarity threshold. In this paper, the region similarity threshold, K is assumed to be 2.21, which was generated 0.085 times the longest distance of the 16 color space.

Determine 2K-neighbors :2 K -neighbors of a bin is defined as a set of all nearby bins whose distance from be used when the XHistogram is built.

Build up the CXHistogram : All areas of each region of the image is added to the areas of all the elements of 2 K -neighbors of the bin corresponding to the region, as shown in Example 8. The XHistograms and the CXHistograms are then generated.

After the CXHistograms of all target images have been constructed, partial similarity search is per-formed against a given query image. The following is an algorithm for XMage in a large image database using the R *-tree and the CXSim() ( Fig. 8 ).
 5. Experimental results
In order to measure the effectiveness of the proposed method, extensive experiments were conducted over an environment containing a large volume of image data. The experiments focused on showing the accuracy and the efficiency of the CXSim(). In WALRUS, the authors examined a two-step query process-the CXSim() filtering and sequential search ( Fig. 2 ). The two-step query processing mentioned above is called IndexSeq . A comparison was made between XMage and IndexSeq. In order to evaluate the quality of image retrieval, a real-life image dataset called misc , which was downloaded from the website of the im-age search engine WBIIS at Stanford University, was used. The misc database contained 10,000 images stored in the JPEG format. The sizes were either 85  X  128, 96  X  128 or 128  X  85. For the experiments, 1 X  2000 images were selected from the misc database for our experiments. The system was written in Microsoft Visual C++ and run under Windows 2000 on a Pentium IV processor.

The overall pruning efficiency and query processing time of XMage were examined by varying the image similarity threshold and we also examined the recall/precision of the filtering step for the R *-tree and the CXSim(). To measure the pruning efficiency, the pruning rate (PR) was used as follows: where j S j denotes the cardinality of the set S . 5.1. Effectiveness of CXSim()
In XMage, the CXSim() reduces the false alarms occurred after the R *-tree search. The recall and pre-cision of the combined filtering of the R *-tree and the CXSim() were examined. Based on the results, it could be observed that the recall of the combined filtering was always 1. This indicates that the combined compared to that of the R *-tree search for the image similarity threshold range [0.1,0.9] where the number of bins of the histogram was set at 200. When the image similarity threshold was 0.95, the ratio is 214. This indicates that the combined filtering effectively reduced the false alarms that occurred during the R *-tree search. Fig. 9 (b) shows the pruning efficiency of the combined filtering. It could be observed that the com-bined filtering prunes 0 X 98% false alarms that are contained in the result of the, R *-tree search for the image similarity threshold range [0.1,1.0] and the same number of bins.
 5.2. Efficiency of the proposed method, XMage
XMage is based on an assumption that there is ground truth available to evaluate item relevance for a specific query. Our primary objective is to improve the efficiency of query processing and the image match-ing of WALRUS is a fairly thorough comparison method, we consider the query result obtained WALRUS approach as query ground truth. They use a greedy algorithm for aggregation of region matches into image matches.
 Fig. 9 (c) shows the pruning efficiency, where the number of bins was set at 100. The pruning rate of
XMage was 38 X 100% while that of IndexSeq was 25 X 58%, for the image similarity threshold range [0.3,1.0]. When the number of bins was set at 200, the pruning rate of XMage was 45 X 100% and that of
IndexSeq was 25 X 58% ( Fig. 9 (d)). Fig. 9 (e) and (f) shows the overall response time. We observe that XMage requires 0.9 X 5.6 and 1.1 X 5.7 s response time for the image similarity threshold range [0.3,1.0] when the numbers of bins of the histogram was set at 100 and 200, respectively. The response time of XMage was 1.1 X 5.9 times faster than that of IndexSeq for the image similarity thresholds with [0.3,1.0].
To show the accuracy of XMage, the visual similarity of images retrieved by XMage were compared to a given query image. The query image with an ID of 866 in the database was selected. The top 15 images were found by XMage ( Fig. 10 ) from 2000 images and were all visually similar to the query image except for image 1605 image. The images are ordered top to bottom, left to right, in decreasing order of similarity. The top 15 similar images to the query image with an ID of 100 were shown in Fig. 11 . The images were ob-tained by using 2.21 and 0.7 as the region similarity threshold and image similarity threshold, respectively. 6. Conclusions and future works
This paper focused on developing an image-to-image similarity measure, CXSim(), based on the Histo-gram Intersection in order to reduce the overall query time while retrieving partially similar images from a large image database. The proposed measure supports location-independent and noise-tolerant searches of images data. It also retrieves candidate images satisfying the criteria of no false dismissals. The major con-tributions of this work include the introduction of a new image representation CXHistogram, and the use of the CXSim() as an image-to-image similarity measure. The CXSim() achieves the effect of comparing regions of two images by simply comparing the two images. The experiment on real-life images, the CXSim() is an efficient measure to prune irrelevant images, being approximately 1.1 X 5.9 times faster than IndexSeq for the image similarity thresholds with 0.3 X 1.0, when the number of bins is set at 100. The
CXSim() will be revised for use as a refinement function with very few false dismissals or a more efficient filtering function with no false dismissals.
 Acknowledgements
This research was supported by the Agency for Defense Development, Korea, through the Image Infor-mation Research Center at Korea Advanced Institute of Science &amp; Technology.
 References
