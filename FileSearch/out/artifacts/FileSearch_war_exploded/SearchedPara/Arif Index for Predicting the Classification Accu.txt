 In pattern classification problem, classification accuracy depends on proper selection of features that can discriminate different classes and design of a good classifier. Design of a classifier includes ability of classifier to approximate decision boundary of arbitrary complexity among different classes in the feature space and generalization power of the classifier. Discrimination power of features decides maximum possible classification accuracy achievable by any classifier. A prior knowledge of maximum achievable classification accuracy can help a lot in designing appropriate optimal classifier. Moreover, if classes are separa ble in the feature space by a decision bound-ary of any arbitrary complexity, then it is possible to achieve maximum classification space as scattered multi-modal clusters. A class can be represented by multiple clus-ters scattered in the feature space. These clusters can be point or line or any arbitrary shaped clusters. Moreover, they can be co mpact and well separated (separated by large margin) within class or overlapping each other. Overlapping of intra-class clus-ters has less effect on classification accuracy as compared to overlap among inter-need not be very compact and well separated in the feature space but the decision boundary among classes should be well separated and non-overlapping. Hence an feature space when information of class labels is available. This index should posses following characteristics. It should be sensitive to the amount of overlap of features among different classes that results in the decrease of classification accuracy and strong correlation may exist between index value and amount of overlap or classifica-tion accuracy. If classes in the feature sp ace are separable by any decision boundary of arbitrary complexity, it should give a consistent value and the value of index may not vary with the complexity of decision boundary. Index may not vary with the num-location with respect to other classes in the feature space. Such an index can give us a prior knowledge of maximum achievable classification accuracy by any perfect classifier. 
Three different kinds of clustering validity indices exist in the literature, namely, external criteria based indices, internal criteria based indices and relative criteria based indices [2]. In internal criteria based indices, clusters generated from a cluster-ing algorithm are evaluated by considering the data itself based on intra-cluster and inter-cluster distances. In these indices, Dunn X  X  Index [3], Alternative Dunn X  X  Index [1], Davies-Boulden Index [4] and Xie and Beni X  X  Index [5] are worth mentioning. In external criteria based indices, user defined partition of data is provided (class labels) that can be compared with the clustering structure revealed by a clustering algorithm. Different external criteria based indices like Rand Index [6], Jaccard Co-efficient [2], Folkes and Mallows [7], Mirkin Index [8] and Adjusted Rand Index [9] are reported in the literature. Density based clustering algorithms can find arbitrary shaped clus-ters. Many such algorithms are reported in the literature like DBSCAN [11], BRIDGE [12], DBCLASD [13] and DENCLUE [14]. These indices are not useful in evaluating the discrimination power of the features in classification problem. These indices can-not be applied directly to the feature representation of different classes in pattern classification problem by simply assuming classes as clusters. Clustering structure within class is required before applying th ese indices. A survey of clustering algo-rithms can be found in [10]. Performance of these indices is very sensitive to the performance of clustering algorithm. Clustering algorithm should be capable of dis-covering cluster structure of any arbitrary shape. In this paper, an index called Arif index is proposed which does not require any clustering algorithm. This index spreads linearly on the scale of zero and one where zero value shows no overlap among clus-ters of different classes. This index is independent of number of clusters per class, type of clusters and their location in feature space. We have used Arif Index to assess the discrimination power of the features used in Arrhythmias beat classification problem [15]. Let number of classes is N C having data points , 1,..., ic ni N = and total data points are scribed as below, Step 1: Normalize the feature vectors by making their means equal to zero and vari-ances equal to one. Step 2: initialize a variable Status t S of size 1 N  X  with zeroes. Step 3: For a data point y of size 1 d  X  of j th Class, Find nearest neighbor of y in the rest of classes which are different from j th Class. Let this nearest neighbor is d nn hav-ing distance , Step 4: Find all data points of j th Class whose distance are less than , point y . Let number of nearest neighbors of y in j th Class whose distance are less than other is defined as, Step 5: If number of nearest neighbors s nn is greater than a user defined threshold value  X  , consider this data points as clustered in the data points of the same class and make the status of the set of data points Step 6: Run steps 2 to 5 for all the data points in the feature space. Step 7: Arif index will be defined as follows, 
Hence Arif index gives the ratio of data points which are not surrounded by data points of its class to the total number of data points. Strength of clustering data points of the same class near a particular data point is controlled by a user defined threshold value  X  . The values of  X  should be greater than 1. Value of Arif index varies from 0 to 1, where value of 0 means no overlapping and maximum accuracy of 100% is achievable and values of 1 means complete overlap and accuracy depends on the data representation of different classes. In case of two classes with equal number of representation, for Arif index equals to 1 means 50% accuracy is possible by just neighbor of all the feature vectors of j th class. This value will give the density estimate of the clustering structure of a particular class. Low value of () Cj shows sparse representation of a class in the feature space. Hence, it will also help in better under-standing the quality of features representing the pattern classification problem in the feature space. Checkerboard data as shown in Figure 1 is used to evaluate the Arif index for separa-ble classes. Furthermore, data of two classes are brought together in steps so that overlapping of both classes increases and at the end they completely overlap each other. K-nearest neighbor is used as a classifier and value of K is set to 5. Half of the index is calculated on training data and classification accuracy of K-nearest neighbor classifier is calculated on testing data. In Figure 2, scatter plot between Arif index and the classification accuracy is plotted. It can be observed from the Figure 2 that when two classes are separable, the value of Arif index was zero and as overlapping be-tween classes increased, the value of Arif index also increased and the classification accuracy decreased. Arif index approached near to its maximum value of 1 for com-pletely overlapping classes. A very nice agreement between values of Arif index and classification accuracy is observed. A linear trend is very prominent in the scatter plot and straight line is fitted with very high value of R 2 = 0.99. For the value of Arif index near to 1, accuracy dropped to almost 50%. This observation is very obvious as we have used equal number of data points for each class in the testing data. If we do not apply any classifier and assign one class label to all the data points of the testing data, we will get the accuracy of 50% without applying any classifier. This shows the use-fulness of using Arif index to get an idea about the upper limit of maximum achiev-able accuracy before applying any classifier to the data. For multi-class problems, lower bound on the accuracy without applying any classi-fier will be the percentage of representation of majority class in the data set if we set lated between 100% classification accuracy and the lower bound of the classification accuracy. An ideal linear trend can be described as below, Where _ lower bound Accuracy is the lower bound on the accuracy depending on the percentage representation of the majority class. To prove this hypothesis, we have generated data for four separable classes as shown in Figure 3a and slowly move them towards each other until they completely overlap each other as shown in Figure 3b. During this process, we have calculated Arif index and accuracy by applying a K-nearest neighbor classifier and plotted it in Figure 4. It can be observed from Figure 4 that for Arif index equals to 1 (case of completely overlap), accuracy dropped to 25%. A linear trend can be fitted on these data points with very high value of regression coefficient R 2 = 0.98. Since there were four classes containing equal number of data points, the classification accuracy at complete overlap will be 25%. This supports our hypothesis and applicability of equation (3). Hence Arif index can be used to predict the quality of features before applying any classifier and value of Arif index can be used to predict maximum achievable classi fication accuracy that can help in proper tuning or selection of the classifiers. 
ECG beat classification, being an integral part of any ECG based automatic deci-sion support system, has been studied by a number of researchers. Different feature extraction methods for beat classification include use of Fourier Transform [16], multi-resolution analysis [17], wavelet transform [18] etc. In our previous work [15], we have used features extracted from two-level wavelet decomposition of an ECG signal from MIT-BIH Arrhythmia Database [19]. It contains two-channel ambulatory ECG recordings from 47 subjects studied by the BIH Arrhythmia Laboratory between 1975 and 1979. ECG recordings were digitized at the sampling rate of 360 Hz with 11-bit resolution. We have used the annotations of the cardiologist originally provided classification accuracy of the beat classification using Arif index. Eleven features extracted from the wavelet decomposition of the ECG beat signal and RR interval are used for classification. Further Principal Component Analysis is used to reduce the please refer to [15]. Two sets, Set6 and Set9, are constructed from the database. Set6 consists of 23200 beats of six types (Paced B eats (PB), Atrial Premature Beat (APB), Premature Ventricular Contraction (PVC), Normal (N), Left and Right Bundle Branch Blocks (LBBB &amp; RBBB)), whereas Set9 consists of 104690 beats of nine types (PB, APB, PVC, N, LBBB, RBBB, Fusion of paced and Normal beats (P&amp;N), Fusion of Normal and Ventricular beats (N&amp;V) and Ventricular Flutter (VF)). A simple K-nearest neighbor classifier has been employed for the classification of different types of beats. Arif index along with C were calculated on Set6 and Set9. Classification half for testing. 
Positive Predictive Values ( PPV ) of each class was calculated as follows, index as explained in Section 2. Values of C represent number of neighbors of a data class. Hence high value of C shows denser clustering and low value corresponds to sparse representation of a class. Arif index, predicted accuracy and achieved accuracy nearly zero, and predicted accuracies and achieved accuracies match each other. C values tabulated in Table 1 are high showing denser clustering and hence PPV values for all six classes with or without PCA are very high, i.e. above 99%. For Set9 with larger number of beat types, results are tabulated in Table 3 and 4. It can be observed from Table 4 that for low values of C (VF, N&amp;V and APB), PPV values are also low as compared to denser classes. For the reduced feature sets (With PCA), values of C further reduced and this reduction is reflected in the decrease of PPV values of less denser classes. Arif index, predicted accuracy and achieved accuracy for Set9 are tabulated in Table 4. Arif index is increas ed a bit as compared to Set6 and corre-spondingly predicted and achieved accuracies are also dropped slightly. Hence it is proved that Arif index and C values can be used efficiently to predict the classifica-tion accuracy and PPV of individual classes. A novel index to assess the classification quality of the feature vectors is proposed in this paper. This index is a model free index and does not require any clustering algo-rithm. It only uses the information of local neighborhood of the feature vectors to cal-culate the overlap or region of confusions in the feature space. Results have shown that value of the proposed index does not depend on the shape, location or the structure of strongly correlated with the classification accuracies. Predicted accuracies of different physiological sets are also found to be consistent with the reported accuracies in the literature. Hence this index will be very useful for the pattern classification problems. 
