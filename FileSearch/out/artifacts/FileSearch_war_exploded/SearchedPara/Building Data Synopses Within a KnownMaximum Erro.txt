 Approximate Query Processing (AQP) has been extensively studied and used to deal with massive data sets in decision support and data exploration applications. As AQP usually relies on the pre-computed data synopses to compute the approx-imate results of queries over original data, research on improving the accuracy of approximate results inevitably focuse s on finding good data synopses construc-tion methods. Many techniques have been proposed on constructing data synopses [4,1]. Among them, the wavelet techniqu e has been considered very promising as it was first adopted by Matias et al. to p rocess range query approximation in re-lational database [11]. The basic idea of constructing a wavelet synopsis of a data vector, with size N , is to first transform the data vector into a representation with respect to a wavelet basis. Then it is approximated by retaining M coeffi-cients as the wavelet synopsis and setting remains to 0 implicitly. The procedure of choosing M coefficients is called coefficients thresholding . A conventional ap-proach is to find M coefficients to minimize the overall mean squared error [13]. This can be easily solved by applying the Parseval X  X  theorem. However, the main drawback of this synopsis is that users have no method in which they can control the approximation error of individual elements in the data vector. This severely impedes further applications of the wavelet approximation. To alleviate this, re-searches have made efforts on constructing wavelet synopses with error guaran-tee [2]. Two dual approaches have been taken: one is to construct size bounded synopses which would minimize the maximum approximation error of single data elements [3] whilst the other is to constru ct the smallest size of synopses such that the maximum approximation error does n ot exceed a given error bound [12]. The optimal synopses construction for both approaches has O ( N 2 ) time complexity. Although several methods have been proposed to improve the performance of con-structing size bounded synopses [5,7,9], there are no investigations in the litera-ture on improving the performance of constructing error bounded synopses. The approximate algorithm for size bounded synopses construction [9] can be easily extended to approximately solve the construction of the error bounded synopses but it may incur large approximation error in some situations as we will illustrate later on. Indeed, there exist some nice fea tures that can greatly improve the per-formance of error bounded synopses X  X  construction, which are not very obvious applicable on the size bounded synopses X  X  construction. Motivated by this, in this paper we develop fast wavelet synopses construction method, which aims at min-imizing synopses size under a given error bound.

Our contributions can be summarized as follows: We have obtained nice fea-tures based on the error tree structure used in Haar wavelet transformation. We propose pruning strategies that can greatly improve the performance of the orig-inal optimal algorithm. With these properties, we give a nontrivial low bound on the size of an optimal synopsis in linear time.

The rest of the paper is organized as follows. Section 2 defines the problem and enumerates related works. Section 3 investigates the error tree structure and proposes our pruning strategy to improve the original optimal algorithm. Sec-tion 4 reports our experiment results on applying our pruning strategy. Section 5 concludes this paper. In this section, we first introduce Haar wavelet transformation and coefficients thresholding. Then we present the two types of synopses and review related techniques. In Table 1 we summarize the math notation used throughout the paper.
 2.1 Haar Wavelet Transformation and Thresholding Approximate query processing using Haar wavelet is first introduced in [11] by Matias et al. The basic idea of Haar wavelet transformation is to recursively find the average and difference of two adjacent data of the data vector D . The final av-erage value, i.e. the average of all data in D , together with those differences form a new vector W D . The data elements of W D are named wavelet coefficients. We use the following example to illustrate details. Given D =[12 , 6 , 4 , 2 , 5 , 1 , 2 , 0], we transform D to W D =[4 , 2 , 3 , 1 , 3 , 1 , 2 , 1]. Figure 1(i) shows details.
Each internal node c i represents a wavelet coefficient whilst each leaf node d i represents an original data item. l represents the corresponding resolution listed in Figure 1(i). Given a node u (internal or leaf), we define path ( u )asthesetofnodes that lie on the path from the root to u (excluding u ); T ( u ) as the subtree rooted at subtree rooted at the right child of u , if it exists. To reconstruct any leaf node d i through the error tree T , we only need to compute the summation of nodes belong to path ( d i ). That is, d i = c  X  path ( d 2 ), i.e. d 2 = 4+2+(  X  3)+1. It is easy to see that reconstructing any original value of an error tree with N internal nodes, requires O (log N ) time complexity.
The idea of wavelet synopses construc tion is to only keep a certain number of exact coefficients of W D , while setting values of the remains as a constant number -zero is the normally implicit one. The goal is to find an optimal synopses that minimize the approximation error under certain metrics. Two commonly adopted error metrics ones are the mean squared error ( L 2 ) and the maximum absolute error ( L  X  ). More formally, let  X  d i be the approximate value of d i . Minimizing L 2 is to minimize 1 N i (  X  d i  X  d i ) 2 . Finding an optimal solution to minimize L 2 leads to a simple graceful algorithm due to the energy preserving property of wavelet transformations [13]. However this error metric is arguably not the best choice for approximate query processing [2]. One of the main drawbacks of this error metric is that users have no way of knowing the accuracy of any individual value approximation. Thus techniques on minimizing L  X  , i.e. max have been developed in recent years.

One approach is to to minimize L  X  under a fixed number of coefficients to construct the size bounded synopses, also called B -bound. The first solution were proposed in [2]. This probabilistic method, however, has flaws due to its questionable expectation guarantees[8 ]. In [3], Garofalakis and Kumar propose a deterministic solution for constructing B -bound synopses. Given a data vector D with N elements, their algorithm takes O ( N 2 B log B ) time complexity and O ( N 2 B ) space complexity. Guha improved th e space requirements of this deter-ministic algorithm to O ( N ) with a divide and conqueror idea in [5]. To make the construction of B -bound synopses applicable in a data stream environment, Kar-ras and Mamoulis propose a greedy algorithm [9]. Meanwhile, Guha extended this problem from the original restricted version to unrestricted version, where the stored set B could be any set of real numbers without being limited to the wavelet coefficients [7,6]. The details are out of the scope of this paper.
The other approach aims at minimizin g the number of necessary coefficients under an error bound (  X  )toconstructthe error bounded synopses. It is also called  X  -bound. Instead of fixing the wavelet synopsis size, it fixes the error tolerance through constructing a synopsis that satisfies L  X  &lt; X  . The goal is to find a synopsis with the smallest set of coefficients B among all possible solutions that would satisfy the  X  bound. This model is also very important and promising on providing approximate answers with good quality. Interestingly, it was only mentioned recently by Muthukrishnan a nd Guha in [12,5]. They proposed an optimal solution which however takes O ( N 2 ) time complexity.

In the next section, we will provide several important properties that can greatly improve the optimal error bounded synopses construction of [12,5]. We start this section by first reviewing the existing optimal wavelet synopses construction algorithm, we then introduc e our pruning techniques to accelerate the synopses construction for  X  -bounded approximation.

The optimal algorithm for  X  -bounded approximation has been proposed in [9]. Briefly, its idea can be described as follows. Assume there is a subtree T ( v ) rooted at node v and set S of retained nodes on path ( v ). Let B ( T ( v ) , X ,S )denote the least number of retained wavelet coefficients of T ( v ) that satisfies  X  -bound for the approximation. The algorithm of [9] uses the following two equations to compute B ( T ( v ) , X ,S ): use Equation (1) if node v is to be retained, otherwise, use Equation (2).
 Therefore, the final B ( T ( v ) , X ,S ) is the minimum of the above two possibilities. This method shares the same dynamic programming idea as the one published in [3], where an optimal algorithm of synopses construction for B -bound approx-imation was proposed.

However, due to special characteristics of the  X  -bounded problem, we can exploit typical  X  related features to improve the performance of the optimal Algorithm 1. minM ax ( c r ,v k ,v d ) algorithm in some cases. For example, in Equation (1) and (2), set S can be constrained to satisfy certain conditions rather than being an arbitrary subset of nodes on path ( v ). In the following, we will describe some properties of  X  -bounded synopses which will be used in our algorithm.

Let M  X  be an optimal  X  -bounded synopsis on error tree T and denote diff ( d i )
By definition, we know that for any viable solution that satisfies the  X  bound, the summation of deleted nodes along any path (from root to a leaf node ) of the error tree is less than  X  .Thatis, | diff ( d i ) | &lt; X  holds for i =0 , 1 ,...N  X  1.
For co efficient c j  X  path ( d i ), we define diff ( c j ) to be the summation of deleted ancestor nodes along path ( d i ), which is Based on these formulae, we develop the following three properties: Property 1. Let T be the error tree on D =[ d 0 ,d 1 ,...,d N  X  1 ]and M  X  be an optimal  X  -bounded synopsis on T . Suppose c j  X  path ( d i ). Then (i) | diff ( c j ) | &lt; X  ; (ii) | diff ( c j ) | + | c j | &lt; X  if c j  X  M  X  ; (iii) For any node c k  X  T , c k  X  M  X  if | c k | X   X  .
 Proof. Suppose there are l leaf nodes in T ( c j ), ranging from d h to d h + l  X  1 . The proof of (i): It is easy to verify that discarding any inner node of T ( c j ) will not change the summation of the difference of the l leaf nodes [10]. That is: The proof of (ii): From (i), we have which implies (ii).
 The proof of (iii): A contradiction will be derived from (ii) if c j  X  M  X  and c  X   X  are assumed. From (ii) can be derived straightforwardly from the above formulas.
 We propose an optimal algorithm with minM ax ( c r ,v r ,v d ) as the key procedure (Algorithm 1). minM ax ( c r ,v r ,v d ) has three parameters: c r is the currently con-sidered node; v r is the summation of the retained nodes that are on the path from the root node to node c r (excluding c r ); and v d is the summation of discarded nodes that are on the path from the root node to node c r (excluding c r ). The function returns the set of coefficients that represents an optimal  X  -bounded synopsis in the subtree T c r under the two given values v r and v d . Property 1(i) and (ii) can be used to check the  X  condition dynamically. Property 1(ii) is used at Steps 15-18 of minM ax ( c r ,v r ,v d ) to prune unnecessary data expansion: node c r can not be discarded if | v d | + | c r | X   X  .
While the time complexity of our property-based algorithm is still of O ( N 2 ) in theory, the extensive experiments, as d escribed in Section 4, indicate that this algorithm is more efficient than the existing algorithms in many situations and no worse in others. Refer to Section 4 for details.

Additionally, Property 1(iii) also gives a lower bound on M  X  which can be used for a rough estimation on the size of M  X  .Thatis, Corollary 1. Let T be the error tree on D =[ d 0 ,d 1 ,...,d N  X  1 ] and M  X  be an optimal  X  -bounded synopses on T .Then Clearly, { c i | ( c i  X  T )  X  ( | c i | X   X  ) } can be obtained in O ( | T | )time. In this section, we evaluate the effectiveness of our pruning techniques. We imple-ment our algorithms through VC++ .NET. All the experiments were performed on a Pentium IV 3.6GHZ machine with 2 GB memory.

Two types of synthetic data sets are generated for our experiments on con-structing  X  -bounded synopses: the coefficient-data set (CD) and the original-data set (OD). The CD data set contains data uniformly selected from [10 , 20] as a set of wavelet coefficients ( W D ). It is actually an error tree and we can directly construct the  X  -bounded synopses from the CD. The OD data set contains data uniformly selected from [0 , 10000] as a vector data ( D ). It is the original data set and we need to apply the Haar wavelet transformation on it before we can construct the synopses.

We conducted experiments to evaluate the efficiency of the two algorithms in generating optimal  X  -bounded synopses, one with our pruning techniques (named as WaveAC ) and one without it (named as Wave ), i.e., the original algorithm men-tioned at [12]. Their comparisons on computation time are depicted in Figure 2.
In Figure 2(1) and (2), the experimental results were on CD data. Figure 2(1) is on a fixed size CD data ( | D | = 8192) under varied  X  ranging from 10 to 50. Figure 2(2) is on a fixed  X  (  X  = 25) under varied data size D ranging from 32 to 65536 nodes. The experiments on OD data under the same scenario are given in Figure 2(3) and (4).
From the experiments, we have the following observations. On a fixed size data set, as indicated in Figure 2(1), the pruning technique ( WaveAC ) can improve the speed up to 25 times faster when  X  is between 10 and 20, which is the range of the values of the coefficients. The increase of speed will drop to 1 . 5timesas  X  increases. Figure 2(2) shows a comparison of varied data size for a fixed  X  . The improvement caused by the pruning techniques increase d the speed to up to 35 times faster. These facts are further supported with the results of Figure 2(3) and (4). In this paper, we have proposed new algorithms on the construction of  X  -bounded synopses to minimize maximum error. Our approach is based on the intrinsic properties of W D upon a  X  error bound.

Our future work is to improve and extend this work in several ways: to apply the obtained properties in different way s to derive better results; to investi-gate more properties that can lead more efficient algorithms on construction of  X  -bounded synopses and to support streaming data processing and applications.
