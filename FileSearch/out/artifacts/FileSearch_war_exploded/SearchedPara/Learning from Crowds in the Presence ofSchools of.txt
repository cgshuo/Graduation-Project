 Crowdsourcing has recently become popular among machine learning researchers and social scientists as an effective way to collect large-scale experimental data from distributed work-ers. To extract useful information from the cheap but poten-tially unreliable answers to tasks, a key problem is to identify reliable workers as well as unambiguous tasks. Although for objective tasks that have one correct answer per task, pre-vious works can estimate worker reliability and task clarity based on the single gold standard assumption, for tasks that are subjective and accept multiple reasonable answers that workers may be grouped into, a phenomenon called schools of thought , existing models cannot be trivially applied. In this work, we present a statistical model to estimate worker reliability and task clarity without resorting to the single gold standard assumption. This is instantiated by explicit-ly characterizing the grouping behavior to form schools of thought with a rank-1 factorization of a worker-task group-size matrix. Instead of performing an intermediate infer-ence step, which can be expensive and unstable, we present an algorithm to analytically compute the sizes of different groups. We perform extensive empirical studies on real data collected from Amazon Mechanical Turk. Our method dis-covers the schools of thought, shows reasonable estimation of worker reliability and task clarity, and is robust to hy-perparameter changes. Furthermore, our estimated worker reliability can be used to improve the gold standard predic-tion for objective tasks.
 I.5.1 [ Pattern Recognition ]: Models -Statistical Algorithms, Experimentation Crowdsourcing, Schools of Thought, Pattern Analysis
Crowdsourcing has emerged as an effective way to collect large-scale data to help solve challenging scientific and engi-neering problems. In web services such as Amazon Mechan-ical Turk (M-Turk) 1 , human intelligence tasks (HITs) (e.g.,  X  X oes the image contain a car? X ) are distributed from the re-questor to an unknown set of workers, called crowds , who are paid with a low cost to fulfill them. There are two kinds of applications for crowdsourcing. One application is to obtain correct labels of a dataset, used in computer vision [21], nat-ural language processing [19], etc. In such a scenario, task is objective with one correct answer, called gold standard . The goal is to recover it from the noisy worker responses. The other application is to use crowdsourcing for qualita-tive user studies [11], demographic survey [16] or solving a hard problem [1]. In this case, each task may have multiple valid answers, called schools of thought , since the tasks are subjective or can be misinterpreted, and the workers come from a variety of cultural and educational background [16].
Due to the open and anonymous nature of crowdsourcing, the quality of the collected data is not guaranteed. In order to use these data well, in both scenarios we need to address two common key problems  X   X  X ow to identify a small num-ber of unreliable workers whose answers may be random or even adversary X  and  X  X ow to identify tasks that may cause confusion to workers X . Formally, we call these two factors worker reliability and task clarity . In crowdsourcing appli-cations that aim to obtain ground truth labels of a dataset, only the labels from reliable workers should be trusted, and ambiguous tasks should be redesigned to remove any mis-understanding in the future. In applications that aim for user study or look for multiple opinions, one needs to dis-tinguish whether a worker has a reasonable opinion, or just puts random answers that may ruin the data distribution.
In the former case, many previous works [15, 23, 19, 14, 10] have been presented and shown promising results com-pared to the  X  X ajority voting X  heuristic. The worker relia-bility is defined either as the degree of concentration (pre-cision) [15, 23, 22] or confusion matrix [9, 18, 5] referencing the estimated gold standard, whose existence is an essential assumption in these works. Some works also model task d-ifficulty [22], again based on the existence of gold standard. Computationally, an iterative approach is usually adopted to estimate the gold standard and worker reliability simul-taneously. The rationale is that knowing the gold standard helps to identify reliable workers and workers X  reliability is useful to weigh their answers to recover the gold standard. https://www.mturk.com
However, in the latter case where more than one answers could be valid and reasonable, defining worker reliability on top of a single gold standard is no longer a good idea. For some workers, their reliability can be underestimated only because they support a reasonable idea that is not the es-timated single gold standard, yet in fact they may follow a unique but reasonable thinking and should be respected. On the other hand, an unambiguous task that is supposed to have alternative answers may also be estimated as confusing.
To deal with this problem, in this paper, we directly mod-el worker reliability and task clarity without the help of gold standard. As a result, this model works in both scenarios of crowdsourcing applications. Our model is built on the following two mild assumptions on the grouping behavior that happens in schools of thought: 1) reliable workers tend to agree with other workers in many tasks; and 2) the an-swers to a clear task tend to form tight clusters. Following this idea, we develop a low-rank computational model to ex-plicitly relate the grouping behavior of schools of thought, characterized by group sizes , to worker reliability and task clarity. To bypass the hard model selection problem of de-termining the unknown number of clusters (i.e., schools), we apply nonparametric Bayesian clustering techniques, which have shown great promise in statistics and machine learn-ing [3, 6, 24]. Moreover, instead of performing a potentially expensive and unstable intermediate inference step, which is necessary for all the previous works [15, 23, 21, 22], we derive an analytical form to estimate the expected group sizes. The analytic form only depends on pairwise distances between answers, making it generalizable to different answer types. Interestingly, our model could provide a generative interpre-tation of latent distance model for social networks [8]. The worker reliability and task clarity are thus obtained via the rank-1 factorization of the expected group size matrix.
Different from most previous works that focus on gold s-tandard estimation, recent work [21] also models the schools of thought for binary queries by assigning each worker a (d-ifferent) linear classifier on hidden multidimensional repre-sentations of tasks, with Gaussian priors on both represen-tations and classifiers. The worker reliability is thus defined as the precision of the linear model. However, it remains a question whether such linear representations and Gaussian priors for both tasks and workers are faithful to the data, and whether heterogeneous tasks can be represented in the same space. Our work avoids such representation issues by explicitly modeling the grouping structure of the data. This leads to fewer assumptions and parameters. Moreover, our method allows an analytic solution, while [21] uses a coor-dinate descent procedure to obtain a local optimum.
Finally, we apply our method to both simulation data and the real data collected from M-Turk. In the real data, we discover the group structure of schools of thought (Fig. 1), and show estimated worker reliability and task clarity, as well as a comparison with several benchmarks and sensitivity analysis. For objective tasks, we use the estimated worker reliability to select high quality workers for recovering gold standard, which outperforms previous works [15, 21].
The paper is structured as follows. Section 2 introduces our statistical model for crowdsourcing data analysis in the presence of schools of thought, together with a simple algo-rithm. Section 3 presents synthetic validation, and Section 4 presents analytical results on M-Turk. Finally, Section 5 concludes with future directions discussed.
In this section, we present a computational model to es-timate worker reliability and task clarity for crowdsourcing data in the presence of schools of thought.
In crowdsourcing, let N be the number of workers and K be the number of tasks. Each worker is required to finish all the K tasks (See the experimental design for more details). We use a scalar  X  i &gt; 0 to model the constant reliability of worker i among different tasks, and a scalar  X  k &gt; 0 to model the constant degree of clarity of task k that holds for all workers 2 .

Like any useful statistical models, we need to make ap-propriate assumptions in order to perform meaningful es-timation and discover useful patterns. Specifically, for our problem of estimating worker reliability and task clarity in the presence of schools of thought, it suffices to make the following two mild assumptions on the behavior of workers and tasks: 1. A worker i who is consistent with many other workers 2. A task k whose answers form a few tight clusters is
We argue that the above two assumptions are reasonable for characterizing crowdsourcing data. The first assumption may fail if all the workers collaborate to cheat, or the task is too hard so that most of the workers are misled towards the same wrong answer. However, since the basic idea of crowdsourcing is to ask the crowds for useful information, it is not restrictive to trust the behavior of the majority of workers. Furthermore, most previous works (e.g., majority voting, [15] and [22]) in crowdsourcing assuming the exis-tence of gold standards implicitly make the first assumption, which is shown in both their initialization steps and their model designs.

The second assumption can be interpreted as  X  X ense-making X  that people make efforts to find interpretations from  X  X xpe-rience X  (their answers) [17]. Reliable workers are expected to use more mental resource to obtain a reasonable answer, while unreliable workers may give random nonsense answer-s. A sensible task only contain a few reasonable answers but random answers could be many. Thus reliable workers will form large groups, while unreliable ones are discordant. This assumption may fail if only a few candidate choices are avail-able for a confusing task that has many potential answers. This can be avoided by concatenating multiple questions in-to one task, which expands the answer space to reveal the true clustering structure (See the experiment section).
Note that K tasks and N workers have to be considered jointly. A single task cannot identify whether a worker is of high quality or not. Similarly, a single worker cannot identify the ambiguity of tasks.
A worker X  X  reliability can be possibly different in various tasks and time-evolving; a task may be clear to a certain subgroup of workers but not to others. A systematic study of this more complicated phenomenon is beyond the scope of this paper. We leave it for future work.
Given the two assumptions, a quantitative relation fol-lows. Suppose we have somehow clustered the worker re-sponses of task k into M k clusters (the cluster model will be presented in Section 2.3), where M k is an unknown param-eter. Let z ik denote the group index that worker i corre-sponds to in task k , and # z ik be the size of that group. In this paper, # z ik is regarded as a way to represent the scale of schools of thought. The larger # z ik is, the smaller the scale is. We thus formally define our computational model by relating # z ik to  X  i and  X  k as follows: where ik is a zero-mean random noise (its distribution is determined by our clustering model). In matrix form, Under expectation, we have #  X  Z =  X  X  &gt; , which is a rank-1 factorization of the N  X  K worker-task groupsize matrix #  X 
Z . The resulting  X  k and  X  i can thus be used to rank tasks or workers. The intuition underlying the low-rank factoriza-tion is that according to the assumptions, reliable workers working on clear and well-defined tasks will give unanimous answers, yielding large group sizes in expectation. Note that we treat # z ik as a continuous variable rather than an inte-ger. Section 2.4 discusses how to estimate its expected value.
Given the assumptions, rank-1 factorization is the most straightforward way to formulate the relationship between # z ik ,  X  i and  X  k . More complicated modeling may help, e.g. assuming a nonlinear relationship or enforcing # Z to be rank-m rather than rank-1 to find multiple factors for both workers and tasks that are related to the grouping behavior. However, we leave these extensions for future work.
To obtain worker reliability and task clarity, a key step is to estimate the expected group sizes. Although many clustering methods, such as spectral clustering [13], Kmean-s and etc., can be applied to first infer the group assignment of each worker in each task and then calculate the group sizes, most of them have a difficult time in determining the unknown cluster number M k . To bypass the hard model s-election problem and also to allow the model to adaptively grow as more data are provided 3 , we resort to nonparamet-ric Bayesian techniques, which have shown great promise in machine learning, statistics, and many application areas [3, 6, 24]. More specifically, we propose to use the Dirichlet process (DP) mixture model [3], which is a nonparametric Bayesian model that can automatically resolve the unknown number of clusters M k . Moreover, as we shall see, for our DP mixture model, we can analytically compute the expect-ed group sizes without an intermediate inference step, which can be expensive and unstable.

Formally, let x ik be the d -dimensional observed answers of worker i to task k . Typically, x ik is a vector encoding the worker i  X  X  answers to a sequence of questions in task k (e.g., a worker gives answers to d questions of a survey). For a task k , answers of workers form M k clusters. Let c ik denote the center of the cluster that worker i belongs to. For differ-ent workers i and j , c ik = c jk if they are in the same group. For each task k = 1 ...K , the DP mixture with a Gaussian likelihood model can thus be written as: Although in principle, we could use a separate variance  X  for each worker i and each task k , here we treat them as one single hyperparameter  X  for simplicity and will provide sensitivity analysis of our model with respect to  X  to the fact that the distributions G k sampled from a DP are discrete almost surely [4], there is a non-zero probabil-ity that two workers belong to the same cluster. Thus, we will have a partition of x ik according to the sampled values c ik and automatically infer the cluster number M k . Alter-natively, the mixture model can be equivalently represented using Chinese restaurant process (CRP) 4 prior, which is: where c mk is the cluster center for cluster m at task k . In
For example, the number of clusters can grow for a DP mix-ture model when more data are provided. In other words, DP mixture can have an unbounded number of clusters.
A CRP is a marginalized version of a DP [6]. this work, we set the base distribution G k 0 as N ( 0 , X  where  X  2 k 0 are the task-specific variances that characterize how much the means of clusters are scattered around the o-rigin. We will present a procedure to automatically estimate them. On the other hand, the hyperparameter  X  character-izes the variance within each cluster and need to be specified. A sensitivity analysis is shown in the experiment.

For the DP mixture, exact inference of the group assign-ment z ik is intractable. Typical solutions resort to variation-al or sampling [12] methods. However, these approximate in-ference methods often lead to local optimum solutions and can be expensive and sensitive to initialization. Thus, we need to estimate the expected group sizes in a more efficient and robust way. Here we derive an analytic solution to the expected group sizes for the clustering model, without in-termediate inference. Our approach can be expected to be faster and more stable compared to those using approximate inference, analogous to what people have popularly done in collapsed sampling [7] or collapsed variational inference [20] in probabilistic latent variable models.
For each task k , we use X k = { x ik } N i =1 to denote all its worker responses. Let W k ij be a binary random variable that equals to 1 if workers i and j are in the same group of thought in task k ( W k ii = 1). From W k ij , the group size # z worker i can be computed as # z ik = P N j =1 W k ij . Thus, by linearity of expectation, the expected group size conditioned on X k is: where the last equality holds because W k ij is binary. Note that the linearity of expectation still applies even if W not independent variables (e.g., for i 6 = i 0 , W k ij and W be dependent because they share the same worker j ).
To compute the posterior distribution of W k ij , we make the following approximation: where D k ij = || x ik  X  x jk || 2 is the squared Euclidean distance between responses of workers i and j . The intuition is that two workers i and j being in the same group is largely due to their affinity, but is almost independent of other work-ers X  responses. Our synthetic experiments verify that this approximation is very accurate (See Section 3 for details). In practice, this approximation is also reasonable in crowd-sourcing services like M-Turk, where the onsite communica-tion between workers is not allowed. After computing the likelihood P D k ij | W k ij and prior P W k ij = 1 , with Bayes X  rule we obtain the posterior link probability: The same result follows when using Euclidean distance. Please see Appendix for detailed derivation. In this work, we derive the prior from the exchangeability property of CRP.
Note that the posterior distribution in Eqn. (7) is not restricted to the CRP-Gaussian cluster model proposed in Eqn. (4). In general, we can apply other priors or explicitly define P W k ij . Besides Gaussian, each cluster X  X  noise model can follow any other unimodal distribution and Eqn. (7) still hold with D k ij with a different distance metric. The metric could also be redefined and generalized to arbitrary type of answers (e.g. binary, categorical).

Interestingly, our link distribution model in Eqn. (7) for two workers being in the same group has the same logistic form as the latent distance model for social network analy-sis [8], where the link distribution model is directly defined.
Once we have obtained the expected group size #  X  z ik for each worker i and each task k , the worker reliability  X  and task clarity  X  can be estimated as the first left and right singular vector corresponding to the largest singular value of the expected group size matrix #  X  Z  X { #  X  z ik } (Eqn. (1)). The entire algorithm is summarized in Alg. 1. Note we do not need to impose positive constraints for  X  and  X  , since the first left and right singular vector of a matrix with positive entries is always positive by Perron-Frobenius theorem. Algorithm 1 Estimation worker reliability and task clarity in the presence of schools of thought. 2: (Output) Worker reliability  X  and task clarity  X  . 3: for k = 1:K do 5: Computer the expected group size #  X  z ik (Eqn. (5)). 6: end for 7: Run SVD on expected worker-task groupsize matrix #
Before ending this section, we introduce a simple proce-dure to estimate the hyperparameters  X  k and  X  k 0 , with the assumption that  X  is given. As we shall see, our model is insensitive to the only tunable hyperparameter  X  . Thus, although the procedure does not estimate all hyperparame-ters, it is good enough for our use.

Specifically, after marginalizing cluster partition, we can obtain P D k ij , a distribution of the observable pairwise squared distances parameterized by the hyperparameters  X  ,  X  k 0 and  X  . Similarly we compute P || x ik || 2 . Given  X  , we can estimate  X  k and  X  k 0 from the equations: The derivation is simple by noticing that E D k ij = P l =0 , 1 E
D k ij | W k ij = l P W k ij = l . Similarly for P || x ik
Before presenting the experiments on real data, we first conduct synthetic experiments to show empirically that our approximation (Eqn. (6)) is valid and our estimation of ex-pected group sizes is reasonably accurate for the clustering model. We investigate the performance with four sets of parameters (  X , X  0 , X  ) as shown in Fig. 2. For each set of pa-rameters, we set d = 12 and generate K = 500 independent tasks according to Eqn. (4), each with N = 50 workers and  X  k 0 =  X  0 , X  k =  X  . We compare our estimated group sizes using Eqn. (5) and posterior link probability using Eqn. (7) with those empirically computed from the simulation. We can see that our theoretical estimation is very accurate, es-pecially when the clusters are well-separated (i.e.,  X  0  X  ).
Now, we present empirical studies on the real data collect-ed from Amazon Mechanical Turk (M-Turk). Since our main focus is to characterize the schools of thought phenomenon in crowdsourcing, most of the experiments are qualitative. At the end, we also present some quantitative results to demonstrate the potential usefulness of our statistical anal-ysis for predicting gold standard (if exists).
For each HIT (i.e., Human Intelligence Task), we design three missions, each containing several tasks with different levels of clarity listed as follows. Each worker is required to finish all the tasks only once. Following [21], all tasks are vision-related. We expect to see workers of various reliabili-ty, task-specific schools of thought due to diversity of clarity, and give insights to possible confusions in human-aided vi-sion tasks. We emphasize that our analysis is not restricted to vision tasks and our techniques can be applied to analyze crowdsourcing data collected in other fields, including text mining, natural language processing, etc.

Mission 1: Object Categorization . In this mission, we provide three tasks. In each task, workers are asked to decide which of the 12 images contain a certain object cat-egory, namely sky , building and computer . Each task is de-signed to have a different level of clarity. For task sky , there are simply 6 images with sky and 6 without sky. For the less clear task building , there are 4 images with a typical build-ing, 4 images without a building, and 4 images that contain a building-like structure. The task computer is the most confusing one, in which 6 out of 12 images are equally divid-ed into three subsets, each containing a typical computer, a Figure 3: Object counting task. A counting his-togram is shown as well as the image. In all tasks, the cluster structures of worker responses are clear. For Count3 , an outlier response 725 is not shown. typical object that is not a computer, and a computer-like electrical appliance (e.g., Apple iPad or Amazon Kindle); and the other 6 images follow the same strategy of three-way-division but the objects in the images are elusive and require some efforts to find.

Mission 2: Object Counting . In this objective mis-sion, workers are asked to count the number of objects in 4 images. We regard each image as one task. Among the 4 images, the simplest one contains 5 humans, one contains 65 small human-shaped objects that are laborious to count, one contains 8 animals huddling together and requires efforts to count, and the most confusing one contains 27 apples that are of various sizes and partially hidden in tree branches. All the 4 images have gold standards counted by authors.
Mission 3: Images Aesthetics . In this subjective mis-sion, there are two tasks with comparably low clarity. In each task, workers are asked to pick 6 most beautiful images from 12 images. Among the 12 images, 3 are considered ordinary-looking, 3 are beautiful, 3 are impressively beauti-ful, and 3 are of astonishing beauty, according to authors X  criterion.

Fig. 1 and Fig. 3 show example images. All images are manually picked online. The images are randomly shuffled when presented to workers to avoid any order bias ( X  X onkey vote X ). Once we have obtained the responses of workers, we remove incomplete and duplicate responses from the same worker and construct a dataset that contains the responses of 402 unique workers to the 9 tasks. For each worker, the response includes a 12 dimensional binary vector for each task in object categorization and image aesthetics missions, and a 1 dimensional integer for each object counting task. the most confusing one. (This figure is best viewed in color.)
Unless explicitly mentioned, in all tasks we set the hyper-parameter  X  = 0 . 2 and estimate  X  and  X  0 from empirical expectation (Eqn. (8) and Eqn. (9)). We will also provide a sensitivity analysis on the hyperparameter  X  .
We apply our low-rank model to all the 9 tasks. The rank-1 residual error || #  X  Z  X   X  X  T || F / || #  X  Z || means 73% of the energy in #  X  Z has been explained away by  X  and  X  . This shows that our model can fit the data well. Although we do not jointly model the interaction be-tween clustering and factorization, the cluster size matrix #  X 
Z naturally follow the rank-1 factorization, which verifies our low-rank assumption. It may be theoretically intriguing to formulate a joint model and design an iterative procedure for model fitting. However, this may result in an improper bias on the data.

Below, we first examine the existence of schools of thought and its two major latent factors  X  worker reliability and task clarity, and then provide detailed analysis on worker relia-bility.

Visualization of schools of thought. We show the patterns of schools of thought for the tasks in object catego-rization and image aesthetics missions as the posterior link probability matrix (Fig. 1) computed from Eqn. (7). For better visualization, we set  X  = 750,  X  = 0 . 6 and  X  0 = 1. Rather than posterior link probability matrix, histograms are shown separately for each of the 4 counting tasks (Fig. 3). Different visualization is used because each counting task is done separately, while for the other missions, workers X  re-sponses are based on 12 images at a time.
 Task-specific schools of thought. From Fig. 1 and Fig. 3 we can clearly see the task-dependent schools of thought. Even for the simplest task (e.g., sky ) and tasks with ground truth (e.g., object counting), there are still substantially di-verse answers. For task sky , a large group of people think the outer space looking from the Moon is not sky, or a glow-ing bluish icy ceiling in a cave is sky. For counting, some workers think the image with 65 human-like drawings does not contain humans and give zero answer. For more compli-cated and confusing tasks, the number of clusters goes up, and each cluster size goes down. In subjective tasks, almost everyone has their own responses and the cluster structure is almost invisible.

Distribution of worker reliability. Fig. 4 shows the structure of the expected worker-task groupsize matrix #  X  as well as the estimated worker reliability  X  and task clarity  X  . From the worker reliability plot, most of the workers are comparably reliable and they tend to stay consistently in larger groups in different tasks. A small portion of workers did a very poor job, consistent with the observation in [19]. Among the three types of missions, object categorization is relatively clear, image aesthetics is in general very subjective and vague. Counting mission shows mixed results. Nearly all workers are correct in task Count2 , making it the clearest one. One the other hand, counting apples of varied size with background clutters (task Count4 ) is extremely confusing.
In this subsection, we present a closer examination of the estimated worker reliability and compare it with baselines. Besides, we also show how to use it for improving prediction of gold standard for objective tasks.  X   X  0 . 2 .

Ranking workers. To verify the computed worker re-liability  X  , we first estimate  X  on the 5 tasks ( sky, build-ing, computer, beauty1, beauty2 ), then check if the estima-tion makes sense in the remaining four objective tasks. For checking, we rank the workers according to  X  , compute the answer variance  X   X  2 T for reliable workers, and the answer vari-ance  X   X  2 UT for unreliable workers, and then compare the two variances. If  X   X  2 UT  X   X  2 T , which means workers labeled as  X  X nreliable X  give inconsistent answers compared to those la-beled as  X  X eliable X , then the ranking is meaningful and can be generalized to other unseen tasks. Specifically,  X   X  2 puted from D most reliable workers, and is averaged over 4 remaining counting tasks. Similarly for  X   X  2 UT . The result is shown in Fig. 5. We vary D from 10 to 50, and vary  X  from 0 . 01 to 0 . 2 for sensitivity analysis. A subset of workers give zero responses to task Count1 , (presumably thinking those drawings are not humans). In the second column, we also show the results after excluding zeros from ranking.
It is clear that in most of the cases, the reliable workers estimated on one set of tasks give answers that are much more consistent (i.e., with a lower variance) than the unre-liable ones in a different set of tasks. This suggests that the worker reliability is generalizable from one task to anoth-er task, which is consistent with what we have observed in Fig. 4. From the results, we can also see that our approach is relatively insensitive to the change of hyperparameter  X  and parameter D .

Comparison with baseline clustering models. As we have stated in Section 2.3, we can use alternative methods to perform the clustering on worker responses. Now, we com-pare the performance of our method (  X  = 0 . 2) with spectral clustering [13], PCA-Kmeans and Gibbs sampling on the DP mixture model in Eqn. (3). Note that all these baselines require inference on the cluster assignment of each work-er in order to compute the group sizes, while our method does not. For spectral clustering, we take the L = 5 to 70 smallest eigenvectors of normalized graph Laplacian and normalize them to be unit vectors as the low-dimensional embedding, on which Kmeans are performed with L cluster-s. For PCA-Kmeans, we first reduce the dimension of the workers X  response to 5 using PCA, and run Kmeans with L = 5 to 70 clusters. For Gibbs sampling, we use the Al-gorithm 8 in [12] with the same set of hyperparameters as estimated in Eqn. (9) with  X  = 0 . 2.
 Table 1: Time cost comparison between the meth-ods using various baseline clustering algorithms and ours.

Fig. 6 shows the performances of different methods. All the baselines are repeated for 500 times with random ini-tialization. We present their best average performances and its associated standard deviations, achieved by tuning the hyperparameter (i.e., the number of clusters). We can see that our approach is comparable with baselines but is much more stable because it does not require initialization. Tbl. 1 shows the average time cost over 50 runs. Ours is faster than spectral clustering and Gibbs sampling. PCA-Kmeans is the fastest since it does not compute pairwise distance, but its performance is worse than ours.
 Table 2: Performance comparison on predicting the gold standard counts for the four counting tasks.

Prediction of gold standard. As a specific case of schools of thought, our approach can also be applied for those tasks having one unanimous answer (e.g., the count-ing tasks) and predict the gold standard. Here, we provide one example that uses selective  X  X ajority voting X , namely, we first select D most reliable workers based on the estimat-ed worker reliability  X  , and then apply majority voting for (d) Gibbs sampling, on the difference  X   X  2 UT  X   X   X  2 T is the variance of the answers of D most unreliable prediction. An alternative method would be weighing the responses of workers with their reliability. Yet we obtain the same performance.

Tbl. 2 shows the comparison of our method to three very competitive baseline methods on predicting the count num-bers for 4 counting tasks. The baselines include the classic inclusive  X  X ajority voting X  (MV) heuristic, which performs over all the 402 workers, the  X  X earning from crowds X  (LFC) method [15], which iteratively estimates workers X  precisions and tasks X  gold standard using an EM procedure, and the  X  X ultidimensional wisdom of crowds X  (MDW) method [21] as we have discussed in the introduction. For LFC, we follow Eqn.(10)-(11) in [15] and use MV as the initial guess of gold standard as suggested in the paper. For MDW, since it does not handle the case that the gold standard is in the contin-uous domain, we first find maximum a posteriori estimation of the workers X  precisions, treat them as workers X  reliability, and estimate the gold standard by averaging the answers of top-10 reliable workers. In MDW, each task k is a hidden c -dimensional vector v k and each worker is represented as a set of weights in the same dimension. Both need to be es-timated from the data. In the experiment, we choose c = 1 and c = 3.

We can see that our selective MV outperforms all the three baselines, especially on Count1 and Count4 , and our pre-diction matches the gold standard very well. MDW has comparable performance yet it is quite sensitive to the ini-tialization. When d = 1, MDW gives the same prediction as ours (i.e. (65 , 5 , 8 , 26)) in most random initializations, however, it also gives (0 , 5 , 8 , 24 . 05) if not initialized prop-erly. The reason is that, although most workers vote for 65 (called  X 65-voters X ), there is a small group voting for 0s ( X 0-voters X ) on Count1 . If MDW falls into this small cluster and regards 0-voters as more reliable than 65-voters, the gold s-tandard estimation of Count4 will also change. In contrast, ours always rate 65-voters over 0-voters since 65-voters form a larger cluster than 0-voters. Thus, ours gives a deter-ministic answer to worker reliability. Besides, on the four counting tasks, using the stopping criterion (where v k is the hidden representation of task k in itera-tion t ), MDW spends 3 . 25  X  3 . 34 seconds for c = 1, and 4 . 26  X  3 . 70 seconds for c = 3, averaged over 50 random ini-tializations. The large variation in the rate of convergence is due to different initialization. In comparison, our method runs for 0 . 68 seconds, is insensitive to the parameter D and the value of the hyperparameter  X  , and has no initialization.
This paper formally analyzes the schools of thought phe-nomenon and its two key underlying factors, worker reliabil-ity and task clarity, in crowdsourcing by presenting a com-putational model based on a low-rank assumption, which characterizes the relationships between the group sizes of worker responses and the two key factors. Furthermore, the expected group sizes can be estimated analytically instead of performing an expensive and unstable inference step. We report real experiments on Amazon Mechanical Turk.

In terms of time cost, the major bottleneck of our work is to compute the groupsize matrix # Z , which has time com-plexity of O ( KN 2 ) ( K is the number of tasks and N is the number of workers). However, if N is large, given worker i , we can sample a few other workers to obtain an unbiased estimate of # z ik , yielding approximately O ( KN ) complexi-ty. Another interesting future direction is to handle the case of missing data that some workers may not give answer to some tasks. In such a case, how to estimate the group size for observed answers and how to factorize the group size matrix # Z in the presence of missing entries deserve more exploration.

From a learning point of view, our analysis could pro-vide insights for developing better predictive tools in several ways. For example, we have shown that high quality labels can be selected from the answers of workers who enjoy top ranking in worker reliability for building better predictive models. For future work, we can acquire new labels from those workers that have higher reliability in the context of active learning [14]. Finally, our analysis could help the market price  X  X igh-reputation X  workers [2].

Acknowledgements Yuandong Tian is supported by Mi-crosoft Research PhD Fellowship (2011-2013) and an ONR grant N00014-11-1-0295. [1] J. Abernethy and R.M. Frongillo. A collaborative [2] E. Adar. Why I hate Mechanical Turk research (and [3] C.E. Antoniak. Mixtures of Dirichlet processes with [4] D. Blackwell and J.B. MacQueen. Ferguson [5] AP Dawid and AM Skene. Maximum likelihood [6] S.J. Gershman and D. Blei. A tutorial on bayesian [7] T.L. Griffiths and M. Steyvers. Finding scientific [8] P.D. Hoff, A.E. Raftery, and M.S. Handcock. Latent [9] P.G. Ipeirotis, F. Provost, and J. Wang. Quality [10] D.R. Karger, S. Oh, and D. Shah. Iterative learning [11] A. Kittur, E. Chi, and B. Suh. Crowdsourcing user [12] R.M. Neal. Markov chain sampling methods for [13] A. Ng, M. Jordan, and Y. Weiss. On spectral [14] D. Pinar, J. Carbonell, and J. Schneider. Efficiently [15] V.C. Raykar, S. Yu, L.H. Zhao, G.H. Valadez, [16] J. Ross, L. Irani, M. Silberman, A. Zaldivar, and [17] D.M. Russell, M.J. Stefik, P. Pirolli, and S.K. Card. [18] P. Smyth, U. Fayyad, M. Burl, P. Perona, and [19] R. Snow, B. O X  X onnor, D. Jurafsky, and A. Ng. Cheap [20] Y.W. Teh, D. Newman, and M. Welling. A collapsed [21] P. Welinder, S. Branson, S. Belongie, and P. Perona. [22] J. Whitehill, P. Ruvolo, T. Wu, J. Bergsma, and [23] Y. Yan, R. Rosales, G. Fung, M. Schmidt, [24] J. Zhu, N. Chen, and E. Xing. Infinite Latent SVM for P By the Bayes X  rule, we have = P where the likelihood term P D k ij | W k ij and the prior term P W k ij = 1 are computed as follows.

The likelihood term P D k ij | W k ij . For W k ij = 1, both x ik and x jk are generated independently from the same cluster center with variance  X  2 , thus we have x ik  X  x N (  X | 0 , 2  X  2 ). Therefore, D k ij = || x ik  X  x jk || tribution with the following pdf: where d is the dimension of the workers X  responses. Simi-larly, for W k ij = 0, by integrating their cluster centers out, we can show x ik , x ik are independently generated from N (  X | 0 , X   X  ). Thus we have P D k ij | W k ij = 0 =  X  ( D k ij ; d, X 
The prior term P W k ij = 1 . By the exchangeability property of Chinese restaurant process, all workers are equal. Thus
Combining the two parts, we thus obtain the posterior distribution P W k ij = 1 | D k ij :
Note the same derivation follows if we use Euclidean dis-tance l ij,k = || x ij  X  x ik || and where is exactly the same as the one using squared Euclidean distance.
