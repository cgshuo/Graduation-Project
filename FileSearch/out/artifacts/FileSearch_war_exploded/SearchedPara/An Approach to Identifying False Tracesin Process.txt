 Process mining provides a bridge between data mining and traditional model-driven Business Process Management (B PM) [10,11]. A business process (e.g. a purchase order, an insurance claim, etc.) is a sequence or network of tasks performed by humans or by machines to purposefully achieve a specific business goal. BPM provides supports, by affording methods, techniques, and softwares etc., for (re)design, deplo yment (system configuration and process enactment), and analysis of operational business p rocesses as well as concerned resources (humans, machines, data, etc.) [9]. Gener ally speaking, a process-aware infor-mation system (PAIS) plays a key role during the whole life cycle of BPM as depicted in Fig. 1. By means of deriving knowledge from event logs manually collected or auto-generat ed by a PAIS [5], process mining, which behaves like the traditional data mining as depicted by the red arrow in Fig. 1, is generally seen as a critical tool to improve operational business processes iteratively. The first of three main classical applications of process mining is model discovery ,which objective is to extract process model s, the most important data of BPM, from event logs [10,11]. An example is to mine a process model shown in Fig. 3 given an event log containing four traces { ACDG,ADCG,BEH,BFH } . An overview of various mining algorithms for model discovery can be found in [9,14], and their implementations can be found in the open source platform, ProM 1 , which has been used in industrial applications.

Generally speaking, the quality of process mining results is not determined only by the algorithm used but also by the quality of the concerned data, i.e. event logs which record the executions o f process businesses. Of the criteria to judge the quality of an event log, one is trustworthy which requires recorded events and their orders being exactly sa me to what they happened [11]. However since event logs are often not treated as the key business data in real life, there are seldom policies to guarantee the quality of event logs. Consequently when a trace, a sequence of events recording an execution of a business process, was written into an event log, sometimes it was not recorded as it should be, namely it was polluted . For example, when deploying a PAIS in an organization for the first time, people have to describe the busin ess processes of interest precisely and formally for configuring the system, whi ch is often based on event logs collected manually where one or more events of a trace may be missed for some reasons. Another example happens daily in a hospital. Blood chemistry tests for patients are often carried out in groups rather than one by one instantly. And the test results are not available until some hours later, which are stamped with a date only. So do X-ray tests. Thus the sequence of such two tests may sometimes be messed up in the log for a patient since the granularity of timestamps is coarse-grained. Such traces that would n ot describe the actual executions of business processes, are called occurrences of noise [2] or polluted traces .The original sequence of events is transfor med into another sequence of events by means of missing some events or interchanging the order of two events. In this paper we focus on these two types of pollution , which are widely accepted as the most common pollution of event logs (e.g., [3,6,15]). Although most problems in process mining have had satisfactory solutions, noise identification of logs is one of those unsolved which present impediments to advancement of the field [11].
Most of model discovery algorithms cannot guarantee the correctness of their mining results if the given event log is polluted. Mining algorithms can be classified into two categories. The first category consists of algorithms which assume the log to be noise-free (e.g., the most famous  X   X  algorithm [13]). For these algorithms it is necessarytoidentifyoccurrencesofnoisei nthelog andremovethembeforestarting process mining. The second category consists of algorithms which have their own ways of dealing with occurrences of noise inthe logs. These algorithms roughlytreat low frequent traces as polluted ones direct ly or indirectly, no matter whether they arepollutedor not,beforeprocessmining (e.g.[15]),during processmining (e.g.[1]) or after process mining (e.g. [2]). However, setting up a convincing threshold value is still a challenging problem.

Noise identification in process mining is similar to but not same as the data clean or outlier detection in data mining and the de-noising in signal processing. Traditional approaches for data clean make full use of relations among attributes and records of data [8], while there are unstructured traces only in event logs. Although a polluted trace is not the same as the normal trace which it should be, it may be by chance the same as another trace that is normal. Hence traditional approaches for outlier detection cannot be used [16]. Approaches for de-noising in signal processing focus on the Gau ssian white noise, the widely accepted pollution type in the field, and are hard to be applied to deal with the pollution in process mining (e.g.,[4,7]). To summarize, algorithms available in these fields cannot be applied to identify polluted tra ces in an event log directly because of the characteristics of event l ogs and pollution concerned.
 This then leads to the demand for a separate approach for noise identification. As a polluted trace may appear as ano ther normal trace, we focus only on false traces in the paper, i.e. polluted traces which are not possibly valid as regards the process model to be discovered. Given a polluted log, as we do not have access to that process model that generated the log, we propose an approach, FATILP (FAlse Trace Identification based on Latent Probability), to helping find out false traces in a probabilistic manner, based on the occurrence frequencies of the observed traces and their transformation relations presented as a conditional probability matrix. The matrix describes the possible pollution type of the log, which itself can be obtained interactively by applying the approach.

It is important to note that our method for identifying false traces in a polluted log is not dependent on the choice of a specific mining algorithm. Our results can directly be used for those algorithms that are sensitive to false traces in logs (e.g. [6,13]). Beyond the field of process mining, the approach may be applied in the field of data provenance (e.g. to find out the origin of data), social network (e.g. to estimate the evolution of a social network), or traditional data mining (e.g. to mine the occurrence patterns of hot topics on the web).

The remainder of this paper is organized as follows. Section 2 describes basic concepts needed to define the problem and to describe our approach, explains three reasonable assumptions needed by our approach and formulates the prob-lem of false trace identification of event logs for process mining. Then the pro-posed approach for the false trace identification problem is outlined in Section 3. In Section 4 the results obtained are eva luatedandexaminedinanexperimental manner. Section 5 concludes the paper and outlines future work. 2.1 Basic Definitions A task is an activity to be performed in the context of a business process. A process model provides an abstraction of a busin ess process capturing its tasks and all possible execution orders of these tasks in a formal manner. A process instance represents an actual execution of a business process. A trace is the result of the successful completion of a process i nstance and consists of a sequence of events, where each event corresponds to the execution of a task and all events are totally ordered typically on the basis of the timestamps that they were recorded. An event log is a set of traces, which records ex ecutions of a process model [12].
Two traces are equivalent if and only if their lengths are equal and every event of the first trace refers to the same task as the corresponding event at the same position of the second trace. A trace class consists of traces equivalent to each other. For simplicity, we refer to a trace as a sequence of task names to which the events of the trace correspond respectively, and thus a log as a bag of traces generated by a process model. As mentioned before, a trace is referred to as a polluted trace if it does not describe the actual execution of a business process, and as a normal trace otherwise. As a polluted trace may appear as a normal one, we define a special kind of polluted trace as follows.
 Definition 1 (False Trace). Given a process model P and a log L .Atrace  X  of L is referred to as a false trace if and only if it is not equivalent to any normal trace of P .
 A trace is referred to as a true trace if it is not a false trace. All normal traces are true traces and all false traces are p olluted traces. Some polluted traces may be same as true traces. As illustrated in Fig. 2, a normal trace T 6 may be transformed into some polluted traces, and an observed trace T 2 in a log may originate from some normal traces. Traces T 0 ,T 1 ,T 8 and T 9 are false traces. Obviously the concepts of event log and false trace are quite different from those of trajectory data and outlier in the field of data mining respectively. 2.2 Assumptions In this subsection the assumptions, which precisely characterise the event log and pollution type on the one hand and underpin the proposed approach on the other hand, are made explicit. Each assumption is described in detail and it is argued that the assumption is reasonable, why it is needed, and what would go wrong if the assumption was not made.
 Assumption 1. Normal traces occur randomly and independently.
 By observing the execution log, it is no t possible to determine what the next trace will be recorded, based on the obs erved traces. It is reasonable to assume that traces appear randomly and independently.

If the occurrence of a new trace depends on an observed trace, the new trace and the observed trace are correlated. We treat them as different occurrences of the same trace as they can be (partia lly) deduced from existing ones. Assumption 2. A normal trace occurs with a constant but unknown probability, which may vary across different traces.
 A trace represents a particular applic ation scenario of a process model. When a business process has been running for years, the same scenario may appear periodically. As time goes by the occurrence frequencies of the traces become relatively stable and in the long run they may converge to constant values, i.e. to their latent generation probabilities . Note that because of pollution, the gener-ation probability of a trace is generally different from its occurrence probability.
If this assumption does not hold, we cannot solve the problem of noise iden-tification of an event log without further information about the occurrence of traces. It is worthwhile noting that this means that our approach does not work so well for logs that result from processes that have not been running for a very long time as trace occurrence frequenci es may not have sufficiently stabilized. Assumption 3. The pollution occurs randomly and independently, and given a normal trace the conditional probability of transforming the normal trace to another polluted trace because of pollution is a constant value, which may vary across different polluted traces.
 According to our observations, it is general that all traces in a log are not pol-luted, and that the pollution of a normal trace seldom depends on previous occurrences of pollution. Thus it is reasonable to assume the random and inde-pendent occurrence of pollution. Note all possible polluted traces of a normal trace are determinate because of its determinate conditional probabilities.
The assumption reflects the key idea of the proposed approach, i.e. trying to mimic the process of pollution and then to identify false traces by making full use of the relationships between false traces and their corresponding normal traces, which can be presented as a conditional probability matrix, i.e. so-called a pollution matrix . Such relationship may be various, yet we here require its con-ditional transformation probability to be constant. Without detail information of pollution, it is typically assumed that all possible polluted traces of a normal trace have the same conditional transformation probability. A priori knowledge of pollution may help set up the probability value for a specific transformation. 2.3 Problem Formulation In this paper we are concerned with finding answers to the following problems related to a polluted event log.
 Problem 1 (False trace identification problem). Givenapollutedlog L of an unknown process model, and a pollution matrix M , which traces among all traces in L are most likely to be false traces? Problem 2 (False trace discovery problem). Given a polluted log L of an unknown process model. Among all traces in L which are most likely to be false traces? 3.1 Key Idea Givenaneventlog L , for all observed traces T 1 ,T 2 ,  X  X  X  ,T M their occurrence frequencies F = { f 1 ,f 2 ,  X  X  X  ,f M } are defined by f i = n i /N for all 1  X  i  X  M , where N = M i =1 n i and n i is the occurrence time of T i . Based on all assumptions presented in subsection 2.2, suppose there are all W possible traces. Let G = { g p i,j = Prob ( T j where 1  X  i  X  M and 1  X  j  X  W ,and P = { p 1 ,p 2 ,  X  X  X  ,p W } the occurrence probability of the traces either observed or unobserved. Especially the combined conditional transformation probability of all unobserved traces of T i is u i = and the probabilities are in gray since they are unknown.

Formally, the relationship between G and P can be described as The start point of the proposed approach, FATILP (FAlse Trace Identification based on Latent Probability), is the occurrence frequencies of traces F , which will converge to the occurrence probabilities of the traces P respectively according to the law of large numbers in probability theory. If P can be estimated based on F ,the G can be calculated by means of the equation (1). As we know a process model does not generate a false t race, which implies the latent generation probability of a false trace should be zero . Thus the false traces can be identified based on their latent generation probabilities. Precisely, the FATILP consists of three steps as follows. 1. Process the given log to derive occurre nce frequencies of observed traces. 2. Estimate the latent generation probabilities of observed traces by means of 3. Perform a  X  2 test on the estimation result, and identify false traces. 3.2 False Traces Identification Since there is often an error between the P and F , it is not appropriate to replace P with F directly. Here we define as follows a distance function Q 2 between P with F . The minimization of the distance function would force P of false traces to be zero or be very near to zero since the unobserved traces have higher weights, and consequently G of false traces would be zero or very near to zero since P and transform probability are non-negative ( refer to equation (1) for detail). subject to M i =1 g i =1and g i  X  0.

Now the false traces identification problem has been modeled as a quadric op-timization problem, whose computation complexity is determined by the number of variables and the number of constraints. From equation (2), it is known that there are M variables and M + 1 constraints. To best of our knowledge, 32,000 and 16,000 are the limits of numbers of variables and constraints for a non-linear optimization problem respectively, achi eved by the Lingo System (version 12.0). 2 Those are enough for almost all false trace identification problems we believe.
Once G are obtained, observed traces with latent generation probabilities lower than one tenth of the smallest o ccurrence frequency among all observed traces, an objective thres hold we proposed, may be fa lse traces. The acceptance of the identification result depends on the result of a  X  2 test with a specified confidence level 1  X   X  . If the test fails, which indicates that F cannot reflect P of traces, the identification result sho uld be rejected. It is necessary to note that passing  X  2 test is not a sufficient condition but a necessary condition. 3.3 False Trace Discovery It is general that only partial information about pollution is known. For example, an observed trace is found being polluted by chance, but it is unknown what the ratio of polluted traces versus obse rved traces is. Yet the FATILP can still help discover possible false traces by trying all types of known pollution and valid pollution ratios with the partial information. Two heuristic rules are used to find a better pollution description: 1) The smaller the distance, the better the pollution description. 2)The smaller the distance, the better the pollution ratio.
We believe that the false traces discov ery is an interactive process. At first the FATILP is run with transformation matrix, elements of which are initialized either based on partial pollution information or with equal transformation prob-ability. After the estimated results have been analyzed, the information about the pollution improved, and the element values of the transformation matrix re-vised, the FATILP will be run again. Iteratively the most possible pollution type of the log, the appropriate pollution ratio and all possible false traces will be found out at last. The FATILP is an indispensable tool during the interaction. Experiments were carried out to 1) validate the proposed approach, 2) demon-strate how to discover an appropriate pollution ratio as well as 3) the most possible pollution type for a given polluted log. 4.1 Experiment Design An experiment consists of two steps, 1) g enerating logs according to the specified generation probabilities of normal traces, pollution type, pollution ratio and log length, and 2) identifying false trace as well as evaluating experiment results. For a process model shown in Fig. 3, there are four normal traces T 1 ( ACDG ), T ( ADCG ), T 3 ( BEH ), and T 4 ( BFH ). For these traces, we here define three typical generation probability distributions of normal traces as shown in Table 2.
Two types of pollution are simulated, pollution D that R % of traces are pol-luted by missing an event and every event of a trace may be missed with the same probability and pollution E that R % of traces are polluted by exchanging orders of two adjacent events and every pair of adjacent events of a trace may be exchanged with the same probability. It is necessary to note that although complicated pollution, e.g. the two elementary types being combined together and/or repeated some times, may lead t o diverse element values of the trans-formation matrix, this diversity can be approximated by means of elementary pollution along with various generation probability distributions of traces (refer to the Q 2 ). That is the reason why pollution types D and E are selected.
To evaluate the performance of approaches for the false trace identification and fn are the numbers of false traces being identified as false traces and as true traces respectively, tn and fp are the numbers of true traces being identified as true traces and as false traces respect ively. Each experiment is repeated 100 times on 100 logs and the average values are used for evaluation.

To distinguish one experiment from the others, we name an experiment with acode XYZK ,where X is a pollution type ( D or E ), Y is a pollution ratio ( Y  X  10%), Z is a generation distribution type ( B , N or I ), and K is sample size, i.e. log length. The K may be omitted when the sample size is 5 k . 4.2 Experiment Results In Fig. 4, both sub-figures (a) and (b) depict that the performance of the pro-posed approach decreases from on balanced logs to on extreme unbalanced logs, but values of best performance of all experiments are greater than 0 . 9. The ap-proach is so sensitive to the pollution ratio that the best identification rates can only be achieved around the real pollution ratio, 50%, no matter what the pollution type is and what the distribution is. Both sub-figures (c) and (d) show that the performance of the approach gets better when the length of the extreme unbalanced log increases. We can conclude that if the log length is big enough, the performance of the approach on the extreme unbalanced logs would be as good as that on balanced logs, and ther e is no significant difference between performance of the proposed approach on logs with E and that on logs with D . Thus to illustrate the performance of the approach, experiments on logs with any type of probability distributions and any type of pollution are acceptable.
The traditional approach for noise identification in process mining is denoted as  X  X hr X  in Table 3, which depends on an empirical threshold [15]. The results of  X  X hr X  are based on the most appropriate threshold values respectively. Although the FATILP works as well as  X  X hr X  on balanced logs, it works better than  X  X hr X  on unbalanced logs. It is interesting th at the performance of FATILP increases when the log length increases, while th e  X  X hr X  does not. The main reason, we believe, is that the proposed approach considers the nature of pollution by means of modeling the process of pollution of event logs in a probabilistic manner.
Table 4 contains average least distances ( Q 2 values) and average performance ( h values) of experiments on E polluted balanced logs. The upper line lists pol-lution ratios used to generate polluted logs. The left column lists assumed pol-lution ratios used to identify false traces. From the values in the table, we know that both the minimal value of distance is obtained and the best performance is achieved when the assumed pollution ratio equals the real ratio. This property can help discover the correct pollution ra tio among assumed ratios, with which the approach performs best on a lo g given correct pollution type.

An example of looking for the exact pollution type as well as pollution ratio of a polluted log is presented in Table 5. A balanced log is polluted by means of pollution D with ratio 50%. To find out the real pollution, first the pollution E is assumed with pollution ratio increasing from 10% to 90%. The pollution ratio 10% seems a good choice since values of the distance Q 2 E and the statistic  X  2 E are minimal respectively. Second the pollution D is tried with, where both Q 2 D and  X 
D reach their minimal values at ratio 50%. And both Q 50% are less than Q 2 E and  X  2 E with ratio 10%, and the D pollution with ratio 50% may be a good option. Furthermore, the value of  X  2 D with ratio 50% is 11, which is much smaller than the critical value 43 . 82(=  X  2 (19)) with a confidence level 99 . 9%. Therefore the pollution D with ratio 50% is acceptable. Thus the proposed approach help find out the real pollution type of a polluted log. In this paper, the noise identification p roblem of event logs for process mining was discussed. We distinguished the concept of false trace, i.e. the invalid traces as regards the process model to be discov ered, from that of the polluted trace, i.e. noise, and focused on the false trace identification problem. On some natural and reasonable assumptions, we characterised the problem and modeled it as a quadric optimization problem of estimating a probability distribution. Then we proposed a common approach, FATILP, to estimate the latent generation probability distribution of normal traces given a polluted log and a description of pollution, and then to identify false traces at a user-specified confidence level. Experiment results show that the proposed approach works better than tradi-tional approaches, and it can be applied not only to identify false traces in a polluted logs but also to discover the most possible pollution type of the log as well as an appropriate pollution ratio interactively.

The work presented in this paper may be ex tended in several directions. First, the approach may be improved by taking informative completeness of event logs into consideration. Second, it may be possible to improve the precision of the estimation of latent generation probabilities of observed traces. Third, the approach may be extended to deal with new types of pollution, e.g. duplicate records of an event.
 Acknowledgements. The authors are indebted to Professor Wil M. P. van der Aalst for his suggestions on the motivation of the topic, to Professor Arthur H. M. ter Hofstede for his advice on the topic, constructive suggestions, and continuous encouragement, and to Dr. Moe T. Wynn for her suggestions on the presentation of the paper.
 The work reported in this paper is partially supported by the 973 Plan Program of China (No. 2009CB320700), the 863 Plan Program of China (No. 2012AA040911 and No. 2012AA040904) and NSF Projects of China (No. 61073005 and No. 61003099).
