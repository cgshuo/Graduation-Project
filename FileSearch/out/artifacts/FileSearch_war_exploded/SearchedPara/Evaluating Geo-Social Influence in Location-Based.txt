 The emerging location-based social network (LBSN) services not only allow people to maintain cyber links with their friends, but also enable them to share the events happening on them at dif-ferent locations. The geo-social correlations among event partic-ipants make it possible to quantify mutual user influence for vari-ous events. Such a quantification of influence could benefit a wide spectrum of real-life applications such as targeted advertising and viral marketing.

In this paper, we perform an in-depth analysis of the geo-social correlations among LBSN users at event level, based on which we address two problems: user influence evaluation and influen-tial events discovery . To capture the geo-social closeness between LBSN users, we propose a unified influence metric. This metric combines a novel social proximity measure named penalized hit-ting time , with a geographical weight function modeled by power law distribution . We propose two approximate algorithms, namely global iteration (GI) and dynamic neighborhood expansion (DNE), to efficiently evaluate user influence with tight theoretical error bounds. We then adopt the sampling technique and the threshold algorithm to support efficient retrieval of top-K influential events. Extensive experiments on both real-life and synthetic LBSN data sets confirm that the proposed algorithms are effective, efficient, and scalable.
 H.2.8 [ Database Applications ]: Data Mining Algorithms, Experimentation Social Network, Information Extraction, Structural Analysis
With the popularity of Web 2.0 technology and the proliferation of GPS-equipped mobile terminals, recent years have witnessed enormous growth in location-based social network (LBSN) ser-vices. These services, such as Foursquare, Facebook Places, and Google Latitude, not only allow one to maintain cyber links with other users, but also enable one to share one X  X  events/activities hap-pening at certain locations in various forms. To give a few exam-ples, a Foursquare user may check-in at a newly opened golf court, and an Apple fan may post a geo-tagged tweet when she is shop-ping at an Apple store. Such events are being created and shared everywhere and every second in LBSNs. Foursquare, as a repre-sentative LBSN, has hit a whopping 2 billion check-ins since its foundation in 2009, and millions of new check-ins are still being added every day [1].

Among the numerous LBSN events, some exhibit strong geo-graphical and social correlations among their participants, while others do not. Figure 1 shows the respective participants of three events in an illustrative LBSN, where each circle represents a user and its color indicates if he/she has participated in that event. We can observe that (1) the iPhone users (the green ones in Figure 1(a)) are socially connected and geographically close to each other; (2) the KFC users are faraway from each other both socially and geo-graphically; (3) the golf users are socially close but geographically faraway.

Such different geo-social correlations motivate us to study the mutual influence between social relation and geographical distance for LBSN events. In Figure 1, if an iPhone user, say u 2 , happens to find a new product at an Apple store in her vicinity, her posted information is likely to spread out across the community and drive nearby Apple fans ( u 1 and u 3 ) to the same store. On the contrary, if a KFC or golf user creates a related post, the others may be less influenced, either because the information cannot reach them or the location of the attraction is too far.

The above description leads to the following observations. On one hand, the social links facilitate the propagation of user-generated information in the network. Therefore, events happening in one X  X  close ties are likely to cause participation [3, 22]. On the other hand, the geographical distance plays a role (either strong or weak) in determining the users X  physical activities. Intuitively, people tend to visit nearby places rather than distant ones in practice [12, 8, 24]. However, the impact of distance on the tendency of partic-ipation is undefined. To date, no previous study has addressed the aforementioned mutual influence .

In this paper, we perform an in-depth analysis of the geographi-cal and social correlations among LBSN users for different events, and attempt to seek the answers to the following two interesting questions: 1. User Influence Evaluation: Given a set of LBSN users at-2. Influential Events Discovery: Given a set of events, how
Not difficult to imagine, the evaluation of geo-social influence can benefit a wide spectrum of real-life applications. Let us look at one example, an Apple store in New York wants to promote the sales of a newly released product (e.g., iPhone 5). By analyzing the mutual geo-social influences among iPhone users, it can simply target the local influential users and send coupons to them. If these users post relevant information on-line, many other iPhone fans are likely to be attracted to the store for that new product. Compared with existing social influence analysis methods [22, 11, 4], the most distinguishing characteristic in the geo-social influence evaluation process is the need to consider geographical distances among users. If a user u in New York has many social friends, but most of them live in Los Angeles, then u should not be regarded as influential : few of u  X  X  friends will be affected by u  X  X  post, because the store near u is too far for them. As another example, marketers can pro-mote products relevant to influential events, because the users of such events are typically close to each other in both geographical space and social space, thus the sales are expected to be elevated virally due to the intrinsic geo-social correlations.

Although a number of studies have analyzed the mutual user influence in social networks [22, 2, 3, 11, 4], none of the pro-posed techniques are capable of quantifying geo-social influence for events. The reasons are threefold: First, these studies typically perform social influence analysis in a global setting without con-sidering the events associated with each user. Second, while the information generated by one LBSN user may reach another via d-ifferent social paths, the influence analysis in the previous studies is usually confined to direct social links. Third, these studies fail to take into account the geographical distance between two users. In practice, however, people are more likely to visit nearby places rather than distant ones, indicating a clear need to explore the im-pact posed by geographical distance.
 Our Contributions. In this paper, we provide a unified user influ-ence metric which tightly combines social proximity and geograph-ical mobility features of LBSN users. On the social side, we pro-pose a modified version of the hitting time measure, named penal-ized hitting time (PHT), to quantify the social proximity between LBSN users. Hitting time is a random-walk-based graph proximity measure which has been shown to be effective for link prediction [17], query suggestion [18], graph clustering [7], and so on. How-ever, it is sensitive to long paths and tends to benefit popular entities [17, 19, 20]. Our PHT measure intrinsically avoids this drawback, owing to a nice property that the path weight is exponentially penal-ized by path length and thus short paths are given more priority. On the geographical side, we explore the mobility patterns of the user-s based on a real-life LBSN data set. The statistical results show that physical distance does play an essential role in determining the mobility behaviors of a user, and the geographical influence with regard to distance can be well modeled by power law distribution .
The computation of PHT is a challenging task, due to the fact that PHT takes account of all social paths between two LBSN user-s. As we will see, directly computing the PHT between two users takes O ( n 3 ) time ( n is the total number of LBSN users), which is intolerable for large LBSNs. In view of this problem, we pro-pose two approximate algorithms, namely the global iteration (GI) and dynamic neighborhood expansion (DNE) algorithms. Both al-gorithms work efficiently when computing PHT, and meanwhile ensure tight theoretical error bounds. In particular, the DNE algo-rithm can compute PHT in constant time regardless of LBSN size.
Relying on the user influence metric, we measure the influence of an event by aggregating the influences of event users, and investi-gate two specific aggregate functions, namely M AX and A VERAGE Not surprisingly, the discovery of influential events is not trivial ei-ther, especially when the number of event users and the number of LBSN events are both large. We employ the sampling technique to avoid computing geo-social influence for each user when esti-mating event score, and adopt the threshold algorithm to efficiently retrieve top-K influential events.

We have conducted extensive experiments on both real-life and synthetic LBSN data sets. The experimental results confirm the ef-fectiveness and efficiency of our proposed algorithms. Specifically, for the user influence evaluation problem, GI and DNE outperform existing solutions in running time by a factor up to an order of mag-nitude; for the influential events discovery problem, the sampling and threshold techniques work effectively for discovering top-K influential events, with many interesting findings.
 Organization. The rest of this paper is organized as follows. We review related work in Section 2 and formally define our problems in Section 3. In Section 4 and 5, we present algorithms for evaluat-ing user influence and discovering influential events, respectively. We study the empirical performance of the proposed algorithms in Section 6, and finally conclude the paper in Section 7.
Generally, existing approaches relevant to our work fall into three categories: social influence analysis, LBSN mining, and graph prox-imity computation.
 Social Influence Analysis. So far, many studies have investigated the influence of a single node in social networks. In a number of papers, it is believed that influence is relevant to the structural roles of the target nodes and their topological interactions with the un-derlying social network, and thus social influences can be derived with link analysis, e.g., PageRank [6] and HITS [16]. Many other s-tudies attempted to estimate social influence by exploring historical user data such as blogs [2] and tweets [4]. All these studies ana-lyzed social influence in a global setting without considering node attributes. In contrast, we compute social influence at event level and provide a finely grained capture of influence strength. Tang et al. [23] also found social influences could vary greatly across d-ifferent topics and performed topical influence computation using probabilistic model. Our social influence analysis significantly d-iffers from their work in that we associate each node with a set of discrete events based on ground-truth LBSN data, rather than a probabilistic latent topic distribution.

The interaction between social influence and structural correla-tion has also been extensively studied in literature. Specifically, Anagnostopoulos et al. [3] proposed to distinguish influence from other correlation factors based on temporal analysis of Flicker us-er behaviors. La Fond et al. [11] performed randomization tests for distinguishing influence and homophily in temporal social net-works. Guan et al. [13] studied the problem of assessing structural correlations on event-level granularity. The focuses of these studies are to determine the existence of social correlation or identify in-fluence hidden behind correlation, whereas we attempt to quantify the strength of influence.
 LBSN Mining. Recently, with the rise of on-line LBSN services, researchers have paid much attention to mining LBSN. To name afew,Cho et al. [8] modeled user location as a dynamic Gaus-sian mixture and employed a generative approach to postulate the mobility pattern of an individual, Scellato et al. [21] exploited ge-ographical features to address the link prediction problem, and Ye et al. [24] incorporated distance information into traditional col-laborative filtering framework for friend recommendation. These studies demonstrated that geographical distance could serve as a useful source for various mining tasks. Unfortunately, none of them attempted to fuse physical proximity with cyber connection to eval-uate influences among LBSN users.
 Graph Proximity Computation. Hitting time and its variants [19, 20] have been proposed and successfully used for link prediction [17], product recommendation [5], query suggestion [18], graph clustering [7], etc. These studies exploited the fact that hitting time captures the holistic feature of the underlying network and is quite robust to noise. However, it is also demonstrated that hitting time is sensitive to long paths and tends to benefit popular entities [17, 19, 20]. Our PHT measure, instead, has a nice property that the path weight is exponentially dampened by the path length, and thus intrinsically avoids this drawback. It is worth mentioning that al-though the decayed hitting time measure proposed by Guan et al. [13] also has this property, it can be viewed as a special case of PHT wherein the dampening parameter is fixed at e  X  1 .
A number of other graph proximity measures have also been pro-posed. In specific, Jaccard X  X  coefficient is defined as the number of the common neighbors of two given vertices divided by the num-ber of their distinct neighbors. The limitation of this measure is that it only considers the direct neighborhood of a vertex. In contrast, Katz [15] avoids this problem by summing over the collection of paths between two vertices, and the weight of a path decays expo-nentially with its length so that small paths are given more weight. Personalized PageRank [14] is another random-walk-based graph proximity, which biases the probability distribution of PageRank towards a set of pre-specified graph vertices. Although we adop-t the PHT measure in this work, the proposed framework can be extended to compute social influence under the above proximity measures.
In this section, we provide some preliminaries for evaluating geo-social influence in LBSN. In what follows, we introduce the concept of penalized hitting time in Section 3.1, conduct geograph-ical influence analysis in Section 3.2, and formulate our problems in Section 3.3. Table 1 lists the notations used in the rest of this paper.

Given an event e ,let u and v be two LBSN users in S e ,weana-lyze the social influence of u to v from a random walk perspective. A random walk in G is defined as follows: a user starts from vertex x 0  X  V G and randomly moves to its neighbors, if at step t the user is at vertex x t = i , then in the next step she moves to i  X  X  neighbor j with probability proportional to the weight w ij , namely: where d i = n j =1 w ij is the degree of vertex i . Clearly, the se-quence { x t } forms a Markov chain. We use P =[ p ij ] n denote the transition probability matrix of this Markov chain, so that p ij = w ij d i if ( i, j )  X  E G and zero otherwise.
Now consider a user performing a random walk from v , the user may hit u along various paths, as shown in Figure 2. Let L be the path along which v hits u for the first time, satisfying | assign a weight  X  h to L where  X  (0 &lt; X &lt; 1) is an attenuation parameter. In other words, the weight of L is exponentially damp-ened by its length, and thus short paths are made more important. The rationale behind is that people are more likely to be affected by their friends, rather than people socially faraway. Hence, two graph vertices are considered socially close if there are many short paths connecting them. Based on this observation, we define the penal-ized hitting time (PHT) as the expected path weight of the random walk that starts from v and hits u for the first time.

D EFINITION 1. Let u and v be two LBSN users in V G , given an attenuation parameter  X   X  (0 , 1) , the penalized hitting time from v to u is where Pr ( H u = h | x 0 = v ) is the probability that the random walk starting from v first hits u after h steps.
To analyze the geographical influence posed by physical dis-tance, we have crawled a real LBSN data set from Gowalla 1 ing a three-month period. We find that the users X  mobility patterns are significantly influenced by geographical distance. Specifical-ly, a user is more likely to visit a POI if that POI is not faraway from him. To better understand this, we calculate the distances be-tween all pairs of two consecutive check-ins and plot a histogram, as shown in Figure 3. Not difficult to observe, the log-scale check-in probability is approximately linear to the log-scale geographi-cal distance. The geographical influence can therefore be suitably modeled as a power law distribution w.r.t. geographical distance. Figure 3: Check-in probability vs. geographical distance.
D EFINITION 2. Given two users u and v ,let || l u  X  l v || geographical distance between u and v , we define the geographical influence of u to v as: where  X  and  X  are the parameters of a power law distribution. Remark. The geographical influence g u ( v ) could be interpreted in the following way: u and v are two users attributed with a common event (e.g., playing golf), if u creates a post related to a golf court near him and v knows this via the LBSN, given the distance of u and v , how likely would v also pay a visit to the golf court?
The PHT measure captures the social proximity between LBSN users and the power law distribution models their physical interac-tions. We combine them to derive a unified geo-social influence metric.

D EFINITION 3. Let u and v be two LBSN users attributed with a common event, the geo-social influence of u to v is given by:
Relying on the unified influence metric, we are now ready to formulate the user influence evaluation and influential events dis-covery problems.

P ROBLEM 1. (User Influence Evaluation) Given an event e and its user set S e , evaluate the geo-social influence of user u to all the other users in S e : http://en.wikipedia.org/wiki/Gowalla
P ROBLEM 2. (Influential Events Discovery) Given an even-t collection C , retrieve K events from C with the largest event s-cores. The score of an event e is defined as the aggregate user influence of the users in S e : where A GG can be the aggregate function M AX or A VERAGE
In this section, we discuss how to derive the influence of one user. Below, we first provide the GI and DNE algorithms for com-puting PHT in Section 4.1, and then investigate the computation of geographical influence in Section 4.2.
Given two users u and v ,thePHT s u ( v ) is the expected path weight of the random walk that starts from v and first hits u . Nat-urally, we could compute s u ( v ) in a one step look-ahead fashion: consuming one step to move to v  X  X  neighbors and then summing up their PHTs. Accordingly, we have:
Hence, the following recurrence relation holds for any user v V . Let P u be a modification of the original transition matrix where the entries in the row corresponding to u are set to all ze-ros; s u be a n  X  1 vector ( n = | V G | )where s u ( v ) is the PHT from v to u ;and c u be a n  X  1 vector with the element corresponding to u set to 1, and all other elements to 0. Then the recurrence relation leads to a linear system consisting of n equations: Now, the problem of computing the PHT of every user v  X  V u is reduced to solving Equation 3 to obtain the vector s nately, the time complexity of solving the linear system is O ( n which is prohibitive for large LBSNs containing millions of users.
Algorithm 1: GlobalIteration( P u , c u , X ,k ) 1 Initialize s (0) u = c u 2for i =1 to k do 4return s ( k ) u
To overcome this problem, we propose the global iteration (GI) algorithm to obtain approximate PHTs. The idea is to assign an arbitrary PHT value for each user in V G , and then iterate over the linear system for a few times. As shown in Algorithm 1, we choose c as an initial PHT vector. Then, we substitute s ( i ) u into Equation 3 and get the next-round PHT vector. After iterating for k rounds, we output s ( k ) u as the resulting PHT vector. In the following, we prove the GI algorithm will converge to the exact value of is large enough, and give an analytical error bound of s (
T HEOREM 1. The iterative process will converge to the exact value of s u if k  X  X  X  .

P ROOF .Let T =  X  P u ,the l  X  natural norm of T is
Then the spectral radius of T satisfies  X  ( T )  X || T ||  X  With Equation 3, we have the k -th round value of s ( k ) Since  X  ( T ) &lt; 1 , the matrix T is convergent and lim which ensures that:
Hence, the sequence { s ( k ) u } converges to ( I  X  T )  X  1 c is exactly the solution of Equation 3.

T HEOREM 2. Let s ( i ) u be the i -th round estimation of V Let || X || be the l  X  natural norm, then: || s
Thus,  X  m&gt;k ,wehave:
We know that lim which completes the proof.
The GI algorithm reduces the complexity of PHT computation still not the best one can hope for. Indeed, for LBSNs involving mil-lions of users, a single matrix-vector multiplication could be quite expensive, making it really necessary to design a more efficient and scalable solution. Below, we propose another, more efficient algo-rithm called dynamic neighborhood expansion (DNE), which can compute PHT in constant time with a tight theoretical error bound.
As stated above, the major problem of GI is that it needs to per-form matrix-vector multiplications over the entire LBSN. We ar-gue that the PHTs of the users socially faraway from u are actually negligible as the weight of a path is exponentially dampened by its length. Based on this observation, DNE performs PHT computa-tion in two phases: (1) In the first phase named expansion-update , DNE starts from u and incrementally expands u  X  X  neighborhood to incorporate users that are close to u , and obtains their PHTs using the recurrence relation (Equation 2). Such a process continues un-til the cardinality of u  X  X  neighborhood is large enough to ensure a small approximation error. (2) In the second phase named refine-ment , DNE performs a few iterations (Equation 2) over the neigh-borhood vertices to refine their PHTs. The PHTs of vertices outside u  X  X  neighborhood are set to zeros and do not need to be computed at all.

Let N u be the set of vertices that have been incorporated into u  X  X  neighborhood, and B u  X  N u be the set of boundary vertices ( X  X oundary X  means the vertex has at least one neighbor not in N A fundamental issue in the first phase is: which vertex in B be chosen to expand in each round? We adopt the best-first strategy and choose the vertex with the largest PHT in B u . The rationale be-hind is twofold: First, for a vertex with large PHT, its neighbors are also likely to have large PHTs (Equation 2). The best-first manner thus gives priority to vertices with high PHTs and inclines to ignore unimportant vertices. Second, soon we will see, the approximation error of DNE is determined by the vertex with the largest PHT in B . By eliminating it, DNE can produce a better approximation after each expansion.

Algorithm 2: DNE( P u , c u , X ,m,k ) 1 Initialize N u = { u } ,B u = { u } , s (0) u = c u 2 while | N u | &lt;m and B u =  X  do 3 Remove w from B u where s (0) u ( w )=max 4 foreach in-neighbor v of w do 5if w/  X  N u then 6 Add w into N u 7 foreach in-neighbor v of w do 8if w has any in-neighbor not in N u then 9 Add w into B u 10 foreach v  X  N u do 11 s (0) u ( v )=  X  // Refinement 12 for i =1 to k do 13 foreach v  X  N u do 14 s ( i ) u ( v )=  X  15 return s ( k ) u
Algorithm 2 presents the details of the DNE algorithm. As shown, we initialize N u with { u } and incrementally expand N u s cardinality reaches a pre-defined number m . Each expansion is directed by the best-first strategy such that the vertex with largest PHT in B u is selected and its neighbors are added into N refinement phase, we iterate over the vertices in N u for k times and finally output s ( k ) u .Let s u be the ideal PHT vector by ignoring all vertices not in N u , it is worth mentioning that the output of DNE is actually the k -th round estimation 2 of s u .
 Figure 4 gives an example of the DNE algorithm with  X  =0 . 6 . We use dark circles to denote the vertices that have been incor-porated into N u . Among them, the ringed ones denote the ver-tices that are in B u . To compute the PHTs of all vertices to u , the DNE algorithm executes the following steps: (1) Initialization: s ( u )=1 . (2) Expand u and update: s u ( u )=1 ,s u ( v 1 and update: s u ( u )=1 ,s u ( v 1 )=0 . 2 ,s u ( v 2 )=0 . 6 ,s 0 . 3 ,s u ( v 4 )=0 . 15 ,s u ( v 5 )=0 . 18 . (4) Expand v s ( u )=1 ,s u ( v 1 )=0 . 2 ,s u ( v 2 )=0 . 6 ,s u ( v 3 )=0 . 354 ,s 0 . 15 ,s u ( v 5 )=0 . 18 ,s u ( v 6 )=0 . 06 ,s u ( v 7 fine PHTs for 10 times: s u ( u )=1 ,s u ( v 1 )=0 . 227 ,s 0 . 6 ,s u ( v 3 )=0 . 366 ,s u ( v 4 )=0 . 15 ,s u ( v 5 0 . 068 ,s u ( v 7 )=0 . 068 .
Suppose the average degree of each vertex in V G is  X  . Then the complexity of the expansion-update phase is O (  X  2 +2  X  2  X  2 )= O ( m 2 ) , and that of the refinement phase is O ( mk X  ) . The total complexity of the DNE algorithm is thus O ( m 2 While it saves vast amounts of computation cost, the question is: how well does DNE approximate the PHTs of all vertices? Below, we provide a theoretical error bound for DNE.
 L EMMA 1.  X  v  X  V G , it is ensured s u ( v )  X  s u ( v ) .
P ROOF .Let P u be a modification of P u where the row entries corresponding to vertices not in N u are set to all zeros, then we have s u =  X  P u s u + c u .Let T =  X  P u , then its spectral radius satisfies  X  ( T )  X || T ||  X  &lt; 1 . Following the same manner as in the proof of Theorem 1, we obtain:  X  k  X  0 ,wehave T k c u  X  T k c u . Hence,  X  v  X  V G ,itis ensured that s u ( v )  X  s u ( v ) . And s ( k ) u = s u when k  X  X  X  .

L EMMA 2. Let M =max not in N u ,then  X  v  X  O u , s u ( v )  X  s u ( v )  X   X  M .
P ROOF .Since  X  v  X  O u , s u ( v )=0 , it suffices to prove  X 
M . We construct a matrix P B for vertices in O u  X  B u , where the rows of vertices in O u stay the same as in P , and the rows of ver-tices in B u are set to all zeros. In addition, we construct a column vector c B where the entries of vertices in O u are set to zeros, and the entries of vertices in B u are set to their accurate PHTs. As the PHTs of all vertices in O u are gained from the vertices in B , the accurate PHTs of vertices in O u  X  B u satisfy s =  X  c . Again, the solution of this linear system can be obtained with the iterative technique, namely s ( k ) =  X  P B s ( k  X  1) lim
Let s (0) = c B ,then  X  v  X  O u  X  B u , s (0) ( v )  X M . Moreover, if  X  v  X  O u  X  B u , s ( k ) ( v )  X M , it is ensured  X  v  X  O u  X 
M . Hence,  X  v  X  O u ,wehave s u ( v ) = lim thus completing the proof.

L EMMA 3. Let M =max s ( v )  X   X  2 M .

P ROOF .Let  X  s u be a n  X  1 vector where  X  s u ( v )= s u s ( v ) . We construct another n  X  1 vector  X  c , where the entries of vertices in O u are set to their accurate PHTs and the entries of vertices in N u are set to zeros. Since the PHT errors for al-l vertices in N u are all caused by vertices in O u ,  X  s  X  s u =  X  P u  X  s u + X  c .

The solution of this linear system is given by the iterative repre-sentation  X  s u = lim V ,  X  s (0) u ( v )  X   X  M . In addition, if  X  v  X  V G ,  X  s  X 
M ,then  X  v  X  N u ,  X  s ( k +1) u ( v )  X   X  2 M . We thus have N u ,  X  s u ( v ) = lim k  X  X  X   X  s max s u ( v )  X  s ( k )
P ROOF .Let w  X  B u be the vertex corresponding to M = max s ( w )  X   X  2 M , which can be transformed to
Meanwhile, following the same manner as in the proof of Theo-rem 2, for any vertex in V G ,wehave (1)With Lemma 2, we obtain  X  v/  X  N u , s u ( v )  X  s ( k s ( v )  X  s u ( v )  X   X  M X   X  1  X  ensured M X  M ( k )  X   X  . Thus, s u ( v )  X  s ( k ) u ( v )  X  ) . (2)With Lemma 3, we have  X  v  X  N u , s u ( v )  X  s  X  s
The computation of geographical influence is quite straightfor-ward so long as the parameters  X  and  X  in Equation 1 are known. In this section, we use ridge regression to estimate  X  and  X  .To achieve this, we first need to transform Equation 1 into log-log s-cale: Let y =log g u ( v ) , x =log || l u  X  l v || ,  X  0 =log  X  ,and  X  then the above equation becomes y =  X  0 +  X  1 x . We employ the least square error as the loss function, namely: Here, n is the number of histogram points, t i is the ground truth probability of point i ,and  X  is the regularization term to avoid overfitting. The optimal values of  X  0 and  X  1 can be obtained as opt {  X  0 , X  1 } =arg  X  0 , X  1 min E (  X  ) . Accordingly,  X  and  X  can be derived as  X  =10  X  0 and  X  =  X  1 .
Up to now, we have restricted our discussion to the user influ-ence evaluation problem. In this section, we address the influen-tial events discovery problem. Recall that the score of an event e is defined as the aggregate (M AX or A VERAGE ) user influence of the users in S e . To retrieve top-K influential events from an event collection C , the straightforward way is as follows: First, we com-pute the influence of each user in S e , and derive their aggregate influence as e  X  X  score. Then, by computing the score of each event e  X  C , we can find out K events with the largest scores. How-ever, such a straightforward solution may be inefficient when the cardinalities of S e and C are both high. In view of this problem, we exploit the sampling technique and the threshold algorithm to speed up the discovery of top-K events.
 When computing the score of one event, we adopt the standard Monte Carlo sampling scheme. To be more specific, given an event e , we randomly pick c users from S e and compute the influences of these c users. Then, we obtain their aggregate influence as an estimate of score ( e ) . Below, we provide the lower bound of c to obtain an -correct answer for score ( e ) when the aggregate func-tion A VERAGE is used.

T HEOREM 4. Suppose we randomly select c users from S e to estimate the average influence score of e , to ensure Pr ( score ( e ) | X  )  X  1  X   X  , the number of samples c must satisfy c P ROOF . According to Hoeffding X  X  inequality, we have Setting 1  X  2 e  X  2 c 2  X  1  X   X  ,weget c  X  1 2 2 ln 2  X  .
To avoid computing influence score for every event in C when retrieving top-K influential events, we adopt the threshold algorith-m [10]. The key observation is that, the geo-social influence of one LBSN user to another must not exceed  X  . Thus, for an event e ,its score will never be larger than  X  ( | S e | X  1) . Based on this observa-tion, Algorithm 3 gives the details of the threshold algorithm. As shown, we first build a list L of all LBSN events, sorted in the de-scending order of cardinality. Then we initialize an empty result set A with a fixed size k , and keep track of the least ranking score in A as threshold . Next, we scan L sequentially and progressively update A . The tricky part is that L is unnecessary to be scanned entirely. For the event e currently being processed, if  X  ( is below threshold , it is ensured the score of any following event will be below threshold as well. Thus, further scanning will not generate top-K results any more and the algorithm safely termi-nates.

Algorithm 3: getTopKEvents( G, K ) 1 Build a list L of all events in G 2 Sort L in the descending order of event cardinality 3 Initialize an empty set A of a fixed size K 4 foreach event e in L do 5 threshold = the least influence score in A 6if | A | = k and  X  ( | S e | X  1)  X  threshold then 7break 8 Compute score ( e ) with sampling technique 9if | A | &lt;k or score ( e ) &gt; threshold then 10 Update A with e 11 return A
In this section, we empirically evaluate the effectiveness and efficiency of the proposed algorithms. First in Section 6.1, we demonstrate the effectiveness of our geo-social influence evalua-tion framework with a toy example. Then we examine the perfor-mance of the proposed algorithms on a real-life LBSN data set in Section 6.2. Finally, we study the scalability of the algorithms with synthetic data sets in Section 6.3. All algorithms were implement-ed in JAVA and the experiments were conducted on an Intel Core 2 Duo 2.93Ghz PC with 4GB memory.
We first apply our geo-social influence computation framework to the running examples described in Figure 1, and see if the pro-posed measures can indeed effectively compute user influence and discover influential LBSN events. We run the GI algorithm with the attenuation parameter  X  =0 . 5 , and the iteration number k =20 . Meanwhile, we compute geographical influence with the parame-ters  X  =6 . 0 , X  =  X  1 . 45 (obtained from Figure 3). Table 2 reports the social and geographical influence of each user, as well as the scores of the three events iPhone, KFC and Golf . Recall that, given an event e and its user set S e , there are two versions of event score, depending on different aggregate functions (M AX or A VERAGE We denote by M-score the maximum user influence of the users in S ,by A-score the average user influence of the users in S e
We can see, user u 2 has the largest geo-social influence to the other users. This agrees with our intuition that u 2 can be easily hit by u 1 and u 3 , and since their geographical distances are small, u and u 3 are likely to visit the Apple store near u 2 . Among the three events, iPhone has the largest score since its users are close both geographically and socially. In contrast, KFC has low social and geographical scores as its users scatter randomly in the LBSN. Golf has high social influence but relatively low geographical influence, due to the fact that although its users are socially close, they are distant to each other geographically.
In this subsection, we evaluate the performance of our proposed algorithms based on a large real data set obtained from Gowal-la. We crawled this data set during a three-month period between September 2011 and December 2011. There are 329839 users with 1679245 undirected social links among them, those users have al-together visited 2973453 distinct POIs. We consider each POI as an event and the users who have checked-in at the POI as the par-ticipants of that event. The location where a user most recently checked-in is regarded as his location.
We study the performance of the GI and DNE algorithms for computing PHT under two performance metrics, namely time and bias . Given an event e and a user u  X  S e , time is the total elapsed time of computing the PHTs of all other users in S e to u ,and bias is the sum of absolute PHT approximation errors. For compari-son, we also implemented the Simulation algorithm (abbreviated as SML) [13], which is essentially a sampling based algorithm for computing decayed hitting time . SML can be slightly modified in the following way to compute PHT: Given an event e and a user u  X  S e , to compute the PHTs of all other users in S e to u , we inde-pendently run c random walk simulations from each v  X  S e Each random walk stops when u is hit or a maximum number of steps s is reached. Then, we derive the average path weight of the c simulations as v  X  X  PHT.
 Convergence of GI and DNE. We first check the convergence of the GI and DNE algorithms. GI has one parameter (the number of iterations k ) and DNE has two parameters (the size of neighbor-hood m and the number of local iterations k ). For GI, we investi-gate its convergence w.r.t k . For DNE, we find that the bias does not vary much when the number of iterations is larger than 5. Thus, we set k =5 and investigate its convergence w.r.t m .
 We randomly choose a popular event e ( | S e | &gt; 1000 ) from the Gowalla data set along with an arbitrary user u  X  S e ,andthen compute the PHTs of other users in S e to u . Such a process is repeated 100 times and the average results are reported. As shown in Figure 5, both algorithms converge rapidly when the respective parameters k and m increase. Moreover, the bias of DNE is only slightly larger than GI, even when the cardinality of neighborhood is as small as 1000. It suggests that DNE empirically provides a good estimation of PHT. Performance vs. Event Size. In this set of experiments, we com-pare the performance of the GI, DNE, and SML algorithms for events of different sizes. We set k =10 for GI; and m = 1000 ,k = 5 for DNE. Such parameter settings are adequate to ensure GI and DNE provide good estimations of PHTs (Figure 5). For SML, larg-er c and s values lead to tighter estimations of PHTs, and smaller c and s values contribute to better efficiency. We set c = 1000 and s =20 , as we find that this setting makes SML reach a good balance between estimation tightness and running time.

Figure 6 reports the results when event size varies from 400 to 2000. As shown, the running time of SML grows linearly while that of GI and DNE stays constant, yet SML still causes much larger bias than GI and DNE. This is expected. Although appealing for its simplicity, SML suffers from two shortcomings: (1) SML needs to perform c random walk simulations for each user v  X  S e  X  X  indicating that the time cost will grow rapidly as | S e | contrast, GI and DNE both compute the PHTs of all users at one time and thus are | S e | -independent. (2) SML is a non-deterministic approximate algorithm and its bias may fluctuate randomly. GI and DNE, on the contrary, are deterministic algorithms with tight theoretical error bounds.

Comparing the performance of GI and DNE, we can see DNE is much more efficient than GI, but it has larger bias than GI. This is because DNE excludes vertices that are too faraway from the target vertex, and thus sacrifices a little precision for speed. Fortunately, since the PHT of each excluded vertex is always small (Lemma 2), the total bias of DNE is still acceptable even when the event size is quite large ( 0 . 023@2000 ).
We proceed to evaluate the influence scores for different events in the Gowalla data set. Since DNE is much faster than GI and also provides quite tight estimations for PHTs, we employ the DNE al-gorithm to compute PHT, with the parameters m = 1000 ,k =10 . Using the ridge regression technique as described in Section 4.2, we obtain the parameters of the power law distribution for comput-ing geographical influence:  X  =6 . 0 , X  =  X  1 . 25 .

Again, given an event e ,wedenoteby M-score the maximum user influence of the users in S e , and by A-score the average user influence of the users in S e . Event Scores of Different Categories. The 2973453 Gowalla events distribute in 416 different categories. In this set of exper-iments, we look into how the M-score and A-score vary across d-ifferent categories. For this purpose, we choose 10 representative categories and compute the M-score and A-score for every event in each category, with the attenuation parameter  X  =0 . 8 . Table 3 presents the largest M-score and A-score in each category. Table 3: Largest M-scores and A-scores for 10 representative categories in Gowalla (  X  =0 . 8 ).

We can see, the M-score and A-score are high for the categories library , bar ,and theater . This indicates that the visitors of a typi-cal POI in these categories are close to each other both geograph-ically and socially. For example, the POI reaching the largest M-score 21.782 in the category library is the M.D. Anderson Library in the University of Houston, which has 97 visitors. Our manual investigation suggests that these visitors are mostly students from the University of Houston, each one having many social links with the others. Not difficult to imagine, if the M.D. Anderson Library launches a new service and employs one of the 97 student to post this message on-line, the information can quickly reach the other students and may drive them to experience it. Likewise, the high scores of the categories bar and theater imply the users form social communities for some hobby (drinking or watching drama), and meanwhile live congregationally.

In contrast, the M-score and A-score are low for the categories hotel and airport terminal . This is because the social relations a-mong hotel and airport visitors are usually weak, resulting in low social correlations. Moreover, people visiting a hotel mostly do not live in the city where the hotel locates, and it is the same for people visiting an airport.

For the rest five categories, the M-score and A-score of the cat-egories apparel and food are lower than the apple store category. This means people are more likely to follow their friends X  prefer-ences when they are purchasing a digital product than purchasing clothes or food. The scores of the categories resort and historic landmark are quite high. Interestingly, we find the events reaching largest M-scores are usually hot places with thousands of visitors, whereas the events reaching largest A-scores are some local places with only a few visitors that are highly correlated. Take the cate-gory resort as an example, the event corresponding to the largest M-score 10.258 is the Disney X  X  Grand Floridian Resort , which has 739 visitors from both Florida and other states. In contrast, the event with the largest A-score is the Bauwagen Estenfeld ,whichis a local resorting club located in Germany, having only 11 visitors living in Estenfeld.
 Top-K Events in Each Category. In this set of experiments, we zoom in to retrieve top-K influential events in one category. In the following, we report the results for the categories apparel and asian food .

Table 4 and 5 are the top-five influential events in category ap-parel with the largest M-scores and A-scores, respectively. From Table 4, we find that the events with large M-scores are usually fa-mous brands (e.g., Zara) having a significant number of consumer-s. One can also observe that hot brands with large M-scores do not necessarily have large A-scores. It is because there exist many consumers who have weak connections with the other consumers of those hot brands, the low influences of such consumers drasti-cally pull down the A-scores. In contrast, the events with large A-scores are mostly some brands not so famous, but possessing a set of consumers that are highly correlated. Take Bergner X  X  as a con-crete example, it is a department store offering mid-line to higher end merchandise. The 15 customers of Bergner X  X  all live in central Illinois, and there are as many as 68 social links among them.
Another interesting finding is that, the retrieved events are most-ly stores selling women X  X  apparel. This implies that females are more likely to discuss with their friends and follow their choices, leading to the formation of fan communities for some brands. In comparison, the purchasing behaviors of males do not exhibit so much aggregation.
 Table 4: Top-5 events with the largest M-scores in category  X  X p-parel X .
 Table 5: Top-5 events with the largest A-scores in category  X  X p-parel X .

Table 6 and 7 present the top-five events in category asian food , along with the POI locations. Somewhat surprisingly, few of the top POIs are located in Asia, especially for the POIs with large A-scores. The reason may be that people visiting Asian restaurants in America or Europe are usually Asian immigrants or Asian stu-dents studying abroad. It is highly possible that they have strong social relations with each other, forming fan communities for the restaurants serving hometown food. Our manual investigation veri-fies this phenomenon. Take the restaurant China Tiger as an exam-ple. We find its consumers are mostly Chinese students studying in Helsinki, they live quite close to each other and there are a signifi-cant number of social links in the ensemble.
To examine the scalability of the proposed algorithms, we exploit the publicly available data set LiveJournal 3 , a free on-line commu-nity whose members are highly active. The LiveJournal data set has 4847571 users and 68993773 directed social links. We do not have user locations or events for this data set, so we only use it to check the scalability of the GI and DNE algorithms. Specifically, we extract synthetic subgraphs with different graph sizes (in terms of vertex number) from LiveJournal. Meanwhile, we randomly s-elect 100 target users. Then we run the GI and DNE algorithms on each subgraph to compute PHTs to those 100 users and report the average running time. Figure 7 is the result. As shown, while http://snap.stanford.edu/data/soc-LiveJournal1.html Table 6: Top-5 events with the largest M-scores in category  X  X sian food X .
 Table 7: Top-5 events with the largest A-scores in category  X  X sian food X .
 the running time of GI grows with graph size, that of DNE remain-s constant. This is because DNE only iterates over vertices in the neighborhood of a target vertex, and thus works more efficiently than GI for large LBSNs.
This paper provided an in-depth study of geo-social influence in location-based social networks. We proposed a unified metric to quantify mutual user influence on event-level granularity. This metric combined a novel social proximity measure named penal-ized hitting time , with a geographical weight function modeled by power law distribution . Based on this metric, we addressed the us-er influence evaluation and influential events discovery problems. Specifically, we proposed two approximation algorithms, namely GI and DNE, to efficiently compute user influence; and we adopted the sampling technique and the threshold algorithm to retrieve top-K influential events. Our experimental results demonstrated that the proposed algorithms are effective, efficient, and scalable.
There are some potential future directions of this work. In partic-ular, besides the power-law distribution, it is promising to consider other methods [9] for modeling the geographical mobility patterns of users. Moreover, it is also interesting to explore the performance of different combinations of geographic influence and social influ-ence in addition to their product.
This work was supported in part by the National Science Foun-dation of China (Grant No. 60970124, 60903038, and 61170034). [1] http://goo.gl/Y39Gm . [2] N. Agarwal, H. Liu, L. Tang, and P. S. Yu. Identifying the [3] A. Anagnostopoulos, R. Kumar, and M. Mahdian. Influence [4] E. Bakshy, J. M. Hofman, W. A. Mason, and D. J. Watts. [5] M. Brand. A random walks perspective on maximizing [6] S. Brin and L. Page. The anatomy of a large-scale [7] M. Chen, J. Liu, and X. Tang. Clustering via random walk [8] E. Cho, S. A. Myers, and J. Leskovec. Friendship and [9] A.Clauset,C.R.Shalizi,andM.E.J.Newman.Power-law [10] R. Fagin, A. Lotem, and M. Naor. Optimal aggregation [11] T. L. Fond and J. Neville. Randomization tests for [12] M. C. Gonz X lez, C. A. H. R., and A.-L. Barab X si.
 [13] Z. Guan, J. Wu, Q. Zhang, A. Singh, and X. Yan. Assessing [14] G. Jeh and J. Widom. Scaling personalized web search. In [15] L. Katz. A new status index derived from sociometric [16] J. M. Kleinberg. Authoritative sources in a hyperlinked [17] D. Liben-Nowell and J. M. Kleinberg. The link prediction [18] Q. Mei, D. Zhou, and K. W. Church. Query suggestion using [19] P. Sarkar and A. W. Moore. A tractable approach to finding [20] P. Sarkar, A. W. Moore, and A. Prakash. Fast incremental [21] S. Scellato, A. Noulas, and C. Mascolo. Exploiting place [22] P. Singla and M. Richardson. Yes, there is a correlation: -[23] J. Tang, J. Sun, C. Wang, and Z. Yang. Social influence [24] M. Ye, P. Yin, W.-C. Lee, and D. L. Lee. Exploiting
