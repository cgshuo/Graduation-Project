 Question Classification plays an im portant role in most Question Answering systems. In this paper, we exploit semantic features in Support Vector Machines (SVMs) for Question Classification. We propose a semantic tree kernel to incorporate semantic similarity information. A diverse set of semantic features is evaluated. Experimental results show that SVMs with semantic features, especially semantic classes, can significantly outperform the state-of-the-art systems. H.3.1 [ Content Analysis and Indexing ], H.3.3 [ Information Search and Retrieval ].
 Semantic Class, Tree Kernel, S upport Vector Machines, Question Classification, Question Answering, Machine Learning Question Answering (QA), initiated in the Text Retrieval Conference (TREC, http://trec.nist.gov) since 1999, aims to find documents. A typical QA system adopts a pipeline structure that contains  X  X uestion analysis X ,  X  X assage retrieval X ,  X  X nswer extraction X  and  X  X nswer ranking X  modules. Question analysis mainly focuses on so-called Ques tion Classification (QC) which divides questions into several pred efined semantic categories. As the first processing step of a QA system, QC can help not only to exclude irrelevant answers with types not matching the identified following processing steps. The accuracy of QC has great impact on the overall performance of QA systems. 
Kernel based methods such as Support Vector Machines (SVMs) have proven to be powerfu l in data classification. Here we adopt a new tree kernel incorporating a rich set of semantic features extracted from the questi ons. Experimental results show that the SVM classifier with the new kernel significantly outperforms the state-of-the-art systems on the community-standard data set. 
Tree Kernel (TK) [1] measures the similarity of two trees by counting the number of their co mmon tree fragments. Here we Semantic Class List of Words Organization company, bank, club, college, army, ...... 
Substance mental, stone, mineral, fuel, gas, ...... (2) WordNet senses. In WordNet, words are organized in a hierarchy of synonyms, hypernyms and hyponyms. As shown in Equation (1), we set appropriate values respectively for the case that two words are synonyms or one is a hypernym of the other. (3) Named Entities (NEs). We use an external Named Entity Recognition (NER) tool to identify NEs in questions. Here we only consider three types of NEs: person, organization and location. 
In our experiments, we use th e public available dataset [2] constructed by UIUC, which is frequently used in Question Classification research. The dataset contains about 5,500 questions as training set and 500 questions from TREC 10 QA Track as test set. These manually labeled questions can be divided into 6 coarse-grained categories and 50 fine-grained ones. Here we only focus on coarse-grained classification. 
First of all, we process the question in the dataset with a noun phrase chunker. In each noun phrase, we only preserve the head word and ignore other words. After that, we replace the identified Named Entities with their corresponding type names. Given the question  X  X hat is the only color Johnny Cash wears on stage? X  as an example, after chunking and NE recognition, we find a noun phrase  X  X he only color X  and a person NE  X  X ohnny Cash X . Thus we preserve the head word  X  X olor X  in the noun phrase and replace  X  X ohnny Cash X  with its NE type, finally we get 
We use an implementation similar to [3] as the baseline. Then we evaluate different combination of the above semantic features. As shown in Table 2, semantic classes can evidently help to improve the accuracy, while the WordNet senses and NE features can only make slightly improvement. Table 3 illustrates the accuracy comparison of our approach with state-of-the-art results in the literatures, in which we can see that our approach observably outperforms the st ate-of-the-art systems. 
In this paper, we have introduced a new tree kernel to encode textual information in Question Cl assification task. We have also evaluated the kernel with comb ination of different semantic feature sets. Our experimental results suggest that semantic information, especially semantic classes, can help to improve accuracy significantly in SVM question classifier. Since the semantic class informa tion appears to be promising in QC, in our future work, we aim to study on automatically mining semantic classes from the web or external corpus, instead of 
