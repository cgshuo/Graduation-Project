 1. Introduction
Researches on data streams are motivated by emerging applications involving continuous massive data sets such as customer click streams, multimedia data and sensor data. Data in these applications can be described as a data stream rather than a persistent finite data set. A data stream is defined as a massive unbounded sequence of data elements continuously generated at a rapid rate. Due to this reason, it is impossible to maintain all the elements of a data stream. Consequently, on-line data stream processing should satisfy the following requirements [1 X 4] . First, each data element should be examined at most once to analyze a data stream. Second, memory usage for data stream processing should be confined finitely although new data ele-ments are continuously generated in a data stream. Third, newly generated data elements should be processed utilized upon request. To satisfy these requirements, data stream processing sacrifices the correctness of its analysis result by allowing some errors.

For emerging applications involving massive data streams, various data mining algorithms [2,5 X 7] have been actively introduced. To find clusters in an on-line data stream, the k -median algorithm [8] uses an
O(1)-approximate k -medoid method for each sub-set of a data stream. In order to overcome the iterative eval-k approximate data elements, i.e., medoids each of which represents the center of a cluster for the data ele-ments observed so far in a data stream. CluStream [6] is proposed to find the clusters of data elements gen-erated in an evolving data stream. It executes the conventional K -means method to find initial q pseudo clusters called micro clusters . A cluster feature vector [10] is used to represent the properties of a cluster.
As a new data element arrives, the cluster features of the q micro clusters are continuously updated. The clus-ter feature vectors of all clusters at each specified timestamp are stored as a snapshot. The CluStream produces k final clusters called macro clusters by executing the K -means algorithm once more on the micro clusters of these snapshots. We have proposed a grid-based clustering method called hybrid-partition method [11] for an on-line data stream. However, it is impossible to employ any index structure to directly access a specific grid-cell whose range includes a newly generated data element in a data stream. Therefore, the ranges of all the partitioned grid-cells should be sequentially examined one by one. As the number of grid-cells is increased, this operation takes longer and becomes a major bottleneck for the algorithm proposed in [11] .
In order to eliminate the above drawbacks of our previous work, a sibling list and a cell tree are proposed in this paper. While the hybrid-partition method divides the range of a selected dimension of a dense grid-cell into two disjoint regions, the proposed method divides a dense grid-cell into a fixed number of equal-size grid-cells. Given a partitioning factor h , a dense grid-cell whose current support becomes greater than or equal consecutive sparse grid-cells can be merged into a single grid-cell. Subsequently, this recursive partitioning process is terminated when the interval of every dimension of a grid-cell becomes the smallest size k . Such factor, it is possible to make the size of every unit grid-cell be the same, so that the problems of our previous work can be resolved. A sibling list is a structure to manage the set of all grid-cells in a one-dimensional data space and it acts as an index for locating a specific grid-cell.

Upon creating a dense unit grid-cell for the dimension of the first level of a cell tree, a new sibling list for another dimension is created as a child of the dense unit grid-cell in the second level. Subsequently, the dis-tribution statistics of two-dimensional rectangular grid-cells in the new sibling list are monitored by the same way. Given a data stream of a d -dimensional data space, the distribution statistics of k -dimensional rectangu-a cluster of the data stream is a set of adjacent d -dimensional dense unit grid-cells whose current supports are greater than or equal to a predefined minimum support S min
Generally, information embedded in a data stream is more likely to be changed as time goes by, so that the obsolete information of old data elements may be no longer useful or possibly invalid at present. Identifying the recent change of a data stream quickly can provide valuable information for the analysis of the data stream. In addition, monitoring the continuous variation of a data stream enables to find the gradual change of embedded information, so that it can be timely utilized. In order to achieve this, the effect of the obsolete information of a data stream on the current result should be eliminated effectively. The old distribution sta-elements on the current result of clustering can be eliminated without storing any data element physically.
The remaining of this paper is organized as follows. In Section 2 , the related works are presented. Section 3 describes how the information of a data element in a data stream is differentiated. Section 4 presents the struc-ture of a sibling list and explains a method of finding clusters over a data stream of a one-dimensional data space. In Section 5 , the method is generalized by employing a cell tree for a data stream of a multi-dimensional data space. In Section 6 , performance enhancement issues are discussed. In Section 7 , several experiment results are comparatively analyzed to evaluate the performance of the proposed method. Finally, Section 8 presents conclusions. 2. Related works
Clustering is one of major data mining categories and it groups a set of data elements in a data set into meaningful classes called clusters. In other words, the purpose of clustering is finding the groups of similar data elements which are defined by a given similarity measure. As a consequence, the potential groups and structures of similar data elements in a data set can be identified. Clustering techniques are categorized into several different approaches: partitioning, hierarchical, density-based, grid-based and model-based [12] . Most conventional clustering algorithms concentrate on finding all the existing clusters of a finite data set without any error. Due to this reason, they require to scan a data set multiple times.

When a data set is enlarged incrementally, it is more efficient to use one of incremental clustering algorithms [13] . For an enlarged data set, the up-to-date clusters can be efficiently identified by examining only those old data elements that are affected by the set of newly added data elements. In [14] , an incremental version of
DBSCAN is introduced. When a data set is enlarged by adding a set of new data elements, the density-reac-hablility of each new data element is examined, which only requires to scan those old data elements that are density-reachable from the new data element. Consequently, the up-to-date clusters of the enlarged data set [8] is proposed. Whenever a new data element is observed, it modifies the current centers of K clusters influ-enced by the data element. Although these algorithms are designed for the dynamic inclusion of new data ele-ments, they are not suitable for a data stream. This is because all the data elements of a data stream should be maintained.

In [5] , the K -median algorithm which is based on the partitioning approach is proposed to find the clusters of continuously generated data elements over a data stream. It regards a data stream as a sequence of stream chunks. A stream chunk is a set of consecutive data elements generated in a data stream. Whenever a new stream chunk containing a set of newly generated data elements is formed, the LSEARCH routine which is an O(1)-approximate K -medoid algorithm is performed to select K data elements from the data elements of the stream chunk as the local centers of the chunk. The algorithm confines its memory space to store a fixed number of local centers for the previous stream chunks observed so far. Therefore, if retaining iK centers is impossible at the i th stream chunk, the LSEARCH routine is performed again to cluster the weighted iK local centers to retain K centers which are the up-to-date centers of K clusters for all the data elements generated so far in the data stream. However, when the number of clusters is not known in advance, the LSEARCH routine should be iteratively performed until the quality of clusters is maximized, which can be computationally intensive.

Another partitioning-based algorithm called CluStream [6] is proposed to trace the evolution of clusters in a data stream. It employs two components: on-line and off-line components. The on-line component executes the K -means algorithm to produce micro clusters. The predefined number of micro clusters is maximized for the available space of main-memory in order to find the grouping structure of clusters as accurately as pos-feature vector of BIRCH [10] . The feature vectors of all micro clusters at each specified timestamp are stored as a snapshot for the off-line component. When a new data element is processed, if the distance between the new data element and the center of the closest micro cluster is less than the root-mean-square (RMS) deviation of those data elements that are within the range of the micro cluster, the feature vector of the micro cluster is updated by the new data element. Otherwise, a new cluster with a unique ID is created for the new data ele-ment. In this case, the number of micro clusters becomes larger than the predefined one. Subsequently, among the micro clusters, the nearest two micro clusters are merged into one micro cluster. The merged cluster main-tains the IDs of the two micro clusters.

In the off-line component, the macro clusters of CluStream are generated by executing the K -means algorithm for the accumulated snapshots of micro clusters. To find the gradual change of micro clusters for a specified time period h , the two snapshots of each micro cluster at the times t other words, its cluster feature vector at t c h is subtracted from that at t period h , the K -means algorithm is executed once more oAWn the subtracted cluster feature vectors. Micro clusters are traced by the on-line component while macro clusters are found by the off-line component. A macro cluster is a true cluster that represents a group of similar objects in a given time period. The evolution of micro clusters in the time period h is analyzed by comparing the cluster IDs of the two snapshots. If a clus-ter with a new ID is created in the later snapshot, the evolution is identified as an addition . If a cluster ID disappears in the later snapshot, the evolution is identified as a deletion . If a cluster with the same ID exists ters over an on-line data stream due to its off-line component.
 A grid-based clustering method called hybrid-partition method [11] for an on-line data stream is proposed.
The multi-dimensional data space of a data stream is partitioned into a set of mutually exclusive equal-size tics of data elements within its range. A dense range of an initial cell is partitioned into two smaller cells repeatedly until it becomes a unit cell which is the smallest size. The range of each partitioned grid-cell is dynamically determined by the distribution statistics of data elements in a grid-cell. Due to this reason, a large number of tiny grid-cells can possibly be created and pruned repeatedly in the neighboring range of a cluster. can be possible, which degrade the performance of the method. 3. Information differentiation
In order to keep only the recent information of a data stream, the weight of information represented by each data element should be differentiated according to the generation time of the data element. In other words, the older a data element becomes, the less its information should influence the current result of clus-tering. A sliding window approach is a primitive way of disregarding obsolete information since the obsolete information of old transactions is eliminated by maintaining them physically. When information is not decayed, its weight remains constant like the line (a) shown in Fig. 1 . The line (b) shows the change of the weight of information in the sliding window approach. The SWF algorithm [16] uses a sliding window to find frequent itemsets in a fixed number of recent transactions in a finite data set. Although the Lossy Counting algorithm [17] finds frequent itemsets over a data stream, it does not differentiate the recent occurrences of each itemset from the old ones. Therefore, an itemset can be regarded as a frequent itemset although it rarely occurs in recent transactions. The Moment algorithm [18] and estWin [21] resolve this problem by employing a sliding window approach. The target transactions of data mining are restricted to those transactions that are generated within the range of a sliding window. Consequently, the information about those data elements that are within the current window should be somehow maintained in order to remove their effects on the current mining result when they are out of the range of a sliding window.

A more flexible way of information differentiation is presented in [19] where correlations among co-evolv-ing time sequences are analyzed. The missing values of sequences are estimated and their future values are predicted. In order to identify the recent change of correlations adaptively, a forgetting factor is used to diminish the effects of old correlations among sequences. A forgetting factor determines how fast the effect of old information is faded away. This type of an information decay model is also introduced in NIDES [20] for anomaly intrusion detection. NIDES models the historical behavior of a user X  X  activities in terms of various measures and generates a long-term profile containing a statistical summary for each measure.
In order to concentrate on the recent behavior of the user, the statistics of old activities in the long-term profile are decayed as new activities are performed by the user. According to this decay model, the weight of information represented by a data element generated in a data stream can be decayed as time goes by. A decay rate means the reducing rate of a weight for a fixed decay-unit. A decay-unit determines the chunk of information to be decayed together. A decay rate is defined by two parameters: a decay-base b and a decay-base-life w .A decay-base b determines the amount of weight reduction per decay-unit and it is greater than 1. When the weight of the current information is set to 1, a decay-base-life w is defined by the number of follows:
When the values of b and w are set to 1, the information weight of every data element is not decayed and re-mains the same regardless of its generation time. The line (c) in Fig. 1 shows the change of the decayed weight of information defined by Eq. (1) . The older the information is, the more its weight is decayed. By varying these two parameters: decay-base b and decay-base-life w , the decay mechanism can control the fading rate of old information flexibly.

A data stream for a d -dimensional data space N  X  N 1 N d generated data elements as follows: (i) A data element generated at the t th turn is denoted by e t  X h e t (ii) The current data stream D t denotes all the data elements which have been generated so far, i.e. (iii) The total number of data elements generated in the current data stream D
When the decay mechanism is applied to a data stream, its time axis can be defined by either the relative generation order of data elements or the absolute generation time of each data element according to the need of an analysis task. The only difference of these two approaches is how to measure the age of a data element.
The former views it as the number of younger data elements while the latter uses the absolute time duration of a data element after it is generated. The decay mechanism is also affected by how large a decay-unit is defined.
As the size of a decay-unit is set to be smaller, the information of each data element is more precisely differ-entiated. For example, the smallest decay-unit of the former is one data element while that of the latter depends on the precision of absolute time to measure the generation time of a data element. For simplicity, the former with the smallest decay-unit is used in this paper in order to illustrate how the proposed method is performed. 4. Sibling lists
To find clusters over a data stream accurately, the distribution statistics of continuously generated data ele-ments should be carefully monitored. A grid-cell in a one-dimensional data space for the current data stream
D t is defined in Definition 1.
Definition 1 (Distribution statistics of a grid-cell g  X  I ; c ; l ; r  X  ). For the current data stream D dimensional data space N , a term g ( I , c t , l t , r t which is defined by an interval I  X  X  s ; f  X  in the range of the data space N . Let D that are in the range of the cell g , i.e., D t g  X f e i j e i 2 D g are defined as follows: (i) c t : the decayed count of data elements in D t g . (ii) l t : l t denotes the decayed average of the data elements in D (iii) r t : r t i denotes the decayed standard deviation of the data elements in D
Given a predefined partitioning factor h , the entire range range( N ) of a one-dimensional data space N is partitioned into h mutually exclusive equal-size initial grid-cells G ={ g range  X  N ) and g i I \ g j I  X  U ( i 6  X  j ; 1 6 i ; j 6 h ). In the current data stream D over the total number of data elements in D t , i.e. g c t = j D dense enough, i.e. greater than or equal to S par ( S par cells. Since such partitioning can be performed recursively in a dense region of the data space N , the interval of each grid-cell in the data space N can be different. However, among grid-cells, there exists total ordering relationship according to the interval of a grid-cell. Let G ={ g data space N and  X  g i , g j ) be an ordering function i.e., g to manage the dynamically varied configuration of grid-cells in the entire range of the data space efficiently, the grid-cells are structured by a sibling list defined in Definition 2 .

Definition 2 ( A sibling list S ). Given the current data stream D list S of order m is defined as follows: 1. A sibling list S  X h E 1 ; E 2 ; E 3 ; ... ; E p i is a single linked list of sibling entries E 2. Each sibling entry E i maintains a data structure E  X  min ; max ; G  X  1 ; ... ; m ; next ptr  X  (ii) When v  X  &lt; m  X  slots are not empty, the range of the entry E (iii) next ptr : a pointer to the next sibling entry of S . 3. The range of S is defined by the union of the ranges of all the sibling entries in S and it is the same as the entire range of the data space N . for a given partitioning factor h .
 max) to locate a specific grid-cell efficiently. As a new data element e includes the data element e t is searched in the sibling list. To accomplish this, the sibling entry whose range includes the element e t is located first and its grid-cells are looked up in sequence. When the distribution sta-grid-cell g is updated as follows: If the grid-cell g becomes dense ( g c t = j D t j P S par g ; ... ; g h , so that the distribution statistics of each partitioned grid-cell can be more precisely monitored.
The grid-cell g is replaced by the partitioned grid-cells g of the grid-cells in S is preserved. As in the hybrid-partition method, the distribution statistics of each parti-statistics of the j th partitioned grid-cell g j are initialized by the normal distribution function of g , u  X  x  X  X  1 ffiffiffiffi
If the number of available empty slots in the sibling entry E is not enough to accommodate all of the newly subsequent sibling entry E 0 is looked up to find out whether the total number of empty slots in both E and
E is greater than h 2. If so, all the grid-cells of E and E
E . Otherwise, another sibling entry E new is newly created and placed between E and E grid-cells of the entry E are evenly allocated into the two entries E and E est possible number of grid-cells in a full sibling entry E is m  X  h 2  X  . Therefore, each of the sibling entries in a B + tree [22] is dynamically managed. Instead of partitioning a full sibling entry, redistributing the grid-cells of the sibling entry into the succeeding sibling entry is a way of avoiding or at least postponing the creation of a new sibling entry. A basic B -tree does not perform this type of redistribution when a new data element is added into a full node since a B-tree is in a secondary storage device. However, since a cell tree is maintained in main memory, performing the redistribution prior to splitting a full sibling entry is always more efficient. Fig. 2 shows how a sibling list of order 5 is dynamically managed when h = 4. Suppose the grid-cell g 2 in Fig. 2 a just become dense upon processing the newly generated data element e grid-cell g 2 is partitioned into four smaller disjoint grid-cells g are estimated as follows:
This partitioning procedure can be recursively invoked until a unit grid-cell is found. By Theorem 1 , given the range( N ) of a data space N , the minimum number of recursive partitioning operations needed to produce a unit grid-cell is log h (range( N )/ k ). A cluster in the current data stream D grid-cells whose current supports are greater than or equal to S
Theorem 1. Given a partitioning factor h for a data stream of a one-dimensional data space N, the minimum number of recursive partitioning operations needed to produce a unit grid-cell g  X  I ; c log
Proof. Suppose a unit grid-cell is produced by performing q number of recursive partitioning operations on the data space N . The size of the grid-cell should be range  X  N  X  = h divides a given interval into h smaller equal-size intervals. Hence,
Since the distribution statistics of data elements in a data stream can be changed as time goes by, a spe-cific grid-cell may become sparse although it was dense in the past. For a grid-cell, when its current support becomes less than or equal to a predefined merging threshold S dense grid-cell in the near future is considered to be low enough to disregard it. Therefore, such a grid-cell g in a sibling entry E is merged with a set of other sparse grid-cells whose intervals are consecutive. However, not all of consecutive grid-cells in the entry E are legitimate candidates for merging. In order to keep the those sparse grid-cells that were partitioned together with the sparse grid-cell g should be the candidates.
For a particular grid-cell g , such candidate grid-cells are found in its merging range defined in Definition 3 .By Theorem 2 , the interval size of every unit grid-cell is kept to be k at all times only when every sparse grid-cell g is allowed to be merged with those sparse grid-cells that are in its merging range. After merging, if the number of grid-cells in the sibling entry E becomes less than d X  m h  X  2  X  = 2 e , the subsequent sibling entry E 0 is looked up to see whether it has extra grid-cells enough to prevent the sibling entry E from being underflowed. If it has, the grid-cells of E 0 are evenly redistributed into E and E
E and E 0 are concatenated into one sibling entry E and the other entry E merging these sparse grid-cells, unnecessary grid-cells are eliminated and the memory usage of a sibling list can be reduced.
 j g I j X j g f g s j . The merging range of a grid-cell g is defined by an interval and the size of the merging range is h j g j I j .
 cells that were originally partitioned together with the grid-cell g are in the merging range of the grid-cell g.
Proof. For a partitioning factor h , the size of the merging range of a grid-cell g  X  I ; c
Definition 3 . The data space N can be divided into range  X  N  X  divided interval includes g I . Since all the grid-cells whose intervals are within the j th divided interval were originally partitioned together with the grid-cell g , the j th divided interval should satisfy the following condition:
Therefore, g s
Given a partitioning factor h , S mer &lt; S par = h should be held between the two support thresholds S
More precisely, there should be an enough gap between the values of the two thresholds S j S of a grid-cell becomes longer, so that less amount of memory space is needed. Consequently, the distribution statistics of data elements in each grid-cell can be traced more accurately. 5. Cell trees
Given a data stream of a multi-dimensional data space N  X  N grid-cell ( k 6 d ) is defined by a k -dimensional rectangular space RS  X  I efficiently, a cell tree of order m defined in Definition 4 is employed. According to the first child-next sibling representation of a multi-way tree [22] , the nodes of a cell tree are composed. Each node of a cell tree main-tains a sibling entry E  X  min ; max ; G  X  1 ; ... ; m ; next ptr  X  and a child array U  X  1 ; ... ; m .
Definition 4 ( Structure of a cell tree ). For the current data stream D
N  X  N 1 N d , a cell tree of order m is defined as follows: 1. A node of a cell tree maintains the following: 3. Given a k -dimensional grid-cell G  X  i  X  g k  X  I ; c ; l ; r  X  of a node in the k th level of a cell tree, The basic structure of a cell tree is similar to a kd -tree [22] which is a multi-dimensional binary search tree. sents an actual data element itself while a node of a cell tree maintains the distribution synopsis of data ele-ments observed so far. Unlike a kd -tree, the maximum depth of a cell tree is fixed to be d for a d -dimensional data stream since each level of a cell tree should be corresponding to a distinct dimension.
Given a dimension sequence N 1 ! N 2 !! N d and a partitioning factor h , a sibling list S maintain the one-dimensional grid-cells g 1  X  I ; c ; l ; r  X  of the one-dimensional data space N tially, the list S 1 maintains h initial grid-cells and a single node is created to form the list S uously generated data elements of a data stream, dense grid-cells in S smaller grid-cells as described in Section 4 . Whenever a new dense unit grid-cell g 1 and g 1 i c = D t P S par is identified in the sibling entry of a node in S in the second level of the cell tree. The child node is the head node of the new sibling list which monitors the g grid-cell g 2 j  X  I ; c ; l ; r  X  is g 1 i I g 2 j I . When the grid-cell g the other hand, when a grid-cell g of a node n in the cell tree becomes sparse, all of its descendent nodes are pruned since they are also sparse. Furthermore, as described in Section 4 , the grid-cell g may be merged with other consecutive sparse grid-cells in the node n .

Theorem 3. Given a partitioning factor h and a dimension sequence N d-dimensional data space, the minimum number of partitioning operations partition  X  g grid-cell g should be also unit grid-cells. By Theorem 1 , the minimum number of recursive partitioning opera-tions needed to produce a unit grid-cell in a sibling list of a one-dimensional data space N every grid-cell in the path should be a unit grid-cell, the number of partitioning operations required to make a unit grid-cell in each level of the cell tree should be added. Therefore, the minimum number of partitioning operations needed to produce a unit grid-cell in the v th level is partition  X  g
Given a dimension sequence X ! Y and h = 4, a cell tree of order 5 for a data stream of a two-dimensional data space X Y is shown in Fig. 3 a. The node n 5 is the head node of the sibling list n grid-cell of all the grid-cells in this sibling list is the grid-cell g grid-cell is shown in Fig. 3 b.

The detailed steps of the proposed method are illustrated in Fig. 4 . The method is composed of three phases: updating phase , expanding phase and shrinking phase . Given a predefined dimension sequence
N 1 ! N 2 !! N d , a cell tree of order m is constructed for a data stream of a d -dimensional data space. according to the dimensional values of e t , i.e. e t 1 ! e t cell tree, find the k -dimensional grid-cell g k whose interval g k I includes the k th dimensional value of e 2 g k I . If such a grid-cell does not exist, terminate the traversal of the path. Otherwise, let the grid-cell g in the i th slot of the sibling entry E of the node v , i.e. v  X  E  X  G [ i ]= g formed by updating the distribution statistics of the grid-cell g cell g k is not a unit grid-cell and just becomes dense ( P S partitioning g k into h smaller grid-cells. If the grid-cell g new child node u is created in the ( k +1)th level v U  X  i  X  u . This new child node becomes the head node of a new sibling list for the ( k  X  1  X  th dimension N k  X  1 . On the other hand, if the updated support of g than or equal to S mer , the shrinking phase (lines 15 X 19) is performed by merging g grid-cells. Furthermore, when the grid-cell g k also has a child node, all of its descendant nodes are pruned.
If the grid-cell g k is already a dense unit grid-cell, its child node pointed to by v U  X  i is visited to reflect the  X  k  X  1  X  th dimensional value e t k  X  1 of e t to the cell tree.
 6. Performance enhancement
A sparse grid-cell is eliminated by merging only when a newly generated data element is in its rectangular space. However, a considerable number of sparse grid-cells in a cell tree may not be eliminated since the pos-sibility of encountering a data element in the rectangular space of a sparse grid-cell is very low. By traversing merging operation . Since the distribution statistics of all the grid-cells in a cell tree should be examined, the processing time of a force-merging operation takes relatively long. Due to this reason, it can be performed periodically or when the current usage of memory space reaches a certain limit.

The sequence of dimensions for the levels of a cell tree does not have to be predefined. Instead, it can be determined dynamically by monitoring the on-going standard deviation of data elements in each dimension.
Whenever a new level of a cell tree needs to be expanded, among the remaining dimensions, the one with the smallest deviation is designated to be expanded next. This is because the corresponding dimensional values of most data elements are congested the most. Therefore, the possibility of creating unit grid-cells is the highest among the dimensions.

The size of available memory space should be confined in data stream processing. Consequently, the amount of memory space used by the proposed method should be adaptively adjusted by dynamically chang-memory space and the size of confined memory space respectively. Whenever the current usage reaches a cer-tree are forced to be merged regardless of their current supports. The size of the merging range of a unit grid-cell is h k since h unit grid-cells were created altogether. Therefore, there are at most h grid-cells left in its merging range. Regardless of the current supports of these grid-cells, they are forced to be merged into a single grid-cell whose interval size is h k . The newly merged grid-cell becomes a unit grid-cell for the adjusted value of k .

After the size of every unit grid-cell at the current level becomes h k , if the current usage is reduced below the limit, the normal operations of the proposed method are resumed. Otherwise, the same opera-tion is performed to the next higher level of the cell tree. Upon visiting a non-leaf node of a cell tree to increase the value of k , the size of every unit grid-cell in all of its descendant nodes has been already adjusted to h k . Accordingly, the unit grid-cells of the node are forced to be merged by the same way.
A unit grid-cell that has not yet adjusted can have at most h unit grid-cells in its merging range. If some of these grid-cells have child nodes, all the sibling lists started by the child nodes should be combined into one sibling list in advance. If every unit grid-cell has its child node, there are at most h sibling lists to be merged. These sibling lists have the same data space since they are in the same level of the cell tree and they share the same set of ancestor grid-cells. In addition, all the grid-cells of a sibling list are ordered by their intervals. Therefore, all of these sibling lists can be combined together just like the merging phase of a k -way merge-sort algorithm [22] . In other words, among the h number of grid-cells each of which is the first grid-cell left to be combined in each list, the one with the smallest interval is chosen to be the next grid-cell g of the combined list. If any of the remaining grid-cells shares its interval with the interval of the grid-cell g , its distribution statistics for the shared interval of the grid-cell g are estimated by the same way as in Eq. (8) . The sum of the estimated distribution statistics of all the overlapped grid-cells is added to the distribution statistics of the grid-cell g . This process is repeated until there is no grid-cell left to be com-bined in any of the lists. Since the value of k is increased, the size of the cell tree is reduced while the precision of clustering is degraded.

On the contrary, if the amount of unused memory space stays to be h times larger than the current size of a cell tree, i.e, l usg c usg P h c usg , the value of k is dynamically adjusted to be k / h in order to enhance the precision of clustering. This process can be performed incrementally. Upon visiting a grid-cell g that used to be each partitioned grid-cell becomes k / h . In addition, if the grid-cell g has a child node, the entire sub-tree pointed to by its child pointer should be newly replicated to be the sub-tree pointed to by the child pointer of every partitioned smaller grid-cell. Since the probability of encountering a new data element whose value eventually.

Two-to-three split and three-to-two concatenation operations used in a B * -tree [22] can also be applied to a sibling list in order to maximize the utilization of memory space for a cell tree. Only when the succeeding sib-ling entry E 0 of a full sibling entry E is also full, the two full entries E and E times. 7. Experimental results
In order to analyze the performance of the proposed method, a data set containing one million 40-dimen-sional data elements is generated by the data generator used in ENCLUS [23] . The domain size of each dimen-sion is set to 100. Most of data elements are concentrated on randomly chosen 20 data regions whose sizes in each dimension are also randomly varied. The two support thresholds S predefined minimum support S min . The conditions of most experiments are S
S par  X  0 : 8 S min , k  X  2, m = 40, h = 4 and w  X 1 unless they are specified differently. A force-merging oper-ation is performed whenever 100K new data elements are processed. The dimension of each level of a cell tree is determined dynamically as described in Section 6 . In all experiments, data elements are looked up one by one in sequence to simulate the environment of an on-line data stream.

The performance of the proposed method is presented in Fig. 5 . STING [24] is a well-known conventional grid-based clustering algorithm and it is used to measure the accuracy of the proposed method. In STING, a cluster is defined by a set of adjacent dense unit grid-cells. Among the data elements of a cluster grouped by the proposed method, those data elements that are also grouped into the same cluster by STING are defined as values of k when the value of k for STING is fixed. It is measured by the ratio of the number of correctly clus-tered data elements over the total number of data elements clustered by STING. When the value of k for the proposed method is the same as that for STING, these two methods have the same accuracy. Fig. 5 b shows the memory usage of the proposed method. Since the support of each grid-cell is too sensitively varied in the early stage of clustering, lots of partitioning operations are performed. However, the memory usage is stabilized after the early stage. As it can be noticed, the memory usage is proportional to the value of k .
The effects of a retaining gap a and a partitioning factor h are illustrated in Fig. 6 . By varying the value of
S mer  X  X  0 : 1 S min  X  , the value of a is enlarged by increasing the value of S titioning a dense grid-cell is delayed, so that less memory space is required as shown in Fig. 6 a. Fig. 6 b shows the variation of the average number of dense unit grid-cells ( g c t = j D the average number of sparse grid-cells ( g c t = j D t j unit grid-cells is found in the early stage of clustering but the number of sparse grid-cells is also increased. However, most of the sparse grid-cells are eliminated by the first force-merging operation. As shown in Fig. 6 c, when the value of h is increased, the accuracy of clustering is improved more rapidly.
Fig. 7 a shows the memory usage of the proposed method when the order m of a cell tree is varied. The annotated number at each point of the figure indicates the average length of sibling lists in a cell tree. As the order is increased, the number of grid-cells managed by a node is increased, so that the average length of sibling lists is shortened. However, the number of empty grid-cells in a node is also increased. As a result, the memory usage is increased as shown in Fig. 7 a. Fig. 7 b shows the processing time of the proposed method.
When the order is too small, i.e. m = 2, the average length of sibling lists is increased rapidly, which prolongs the processing time. On the other hand, when the order is too large, the internal search of a particular grid-cell inside a node takes relatively long, which makes the average processing time be also increased.
A force-merging operation is usually performed periodically or when it is needed. Fig. 8 a shows the mem-ory usage of the proposed method by varying the period of a force-merging operation. In this experiment, four force-merging periods f = 10K, 50K, 100K and f = 1 are compared. A force-merging period f = 10K means that a force-merging operation is performed whenever 10K new data elements are processed. In this figure, the sequence of generated data elements is divided into five disjoint intervals each of which consists of 200K data elements. Fig. 8 b shows the average processing time of each interval. When no force-pruning operation is exe-cuted ( f = 1 ), merging most sparse grid-cells is delayed and a considerable number of the sparse grid-cells are not merged at all. As shown in this figure, a force-merging operation is useful to minimize not only memory usage but also processing time.

In Fig. 9 , the performance of a cell tree is compared with that of a cell * tree. The average length of sibling as shown in Fig. 9 a. However, because a cell * tree needs to traverse more number of nodes than a cell tree does, it takes more time to traverse a sibling list as shown in Fig. 9 b.

Fig. 10 a shows the accuracy of the proposed method when the value of a decay-base-life w is varied. For this purpose, the decay mechanism described in Section 3 is applied to STING. This version of STING is called as dSTING in this paper. The ratio of the number of correctly clustered data elements over the total number of data elements clustered by dSTING is presented. As the value of w is shortened, the weight of a new data element drops quickly, so that the support of each grid-cell is changed rapidly. In Fig. 10 b and
Fig. 10 c, the memory usage and processing time of the proposed method are evaluated. As the value of w is shortened, the support of each grid-cell is more rapidly decayed, so that the total number of grid-cells in a cell tree is decreased. In other words, only recently dense grid-cells are maintained.

Fig. 11 shows the effects of the dynamic determination of a dimension sequence when a cell tree is expanded. In the figure, the term increasing order indicates when the order of dimensions is determined by the increasing order of the standard deviation of data elements in each dimension and the term decreasing order indicates the exactly reverse order. The term greedy indicates the proposed method when the order of dimensions is dynamically determined as described in Section 6 . More precisely, among the remaining dimen-sions, the one with the smallest standard deviation of data elements is selected to be used for a new level of a cell tree when the cell tree needs to be expanded. A data set denoted by the term D _ std 0.3 means that the average difference of its standard deviations between two consecutive dimensions in a dimension sequence is with in 0.3. As expected, the performance of the increasing order is the best and that of the greedy method is slightly below. The performance of the decreasing order is the worst because more number of sparse grid-cells are created at the higher levels of its cell tree.

Table 1 shows the performance of the proposed method when the number of dimensions is varied. Data sets from 10-dimensional data space to 60-dimensional data space are created. The number of clusters in each data set is the same. As the number of dimensions is increased, the memory usage and processing time of the hybrid-partition method are more rapidly increased than those of the proposed method do.

In Fig. 12 , the accuracy of the proposed method is compared with those of the hybrid-partition method [11] and LSEARCH [5] . Since the support threshold S prn in the hybrid-partition method plays the same role as the merging threshold S mer in the proposed method, their values are set to be the same. The accuracy of
LSEARCH is measured by the K -means algorithm. However, the iterative optimization part of LSEARCH is not included since it is not suitable for an on-line data stream. The performance of CluStream [6] is not com-pared since its true clusters, i.e., macro clusters are found by its off-line component. For the same value of K , among the data elements of a cluster obtained by LSEARCH, those data elements that are also grouped into the same cluster by K -means are correctly clustered data elements. Therefore, the ratio of the number of cor-rectly clustered data elements over the total number of data elements is the accuracy of LSEARCH. Since the seed value of LSEARCH affects its performance, the average accuracy of 100 independent executions of the LSEARCH routine is shown in the figure. Six different data sets with no noise data element are generated.
The numbers of clusters in these data sets are set to 4, 8, 12, 16, 20 and 40 respectively. Fig. 12 a shows the accuracies of the three methods by varying the number of clusters. As the number of clusters is increased, the accuracy of LSEARCH is decreased while the accuracies of the other clustering methods remain the same.
On the other hand, Fig. 12 b shows how these methods deal with noise data elements. The data set of 20 clus-ters ( K = 20) is used and the amount of noise data elements is varied up to 10%. The accuracy of LSEARCH is sensitively changed by the ratio of noise data elements since a partitioning clustering method cannot handle noises well enough. In Fig. 12 c, three data sets of different data distributions are experimented. The uniform and normal mean that clusters are distributed by the uniform and normal distributions respectively. On the other hand, the skewed means that clusters are congested. Unlike the other two methods, the accuracy of a
In order to show the performance of the proposed method on a real data set, the KDD-CUP X 99 network intrusion detection data set [25] is experimented in Fig. 13 .Asin [6] , all 34 continuous attributes are employed ber of clusters for each value of k is used to assign the value of k for LSEARCH. Fig. 13 b shows how the proposed method adaptively maximizes the usage of confined memory space (20 MB). Two different schemes of the proposed method, namely adjust and fixed schemes, are compared with the adjusted scheme of the hybrid-partition method. The value of k is dynamically adjusted in the adjusted scheme while it is statically set in the fixed scheme. All the previous experiments are based on the fixed scheme. The value of k in the fixed scheme is set to 4 while the initial value of k in the adjusted scheme is set to 16. Lots of grid-cells are parti-tioned in the early stage of clustering. Consequently, the memory usage of the fixed scheme becomes larger than the confined memory space. Whenever the unused memory space becomes h times of the currently used memory space, the adjusted scheme changes the value of k to be k = h adaptively in order to utilize the unused memory space. As a result, the memory usage of the adjusted scheme is gradually increased and managed to be slightly less than the confined memory space. Subsequently, it becomes almost the same as that of the fixed scheme because the value of k in the adjusted scheme is finally set to 4. Fig. 13 c shows the accuracy of the proposed method in this experiment. When the memory usage is being adjusted, the accuracy of the adjusted scheme is lower than that of the fixed scheme as shown in Fig. 13 c. However, the two schemes provide the same accuracy eventually. By the adjusted scheme of the proposed method, it is possible to avoid employing a large amount of memory space that is only required to pass the early stage of clustering. Fig. 13 d shows how the accuracy of the proposed method is varied according to the different ordering schemes of dimensions.
When the increasing order of the standard deviation of data elements is used, the most accurate result is obtained. Generally, the information about the standard deviation of data elements in each dimension is not available in advance. In such environment, the greedy approach employed in the proposed method can be useful as shown in this experiment.
 Fig. 14 a shows the adaptability for the change of information in a data stream. The data set D experiment is composed of two consecutive subparts D A and D D includes a sequence of 500K data elements while the second part denoted by the data set D a sequence of 500K data elements. The data regions of the data set D posed method can adapt the change of information in a data stream, a coverage rate CR is introduced. Let
P ( D i ) denote the set of clustered data elements in a data set D erage rate CR  X  D i  X  of a data set D i is defined as follows:
As the value of a decay-base-life w becomes smaller, the proposed method more rapidly adapts the change of recent information. By varying the value of a decay-base-life w , the adaptability for the recent change of a data stream can be controlled. The similar effect can be achieved by varying a decay-base b . As the value of a decay-base b becomes larger, the proposed method adapts more rapidly the recent change of a data stream. Fig. 14 b shows the variation of the accuracy of the proposed method in the course of information change. The accuracy is measured by dSTING as describe in Fig. 10 . As the coverage rate CR  X  D decrease at the 500Kth data element, the accuracy is also decreased. This is because the dense grid-cells of D A are not dense any longer. However, the accuracy is increased as soon as the dense grid-cells of D tified after the 600Kth element. Fig. 14 c illustrates the variations of grid-cells when information embedded in a data stream is rapidly changing. In the early stage of clustering, the number of sparse grid-cells is rapidly de-creased as they are merged: On the other hand, the number of dense grid-cells is increased when dense grid-cells are found later. Around the 500Kth data element, the dense grid-cells of D that the number of dense grid-cells is decreased. However, as the dense grid-cells of D the number of dense grid-cells is increased again after the 600Kth data element. 8. Conclusion
In the hybrid-partition method, the multi-dimensional data space of a data stream is dynamically divided into a set of grid-cells with different sizes. By maintaining only the distribution statistics of data elements in each grid-cell, its current support is precisely monitored. However, they requires relatively long processing time since they should scan the ranges of partitioned grid-cells in sequence to locate a grid-cell whose range includes a newly generated data element. In order to avoid this, a cell tree is proposed in this paper to effec-tively maintain the on-going distribution statistics of continuously generated data elements in a data stream such that the grid-cell in a multi-dimensional data space for a newly generated data element can be accessed more efficiently. As a result, the average processing time of a data element is greatly enhanced. To emphasize the recent change of information in a data stream on the result of clustering, the weight of information rep-resented by old data elements in the data stream is gradually diminished as time goes by. As a result, no data element needs to be stored physically in order to disregard the obsolete information of the data stream.
Depending on the requirements of an application, the interesting recent range of a data stream can be flexibly defined by the two decay parameters. In order to confine the memory usage of the proposed method, the size of a unit grid-cell can be dynamically adjusted based on the current usage of memory space. As a result, although the distribution statistics of data elements in the multi-dimensional data space of a data stream are continuously varied, it is possible to maximize the clustering accuracy of the proposed method for confined memory space.
 Acknowledgements This work was supported by the Korea Science and Engineering Foundation (KOSEF) through the
National Research Lab. Program funded by the Ministry of Science and Technology (No. M10600000225-06J0000-22510).

References
