 Users love Short Message Service (SMS) text messaging; so much so that 3 trillion SMS me s-sages are expected to have be en sent in 2009 alone (Stross, 2008). Because research has shown that SMS messaging while driving results in 35% slower reaction time than being into x-icated (Reed &amp; Robbins, 2008), campaigns have been launched by states, governments and even cell phone carriers to discourage and ban SMS messaging while driving (DOT, 2009). Yet, a u-tomobile manufacturers have started to offer i n-fotainment syst ems, such as the Ford Sync, which feature the ability to listen to incoming SMS messages using text -to -speech (TTS). A u-tomatic speech recognition (ASR) affords users a hands -free, eyes -free method of reply ing to SMS messages. However, to date, manufacturer s have not established a safe and reliable method of l e-veraging ASR, though some researchers have begun to explore techniques. In previous r e-search (Ju &amp; Paek, 2009 ) , we examined three ASR approaches to replying to SMS messages: dictation using a language model trained on SMS responses, canned responses using a probabilistic context -free grammar (PCFG), and a  X  X oice search X  approach based on template matching. Voice search proceeds in two steps (Natarajan et al., 2002): an utterance is first converted into text, which is then used as a search query to match the most similar items of an index using IR techniques (Yu et al., 2007). For SMS replies, we created an index of SMS response templates, with slots for semantic concepts such as time and place, from a la rge SMS corpus. After convol v-ing recorded SMS replies so that the audio would exhibit the acoustic characteristics of in -car re c-ognition, they compared how the three approac h-es handled the convolved audio with respect to the top n -best reply candidates. Th e voice search approach consistently outperformed dictation and canned responses, achieving as high as 89.7% task completion with respect to the top 5 reply candidates.

Even if the voice search approach may be more robust to in -car noise, this does not gua ra n-tee that it will be more usable. Indeed, because voice search can only match semantic concepts contained in the templates (which may or may not utilize the same wording as the reply) , users must verify that a retrieved template matches the semantics of their intended reply. For example, suppose a user replies to the SMS message  X  how about lunch  X  with  X  can X  X  right now running e r-rands  X . Voice search may find  X  nope, got e r-rands to run  X  as the closest template match, in which case, users will have to decide whether this response has the same meaning as their r e-ply. This of course entails cognitive effort, which is very limited in the context of driving. On the other hand, a dictation approach to replying to SMS messages may be far worse due to misr e-cognitions . For example, dictation may interpret  X  can X  X  right now running errands  X  as  X  can right now fun in errands  X . We posited that voice search has the advantage because it always gen e-rates intelligible SMS replies (since response templates are manually filtered) , as opposed to dictation, which can sometimes result in unpr e-dictable and nonsensical misrecognitions. Ho w-ever, this advantage has not been empirically demonstrated in a user study. This paper presents a user study investigating how the two approac h-es com pare when users are actually driving  X  that is, when usability matters most . Although ASR affords users hands -free, eyes -free interaction, the benefits of leveraging speech can be forfeit if users are expending cognitive effort judg ing whether the speech interface co r-rectly interpreted their utterances. Indeed, r e-search has shown that the cognitive demands of dialogue seem to play a more important role in distracting drivers than physically handling cell phones (Nunes &amp; Recarte, 2002 ; Strayer &amp; Johnston, 2001). Furthermore, Kun et al. (2007) have found that when in -car speech interfaces encounter recognition problems , users tend to drive more dangerously as they attempt to figure out why their utterances are failing . Hence, any approa ch to replying to SMS messages in aut o-mobiles must avoid distracting drivers with e r-rors and be highly usable while users are e n-gaged in their primary task, driving. 2.1 Method To assess the usability and performance of both the voice search approach and dicta tion, we co n-ducted a controlled experiment using the STISIM Drive X  simulator. Our simulation setup co n-sisted of a central console with a steering wheel and two turn signals, surrounded by three 47 X  X  flat panels placed at a 45 X  angle to immerse the driver. Figure 1 displays the setup.

We recruited 16 participants (9 males, 7 f e-males) through an email sent to employees of our organization. The mean age was 38.8 . All parti c-ipants had a driver X  X  license and were compe n-sated for their time.
 We examined two independent variables: SMS Reply Approach , consisting of voice search and dictation , and Driving Condition , consisting of no driving , easy driving and difficult driving . We included Driving Condition as a way of incre a s-ing cognitive demand (see next section). Overall, we conducted a 2 ( SMS Reply Approach )  X  3 ( Driving Condition ) repeated measures, within -subjects design experiment in which the order of SMS Reply for each Driving Condition was cou n-ter -balanced. Because our primary variable of interest was SMS Reply , we had users experience both voice search and dictation with no driving first, then easy driving , followed by difficult dri v ing . This gave users a chance to adjust the m-selves to increasingly difficult road co nditions. Driving Task : As the primary task, users were asked to drive two courses we developed with easy driving and difficult driving conditions while obeying all rules of the road, as they would in real driving and not in a videogame. With speed limits ranging from 25 mph to 55 mph, both courses contained five sequential sections which took about 15 -20 minutes to complete: a residentia l area, a country highway, and a small city with a downtown area as well as a bus i-ness/industrial park. Although both courses were almost identical in the number of turns, curves, stops, and traffic lights, the easy course consisted mostly of simple road s egments with relatively no traffic, whereas the difficult course had four times as many vehicles, cyclists, and pedestrians. The difficult course also included a foggy road section, a few busy construction sites, and many unexpected events, such a s a car i n front sudde n-ly breaking, a parked car merging into traffic, and a pedestrian jaywalking. In short, the diff i-cult course was designed to fully engage the a t-tention and cognitive resources of drivers.
 SMS Reply Task : As the secondary task, we asked users to listen to an incoming SMS me s-sage together with a formulated reply, such as: (1) Message Re ceived:  X  Are you lost?  X  Your The users were asked to repeat the reply back to the system . For Example (1) above, users would have to u tter  X  No , never with my GPS  X . U sers could also say  X  Repeat  X  if they had any difficu l-ties understanding the TTS rendering or if they experienced lapses in attention . For each course, users engaged in 10 SMS reply tasks. SMS me s-sages were cued every 3000 fee t, roughly every 90 seconds, which provided enough time to complete each SMS dialogue. Once users uttered the formulated reply, they received a list of 4 possible reply candidates (each labeled as  X  One  X ,  X  Two  X , etc.), from which they were asked to e i-ther p ick the correct reply (by stating its number at any time) or reject them all (by stating  X  All wrong  X ). We did not provide any feedback about whether the replies they picked were cor rect or incorrect in order to avoid priming users to pay more or less attention in subsequent messages. Users did not have to finish listening to the entire list before making their selection .
 Stimuli : Because we were interested in exami n-ing which was wo rse, verifying whether SMS response templates matched the meaning of an intended reply, or deciphering the sometimes nonsensical misrecognitions of dictation, we d e-cided to experimentally control both the SMS reply uttered by the user as well as the 4 -best list generated by the system. However, a ll SMS re p-lies and 4 -best lists were derived from the logs of an actual SMS Reply interface which impl e-mented the dictation and the voice search a p-proach es (see J u &amp; Paek, 2009 ) . For each course, 5 of the SMS replie s were short (with 3 or fewer words) and 5 were long (with 4 to 7 words). The mean length of the replies was 3.5 words ( 17.3 chars) . The order of the short and long replies was randomized.

We selected 4 -best lists where the correct a n-swer was in each of four possible positions (1 -4) or All Wrong; that is, there were as many 4 -best lists with the first choice correct as there were with the second choice correct, and so forth. We then randomly ordered the presentation of diffe r-ent 4 -best lists. Although one might argue that the four positions are not equally likely and that the top item of a 4 -best list is most often the co r-rect answer, we decided to experimentally co n-trol the position for two reasons: first, our pr e-vious research (Ju &amp; P aek, 2009) had already demonstrated the superiority of the voice search approach with respect to the top position (i.e., 1 -best ) , and second, our experimental design sought to identify whether the voice search a p-proach was more usable than the dictation a p-proach even when the ASR accuracy of the two approach es was the same.

In the dictation condition, the correct answer was not always an exact copy of the reply in 0 -2 of the 10 SMS messages. For instance, a correct dictation answer for Example (1) above was  X  no I X  X  never with my GPS  X . On the other hand, the voice search condition had more cases (2 -4 me s-sages) in which the correct answer was not an exact copy (e.g.,  X  no I have GPS  X ) due to the nature of the template approach . To some degree, this could be see n as handicapping the voice search condition, though the results did not r e-flect the disadvantage, as we discuss later . Measures : Performance for both the driving task and the SMS reply tasks were recorded. For the driving task, we measured the numbers of coll i-sions, speeding (exceeding 10 mph above the limit), traffic light and stop sign violations, and missed or incorrect turns. For the SMS reply task, we measured duration (i.e., time elapsed between the beginning of the 4 -best list and when users ultima tely provided their answer) and the number of times users correctly identified which of the 4 reply candidates contained the correct answer .

O riginally , we had an independent rater verify the position of the correct answer in all 4 -best lists, however, we considered that some partic i-pants might be choosing replies that are semant i-cally sufficient, even if they are not exactly co r-rect . For example, a 4 -best list generated by the dictation approach for Example (1) had :  X  One: no I X  X  never want my GPS. Two : no I X  X  never with my GPS. Three : no I X  X  nev er when my GPS. Or Four : no no I X  X  in my GPS.  X  Although the rater identified the second reply as being  X  X orrect X , a participant might view the first or third replies as sufficient . In order to avoid a m-biguity ab out correctness , after the study, we showed the same 16 participants the SMS me s-sages and replies as well as the 4 -best lists they received during the study and asked them to s e-lect, for each SMS reply, any 4 -best list items they felt sufficiently convey ed the same mea n-ing, even if the item s were un grammatical . Pa r-ticipants were explicitly told that they could s e-lect multiple items from the 4 -best list. We did not indicate which item they selected during the experiment and because this selection task o c-curr ed months after the experiment, it was u n-likely that they would remember anyway. Parti c-ipants were compensated with a cafeteria vouc h-er.

In com puting the number of  X  X orrect X  a n-swers , for each SMS reply, we counted an a n-swer to be correct if it was included among the participants X  set of semantically sufficient 4 -best list items . Hence, we calculated the number of correct items in a perso nalized fashion f o r every participant. 2.2 Results We conducted a series of repeated measures ANOVAs on all driving task and SMS reply task measures. For the driving task, we did not find any statistically significant differences between the voice searc h and dictation conditions. In ot h-er words, we could n ot reject the null hypothesis that the two approaches were the same in terms of their influence on driving performance. Ho w-ever, for the SMS reply task, we did find a main effect for SMS Reply Approach (F 1,47 = 81.28 , p &lt; As shown in Figure 2, the average number of errors per driving course for dictation is roughly 6 times that for voice search . We also found a main effect for total duration (F 1,47 = 11 . 94, p &lt; .01,  X  Dictation = 113 . 75 sec (3 . 54) or 11.4 sec/reply ,  X  VoiceSearch = 125 . 32 sec (3 . 37) or 12.5 sec/reply ). We discuss our explanation for the shorter dur a-tion below . For both errors and duration, we did not find any interaction effects with Driving Conditions . 3 Discussion We conducted a sim ulator study in order to e x-amine which was worse while driving: verifying whether SMS response templates matched the meaning of an intended reply, or deciphering the sometimes nonsensical misrecognitions of dict a-tion. Our results suggest that deciphering d ict a-tion results under the duress of driving leads to more errors. In conducting a post -hoc error ana l-ysis, we noticed that participants tended to err when the 4 -best lists generated by the dictation approach contained phonetically similar cand i-date replie s. Because it is not atypical for the di c-tation approach to have n -best list candidates differing from each other in this way, we re c-ommend not utili zing this approach in speech -only user interfaces , unless the n -best list cand i-dates can be made as distinc t from each other as possible, phonetically , syntactically and most importantly, semantically. T he voice search a p-proach circumvents this problem in two ways: 1) templates were real responses and manually s e-lected and cleaned up during the development phase so there were no grammatical mistakes, and 2) semantically redundant templates can be further discarded to only present the distinct co n-cepts at the rendering time using the paraphrase detection algorithms reported in (Wu et al., 2010) .

Given that users committed more errors in the dictation condition, we initially expected that dictation would exhibit higher durati on than voice search since users might be spending more time figuring out the differences between the similar 4 -best list candidates generated by the dictation approach. However, in our error anal y-sis we observed that most likely users did not discover the misrecognitions, and prematurely selected a reply candidate, resulting in shorter durations. T he slightly higher duration for the voice search approach does not constitute a pro b-lem if users are listening to all of their choices and correctly selecting th eir intended SMS reply . Note that the duration did not bring about any significant d riving performance differences.
Although we did not find any significant dri v-ing performance differences, users experienced more difficulties confirming whether the dict a-tion approach correctly interpreted their utte r-ances than they did with the voice search a p-proach. As such, if a user deems it absolutely necessary to respond to SMS messages while driving, our simulator study suggests that the most reliable (i.e., least e rror -prone) way to r e-spond may just well be the voice search a p-proach.

