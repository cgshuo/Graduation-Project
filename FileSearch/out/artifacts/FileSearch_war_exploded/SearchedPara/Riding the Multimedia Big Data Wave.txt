 Across multiple generations of information technology that have dealt with structured and unstructured data, the ex-plosion of multimedia data is creating the biggest wave of all. Huge volumes of multimedia  X  images, video and audio are being generated and consumed daily. Currently, multi-media makes up 60% of internet traffic, 70% of mobile phone traffic and 70% of all available unstructured data. To give specific examples, Web users are uploading 72 video-hours to YouTube per minute, and on an average day, social media users post 300 hundred million photos to Facebook. Con-sumers using mobile phones and digital cameras are tak-ing 500 billion photos per year, or 78 per person on the planet [1]. Specialized domains are participating too. Medi-cal institutions are acquiring one billion radiological images per year, and cities are installing hundreds of millions of video cameras worldwide for safety, security and law enforce-ment. Industries across life sciences, petroleum exploration, astronomy, insurance, retail and many others are faced with huge and growing volumes of multimedia data.

Multimedia clearly is  X  X ig data X . But, it it big data not just because there is a lot of it. Multimedia is big data because increasingly it is becoming a valuable source for in-sights and information. Multimedia data can tell us about things happening in the world, point out places, events or topics of interest (memes), give clues about a person X  X  pref-erences and even capture a rolling log of human history [1, 2]. However, the challenge with multimedia big data is that images, video and audio require much more sophisticated al-gorithms for content analysis than previous waves of struc-tured and unstructured data. This is spurring on a tremen-dous amount of research on efficient and effective techniques for  X  X ridging the semantic gap X  to enable large-scale multi-media information extraction and retrieval [3, 4].
In this talk we present a perspective across multiple indus-try problems, including safety and security, medical, Web, social and mobile media, and motivate the need for large-scale analysis and retrieval of multimedia data. We de-System (IMARS), which has been recognized by multiple awards including a Wall St. Journal innovation award. Dr. Smith is a long-time participant in the NIST TRECVID video retrieval evaluation and co-led the development of the Large Scale Concept Ontology for Multimedia (LSCOM), which has been incorporated into the TRECVID evalua-tion. From 2000-2004, Dr. Smith served as Chair, ISO/IEC MPEG Multimedia Description Schemes Group and led the development of multiple parts of the MPEG-7 Multime-dia Metadata Standard and MPEG-21 Digital Framework Standard. While a student with Prof. Shih-Fu Chang at Columbia University, Dr. Smith conducted some of the earli-est work on content-based image retrieval (VisualSEEk) and Web image/video search (WebSEEk), which has been highly influential for researchers and practitioners. Dr. Smith has published more than two hundred papers ( &gt; 14K citations, h-index of 55, i-index of 166). Dr. Smith is currently a mem-ber of ACM SIGMM, Fellow of IEEE and Editor-in-Chief of IEEE MultiMedia . [1] John R. Smith. History made everyday. IEEE [2] L. Xie, A. Natsev, J. R. Kender, M. Hill, and J. R. [3] John R. Smith. Minding the gap. IEEE MultiMedia , [4] A. Hanjalic, R. Lienhart, W.-Y. Ma, and J. R. Smith. [5] M. Naphade, J. R. Smith, J. Tesic, S.-F. Chang, [6] John R. Smith. Just the facets. IEEE MultiMedia , [7] R. Yan, M. O. Fleury, M. Merler, A. Natsev, and J. R.
