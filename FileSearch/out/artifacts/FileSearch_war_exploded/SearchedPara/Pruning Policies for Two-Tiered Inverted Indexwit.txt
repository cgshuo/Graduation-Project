 The Web search engines maintain large-scale inverted indexes which are queried thousands of times per second by users eager for information. In order to cope with the vast amounts of query loads, search engines prune their index to keep documents that are likely to be returned as top results, and use this pruned index to compute the first batches of results. While this approach can im-prove performance by reducing the size of the index, if we compute the top results only from the pruned index we may notice a signif-icant degradation in the result quality: if a document should be in the top results but was not included in the pruned index, it will be placed behind the results computed from the pruned index. Given the fierce competition in the online search market, this phenomenon is clearly undesirable.

In this paper, we study how we can avoid any degradation of result quality due to the pruning-based performance optimization, while still realizing most of its benefit. Our contribution is a num-ber of modifications in the pruning techniques for creating the pruned index and a new result computation algorithm that guar-antees that the top-matching pages are always placed at the top search results, even though we are computing the first batch from the pruned index most of the time. We also show how to determine the optimal size of a pruned index and we experimentally evaluate our algorithms on a collection of 130 million Web pages. H.3.1 [ Information Storage and Retrieval ]: Content Analysis and Indexing; H.3.3 [ Information Storage and Retrieval ]: Infor-mation Search and Retrieval Algorithms, Measuring, Performance, Design, Experimentation Inverted index, pruning, correctness guarantee, Web search engines
The amount of information on the Web is growing at a prodigious rate [24]. According to a recent study [13], it is estimated that the Copyright 2007 ACM 978-1-59593-597-7/07/0007 ... $ 5.00. Web currently consists of more than 11 billion pages. Due to this immense amount of available information, the users are becoming more and more dependent on the Web search engines for locating relevant information on the Web. Typically, the Web search en-gines, similar to other information retrieval applications, utilize a data structure called inverted index .An inverted index provides for the efficient retrieval of the documents (or Web pages) that contain a particular keyword.

In most cases, a query that the user issues may have thousands or even millions of matching documents. In order to avoid over-whelming the users with a huge amount of results, the search en-gines present the results in batches of 10 to 20 relevant documents. The user then looks through the first batch of results and, if she doesn X  X  find the answer she is looking for, she may potentially re-quest to view the next batch or decide to issue a new query.
A recent study [16] indicated that approximately 80% of the users examine at most the first 3 batches of the results. That is, 80% of the users typically view at most 30 to 60 results for every query that they issue to a search engine. At the same time, given the size of the Web, the inverted index that the search engines maintain can grow very large. Since the users are interested in a small num-ber of results (and thus are viewing a small portion of the index for every query that they issue), using an index that is capable of re-turning all the results for a query may constitute a significant waste in terms of time, storage space and computational resources, which is bound to get worse as the Web grows larger over time [24].
One natural solution to this problem is to create a small index on a subset of the documents that are likely to be returned as the top re-sults (by using, for example, the pruning techniques in [7, 20]) and compute the first batch of answers using the pruned index. While this approach has been shown to give significant improvement in performance, it also leads to noticeable degradation in the quality of the search results, because the top answers are computed only from the pruned index [7, 20]. That is, even if a page should be placed as the top-matching page according to a search engine X  X  ranking met-ric, the page may be placed behind the ones contained in the pruned index if the page did not become part of the pruned index for var-ious reasons [7, 20]. Given the fierce competition among search engines today this degradation is clearly undesirable and needs to be addressed if possible.

In this paper, we study how we can avoid any degradation of search quality due to the above performance optimization while still realizing most of its benefit. That is, we present a number of simple (yet important) changes in the pruning techniques for cre-ating the pruned index. Our main contribution is a new answer computation algorithm that guarantees that the top-matching pages (according to the search-engine X  X  ranking metric) are always placed at the top of search results, even though we are computing the first batch of answers from the pruned index most of the time. These enhanced pruning techniques and answer-computation algorithms are explored in the context of the cluster architecture commonly employed by today X  X  search engines. Finally, we study and present how search engines can minimize the operational cost of answering queries while providing high quality search results.
 Figure 1: (a) Search engine replicates its full index I F crease query-answering capacity. (b) In the 1 st tier, small p-indexes I P handle most of the queries. When I P cannot answer a query, it is redirected to the 2 nd tier, where the full index is used to compute the answer.
Typically, a search engine downloads documents from the Web and maintains a local inverted index that is used to answer queries quickly.
 Inverted indexes. Assume that we have collected a set of doc-uments D = { D 1 ,...,D M } and that we have extracted all the terms T = { t 1 ,...,t n } from the documents. For every single term t i  X  X  we maintain a list I ( t i ) of document IDs that contain t . Every entry in I ( t i ) is called a posting and can be extended to include additional information, such as how many times t i in a document, the positions of t i in the document, whether bold/italic, etc. The set of all the lists I = { I ( t 1 our inverted index.
Search engines are accepting an enormous number of queries every day from eager users searching for relevant information. For example, Google is estimated to answer more than 250 million user queries per day. In order to cope with this huge query load, search engines typically replicate their index across a large cluster of ma-chines as the following example illustrates: Example 1 Consider a search engine that maintains a cluster of machines as in Figure 1(a). The size of its full inverted index is larger than what can be stored in a single machine, so each copy of
I F is stored across four different machines. We also suppose that one copy of I F can handle the query load of 1000 queries/sec. Assuming that the search engine gets 5000 queries/sec, it needs to replicate I F five times to handle the load. Overall, the search engine needs to maintain 4  X  5=20 machines in its cluster.
While fully replicating the entire index I F multiple times is a straightforward way to scale to a large number of queries, typical query loads at search engines exhibit certain localities, allowing for significant reduction in cost by replicating only a small portion of the full index. In principle, this is typically done by pruning a full index I F to create a smaller, pruned index (or p-index) I contains a subset of the documents that are likely to be returned as top results.

Given the p-index, search engines operate by employing a two-tier index architecture as we show in Figure 1(b): All incoming queries are first directed to one of the p-indexes kept in the In the cases where a p-index cannot compute the answer (e.g. was unable to find enough documents to return to the user) the query is answered by redirecting it to the 2 nd tier, where we maintain a full index I F . The following example illustrates the potential reduction in the query-processing cost by employing this two-tier index architecture.
 Example 2 Assume the same parameter settings as in Example 1. That is, the search engine gets a query load of 5000 queries/sec Figure 2: Computing the answer under the two-tier architec-ture with the result correctness guarantee. and every copy of an index (both the full I F and p-index handle up to 1000 queries/sec. Also assume that the size of one fourth of I F and thus can be stored on a single machine. Fi-nally, suppose that the p-indexes can handle 80% of the user queries by themselves and only forward the remaining 20% queries to Under this setting, since all 5000/sec user queries are first directed to a p-index, five copies of I P are needed in the 1 st tier. For the 2 nd tier, since 20% (or 1000 queries/sec) are forwarded, we need to maintain one copy of I F to handle the load. Overall we need a total of 9 machines (five machines for the five copies of four machines for one copy of I F ). Compared to Example 1, this is more than 50% reduction in the number of machines.

The above example demonstrates the potential cost saving achieved by using a p-index. However, the two-tier architecture may have a significant drawback in terms of its result quality com-pared to the full replication of I F ; given the fact that the p-index contains only a subset of the data of the full index, it is possible that, for some queries, the p-index may not contain the top-ranked docu-ment according to the particular ranking criteria used by the search engine and fail to return it as the top page, leading to noticeable quality degradation in search results. Given the fierce competition in the online search market, search engine operators desperately try to avoid any reduction in search quality in order to maximize user satisfaction.
How can we avoid the potential degradation of search quality under the two-tier architecture? Our basic idea is straightforward: We use the top-k result from the p-index only if we know for sure that the result is the same as the top-k result from the full index. The algorithm in Figure 2 formalizes this idea. In the algorithm, when we compute the result from I P (Step 1), we compute not only the top-k result A , but also the correctness indicator function C defined as follows: Definition 1 (Correctness indicator function) Given a query the p-index I P returns the answer A together with a correctness indicator function C . C is set to 1 if A is guaranteed to be identical (i.e. same results in the same order) to the result computed from the full index I F . If it is possible that A is different,
Note that the algorithm returns the result from I P (Step 3) only when it is identical to the result from I F (condition Step 2). Otherwise, the algorithm recomputes and returns the re-sult from the full index I F (Step 5). Therefore, the algorithm is guaranteed to return the same result as the full replication of the time.

Now, the real challenge is to find out (1) how we can compute the correctness indicator function C and (2) how we should prune the index to make sure that the majority of queries are handled by I P alone.
 Question 1 How can we compute the correctness indicator func-tion C ?
A straightforward way to calculate C is to compute the top-swer both from I P and I F and compare them. This naive solution, however, incurs a cost even higher than the full replication of because the answers are computed twice : once from I P and once from I F . Is there any way to compute the correctness indicator function C only from I P without computing the answer from Question 2 How should we prune I F to I P to realize the maximum cost saving?
The effectiveness of Algorithm 2.1 critically depends on how often the correctness indicator function C is evaluated to be 1. If C =0 for all queries, for example, the answers to all queries will be computed twice, once from I P (Step 1) and once from I F (Step 5), so the performance will be worse than the full replication of What will be the optimal way to prune I F to I P , such that for a large fraction of queries? In the next few sections, we try to address these questions. Intuitively, there exists a clear tradeoff between the size of and the fraction of queries that I P can handle: When I P has more information, it will be able to handle more queries, but the cost for maintaining and looking up I P will be higher. When I
P is small, on the other hand, the cost for I P will be smaller, but more queries will be forwarded to I F , requiring us to maintain more copies of I F . Given this tradeoff, how should we determine the optimal size of I P in order to maximize the cost saving? To find the answer, we start with a simple example.
 Example 3 Again, consider a scenario similar to Example 1, where the query load is 5000 queries/sec, each copy of an index can handle 1000 queries/sec, and the full index spans across 4 ma-chines. But now, suppose that if we prune I F by 75% to I the size of I P 1 is 25% of I F ), I P 1 can handle 40% of the queries (i.e., C =1 for 40% of the queries). Also suppose that if pruned by 50% to I P 2 , I P 2 can handle 80% of the queries. Which one of the I P 1 , I P 2 is preferable for the 1 st -tier index?
To find out the answer, we first compute the number of machines needed when we use I P 1 for the 1 st tier. At the 1 st tier, we need 5 copies of I P 1 to handle the query load of 5000 queries/sec. Since the size of I P 1 is 25% of I F (that requires 4 machines), one copy of I 1 requires one machine. Therefore, the total number of machines required for the 1 st tier is 5  X  1=5 (5 copies of I P 1 with 1 machine per copy). Also, since I P 1 can handle 40% of the queries, the tier has to handle 3000 queries/sec (60% of the 5000 queries/sec), so we need a total of 3  X  4=12 machines for the 2 nd tier (3 copies of
I F with 4 machines per copy). Overall, when we use I P 1 1 st tier, we need 5+12=17 machines to handle the load. We can do similar analysis when we use I P 2 and see that a total of 14 machines are needed when I P 2 is used. Given this result, we can conclude that using I P 2 is preferable.

The above example shows that the cost of the two-tier architec-ture depends on two important parameters: the size of the p-index and the fraction of the queries that can be handled by the index alone. We use s to denote the size of the p-index relative to I F (i.e., if s =0 . 2 , for example, the p-index is 20% of the size of I ). We use f ( s ) to denote the fraction of the queries that a p-index of size s can handle (i.e., if f ( s )=0 . 3 , 30% of the queries return the value C =1 from I P ). In general, we can expect that increase as s gets larger because I P can handle more queries as its size grows. In Figure 3, we show an example graph of f ( s )
Given the notation, we can state the problem of p-index-size op-timization as follows. In formulating the problem, we assume that the number of machines required to operate a two-tier architecture Figure 3: Example function showing the fraction of guaranteed queries f ( s ) at a given size s of the p-index. is roughly proportional to the total size of the indexes necessary to handle the query load.
 Problem 1 (Optimal index size) Given a query load Q and the function f ( s ) , find the optimal p-index size s that minimizes the total size of the indexes necessary to handle the load Q .
The following theorem shows how we can determine the optimal index size.
 Theorem 1 The cost for handling the query load Q is minimal when the size of the p-index, s , satisfies df ( s ) ds =1 Proof The proof of this and the following theorems is omitted due to space constraints.

This theorem shows that the optimal point is when the slope of the f ( s ) curve is 1. For example, in Figure 3, the optimal size is when s =0 . 16 . Note that the exact shape of the f ( s ) may vary depending on the query load and the pruning policy. For example, even for the same p-index, if the query load changes sig-nificantly, fewer (or more) queries may be handled by the p-index, decreasing (or increasing) f ( s ) . Similarly, if we use an effective pruning policy, more queries will be handled by I P than when we use an ineffective pruning policy, increasing f ( s ) . Therefore, the function f ( s ) and the optimal-index size may change significantly depending on the query load and the pruning policy. In our later ex-periments, however, we find that even though the shape of the graph changes noticeably between experiments, the optimal index size consistently lies between 10% X 30% in most experiments. In this section, we show how we should prune the full index to I P , so that (1) we can compute the correctness indicator function C from I P itself and (2) we can handle a large fraction of queries by
I P . In designing the pruning policies, we note the following two localities in the users X  search behavior: 1. Keyword locality: Although there are many different words 2. Document locality: Even if a query has millions of match-
Based on the above two localities, we now investigate two differ-ent types of pruning policies: (1) a keyword pruning policy, which takes advantage of the keyword locality by pruning the whole in-verted list I ( t i ) for unpopular keywords t i  X  X  and (2) a document pruning policy, which takes advantage of the document locality by keeping only a few postings in each list I ( t i ) , which are likely to be included in the top-k results.

As we discussed before, we need to be able to compute the cor-rectness indicator function from the pruned index alone in order to provide the correctness guarantee. Since the computation of cor-rectness indicator function may critically depend on the particular ranking function used by a search engine, we first clarify our as-sumptions on the ranking function.
Consider a query q = { t 1 ,t 2 ,...,t w } that contains a subset of the index terms. The goal of the search engine is to return the documents that are most relevant to query q . This is done in two steps: first we use the inverted index to find all the documents that contain the terms in the query. Second, once we have the rele-vant documents, we calculate the rank (or score) of each one of the documents with respect to the query and we return to the user the documents that rank the highest.

Most of the major search engines today return documents con-taining all query terms (i.e. they use AND-semantics). In order to make our discussions more concise, we will also assume the popu-lar AND-semantics while answering a query. It is straightforward to extend our results to OR-semantics as well. The exact ranking function that search engines employ is a closely guarded secret. What is known, however, is that the factors in determining the doc-ument ranking can be roughly categorized into two classes: Query-dependent relevance. This particular factor of relevance captures how relevant the query is to every document. At a high level, given a document D , for every term t i a search engine assigns a term relevance score tr ( D, t i ) to D . Given the tr ( D, t for every t i , then the query-dependent relevance of D to the query, noted as tr ( D, q ) , can be computed by combining the individual term relevance values. One popular way for calculating the query X  dependent relevance is to represent both the document D and the query q using the TF.IDF vector space model [29] and employ a cosine distance metric.

Since the exact form of tr ( D, t i ) and tr ( D, q ) differs depend-ing on the search engine, we will not restrict to any particular form; instead, in order to make our work applicable in the general case, we will make the generic assumption that the query-dependent rel-evance is computed as a function of the individual term relevance values in the query: Query-independent document quality. This is a factor that mea-sures the overall  X  X uality X  of a document D independent of the par-ticular query issued by the user. Popular techniques that compute the general quality of a page include PageRank [26], HITS [17] and the likelihood that the page is a  X  X pam X  page [25, 15]. Here, we will use pr ( D ) to denote this query-independent part of the final ranking function for document D .

The final ranking score r ( D, q ) of a document will depend on both the query-dependent and query-independent parts of the rank-ing function. The exact combination of these parts may be done in a variety of ways. In general, we can assume that the final rank-ing score of a document is a function of its query-dependent and query-independent relevance scores. More formally: For example, f r ( tr ( D, q ) ,pr ( D )) may take the form f ( tr ( D, q ) ,pr ( D )) =  X   X  tr ( D, q )+(1  X   X  )  X  pr ( D ) thus giving weight  X  to the query-dependent part and the weight 1  X   X  to the query-independent part.

In Equations 1 and 2 the exact form of f r and f tr can vary de-pending on the search engine. Therefore, to make our discussion applicable independent of the particular ranking function used by search engines, in this paper, we will make only the generic as-sumption that the ranking function r ( D, q ) is monotonic on its pa-rameters tr ( D, t 1 ) ,...,tr ( D, t w ) and pr ( D ) . Definition 2 A function f (  X , X ,..., X  ) is monotonic if  X  ,  X   X  1  X   X  2 , ...  X   X  1  X   X  2 it holds that: f (  X  1 , X  f (  X  2 , X  2 ,..., X  2 ) .

Roughly, the monotonicity of the ranking function implies that, between two documents D 1 and D 2 ,if D 1 has higher query-dependent relevance than D 2 and also a higher query-independent score than D 2 ,then D 1 should be ranked higher than D 2 we believe is a reasonable assumption in most practical settings.
Given our assumptions on the ranking function, we now investi-gate the  X  X eyword pruning X  policy, which prunes the inverted index I
F  X  X orizontally X  by removing the whole I ( t i )  X  X  corresponding to the least frequent terms. In Figure 4 we show a graphical represen-tation of keyword pruning, where we remove the inverted lists for t and t 5 , assuming that they do not appear often in the query load.
Note that after keyword pruning, if all keywords { t 1 ,...,t the query q appear in I P , the p-index has the same information as I
F as long as q is concerned. In other words, if all keywords in appear in I P , the answer computed from I P is guaranteed to be the same as the answer computed from I F . Figure 5 formalizes this observation and computes the correctness indicator function a keyword-pruned index I P . It is straightforward to prove that the answer from I P is identical to that from I F if C =1 in the above algorithm.

We now consider the issue of optimizing the I P such that it can handle the largest fraction of queries. This problem can be formally stated as follows: Problem 2 (Optimal keyword pruning) Given the query load Q and a goal index size s  X | I F | for the pruned index, select the in-verted lists I P = { I ( t 1 ) ,...,I ( t h ) } such that the fraction of queries that I P can answer (expressed by maximized.
 Unfortunately, the optimal solution to the above problem is in-tractable as we can show by reducing from knapsack (we omit the complete proof).
 Theorem 2 The problem of calculating the optimal keyword prun-ing is NP-hard.

Given the intractability of the optimal solution, we need to resort to an approximate solution. A common approach for similar knap-sack problems is to adopt a greedy policy by keeping the items with the maximum benefit per unit cost [9]. In our context, the potential benefit of an inverted list I ( t i ) is the number of queries that can be answered by I P when I ( t i ) is included in approximate this number by the fraction of queries in the query load Q that include the term t i and represent it as P ( t ample, if 100 out of 1000 queries contain the term computer , Figure 6: Approximation algorithm for the optimal keyword pruning.
 then P ( computer )=0 . 1 . The cost of including I ( t index is its size | I ( t i ) | . Thus, in our greedy approach in Figure 6, we include I ( t i )  X  X  in the decreasing order of P ( t i as | I P | X  s  X | I F | . Later in our experiment section, we evaluate what fraction of queries can be handled by I P when we employ this greedy keyword-pruning policy.
At a high level, document pruning tries to take advantage of the observation that most users are mainly interested in viewing the top few answers to a query. Given this, it is unnecessary to keep all postings in an inverted list I ( t i ) , because users will not look at most of the documents in the list anyway. We depict the conceptual diagram of the document pruning policy in Figure 4. In the figure, we  X  X ertically prune X  postings corresponding to D 4 ,D 5 and t and D 8 of t 3 , assuming that these documents are unlikely to be part of top-k answers to user queries. Again, our goal is to develop a pruning policy such that (1) we can compute the correctness in-dicator function C from I P alone and (2) we can handle the largest fraction of queries with I P . In the next few sections, we discuss a few alternative approaches for document pruning.
We first investigate the pruning policy that is commonly used by existing search engines. The basic idea for this pruning policy is that the query-independent quality score pr ( D ) is a very important factor in computing the final ranking of the document (e.g. PageR-ank is known to be one of the most important factors determining the overall ranking in the search results), so we build the p-index by keeping only those documents whose pr values are high (i.e., pr ( D ) &gt; X  p for a threshold value  X  p ). The hope is that most of the top-ranked results are likely to have high pr ( D ) values, so the answer computed from this p-index is likely to be similar to the an-swer computed from the full index. Figure 7 describes this pruning policy more formally, where we sort all documents D i  X  X  by their respective pr ( D i ) values and keep a D i in the p-index when its Figure 9: Extended keyword-specific document pruning based on pr and tr . pr ( D i ) value is higher than the global threshold value to this pruning policy as global PR-based pruning (GPR) .
Variations of this pruning policy are possible. For example, we may adjust the threshold value  X  p locally for each inverted list I ( t i ) , so that we maintain at least a certain number of postings for each inverted list I ( t i ) . This policy is shown in Figure 8. We refer to this pruning policy as local PR-based pruning (LPR) .Un-fortunately, the biggest shortcoming of this policy is that we can prove that we cannot compute the correctness function C from alone when I P is constructed this way.
 Theorem 3 No PR-based document pruning can provide the result guarantee.
 Proof Assume we create I P based on the GPR policy (general-izing the proof to LPR is straightforward) and that every docu-ment D with pr ( D ) &gt; X  p is included in I P . Assume that the k th entry in the top-k results, has a ranking score of r ( D f ( tr ( D k ,q ) ,pr ( D k )) . Now consider another document was pruned from I P because pr ( D j ) &lt; X  p . Even so, it is still possible that the document X  X  tr ( D j ,q ) valueisveryhighsuchthat r ( D j ,q )= f r ( tr ( D j ,q ) ,pr ( D j )) &gt;r ( D k Therefore, under a PR-based pruning policy, the quality of the an-swer computed from I P can be significantly worse than that from I
F and it is not possible to detect this degradation without comput-ing the answer from I F . In the next section, we propose simple yet essential changes to this pruning policy that allows us to compute the correctness function C from I P alone.
The main problem of global PR-based document pruning poli-cies is that we do not know the term-relevance score tr ( D, t the pruned documents, so a document not in I P may have a higher ranking score than the ones returned from I P because of their high tr scores.

Here, we propose a new pruning policy, called extended keyword-specific document pruning (EKS) , which avoids this prob-lem by pruning not just based on the query-independent score but also based on the term-relevance tr ( D, t i ) score. That is, for every inverted list I ( t i ) , we pick two threshold values, for pr and  X  ti for tr , such that if a document D  X  I ( t pr ( D ) &gt; X  pi or tr ( D, t i ) &gt; X  ti , we include it in Otherwise, we prune it from I P . Figure 9 formally describes this algorithm. The threshold values,  X  pi and  X  ti , may be selected in a number of different ways. For example, if pr and tr have equal weight in the final ranking and if we want to keep at most ings in each inverted list I ( t i ) , we may want to set the two thresh-old values equal to  X  i (  X  pi =  X  ti =  X  i )andadjust  X  i postings remain in I ( t i ) .

This new pruning policy, when combined with a monotonic scor-ing function, enables us to compute the correctness indicator func-tion C from the pruned index. We use the following example to explain how we may compute C .
 Example 4 Consider the query q = { t 1 ,t 2 } and a monotonic ranking function, f ( pr ( D ) ,tr ( D, t 1 ) ,tr ( D, t 2 possible scenarios on how a document D appears in the pruned index I P . 1. D appears in both I ( t 1 ) and I ( t 2 ) of I P : Since complete
Figure 10: Ranking based on thresholds tr  X  ( t i ) and pr 2. D appears only in I ( t 1 ) but not in I ( t 2 ) :Since 3. D does not appear in any list :Since D does not appear
The above example shows that when a document does not appear in one of the inverted lists I ( t i ) with t i  X  q , we cannot compute its exact ranking score, but we can still compute its upper bound score by using the threshold value  X  ti for the missing values. This suggests the algorithm in Figure 10 that computes the top-A from I P together with the correctness indicator function the algorithm, the correctness indicator function C is set to one only if all documents in the top-k result A appear in all inverted lists I ( t i ) with t i  X  q , so we know their exact score. In this case, because these documents have scores higher than the upper bound scores of any other documents, we know that no other documents can appear in the top-k . The following theorem formally proves the correctness of the algorithm. In [11] Fagin et al., provides a similar proof in the context of multimedia middleware.
 Theorem 4 Given an inverted index I P pruned by the algorithm in Figure 9, a query q = { t 1 ,...,t w } and a monotonic ranking function, the top-k result from I P computed by Algorithm 4.6 is the same as the top-k result from I F if C =1 .
 Proof Let us assume D k is the k th ranked document computed from I P according to Algorithm 4.6. For every document D I
F that is not in the top-k result from I P , there are two possible scenarios:
First, D i is not in the final answer because it was pruned from all inverted lists I ( t j ) , 1  X  j  X  w ,in I P . In this case, we know that pr ( D i )  X  min 1  X  j  X  w  X  pj &lt;pr ( D k ) and that  X  tj &lt;tr ( D k ,t j ) , 1  X  j  X  w . From the monotonicity assumption, it follows that the ranking score of D I is r ( D i ) &lt;r ( D D  X  X  score can never be larger than that of D k .

Second, D i is not in the answer because D i is pruned from some inverted lists, say, I ( t 1 ) ,...,I ( t m ) ,in I P . Let us assume f ( pr ( D i ) ,  X  t 1 , ... ,  X  tm , tr ( D i ,t m +1 ) , tr ( D i ,t j )  X   X  tj (1  X  j  X  m ) and the monotonicity assumption, Figure 11: Fraction of guaranteed queries f ( s ) answered in a keyword-pruned p-index of size s . we know that r ( D i )  X   X  r ( D i ) . Also, Algorithm 4.6 sets 1 only when the top-k documents have scores larger than  X  r ( D Therefore, r ( D i ) cannot be larger than r ( D k ) .
In order to perform realistic tests for our pruning policies, we implemented a search engine prototype. For the experiments in this paper, our search engine indexed about 130 million pages, crawled from the Web during March of 2004. The crawl started from the Open Directory X  X  [10] homepage and proceeded in a breadth-first manner. Overall, the total uncompressed size of our crawled Web pages is approximately 1.9 TB, yielding a full inverted index approximately 1.2 TB.

For the experiments reported in this section we used a real set of queries issued to Looksmart [22] on a daily basis during April of 2003. After keeping only the queries containing keywords that were present in our inverted index, we were left with a set of about 462 million queries. Within our query set, the average number of terms per query is 2 and 98% of the queries contain at most
Some experiments require us to use a particular ranking func-tion. For these, we use the ranking function similar to the one used in [20]. More precisely, our ranking function r ( D, q ) is where pr norm ( D ) is the normalized PageRank of D computed from the downloaded pages and tr norm ( D, q ) is the normalized TF.IDF cosine distance of D to q . This function is clearly simpler than the real functions employed by commercial search engines, but we believe for our evaluation this simple function is adequate, because we are not studying the effectiveness of a ranking function, but the effectiveness of pruning policies.
In our first experiment we study the performance of the keyword pruning, described in Section 4.2. More specifically, we apply the algorithm HS of Figure 6 to our full index I F keyword-pruned p-index I P of size s . For the construction of our keyword-pruned p-index we used the query frequencies observed during the first 10 days of our data set. Then, using the remaining 20-day query load, we measured f ( s ) , the fraction of queries han-dled by I P . According to the algorithm of Figure 5, a query can be handled by I P (i.e., C =1 )if I P includes the inverted lists for all of the query X  X  keywords.

We have repeated the experiment for varying values of s ,pick-ing the keywords greedily as discussed in Section 4.2.The result is shown in Figure 11. The horizontal axis denotes the size p-index as a fraction of the size of I F . The vertical axis shows the fraction f ( s ) of the queries that the p-index of size s The results of Figure 11, are very encouraging: we can answer a significant fraction of the queries with a small fraction of the orig-inal index. For example, approximately 73% of the queries can be answered using 30% of the original index. Also, we find that when we use the keyword pruning policy only, the optimal index size is s =0 . 17 .
 Figure 12: Fraction of guaranteed queries f ( s ) answered in a document-pruned p-index of size s . Figure 13: Fraction of queries answered in a document-pruned p-index of size s .
We continue our experimental evaluation by studying the perfor-mance of the various document pruning policies described in Sec-tion 4.3. For the experiments on document pruning reported here we worked with a 5.5% sample of the whole query set. The reason behind this is merely practical: since we have much less machines compared to a commercial search engine it would take us about a year of computation to process all 462 million queries.

For our first experiment, we generate a document-pruned p-index of size s by using the Extended Keyword-Specific pruning (EKS) in Section 4. Within the p-index we measure the fraction of queries that can be guaranteed (according to Theorem 4) to be correct. We have performed the experiment for varying index sizes s and the result is shown in Figure 12. Based on this figure, we can see that our document pruning algorithm performs well across the scale of index sizes s : for all index sizes larger than 40% , we can guarantee the correct answer for about 70% of the queries. This implies that our EKS algorithm can successfully identify the necessary post-ings for calculating the top-20 results for 70% of the queries by using at least 40% of the full index size. From the figure, we can see that the optimal index size s =0 . 20 when we use EKS as our pruning policy.

We can compare the two pruning schemes, namely the keyword pruning and EKS , by contrasting Figures 11 and 12. Our obser-vation is that, if we would have to pick one of the two pruning policies, then the two policies seem to be more or less equivalent for the p-index sizes s  X  20% . For the p-index sizes s&gt; 20% keyword pruning does a much better job as it provides a higher number of guarantees at any given index size. Later in Section 5.3, we discuss the combination of the two policies.

In our next experiment, we are interested in comparing EKS with the PR-based pruning policies described in Section 4.3. To this end, apart from EKS , we also generated document-pruned p-indexes for the Global pr -based pruning (GPR) and the Local based pruning (LPR) policies. For each of the polices we created document-pruned p-indexes of varying sizes s .Since GP R and LP R cannot provide a correctness guarantee, we will compare the fraction of queries from each policy that are identical (i.e. the same results in the same order) to the top-k results calculated from the full index. Here, we will report our results for k =20 ; the results are similar for other values of k . The results are shown in Figure 13. Figure 14: Average fraction of the top-20 results of p-index with size s contained in top-20 results of the full index.
 The horizontal axis shows the size s of the p-index; the vertical axis shows the fraction f ( s ) of the queries whose top-20 results are identical to the top-20 results of the full index, for a given size
By observing Figure 13, we can see that GP R performs the worst of the three policies. On the other hand EKS , picks up early, by answering a great fraction of queries (about 62% ) correctly with only 10% of the index size. The fraction of queries that answer remains below that of EKS until about s =37% .Forany index size larger than 37% , LP R performs the best.

In the experiment of Figure 13, we applied the strict definition that the results of the p-index have to be in the same order as the ones of the full index. However, in a practical scenario, it may be acceptable to have some of the results out of order. Therefore, in our next experiment we will measure the fraction of the results coming from an p-index that are contained within the results of the full index. The result of the experiment is shown on Figure 14. The horizontal axis is, again, the size s of the p-index; the vertical axis shows the average fraction of the top-20 results common with the top-20 results from the full index. Overall, Figure 14 depicts that EKS and LP R identify the same high (  X  96% ) fraction of results on average for any size s  X  30% , with GP R not too far behind.
In Sections 5.1 and 5.2 we studied the individual performance of our keyword and document pruning schemes. One interesting question however is how do these policies perform in combina-tion? What fraction of queries can we guarantee if we apply both keyword and document pruning in our full index I F ? To answer this question, we performed the following experiment. We started with the full index I F and we applied keyword pruning to create an index I h P of size s h  X  100% of I F . After that, we further applied document pruning to I h P , and created our final p-index I P of size s v  X  100% of I h P . We then calculated the fraction of guaranteed queries in I P . We repeated the experiment for different values of s h and s v . The result is shown on Figure 15. The x-axis shows the index size s h after applying keyword pruning; the y-axis shows the index size s v after applying document pruning; the z-axis shows the fraction of guaranteed queries after the two prunings. For example the point (0.2, 0.3, 0.4) means that if we apply keyword pruning and keep 20% of I F , and subsequently on the resulting index we apply document pruning keeping 30% (thus creating a p-index of size 20%  X  30% = 6% of I F ) we can guarantee 40% queries. By observing Figure 15, we can see that for p-index sizes smaller than 50% , our combined pruning does relatively well. For example, by performing 40% keyword and 40% document pruning (which translates to a pruned index with s =0 . 16 ) we can provide a guarantee for about 60% of the queries. In Figure 15, we also observe a  X  X lateau X  for s h &gt; 0 . 5 and s v &gt; 0 . 5 pruning policy, the optimal index size is at s =0 . 13 , with 0 . 46 and s v =0 . 29 . [3, 30] provide a good overview of inverted indexing in Web search engines and IR systems. Experimental studies and analyses of various partitioning schemes for an inverted index are presented in [6, 23, 33]. The pruning algorithms that we have presented in this paper are independent of the partitioning scheme used.
The works in [1, 5, 7, 20, 27] are the most related to ours, as they describe pruning techniques based on the idea of keeping the post-ings that contribute the most in the final ranking. However, [1, 5, 7, 27] do not consider any query-independent quality (such as PageR-ank) in the ranking function. [32] presents a generic framework for computing approximate top-k answers with some probabilistic bounds on the quality of results. Our work essentially extends [1, 2, 4, 7, 20, 27, 31] by proposing mechanisms for providing the correctness guarantee to the computed top-k results.

Search engines use various methods of caching as a means of re-ducing the cost associated with queries [18, 19, 21, 31]. This thread of work is also orthogonal to ours because a caching scheme may operate on top of our p-index in order to minimize the answer com-putation cost. The exact ranking functions employed by current search engines are closely guarded secrets. In general, however, the rankings are based on query-dependent relevance and query-independent document  X  X uality. X  Query-dependent relevance can be calculated in a variety of ways (see [3, 30]). Similarly, there are a number of works that measure the  X  X uality X  of the documents, typ-ically as captured through link-based analysis [17, 28, 26]. Since our work does not assume a particular form of ranking function, it is complementary to this body of work.
 There has been a great body of work on top-k result calculation . early, or to shrink the lists by pruning postings from the lists [14, 4, 11, 8]. Our proof for the correctness indicator function was pri-marily inspired by [12].
Web search engines typically prune their large-scale inverted in-dexes in order to scale to enormous query loads. While this ap-proach may improve performance, by computing the top results from a pruned index we may notice a significant degradation in the result quality. In this paper, we provided a framework for new pruning techniques and answer computation algorithms that guarantee that the top matching pages are always placed at the top of search results in the correct order. We studied two pruning techniques, namely keyword-based and document-based pruning as well as their combination. Our experimental results demonstrated that our algorithms can effectively be used to prune an inverted index without degradation in the quality of results. In particular, a keyword-pruned index can guarantee 73% of the queries with a size of 30% of the full index, while a document-pruned index can guar-antee 68% of the queries with the same size. When we combine the two pruning algorithms we can guarantee 60% of the queries with an index size of 16%. It is our hope that our work will help search engines develop better, faster and more efficient indexes and thus provide for a better user search experience on the Web.
