 Given a topic of interest, a contrastive theme is a group of oppos-ing pairs of viewpoints. We address the task of summarizing con-trastive themes: given a set of opinionated documents, select mean-ingful sentences to represent contrastive themes present in those documents. Several factors make this a challenging problem: un-known numbers of topics, unknown relationships among topics, and the extraction of comparative sentences. Our approach has three core ingredients: contrastive theme modeling, diverse theme extraction, and contrastive theme summarization. Specifically, we present a hierarchical non-parametric model to describe hierarchi-cal relations among topics; this model is used to infer threads of topics as themes from the nested Chinese restaurant process. We enhance the diversity of themes by using structured determinan-tal point processes for selecting a set of diverse themes with high quality. Finally, we pair contrastive themes and employ an iterative optimization algorithm to select sentences, explicitly considering contrast, relevance, and diversity. Experiments on three datasets demonstrate the effectiveness of our method.
 H.3.3 [ Information Search and Retrieval ]: Information filtering Contrastive theme summarization; Structured determinantal point processes; Hierarchical sentiment-LDA; Topic modeling
In recent years multi-document summarization has become a well studied task for helping users understanding a set of docu-ments. Typically, the focus has been on relatively long, factual and grammatically correct documents [6, 17, 25, 41, 44, 48]. However, the web now holds a large number of opinionated documents, espe-cially in opinion pieces, microblogs, question answering platforms and web forum threads. The growth in volume of such opinionated documents on the web motivates the development of methods to facilitate the understanding of subjective viewpoints present in sets of documents.

Given a set of opinionated documents, we define a viewpoint to be a topic with a specific sentiment label, following [37]. A theme is a set of viewpoints around a specific set of topics and an explicit sentiment opinion. Given a set of specific topics, two themes are contrastive if they are related to the topics, but opposite in terms of sentiment. The phenomenon of contrastive themes is widespread in opinionated web documents [8]. In Fig. 1 we show an example of three contrastive themes about the  X  X alestine and Israel relation-ship. X  Here, each pair of contrastive themes includes two sentences representing two relevant but opposing themes. In this paper, our focus is on developing methods for automatically detecting and de-scribing contrastive themes.
 Figure 1: Three example contrastive themes related to  X  X ales-tine and Israel." Each contrastive theme shows a pair of oppos-ing sentences.
 The task on which we focus is contrastive summarization [18, 37] of multiple themes. The task is similar to opinion summarization , in which opinionated documents are summarized into structured or semi-structured summaries [12, 13, 15, 19]. However, most exist-ing opinion summarization strategies are not adequate for summa-rizing contrastive themes from a set of unstructured documents. To our knowledge, the most similar task in the literature is the con-trastive viewpoint summarization task [37], in which the authors extract contrastive but relevant sentences to reflect contrastive topic aspects, which are derived from a latent topic-aspect model [36]. However, their proposed method for contrastive viewpoint sum-marization neglects to explicitly model the number of topics and the relations among topics in contrastive topic modeling X  X hese are two key features in contrastive theme modeling.

The specific contrastive summarization task that we address in this paper is contrastive theme summarization of multiple opinion-ated documents . In our case, the output consists of contrastive sen-tence pairs that highlight every contrastive theme in the given doc-uments. To address this task, we employ a non-parametric strategy based on the nested Chinese restaurant process (nCRP) [4]. Pre-vious work has proved the effectiveness of non-parametric models in topic modeling [1, 39]. But none of them considers the task of contrastive theme summarization. We introduce a topic model that aims to extract contrastive themes and describe hierarchical rela-tions among the underlying topics. Each document in our model is represented by hierarchical threads of topics, whereas a word in each document is assigned a finite mixture of topic paths. We apply collapsed Gibbs sampling to infer approximate posterior distribu-tions of themes.

To enhance the diversity of the contrastive theme modeling, we then proceed as follows. Structured determinantal point processes (SDPPs) [21] are a novel probabilistic strategy to extract diverse and salient threads from large data collections. Given theme dis-tributions obtained via hierarchical sentiment topic modeling, we employ SDPPs to extract a set of diverse and salient themes. Fi-nally, based on themes extracted in the first two steps, we develop an iterative optimization algorithm to generate the final contrastive theme summary. During this process, relevance , diversity and con-trast are considered.

Our experimental results, obtained using three publicly available opinionated document datasets, show that contrastive themes can be successfully extracted from a given corpus of opinionated docu-ments. Our proposed method for multiple contrastive themes sum-marization outperforms state-of-the-art baselines, as measured us-ing ROUGE metrics.

To sum up, our contributions in this paper are as follows: We introduce related work in  X 2. We formulate our research prob-lem in  X 3 and describe our approach in  X 4. Then,  X 5 details our experimental setup and  X 6 presents the experimental results. Fi-nally,  X 7 concludes the paper.
Multi-document summarization (MDS) is useful since it is able to provide a brief digest of large numbers of relevant documents on the same topic [34]. Most existing work on MDS is based on the extractive format, where the target is to extract salient sentences to construct a summary. Both unsupervised and supervised based learning strategies have received lots of attention. One of the most widely used unsupervised strategies is clustering with respect to the centroid of the sentences within a given set of documents; this idea has been applied by NeATS [28] and MEAD [38]. Many other recent publications on MDS employ graph-based ranking meth-ods [10]. Wan and Yang [48] propose a theme-cluster strategy based on conditional Markov random walks. Similar methods are also applied in [49] for a query-based MDS task. Celikyilmaz and Hakkani-Tur [6] consider the summarization task as a supervised prediction problem based on a two-step hybrid generative model, whereas the Pythy summarization system [47] learns a log-linear sentence ranking model by combining a set of semantic features. As to discriminative models, CRF-based algorithms [44] and struc-tured SVM-based classifiers [25] have proved to be effective in ex-tractive document summarization. Learning to rank models have also been employed to query-based MDS [43] and to topic-focused MDS [50]. In recent years, with the development of social me-dia, multi-document summarization is being applied to social doc-uments, e.g., tweets, weibos, and Facebook posts [7, 9, 35, 40, 41]. Temporal and update summarization [2] is becoming a popular task in MDS research [ 34]; for this task one follows a stream of docu-ments over time and summarizes information on what is new com-pared to what has been summarized previously [31, 35, 45].
In recent years, opinion summarization has received extensive attention. Opinion summarization generates structured [15, 24, 30, 32] or semi-structured summaries [13, 16, 20] given opinionated documents as input. Opinosis [12] generates a summary from re-dundant data sources. Similarly, a graph-based multi-sentence com-pression approach has been proposed in [11]. Meng et al. [33] pro-pose an entity-centric topic-based opinion summarization frame-work, which is aimed at generating summaries with respect to top-ics and opinions.

Other relevant work for our contrastive summarization has been published by Lerman and McDonald [23] and Paul et al. [37]. Ler-man and McDonald [23] propose an approach to extract represen-tative contrastive descriptions from product reviews. A joint model between sentiment mining and topic modeling is applied in [37].
Non-parametric topic models are aimed at handling infinitely many topics; they have received much attention. For instance, hi-erarchical Latent Dirichlet Allocation (hLDA) [4] describes latent topics over nested Chinese restaurant processes. To capture the relationship between latent topics, nested Chinese restaurant pro-cesses generate tree-like topical structures over documents. Tra-ditional non-parametric topic models do not explicitly address di-versification among latent variables during clustering. To tackle this issue, Kulesza and Taskar [21, 22] propose a stochastic pro-cess named structured determinantal point process (SDPP), where diversity is explicitly considered. As an application in text mining, Gillenwater et al. [14] propose a method for topic modeling based on SDPPs. As far as we know, the determinantal point process has not been integrated with other non-parametric models yet. To the best of our knowledge, there is little previous work on sum-marizing contrastive themes. In this paper, by optimizing the num-ber of topics, building relations among topics and enhancing the diversity among themes, we propose a hierarchical topic modeling strategy to summarize contrastive themes in the given documents.
Before introducing our method for contrastive theme summa-rization, we introduce our notation and key concepts. Table 1 lists the notation we use in this paper. Symbol Description
Given a corpus D , we begin by defining the notions of topic, sen-timent and theme in our work. Following topic modeling customs [3], we define a topic in a document d to be a probability distri-bution over words. Unlike  X  X lat X  topic models [3], we assume that each document d can be represented by multiple topics that are or-ganized in an infinite tree-like hierarchy c = { ( z 0 ,c ) , ( z z 0  X  z 1  X  ... , i.e., c indicates a path from the root topic level z on the infinite tree to more specialized topics that appear at the leaves of the tree, and for each topic level z we define a topic node b = ( z,c ) on the topic path c .

Sentiment is defined as a probability distribution over sentiment labels positive , negative , and neutral . A sentiment label x is at-tached with each word w . Considering the sentiment , we divide topics into three classes: positive topics (2), neutral topics (1) and negative topics (0).

Given all hierarchical topics and sentiment labels, we define a theme k c,x as a threaded topic path c from the root level to the leaf level for the given sentiment label x . Let K be the set of themes, and let K pos , K neg , K neu indicate the set of positive, negative and neutral themes, respectively, i.e., K = K pos  X  X  neg  X  X  Furthermore, we define a contrastive theme to be a theme tuple t = ( c pos ,c neg ,c neu ) by extracting themes fromis contained in K are relevant in topic but opposite in sentiment labels.
Finally, we define contrastive theme summarization. Given a set of documents D = { d 1 ,d 2 ,...,d D } , the purpose of the contrastive theme summarization task (CTS) is to select a set of meaningful sentences S t = { S c pos ,S c neg ,S c neu } to reflect the representative information in each possible theme tuple t = ( c pos ,c neg A point process P on a discrete set Y = { y 1 ,y 2 ,...,y a probability measure on the power set 2 Y of Y . We follow the definitions from [21]. A determinantal point process (DPP) P is a point process with a positive semidefinite matrix M indexed by the elements of Y , such that if Y  X  P , then for each A  X  Y , there is P ( A  X  Y ) = det( M A ) . Here, M A = [ M i,j is the restriction of M to the entries indexed by elements of A . Matrix M is defined as the marginal kernel, where it contains all information to compute the probability of A X  X  . For the purpose of modeling data, the construction of DPP is via L-ensemble [5]. Using L-ensemble, we have where I is the N  X  N identity matrix, L is a positive semidefinite matrix; L Y = [ L i,j ] y entries indexed by elements of Y , and det( L  X  ) = 1 . For each entry of L , we have where q ( y i )  X  R + is considered as the  X  X uality X  of an item y  X  ( y i ) T  X  ( y j )  X  [  X  1 , 1] measures the similarity between item y and y j . Here, for each  X  ( y i ) we set  X  ( y i )  X  R D value of a determinant of vectors is equivalent to the volume of the polyhedron spanned by those vectors, P ( Y ) is proportional to the volumes spanned by q ( y i )  X  ( y i ) . Thus, sets with high-quality, diverse items will get the highest probability in DPP.

Building on the DPP, structured determinantal point processes (SDPPs) have been proposed to efficiently handle the problem con-taining exponentially many structures [14, 21, 22]. In the setting of SDPPs, items set Y contains a set of threads of length T . Thus in SDPPs, each item y i has the form y i = { y (1) i ,y (2) where y ( t ) i indicates the document at the t -th position of thread y To make the normalization and sampling efficient, SDPPs assume quality multiplicatively and similarity additively, as follows: the quality function q ( y i ) has a simple log-linear model setting balances between quality and diversity. An efficient sampling al-gorithm for SDPPs has been proposed by Kulesza and Taskar [21]. Since SDPPs specifically address  X  X iversification X  and  X  X aliency, X  we apply them to identify diversified and salient themes from themes sets K . We will detail this step in  X 4.
We provide a general overview of our method for performing contrastive theme summarization (CTS) in Fig. 2. There are three main phases: (A) contrastive theme modeling; (B) diverse theme extraction; and (C) contrastive theme summarization. To summa-rize, we are given a set of documents D = { d 1 ,d 2 ,...,d input. For each document d  X  D , in phase (A) (see  X 4.2), we ob-tain a structured themes set K with a root node r , topic distributions  X  and opinion distributions o s .

In (B) (see  X 4.3), given the structured output themes K , we em-ploy a structured determinantal point process to obtain a subset K 0  X  X  to enhance the saliency and diversity among themes.
Based on themes K 0 and their corresponding topic distributions and opinion distributions, in (C) (see  X 4.4) we generate the final contrastive theme summary S . We develop an iterative optimiza-tion algorithm for this process: the first part in  X 4.4 is to generate the contrastive theme tuples T , each of which includes relevant themes for a topic but contrastive in sentiment; the second part in  X 4.4 is meant to generate the final contrastive summary S = { S for each theme tuple.
We start by proposing a hierarchical sentiment-LDA model to jointly extract topics and opinions from our input corpus. Unlike previous work on traditional  X  X lat X  topic models [37], our method can adaptively generate topics organized in a tree-like hierarchy.
Briefly, each document d  X  D can be represented as a collec-tion of sentences, whereas each sentence s  X  d is composed of a collection of words. By using a state-of-the-art sentiment analy-sis method [46], for each word w in each document d we extract its sentiment label x w , where x w  X  { pos,neu,neg } . Generally, for document d we select three threaded topic paths { c x = pos , neu , neg , each of which is generated by a nested Chi-nese restaurant process (nCRP) [4]. After deriving the sentiment label x , each word w  X  d is assigned to a specific topic level z by traversing from the root to the leave on the path c x . Next, we give a more detailed technical account of our model. Following the nested Chinese restaurant process [4], our topic model identifies documents with threaded topic paths generated by nCRP. Given level z , we consider each node ( z,c ) on a threaded topic path c as a specific topic. To select the exact topic level z  X  [1 ,L ] , we draw a variable  X  d from a Dirichlet distribution derived from hy-perparameter m , to define a probability distribution on topic levels along the topic path c . Given a draw from a Dirichlet distribution, document d is generated by repeatedly selecting a topic level. We assume that each document d  X  D is represented by three classes of topics: positive, negative and neutral topics.

In document d , for each sentence s  X  d we define a sentiment distribution o s from a Dirichlet distribution over a hyper parame-ter  X  . For each word w  X  W , we select three topic levels z z neg and z neu from a discrete distribution over  X  d , respectively. While the sentiment label is derived from a multinomial distribu-tion over o s , w is derived from a discrete distribution over topic levels { z pos ,z neg ,z neu } . The generation process of our proposed model is shown in Fig. 3.

Since exact posterior inference in hierarchical sentiment-LDA is intractable, we employ a collapsed Gibbs sampler to approximate the posterior distributions of topic level z w for each word w and topic path c d for each document d . In our model, two sets of vari-ables are observed: the sentiment labels x w for each word w , and the words set W . Our sampling procedure is divided into two steps for each iteration: (1) sampling a topic path for each document; (2) sampling level allocation for each word.

For the sampling procedure of thread c d , given current other vari-ables on document d , we have: 1. For each topic level z x  X  X  x in infinite tree: 2. For each document d  X  X  :
Figure 3: Generative process in hierarchical sentiment-LDA. Chinese restaurant process, whereas for each topic node ( z,c path c d , we have: where b i indicates a node that has been taken before, b new a new node that has not been considered yet; n i refers to the number of times that topic node ( z,c d ) is assigned to a document. To infer p ( W d | W  X  d ,c,x,o,z ) , we integrate over multinomial parameters and have: p ( W d | W  X  d ,c,x,o,z )  X  where n z,c  X  d indicates the number of times that documents have been assigned to topic node ( z,c ) leaving out document d ; n notes the number of times that word w has been assigned to the topic node ( z,c ) leaving out document d .

To sample topic level z d,n for each word w n in document d , we find its joint probabilistic distribution of terms, sentiment labels and topics as follows: where z x  X  ( d,n ) denotes the vectors of level allocations leaving out z d,n in document d . Further, n that words have been assigned to topic node (  X ,c ) that are the same as word w n ; n  X  d,  X  n denotes the number of times that document d have been assigned to level k leaving out word w n .

After Gibbs sampling, we get a set of topic paths { c x } that can be represented as themes K = { k c,x } ; for each word w in d , we have hybrid parametric distributions  X  x that reflect the topic distribution given a specific level z on path c , i.e., P ( w,x | c,z ) =  X  each sentence s , we have a probability distribution o s over senti-ment labels, i.e., P ( x | s ) = o s,x .
Given a set of themes K = { k c,x } resulting from step (A), some further issues need to be tackled before we arrive at our desired summary. On the one hand, many themes in K share common top-ics; on the other hand, many words X  topic probabilities  X  are sim-ilar, which makes it difficult to distinguish the importance of the themes.

To address this dual problem, we employ the structured determi-nantal point process (SDPP) [22] to select a subset of salient and diverse themes from K . Following [21], we define a structured de-terminantal point process P as a type of probability distribution over a subset of themes belonging to K . Two main factors are con-sidered in SDPPs: the quality q i and the similarity  X  i T set with high quality and highly diverse themes will be assigned the highest probability P by the SDPPs.

Given themes K sampled from (A), we proceed as follows. Firstly, for each theme k  X  K we use q (( z i ,c )) to indicate the  X  X uality X  of topic ( z i ,c )  X  k and we use  X  (( z i ,c )) T  X  (( z to refer to a measure of similarity between two topics ( z ( z ,c 0 ) : q (( z i ,c )) = X  X  (( z i ,c )) T  X  (( z j ,c 0 )) = exp  X  where  X  z i ,c indicates the vector {  X  z,c,w } w  X  X  ;  X  z is the squared Euclidean distance between  X  z i ,c and  X  z indicates the top-n salient words;  X  is a free parameter. Based on (1) and (2), we construct the semidefinite matrix M for SDPPs.
For two topic paths c i = { ( z 1 ,c i ) ,..., ( z L ,c ing quality multiplicatively and similarity additively, i.e., for topic tively.

To infer the posterior results of SDPPs over themes, we adapt an efficient sampling algorithm as described in Algorithm 1. Follow-ing [21], we let M = P K k =1  X  k v k v T k be an orthonormal eigen-decomposition, and let e i be the i th standard basis K -vector. The sampling algorithm of SDPPs outputs a subset of themes, i.e., K { k c,x } , which reflect a trade-off between high quality and high di-versity.
 Algorithm 1: Sampling process for SDPPs Input : Eigenvector/values pairs { ( v k , X  k ) } ; Themes set K ; Output : Filtered themes set K 0 from SDPPs;
J  X  0 ; K 0  X  0 ; for k  X  X  do end while | V | &gt; 0 do end return K 0 .
In this section, we specify the sentence selection procedure for contrastive themes. Considering the diversity among topics, we only consider leaf topics in each theme k 0 c,x  X  K theme k 0 c,x can be represented by a leaf topic ( z x L ,c For simplicity, we abbreviate leaf topics sets { ( z x L ,c
Given { c x } , we need to connect topics in various classes to a set of contrastive theme tuples of the form t = ( c pos i ,c neg assess the correlation between two topics ( c x i ) and ( c classes, we define a correlation based on topic distributions  X  follows: We sample three leaf topics from the three classes mentioned earlier (positive, negative and neutral), so that the total correlation values for all three topic pairs has maximal values.

Next, we extract representative sentences for each contrastive ating the contrastive theme summary is to extract the most salient sentences as a summary. However, high-degree topical relevance cannot be taken as the only criterion for sentence selection. To ex-tract a contrastive theme summary S t = { S c pos two more key requirements contrast and diversity . Given selected sentences S 0 t , we define a salient score F ( s i |S 0 c where ctr ( s i |S 0 t ,t ) indicates the contrast between s div ( s i , S 0 t ) indicates the divergence between s i and S indicates the relevance of s i given t .

Contrast calculates the sentiment divergence between the cur-rently selected sentence s i and the results of extracted sentences set S 0 t , under the given theme t . Our intention is to make the cur-rent sentence as contrastive as possible from extracted sentences as much as possible. Therefore, we have: Diversity calculates the information divergence among all sentences within the current candidate result set. Ideally, the contrastive sum-mary results have the largest possible difference in theme distribu-Algorithm 2: Iterative process for generating the summary S . Input : T = { ( c pos i ,c neg ii ,c neu iii ) } ,  X  ,  X  , S , N ;
Output : S = n { S c pos end return S . tions with each other. The equation is as follows: Furthermore, a contrastive summary should contain relevant sen-tences for each theme t , and minimize the information loss with the set of all candidate sentences. Thus, given  X  x z L ,c,w vance of sentence s i given theme t is calculated as follows: Algorithm 2 shows the details of our sentence extraction procedure.
We list the research questions RQ1  X  RQ4 that guide the remain-der of the paper.
 RQ1 Is hierarchical sentiment-LDA effective for extracting con-RQ2 Is the structured determinantal point process helpful for com-RQ3 How does our iterative optimization algorithm perform on RQ4 What is the effect of contrast , diversity and relevance for
We employ three datasets in our experiments. Two of them have been used in previous work [36, 37], and another one is extracted from news articles of the New York Times. 1 All documents in our http://ilps.science.uva.nl/resources/nyt_ cts Table 2: Top 15 topics in our three datasets. Column 1 shows the name of topic; column 2 shows the number of articles in-cluded in the topic; column 3 shows the publication period of those articles, and column 4 indicates to which dataset the topic belongs.
 General description # articles Period Dataset U.S. International Relations 3121 2004 X 2007 3 Terrorism 2709 2004 X 2007 3 Presidential Election of 2004 1686 2004 3 U.S. Healthcare Bill 940 2010 1 Budgets &amp; Budgeting 852 2004 X 2007 3 Israel-Palestine conflict 594 2001 X 2005 2 Airlines &amp; Airplanes 540 2004 X 2007 3 Colleges and Universities 490 2004 X 2007 3 Freedom and Human Rights 442 2004 X 2007 3 Children and Youth 424 2004 X 2007 3 Computers and the Internet 395 2004 X 2007 3 Atomic Weapons 362 2004 X 2005 3 Books and Literature 274 2004 X 2007 3 Abortion 170 2004 X 2007 3
Biological and Chemical Warfare 152 2004 X 2006 3 datasets are written in English. All three datasets include human-made summaries, which are considered as ground-truth in our ex-periments. As an example, Table 2 shows statistics of 15 themes from the three datasets that include the largest number of articles in our dataset. In total, 15 , 736 articles are used in our experiments.
The first dataset ( X  X ataset 1 X  in Table 2) consists of documents from a Gallup 2 phone survey about the 2010 U.S. healthcare bill. It contains 948 verbatim responses, collected March 4 X 7, 2010. Re-spondents indicate if they are  X  X or X  or  X  X gainst X  the bill, and there is a roughly even mix of the two opinions (45% for and 48% against). Each document in this dataset only includes 1 X 2 sentences.
Our second dataset ( X  X ataset 2 X ) is extracted from the Bitter-lemons corpus, which is a collection of 594 opinionated articles about the Israel-Palestine conflict. The Bitterlemons corpus con-sists of the articles published on the Bitterlemons website late 2001 to early 2005. This dataset has also been applied in previ-ous work [29, 36]. Unlike the first dataset, this dataset contains long opinionated articles with well-formed sentences. It too contains a fairly even mixture of two different perspectives: 312 articles from Israeli authors and 282 articles from Palestinian authors. Our third dataset ( X  X ataset 3 X ) is a set of articles from the New York Times. The New York Times Corpus contains over 1.8 mil-lion articles written and published between January 1, 1987 and June 19, 2007. Over 650,000 articles have manually written arti-cle summaries. In our experiments, we only use Opinion column articles that were published during 2004 X 2007. We list the methods and baselines that we consider in Table 3. We write HSDPP for the overall process as described in Section 4, which includes steps (A) contrastive theme modeling, (B) diverse theme extraction and (C) contrastive theme summarization. We write HSLDA for the model that only considers steps (A) and (C), so skipping the structured determinantal point processes in (B). To evaluate the effect of contrast , relevance and diversity , we consider HSDPPC, the method that only considers contrast in contrastive http://www.gallup.com/home.aspx http://www.bitterlemons.org Table 3: Our methods and baselines used for comparison. theme summarization. We write HSDPPR for the method that only considers relevance and HSDPPD for the method that only consid-ers diversity in the summarization.

To assess the contribution of our proposed methods, our base-lines include recent related work. For contrastive theme modeling, we use the Topic-aspect model (TAM, [36]) and the Sentiment-topic model (Sen-TM, [24]) as baselines for topic models. Both focus on the joint process between topics and opinions. Other topic models, such as Latent dirichlet allocation (LDA) [3] and hierar-chical latent dirichlet allocation (HLDA) [4], are also considered in our experiments. For the above  X  X lat X  topic models, we evaluate their performance using varying numbers of topics ( 10 , 30 and 50 respectively). The number of topics used will be shown as a suffix to the model X  X  name, e.g., TAM-10.

We also consider previous document summarization work as base-lines: (1) A depth-first search strategy (DFS, [13]) based on our topic model. (2) The LexRank algorithm [10] that ranks sentences via a Markov random walk strategy. (3) ClusterCMRW [48] that ranks sentences via a clustering-based method. (4) Random, which extracts sentences randomly.
Following existing models, we set pre-defined values for some parameters in our proposed method. In our proposed hierarchical sentiment-LDA model, we set m as 0 . 1 and  X  as 0 . 33 as default values in our experiments.

Optimizing the number of topics is a problem shared between all topic modeling approaches. In our hierarchical sentiment-LDA model, we set the default length of L to 10 , and we discuss it in our experiments. As same as other non-parametric topic models, our HSLDA model optimizes the number of themes automatically. Under the default settings in our topic modeling, we find that for the Gallup investigation data, the optimal number of topics is 23 ; the Bitterlemons corpus, it is 67 ; for the New York Times dataset, it is 282 .
To assess the saliency of contrastive theme modeling in our ex-periments, we adapt the purity and accuracy in our experiments to measure performance. To evaluate the diversity among topics we calculate the diversity as follows: We adopt the ROUGE evaluation metrics [27], a widely-used recall-oriented metric for document summarization that evaluates the over-lap between a gold standard and candidate selections. We use ROUGE-1 (R-1, unigram based method ), ROUGE-2 (R-2, bigram based method ) and ROUGE-W (R-W, weighted longest common sequence ) in our experiments.

Statistical significance of observed differences between the per-formance of two runs is tested using a two-tailed paired t-test and is denoted using N (or H ) for strong significance for  X  = 0 . 01 ; or (or O ) for weak significance for  X  = 0 . 05 . In our experiments, significant difference are with regard to TAM and TAM-Lex for contrastive theme modeling and contrastive theme summarization, respectively. We start by addressing RQ1 and test whether HSLDA and HS-DPP are effective for the contrastive theme modeling task. First, Table 4 shows an example topic path of our hierarchical sentiment-LDA model. Column 1 shows the topic levels, columns 2, 3 and 4 show the 7 most representative words with positive, neutral and negative sentiment labels, respectively. For each sentiment label, we find semantic dependencies between adjacent levels.

Table 5 compares the accuracy and purity of our proposed meth-ods to four baselines. We find that HSDPP and HSLDA tend to outperform the baselines. For the Bitterlemons and New York Times corpora, HSDPP exhibits the best performance both in terms of ac-curacy and purity . Compared to TAM, HSDPP shows a 9 . 5 % in-crease in terms of accuracy . TAM achieves the best performance on the Healthcare Corpus when we set its number of topics to 10 . However, the performance differences between HSDPP and TAM on this corpus are not statistically significant. This shows that our proposed contrastive topic modeling strategy is effective in con-trastive topic extraction.
To start, for research question RQ1 , to evaluate the effect of the length of each topic path to the performance of contrastive theme modeling, we examine the performance of HSDPP with different values of topic level L , in terms of accuracy . In Figure 4, we find that the performance of HSDPP in terms of accuracy peaks when the length of L equals 12 ; with fewer than 12 , performance keeps increasing but if the number exceeds 12 , due to the redundancy of topics in contrastive summarization, performance decreases.
Unlike TAM and Sen-LDA, HSDPP and HSLDA determine the optimal number of topics automatically. In Table 5 we find that the results for TAM change with various number of topics. However, for HSDPP we find that it remains competitive for all three corpora while automatically determining the number of topics. Turning to RQ2 , Table 5 shows that performance of HSDPP and HSLDA on contrastive theme modeling in terms of accuracy and purity , for all three datasets. We find that HSDPP outperforms HSLDA in terms of both accuracy and purity . Table 5 also con-trasts the evaluation results for HSDPP with TAM and Sen-TM in to TAM-10 (row with shaded background).
 0.350 H 0.167 O 0.321 H 0.322 H 0.172 H 0.332 H 0.137 H 0.317 H 0.317 H 0.144 H 0.309 H 0.121 H 0.295 H 0.301 H 0.134 H 0.596 O 0.1740 0.5760 0.5820 0.195 H 0.539 H 0.2090 0.5140 0.5180 0.2550 0.502 H 0.163 O 0.4730 0.4780 0.195 H 0.482 H 0.152 O 0.454 H 0.456 H 0.182 H 0.342 H 0.2630 0.329 H 0.330 H 0.2910 Figure 4: RQ1: Performance with different values of hierarchi-cal topic level L , in terms of accuracy terms of diversity (columns 4, 7, 10). We evaluate the performance of TAM and Sen-TM by varying the number of topics. HSDPP achieves the highest diversity scores. The diversity scores for TAM and Sen-TM decrease as the number of topics increases. In Table 6, we see that HSDPP outperforms HSLDA for all top 15 topics in our dataset in terms of diversity. In terms of diversity, HSDPP offers a significant increase over HSLDA of up to 18.2%.
To evaluate the performance before and after structured deter-minantal point processes in terms of accuracy , Table 6 contrasts the evaluation results for HSDPP with those of HSLDA, which excludes structured determinantal point processes, in terms of ac-curacy . We find that HSDPP outperforms HSLDA for each topic listed in Table 6. In terms of accuracy , HSDPP offers a significant increase over HSLDA of up to 14.6%. Overall, HSDPP outper-forms HSLDA with a 5.6% increase in terms of accuracy. Hence, we conclude that the structured determinantal point processes helps to enhance the performance of contrastive theme extraction.
To help us answer RQ3 , Table 7 lists the ROUGE performance for all summarization methods. As expected, Random performs worst. Using a depth-first search-based summary method (DFS) does not perform well in our experiments. Our proposed method HSDPP significantly outperforms the baselines on two datasets, whereas on the healthcare corpus the LexRank-based method per-forms better than HSDPP, but not significantly. A manual inspec-tion of the outcomes indicates that the contrastive summarizer in HSDPP (i.e., step (C) in Fig. 2) is being outperformed by the Lex-Rank summarizer in HSDPP-Lex on the Healthcare dataset be-cause of the small vocabulary and the relative shortness of the doc-uments in this dataset (at most two sentences per document). The summarizer in HSDPP prefers longer documents and a larger vo-cabulary. We can see this phenomenon on the Bitterlemons Corpus , which has 20 X 40 sentences per document, where HSDPP achieves a 10 . 3 % ( 13 . 4 %) increase over TAM-Lex in terms of ROUGE-1 (ROUGE-2), whereas the ROUGE-1 (ROUGE-2) score increases 2 . 2 % ( 4 . 8 %) over HSDPP-Lex. On the New York Times , HSDPP offers a significant improvement over TAM-Lex of up to 13 . 2 % and 18 . 2 % in terms of ROUGE-1 and ROUGE-2, respectively. Several factors play a role in our proposed summarization method, HSDPP. To determine the contribution of contrast , relevance and diversity , Table 8 shows the performance of HSDPPD, HSDPPR, respect to TAM-Lex (row with shaded background).

Random 0.132 H 0.022 H 0.045 H 0.105 H 0.019 H 0.038 H 0.102 H 0.015 H 0.033 H
ClusterCMRW 0.292 H 0.071 H 0.155 H 0.263 H 0.065 H 0.1060 0.252 H 0.066 H 0.098 H
DSF 0.264 H 0.064 H 0.125 H 0.235 H 0.054 H 0.091 H 0.211 H 0.047 H 0.088 H
Sen-TM-Lex 0.312 H 0.077 O 0.1410 0.296 H 0.062 H 0.1290 0.284 H 0.057 H 0.1220 TAM-Lex 0.397 0.085 0.147 0.362 0.071 0.135 0.341 0.068 0.125
HSDPP 0.398 0 0.089 0 0.1420 0.404 N 0.082 N 0.159 N 0.393 N 0.082 N 0.149 N Table 6: RQ2: Effect of structured determinantal point pro-cesses in topic modeling for the top 15 topics in our datasets. Acc. abbreviates accuracy, Div. abbreviates diversity.
 Descriptions Acc. Div. Acc. Div.
 U.S. Inter. Relations 0.5320 0.2940 0.583 M 0.312 0
Terrorism 0.5690 0.3010 0.621 N 0.341 N 2004 Election 0.5910 0.2660 0.641 N 0.281 0 US. Healthcare 0.5910 0.2250 0.603 0.244 0 Budget 0.5060 0.2480 0.551 N 0.299 M Israel-Palestine 0.658 0 0.2690 0.6520 0.292 0 Airlines 0.6020 0.3250 0.6020 0.384 N Universities 0.596 0 0.2070 0.5620 0.219 0 Human Rights 0.5710 0.1990 0.624 M 0.206 M Children 0.712 0 0.3520 0.6220 0.394 N Internet 0.5470 0.2770 0.601 N 0.298 0 Atomic Weapons 0.6140 0.2920 0.662 M 0.306 M Literature 0.5550 0.2120 0.611 M 0.255 M Abortions 0.5940 0.3010 0.608 0 0.322 M Bio.&amp;Chemi. warfare 0.5960 0.2750 0.597 0 0.302 M
Overall 0.5810 0.2960 0.614 M 0.317 M and HSDPPC in terms of the ROUGE metrics. We find that HS-DPP, which combines contrast , relevance and diversity , outper-forms the other approaches on all corpora. After HSDPP, HSDPPR, which includes relevance during the summarization process, per-forms best. Thus, from Table 8 we conclude that relevance is the most important part during the summarization process.
We have considered the task of contrastive theme summarization of multiple opinionated documents. We have identified two main challenges: unknown number of topics and unknown relationships among topics. We have tackled these challenges by combining the nested Chinese restaurant process with contrastive theme modeling, which outputs a set of threaded topic paths as themes. To enhance the diversity of contrastive theme modeling, we have presented the structured determinantal point process to extract a subset of di-verse and salient themes. Based on the probabilistic distributions of themes, we generate contrastive summaries subject to three key criteria: contrast, diversity and relevance. In our experiments, we have demonstrated the effectiveness of our proposed method, find-ing significant improvements over state-of-the-art baselines tested with three manually annotated datasets. Contrastive theme model-ing is helpful for extracting contrastive themes and optimizing the number of topics. We have also shown that structured determinan-tal point processes are effective for diverse theme extraction.
Although we focused mostly on news articles or news-relate ar-ticles, our methods are more broadly applicable to other settings with opinionated and conflicted content, such as comment sites or product reviews. Limitations of our work include its ignorance of word dependencies and, being based on hierarchical LDA, the doc-uments that our methods work with should be sufficiently large.
As to future work, parallel processing methods may enhance the efficiency of our topic model on large-scale opinionated doc-uments. Also, the transfer of our approach to streaming corpora should give new insights. It is interesting to consider recent studies such as [26] on search result diversification for selecting salient and diverse themes. Finally, supervised and semi-supervised learning can be used to improve the accuracy in contrastive theme summa-rization [42].
 [1] A. Ahmed, L. Hong, and A. Smola. Nested chinese [2] J. Allan, C. Wade, and A. Bolivar. Retrieval and novelty [3] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet [4] D. M. Blei, T. L. Griffiths, and M. I. Jordan. The nested [5] A. Borodin. Determinantal point processes. In The Oxford [6] A. Celikyilmaz and D. Hakkani-Tur. A hybrid hierarchical [7] D. Chakrabarti and K. Punera. Event summarization using [8] S. Dori-Hacohen and J. Allan. Detecting controversy on the [9] Y. Duan, F. Wei, C. Zhumin, Z. Ming, and Y. Shum. Twitter [10] G. Erkan and D. Radev. Lexrank: Graph-based lexical are with respect to the row labeled HSDPPD, with shaded background. HSDPPD 0.291 0.054 0.133 0.301 0.045 0.136 0.284 0.042 0.132
HSDPPR 0.392 N 0.082 N 0.1380 0.394 N 0.079 N 0.146 N 0.376 N 0.072 N 0.147 N HSDPPC 0.3620 0.0780 0.1360 0.3190 0.0590 0.1360 0.3080 0.0670 0.1410
HSDPP 0.398 N 0.089 N 0.142 M 0.404 N 0.082 N 0.159 N 0.393 N 0.082 N 0.149 N [11] K. Filippova. Multi-sentence compression: Finding shortest [12] K. Ganesan, C. Zhai, and J. Han. Opinosis: a graph-based [13] K. Ganesan, C. Zhai, and E. Viegas. Micropinion generation: [14] J. Gillenwater, A. Kulesza, and B. Taskar. Discovering [15] M. Hu and B. Liu. Mining opinion features in customer [16] M. Hu and B. Liu. Opinion extraction and summarization on [17] X. Huang, X. Wan, and J. Xiao. Comparative news [18] H. D. Kim and C. Zhai. Generating comparative summaries [19] H. D. Kim, K. Ganesan, P. Sondhi, and C. Zhai.
 [20] H. D. Kim, M. G. Castellanos, M. Hsu, C. Zhai, U. Dayal, [21] A. Kulesza and B. Taskar. Structured determinantal point [22] A. Kulesza and B. Taskar. Determinantal point processes for [23] K. Lerman and R. McDonald. Contrastive summarization: [24] F. Li, C. Han, M. Huang, X. Zhu, Y.-J. Xia, S. Zhang, and [25] L. Li, K. Zhou, G. Xue, H. Zha, and Y. Yu. Enhancing [26] S. Liang, Z. Ren, and M. de Rijke. Fusion helps [27] C.-Y. Lin. Rouge: A package for automatic evaluation of [28] C.-Y. Lin and E. Hovy. From single to multi-document [29] W.-H. Lin, T. Wilson, J. Wiebe, and A. Hauptmann. Which [30] Y. Lu, C. Zhai, and N. Sundaresan. Rated aspect [31] R. McCreadie, C. Macdonald, and I. Ounis. Incremental [32] Q. Mei, X. Ling, M. Wondra, H. Su, and C. Zhai. Topic [33] X. Meng, F. Wei, X. Liu, M. Zhou, S. Li, and H. Wang. [34] A. Nenkova and K. McKeown. Automatic summarization. [35] J. Nichols, J. Mahmud, and C. Drews. Summarizing sporting [36] M. Paul and R. Girju. A two-dimensional topic-aspect model [37] M. J. Paul, C. Zhai, and R. Girju. Summarizing contrastive [38] D. Radev et al. MEAD X  X  platform for multidocument [39] L. Ren, D. B. Dunson, and L. Carin. The dynamic [40] Z. Ren, J. Ma, S. Wang, and Y. Liu. Summarizing web forum [41] Z. Ren, S. Liang, E. Meij, and M. de Rijke. Personalized [42] Z. Ren, M.-H. Peetz, S. Liang, W. van Dolen, and [43] C. Shen and T. Li. Learning to rank for query-focused [44] D. Shen, J. Sun, H. Li, Q. Yang, and Z. Chen. Document [45] L. Shou, Z. Wang, K. Chen, and G. Chen. Sumblr: [46] R. Socher et al. Recursive deep models for semantic [47] K. Toutanova, C. Brockett, M. Gamon, J. Jagarlamudi, [48] X. Wan and J. Yang. Multi-document summarization using [49] F. Wei, W. Li, Q. Lu, and Y. He. Query-sensitive mutual [50] Y. Zhu, Y. Lan, J. Guo, P. Du, and X. Cheng. A novel
