 The easily accessible Internet creates a p rofit-generating market place and con-venient shopping environment for many users. One example is the online auction Web sites such as ebay.com . Individual sellers place items for bidding in the auc-tion Web sites. Potential buyers can then start bidding the items by setting the prices that they are willing to pay. The item is then sold to the one with the highest bid at the end of the bidding period. Online auction Web sites are be-coming increasingly popular . According to the press release from ebay.com, they currently have 147 million community members and approximately 50 million items for sale at any given time 1 . Several reasons account for the popularity of the online auction business. One reason is that sellers do not need to set up and promote for their own Web sites for selling the items and hence reduce the cost. Another reason is that potential buyers can ask the price for the items depend-ing on their budgets and have a chance to successfully buy the items at a lower price if they can bid the right price at the right time.

Since online auction Web sites have a large number of sellers and potential buyers with tremendous number of items from different categories listed for bid-ding at any time, they are fast changing, highly dynamic, and complex systems. For example, a digital camera may recei ve a large number of bids ranging from few US dollars to few hundreds US dollars in just one or two days. The mutual influences of the items can be seen from the fact that an item being sold may be seriously affected if another similar item is placed for bidding with a lower bidding price. Therefore, acquiring the up-to-date and accurate information in the auction Web sites offers many potential benefits.

It is useful for both sellers and potential buyers to digest the huge amount of continuously changing information. For example, when a seller intends to place an item for bidding, he/she is required to set a start bidding price. Some sellers may set the start bidding price with their subjective expectations. This can easily result in either that the start bidding price is set too high and hence the chance of the item being sold may be very slim, or that the start bidding price is set too low and hence the retur n may decrease. Some other sellers may manually analyze the items currently listed for bidding and their prices before setting the start bidding price. However, this manual process for analyzing the vast amount of information is tedious. Besides the sellers, it is also beneficial for a potential buyer to obtain up-to-date, detailed, and accurate information to assist the decision. For example, before bidding for a particular item, the potential buyer may study the description of the item, and other similar items listed for bidding. After certain investigation, he/she can then decide on the amount of money for this bid. Due to the highly dynamic and fast changing nature of the online auction Web sites, rapid decision is essential. If the potential buyer spends too long time for analysis, he/she may either lose the opportunity for successfully buying the items, or need to pay a higher cost.

We develop a framework which can automatically extract and summarize the hot item features across diff erent auction Web sites to assist the sellers and the buyers in decision marking. One objective o f our framework is to characterize the popularity of an item listed for bidding. Intuitively, a hot item is the item which attracts many potential buyers for bidding. However, we should not measure the popularity of an item solely by its number of bids because of the following reasons. First, the number of bids on a hot item may be affected by the presence of another similar item listed with a lower price. Both of these items actually attract many buyers X  interest and should be considered as hot items. Second, from Auction Software Review, we know that about one-forth of the items re-ceive only one bid at the end of the auction period and potential buyers like to place the bid in the last minute [1]. Therefore, our approach for characterizing the popularity of the items is based on the product features of the items. For example, a possible product feature of a digital camera may be  X 4 megapixel resolution X . Our approach can automatically discover the product features from the descriptions provided by the sellers . However, the diversified format of the descriptions can range from regular format such as tables to unstructured free texts, making the extraction task difficult. For example, Figures 1 and 2 depict two Web pages collected from ebay.com. These two Web pages are about the auction of digital cameras. However, the descriptions provided by the sellers are very different in layout format.

Our framework is able to collaboratively discover and summarize the hot item features across different auction Web sites. We formulate the product fea-ture extraction task and hot item feature summarization task as a single graph labeling problem using conditional random fields (CRF) [2]. One characteristic of this graph is that it can model the relationship between the inter-dependence between the neighbouring tokens in the Web page, as well as the tokens in dif-ferent Web pages. As a result, Web pages collected from different Web sites can then be considered under a coherent model improving the extraction quality. This also leads to another characteristic that various information such as the hot item feature information can be easily integrated in the graphical structure. We have conducted extensive experiments on several real-world auction Web sites to demonstrate the eff ectiveness of our framework. Ghani and Simmons proposed a closely related work on end-price prediction from auction Web sites [3]. They predict the price of the items at the end of the bidding period using four different kinds of features. The first kind of features is related to the sellers such as the seller rating. The second kind of feature is related to auction such as the first bid price of the item. The third kind of feature is related to the item. This kind of features consists of the indicators of the occurrence of certain phrases such as  X  like new X  in the title. The last kind of feature is called temporal feature which i s obtained from the recent history of the same item. They compared different machine learning techniques such as neural network and decision tree for the end-price prediction based on these features. Our proposed framework is different from their work in several aspects. First, the objective of their approach is to predict end-price whereas our framework is to extract and summarize the hot item fe atures. Second, their approach assumes that each item placed for bidding is independent. However, as mentioned in Section 1, the items actually have a lot of mutual influences.

Hui and Liu [4] have investigated the t ask of summarizing customer reviews posted on the Web sites which is similar to sentiment classification [5]. Their objective is to classify sentences with su bjective orientation. They make use of opinion terms such as  X  X refect X ,  X  X ood X  as c lues and extract the frequent features of the product from the reviews. Popescu and Etzioi [6] also conducted similar research. They first made use of the extraction system called KnowItAll [7] to extract the explicit features of the produc t. Next the extracted explicit features are utilized to identify the opinion or orientation from the reviews. Both of these two methods apply linguistic techniques and focus on the sentences which are largely grammatical. In contrast, the proposed work in this paper is to discover the product features of the hot items from the descriptions provided by the sellers in the auction Web sites. Such descriptions can be vary largely in layout format ranging from rigid table to free texts. Our work is also different from the research work on text summarization [8] whose objective is to produce text summary from text documents.

For semi-structured documents such a s Web pages, different information ex-traction techniques have been proposed [9, 10]. Wrapper is a popular informa-tion extraction method and it usually consists of a set of extraction rules which can identify the attributes of interest from Web documents. Several machine learning methods have been developed for automatic wrapper generation by learning extraction models from training examples and achieve promising re-sults [11, 12, 13, 14]. All these methods suffer from one common shortcoming in that the learned wrapper can only extract the attributes specified in the training examples. For example, if we just annotate the start time, end time, location, and speaker in the training examples in the seminar announcement domain, the learned wrapper can only extract these f our attributes. Some other useful infor-mation such as the title of the seminar will not be extracted. In our previous work, we extended the traditional information extraction technique for discov-ering new attributes in Web pages [15]. It should be noted that our objective of hot item feature extraction and summarization is different from the objec-tive of ordinary information extraction since our goal is not only to extract the product features, but also to generate the summary for the hot items across different auction Web sites. Some techniques have also been developed for fully automatic information extraction from Web pages without using any training examples such as IEPAD [16], MDR [17], Roadrunner [18]. Both IEPAD and MDR assume that the input Web pages contain multiple records and make use of the repeated patterns for extraction. However, a Web page normally consists of one item for bidding in the auction sites. Roadrunner does not require the Web pages contain multiple records. However, the Web pages are required to have similar layout format and this is rare in auction Web sites.

Recently, various techniques have been proposed for collectively conducting information extraction and data mining [19]. For example, Wellner et al. pro-posed an approach for extracting different fields in citation and solving the ci-tation matching problem using conditional random fields [20]. McCallum and Wellner also proposed an approach to extracting proper nouns and linking the extracted proper nouns using a single model [21]. Bunescu and Mooney pro-posed to use relational Markov networks to collectively extract information from documents [22]. 3.1 Model Formulation In CRF, each node in the graph represents a variable and each edge represents the inter-dependence between the connected variables. Suppose we collect a set of Web pages from the auction Web sites and we wish to discover the hot item features. Figure 3 shows a simplified CR F model automatically constructed for the hot item feature mining application. The size of the graph is much larger when dealing with real data. There are two kinds of nodes. The shaded nodes represent observable variables while the unshaded nodes represent unobservable variables. Suppose we have a collection of Web pages P . As mentioned above, a Web page, M  X  P , can be regarded as a set of text fragments denoted by S M and each text fragment is considered as a sequence of tokens. For a particular sequence A  X  S M , each token is actually composed of two kinds of information. The first kind of information is the observation of the tokens such as the content characteristics or the context character istics. This information can be observed and is represented by the observable variable X A . The second kind of information is the labeling information of the token. In product feature extraction, each token is labeled with either product feature or normal text . This information is hidden and is represented by the unobservable variable Y A .Noticethat X A and Y
A actually represent a sequence of variables X A 0 &lt;i&lt;L and L denotes the number of the tokens in the sequence A .A node denoted by W A represents the identified pro duct features in the sequence A .Each Y A i is connected to Y A i  X  1 , Y A i +1 , X A ,and W A as shown in Figure 3 since the tag label of each token is inter-dependent with the tag labels of the neighbouring tokens, the observation of the sequence, and the product features. There is another unobservable node called Z A which refers to the hot item feature found in the sequence. An observable variable denoted by  X  M in Figure 3 represents the number of bids of the item listed in page M . In page M , Z A is connected with W A and X A because a hot item feature is related to the observation and the product feature found in the sequence. Z A is also connected to  X  M because a hot item feature is inter-dependent with the number of bids of the item listed in page M . For example, it is likely that the product feature is a hot item feature if the item receives h igh number of bids from the potential buyers. In Figure 3, the sequence B, C  X  S N are collected from the same page N  X  P and N = M . As mentioned in Section 1, a hot item is not only related to its number of bids, but also related to other items listed for bidding. Therefore, X
B and Z B ,aswellas X C and Z C in page N are also connected to the Z A in page M .

Once the undirected graph is constructed, the conditional probability of a par-ticular configuration of the hidden variables, given the values of all the observed variables can be written as follows: where x and y are the set of observable variables and the set of unobservable variables respectively, C ( x, y ) refers to the set of cliques of the graph. A clique is defined as the maximal complete subgraph.  X  ( C ( x, y )) refers to the clique potential for C ( x, y ). Z is called the partition function defined as: We define the clique potential as a linear exponential function as follows: where f i ( x, y )and  X  i are the i -th binary feature and the associated weight respec-tively. For example, f i ( x, y ) equals to one if the underlying token is  X  X esolution X  and the tag label is product feature and equals to zero otherwise in the digital camera domain. Hence, Equation 1 can be written as follows: Given the set of  X  i , one can find the optimal labeling of the unobserved variables of the graph via conducting inference. The graph typically consists of a large number of combination for the labels of a ll the unobservable variables. Hence, direct computation of the probability of a particular labeling of the unobservable variables is infeasible. The inference can be carried out by the message passing algorithm, also known as the sum-product algorithm, by transforming the graph into junction tree or factor graph [23]. By finding the configuration of the hidden variables achieving the highest conditional probability stated in Equation 1, the hot item features can then be discovered from these Web pages. 3.2 Adaptive Training of CRF Learning in CRF refers to estimating the value of the weights  X  i associated with each f i in Equation 4. Suppose we have a set of training examples denoted by Tra for which the actual labels of the variables are known. We define the log likelihood function as follows: where | Tra | and ( x ( j ) ,y ( j ) ) denotes the number of training examples and the j -th training example respectively. Maximum likelihood approach aims at finding the set of  X  i which maximize Equation 5. It can be shown that Equation 5 is convex and achieves maximum when the following condition holds:
Therefore, one can obtain the set of  X  i achieving the maximum of Equation 5 by using iterative methods such as conjugate gradient methods or voted percep-tron algorithm [24]. In particular, Figure 4 shows the outline of voted perceptron algorithm for learning the parameters. In essence, the voted perceptron algorithm estimates the weight by iteratively minimizing the following expression: where  X  y ( j ) is the predicted labeling using the current weighting.
However, recall that one objective of o ur framework is to extract the previ-ously unseen product feature contained in the Web pages. To achieve this, we exploit the clue embodied in the context characteristic such as the layout for-mat of the extracted data. However, th e extracted data ca nnot be directly used because they involve uncertainty. To tac kle this problem, we treat the extracted data as unlabeled data and develop an ex pectation-maximi zation (EM) based voted perceptron algorithm as shown in Figure 5. In the E-step of our algorithm, we estimate the probability of the labeling of the unobservable variables. In the M-step, we employ the voted perceptron algorithm augmented with the following weight updating function:
Compared with the algorithm stated in Figure 4, our EM based voted per-ceptron algorithm estimates the weight by iteratively diminishing the following expression: expectation value of f i ( x ( j ) ,y ) and it approaches to the first term of Equation 7 We conducted experiments on three real-world auction Web sites in the digital camera domain to demonstrate the effect iveness of our framework. The three auction Web sites are www.ebay.com , auctions.yahoo.com ,and www.ubid.com . We collected 50 Web pages from each of the auction sites for the evaluation. Each Web page contains an item listed for bidding and the remaining bidding time is less than an hour. We conducted two sets of experiments to evaluate our approach to product feature extraction and hot item feature summarization.
We manually annotated the product features in the Web pages. These anno-tated product features were served as the gold standard in our evaluation. We randomly chose 5 pages from each of the Web sites (a total of 15 Web pages) to produce the set of training examples to train our model as described in Sec-tion 3.2. The trained model is then applied to the remaining Web pages to extract the product features of the items. Recal l(R) , precision(P) ,and F-measure(F) are adopted as the evaluation metrics. Recall is defined as the number of items for which the system correctly identified div ided by the total number of actual items. Precision is defined as the number of item s for which the system correctly iden-tified divided by the total number of item s it extracts. F-measure is defined as 2 PR/ ( P + R ). Table 1 depicts the extraction performance of our approach. Our approach achieves about 81% and 75% for average precision and recall respec-tively. This shows that our approach can effectively leverage the content and context characteris tics to extract the product features.

Next, we employ our framework to generate the summary of the hot item features. To increase comprehensibility, we generate the summary by outputting the text fragments containing the hot it em features instead of individual token. Table 2 shows some text fragments extracted. We manually investigate the items listed for bidding in the auction Web sites and find that over 70% of the items receiving at least one bid from the potent ial buyers contain at least three of the reported product features mentioned in the summary. This demonstrates that the summary generated is very helpful for the auction Web site participants. We have developed a unified framework which is able to extract and summarize the hot item features across different auction Web sites. Our system can assist sellers and potential buyers in making decision. One challenge of this problem is to extract information from the product descriptions provided by different sellers, which vary largely in the layout format. We formulate the problem as a single graph labeling problem employing conditional random fields. The solution is then obtained by conducting inference in the graph. One characteristic of our framework is to extract the previously unseen product features by making use of the clue embodied in the layout format of the extracted data. We have designed an EM based voted perceptron algorithm to handle the uncertainty involved. Extensive experiments from sev eral real-world auction Web sites have been conducted to demonstrate the effectiveness of our framework.

