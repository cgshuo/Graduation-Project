 One of the most challenging recommendation tasks is recom-mending to a new, previously unseen user. This is known as the user cold start problem. Assuming certain features or attributes of users are known, one approach for handling new users is to initially model them based on their features.
Motivated by an ad targeting application, this paper de-scribes an extreme online recommendation setting where the cold start problem is perpetual. Every user is encountered by the system just once, receives a recommendation, and either consumes or ignores it, registering a binary reward. We introduce One-pass Factorization of Feature Sets, OFF-Set , a novel recommendation algorithm based on Latent Fac-tor analysis, which models users by mapping their features to a latent space. OFF-Set is able to model non-linear in-teractions between pairs of features, and updates its model per each recommendation-reward observation in a pure on-line fashion. We evaluate OFF-Set against several state of the art baselines, and demonstrate its superiority on real ad-targeting data.
 H.4 [ Information Systems Applications ]: Miscellaneous; D.2.8 [ Software Engineering ]: Metrics X  complexity mea-sures, performance measures Algorithms, Experimentation Dynamic Ad Optimization, Matrix Factorization, Collabo-rative Filtering, Persistent cold start problem
In recent years, Collaborative Filtering (CF) based recom-mender systems have gained both commercial success and increased focus from the research community. Generally speaking, CF discovers and exploits recurring consumption patterns of items by users, at scale, in order to recommend items to users. Studied consumption types include ratings of items by users, which explicitly articulate users X  likings and dislikings of items; binary indication of users X  consump-tion of items, without explicit evidence regarding the users X  opinions on their consumed items; richer implicit interac-tion settings where users, while still not explicitly providing ratings on items, can perform multiple operations on items (e.g. click or comment on news stories), etc.

In order to provide high-quality recommendations of items to a user, recommender systems must observe some past ac-tivity of the user. When new users first arrive to a system, no previous activity is available and they are said to be  X  X old X ; recommending to such users is challenging, and has been coined the  X  X ser cold-start problem X  [12, 6, 8].

Motivated by an online ad targeting application (Section 3), this paper addresses an extreme online recommendation set-ting where the cold start problem is perpetual -practically every user encountered by the system is seen just once, i.e. every recommendation request is for a previously un-seen user. Nevertheless, certain attributes of the users are known, and those are leveraged for recommendation. For ev-ery recommendation made, a binary indication (i.e. reward) is observed. The goal is to maximize the reward.
 We introduce One-pass Factorization of Feature Sets -OFF-Set  X  a novel recommendation algorithm based on la-tent factor analysis [7], which models both users and items by mapping their features to a latent space. OFF-Set of-fers a non-linear solution by designing a latent space that models individual as well as pairwise combinations of fea-tures. OFF-Set is formulated for purely online recommen-dation, performing lightweight updates of its model per each recommendation-reward observation. We evaluate OFF-Set against several state of the art baselines, and demon-strate its advantage on real ad-targeting data.
The ever-growing demand for automated recommenda-tions at scale has prompted the development of a variety of recommendation techniques. Collaborative Filtering (CF) algorithms are often the alternative of choice, among which, the matrix factorization (MF) [7] technique is successful and popular [3, 2]. In its most basic form, MF associates each user and each item with a latent factor (vector). The match score between a user and an item is represented as an inner product between the corresponding vectors.
Although collaborative filtering algorithms have been gain-i ng great success in recent years, they are often challenged by the well-known user cold-start problem [6]  X  namely, mak-ing recommendations to previously unobserved users. In oder to overcome this problem at scale, reference to user features is often done. One such approach is factorization machines (FM), first presented by Rendle [9, 10]. FM is known for its capability to model sparse feature spaces. It is a combination of support vector machines (SVM) [4] and matrix factorization, and it closely fits our problem specifi-cation. FM was shown to be superior to other approaches, including  X  X egular X  matrix factorization [11].

Outside of collaborative filtering there may be found other solutions for feature-based prediction modeling to offer a dif-ferent approach to the cold-start and sparsity issues. The gradient-boosted decision trees (GBDT) algorithm [5] is one such approach. In contrast with linear methods, GBDT models the scoring process as an aggregation over an ensem-ble of decision trees. GBDT has been shown to be successful in non-latent feature spaces, including those with interdep-dendent features.

Both FM and GBDT are not designed to work in an online setting, as they require several passes over the data in order to converge. In this sense they differ from our approach, as OFF-Set is completely online  X  i.e., every input element is processed exactly once and the ensuing update of the model is lightweight.
Dynamic advertising campaigns are a relatively new form of digital display advertising, where the advertiser offers multiple products or multiple ad creative alternatives (re-ferred to as  X  X d variants X ) to be presented to users. Un-like traditional display advertising settings, where the ad exchange assigns a specific ad to every user impression, in dynamic campaigns the exchange designates a campaign to the impression. It is up to a follow-up process -a selection algorithm -to determine which variant, i.e. which specific ad instance, to actually serve to the user. That decision is based upon data (context) provided to the selection al-gorithm, e.g. properties about the user, the page content surrounding the ad slot, the time of day, etc. In this work we assume only basic demographic information about the users (age, gender, geographic location) is known.
A typical optimization task in dynamic campaigns is to maximize the campaign X  X  click-through rate (CTR), i.e. the CTR over all user impressions which were served by some ad variant of the campaign. We formulate dynamic ad cam-paign optimization as a recommendation task which attempts to assign, to each user impression, the variant that a user is most likely to click on.

Display ads, as opposed to content (e.g. articles, search results) and other digital advertising types (e.g. sponsored search) are characterized by very low CTR. In addition, many campaigns target (i.e. compete over) the same set of users, resulting in most users being exposed to a campaign no more than once. These two factors lead to an extremely sparse user signal -most users do not register a single click in most campaigns -and impose a great challenge to any recommendation algorithm. Our problem is about recommending items, in our case ad Figure 1: Example of Dynamic Ad Campaign (for Y ahoo! Shopping) variants A = { a 1 , a 2 , . . . , a L } , to users U = { u Each user u i is associated with a set of feature values [ u for feature k (e.g., one feature can be  X  X ender X , where the set of available values is  X  X ale X ,  X  X emale X  and  X  X nknown X ). We now define C as the set of (user, ad variant) pairs that re-sulted in a click Similarly, we denote by NC the set of (user, ad variant) pairs that did not result in a click. Finally, let N = C
Dynamic ad selection is yet another ranking problem. Given a new user entering the system, we aim at selecting the best possible ad variant that will maximize the probability of a click, thus maximizing the CTR of the overall campaign. Like in many other ranking problems, we chose to use a la-tent factors approach, where each ad variant and each user are represented by a latent vector, v a j  X  R D and v u i respectively. The score of the match for a pair ( u i , a defined by the inner product of the two corresponding vec-tors, S ( u i , a j ) = v u i , v a j = v T u products represent better match, or a higher probability of a click. Hence, given a user, the OFF-Set algorithm suggests the ad variant that results in the highest matching score, in order to maximize the CTR of the campaign. As previously mentioned, the user vector is not directly trained by the al-gorithm, but rather the feature vectors that construct it, as will be detailed in section 6.
We define the target function for maximization following the approach suggested by Aizenberg et al. [2]. Given the training data described above, that includes | C | click inter-actions, we define a multinomial distribution for a click over all our (user, ad variant) pairs as follows: where P C ( u i , a j ) is the probability of a click for the ( u pair, and S ( u i , a j ) is the score our model assigns this pair. Note that this is a general definition of probability that sat-isfies all i and j , 0 &lt; P C ( u i , a j )  X  1 under the constraint that | S ( u i , a j ) |  X   X  , for  X  = 0 . 5 ln | N | | C | 1 .
O ur model X  X  parameters (denoted hereafter by  X ) are now trained in order to maximize the mutual probability of the pairs that actually resulted in a click (assuming indepen-dence between all pairs). Using the log likelihood approach,
A s the score value is not important by itself, but rather the ranking it derives, scores can always be normalized in order to satisfy this constraint. Therefore, from now on, we will not refer to this constraint. we get 2 We extract  X  using a stochastic gradient ascent method. The derivative of the above target function depends on whether the (user, ad variant) pair resulted in a click or not. When-ever ( u i , a j )  X  C , we get: And when ( u i , a j )  X  NC we get
It is clear that a positive reward (a click) will always re-sult in an increase in the value of S ( u i , a j ), and vice versa. However, the increase and decrease step sizes are not equal.
If we begin the training process with random variables, as-suming equal probability of a click to all pairs (which equals | N | ) , we get that the ratio (denoted by  X  ) between the step sizes of a negative and a positive rewards is  X  =  X  | C | T his implies that for any positive reward we should apply a gradient ascent step that will increase S ( u i , a j ) in some learning step  X  , while for any negative reward, we apply a gradient ascent step of size  X   X   X  , that will decrease S ( u
Throughout the training process, assuming the model suc-ceeds in representing the user preferences by representing the real probabilities, the step sizes should be decreased in both directions, and dependent on the specific pair. For sim-plicity reasons, we keep  X  as the ratio between the update steps, and update its value throughout the training process, as detailed in Section 5.3.
Up until now we have referred to the training data as a fixed and known set of examples. This, however, does not hold in the real world settings we operate in. The amount of data pairs and the rate in which they are produced are high. On the one hand, the data sparsity issue requires gathering many samples for training. On the other hand, as a single campaign may run for only a few hours, the training must be done with minimal latency. Considering these constraints together, an on-line training scheme is required. In such a solution, each sample updates the model X  X  parameters only once (either positively, or negatively, according to the re-ward). Furthermore, the update depends only on this single sample, with no reliance on previous data samples. The only accumulative value we aggregate from the collection of data samples is the updated  X  factor, the ratio between the step sizes of updates stemming from positive and negative rewards.
We now turn to describe the separate latent vector repre-sentations that map the ad variants and users into the same
A more comprehensive technical description was omitted, and can be found at[1] Figure 2: Example of a user latent factor construc-t ion from its feature value vectors ( K = 3 ). In this example, D = 18 , d = 10 , s = 2 and o = 4 . The middle illustration presents the auxiliary vectors e v k u latent space. For ad variants which are repeating and sta-ble along the campaign, we simply assign one D -dimensional latent factor per ad variant (item) a j , v a j  X  R D .
We offer a novel construction of the latent representation on the user side. Recall that we assume that users are en-countered once, and so are perpetually cold. Hence, they must be modeled by their features. Previous works in matrix factorization assigned a latent vector to each feature value, and modeled users (or items) as a linear combination of their features X  vectors [2].While this approach can handle sparse user data, it cannot capture any dependencies between the features as the combination between the features is linear. Instead, we construct a more complex latent space over user features, that allows the representation of strong dependen-cies between each pair of features. Recall that items were mapped into R D , and assume that each user has some val-ues across K features. We select an overlap dimension o and a standalone dimension s such that D = Ks + K 2 o . Each feature value is assigned a d -dimensional vector where d = s + ( K  X  1) o , so that v k u i  X  R d is the vector assigned to the k th feature value of user u i . That vector has s entries that are attributed only to the specific feature, and K  X  1 blocks of o entries that are in overlap with each of the K  X  1 other features 3 .

We now compose v u i  X  R D from K 2 chunks of size o , each holding the products of the values from a pair of feature vectors. The rest of v u i holds the Ks standalone values from each of the feature vectors. The process is illustrated in Figure 2. Now, let e v j u so that the values of v j u according to their indices and the rest of the entries are set to 1 (see middle part of Figure 2). Using this formulation, v
We evaluate OFF-Set against two state-of-the-art meth-ods mentioned in Section 2 as well as a simple  X  X opularity X  algorithm. We use three baselines throughout our exper-iments: the Factorization Machines (FM) [9, 10] (which is given pairs of features, that allows it to represent depen-dencies between them), Gradient-Boosted Decision Trees
F or simplicity, we assume each feature merits s unique en-tries and every pair of features merits an overlap of o entries. Non-uniform assignments of entries are possible and have no effect on the rest of the algorithm.
Campaign clicks in clicks in number of A 100 2400 14 B 100 900 22 Table 1: Real-life campaign statistics. Significance w as computed from Hoeffding X  X  formula with confi-dence of 95% . (GBDT) [5] and a global-popularity based algorithm (Popu-larity), which also follows the trend of the data, by applying a decay factor to the CTR values of all variants 4
The evaluation metric we used was Mean Reciprocal Rank (mrr), applied only on positive observation ( C ). Formally, for algorithm A , where the function r u i A ( a j ) is the rank of the ad variant a in algorithm A  X  X  computed ranked list for user u i (1 for the first location). Under the assumption that the presented ad variants appear uniformly at random in the test data (and independently of the user), this metric quantifies well the ability of an algorithm to predict a click.

For evaluation on real data we chose two different dynamic campaigns, henceforth referred to as Campaign A and Cam-paign B. In order to simulate an on-line setting, the test (on both campaigns) was performed as follows. First, some ini-tial number of observations is used for warm-up training. Subsequently, all remaining observations are iterated over, sorted by time of appearance. Observations that did not result in a click are used for further training. Any obser-vation that resulted in a click is first used for evaluation, by requesting each algorithm to rank the available items for the given user. Afterward, the observation (along with its positive reward) is added as an additional training ex-ample. Table 1 provides some statistics on both campaigns, including the number of clicks contained in the warm-up and online test phases described above. Due to business sensitiv-ity, we cannot disclose the exact number of non-clicks in the data. Rather, we roughly disclose that in both campaigns, the number of non-clicks was 2-3 orders of magnitude larger than the number of clicks.

For OFF-Set, being a single pass algorithm, the procedure above is straightforward. FM and GBDT, however, must be retrained from scratch once encountering a click in the online portion of the test 5 .

The results are presented in Table 2. We can see a clear and significant advantage to OFF-Set as compared to the baselines (see Table 1 for the significant gap values for each campaign). In addition, its efficiency, being a single pass method, along with its low memory footprint, establish its superiority over the other methods for this problem.
In this work we introduced OFF-Set -an online single-pass algorithm that handles a perpetual user cold start problem.
A more detailed evaluation section is given in[1]
Since MRR is only measured on clicks, there is no need to retrain these models, for the purposes of the experiment, on each non-click.
 Table 2: MRR results on real (offline) data. MRR d ifferences higher than 0 . 055 and 0 . 091 for campaigns A and B respectively are significant (with 95% con-fidence).
 OFF-Set is based on Matrix Factorization, and is motivated by a log-likelihood approach. It exploits repeating user fea-tures and captures pairwise feature dependencies. We eval-uated OFF-Set on real-life data, and demonstrated its su-periority over state-of-the-art methods. [1] M. Aharon, N. Aizenberg, E. Bortnikov, R. Lempel, [2] N. Aizenberg, Y. Koren, and O. Somekh. Build your [3] K. Barman and O. Dabeer. Analysis of a collaborative [4] N. Cristianini and J. Shawe-Taylor. An Introduction to [5] J. H. Friedman. Greedy function approximation: A [6] Z. Gantner, L. Drumond, C. Freudenthaler, S. Rendle, [7] Y. Koren, R. Bell, and C. Volinsky. Matrix [8] S. Park and W. Chu. Pairwise preference regression [9] S. Rendle. Factorization machines. Proceedings of the [10] S. Rendle. Social network and clickthrough prediction [11] S. Rendle. Factorization machines with libfm. ACM [12] K. Zhou, S. Yang, and H. Zha. Functional matrix
