 Biological databases contain a wide variety of data types, often with rich relational structure. Consequen tly multi-relational data mining techniques frequen tly are applied to biological data. This paper presen ts several applications of multi-relational data mining to biological data, taking care to cover a broad range of multi-relational data mining tech-niques. Biological databases contain a wide variety of data. Con-sider storing in a database the operational details of a single-cell organism. At minim um one would need to encode the following. In fact, such a database exists for part of what is known of the widely-studied model organism E. coli |EcoCyc [28]. This database contains other information as well besides the items listed above, such as operons (see Section 6). Recording the diversity of data in the previous paragraph obviously requires a rich relational schema with multiple, in-teracting relational tables. In fact, even recording one type of data, such as metab olic pathways, requires multiple re-lational tables because of the graphical nature of pathways. And biological data can grow much more involved still. For example, when we move to multi-cellular organisms we need to include cell signaling and other aspects of one cell's inter-action with other cells. Furthermore, because at presen t we do not have complete knowledge of the workings of any or-ganism, biological databases often encode a variety of types of laboratory data that provide further insigh t into organism behavior. This may include data from the following high-throughput techniques: It is possible to gain insigh ts from using any one of the data types describ ed so far by itself. For example, standard ma-chine learning and data mining algorithms have been applied to gene expression microarra y data for a variety of purp oses, as surveyed by Molla et al. [37]. Nevertheless, researc hers in both data mining and biology are realizing that, often, stronger results can be obtained by using many of these data types together. Mining a database that contains several, or all, of these data types necessarily requires multi-relational techniques, either to analyze the data directly or to convert it into a single table in a useful way. The last two KDD Cup comp etitions have focused on biological databases and, not coinciden tally, have highligh ted the need for multi-relational data mining tools [9; 11].
 The data types discussed so far, though many and diverse, only scratc h the surface for biological databases. As re-searc hers attempt to modulate the behavior of biological processes, for example through developmen t of novel phar-maceuticals, still more types of data arise. Each year mil-lions of comp ounds (molecules) are tested in vitro (in the \test tube") and in vivo (in organisms) to see if they will bind to a target protein or have a desired biological e X ect. Even if a molecule has a desired e X ect, such as killing a harmful bacterium, it may be useless as a drug because it may be toxic to humans, it may break down too quickly or too slowly within the human body, it may not di X use from the gut to the bloodstream (so it has to be taken by injection|unacceptable for some target activities), or it may not cross the blood-brain barrier (unacceptable, for example, for an anti-depressan t or migraine medication). Therefore, molecules also are tested for these other factors, giving rise to volumes of diverse data within pharmaceuti-cal companies and university laboratories. Furthermore, the three-dimensional structures of molecules and target pro-teins, where known or estimated, are importan t items of information that require multiple relational tables to fully represen t.
 Both the amoun t and diversity of biological data will con-tinue to grow rapidly because of a coming paradigm shift in biology , toward systems biology . As Hood and Galas (2003) note, whereas in the past biologists could study a \complex system only one gene or one protein at a time," the \systems approac h permits the study of all elemen ts in a system in re-sponse to genetic (digital) or environmen tal perturbations." Hood and Galas go on to state: In addition to data describing our curren t knowledge of or-ganisms, novel types of high-throughput data, and data that arises from our attempts to alter organism behavior, an-other major type of biological data is semi-structured or text data. For example, the medline database [41] indexes more than 11 million articles in the biomedical literature, and contains abstracts and pointers to electronic versions for many of these articles. As another example, one of the web sites used most widely by biologists is GeneCards [46], which presen ts, for each human gene, information mined from biological text. Text data also has been integrated into the process of mining other types of data such as gene expression microarra y data [53; 36].
 Discussing in detail the variety of data types in biological databases is beyond the scope of any single paper. The goal of the presen t paper is to look more closely at a few examples of multi-relational data mining applied to biological data. The paper seeks to presen t a diversity of data types and of approac hes, not focusing on any one particular metho d for multi-relational data mining. Before focusing on a small number of biological applications of multi-relational data mining with which we are most fa-miliar, we  X rst presen t an overview of a variety of such ap-plications. The earliest such work involved the application of inductiv e logic programming (ILP) to molecular data. Molecular data is a natural application for multi-relational data mining because no metho d has been found for repre-senting molecules in ordinary feature-v ector form without some loss of information.
 In the  X rst successful application of ILP to molecular data [29], the golem program [39] was used to model the structure-activit y relationships of trimethoprim analogues binding to dihydrofolate reductase. 1 The training data consisted of 44 trimethoprim analogues and their observ ed inhibition of E. 1 In structure-activit y prediction, the task is to train a model Figure 1: The family of analogues in the  X rst ILP study . A) Template of 2,4-diamino-5(substituted-b enzyl)p yrimidines: R3, R4, and R5 are the three possible substitution positions. B) Example comp ound: R 3  X  X  Cl ; R 4  X  X  N H 2 ; R 5  X  X  CH coli dihydrofolate reductase. Eleven additional comp ounds were used as unseen test data. golem obtained rules that were statistically more accurate on the training data and on the test data than a previously published linear regres-sion model. It was possible to run linear regression on this set because the molecules shared a common structure. Fig-ure 1 shows the shared structure, or template, for all the molecules, as well as one particular instance of the template. Following shortly after this work [30] the two-dimensional atom-and-b ond molecular descriptions of 229 aromatic and heteroaromatic nitro comp ounds [15] were given to the ILP system progol [38]. Such comp ounds frequen tly are muta-genic. The study was con X ned to the problem of obtaining structural descriptions that discriminate molecules with pos-itive mutagenicit y from those which have zero or negativ e mutagenicit y. A set of eight optimally compact rules were automatically disco vered by progol . These rules suggested three previously unkno wn features leading to mutagenicit y. Attempts to force the multi-relational represen tation of the atom-and-b ond structures into feature vectors resulted in the generation of examples containing millions of features each. Hence, unlik e in the earlier molecular application, a claim can be made that this application truly needed multi-relational data mining. The mutagenicit y data set remains a widely-used testb ed for multi-relational learning algorithms. A number of interesting lines of researc h were motiv ated by this work on mutagenicit y. First, this work led to a com-petition called the Predictiv e Toxicology Challenge 2000-2001 [22], in which both ordinary and multi-relational data mining tools were applied to the task of predicting rodent to accurately predict which molecules have a particular bi-ological activit y (or to predict their degrees of the activit y) from molecular structure. Details of the speci X c biological activities discussed in this section are beyond the scope of the paper. carcinogenicit y for 185 comp ounds slated to be tested in mice and rats. Further details and results can be found in the special issue of Bioinformatics (Vol. 19, No. 10) de-voted to the challenge. Another line of researc h motiv ated by the previous work is pharmac ophor e discovery . This task requires data mining systems to move from the two-dimensional atom-and-b ond represen tation of a molecule to a three-dimensional represen tation. Because a molecule may have multiple three-dimensional shap es, or conformers , this line of researc h has interesting links with multiple instance learning and is describ ed in more detail in the next sec-tion. In another line of work, the Apriori-lik e ILP system WARMR was used to  X nd all the molecular substructures (in the two-dimensional atom-and-b ond structures) that appear with at least some minim um frequency in a set of molecules [16]. That work, which won a KDD Best Applied Paper Award, in turn motiv ated work on a molecular feature miner system, Molfea [32]. It also motiv ated work on Apriori-lik e algorithms for  X nding commonly-o ccurring subgraphs in a set of graphs [25; 57]. This is an exciting line of researc h that requires scaling Apriori's notion of frequen t itemsets to apply to graphs, but doing so in such a way that the compu-tational demands do not become overwhelming. One other piece of work in the area of mining molecular data was work on predicting the biodegradabilit y of various comp ounds us-ing ILP [18].
 Another early application of multi-relational data mining was to protein secondary structure prediction [40]. We will not discuss this application because secondary structure pre-diction, while di X cult, has proven amenable to feature-based approac hes, such as neural networks as emplo yed in the PHD system [50]. Nevertheless, protein tertiary structure, or three-dimensional topology , involves a variety of relation-ships among the portions of a protein and hence appears to demand the power of multi-relational data mining. Pro-teins are categorized into di X eren t \fold types," or classes of three-dimensional structure. One notable application in this area is the use of ILP to classify proteins into di X eren t fold types [56].
 Perhaps the most exciting new direction for biological appli-cations of multi-relational data mining is in the construction of biological pathways from data. Section 4 goes into some detail about such an application of probabilistic relational models (PRMs), a multi-relational form of Bayesian net-works. Other multi-relational techniques that have been applied to this task include graph learning [10] and ILP [5; 47]. One interesting twist in the application of ILP is the automatic prop osal and execution of experimen ts. In this project, dubb ed the \Rob ot Scien tist Project," the ILP system starts with a partial pathway model for biosyn the-sis of aromatic amino acids in yeast, expressed in logic. The system then form ulates experimen ts that will provide it with information enabling it to complete its model, and a robot carries out the experimen ts. All experimen ts are auxotrophic growth experimen ts. In other words, they test whether some given yeast \kno ck-out"|y east with one gene e X ectiv ely remo ved|will grow on some particular medium, that is, in the presence of a certain set of nutrien ts. As the system obtains experimen tal results, it re X nes its model and, if necessary , performs further experimen ts.
 Having presen ted an overview of biological applications of multi-relational data mining, we now turn to an more in-depth treatmen t of a small set of such applications. This more in-depth treatmen t will permit us to better discuss lessons and challenges for such applications. Motiv ated by the success of multi-relational data mining techniques to handle two-dimensional atom-and-b ond molec-ular structure data, researc hers in the pharmaceutical indus-try began to inquire whether these tools could be used to handle three-dimensional molecular structures. Such struc-tures are of particular interest because the abilit y of a drug molecule to bind to its target protein typically is depen-dent on the abilit y of the drug molecule to  X t into a pocket in the target protein and establish interactions based on charges or other prop erties of atoms. The 3D substructure of a molecule that interacts with the target is called a phar-macophor e ; identifying a pharmacophore can be an impor-tant step in the design of new drug molecules. For example, the following is a potential pharmacophore for ACE inhi-bition (a form of hypertension medication), where the spa-tial relationships are describ ed through pairwise distances in units of Angstroms. 2 This pharmacophore was learned by an ILP system in an initial study applying multi-relational data mining to three-dimensional molecular structures. Fig-ures 2 and 3 show two di X eren t ACE inhibitors with the parts of pharmacophore highligh ted and labeled. The same ILP approac h has been applied successfully to other related tasks and has been extended to predict activit y levels [34]. Figure 4 illustrates how biomolecular activit y and three-dimensional structure migh t be represen ted in a relational database. Attempts to represen t the atom-and-b ond struc-ture and multiple conformations (three-dimensional shap es) of a molecule in a single  X le lead to loss of information for the data mining task. Even performing a natural join on the tables in Figure 4, while resulting in a single table, will not leave the features of the molecules aligned in a way that will permit standard feature-based algorithms to learn a phar-macophore. Correctly aligning the features resulting from the natural join would require almost complete knowledge of the target concept, or true pharmacophore.
 Notice furthermore how the ILP-learned rule naturally ad-dresses the multiple-instance problem [17]. While molecules (examples) are labeled as activ e or not, they obtain their ac-tivity through one or more of their conformers (instances). The rule labels a molecule A as activ e just if it has some conformer Conf that satis X es the rule. 2 Hydrogen acceptors are atoms with a weak negativ e charge. Ordinarily , zinc-binding would be irrelev ant; it is relev ant here because ACE is one of several proteins in the body that typically contains an associated zinc ion. This is an auto-matically generated translation of an ILP-generated clause. Figure 2: ACE inhibitor number 1 with highligh ted 4-point pharmacophore.
 Before closing this section, several areas of related work should be mentioned. First, the pharmaceutical industry has developed a variety of creativ e ways to encode molecules into features vectors so that, even though some importan t information is lost, feature-based techniques can be applied from statistics, machine learning and data-mining. One ex-ample of such an encoding is the one used for Task 1 of KDD Cup 2001, predicting binding to throm bin [9]. Another ex-ample is the feature-generation stage of the comp ass algo-rithm [26; 27].
 One may conclude based on the preceding paragraph that multi-relational data mining algorithms are not always re-quired in order to mine a multi-relational database. We take a broader view, that multi-relational techniques still are be-ing emplo yed in order to convert the task to a feature-based task. These multi-relational techniques may be domain-speci X c, as in the case of carefully-engineered feature-genera-tion algorithms for molecular data, or they may be general-purp ose. One example of a general-purp ose algorithm is the ILP system rela ggs , which was used to win Task 2 of KDD Cup 2001 [9]. rela ggs was used to convert a multi-relational databases containing information about genes, gene expression, proteins, and protein-protein interactions into a single table. From this table, a model was learned using the supp ort vector machine package SVM-ligh t (svmligh t.joa-chims.org) to predict protein function. Another general-purp ose approac h that has been emplo yed to convert a multi-relational data set into a single table is the use of ILP to learn rules for a task, such as predicting mutagenicit y; these ILP-learned rules are then used as features in order to pro-duce a feature vector [55]. An example has a value of one for a given binary feature if and only if the ILP rule that corresp onds to that feature applies to the example. Figure 3: ACE inhibitor number 2 with highligh ted 4-point pharmacophore.
 Stern berg [56] using ILP to learn rules to predict the three-dimensional structural classes of proteins. As noted in the introduction, systems biology seeks to in-tegrate data from a variety of related sources in order to construct whole-system models. One exciting example of multi-relational data mining in systems biology is the work of Segal et al. [52] in applying probabilistic relational mod-els (PRMs) to induce gene regulatory networks from both sequence data and gene expression microarra y data. Gene expression refers to the two-step process through which a gene is transcrib ed into mRNA, and that mRNA is trans-lated into protein. Gene expression microarra ys measure Figure 4: Sample three-dimensional molecular database. Gene Figure 5: The PRM emplo yed by Segal and colleagues. The Expression table records the measured mRNA level for each given h Gene ; Experiment i pair. The Phase  X eld of the Ex-periment table gives the experimen tal condition, while the ACluster  X eld assigns experimen ts to clusters of similar ex-perimen ts. The Gene relational table is simpli X ed in the drawing; it actually contains nine nodes of the form R ( t and nine nodes of the form L ( t i ), corresp onding to nine known transcription factors. R ( t i ) tells whether transcrip-tion factor t i actually can bind to a site just upstream of the given gene. L ( t i ) is a (noisy) measuremen t of whether such binding occurs. The S j  X elds specify the bases in the DNA sequence upstream of the given gene; showing only three such  X elds is another simpli X cation. In the database, the actual values for the R ( t i ) and ACluster  X elds are not known; these are missing values, for which the learning al-gorithm will provide a prediction metho d. the  X rst part of this process, because mRNA levels are eas-ier to measure than protein levels. In using microarra y data, there often is a tacit assumption that transcription is a good surrogate for expression.
 When the expression of one gene goes up, that gene's prod-uct (protein or mRNA) can in X  X ence the expression of other genes, or of that gene itself in a feedbac k loop. Such regula-tion is especially likely if the gene codes for a transcription factor . Transcription factors are proteins that bind to a sub-sequence of the DNA before a gene and encourage or repress the start of transcription. The subsequence to which a tran-scription factor binds is called the transcription factor bind-ing site. If two genes have similar expression pro X les, it is likely that they are controlled by the same transcription fac-tor(s) and therefore have similar transcription factor binding sites in the sequence preceding them. Segal and colleagues seek to model both expression data, from microarra ys, and sequence data.
 A PRM can be viewed as a Bayes net where the variables of the Bayes net corresp ond to particular  X elds of a multi-relational database. The conditional probabilit y distribu-tions for a variable may be dependen t on other variables from the same relational table or from other tables. In their application of PRMs to gene regulation, Segal and col-leagues have a relational table for genes, a relational table for experimen ts, and a relational table for gene expression microarra y measuremen ts, as shown in Figure 5. An expres-sion measuremen t is for one gene within one experimen t, i.e. under one set of experimen tal conditions. Therefore, in the database schema the expression measuremen t table captures the many-to-man y relationship that exists between genes and experimen ts.
 As with ordinary Bayes net learning given known structure, the task is to estimate the conditional probabilit y distribu-tions given data. This task is straigh tforw ard when there is no missing data. But in the presen t application, the val-ues of the R ( t i )  X elds (matc hing transcription factors with genes) and the ACluster  X eld (matc hing each experimen t with a cluster of related experimen ts) are in fact unkno wn. Therefore an expectation-maximization (EM) algorithm is used to simultaneously learn which genes are controlled by which transcription factors and to cluster the experimen ts. The relationship between these two types of hidden variables is that under di X eren t experimen tal conditions, or in di X er-ent clusters of experimen ts, di X eren t transcription factors will be activ e. While other work has been done on either modeling gene expression experimen ts or modeling the se-quences of transcription factor binding sites, the novelty of this multi-relational application is that both types of mod-eling are done together, in synergy , using EM. The experi-mental results provide supp ort for the claim of synergy , that modeling the two disparate types of data together is more successful than modeling either alone. We will return later to the general issue of predicting multiple aspects of gene regulation in concert. Many biological learning problems have a sequen tial nature. In this section and the next, we discuss two applications of this type and describ e how they can be framed as multi-relational data mining problems. The  X rst task that we consider is information extraction (IE) from the biological literature, which has receiv ed much atten tion recen tly [23]. In this task, one is interested in automatically recognizing and extracting speci X c classes of entities (e.g. proteins), re-lations among entities, or even complex events comp osed from relations. The abilit y to perform this task with high accuracy would be of great interest to many biologists. For example, this capabilit y would signi X can tly increase the pro-ductivit y of the curators of genome databases who spend much of their time performing this task manually . Figure 6 provides an illustration of the information extrac-tion task. In this example, we are assuming that we are in-terested in identifying the names of proteins and the names of subcellular locations. Additionally , we are interested in extracting instances of the binary relation sub cellula r-lo calization , which represen ts the location of particular proteins within cells. We refer to an instance of a relation as a tuple . The top of the  X gure shows two sentences in an abstract, and the bottom of the  X gure shows the instances of the target classes and relation we would like to extract from the sec-ond sentence. The relation tuple asserts that the protein UBC6 is found in the subcellular compartmen t called the endoplasmic reticulum.
 In order to learn models to perform this task, we could use training examples consisting of passages of text, annotated Figure 6: An example of the information extraction task. The top of the  X gure shows part of a documen t being pro-cessed. The bottom of the  X gure shows two extracted enti-ties and one extracted relation instance. with the entities and tuples that should be extracted from them. Since natural language has such rich structure, this task can naturally be framed as a multi-relational data min-ing problem.
 Figure 7 shows a sentence represen tation that has been used in one biological IE project [45; 54]. This represen tation is based on syntactic parses produced by the Sundance [49] sys-tem. The sentence is segmen ted into typed phrases and each phrase is segmen ted into words typed with part-of-sp eech tags. For example, the second phrase segmen t is a noun phrase ( NP SEGMENT ) that contains the protein name UBC6 (hence the PROTEIN label). In positiv e training examples, if a segmen t contains a word or words that belong to a domain in a target tuple, the segmen t and the words of interest are annotated with the corresp onding domain. We refer to these annotations as labels . Test instances do not contain labels { the labels are to be predicted by the learned IE model. Figure 7 illustrates some of the relationships that migh t be encoded in a represen tation for learning information-extraction models. There are others as well. Rilo X  [48] has developed semi-sup ervised IE metho ds that exploit subject-verb-ob ject relationships. In learning models for recognizing protein names, Bunescu et al. [6] augmen t their represen ta-tion with matc hes against a generalized dictionary of protein names. This generalized dictionary is created from a list of known protein names by replacing numbers with a generic number symbol &lt; n &gt; , Roman letters with &lt; r &gt; , and Greek letters with &lt; g &gt; . For example, the protein name \NL-IL6-beta" would be generalized to \NF IL &lt; n &gt; &lt; g &gt; ." Given a sentence to be processed, Bunescu et al. look for sub-strings that matc h an item in the generalized dictionary . Such matc hes are recorded in the input represen tation of the sentence. Some of these matc hes represen t actual pro-tein names, but others do not. The learner, however, can try to learn the conditions under which such matc hes do corre-spond to actual protein names, and it can learn to recognize protein names that do not involve dictionary matc hes. A variety of learning algorithms have been used to induce models for information extraction from the biological liter-ature. Bunescu et al. [6] have conducted an empirical in-vestigation comparing a handful of learning algorithms and several hand-co ded systems on two biological information-extraction tasks. In their experimen ts, the learned IE sys-tems are consisten tly more accurate than the hand-co ded Figure 7: Input represen tation for a sentence which contains a sub cellula r-lo calization tuple: the sentence is segmen ted into typed phrases and each phrase is segmen ted into words typed with part-of-sp eech tags. Phrase types and labels are shown in column (a). Word part-of-sp eech tags and labels are shown in column (b). The words of the sentence are shown in column (c). Note the grouping of words in phrases. The labels ( PROTEIN, LOCATION ) are presen t only in the training sentences. ones. Among other algorithms, they evaluate several that emplo y relational represen tations, including Rapier [8] and BWI [21]. In earlier work, Craven and Kumlien [12] used a relational learner [14] based on FOIL [43; 44] to learn information-extraction models for such problems. It is not clear yet which learning algorithms are best suited to biolog-ical IE tasks. However, a prop osed series of comm unity-wide evaluations [1] promises to shed more light on this issue. From the early work in biological IE, one lesson that seems to hold is that rich, structured represen tations are bene X -cial. We consider one such case in more detail. The Craven group has developed an approac h [45; 54] based on using hi-erarchical hidden Mark ov models [19] to extract information from the scien ti X c literature. Hierarc hical hidden Mark ov models have multiple \levels" of states which describ e input sequences at di X eren t levels of granularit y. This approac h uses the input represen tation depicted in Figure 7, and thus each sentence is represen ted as a partially \ X  X ttened", two-level description of each Sundance parse tree.
 A schematic of one of their hierarc hical HMMs is shown in Figure 8. The top of the  X gure shows the positive model , which is trained to represen t sentences that contain instances of the target relation. The bottom of the  X gure shows the null model , which is trained to represen t sentences that do not contain relation instances (e.g. o X -topic sentences). At the \coarse" level, the hierarc hical HMMs represen t sen-tences as sequences of phrases. Thus, we can think of the top level as an HMM whose states emit phrases. This HMM is referred to as the phrase HMM , and its states are referred to as phrase states . At the \ X ne" level, each phrase is repre-sented as a sequence of words. This is achieved by embed-ding an HMM within each phrase state. These embedded HMMs are referred to as word HMMs and their states as Figure 8: Schematic of the architecture of a hierarc hical HMM for the sub cellula r-lo calization relation. The top part of the  X gure shows the positiv e model and the bottom part the null model. Phrase states are depicted as rounded rect-angles and word states as ovals. The types and labels of the phrase states are shown within rectangles at the bottom right of each state. Labels are shown in bold and states as-sociated with non-empt y label sets are depicted with bold borders. The labels of word states are abbreviated for com-pactness. word states . The phrase states in Figure 8 are depicted with rounded rectangles and word states are depicted with ovals. To explain a sentence, the HMM would  X rst follow a transition from the START state to some phrase state q i then use the word HMM of q i to emit the  X rst phrase of the sentence, then transition to another phrase state q j , emit another phrase using the word HMM of q j and so on until it moves to the END state of the phrase HMM.
 Like the phrases in the input represen tation, each phrase state in the HMM has a type and may have one or more labels. Each phrase state is constrained to emit only phrases whose type agrees with the state's type. Once a model has been trained, the Viterbi algorithm is used to predict tuples in test sentences. A tuple is extracted from a given sentence if the Viterbi path goes through states with labels for all the domains of the relation. For example, for the sub cellula r-localization relation, the Viterbi path for a sentence must pass through a state with the PROTEIN label and a state with the LOCATION label.
 The experimen tal evaluation of this approac h has shown that, in general, the more grammatical information incorp o-rated into the models, the more accurate they are [54]. This result indicates the importance of using a multi-relational represen tation for the IE problem in biological domains. Figure 9: The concept of an operon. The curved line rep-resen ts part of a bacterial chromosome and the rectangu-lar boxes on it represen t genes. An operon is a sequence of genes, such as [ g 2 ; g 3 ; g 4] that is transcrib ed as a unit. Transcription is controlled via an upstream sequence, called a promoter , and a downstream sequence, called a terminator . A promoter enables the molecule performing transcription to bind to the DNA, and terminator signals the molecule to detac h from the DNA. Each gene is transcrib ed in a partic-ular direction, determined by which of the two strands it is located. The arrows in the  X gure indicate the direction of transcription for each gene. There are many data mining problems in molecular biol-ogy that involve represen ting and reasoning about DNA, RNA and protein sequences. Among these problems are gene  X nding [7], motif disco very [33], and protein structure prediction [51]. We argue that, increasingly , such sequence-analysis tasks are becoming multi-relational problems. The reasons for this trend are twofold. First, other sources of evidence, in addition to the sequences themselv es are being leveraged in the learning and inference processes. Second, many sequence elemen ts of interest are comp osed from other sequence elemen ts. In this section, we discuss these issues in more detail, focusing in particular on our recen t work in analyzing bacterial genomes. [3; 4; 13].
 Recall that the  X rst step in the process of a gene being ex-pressed is for it to be transcrib ed into a similar RNA se-quence. Although the expression of a gene can be regulated at various points, the most signi X can t regulatory controls are exerted on the transcription process. For example, a gene can be \shut o X " by preventing it from being transcrib ed. In some organisms, especially bacteria, there are certain sets of contiguous genes, called operons that are transcrib ed coor-dinately . In other words, the genes in an operon are \turned on" or \shut o X " as a unit.
 Figure 9 illustrates the concept of an operon. The tran-scription process is initiated when a molecule called RNA polymer ase binds to the DNA before the  X rst gene in an operon. The RNA polymerase binds to a special sequence called a promoter . It then moves along the DNA using it as a template to produce an RNA molecule. When the RNA polymerase gets past the last gene in the operon, it encoun-ters a special sequence called a terminator that signals it to release the DNA and ceases transcription.
 Consider the task of analyzing and annotating a newly se-quenced genome. More than 100 bacterial genomes have been sequenced [2], and several hundred others are in the process of being sequenced, so this is an increasingly com-mon task to be addressed. In addition to identifying the genes in the genome and predicting something about their functions, we would also like to identify regulatory elemen ts such as operons, promoters, terminators, and others. Of-ten, it is the case that we know about some experimen tally determined instances of these elemen ts.
 Figure 10 shows a sample database that represen ts what Figure 10: A sample database describing known attributes of a bacterial genome. migh t be known about a particular bacterial genome. The operon table lists known operons. The gene table describ es attributes of known genes including their sequence coordi-nates and which operon they are contained within, if this is known. The promoter and terminator tables list a reference sequence coordinate for each known instance. The expres-sion table contains expression measuremen ts from microar-rays, across a variety of experimen tal conditions. The table also lists a reference sequence coordinate for each probe that is used to take an expression measuremen t. Note that the sequence coordinates provide a means for computing other relations among entities, such as the linear order of known genes, promoters and terminators in the genome.
 Given a data set such as that shown in Figure 10, there are a number of prediction tasks that we migh t want to address. These include predicting additional genes, promoters and terminators, and predicting how genes are organized into operons, in cases where this is not known. Note that these tasks are clearly multi-relational in that the represen tation includes attributes of genes (e.g. sequence coordinates), re-lations among genes (e.g. containmen t in the same operon), and relations between genes and other entities, such as pro-moters and terminators. Additionally , the records in the ex-pression table are linked to these entities via their sequence coordinates.
 In our researc h, we have considered various approac hes to recognizing regulatory elemen ts in bacterial genomes. In our most recen t work [4], we have developed a probabilistic language model to simultaneously predict promoters, ter-minators and operons. This model is, for the most part, a hidden Mark ov model, although two comp onen ts of it are actually stochastic context free grammars. Most of the re-lational structure in this problem is sequen tial, and thus probabilistic language models are especially suited to the task.
 We argue that those interested in relational data mining should consider probabilistic language models, such as HMMs, to be powerful tools in their arsenal. For many key biolog-ical sequence-analysis tasks, such as gene  X nding [7], these metho ds are the ones that provide state-of-the-art predictiv e accuracy .
 One exciting topic of researc h in this area is investigating ways in which learned models can take into accoun t all of the relev ant data that is available. For example, there are several new gene- X nding HMM metho ds [31; 35] that take sequences from multiple organisms as input, and use the evo-lutionary relationships among the organisms to aid in gene prediction. As another example, our bacterial genome model takes gene expression data (as illustrated in Figure 10) as in-put in addition to sequence data. In both of these cases, the augmen ted represen tation has resulted in impro ved predic-tive accuracy . We conjecture that this trend of leveraging additional data will lead to represen tations that are even more multi-relational than curren t ones. One interesting lesson that biological applications such as pharmacophore disco very have provided is how naturally multi-relational data mining address the multiple instance problem. This has been noted earlier, for example in the original pharmacophore disco very paper [20]. Recen tly, Per-lich and Provost have provided a useful hierarc hy of data mining tasks, based on represen tation, where multiple in-stance tasks form a class subsumed by multi-relational tasks [42].
 A second lesson, importan t though perhaps not novel, is that multiple distinct sources of information can provide impro ved accuracy . For example, the application of PRMs used both expression data and sequence data to accurately recognize which genes are controlled by the same transcrip-tion factors. As another example, two consecutiv e genes are likely to be in the same operon if their expression pat-terns are correlated, if they are separated by a relativ ely small number of bases, and if no promoters or terminators appear between them; using these multiple sources of infor-mation provides impro ved operon prediction over using any one source alone. Multi-relational data mining is naturally suited to using distinct sources of information that can be encoded in distinct relational tables.
 One major challenge that biological applications highligh t for the area of multi-relational data mining is simply com-putational complexit y. Biological databases are growing at an exponen tial rate. Moreo ver, the time to simply check a potential hypothesis or disco very against the data can be much higher for a multi-relational system that for an or-dinary single-table or feature-v ector system. For example, the task of determining whether a molecule contains a given substructure is the NP-complete task of subgraph isomor-phism.
 A second, related challenge that biological applications raise for multi-relational data mining systems is ease of use. A bi-ologist can run a decision-tree learner or a linear regression routine on his or her data with relativ ely little training and prepro cessing. But running a multi-relational data mining system typically requires a much larger knowledge engineer-ing e X ort. Researc h is needed into ways of making multi-relational data mining systems easier to use by biologists or other domain experts. Multi-relational data mining tools have been applied to a variety of biological tasks. Nevertheless, the breadth of inter-related data types discussed in the introduction is sig-ni X can tly greater than in any of the speci X c applications we discussed. Furthermore, with the growth in systems biology , the breadth and relational structure of biological databases will only increase. Therefore, biological databases provide a major challenge for multi-relational data mining. Already , data mining researc hers should be more ambitious in apply-ing multi-relational algorithms to larger and more diverse databases. For example, we should be integrating data on DNA (SNPs), mRNA (from gene expression microarra ys), proteins (from mass spectrometry) and metab olomics into multi-relational analyses. We should be drawing on relev ant text sources as well. Stretc hing ourselv es in this manner in applications is sure to reveal new researc h directions in the developmen t of multi-relational data mining algorithms. M.C. was supp orted by NSF grant IIS-0093016 and NIH grant R01-LM07050-01. D.P. was supp orted by NSF grant 9987841. [1] Critical assessmen t of information ex-[2] A. Bernal, U. Ear, and N. Kyrpides. Genomes On-[3] J. Bockhorst, M. Craven, D. Page, J. Shavlik, and [4] J. Bockhorst, Y. Qiu, J. Glasner, M. Liu, F. Blat-[5] C. Bryant, S. Muggleton, S. Oliver, D. Kell, P. Reiser, [6] R. Bunescu, R. Ge, R. Kate, R. Mooney, E. Marcotte, [7] C. Burge and S. Karlin. Prediction of complete gene [8] M. E. Cali X  and R. Mooney. Bottom-up relational [9] J. Cheng, C. Hatzis, H. Hayashi, M.-A. Krogel, S. Mor-[10] L. Chrisman, P. Langley , S. Bay, and A. Pohorille. [11] M. Craven. The genomics of a signaling pathway: [12] M. Craven and J. Kumlien. Constructing biological [13] M. Craven, D. Page, J. Shavlik, J. Bockhorst, and [14] M. Craven and S. Slattery . Relational learning with sta-[15] A. Debnath, R. L. de Compadre, G. Debnath, A. Schus-[16] L. Dehasp e, H. Toivonen, and R. King. Finding [17] T. Dietteric h, R. Lathrop, and T. Lozano-P erez. Solv-[18] S. D X  X eroski, H. Blockeel, B. Kompare, S. Kramer, [19] S. Fine, Y. Singer, and N. Tishby. The hierarc hical hid-[20] P. Finn, S. Muggleton, D. Page, and A. Sriniv asan. Dis-[21] D. Freitag and N. Kushmeric k. Boosted wrapp er induc-[22] C. Helma and S. Kramer. A survey of the predic-[23] L. Hirsc hman, J. Park, J. Tsujii, L. Wong, and C. Wu. [24] L. Hood and D. Galas. The digital code of DNA. Na-[25] A. Inokuc hi, T. Washio, and H. Moto da. An apriori-[26] A. Jain, T. Dietteric h, R. Lathrop, D. Chapman, [27] A. Jain, K. Koile, B. Bauer, and D. Chapman. Com-[28] P. Karp, M. Riley , S. Paley, and A. Pellegrini-To ole. [29] R. King, S. Muggleton, R. Lewis, and M. Stern berg. [30] R. King, S. Muggleton, A. Sriniv asan, and M. Stern-[31] I. Korf, P. Flicek, D. Duan, and M. Bren t. Integrat-[32] S. Kramer, L. D. Raedt, and C. Helma. Molecular fea-[33] C. Lawrence, S. Altsc hul, M. Boguski, J. Liu, [34] N. Marc hand-Geneste, K. Watson, B. Alsb erg, and [35] I. Meyer and R. Durbin. Comparativ e ab initio predic-[36] M. Molla, P. Andrae, J. Glasner, F. Blattner, and [37] M. Molla, M. Waddell, D. Page, and J. Shavlik. Us-[38] S. Muggleton. Inverse entailmen t and Progol. New Gen-[39] S. Muggleton and C. Feng. E X cien t induction of logic [40] S. Muggleton, R. King, and M. Stern berg. Protein sec-[41] National Library of Medicine. Pubmed, 1999. [42] C. Perlich and F. Provost. Aggregation-based feature [43] J. R. Quinlan. Learning logical de X nitions from rela-[44] J. R. Quinlan and R. M. Cameron-Jones. FOIL: A [45] S. Ray and M. Craven. Represen ting sentence structure [46] M. Rebhan, V. Chalifa-Caspi, J. Prilusky , [47] P. Reiser, R. King, D. Kell, S. Muggleton, C. Bryant, [48] E. Rilo X . An empirical study of automated dictionary [49] E. Rilo X . The sundance sentence analyzer, 1998. [50] B. Rost and C. Sander. Com bining evolutionary in-[51] S. Schmidler, J. Liu, and D. Brutlag. Bayesian segmen-[52] E. Segal, B. Taskar, A. Gasc h, N. Friedman, and [53] H. Shatk ay, S. Edwards, W. J. Wilbur, and M. Boguski. [54] M. Skounakis, M. Craven, and S. Ray. Hierarc hical hid-[55] A. Sriniv asan and R. King. Feature construction with [56] M. Turcotte, S. Muggleton, and M. Stern berg. Auto-[57] X. Yan and J. Han. Closegraph: Mining closed frequen t
