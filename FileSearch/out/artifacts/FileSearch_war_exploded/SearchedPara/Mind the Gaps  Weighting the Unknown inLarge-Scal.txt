 One-Class Collaborative Filtering (OCCF) is a task that naturally emerges in recommender system settings. Typical characteristics include: Only positive examples can be ob-served, classes are highly imbalanced, and the vast majority of data points are missing. The idea of introducing weights for missing parts of a matrix has recently been shown to help in OCCF. While existing weighting approaches mitigate the first two problems above, a sparsity preserving solution that would allow to efficiently utilize data sets with e.g., hundred thousands of users and items has not yet been reported. In this paper, we study three different collaborative filtering frameworks: Low-rank matrix approximation, probabilistic latent semantic analysis, and maximum-margin matrix fac-torization. We propose two novel algorithms for large-scale OCCF that allow to weight the unknowns. Our experimen-tal results demonstrate their effectiveness and efficiency on different problems, including the Netflix Prize data. G.1.2 [ Approximation ]: Least squares approximation; H.2.8 [ Database Applications ]: Data Mining Algorithms Collaborative Filtering, Large-Scale, One-Class
Collaborative filtering is at the core of modern person-alization machinery. The longer-term vision is to be able to automatically stream the right kind of news to our desks and to recommend the movies and music we have not yet no-ticed we desired, without ever having to bother with search queries. Recommender systems have found their way into practice over the last decade. Prominent examples include Amazon X  X  product recommender and the Google News web-site. Those systems leverage a large pool of training obser-vations and rely to a large part on implicit feedback, i.e., which user performed which action.

Our work addresses a particularly hard case that emerges from several real-world prediction tasks: We try to learn from implicit feedback only, and under the restriction that each observation is a positive example of e.g., a user X  X  inter-est. Examples include (i) tracking which items a user bought in the past, and trying to predict the current interests, or (ii) using the (social) bookmarks of a user to predict which other yet unknown sites she also might like. In both these cases, the observed events are positive examples of what a user likes, so all observations belong to a single class.
There are two different strategies for handling such one-class problems. The first one is to assume that all unob-served events (e.g., sites that were not bookmarked) are negative examples. This is obviously simplistic, but allows one to restate the problem in terms of traditional binary classification. We refer to this strategy as all missing as negative (AMAN). The second strategy is to explicitly state that the missing values are unknown, and to turn to prob-abilistic density estimation techniques that are capable of working with positives only. We refer to this strategy as all missing as unknown (AMAU). We recently proposed the use of instance weighting techniques after substituting ze-ros for unknown values [13]. This allows us to balance the extreme cases of AMAN and AMAU: A weight of one after substitution is identical with the AMAN strategy, whereas a weight of zero results in an AMAU strategy. Choosing fractional weights reflects degrees of confidence that missing values are in fact negatives.

This paper entails an empirical study that covers the ma-jor families of algorithms: an AMAU-based probabilistic model, an AMAN technique based on a low-rank approx-imation, and another AMAN technique that is based on a maximum margin approach. Our previous empirical study was limited by the scalability of algorithms [13]. Since col-laborative filtering systems benefit from large user bases, we mostly focus on scalability aspects and the performance on large-scale benchmarks in this paper. Our goal is to gain a better understanding which methods are truly valuable in practice, and how much we gain by introducing weights. As a major contribution, we propose two scalable algorithms that allow to weight missing values in sparse matrices. The first one is based on low-rank approximations, the second one extends maximum-margin matrix factorization.
The common goal of techniques discussed in this paper is to decompose a given n  X  m matrix R , for example describing which news articles were read by which users. We investi-gate the predictive performance of three different families or tools. The first one (pLSI) is based on a probabilistic model, the second one (ALS) on low-rank approximations, and the third one follows the paradigm of maximum-margin classifi-cation. Surprisingly, despite those deep semantic differences, all three methods yield a very similar output: All models consist of two matrices X = ( X ) n  X  d and Y = ( Y ) m  X  d are chosen so that XY T approximates the original matrix of observations R . We will discuss the different techniques in more depth in the following sections.

Regarding notation, we will use bold upper-case letters for matrices and vectors throughout this work. A matrix with a single index e.g., R r denotes the r-th row vector. Individ-ual components are referred to when using two indices, e.g., R r,c denotes the element in row r and column c . For column vectors we use the notation R  X  ,c . For any matrix R , || R || denotes the Frobenius norm. The vector 1 denotes the col-umn vector that has 1 as the value of each component. Its dimensionality can be concluded from the context. Finally, I refers to the identity matrix.

Let R = ( R ) n  X  m be a user-item matrix. As discussed in the problem statement, R contains only positives, since only positives are observable. We might represent those as entries with a value of 1. Unobserved values are not necessarily negative though, so we try to avoid respresenting them using any fixed value at this point. Let instead M := { 1 ,...,m } be the set of all column indices of R , that is, the set of all items, and M r denote the set of indices of all observed (hence positive) items in row R r .
The first model we want to include in our study is called probabilistic latent semantic indexing (pLSI) [9]. It was used in the context of the Google News recommender engine [7], an application that is very close to OCCF.

PLSI is based on a generative model: Each user has a distribution over interests, and each interest  X  X enerates X  the action of picking a particular item with a fixed probability. Interests are modeled as latent topics z that connect users and items in a graphical model. The model specifies condi-tional probabilities P ( z | u ) for each user u to like / pick each of the latent topics z , and for each topic z to generate a particular item i , P ( i | z ). The assumption is that the choice of an item is independent of the user given the latent topic. The probability that user u picks item i simplifies to under this assumption. Since pLSI follows a probabilistic framework, the goal is to find a maximum likelihood model that best explains the observations. There is a well-known EM algorithm for this task [9].

The pLSI model and algorithm provide a good example of an AMAU strategy, because the model operates exclusively on the positives. The resulting estimates of P ( u,i ) can be used to rank items for each user according to the estimated likelihoods of preference for each item.
 Require: data matrix R  X  R n  X  m , rank d Ensure: Matrices X  X  R n  X  d and Y  X  R m  X  d
Initialize Y randomly repeat until convergence. return X and Y
Given the AMAU nature of pLSI, introducing weights into this framework is only reasonable for non-missing values. As we will discuss later, we are exclusively looking into the problem of weighting the missing values in this paper, so we skip the option of weighting pLSI.
The techniques discussed throughout Section 2.3 have their roots in singular value decomposition (SVD). For a given matrix R  X  R n  X  m , an SVD is a decomposition of the ma-trix R = X S Y T , where X  X  R n  X  r and Y  X  R m  X  r are or-thonormal matrices, r is the rank of R , and S is a diagonal matrix with the singular values of R on its main diagonal. When projecting X , S , and Y onto the d  X  r columns for which S has the highest singular values, the product of the three resulting matrices gives the best approximation  X  R of R of rank d with respect to || R  X   X  R || 2 F .

Unfortunately, the SVD framework loses its convexity if it encounters missing values. The alternating least squares algorithm (ALS) provides an efficient search strategy and handles missing values gracefully, but only guarantees to find local optima in such cases. Due to its success in the Netflix Prize (where most of the values are missing) ALS gained a lot of attention recently. It fits the objective of this competition well: to optimize for the Frobenius norm.
The variations of ALS discussed in this work all have the skeleton depicted in Algorithm 1 in common, and only differ in terms of the loss function and corresponding updates of X and Y . The algorithm starts with a random matrix Y , and then alternates steps of optimizing X for fixed Y and of optimizing Y for fixed X . Since both these steps are perfectly symmetric, we will for notational simplicity just discuss the case of optimizing X throughout this section. Some additional notation helps describing those updates. ALS exploits sparsity and handles missing values by project-ing matrices and vectors so that missing values in R have no effect. Let  X  r denote a function that projects exactly those components of a column vector into a lower dimen-sional space for which the indices are not missing in the vector R T r , that is, it projects the components with index in M r into a |M r | -dimensional subspace. Analogously, for a matrix Y , let  X  r ( Y ) denote the matrix that results from projecting each column vector Y  X  ,c to  X  r ( Y  X  ,c ). For illus-tration, if no values are missing in R r , then otherwise the multiplication after projection (left hand side) simply ignores all products containing a missing value.
We use ALS with Tikhonov-regularization (parameter  X  ) in this work, as regularization consistently gives better re-sults. We refer to it as  X  X egular ALS X . Its loss function is When updating X for given R , Y , and  X  , each row X of X can be updated separately, and there is a closed-form solution for minimizing the loss: Besides having this neat closed form solution, ALS has a few other pleasant properties worth mentioning, see also [21]: First, all ALS variants we evaluated had a stable behav-ior when it came to parameter tuning. We found it to be substantially less sensitive to parameter settings and more stable in its performance than e.g., pLSI. Second, the ALS variant that includes regularization hardly ever overfits, so by increasing the number of latent features d (the rank of  X  R ) ALS tends to monotonically improve its predictive per-formance, just with diminishing returns for every extra CPU cycle (additional features). Finally, it is easy to parallelize.
For one-class problems, the ALS framework seems a bit unmotivated at first. ALS provides a solution to a regression-style matrix completion problem, but in OCCF we only have one kind of observed value, and all the remaining values are missing. However, as a first step we can use the AMAN substitution and rephrase OCCF as a binary classification-style problem, which is a special case of regression with the response being either 0 or 1. A regularized low-rank approx-imation will fail to reproduce the matrix exactly, so for each user we can rank items with originally unknown values with respect to the predicted values in  X  R .

The results in [13] indicate that this approach, which we refer to as ALS after AMAN substitution , benefits from in-troducing weights for the originally unknown values of R ; different weighting schemes based on whether a value is present or missing, and  X  optionally  X  based on the indi-vidual user and item under consideration improved the pre-dictive power of collaborative filtering models.

A straightforward adaptation of the loss function L above supports this kind of weighting [16]: If W is the weight matrix, then we define weighted loss with respect to W as The problem of updating X to minimize the loss L W still has a closed-form solution after AMAN substitution [13]: where g W r is a n  X  n diagonal matrix with the weights of row r on the main diagonal. In our experiments, we will only consider the three weighting schemes proposed in [13].
The basic idea in all three cases is to let W reflect the credibility of the training data ( R ) that we use to build a collaborative filtering model. Positive examples are likely indeed positive. Given that the information of this kind is rare in typical one-class applications, we trust the data in this case, and set W ij = 1 whenever R ij = 1.

In turn, missing data points are likely to be negative ex-amples. In social bookmarking, for example, each user has very few web pages and tags; for news recommendation, each user reads only a small fraction of the available articles. We observe that the confidence in missing values being negative is not as high as in non-missing values being positive, which suggests to assign lower weights to allegedly negative ex-amples. This is addressed by our first weighting scheme. It uniformly assigns a confidence weight  X   X  [0 , 1] to each  X  X eg-ative X  example. The rationale behind the second weighting scheme is that the available data on some users is poor, so we should lower our confidence in the data for these users and not trust missing parts to be negative. Poor informa-tion means that we have only a few observations (positive examples) for a user. The third weighting scheme resem-bles the popularity-based ranking of items. Here we expect to have more positives in the missing parts if the items are more popular. Table 1 summarizes these three schemes. We plan to investigate more complex weighting schemes in our future work.

There are two reasons why we do not consider weighting the non-missing values in this paper. First, the success of weighting known values inherently depends on the quality and encoding of background knowledge into weights (e.g., [20]); in this case, we do not even trust our very few known data points after all. Collecting and incorporating back-ground knowledge is an orthogonal problem, that is out of the scope of this paper. Second, weighting just the non-missing values for all three matrix decomposition techniques, PLSA, ALS, and MMMF, does not increase asymptotic run-time complexity. It is straightforward to extend all subse-quently proposed techniques in this fashion. Scalability is decisive for practical OCCF applications. We first look into the complexity of regular ALS. Let in the subsequent analysis | R | denote the number of non-missing values in R . Regular ALS can basically  X  X andle X  missing val-ues by ignoring them. When updating the r -th row of X ac-cording to Eq. (1), ALS only requires the projection  X  r ( Y ), or equivalently, only the columns of Y T for which the col-umn in the r -th row of R is not missing. In total, the whole recomputation of X (for all rows together) hence requires to read | R | rows from Y . In the next step,  X  r ( Y ) T  X  can trivially be computed in time O ( d 2  X |M r | ) for each indi-vidual row r . This term dominates the previous read oper-ation and the subsequent multiplications with  X  r ( Y ) T  X  ( R T r ). In practice, it will usually also dominate the n ma-trix inversions, although for very sparse matrices or large d one should keep in mind that the costs per matrix inver-sion are cubic when using naive implementations, and still no better than O ( d 2 . 376 ) even for the fastest known algo-rithm [6]. The total costs for updating X (or analogously Y ) without the matrix inversions are in O ( | R | X  d 2 ), since the sum of |M r | over all rows is | R | . Putting together all costs and assuming a naive matrix inversion we still end up with an upper bound of only per iteration when updating both X and Y with regular ALS. For a fixed number of latent variables d , computational costs scale linearly with the number of non-missing values.
Regular ALS lacks the good generalization performance of its gap-weighting counter-part though [13]. The weight-ing algorithm proposed in [20] is somewhere in between. It supports weights only for the small set of non-missing val-ues, which does not increase the runtime complexity above. In order to support weights for missing values we want to apply methods as described in [13] (see Eq. (2)). Unfortu-nately, explicitly substituting all missing values with zeros and weighting the full matrix increases the runtime complex-ity from O ( | R | ) to  X ( n  X  m ). Collaborative filtering relies on a large number of users and items and is performed on sparse matrices, so this last strategy is impractical.

One work-around that avoids this strategy is an ensemble technique that runs ALS multiple times [13]. Each iteration uses only a subsample of negative examples, while ignoring the (still) missing values just like regular ALS does. This makes the approach feasible in practice, but (i) it decreases the amount of negative examples considered during training, which reduces the expected predictiveness of results, and (ii) it still increases the runtime considerably compared to the case of ALS without substituting any examples, since ALS is run multiple times on expanded data sets.
We next describe an algorithm that is capable of solv-ing the above-mentioned ALS optimization problem with weighted missing values very efficiently. It supports all weight-ing schemes shown in Table 1 at the same asymptotic com-putational costs as the regular ALS algorithm, see Eq. (3). In fact, the increase in runtimes compared to regular ALS is quite small in practice, even in absolute terms. The same al-gorithm applies to a much larger family of weighting schemes that can all be incorporated in time linear in the number of non-missing values.

Before going into detail, it is worth mentioning that the key property of ALS that enables this kind of optimization is its closed-form solution for computing optimal updates. Both pLSI and MMMF lack this property.

As our only constraint, we will assume that the weight ma-trix for the missing values can be expressed (or well approxi-mated) by a low rank approximation: W = UV T . Positives automatically receive a weight of 1, regardless of the corre-sponding value in UV T . All the weighting schemes pro-posed in [13] are covered as special cases of rank 1. Higher ranks allow for much more complex weighting schemes that can e.g., be motivated by domain knowledge or by iteratively adding latent features as part of a weight learning scheme. We leave the investigation of such schemes for future work.
To avoid confusion with the latent variables of X and Y , referred to by using the summation variable d , we will use D as the variable for the latent features of U and V , and in slight abuse of notation also denote the rank of W as | D | .
The novel gap-ALS algorithm (GALS) adapts Algorithm 1, but uses a much more efficient update rule than Eq. (2). We just show the case of updating X in Algorithm 2. Updat-Ensure: X with minimal loss L W ( X , Y ) for fixed Y /* init */
V P := V T 1 for all  X  D  X  X  1 ,..., | D |} do /* row-wise recomputation of X */ for rows r  X  X  1 ,...,n } do return X Algorithm 2: GALS update of X given R and Y when weighting (only) missing values with W = UV T . ing Y works analogously. Please refer to the appendix for a proof that Algorithm 2 optimizes X with respect to L W when substituting AMAN and setting W i,j = 1 for positives.
The runtime complexity of Algorithm 2 benefits substan-tially from precomputing the matrices b A (  X  D ) j,k just once during the init-stage. The costs for this step, and for the whole ini-tialization, are in  X ( | D | X  d 2  X  m ). The costs for computing A , B 0 , C 0 and q r during each row-wise computation are low, because the computations are based on projections of matrices to M r . These costs are dominated by computing the | D | matrices e B (  X  ) , which takes time  X ( | D | X  d together. Finally we invert a d  X  d matrix for each row, as in regular ALS. The initialization phase is dominated by the row-wise updates. In the case of a rank 1 weighting, the asymptotic costs of GALS are identical to those of reg-ular ALS, see Eq. (3). When using more complex weight matrices W , GALS scales linearly with the rank of W .
We want to conclude the discussion of runtime complex-ities by pointing out that GALS tends to converge quickly in practice due to the effective closed form updates. Even for large datasets, 20 to 30 iterations of updates are usually sufficient. In contrast, pLSI required hundreds of iterations in our experiments until convergence.
In this section, we apply the idea of weighting unknowns into the context of Maximum Margin Matrix Factorization (MMMF) [17]. Given a matrix R = ( R ij ) m  X  n  X  { X  1 } m  X  n with m users and n items and a corresponding non-negative weight matrix W = ( W i,j ) m  X  n  X  R m  X  n + , weighted low-rank approximation aims at approximating R with a low rank matrix e R = ( e R i,j ) m  X  n minimizing the objective of the weighted hinge loss and the trace norm of e R as follows. where h (  X  ) is the Smooth Hinge loss function in [17],  X  is a parameter trading off the weighted hinge loss and the mar-gin and k X k  X  is the trace norm of a matrix. In the above objective function (Eq. (4)), W i,j reflects the contribution of minimizing the term to the overall objective L ( e R ).
Following the discussion in Subec. 2.3.2, we substitute negative labels (  X  1) for missing values and adopt the weight-ing schemes depicted in Table 1: Positive examples receive a fixed weight of W i,j = 1, while the weights of negatives vary based on our confidence that they are in fact negative.
In order to solve the optimization problem min L ( e R ), we consider the decomposition e R = XY T where X  X  R m  X  d and Y  X  R n  X  d . Note that usually the number of features d r where r  X  min ( m,n ) is the rank of the matrix R . We can re-write the objective function (Eq. (4)) as Eq. (5) Taking partial derivatives of L with respect to each entry of U and V , we obtain As suggested in [15], we apply the Conjugate Gradients (MMMF-CG) algorithm to solve the optimization problem min L ( X , Y ). Note that the running time for wMMMF with CG is  X ( m  X  n ) however, if we substitute negatives for all missing values. Considering the large number of missing val-ues, this is intractable for large-scale problems, and it may still cause issues related to class-imbalance, otherwise. Un-like for wALS, wMMMF updates do not have a closed-form solution. It is not clear how to speed up wMMMF in a sim-ilar manner as discussed in Subsec. 2.3.4. We hence adapt the previously discussed idea of subsampling (cf. Sec. 2.3.3).
Algorithm 3 summarizes this method. It combines the idea of subsampling unknowns as negatives with the bag-ging technique [5]. The algorithm runs iteratively, and each iteration i can be broken down into two phases.

In phase I, the algorithm samples a limited number of q negative examples from missing values, proportionately to our weight matrix W . It then generates a new matrix R ( i ) that includes the sample together with all positives from R (since positives are rare). For sparse matrices, the number of negative examples is close to m  X  n , so care must be taken when selecting a negative example sampling (NES) technique to avoid complexities of  X ( m  X  n ). We suggest using a fast ( O ( q )) random sampling scheme [18] in these cases to generate R ( i ) from R .

In phase II, the algorithm re-constructs the rating matrix e R ( i ) from R ( i ) by applying a conjugate gradients algorithm (MMMF-CG) [15].
 Require: matrix R  X  R m  X  n , matrix c W  X  R m  X  n , sample size q , number of single predictor ` Ensure: Reconstructed matrix e R for i = 1 : ` do e
R = 1 return e R
In the post-processing step, we compute an unweighted average of all the e R ( i ) that were computed throughout the different iterations. This yields the final matrix e R which ap-proximates R . Bagging is promising in this setting, because it allows to exploit the stochastic, unstable nature induced by the underlying boostrap sampling approach. We refer to Algorithm 3 as sampling MMMF Ensemble (sMMMF-ENS).
In this section, we empirically evaluate the effectiveness and efficiency of the algorithms proposed in Section 2. We first study the predictive performance of all algorithms dis-cussed in this paper on the same (small) datasets that were used in [13]. Then we study both predictive performance and algorithmic efficiency on three large-scale datasets. We use Mean Average Precision (MAP), Half-Life Utility (HLU) [13] and the Area Under the ROC curve (AUC) as our met-rics for the predictiveness of models.

MAP (Mean Average Precision) assesses the overall per-formance based on precisions at different recall levels on a test set. It computes the mean of average precision (AP) over all users in the test set, where AP is the average of precisions computed at all positions with a preferred item: where i is the position in the rank list, N is the number of re-trieved items, prec ( i ) is the precision (fractions of retrieved items that are preferred by the user) of a cut-off rank list from 1 to i , and pref ( i ) is a binary indicator returning 1 if the i -th item is preferred or 0, otherwise.

Half-Life Utility (HLU) [4] estimates how likely a user will view/choose an item from a ranked list, which assumes that the user will view each consecutive item in the list with an exponential decay of possibility. A half-life utility over all users in a test set is defined as in Eq. (8).
 where R u is the expected utility of the ranked list for user u and R max u is the maximally achievable utility if all true positive items are at the top of the ranked list. R u is defined as follows.
 where  X  ( j ) equals 1 if the item at position j is preferred by the user and 0 otherwise, and  X  is the half-life parameter which is set to 5 in this paper.
The following experiments compare the predictive perfor-mances of GALS, wMMMF, and some baseline algorithms. For the purpose of comparisons, we use the same datasets as in [13]. This includes data from the news domain (Yahoo! News usage) and from the domain of social bookmarking (delicious.com). For validation purposes, each dataset con-tains 20 pairs of training and test sets, each with an 80/20 splitting ratio. The Yahoo! data contains 84117 user-article pairs with 3158 unique users and 1536 different articles. The delicious.com data contains 246 , 436 posts by 3000 users, and it covers 2000 different tags.

Figure 1 shows results in terms of MAP, HLU and AUC, averaged over the 20 folds. SVD (with all missing as nega-tive substitution) and Popularity are two baselines also used in [13]. As expected, wMMMF performs best with respect to both MAP and HLU and is competitive for AUC, which ver-ifies that the maximum-margin paradigm can also achieve outstanding performance on classification problems in col-laborative filtering setting. GALS yields competitive results with all three weighting schemes. Surprisingly, pLSI works poorly for OCCF. One possible reason is that it implicitly makes the  X  X ll missing as unknown X  assumption.
We used three large test datasets to compare our proposed algorithms to state-of-the-art baseline algorithms. The first one is a clickstream dataset of News articles 1 . Each record is a user-article pair that consists of a user ID and the URL of a NYTimes, Washington Post, or Yahoo news article. The
We thank  X  X ielsenOnline X  for providing the clickstream data. data set contains 59202 unique users and 138 , 575 different news stories. We call this dataset newsLarge in our experi-ments. We also generated a smaller dataset from newsLarge, such that each user or each item has at least ten records. We call this dataset newsSmall . It contains 23 , 495 users and 36 , 339 articles. The third dataset is generated from the Netflix Prize data. It contains about 100 million ratings with 480 , 189 users and 17 , 770 movies. The ratings in the original data ranges from 1 to 5, but we just tried to predict whether a user rated a movie at all. That is, we treat all rated user-movie pairs as positive examples, and all pairs without given ratings as missing values.

We randomly divided each of the three datasets into a training, a validation and a test set with a 60/20/20 split-ting ratio. The training set contains 60% known positive examples. The other elements of the matrix are treated as unknown. The validation set includes 20% known positives, and all the unknown examples for parameter tuning. The test set includes the remaining 20% known positives and all unknown examples.

Note that the known positives in the training set are ex-cluded from the test process. We evaluate the performance on the test set using AUC, MAP, and half-life utility (HLU). The parameters of all algorithms were determined by the performance on validation set.
We conducted experiments on our three large datasets to demonstrate the utility of the proposed algorithms for OCCF. The algorithms involved in these experiments in-clude Popularity, SVD (AMAU), pLSI, sMMMF-ENS (Al-gorithm 3) 2 , and GALS with the three weighting schemes discussed in Section 2.3.2. We fixed the number of features to 50 throughout these experiments. Table 2 lists the results. Although sMMMF-ENS achieves highest AUC values, it is not as good as wMMMF (shown in Figure 1) on MAP and HLU. In contrast, GALS with different weighting schemes outperforms other algorithms on all three datasets, which shows great merit in solving large-scale OCCF problems. We will also illustrate the advantages of GALS in terms of time complexity.
We implemented the GALS algorithm in Matlab and Java to confirm that it gives identical results as the less scalable counter-part and to study how it scales up as a function of different variables. The results we report here were gen-wMMMF is not included because it is intractable for large-scale datasets, although it performs well in the above exper-iments. time as a function of an increasing number of features. erated using the Matlab code on the binary (who ranked what?) Netflix data set. The sparsity of the data is about 1%, there are about 20 , 000 movies and 500 , 000 users.
Figure 2 shows the convergence of GALS and pLSI. We can see that GALS converges after roughly 15 to 20 itera-tions, much earlier than pLSI.

Figure 3 (a) compares the time consumed by the updates for the old method that performs a full substitution of miss-ing values and weights the whole matrix, and the new GALS update method.  X  X pdating U X  refers to an update of the user matrix (corresponds to X ), while  X  X pdating M X  corresponds to the item matrix ( Y ). We only evaluated the case of rank 1 weight matrices here. We failed to run the old method for more than 400 , 000 users. It is obvious that the new method brings incredible savings in terms of CPU costs.

In Figure 3 (b), we fixed the matrix but removed positives at random. This allows us to increase the sparsity from 1% positives (right) to 0 . 1% left. Since we used the full matrix, we could only run our new method on this set. The plot confirms the linearity of our method in the number of non-missing values.

Figure 3 (c) confirms that increasing the rank of the weight matrix affects the computational costs only linearly.
Finally, Figure 3 (d) confirms that the number of features has an impact of square order on CPU time as analyzed in Section 2.3.
Many researchers have explored different aspects of col-laborative filtering (CF) in the past, ranging from improv-ing the performance of algorithms to incorporating more re-sources from heterogeneous data sources [1]. However, col-laborative filtering research still assumes that there are ex-plicit positive (high rating) and negative (low rating) exam-ples and the goal is to distinguish between those two, which is different from the one-class case studied in this paper. Missing values (e.g., ratings) are a common issue in CF. In [2] and [12], the authors discuss the issue of modeling the distribution of missing values. Both approaches cannot handle cases in which no negative examples are given.
In the binary case, each example is either positive or nega-tive. Das et al. [7] describe a news recommendation problem in which clicks on news stories are interpreted as positive ex-amples, and  X  X on-clicks X  as negative examples. The authors compare some practical methods on this large scale binary CF problem, which is close to the one-class case. The KDD Cup 2007 task was a  X  X ho rated What X  prediction problem based on the Netflix Prize dataset. We included a similar prediction problem in our experimental study. The winning team [10] proposed a hybrid method that combined SVD and popularity using binary training data.

Our work also has some commonalities with the class im-balance literature. Class-imbalance is typically studied for classification tasks. The two strategies that are commonly used to solve the problem are sampling to re-balance the data [3, 11] and cost-sensitive learning [8, 19]. A compari-son of the two strategies can be found in [14].
We studied the question which matrix decomposition tech-niques work well on large-scale one-class collaborative fil-tering techniques. This question can be decomposed into two major parts: Which techniques have a good predic-tive performance, and how well do the techniques scale up. Our baseline was a popular probabilistic method, which we compared to low-rank approximation and maximum-margin methods. We recently demonstrated that weighting schemes are very valuable in this area, so we were also concerned with the question of how to incorporate the ability for weighting the unknown parts of a matrix.

The results without the scalability aspect were close to our expectation: The maximum-margin method performed very well, closely followed by ALS. The only surprise was the poor performance of pLSI. Weighting the gaps clearly helped to further improve the results for both MMMF and ALS. To the best of our knowledge, we ran the first experiments with a weighted MMMF variant. As another theoretical contribution, we proved that there is an exact, yet scalable updating mechanism for ALS for large-scale data sets that allows to weight all the gaps, as long as the corresponding weight matrix has a good or exact low-rank approximation. In contrast, at a large scale, MMMF can only make use of weights via a subsampling / ensemble technique, because the hinge loss is too complex to allow for adaptations similar to those we incorporated into ALS. We empirically showed that the subsampling work-around does not work as well as using the full set of weighted negatives, so MMMF lost the edge and the novel GALS algorithm excelled as the method of choice in our large-scale experiments.

In our future research, we plan to experiment with more complex weighting schemes and to learn such schemes iter-atively. [1] G. Adomavicius and A. Tuzhilin. Toward the next [2] Y. Azar, A. Fiat, A. R. Karlin, F. McSherry, and [3] G. E. A. P. A. Batista, R. C. Prati, and M. C. [4] J. S. Breese, D. Heckerman, and C. M. Kadie.
 [5] L. Breiman. Bagging predictors. Machine Learning , [6] D. Coppersmith and S. Winograd. Matrix [7] A. Das, M. Datar, A. Garg, and S. Rajaram. Google [8] C. Drummond and R. Holte. C4.5, class imbalance, [9] T. Hofmann. Latent semantic models for collaborative [10] M. Kurucz, A. A. Benczur, T. Kiss, I. Nagy, A. Szabo, [11] X.-Y. Liu, J. Wu, and Z.-H. Zhou. Exploratory [12] B. Marlin, R. Zemel, S. Roweis, and M. Slaney. [13] R. Pan, Y. Zhou, B. Cao, N. N. Liu, R. Lukose, [14] B. Raskutti and A. Kowalczyk. Extreme re-balancing [15] J. D. M. Rennie and N. Srebro. Fast maximum margin [16] N. Srebro and T. Jaakkola. Weighted low-rank [17] N. Srebro, J. D. M. Rennie, and T. Jaakkola.
 [18] J. S. Vitter. Faster methods for random sampling. [19] G. M. Weiss. Mining with rarity: a unifying [20] C. V. Yehuda Koren, Yifan Hu. Collaborative filtering [21] Y. Zhou, D. Wilkinson, R. Schreiber, and R. Pan.
We start from the objective function and break it down into parts. For notational simplicity and brevity we omit some arguments if clear from the context, and define L  X  , A through C , A 0 through C 0 , and q r inline.
 We now simplify the row-wise unregularized loss L  X  ( X r exploiting that R r,i = 1 and W r,i = 1 whenever i  X  M (non-missing) and R r,i = 0, otherwise. Then we decompose it into a (mostly) global part A and a row-dependent B : After this decomposition, we are interested in the derivatives for all components X r,c of vector X r to set them to 0. This we do in the form of a linear equation system, where each component (value of c  X  X  1 ,...,d } ) corresponds to another line. The equation system will be of the form ( A 0 + B 0 C ) X T r = q r , where A 0 X T r through C 0 X T r correspond to the partial derivatives of A through C . We start with A  X  X 
Based on the inner sum, we define | D | (the rank of the weight matrix W ) two-dimensional matrices b A (1) ,..., b We can now define A 0 by weighting the | D | matrices accord-ing to the row-specific weight vector U r : We already dropped the factor of 2 that is shared by B C , and q r and cancels out later. The partial derivative of B is:  X  X  After removing factor of 2, = X The matrix form to be plugged into the equation system is: The regularization part C can be rewritten as
C = X A trivial multiplication of U and V leads to non-linear costs, so we instead decompose the derivative and compute the corresponding matrix C 0 as Now we can plug in in the partial results used by Algorithm 2 and confirm that ( A 0 + B 0 + C 0 )  X  1 q r in fact solves the linear equation system we get when setting all partial derivatives to 0: Due to the regularization term, the matrix inversion is al-ways well-defined. It can easily be seen that the overall optimization problem is still convex, so Algorithm 2 com-putes the global optimum for each X r , and hence for X . q.e.d.
