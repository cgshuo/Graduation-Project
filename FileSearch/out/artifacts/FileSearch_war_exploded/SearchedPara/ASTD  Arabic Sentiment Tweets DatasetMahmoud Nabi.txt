 Arabic sentiment analysis work is gaining large at-tention nowadays. This is mainly due to the need of a product that can utilize natural language pro-cessing technology to track and analyze the public mood through processing social data streams. This calls for using standard social sentiment analysis datasets. In this work we present ASTD ( A rabic S entiment T weets D ataset) an Arabic social sen-timent analysis dataset gathered from Twitter. We discuss our method for gathering and annotating the dataset, and present its properties and statis-tics through the following tasks: (1) 4 way sen-timent classification (2) Two stage class classifi-cation; and (3) sentiment lexicon generation. The contributions in this work can be summarized as: 1. We present an Arabic social dataset of about 2. We investigate the properties and the statis-3. We present a set of benchmark experiments 4. We make the dataset and the used experi-The detection of user sentiment in texts is a re-cent task in natural language processing. This task is gaining a large attention nowadays due to the explosion in the number of social media plat-forms and the number of people using them. Some Arabic sentiment datasets have been collected (see Table 1). (Abdul-Mageed et al., 2014) pro-posed the SAMAR system that perform subjectiv-ity and sentiment analysis for Arabic social media where they used different multi-domain datasets collected from Wikipedia TalkPages, Twitter, and Arabic forums. (Aly and Atiya, 2013) proposed LABR, a book reviews dataset collected from GoodReads. (Rushdi-Saleh et al., 2011) presented an Arabic corpus of 500 movie reviews collected from different web pages. (Refaee and Rieser, 2014) presented a manually annotated Arabic so-cial corpus of 8,868 Tweets and they discussed the method of collecting and annotating the cor-pus. (Abdul-Mageed and Diab, 2014) proposed SANA, a large-scale, multi-domain, and multi-genre Arabic sentiment lexicon. The lexicon au-tomatically extends two manually collected lex-icons HUDA (4,905 entries) and SIFFAT (3,325 entries). (Ibrahim et al., 2015) built a manual cor-pus of 1,000 tweets and 1000 microblogs and used it for sentiment analysis task. (ElSahar and El-Beltagy, 2015) introduced four datasets in their work to build a multi-domain Arabic resource (sentiment lexicon). (Nabil et al., 2014) and (El-Sahar and El-Beltagy, 2015) proposed a semi-supervised method for building a sentiment lexi-con that can be used efficiently in sentiment anal-ysis. Figure 1: Tweets Histogram : The number of tweets for each class category. Notice the un-balance in the dataset, with much more objective tweets than positive, negative, or mixed. 3.1 Dataset Collection We have collected over 84,000 Arabic tweets. We downloaded the tweets over two stages: In the most active Egyptian Twitter accounts. This gave us a list of 30 names. We got the recent tweets of these accounts till November 2013, and this amounted to about 36,000. In the second stage we trending hash tags in Egypt. We got about 2500 distinct hash tags which are used again to down-load the tweets. We ended up obtaining about 48,000 tweets. After filtering out the non-Arabic tweets, and performing some pre-processing steps to clean up unwanted content like HTML, we ended up with 54,716 Arabic tweets. 3.2 Dataset Annotation We used Amazon Mechanical Turk ( AMT ) ser-vice to manually annotate the data set through an Total Number of conflict free tweets 10,006 Figure 3: Feature Counts. Number of unigram, bigram, and trigram features per each class cate-gory.
 subjective positive, subjective negative, and sub-jective mixed. The tweets that are assigned the same rating from at least two raters were consid-ered as conflict free and are accepted for further processing. Other tweets that have conflict from all the three raters were ignored. We were able to label around 10k tweets. Table 2 summarizes the statistics for the conflict free ratings tweets. 3.3 Dataset Properties The dataset has 10,006 tweets. Table 2 contains some statistics gathered from the dataset. The his-togram of the class categories is shown in Fig. 1, review on the middle column, and the rating shown in right. where we notice the unbalance in the dataset, with much more objective tweets than positive, nega-tive, or mixed. Fig. 2 shows some examples from the data set, including positive, negative, mixed ,and objective tweets. In this work, we performed a standard partition-ing to the dataset then we used it for the sentiment polarity classification problem using a wide range of standard classifiers to perform 4 way sentiment classification. 4.1 Data Preparation We partitioned the data into training, validation and test sets. The validation set is used as a mini-test for evaluating and comparing models for pos-sible inclusion into the final model. The ratio of the data among these three sets is 6:2:2 respec-tively.

Fig. 4 and Table 4 show the number of tweets for each class category in the training, test, and validation sets for both the balanced and unbal-anced settings. Fig. 3 also shows the number of n-gram counts for both the balanced and unbal-anced settings. 4.2 4 Way Sentiment Classification We explore using the dataset for the same set of ex-periments presented in (Nabil et al., 2014) by ap-Figure 4: Dataset Splits. Number of tweets for each class category for training, validation, and test sets for both balanced and unbalanced set-tings. plying a wide range of standard classifiers on the balanced and unbalanced settings of the dataset. The experiment is applied on both the token counts and the Tf-Idf (token frequency inverse document frequency) of the n-grams. Also we used the same accuracy measures for evaluating our results which are the weighted accuracy and the weighted F1 measure.

Table 5 shows the result for each classifier after training on both the training and the validation set and evaluating the result on the test set (i.e. the train:test ratio is 8:2). Each cell has numbers that represent weighted accuracy / F1 measure where the evaluation is performed on the test set. All the experiments were implemented in Python us-formed on a machine with Intel X  Core X  i5-4440 part shows the number of features.
 CPU @ 3.10GHz (4 cores) and 16GB of RAM.

From table 5 we can make the following obser-vations: 1. The 4 way sentiment classification task is 2. The balanced set is more challenging than 3. SVM is the best classifier and this is consis-In this paper we presented ASTD an Arabic social sentiment analysis dataset gathered from twitter. We presented our method of collecting and anno-tating the dataset. We investigated the properties and the statistics of the dataset and performed two set of benchmark experiments: (1) 4 way senti-ment classification; (2) Two stage classification. Also we constructed a seed sentiment lexicon from the dataset. Our planned next steps include: 1. Increase the size of the dataset. 2. Discuss the issue of unbalanced dataset and 3. Extend the generated method either auto-This work has been funded by ITIDA X  X  ITAC project number CFP-65.
