 Recommendation systems have become increasingly popular in recent years and are Facebook 3 . Amazon.com recommends specific products that customers may be provide personalized recommendations for products that are aligned with users X  tastes. 
There are two types of users in recommendation systems: existing users and new users. Existing users are those who already have historical data attached to them, and new users are those who have not previously been evaluated in the recommendation system. However, we can also categorize all items as existing items or new items by considering whether the item has received ratings. Thus, there are four partitions in a recommendation system, consisting of two types of users and two types of items. Fig. 1 illustrates these partitions. 
Partition 1 consists of the recommendations of existing items to existing users and represents the standard situation in recommendation systems. Many Collaborative includes recommendations of new items to existing users. Content-based Filtering This approach can recommend items if the content information of the items is available [3], for example, the actors, genre and release year of a movie or the text in a book. Partition 3 is an important part of recommendation systems and represents the situation of recommendation of existing items to new users. To survive, recommendation systems always need to attr act new users as customers. The system should indicate the taste of a new user within a short time. New users may continue to use the system if they find what they are looking for in the recommendations offered paper. Partition 4 indicates recommendations of new items to new users, which is items and users. 
This situation with new users and new items is referred to as the cold-start problem [12]. A natural method for solving the cold-start problem to elicit new users X  information by having them answer interview questions [9]. The system characterizes recommendations in the future. The interview process should not be time-consuming. Customers will become impatient and leave the system if they are presented with too many interview questions. Furthermore, the system should construct a rough profile measurements. They build the best decision tree in the interview process through the responses to just one question. The decision tree method locally chooses the interview question and groups the users in the nodes. The method only considers the behavior of users in certain nodes. We argue that this method should be used to globally build the framework of the interview process. 2.1 Collaborative Filtering recommendation system, called Tasestry [6]. The system was designed to recommend documents to prevent users from becoming inundated by a huge stream of documents. In recent years, many studies of recommendation systems have focused on collaborative filtering approaches. This method can identify the new user-item association by analyzing the relationships between both users and items. The two primary types of collaborative filtering methods are memory-based [2] and model-based [13]. Memory-based methods compute the relationships between items and ratings by the same user of neighboring items. Two items are considered to be neighbors if they receive similar ratings by users. Model-based methods are an large datasets effectively and has good prediction performance. Matrix Factorization dimension vector to represent each user and item and learns the vectors by user-item rating data. 2.2 Cold-Start Collaborative Filtering A recommendation system knows nothing about the new users because there is no information available. The most direct way to learn the preferences of new users is to strategies for finding the best items through interview questions. The GroupLens team [9, 11] provides a balanced strategy that considers both the popularity and the entropy of movies based on the selection of interview questions. In a decision tree, each node is an interview question, and users are dir ected to one of the child nodes according by decision tree based on the interview question s. The decision is created and optimized questions. Users have three choices X  X  X ike, X   X  X nlike, X  or  X  X nknown X  X  X or their response to the current question. Different responses to the current question result in different following questions. New users are characterized after answering the and Movielens databases. We first group the training users by observed the rating data. Because the real-world data are sparse, and no user provides ratings for all of the items, we group the users to find virtual users who have similar rating behaviors to the users in same group. When virtual users according to their responses. Thus, the system can predict the new users X  tastes based on the similar virtual users. Our system X  X  flowchart is presented in Fig. 2. interview questions by fitting the latent user features. 3.1 Low-Rank Matrix Factorization Matrix Factorization maps users and items to the latent factor space of dimensionality R can be approximated by the product of the user matrix  X  X  X   X  X  X  X  and item matrix  X  X  X   X  X  X  X  , which contain M user feature vectors and N item feature vectors, respectively. This model is closely related to singular value decomposition (SVD), which is a well-known technique in information retrieval. The system learns the models by fitting the observed ratings to predict the unknown ratings. It should avoid overfitting the (a) System Interview Concept (b) System Flowchart all observed ratings and  X  is a constant that controls the extent of the regularization. 3.2 Latent Factor Clustering The goal of grouping users is to find several cliques that can represent different tastes of users. Each user has his or her own attributes in the features vector, as described in the in previous section. Thus, we can group users based on these features. The K-used. We apply the K-Means Clustering method to group the user features vectors in the training data by minimizing the within-cluster sum of squares, which is define as follows: where  X   X  is the centroid of the cluster  X   X  and  X  is the number of clusters. 3.3 Question Selection Process We present an optimization process to ensure that the questions we select can identify the new users X  tastes. We first define an objective function: error if we use  X  as the interview questions. Thus, we can calculate the error for each  X  after asking the interview questions in  X  . We define  X   X   X  X  X , X  as the following: where K denotes the number of nearest neighbors and  X   X  is one of cluster centers that approaches the user  X   X  . We use the average of the choices of the cluster centers by the K-Nearest Neighbor (KNN) method to prevent overfitting. Next, we calculate the follows: equals 1 if  X   X  X  X   X  X  and 0 otherwise. It is a constant that indicates whether the user  X   X  questions because it has minimum error when this item and the previous item we select are both interview questions. The following equation shows how we choose the interview questions: following section describes how we select the items in  X  . 3.4 Question Selection Strategies items as popular items. The advantage of choosing the most popular items to be interview questions is that new users usually provide answers. However, popular by their responses to an item that nearly everyone liked. Users often give a high rating controversial the item is. Prior works [10] define the entropy of item to indicate how controversial it is, as defined by the following equation: item  X   X  has been rated by 1000 people, while there are a total of 2000 people in the data set. In the 1000 ratings data, there are 100 ratings equal to 1, 100 ratings equal to  X  ,1 X  X  X 5 are 100/1000, 100/1000, 200/1000, 300/1000, 300/1000, respectively. ratings having the same score leads to the minimum entropy. 
Popular items usually are not controversial, while items that have widely spread entropy and the log of popularity. It takes the log of popularity because the number of ratings of items is an exponential distribution. Popularity will dominate the score if it does not take the log. 4.1 Data Set We used the Movielens dataset for our experiment, which is a public dataset that can be downloaded from GroupLens 4 website. The data set contains a total of 1,000,209 rating data items from 6,040 users on 3,951 movies. 
We split the dataset into two separate sets: the training set and the testing set. The training set contains 75% of all users, and the testing set contains 25% of the users. In performance after the interview process. The system characterizes each new user after mentioned previously is calculated to evaluate the performance. 4.2 Evaluation Root mean square error (RMSE) measurement has been widely used to evaluate the performance of collaborative filtering algorithm. The RMSE formula is defined as follows:  X   X  is the value predicted by models. The smaller value of RMSE means better performance of the model because the pred iction ratings are approaching the ground-truth rating. 4.3 Comparisons Because MFK methods predict the rating by finding the neighbors of feature clusters according to the responses to interview questions, we compare two types of baseline to our approach. The first type of baseline is the method of predicting ratings. We use neighbor cluster according to the response.  X  Global Average:  X  User Average:  X  Item Average: 
Table 1 shows the performance of our approach compared with baselines. Note that  X  X  X   X  X  X  X  X  X  X  X  X  X  in this case is the performance we show for seven interview seven interview questions. 
The following strategies are our approaches, which combine the selection criteria and optimization processes we described in Section 3. 
In Table 2, the performance of the popularity strategy shows a substantial improvement when we show seven questions. However, the entropy strategy does not improve when the number of shown questions increases. Fig. 4 shows that more than 90% of users do not give any response to interview questions that have high entropy scores. For almost all the interview questions, the system cannot indicate users X  tastes correctly through the  X  X nknown X  response. The balance method shows better performance than the popularity methods. This finding indicates that considering the entropy of an item is a way to improve the performance. In our approach, we consider both the popularity and the entropy of items, and we also implement an optimization process to ensure that we obtain the best performance compared with other strategies. 4.4 Impact of Parameters Fig. 5 and Fig. 6 show the different numbers of neighbors in certain clusters. We will discuss the effect of the number of clusters and the number of user neighbors selected by their response to interview questions. observe good performance when we set 20% or 30% of the number of clusters as the the number of clusters, indicating that the prediction of ratings is based on the average of all the clusters. Thus, the RMSEs are similar. When we consider only the smaller number of neighbors for the new users, we obtain bad performance because we consider a small amount of information. reveals that we obtain better performance when we set larger numbers of clusters. In large numbers of clusters, users can find their neighbors more accurately because there are more different numerical responses to the interview questions. In this paper, we proposed the MFK algorithm, which combines user feature selection and interview question optimization to address the new user problem. We can the objective functions. We first use the feature extraction model to extract the latent values in user-item rating data and indicate the existing users X  tastes. After clustering the user features, we can ensure that the users in the same cluster are similar. We can indicate the new users X  tastes according to their responses to the interview questions, which we learn through an optimization process. 
