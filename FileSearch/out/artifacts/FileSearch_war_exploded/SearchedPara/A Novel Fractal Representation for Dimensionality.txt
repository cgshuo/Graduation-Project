 The ultimate goal to improve time series mining tasks is both speedup and increasing accuracy. Unfortunately, there is a tradeoff between accuracy and computational cost; for example, Euclidean distance is very fast, but the accuracy may be low when comparing with other similarity measures. On the other hand, Dynamic Time Warping (DTW) distance measure [1] is relatively slow, but it has been widely computation time, time complexity can be reduced by combining DTW distance with other algorithms, especially bounding function [2]. High computational cost for DTW distance is clearly inappropriate for large time series data; therefore, a recent Compression-Based Dissimilarity Measure [3] has been proposed for similarity measure between two time series data based on file compression, which focuses mainly on large time series data. However, CDM is I/O bounded, which affects the computational time. 
Alternatively, the speedup has been improved through indexing, dimensionality reduction/data representation, among many others. For large time series data, the current dimensionality reduction techniques cannot reduce the dimension by a large margin without losing their global characteristics. Most of these methods are used for pruning off time series data that are not the answer, such as Symbolic Aggregate Approximation (SAX) [4], and clipped data representation [5]. 
The ideal case for dimensionality reduction is to represent time series data with only one dimension, while preserving original data X  X  characteristics. Once these resulted dimensions are sorted, we can compare two time series using constant time. Consequently, this research work focuses on reducing the number of dimensions of large time series data. 
In this work, we introduce a novel representation, Fractal Representation, for large time series data based on fractal dimension, using merely three real values to represent the internal structure of a time series data. In our experiment, Fractal Representation can accomplish a large speedup in a wide range of data mining tasks. In addition, we demonstrate the superiority of our proposed method over the well-known distance measures, i.e., Euclidean distance, DTW distance, and CDM, on classification problems. The results have demonstrated that our representation can Representation can effectively represent global characteristics of the data. 
The rest of this paper is organized as follows. In section 2, we review related work on time series mining and dimensionality reduction techniques. Section 3 describes background knowledge of the fractal dimension. After that, our proposed Fractal Representation is introduced in section 4. Section 5 contains our experimental evaluation and discussion, and, finally, section 6 draws some conclusions and gives suggestions for future work. However, the dimension, i.e., Fractal dimension [8], can be a real value which considers the local structure of the data by seeking self similarity within. Both fractal theory and fractal dimension are based on chaos theory, which is a non linear and deterministic dynamic system. Fractal theory X  X  key characteristic is the self similarity; nesting of structure at all scales. To calculate the fractal dimension, many techniques, e.g., compass dimension, box-counting dimension, information dimension, and correlation dimension, have been proposed. Generally, framework of fractal dimension is commonly calculated iteratively in different levels of local structure, as shown in Fig. 1. 
Concept of fractal dimension is not commonly applied for the dimensionality reduction on data mining tasks. More specifically, fractal dimension is typically used for determining the dimension of a picture. Some research applies fractal dimension for data points and time series data, i.e., Barbara and Chen [6] applied fractal dimension for data points classification, and Xiao et al. [7] used fractal dimension to distinguish the classes very effectively. 2.1 Compass Dimension The idea of compass dimension [8] is to estimate the dimension by seeking self data based on distance. For example, in the first step, the compass segment with length s is assigned, and this compass segment traverses from the starting position to the ending position of the input data. The overall image perimeter length is then estimated from the compass function. Next, a new compass segment X  X  length is assigned as half of the previous length, and the compass function calculation is repeated. Each coordinate of the compass segment and the compass function output is compass dimension ( D c ), shown in equation (1). Where s is the compass length, and N ( s ) is the sum of the compass segments X  lengths s from any starting position to the ending position. 2.2 Correlation Dimension Correlation dimension [8, 9], proposed by Grassberger and Procaccia, measures the self-similarity by calculating correlation am ong all data points in space. Correlation of fixed point and every other point. When the distance is less than a threshold distance number of a pair of data points, which has distance less than the threshold distance r . This correlation integral is estimated by the following equation. where N is the total number of points, x distance. ) ( x  X  is the Heaviside step function, and is defined in equation (3). 
To calculate the correlation dimension, the initial threshold distance r is first then r is set to half of its previous value. Correlation integral is repeatedly calculated. axis) is plotted on a log-log diagram. The slope of the best-fitted line is the correlation dimension ( D C2 ), defined by an equation below. real values to represent each time series sequence efficiently, according to our proposed fractal dimension approaches below. 
Although fractal dimension can significantly reduce dimensions of time series, a bad set of parameters does affect the accuracy. Hence, our proposed work also includes automatic parameter tuning, which is demonstrated to achieve higher accuracy than those of existing methods, especially for z -normalized large time series data. 3.1 Equi-width Compass Dimension Equi-width compass dimension is extended from the original compass dimension to be applied specifically to time series data. We divide a sequence on x -axis into equal widths, called a time slice, and then traverse a line within each time slice. As shown time series is equally divided to 10 periods, and then travel along from period 1 to 10. The compass function is based on y -axis values only, and the time slice in each iteration is assigned accord ing to equation (5). current iteration, and L is length of time series data. 
From equation (5), in iteration 1 ( k = 1), the time slice is initialized by log 2 of time series length because large time slice leads to an inaccurate approximation. The time values of compass function and time slice are then plotted on graph, and then the equi-width compass dimension is determined by the slope of the best-fitted line of the points in the log-log scale, shown in equation (1). 3.2 Equi-length Compass Dimension Equi-length compass dimension resembles the original compass dimension. A line around time series. Total summation of all the compass segment length is a compass for each iteration s ( k ) of equi-length compass dimension is shown in equation (6). data. 
From equation (6), we use the difference between max( ts ) and min( ts ) value to initialize the compass segment. For each iteration, s ( k ) is divided into half of previous length. When every data point of the time slice are traversed in any particular s ( k ), it terminates. We obtain equi-length compass dimension from the slope of the best-fitted line of the points in the log-log scale, as shown in equation (1). 3.3 Correlation Dimension Correlation dimension for time series data resembles the original method. We use point, and then the threshold distance r is reduced to half. Until correlation integral is correlation dimension is shown in equation (7). where r ( k ) is a threshold distance of each iteration k , max( ts ) is maximum value of a time series data, and min( ts ) is minimum value of a time series data. Finally, our proposed method are three real values to represent a time series called Fractal Representation , which also give a new identity to the time series data, with a massive reduction. Moreover, our proposed method is automatic parameter. classification problem in terms of accuracy and computation time. We compare our proposed method with Euclidean Distance, DTW distance, and CDM. 4.1 Datasets In our experiment, we build our datasets by generating time series data from the benchmark datasets of the UCR Time Series Data Mining Archive [10]. We test on both long and short time series data. Note that all datasets are z-normalized. A total of eight datasets are described in Table 1. 4.2 Experiment We evaluate our proposed method, Fractal Representation, on classification problem, using 1-nearest-neighbor classifier with leaving-one-out technique in terms of both accuracy and running time, and then compare our algorithm with Euclidean distance, DTW distance, and CDM. Results from 8 datasets are shown in Table 2. 
From Table 2, Fractal Representation outperforms other methods in all datasets in speedup magnitude in wall clock time, especially when comparing with DTW. For large time series (datasets 1-6), our Fractal Representation performs well in many cases in terms of the accuracy. In dataset 3, we get the accuracy less than DTW distance, but our running time is almost 90,000 times faster. For dataset 4, our accuracy is not high, structures very well. In general, DTW outperforms our Fractal Representation when both accuracy and time of short time series perform well in all cases. In addition, CDM does not seem to work very well here since CDM generally works well with unnormalized data, whereas every dataset here is z -normalized. Amplitude of each time directly affects and degrades the classification results. Our Fractal Representation is a novel dimensionality reduction technique that does not need extra pruning of unnecessary data, providing great speedup for the mining tasks because of the large reduction in the number of dimensions down to only three Fractal Representation has demonstrated to be both effective and efficient for time series data under automatic parameter selection. For our future work, if we could speedup to any data mining tasks. MRG5080246). 
