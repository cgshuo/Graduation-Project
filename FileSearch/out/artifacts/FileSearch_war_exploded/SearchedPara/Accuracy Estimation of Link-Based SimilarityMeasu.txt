 In Web Age, graphs are ubiquitous, such as the web, social networks, biblio-graphic graphs and entity-relationship graphs, calling for solutions to measure similarity between nodes on graphs. Measu res of similarity between objects play significant role in many graph based applications: recommendation systems [3], link prediction [9], fraud detection [7], and collaborative filtering [1]. Many link-based similarity measures have been proposed, such as Personalized PageRank (PPR) [5], SimRank (SR) [4], Hitting time [13] and Commute time [12]. Among them, both PPR and SR have emerged as the most popular and influential link-based similarity measures due to their effectiveness and solid theoretical foundation.

Although iterative similarity scores of SR and PPR are convergent [4][5], in practice the corresponding computations naturally involve performing a finite number of iterations. SR and PPR computations are time-consuming. With in-creasing of iterations, the computations incur significant overhead, especially on a large graph. In [10], given a graph which consists of 10,000 nodes, Lizorkin et al run the original iterative SR on a 2.1GHz Intel Pentium processor with 1Gb RAM. After 5 iterations, it took 46 hours and 5 minutes for the algorithm to obtain all node pairs similarities.

However, the existing upper bounds are too coarse to be useful in general. It is advised that choosing the decay factor value c = 0.8 and the total number of iterations K = 5 to compute iterative SR similarity in research [4], and, according to proposition 1 in [10], the corresponding difference between theoretical and computed similarity scores is 0.26 . Bas ed on the lemma 2 in [14], the difference between theoretical and iterative PPR scores is also 0.26 when c = 0.8 and the total number of iterations K = 5. Obviously, the existing upper bounds of PPR and SR are relatively large because the interval of the theoretical scores is [0, 1].
Accordingly, an accurate difference bet ween iterative similarity scores and theoretical ones remains an open question. The ideal solution is that computing similarity within the minimum number of iterations is sufficient to guarantee a desired accuracy.

At i th iteration, if the iterative score is P i and the difference between theoret-ical and computed similarity score is P  X  P i  X   X  i , then the corresponding upper bound is P i +  X  i , and vice versa. Based on this relationship, for convenience we abuse terminology: the difference and upper bound are considered to be same in the paper. The intended meaning sh ould be clear from the context.

In summary, it is significance that designing accurate and tight upper bounds in theory and practice. Given a desired a ccuracy, we terminate the iteration as soon as possible to save overhead by leveraging tight upper bound. Furthermore we can accelerate graph-based query such as link-based similarity join [14] and top-k similarity search by utilizing tight upper bound.

We say that difference between iterative s imilarity scores and theoretical ones is good if the following properties hold: 1. Accurate: the difference is very close to the true difference and is not coarse. 2. Fast: we can efficiently obtain the difference. Our differences are accura te and can be efficiently obtained.
In the paper we focus on designing accurate and tight upper bounds of PPR and SR (sect. 3). Our upper bounds are designed based on following human intuition:  X  X he smaller the difference between the two consecutive iteration step results is, the smaller the difference between iterative similarity scores and the-oretical ones is X . We can efficiently obtain the bounds without spending extra overhead. Furthermore, we tailor our upper bounds to accelerate the top-k sim-ilar nodes query (sect. 4). At the experiments, we show that our upper bounds significantly outperform the state-of-the-art upper bounds (sect. 5). Given a directed graph G =( V,E ) where nodes in V represent objects and edges in E represent relationships between objects. For any v  X  V ,Set I ( v )and O ( v ) denote in-neighbors and out-neighbors of v , respectively. I i ( v )or O j ( v )isan
Like PageRank, PPR is the steady-state probabilities of random walks; at each step, a surfer random walk along out link with probability c, and with probability 1-c jump back to the random node of the set of preferred nodes. If the preferred set contains only one node, PPR actually is RWR. RWR is a special case of PPR. In the paper we only consider the situation that the preferred set contains one node (query node).

According to [5][14], the equation of PPR is where  X  is the unidirectional path from q to v :( q,w 1 ,...,w n ,v ), l (  X  )isthe the  X  . r ( q,v ) is the similarity between q and v from the q  X  X  personalized view. In practice is used to estimate r ( q,v ).

SR measures similarity of nodes is based on following human intuition:  X  X wo objects are similar if they are related to similar objects X  [4]. So SR score ( a,b ) actually is the average SR score between in-neighbors of a and in-neighbors of b :
Correspondingly, as showed in [4] the iterative formula is: ( k =0 , 1 , 2 , ... ).

From the view of random surfer model, the SR score measures how soon two random surfers are expected to meet at the same node if they started at nodes a and b and randomly walked the graph backwards [4]. According to [4], the formula of SR can be written as follows: where  X  is a tour (paths may have cycles) along which two random suffers walk backwards starting at nodes a and b respectively until they first and only first meet at any node x , l (  X  ) is the length of tour  X  .

Based on [16], the corresponding iterative formula is: The existing upper bounds of PPR and SR are too coarse to be useful in general. In this section we introduce novel upper bounds of PPR and SR. 3.1 Bounding of PPR By walking one step beforehand from node q , the formula (1) can be transformed as: Similar, we have: lowing theorem: Theorem 1. the difference between theoretical and iterative PPR scores is Proof. According to (2), r m +1 ( q,v )  X  r m ( q,v )=(1  X  c ) t : q  X  v Thus Likewise, r m + k ( a, b )  X  r m + k  X  1 ( a, b )  X  c k  X  m . Therefore
Theorem 1 gives the lower and upper bounds of PPR at m th iteration: r The lemma 2 in [14] gives an upper bound of PPR, c m +1 ,at m th iteration. The following proposition states our upper bound is better than that in [14]. Proposition 1. At m th iteration,  X  m c 1  X  c  X  c m +1 .
 Proof. Proposition 1 guarantees that our upper bound is superior to that in [14] in theory. Obviously, our upper bound decreases drastically with increasing of it-erations due to  X  m c 1  X  c  X  c m +1 . 3.2 Bounding of SR lowing theorem: Theorem 2. the difference between theoretical and iterative SR scores is Proof. Based on e.q.(4), as  X  m = max { s m ( a, b )  X  s m  X  1 ( a, b ) } (  X  a, b  X  V ). Accordingly, likewise: s m + k ( a, b )  X  s m + k  X  1 ( a, b )  X  c k  X  m
On the other hand, according to e.q.(6)(5), s m +1 ( a, b )  X  s m ( a, b ) =
Theorem 2 gives the lower and upper bounds of SR at m th iteration. As soon When m  X  3, the difference is largely less than the difference, c m +1 ,in[10] difference in order to obtain better result. 3.3 Obtain Upper Bounds We do not need to spend extra overhead to obtain our upper bounds by incre-mental updating similarity scores.

E.q. (2) can be written as
Likewise, e.q. (6) can be transformed as
The above two equations say that the current similarity score is the sum of previous score and the increment. At each iteration we actually compute the increment to obtain similarity score. And the  X  m in e.q.(8) (or e.q.(9)) is the maximal increment. Optimization computation of PPR in [18] and SR in [16] are based on e.q. (10) and e.q. (11) respectively. Consequently, we do not need to spend extra overhead to obtain upper bounds. By leveraging tight upper bound, we terminate the iteration as soon as possible to reduce overhead. Furthermore, we al so can accelerate graph-based query by utilizing more tight upper bound. In this section, we demonstrate effectiveness of our novel upper bounds in the scenario of top-k similar nodes query.
In the paper, P denote as PPR or SR similarity score. Observe from e.q.(2) and (5) that P(a,b) involves an infinite number of random walks. Consequently, it is infeasible to achieve accurate P(a,b). It is effective to compute P w ( a, b ) instead: where controls the accuracy of P w ( a, b ) in estimating P ( a, b ), and w is the minimum value that satisfies the inequation.

Algorithm 1. Top-k similar nodes query
Problem statement (Top-k similar nodes query) Given a query node q ,a number k and ,theresultofquery, the top-k similarity nodes of q ,is T k ( q )= { t 1 ,...,t k graph G ( V ).

The general framework of top-k similar nodes query. Starting at a query node q , we do a breadth-first traverse to visit remaining nodes. At m th iteration, when a node v is visited, we compute P m ( q,v ). After m th iteration, we obtain its upper bound value P m ( q,v )and m ( m is the difference between k nodes with the highest scores of lower bounds. Let T k be the k th largest score. We terminate the query and obtain the final result of the top-k query if one of following conditions is true:  X  T k  X  P m ( q,t )(  X  t  X  V ( G ( V )) /T k ( q )).

With help of upper bound, we can obtain top-k nodes via local expansion around the query node. The local top-k similarity search method avoids accessing the whole graph.

The local top-k similar nodes search method effectively handle similarity search because it does not need to acces s the whole graph, especially, when the graph is very large. While, the upper bounds, discussed in section 3, are obtained based on the whole global information on graphs. Therefore, the up-per bounds can not directly be applied to the top-k query when the only local information of the query node is available. Furthermore, we tailor upper bounds based on theory mentioned in section 3.

We customize upper bounds based on the local information. At each iteration, we obtain the similarity scores between the query node and accessed nodes, which belong to the neighborhood of the query node. The average difference between the two consecutive iteration s tep results can be used to estimate  X  m in e.q.(8)(9). As the result, we obtain variants of the upper bounds based on the local information. Although the variants of the upper bounds can not be proved to be accurate in theory, they are reasonable: the average difference is very close to the true difference due to principle of locality.

Algorithm 1 is top-k similar nodes query method based on PPR. Top-k method based on SR is similar to algorithm 1 and is not listed in the paper.
It is worth to mention that top-k query is exploited to demonstrate effective-ness of the upper bounds. Top-k query algorithm is not our target in the paper, although our algorithm is concise and efficient. From above analysis, the upper bounds play a key role in the algorithm. The upper bounds accelerate the query speed and avoid accessing the whole graph. We implemented all experiments on a PC with i 3  X  550 CPU, 4G main memory, running windows 7 operating system. All codes are written in C++.

The data sets used in the experiments are showed in table 1. Cora 1 is a citation graph. Graphs FaceBook, Hamster (social graph) and Subelj (E-road network) can be visited at KONECT 2 . The remaining data can be visited at SNAP 3 .For the first 5 data sets in table 1, we use their maximum graph components instead of the original graphs (The corresponding informations in table 1 are that of their maximum components).

The state-of-the-art upper bounds, PPR upper bound in [14] and SR upper bound in [10], are used to be baselines to compare with our upper bounds in experiments.

When  X  m is estimated by the average of to p 100 largest difference between the two consecutive iteration step results, the corresponding upper bounds are denoted as approximate and achieve a very high precision (  X  99%).

Figures 1-7 show the results of our accurate and approximate upper bounds compared with the baselines on 5 real data sets. When m  X  3, our SR difference is largely less than the baseline although the rate of SR convergence is different on these different real data sets. Our a pproximate PPR upper bound is superior to the baseline. And our accurate PPR difference is less than the baseline in some data sets. In worst case, our accurate PPR difference equals the baseline.
Then we test efficiency of our bounds in the scenario of top-k node query on two large real data (figures 8-9). All the top-k queries are repeated 200 times and the reported values are the average values. Our SR bound is 1.5-2.3 times faster than the baseline while it achieves a high precision (  X  96%). Our PPR bound is 200-400 times faster than the baseline while it achieves a very high precision (  X  97%).

In a nut shell, our bounds significantly outperform the state-of-the-art upper bounds. Recently, the link-based similarity meas ures attract the a ttention of many re-searchers. The related work s are outlined as follows:
Optimization computation. The PPR and SR involve an infinite number of random walks. The nature incurs heavy overhead of computation. 1. SR. Lizorkin et al. [11] proposed three excellent optimization methods which improve the time cost from O ( kn 4 )to O ( knl )where k is the number of itera-tion, n is the number of nodes, l is the number of edges. They also gave a precise accuracy estimate , which has been discussed at section 1, for SR itera-tive computation. Observe that computations among different partial sums [11] may have duplicate redundancy. Therefore, Yu et al. [15] eliminate partial sums redundancy by using an adaptive clustering strategy. Yu et al. also proposed a variant of SR and give a corresponding difference between theoretical and itera-tive scores [15]. In contrast, we focus on the upper bound of original SR. Based on e.q. (6) (11), Zhang et al presented an optimization algorithm [16] which also improve the time cost from O ( kn 4 )to O ( knl ). According to results of experiment in [16], the optimization algorithm outperforms partial sums method. 2. PPR. For PPR, computing and storing all possible personalized views in advance is impractical [5]. Jeh et al. suggested a scalable solution for PPR based on the observation that PPR vectors actually is a linear combination of basis vectors and considering hub-pivoted paths that pass through some important  X  X ub X  nodes [5]. Based on e.q. (10), Zhu et al proposed FastPPV, an approximate PPV computation algorithm that is incremental [18]. They proposed L1 error to control accuracy of PPR at query time. The L1 error is defined as follows  X  k =1  X  PPR upper bound of any specific node pairs. They both are totally different. Application of link-based Measure. By utilizing upper/lower relevance es-timations, the speed of the query, computing top-k relevant nodes w.r.t a query node, can be accelerated [2,8].

Considering a general situation where the average in/out-degree is D (D  X  1), Li defined a new average SR upper bound as a function of D [8]. However, networks, such as the Internet, the world wide web, and some social networks, are found to have degree distributions that approximately follow a power law. In other words, these networks are highly right-skewed, meaning that a large majority of nodes have low degree but a small number have high degree. On the other hand, the top-k similarity search method only access the local neighbor-hood of the query node. Therefore, the average SR upper bound does not reflect the true local information.

Fujiwara et al suggested an approach to find the top-k nodes so as to support interactive similarity search based on PPR [2]. To compute the upper similarity bound, They utilized R i , the set of nodes that is reachable to any nodes in S i for which they would update lower and upper similarity bounds. However, due to research [6], the method that tells whet her a vertex u can reach another vertex v is time-consuming. In contrast, our upper bound can be easily obtained.
Sun et al proposed link-based similarity join (LS-join), which extends the similarity join operator to link-based m easures [14]. They accelerated the speed of the join query by utilizing upper bounds of PPR and SR. The upper bounds in [14] are used to be baseline to compare with our upper bounds .

Zheng et al proposed an estimated shortest-path distance based upper bound for SR [17]. However, it is also expensive to compute the shortest path between two vertices on the fly. Furthermore, as with the upper bound in [10], the shortest-path distance based upper bound is also coarse. We proposed upper bounds of PPR and SR, which are based on following hu-man intuition:  X  X he smaller the differenc e between the two consecutive iteration step results is, the smaller the difference between iterative similarity scores and theoretical ones is X . Our upper bounds are accurate and can easily be achieved. Furthermore, we customized our bounds to accelerate top-k similar nodes query. At last, we showed that our upper bounds significantly outperform the state-of-the-art upper bounds.

