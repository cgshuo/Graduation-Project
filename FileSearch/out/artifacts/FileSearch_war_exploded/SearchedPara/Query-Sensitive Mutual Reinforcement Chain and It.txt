 Sentence ranking is the issue of most concern in document summarization. Early researchers have presented the mutual reinforcement principle (MR) between sentence and term for simultaneous key phrase and salient sentence extraction in generic single-document summarization. In this work, we extend the MR to the mutual reinforcement chain (MRC) of three different text granularities, i.e., document, sentence and terms. The aim is to provide a general reinforcement framework and a formal mathematical modeling for the MRC. Going one step further, we incorporate the query influence into the MRC to cope with the need for query-oriented multi-document summarization. While the previous summarization approaches often calculate the similarity regardless of the query, we develop a query-sensitive similarity to measure the affinity between the pair of texts. When evaluated on the DUC 2005 dataset, the experime ntal results suggest that the proposed query-sensitive MRC (Qs-M RC) is a promising approach for summarization. I.7 [ Document and Text Processing ]: Miscellaneous Mutual Reinforcement Chain, Query-Sensitive Similarity, Query-Oriented Summarization, Ranking Algorithms The explosion of the WWW has brought with it a vast hoard of information. It has become virtua lly impossible for anyone to read and understand large numbers of individual documents that are available. Automatic document su mmarization provides an effective means to manage such an exponentially increased collection of information and to support info rmation seeking and condensing goals. The main evaluation forum providing benchmarks for researchers working on document summarization [10] [13] to exchange their ideas and experiences is the Document Understanding Conferences (DUC [4]). The goals of DUC are to enable researchers to participate in large-scale experi ments upon the standard benchmark and to increase the availability of appropriate evaluation techniques. Over the past years, the DUC ev aluations have evolved gradually from single-document summarization to multi-document summarization and from generic su mmarization to query-oriented summarization [17]. Query-oriented multi-document summarization initiated by the DUC in 2005 aims to produce a short and concise summary for a cluster of relevant documents according to a given query that describes a user X  X  information need. Up to the present, the dominant approaches in document summarization regardless of the natu re and the goals of the tasks have still been built upon the sentence extraction framework. Under this framework, sentence ranking is th e issue of most concern. Most previous work in the literature addressed the ranking issue by merely examining characteristic of sentence, such as its content, its grammatical structure, the relationship or association of each other and etc. It is a remarkable advance in our understanding when Zha [22] proposed the following mutual reinforcement (MR) principle:  X  X  term should have a high saliency score if it appears in many sentences with high saliency scores while a sentence should have a high saliency scor e if it contains many terms with high saliency scores. X  Based on this MR principle, Zha developed a generic summarization model by representi ng the documents as a weighted undirected bipartite text graph and linking a term and sentences containing that term together. As they assembled a cluster of documents to a single larger document, the model in essence is a single-document summarization mode l. The advantage of this model is that at the end of iterative reinforcement both significant sentences and key phrases coul d be obtained simultaneously. Intuitively, Zha X  X  MR principle is sound and applicable. Since a document is always structured into meaningful text units such as paragraph, sentence, phrase and word in turn, the affiliation relation or the affinity relation between sentence and term (i.e., text of different granularity) can effectively mutually reinforce the importance of each other. This allows for more genuine and reliable judgment. In this study, query-oriented multi-document summarization, a more However, though starting from the MR principle, our goal is not only simply to adapt it to a different summarization task, but also to establish a general framework that can be extensible to other applications, such as document retr ieval. To achieve this goal, two issues are essential to us. They are how to introduce the document information and how to incorporat e the query information (which can be deemed as the external context outside the documents) in the course of mutual reinforcement. We extend the MR principle to the document, sentence and term mutual reinforcement chain (D -S-T MRC or MRC for short) framework, upon which three interrelated iterative ranking algorithms are developed. Although ranking sentences is the primary goal of document summarization, eventually both documents and terms are also ranke d and these by-products can be of potential advantage for other text processing purposes. Notice that the MRC X  X  capability of exploiting the relation among documents extremely facilitates multi-document summarization which is required to handle the sentences coming either from the same document or from the differe nt documents. To cope with query-oriented summarization, we further advance the MRC to the query-sensitive MRC (Qs-MRC). As in previous work, we consider the relevant of a text unit to the query. But different from them, we also count the query impact on the relation of text units. A query-sensitive similarity measure is par ticularly devised for this purpose query. We would like to point out that although the MRC and the Qs-MRC based ranking algorithms are developed for the application of query-oriented multi-document summarization in this paper, the unified framework is general enough to be applied to the other text ranking tasks. Another contribution of this study is trying to provide a formal mathematical modeling for the MRC. The remainder of this paper is organized as follows. Section 2 reviews related work. Section 3 in troduces the mutual reinforcement chain (MRC) framework and explai ns how the general MRC can be extended to the query-sensitiv e MRC (Qs-MRC). Section 4 proposes the query-sensitive similar ity measure. Section 5 suggests a summarization model based on Qs-MRC. Section 6 reports experiments and evaluation results. Section 7 concludes the paper. Sentence ranking is the issue of most concern under the framework of extractive summarization. Traditional feature-based approaches evaluated sentence significance a nd ranked sentences depending on the features that were designed to characterize the different aspects of the sentences. A variety of statis tical and linguistic features such as term frequency (distribution) , sentence dependency structure, sentence position and query relevance etc. have been extensively investigated in the past. Among th em, centroid [18] and signature term [8] are most remarkable. The features were often linearly combined and the weights of them were either experimentally tuned or automatically derived by applying a certain learning-based mechanism [16]. Newly emerged graph-based approaches like LexRank [5] and TextRank [11] [12] modeled a docum ent or a set of documents as a weighed text graph. Different from feature-based approaches, graph-based approaches took into account global information and recursively calculated sentence significance from the entire text graph rather than only replying on single sentences. These approaches were actually inspired by PageRank [2], which has been successfully used for ranking web pages in the Web graph. The effectiveness of PageRank-like approaches came from the advantage of making use of the link structure information. It further promoted the use of topic-sensitive PageRank [6], i.e., an extension of PageRank, for query-ori ented summarization [15]. While those PageRank-like approaches normally considered the similarity or the association of the sentences, Zha [23], in contrast, proposed a mutual reinforcement principle that is capable of extracting significant sentences and key phrases at the same time. In his work, a weighted bipartite document graph was built by linking together the sentences in a document and the terms appearing in those sentences. Zha argued that a term should have a high salience score if it appears in many sentences with high salience scores while a sentence should have high salience scores if it contains many terms with high salience scores. This mutual reinforcement principle was reduced to a solution for the singular vectors of the transition matrix of the bipartite graph. In fact, as early in 1998, the similar idea has been used in HITS algorithm [14] to identify hub and authority web pages in a small subset of the web graph. Zha X  X  work was later advanced by Wan et al [21] who additionally calculated the links among the sentences and the links among the terms. Zha X  X  and Wan X  X  work are the ones most re levant to our studies presented in this paper. But they all con centrated on single-document generic summarization. Measuring similarities between two text units such as documents, sentences or terms has been one of the most fundamental issues in information retrieval and other re lated domains. While a great deal of previous work was found in the literature, few of them addressed the issue of measuring similarity with respect to a particular external context such as a query from a user. Tombros and Rijsbergen [20] pioneered the development of query -sensitive similarity functions. They combined the traditional cosine similarity between the pair of documents with the collective sim ilarity of the two documents and the query together, which was defined as the cosine similarity between the centroid of the two documents and the query. Zhou and Dai [23] also proposed a query-s ensitive similarity measure for content-based image retrieval based on Euclidean distance which was widely used in image processing. Without doubt, the most critical issue in document summarization is sentence ranking. However, the sent ences could not stand alone in always organized and structured in a certain way so that the core information would be easily identifiable. In text processing applications, people often work with the text of three different granularities, i.e., document (D), sentence (S) and term (T). They are actually not independent of each other in delivering meanings. A sentence is the component of a document and meanwhile it is the composition of a set of terms. Th erefore, the constraints or the influences among documents, sent ences and terms could not be ignored in sentence (document, or term) ranking although they have not been well studied before. In this paper we call the reinforcement among D, S and T the external reinforcement . Meanwhile, we also consider the internal reinforcement within D, S or T, i.e., the reinforcement among documents (senten ces or terms). In the past, the relations of se ntences have been emphasized in graph-based summarization models and their contribution to the performance improvement has been recognized [21]. We put them forward to the relations at the docum ent level as well as at the term level to make a more unified mode ling. Finally, the external and the internal reinforcements together form a complete document, sentence and term mutual reinforcement chain (D-S-T MRC or MRC for short) framework, as illustrated in Figure 1. This MRC framework is developed with an attempt to capture the following intuition: 1. A document is important if (1) it includes the important 2. A sentence is important if (1) it appears in the important 3. A term is important if (1) it appears in the important documents; Then, the ranking of documents, sentences and terms can be iteratively derived from the MRC. Let D R , S R and T ranking scores of D , S and T , respectively, the MRC-based ranking can be formulated as follows: where D D denotes the D-D affinity matrix, S D denotes the D-S affinity matrix, T D denotes the D-T affinity matrix, and so on. The calculation of the nine matrices in Equation (1) will be detailed in Section 5.1. balance the relative weight among D-S-T in the MRC. Equation (1) corresponds to a block matrix, Let eigenvector of M . Given that the corresponding graph of M is not bipartite, in order to guarantee a unique R , we must force M stochastic and irreducible [7]. To this end, the necessary matrix transformation must be performed. We can prove that the new transformed M is stochastic and irreducible. To force M stochastic, we must make the nine block matrices in M column stochastic . For the sake of simplicity, let X denote any of the three diagonal block matrices (i.e., D D , S S , or T the remaining six block matrices (i.e., S D , T D , D S first delete the rows and the columns that contain all zero elements in X . Note that there are no zero columns in Y . Let us take S example. The affinity of the sentence s and the document d is at normalized by columns to their column stochastic versions X and Y . We then replace X and Y by X and Y in M . Let new matrix, we can prove that: Lemma 1 . M is also column stochastic, if the weight matrix W is column stochastic. Proof : Let A , B and C denote the three block matrices in M for any column under concern, then Next, we manage to make M irreducible. Let X denote any of the three new diagonal block matrices in M .As used in PageRank calculation, we will make the graph corresponding to X strongly connect by adding links from one node to any other nodes with a probability vector p r . After such an adjustment, the revised X becomes where 1 0 &lt; &lt;  X  and  X  is usually set to 0.85 according to PageRank, and k is order of X . The probability vector p many different ways. A typical de finition is to assume a uniform distribution over all elements, i.e., [ ] both stochastic and irreducible. We finally replace X by X in M , and let M denote the new matrix. We can prove that: Lemma 2 : M is irreducible. Proof : Since the three graphs corresponding to the three diagonal block matrices in M are strongly connected (they are irreducible) and the links connected the three graphs are bidirectional , the graph corresponding to M is also obviously strongly connected. Thus, M must be also irreducible.  X  Now the matrix M is stochastic and irreducible. Meanwhile, it is can compute the unique dominant eigenvector (with 1 as the eigenvalue) of M . It is well-known that the power method applied to M will converge to R . In the above introduced MRC, th e reinforcements of documents, sentences and terms are query-unaware . It means that only the content of the text is concerned. However, for the tasks like query-oriented summarization, how the reinforcement is biased to an external context (such as a user X  X  query) is often of great interest. Generally, the query information can be incorporated into the general MRC framework in two altern ative ways. The first way is to impose the influence of a user X  X  query on each text unit, (document, sentence, or term) such that it works in the internal reinforcement. This somewhat can be viewed as a topic-sensitive PageRank [6] at each level of text granularity. In the second way, the query effect is modeled in the affinity matrices in both the internal reinforcement and external reinforcement. By doing so, the MRC turns into a query-sensitive mutual reinfo rcement chain (Qs-MRC). With regard to the first way, the key to making ranking biased towards the query rests with the definition of the query-sensitive probability vector p r . A simple yet effective solution is to define p as where, () q o rel i | denote the relevance of calculated by cosine similarity.  X  is an extremely small real number for it to be a probability vector. As for the second way, the remaining problem is how to design a query-sensitive similarity measure so that the query dimension can be taken into consideration when measuring the affinity between the text units (documents, se ntences or terms) in the affinity matrices. In the following sections, we will fi rst introduce the query-sensitive similarity and then explain how to apply the Qs-MRC to query-oriented multi-document summarization. Existing similarity measures produ ce static and constant scores. However, the similarity between a pair of texts may vary with the different contexts involved. Now, we consider a more general problem: measuring the similarity between any two text objects document, a sentence or a term. We believe that the similarity between i o and j o themselves would be adjusted when q is involved. This is not difficult to understand. Similar to the social relationship, when the third party comes in, the connection of the two will undoubtedly change more or less. This problem can be explained from the set intersection perspective. As illustrated in Figure 2,  X  A  X  in the left picture corresponds to the similarity between the two objects 1 o and 2 o regardless of the query. It is what we call query-unaware similarity. But in the right picture, when the query q becomes explicit, it divides the overlapping area of i o and j o into two separated parts, i.e.,  X  B  X  and  X  C  X . We could then deduce that a query-sensitive similarity measure should consist of two parts, i.e., the query-independent part and the query-dependent part. The query-independent part concerns the dedication of query-unaware simila rity, while the query-dependent part further highlights the contri bution of the terms in common not only in i o and j o but also in q . Formally, the query-sensitive be the three n -dimensional vectors. () k q max =  X  and where n k  X   X  1 and 0  X  k q . We then define the following weight coefficient function, where 0&lt; 1  X  &lt; 2  X  &lt;  X  &lt;1. 0 = k q and 0  X  Figure 2. Notice that there is a special case that the above function can not cope with, i.e.,  X   X  = . In this case Then, we define the query-sensitive similarity function as When we move from query -unaware similarity ( ) j i o o sim , subject to the certain constraints by Equation (8). Proposition 1 . The query-sensitive similarity defined by Equation (9) ranges from ( ) 2 1 , o o sim  X   X  to ()() 2 1 2 , o o sim from ( )() 2 1 1 2 1 , ' , o o sim o o sim  X  +  X   X   X  to  X  . ( ) 2 1 , o o sim is defined as the cosine similarity between the two corresponding vectors. () 2 1 ' , o o sim from the query-dependent part. Proof : Let { } 0 |  X  = k q q k n , then There are three parameters in Proposition 1, i.e.,  X  , They are all meaningful and can be appropriately determined according to the practical application requirements.  X  is the contribution degree of the original query-unaware similarity be viewed as the lower and upper bounds of the contribution from the query-dependent part. Query-sensitive similarity is extremely important for the study of query-o riented summarization. The given query can be treated as the external context that influences or even determines how the summary is produced. The query-oriented multi-document summarization task defined in DUC evaluations requires generati ng a concise and well-organized summary for a cluster of the relevant documents according to a given query that simulates a user X  X  information need. The query usually consists of one or more interrogative and/or narrative sentences. Here is a query ex ample from the DUC 2005 document cluster  X  X 331f X . According to the task definition, system-generated summaries are strictly limited to 250 words in length. Existing query-oriented summarizati on approaches basically follow sentences with reference to the gi ven query with/without using some sorts of sentence relations; (2) then rank the sentences according to certain criteria and measures; (3) finally extract the top-ranked but non-redundant sentences from the original documents to create a summary. Under this extractive framework, undoubtedly the two critical processes involved are sentence ranking and sentence selection. In Section 3, we introduce the general MRC and the extended Qs-MRC frameworks that can prescribe the reinforcement-based procedure for ranking the text of different granularities simultaneously. The frameworks themselves are applicable to document retrieval, sentence retrieval or key word extraction etc. In this section, however, we manage to take the advantage of the Qs-MRC framework to deal with the sentence ranking problem in the query-oriented multi-document summarization task. To this end, the design of the a ffinity matrices among the documents, the sentences and the terms in Equation (1) is the first of all. In this work, we define the affinity betw een any two text units as their query-sensitive similarity, as propos ed in Section 4. The documents, the sentences as well as the queries can be naturally represented by the vectors of the terms. However, this representation does not suit the single terms. We cannot say that it is impossible for two different terms to be relevant to each other. This is because the single terms (or even those shor t text snippets without any overlapping terms) themselves do not carry sufficient information for measuring the similarity of them. In the past, many researchers have proposed different methods that attempted to capture more context of a single term or a short text snippet (such as the query posed by the user to the search engine that contains only a few words). For example, Sahami and Heliman [19] submitted each snippet as a query to the Web search engine and created a context vector of the snippet by collecting a number of returned documents that contain the words in the snippet. The context vector created in this way contains the words that tend to occur in context with the snippet. When calculating similarity, they used a context vector as a substitute for snippet. Similarly, Bollegala et al. [1] measured similarity between words or entities by making use of the information available on the Web such as page counts and text snippets returned, while Cilibrasi and Vitanyi [3] on the other side extracted Google similarity distance of words and phrases from WWW using Google page counts. The basic idea behind these approach es is try to expand single terms or short text snippets by explori ng web resources for more relevant information. The approaches using web context vectors are sound, but they heavily rely on the effectiveness of search engines and most important they are time-consuming. In this work, we utilize a semantic lexical resource WordNet 2 that has been widely used in the natural language processing community. WordNet groups terms into sets of synonyms called synset s and provides short, general definitions of them. A term may be long to many different synsets. We use all its descriptions in thos e synsets to composite the context vector, i.e., WordNet context vector , of that term. See Algorithm 1 below. The top 10 terms that are supposed to be close to an example term  X  X olicies X  in document cluste r  X  X 331f X  are given below. The similarities calculated by means of WordNet context vector are reasonable. Finally, each element in affinity matrices is defined as the query-sensitive similarity between the two text units ( ) q o o sim calculated by Equation (10). q is a query vector, o can be a vector of a document, a sentence or a WordNet context vector of a term. The Qs-MRC based ranking algorithm formulated in Equation (1) is then implemented using the following iterative procedure. Sentences are ranked according to their ranking scores eventually converged in 
R . In multi-document summarization, the number of the documents to be summarized can be very la rge. This makes information redundancy problem appear to be more serious in multi-document summarization than in singl e-document summarization. Redundancy removal becomes an inevitable process. Since our focus in this study is the design of effective (sentence) ranking algorithm, we apply the following straightforward yet effective sentence selection principle. We incrementally add into the summary the highest ranked sentence of concern if it doesn X  X  significantly repeat the information already included in the summary until the word limitation of the summary is reached. Experiments are conducted on th e DUC 2005 50 document clusters. Each cluster of documents is accompanied with a query description representing a user X  X  informati on need. Table 1 below shows the basic statistics of the dataset. Stop-words in both documents and queries are removed 5 and the remaining words are stemmed by Porter Stemmer 6 and considered as terms. As for the evaluation metric, it is difficult to come up with a universally accepted method to measure the quality of machine-generated summaries. In this work, ROUGE 7 [8], which has been officially adopted by the DUC for automatic evaluations since 2005, is used to evaluate the system-generated summaries. In all the following experiments, both text units and queries are represented as the vectors of terms. Notice that the term weights are normally measured in summariza tion models by the TF*IDF scheme as in conventional vector space models. However, we argue that it would be more reasonable to use the sentence-level inverse sentence frequency (ISF) instead of the document-level IDF when dealing with a sentence-level text processing application. This has been verified in our early study. The TF*ISF weighting scheme is applied to the WordNet context vectors as well. When a definition word does not appear in a document cluster at all, its ISF is approximated by the mean of the ISF of the terms that appears in the document cluster. Notice that the te rm itself is also included in its context vector. As for the weight matrix W in the MRC, we set it as  X   X   X   X   X  Document-Sentence-Term. W is also normalized to be column stochastic.  X  in Equation (6) is assigned the 20% of the minimized value of the relevance of the documen ts (sentences or terms) to the query in a document cluster. The th ree parameters in query-sensitive similarity measure presented in Equation (10) are assigned the values 0.8 for  X  , 0.1 for 1  X  and 0.2 for 2  X  . First of all, we would like to see how the proposed Qs-MRC based ranking algorithm works for the task of query-oriented multi-document summarization. The first set of experiments is conducted for this purpose. For reference, we also implement another two widely used and well-performed ranki ng strategies. One is to simply rank the sentences according to their relevance to the query (denoted by QR). The other is the PageRank deduced iterative ranking algorithm (denoted by PR). Th e damping factor used here is set to 0.85 as the same used in Google X  X  PageRank. To avoid the link-by-chance problem that happens when the two text units share only one or two terms by chance, we do not consider the reinforcement between them if their similarity is below a very small threshold (it is 0.05 in this work). Table 2 below shows the results of average recall scores of ROUGE-1, ROUGE-2 and ROUGE -SU4 along with their 95% confidence intervals within square brackets. Among them, ROUGE-2 is the prim ary DUC evaluation criterion. As shown in Table 2, both Qs-MRC and PR are able to produce much better results than QR which evaluates sentence individually. Qs-MRC is above QR by 17.32% of ROUGE-2, 7.53% of ROUGE-1, and 11.15% of ROUGE-SU4. Even PR is above QR by 9.19% of ROUGE-2, 2.92% of ROUGE-1, and 6.27% of ROUGE-SU4. Qs-MRC further improves PR by increasing 7.45% of ROUGE-2, 4.48% of ROUGE-1, and 4.59% of ROUGE-SU4. The improvements by involving the MRC are promising. As mentioned in previous Sec tion 3, reinforcement can be categorized as either external or internal, and external reinforcement to sentence can come from document and/or term. The second set of experiments here is to evaluate the functions of the reinforcement in different scopes. In Table 3, the MR between document and sentence or between sentence and term are indicated by Qs-MR_DS or Qs-MR_ST. The same MRC framework is applied to Qs-MR_DS and Qs-MR_ST. The only difference is that simply the affinity and weight matrices involved are pro cessed in calculation. Since we focus on sentence ranking in summari zation, the MR between term and document is ignored in the experiments. Qs-MR_S considers internal reinforcement only. From the results shown in Tables 2 and 3, we come up with the following observations. First, it is obvious that all the algorithms (Qs-MRC, Qs-MR_DS, QS-MR_ST and Qs-MR_S) that take the mutual reinforcement into consider ation are superior to the simple query relevance ranking algorithm (QR). Second, the external reinforcement is more useful than internal reinforcement. Qs-MRC, Qs-MR_DS and QS-MR_ST eviden tly outperform the Qs-MR_S. Notice that Qs-MR_S is very similar to PR but it calculates query-sensitive similarity while PR calculates normal cosine similarity. The results suggest that external reinforcement is more important than internal reinforcement. Third, for sentence ranking, the external reinforcement from document appears more significant than the same from term. Qs-MR_DS is even comparable to Qs-MRC. As recognized by other researchers, how to formulate the effect of a smaller text unit such as a term on the text unit does matter. A more comprehensive study on the term re presentation is expected in our future work. Afterwards, we evaluate our mode ling of query influence. Table 4 below gives the ROUGE results in te rms of three different ways to incorporate the query information, i.e., to calculate text relevance to the query only (MRC_QR), query-sensitive reinforcement only (MRC_QsS) and all of them (Q s-MRC). Although absolutely the query must be taken into consideration in the query-oriented summarization task, we also present the results of MRC that ignores the query influence for reference.
 Evidently, the query is extrem ely important. Qs-MRC is above MRC by 17.3% of ROUGE-2, 7.53% of ROUGE-1, and 11.1% of ROUGE-SU4. The difference is significant. Meanwhile, MRC_QR and MRC_QsS are also superior to MRC. The reason is intuitive. In query-oriented summarization, users are particularly interested in the information conveyed in the query that reflects their information needs. On the other hand, the improvements from text relevance alone are much better than query -sensitive reinforcement alone. This is reasonable. No matter how important the reinforcement is, it can not supersede the essential nature of text materials. Even so, the improvement of MRC_QsS over MRC is still very competing especially in ROUGE-2, i.e., 13.45%. These improvements are meaningful, especially when they are compared with the improvements among DUC 2005 participating systems as we will show later. Thus it is easy to conclude that the query-sensitive similarity is a direction worth further extensive study. More important, it can be applied in many applications other than query-oriented summarization. Thirty-one systems have been submitted to DUC for evaluation in 2005. Table 5 compares the Qs-M RC with them. To provide a global picture, we present the following representative ROUGE results of (1) the worst-performed human summary (i.e., H), which reflects the margin between the machine-generated summaries and the human summaries; (2) the top five and worst participating systems according to ROUGE-2; (3) the average ROUGE scores (i.e., AVG); and (4) the NIST baseline which simply selects the first sentences in the documents. We can then easily locate the positions of the proposed models among th em. Notice that the ROUGE-1 scores are not officially released by DUC. It clearly shows in Table 4 th at Qs-MRC outperforms the first-ranked system (i.e., S15). It is above S15 by 7.45% of ROUGE-2 and 3.80% of ROUGE-SU4. These are definitely exciting achievements since the best system (i.e., S15) is only 1.12% above the second-best system (i.e., S17) on ROUGE-2 and 1.46% on ROUGE-SU4. In this paper, we propose a mutu al reinforcement chain framework (MRC and Qs-MRC). Based on it, we develop an interactively reinforced ranking algorithm for the application of query-oriented multi-document summarization. The main contributions of this work are three-fold. First, we extend the mutual reinforcement principle between two objects to the mutual reinforcement chain (MRC) among three (or more than) objects and provide a formal mathematical modeling for the M RC. Second, we design a query-sensitive similarity measure and in corporate it into the MRC, i.e., the Qs-MRC. Last but not least, we exploit the effectiveness of Qs-MRC for sentence ranking in query-oriented multi-document summarization. The work suggests th at it is worth further studying on more appropriate and mathematical sound query-sensitive similarity measures and more accurate term context representation. The work described in this paper was supported by the grants from the RGC of HK, (Project No. PolyU5211/05E and PolyU5217/07E), the grant from the NSF of China (Project No. 60703008), and the internal grant from the Hong Kong Polytechnic University (Project No. A-PA6L). [1] Bollegala, D., Matsuo, Y., and Ishi zuka, M. 2007. Measuring Semantic [2] Brin, S. and Page, L. 1998. The Anatomy of a Large-scale Hypertextual [3] Cilibrasi, R. L. and Vitanyi, P. M. B. 2007. The Google Similarity [4] DUC: http://www-nlpir.nist.gov/ projects/duc/pubs.html. [5] Erkan, G. and Radev, D. R. 2004. LexRank: Gr aph-based Centrality as [6] Haveliwala, T. H. 2003. Topic-Sensitive PageRank: A Context-[7] Langville, A. N. and Meyer, C. D. 2004. Deeper Inside PageRank. [8] Lin, C. Y. and Hovy, E. 2000. Th e Automated Acquisition of Topic [9] Lin, C. Y. and Hovy, E. 2003. Automatic Evaluation of Summaries [10] Mani, I. and Maybury, M. T.(Eds.). 1999. Advances in Automatic [11] Mihalcea, R. 2004. Graph-based Ranking Algorithms for Sentence [12] Mihalcea, R. 2005. Language Indepe ndent Extractive Summarization. [13] Jones, K. S. 2007. Automatic Summarising: The State of the art. [14] Kleinberg, J. M. 1999. Authoritative Sources in a Hyperlinked [15] Otterbacher, J., Erkan, G., and Radev, D. R. 2005. Using Random [16] Ouyang, Y., Li, S. J., and Li, W. J. 2007. Developing Learning [17] Over, P., Dang, H., and Harman, D. 2007. DUC in Context, [18] Radev, D. R., Jing, H. Y., Stys, M., and Tam, D. 2004. Centroid-based [19] Sahami, M.and Heliman, T. D. 2006. A Web-based Kernel Function for [20] Tombros, A. and Rijsbergen, C. J. v. 2004. Query-Sensitive Similarity [21] Wan, X. Y., Yang, J. W., and Xiao, J. G. 2007. Towards Iterative [22] Zha, H. Y. 2002. Generic Summarization and Key Phrase Extraction [23] Zhou, Z. H. and Dai, H. B. 2006. Query-Sensitive Similarity Measure 
