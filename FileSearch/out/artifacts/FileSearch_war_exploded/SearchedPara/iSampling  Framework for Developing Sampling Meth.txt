 Sampling is one of fundamental techniques for data preprocessing and mining. It helps to reduce computational costs and improve the mining quality. A sampling method is typically developed indepen-dently for a specific problem and for a specific user X  X  interest, be-cause it is hard to develop a method that is generalized across vari-ous user X  X  interests. An absence of general framework for sampling makes it inefficient to develop or revise a sampling method as user X  X  interest changes. This paper proposes a general framework, iSam-pling , which facilitates a user developing sampling methods and easily modifying the user X  X  sampling interest in the method. In the framework, a user explicitly describes her sampling interest into a graph model called interest model . Then, iSampling automatically selects a sample set according to the model, which satisfies the user X  X  interest. In order to demonstrate the effectiveness of our framework, we develop new trajectory sampling methods using our framework; trajectory sampling has been a challenging problem due to its high complexity of data and various user X  X  interests. We demonstrate the flexibility of our framework by showing how eas-ily trajectory samples of different interests can be generated within our framework.
 H.4.0 [ Information Systems Applications ]: General X  Sampling framework Algorithm, Theory Sampling Framework for various interests, Model-based Sampling, Trajectory Sampling
This work was partially supported by Mid-career Researcher Pro-gram through NRF grant funded by the MEST (No. KRF-2011-0016029). This work was also supported by IT Consilience Cre-ative Program of MKE and NIPA (C1515-1121-0003). corresponding author
Sampling is one of fundamental techniques for data preprocess-ing and mining. The main purpose of sampling is to reduce the size of target dataset while preserving the characteristics of the dataset. Thus, it helps to reduce computational cost in various applications [1, 2, 3, 12, 13]. Also, an adoption of appropriate sampling tech-niques provides additional benefits such as enhancing the perfor-mance of application [3], reducing the cost (which is not limited to computational time) for data analyzing and gathering [12, 13], and providing solution itself for some problems such as rare-class problem and network traffic inference problem [2].

A sampling method is typically developed independently for a specific problem and for a specific user X  X  interest, because it is hard to develop a method that is generalized across various user X  X  inter-ests. For example, we want to sample 3 trajectories from the tra-jectory data in Figure 1(a). Figure 1(b), 1(c), and 1(d) show three possible sampling results with different interests  X  random sam-pling, type-preserving sampling, and traffic-preserving sampling, respectively. If a user is interested to keep the traffic types, Figure 1(c) might be a desirable sampling result. Similarly, if a user is in-terested to keep the traffic ratio on each road, Figure 1(d) might be a desirable sampling result.

An absence of general framework for sampling incurs several problems: (1) Researchers have to repeatedly pour the same efforts to develop and verify their sampling methods. (2) The inefficiency of sampling development process results in the shortage of sam-pling methods. For example, sampling methods for trajectory min-ing, temporal mining, and pattern mining are not actively proposed though their attentions grow continuously [11]. (3) Sampling inter-ests are sometimes not explicitly specified.

This paper proposes a general framework, iSampling , for de-veloping sampling methods considering the user X  X  interest. Our key idea is that there are implicit sampling interests on existing (c) Type preserving sam-pling Figure 1: Three different trajectory sampling results. A line is a trajectory and there are three types of trajectories. Figure 2: Two different subgrouping policies reflecting differ-ent interests for stratified sampling. The shape of points indi-cate the class. sampling techniques, and we can extract general interest model by formalizing such implicit sampling interests . For example, strati-fied sampling is defined to be sampling based on disjoint and ex-haustive subgroups. However, when it is applied to a classification problem, the subgroups implicitly denote the classes. This, focus-ing on class, is the user X  X  implicit sampling interest because it is not the only way to stratify. For example, consider the data of two classes in Figure 2(a). The stratified sampling would generate a dif-ferent result when the subgroups are quadrants (Figure 2(b)). The data sampled according to the quadrants can be more representative than those sampled from the typical stratified sampling in terms of data distribution. iSampling facilitates a user devel oping sampling methods and easily modifying the user X  X  sampling interest in the method. In the framework, a user explicitly describes her sampling interest into a graph model called interest model . Then, iSampling automatically selects a sample according to the model, which satisfies the user X  X  interest. In particular, the framework consists of two steps: Sample selection is done automatically, thus a user only needs to change the interest model in order to select a sample of different interest.

In order to demonstrate the effectiveness of our framework, we develop new trajectory sampling methods using our framework; trajectory sampling has been a challenging problem due to its high complexity of data and various user X  X  interests. We demonstrate the flexibility of our framework by showing how easily trajectory sam-ples of different interests can be generated within our framework.
As we discussed in Section 1, stratified sampling works as fol-lows: (1) At first, a process called stratification divides the pop-ulation into mutually exclusive and exhaustive homogeneous sub-groups , (2) After that, a simple random sampling is processed within each subgroup proportional to the size of subgroup. Stratified sam-pling requires the dataset to be well divided into a finite number of disjoint groups. However, for some unsupervised problems, it is hard to find strictly mutually exclusive and exhaustive subgroups without loss of generality. For th is reason, stratified sampling is not used for unsupervised mining problems such as frequent pat-tern mining, clustering, trajectory mining.

Under or over-sampling is also popularly used to relieve the prob-lem of imbalanced dataset in classification [8]. For example, Chawla et al. proposed a sampling technique for imbalanced dataset [1]. The key idea of the paper is that combining both under-sampling and over-sampling is better than performing one of them. The pa-per proposes and evaluates the performance of SMOTE on varying dataset and empirically proves that SMOTE generates higher ROC accuracy for imbalanced dataset.

Yu et al. proposed selective sampling technique for ranking SVM [12]. Proposed sampling technique is a sampling method for pick-ing most informative samples during active learning process. Don-mez et al. addressed the problem of how to jointly learn the accu-racy of labeling sources and obtain the most informative labels for the active learning task to minimize total labeling effort [3].
Sampling has been also developed for measuring network traffic [2, 4]. Those works aim to observe network traffic by sampling on packet data; they sample packets from networks, and based on the sampled packets, they infer the entire traffic of network.
So far, trajectory sampling methods have focused on sampling network packets and inferring overall network traffic. Duffield et al. aims to observe traffic by using sampling techniques [5]. A simple random sampling is used in the paper and it turns out to be useful to observe the traffic data. El Mahrsi et al. proposed a new sampling technique which is capable of constructing high quality summaries of incoming data on the fly [6]. In this paper, sampling is done on a single trajectory, and the sampling target is the intermediate points of a trajectory.

Recently, Pelekis et al. proposed a method which samples trajec-tories from a trajectory dataset [11]. The method divided the whole spatial domain into a fine-grained grid and, simplified a trajectory to have p line segments. Based on these preprocessed segments and cells, the method calculates the weight of each pair by using voting scheme and uses the score while sampling. However, the method lacks flexibility, and major interest is already fixed as coverage of the sample. The method also requires several parameters to tune and manual preprocessing which could produce information loss.
The interest model consists of the following primitives, which are actually components for constructing a graph 1. Interest elements  X  nodes of the graph 2. Criteria function  X  computing weights of nodes ( input: a 3. Assigning function  X  linking between nodes and data in-4. Element distance function  X  computing distances (or edges)
Constructing an interest model corresponds to building the four primitives. First, the user specifies the sampling interest using in-terest elements and criteria function . For example, in the quadrant-based stratified sampling (Figure 2(b)), since the user wants to keep the quadrant ratio in the sample, interest elements are the quad-rants , and criteria function computes the ratios of each quadrants from the dataset. Thus, the weights of nodes will be the ratios of the quadrants.

Second, to select data instances or evaluate the quality of data selection, data instances must be related to some interest elements so as to check whether the selected instances satisfy the specified interests. Thus, assigning function returns corresponding interest elements (or nodes) for each data instance. For example, in the quadrant-bassed stratified sampling, assigning function returns the quadrant that each data instance belongs to.

Finally, we need distances among nodes in order to measure and minimize the cost of mis-sampling. For example, in the quadrant-based stratified sampling, when we sample instances missing the target interest elements, (e.g., instances that fail to satisfy the quad-rant ratio), it will incur sampling costs (e.g., degrade in sampling accuracy). In that case, we should be able to measure the de-gree of cost and try to minimize the cost in sampling. Thus, el-ement distance function , returning distances among nodes, is used in the sample selection step in order to sample according to the model while minimizing the cost. In the example of the quadrant-based stratified sampling, the distances among quadrants may be set equally, or the distance between adjacent quadrants may be set shorter than that between diagonal quadrants.
In this section, to explain each primitive of interest model in de-tail, we exemplify the following four cases. Interest elements: Interest elements are the targets on which the user wants to specify sampling criteria. It corresponds to the nodes in the graph. Examples of interest elements follows. Criteria function: Criteria function returns sampling criteria for interest elements (i.e., weights of nodes), which describe the char-acteristics to preserve in the sample. Criteria function computes normalized weights of nodes ( weights =1 ) from an input of a dataset. (The weights will be used in the sample selection step in order to evaluate the quality of selected sample.) The user de-fines a criteria function to specify the sampling criteria on interest elements. Depending on the data distribution or concern of users, criteria function can be defined in various ways. Examples of cri-teria function follow. Assigning function: In order to sample or select instances match-ing the specified interest, we need to link each data instance to in-terest elements. Assigning function returns corresponding nodes of each data instance. This assigning function can be used in criteria function (to compute node weights) and also used in the sample selection step. Examples of assigning function follow. Element distance function: Element distance function computes and returns the distance given a pair of nodes. Element distances are the semantic distances among interest elements (i.e., edges among nodes). Why do we need element distances in the framework? For some cases, it is nearly impossible to sample instances exactly sat-isfying the specified interest. For instance, in trajectory dataset, it is hard to sample while perfectly preserving the traffic ratio, thus sometimes we have to sample instances missing the interest (e.g., instances that fail to satisfy the traffic ratio), which will incur sam-pling costs (e.g., inaccurate traffic ratio in the sample set). In that case, we must be able to measure the degree of the cost and try to minimize the cost while sampling. Thus, element distances are used in the sample selection step in order to sample according to the model while minimizing the cost. Examples of element dis-tance function follow. (c) Under-or over-sampling Figure 3: Examples of interest models for existing sampling methods. Italic numbers denote weights of nodes.
Figure 3 shows some examples of interest models. Examples of interest models and how to draw them using the primitives are detailed in our technical report [10].
The aim of an interest model is to describe the status of dataset with respect to the user X  X  sampling interest, thus a selected sample set can be evaluated according to the model whether the sample set satisfies the user X  X  interest. Note that the node weights are gen-erated by criteria function that is defined by the user, and criteria function computes the weights from the dataset. For example, class ratio or quadrant ratio in the stratified sampling is computed from the dataset. If the weights are computed from a selected sample set instead of the original dataset, then this interest model represent the status of the sample set with respect to users X  interest.
Our key idea is that, in the optimal result, the sampling set should construct a similar interest model compared to that from the origi-nal dataset. Consequently, the quality of a selected sample can be evaluated based on the similarity of two graphs  X  the graph whose weights are computed from the sample and that computed from the original data set. The remaining challenge is 1) how to compare two interest models, and 2) how to select a sample set which con-struct a interest model which having minimum distance from that of the original dataset.
We transform the problem of measuring the distance between interest models into the transportation problem since the distance is closely related to the concept of flow. For example, suppose an city x i produces x + i apples and consumes x  X  i apples. Then, the source of the city is x + i and sink is x  X  i . Depending on the amount of source and sink, the city may need to import or export apples to balance the source and sink, i.e., x + i  X  x  X  i =0 . Given a set of cities with source and sink, the goal of transportation problem is to find optimal flows that minimize transportation costs to balance the source and sink of all cities, i.e., x + i  X  x  X  i =0 for all x i . In our application, we treat the normalized weights of model M the amount of weights to be moved), and the normalized weights of model M S , which is constructed from the selected sample set, as sink (i.e., the amount of weights to be filled). Then, the problem is transformed to finding minimum cost to balance the weights of source and sink. To solve the transportation problem, we adopt the Earth Mover X  X  Distance (EMD) measure which is frequently used and actively researched in Computer Vision, Statistic, and Privacy and Security societies [9].
 Earth Mover X  X  Distance: Let S + and S  X  are the source and sink defined on a graph G consisting of nodes { n 1 ,...,n k } S + = { ( n 1 ,w + ( n k ,w  X  k ) } where w + k and w  X  k denotes the weight of source and sink at a node n k , respectively. Earth Mover X  X  Distance (EMD) captures the minimum costs of transporting particles to balance source and sink. The workload, which is needed to balance source and sink, is defined as follows.
 with constraints where f ij is a flow of mass (the amount of moving particles) from n matrix of flow f ij (i.e., F =[ f ij ]) . Note that, in our application, equality holds for Equation 4, 5 since we used normalized weights for source and sink. From this setting, EMD measures the mini-mum workload, defined as More details are in our technical report [10].
Now, the remaining challenge for sampling process is how to select a sample set that minimizes the EMD distance. We formulate the objective of our optimization problem as follows.
Unfortunately, this problem cannot be solved analytically, and calculating the EMD between two interest models is an another optimization problem itself. A naive method is trying all possible combinations of samples and choosing the optimal sample among them. However, such a naive method is not applicable because the complexity of the naive method is n C k ,where n is the size of orig-inal dataset and k is the size of the sample set, and n is a very large number in most applications. We propose a method based on greedy approach. Our algorithm iteratively picks an instance which produces the minimum EMD. More specifically, our sampling al-gorithm is processed in the following steps 1. Start with an empty set S . 3. Pick the instance having the minimum EMD and accumulate 4. Repeat step 2 and 3 until S is filled.
This section develops new trajectory sampling methods using our framework. Trajectory data mining has been actively researched, but sampling on trajectory data has not been actively proposed, be-cause users may have various interests on trajectory sampling, and sampling reflecting the user X  X  interest is nontrivial because of the high complexity of trajectory data.

In this section, we are interested to preserve traffic-ratio of each time window on each spatio-temporal spot. In other words, we want to preserve the traffic ratio of each spatio-temporal location. However, it is not easy to preserve the traffic ratio in sampling, because the traffic ratio of each spatio-temporal point is connected to others, and sampling a trajectory affects on the traffic of multiple spatio-temporal locations. We used interest model which is already provided for explanation on primitives.
We use a real-world trajectory dataset, Trucks [7]. This dataset contains the trajectory of a fleet of trucks, and consists of 276 in-dividual trajectories. Each trajectory has various length of GPS signal, and the total number of GPS signal is 112,203. To make dataset realistic, we divided a trajectories into multiple instances if the trajectory has a time gap longer than 10 minutes. Our final preprocessed dataset contains 1,938 trajectories with 107,616 GPS signals. More evaluation results and discussion are provided in our technical report [10].
 Sampling quality: Our method shows better results with respect to time. Figure 4 shows the difference of traffic ratio from the original dataset at each time window. From this figure, we can easily notify that random sampling technique samples far more trajectories at time window 9 than as it is. And, this over sampling results in under sample for trajectories at time window 10. On the contrary, our method shows smaller difference than random sampling. Figure 4: Difference of traffic ratio from the original dataset at each time window. X-axis: time window; Y-axis: sum of each node X  X  traffic ratio differences Result with varying sizes of sample: We report the change of sam-pling quality, as the size of sample changes. We run random sam-pling 100 times and report the average distance. Figure 5 shows the distances using EMD, which considers the semantic distance among interest elements. In this figure, our traffic-preserving sam-pling shows substantially lower distance than random sampling, which implies that sample set
This paper addresses the problem of an absence of general frame-work for developing sampling technique supporting various user X  X  interests. We propose a general framework, iSampling ,inwhicha Figure 5: Change of sampling quality w.r.t. the sample size. X-axis: sample size; Y-axis: distance from the original model using two different distance measures user explicitly describes her sampling interest into a graph model called interest model , and a sample is selected according to the model. The problem of selecting a sample set is transformed to the problem of choosing the most similar graph based on the con-cept of flow. We adopt Earth Mover X  X  Distance (EMD) to measure the sampling cost (i.e., distance between interest models), and pro-vide an efficient method for selecting a sample set based on greedy approach. To verify the effectiveness of our framework, we develop new trajectory sampling methods using our framework. Our traffic-preserving sampling methods, developed based on our framework, produce samples reflecting the user X  X  interest and also are flexible so that the user can easily change her interest in sampling.
