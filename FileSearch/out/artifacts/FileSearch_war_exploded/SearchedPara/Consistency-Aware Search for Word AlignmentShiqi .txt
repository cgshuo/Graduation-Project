 Word alignment, which aims to identify the correspondence between words in two languages, plays an important role in statistical machine translation (Brown et al., 1993). Word alignment and translation rule extraction often constitute two consecutive steps in the training pipeline. Word-aligned bilingual corpora serve as a fundamental resource for translation rule extraction, not only for phrase-based models (Koehn et al., 2003; Och and Ney, 2004), but also for syntax-based models (Chiang, 2005; Galley et al., 2006). Dividing alignment and extraction into two separate steps significantly improves the efficiency and scala-bility of parameter estimation as compared with directly learning translation models from bilingual corpora (Marcu and Wong, 2002; DeNero and Klein, 2008; Cohn and Blunsom, 2009).

However, separating word alignment from translation rule extraction suffers from a major problem: maximizing the accuracy of word align-ment does not necessarily lead to the improvement of translation quality. A number of studies show that alignment error rate (AER) only has a loose correlation with BLEU (Callison-Burch et al., 2004; Goutte et al., 2004; Ittycheriah and Roukos, 2005). Ayan and Dorr (2006) find that precision-oriented alignments result in better translation performance than recall-oriented alignments. Fraser and Marcu (2007) show that using AER and balanced F-measure can only partially explain the effect of alignment quality on BLEU for several language pairs.

We believe that the correlation problem arises from the discrepancy between word alignment and translation rule extraction. On one hand, aligners seek to find the alignment with the highest alignment model score, without regard to structural constraints. Consequently, sensible translation rules may not be extracted because they violate consistency constraints required by translation rule extraction (Och and Ney, 2004). Wang et al. (2010) find that the standard alignment tools are not optimal for training syntax-based models. As a result, they have to resort to re-aligning. On the other hand, the consistency constraint used in most translation rule extraction algorithms tolerate wrong links within consistent phrase pairs. Chiang (2007) uses the union of two unidirectional alignments, which usually has a low precision, for extracting hierarchical phrases. Therefore, it is important to include both alignment model score and the consistency constraint in the optimization objective of word alignment.

In this work, we propose to use coverage , which measures how well extracted phrases can  X  X old X ). recover the training data, to bridge word alignment and (hierarchical) phrase-based translation. We introduce a new alignment search algorithm with an objective that maximizes both alignment model score and coverage while keeping the training algorithm unchanged. The coverage of an align-ment is calculated on the fly during search using a local phrase extraction algorithm. Experiments show that our approach achieves significant im-provements over state-of-the-art baselines across various languages and translation models. We begin by introducing the preliminaries of word alignment and phrase-based translation.
 Definition 1 Given a source-language sentence f = f J 1 = f 1 ...f J and a target-language sentence e = e I 1 = e 1 ...e I , an alignment a is a subset of the Cartesian product of the word positions of two sentences: a  X  { ( j,i ) : j = 1 ,...,J ; i = 1 ,...,I } .

Figure 1(a) shows an alignment for a Chinese sentence  X  X umeng he eluosi shounao huiwu zai mosike juxing X  and an English sentence  X  X U and Russia hold summit in Moscow X . We use black circles to denote links. The link (1 , 1) indicates that the first Chinese word  X  X umeng X  and the first English word  X  X U X  are translations of each other. Definition 2 Given a training example  X  f , e , a  X  , a bilingual phrase B is a pair of source and target phrases: B = ( f j 2 J  X  1  X  i 1  X  i 2  X  I .
 For example, (  X  X ai mosike X  ,  X  X n Moscow X  ) in Figure 1 can be denoted as a bilingual phrase B = ( f 7 6 ,e 7 6 ) . For convenience, We use B.j 1 and B.j 2 to denote the beginning and ending positions of the source phrase in B , respectively. B.i 1 and B.i 2 are defined likewise for the target side. Definition 3 A bilingual phrase B = ( f j 2 said to be tight if and only if all boundary words (i.e., f j it is a loose bilingual phrase.

For example, in Figure 1, while ( f 3 1 ,e 3 1 ) is a tight bilingual phrase, ( f 4 1 ,e 4 1 ) is a loose bilingual phrase.
 Definition 4 (Och and Ney, 2004) Given a train-ing example  X  f , e , a  X  , a bilingual phrase B = ( f alignment a if and only if: 1. No words in the source phrase are aligned 2. At least one word in the source phrase is
Alignment consistency forms the basis of trans-lation rule extraction in modern SMT systems (Koehn and Hoang, 2007; Chiang, 2007; Galley et al., 2006; Liu et al., 2006). In Figure 1, 1 ,e 3 1 ) is consistent with the alignment because all words in  X  X umeng he eluosi X  are aligned with all words in  X  X U and Russia X . In contrast, in Figure 1(b),  X  X uiwu shounao X  and  X  X old summit X  are not consistent with the alignment because  X  X old X  is also aligned to a word  X  X uxing X  outside.
However, alignment consistency only defines a loose relationship between alignment and trans-lation. A phrase pair consistent with alignment tolerates wrong inside links. For example, even if  X  X umeng X  is aligned with  X  X ussia X , ( f 3 1 ,e 3 1 ) is still consistent. This is one possible reason that maximizing alignment accuracy does not neces-sarily lead to improved translation performance. Our intuition is that including the consistency constraint in word alignment can hopefully reduce the discrepancy between alignment and transla-tion. While this idea has been suggested by a number of authors (e.g., (Deng and Zhou, 2009; DeNero and Klein, 2010)), our goal is to optimize arbitrary alignment models with respect to end-to-end translation in the search phase without labeled data (see Related Work for detailed comparison).
A natural way is to include consistency in the optimization objective as a regularization term. However, as consistency is only defined at the phrase level (see Definition 4 ), we need a sentence-level measure to reflect how well an alignment conforms to the consistency constraint. A straightforward measure is the number of bilin-gual phrases consistent with the alignment ( phrase count for short), which is easy and efficient to calculate during search (Deng and Zhou, 2009). Unfortunately, optimizing with respect to phrase count is prone to yield alignments with very few links in a biased way, which result in a large number of bilingual phrases extracted from a small fraction of the training data. Another alternative is reachability (Liang et al., 2006a; Yu et al., 2013) that indicates whether there exists a full derivation to recover the training data. However, calculating reachability faces a major problem: a large portion of training data cannot be fully recovered due to noisy alignments and the distortion limit (Yu et al., 2013).

In this work, we propose coverage , which reflects how well extracted phrases can recover the training data, to measure the sentence-level consistency. In the following, we will introduce a number of definitions to facilitate the exposition. Definition 5 A source word f j is said to be covered by a bilingual phrase B = ( f j 2 and only if j 1  X  j  X  j 2 : cov ( f j ,B ) = J j 1  X  j  X  j
K . Similarly, a target word e i is covered by B if and only if i 1  X  i  X  i 2 .

The indicator function J expr K returns 1 if the boolean expression expr is true and returns 0 otherwise. For example, in Figure 1(a),  X  X umeng X  and  X  X U X  are covered by the bilingual phrase B = Definition 6 Given a set of bilingual phrases B = by the bilingual phrase set B if and only if it is covered by at least one phrase in B : cov ( f j , B ) = J target word is similar.

For example, in Figure 1(a), all source and target words are covered by the bilingual phrase set. In Figure 1(b), the source words  X  X hounao X ,  X  X uiwu X ,  X  X uxing X  and the target words  X  X old X  and  X  X ummit X  are not covered.
 Definition 7 Given a sentence pair  X  f , e  X  and a phrase length limit w 1 , the hard coverage of an alignment a is defined as a boolean value:
C h ( f , e , a ,w ) = where B = E XTRACT ( f , e , a , 1 ,J, 1 ,I,w ) is the set of consistent bilingual phrases extracted from the sentence pair using a standard phrase extraction algorithm (Och and Ney, 2004). The function  X  returns true if the two parameters are same and returns false otherwise. Algorithm 1 A consistency-aware search algorithm for word alignment.
Depending on the tightness of extracted phrases (see Definition 3 ), we further distinguish between C h + t ( f , e , a ,w ) and C h + l ( f , e , a ,w ) , which denote hard coverage calculated with tight and loose phrases, respectively.

Hard coverage denotes whether extracted phrases can fully recover the training data. For example, the values of hard coverage for Figures 1(a) and 1(b) are 1 and 0 , respectively. As most training examples can hardly be fully recovered, we introduce soft coverage to better account for partially recoverable training data.
 Definition 8 Given a sentence pair  X  f , e  X  and a phrase length limit w , the soft coverage of an alignment a is defined as = Similarly, we also distinguish between C s + t and C s + l depending on the tightness of extracted phrases.
 Definition 9 Given a word-aligned bilingual cor-length limit w , the corpus-level soft coverage is defined as Algorithm 2 Updating the set of extracted bilingual phrases after adding a link. The corpus-level hard coverage is defined like-wise. While Deng and Zhou (2009) focus on intro-ducing an effectiveness function such as phrase count into alignment symmetrization, we are inter-ested in guiding the search algorithms of arbitrary alignment models using coverage. Therefore, the objective of our search algorithm is defined as where M ( f , e , a ,  X  ) is alignment model score,  X  is a set of model parameters, C ( f , e , a ,w ) is coverage (either hard or soft), and  X  is a hyper-parameter that controls the preference between
Therefore, the decision rule is given by where A ( f , e ) is a set of all possible alignments for the sentence pair.

Algorithm 1 shows the consistency-aware search algorithm for word alignment. The input of the algorithm includes a source sentence f , a target sentence e , a set of model parameters  X  , phrase length limit w , pruning parameters  X  and b , and the number of most likely alignments to be retaind n (line 1). Inspired by Liu et al. (2010), the algorithm starts with an empty alignment a together with an empty phrase set B . We use open to store active alignments during search and N to store top-n alignments after search (lines 2-4). The procedure A DD ( open,  X  a , B  X  , X ,b ) adds  X  a , B  X  to open and discards any alignment that has a score worse than  X  multiplied by the best score in the list or the score of the b -th best alignment (line 5). For each iteration (line 6), we use a list closed to store promising alignments that have higher scores than the current alignment (line 8). For every possible link l (line 9), the algorithm produces a new alignment a 0 and updates the phrase set by calling a procedure U
PDATE ( f , e , a ,l, B ,w ) (lines 10-11). Then, the algorithm calls a procedure G AIN ( f , e , a , a 0 ,w,  X  ) to calculate the difference of model score after adding the link l : score ( f , e , a 0 ,w,  X  )  X  score ( f , e , a ,w,  X  ) If a 0 has a higher score, it is added to closed (line 13). We also update N to retain the top n alignment explored during the search (line 15). This process iterates until the model score does not increase.

Algorithm 2 describes how to update the set of extracted bilingual phrases after adding a link. Our idea is to only update the phrases near the added link l and keep other phrases unchanged. This strategy improves the efficiency by avoiding extracting phrases from the entire sentence pair. The algorithm first removes bilingual phrases that are either in the same row or in the same column with l (lines 2-7). For example, in Figure 1, the following bilingual phrases are removed after adding the link between  X  X uiwu X  and  X  X old X  because the link breaks the consistency: Other phrases out of the reach of the added link remain unchanged.

Then, the algorithm extracts bilingual phrases near l by calling the procedure E XTRACT . Note that the phrase extraction is restricted to a local region ( j 1 ,j 2 ,i 1 ,i 2 ) by the phrase length limit w . We use l.i and l.j to denote the source and target positions of the link, respectively. Table 1: Comparison of different settings of coverage on the Chinese-English dataset using Moses.  X  h  X  denotes  X  X ard X ,  X  s  X  denotes  X  X oft X ,  X  l  X  denotes  X  X oose X , and  X  t  X  denotes  X  X ight X . The BLEU scores were calculated on the development set. For quick validation, we used a small fraction of the training data to train the phrase-based model. 5.1 Setup 5.1.1 Languages and Datasets We evaluated our approach in terms of alignment and translation quality on five language pairs: Chinese-English (ZH-EN), Czech-English (CS-EN), German-English (DE-EN), Spanish-English (ES-EN), and French-English (FR-EN). The eval-uation metrics for alignment and translation are alignment error rate (AER) (Och and Ney, 2003) and case-insensitive BLEU (Papineni et al., 2002), respectively.

For Chinese-English, the training data consists of 1.2M pairs of sentences with 30.9M Chinese words and 35.5M English words. We used the SRILM toolkit (Stolcke, 2002) to train a 4-gram language model on the Xinhua portion of the English GIGAWORD corpus, which contains 398.6M words. For alignment evaluation, we used the Tsinghua Chinese-English word alignment translation evaluation, we used the NIST 2006 dataset as the development set and the NIST 2002, 2003, 2004, 2005 and 2008 datasets as the test sets.

For other languages, the training data is Euro-parl v7. The English language model trained on the Xinhua portion of the English GIGA-WORD corpus was also used for translation from European languages to English. For translation evaluation, we used the  X  X ews-test2012 X  dataset that contains 3,003 sentences as the development set and the  X  X ews-test2013 X  dataset that contains 3,000 sentences as the test set. 5.1.2 Alignment Models We apply our approach to both generative and discriminative alignment models. For generative models, we used GIZA++ (Och and Ney, 2003) to train IBM Model 4 in two directions. To calculate a model score for symmetrized alignments, we fol-low Liang et al. (2006b) to leverage link posterior marginal probabilities. For discriminative models, we used the open-source toolkit TsinghuaAligner (Liu and Sun, 2015) that implements the log-linear alignment model as described in (Liu et al., 2010). The model score for the log-linear model is also defined using link posteriors. 5.1.3 Translation Models Two kinds of translation models, phrase-based (Koehn et al., 2003) and hierarchical phrase-based (Chiang, 2007), are used to evaluate whether our approach improves the correlation between alignment and translation. For the phrase-based model, we used the open-source toolkit Moses (Koehn and Hoang, 2007). For the hierarchical phrase-based model, we used an in-house re-implementation on par with state-of-the-art open-source decoders. 5.2 Comparison of Different Settings We first investigate the optimal setting for coverage (hard vs. soft, tight vs. loose) on the Chinese-English dataset. For quick validation, we used a subset of the training data to train the phrase-based model using Moses. We used the development set to optimize the scaling factor  X  (see Eq. (4)) and set it to 0 . 3 in our experiments. We find that the  X  soft + tight  X  combination (i.e., C s + t ) yields the highest BLEU score on the development set. One possible reason is that tight phrases are usually of high quality and soft coverage allows for taking full advantage of the training data. On the contrary, C h + t yields the lowest BLEU score because hard coverage fails to distinguish between partially recoverable training examples as it assigns zero to all partially recoverable data.

Then, we investigate the effect of the phrase length limit w in Algorithm 1 on translation quality. We find w = 7 achieves the best result, which is consistent with the default setting in Moses. As a result, we used C s + t and set w = 7 in the following experiments. 5.3 Comparison of Different Alignment We compare our approach with a number of alignment methods in terms of AER and BLEU, including IBM Model 4 in two directions (C  X  E and E  X  C), symmetrization heuristics (Inter-section, Union, grow-diag-final), and consistency-aware models (tight phrase count and coverage). We used Moses to extract loose bilingual phrases from word-aligned bilingual corpora from all methods. Note that our approach uses C s + t for finding alignments, from which Moses extracts loose phrases.

Table 2 lists the numbers of extracted bilingual phrases ( X # bp X ), source phrases ( X # sp X ), target phrases ( X # tp X ), source vocabulary size ( X # sw X ), and target vocabulary size ( X # tw X ). We find that a very large number of loose phrases can be extracted from the Intersection alignments, which also have the highest vocabulary sizes. However, a large portion of words in these phrases are actually unaligned, resulting in low translation quality.
We observe that adding consistency, either in terms of phrase count or coverage, significantly improves alignment accuracy by a large margin, suggesting that imposing structural constraint helps to reduce alignment errors. Our approach outperforms all methods in terms of BLEU significantly. Note that the coverage itself does not correlate well with BLEU. It is important to achieve a balance between model score and coverage. As mentioned in Section 5.2, we set  X  = 0 . 3 in our experiments. 5.4 Translation Evaluation on Different We apply our approach to both generative (Brown et al., 1993) and discriminative (Liu et al., 2010) alignment models. As shown in Table 3, we find that adding coverage to the optimization objective significantly improves the BLEU scores. All differences are statistically significant at p &lt; 0 . 01 level. This finding suggests that our approach generalizes well to various alignment models. 5.5 Translation Evaluation on Different We also evaluated our approach on both phrase-based and hierarchical phrase-based models. As shown in Table 4, adding coverage to generative models leads to significant improvements for both models. All the differences are statistically significant at p &lt; 0 . 01 level.

Although coverage is designed for extracting phrases, using coverage is still beneficial to hier-archical phrase-based models because hierarchical phrases are derived from phrases consistent with 5.6 Translation Evaluation on Different Finally, we report BLEU scores across five language pairs in Table 5: Chinese-English (ZH-EN), Czech-English (CS-EN), German-English (DE-EN), Spanish-English (ES-EN), and French-English (FR-EN). ZH-EN uses four references and other language pairs only use single references.
We find that our approach outperforms the baseline statistically significantly at p &lt; 0 . 01 for four language pairs and p &lt; 0 . 05 for one language pair. Therefore, using coverage to bridge word alignment and machine translation can hopefully benefit more languages. Our work is inspired by three lines of research: (1) reachability in discriminative training of translation models, (2) structural constraints for alignment, and (3) learning with constraints. 6.1 Reachability in Discriminative Training Discriminative training algorithms for statistical machine translation often need reachable training examples to find full derivations for updating model parameters (Liang et al., 2006a; Yu et al., 2013). Yu et al. (2013) report that only 32.1% sentences in the Chinese-English training data that contain 12.7% words are fully reachable is statistically significant at p &lt; 0 . 01 level. due to noisy alignments and distortion limit. They find that most reachable sentences are short and generally literal.

We borrow the idea of measuring the degree of recovering training data from reachability but ignore the dependency between bilingual phrases for efficiency. To calculate reachability, one needs to figure out a full derivation, in which the bilingual phrases cover the training data and do not intersect with each other. Yu et al. (2013) indicate that using forced decoding to select reachable sentences with an unlimited distortion limit runs in O (2 n n 3 ) time. In contrast, calculating coverage is much easier and more efficient by ignoring the dependency between phrases but still retains the spirit of measuring recovery. 6.2 Structural Constraints for Alignment Modeling structural constraints in alignment has received intensive attention in the community, either directly modeling phrase-to-phrase align-ment (Marcu and Wong, 2002; DeNero and Klein, 2008; Cohn and Blunsom, 2009) or inter-secting synchronous grammars with alignment (Wu, 1997; Zhang and Gildea, 2005; Haghighi et al., 2009).
 Our work is in spirit most close to (Deng and Zhou, 2009) and (DeNero and Klein, 2010). Deng and Bowen (2009) cast combining IBM Model 4 alignments in two directions as an optimization problem driven by an effectiveness function. They evaluate the impact of adding or removing a link with respect to phrase extraction using the effectiveness function of phrase count. The major difference is that we generalize their idea to arbitrary alignment models in the search phase rather than bidirectional alignment combination in the post-processing phase. In addition, we find that using coverage instead of phrase count results in better translation performance (see Table 2).
DeNero and Klein (2010) develop a discrimi-native model of extraction sets and optimize an extraction-based loss function with respect to translation. Their model is capable of predicting the extracted phrase set. While their approach relies on annotated data for training the discrimi-native model, our method only needs to tune the scaling factor  X  on the development set. In addition, our approach is very general and can easily apply to arbitrary alignment models by appending a term to the optimization objective. 6.3 Learning with Constraints Our work is also related to learning with con-straints such as constraint-driven learning (Chang et al., 2007) and posterior regularization (Ganchev et al., 2010). The basic idea is to inject prior knowledge to the model as a regularization term. The major difference is that our coverage regularizer is independent of model parameters. As a result, alignment models can still be trained independently. In this work, we have presented a general frame-work for optimizing word alignment with respect to machine translation. We introduce coverage to measure how well extracted bilingual phrases can recover the training data. We develop a consistency-aware search algorithm that calculates coverage on the fly during search efficiently. Experiments show the our approach is effective in both alignment and translation tasks across various alignment models, translation models, and language pairs.

In the future, we plan to apply our approach to syntax-based models (Galley et al., 2006; Liu et al., 2006; Shen et al., 2008) and include the con-stituency constraint in the optimization objective. It is also interesting to develop consistency-aware training algorithms for word alignment.
 Yang Liu and Maosong Sun are supported by the 863 Program (2015AA011808) and the Na-tional Natural Science Foundation of China (No. 61331013 and No. 61432013). Huanbo Luan is supported by the National Natural Science Foundation of China (No. 61303075). This research is also supported by the Singapore Na-tional Research Foundation under its International Research Centre@Singapore Funding Initiative and administered by the IDM Programme. Many thanks go to Chunyang Liu and Meng Zhang for their discussions. We also thank the anonymous reviewers for their valuable feedback.

