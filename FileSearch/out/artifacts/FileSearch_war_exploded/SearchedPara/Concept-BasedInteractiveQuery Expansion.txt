 Despite the recent adv ances in search quality , the fast increase in the size of the Web collection has introduced new challenges for Web ranking algorithms. In fact, there are still man y situations in which the users are presented with imprecise or very poor results. One of the key dif ficulties is the fact that users usually submit very short and ambiguous queries, and the y do not fully specify their in-formation needs. That is, it is necessary to impro ve the query for -mation process if better answers are to be pro vided. In this work we propose a novel concept-based query expansion technique, which allo ws disambiguating queries submitted to search engines. The concepts are extracted by analyzing and locating cycles in a special type of query relations graph. This is a directed graph built from query relations mined using association rules. The concepts related to the current query are then sho wn to the user who selects the one concept that he interprets is most related to his query . This con-cept is used to expand the original query and the expanded query is processed instead. Using a Web test collection, we sho w that our approach leads to gains in average precision figures of roughly 32%. Further , if the user also pro vides information on the type of relation between his query and the selected concept, the gains in average precision go up to roughly 52%.
 H.3.3 [ Inf ormation Storage and Retrie val ]: Information Search and Retrie val X  Rele vance Feedbac k, Query Formulation .; H.2.8 [ Database Management ]: Database Applications X  Data Mining Theory , algorithms, experimentation, performance.
 Association rules, interacti ve query expansion, user feedback, web searching. 1 Federal Uni versity of Minas Gerais: 30161-970 Belo Horizonte-MG, Brazil 2 Google Brazil: Av. Abra  X  ao Caram, 430, 4 0 andar -Pampulha, Belo Horizonte-MG, Brazil Cop yright 2005 ACM 1-59593-140-6/05/0010 ... $ 5.00.
The Web is an inno vation that has modified the way we learn, work and live. The novelty lies not only on the freedom to publish, but also in the almost uni versal communication facilities. It marks the beginning of a new era, of a new society , started by what we may call the information revolution .

In these new times, the volume of information that can be ac-cessed at low cost and high con venience is mind boggling. To illus-trate, Google 1 adv ertised inde xing more than 8 billion Web pages in 2004. And this volume of information tends to become even lar ger . As a result, information of critical value appears frequently mix ed in with other pieces of information that are not of interest.
Because the volume of data is now much lar ger and frequently poorly organized, finding useful or rele vant information might be rather dif ficult. In fact, this is the case even with modern search engines that tak e adv antage of link analysis to identify popular sources of rele vant information.

It is general consensus that Web users pro vide poor specifications of their information needs in general. Either because the y are in a hurry or because the y do not understand the search process well, Web users frequently specify short queries with little or no conte xt information associated with them. Further , the y are the sole masters in the moment of deciding what is rele vant and what is not. The combination of these two factors suggests that interacting with the user is a key step if the precision of the results is to be impro ved [2]. In other words, to impro ve the user information search experience we have to ask more information from him.

In this work we focus our attention on the problem of impro ving the process of query formation. Our approach is to pro vide high level suggestions for expanding the original user query with addi-tional conte xt. This is done using information extracted from a log of past queries  X  an important piece of evidence that is generated in abundance by search engines.

Our approach is composed of four basic steps. First, compute past queries related to the current query using the frame work of association rules. Second, build a query relations graph encom-passing all these query relations. Third, identify subsets of queries that are strongly related among themselv es. Each of these subsets is vie wed as a concept , an entity of the world that might be related to the current query . Fourth, sho w these related concepts to the user , collect his feedbac k on the most related concept, expand the original query with the concept selected, and execute the expanded query instead.

Our concepts are labelled with subsets of past queries such as, for instance,  X  X a guar , lion, tig er X  . Since these labels were speci-fied by the users themselv es, the y are short in nature. We say that the concepts we use are of a high level nature. By this, we mean that the y are simple, intuiti ve, and can be interpreted by quick in-spection. Because of this, we claim that our concept-based feed-bac k approach is intuiti ve and lik ely to be engaged by Web users in general.

To validate our approach we ran experiments using a test collec-tion composed of more than 14 million Web pages (extracted from the  X .br X  domain). Our query log was divided into two parts: a first part composed of 182,017 sample queries from January of 2004 to December of 2004, and a second part composed of 100 test queries from January of 2005 to February of 2005. The first part was used to compute an all-queries relation graph. The second part was used to test our concept-based expansion method.

The results were compiled for the 100 test queries and were quantified using standard 11-point recall-precision figures. As base-line, we adopted a modern ranking function that combines informa-tion on the text of the documents, on the anchor texts, and on link analysis [8]. We investigated whether the expansion of the current query with the feedback pro vided by the user , through the selec-tion of a single most related concept, leads to impro ved results. Our measures indicate that average precision impro ved for all re-call levels and that the average gain in precision was of 32.26%.
Follo wing, we also ask ed the user to specify the natur e of the re-lation between the current query and the concept selected. We were interested in obtaining extra information from the user on whether this relation was of a synon ym, specialization, generalization, or association type. As before, we claim that this can be done in intu-itive and natural fashion (for instance, it is simple to determine that  X  X ar s X  pro vide a generalization for  X  X err ari X  ). Most important, we were interested in determining whether this extra information could be used to obtain impro ved results. Indeed this was the case, use of this extra information impro ved the average gain in precision from 32.26% to 52.99%, with regard to our baseline.

To the best of our kno wledge, our approach is novel in the fol-lowing aspects. First, it proposes the use of association rules to mine query relations in a query log. Second, it introduces the no-tion of a query relations graph which is central to allo w identifying a small number of concepts that are strongly related to the current query and that can be meaningfully labelled. Third, it proposes to collect further feedback from the user on the natur e of the re-lation between the current query and the concept the user selected for feedback. Fourth, all feedback required from the user is sim-ple, intuiti ve, and can be pro vided by glancing through the options displayed. Fifth, it suggests that considerable gains in average pre-cision can be obtained (over 50% in our experiments, with regard to a ranking function that already tak es link analysis into consider -ation) with little input from the user .
 The paper is organized as follo ws. We first discuss related work. We then present our concept generation algorithm. Ne xt, we de-scribe our method for query expansion using a single related con-cept selected by the user . Follo wing, we present our experimental setup and how we fine tunned our concept generation algorithm. At the end, we discuss our experimental results follo wed by our conclusions.
Query expansion has impro ved the effecti veness of rank ed re-trie val by automatically adding additional terms to a query . In [7] an original query is run using con ventional information retrie val techniques [4]. Then, related terms are extracted from the top doc-uments that are returned in response to the original query using statistical heuristics. This approach has been sho wn to be effec-tive on some collections, but results on lar ge collections of web data have been mix ed. For example, the work in [6], using the Okapi approach to ranking, have found that the standard parameters are inappropriate for web data, and even with the best parameters found by tuning to that data and queries, the performance gains are insignificant. The work in [3] presents a approach for query expan-sion using terms that appears with noun compounds. This approach classifies related terms by cate gories with recognazible names.
The work in [11] was one of the first that used past user queries to impro ve automatic query expansion. The y use the results of past queries to form affinity pools, from which expansion terms are then selected. The process works as follo ws: (1) for a query that is to be expanded, (2) up to three past queries that are highly similar to the current query are identified and the top 100 documents that were returned for each of these past queries are then mer ged, (3) forming the affinity pool. Indi vidual terms are then selected from the top rank ed documents using a TF-IDF term scoring algorithm. Their method impro ves relati ve average precision for the TREC-5 collection by around 15%.

The work in [5] chooses expansion terms from past user queries directly , rather than using them to construct sets of full text doc-uments from which terms are then selected. The method consists of three phases: ranking the original query against the collection of documents; extracting additional query terms from the highly rank ed items; then ranking the new query against the collection. The results sho w relati ve impro vements over une xpanded full text retrie val of 26% X 29%.

In [9] the y suggest a method for finding relations between queries and phrases of documents based on query logs. The y use the hy-pothesis that the click through information available on search en-gine logs represents an evidence of relation between queries and documents chosen to be visited by users. This evidence is called cross-reference of documents. Based on this evidence, the authors establish relationships between queries and phrases that occur in the documents chosen. These relationships are then used to ex-pand the initial query or to give query suggestions. This approach can also be used to cluster queries extracted from log files [19]. Cross-reference of documents are combined with similarity func-tions based on query content, edit distance and document hierarchy to find better clusters. These clusters are used in question answer -ing systems to find similar queries.

The work in [16] presents another log-based approach based on the fact that the rele vant terms suggested for an user query are those that co-occur in similar query sessions from search engine logs, rather than in the retrie ved documents. The suggested terms in each interacti ve search step with the user can be organised according to its rele vance to the entire query session, rather than to the most re-cent single query . The y sho w that their log-based method generates better results than document based methods.

In [17] the y propose a method to choose expansion terms by min-ing anchor text for a lar ge document collection. The similarity be-tween search queries and anchor texts reported in [10] is exploited by the authors to produce high quality refinement suggestions.
The work in [12] uses association rules to extract related queries from search engines log files. Association rules are widely used to develop high quality recommendation systems in e-commerce applications available in the Web [13, 18]. These applications tak e user sessions stored at system logs to obtain information about the user beha vior to recommend services and products. The same idea is applied to find related queries and pro vide suggestions to Web search engine users. The y find pre vious search patterns that match the current query and use this information to suggest related queries that may be useful to users.

Our work dif fers from the related work in one or more of the follo wing aspects: the use of associaton rules to mine query rela-tions, the building of a query relations graph for identifying str ong concepts (or entities), the use of information on the type of rela-tion between a query and a concept selected to impro ve retrie val, and the fact that all feedback the user has to pro vide is simple and intuiti ve.
Our method for generating concepts from query logs is com-posed of three steps: (1) determining query relations in the log, (2) building a query relations graph, and (3) identifying concepts in this graph for expanding user queries. While the first step can be performed offline, steps 2 and 3 should be performed during query processing time.

In the follo wing, we discuss each of these 3 steps.
To unco ver relations among the queries in the log, we rely on the frame work of association rules. The moti vation is to use asso-ciation rules to quantify patterns of query co-occurence in a same user session. Stronger are these patterns of co-occurence more re-lated the queries are considered to be. Related queries are important because the y allo w establishing semantic associations between the current query and concepts that appeared in (related) past queries.
To quantify the strength of these query relations we use associa-tion rules. Thus, before proceeding, let us revie w basic definitions on association rules.
 The problem of mining association rules was introduced in the con-text of customer commercial transactions [1]. The problem in this case is to determine what is the lik elihood that a customer buy a set p of products, given that he has bought a set p 1 of products before. This problem can be stated as follo ws.

Let p be the set of all products referred to in all transactions. Let p and p 2 be two subsets of p , not necessarily disjoint. Let a set of transactions involving the acquision of products in the set p . Let s 2 be a set of transaction involving products in the set Then, how to find association rules of the form p 1 ! p 2 More formally this problem is defined as follo ws.

Definition 1. Let I = f i 1 , i 2 , ..., i m g be the set of unique literals (called items) and D a database of transactions. Each transaction T 2 D is a non-empty set of items, i.e., T 6 = ; and T I .
Definition 2. There is a total ordering among the transaction items, which is based on its lexicographical order , so that i j 1 j m 1 .

Definition 3. An n -itemset I j is an ordered set of n unique items, such that I j I . Whene ver the number n of items is not important, we refer simply to the itemset I j .

Notice that the order among items in I j follo ws the aforemen-tioned total ordering.

Definition 4. The support count ( I j ) of an itemset I j as the number of transactions in D that contain I j .

Definition 5. An itemset I j is a frequent itemset if its support ( I j ) is greater than or equal to a given threshold, which is kno wn as minimum support.

Definition 6. An association rule is an expression A ! B , where A and B are itemsets. The support of the rule is defined probability that a transaction contains B , given that it contains During an interacti ve session with a search engine, the user speci-fies a set of queries. These queries might be related, particularly if the y co-occur together in other user sessions (besides the one under consideration). Thus, to identify query relations we need to define a user session, which we do as follo ws.

Definition 7. A query is represented by the triplet &lt; q where id i 2 is the IP address of the user who submitted the query , is the time stamp for the instant the query was submitted, and the set of terms that form the query .

Definition 8. A user session is a set of triplets f &lt; q ; &lt; q 2 ; id 2 ; t 2 &gt;; :::; &lt; q n ; id n ; t n &gt; g ::: = id n and ( t 2 t 1 ) &lt; T; ( t 3 t 2 ) &lt; T; :::; ( t The parameter T , set to 10 minutes in all our experiments, defines the maximum time interv al allo wed between any two consecuti ve queries in a same session.
 If the time interv al between two consecuti ve queries exceeds interpret that a new user session has started.
 We illustrate with an example.

Example 1. Consider a log with 3 user sessions SS 1 , SS 2 SS 3 , as follo ws.

This query log is mapped into 3 transactions, one for each user session, as follo ws: T 1 = f Q a ; Q b ; Q c g , T 2 = f Q and T 3 = f Q a ; Q c ; Q e g . The set I of items is given by f Q a ; Q b ; Q c ; Q d ; Q e g .

Once we have mapped queries into items and user sessions into transactions, we proceed to determine association rules for sets, i.e., we are only interested in relations between pairs of queries. We consider that two queries are related if there is an association 2 The authors ackno wledge the inherent imprecision of using IP adresses as user identifiers since distinct users may share the same IP adresses due, for instance, to a proxy or nat serv er. Ev en though, since user sessions are short lived, an IP address reasonably identi-fies a user for the purposes of our study . rule between them. For instance, assume that a user query pears accompanied frequently by a second user query Q b in various user sessions. Then, the association rule Q b ! Q a captures the se-mantics that Q b is a query related to the query Q a . Further , we can frequently interpret that Q b pro vides a more specific alterna-tive formulation of Q a and thus, can be used to expand the terms of Q a . Let us illustrate with an example.

Example 2. Consider the query log illustrated in Example 1. With respect to Q a , considering a minimum confidence of 100% minimum support greater than 1 session, two association rules can be computed are as follo ws: Notice that these two rules are more popular than the other rules, because the y appear in 2 user sessions. Further , both Q pro vide alternati ve specific formulations for Q a . That is, using ei-ther Q b or Q c to expand Q a will narro w the conte xt of query Thus, we define the relation operator r ( Q a ; Q b ) as the relation-ship between the query Q a and its alternati ve specific formulation Q . Notice that the direction of the operator is the opposite of the association rule Q b ! Q a .
 The rule Q a ! Q b could also have been defined to expand Ho we ver, in this case, Q a appears at the left hand side of the rule and would lik ely pro vide a generic alternati ve formulation of which is frequently not as useful for expanding Q b . It happens because the association Q a ! Q b has a confidence lower than the minimum threshold defined for this example. This is a subtle, and yet crictically important, distinction in the conte xt of our work.
Given a log of Web queries, we determine all relations involving any pair of queries. The output of this procedure is the list (possibly empty) of queries related to every query Q i present in the log.

Simplicity is one key adv antage of our approach. Because of that, we can compute the relation between queries very quickly , which means that new association rules can be updated periodically to identify new groups of related queries. This feature is important since the topics queried on the Web are dynamic and new relations may arise every day .
Using the query log and the set of association rules computed from it, we can find past queries related to the current user query (in fact, we do more than this, we identify related concepts as we later discuss). For this, we look for a query in the log that matches the current query exactly , i.e., one that contains exactly the same terms that compose the current query (if there is none, our approach can-not be applied). Let Q a be this query . Then look for queries related to
Q a follo wing the relations we computed. Besides the queries directly related to Q a , we also inspect queries that are transiti vely related to Q a . That is, if r ( Q b ; Q c ) and r ( Q a ; Q also be a candidate for expanding Q a . Ho we ver, we only follo w transiti ve relations if the queries are firmly related to each other , as we later explain in Section 3.3.

To follo w transiti ve relations we build a query relations graph for the current query Q a (we use Q a to refer both to the current query and to the past query that matches it exactly), defined as follo ws. Let R a be the set of queries in the log related to past query thus, to the current user query). For each pair of queries R , we look for the relations of the form r ( Q i ; Q j ) . Using these relations, we build a query relations graph for Q a . This graph is referred to as G a and is built as follo ws. A vertice is created in G a for each query in the set R a . Let Q i 2 R a and Q j 2 R two vertices of G a . For each relation r ( Q i ; Q j ) , we insert in a directed edge from Q i to Q j (meaning that Q j pro vides a more specific alternati ve formulation for Q i ).
 Figure 1 ilustrates the query relations graph for Q a = X  X aguar X . We notice that  X  X auber X  can be used to expand  X  X errari X , pro viding an alternati ve specific formulation. The con verse in this case is also true. We notice further that  X  X errari X  can be used to expand  X  X ars X , pro viding a more specific variation. In this case, the con verse rule leads to a more generic variation, using  X  X ars X  to expand  X  X errari X  (which might still be useful after all). Once a query relations graph G a for the current user query has been built, we can use it to identify related concepts . Concepts are the minimal cycles in the graph, formally:
Definition 9. A concept C j is a subset of the nodes in G that starting from any node Q i 2 C j we can visit all nodes in and return to Q i , without visiting a node twice. Further , there is no other concept C 0 such that C C 0 .
 Our definition of a concept allo ws identifying groups of queries that appear together repeatedly . Figure 2 sho ws the concepts associated with the query Q a = X  X aguar X , according to its corresponding query relations graph illustrated in Figure 1. We notice that for distinct concepts are identified, as follo ws.
 Further , in this case, the concepts identified clearly refer to reason-able alternati ve formulations for the query  X  X aguar X .

Our whole moti vation in this work is to expand the original query  X  X aguar X  with one of its alternati ve formulations, pro viding more conte xt to the original query , as we now discuss.
Once we have identified a set of concepts related to the user query , we need to determine which concept better satisfies the user information need. For this, we ask the user to select the concept that better suites his information need at the moment.

While this implies that the user has to pro vide feedback informa-tion, this feedback is of a high level nature and simple to pro vide. In fact, consider the case illustrated in Figure 2, which was obtained from the query log we will use in our experimentation later on. It is simple for the user to determine which of the four available con-cepts better suites his information need. Compare for instance with the case studied in [15] in which the user selects clusters generated from documents in the answer set. In that case, the clusters were labelled by sets of terms extracted from the documents, making it dif ficult for the user to interpret the meaning of each cluster . In our approach, the user selects concepts whose labels are subsets com-posed of past queries. As illustrated in Figure 2, these concepts are high level entities whose meaning is easily identifiable by inspec-tion.

Once the user has selected one concept related to the query , we add this concept to the original user query and the expanded query is processed. To illustrate this expansion process, consider that the user is presented with the four concepts associated with the query  X  X aguar X , illustrated in Figure 2, and that he selects the concept 4 labelled  X  X ion, tiger X . Then the original query is expanded to become  X  X aguar AND (lion OR tiger) X .

This approach is simple, intuiti ve, and yet effecti ve. In fact, in the experiments we later discuss we observ ed gains in average pre-cision figures of roughly 32%. And these gains were obtained by the simple selection of a concept for feedback by the user .
While our experimentation suggests that our approach is promis-ing, we observ ed that the adoption of a conjuncti ve operator (to re-strict the semantics of the original query) might be too restricti ve. To illustrate this point consider a concept that pro vides a synon ym relation to the user query . Then, our adoption of a conjuncti ve op-erator implies that both the synon ym and the original query terms need to appear in a document that is to be retrie ved. Ho we ver, in this case of a synon ym relation, if just the synon ym appears the document might be of interest to the user . This suggests pro viding some form of flexibility in the use of distinct operators for com-bining the original query with the concept used to expand it. For-tunately , in our approach there is a simple and intuiti ve form of changing this operator , as follo ws.

We classify the concepts to be used for query expansion into four types: (1) synon ym, (2) specialization, (3) generalization, and (4) association. When a user selects a concept for query expansion, he might additionally indicate whether the selected concept pro vides a synon ym, specialization, generalization, or association relation for the current query . This is important because distinct concept types lead to dif ferent query processing strate gies, as we now discuss.
Our option is to use a conjunction with concepts of a more generic nature. With concepts more closely related to the user query , we use a disjunction. This is because, for instance, a synon ym con-cept pro vides an interesting match for a document even if the terms specified in the original query do not appear in that document.
In this section we discuss our experimental setup. We also dis-cuss how we fine tunned parameters of our concept-based algo-rithm such as minimum support and minimum confidence.
In our experimentation we used a collection of Web pages, re-ferred to as the WBR reference collection, collected by the TodoBR 3 search engine. This collection is composed of 14,594,308 pages of the Brazilian Web, under the domain  X .br X . Table 2 presents the main characteristics of this collection.
 Table 2: Characteristics of the WBR Refer ence Collection
With regard to the user queries, we assembled a query log com-posed of query samples covering a period of 14 months from Jan-uary of 2004 to February of 2005. This query log was divided into two parts: a first one covering the 12 months from January of 2004 to December of 2004 and a second one covering the 2 months from January of 2005 to February of 2005. The first part of the query log was used to build a query relations graph for all queries. The sec-ond part was used for testing our concept-based query expansion method. Table 3 presents the main characteristics of our query log.
While the first part of the log is composed of 913,076 distinct query samples, the second part is composed of 100 selected test queries. These queries were selected according to a 2 steps proce-dure: (a) select the 50 most frequent queries excluding queries re-lated to sex and (b) select 50 queries randomly excluding the ones pre viously selected and queries related to sex. The average number of keyw ords per selected test query is 1.76.

The execution of these 100 test queries in the TodoBR search en-gine, which implements a modern ranking function that considers link analysis, pro vided the results that we tak e as our baseline .
For each of the 100 test queries we determined lik ely meanings (information needs) that can be associated with them. We ended up with 284 information needs associated with the 100 test queries. Table 4 sho ws some of the information needs that were associated with our test queries.
 Table 4: Inf ormation Needs Associated with Some of Our Test Queries
Using the first part of our query log, we computed all association rules involving any pair of distinct queries. Follo wing, we applied our concept-based expansion method to the 100 test queries. This was done as follo ws.

We ask ed the assistance of 10 volunteer users, all of them fa-miliar with the Web and search engines. We divided the 284 in-formation needs to the 10 users. For each test query we sho wed a description of a valid information need (i.e., an information need that we associated with a query), and a list of concepts related to the query generated by our approach 4 . For each query , the user then selected the one concept that he belie ved better described the information need that was presented to him. The original query was expanded with the concept selected and then processed. This strate gy is referred to as concept-based .

In a second round of experimentation we also ask ed the user to specify whether the concept selected pro vided a synon ym, special-ization, generalization, or association relation with regard to the original query . This was simple to determine and took almost no extra effort from the user , since the nature of the relation was in-variably clear . But, it was important because the extra gains in average precision figures were considerable. This second strate gy is referred to as concept-type-based .

In the feedback process the user had the option of not chosing any of the concepts. In this case, he selected the option no con-cepts apply . For the 284 information needs described, the users found meaningful concepts to 153 (53.9%) of them. That is, in our concept-based approach the users found that the suggestions could be used to complement or describe the intended semantics for the query 53.9% of the time. 4 Notice that if various distinct information needs were associated with a same query , each of them was treated as a separate query .
We took the 153 information needs for which the user selected a concept and, for each of them, composed a query pool formed by the top 10 rank ed documents retrie ved by each of the three rank-ing algorithms we consider (baseline, concept-based, and concept-type-based). Top-10 documents are the most rele vant in the web conte xt where users frequently focus only on the first page. This is the same pooling method used for the Web-based collection of TREC [14]. Each query information need contained an average of 23 : 86 documents. These documents were then manually evaluated for rele vance by a pool of specialists with high familiarity in Web searching, resulting in an average number of rele vant documents per query information need of 10.62.
To generate the association rules of interest and label them prop-erly , we need to determine values for minimum support, minimum confidence, and minimum inverse concept frequenc y, as we now discuss. These are the three parameters used for tuning our concept generation algorithm. The y are set offline and that do not increase the time performance of our method. On the contrary , since the y allo w prunning the set of query relations the y lead to faster compu-tation.
 We wanted to consider only the query relations that are statisti-cally meaningful (i.e., that occur with a minimum frequenc y or support). This pruning strate gy is used to pre vent that statisticaly non-rele vant relations arise from the user sessions.

Figure 3 illustrates the distrib ution of support values for all the relations that can be generated from our query log. We observ e that query relations with support values lower than 3 occur too fre-quently and are not very discriminati ve. Thus, we set the minimum support value to 3, which excludes 93% of the query relations from consideration. The remaining 7% pro vide strong query relations and are maintained. Of the remaining 7% query relations we were left with after the cut done using the minimum support value of 3 sessions, we wanted to keep only the strongest ones. This can be accomplished by vary-ing the minimal confidence, which allo ws exploring a trade-of f be-tween accurac y and the number of query relations that are used. A higher value for the minimum confidence leads to a smaller number of query relations and to faster computation. We aim at reducing the number of query relations without discarding relations that are meaningful for query expansion purposes.

Figure 4 illustrates the distrib ution of confidence values for the query relations we were left with after the cut by the minimum support. We observ e that query relations with confidence values lower than 20% occur too frequently and are not very discrimina-tive. Thus, we set the minimum confidence threshold to 20% and discarded all query relations with smaller values of confidence (i.e., we were left only with the strongest query relations). Using the remaining query relations we were left with after the cut done using the minimum confidence of 20%, we generated an all-queries relation graph. Cyles in this graph identify the concepts we work with. The last step is to label each of these concepts. For this, we simply use the list of queries that compose the concept. Ho we ver, queries that appear too frequently work as stopw ords in-troducing noise in our labelling procedure. For instance, a query such as  X  X p3 X  might cover a lar ge number of concepts and so does not pro vide any discriminati ve effect. We remo ve these queries from our query relations graph before labelling the concepts. This is accomplished as follo ws.

Let ICF be the inver se concept frequency of a query . This is defined as follo ws.
 where N c is the total number of concepts in our system and the number of concepts that contain the query q i .

Figure 5 sho ws the distrib ution of ICFs. We notice that a few queries have relati ve low values of ICF (to the left of the minimum ICF sho wn). We remo ve these queries from the system. The minimum value of ICF we used in our experiments was 6.67. Notice that this value can be set slightly dif ferent and that this is not important. The important point is to adjust the minimum ICF near the knee of the distrib ution sho wn, eliminating queries that appear too frequently in the description of the concepts that are generated. This cleans up the labels associated with the concepts, facilitating the task of the user when it is time to select a concept for feedback.
In this section we describe our experimental results. We quantify retrie val effecti veness through standard measures of average recall and precision. We emplo yed two aggre gate metrics: (i) standard 11-point average precision figures and (ii) average precision over the retrie ved documents.

Our analysis is based on a comparison to the ranking algorithm of the TodoBR search engine, which combines information ex-tracted from the document text, the anchor text, and hub and au-thority link values, as described in [8]. That is, our baseline is a modern Web ranking algorithm that combines text related informa-tion with link analysis.

We pro vide results for three distinct ranking algorithms: the base-line, the concept-based expanded query , and the concept-type-based expanded query . In the concept-type-based case, the user specifies not only the concept to expand the query but also the type of the relation between the concept and the query (i.e., synon ym, special-ization, generalization, association).

Figure 6 sho ws the 11-point average precision figures for the baseline, the concept-based, and the concept-type-based algorithms. We observ e that the concept-based and the concept-type-based al-gorithms yield better precision than the baseline, regardless of the recall level. The concept-type-based ranking yields the lar gest gains in average precision, which suggests that obtaining information on the type (nature) of the query relation can be of great value. Figur e 6: Pr ecision-r ecall cur ves for the baseline, the concept-based, and the concept-type-based algorithms, relati ve to the WBR test collection.

Ov erall average precision for the baseline, the concept-based, and the concept-type-based algorithms is presented in Table 5. The gains in average precision were of 32.26% for the concept-based and of 52.99% for the concept-type-based with regard to the base-line. Our approach outperforms the baseline because its disam-biguation scheme can be used to sucessfully describe user informa-tion needs, capturing the concepts related to the user search experi-ence.
 Table 5: Baseline, Concept-based, and Concept-type-based av-erage precision figur es for the WBR collection.

In terms of time performance, a simple implementation of our concept generation algorithm, running on a standard PC serv er pow-ered by a 1GHz Intel Celeron CPU, took 300 miliseconds on aver-age to produce the concepts related to a given query (the average was computed over the 100 test queries). This is fairly reasonable, since it is similar to the average time to process a Web query . Fur -ther , this average processing time was obtained without the benefits of any form of inde xing or optimization, which means that much shorter times can be obtained with an optimized version.
We have proposed a concept-based query expansion for Web users. Our moti vation was to pro vide the user with reasonable and meaningful suggestions whene ver he specifies a vague (short) query that has also occured in the past. For that we look ed at past user sessions for queries that had co-occured with the current user query i.e., are related to the current query .

Our approach is distinct because of the frame work we proposed for mining, identifying, and labelling query relations. Query rela-tions were modelled as association rules. To capture transiti ve rela-tions we assembled a query relations graph. To restrict the number of relations to consider , we look ed for cycles in the query relations graph. These cycles were interpreted as references to concepts (en-tities) of the world related to the current query .

Given a test query , the user was faced with concepts related to that query . He then selected a single concept that he interpreted was most strongly related to the query . This concept was used to expand the original query and the expanded query was processed. Using a Web reference collection, we validated our approach. Our results indicated gains in average precision of roughly 32% with regard to a modern Web ranking function (that tak es link anal-ysis into consideration). Further , with additional feedback from the user (on the type of relation between the selected concept and the query) this gain in average precision went up to roughly 52%.
These are interesting results that suggest that considerable gains in precision can be obtained with little extra effort from the user . This work was supported in part by the GERINDO project-grant MCT/CNPq/CT -INFO 552.087/02-5, by CNPq grant 520.916/94-8 (Ni vio Ziviani) and by CNPq grant 30.0188/95-1 (Berthier Ribeiro-Neto). [1] R. Agra wal, T. Imielinski, and A. Sw ami. Mining association [2] P. Anick. Using terminological feedback for web search [3] P. G. Anick and S. Tipirneni. The paraphrase search [4] R. Baeza-Y ates and B. Ribeiro-Neto. Modern Information [5] B. Billerbeck, F. Scholer , H. E. Williams, and J. Zobel. [6] B. Billerbeck and J. Zobel. When query expansion fails. In [7] C. Buckle y, G. Salton, J. Allan, and A. Singhal. Automatic [8] P. Calado, B. Ribeiro-Neto, N. Ziviani, E. Moura, and [9] H. Cui, J.-R. Wen, J.-Y . Nie, and W.-Y . Ma. Probabilistic [10] N. Eiron and K. McCurle y. Analysis of anchor text for web [11] L. Fitzpatrick and M. Dent. Automatic feedback using past [12] B. M. Fonseca, P. B. Golgher , E. S. de Moura, B. P  X  ossas, and [13] A. Ge yer -Schulz and M. Hahsler . Ev aluation of [14] D. Ha wking, N. Craswell, P. B. Thistle waite, and D. Harman. [15] M. A. Hearst and J. O. Pedersen. Ree xamining the cluster [16] C.-K. Huang, L.-F . Chien, and Y.-J. Oyang. Rele vant term [17] R. Kraft and J. Zien. Mining anchor text for query [18] W. Lin, S. Alv arez, and C. Ruiz. Efficient adapti ve-support [19] J.-R. Wen, J.-Y . Nie, and H.-J. Zhang. Clustering user
