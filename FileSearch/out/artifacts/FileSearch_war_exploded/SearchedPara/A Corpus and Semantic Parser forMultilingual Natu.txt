 database of geographic data, containing user-contributed local and up-to-date information about landmarks all over the world. Currently, the database contains over 3 billion data objects and is continuously growing with contributions from over 2 million registered users. While the main API is op-timized for editing map data, there exists an API that allow to filter map data based on search criteria such as location, type of objects, or features with which objects are tagged. However, issuing a query that is executable against the OSM database still requires detailed knowledge of database internals, something that cannot be expected from a layman user.

The goal of our work is the development of an interface to OSM that lets a user ask a question in natural language, which is then parsed into a database query that is executable against a web-based filtering tool and returns OSM data on an interactive map. For example, we want a user without detailed knowledge of OSM to be able to ask questions that embrace the  X  X uzziness X  of nat-ural language, for example,  X  What are the loca-tions, names and telephone numbers of hotels in Paris with wheelchair access that are close to the station Gare du Nord?  X . To find such informa-tion one would have to issue a query that requires detailed knowledge of the database and the query language:  X  area[name= X  X aris X  X   X  .a;node(area.a) [name= X  X are du Nord X  X   X  .b;node(around.b:1000) [tourism= X  X otel X  X [wheelchair= X  X es X  X ;out;  X . Addi-tionally, we present an adaptation of a statistical ma-chine translation (SMT) system for multilingual ac-cess to OSM by response-based learning from parser executability of translated queries.

As a starting point for our natural language in-terface we built a corpus of 2,380 natural lan-guage queries paired with machine readable lan-guage (MRL) formulae that we used to extract a se-mantic parser. We chose to manually creating a cor-pus of MRLs from which structure and weights of a semantic parser can be learned for three reasons: Online availability: We want to be able to present Accuracy: For an online natural language interface, Complexity: Our corpus adds a new and complex Our contributions in this paper are threefold: First, we introduce OSM as a new knowledge base that has not, to the best of our knowledge, been used for question answering, and offer a new corpus to the research community. Second, we show that a parser read off the corpus achieves promising parsing accu-racy and can be used to adapt SMT to multilingual database access. Third, our work builds the basis of a natural language interface to OSM that will be en-abling for interesting directions of future research, e.g., response-based learning to improve semantic parsing and multilingual database access. The common approach to semantic parsing is a man-ual annotation of a corpus with natural language ut-terances and machine readable formulae which are then used to learn the structure and weights of a se-mantic parser. Corpora that have been used for train-ing and testing a number of semantic parsers are G
EOQUERY (Zelle and Mooney, 1996; Kate et al., 2005) and F REE 917 (Cai and Yates, 2013). While G
EOQUERY queries are restricted to the closed do-main of US geography, the structural complex-ity of the questions is higher than for F REE 917, which focuses on open domain queries. Seminal work on building semantic parsers from the G EO -QUERY meaning representations are Zettlemoyer and Collins (2005) or Wong and Mooney (2006). Later approaches try to learn semantic parsers from question-answer pairs only, for example, Liang et al. (2009) for G EOQUERY , or Kwiatkowski et al. (2013) or Berant et al. (2013) for F REE 917. Newer research attempts to close the gap between lexical variability and structural complexity (Vlachos and Clark, 2014; Artzi et al., 2015; Pasupat and Liang, 2015), however, answer retrieval accuracy is low if semantic parsers cannot be bootstrapped from a cor-pus of queries and MRLs (Wang et al., 2015; Pasu-pat and Liang, 2015).

Our approach treats semantic parsing as a mono-lingual machine translation problem in which natu-ral language is translated into the machine readable language. This approach is convenient because one can make use of the efficient and robust decoders that are freely available for SMT. Despite the sim-plicity of the approach, Andreas et al. (2013) have shown that highly accurate semantic parsers can be trained from annotated data.

OSM has previously been used by Boye et al. (2014) for pedestrian routing using a dialogue sys-tem, however, no details on semantic parsing and no resource are provided.

Our SMT tuning experiment builds on the work of Riezler et al. (2014) and Haas and Riezler (2015) who applied response-based learning for SMT to the G
EOQUERY and F REE 917 domains, respectively. OpenStreetMap is a freely available map of the world, annotated by volunteers and editable by any-one. Entered GPS points, referred to as nodes , constitute the basis of the database and currently amount to over 3 billion examples (see Figure 1 for more statistics on the OSM database). Nodes can be given tags which are key-value pairs, such as  X  amenity=restaurant  X ,  X  highway=living street  X  or  X  abandoned:tourism=theme park  X . In total there are over 76 million distinct tags which are based on 57,159 unique keys. Nodes may be grouped to-gether to form ways . Ways can be given their own set of tags and are for example used to display roads or building outlines. Both nodes and ways may be joined to be part of a relation which is used to model the interdependence of several objects. A relation can for example be employed to delineate bus lines or to define administrative boundaries. As relations can also be part of other relations, one can even ex-press hierarchical structures.
 database made up of the aforementioned nodes, ways and relations. It can efficiently extract the cor-rect subset of database objects that satisfy the en-tered constraints. The following constraints are most relevant for our corpus creation later on:  X  The simplest constraints require the database  X  Overpass can find ways and relations that form  X  The operator called around allows the a web interface that allows users to run Overpass queries, and the Overpass turbo Query Wizard, which supports querying by predefined human read-able shorthands to executable Overpass queries. A screenshot of the map and an example database en-try for an Overpass query is shown in Figure 1. Since even the Overpass Query Wizard requires users to be familiar with the tag set of OSM key-value pairs, it unusable for users with only casual or no knowledge of OSM X  X  internal struc-ture. Nonetheless, we could use parts of the user query log to formulate natural language ques-tions. For example users would enter the query  X  (node[ X  X bandoned:tourism X = X  X heme park X  X ; way[ X  X bandoned:tourism X = X  X heme park X  X ; rela-tion[ X  X bandoned:tourism X = X  X heme park X  X ;);out;  X  which we then extended to  X  X hen did the abandoned theme parks close? X  and added the corresponding MRL  X  query(nwr(keyval( X  X bandoned:tourism X , X  X heme park X  )),qtype(findkey( X  X nd date X )))  X . Additionally we often had to provide a reference point for the queries, as users usually searched their current map cut-out and while all abandoned theme parks in the world is a short list, all restaurants for example would be too many to realistically handle. Thus we fell back to 3 chosen cities in those cases, Heidelberg, Paris and Edinburgh. In sum, most of the queries are based on OSM user queries that were issued to the Overpass turbo Query Wizard and shared among users; others were written by the first author with an utilization of the underlying Overpass API in mind. Our corpus creation process was guided by the goal to pair a diverse range of questions with machine readable language (MRL) formulae. These should include the most important OSM tags so that the parser is able to learn a mapping between these tags and the different corresponding natural language ex-pressions.

To answer concise questions without including superfluous details, the MRL needs to be able to ex-tract more specific information instead of a list of all database objects as in the underlying Overpass result. The MRL thus wraps around Overpass and contains additional indicators about what informa-tion should be returned from a database object, for example just its GPS coordinates, or a website ad-dress, or the number of returned objects.
 Given the above consideration, we define our MRL as a variable free language that focuses on practicality and speed, akin in style to the G EO QUERY MRL language. It is unambiguously defined via a context-free grammar (CFG) so that one can always ascertain whether or not a formula is valid. While the written form of the MRL is a bracket structure, this structure can easily be encoded as a tree by taking a pre-order traversal which makes it easy and efficient to work with. An example CFG tree for a MRL is given in Figure 2. In the follow-ing, we list the operators of our MRL.
 Query Operator. A single database query is en-coded in the operator query() which will hold the Overpass query as well as further specifications about what kind of answer should be retrieved. A few operators are directly derived from Overpass, merely re-written as a tree structure. As such OSM key-value pairs are encoded using the operator key-val() which takes 2 arguments, the first being the key and the second the value . The area operator from Overpass directly translates to the operator area() . Nodes, ways and relations are grouped together un-der the nwr() operator which will supply the union of the query run with the 3 types in turn. This is nec-essary because often buildings, e.g. schools, may be represented as any of the 3 types depending on how specific the annotator wanted to be. Both area() and nwr() then take one ore more keyval() arguments. If area() and nwr() appear as siblings in the tree (for an example see Figure 2), then only the objects that lie within area() will be searched to determine if they fulfil the nwr() constraints.
 Meta Operators. In order to add specificity be-yond the lists returned by Overpass, each MRL for-mula needs one or more of the following meta pa-rameters to be valid; the meta parameters in turn are held by the operator qtype() . The operator latlong() retrieves the geographical coordinates of the database objects. For a node this is simply its recorded GPS point. In the case of ways and re-lations the centre of the associated nodes is calcu-lated. findkey() searches for a specific key (such as name or website ) in the database objects of the retrieved set and returns its value. count() simply counts the number of elements in the retrieved set. least() checks for the existence of at least x elements in the returned set, whereas x is defined in a sec-ond meta function topx() which returns the top x elements of a set. topx() may also be used in con-junction with latlong() and findkey() .

Additionally the user can ask for the distance between two points of interests. This operator, dist() needs to be supplied with two separate query() operators using the latlong() meta operator, and can return the value in either kilometres or miles ( unit(mi/km) ). In conjunction with that the user can inquire if the point of interest is still within walking distance ( for( X  X alk X ) ), or if a car is recommended ( for( X  X ar X ) ).
 Fuzzy Language Operators. Fuzzy terms such as  X  X earby X ,  X  X ithin walking distance X  and  X  X losest X  can be modelled by making use of the around op-erator from Overpass. around() searches for points of interest (supplied via search() ) in the vicinity of another (supplied using center() ). If only the x clos-est points are to be returned, topx() can be added. The radius is defined via dist() . This information can occur either explicitly (  X  X o further than 200m away X  ), or implicitly (  X  X ive me a cinema with a car park close by X  implies that the car park should be in walking distance). For the implicit case 4 options are available: walking distance, within town distance, out of town distance, and day trip distance. Choos-ing the appropriate distance in the implicit case is of particular difficulty because often a term such as  X  close by  X  implies a different distance depending on the surrounding context. For example,  X  a close by airport  X  may imply day trip distance, while  X  a close by restaurant  X  at most implies a just out of town dis-tance (see also Minock and Mollevik (2013)).
Another set of fuzzy terms are the cardinal direc-tions, either within an area() operator ( X  Where are hotels in the north of Paris?  X ), or beyond an nwr() operator ( X  Where are hotels north of Gare du Nord in Paris?  X ). The correct operator, north() , east() , south() or west() , follows after query() , if present. Further Operators. Some further operators were needed to model the MRL formula for complex questions. and() is used when the user asks for two different nuggets of information (  X  X here is the clos-est bakery and the closest butcher? X  or  X  X ive me the website and name of ... X  ). or() is used to create unions, as for example, needed in a sentence such as  X  X ive me the closest bar or restaurant. X   X  *  X  can be used as a wild card in a value position, e.g. [ X  X is-toric X =*] will returned any historic objects, be it a castle, a monument or something else. nodup() re-turns a set with no duplicates. This is, for example, needed in  X  X hich cuisines are there? X  .
The complete pipeline process leading from nat-ural language question to an appropriate answer can be seen in Figure 3. The natural language question is first translated by the semantic parser into a MRL, from which the Overpass query is deterministically extracted, while keeping a list of the relevant fur-ther indicators. These indicators then operate on the database objects returned by the Overpass query to form the answer. Our corpus, called NL MAPS , is more than twice as large as G EOQUERY or F REE 917. In the following, we present a comparison of the lexical and syntactic complexity of the three corpora. All statistics re-ported in Figure 5 are normalized by the number of sentences.
 Lexically, NL MAPS is more diverse than G EO -QUERY , as can be seen by the average number of types, but less so compared to F REE 917 due to the fact that the OSM database is still a somewhat more closed domain compared to Freebase. Syntactically however, NL MAPS is with 3 more words on aver-age per sentence more complex than G EOQUERY and F REE 917, which have nearly identical sentence length. As a further test, we ran the Stanford Parser (Klein and Manning, 2003) on the queries to gener-ate syntactic parse trees. We then counted the num-ber of non-terminals required to produce the parse tree. This result reaffirms what the simpler sentence length already reported: the language in NL MAPS is more complex than in the other two corpora, which have identical complexity.

In Figure 4 we report the number of operators and values needed to construct the different gold formu-lae. While there are a few questions that need a formula shorter than 10, the vast majority needs a length of around 15, followed by a long tail of sizes with decreasing frequency of up to 36. The fact that many of the gold formulae are in fact longer than the average sentence length shows that the questions are far from trivial and require elaborate database queries to be answered. The last measure we re-port is the Flesch Reading Ease Score (Flesch, 1974) which is usually used to asses the text difficulty for readers. In this score, a lower number indicates a harder text. NL MAPS receives the lowest number, indicating it as the most complex corpus.

Overall we can infer that NL MAPS provides a good balance between lexical diversity as well as stability for a machine learning algorithm to learn. With regards to syntactic complexity, NL MAPS eas-ily supersedes the other two corpora. We conclude this section with a few example sentences: We treat semantic parsing as an SMT problem, us-ing our own implementation of the framework in-troduced by Andreas et al. (2013) who have shown that this approach achieves state-of-the-art perfor-mance on G EOQUERY . In this framework it is cru-cial that the MRL can be represented as a tree. A pre-order tree traversal can give a unique string in which each node is a word (i.e. surrounded by white space). Once the MRL has been converted into such a structure (for an example see Figure 2), a word aligner, here GIZA++ (Och and Ney, 2003), can be used to generate word-to-word alignments in both translation directions which can then be com-bined with various heuristics (Koehn, 2010, Chap-ter 4.5.3). From the next step onwards we use the freely available SMT framework CDEC (Dyer et al., 2010). After building a language model for the tar-get (MRL) side, SCFG grammars for hierarchical phrases for tuning and testing were extracted. Ex-periments in n -gram order showed that 5-gram mod-els are sufficient for language modelling.

At test time, a critical issue is the fact that mono-lingual SMT does not ensure that the translations are valid MRL formulae. Thus a k -best list (sorted from most probable to least) is generated which needs to be traversed until a valid formula is found. Experi-mentation with the k -best list size showed that 100 is a good trade-off between speed and performance. A bigger size of k might enable us to find a valid (and correct) formula further down the k -best, however, we verified experimentally that in most cases no op-tion in the extended k -best list contained a valid for-mula either.

Once a valid formula is found, it is executed against a database and the resulting answer is com-pared to the answer the gold formula provides. Only exact matches are considered correct. We report Precision , Recall and F1-score to evaluate the se-
Table 2 shows experimental results for different settings of semantic parsing on NL MAPS . Statis-tical significance of system differences in terms of F1 was assessed by an Approximate Randomiza-tion test (Noreen, 1989). For the word-alignment step, we found that the choice of the strategy for combining word alignments from both translation directions is crucial to the semantic parser X  X  perfor-mance. The intersect strategy performs significantly better than any other, suggesting that high precision alignments are very important when using a mono-lingual SMT approach for semantic parsing. Fur-ther, stemming the words on the NL side is also always significantly better than not doing so. In a next step we compare the use of dense features (Dyer et al., 2010) in conjunction with the tuning algorithm M ERT (Och, 2003) and additional sparse features (Simianer et al., 2012). As M ERT cannot handle such a large amount of features, we paired the sparse features with the tuning algorithm M IRA (Crammer and Singer, 2003). Because M ERT suffers from optimizer instability (Clark et al., 2011) due to random initialization, the experiments 1 &amp; 3 in Ta-ble 2 report the average result based on 3 different M
ERT runs. Another variation we tested is the use of the NL MAPS CFG to check whether or not a trans-lation is a valid MRL, instead of a quicker check that only ensures that a translation can be parsed as a tree. This variation is indicated with  X  +cfg  X . Lastly, while the system was able to directly learn the mapping of named entities previously seen dur-ing training, this is not possible for new named en-tities. These unknown named entities will automati-cally be passed through by the SMT system but they will be missing the marker of where in the tree they belong. As named entities always have to be in a value position in the corresponding MRL and val-ues are always leave nodes, this can easily be rec-tified by appending the marker for a leave node to passed through words ( X  +pass  X ). Of course, when stemming is used, one has to also keep track of the unstemmed form. The decision of which route to go with named entities is left up to the SMT system.
Overall, the modules tested in Table 2 add up to a total F1 score of 77.3%. Given the complexity of our corpus and the simplicity of the semantic parser, this is a promising result. Riezler et al. (2014) and Haas and Riezler (2015) have shown how to use semantic parsers for G EO -QUERY and F REE 917, respectively, to adapt an SMT system for multilingual database access. In this section we show that our semantic parser can be used for response-based learning of an SMT sys-tem to allow multilingual natural language queries to OSM, here German. To this end, a SMT sys-tem first translates the question from German to En-glish and then the translation is passed to the seman-tic parser to answer the question. The SMT system uses the feedback from the parser, i.e. the knowl-edge whether or not the question could be parsed to the correct answer, to improve translations.
More formally, assume an SMT system with a joint feature representation  X  ( x,y ) for input sen-tences x and output translations y  X  Y ( x ) , that uses a linear scoring function to predict the most likely translation  X  y = arg max y  X  Y ( x ) w &gt;  X  ( x,y ) . We de-based on sentence-wise BLEU (Nakov et al., 2012) and a binary feedback function e ( y )  X  { 1 , 0 } . The binary function evaluates to 1 if and only if a natu-ral language X  X  semantic parse receives the same an-swer as the corresponding gold parse. Training is performed by moving w closer to a hope translation y + while pushing it away from a fear translation y  X  . Both y + and y  X  have a high model score. y + incor-porates the hope for a best translation to have a low cost and positive feedback. y  X  is feared due to a high cost and negative feedback, thus we define: y + = arg max y  X  = arg max
The algorithm, called R EBOL (Riezler et al., 2014), proceeds by iterating over the training data, predicting the top translation  X  y , and receiving feed-back for this translation from a semantic parser. If the feedback is positive,  X  y is set equal to y + , other-wise to y  X  . The algorithm then searches the k -best list for the missing y  X  or y + , respectively, and per-onto w , and subtracts the feature vector of y  X  .
For our experiment, the NL MAPS questions were translated by the first author into German. As parser we chose to use number 3 (+intersect +stem +cdec +pass +cfg) from Table 2, deciding against the use of sparse features due speed reasons. The CDEC (Dyer et al., 2010) decoder was used for machine trans-lation from German to English. Here we employ pus to built the baseline SMT system.

R EBOL is compared to a baseline system with-out discriminative training ( CDEC ) and to a stochas-tic (sub)gradient descent variant of R AMPION (Gim-pel and Smith, 2012). Both baseline systems do not make use of the feedback from the semantic parser. While both R EBOL and R AMPION assume the availability of both a reference translation and a gold parse, response-based learning can also suc-ceed without any access to reference translations or even to gold standard parses. Riezler et al. (2014) introduced an algorithm, called E XEC , that only re-lies on task-based feedback and omits the cost func-tion based on sentence-wise BLEU. Collecting real world data for this algorithm is realistic for an on-line interface to OSM since it only requires a user to pose a question and then indicate if it was answered to their satisfaction. method P R F1 BLEU 1 CDEC 67.8 24.89 36.41 38.3 E
While we do report BLEU (Papineni et al., 2002), the primary goal in our work is to achieve highest possible F1 score. This is vital because our ultimate aim is to give users asking German questions the correct answer, whereas the English translation from which BLEU is be calculated is only an intermediate result that is irrelevant for the task goal.
To test significance of F1 and BLEU, we again use Approximate Randomization. Before training, we split of 200 sentences from the training set to use as held out data (dev set). R AMPION , R EBOL and E
XEC ran for 50 epochs and then the dev set was used to pinpoint the best epoch for each algorithm. In the case of R AMPION , the best epoch equalled the epoch in which the dev set achieved the highest BLEU score (epoch 20). For R EBOL and E XEC , on the other hand, this decision was made by the high-est F1 score on the dev set (epoch 40 and 6 respec-tively). The learning rate for both algorithms was set on a per feature basis using Adadelta (Zeiler, 2012).
As shown in Table 3, R EBOL can significantly im-prove in terms of F1 and BLEU over the CDEC base-line. It is also significantly better than R AMPION in terms of F1 while being able to keep up in BLEU. Should reference translations not be available, E XEC shows that it can still significantly outperform the CDEC baseline, it however cannot keep up with R E -BOL or R AMPION which have a more detailed su-pervision signal available to them. We presented an approach to query the OSM database for complex geographical facts via natural language questions. The key technology is a seman-tic parser that is trained in supervised fashion from a large set of questions annotated with executable MRLs. Our corpus is larger than previous annotated question-answer corpora, while including a wide va-riety of challenging questions.

Terms such as  X  nearby  X ,  X  in the south of  X ,  X  within x miles  X  are particularly well-suited for a natural lan-guage query interface that allows to map the fuzzi-ness of natural language to flexible spatial poly-site where users can query OSM using natural lan-us new and more realistic data which we can use to extend the corpus and to improve the semantic parser.

An online version of our natural language inter-face to OSM will be enabling for various interesting directions of future research: Besides the possibil-ity to gain new and more realistic data which we can use to extend the corpus, the semantic parser can be improved itself by response-based learning, where supervision signals can be extracted from the executed parses of new user queries against the database (Kwiatowski et al. (2013), Berant et al. (2013), Goldwasser and Roth (2013), inter alia ). In a similar way, multilingual database access can be enhanced by adapting an SMT system by response-based learning, using executability of a parse of a translated query as supervision signal (Riezler et al., 2014). Both cases of response-based learning only require a user who issues a query and gives feed-back on whether the proposed OSM object was the intended answer. Such an interactive scenario en-ables further research on alternative algorithms for learning from partial feedback (Szepesv  X  ari, 2009; Bubeck and Cesa-Bianchi, 2012).
 We would like to thank the OSM developers Roland Olbricht and Martin Raifer for their support and for contributing a dataset of shared user queries. The research reported in this paper was supported in part by DFG grant RI-2221/2-1  X  X rounding Statistical Machine Translation in Perception and Action X .
