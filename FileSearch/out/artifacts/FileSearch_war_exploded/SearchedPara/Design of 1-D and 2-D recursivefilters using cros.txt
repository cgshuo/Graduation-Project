 1. Introduction
During the last four decades, authors have proposed various methods for the design of one-dimensional (1-D) and two-1982; Kaczorek, 1985; Lu and Antoniou, 1992; Maria and Fahmy, 1974; sing, biomedical imaging, pattern recognition, remote sensing, etc. characteristic over a wide frequency range. However, when compared fl at frequency response with lower order. Lower order reduces the mathematical operations on sampled data. In addition, recursive made to design recursive fi lters using evolutionary optimization algorithms.

Evolutionary fi lter design (EFD) technique has demonstrated its 2004; Das and Konar, 2006, 2007; Panda et al., 2013a, 2013b; Dai successfully applied to solve the problem of fi lter design without requiring a good model to estimate fi lter parameters. This advan-tage is mainly motivated by the global optimization principle of evolutionary computing approaches, which allows them to per-form well in a large search space. The fi rst attempt to tackle the problem can be found in Mastorakis et al. (2003) . Since then, EFD has become an active area of research and several well-known EAs have been considered to tackle the problem of recursive fi design ( Das and Konar, 2006; Chen and Luk, 2010; Luitel and Venayagamoorthy, 2010; Rashedi et al., 2011; R. Panda et al., 2011,
G. Panda et al., 2011; Saha et al., 2013a, 2013b ), causing an outstanding interest. Nevertheless, some of the EAs are not used so far to solve the problem. The aim of the current contribution is to bridge that gap and to create interest among researchers. In addition, by developing an extensive simulation study on the performance of two relatively new EAs, effort is made to convince the readers about the suitability of our approach to solving the problem.

Arti fi cial Intelligence (AI) methods such as evolutionary computing (EC) play a major rol e in the synthesis of recursive fi lters. To attract readers, design of IIR fi lters using AI techni-ques and their applications in different areas is explained in the following block diagram shown in Fig. 1 (a) and (b). In Fig. 1 (a), we demonstrate the application of adaptive 1-D IIR fi for system identi fi cation. Another potential application of 2-D IIR fi lter in the area of image processing is shown in Fig. 1 (b).
This has motivated us to design IIR fi lters using AI techniques, which is presented in this contribution.

As displayed in Fig. 1 (a) and (b), synthesis of digital IIR requires evolutionary computing technique before deciding coef fi cients. To be precise, fi lter coef fi cients must be optimized before using it for some applications. In this sense, AI techniques using particle swarm optimization is proposed in Chen and Luk (2010) . In this paper, we present the idea of recursive fi using two relatively new EC techniques.

In general, 1-D recursive fi lters can be implemented using two different methods: (i) frequency sampling technique is employed for least square error ( Lang, 2000 ) and Remez Exchange algorithm order are constructed in the analogue domain ( Antoniou, 2005;
Saha et al., 2013a, 2013b ), which is subsequently transferred into digital domain using the bilinear transformation method. These methods are useful at low frequency. But at high frequencies, we encounter frequency warping problem ( Hussain et al., 2011 ). Some authors have proposed design methods for exclusive 2-D recursive fi lters ( Ladenov and Mastorakis, 2001; Mastorakis et al., 2004; Das and Konar, 2007; Panda et al., 2013a, 2013b ). This has been a worthwhile subject of study. In general, design methods for 2-D recursive fi lters are classi fi ed into two different categories: (i) Methods using the transformation of one-dimensional (1-D) fi lters ( Kaczorek, 1985 ). (ii) Methods using various transformation techniques ( Laasko and
Ovaska, 1994; Hsieh et al., 1997; Daniel and Willsky, 1997; Zhu et al., 1997; Rajan and Swamy, 1983 ).

From the above discussions, one can consider recursive fi design as an interesting yet challenging optimization problem. Some of the fast and ef fi cient gradient-based algorithms like steepest descent and quasi Newton algorithms have been deployed for optimization of recursive fi lter parameters ( Antoniou, 2005 ).
However, these methods are useful for solving optimization pro-blems, which are unimodal in nature. But while solving recursive fi lter design problems, we need to minimize mean square error between the desired response and estimated response, which is multimodal in nature. In this sense, evolutionary computational techniques are useful to solve such types of optimization problems.
Researchers have proposed different evolutionary techniques for
Cetinkaya (2004) and Yu and Xinjie (2007) . Yu et al. (2009) presented a method for 1-D IIR fi lter design using particle swarm optimization. Ant colony optimization has been used for 1-D recursive fi lter design by Karaboga et al., (2004) .Designof1-D recursive fi lter by using Bee colony algorithm was proposed in Karaboga and Cetinkaya, (2011) . Sarangi et al. (2011) presented
DEPSO and PSO-QI in digital fi lter design. Cat swarm optimization of optimal linear phase FIR high pass fi lter using craziness-based particle swarm optimization. Mandal et al. (2011) proposed the
IIR fi lters. These authors are silent about constraint handling and impairment to ensure stability of their proposed 1-D IIR fi have not considered their design problem as a constrained optimi-zation problem.

On the other hand, some other researchers took it as a constrained optimization problem and solved it for the design of
Das and Konar (2006, 2007) proposed differential evolution (DE) and particle swarm optimization (PSO) for solving 2-D recursive fi lter design problem. Panda et al. (2013a, 2013b) proposed a 2-D recursive fi lter design using bacteria foraging optimization (BFO) technique.

From the above arguments, it seems that much work has not we have made an attempt to exploit the global searching cap-ability of a recently proposed crossover bacterial foraging optimi-zation (COBFO) technique ( Panda and Naik, 2012 ) and a meta heuristic search technique called Cuckoo search (CS) technique.
COBFO can provide us the better objective function values (mini-mum error) although it requires more computation time. The main attraction behind the use of CS algorithm is its simplicity in computation as we need only few parameter settings. This con-tribution gives us many interesting ideas about COBFO, CS, BFO and GA and their uses for the design in, especially, 2-D recursive fi lters.

It is important to note here that the stability of the digital is very much needed for practical realization. However, most of the existing techniques provide us unstable fi lters. The stability ( Tzafestas, 1986 ) of recursive IIR fi lters has not been ensured, because those approaches were based on more or less trial-and-error basis ( Antoniou, 2005; Tzafestas, 1986 ). To overcome this problem, one approach is to avoid the instability by imposing some inbuilt constraints. In this connection, the design of 2-D random search strategy, has been proposed in Mastorakis (2003) as a constrained optimization problem. But in GA, the offspring never ends with a desired location. On the other hand, crossover bacteria foraging optimization (COBFO) ( Panda and Naik, 2012 ) provides us a random bias walk to produce quality results.
However, both GA and COBFO take more time. This time-consuming problem can ef fi ciently be solved by using the Cuckoo search (CS) optimization algorithm. In this paper, COBFO, CS, BFO and GA algorithms are implemented for the design of both one-dimensional (1-D) and two-dimensional (2-D) recursive fi lters.
The stability of BFO is discussed in Das et al. (2009) , Dasgupta et al. (2009) and Naik and Panda (2010) . The BFO is useful for various engineering applications (to solve optimization problems). Recently, the bacteria foraging optimization have been used in R. for different engineering applications, which outperforms the GA. In this paper, we have been motivated to use COBFO to solve the IIR fi lter design problem as a constrained optimization problem. Here, we use COBFO to solve the constrained optimization pro-blem for designing both 1-D and 2-D recursive fi lters. We have also used CS to reduce time complexity. Results are compared with GA and BFO. We have studied six sets of parameters for this work using COBFO, CS, BFO and GA approaches. However, the best set is used to obtain the results. The parameters used for simulation using MATLAB are displayed in the form of tables in the results and conclusion section.

In this paper, the proposed COBFO algorithm offers us two distinct additional advantages  X  the proposed algorithm supple-ments the features of GA, and the random bias incorporated into the COBFO algorithm guides us to move in the direction of the increasingly favourable environment. In addition, COBFO algo-rithm allows us for a physical dispersal of the child in a chosen Further, we impose inbuilt constraints to provide stability. But COBFO consumes more time to optimize the parameters in this work while considering 2-D recursive fi lter design. Hence, to overcome the time consuming factor, there is yet another optimi-zation algorithm available, named as Cuckoo search (CS) techni-que, which provides the optimized result by consuming about 15  X  30% less time as compared to COBFO, BFO and GA optimization techniques. This has motivated us to investigate design methods for both 1-D and 2-D recursive fi lters using the CS technique. Interestingly, inbuilt constraint handling and repair mechanism are already present in the CS algorithm, which is used here to provide stability. Here we use both COBFO and CS to design recursive fi lters with improved performance.

The organization of this paper is as follows: Section 1 deals with the introduction part. Design methodology is presented in discussions are presented in Section 4 . Concluding remarks are found in Section 5 . 2. Design methodology
A system is said to be recursive if the present output of the system depends on past and present input as well as past output of that system.

For a 1-dimensional system, y  X  n  X  X f x  X  n  X  ; x  X  n 1  X  ; x  X  n 2  X  ; ... ; x  X  n M  X  Similarly, for a 2-dimensional system, y  X  n ; m  X  X f x  X  n ; m  X  ; x  X  n 1 ; m 1  X  ; x  X  n 2 ; m 2  X  ; ... ; y  X  n 1 ; m 1  X  ; y  X  n 2 ; m 2  X  ; ... ; y  X  n N ; m M  X g X  2  X  For design purposes, we consider the following six (three 1-D and three 2-D) transfer functions in this paper.

Let us consider M d as the desirable amplitude response of the 1-D fi lter as a function of the frequency  X  A [0,  X  ]. M  X   X   X  X 
The design task at hand amounts to fi nding a transfer function H ( z ) such that the function approximates the desired amplitude response. This approximation can be achieved by minimizing
J  X   X  N where M (  X  ) is the Fourier transform of H ( z ), i.e.
M  X   X   X  X  H  X  z  X j
Hence, the aim is to minimize the difference between the Here we choose q  X  2.

Here we consider three different 1-D IIR fi lter transfer functions for design purpose.
 Example 1:
H  X  z  X  X  H 0 Stability conditions are given by H  X  z  X  X  A  X  z  X  B  X  z  X  ; where B  X  z  X  a 0 ; for z Z 1 j j X  6  X  For N  X  2, we get
H  X  z  X  X  H 0 1  X  a 1 z  X  a 2 z 2 1  X  b
In the present problem, the aim is to minimize the vector ( X ). where X  X  X  a 1 ; a 2 ; b 0 ; b 1 ; b 2 ; H 0 :
Subject to the following constraints:  X  1  X  b i  X  4 0 and  X  1 b i  X  o 0  X  8  X  Example 2:
H  X  z  X  X  H 0 Stability condition is given by H  X  z  X  X  A  X  z  X  B  X  z  X  ; where B  X  z  X  a 0 ; for z Z 1 j j X  10  X  For N  X  2, we get
H  X  z  X  X  H 0 1  X  a 1 z 1  X  a 2 z 2 1  X  b Here our aim is to minimize the vector ( X ).where X  X  X  a 1 ; a 2 ; b 1 ; b 2 ; H 0 :
Subject to the following constraints:  X  1  X  b i  X  4 0 and  X  1 b i  X  o 0  X  12  X  Example 3:
H  X  z  X  X  H 0  X  1  X  a 1 z 1  X  X  1  X  a 2 z 1  X  a 3 z 2  X   X  1  X  b Stability condition is given by H  X  z  X  X  A  X  z  X  B  X  z  X  ; where B  X  z  X  a 0 ; for z Z 1 j j  X  14  X 
In the problem under consideration, the aim is to minimize the vector ( X ).where X  X  X  a 1 ; a 2 ; a 3 ; b 1 ; b 2 ; b 3
Subject to the following constraints:  X  1  X  b i  X  4 0 and  X  1 b i  X  o 0  X  15  X  Let us consider M d as the desirable amplitude response of the 2-D fi lter as a function of the frequencies  X  1 and  X  2 ,  X   X  1
M  X 
The design task at hand amounts to fi nding a transfer function H ( z , z ) such that the function approximates the desired amplitude response. This approximation can be achieved by minimizing ( Mastorakis, 2003 )
J  X   X  where M (  X  1 ,  X  2 ) is the Fourier transform of H ( z 1
M  X  ;  X  2  X  X  H  X  z 1 ; z 2  X  z 1  X  e j and 1  X  X  (usually q  X  2 or 4).

Hence, the aim is to minimize the difference between the actual and desired amplitude response of the fi lter at ( N 1 , N
J  X   X  for design purpose are given below.
 Example 4:
H  X  z ; z 2  X  X  H 0
Since we are dealing with only fi rst-degree factors in the denomi-nator, the stability conditions are given by ( Mastorakis, 2003 )  X  1  X  d k  X  o  X  b k  X  c k  X  o  X  1  X  d k  X   X  1 d k  X  o  X  b k c k  X  o  X  1 d k  X   X  1  X  d k  X  4 0  X  1 d k  X  4 0  X  20  X 
Subject to the constraints j d  X  c k j 1 o b k ; k  X  1 ; 2 ; ... ; N b o 1 j d k c k j ; k  X  1 ; 2 ; ... ; N  X  21  X  where N 1 , N 2 and N are all positive integers For N  X  2, we get
H  X  z ; and a 00  X  1 :  X  22  X 
In the present problem under consideration, the aim is to minimize the vector ( X ).where X  X  X  a 10 ; a 01 ; a 02 a ; a
For the successful implementation, we need to calculate j M  X 
M  X  ;  X  2  X  X  H 0 A R jA I where A A  X  a
B  X  1  X  b 1 c 10  X  c 1 c 01  X  d 1 c 11
B
B  X  1  X  b 2 c 10  X  c 2 c 01  X  d 2 c 11
B c  X  c
Therefore, we obtain an equation for j M  X   X  1 ;  X  2  X j j M  X  Example 5:
H  X  z ; z 2  X  X  H 0
Stability conditions are given by  X  1  X  d k  X  o  X  b k  X  c k  X  o  X  1  X  d k  X   X  1 d k  X  o  X  b k c k  X  o  X  1 d k  X   X  1  X  d k  X  4 0  X  1 d k  X  4 0  X  26  X 
Subject to the constraints j d  X  c k j 1 o b k ; k  X  1 ; 2 ; ... ; N b o 1 j d k c k j ; k  X  1 ; 2 ; ... ; N  X  27  X  where N 1 , N 2 and N are all positive integers For N  X  2, we get
H  X  z ; z 2  X  X  H 0  X  1  X  a 10 z 1  X  a 11 z 2  X  a 12 z 1 z 2  X  X  1  X  a
In the present problem, the aim is to minimize the vector ( X ). where X  X  X  a 10 ; a 11 ; a 12 ; a 20 ; a 21 ; a 22 ; b 1 ; Example 6:
H  X  z ; z 2  X  X  H 0 Stability conditions are given by
H  X  z ;
B  X  z ; z 2  X  a 0 j z j
Z 1 j z j
Z 1 For N  X  2, we get
In the present problem, the aim is to minimize the vector ( X ). where X  X  X  a 01 ; a 02 ; a 10 ; a 11 ; a 12 ; a 20 ; a 21 b ; b
In this paper, we use soft computing techniques to obtain and useful evolutionary computing techniques called crossover bacterial foraging optimization technique (COBFO) and Cuckoo search (CS) technique.
  X  a  X  b
In this work, one variable is to represent each fi lter coef X shown above. In fact, we require an initial set of solutions in the initial location of search space. Here we use the normally distributed pseudorandom number generator for initial set of solutions, which satis fi es the constraints discussed above. Both the algorithms are presented below. 3. Evolutionary computing techniques
In this section, four different evolutionary computing techniques are discussed for more clarity. 3.1. Genetic algorithm
A simple GA relies on the processes of reproduction, crossover the search, GA requires an initial set of points ( Holland, 1992; Krishnakumar and Melkote, 2000 ). This set is called population, analogous to the biological system. It has a population size. A random number generator creates the initial population. This initial set is converted to binary streams and is considered as Chromosomes, which are actually sequences of  X  0  X  sand  X  parents for a reproduction. Parents participate in reproduction and interchange parts of their genetic material. This is achieved by crossover. After crossover, there is a very small probability for mutation. Mutation is the phenomenon where a random  X  0  X  mutation is necessary. Assume that each pair of  X  parents to children. Thus, the GA generates the initial layouts and obtains the objective function values. The above operations are carried out and the next generation with a new population of strings is formed. By the process of reproduction, the population of the  X  parents as new members are added. The parents always belong to the population under consideration. The new population has now new members. Then the process of natural selection is applied. Accord-ing to this scheme, only members with best fi tness value survive out of all members when we are attempting to maximize an objective function. Those members who have the lowest fi tness values are selected while attempting to minimize an objective function. 3.2. Bacterial foraging optimization (BFO) algorithm
Bacterial foraging optimization (BFO) algorithm is basically a distributed optimization technique introduced in Passino (2002) . BFO algorithm emulates the chemotaxis (foraging) behaviour of bacteria, which is used to solve non-gradient optimization pro-blems with the help of a run and a tumble method to move the cell patterns of bacteria are decided using a swarming (where cell releases attractants for signalling other cells so that they can swarm together) behaviour. There are also some other vital steps in a bacterial foraging optimization technique coined as reproduc-tion, elimination and dispersal. These steps are very worthwhile reproduction step, the least healthy bacteria die as they could not into two). In the elimination-dispersal step, any bacteria can be eliminated from the population by dispersing it to a desired location (unlike the genetic algorithm). Note that the frequency of chemotactic steps in BFO is always greater than the frequency of reproduction steps. The more characteristics of chemotaxis and swarming behaviour of bacteria are discussed in Passino (2002) . 3.3. Crossover bacterial foraging optimization (COBFO) algorithm
The idea of using the crossover mechanism in the COBFO algorithm ( Panda and Naik, 2012 ) is to search nearby locations by deploying 50 per cent of bacteria randomly at different locations. Through this process, we get some more missing nutrient. The fact may be reiterated that in the traditional BFO algorithm, the search starts from the same locations (50 per cent ignore some characteristics of chemotaxis and swarming beha-viour of bacteria to make our simulation programs simple. 3.3.1. Modi fi cation to the crossover bacterial foraging optimization algorithm
Our proposal is based on the underlying principle of the crossover BFO algorithm and the mutation property of GA. Muta-tion is the process of randomly disturbing genetic information to population whenever the population tends to become homoge-neous due to repeated use of the reproduction and crossover requirement for a mutation operation is to create a point in the neighbourhood of the current point, thereby achieving a local search around the current solution.

In fact, a crossover mechanism is incorporated to converge into one of the best solutions. Concurrently, we also think for the bacterium so that it must avoid the local minima. This can be achieved by avoiding convergence and explore more nutrient. In order to achieve this, we add the mutation concept of GA together with the crossover mechanism. The total bacterium S goes for the offspring bacteria are placed randomly at different locations (unlike BFOA) and start searching for nearby locations. Let N the number of crossover-mutation-reproduction steps and N the number of elimination-dispersal events with probability p
This helps keep track of a sudden change, in the environmental condition, which may affect the life of the bacterium. So a new set of bacterium can be deployed in the search space.

In addition to the crossover mechanism, mutation at a desired
In a nutshell, the proposed hybridized algorithm inherits both crossover and mutation features of GA to improve its performance.
The algorithm is summarized in Appendix A . 3.4. CS algorithm Cuckoo search (CS) is an optimization algorithm proposed by the breeding of some Cuckoo species by laying their eggs in the nests of other host birds (of other species). Some host birds can the probability of hatching Cuckoo's egg depends on the intelli-that are not her own, it will either throw these alien eggs away or simply abandon its nest and build a new nest elsewhere as discussed in Chakraverty and Kumar (2011) . To be interesting, few Cuckoo species like the new worlds brood-parasitic Tapare have evolved in such a way that female parasitic Cuckoos are often very chosen host species. Cuckoo search technique idealized such breeding behaviour and, thus, can be applied to different engineer-
CS outperforms other Meta heuristic algorithms in some speci applications. This has motivated us to design recursive fi using the Cuckoo search technique. Here, we incorporate the constraint and repair mechanism for stability reasons. The proposed inbuilt constraint handling and repair mechanism attract the CS algorithm for recursive fi lter design applications.
 The fl ow chart for the Cuckoo search algorithm is presented in
Fig. 2 . The fl ow chart is explained in Appendix B . The cuckoo search algorithm is used here to optimize different fi lter coef cients that determine the performance of a fi lter. 4. Results and discussions
In this experiment, the maximum dimension of the search space for optimization is p  X  15 : Cost functions are given in Eqs. (4) and (18) .

The different parameters chosen for the COBFO and BFO algorithm are displayed in Table 1 . These parameters are chosen to obtain the best result. To reduce the computational burden, we usually assumed that the numbers of chemotaxis steps N c are greater than the number of reproduction steps N re , and N greater than the number of elimination and dispersal steps N
We choose N s  X  3, because we need a biased random walk (using the swim and tumble) very fast to get new sets of search space.
Other parameters are given as the best parameters obtained by extensive simulation. We have considered 100 independent runs.
The simulation is carried out on an Intel dual core processor with 1.75 GHz and 1 GB RAM, running under Windows 7 operating system. The algorithms are developed using MATLAB release 2009.
The different parameters chosen for the CS and GA algorithms are egg is recognized by the host bird. Hence, these nests are abandoned and removed from the population. But, in GA, mutation is the process of randomly disturbing genetic information to avoid in the population whenever the population tends to become homogeneous due to repeated use of reproduction and crossover which is usually a small value, termed as mutation probability. The requirement for mutation process is to generate a point in the neighbourhood of the current point, thereby attaining a local search around the existing solution. Therefore, we choose two different values for CS and GA. Such values are chosen to get the best results. 4.1. Results of Example 1 optimization algorithms and the corresponding values are given in Table 3 . 4.2. Results of Example 2
The fi lter coef fi cients for Example 2 are optimized using four optimization algorithms and the corresponding values are given in Table 4 . 4.3. Results of Example 3
The fi lter coef fi cients for Example 3 are optimized using four optimization algorithms and the corresponding values are pre-sented in Table 5 . 4.4. Results of Example 4
The fi lter coef fi cients for Example 4 are optimized using four optimization algorithms and the corresponding values are pre-sented in Table 6 .

The amplitude response of an ideal low pass fi lter M d  X  displayed in Fig. 3 . For a comparison, the use of Fig. 3 is quite signi fi cant in this work.

Estimated responses, for Example 4 using CS, CBFO and GA, are presented in Figs. 4  X  6 .

Tables 3  X  5 . These tables display the mean value of fi lter coef 9000 function evaluations, respectively. It may reiterate the fact that the mean of the 100 independent runs of each of the competing algorithms is taken. For Examples 1  X  3, the maximum dimension of the problem is 7. The best results (with minimum error) are shown in boldface letters.
 using CS, COBFO and GA as the competing algorithms. All these magnitude responses are drawn using the results obtained by minimizing J for 9000 functions evaluation. For the same numer-ical example, the result obtained using the COBFO algorithm provides a better approximation of the transfer function than the other algorithms. The CS algorithm is the second contestant here.
From Fig. 8 , it is seen that the frequency response obtained using the COBFO algorithm is closer to the desired response. COBFO is a better optimization approach than CS, BFO and GA. We conclude that the application of COBFO to optimize the design of arti fi cial intelligence. The application of COBFO to 2-D design may be useful for different image processing applications elapsed time is less than that of BFO and GA by 15  X  30%. From the bacteria foraging optimization is the best suitable evolutionary algorithm among the four.
 Appendix A COBFO algorithm
Step 1 : Initialize S number of bacteria with a p number of solutions, which satis fi es the constraints imposed.
Step 2 : Initialize the N c (chemotactic steps), N s (swimming length), N cmr (crossover-mutation-reproduction steps), N (elimination-dispersal steps), S r (bacteria that can reproduce), d attract (the depth of the attractant released by the cell), w (the width of the attractant signal), h repellant (height of the chemotactic step size), the mutation probability p m , P ed probability with which the elimination and dispersal event is done).
 Step 3 : Iterative algorithm for search
The modi fi ed algorithm that models bacterial population che-motaxis, swarming, reproduction, elimination, and dispersal is given here (initially, j  X  k  X  l  X  0). The algorithm automatically updates P using updates on  X  i .
 A. Elimination-dispersal loop: l  X  l  X  1 B. Crossover-mutation-Reproduction loop: k  X  k  X  1
C. Chemotaxis loop: j  X  j  X  1 iii) If J ( min ) {minimum value of  X  J  X  among all bacteria con-
D. If j  X  N c , then go to step 3. Otherwise continue chemotaxis process, since the life of the bacteria is not over.
 E. Crossover-mutation-reproduction:
After the N c chemotactic steps, a crossover-mutation-reproduction step is taken here. Let N cmr be the number of crossover-mutation-reproduction steps to be taken. After chemotactic steps, the population reproduces the next gen-eration consisting of suf fi cient nutrient values. For simplicity, we consider S to be a positive number (divisible by 4). Let
S c  X  S 2  X  35  X  be the number (population) having suf fi cient nutrient values, which continue for the next generation. For crossover-mutation-reproduction steps, the population is sorted in order of ascending accumulated cost (higher cost means the nutrient value is less); then the S c least healthy bacteria die. Note that the other S c healthiest bacteria are used for a crossover with probability p c to get S c child bacteria. Then, the new set of bacteria is formed by appending S c number healthiest (parent) bacteria and S c number of child bacteria. This helps us make the search domain more dynamic in nature, as parent bacteria start the search in the next generation where nutrient concentration is more while child bacteria search their nearby places that might be untouched due to the use of the BFO algorithm. constant. In this case, we have not reached the number of speci fi ed reproduction steps, so we start the next generation of the chemotactic loop.

G. Elimination-dispersal: For i  X  1, 2 ... S , with probability p eliminate and disperse each bacterium. To achieve this, if we eliminate a bacterium, simply disperse one to a random location within the optimization domain.
 H. If l o N ed , then go to step 1. Otherwise end .
 Appendix B CS algorithm Step 1 : Note that a set of host nests denotes a generation.
Interestingly, each nest carries an egg as a  X  solution  X  Step 2 : Check the constraints and inbuilt repair mechanism.
Step 3 : Here, the best nests with very high quality eggs or  X  solutions  X  from each generation are passed over to the next generation.

Step 4 : Note that the number of host nests is fi xed in each generation. An egg  X  solution  X  is chosen from a randomly selected nest. The egg is compared to an existing egg of another randomly selected nest. If it is better, replace the existing egg by the new egg.

Cuckoo's egg is recognized by the host bird. Such nests are abandoned and removed from the population.
 References
