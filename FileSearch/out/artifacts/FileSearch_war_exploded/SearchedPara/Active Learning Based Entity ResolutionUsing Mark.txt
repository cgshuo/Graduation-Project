 Entity resolution (ER) is a common data cleaning and data integration task that involves determining which records in one or more data sets refer to the same real-world entities. It has numerous applications for commercial, academic and government organisations including matching customer databases following a corporate merger, combining different data sets for research purposes, and detecting persons of interest for national security [ 4 ].
 In many applications, a domain expert can perform the ER task manually, albeit in a very time-consuming fashion [ 4 ]. If a domain expert is presented with two records and their context, they can usually determine whether or not the two records refer to the same real-world entity. As a result, one approach that learning algorithm selects pairs of records to present to an expert who then manually classifies them as either matches or non-matches. The results are then used to build an automated classification model.
 However, in domains such as group linkage [ 11 , 20 ] or population reconstruction form ER and the classification model may need to be more complex to capture the those proposed by Bhattacharya and Getoor [ 3 ], Kalashnikov and Mehrotra [ 15 ], and Markov logic networks (MLNs) [ 22 , 27 ], are all effective at capturing the intricacies of complex ER problems such as matching bibliographic data, group linkage and population reconstruction. In this paper we demonstrate how we can use active learning to incorporate the domain knowledge of experts into an active learning based framework to generate and refine the rules for an MLN based ER model. While the expert still classifies pairs of records as either matches or non-matches, the rule-based approach of MLNs allows a much more sophisticated ER model to be developed.
 literature relating to active learning, MLNs and ER, and provide a short back-ground on MLNs. In Sect. 3 we describe our notation and formally define the problem we are attempting to solve. In Sect. 4 we then present our approach for using active learning to create the rules and weights for an MLN based ER model. In Sect. 5 we evaluate our approach and in Sect. 6 we present our conclusions and some directions for future work. Entity resolution has been the subject of a large amount of literature, and several recent surveys have been conducted [ 9 , 17 ]. In this section we briefly outline recent techniques relating to MLN based ER and active learning based ER. to a range of problems. Proposed by Richardson and Domingos [ 22 ] they combine first-order logic and probabilistic graphical models into a single approach. First-order logic allows a compact representation and expression of knowledge, and probabilistic graphical models allow treatment of uncertainty. Combining these two techniques allows MLNs to perform inference on a wide variety of problems and to handle contradictory knowledge and uncertainty.
 all rely on training data being available which is often not the case for ER [ 4 ]. Moreover, due to the fact that the classes of matches and non-matches are typi-example, a random sampling might require reviewing hundreds or thousands of non-matches for every match found.
 scalability of MLNs is a problem which has been partially overcome by Rastogi et al. [ 21 ]. Their experiments showed that MLN based techniques can achieve very high quality ER in situations where training data exists and the scalability problems can be overcome. As a result, an approach that uses active learning to generate training data can be used to learn the rules and weights for an MLN. In doing so it would allow the full power of MLNs to be applied to many more entity resolution applications where training data does not exist. data so that supervised classification techniques can be applied. It has been extensively studied and a survey of relevant literature has been conducted by for manual classification and the features of these examples are used to build a classification model.
 As described above, one particular problem when using active learning for entity resolution is that the classes of matches and non-matches are typically very unbalanced. As a result, a challenge with each of these techniques is to select representative examples of each class to present to the expert for manual clas-sification. This has been addressed in several ways including exploiting cluster structure in the data [ 29 ] and using a multi-stage algorithm that prunes redun-dant pairs [ 7 ]. However, active learning has not been used to generate a training set for use in creating an MLN based ER model.
 Active learning techniques vary based on the way examples are selected for manual classification. Of particular relevance to this paper are techniques deal-ing with variance reduction and density weighted methods. Variance reduction based techniques aim to reduce generalisation errors by minimising output vari-ance and have been applied to classification models such as neural networks [ 18 ] and conditional random fields [ 25 ]. Density based techniques such as that pro-posed by Settles and Craven [ 25 ] aim to ensure that the examples chosen for manual classification are not only uncertain, but also somehow representative of the underlying distribution. This means that the expert does not waste time classifying outliers, which may be uncertain, but have minimal impact on the overall classification quality.
 Finally, while traditional active learning techniques make use of an all-knowing domain expert to perform the manual classification, from a practical perspective this may not always be possible. Variations have been proposed which deal with noisy oracles, i.e. experts who return the wrong classification result [ 8 ]. Instead of a domain expert, other techniques make use of crowd-sourcing to perform the labelling [ 28 ]. While our technique does not explicitly deal with these variations, there is no reason why different forms of oracles could not be used instead of the traditional domain expert. 2.1 Markov Logic Networks An MLN consists of a set of weighted first-order logical formulae (rules). In a traditional first-order knowledge base, a single violation of a formula invalidates the entire knowledge base. However, for an MLN, the weight of a formula indi-cates the relative strength of the formula, i.e. its likelihood of being true. As a result, an MLN can handle noisy or inconsistent data without requiring a huge number of very specific formulae. Formally, given a set of first-order formulae MLN as a Markov random field where each node is a grounding of a predicate and each feature is a grounding of one of the formulae. The joint probability distribution is given by: where n i is the number of times the i th formula is satisified in world a normalisation constant [ 22 ].
 inductive logic programming [ 16 ], and a number of techniques have been devel-oped to determine their weights using training data, both in batch mode [ 13 , 26 ] and online [ 14 , 19 ]. We briefly describe the notation we will use in this paper. We begin with a data set R . We assume a finite list of rules U = u 1 ,u 2 ,...u is a function that takes as input two records r i ,r j  X  R and returns either or False . We denote the number of rules in U as | U | . Each rule real valued weight denoted w ( u ). An example of a rule is: which returns True if records r 1 and r 2 have values n 1 the Name attribute, and n 1 and n 2 are the same, and False with positive weights indicate positive evidence that records same entity (match), while rules with negative weights indicate negative evidence that r i and r j refer to the same entity (non-match). By creating rules in this format and relating them to whether the records are a match or non-match, these rules can later be easily converted to formulae for the MLN model [ 27 ]. We assume that the initial list of rules is provided by a domain expert who will be performing the manual classification in the active learning process. as V . We generate a rule vector by applying each u  X  U to a pair of records r ,r |
U | where v [ k ]=1if u for 1  X  k  X | U | . Since different pairs of records may produce the same rule vector, for each rule vector v x we define a set of record pairs r ,r Since V only includes rule vectors that are produced by a pair of records in R , its size is limited to the smaller of O( | R | 2 ) and O(2 significantly smaller than both these limits. The weight of each w ( v )=( w ( u weights of those rules that are set to True in v .
 as per other active learning techniques [ 24 ]) to perform manual classification as part of our approach. However, typically the expert can only classify a certain number of record pairs so we assume a total budget of manual classifications b with b  X  1. The budget is divided into q manual classifications per round, over n rounds, where q  X  n = b . In future work we intend to investigate ways to adaptively distribute the budget [ 29 ]. We denote the output of the manual classification of records r j and r k as o jk where o jk = classified as a match by the expert and o jk = False if they are classified as a non-match.
 During the active learning process we need a way of determining which record strategy S as an ordering of the rule vectors in V . After ordering V by we select one candidate pair from each of P ( v 1 ) ...P ( the expert, where q is the number of manual classifications each round. Some (
S := descending sort of w ( v )), (2) the most definite negative examples ( ascending sort of w ( v )), (3) the most definite examples of either type ( descending sort of | w ( v ) | ), (4) the most ambiguous cases ( of | w ( v ) | , since the most ambiguous cases have a total weight close to 0), (5) the most commonly occuring vectors ( S c := descending sort of S := random ordering.
 Problem Statement: Given a data set R , an initial set of rules U a strategy S , and an expert E who can make manual classifications, the problem is to generate a balanced set of training examples for an MLN based ER model, a final set of rules U n , and values of w ( u i )foreach The basic idea of our approach is that we apply traditional active learning tech-However, in addition to classifying each pair as either a match or a non-match we ask the expert to specify the reason for their decisions -i.e. the rule(s) that most influenced their decisions. In the case where the expert X  X  classification of a pair contradicts the weight of the corresponding rule vector, i.e. a record pair the expert to specify a new rule that would cover the particular pair. We could also use inductive logic programming based techniques [ 16 ] to specify the new rule instead. This new rule is then added to the current list of rules and is used to evaluate record pairs in the next iteration of the active learning process. Our approach is described in Algorithm 1. We begin with an initial list of rules U created by the domain expert, along with a selected strategy the process, we refine the list of rules along with the weights in order to end up with a final list of rules that will be converted to formulae in an MLN based ER model. Our algorithm assumes the budget is split into n rounds, with classifications per round, such that q  X  n = b . Each iteration of the main loop (lines 2  X  22) is one round of the algorithm.
 Within each round, we start by creating an empty set of rule vectors (line 3). Because calculating a rule vector for each pair r i ,r j  X  O ( | R | 2 ), we make use of blocking to reduce the number of rule vectors calculated. records within the same block are compared [ 5 ]. We assume the blocking process is a black box where we pass a data set and get back a set of blocks (line 4). Within (lines 5 X 11).
 (line 12). Then, we select a candidate pair from each of the first V  X  to be presented to the expert E for manual classification (lines 14 X 15). Based on the output of this manual classification we update the weights of the rules in U i , and if the manual classification result is contrary to what the weights of the rule vectors indicate, i.e. w ( v ij ) &gt; 0 but o but o ij = True , we ask the expert to create a new rule that would cover the incorrectly classified pair (line 18). Alternatively, techniques such as inductive logic programming based learning [ 16 ] could also be used to refine the rules in U i so that the incorrectly classified pair is fixed.
 look at removing the least informative rules from U i based on a combination of the absolute values of their weights and their coverage. For each rule we calculate a score s = | w ( u j ) | X  log ( | T ( u j ) R ,u which allows us to avoid overfitting and keeps rules with a balance of high predic-tive power (both positive and negative) and high coverage. 4.1 Building Blocks of the Algorithm We discuss some aspects of the approach in more detail, namely blocking, the choice of strategy S , and some considerations to prevent overfitting. Blocking. In our approach we treat the blocking step in line 4 as a black box. However, there are some blocking techniques that are more appropriate to our approach than others. One practical consideration is that ideally we will use the same blocks from our algorithm in the MLN based ER model. Since the scalability of MLNs is typically very poor, this means we need to limit the maximum block size by using sorted neighbourhood based blocking [ 12 ]ora size-constrained clustering approach similar to Fisher et al. [ 10 ]. In addition, the rules in U i can be used to inform the blocking. If we sort the rules in U i based on w ( u ) and use the rules with the highest weights to generate blocks, we typically get a blocking approach that is well aligned with an MLN based ER model. For example, if having the same surname is strong evidence that the records are a match (as indicated by a large positive weight to the associated rule), then by placing records with the same surname into blocks, we know that during the ER process, the records being compared have a higher likelihood of being matches since they satisfy at least one rule with a large positive weight. After we have generated the set of blocks B , we need to use the candidate pairs in each b  X  B to generate our rule vectors. Even when blocking is used, computing  X  ( U ,r i ,r j ) for all candidate pairs within all blocks is equivalent to the complete matching step in a traditional manual classification anyway, we instead sample a large number of pairs. While this does not mathematically guarantee that every rule vector is generated, in practice it means that the frequently ocurring ones are present. In addition, after an earlier round, we can apply U to the pairs in P ( v k ) from the earlier round to ensure that v k is also represented in the current round.
 Selection Strategy. In Sect. 3 we described several possible strategies for based on w ( v )and | P ( v ) | . In practice we also wish to record the number of manually classified examples for each v  X  V , along with their counts of and False from the manual classifications. This is because if we keep the same rounds. As a result, we end up sampling candidate pairs for the same rule vectors in each round. We can avoid this problem by incorporating previous results into the ordering. If the manual classification for a rule vector always returns the same value of True or False we can lower its priority in the ordering. However, if a rule vector produces a mix of True and False values when being manually to change the strategy S between rounds. For example, we can start by looking at the most frequently occuring rule vectors (highest values of we have a good list of rules for the frequent pairs we can change strategies to deal with the difficult cases (lowest values of | w ( v ) investigate ways to determine the optimal choice of strategy.
 Overfitting. In practice care needs to be taken to prevent overfitting. In the implementation of our approach described in Algorithm 1, we assume the starting number of rules is the desired number for the final model. However, there is no reason this needs to be the case and we can use a different mechanism to limit the number of rules such as specifying a different maximum number of rules or a minimum score s min , using the scoring method described in Sect. 4.0. In practice it can be the case that the newly added rule has the lowest score and we end up removing it straight away. This essen tially means that the expert E has ended up manually classifying an outlier or exception, so using it to inform other matching decisions will lead to overfitting. We have evaluated our approach on two data sets. (1) Cora: This is a public bibliographic data set of scientific papers that has previously been used to eval-uate ER techniques [ 27 ]. This data set contains 1,295 records and truth data is available. (2) UKCD: This data set consists of census data for the years 1851 to 1901 in 10 year intervals for the town of Rawtenstall and surrounds in the United Kingdom. It contains approximately 150,000 individual records of 32,000 households. A portion of this data (nearly 5,000 records) has been manually linked by domain experts. Fu et al. [ 11 ] have used this data set for household based group linkage where the task was to link households across time. tion, we limited our evaluation to the portions of the two data sets that truth data was available and o ij was known for all pairs of r i Cora and about 5,000 records in UKCD. Instead of allowing the expert to select significant rules and altering their weights appropriately we adjusted the weights automatically. For each rule vector v ij , where a candidate pair was selected for manual classification, we adjusted the weights for each where u k ( r i ,r j )= True as follows: if o ij = True and w ( u If o that rules that were True and correctly predicted the classification result had their weights increased while those that were True but incorrectly predicted the classification result had their weights decreased.
 1.3 Ghz CPU, 4 GBytes of memory and running OS X. All programs were written in Python 3. None of our experiments took longer than five minutes to run 20 rounds of 10 manual classifications each (200 manual classifications in total). Since in a practical ER application each manual classification is likely to take a few minutes, our approach runs fast enough that the slowest part of the process will be most likely be the manual classification step.
 For our evaluation we consider two measures, the ratio of candidate pairs classified as matches to the candidate pairs classified as non-matches by the expert E , and the rule weights generated by our techniques. To generate a bal-anced training set the ratio between matches and non-matches should be as close to 1 as possible. We also examine the weights that are generated for the rules in U n at the end of our algorithm as ideally these will be used as the weights for the corresponding formulae in the MLN. We consider both the total sum of the weights calculated as | ( w ( u i ): u i  X  U n ) | as well as the maximum value of | w ( u For both data sets, we created a list of rules based on simple attribute equality and assigned weights of 1 to those rules that were positive evidence that the two records might be the same (i.e. the values in the attribute were the same) and weights of  X  1 to those rules that were negative evidence that the two records might be the same (the values in the attribute were different). For Cora we used a total of eight rules, four with positive weights and four with negative weights, and for UKCD we used 10 rules, five with positive weights and five with negative weights. For both data sets we set q = 10 and varied the value of different budgets b .
 Figure 1 shows the ratio of candidate pairs classified as matches vs non-matches in the manual classification step for the strategies described in Sect. 3 . Figure 2 shows the sum of the rule weights for the rules in U strategies that produce the most balanced splits of the training data between matches and non-matches are S + and S a with the other strategies generally performing poorly. The strategy S + orders the rule vectors by descending walue of w ( v ) which means that a candidate pair from rule vectors with the highest positive weights are always presented to the expert for manual classification in each round. Since apriori these are the rule vectors most likely to be matches, this strategy is effective at overcoming the class imbalance between matches and non-matches. While S a selects candidate pairs from rule vectors that are hard higher proportion of non-matches, as the algorithm proceeds the negative rule weights get further away from 0. This means that the candidate pairs that are presented to the expert are more likely to have satisfied positive rules and thus be matches which leads to a degree of balance in the classifications. This is also true of the weights generated by these two strategies which do not get very large, either in terms of the sum of the weights or the largest absolute weight. This is because after the initial rounds, these strategies mean that the expert is almost exclusively being presented with non-matches which creates a com-pounding feedback loop where the weights on the negative rules get more and more negative. As a result, none of these strategies produce balanced training sets and the weights they produce for the rules are not useful at all for an MLN based entity resolution model.
 MLN based ER model, they do not resolve to an equilibrium around the correct weights like we had hoped for. As a result, in the future we intend to combine our technique with an online weight learning algorithm such as those proposed by Mihalkova and Mooney [ 19 ] or Huynh and Mooney [ 14 ]. By linking the weight learning with the generation of training data through active learning we hope to be able to generate weights for an MLN with our technique. In this paper we have presented an active learning technique for generating training examples for a Markov logic network based entity resolution model, as well as a technique for learning the necessary weights for the MLN formulae. We have also presented a method which allows a domain expert to add new rules to the MLN to capture pairs of records that are not being correctly classified by the existing model. We show that our technique is effective at generating balanced training sets to be used for learning an MLN based ER model, however it is currently less effective at generating appropriate weights for the MLN formulae. In the future we intend to extend the work in several directions. We aim to investigate ways of adaptively distributing the budget of manual classifications, both in terms of the number of questions per round and the number of rounds similar to Wang et al. [ 29 ]. We also aim to test our techniques on other data sets and ER problems such as population reconstruction [ 6 ]. Finally, due to the fact that our techniques were not as successful at learning correct weights for the formulae in the MLN, we intend to investigate using our technique in conjunction with an online weight learning approach for MLNs, such as those proposed by Mihalkova and Mooney [ 19 ] or Huynh and Mooney [ 14 ].

