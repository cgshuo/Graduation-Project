 Da Yan  X  James Cheng  X  Zhou Zhao  X  Wilfred Ng Abstract Given a database of trajectories and a set of query locations, location-based tra-Location-based trajectory search has many applications such as providing reference routes without paying a visit. We propose the k Important Connected Trajectories ( k -ICT ) query by ries should contain an important point close to it. We describe an effective method to infer the importance of trajectory points from the temporal information. We also propose efficient R-tree-based and grid-based algorithms to answer k -ICT queries, and verify the efficiency of our algorithms through extensive experiments on both real and synthetic datasets. Keywords Trajectory  X  Location importance  X  Threshold algorithm  X  Voronoi diagram 1 Introduction With the popularity of location-acquisition technology, huge amounts of trajectory data are being generated at an unprecedented scale. We differentiate two types of trajectory data. The first type is simply a sequence of time-stamped locations, usually generated by mobile devices such as cell phones and GPS receivers at a relatively high sampling rate. The sample points in such trajectories have very little or no semantics, and many recorded locations are not important. The second type of trajectory is a sequence of locations with semantics, where each recorded location is usually important. One example of such a trajectory is a sequence of geo-tagged photographs taken by a traveler in a trip. Numerous such trajectories can be obtained from photo-sharing Web sites such as Flickr ( www.flickr.com ), and people usually take photographs at locations they like. Another example of such a trajectory is a sequence from location-based social network services such as FourSquare ( foursquare.com ).
The proliferation of trajectory data has spawned many novel applications. One example is in Chen et al. [ 1 ]asthe k Best-Connected Trajectories ( k -BCT) query. Given a few query database. Location-based trajectory search can benefit users in many real-life applications. unfamiliar city, by providing similar routes traveled by other people for reference. Location-based trajectory search is also useful in human behavior analysis, where the query locations can be tourist attractions (specified by a travel agency) or the stops of a new metro line (specified by the transport department).

The k -BCT query, however, considers only the spatial aspect of trajectories, which is inadequate for many real applications. Consider a travel agency that queries a database of belonging to a different tourist. For simplicity, we assume the data space to be 1D rather than 2D, and we only mark the relevant trajectory samples using . For example, Tom spent 15 min at the airport (for check-out), 1 h at Outlet A (for shopping), 8 s at Outlet B (just passing by), and 30 min at the hotel (for check-in and taking a rest). From Fig. 1 , we can see that young people (e.g., Peter and Alice) may usually go shopping at Outlet B on their way from the airport to the hotel, while middle-aged people (e.g., Tom and Mary) would prefer to go shopping at Outlet A. Unfortunately, a 2-BCT query over the database with query locations, {Airport, Outlet B, Hotel}, would return the trajectories of Tom and Mary (who actually went shopping at Outlet A), since the fifth sample in the trajectories of Tom and Mary is closer to Outlet B than any of the samples in the trajectories of Peter and Alice. As a result, the travel agency may make a wrong arrangement: When a tourist bus picks up for the tourists to go shopping.

This example demonstrates that it is necessary to take location importance into consider-ation. Although Tom and Mary have a trajectory sample close to Outlet B, the importance of the sample with respect to the whole trajectory is low since Tom and Mary just passed by Outlet B. On the contrary, Peter and Alice went shopping at Outlet B, though their trajectory samples are farther away from Outlet B (the samples were probably recorded at a car park nearby).
 Important Connected Trajectories ( k -ICT) query, over a database of trajectories associated with location importance. We discuss how to derive the importance of trajectory sample points from their timestamps, and develop efficient algorithms for answering k -ICT queries.
The main contributions of this paper are summarized as follows:  X  We propose the k -ICT query over a database of trajectories with location importance, which returns trajectories of much higher utility compared with the k -BCT query [ 1 ].  X  We design a practical method for deriving the importance of trajectory sample points from their timestamps.  X  We propose two R-tree-based algorithms for answering k -ICT queries, founded on two variants of Threshold Algorithm (TA) for top-k queries.  X  We further develop two grid-based algorithms, which process k -ICT queries using our grid index built from the multiplicatively weighted Voronoi diagram (MWVD) of trajec-tories. The grid-based algorithms address the drawbacks of the R-tree-based algorithms.
Experiments show that the grid-based algorithms are more efficient in terms of both time and space.
 The rest of this paper is organized as follows. Section 2 reviews the related work. In Sect. 3 , we formulate the k -ICT query. Section 4 discusses how to derive trajectory location importance from raw GPS data. We present our R-tree-based algorithms in Sect. 5 and describe the grid-based algorithms in Sect. 6 . We report experimental results in Sect. 7 and conclude the paper in Sect. 8 . 2 Related work Conventional trajectory search Given a query trajectory, conventional trajectory search finds samples and thus may overrate insignificant trajectory samples.
 Trajectory search by locations Location-based trajectory search was first proposed by Chen specify the places he/she intends to visit as the query points, by clicking them on a digital trajectory. However, as we shall discuss in Sect. 3 ,Chenetal.[ 1 ] adopt a distance measure is more reasonable in real-life applications. Recent research starts to enhance location-based trajectory search with keywords [ 2 , 3 ].

The problem with these works is that they do not consider location importance and thus queries may easily overrate insignificant trajectory samples, as illustrated by the example described in Sect. 1 .
 Trajectory search by patterns The location-based trajectory search mentioned above does not allow users to specify any constraints other than a set of query location. This kind of query is easy to specify and satisfies the requirement of many applications. For example, a tourist to an unfamiliar city may have some famous scenic spots in mind, but does not have a concrete plan yet. He/she may use the location-based trajectory search to find some related trajectories for reference.
 However, there are also cases where users would like to add more constraints to the query. For example, a tourist in Seattle may want to visit the museums first as they only open in the daytime and then goes to the Space Needle that stays open at night. In fact, the city view may be more beautiful at night. In this case, a user may formulate a spatial-temporal pattern in Hadjieleftheriou et al. [ 10 ].
 Mining important locations from trajectories There are studies on how to mine important measure location importance from all the trajectories. Another work [ 13 ] finds important locations from a single trajectory. The work models a trajectory by stops and moves ,wherea stop is a semantically important part of the trajectory. They proposed the IB-SMoT algorithm to generate stops: Given a database of geographic objects, if a part of trajectory intersects with the object and the time span of the sub-trajectory is above a minimum time threshold, trajectory samples to find stops, such as CB-SMoT [ 14 ]andDB-SMoT[ 15 ]. Conceptually, the samples of a stop are important, while the samples of a move are immaterial. However, these methods do not provide a concrete importance score for the samples (or stops), and thus, it is impossible to compare the importance of different samples (or stops). Other topic about trajectory processing Sometimes, the trajectory data are sampled in a very low rate like every several minutes or even every several hours. In this case, the behavior trajectories, where the road network information is used to reduce the uncertainty caused by low sampling rate.

There are also works that use the trajectories to discover regions of different functions in functional sections of Beijing, by using data sources such as points of interest (POIs) and GPS readings collected from taxis. 3 Problem formulation We now formally define the k -ICT query. Let D be a database of trajectories, where each For raw GPS data, we can derive the importance score using the time stamps of the trajectory photographs, the location importance of a photo can be derived using the number of page visits; the score can also be manually set by the photo owner.
 We first introduce the distance functions that define how a k -ICT query is to be evaluated. Distance related to one query point Let us first focus on a specific query point q i  X  Q .We define the weighted distance between query point q i and a trajectory point p j as follows: where we use pq to denote the Euclidean distance between two points p and q . Note that a larger importance score w( p j ) makes p j closer to q i (since d ( q i , p j ) is smaller).
We define the weighted distance between query point q i and a trajectory T = ( p 1 , p 2 ,..., p ) as the weighted distance between q i and its closest trajectory point in T : GPS trajectory fragment shown in Fig. 2 , which is generated as follows. A traveler rented a GPS-equipped car to travel around a city. He drove to a car park near a museum, parked his car, stayed in the museum for an hour, and then drove to the next destination. Since the car was turned off when it was parked, the on-board GPS device was also off. As a result, no sample was generated during that 1 h when the car was parked, and p i  X  T is the first sample after the traveler drove the car away from the car park.

In this example, the query point q in question is the museum. Now assume that w( p ) is estimates the confidence that the traveler of T visited the museum, since he may instead the confidence that the traveler visited the museum since he actually visited the aquarium nearby the point p i + 1 . Thus, d ( q , p i ) presents an accurate estimate in this case. Overall distance function We now define the weighted distance between a query Q and a trajectories close to all query points in Q , we define the overall weighted distance as: all q i  X  Q .
In addition to the physical meaning described above, Eq. ( 3 ) is also meaningful from the probabilistic point of view, which we discuss next. Let us denote p n i to be the trajectory  X  e that the owner of trajectory T visited all q i  X  Q is: where we assume that  X  X hether the owner visited one query location X  is independent of  X  X hether he visited another query location. X 
Since we want to maximize the probability value of Eq. ( 4 ), it is equivalent to minimize d ( Q , T ) = m i = 1 d ( q i , T ) .
  X  = 1, then sim ( Q , T ) = m is undesirable, since the similarity value is high as long as one query point is close to T , even if all other query points are far from T . Similar observation is mentioned in Tang et al. [ 8 ], which proposes to use a sum-of-Euclidean-distance measure. In this paper, we use the sum-of-weighted-distance measure to incorporate object importance.
 We d e fi n e k -ICT querying as follows.

Complexity analysis Let us denote the size of a trajectory T (i.e., the number of trajectory by D = T  X  D | T | .Notethat D is different from the number of trajectories in D , which is given by n =| D | .Givena k -ICT with m query locations, for each trajectory T , we may compute the closest point to each query location in O ( | T | ) time and thus compute the closest points to all query locations in O ( m | T | ) time. We may then compute the sum-of-weighted-distance score for each trajectory in O ( | T | ) time. Therefore, we may compute the scores for all trajectories in T  X  D O ( m | T | ) = O ( m T  X  D | T | ) = O ( m D ) time. a priority queue of size at most k . Therefore, the time complexity of a k -ICT is bounded by O ( m D + n log k ) . However, this brute-force approach requires scanning the whole database once, as the time complexity is linear to D and n . In the rest of this paper, we trajectories. 4 Location importance In this section, we discuss how to compute the importance of trajectory samples from raw GPS data. stop is more likely to be important. On the other hand, a 1-h stop quite certainly implies an important location, and the score should not increase too much even if t ( p i ) becomes 2 h.
When t ( p i ) = 0, we want the importance w( p i ) = 0. Furthermore, we want w( p i ) trajectory T stops at p i . As a result, we define our importance score as follows: where  X  controls how fast w( p i ) increases with t ( p i ) .
 Computation details Next, we discuss the details of computing t ( p i ) .Wefirstdescribe how we compute p r (the computation of p l is similar) for the scenario in Fig. 3 b, where p j  X  T is inside Cir ( p i ) and the next sample p j + 1 is outside of Cir ( p i ) .
Instead of directly computing p r , we first compute segment length p j p r . According to thecosinelaw,wecancomputecos p i p j p r as follows: where p i p j , p j p j + 1 and p i p j + 1 can be easily computed from the coordinates of p , p j and p j + 1 .

Then, according to the cosine Law, p j p r can be obtained by solving the following quadratic equation: where p i p j is computed from the coordinates of p i and p j ,and p i p r = r . The roots of Eq. ( 7 )are:
However, the second root p j p r ( 2 ) can be discarded since its value is negative. To see this, recall that p j is inside Cir ( p i ) , and hence, p i p j &lt; r . Thus, we have given by Eq. ( 8 ).
 The algorithm is described in Algorithm 1 . We check samples forward along T starting from p is inside Cir ( p i ) (due to the convexity of circles), and we accumulate the time spent on Algorithm 1 Computing ( t ( p r )  X  t ( p i )) p p j + 1 to the result (Lines 3 X 4). Otherwise, we compute p r and accumulate the time spent of Cir ( p i ) and thus the accumulated time is directly returned (Line 8).
 Parameter setting We have two parameters: (1) radius r of Cir ( p i ) and (2) the decay rate  X  in Eq. ( 6 ). Typically, r is set as the diagonal length of a market place, or the distance between a car park and the intended destination. While the parameter choice is application dependent, our experiments on several vehicle GPS datasets show that our method always provides reasonable importance score (judged by human) when r = 50 m and  X  = 0 . 002. The details are omitted due to the space limitation. 5 R-tree-based algorithms In this section, we introduce two R-tree-based algorithms for answering k -ICT queries. Before we present our algorithms, we first describe the Threshold Algorithm (TA) [ 18 ], since our algorithms adopt the TA framework for top-k query processing. 5.1 Threshold algorithm and its variants TA [ 18 ] has been widely adopted for processing top-k queries, including the k -BCT querying equals the summation of the values of all its m attributes (a smaller score is preferred). from each list in a round-robin manner, until there are k tuples whose ids have been seen table D if any of its attribute values are missing (random access to D is needed). Step 3: compute the ranking score by summing the attribute values for each tuple whose id has been seen, and return the k tuples with the smallest summation values. Threshold algorithm (TA) Unlike the filter-and-refine framework of FA where random access to D is only used in the refinement step, TA adopts a more aggressive approach. TA also reads a ( id ,v al ) pair from each list in a round-robin manner, but for each tuple id seen, TA immediately retrieves the tuple from D by random access, computes the ranking score, the ranking score of the current top k -th tuple is equal to or smaller than m i = 1  X  i .
In general, TA reads less pairs from the lists than FA, but performs more random accesses to D than FA. While we focus on FA and TA when introducing our algorithms, other variants of TA may also be adopted by our algorithm. 5.2 R-tree-based algorithms We now present our R-tree-based algorithms. We first describe a key operator used by our algorithms: the incremental weighted nearest-neighbor ( NN ) algorithm.
 Incremental weighted NN algorithm Unlike Chen et al. [ 1 ], in our problem, each trajectory evaluated as qp i w( p function MAX, called MAX R-tree .

Compared with a traditional R-tree, each node entry e of a MAX R-tree maintains the maximum importance score among all points indexed under e (i.e., indexed in the subtree aggregate value by w( e ) . We also denote the minimum bounding rectangle ( MBR )of e by mbr ( e ) . Then, for any trajectory point p indexed under e , its weighted distance to query point q is given by: holds as mindist ( q , mbr ( e ))  X  qp and w( e )  X  w( p ) .
 For simplicity, given an R-tree node entry e and a query point q ,wedefine: under e to q .

Algorithm 2 describes our incremental weighted NN algorithm. When processing a k -ICT next NN of q i can be incrementally obtained using Algorithm 2 . Initially, the priority queue min-heap contains only the root node of the Max R-tree tree , and each call of Algorithm 2 updates min-heap and retrieves the next NN of q i .
 We now explain Algorithm 2 in details. In each round, the entry e with the smallest next NN (Line 5), since any unseen trajectory point p is indexed under some node entry en node node , and we enqueue all the entries of node into min-heap (Lines 7 X 10). Algorithm 2 Computing the Next Weighted NN of q i R-tree-based FA and TA We now introduce our two R-tree-based algorithms for answering k -ICT queries, one based on FA and the other based on TA. Both algorithms use Algorithm 2 for sequentially accessing the next NN of each query point q i .
 Algorithm 3 presents the R-tree-based FA for answering k -ICT queries. Similar to FA, (Lines 16 X 20).
 Algorithm 3 R-tree-based FA for Answering k -ICT Queries
In each round of the filtering phase, Algorithm 3 obtains the next NN of each q i for processing (Line 4), i.e., the NNs of the query points are processed in a round-robin manner. Since there are N trajectory points indexed by tree , there are at most N rounds (Line 3). All the seen trajectories are maintained using a hash table table , where the hash key is the Algorithm 4 R-tree-based TA for Answering k -ICT Queries trajectory id. If the trajectory of the obtained point p has not been seen yet, we know that d ( we ignore the obtained point p since the point in T that is closest to q i has already been q  X  Q , which is similar to the traditional FA.
 been assigned (a more efficient method of obtaining T [ i ] is actually used, which we will the k tuples with the smallest values of d ( Q , T ) are returned.

Algorithm 4 presents the R-tree-based TA for answering k -ICT queries. Recall that the conventional TA maintains a variable  X  i for each list L i , whose value equals the attribute NN of q i .Weset  X  to 0 at the beginning of a round-robin processing round (Line 5) and add  X  processing round,  X  = m i = 1  X  i is exactly the pruning threshold, which is then compared with the top k -th trajectory in Line 17 to determine the stopping condition.
In Lines 9 X 15, we only process the trajectory T of the current point p if T is not in table , must have been assigned for all i = 1 ,..., m (Lines 10 X 12), and hence, we can ignore T .
Finally, we note that the correctness of both Algorithms 3 and 4 is easy to see by following the correctness of FA and TA [ 18 ]. We thus omit the details here. Limitations of R-tree-based algorithms We identify the following limitations of using an R-algorithm to be introduced in Sect. 6 .

Firstly, the incremental NN search for each query q i is done over an R-tree that contains all the trajectory samples. However, if we know q i beforehand, then only one sample per trajectory requires examining (i.e., the sample with the shortest weighted distance to q i ), and there are totally n =| D | such samples, much less than the number of all samples in D . Therefore, there is huge room for improvement in terms of sample candidate pruning. Secondly, much of the computation done by the R-tree-based algorithms could be wasteful. This is because consecutive samples of a trajectory are close in space and are very likely indexed under the same R-tree node. As a result, in consecutive calls of Algorithm 2 for retrieving the NNs of a query point q i , many returned NNs may come from the same trajectory.
Finally, we use the maximum importance w( e ) of an R-tree node entry to compute the lower bound in Eq. ( 11 ), which is not tight. As long as there is one point indexed under e with a large weight, the whole entry e has to be accessed early even if all the other points 6 Grid-based algorithms In this section, we present the grid-based algorithms.
 Overview We first give an overview of how our grid-based algorithms address all the three drawbacks of the R-tree-based algorithms mentioned in Sect. 5.2 .

Firstly, to avoid doing NN search over all trajectory points, we divide the data space by a grid, so that each grid cell covers a small region. We observe that only a small fraction of samples per trajectory have the chance to be the NN of some location in a cell. Thus, if a query point locates in a grid cell, we only need to check the samples relevant to the cell.
Secondly, to avoid checking a lot of samples of a trajectory that do not contribute to the top-k answers, we propose to pre-compute the multiplicatively weighted Voronoi diagram ( MWVD ) of the points of each trajectory. Note that a sample p i is the weighted NN of q if and only if q locates inside the Voronoi cell of p i .
 is done in the unit of trajectories rather than trajectory points.

We discuss these ideas in details in the following subsections. 6.1 Trajectory preprocessing by MWVD For each trajectory T = ( p 1 , p 2 ,..., p ) , we pre-compute the MWVD [ 20 ] of its points, which is then used to build our grid index. We first briefly review the MWVD and then show how we use it in our solution.

Let U be the data domain. Given two samples p and p ,the dominant region of p over p is defined as:
We now consider the shape of R p | p . Let us first assume that w( p )&lt;w( p ) ,then R p | p follows: Apollonius circle, since for any point x on its boundary, px p x = w( p ) w( p ) .
When w( p )&gt;w( p ), R p | p is characterized by the region outside of circle C p | p .For to the half plane that contains p , denoted by H p | p .
 The Voronoi cell of a trajectory point p  X  T is given by: since any point in VC ( p ) should be in R p | p for any p  X  T  X  X  p } .Givenasample p  X  T , we divide the other samples in T into three sets: T + contains all samples p with w( p )&gt; w( p ) , T  X  contains all samples p with w( p )&lt;w( p ) ,and T 0 contains all samples p with w( p ) = w( p ) .

Equation ( 12 ) implies that VC ( p ) may be represented by  X  1 circles or lines in the worst can be pruned by the six pruning rules presented in Wu et al. [ 21 ]. We adopt the best-first search algorithm of Wu et al. [ 21 ] for MWVD computation, but the computation is done in memory since the number of points in each trajectory is usually not large. 6.2 Grid index Next, we describe two indices used in our grid-based algorithms. In our problem, we assume locate inside U . For example, U can be the bounding box of a city region. Our grid-based approach divides U by an N  X  N grid, denoted by G .

For each trajectory T , we build a random access index, denoted by RAI [ T ] , which returns d ( for a query point q falling in G [ i , j ] . Random access index (RAI) We now describe how we build RAI [ T ] . First, we compute need to characterize its shape within R .If VC ( p ) does not overlap with R , p cannot be the weighted NN of any location in R , and is thus pruned.

We now consider how to compute VC R ( p ) from the original VC ( p ) .Wedividethe the following:
VC ( p )  X  R p | p = X  ; thus ( p , R p | p ) is not included in VC R ( p ) ;  X  Otherwise, ( p , R p | p ) is added to VC R ( p ) .
 Figure 5 lists the conditions for cell pruning and pair pruning when p  X  S + , S  X  ,and S 0 .
In our implementation, we do not compute S ( R ) for each grid G [ i , j ] with region R directly from the original Voronoi set. Instead, we perform the computation by building a quadtree qtree whose leaf nodes correspond to the grid cells. By specifying the height of the quadtree as h , we obtain a 2 h  X  2 h grid (i.e., N = 2 h ).

Each quadtree node, node , is associated with a region node . R and a set of the Voronoi cells child node of r oot with le v el = 1. For each node, we compute its Voronoi cell set only Algorithm 5 Computing Quadtree Node node for any location in node . R , p is its weighted NN. We stop recursion in that case (Line 5). Otherwise, if the current level is not the leaf level, we continue to split node and construct its four children (Lines 6 X 8).

After the quadtree qtree is constructed, for all its nodes node , S ( node . R ) is already computed. Then, for each grid cell G [ i , j ] with region R , we compute the set of trajec-
It is easy to see that, for any query location in R , its weighted NN must be some trajectory trajectory T ,westore C T , which is an N  X  N array of trajectory point lists, on disk as the random access index RAI [ T ] .
 Given a query point q , we identify the grid cell G [ i , j ] that q locates in, load the list C
T [ i , j ] into memory, and compute d ( q , T ) as follows:
Compared with loading the whole trajectory T in memory, it is more efficient to obtain d ( length . Therefore, in our implementation, we use this index to compute d ( q , T ) instead of accessing T directly (recall Lines 17 X 18 of Algorithm 3 and Line 11 of Algorithm 4 ). G [ where R is the region of G [ i , j ] .
 We store the N  X  N list array L on disk.
 get the next trajectory T with the smallest value of d ( q , T ) in two steps:  X  X ereturn T = min-heap . top () as the next NN and remove it from min-heap .

The priority queue min-heap is a memory buffer that reorders the trajectories in L [ i , j ] Grid-based algorithms Our two grid-based algorithms also follow the FA and TA frameworks, respectively, but use the grid index (i.e., the RAI and SAI) in replace of the R-tree index.
The grid-based FA differs from Algorithm 3 in the following aspects:  X  Line 2 now becomes  X  N  X  n  X , where n =| D | ;
G [ j , k ]  X ; d ( q i , T ) ;  X  Lines 9 and 12 now become  X  T [ i ] X  d ( q i , T )  X ;  X  We no longer need to do the checking in Line 11, since each T will be accessed only once for each query point q i .

The grid-based TA differs from Algorithm 4 in the following aspects:  X  Line 2 now becomes  X  N  X  n  X ;  X  Line 8 is no longer necessary;  X  Line 10 now becomes  X  T [ i ] X  d ( q i , T )  X ; Extension to skewed trajectory distribution Our current algorithm uses a uniform grid to partition the rectangular data space U . Our experiments show that our algorithm works quite well on the datasets with trajectories relatively uniformly distributed over U .However,itis not the best choice when the trajectory distribution is skewed.

Although the road network of most regions occupies the majority of the region X  X  bounding box U (e.g., Colorado), it is not always true. For example, in the bounding box of Florida, most regions correspond to the ocean where no trajectory can exist, and it is meaningless to divide such regions into grid cells. Furthermore, there are usually much more trajectory points in city centers than in outskirts, and thus, dense regions should be divided into finer granularity.

We proposes a heuristics to handle data skewness. Specifically, we first build a linear quadtree index over all the trajectory points. Then, we build our RAI and SAI indices over the leaf nodes of the linear quadtree. We have conducted experiments to compare the performance of using uniform grid with that of using linear quadtree over skewed trajectory data and found compared with using uniform grid over relatively uniform trajectory data. 7 Experimental results and Grid-FA . We implemented our algorithms in JAVA. All the experiments were run on a public Linux server with eight 3GHz Intel CPU and 32GB memory. 7.1 Datasets and query-sets We first describe the datasets and query-sets used in our experiments.
 using four real trajectory datasets that are publicly available: construction places around Athens metropolitan area in Greece for 33 distinct days.  X  SchoolBuses 2 : This dataset consists of 145 trajectories of 2 school buses collecting (and delivering) students around Athens metropolitan area in Greece for 108 distinct days.  X  Geolife 3 : This GPS trajectory dataset was collected in MSRA Geolife project by 182 users in a period of over five years (from April 2007 to August 2012). February 2 to February 8, 2008, within Beijing.

For the two small datasets Trucks and SchoolBuses , the length of the trajectories is in the order of hundreds. We choose these datasets for empirical evaluation since there exist some important locations in their underlying applications, such as construction places and schools.
Unlike the Trucks and SchoolBuses datasets where most trajectories have a sampling rate lot. Specifically, the Geolife dataset contains 10,373 trajectories recorded by different GPS loggers and GPS phones with a variety of sampling rates, where 91.5 % of the trajectories are logged in a dense representation, like every 1 X 5 s or every 5 X 10 m per trajectory point. As a result, the length of the trajectories is in the order of thousands to tens of thousands. For the T -Drive dataset, the sampling rate is much lower, with the average sampling interval in the order of thousands.

The dense sampling rate of Geolife is not useful, since two consecutive trajectory points that are 1 s or 1 m apart usually refer to the same Point of Interest (POI). Therefore, we re-sample the trajectories as follows:  X  We always sample the first trajectory point; point, we skip the trajectory point.

We also do the trajectory re-sampling over T -Drive despite its low sampling rate, because we find that T -Drive records a lot of samples for a taxi even when it stops, and we want to remove the redundant samples that refer to the same stop locations. After the re-sampling sands.
 bution of the trajectory points is highly skewed. For Geolife , the majority of the data was created in Beijing, China. However, some trajectory points may locate in other cities like those in the USA and Europe. If we use our grid-based indexing approach, the majority of empty. Moreover, a traveler usually use the k -ICT query to find some reference trajectories which account for 71.93 % of the trajectories in the dataset.
 Query-sets We do not generate query locations randomly, since trajectories usually follow the underlying road network. Moreover, a query location in a sparse region not covered by the road network is meaningless in real applications.

We generate a meaningful query-set containing m query locations in the following way: (1) randomly pick a trajectory from the trajectory dataset to query over; (2) pick the top-10 % points of the trajectory in terms of importance; (3) randomly select m locations from these points without replacement; (4) shift these locations in a random direction by a small randomly generated distance (within 200 m), and add them to the query-set.

In this way, we are generating meaningful query locations that are important and correlated for at least one trajectory in the dataset. 7.2 Evaluation measures The k -ICT query has two query parameters: (1) the number of query points, m , and (2) the small in real applications. We also have a parameter for the dataset, which is the number of trajectories, n .

We measure the following four costs of our algorithms when the above parameters change: (1) CPU time, (2) number of blocks accessed by sequential index (the Max R-tree, or the grid index SAI), (3) number of blocks accessed by random index (the grid index RAI), and (4) number of priority queue entries in main memory.

Since our algorithms are I/O bound, the number of blocks accessed by sequential/random indices is the most important performance criterion. When using the grid index SAI [ i , j ] number of blocks accessed can be measured.

The smaller memory a query requires, the more queries a server can handle simultane-ously. Therefore, we also measure the memory cost of our algorithms. For the R-tree-based algorithms, the memory cost is dominated by the priority queue min-heap used for NN search (see Algorithm 2 ), while for grid-based ones, the memory cost is dominated by the priority maximum number among all the round-robin iterations.

For the Trucks and SchoolBuses datasets, we manually mark the points of some trajectories marked data using Eq. ( 6 ). We find that the choice of r = 50 m and  X  = 0 . 002 effectively distinguishes between the important and unimportant trajectories points, and we use these parameter values when generating sample importance by the method discussed in Sect. 4 .
The trajectories in the Geolife dataset have various speed, as they records different out-door movements such as walking, biking, or driving. Therefore, we fix r = 50 m but use priate for a vehicle trajectory, the importance scores of most trajectory points in the tra-jectory of a walking person are close to 1, although many of them are not important. We use the following approach to set  X  of a trajectory, which is observed to well character-(when r = 50 m) equals the longest one among all points p i in the trajectory, the score w( p i ) = 0 . 99.

As for the T -Drive dataset, the sampling rate is very low and thus a radius of r = 50 m is not able to cover a sufficient number samples around the current trajectory point. We set the parameters as follows, which is observed to well characterize the location importance of the trajectories: r is fixed to 500 m and we set  X  such that when t ( p i ) = 500 s (when r = 500 m), the score w( p i ) = 0 . 99.

Throughout the experiments, we fix the size of a block as 512 bytes. We generate 1,000 queries in each experiment, and all results are averaged over the 1,000 runs. 7.3 Effect of query parameters We first study the performance of our algorithms with respect to the query parameters m and k . For the relatively small Trucks and SchoolBuses datasets, we build grid indices by constructing a quadtree of height h = 5. Accordingly, the grid we use is of size 32  X  32. For the large datasets Geolife and T -Drive , we build a grid index by constructing a quadtree of height h = 7. Accordingly, the grid we use is of size 128  X  128.

To study the effect of m ,wefix k as 5 and process queries with m = 1 , 2 ,..., 10. On the Figure 6 reports the performance of our algorithms for processing k -ICT queries over the Trucks dataset when k = 5 and the number of query points m increases from 1 to 10.
Figure 6 a shows that the CPU time of RTree-FA is much larger than the other three algorithms, while the grid-based algorithms record the shortest CPU time.

Since all our algorithms are I/O bound, the results reported in Fig. 6 b, c dominate the overall performance of query processing. According to Fig. 6 b, RTree-FA requires reading a lot of blocks (or R-tree nodes) for the incremental NN search, and both of the R-tree-based algorithms read significantly more blocks for sequential access than the grid-based algorithms. For example, when m = 5, RTree-FA reads over 1,844 blocks while Grid-FA reads only 87 blocks. For random access, Fig. 6 c shows that Grid-FA (or respectively, Grid -TA ) also reads fewer blocks than RTree-FA (or respectively, RTree-TA ), though the difference is not as big as in the case of sequential access.
 Overall, Grid -TA is around 1.3 times faster than Grid-FA , several times faster than RTree-TA , and an order of magnitude faster than RTree-FA .

Figure 6 d shows that the number of data entries maintained in memory by RTree-TA and based algorithms. Given the fact that the size of an entry maintained by the grid index is much smaller than an R-tree node entry (which contains MBR and weight besides the node pointer), the grid-based algorithms are much more memory efficient than the R-tree-based ones.

Figure 7 reports the performance of our algorithms over the Trucks dataset when m = discussed, except for the I/O cost of random access. As shown in Fig. 7 c, the two FA-based algorithms, RTree-FA and Grid-FA , read fewer blocks when k increases, while the two TA-based algorithms, RTree-TA and Grid -TA , read more blocks when k increases. This is because C P U Time (ms) # of Blocks (Random) C P
U Time (ms) C P U Time (ms) ( a )(b) (c) ( d ) FA adopts a filter(sequential access)-and-refine(random access) approach. A larger k requires that FA do more sequential accesses, and since more trajectories are accessed, the need for random access is reduced.

As for the SchoolBuses dataset, Fig. 8 reports the performance of our algorithms when m changes, and Fig. 9 reports the performance of our algorithms when k changes. It can be observed that the performance trend of the algorithms is similar to that of the Trucks dataset discussed above (we thus omit the details).

For the Geolife dataset, Fig. 10 reports the performance of our algorithms when m changes, and Fig. 11 reports the performance of our algorithms when k changes. The performance trend of the algorithms is mostly similar to that of the Trucks and SchoolBuses datasets discussed above, except for the random IO cost shown in Figs. 10 cand 11 c, where we can see that the FA-based algorithms incur much more random IO cost than the TA-based algorithms. This shows that the effectiveness of TA over FA is more prominent for a larger trajectory dataset. Also, Fig. 11 c shows that the random IO cost of the FA-based algorithms reads more blocks when k increases, which is different from that observed from Figs. 7 cand 9 c. This is because the refinement phase still requires more random accesses as k increases. Overall, Grid -TA is around twice faster than Grid-FA , 3 X 19 times faster than RTree-TA and 20 X 70 times faster than RTree-FA .

As for the T -Drive dataset, Fig. 12 reports the performance of our algorithms when m changes, and Fig. 13 reports the performance of our algorithms when k changes. It can be than RTree-TA and 10 X 50 times faster than RTree-FA . C P
U Time (ms) ( a ) (b) (c) ( d ) C P U Time (ms) # of Blocks (Random) C P
U Time (ms) # of Blocks (Random) ( a ) (b) (c) ( d ) C P U Time (ms) # of Blocks (Random) ( a ) (b) C P
U Time (ms) ( a ) (b) (c) ( d ) 7.4 Results of scalability test To study the scalability of our algorithms when the number of trajectories increases, we generate synthetic datasets based on the Trucks dataset. Specifically, to generate a dataset from the Trucks dataset; (2) shift it in a random direction by a small randomly generated generate synthetic datasets from a real dataset since we want the generated trajectories to exhibit the properties of real trajectories.

We generate synthetic datasets D with | D |= 10 k , 20 k ,..., 100 k and process queries with m = 3and k = 5. The grid indices are built by constructing a quadtree of height h = 6, and accordingly, the grid is of size 64  X  64.
 Figure 14 shows the scalability of our algorithms when the number of trajectories increases. reading many more blocks using random access than TA-based algorithms do. Otherwise, the performance trend is quite consistent with the results on the Trucks dataset reported in Sect. 7.3 .

Overall, our algorithms scale well with the data size. Grid -TA is slightly (less than 10 %) 7.5 Quality of trajectory answers compare the quality of the trajectories found by our sum-of-weighted-distance measure with C P U Time (ms) # of Blocks (Random) ( a ) (b) that of the traditional sum-of-Euclidean-distance (or simply, sum-of-distance) measure. We and thus, the result trajectories exhibit similar characterizations.

We now report the result when m = 3and k = 5. Table 1 (a) shows the top-5 trajectories found by our sum-of-weighted-distance measure (i.e., a 5-ICT query), for a randomly gen-its trajectory ID, the values of sum-of-weighted-distance and sum-of-distance. Let us define the match of a query point q j in trajectory T as the point p i  X  T closest to q j in terms of p of each of the three query locations q j . Obviously, the top-1 trajectory is of high quality, since (1) the sum-of-distance is only 107.90 m, which means that the trajectory is physically q , which means that the truck spent a while in the 50-m-radius neighborhood Cir ( p i ) and high quality and are likely to be helpful to the user.

For the same query locations, we also find the top-5 trajectories found by the traditional sum-of-distance measure, which are shown in Table 1 (b). In Table 1 (b), we define the match of a query point q j in trajectory T as the point p i  X  T closest to q j in terms of Euclidean distance. We can see that most matching trajectory point p i has a small value of t ( p i ) , which means that these locations are not very important. The sum-of-distance measure fails to find important trajectories such as Trajectory 214, and even though it finds some important trajectories such as Trajectory 89, the matches of the query locations are of low quality.
We now show that sum-of-weighted-distance is superior to sum-of-distance in general, by randomly generating 1,000 queries and report the quality measures averaged over the 1,000 represents the total time spent by the trajectory at the locations of interest. Table 2 shows by sum-of-distance, where we set the query parameter m = 3. The figure clearly shows that trajectories found by sum-of-weighted-distance have higher quality. We also test the average sum-of-t ( p i ) of the top-1 trajectory found by sum-of-weighted-distance and by sum-of-distance, by varying the query parameter m . The result is shown in Table 3 ,which also confirms that trajectories found by sum-of-weighted-distance have higher quality.
We also compare the quality of the trajectories found by our sum-of-weighted-distance measure with that of the sum-of-distance measure on the T -Drive dataset. Table 4 shows by sum-of-distance, where the query parameter m = 3. Table 5 shows the average sum-of-t ( p i ) of the top-1 trajectory found by sum-of-weighted-distance and by sum-of-distance, by varying the query parameter m . Both figures confirm that trajectories found by sum-of-weighted-distance have higher quality. 7.6 Summary of experimental results To sum up, we have the following observations: (1) the grid-based algorithms are signifi-cantly more efficient than the R-tree-based algorithms; (2) the TA-based algorithms are more efficient than the FA-based algorithms; and (3) Grid -TA is much faster than the other three algorithms on large datasets. 8 Conclusions We proposed the new problem of k Important Connected Trajectories ( k -ICT) query process-ing over trajectories with location importance. We designed effective methods to infer the importance of trajectory locations from the temporal information and developed four algo-rithms to answer the queries: two based on the R-tree index and the other two based on an efficient grid index. The R-tree index-based algorithms are adaptations of the algorithms tures the spatial aspects of the trajectory points, and location weights are only considered during R-tree querying. On the other hand, our grid index includes the location weights as
We showed by experiments on both real and synthetic datasets that our algorithms are in terms of both time and space: They incur one to two orders of magnitude less sequential IO cost and computational overhead compared with R-tree index-based algorithms, due to the more effective pruning power of the grid index. As for trajectory traversal, TA is more effective than FA since the aggressive strategy of TA tightens the pruning threshold much faster. Overall, the combination of TA with grid index offers the best performance. References
