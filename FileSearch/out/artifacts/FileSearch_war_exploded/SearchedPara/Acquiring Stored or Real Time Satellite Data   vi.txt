 The core of our research concerns how to bridge the technical parameters of satellite keyword search of geo-portals such as the Google MAP 1 , the National Aeronautics and Space Administration (NASA) Earth Observing System Data and the Information System EoDIS 2 . 
The Sensor Web [2] allows satellite data to be obtained in real time. But how to find it? Sensor Web services integrate easily with other Web services. However, most people find the interfaces of service (such as Sensor Observation Service [12] or Sensor Plan-ning Service [14]) opaque due to their technical parameters and specifications. 
In this study, we propose a novel method that allows natural language query to search and retrieve archived or real-time satellite data. We use a rules-based method to find named entities, with the help of a knowledge base. We use rule-based methods to link time, location and domain tasks entered by users with the technical specifica-tions of the existing infrastructure for the Sensor Web. 
The remainder of this paper is organized as follows: Section 2 outlines an architec-ture of our system. A structured natural language template and knowledge base are described in Section 3. Section 4 explains how keywords and named entities are iden-tified. A system implementation and the experimental study are discussed in Section 5. Section 6 describes related work, and Section 7 summarizes the conclusions and gives potential directions for future research. Many Sensor Web services have been implemented and can be accessed by Internet, eg., the company 52 X North, with its Sensor Web community 3 , which can be used as a data layer for acquiring satellite data. We require an intelligent analysis layer as a sort of middleware between client and existing Sensor Web services. Therefore, the framework could be divided into three layers: user interface layer, intelligent analysis layer, and data layer, as shown in Fig. 1. User Interface Layer: is a simple and user-friendly Web browser client. Anyone can an observation task. Multi-condition combination query and a bulk feed are also supported. Results are also shown in this layer. Intelligent analysis layer : is the core layer that achieves task recognition and reason-ing. It includes a rules-based classifier for named entities which draws upon the knowledge base. In section 3.2, we describe how the knowledge base includes a time this layer are normalized values based on the format which we defined. transformation function is provided in this layer which transform the result of Intelli-gent Analysis Layer to values of interface parameters of the standard Sensor Web services, then we can invoke existing Sensor Web services such as the Sensor Obser-vation Service, or the Sensor Planning Service. 3.1 Template for Input than formalized language. However, keyword search of data collections often lack the parsing problems of Natural Language Processing and remove the limitations of keyword search.

We investigate four areas where such satellite data might be useful, including Bu-reau of Surveying and Mapping, Department of Forestry, Department of Agriculture, Ministry of Civil Affairs. We asked officials who worked in these departments for quirement descriptions were collected. Then we used a ground-up approach to con-struct a template for future unseen queries based on their requirements. It is based on These basic elements can be used to construct a data query or a satellite plan. There-fore, we present a structured natural language template, which is defined as follows:  X  ObservationTask = { Time , Location , DomainTask, SatelliteRequirement } Time expresses when the task should be executed, eg., About 2003.8.21. Location expresses where the task covers with, e.g., southwest Montana. DomainTask describes a specific domain task, e.g., monitoring of wildfires. 
SatelliteRequirement expresses the detailed description of image parameters and sensor parameters, e.g., MODIS. 
User could easily describe an observation tasks based on this template: " About 2003.8.21, monitoring of wildfires in southwest Montana, the sensor should be MODIS. " 3.2 Knowledge Base Ontologies are used to model the domain knowledge, and organize the concepts and properties of time, spatial information, domain task and satellite. In order to recognize the entities in a user query, we collected vocabulary specific to four domains: forestry, agriculture, surveying and mapping, and disa ster response. We collect terms, relation-ships from Wikipedia 4 , WenkuBaidu 5 , terminological dictionaries and standards of each domain (such as ISO Standards for Geographic Information[8]), website of or-satellite ontology, task reasoning rules and spatiotemporal calculation rules. Ontologies in th e Knowledge Base. Time information describes the time or duration of a user observation task (such as assess the wildfire X  X  area). Location describes the domain, satellite information is about satellite data to achieve observation task. There-fore, we built four types of ontologies to model the requirement of observation task. Time Ontology: OWL-time is a temporal ontology that provides a vocabulary for with the duration and date X  X ime information [6].We adopt the OWL-time as a basis for the time ontology. Time ontology includes temporal terms (e.g., festival, season), refer to Time ontology in English. However, Mandarin has some special temporal are added into the Chinese time ontology, which provide better support for the observation task described in Chinese. Location Ontology: We reference GeoNames Ontology 7 and build the Location on-tology. Location ontology is used to organize concepts of toponym, spatial relation-ships, feature types, spatial range and so on, which consists of the geo-feature entity, geo-feature-type, and spatial relationship ontologies. The geo-feature entity ontology includes the place name, geocoding, feature type, and footprint. The geo-feature-type tology is built to describe the spatial relationship which defined in the DE-9IM model [3]. Toponyms in gazetteer are regarded as instances of Location Ontology. Domain Task Ontology: The vocabulary came from speaking with experts and noting keywords about tasks that might use the satellite data, terminological dictionaries and standards of domain. The inter-relations were made by hand with the help of domain experts. In this study ,  X  X ask X  refers to the observation task, especially for Earth obser-vation task. Domain means application domain of Earth observation technology, dif-ferent domain has different tasks, vocabularies, and concepts, building domain task observation action, object attribute, and their relations. Satellite Ontology: The vocabulary came from Wikipedia and some satellite websites. The inter-relations were also made by hand with the help of domain experts. Proper-ties of Satellite Ontology include id, mission type, operator, reference system, regime, Sensor Ontology and Satellite Data Ontology. Sensor Ontology describes specific specific properties of data, e.g. spatial resolution, fabric width, band, and signal noise ratio. Reasoning Rules in the Knowledge Base. In addition to these ontologies, we use rules to find enough information in order to determine which satellite to call upon. Task Reasoning Rules: Many observation tasks described by natural language are incomplete. If the query lacks satellite-related information, for example, it is hard to find satellite data. Therefore, we defined a variety of task requirements based on tem-plate in several specific domains (disaster response, agriculture, surveying and map-ping, forestry) and encode the reasoning in Semantic Web Rule Language. 8 For example,  X  X onitoring of forest fire X  is a typical observation task, which demands wave band. The rules can be expressed as follows: 
Monitoring of Forest fire (?task)  X  satelliteData(?x)  X  hasSpatialResolution(?x,?y) ^ swrlb:lessThan(?y,1000) ^hasBand(?x,?z) ^ bandName(?z,?bName)^ swrlb:stringEqualIgnoreCase(?bName,"Near Infrared") Spatiotemporal Calculation Rules: We also use rules to find a specific time and loca-tion, coordinate transformation (WGS 84 is the first choice), time transformation, normalization of relative temporal expressions (e.g. today) and implicit temporal ex-pressions (e.g. spring season) and so on. 
We have found experimentally that our ontologies, reasoning rules, and gazetteer provide a sufficient resources to support Named Entities Recognition, normalization and inference of user queries in natural language. The observation task described by natural language is processed by a rule-based algo-rithm that recognizes keywords and named entities with the help of the knowledge base described in section 3.2. The way it works is that time entities, location entities, domain task entities, and satellite requirements are recognized. Then normalization and inference is used to gain deeper understanding of the user query. Algorithm. A Rule-based Recognition Input : User query Q i Output: R{T i |P i , L i |A i , S i } 1 for each Q i 2 Named Entities Recognition(Q i ) ; 3 if (time entities exist and NumofTime == 2) then 4 TemporalCalculation(T 1 ,T 2 ); 5 Period of Pi, add Pi to R; 6 else if (time entities exist and NumofTime == 1) then 7 time normalization T i ; 8 add T i to R; 9 if ( location entities exist and 6&gt;NumofLocation&gt;1) then 10 SpatialCalculation (L 1 ,L 2 ...L Num ); 11 MBR of A i ; 12 add A i to R; 13 else if (location entities exist and NumofLocation==1) then 15 add L i to R; 16 if domain task entities exist then 17 task reasoning S' i ; 18 if satellite requirement exist then 20 S i = intersection(S' i ,S'' i ) ; 21 add S i to R; 22 return R; query or set of queries, Q i . The output is set R, which includes normalization time T i or a period of time P i , geographical coordinates of L i or a minimum enclosing rectan-reasoning S' i and satellite requirement S'' i . 4.1 Expression Rules We inferred these rules based on collecting actual data from professionals in our do-and satellite parameters, then we defined these rules based on Backus X  X aur Form. Each rule is explained below. Time. Time data divides into instants and intervals. The terms contain  X  X ay, X   X  X onth, X   X  X ear, X   X  X hristmas, X   X  X ugust, X  and so on. An example of an instant is time contains  X  X efore, X   X  X fter, X   X  X etween, X  and so on. These vocabularies are used to describe time in the observation, e.g.,  X  X efore August 21, 2003, X  The expression rules of the temporal information are described as follows: 
Time Information::={Qualifier} + &lt;Value&gt; + [Month] + &lt;Value&gt; + [Day] +&lt;Value&gt;+ [Year].
 Location.  X  X n the boundary between Montana and Idaho X  and  X  X n southwest Mon-tana, X  are examples of the location information in the observation task, which include ponym indicates terms such as  X  X dministrative division, X   X  X iver, X   X  X ountain X , spatial range is another choice to describe a observation range. Location Information::= [Qualifier] + [Rela tionship] + {&lt;Toponym&gt;  X  &lt;Spatial Range&gt; + [Qualifier]}.
 Task. Domain task information is the core of the observation task. This is subdi- X  X pdating X ), task aspect (found in natural language queries in terms such as  X  X rea, X  or fires, X  or  X  X igital terrain map X ). Domain Task::=&lt;Action&gt; + {[Aspect]} + &lt;Object&gt;.
 Satellite Parameters. In the description of the observation task, users impose some restrictions on the satellite parameters (such as  X  X he spatial resolution should be better  X  X ive. X  Unit is the unit of the parameters, e.g.,  X  X  X  or  X  X m. X  
Satellite Requirement::=[Satellite parameters] + {Qualifier} + &lt;Value&gt; + &lt;Unit&gt;. 4.2 Normalization and Inference satellite information. Therefore, we execute normalization and inference based on the result of Named Entities Recognition. 
For example, the user input this query: "About 2003.8.21, monitoring of wildfires in southwest Montana, the sensor should be MODIS." 
After the Named Entities Recognition, the time entities, location entities, and do-and knowledge base. The intermediate result resembles the following: transform the named entity to standard time information, spatial information, and satellite information, the result as following: 5.1 Prototype System We developed a prototype system to test and verify this method of retrieving satellite Fig.2. A input field is on the top panel, we can input an observation task described by normalization and inference, the normalization of temporal information, spatial coor-dinates, the detailed satellite information are shown on the right panel. Then, we can invoke existing Sensor Web services based on the results to acquire satellite data. 5.2 Evaluation We tested the ability of our system to retrieve satellite data based on natural language culture, disaster reduction. We collected 212 observation task keywords in Mandarin described by experts. Then the authors of this paper ourselves wrote 623 more sets of tasks with related, but not duplicate keywords. We had experts re-read the queries that the authors had written to verify their plausibility, and to modify the queries if neces-sary. The break-down of queries by domain in the sample data set appears in Table1. 
To evaluate, we randomly selected six groups queries (each group has 100 queries) from these domain samples. Then we gave both query and results to a group of ex-sion, with the results shown in Table 2. We score results in terms of precision and recall: 
If one of the named entities in a query is not extracted, we judge the query is not recognized. For example, in Sample query_ 2, If "In the autumn of 2011" is not recog-nized, despite "wooded area investigation , Heilongjiang Province , resolution is not represents the first pass of the query through the system. However, this is sometimes formation. Therefore, we score results of normalization and inference: NER, if one of the named entities is not normalized or reasoning correctly, we judge get the standard time and satellite specific information. 
The average precision and recall of NER is above 96%, because we utilize the a completeness of knowledge base and rules, we provide a function to add new know-ledge and rules, to enhance the extendibility of our system. The average precision and recall ration of normalization and inference is also above 94%, assuming that results from NER are correct. Therefore, our prototype system is promising for assisting in Earth observation applications. Our system is able to return satellite data to users based on their task domains, while comparable systems by the NASA and the ESRI Company return data only in direct response to user keywords. Recall that the core of our research concerns how sub-parameters in order to review the literature. Location. Recognizing geospatial information in document files (for example, from txt, html, xml and doc) is an active research direction in the geo-spatial domain. Most studies focus on place name, also called toponym recognition. The recognition of toponyms based on Gazetteer [7] is a fundamental method. Many NER approaches are used for toponym recognition, the approach that employs dictionaries and hand-popular method for toponym recognition, including Maximum Entropy[1], Condi-tional Random Field sequence models [4] and so on. A combination of rule-based method and Machine Learning is a new trend for toponym recognition [10, 5]. Location and Time. Some algorithms combine temporal and geographic information. Str X tgen et al. use temporal and geographic information extracted from documents and recorded in temporal and geographic document profiles[15]. research focuses on identifying events from temporally-ordered streams of documents and organizes these documents according to the events they describe[17]. Our obser-spatial information than other events. meaning that they are developed for one domain but do not typically perform well on other domains [13]. Therefore, research on entity recognition to acquire satellite data is significant. In this study, we describe a novel method to acquire stored or real time satellite data our algorithm uses Named Entities Recognition, normalization and inference to find relevant items in the satellite data. Our evaluation is based on our in-house prototype system which showed precision and recall. Open questions for future research include data automatically by machine learning. Acknowledgment. This work was supported by the grants of the National Basic Re-search Program of China (2011CB707101), the National Natural Science Foundation of China (41201405, 61070013), China Scholarship Council No. 201308420300. 
