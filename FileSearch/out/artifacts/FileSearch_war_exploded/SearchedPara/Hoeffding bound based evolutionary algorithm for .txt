 1. Introduction
Evolutionary algorithms have been applied successfully to a variety of complicated real-world applications. One main diffi-culty in these applications is that EAs usually need a large number of fitness evaluations before obtaining a satisfying result. How-ever, when the evaluation of the fitness is computationally very expensive or an explicit fitness function does not exist, we have to construct an approximate model to estimate the fitness.
Fitness approximation has become an active area in evolu-tionary computation with many varying approaches and results ( Jin, 2005 ). There are several reasons for utilizing fitness approx-imation through modeling. The first and most common reason is to reduce the computational complexity of expensive fitness evaluations. Many applications of evolutionary algorithms are in high-complexity or intractable domains, where the fitness calcu-lation can be prohibitively time consuming ( Ong et al., 2003 ; Jin et al., 2002 ; Regis and Shoemaker, 2004 ; Regis and Shoemaker, 2005 ) and the exact fitness objective is unnecessary for evolutionary progress. At the same time, approximation can be used advantageously in other problems, such as handling noisy fitness functions, smooth multimodal landscapes, and defining a continuous fitness in domains that lack an explicit fitness ( Regis and Shoemaker, 2004 ; Regis and Shoemaker, 2005 ; Arnold, 2001 ; Sano and Kita, 2000 ; Audet et al., 2000 ).
 tion. Problem approximation tries to replace the orig inal problem by another problem which is approximately the same to the original problem but easier to solve ( Anderson, 1995 ; Bradshaw et al., 1976 ).
In functional approximation, an alternate and explicit expression is constructed for the obj ective function. Several methods have been proposed for constructing approximate models. In ( Johanson and
Poli, 1998 ), a neural network has been used to model the behavior of the human to reduce human fatigue and evaluate the fitness. In Hart and Belew (1996) , Liang et al. (2000) , approximate models were used to smooth the rough fitness functions and prevent the evolu-tionary algorithm from stagnating in a local optimum. In Myers and
Montgomery (1995) , Sacks et al. (1989) ,aglobalpolyno mial approx-imation and a local Gaussian process were combined together to estimate the parameters used. Artificial neural networks, including multilayer perceptions and radial basis function networks have also been used to build approximate models for evolutionary optimization ( Bartelemy and Haftka 1993 ; Carpenter and
Barthelemy, 1993 ; Shyy et al., 1999 ; Simpson et al., 1998 ). Evolu-tionary approximation is a type of approximation for evolutionary algorithms. Fitness inheritance i s a popular evolutionary approxima-tion method, in which fitness evaluations can be spared by estimat-ing the fitness value of the offspring individuals from the value of their parents. In Kim and Cho (2001) , the individuals are clustered into several groups and only the ind ividual representing its cluster will be evaluated using the fitness f unction. The fitness value of other individuals in the same cluster will be estimated from the represen-tative individual based a distance measure.

However, to get an accurate approximate model is a difficult task, the models achieved often have large approximation errors and always introduces a false optima. So, the evolutionary algorithm with approximate models for fitness evaluation always converges to an incorrectly solution ( Kim and Cho, 2001 ).
How to guarantee that the solution discovered is optimal or near-optimal is a key problem we have to face. Most methods with approximate model for fitness evaluation assume that the approximate model is correct and the evolutionary algorithm will converge to a global or near-optimal solution ( Redmond and
Parker, 1996 ; Pierret, 1999 ). These methods can only succeed when the approximate model is globally correct. To guarantee to converge to the global solution, many frameworks for managing approximate models were proposed ( More, 1983 ; Schramm and
Zowe, 1992 ; Brooker et al., 1998 ). In Dennis and Torczon (1997) ,a framework was represented based on the classical trust-region methods, which ensures that the search process converges to a reasonable solution of original problem. In Ratle (1998) , a heuristic convergence criterion is used to determine the updat-ing time of the approximate model. In Ratle (1999) , the original fitness function is used in every k generations to update the approximate model. However, if there is a large discrepancy between the approximate model and the original fitness function, the evolution process may become very unstable ( Jin et al., 2000 ).
In Bull (1999) , an evolutionary algorithm with a neural network trained with some initial samples to approximate the model is proposed. During the evolutionary process, the fittest individual in the population is evaluated on the original fitness function once in every 50 generations. The individual then replaces the one with the lowest fitness in the training set and the neural network is retrained. However, when the complexity of the original fitness landscape is high, the neural network model will mislead the evolutionary algorithm to a default way. To improve the convergence of the evolutionary algorithm, a concept of evolution control, in which the evolution proceeds based on fitness evaluations using not only the approximate fitness model, but also the original fitness function, was proposed in Jin et al. (2002) .

In this paper, we propose a new framework for evolutionary algorithm named Hoeffding evolutionary algorithm and it can be used with other traditional evolutionary algorithm together to deal with a kind of problems in which the evaluation of the fitness is computationally very expensive. The algorithm can exactly decide how many samples are necessary for choosing i best individuals from a population in evolutionary algorithms without calculating the fitness completely. The major advantage of the proposed algorithm is that it can guarantee that the solution discovered has performance matching what would be discovered with a traditional GP selection operator, with a determinate prob-ability; and with the similar accuracy, the HEA algorithm can find the solution more efficiently than tradition EA.

The rest of this paper is organized as follows. We first review the related work on the Hoeffding bound, symbolic regression and genetic programming. Next, different kinds of fitness functions were introduced and two iterative fitness function models were built. Third, we represent the Hoeffding-EA algorithm (Hoeffding evolutionary framework with evolutionary algorithm) for sym-bolic regression and give some theorem analysis. Then we describe several experiments in which the parameters of the algorithm are examined and the algorithm is effectively applied to find a regression model. Finally, we conclude this paper by highlighting the key contributions of this work. 2. Related work 2.1. Hoeffding bound and relevant algorithms
The distribution function for the sum of independent random variables, x 1  X  x 2  X  X  x i  X  X  x n , when some information about the distribution of the x i is available, is very important for the modern theory of probability. Much work has been carried out on the asymptotic form of the distribution of such sums when the number of component random variables is large or when the component variables have identical distributions. If we test a given model on N samples, the average error of them can be expressed by E true . However, when N is a large number, the time we cost will become very long. So, we can test the model on n ( n 5 N ) sample. The estimate error on n samples can be expressed E
In 1963, Hoeffding proposed their inequality about the upper probability bounds for sums of independent random variables ( Hoeffding, 1963 ), in which the probability of the estimated mean E est being more than epsilon far away from the true mean E after n independently drawn points is bounded by: Pr  X  where B bounds the possible spread of point values.

We can say that with confidence 1 d , the estimate of the mean is within e of the true mean. In other words, Pr( 9 E E est 9 4 e ) o d . Combining the two equations and solving for e gives us a bound on how close the estimated mean is to the true mean after n points with confidence 1 d :  X 
Changing the form of Eq. (2), we can determine the number of samples n necessary to obtain a certain accuracy e and confidence d . n 4 B Based on Hoeffding inequality, Oded Maron and Andrew W. Moore proposed an algorithm, called Hoeffding races, for finding a good model ( Maron and Moore, 1994 ; Maron and Moore, 1997 ). In the proposed algorithm, each model was called a learning box and the errors of all the learning boxes were computed at each arrived point which comes from the test set. Then the learning boxes whose best possible error is greater than the worst error of the best learning box were eliminated. The algorithm is especially suitable for selecting lazy learners and finding relevant features for its negligible expense. Inspired by these ideas, Mauro Birattari pro-posed a racing procedure for finding a good configuration through experimental evaluations. The racing algorithm can provide a better allocation of computational resources among candidate configura-tions and can overcome the drawbacks of brute-force ( Birattari et al., 2002 ). Pedro Domingos described a classification algorithm, VFDT, to build decision trees on data stream mining ( Domingos and
Hulten, 2000 ). In VFDT, Hoeffding bound was used to decide how many examples were necessary at the nodes of the tree. Then, the CVFDT system, an extension of VFDT, was proposed by Geoff
Hulten, which maintains the advantages of VFDT and adds the ability to detect and respond to concept drifts. In this algorithm,
Hoeffding bound was used to guarantee that the output of the learner is asymptotically nearly identical to that of a conventional learner ( Hulten et al., 2001 ). In Kohavi and John (1997) ,feature subset selection was looked on as search with probabilistic esti-mates. The Hoeffding formula was used to define the confidence interval which was used in the race of different models. In Bollobas et al. (2001) , the Hoeffding inequality was used in modeling com-plex real-world networks such as the world-wide-web. In Yuan and
Gallagher (2004) , Bo Yuan proposed a statistical method, racing algorithm, to reduce the cost of exhaustive experimental studies and to increase the capacity and efficiency of it in EAs. In that paper, the racing algorithm was applied to tasks of running a set of algorithms on a single test problem, qualifying the performance of a single algorithm on a variety of test problems, and identifying the best performing algorithms for a set of problems and to identifying the most difficult problems for a set of algorithms. 2.2. Symbolic regression and genetic programming
Given a class of functions and a set of experimental observa-tions, the problem of searching for the element in the class that best fits the given data is known as regression. In its more usual form, the structure of the function is predefined in advance and the task left is to determine a certain coefficients of it. Then, a suitable optimization procedure is used to minimize the distance between the predicted results and the data available. If the structure of the function is not  X  X  X  priori X  X  defined, the optimization procedure contained structure optimization and parameters opti-mization is known as symbolic regression.

Many modeling techniques have been used to construct regres-sion models, such as linear regression, nonlinear regression, kriging, radial basis functions, neural networks, support vector machines and genetic programming ( Johnson and Wichern, 1988 ; Sacks et al., 1989 ; Powell, 1987 ; Haykin, 1994 ; Vapnik, 1997 ;
Cherkassky and Mulier, 1998 ; Koza, 1992 ). These techniques are always used together to complement each other in modeling com-plex processes. Symbolic regression via GP is a methodology to automatically generate symbolic models that describe functional relationships on given data. GP, neural networks and SVMs have advantages over classical statistical methods when no a priori information is known. It is because that if no a priori information is given, the search space is a set of all possible symbolic models representing valid operations from the fixed set on the given input variables and the classical numerical optimization techniques will become ineffective. At the same time, if we want a simple model with interpretable analytic expressions, GP is a more suitable algorithm for symbolic regression than neural networks and SVMs ( Smits and Kotanchek, 2004 ; Smits et al., 2005 ).

GP is a soft computing search technique, it deals with a tree-structured program, called GP tree, whose structure is evolved toward minimizing its fitness value by using genetic operators. The structure of the GP tree is modified and optimized so as to it is more appropriate for model approximation. Cramer (1985) introduced GP in 1985 and Koza improved it and enabled it to be applicable to wider areas, i.e., data mining, artificial intelligence and machine learning ( Koza, 1992 ). Genetic programming can be seen as a kind of extension of GA and the main difference between them is the representation of the structure and meaning of representation.
A large amount of research works regarding GP with regression problems and system identifications were carried out.
 programming are proposed, for example, linear genetic program-ming (LGP), Cartesian genetic programming (CGP) etc. In Ferreira (2001) , gene expression programming (GEP) was introduced by
Ferreira, which incorporates simple fixed length linear chromo-somes, similar to the ones used in GA. The chromosomes were called genotype in GEP and changed as the ramified structures of different sizes and shape. The phenotype, as a ramified expression tree of different sizes and shapes, is translated form chromosome according to certain criteria. Many symbolic regression and time series prediction problems were dissolved by GEP effectively ( Ferreira, 2002 ; Lopes and Weinert, 2004 ).
 to the manner of representation, selection, crossover, and mutation.
However, in symbolic regression, when the number of samples is very large, it is very hard for traditional GP to be used to find a satisfying solution. The evaluation of the fitness is computationally very expensive. How to construct an approximate model and to estimate the fitness are important things for GP. Most of the present models achieved often have large approximation errors and that will prevent the algorithm from converging to the global optimal solution. In the proposed HGP algorithm, the Hoeffding bound was used to decide how many samples are necessary for choosing i best individuals from a population in evolutionary algorithms without calculating the fitness completely. The proposed algorithm can guarantee that the solution discovered is optimal or near-optimal with a determinate probability. 3. Iterative fitness function which is given by systems of arbitrary complexity. Different fitness functions in evolutionary optimization were mainly categorized into four classes: noise, time-varying, robustness and iteration. may come from many different sources such as sensory measure-ment errors or randomized simulations. The two common noises are Gaussian and Cauhy ( Stroud, 2001 ). The time-varying fitness function is deterministic at any point in time, but is dependent on time. As a consequence, also the optimum changes over time. Thus, the evolutionary algorithm should be able to continuously track the changing optimum rather than requiring a repeated restart of the optimization process. The challenge here is to reuse information from previous environments to speedup optimization after a change. The design variables in the problems with robust fitness function are subject to perturbations or changes after the optimal solution has been determined. Therefore, a common requirement is that a solution should still work satisfactorily when the design variables change slightly, e.g., due to manufacturing tolerances.
Such solutions are termed robust solutions. To search for robust solutions, evolutionary algorithms should work on an expected fitness function based on the probability distribution of the possible disturbances, which are often assumed to be independent of each other and normally distributed ( Paenke et al., 2006 ). When the calculation of fitness function is an iterative or multistage process, for example, calculating the average mean of finite-element, the consumed time is always very large. In order to consult this kind of problems, many algorithms were proposed. Schmidt present an algorithm of fitness prediction which reduces fitness evaluation cost when time-consuming finite-element calculations are needed ( Schmidt and Lipson, 2008 ). Regis developed an approach for the optimization of continuous costly functions that uses function approximation to reduce the number of function evaluations in an evolutionary algorithm ( Regis and Shoemaker, 2004 ).
In general, an optimization problem needs to find a setting x A
M of free parameters of the system under consideration, such that a certain quality criterion f : M -R is maximized (or, equiva-lently, minimized), f  X  x ,  X  -max. The solution to the global optimi-zation problem requires finding a vector x , such that 8 x A
M : f  X  x !  X  r f  X  x ! n  X  X  f n . Being restricted with the function g : M
A R , the feasible solutions F D M is only a subset of the domain of the variables F  X f x ! A M 9 gj  X  x !  X  Z 0 8 j g . There are two kinds of iterative fitness functions for evolutionary algorithm. Mathematically, they can be described as follows: F  X  x  X  X  F  X  x  X  X  4. Hoeffding evolutionary algorithm 4.1. Hoeffding selection operation Consider a real-valued random variable r whose range is B .
Suppose we have made n independent observations of this variable, and computed their mean r mean . The Hoeffding bound states that, with probability 1 d , the true mean of the variable is at least r mean e , where  X  s
Hoeffding selection operation is operations that can be used to select individuals without entirely calculate the fitness value of them.
We can solve the difficult problem of deciding exactly how many samples are necessary for choosing i individuals from a population (containing m individuals) with it. Let X i be the i individual after seeing n examples, and X i  X  1 be the ( i  X  1) individual. Let F ( X heuristic measure, by which we can choose the best i individuals from the population. Ranging the individuals in a population accord-their observed heuristic values. Then, given a desired d , the Hoeffding selection operation can guarantees that the first i individuals are the correct choice with probability 1 d if n examples have been seen in the population and D F 4 e . Thus, if we want to rightly select the best i individuals with probability 1 d ,weshouldwaitforthepopulation to accumulate examples from the dataset until e becomes smaller than D F. e is a monotonically decreasing function of n . The Hoeffing bound is independent of the probability distribution.
But at the same time, it is more conservative than distribution depen-dent ones. For an iterative fitness function which can be described by formula (4), The Hoeffding select ion operation is defined below:
Definition 1. (Incremental fitness of an individual): the incre-of the individual when it meet the j sample.

D IF j  X  X i  X  X  f j  X  X i  X  p  X  j  X  X  6  X 
Definition 2. (Real-time fitness of an individual): The real-time individual when it has met j samples.

F  X  X  X  X  Definition 3. (Fitness of an individual): The fitness F ( X individual X i is the average of the fitness of the individual when it has met all of the samples.
 F  X  X i  X  X  Definition 4. (Hoeffding selection operation): The Hoeffding selection operation used in our proposed algorithm is represented as below, which is suitable for calculating the value of iterative fitness function: (1) Give a probability, 1 d , and the scale of the training samples, N . (2) Sequentially read in a sample j (on the locations of the (3) Order the individuals according to their real-time fitness (4) If the record/sample is the last one in the dataset, or the real-4.2. Hoeffding genetic programming for symbolic regression Genetic programming (GP) is an automatic learning methodology and breeds a population of trial solutions with several biologically inspired operators, such as reproduction, selection, crossover and mutation. The main difference between algorithm HGP and GP is the selection operation. The most popular selection algorithm used in traditional GA is roulette wheel parent selection algo-rithm or tournament selection algorithm. However, in HGP, the selection algorithm used is Hoeffding selection algorithm.
Given a class of functions and a set of experimental observa-tions, the problem of searching for the element in this class that best fits the given data is known as regression. We can use the proposed HGP algorithm to minimize the distance between the predicted results and the data available. Let expect j be the value of the given observation point j . Let N be the total number of the sample points. Let compute i , j be the value of the individual i at the point j , the incremental fitness D IF j ( X i ) of an individual X be expressed by D IF j  X  X i  X  X  9 expect j compute i , j 9  X  9  X 
The real-time fitness F j ( X i ) of an individual X i can be expressed by F  X  X i  X  X  The fitness F ( X i ) of an individual X i can be expressed by F  X  X i  X  X 
The proposed Hoeffding genetic programming algorithm for symbolic regression is presented below and is illustrated in Fig. 1 . (1) Initialization: select parameters t , m and g , where t is the (2) Individuals selection: select good individuals from the popu-(3) Crossover: do a traditional crossover operation. (4) Mutation: do a traditional mutation operation. (5) Check convergence: repeat steps (2) to (4) until the stopping
The proposed Hoeffding evolutionary algorithm can guarantee that the individuals it chosen are asymptotically arbitrarily close to the ones produced by the whole dataset. That is to say, the incremental nature of the Hoeffding evolutionary algorithm does not significantly affect the quality of the individuals it chosen. 4.3. Correctness analysis
Definition 4. (Probability of population correctness): The prob-ability of population correctness Pr j is the probability that all real-time fitness F j ( X i ) of individuals in the population P are less than e when j samples has been met.

Definition 5. (Probability of selection correctness): The probabil-ity of selection correctness Pr selection( i / m ) is the probability that correctly select i best individuals from the population P in one selection operation.

Definition 6. (Probability of algorithm correctness): The prob-ability of algorithm correctness Pr algorithm( t ) is the probability that correctly select i best individuals from the population P within t continual generations.

Theorem 1. If Pr j is the probability of population correctness, j is the number of the samples met, m is the number of individuals in the population P , B is the bound of prediction errors, then
Proof. Let X 1 ,X 2 , y , X m are individuals in the population P . After meeting j samples, the real-time fitness F j ( X i ) of individuals in we can get that
Pr  X  9 F  X  X i  X  F j  X  X i  X  9 4 e  X  o 2 e 2 j e 2 = B 2  X  13  X  we can say
Pr f 9 F  X  X 1  X  F j  X  X 1  X  9 4 e v e  X 
Theorem 2. If Pr algorithm( t ) is the probability that correctly select i best individuals from the population P within t continual genera-tions., m is the population size, j is the number of the samples, B is the bound of prediction errors, then
Proof. Let Pr selection( i / m ) is the probability that correctly select i best individuals from the population P in a selection operation, according to Theorem 1 not very important for searching the optimal solution in evolu-tionary algorithms. EAs are stockastic algorithms. Even a wrong selecting operation takes place in the process of optimization the result of the whole process will not be affected by it largely. 4.4. Complexity analysis space required to execute the algorithm in the worst case. For HGP, the time needed to execute it comprises with three main parts: (1) Initialization phase: initialize a parent population and a generation number counter g , fitness bound B , sample sum N and generation interval constant t . These can be performed in
O ( M ) time. (2) Selection phase: in step 2, for every t generation, the time T for calculating current fitness function and doing selection operation with GP selection is O ( N M )  X  O ( M 2 ). The time T cost by Hoeffding selection is O (( t 1) n M )  X  O (( t 1) (2 M ) 2 ). Parameter n is the current sample number when a
Hoeffding selection takes place. (3) Crossover and mutation phase: in step 3 and 4, the computa-tional time required by crossover and mutation operation, Tc and Tm ,is O ( M ) and O ( M ).

By summing up the computational time required for each of these phases, it is possible to determine the total computational time of the algorithm. Let the number of iterations is g , hence, the computational time of the whole process is given by
O  X  M  X  X  O  X  N M g = t  X  X  O  X  M 2 g = t  X  X  O  X  X  t 1  X  n M g = t  X  X  O  X  X  t 1  X  X  2 M  X  2 g = t  X  X  O  X  M g  X  X  O  X  M g  X   X  O  X  N M g = t  X  M 2 g = t  X  X  t 1  X  n M g = t  X  X  t 1  X   X  2 M  X  2 g = t  X  2 M g  X   X  O  X  X  N = t  X  M = t  X  X  t 1  X  n = t  X  X  t 1  X  4 M = t  X  2  X  M g  X   X  O  X  N M g = t  X  X  Where N f M , N f n and N f t  X  X  16  X 
It is clear that the computational time of the HGP algorithm is determined by some factors such as population scale M , genera-tion interval t , sample sum N and the current sample number n . Parameter n is decided by formula (3).

For traditional GP algorithm, in selection phase, the time T calculating current fitness function and doing selection operation with GP selection is O ( N M )  X  O ( M 2 ). The total computation time of the whole process is given by
O  X  M  X  X  O  X  N M g  X  X  O  X  M 2 g  X  X  O  X  M g  X  X  O  X  M g  X   X  O  X  N M g  X  M 2 g  X  2 M g  X  X  O  X  X  N  X  M  X  2  X  M g  X   X  O  X  N M g  X  X  Where N b M  X  X  17  X 
From (16) to (17), we can see that the time cost by GP is t time greater than HGP when sample sum N is far greater than population scale, generation interval and current sample number.
The memory required to run the algorithm is proportional to the number of individuals M and the number of records in a data block. 5. Performance evaluation
The experiments were conducted on a 3.0 GHz Pentium 4 with 1.0 GB of memory running Microsoft Windows XP. All code was compiled using Microsoft Visual C  X  X  6.0.

In fact, the proposed algorithm HEA/HGP is not a simply algorithm, but an evolution framework. Every kind of evolution-ary algorithm can be inserted in it. In Sections 5.1 X 5.5 ,we inserted a traditional EA algorithm to this framework. We use the function  X  X  f ( x )  X  min{2/ x , sin(4 x )  X  1} X  X  to produce the set of sample points. When we searched for the best model, we assumed that the structure of the function is known and the task left to us is to select the optimal parameters. The function and d are parameters needed to optimize. In Sections 5.6 and 5.7 , we constructed the HGP, HTAG3P and HGP  X  CSAW algorithm by uniting the proposed framework with GP, TAG3P and GP  X  CSAW algorithm and searched for the optimal solutions separately for the test function.

To demonstrate the feasibility of the proposed algorithm, we present some measures used to statistically analyze the models obtained ( Ferreira, 2001 ; Ferreira, 2002 ).
 Let n be the number of the sample points in the given data set. Let expect j be the true function value at point j . Let compute the function value calculated by the i individual (solution). 9 expect j compute ij 9 is the absolute error of the candidate solu-tion i at point j .

The sum of absolute errors (SAE) of a solution is the sum of the prediction errors.
 SAE i  X 
The mean absolute error (MAE) of a solution is the average of the prediction errors.
 MAE i  X  The root mean squared error (RMSE) is computed by RMSE i  X 
If the root mean squared error is significantly greater than the mean absolute error, it means that there are test cases in which the prediction error is significantly greater than the average error. 5.1. Sample size
To demonstrate the importance of the sample number, we product some samples with the given function y  X  f ( x )  X  min{2/ x , sin(4 x )  X  1}. The variable x was uniformly distributed in ( Jin, 2005 ; Sacks et al., 1989 ). We symmetrically select 9, 18 and 150 sample points to draw three sketches. From Fig. 2 , we can see how different the three sketches are. Too little number of sample points will lead to missing some important structural informa-tion. Constructing an unknown function with finite number of samples bears the risk of overfitting. Adequate samples are necessary for acquiring an accuracy model. However, too many samples will lead to an inefficient implementation of the sym-bolic regression algorithms. Meanwhile, care should be also taken to avoid the process noise. We can see it from Fig. 3 , in which the different running time of 20 generations is listed on the case of b sin( c x )  X  d} X  X , where a , b , c and d are coefficients needed to optimize. The mutation probability was set to 0.2. The population size was set to 40. From Figs. 2 to 3 we can find that too little number of sampling points will lead to missing some important structural information. However, too large number of sampling points will lead to long implementation time. So, when the sampling number is a large one, how to reduce the implementa-tion time of the algorithm is an important task left to us. 5.2. How to select the range B of a random variable?
For Hoeffding bound, B is the range of a real-valued random variable r . In symbolic regression, r is defined as the prediction error of a model. For different models, there exists many different value of r . It is hard to set a common range B for different models. Then, how to set the parameter B ?
Theoretical speaking, there is not a range B existed for different kinds of models. However, in order to take advantage of Hoeffding bound in our evolutionary algorithm, we have to find a suitable value for B . So, we set B to the value B  X , where B  X   X  f
And to guarantee that every r is less than B , we have to changes the initial conditions and the elitism. First, in the step of initiali-zation, we have to choose the initial individuals carefully to ensure that each of them is less than B . Then, the elitist breeding policy has to be changed. The whole population of father genera-tion will be preserved. Every time the selection operation takes place, we should firstly mixture the parent population with the current population and then select the fixed number of indivi-duals to make up of the next population. In this way, the fitness of individuals in every generation will be less than B .

In Fig. 4 ,different B was set in the proposed algorithm. We can see that, if the parameter B was set to a large one, we can obtain a more accuracy result, but the implementation time will became greater than standard EA. On the contrary, if we set a too small value for B , the run time will become very short, but the optimized result was very poor. The explanation of this phenomenon is that if we fix the parameter e and 1 d , with the increasing of B , n has to become larger to keep the balance of the formula (3). So, more samples were needed to do the Hoeffding selection operation.
When B was set to a too small value, with the initial condition, it is very hard to find individuals whose fitness is less than B .Thus, although the time cost is cut down, the optimization result was very poor. 5.3. Population scale select i best individuals from the population P will become smaller as the population size m increasing. However, when we set the judgment condition to g mod t  X  1in Fig. 1 and fix the parameter B , n and d , the algorithm finds the optimal solution more stably and quickly as the increasing of m . From Fig. 5 ,we can see that MAE becomes smaller as the parameter m increasing. How dose it happen? population P are less than e when j samples has been met. duals from the population P in one selection operation. Constantly,
Pr selection( i / m ) is greater than Pr j . Theorem 2 is based on the assumption that we can correctly select i best individuals from the population no matter whether we have correctly estimated every individual X  X  fitness. In fact, even if we have wrongfully calculated the whole individual X  X  fitness, we still have the prob-ability to select i best individuals from the population. For example, ten true fitness values of ten individuals are {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}. If the values of them were presented by {0, 1.1, 2.2, 3.2, 4.1, 5.1, 6.3, 7.6, 8.1, 9.2}, we still can select five best individuals by their wrong fitness, just like do it with the ten true fitness value.
Further more, with the increasing of the population, the probability of correctly doing it increases simultaneously. 5.4. Selection interval t
From Fig. 1 , we can see that parameter t is the generation interval of two EA selections. Within them, t 1 times of Hoeffding selections will be implemented. The probability of correctly select-ing i best individuals from the population P within t continual generations will become smaller with the increasing of t .Wecan get if from formula (15). However, the effect of the HEA algorithm was decided by the parameters t , m , n and B together. We should not judge the algorithm X  X  capability by only one or two parameter simply. For example, when d was set to a large value, the prob-ability Pr selection( m ) was a small one. Every time the selection operation takes place, the algorithm will correctly select indivi-duals and form the next generation with a very small probability.
At this time, if we enlarge the parameter t , the algorithm will hardly converge to the optimal solution. On the contrary, when d was set to a small one, the probability Pr selection( m ) So, when the selection operation takes place, the algorithm will correctly select individuals and form the next generation with a large probability. Thus, if we enlarge the parameter t ,thealgorithm will converge to the optimal solution within a short time. We can see it from Fig. 6 .When d  X  0.8, B  X  1.2, m  X  40 and t was set to a small value 3, the algorithm will converge to the optimal solution soon. If we set t to a value 10, the algorithm could not converge to the optimal solution within the given generations. On the other hand, when we set d  X  0.1, B  X  1.2 and m  X  40, the algorithm will converge to the optimal solution no matter what value was set to parameter t . 5.5. Selection probability 1 d and sample sum N Definition 7. (Relative running time): The relative running time T
HEA/EA is the time cost by algorithm HEA divided by the time cost by algorithm EA in a certain number of generations.

We tested the performances of the HEA algorithm with parameters N (sample size) and 1 d (selection probability). In our imagination, the mean absolute error (MAE) will increase with the increasing of the parameter 1 d . However, it seems that no obvious relevancy between the two things. We can see it from Table 1 . (The minimal, average and maximal value of MAE and the ranges of time on 50 times implementation were list in it). What is the reason?
In fact, evolutionary algorithms are search methods that take their inspiration from natural selection and survival of the fittest in the biological world. Each iterative process of an EA involves a competitive selection that weeds out poor solutions. When 1 d was set to a high value, Hoeffding selection operation will correctly select a certain number of best individuals from the population with a high probability. With the increasing of parameter 1 d ,the probability will rise. However, at the same time, the diversity of the individuals will decrease. That always leads to a local optimal solution. So, the mean absolute error (MAE) will not be simply decided by the parameter 1 d .

On the other hand, the running time changed obviously with the increasing of the sample number and parameter 1 d . For standard EA, it is easy to understand that more sample points mean more calculations and longer calculation time. But why the relative running time T HEA/EA became shorter as the increasing of the sample number?
From Section 4.1 , we can see that the termination condition of the Hoeffding selection operation is  X  X  D F 4 e  X  X . According to for-mula (12), when B , m and d were fixed, the parameter e is decided mainly by the current sample number j , not the total number of selection operation has no obvious relationship with N . But for the traditional selection operation, the time cost is a function of parameter N . So, the relative running time T HEA/EA will become shorter with the increasing of parameter N . We can see it from Fig. 7 and formula (16) and (17), the limit of T HEA/EA 1/ t  X  0.2( t  X  5). 5.6. Comparisons-1 (GP, HGP and sampling-GP)
In HGP algorithm, the nature of the approximation method was to calculate the fitness value with a subset of the original sample set.
For the purpose of comparison, we introduce a random sampling GP algorithm (S-GP) and make some comparative research with it. In
Sampling-GP algorithm, we build a subset of the original sample set with the technique of random sampling; and then, we calculate the fitness value of individuals with the subset.

In order to examine the performances of the three algorithms, we implement them on several test data sets generated by functions in Table 2 . The number of the pairs ( x i , y i distribution range are listed in it too. The parameters of algorithm
GP, Sampling-GP and HGP, used in the regression process were listed in Tables 3 and 4 . For GP and Sampling-GP, the selection method was tournament selection. For HGP, the selection method was Hoeffding selection. For Hoeffding selection, parameter  X  X 50% X  X  means that the former half of the individuals in the population was selected. In other words, the population size is 2 * i . errors (RMSE), and the running time of the three algorithms were represented in Table 5 . In Sample 1 X 3, the maximum number of nodes in the trees was set to 25. In Sample 4 X 6, the maximum number of nodes in the trees was set to 50. In all test samples, the elitism was applied to the individuals ranked in the top 1/100th of the population. For all functions we used as fitness the sum of absolute errors, SAE. We define protected division as the operator that returns one if the denominator is exactly zero. The ephemeral random constant R appeared in Table 2 is uniformly distributed over a specified interval of [ 10, 10]. Table 5 sum-marizes the best-of-trial results of the experiment.

To assess the accuracy of the solutions, we considered the fitness of the best individual found within given generations. We computed the sum of absolute errors (SAE), the mean absolute error (MAE) and the root mean squared error (RMSE) across all runs. Table 5 shows the results for each approach, in which we report the total time spent for each tested samples and each approach. From Table 5 we can find that within the same generation, the accuracy of the best solutions obtained by GP is better than that obtained by Sampling-GP. But the time cost by
Sampling-GP is shorter. In fact, the running time of Sampling-GP algorithm is decided by sampling rate. To make the running time of the two algorithms (S-GP and HGP) similar, we set the sampling rate of Sampling-GP algorithm to 30%. We can see that, with the similar running time, HGP algorithm can find more accuracy solutions than Sampling-GP. What is the reason? The first answer is that the distribution of the samples obtained by
S-GP is not balanced. Unbalanced sample points will have bad influences on the regression model. The second answer is that smaller number of sampling points will lead to the loss of some important structural information.

From the analysis in Section 5.5 , we know that the relative running time T HGP/GP will become shorter with the increasing of parameter N and the limit of it is 1/ t . In this experiment, all the parameter t was set to 5. From Table 5 , we can see that the parameters T HGP/GP are so different and changed from 0.28 to 0.42.
The explanation is that in different data set, the distributions of the independent random variables are different. The limit or boundary 1/ t is a theoretical value and is very hard to achieve in practice. Generally speaking, large sample number N will lead to small relative running time.

In fact, the result appeared in Table 5 was based on the number of maximal generation which was decided before run-ning. We can see that from Table 4 . Comparing with GP, HGP did not show significant accuracy improvement on Samples 2 and 5 within the maximal generation. However, the running time of
HGP algorithm was also shorter than GP on Samples 2 and 5. If we increase the maximal generation of HGP, we could found that within the similar running time, HGP will find more accuracy value for Samples 2 and 5 than GP. The implementations of the two algorithms on other samples are the same. 5.7. Comparisons-2 (GP, TAG3P, GP  X  CSAW, HGP, HTAG3P and HGP  X  CSAW)
In order to examine the performance of the proposed frame-work, we constructed three algorithms HGP, HTAG3P and HGP  X  CSAW. The tree adjunct grammar guided genetic programming (TAG3P) is a grammar guided genetic programming system which works well on symbolic regression problem and was proposed by Hoai et al. (2002) . The GP  X  CSAW algorithm is a GP-like algorithm, in which the technique of stepwise adaptation of weights (SAW) was used to improve the performance of genetic programming algorithm ( Eggermont and Hemert, 2001 ). Since the proposed algorithm HEA/HGP is not a simply algorithm, but an evolution framework. Every kind of evolutionary algorithm can be inserted in it. In this section, we constructed there algorithms (HGP, HTAG3P and HGP  X  CSAW) by uniting the proposed frame-work with GP, TAG3P, and GP  X  CSAW algorithms. The parameters of them were listed in Table 7 . In order to observe the efficiency of the six algorithms, we implement them on four test data sets which were produced by functions listed in Table 6 . The structural complexity of them increased step by step.

In each experiment, the problem of symbolic regression was seen as finding a solution (function) which can fit the given sample points. The function set, terminal set and the number of the sample points were list in Table 6 . Totally 300 runs were conducted: 50 runs for each algorithm. If the difference between the sample value and the value calculated by an algorithm was less than 0.0001 at a sample point, we say the algorithm can fit the given sample point. The probability of success of an algorithm is the number of the fitted points divided by the sum of the whole sample points. We can see the probability of success in Fig. 8 . In order to compare the true efficiency of the six algorithms, the abscissa axis we selected was not generation number, but running time. From it we can see that with the increasing of the complex-ity of the four test data sets, the probability of success for the six algorithms kept decreasing. However, the Hoeffding bound based algorithms HGP, HTAG3P and HGP  X  CSAW are more efficient than their original ones Table 7 . 6. Discussions and conclusion
In fact, different evolutionary algorithms have been proposed to dealing with the problem of symbolic regression. For example, linear genetic programming (LGP), Cartesian genetic programming (CGP), gene expression programming (GEP), grammar guided genetic pro-gramming (GGGP), Tree adjunct gr ammar guided genetic program-ming (TAG3P), etc. But most of them pay more attention to the manner of representation, selection, crossover, and mutation. When the number of samples is very large, it is very hard for them to be used to find a satisfying solution in symbolic regression. SAW technique was also used to improve the performance and solution quality of some evolutionary algorithms, but the emphasis of them lies in adapting the fitness function with the information of the problem from the run. Comparativ ely speaking, the proposed HGP algorithm pays more attention to the manner of calculating the fitness values of the individuals. It can find a satisfying solution in an estimate manner and can guarantee that the solution discovered is optimal or near-optimal with a determinate probability. work and can estimate the fitness of individuals without reading in the whole date set, it can be widely used in many areas where the evaluation of the fitness is computationally very expensive.
For example, aerodynamic design optimization, circuit design, routing, and scheduling. In fact, when 1 d was set to a high value, Hoeffding selection operation will correctly select a certain number of best individuals from the population with a high probability. But the running time of it will increase simultane-ously. On the contrary, when it is set to a low value, the running time will decrease, but it will lead to a deceasing of accuracy. It is difficult to select a proper value for it. Perhaps, we can start with a small 1 d at the beginning of the run (fast evaluations, but very coarse-grain) and converge to a large 1 d at the end of the run (expensive evaluations with good validation). In addition, in
Section 3 , two kinds of iterative fitness function were represented by formula (4) and (5). The problem of symbolic regression with large number of sample points can be described by the first one and can be dissolved by the proposed framework. However, how to develop the framework to deal with the other kind of fitness function is the task left to us.

Based on the empirical convergence studies on several symbolic regression problems, Hoeffding bound based evolution framework is suggested to ensure the correct convergence and to accelerate the evolutionary process. With the helping of Hoeffding inequality, we can estimate the fitness of individuals without reading in the whole date set. The computation time was reduced obviously and can be tuned with parameter t . Results on examples show that the proposed framework is very promising to problems with the iterative fitness function and can find solutions more efficiently than tradition EA. It is very useful for regression problems with large number of training samples.
 Acknowledgment
We are grateful to the anonymous r eferees for their invaluable suggestions to improve the paper. This work was supported by the
National Natural Science Foundation of China (Grant nos. 60873035, 61073091, 61100009) and by Founda tion of Excellent Doctoral Dissertation of Xi X  X n University of Technology (116-211102). References
