 Naive Bayes (NB) [1] is a simple, computationally efficient probabilistic approach to classification learning. It assumes that all attributes are conditionally inde-pendent of each other given the class. As an improvement to NB, Averaged One-Dependence Estimators (AODE) [2] relaxes the attribute independence as-sumption by averaging all models that assume all attributes are conditionally dependent on the class and one common attribute, known as the super-parent. This often improves the classification p erformance significa ntly. An extensive comparative study [3] shows that AODE obtains significant lower error rates than most alternative semi-naive Bayes algorithms with similar computational complexity. One of the attractive features of AODE is that it has complexity linear with respect to data quantity, making it a useful approach for big data.
Attribute selection has been demonstr ated to be effective at improving the accuracy of AODE [4,5]. However, the mos t effective conventional attribute se-lection techniques have high computational complexity and hence are not feasible in the context of big data. In this pape r we develop an efficient attribute selec-tion algorithm for AODE that is linear with respect to data quantity, and of low polynomial complexity in the number of attributes and hence well suited to big data. The empirical results show that this technique obtains lower bias than AODE, and thus usually achieves lower error on larger data sets, at the cost of only a modest increase in training time. The classification task can be described as follows, given a training sample T of t classified objects, we are required to predict the probability P( y | x )thata new example x = x 1 ,...,x a belongs to some class y ,where x i is the value of the attribute x i and y  X  X  c 1 ,...,c k } .

In the following sections, we describe AODE for this classification task and a number of its key variants. 2.1 AODE From the definition of conditional probability, we have P( y | x )=P( y, x ) / P( x ) . as the normalizing constant and estimate only the joint probability P( y, x )in the remainder of this paper.

Since the example x does not appear frequently enough in the training data, we cannot directly derive an accurate estimate of P( y, x ) and must extrapolate this estimate from observations of lower-dimensional probabilities in the data [6]. Applying the definition of conditional probabilities again, we have P( y, x )= estimated from the sample frequencies, if the number of classes, k ,isnottoo large. For the second term P( x | y ), AODE assumes every attribute depends on the same parent attribute, the super-parent, thus obtains an one-dependence estimator (ODE), and then averages all eligible ODEs [2]. The joint probability P( y, x ) is estimated as follows, where | X | denotes the cardinality of a set,  X  P(  X  ) represents an estimate of P(  X  ), F( x i ) is the frequency of x i and m is the minimum frequency to accept x i as a super parent. The current research uses m =1[7]. 2.2 Weightily AODE In the classification of AODE, each ODE is treated equally, that is, all eligible models are averaged and contribute uniformly to the classification rule. How-ever, in many real world applications, attributes do not play the same role in classification. This observation inspires the weightily AODE [8], in which the joint probability is estimated as, In practice, mutual information between the super-parent and the class is often used as the weight W i . 2.3 AODE with Subsumption Resolution One extreme type of inter-dependence between attributes results in a value of one being a generalization of a value of the other. For example, consider Gender and Pregnant as two attributes, then Pregnant = yes implies that Gender = female . Therefore, Gender = female is a generalization of Pregnant = yes . Likewise, Pregnant = no is a generalization of Gender = male . Where one value x i is a generalization of another, x j , P ( y dropping the more general value from any calculations should not harm any posterior probability estimates, whereas assuming independence between them may.

Motivated by this observation, Subsumption Resolution (SR) [9] identifies pairs of attribute values such that one appears to subsume the other and deletes the generalization. Suppose that the set of indices of the resulting attribute subset is denoted by R , the joint probability is estimated as, 2.4 Forward and Backward Attribute Selection in AODE In order to repair harmful inter-dependencies among highly correlated attributes, Zheng et al [5] proposed to select an appropriate attribute subset by hill climbing search. Two different search strategies can be used: FSS begins with the empty attribute set and successively adds attributes [10], while BSE starts with the complete attribute set and successively re moves attributes [11]. Both strategies greedily select the attribute whose addition or elimination best reduces the leave-one-out cross validation error on the training set. The process is terminated if there is no error improvement.

To differentiate the selection of parent or child, they introduce the use of a parent ( p )anda child ( c ) set, each of which contains the set of indices of attributes that can be employed in, respectively, a parent or a child role in AODE. The joint probability is estimated as,
As indicated in [5], the performance of BSE is better than FSS, so we focus on BSE in this paper. Four types of attribute elimination are considered, parent elimination (PE), child elimination (CE), parent and child elimination (P  X  CE), parent or child elimination (P  X  CE) which performs the former three types of attribute eliminations in each iteration, selecting the option that best reduces the error.

The last strategy allows flexible select ion of parents and children, but comes at a high cost, since it needs to scan the training data 2 a times in the worst case. 2.5 A n DE The last extension to AODE we review here is A n DE [6], which allows children to depend on not just one super-parent, but a combination of n parents. The joint probability P( y, x ) is estimated as follows, where A n indicates the set of all size-n subsets of { 1 ,  X  X  X  ,a } and x s means the set of attribute values indexed by the element in s .
 Note that A n DE is in fact a superclass of AODE and NB. That is, AODE is A n DE with n = 1 (A1DE) and NB is A n DE with n =0(A0DE). Previous work on attribute selection for AODE through BSE and FSS [4,5] has demonstrated attribute selection did succeed in reducing the harmful influence of inter-dependencies among attributes. This success m ay be attributed to their ability to search in a large model space. For P  X  CE, the search space is of size 2 a +1 , as it includes all subsets of attributes in parent role coupled with all subsets of attributes in child role. 1
Nevertheless, this is achieved at a high computational overhead. The strategy of P  X  CE needs to scan the training data 2 a times, as each time either one child or one parent can be deleted. This is impractical for data sets with a large number of attributes.

In order to explore a large space of models in a single additional pass through the data, we propose a new attribute selection approach for AODE. Our proposal is based on the observation that it is possible to nest a large space of alternative models such that each is a trivi al extension to another. Let p and c be the set of indices of parent and child attributes , respectively. For every attribute x i ,the AODE models that use attributes in p as parents and attributes in c  X  X  i } as children are minor extensions of a model that uses attributes in p as parents and attributes in c as children. The same is true of models that use attributes in p  X  X  i } as parents and attributes in c as children. Importantly, multiple models that build upon one another in this way can be efficiently evaluated in a single set of computations. Using this observation, we create a space of models that are nested together, and then select the b est model using leave-one-out cross validation in single extra pass through the training data.

Step by step information of the algorithm is provided in the following sections. 3.1 Ranking the Attributes Our method for nesting models depends on a ranking of the attributes. Models containing lower ranked attributes will be built upon models containing higher ranked attributes. The mutual information between an attribute and the class measures how informative this attribute is about the class [12], and thus it is a suitable metric to rank the attributes.

The advantage of using mutual information is that it can be computed very efficiently after one pass through the training data. Although the mutual infor-mation between an attribute and the class can help to identify the attributes that are individually most discriminative, it is important to note that it does not directly assess the discriminative power of an attribute in combination with other attributes. Nevertheless, the ranking of attributes based on mutual information with the class will permit the search over a large space of possible models and the deficiencies of this discriminative approach will be mitigated by the richness of the search space that is evaluated in a discriminative fashion. 3.2 Building the Model Space Without loss of generality, in the following we assume that the attributes are ordered by mutual information. That is, x i represents the attribute with the i th greatest mutual information with the cl ass. As the attributes have been ranked, we can create, in total, a 2 nested submodels of attribute subsets. To be more specific, suppose we select top r attributes as parents and top s attributes as children, where 1  X  r, s  X  a , the candidate AODE model would be,
Figure 1 gives an example of the model space with 3 attributes. For instance, model m 21 considers the two attributes { x 1 , x 2 } as parents and a single attribute { x we obtain a new model m 22 . When instead the attribute x 3 is considered to be added as a parent, we obtain a new model m 31 . Both of these models are minor extensions to the existing model m 21 and all three (and all their extensions) can be applied to a test instance in a single nested computation. Consequently all models can be efficiently evaluated in a single set of nested computations. 3.3 Selecting the Best Model Once we have built the model space, we ca n perform model selection within this space. To evaluate the goodness of an alternative model, an evaluation function is required, which commonly measures the discriminative ability of the model among classes.

We use leave-one-out cross validation e rror to measure the performance of each model. Rather than building a new model for every fold, we use incremental cross validation [13], in which the contribution of the training example being left out in each fold is simply subtracted from the count table, thus producing a model without that training example. This method allows the model to be evaluated quickly, whilst obtaining a good estimate of the generalization error.
There are several loss functions to measu re model performance for leave-one-out cross validation, zero-one loss and root mean squared error (RMSE) are among the most common and effective. Zero -one loss simply assigns a loss of  X 0 X  fications as equally undesirable. RMSE, however, accumulates for each example the squared error, which is the probability of incorrectly classifying the example, and then computes the root mean of the sum. As RMSE gives a finer grained measure of the calibration of the probability estimates compared to zero-one loss, with the error depending not just on which class is predicted, but also on the probabilities estimated for each class, we use RMSE to evaluate the candidate models in this research. 3.4 Algorithm and Analysis Based on the methodology presented above, we develop the training algorithm for attribute selective AODE shown in Algorithm 1.
 Algorithm 1. Training algorithm for attribute selective AODE
As in AODE, we need to form the table of joint frequencies of pairs of y,x i ) and the mutual information between the attributes and class are derived. This is done in one pass through the training data (line 1). Note that this pro-vides all of the information needed to create any selective AODE model with any sets of parent and child attributes.

In the second pass through the training data (line 4-8), the squared error is accumulated for each model. After thi s pass, the RMSE will be computed and used to select the best model.

At training time, the space complexity of the table of joint frequencies of attribute-values and class is O ( k ( av ) 2 )asinAODE,where v is the average number of values per attribute. Attribut e selection will not require more memory. Derivation of the frequencies required to populate this table is of time complexity O ( ta 2 ). Attribute selection needs one more pass through the training data, the time complexity of which is O ( tka 2 ), since for each example we need to compute the joint probability in (1) for each class. So the overall time complexity is O ( t ( k +1) a 2 ).

Classification requires the table of probability estimates formed at training time of space complexity O ( k ( av ) 2 ). The time complexity of classifying a single example is O ( ka 2 ) in the worst-case scenario, b ecause some attributes may be omitted after attribute selection. In this section, we compare the newly p roposed attribute selective AODE (AS-AODE) with AODE, weightily AODE (WAODE), AODE with subsumption resolution (AODESR), BSE selective AODE (BSEAODE) and A2DE.
 Zheng et al [9] discussed three different subsumption resolution techniques, Lazy SR, Eager SR and Near SR. Lazy SR is used in this paper, as it can improve AODE with low training time and modest test time overheads. The minimum frequency for identifying generalizations is set to 100. The results in [5] show that BSE performs better than FSS, and the elimination of a child is more effective than the elimination of a parent. So we select only the children in BSEAODE. However, we do not perform statistical tests in BSEAODE, as we do not do this in ASAODE, either. We also include A2DE in the set of experiments so as to provide a comprehensive comparison.

The experimental system is impleme nted in C++. In order to deal with nu-merical data, Minimum Description Length (MDL) discretization [14] is imple-mented. More specifically, the cut points are computed on 100,000 examples randomly selected from training data or on all training examples if the train-ing data is less than 100,000. These cut points are then used to discretize the training and test data. The base probabilities are estimated using m -estimation ( m = 1) [15]. Missing values have been considered as a distinct value. We run the above algorithms on 71 data sets from the UCI repository [16]. Table 1 presents the detailed characteristics of data sets in ascending order on the number of instances. We run the experiments on a single CPU single core virtual Linux machine running on a Sun grid node with dual 6 core Intel Xeon L5640 processors running at 2.27 GHz with 96 GB RAM.
 4.1 Bias, Variance and RMSE Because ASAODE explores a larger space of models than AODE and BSEAODE explores a larger space of models than ASAODE, we expect BSEAODE to have the lowest bias, followed by ASAODE then AODE and this order to be reversed for their relative variance. Hence we expect AODE to deliver the lowest error on smaller datasets, ASAODE to dominate at some intermediate data size, and for BSEAODE to deliver the lowest error on very large data. The bias and variance of ASAODE relative to WAODE, AODESR and A2DE can be expected to vary from dataset to dataset as these all embody different learning biases and none of their spaces of models subsumes the other.

In order to assess these expectations, w e first perform bias variance decompo-sition using the experimental method proposed by Kohavi and Wolpert [17]. As this study is more meaningful with more data, we run these experiments only on the largest 28 data sets which have at least 2000 examples. For each data set, 1000 training examples and 1000 test examples are randomly selected. The bias variance decomposition is calculated f rom the error on the test examples. This process is repeated 10 times to ob tain the mean bias and variance.
A summary of pairwise win/draw/loss records, which indicate the number of data sets on which one algorithm has lower, equal or higher outcome relative to the other, is presented in Table 2. Each entry in cell [ i, j ] compares the al-gorithm in row i against the algorithm in column j .The p value following each win/draw/loss record is the outcome of a b inomial sign test and represents the probability of observing the given number of wins and losses if each were equally likely. The reported p value is the result of a two-tailed test. We consider a difference to be significant if p  X  0 . 05. All such p values have been changed to boldface in the table.

Table 2 shows that all five variants to AODE achieve significant reductions in bias relative to AODE. While ASAODE achieves lower bias than WAODE and AODESR more often than not, the reverse is true for BSEAODE and A2DE; although these differences are not significant.

Next, we conduct 10-fold cross validation experiments to obtain the error of the alternative algorithms. As attribut e selection is based on the RMSE metric, we are inclined to evaluate the error by RMSE. The win/draw/loss records of alternative algorithms for RMSE on 71 data sets are also presented in Table 2.
We can see that all five improvements to AODE have achieved significant reductions in RMSE relative to AODE. ASAODE has also achieved signif-icant reductions in RMSE relative to WAODE and AODESR. The p value (0 . 807)indicates that ASAODE and BSEAODE have achieved almost the same performance. But the advantages of BSEAODE over WAODE and AODESR are not as significant as those of ASAODE over WAODE and AODESR. While A2DE achieves significant reductions in RMSE relative to AODE, WAODE, AODESR and BSEAODE, its advantage over ASAODE is not significant.

The fact that ASAODE obtains, in general, lower bias and higher variance compared with WAODE and AODESR, indicates that it will perform better on larger datasets, since it will be able to capture more complex relationships from large amount of data [18]. In order to demonstrate this hypothesis, we also compile the win/draw/loss results in terms of RMSE on the 43 smallest data sets and the 28 largest data sets in Table 2. We can see that the performance of ASAODE is better on large data sets than on small data sets. While for even larger data sets BSEAODE and A2DE might outperform ASAODE for the same reason, both have high computational complexity that can be prohibitive for large data, since BSEAODE requires 2 a pases on the whole training set and A2DE X  X  memory requirements and classification time are very high (see the following Section 4.2). 4.2 Computation Time The logarithmic means of training and classification time on the 71 data sets for all algorithms are shown in Fig. 2. We have added 1 to each mean before comput-ing the logarithm to avoid negative bars. ASAODE requires more training time than such one pass algorithms as AODE, WAODE and AODESR. This is because ASAODE involves two passes through the training data. As BSEAODE needs at most 2 a passes, it requires significantly more training time than ASAODE.
As for the classification time, ASAODE, AODESR and BSEAODE require, in general, less time than AODE and WAODE because they might eliminate some attributes. Fig. 2 also shows that ASAODE requires even less classification time than AODESR and BSEAODE.
A2DE requires more training and classification time than AODE, as it needs to compile a more complicated table at training time and requires more compu-tation at classification time. In this paper, a new attribute selection algorithm is proposed for AODE. It is a two-pass algorithm, so compared to AODE, it just requires one more pass through the training data. The alternative attribute selection methods, such as FSA and BSE, need a number of passes that is linear to the number of attributes to obtain similar results.

The empirical results show that the new algorithm is significantly more accu-rate than AODE, WAODE and AODESR, has comparable error to BSEAODE, and as we expected, worse than A2DE. It req uires significantly less training time than BSEAODE, and less classification time than AODE and all other variants, especially than A2DE.

It is worthwhile to note that the technique proposed in this paper is of squared complexity in the number of attributes, so it is not scalable to high dimensional data. On the other hand, it is compatible with weighting, subsumption resolution and higher orders of A n DE. Consequently, it might be possible to further improve the accuracy by combining it with weighting, subsumption resolution and A2DE. This is a promising direction for future research.
 Acknowledgments. This research has been supported by the Australian Re-search Council under gra nt DP110101427, Asian Office of Aerospace Research and Development, Air Force Office of Scientific Research under contract FA2386-1214030, National Natural Science Fo undation of Chin a under g rant 71271117, 61202135, Natural Science Foundation of Jiangsu, China under gra nt BK2011692, BK2012472, Qinglan Project and Priority Academic Program of Audit Science and Technology of Jiangsu, China, Jiangsu Government Scholarship for Overseas Studies, Overseas Studying Scholarship of Nanjing Audit University.
 This research has also been supported in part by the Monash e-Research Center and eSolutions-Research Support Services through the use of the Monash Campus HPC Cluster and the LIEF grant. This research was also undertaken on the NCI National Facility in Canberra, Australia, which is supported by the Australian Commonw ealth Government.

