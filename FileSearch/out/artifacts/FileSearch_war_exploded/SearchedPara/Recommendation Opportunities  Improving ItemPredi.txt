 This paper proposes a novel method for estimating unknown r atings and recommendation opportunities and illustrates the practical implementation of the proposed approach by presenting a certain variation of the classical k -NN method in neighborhood-based collaborative filtering systems using weighted percentiles. We conduct an empirical study show-ing that the proposed method outperforms the standard user-based collaborative filtering approach by a wide mar-gin in terms of item prediction accuracy and utility-based ranking metrics across various experimental settings. We also demonstrate that this performance improvement is not achieved at the expense of other popular performance mea-sures, such as catalog coverage and aggregate diversity. The proposed approach can also be applied to other popular methods for rating estimation.
 H.4.m [ I nformation Systems Applications ]: Miscella-neous Keywords: Weighted Percentiles; Item Accuracy; Collabo-rative Filtering; Recommendations; Recommender Systems
Although there have been many rating estimation meth-o ds developed over the last 20 years [6], the classical user-based k -NN collaborative filtering (CF) method still remains one of the most popular and prominent methods used in the recommender systems (RSs) community.

In this paper, we propose a novel method for estimating unknown ratings and recommendation opportunities and il-lustrate the practical implementation of the proposed ap-proach by presenting a certain variation of the classical k -NN method in which the estimation of an unknown rating of the user for an item is based not on the weighted average of the k nearest neighbors but on the weighted percentile of the ratings of these k neighbors. The key intuition behind using this weighted percentiles method, instead of weighted averages, is that high percentiles (such as in the 70% to 90% range) constitute more realistic estimates of how much a targeted user could possibly like the candidate item based on the experiences of his/her neighbors. Using such high percentiles is analogous to  X  X hifting the needle X  in our rating combining function from the middle of the rating distribu-tion, as in the case of the weighted average, toward the tail on the right side of the distribution, targeting recommenda-tions that the users will like better.

To support this claim, we conducted an empirical study and showed that the proposed percentile method outper-forms the standard user-based CF approach by a very wide margin, across various experimental settings, in terms of popular item prediction accuracy and utility-based ranking metrics. Finally, we demonstrate that this performance im-provement is not achieved at the expense of some other pop-ular performance measures, such as aggregate diversity.
In the recommender systems literature, since the first CF s ystems were proposed in the mid-90 X  X  [11], [21], there have been many attempts to improve their performance [20]. For instance, [12] studies variations of rating normalization, sim-ilarity weighting and neighbor selection schemes, and [22] calculates similarities using regressions. However, there is still a long way to go in terms of satisfaction of users X  actual needs [17] and many approaches that go beyond the rating prediction perspective trying to alleviate the problems per-taining to the narrow rating prediction accuracy-based focus [1] have been gaining significant attention [14].

Moving beyond this narrow focus, in the related field of data mining, [19] discusses the use of combining functions in clustering and [18] utilizes the concept of percentiles, look-ing for the 80 percent of the conditional spending distribu-tion of customers, in order to identify new sales prospects. Even though this idea of percentiles was applied to cluster-ing techniques in data mining, it has not yet been applied to the RSs problems. In this paper, we apply the concept of percentiles, proposed in the data mining community, to the CF approach and show that this method improves per-formance on neighborhood models in very significant ways.
Under a definition of r ecommendation opportunity as how much a user could realistically like an item, we are look-ing for a high percentile (e.g. 80 percent) of the conditional distribution of the rating for the specific target user and candidate item, given all the information we have about them. Utilizing the high percentiles, we aim at recommend-ing items that the users will remarkably like. One of the challenges here is to get a good estimate of the conditional rating percentile for each user and item from the available data. In the next section, we illustrate the practical im-plementation of the proposed approach in the context of neighborhood models.
User-based neighborhood recommendation methods pre-d ict the rating r u,i of user u f or item i using the ratings given to i by users most similar to u , called nearest neigh-bors and denoted by N i ( u ) . Taking into account the fact that the neighbors can have different levels of similarity, w u,v , and considering the k u sers v with the highest sim-ilarity to u (i.e. the standard user-based k -NN collaborative filtering approach), the predicted rating is:
However, the ratings given to item i by the nearest neigh-bors of user u can be combined into a single estimation using various combining (or aggregating) functions [6].

In this paper, we propose to use higher weighted per-centiles as a combining function. Such a high percentile p (e.g. 70 th , . . . , 90 th ) of the conditional distribution of the u ser X  X  rating, given all the information that we have avail-able, characterizes how much the target user u could real-istically like the candidate item i . Intuitively, using high percentiles is analogous to  X  X hifting the needle X  in our rating combining function from the middle of the rating distribu-tion, as is the case with the weighted average, toward the tail on the right side of the distribution targeting recom-mendations that the users will like better. Formally, the percentile, denoted by  X  r p u ,i , is defined such that the proba-b ility that user u would rate item i with a rating of  X  r l ess is p %. Note that both low and high ratings contribute to the estimation since they affect the rank of the values and, thus, the percentile quantity of interest.

In a typical k -NN collaborative filtering model, the in-formation that we have available in order to estimate an unknown rating, and respectively the quantity  X  r p u ,i , is the n eighbors of user u , denoted by N i ( u ) , the similarity levels of these neighbors w N example of the proposed method and its differences from the classical approaches, consider the neighborhood N ( u ) and items x and y with ratings r N ( u ) , x = (2 , 3 , 3 , 4 ) and r
N ( u ) , y = (2 , 2 , 4 , 4 ), respectively. Using the standard com-bining function as in (1), item x would be recommended. However, using, for instance, the weighted 80 th percentile of t he variable r N ( u ) , i , item y w ould be recommended since the specific percentile for item y , denoted by  X  r p = 80 t o a higher rating than item x and, thus, there is high po-tential that user u could realistically like item y more than x ; equivalently, the probability of user u assigning a rating greater or equal to 4 is higher for item y than x .
Algorithm 1 summarizes the user-based k -nearest neigh-bors ( k -NN) collaborative filtering approach with a general combining function and Algorithm 2 shows a procedure to estimate a weighted percentile  X  r p u ,i (i.e. the proposed com-b ining function), where the values r N ( u ) , i are the ratings given to candidate item i by neighbors N i ( u ) , the k users most similar to target user u , and the weights w N t he corresponding similarity levels of neighbors to user u .
To empirically validate the proposed method and evaluate t he generated recommendations, we conduct a large number of experiments on  X  X eal-world X  data sets and compare our results to the k -NN CF approach, which has been found to perform well also in terms of other performance measures besides the classical accuracy metrics [7], [13], [3, 4]. The data sets that we used are the RecSys HetRec 2011 M ovieLens data set [8] and the BookCrossing data set [23].
The RecSys HetRec 2011 MovieLens (ML) data set con-tains personal ratings and tags about movies and consists of 855,598 ratings from 2,113 users on 10,197 items.

The BookCrossing (BX) data set is described by [23] and gathered from Bookcrossing.com, a social networking site founded to encourage the exchange of books. Following Ziegler et al. [23] and owing to the extreme sparsity of the data, we decided to condense the data set in order to ob-tain more meaningful results from collaborative filtering al-gorithms. Hence, we discarded as in [23] all books for which we were not able to find any information, along with all the ratings referring to them. Next, we also removed book ti-tles with fewer than 4 ratings and community members with fewer than 8 ratings each. The dimensions of the resulting data set were considerably more moderate, featuring 8,824 users, 7,818 books, and 107,367 explicit ratings.
Using the ML and BX data sets, we conducted a large n umber of experiments and compared our method against the standard user-based k nearest neighbors collaborative filtering approach. In order to test the proposed approach of weighted percentiles under various experimental settings, we used 2 data sets, 6 different sizes of neighborhoods ( k  X  { 30 , 40 , . . . , 80 } ), 9 different percentiles as combining func-tions ( p  X  { 10 , 20 , . . . , 90 } ), and generated recommendation Data Method Recommendation List Size Set 3 5 10 30 50 100
ML
BX sulting in 1,404 experiments in total.

For the computation of the weighted percentiles, we used the gmisclib [10] scientific library. Besides, we used Pearson correlation to measure similarity. Finally, we used a holdout validation scheme in all of our experiments with 80 / 20 splits of data to the training/test part in order to avoid overfitting.
The aim of this study is to demonstrate that the proposed m ethod is indeed effectively increasing the classical item pre-diction accuracy measures and performs well in terms of other popular performance measures, such as catalog cover-age, by a comparative analysis of our method and the stan-dard k -NN algorithm, in different experimental settings.
The goal in this section is to compare our method with the s tandard baseline methods in terms of traditional metrics for item prediction , such as precision, recall, and F 1 score. Ta-b le 1 presents the results obtained by applying our method to the MovieLens and BookCrossing data sets. The values reported are computed as the average performance over the six neighborhood sizes using the F 1 score for recommenda-1 illustrates the average performance for neighborhoods of
Table 1 and Fig. 1 demonstrate that the proposed method outperforms the k -NN method by a wide margin. In partic-ular, for both data sets, accuracy was improved in all the experiments using high percentiles. Besides, as we can ob-serve, the increase in performance is larger for recommenda-tion lists of larger size. For the ML data set the maximum F score was achieved using the 70 th percentile (0 . 0 24) whereas for BX the maximum was 0 . 0048 using the 90 th percentile.
T o determine statistical significance, we have tested the null hypothesis that the performance of each of the methods is the same using the Friedman test. Based on the results, we reject the null hypothesis with p &lt; 0 . 0001. Performing post hoc analysis on Friedman X  X  Test results, the differences between the Baseline k -NN and each one of the experimental settings are statistically significant. Fig. 2 presents the box-Figure 1: Prediction Accuracy (F 1 score) for the (a), (b) M ovieLens (ML) and (c), (d) BookCrossing (BX) data sets. (a) MovieLens data set (b) BookCrossing data set Figure 2: Post hoc analysis for Friedman X  X  Test of Item Pre-diction Accuracy (F 1 score) for the both data sets. a nd-whisker diagrams displaying the aforementioned differ-ences among the various methods.

Similar results were also obtained using standard utility-based ranking metrics, such as the normalized discounted cumulative gain (nDCG) and mean reciprocal rank (MRR).
In this section we investigate the effect of the proposed m ethod on coverage and aggregate diversity, two important metrics for RSs [20], that go beyond the classical perspec-tive of rating prediction accuracy [1]. The results obtained using the catalog coverage metric [9] (i.e. the percentage of items in the catalog that are ever recommended to users) are equivalent to those using the diversity-in-top-N metric for aggregate diversity [5]; henceforth, only results on cov-erage are presented. Table 2 presents the results obtained by applying our method to the ML and BX data sets. The values reported are computed as the average catalog cov-erage over six neighborhood sizes ( k  X  { 30 , 40 , . . . , 80 } ) for recommendation lists of size l = { 3 , 5 , 10 , 30 , 50 , 100 } .
Table 2 demonstrates that the proposed method performs at least as well as, and is some cases even better than, the Data Method Recommendation List Size Set 3 5 10 30 50 100
ML
BX standard user-based k -NN method. In particular, for the ML data set, where the Baseline k -NN results in low cover-age, performance is increased on average by 643 . 77%, with the 90 th percentile exhibiting the highest coverage. For the B X data, where the Baseline k -NN results in high cover-age because of the specifics of the particular data set and the larger number of users, the performance is on average the same (+0 . 00). In terms of statistical significance, using the Friedman test and performing post hoc analysis, for the ML data set the differences among the standard user-based k -NN method and all the experimental settings are statisti-cally significant ( p &lt; 0 . 005). For the BX data set, only the differences between the 70 th percentile and the remaining e xperimental settings are statistically significant.
The generated recommendation lists can also be evaluated for the inequality across items using the Gini coefficient. In particular, for the ML and BX data sets the Gini coefficient was on average improved by 2 . 58% and 0 . 27%, respectively. As we can conclude, in the recommendation lists generated from the proposed method, the number of times an item is recommended is more equally distributed.

In summary, we demonstrated that the proposed method outperforms the standard user-based k -NN algorithm by a wide margin in terms of item prediction accuracy and utility-based ranking metrics and performs at least as well as, and in some cases even better than, the standard baseline method in terms of some other popular performance measures.
In this paper, we present a novel method for estimating u nknown ratings and recommendation opportunities based on weighted percentiles. We illustrate the practical imple-mentation of the proposed approach in the context of neigh-borhood models adapting the classical k -nearest neighbors method. In addition, we conduct an empirical study showing that the proposed method outperforms the standard user-based collaborative filtering approach by a wide margin in terms of item prediction accuracy and utility-based ranking measures, such as the F-measure and normalized discounted cumulative gain, across various experimental settings. We also demonstrate that this performance improvement is not achieved at the expense of some other popular performance measures, such as aggregate diversity.
 Moreover, apart from the user-based and item-based k -NN collaborative filtering approaches, other popular meth-ods that can be easily extended, with the use of quantile regression, in order to allow us both to build models that predict high percentiles and to evaluate them with regard to the goal of predicting percentiles of estimated ratings, in-clude content-based methods, and Matrix Factorization [16].
Nevertheless, the proposed approach should be tested us-ing various rating normalization and similarity weighting schemes [15] as well as different distance metrics [12].
As a part of the future work, we would like to conduct live experiments with real users in an on-line retail setting as well as in a platform for massive open on-line courses [2]. Also, we will study the impact of the proposed method on novelty, serendipity, and unexpectedness [3, 4] of RSs.
