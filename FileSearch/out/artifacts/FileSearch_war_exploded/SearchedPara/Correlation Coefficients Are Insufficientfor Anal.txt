 equivalent to the full dependence.
 that the impact of correlations is negligible for small popu lations of neurons. information measures even if they are present and go unnotic ed or are ignored. neurons and small numbers of samples.
 discussion of the advantages and limitations of the present ed methods and cases. We will now describe formal aspects of spike count models and their Shannon information. 2.1 Copula-based models with discrete marginals uniform marginals [ 16 ]. Formally, a bivariate copula C is defined as follows: Definition 1. A copula is a function C : [0 , 1] 2  X  X  X  [0 , 1] such that: Copulas can be used to couple arbitrary marginal CDF X  X  F F
X ( r 1 , r 2 ) = C ( F X 1 ( r 1 ) , F X 2 ( r 2 )) by The Frank family is commutative and radial symmetric: its pr obability density c pendence. As  X   X   X  X  the copula approaches deterministic positive/negative de pendence: knowl-variate Gaussian copula family defined as C marginals.
 For a given realization ~r , which can represent the counts of two neurons, we can set u and F multivariate distribution with specific marginals F bution the CDF X  X  of the marginals take the form where  X  binomial distribution as a generalization of the Poisson di stribution: where  X  is the gamma function. The additional parameter  X  the smaller the value of  X  of Poincar  X  e and Sylvester. The probability of a realization ( x F probability mass of a realization ~x using only the CDF of ~ X . 2.2 Computation of information entropy decoder is missing when it does not know the value ~x of ~ X . It is given by where I ( ~x ) =  X  log 2.3 Leaky integrate-and-fire model brane potentials. The equation for the membrane potential i s given by where E the synaptic input current, and  X  states that whenever V reaches a threshold V V and V  X  -function [ 22 ]: I decays with time constant  X  hibitory synapse by a negative I for inhibitory synapses, and  X  Frank shuffle copulas. (a, d): Independence:  X  in outer square:  X   X  =  X  5 ,  X  2 = 30 ,  X  = 0 . 2 . and show that such effects can occur in very simple biologica l networks. 3.1 Frank shuffle copula coefficient would vanish.
 Proposition 1. The following function defines a copula  X   X  C where  X   X  (  X ,  X , m, 1  X   X  ) / X   X  copula with  X  z be sufficient to select  X  Fig. 1 .
 Figure 2: Entropy of distributions based on the Frank shuffle copula C different dependence strengths  X  we selected rates  X  C model with independent elements in percent of the independe nt model. marginals for uncorrelated but dependent elements.  X  coefficient as the objective function. Independence is atta ined for  X  dence the entropy decreases until it reaches a minimum at  X  dependency is almost deterministic and thus does not repres ent a relevant case. The entropy deviated by up to 25 % for the Poisson marginals and up to 15 % for the negative correlated elements.
 network models. 3.2 LIF network excitatory neurons can project to both excitatory and inhib itory neurons. strengths of the input populations: where  X  A copula of this family is shown in Fig. 3 (b).
 sity of the Clayton mixture model C cm of Correlation coefficients of the first mixture component of C cm coefficients of the second mixture component of C cm feed-forward network that contains positive and negative w eights. measure for the dependence. of-fit test to see if the model is adequate for the data.
 with different dependence strengths and Poisson marginals with rates  X  correlation kept at zero. (b): Clayton mixture family C cm (d): Gaussian family. independence test is a special case of our linear correlatio n test. of Kendall X  X   X  . Kendall X  X   X  is a measure of dependence defined as  X  ( ~x, ~y ) = c  X  d number of elements in the set { ( i, j ) | ( x the number of element in the set { ( i, j ) | ( x For the Frank copula with continuous marginals the relation between  X  and  X  is given by  X  marginals this is an approximate relation. Unfortunately,  X   X  1 but can be easily obtained numerically using Newton X  X  metho d. frequencies are compared to expected frequencies using the following statistic: where n where N is the number of rows, M is the number of columns, and s is the number of parameters in the H the hypothesis H freedom.
 frequencies m grouped from left to right such that the grouped m grouped expected and grouped observed frequencies.
 dependence. We therefore expected that the test should acce pt H lation does not reflect the dependence strength. Hence, the t est should reject H when there is dependence.
 Therefore, the test is unreliable when dependencies and sam ple sizes are both very small. the full dependence structure and a closer look at experimen tally observed dependencies. Acknowledgments. This work was supported by BMBF grant 01GQ0410. Proof. We show that C For u = 0 or v = 0 and for u = 1 or v = 1 we have C follows directly from C show this in two steps: 1) We show that C For v  X  (  X , 1  X   X  ) : We can use l X  X   X  opital X  X  rule since lim Thus, the quotient is constant and lim 2) [  X , 1  X   X  ] 2 , because C  X  Thus, C increasing.

