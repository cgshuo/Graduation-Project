 School of Computing Science A health care claims processing application is introduced which processes both structured and unstr uctured information associated with medical insurance claims. The application makes use of a natural language processing (NLP) engine, together with application-specific knowledge, written in a concept specification language. Using NLP techniques, the entities and relationships that act as indicators of recoverable claims are mined from management notes, call centre logs and patient records to identify medical claims that require furt her investigation. Text mining techniques can then be applie d to find dependencies between different entities, and to combine indicators to provide scores to individual claims. Claims are scored to determine whether they involve potential fraud or abuse, or to determine whether claims should be paid by or in conjunction with other insurers or organizations. Dependencies betw een claims and other records can then be combined to create cas es. Issues related to the design of the application are discussed, specifically the use of rule-based techniques which provide a capability for deeper analysis than traditionally found in statistical techniques. Information extraction, informa tion retrieval, categorization, pattern matching, other party liability indicators. Text mining is concerned with the detection of patterns in natural language texts, just as data mini ng is concerned with the detection of patterns in databases. Inform ation processing applications can benefit from having access to both structured information, as found in databases, along with unstructured information, traditionally found in documents or unstructured text fields within databases. When accessing this textual information, applications can also benefit from a more detailed linguistic analysis of the text, as opposed to a shallower  X  X  ord based X  analysis. There are a wide range of techniques that can be applied to analyzing these natural language texts, as reflected in the considerable amount of research in the field of natural language processing [5]. As noted in [9], document categorization is one of the most popular applications of text mining. In this paper, we consider the analysis of textual information and categorization in the context context, the textual information is dominated by descriptions entered by call centre operators, and by comments associated with individual claims and/or cases. Th e texts that are encountered are highly constrained with respect to their semantics. These texts treatment and diagnosis taxonomies. 1 The texts themselves may be highly fragmented and ma y make use of numerous abbreviations and acronyms. As a result of the constrained nature of the textual information, we are able to leverage the information contained in standard treatme nt and diagnosis taxonomies, together with concept taxonomies specific to other-party-liability and to fraud-and-abuse, to provide indicators that can be combined with structured inform ation associated with insurance claims to obtain more effective identification of claims involving third party liability, subrogation, or fraud and abuse. The process of automated medical claims auditing is outlined in Figure 1. It illustrates how the output of a natural language processing system, which perform s detailed linguistic analysis using domain specific informati on in the form of Concept Taxonomies, is then used by a mining system to produce output which is then subjected to human analysis. The disease and treatment taxonomies are discussed in [10]. Medical-Claims Call-Center-Logs Notes We start, in section 2, by pr oviding an introduction to NLP and outline the NLP techniques that we w ill be using. In section 3, we then introduce a specific applica tion in the area of health care claims processing, and we see how the NLP techniques can be used to identify indicators of claims that may require detailed human investigation. In secti on 4, we look at how the concept taxonomies required for the claims processing system can be developed. Then in section 5 we examine how these indicators can be used by text and data mi ning techniques to detect patterns in claims, and score individual claims. Natural language processing (NLP) deals with the automatic processing and analysis of unstruc tured textual information. One direction of NLP research re lies on statistical techniques, typically involving the processing of words found in texts [7]. Another approach makes use of ru le based techniques, leveraging knowledge resources such as ontologies, taxonomies, and linguistic rule bases. Statis tical human language processing systems require collections of tr aining material which exemplify the desirable (and/or undesirable) relationships and dependencies. Subsequent modification of the sy stem then requires some degree of retraining of the system. Instead of requiring training material, rule based techniques require know ledge in the form of on-line dictionaries, established linguistic theories, and they are able to leverage existing classification systems or taxonomic frameworks. NLP applications may make use of either or both of these techniques, and the decision of wh ich technique to use is often dependent on the availability of training materials, external resources, and the actual text analysis tasks required in the resulting application. The Axonwave Content Intelligence System (CIS) contains core natural language processing system s that perform both rule-based and statistic-based NLP. The CIS is able to leverage existing knowledge sources, plus provide th e capability for ordinary users to tailor or customize the knowledge base with concepts that are of interest to them. The general architecture of the system is shown in Figure 2. The system makes use of a statistical tagger, rule-based partial parser, together with extern al resources including Wordnet [8]. The tagger and partial parser are r obust, and able to deal with the often ungrammatical text found in call logs, which contains numerous instances of abbreviations and acronyms 3 , as well as the more polished text found in medi cal services plan documents. The partial parser provides more information than just tagged words. It provides proper name id entification, plus it determines the arguments and modifiers of relationships and entities found in a document (as appropriate). 4 The core technology concerns the matching of  X  X oncepts X  which are represented in a Concept Specification Language (CSL). CSL is used to specify rich linguistic patterns that incorporate as fundamental the notion of recursion (embedding) of patterns and various linguistic predicates. CSL and concept matching are embodied in the CIS, which analyzes the structure of words, phrases and sentences (making use of general purpose linguistic ru les and dictionaries). The first stage of analysis consists of abbreviation expansion and spelling correction, which is then followed by tagging and then partial parsing [1]. Specific information can then be extracted according to rules and concepts formulated with CSL which is organized within various taxonomies. CSL allows the definition of key concepts or terms; and the speci fication of the interrelationship among concepts in the form of multiple operators, such as OR, NOT, Precedes, Immediately Precedes, Is Related, or Causes; and also the formulation of advanced categories for concepts, such as whether a concept is a word, has synonyms, is a general or a specific term, etc. To illustrate CSL, let us consid er the definition of a concept which we will call AccidentsAndT rauma, which is intended to match a wide range of descriptions of different kinds of accidents or trauma that might be encountered in documents supporting One of the key challenges when using a resource like Wordnet, is to prevent overgeneration associated with inappropriate word senses and their associated synony ms. This issue is addressed in detail in [12], where there is a discussion on how Wordnet can be pruned for specific domains. The text analysis engine was originally designed to deal with poorly structured English containing numerous acronyms and abbreviations, like the text found in aviation safety reports [2]. 
Our approach has been to avoid  X  X leaning X  the data, but instead providing the modules with enough knowledge so that they can deal with  X  X irty X  data. For example, given a data collection, we perform a statistical analysis of the different abbreviations and acronyms encountered in a collection, and provide an appropriate semantics for these tokens. Some issues concerning acronyms are discussed in [13]. As expected, the performance of the tagger can be improved by providing training data specific to the targeted domain and style of text. medical insurance claims. In Fi gure 3 below, we define this concept as a disjunction of subconcepts. concept AccidentsAndTrauma ( %Trauma | %AccidentalFall | %Accident-Sports | %Accident-Involving-Children | %Accident-Auto ) Each of the subconcepts will have its own definition, resulting in a rich hierarchical taxonomy of concepts (Figure 4). Specifically, a concept like AccidentalFall includes a subconcept FallFromDifferentLevel. The categories are not necessarily mutually exclusive. So for an accident taxonomy, an excerpt of which is provided in Figure 4, a given incident could be an accidental fall, and an accident involving children. The CSL for this final concept is gi ven in Figure 5. Note that this concept contains individual word s, (specifically  X  X ff X ,  X  X  X rom X ,  X  X o X  and  X  X eet X ), which will match text that is linguistically linked (in this case,  X  X elated X ) to a word or phrase that matches the SlippedOrFell concept. Altern atively, it will match a phrase in which a SlippedOrFell phrase is followed by the word  X  X own X  which is then followed somewhere later by a NOUN. concept FallFromDifferentLevel( Related( | (%SlippedOrFell &amp; down &amp; /NOUN ) This concept will match phrases su ch as  X  X ell 15 ft X  or  X  X ell down FallFromDifferentLevel. Note that there is no need to specify all the abbreviations for a word in the CSL, nor is it necessary to specify all of the synonyms. The CIS engine can automatically handle the different variations of a word. Once the text is tagged, subsequent mining phase. CSL can be viewed in some respects as a linguistic programming language, and from this perspective, it is similar to the declarative information analysis language (DIAL) described in [11] and used by Clearforest in their text mining applications. DIAL is presented as a rule-based info rmation extraction language where  X  X he pattern matching elements ar e either explicit strings found in the text (such as the word expression), a word class (a specific set of lexical terms), or another ru le X  [11, p. 848]. However, CSL provides a richer selection of matching elements, taking into account syntactic and semantic primitives. Furthermore, as will be seen in section 4, we can also use natural language processing techniques to assist in the creation of CSL. When a medical insurer is presented with a claim for a treatment in response to diagnosis, there is a large amount of information descriptions contained in the clai m itself. Consider the situation where a patient is treated in the emergency room of hospital for a broken arm, which requires an initial examination, an x-ray, and the application of a cast. There will be charges associated with each of these aspects of the clai m (also known as a line item), and there might very well be textual comments associated with line items, and in supporting documents. For example, there might be a note saying  X  X atnt fell off desk while chnging light bulb at work X , which could contain a bbreviations, acronyms, and might even be ungrammatical. This information could provide evidence that the claim should be subject to workman X  X  compensation rules, rather than being treated as a claim to be covered only by the insurance plan. So, what kind of textual indicators are important when determining whether other parties should be partially responsible for covering the costs of claims? They are indicators which suggest that a claim falls into one of the following categories. Based on the rules that are used by claims examiners, we were able to construct a taxonomy of indicators that play a role in determining likelihood of one of these categories. The medical claims taxonomy contains approximately 3000 nodes and averages five levels deep. Associated with each of these indicators is a CSL specification that makes use of domain independent entities and relationships, combined with domain specific terminology. The image in Figure 6 shows a collection of indicators extracted from medical call center notes. 5 The first note in Figure 6 shows two matches: one for the Trau ma indicator, which matches  X  X njury X , and one for the Accide nt-Auto indicator, which matches Information in all images has been altered to protect the privacy of the individuals involved with the claims. Trauma Accidental  X  X ell off his motorcycle X . The second and third note both contain evidence of a WorkersCompensati on indicator, while the last note contains several indicators, one of which is SlipAndFall, which matches the text  X  X lipped on the ice. X  By using CSL to describe text i ndicative of given concept, we are able to take into account the high degree of variation encountered in the English text used to desc ribe different circumstances and events. Specifically, one can specify entire classes of words, based on part-of-speech or based on meaning, rather than simple lists of words or strings. Additi onally, one can specify constraints based on linguistic syntactic re lationship (modifies) or even semantic relationships (cause/effect), rather than a simple proximity measure. Since we are working in a highly constrained domain, it is possible to achieve very high levels of accuracy. Precision and recall measures are calculated on a regular basis for a selection of the thousands of indicators that are extracted from documents. Precision is calculated on a ra ndom selection of 100 matches taken from a corpus of customer se rvice logs, and text fields from medical claims and management notes. For the Commercial and Medical Coordination of Benefits indicators mentioned earlier in this section, the average precision is 99%. Not all indicators are so accurate, though. The precision of the indicator for determining that a child is covered under more than one plan (Multiple Plan Child Coverage) is only 84%. The recall for an indicator is determined through a test pro cedure where a human evaluates documents containing regions of text that should match an indicator. They run the system on these documents to determine what percentage of these matches are found by the system. For Coordination of Benefits, the recall averages 85%, with the Multiple Plan Child Coverage indicator obtaining a recall of 81%. The next step of the process is to use these indicators to determine which claims require further hum an investigation, and whether some claims can be combined together with supplemental information to form an actual case to be assigned to a human analyst. We achieve this by a pplying text-mining techniques to claims and documents annotated with indicators, rather than applying the techniques to just the original documents. At this time, we also leverage the struct ured information contained within the claims, such as the dollar value of the claim, claimant, zip-code, date, and so on. So, we are effectively performing traditional data mining on the structured information, which is augmented with the indicators extracted from unstructured text. We can perform clustering, clique analysis, outlier analysis, and many other techniques. However, given that the focus of the current paper is on natural langua ge processing and unstructured text, in section 5 we will focus on the techniques that concentrate on the use of the indicators identified by the CIS engine. First, we will look in detail at how CSL can be created using natural language processing techniques. While it is possible to create very complex and accurate specifications using CSL, this can be a very time consuming task, Furthermore, it may require both linguistic expertise, and domain expertise. To facilitate this task , we can leverage the linguistic and domain expertise contained w ithin the linguistic rules and knowledge base of a natural language processing system to assist in the creation of new CSL. So, we can boot-strap from an existing system to create a new system that has a richer knowledge base using what we will call text-based concept creation, allowing a user to cr eate CSL without any knowledge of CSL. The text-based concept creation algorithm consists of the following eight steps. An example that illustrates each of these steps is then provided in Figure 8. 1. Input of text fragments . The user is prompted for one or 2. Fragments split into words . The fragments are split into 3. Selection of relevant words . The user selects relevant words 4. Optional operations on relevant words . For any selected 5. Concept matching . A predefined set of Concepts from the 6. Removal of Concept matches . Certain Concept matches are 7. Building of Concept chains (tiling ). A list of  X  X hains X  is 8. Chains written as CSL Concept . Every chain that passed The Rule Base contains domain independent concept definitions, along with rules that transform general Concepts that matched the text fragments into Concepts of the resulting Concept. As an example of a rule, consider  X  X ubj_Passive_Verb_Obj =&gt; Subj_Verb_Obj X . This rule states that if a text fragment contains a construct that matches the S ubj_Passive_Verb_Obj Concept, then the resulting Concept should contain a slightly more general Concept Call Subj_Verb_Obj.
 The Concept creation process ensures that only the Concepts that cover the selected relevant key words are considered. In cases where there is more than one Concept covering the input fragment, it uses the tiling algorithm (from step 7 of the earlier ten-step algorithm) to pick the most important Concepts. The ranking of the different possible C oncept chains is determined by the order of the concept definitions contained in the Rule Base. Consider the example shown in Fi gure 8. For the first 4 steps of the process, the user is required to provide inputs to guide the creation of the CSL. Note that the user is not required to have any knowledge of the syntax of CSL. The user needs only domain knowledge, plus basic knowledge of language. The algorithm determines in step 5 that seve ral concepts match the input, and that both are potentially relevant (since they all contain the key words). Three of these matching c oncepts are shown in Figure 8, and assuming that the user does not remove any of these selections, the tiling algorithm finds one chain that spans the input. It then generates the Adora tion concept, (where the name of the concept can be supplied by the user). } By themselves, the textual indicators that are identified or extracted from the documents based on CSL specifications do not have any real value. The value lies in the patterns or relationships between the indicators that are not only valid, but also interesting (with respect to some user-defined measure of what is interesting) [6]. Given that there are already well established human procedures to determine whether an insurance claim is interesting (with respect to reimbursement [4]), we can encode this human knowledge, and use it as a starting point for a scheme for scoring and ranking medical claims, base d on a selection of indicators derived from structured inform ation, and from unstructured information. For each of the high level indicators, rules are defined with initial weights specified by human expert s. As reflected in Figure 7, these initial weights contain references to not only structured information (like dollar value, and diagnosis code), but also unstructured information, incl uding diagnosis and treatment indicators extracted from call logs and notes. These initial rules can also take into account conflicts between the structured and unstructured information. For ex ample, structured data-field stating that the claim was not a work-related injury may conflict with a call log entry for the same claim which stipulates with a high certainty that it was a work place injury. Depending on the dollar value of the claim, or perhaps the claim history of a patient, a provider, and a health services organization, such a conflict may be sufficient to categorize a claim as one which requires human investigation. Due to the hierarchical nature of the different indicators and subindicators, one can also estab lish relationships between closely related indicators in circumstances where there might be sufficient evidence from any one indicator. Consider the case where a patient has one claim for an injury resulting from generalizing over the different types of accidents, the data may call for further investigation into this individual, and could create a  X  X ase X  resulting from the data accumulated in several claims, over even the creation of a case before a claim has been submitted into the system. The result of this evaluation proce ss is a prioritized list of medical claims, as shown in Figure 9, where the score (Scr) is the value calculated from the different indicators. The score is an integer concerning how the score was calculated (s)he need only click on the score contained on the summary page shown below. Finally, since a health care claims auditing system is a system which involves a human in the investigation of the resulting claims and cases, it is possible, over time, to build up a rich corpus of what constitutes an interesting (or uninteresting) claim, along with a wide range of associat ed indicators. With this data, it is possible to automatically change the weights associated with the different indicators, or even introduce new indicators into the equation. In developing a health care claims auditor, we have created a system that combines both text mining and NLP, and we have illustrated one way to  X  X ridge th e gap X  between NLP and text mining. Using an NLP Concept Matcher, we obtain the capability to enrich text with semantic tags in a manner than can deal with spelling errors, abbreviations, acronyms, and the different variations in phasing that are used to express a concept. The Concept Matcher effectively provides the means to normalize the unstructured textual data into standard tags which can be extracted and feed into different data or text mining algorithms. It uses not only part of speech information, but also a syntactic parser, a rich lexicon, and a great deal of domain knowledge embodied on concept taxonomies. The system is successful largely due to the constrained nature of the semantic domain. Because the system only deals with diseases, treatments, and medical insurance claim categorization, it is feasible to create a rela tively complete knowledge model, leveraging existing taxonomies for diseases and treatments. We have seen techniques to semi-automatically create the CSL used in knowledge models. These techni ques are applicable not only to health care claims auditing systems, but any system in which there is linguistic knowledge and domain specific semantic knowledge. What we have seen is that it is possible to gain high value by using NLP techniques to map di fferent sequences of natural language text to a relatively small number of high level indicators. The frequency, distribution and co-occurrence of these indicators form patterns a nd provide scores for claims, which can then be used to prioritize claims for human investigation, and create cases consisting of the claims and the relevant supporting information. In the future, when more indicator-enhanced claim data becomes available, it will be possible to apply additional data-mining techniques [3] to detect previously unknown patterns. Of particular interest will be the us e of association rules for fraud and abuse detection. Thanks to all the staff at Axonw ave Software who have devoted years to the development of the algorithms and the infrastructure needed to support the work describe d in this paper. Special thanks go to Julia Birke and Lorna Fadden for their work on developing and integrating the concept ta xonomies, and Dan Fass for his formalization and description of the algorithm introduced in section 4. [1] Abney, S. Part-of-Speech Tagging and Partial Parsing. In [2] Dilkina, K., and Popowich, F. An algorithm for anaphora [3] Han, J., and Kamber, M. Da ta Mining: Concepts and [4] Jones, L.M. (ed). Reimbur sement Methodologies for [5] Jurafsky, D., and Martin, J. Speech and Language [6] Lavrac, N. and Grobelnik, M. Data Mining. In Mladenic, D., [7] Manning, C. and Schutze, H. Foundations of Statistical [8] Miller, G.A., Beckwith, R., Fellbaum, C., Gross, D., [9] Mladenic, D. and Grobelnik, M. Text and Web Mining. In [10] Popowich, F. Use of Text Analytics and Taxonomies for [11] Shatkay, H. and Feldman, R. Mining the Biomedical [12] Turcato, D., Popowich, F. Toole, J. Fass, D. Nicholson, D. [13] Zahariev, M. A linguistic approach to extracting acronym Dr. Fred Popowich is a Professor of Computing Science at Simon Fraser University, and an Associate Member of the Department of Linguistics. His non-academic roles include President and Chief Technology Officer of Axonwave Software, and chair of the Canadian Language Technology Roadmap Committee. He received his Ph.D. in Cognitive Science from the University of Edinburgh in 1989. Over the course of his twenty-year research career he has produced over fifty refereed publications. He and his colleagues jointly founded A xonwave Software in 1999, and have developed technologies for sophisticated classification, filtering, monitoring and retrieva l of unstructured information, using natural language processi ng techniques, to produce claim recovery and cost containment software solutions for the health care industry. 
