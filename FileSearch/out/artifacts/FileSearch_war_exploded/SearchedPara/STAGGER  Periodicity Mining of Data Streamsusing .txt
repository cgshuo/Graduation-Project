
Keywords: IVlining data streams, Periodicity mining
Data streams consist of continuous and time sensitive data. Periodicity mining is a tool that helps in predicting the behavior of data streams. For example, periodicity mining allows a telephone company to analyze telephone calling patterns and predict periods of high and Imv usage so that proper planning may take place. In this paper, we address the problem of mining such periodic patterns over data streams. We define periodicity mining as the detection of frequent periodic patterns where the periodicity rate (period length) is also unknown. Therefore, the first step, termed Periodicity Detection, is to discover potential periodicity rates. The second step, termed Mining Periodic Patterns, is to detect the frequent periodic patterns of each discovered periodicity rate. vVhile this two-step process \vorks for traditional time series data [32, 25], it does not apply well to real-time data streams. Furthermore, data streams are potentially infinite and therefore require online and incremental processing. Recently, Papadimitriou et a!. [29] have addressed the problem of periodicity detection (the first step, above) in data streams using \A/avelets. In this paper, we propose a complete solution to the periodicity mining problem in data streams, which combines both periodicity detection and mining periodic patterns in a one-pass algorithm. l\loreover, in contrast to the techniques proposed in this paper, the vVavelet-based approaches are approximate. The experiments demonstrate that the quality of the proposed techniques are i::iuperior in terms of the accuracy of the discovered periodicity rates. gered over the data stream. Using a convolution-based algorithm [14, 15], a sliding window! of length w can discover period lengths up to w /2. 'Whereas a small window length is re-quired for early and real-time output, it limits the period lengths that can be discovered.
Therefore, \ve propose STAGGER, a new algorithm that uses the algorithm in [14] as a build-ing block. STAGGER allows multiple small sliding windows to expand in length to cover the whole data stream, i.e., STAGGER staggers the stream with multiple and concurrent expanding sliding \vindows. Computations are shared among the multiple overlapping win-dows. Thus, STAGGER is able to produce interactive output as well as to discover a wide range of potential period lengths. Subsequently, we maintain a max-subpattern tree [19] for each potential period length, which discovers the periodic patterns for that length. \Ve propose an approximate incremental technique for building and maintaining max-subpattern trees.
 ditional data mining techniques employ a single frequency threshold value. A pattern is reported as frequent only if its frequency is above that threshold. When data arrives contin-uously, a pattern may oscillate between being frequent and being infrequent. IVlaintaining a data structure for frequent patterns, e.g., the max-subpattern tree, such an oscillating pat-tern loses its history information every time it becomes infrequent. When it becomes frequent again, the pattern's history has already gone without being stored. Losing a pattern's his-tory deteriorates the accuracy of one-pass online stream mining algorithms. A naIve solution is to keep all patterns' histories even for those patterns that become infrequent. However, this solution requires an excessive amount of storage. \Ve propose a new approach, termed "hysteresis;; thresholding, that maintains two thresholds. A pattern is considered frequent if its frequency is above the higher threshold value, and is considered infrequent if its frequency is below the lower threshold value. The distance between the two threshold values acts as a period of time during which a pattern is given a chance to stabilize rather than to oscillate.
As we demonstrate on the experimental section, the proposed "hysteresis" thresholding ap-proach shows significant performance improvement over that of the traditional thresholding approach.
 introduce the notation used throughout the paper. We outline STAGGER in Section 2. In
Section 3, ,ve present the proposed technique for online periodicity detection. In Section 4, we present the proposed technique for incremental mining of periodic patterns. In Section 5, we evaluate the performance of STAGGER, and compare it to other approaches using both synthetic and real data. A discussion of the related work is given in Section 6, and we conclude the paper in Section 7.
A data stream of events is an infinite sequence of timestamped events drawn from a finite set of nomina1 2 event types. An example is an event stream in a computer network that monitors the various events. Let ei be the event occurring at timestamp i, then the data stream S is represented as S = eo, el, ... , ei, .. .. Each event type can be denoted by a symbol (e.g., a, b, c). The set of event types can be denoted 2:: = {a, b, c, ... }. Thus, the data stream Scan be considered a sequence of infinite length over a finite alphabet 2::.
 sensor measuring a specific feature. For example, the feature in a data stream for stock prices might be the final daily stock price of a specific company. If we discretize 3 the data stream feature values into nominal discrete levels and denote each level (e.g., high, medium, low) by a symbol (e.g., a, b, c), then we can use the same notation above.
In this section, we outline STAGGER algorithmic behavior. The input is a data stream for which we output its periodic patterns. 'vVe are given a periodicity threshold (or two periodicity thresholds if the "hysteresis" thresholding approach is used). Arbitrarily, we select m different windows of lengths WI &lt; U'2 &lt; ... &lt; large as the buffer size that is allocated for buffering the data stream. STAGGER maintains an event-based priority queue where an event is triggered by the arrival of new data in the stream. The events in the priority queue are sorted in increasing order of their timestamps.
Periodicity detection, in our terms, stands for discovering potential rates at which the data stream is periodic. For example, a data stream of the closing price of a specific stock may have a periodicity rate of 7 that describes its weekly periodic pattern. A periodic pattern describes the periodic behavior at, not necessarily all, the points in the period. For example, the closing price of a specific stock may be high every Friday and low every Tuesday, yet may not have any regularity on t he other week days. That description of periodic patterns implies that the technique devised for periodicity detection should consider symbol periodicities.
Recall that a symbol may represent an event in an event data stream or a nominal discrete level in a discretized real-ndued data stream.
In a data stream 5, a symbol s is said to be periodic with a period of length "almost" every p timestamps. For example, in the data stream 5 b is periodic ,vith a period of length 4 since b exists every four timestamps (positions 1, 5 and 9). l\loreoveL the symbol a is periodic with a period of length 3 since a exists almost every three timestamps (positions 0, 3, and 6 but not 9). Let of a data stream 5 according to a period p starting from position where 0 :::; 1 &lt; p, m = f(n -l)/p l, and n is the length of 5. For example. if 5 then 7f4.1(5) = bbb, and 7f3,o(5) = aaab. Intuitively, the ratio of the number of occurrences of a symbol s in a certain projection 7f often this symbol occurs every p timestamps. This ratio, however, is not quite accurate since it captures all the occurrences including the outliers. In the example above, 7f3.o(5) implies that the symbol b is periodic with a period of length 3 with a frequency of 1/4, which is not quite true. As another example, if for a certain 5, changes every p timestamps and hence no symbol should be considered periodic ,vith a period of length p. vVe remedy this problem by considering only the consecutive occurrences. A consecutive occurrence of a symbol s in a certain projection s has reappeared in 5 after p timestamps from the previous appearance. Let F the number of times the symbol s occurs in two consecutive positions in the data stream 5.
For example, if 5 = abbaaabaa, then F 2 (a, 5) = 3 and F 2 of the number of consecutive occurrences of a symbol s in a certain projection the length of this proJ' ection (h(s,"lrp,/(S))) indicates how often the symbol s occurs every timestamps in a data stream 5.
 Definition 1 If a data stream 5 of length n contains a symbol
O l d .:F2(S,"lrp./(S)) period of length p at position 1 with respect to periodicity threshold
For example, in the data stream 5 = abcabbabdb, .:F2i\ao/~i~~)) is periodic with a period of length 3 at position 0 with respect to a periodicity threshold respect to a periodicity threshold T periodic symbols and their corresponding periods, but also it locates their corresponding positions. In other words, each symbol that exhibits periodicity according to Definition 1 produces a frequent single-symbol periodic pattern.

Definition 2 In a data stream S of a finite alphabet 2::, a pattern of length p is a sequence q = qo X  X  X  qp-l, such that q; ~ 2::.

Definition 3 If a data stream S of length n contains a symbol s that is periodic with a period of length p at position I, then a frequent single-symbol periodic pattern q of length p zs formed by setting all q;'s to the empty set except for q, that is set to {s}.
For example, in the data stream S = abcabbabdb, for a periodicity threshold that is less than 2/3, the pattern 4 a * * is a frequent single-symbol periodic pattern of length 3, and so is the single-symbol periodic pattern *b*.
 form a maximal periodic pattern that is the root node of the max-subpattern tree of the corresponding period length.
 potential period lengths and all the corresponding frequent single-symbol periodic patterns in one pass over the data stream. At the core of STAGGER is a symbol periodicity detection algorithm [14], called SPD, that deals with data stream portions (windows) of known lengths.
We present the SPD algorithm (Section 3.2) partly to render this paper self-contained, but also to facilitate introducing the multiple sliding windows online incremental technique for infinite data streams (Section 3.3).
Assume that the period length p is known for some symbols of a specific portion, say 5, of a data stream. Then, the problem is reduced to mining 5 for the frequent single-symbol periodic patterns of period length p. In other words, the problem is to detect the symbols that are periodic with period length p within 5. A way to solve this simpler problem is to shift 5 by p positions, denoted as 5(p), and then compare 5 = abcabbabcb, then shifting 5 three positions results in 5(3) 5 to 5(3) results in four symbol matches. If the symbols are mapped in a particular \vay, we can deduce that these four matches are actually two for the symbol a and two for the symbol b.
 length data stream portions. The first idea is to use the concept of convolution in order to shift and compare the data stream portion for all possible values at once. The second idea is to obtain a mapping scheme for the symbols, which reveals, upon comparison, the identity of 'which symbols that match and their corresponding positions. The remaining part of this section describes these ideas in detail. The convolution is covered in Section 3.2.1 while the mapping scheme is covered in Section 3.2.2. 3.2.1 Convolution
A convolution [11] is defined as follows. Let X = [xo, Xl, X  X  X , X be two finite length sequences of numbers 5 , each of length n. The convolution of X and Y is defined as another finite length sequence X  X  Y of length n such that for i = 0,1, ... , n -1. Let X' = [x~, x~, ... ,X~_l] denote the reverse of the vector X, i.e., x~ = X n -1-i' Taking the convolution of XI and Y, and obtaining its reverse leads to the following:
In other words, the component of the resulting sequence at position one of the input sequences i positions and comparing it to the other input sequence. (based on the mapping scheme 1&gt; described in Section 3.2.2), (ii) Perform the convolution between the two sequences 1&gt;(5)' X 1&gt;(5), and (iii) Reverse the output (1)(5)'  X 1&gt;(5))/. The component values of the resulting sequence correspond to shifting and comparing the data stream portion for all possible values.
 as follows:
This computation reduces the time complexity of the convolution to O(nlogn). The brute-force approach of shifting and comparing the data stream portion for all possible values has the time complexity 0(71 2 ). 3.2.2 Mapping Scheme
Let 5 = eo, el, ... ,en-l be a data stream portion of length a finite alphabet I: of size 0". Let 1&gt; be a mapping for the symbols of 5 such that 1&gt;(5)
C(5). The mapping scheme ofthe SPD algorithm satisfies two conditions: (i) \iVhile matched symbols contribute a non-zero value in the product 1&gt;( c contribute 0, and (ii) the value of each component of C(5), c;(5) identifies the matched symbols and their corresponding positions. of 2. For example, if a data stream contains only the 3 symbols a, b, and c, then a possible mapping would be a : 001, b : 010, and c : 100, \vhich correspond to power values of 0, 1, and 2, respectively. Hence, a data stream portion of length n is converted to a binary vector of length ern. For example, let 5 = acccabb, then 5 is converted to the binary vector
S = 001100100100001010010. Using convolution results in a sequence C(S) of length
Considering just the n positions 0, (J, 2(J, ... , (n -1)(J that are the exact start positions of the symbols, gives back the sequence C(5). The latter derivation of C(5) can be written as C (5) = 7f a.O (C (S)) using the notation defined in Section 3.1.
 Notice that this definition still preserves that The reason for adding the coefficient 2) is to get a different contribution for each match.
For example, Figure 2 illustrates an example where 5 = acccabb. The powers of 2 in the value of Cl (5) are 1. 11, and 14. Examining those powers modulo 3, which is the size of the alphabet in this particular example, results in 1, 2 and 2, respectively, which correspond to the symbols b, c, and c, respectively.
 corresponds to the symbol a since 6 mod 3 = 0 and a was originally mapped to the binary representation of 2 X . This means that comparing 5 to 5(4) the symbol a. l'vloreover, the power value of 6 reveals that the symbol a is at position 0 in
S(4). Therefore, the power values reveal not only the number of matches of each symbol at each period, but also the corresponding starting positions. This latter observation complies with the definition of symbol periodicity. Hereby, we direct the reader to [14] for a complete discussion of that algorithm.
The idea of STAGGER is to perform the SPD algorithm incrementally on multiple sliding windows of expanding lengths. Sliding a window implies discarding an earlier portion of the data stream and considering a more recent portion. After sliding a window, the results are carried from the previous step to the current one. The SPD algorithm is performed only over the recent portion of the data stream without losing any information about the discarded portion. l\Ioreover, the results are shared among the multiple windows in order to avoid recomputing what has been computed earlier. (Section 3.3.1). Then, we justify the need for multiple sliding windows, and show how the results are shared among them (Section 3.3.2). 3.3.1 Single Sliding-Window
Let S = eo, el, ... be an infinite length data stream, where e/s are symbols from a finite alphabet I: of size 0". Consider a window of length w, and let Si,1O denote the portion of the data stream S that is of length wand starts at position i. Performing the SPD algorithm over the very first window SO,1o discovers all potential periods of values that range from 1 to w/2. Clearly, periods larger than w /2 are not significant in a data stream window of length w.
Therefore, we focus on the values Ci(SO.1O) for i = 1,2, ... , w/2 in the sequence C(So,w)' As mentioned earlier, these values correspond to comparing SO,w to its shifted versions i = 1,2, ... ,w/2. Let the window slide z ~ w positions such that the current portion of the data stream is Sz,w. The SPD algorithm executes over Sz,w and the results from the previous and the current portions should be combined. \Ve observe that if z would be missed. For example, if S = eO,el, ... and w = 6, then C3(SO,w) corresponds to comparing 5 0 "" = eo, ej, ,e5 to 5~3l = * * *eo, el. e2' For z comparing 5 z ,u' = e4, e5,' eg to 5i~{u = * * *e4, e5, eG X  Although comparing e6 to e3 should be part of comparing the entire data stream 5 = eo, el, ... is not included in either c3(5 0 ,1O) or c3(5 z ,w). Hence, we can deduce that a window of length 70 should not slide more than 70/2 positions in order not to lose any comparison information . .lvloreover, using the same example, we observe that the lower the value of z is, the more overlap we get in symbol comparisons. Consequently, we choose to slide a window of length 70 a number of positions equal to 70/2, as illustrated in Figure 1(a).
 perform the shift and compare operations all at once. In such terms, we can define the combined values for the entire data stream, which has arrived so far, as follows:
At every stage of sliding the window with 70/2 positions, the previous values are shifted to the left and are added to the new values. Since we deal with powers of 2, shifting w/2 positions to the left before the addition operation ensures that every single match has a different power of 2 in the total sum. Hence, we are able to take care of the overlap and discard any overlapped values. Note that in the previous equations, i ranges up to only
CJW -1 even when the data stream has been extended in length. In other words, only the first 70 components of the sequence C(5 0 ,w+kw/2) are computed. 3.3.2 Multiple Sliding-Windows
After sliding a single window k times, the entire data stream has become of length 70
However, we are still limited to potential period lengths up to 70/2. Even if we consider period length values larger than 70/2, we are bounded by 70 as the maximum period length to be discovered. Thus, the smaller the length of the window, the more potential periods that are missed. On the other hand, the larger the length of the window is, the more time the algorithm waits until it produces interactive output.
 of different expanding lengths that are staggered over the data stream. The computations are shared among the multiple windows in a way similar to that of sliding a single window. Assume that we have two windows of lengths WI &lt; W2, and that all the first of the sequence C(SO,Wl) are computed. Only the first wI/2 components are of particular interest to discover the potential period lengths up to wI/2. We are now interested in the first W2 components of the sequence C(SO,W2). \N'e observe that the components that lie between wI/2 and W2 are the only ones to be computed for the window components are updated in the next sliding of the window WI.
 W2, we combine the results of the components between wl/2 and components between WI and W2.
 This process is carried out between each two consecutive windows selection of W m is bounded by the buffer size allowed by the system for buffering the data stream. Therefore, w m /2 is the maximum period length value that we can discover.
The max-subpattern tree [19] has proved to be efficient in mining periodic patterns in time series data. Han et al. [19] have presented a two-pass algorithm for building such a tree. Aref et al. [7] have presented an incremental version of the algorithm that maintains the max-sub pattern tree during continuously arriving data. However, the algorithm in [7] requires two passes over the new data and a possible reprocessing of the previously seen data. In this section, we propose a new incremental technique that fits the data stream model. Data is not stored and hence a reprocessing of the previously seen data is not possible. The produced results are approximate compared to the exact results produced by the two-pass algorithms [19, 7]. Yet, this approximation is unavoidable and is empirically reasonable as the accuracy exceeds 90%.
 duce how STAGGER maintains the max-subpattern tree incrementally over a data stream (Section 4.2). Subsequently, we introduce the "hysteresis" approach for maintaining the periodicity thresholds over the data stream (Section 4.3).
Figure 3 gives an example of a max-subpattern tree built with a period of length 4. Every node represents a candidate periodic pattern and has a count that reflects X  the number of occurrences of this pattern in the data. Recall that, according to Definition 2, a pattern is a sequence of subsets over the entire alphabet. A node is a parent to another if the pattern of the latter node is a subpattern of the pattern of the former node. A pattern q' is called a subpattern of another pattern q if for each position i, paTent node and a child node is labeled by the difference between their two patterns. Notice that a pattern may be a subpattern of more than one pattern. Therefore, the data structure is actually a graph rather than a tree. In order to preserve the data structure as a tree and decrease the complexity of insertion and search, not all the parent-child links are kept. The dotted lines in Figure 3 represent those links that are not kept.
 pattern that all the other candidate periodic patterns are subpatterns of. Hence, the root node pattern is called the maximal periodic pattern Q. The algorithm of [19] determines Q by extracting all the single-symbol patterns of length p from a first pass over the data. The frequent single-symbol patterns are determined with respect to the periodicity threshold, and Q is computed by the union operation of all these frequent single-symbol patterns. For example, if the frequent single-symbol periodic patterns of length 4 are *b * *, *c * *, a * **, and * * d*, then Q = a{b, c}d*.
 filtered by the maximal periodic pattern, into the max-subpattern tree. Once it is built, the max-subpattern tree is traversed in order to detect those actual frequent periodic patterns with respect to the periodicity threshold. Note that the count of every pattern is actually the count of its corresponding node plus all the counts of its parent nodes (both the direct parent and the other hidden parents).
 technique (Section 3) reveals not only the potential period lengths but also their single-symbol periodic patterns that form their corresponding maximal periodic patterns.
The idea of our proposed technique for mining periodic patterns in data streams is to main-tain the max-subpattern tree over the continuous arrival of new data. The arrival of new data may update the maximal periodic pattern Q due to the discovered single-symbol peri-odic patterns. Accordingly, the max-subpattern tree should be updated. Let Q and Q' be the maximal periodic patterns before and after the update, respectively. Let the components at position j of Q and Q', respectively. If cj implies deletion and/or insertion of one or more symbols. For example, if Q
Q' = a{b, e}df, then updating Q to Q' implies deleting the symbol c from position 2, and inserting the symbols e and f at positions 2 and 4, respectively.
 an insertion step. Let Qt be the pattern resulting from deleting the necessary symbols from Q, e.g., in the previous example, deleting the symbol c from position 2 results in Qt = abd*. If the original max-subpattern tree R contains a node representing the pattern Qt, then STAGGER converts that node to be the root of the updated max-subpattern tree.
Otherwise, STAGGER creates a new root node representing the pattern Qt. There are two aspects concerning that intermediate resulting tree. First, the counts must be fixed since some deleted nodes were parents to some retained nodes (e.g., in Figure 3, deleting the root node means a missing count of 10 for all its children nodes). Second, the non-linked children from R should be added. To consider both of these two aspects simultaneously, STAGGER scans the original max-subpattern tIee R and inserts R's patterns into the intermediate max-subpattern tree with their corresponding counts. For example, in Figure 3, where a{b,c}d*, assume that Q' = a{b,e}f, then Qt = abd*. The intermediate max-subpattern tree is given in Figure 4(30). Notice that, \'"ithout fixation, the intermediate max-subpattern tree would have had only two nodes: one for the pattern abd* with a count of 40, and one for the pattern ab * * with a count of 2.
 tree that represents the updated maximal periodic pattern Q'. Nevertheless, the updated max-subpattern tree is not accurate since it has no information about those inserted symbols.
In other words, the counts of the newly created nodes along the path from the new root to the old root are set to O. The only way to have their real counts is to reprocess the previous data, which is not possible. This is why STAGGER is considered an approximate algorithm. For example, Figure 4(b) shows the max-su bpattern tree updated from Figure 4( a) to have
QJ = a{b, e }df as its root node. Although the previously seen data might contain patterns that had the symbol f in position 4, the fact that this symbol was not frequent before had prohibited us from including any pattern containing this symbol in the max-subpattern tree. odic pattern, the newly arrived data patterns are inserted into the updated tree. Thus, the max-subpattern tree now represents approximately the whole data stream.
The proposed technique, as well as any traditional data mining technique, handles the pat-terns as follo X ws. As long as a pattern, say q, is not frequent, q is not included in the max-subpattern tree. As soon as q becomes frequent, it is added to the max-subpattern tree, and its history starts. As long as q is frequent, it is kept in the max-subpattern tree up-dating its history. As soon as q becomes infrequent, it is removed from the max-subpattern tree losing its history information. The frequency of the pattern is determined by a single threshold. This approach is illustrated in Figure 5(a). A disadvantage of this approach is that it fails to handle a pattern that oscillates between being frequent and being infrequent.
Such a pattern, say q, will lose all the history information (max-subpattern tree counts) as soon as it becomes infrequent. When q becomes frequent again, it will be treated as a newly appeared frequent pattern which has no history information.
 not remove an infrequent pattern from the max-subpattern tree as it may become frequent later. This approach, however, suffers the disadvantage that the max-subpattern tree will be huge and will contain several infrequent patterns, especially when a data stream has a rather lengthy transient component. Another approach is to have another max-subpattern tree for those patterns that are infrequent but are candidates to be frequent later. Those patterns are determined by a lower threshold value than the original one. Yet, this approach migrates the problem to that other max-subpattern tree, which will suffer the same disadvantage with a lower threshold value. represents the history dependence of physical systems 6 .
 thresholds, as illustrated in Figure 5(b). A pattern is considered frequent if its frequency is above the higher threshold value, and is considered infrequent if its frequency is below the lower threshold value. The distance between the two threshold values acts as a period of time during which a pattern is given a chance to stabilize rather than to oscillate.
This section contains the results of an experimental study that examines STAGGER for different aspects. In Section 5.1, experiments are conducted using synthetic data in order to examine the accuracy and the time performance of STAGGER. In Section 5.2, the practicality and usefulness of the output are explored using real data experiments.
 bution, period length, alphabet size, and noise amount. Both uniform and normal data distributions are considered. First, inerrant data is generated by repeating a partial pattern that is randomly generated from the specified data distribution. Then, noise is introduced randomly and uniformly over the whole data stream. Noise is introduced by altering a sym-bol by another, inserting a new symbol, or deleting the current symbol at a randomly selected position in the data stream. Unless stated otherwise, data streams lengths of lI'1l symbols are used with alphabet size of 10, and the values collected are averaged over 100 runs. With respect to the period lengths, we consider values that divide the whole data stream length as well as values that do not. We thus inspect STAGGER bias, if any, towards any particular set of period length values.
 streams that combines both periodicity detection and periodic patterns mining. Hence, there is no direct comparison between STAGGER and any of the algorithms in the litera-ture. However, we compare our periodicity detection technique to the periodicity detection algorithm, AWSOM [29]. AWSOM uses Wavelets to approximate data streams and hence discovers potential periodicity rates.
The first experiment studies the accuracy of the proposed incremental technique for mining periodic patterns. The fact that STAGGER is approximate in building the max-subpattern tree in one pass implies how the accuracy is measured. The approximate tree is compared to the accurate tree that is built offline in a two-pass algorithm [19]. The relative error of each node in the tree is computed and averaged over the total number of nodes in the tree. In Figure 6, we use the symbols "U" and "N" to denote the uniform and the normal distributions, respectively; and the symbol "P" to denote the embedded period length. window length increases the accuracy since the effect of transient frequent periodic patterns is reduced. Furthermore, as the stream data continuously arrives, the accuracy increases, as shown in Figure 6(b), since the data becomes progressively more stable. Therefore, the frequent periodic patterns are determined and the probability of adding new frequent periodic patterns is very low. Both Figures 6(a) and 6(b) show that STAGGER is highly accurate (in the 90% level).
 ing the distance between the two threshold values. A zero distance means only one threshold value, that is the traditional thresholding approach. Figure 6( c) shows that the "hysteresis" thresholding approach increases the accuracy of the approximate max-subpattern tree. As the distance between the two threshold v8lues increases, the accuracy increases since we allow more time for a pattern not to lose its history (max-subpattern tree counts). After some distance level, the accuracy does not increase more since the allowed time is more than enough for all patterns to keep their history.
 potential period lengths. The accuracy measure that we use is the ability of STAGGER to detect all the period lengths that were artificially embedded into the synthetic data. To discover a period length accurately, it is not enough to discover it at any periodicity thresh-old value. In other words, the period lengths discovered with a high periodicity threshold value are better candidates than those discovered with a lower periodicity threshold value.
Therefore, we define the confidence of a discovered period length to be the minimum period-icity threshold value required to detect this period length. The accuracy is measured by the average confidence of all the period lengths that are embedded artificially into the synthetic data. Figure 7 gives the results of this experiment. Recall that synthetic data is generated such that the embedded period lengths are: P, 2P, ....
 creases the accuracy since this allows the algorithm to detect more period lengths (of larger lengths). Subsequently, using a single sliding window of maximum buffer size, Figure 7(b) shows an unbiased behavior with respect to the embedded period length. Moreover, Fig-ure 7( c) shows that the accuracy does not rely on the number of expanding sliding windows as far as the largest sliding window is selected to be as large as the buffer size in order to de-tect all possible period lengths. Both Figures 7(b) and 7( c) show that STAGGER achieves an average of 80% accuracy, i.e., STAGGER detects all the artificially embedded period lengths at a periodicity threshold value of 80%.
 consider both the time performance and the accuracy of the discovered potential periodicity rates. AWSOM has two main limiting features. First, A\VSOrd discovers only periodicity rates of lengths that are powers of two. This limitation is due to the use of Wavelets to approximate the data stream. Periodicity rates of lengths that are not powers of two will be missed by AWSOM. The second limitation of AWSOt\l is that it discovers periodicities that are complete, e.g., full sinusoidal periods. If a period has only few periodic symbols,
AWSOM fails to discover such a period. On the other hand, STAGGER does not suffer either disadvantage as (i) it uses convolution to consider all possible period lengths, and (ii) it defines the periodicity in terms of its symbols. Figure 8(a) shows empirically this latter property. The experiment compares STAGGER to A\VSOM based on their ability to discover semi-full periods. The experiment considers only periodicity rates of powers of two.
Figure 8(a) shows that both algorithms achieve 80% accuracy at a full period (1.0 period fullness). However, for semi-full periods, STAGGER outperforms AVlSOrvI with an order of magnitude.
 spect to the processing time. AWSOM is a Wavelet-based algorithm that takes O(n) time to compute. However, STAGGER takes O(nlogn) time to compute the convolution. In con-clusion, STAGGER trades processing time for more accurate periodicity rates, more general periodicities in terms of symbols, and more discovered information (the periodic patterns themselves). In contrast, AWSOM trades accuracy for processing time by the \iVavelet ap-proximation that may lead to discarding potential periodicities.
 ing sliding windows is the key factor of the processing time, as depicted in Figure 9( a). 'vVe have three different settings for the lengths of the expanding sliding windows: arbitrary, geometric. and equi-distance settings. Let m be the number of expanding sliding windows all i = 1,2, ... , m -1, while the arbitrary setting selects Wi randomly, the geometric setting selects Wi to equal wi+d2, and the equi-distance setting selects Wi to equal (ijm)w ure 9(a) shows that the arbitrary setting gives the least processing time while the geometric setting gives the most processing time.
 settings increases gradually over time (as the data stream increases in size), whereas the processing time of the arbitrary setting increases irregularly. The importance of the gradual increase is that it gives a bound on the data arrival rate that STAGGER can manage without dropping any data symbols. For example, Figure 9(b), drawn with 10 expanding sliding windows, shows that STAGGER with the geometric setting has processed 11'-.1 symbols in approximately 100 seconds. This means that STAGGER can cope with an arrival rate of 10,000 symbols per second. Of course, this high rate is due to the high speed processor we used in our experiments.

The most important advantage of having expanding sliding windows is shown in Fig-ure 9( c), that is a much better average waiting time over a single sliding window. Clearly, the more the number of expanding sliding windows, the less average waiting time between consecutive outputs. Moreover, Figure 9(c) shows"that the geometric setting of the expand-ing sliding windows has the best performance with respect to the average waiting time.
A real-world database that contains sanitized data of timed sales transactions for some stores over a period of 15 months serves the purpose of real data experiments. Timed sales transactions data, of size 130 Megabytes is streamed to STAGGER. Although this data stream has a slow arrival rate (one value per hour), the purpose of the experiment is to demonstrate the practicality of the discovered periodic patterns. The numeric data values are discretized into five levels, i.e., the alphabet is of size 5. The levels are very low, low, medium, high, and very high. Discretization is based on manual inspection of the values (very low corresponds to zero transactions per hour, low corresponds to less than 200 transactions per hour, and each level has a 200 transactions range). Notice that although data is in terms of transactions per hour, the algorithm streams the data at a much higher rate. for different values of the periodicity threshold. Clearly, STAGGER outputs fewer period lengths for higher threshold values, and the period lengths detected with respect to a certain value of the threshold are enclosed within those detected with respect to a lower value. To verify its accuracy, STAGGER should at least output the period lengths that are expected in the data. Our real data has an expected period of length 24 that corresponds to the daily pattern of number of transactions per hour. Table 1 shows that a period of length 24 is detected when the threshold is 95% or less. In addition, STAGGER detects many more period lengths, some of which are quite interesting. A period of length 168 (24x7) can be explained as the weekly pattern of number of transactions per hour. A period of length 3961 shows a periodicity of exactly 5.5 months plus one hour, which can be explained as the daylight savings hour. One may argue against the clarity of this explanation, yet this proves that there may be obscure periods, unknown a priori, that STAGGER can detect. (single-symbol periodic patterns) with respect to a periodicity threshold of 50%. The pat-length 24. Table 2 gives the final output of STAGGER only for the period of length 24.
Knowing the meaning of every symbol leads to useful interpretation of the patterns. For example, the first pattern enunciates that on about 50% of the days, the number of trans-actions that occur at the first 4 hours and the last 3 hours of the day (9:00PlVI -4:00AI\iI) is equal to zero. This periodic pattern, and alike ones, can help the store manager to decide when to close the store, or when to reduce the number of sales assistants.
Related work falls into two main categories: data mining in data streams, and time series data mining.

III data streams. Domingos et a1. [13, 21] have presented an incremental technique for building decision trees over high-speed data streams. Guha et al. [18, 27] have extended the k-median clustering algorithm to fit the data stream model. In [1, 2]' Aggarwal et al. have proposed a more general framework for clustering and classifying data streams taking into consideration the evolution nature of data streams. Another data mining technique that has been addressed in the data stream context is regression analysis [10] that has been used for summarizing data streams and building online data cubes. Similarity search queries for patterns have been addressed recently in [16] using Fourier transform. As a related issue to most data mining techniques, counting the data items and finding the most frequent ones have been studied for data streams in [9, 26].
 patterns. Agrawal et a1. [3, 4] have developed a model for similarity of time sequences that can be used for mining periodic patterns. In [6, 30], Agrawal and Srikant have presented
Apriori-like [5] techniques for mining sequential patterns, which has been studied further by Garofalakis et al. [17] and by Ayres et a1. [8]. Ozden et al. [28] have studied mining of association rules of periodic nature. Han et al. [20, 19] have introduced the notion of partial periodic patterns and have presented two algorithms for mining this type of patterns. That work has been extended by Yang et a1. [32] to account for the intervention of random noise, and by I'vla and Hellerstein [25] to account for the case when the period is unknown a priori. advantages that it is computationally efficient as it requires O(nlogn) time for a signal of length n using FFT [23], and is scalable for large values of n as it can operate externally (on disk) using external FFT [31]. However, it does not discover periodicities with respect to symbols, and deals with fixed length signals and cannot be updated as new points arrive.
In this paper, we have proposed an online and incremental algorithm, named STAGGER, for periodicity mining in data streams. STAGGER is novel in the sense that it detects periodicity rates and discovers frequent periodic patterns in one pass through the data. This feature is essential when dealing with potentially infinite streams. To maximize the coverage over the stream, STAGGER uses expanding sliding windows to detect all periodicity rates.
STAGGER maintains a tree-like data structure to discover the frequent periodic patterns. 'l'/e have proposed a new approach for handling the thresholds in order to improve the accuracy of STAGGER. An empirical study using synthetic and real data validates the accuracy of STAGGER, shows the usefulness of the output, and shmvs the tradeoff between accuracy (favoring STAGGER) and processing time (favoring vVavelet-based techniques). [1] C. Aggarwal, J. Han, J. Wang, and P. Yu. A framework for clustering evolving data [2] C. Aggarwal, J. Han, J. Wang, and P. Yu. On demand classification of data streams. [3] R. Agrawal, K. Lin, H. Sawhney, and K. Shim. Fast similarity search in the presence [4] R. Agrawal, G. Psaila, E. Wimmers, and M. Zait. Querying shapes of histories. In [5] R. Agrawal and R. Srikant. Fast algorithms for mining association rules. In Proceed-[6] R. Agrawal and R. Srikant. Mining sequential patterns. In Proceedings of the 11th [7] W. Aref, M. Elfeky, and A. Elmagarmid. Incremental, online, and merge mining of [8] J. Ayres, J. Gehrke, T. Yiu, and J. Flannick. Sequential pattern mining using a bitmap [9] 1\11. Charikar, K. Chen, and ]\1. Farach-Colton. Finding frequent items in data streams. [10] Y. Chen, G. Dong, J. Han, B. Wah, and J. Wang. Multi-dimensional regression analysis [11] T. Carmen, C. Leiserson, and R. Rivest. Introduction to Algorithms. The MIT Press, [12] C. Daw, C. Finney, and E. Tracy. A review of symbolic analysis of experimental data. [13] P. Domingos and G. Hulten. lVIining high-speed data streams. In Proceedings of the 6th [14] M. Elfeky, VV. Aref, and A. Elmagarmid. Using convolution to mine obscure periodic [15] M. Elfeky, '0/. Aref, and A. Elmagarmid. Periodicity detection in time series databases. [16] L. Gao and X. Wang. Continually evaluating similarity-based pattern quenes on a [17] M. Garofalakis, R. Rastogi, and K. Shim. SPIRIT: Sequential pattern mining with [18] S. Guha, N. Mishra, R. Motwani, and 1. O'Callaghan. Clustering data streams. In Pro-[19] J. Han, G. Dong, and Y. Yin. Efficient mining of partial periodic patterns in time series [20] J. Han, \!IJ. Gong, and Y. Yin. Mining segment-wise periodic patterns in time related [21] G. Hulten, L. Spencer, and P. Domingos. Mining time-changing data streams. In [22] E. Keogh, S. Chu, D. Hart, and I'v1. Pazzani. Segmenting time series: A survey and [23] D. Knuth. The Art of Computer Programming, volume 2 of Series in Computer Science [24] J. Lin, E. Keogh, S. Lonardi, and B. Chiu. A symbolic representation of time series, [25] S. l\la and J. Hellerstein. Mining partially periodic event patterns with unknown periods. [26] G. Manku and R. Motwani. Approximate frequency counts over data streams. In [27] L. O'Callaghan, N. Mishra, A. Meyerson, S. Guha, and R. Motwani. Streaming-data al-[28] B. Ozden, S. Ramaswamy, and A. Silberschatz. Cyclic association rules. In Proceedings [29] S. Papadimitriou, A. BrockwelL and C. Faloutsos. Adaptive, hands-off stream mining. [30] R. Srikant and R. Agrawal. Mining sequential patterns: Generalizations and perfor-[31] J. Vitter. External memory algorithms and data structures: Dealing with massive data. [32] J. Yang, W. Wang, and P. Yu. l\,iining asynchronous periodic patterns in time series
