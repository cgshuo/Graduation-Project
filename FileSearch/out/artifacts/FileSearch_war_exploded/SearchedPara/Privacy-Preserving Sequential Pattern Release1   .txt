 Data mining poses the dilemma of discovering useful knowledge from databases while avoiding privacy disclosure. Ther e have been various research efforts on privacy-preserving data mining [1,2] fro m different perspectives such as identifi-cation [3], secure computat ion [1] and sensitive rules [4]. However, little work has been concentrated on removing privacy thr eats carried by data mining results [5], e.g., sequential patterns. In this work we study how released sequential patterns represent threats to privac y. We will cover sensitive attribute values disclosure and identification disclosure that focuses on the anonymity of individuals.
Our research motivation is from the he althcare domain wh ere protecting the patients X  privacy, such as anonymity and health status, is crucial. In Australia, e.g., the government agency Medicare Australia holds data on drug prescrip-tions, while each state government holds local hospitalisation data including di-agnoses [6]. To enhance healthcare, government agencies could analyse the health events and release knowledge discovere d, e.g., frequent sequential patterns. Example 1. Bob gets 3 sequential patterns from the above healthcare databases: 1. [ a, b, c, d ] with support 1000, i.e., 1000 patients having a ,lateron, b ,andthen 2. [ a, b, d ] with support 1000; 3. [ a, d ] with support 1001.
 These frequent sequential patterns represent a number of individuals as required by the minimum support threshold [7], and seemingly do not compromise pri-vacy. However, these released sequenti al patterns alone can indirectly divulge privacy including sensitive values and re-identification. (1) From the first two patterns, Bob easily infers that if a patient took Drugs a , b and then d ,he/she certainly suffered Condition c , which can be sensitive like HIV. This is risky if one party, say, Medicare Australia or a third commercial insurance company, holds prescriptions only. (2) Based on Patterns 2 and 3, Bob knows that one and only one patient has a and then d but without b in between. Through linkage with other data sources, this patient can b e re-identified. This results in privacy leakage via linking attacks [8,2].

To protect privacy while releasing sequential patterns and their frequency in-formation, in Section 2, we will propose two new concrete privacy-preserving objectives: (1) k -anonymous sequential patterns from which one impossibly in-fers the existence of patterns with very low support; (2)  X  -dissociative sequential patterns from which one impossibly infers an attribute value with very high cer-tainty. They can serve as a standard of releasing frequent sequential patterns without undue privacy divulgence. We analyse and formulate privacy disclosure inference channels for the two objectives in Section 3. In Section 4, we develop an algorithm PICS (Privacy Inference Channel Sanitisation) to detect and re-move these possible privacy threats by de liberately incrementing support values of released frequent sequential patterns. With small distortion, these frequent sequential patterns can be released without undue privacy divulgence w.r.t. the two objectives. We conclude the work in Section 5. We first brief some definitions related to sequential patterns. Let E = { e 1 ,e 2 ,  X  X  X  ,e d } be a set of d items. We call a subset A  X  X  an itemset and | A | the size of A .A sequence S = A 1 ,A 2 ,  X  X  X  ,A m is an ordered list of itemsets, where A i  X  X  , i  X  { 1 ,  X  X  X  ,m } .The size , m , of a sequence is the number of itemsets in the sequence, i.e., | S | = m .The length of a sequence S = A 1 ,  X  X  X  ,A m is defined as L ( S )= A sequence S a = A 1 ,  X  X  X  ,A n is contained in another sequence S b = B 1 , ..., B m denote S a S b , e.g., a ( bc ) a ab ( abc )( ad ) . For simplicity, we use ( ab ) to indi-cate a transaction where Items a and b occur at the same time, and ab to indicate that Item b is preceded by a .A sequence database D is a set of sequences with trans-actions from E .
 A pattern is an ordered list of itemsets from E , where items can be negative e i . A negative item e i means that Item e i surely does not occur. In Pattern a b ( cd ) , e.g., b doesn X  X  occur between a and ( cd ). A sequential pattern is an ordered list of itemsets from E without negative one. Patterns have similar operations with sequences, though they will be placed between  X  X  X  and  X  X  X , instead of  X   X  X nd X   X , e.g., Sequence ab ( cdf ) g contains Pattern [ a ( cd )] but not a b ( cd ) .

The support of a sequential pattern P in D is defined as the number of se-quences that contain P , i.e., supp D ( P )= |{ S | P S, S  X  X }| .If P 1 P 2 ,wehave supp D ( P 1 )  X  supp D ( P 2 ). Given a support threshold  X  s , a sequential pattern is called a frequent sequential pattern if its support supp D ( P ) is not less than  X  s , i.e., supp D ( P )  X   X  s . The problem of mining sequential patterns is to find all frequent sequential patterns for a sequence database D ,given  X  s .Wedenoteallthefrequent sequential patterns as FSP ( D , X  s ), and all frequent sequential patterns with length l as FSP ( l ) ( D , X  s ). We omit D if it is clear from the context.

We now define concrete privacy protectio n objectives for releasing frequent se-quential patterns to end users. To simplify t he discussion, we assume these patterns are generated without priva cy disclosure, say, in a secure environment. A frequent sequential pattern with its support value can be regarded as a select query that returns the size of a set of sequences contai ning the pattern. From this viewpoint, we can adapt the concept of k -anonymity [8] from data to patterns in a straight-forward way.
 Definition 1. Given a small integer threshold k ( &gt; 1),asetoffrequentsequential patterns from D are called k -anonymous sequential patterns if it is impossi-ble to identify a pattern P such that 0 &lt; supp D ( P ) &lt;k . Pattern P is non-k -anonymous if 0 &lt; supp D ( P ) &lt;k .
 Anon-k -anonymous pattern may be used to identify a set of sequences of cardi-nality greater than 0 and less than k . It may serve as a quasi-identifier for linking attack [2], e.g., supp D a bd =1 in Example 1. We assume the support threshold  X  &gt;k , i.e., a single frequent sequential pattern is not non-k -anonymous.
Besides violating anonymity, there is another possibility of releasing sensitive information. As in Example 1, if one patient contains [ abd ], it is 100% sure that he/she suffers Condition c between taking b and d . Condition c could be sensitive. Definition 2. Give a rational  X  (slightly smaller than 1.0), a set of frequent se-quential patterns are  X  -dissociative sequential patterns if it is impossible to identify a pair of patterns P 1 and P 2 such that Using non- X  -dissociative patterns, for some individuals, we can use the existence of sub-pattern P 1 to infer the existence of super-pattern P 2 that may contain sensitive information with high certainty, say,  X   X  .

The parameters k and  X  can be set at any level, depending on the amount of protection that is desired. Thus, if a s et of frequent sequential patterns are k -anonymous and  X  -dissociative, it is acceptable f or releasing them from these two concrete privacy-pres erving perspectives. We now study the possibility of inferring non-k -anonymous or non- X  -dissociative patterns from the set of frequent sequential patterns FSP ( D , X  s ). A privacy in-ference channel indicates a subset of frequent sequential patterns from which it is probable to infer sensitive information such as non-k -anonymous or non- X  -dissociative patterns. Based on the anti-monotonicity of frequent sequential pat-terns[7],wehavethefollowingtheorem.
 Theorem 1. If FSP ( D , X  s ) is not  X  -dissociative, there must exist a pair of patterns P t and P s such that L ( P s )= L ( P t ) Proof: If it is incorrect, i.e., for each pair of P t and P s ,if L ( P s )= L ( P t )  X  1and P of patterns P 1 and P 2 satisfying Equation 1. For any P 1 P 2 , P 2  X  FSP ( D , X  s ), there exists a list of frequent sequential patterns, { P t 1 ,P t 2 ,  X  X  X  ,P t j } ( j L ( P 2 )  X  Theorem 1 implies that, to detect whether there exist privacy inference channels for  X  -dissociation, we only need to compare the support values of pairs of frequent sequential patterns wit h length difference of 1.

As for support values of patterns with negative items, it is intuitive to de-fine one for a pattern with one negative item. For example, supp D ([ e i 1 e i 2 e i 3 ]) to extend this inference channel to patte rns with two or more negative items based on the inclusion-exclusion principle [3]. We will further show that there are not re-liable inference channels for all but one definition (i.e., Definition 4) of support for patterns with more than one negative item.

We first illustrate this on Pattern [ e i 1 e i 2 e i 3 ]. To define whether a sequence sup-ports it, we may take account of every e i 2 or at least one e i 2 satisfying the pattern. We may consider both  X  X o Item e i 1 preceding Item e i 2  X  X nd X  X oItem e i 3 following Item e i 2  X  are valid or either of them. Thus, Definition 3. There are four possible ways to define support of [ e i 1 e i 2 e i 3 ]: 3.2 A sequence S is defined to support the pattern [ e i 1 e i 2 e i 3 ]ifin S there exists 3.3 A sequence S is defined to support the pattern [ e i 1 e i 2 e i 3 ]ifany e i 2 in S is 3.4 A sequence S is defined to support the pattern [ e i 1 e i 2 e i 3 ]ifany e i 2 in S is We will extend Definition 3.4 to Definition 4 for any pattern P with multiple neg-ative items to discuss its privacy inference channels. The follow theorem indicates there are no reliable inference channels w.r.t. Definitions 3.1-3.3.
 Theorem 2. There are no reliable inference channels based on the frequent sequen-or not w.r.t. Definition 3.1 (or Definition 3.2 or 3.3).
 The basic idea of the proof is that we can create two sequence sets that have same frequent sequential patterns but much difference on infrequent sequential patterns. One underlying observation is that the ordering is crucial in sequential patterns. ily contain [ e i 1 e i 2 e i 3 ]. For other patterns with two or more negative items, we can similarly show there are no privacy inference channels for all but one definition of support. The proof is omitted due to space limitation.
 We introduce two patterns related to P . Let the lower bound sequential pattern P ( l ) P consist of only positive items, and the upper bound one P ( u ) is generated Definition 4. Sequence S is defined to support Pattern P with at least a nega-tive item, i.e., supp S ( P ) = 1, if it supports its lower bound sequential pattern P ( l ) while does not support its upper bound one P ( u ) . The support of any pattern with negative item(s) is then defined as. So, if both P ( u ) and P ( l ) are frequent, there may be a privacy inference channel for P ,say,violating k -anonymity. Similar to Theorem 1, to detect and then remove non-k -anonymity privacy inference channels of a whole set of frequent sequential patterns, we only need to examine the support values of those patterns with one and only one negative item due to the following property.
 Theorem 3. If there are two patterns P 1 and P 2 such that P ( l ) 1 P ( l ) 2 and P ( u ) 2 P 1 , then, w.r.t. Definition 4, The proof is easy because supp D ( P ( l ) 1 )  X  supp D ( P ( l ) 2 )and supp D ( P ( u ) 2 )  X  supp D ( P ( u ) 1 ). Then, simply based on Equation 2, we get Equation 3. Therefore, the search space for channel detection is r educed immensely, and our detection al-gorithm for privacy inference channels can be very efficient. Algorithm 1. Privacy Inference Channel Sanitisation ( PICS ) Our privacy-preserving release d frequent sequential patterns FSP ( D , X  s )are achieved by adjusting their support values to remove privacy inference channels discussed in Section 3 and meanwhile maintain database compatibility. The basic idea is to create a pse udo sequence database D p by inserting some sequences into D such that (1) FSP ( D p , X  s ) contains the same frequent patterns as FSP ( D , X  s ) but with a bit different support values and (2) there are no privacy inference channels from FSP ( D p , X  s ). Then we release FSP ( D p , X  s ) instead of FSP ( D , X  s ). To keep the result accurate, we insert as few sequences as possible. For any inference channel related to non- X  -dissociation as in Equation 1, we simply increment the support of the sub-pattern P 1 by K 1 . To maintain database compatibility, the support val-ues of all its sub-patterns are increased by K 1 accordingly. It change FSP ( D , X  s ) into FSP ( D 1 , X  s )where D 1 is D plus K 1 copies of sequences only containing P 1 . K 1 =max 0 , port value of P 1 is greater than supp ( P 2 )  X  . For any non-k -anonymity inference chan-nel as in Equation 2, we increment the support values of the lower bound frequent pattern P ( l ) and all its sub-patterns by K 2 . It looks like inserting K 2 copies of P ( l ) s. K 2 =max 0 ,k  X  ( supp ( P ( l ) )  X  supp ( P ( u ) )) is minimal to ensure that the new support value of P ( l ) is not less than supp ( P ( u ) )+ k . Thus, incrementing the support values in this way is equivalent to inserting sequences into the original D , and thus database-compatibility is maintained. Moreover, it will not create new inference channels.

According to Theorems 1 and 3, we only n eed to examine and remove the infer-ence channels caused by pairs of frequent s equential patterns with length difference of 1. Based on these, we propose our PICS (Privacy Inference Channel Sanitisa-tion) algorithm for sanitising frequent sequential patterns as in Algorithm 1. Here P . supp supp D ( P i ) is the original support value for the pattern P i in D ,and P . X  is the support increment introduced by the sanitisation procedure. Basically, we start from frequent sequential patterns P i with the maximal length one by one until with the shortest patterns. For given parameters k and  X  ,wecheck whether there exists P j  X  FSP ( | P i | +1) ( D , X  s ) such that P i P j ,  X &lt;K where then increase P i . X  by K  X   X  (i.e., max { K 1 ,K 2 } mentioned above) to ensure the new support difference between P i and P j is K . This is embedded in Line 10. In addition, we increase all the sub-patterns of P i by K  X   X  . This is implemented in Line 6. The adjusted support for each P i is P i . supp + P i . X  as in Line 6. Lines 4-6 ensure the sanitised support values satisfy anti-monotonicity, i.e., if P i P j ,then P . supp + P i . X   X  P j . supp + P j . X  . There is a sequence database D p whose frequent sequential patterns are exactly the output from PICS, i.e., FSP ( D p , X  s )= O k, X  for given k and  X  .

We chose freeware SPAM [7] to generate frequent sequential patterns for a sequence database. We implemented PI CS in Python. Two sequence databases were generated by IBM Quest Market-Basket Synthetic Data Generator [7]. The first has 20,000 sequences, and 10 different items. The second has 8,000 differ-ent sequences and 12 different items. Sin ce PICS ensures the resulting frequent sequential patterns are k -anonymous and  X  -dissociative, we only measure how much the sanitised support values differ from the original ones. Three metrics are used to evaluate the distortion to support values. (1) Average distortion ratio is how often support values are incremented. (3) The execution time of PICS is compared with that of SPAM.

A series of experimental results of PICS with different k and  X  on the first se-quence database are illustrated in Fig. 1. The support threshold  X  s is 36, 40,  X  X  X  , or 60; k is 2, 5 or 10; and  X  is 0.90% or 0.95%. Clearly, the execution overhead of PICS is quite small in comparison with SPAM as in Fig. 1(c). When  X  s = 40, e.g., SPAM takes 12.11 seconds while PICS takes 1.08 seconds, only 8.92% of SPAM. PICS is quite conservative for low value of k and (1  X   X  ). Typically, when  X  s = 40, SPAM generates 770 frequent sequential patterns. PICS adjusts less than 4% sup-port values as in Fig. 1(b), and the average distortion ratio is less than 0.72% as in Fig. 1(a). The average distortion ratio and fraction of support adjusted appear to decrease with  X  s with all the settings of k and  X  . In addition, when k is quite small, say, 2, the average distortion ratio (or the fraction of support adjusted) with  X  =0 . 95 is much smaller than that with  X  =0 . 90. When k is quite large, say, 10,  X  values have little influence during the sanitisation procedure. This clearly illustrates that k -anonymity and  X  -dissociation are two complementary privacy-preserving object ives. Similar performance is observed for the second se-quence database. Thus, with a small computation overhead, PICS maintains rea-sonably good accuracy w.r.t. the original sequential patterns while resulting in k -anonymous and  X  -dissociative frequent sequential patterns. In this paper, to reduce the privacy disclosure risk caused by releasing frequent sequential patterns, we have introduced two complementary privacy-preserving objectives: k -anonymity and  X  -dissociation. They addr ess identification and at-tribute value disclosure respectively. We have established a practical algorithm PICS to detect and remove all the privacy inference channels with respect to both the objectives. After incrementing suppor t values of a small proportion of frequent sequential patterns, PICS can effectively a nd efficiently sanitise frequent sequen-tial patterns for privacy-preserving release, as substantiated by a series of exper-imental results. We are studying possible privacy disclosure caused by releasing different types of data mining results but from the same database.

