 1. Introduction
The development of the Semantic Web proceeds in steps, each step building a layer on top of another. At tion logic-based language OWL [1] . The next step in the development of the Semantic Web will be the logic permit the computer to infer new knowledge by applying these principles on the existing data. Rule systems appear to lie in the mainstream of such activities.

Many recent studies have focused on the integration of rules and ontologies, and various solutions have been proposed. The Description Logic Programs is the approach followed in [2] ; DLPs derive from the inter-section of Description Logics and Horn Logic, and enable reasoning with available efficient LP inferencing Semantic Web are TRIPLE [5] and SWRL [6] . They both provide a model for rules on the Semantic Web. TRIPLE is based on F-Logic and provides support for RDFS and a subset of OWL Lite, while SWRL extends OWL DL with Horn-style rules.
 Different, but equally interesting research efforts, deal with the standardization of rules for the Semantic a canonical Web language for rules using XML markup, formal semantics, and efficient implementations; and (b) the research conducted by the Rule Interchange Format (RIF) Working Group, which was recently launched by W3C.

Moreover, rule systems can also be utilized in ontology languages. So, in general rule systems can play a two-fold role in the Semantic Web initiative: (a) they can serve as extensions of, or alternatives to, description logic-based ontology languages; and (b) they can be used to develop declarative systems on top of (using) ontologies.
 tems capable of handling conflicts among rules and reasoning with partial information. Recently developed nonmonotonic rule systems for the Semantic Web are: (a) DR-Prolog [8] is a system that implements the entire framework of Defeasible Logic, and is thus able to (b) DR-DEVICE [9] is also a defeasible reasoning system for the Semantic Web. It is implemented in Jess, (c) SweetJess [10] implements defeasible reasoning through the use of situated courteous logic programs. It
The upper levels of the Semantic Web have not been researched enough and contain critical issues, like and little has been written and done for this layer.

The main difference between a query posed to a  X  X  X raditional X  X  database system and a Semantic Web system is
Thus, a Semantic Web answering system, to gain the trust of a user must be able, if required, to provide an can be given as a derivation of the conclusion with the sources of information for the various steps.
In this work, we describe a system for representing and exchanging explanations on the Semantic Web, which uses Defeasible Logic as the underlying inference system. Defeasible Logic has been shown useful ations [14] , semantic brokering [15] , and applications to the Semantic Web [8,9] .

The paper is organised as follows. Section 2 presents the basics of Defeasible Logic, a nonmonotonic rules system used as the underlying knowledge representation and reasoning method. Section 3 describes the meth-to present an explanation to the user. Section 5 describes the implementation of a multi-agent environment allowing agents to request and receive answers and explanations. Explanations are exchanged in an XML lan-guage, an extension of RuleML described in Section 6 . Section 7 briefly discusses some potential use cases.
Finally, Section 8 discusses related work. 2. Use cases
In this section, we mention three examples where the agents make use of explanations in the Semantic Web:  X  An agent can make use of an explanation during a e-commerce negotiation. For example, an agent that represents a buyer can send a message to the agent that represents the online shop asking if the buyer owns money to the shop. If the agent that represents the online shop answers positively, then the buyer X  X  agent may ask for an explanation why he owns the money. Then the online shop X  X  agent will answer sending back the full explanation. This exchange of proofs is crucial for large-scale success of automated e-commerce on the Semantic Web.  X  Another case where an agent can use an explanation is at a University System. For example an agent that represents a student may ask for the student X  X  grades. Then for every lesson that the student failed to pass the agent may ask for an explanation why he failed. The university X  X  agent then will respond with a full explanation containing the midterms grade, the grade of the project, and the grade of the final exam.
The same may happen for the lessons that the student succeeded; in the latter case, the agents may ask for an explanation about how the grades were extracted. Thus, proofs can enhance the interactive behavior of web sites. have the right permissions to access it. Then the agent may ask for an explanation about why it is not authorized to access the system. An approach in this direction has been developed in the infrastructure described in [16] . That study describes the development of a rule-based management system that provides a mechanism for the exchange of rules and proofs for access control in the Web, in cases such as who owns the copyright to a given piece of information, what privacy rules apply to an exchange of personal infor-mation, etc.

In all these cases, the negotiation is made automatically without the user X  X  direct involvement. The agent makes all the appropriate actions and presents only the result and the explanation to the user. 3. Basics of Defeasible Logic 3.1. Basic characteristics
Defeasible reasoning is a simple rule-based approach to reasoning with incomplete and inconsistent infor-main advantage of this approach is the combination of two desirable features: enhanced representational capabilities allowing one to reason with incomplete and contradictory information, coupled with low compu-tational complexity compared to mainstream nonmonotonic reasoning. The basic characteristics of Defeasible
Logics are:  X  Defeasible Logics are rule-based, without disjunction. language (it can easily be simulated, if necessary [19] ).  X  Rules may support conflicting conclusions.  X  The logics are skeptical in the sense that conflicting rules do not fire. Thus, consistency is preserved.  X  Priorities on rules may be used to resolve some conflicts among rules.  X  The logics take a pragmatic view and have low computational complexity. 3.2. Syntax ing free variables are interpreted as the set of their variable-free instances.
 the conclusion. An example of a strict rule is  X  X  Professors are faculty members  X  X . Written formally: ing inconsistencies in definite inference.

Defeasible rules are denoted by A ) p , and can be defeated by contrary evidence. An example of such a rule is which reads as follows: X  X  Professors are typically tenured  X  X .

Defeaters are denoted by A p and are used to prevent some conclusions. In other words, they are used to defeat some defeasible rules by producing evidence to the contrary. An example is the rule which reads as follows:  X  X  X ssistant professors may not be tenured X  X . This means that the information that dence that he may not be tenured.
 expresses that r 1 may override r 2. For example, given the rules tenured. 3.3. Proof theory
A conclusion of D is a tagged literal and can have one of the following four forms:  X + D q , which is intended to mean that q is definitely provable in D .  X  D q , which is intended to mean that we have proved that q is not definitely provable in D .  X + o q , which is intended to mean that q is defeasibly provable in D .  X  o q , which is intended to mean that we have proved that q is not defeasibly provable in D . facts W .
 denotes the initial part of the sequence P of length i ): ability below, where opposing chains of reasoning must be taken into account, too).
 least one antecedent a for which we have established that a is not definitely provable ( D a ): the single rule p ! p , we can see that p cannot be proven, but Defeasible Logic is unable to prove D p : + o : We may append P ( i +1)=+ o q if either
Let us illustrate this definition. To show that q is provable defeasibly we have two choices: (1) we show that q is already definitely provable; or (2) we need to argue using the defeasible part of D as well. In particular, we require that there must be a strict or defeasible rule with head q which can be applied (2.1). But now we need to consider possible attacks, that is, reasoning chains in support of q .Tobe more specific: to prove q defeasibly we must show that q is not definitely provable (2.2). Also (2.3) we must consider the set of all rules which are not known to be inapplicable and which have head q . Essentially each such rule s attacks the conclusion q . For q to be provable, each such rule must be counterattacked by a rule t with head q with the following properties: (i) t must be applicable at this point, and (ii) t must be stronger than s . Thus, each attack on the conclusion q must be counterattacked by a stronger rule.

The definition of the proof theory of Defeasible Logic is completed by the condition X  o . It is nothing more than a strong negation of the condition + o : sibly applicable rule s with head q is superior to s (2.3).
 from the context we write  X  L .

It is instructive to consider the conditions + o and o in the terminology of teams , borrowed from Gro-sisting of the applicable rules with head q . These teams compete with one another. Team A wins iff every wins, in which case we can prove + o q . But there are several intermediate cases, for example one in which we can prove that neither q nor q are provable. And there are cases where nothing can be proved (due to loops).

Concepts of a model-theoretic semantics in [20] , and argumentation semantics is discussed in [21] . 3.4. Defeasible Logic metaprogram In order to perform reasoning over a defeasible theory, we have adopted the approach proposed in [22,23] . this framework is based on two  X  X  X arameters X  X : (a) The metaprogram P ( D ). (b) The negation semantics adopted to interpret the negation appearances within P ( D ).
For part (b), different semantics have been proposed and studied in the literature: the well-founded seman-tics, answer set semantics, and the classical negation-as-failure operator of Prolog.
In this work, we use a similar metaprogram which fits better our needs for representing explanations. This defeasible theory: supportive _ rule(Name,Head,Body):-strict(Name,Head,Body) . supportive _ rule(Name,Head,Body):-defeasible(Name,Head,Body) .
 by a strict rule, the premises of which are definitely provable: definitely(X):-fact(X) . definitely(X):-strict(R,X,L),definitely _ provable(L) . definitely _ provable([X1|X2]):-definitely _ provable(X1), definitely _ provable(X2) . definitely _ provable(X):-definitely(X) . definitely _ provable([]) .
 premises of which are defeasibly provable, and which is unblocked.
 defeasibly(X):-definitely(X) . defeasibly(X):-negation(X,X1), supportive _ rule(R,X,L), defeasibly _ provable(L) , unblocked(R,X), xsb _ meta _ not(definitely(X1)) . defeasibly _ provable([X1|X2]):-defeasibly _ provable(X1), defeasibly _ provable(X2) . defeasibly _ provable(X):-defeasibly(X) . defeasibly _ provable([]) .

A rule is unblocked when there is not an undefeated conflicting rule: unblocked(R,X):-negation(X,X1), xsb _ meta _ not(undefeated(X1)) .

A literal is undefeated when it is supported by a defeasible rule which in not blocked: undefeated(X):-supportive _ rule(S,X,L), xsb _ meta _ not(blocked(S,X)) .

A rule is blocked either if its premises are not defeasibly provable, or if it is defeated: blocked(R,X):-supportive _ rule(R,X,L), xsb _ meta _ not(defeasibly _ provable(L)) . blocked(R,X):-supportive _ rule(R,X,L), defeasibly _ provable(L), defeated(R,X) .
 provable: defeated(S,X):-negation(X,X1), supportive _ rule(T,X1,V) , defeasibly _ provable(V), sup(T,S) .

We define the predicate negation to represent the negation of a predicate and evaluate the double negation the not predicate when executing a program in XSB trace.
 clusion cannot be reached. We define when a literal is not definitely provable and when it is not defeasibly plementary is definitely provable or for every defeasible rule that supports it, either its premises are not defeasibly provable, or it is not unblocked. 4. Explanation in Defeasible Logic 4.1. Search tree construction
The metaprogram works in conjunction with a Prolog system. In our prototype we use XSB Prolog. It was chosen mainly because we were able to experiment with various LP semantics (usual Prolog not, and well-to the selection of a particular Prolog system.

The foundation of the proof system lies in the Prolog metaprogram that implements Defeasible Logic, with of the metaprogram to generate a Defeasible Logic search tree, that subsequently will be transformed into a proof suitable to be presented to an end user.

The negation we use in conjunction with the metaprogram is the negation-as-failure of Prolog. Unfortu-nately, the XSB trace information for well-founded semantics does not provide the information we would require to produce meaningful explanations.
To enable the trace facility, the XSB process executes the command trace . After loading of the metapro-gram and the defeasible theory, the system is ready to accept any queries which are forwarded unmodified sage each time a predicate is: 1. initially entered ( Call ), 2. successfully returned from ( Exit ), 3. failed back into ( Redo ), and 4. completely failed out of ( Fail ).

The produced trace is incrementally parsed by the Java XSB invoker front-end and a tree whose nodes rep-
Namely:  X  A string representation of the predicate X  X  name.  X  The predicate X  X  arguments.  X  Whether it was found to be true ( Exit ) or false ( Fail ).  X  Whether it was failed back into ( Redo ).

In addition to the above, the traced predicate representation node has a Boolean attribute that encodes whether the specific predicate is negated. That was necessary for overcoming the lack of trace information for the not predicate (see next section).

One remark is due at this stage: Of course our work relies on the trace provided by the underlying logic programming system (in our case XSB). If we had used an LP directly for knowledge representation, expla-nations on the basis of LP would have been appropriate. However, here we use defeasible reasoning for knowledge representation purposes (for reasons explained extensively in previous literature), thus explana-tions must also be at the level of Defeasible Logics. 4.2. Search tree pruning: illustration
The pruning algorithm, that produces the final tree from the initial XSB trace, focuses on two major points. Firstly, the XSB trace produces a tree with information not relevant for the generation of the search tree. One reason for this is that we use a particular metaprogram to translate the Defeasible Logic into logic programming. For the translation to be successful, we need some additional clauses which add additional information to the XSB trace. Another reason derives from the way Prolog evaluates the clauses, showing both successful and unsuccessful paths. Secondly, the tree produced by the XSB trace is built according to the metaprogram structure but the final tree needs to be in a complete different form, compliant with the XML schema described in Section 6 . We will take a closer look at the details of these issues.

A main issue of the pruning process was the way Prolog evaluates its rules. Specifically, upon rule evalu-or combinations of both. Suppose we have the following defeasibly theory, translated into logic programming clauses as follows: fact(a) . fact(e) . defeasible(r1,b,a) . defeasible(r2,b,e) . defeasible(r3, (b),d) .
 duces a search tree, which begins with the following lines:
In this type of proof, we are only interested in successful paths and the pruning algorithm removes the subtree with the false goal to prove that b is definitely provable and the false predicate to find a strict supportive rule for b. It also prunes the metaprogram additional negation clause. The complementary lit-eral is used in next parts of the proof. The corresponding final pruned subtree for this query has the fol-lowing form:
Suppose we have the following defeasibly theory: fact(a) . defeasible(r1,b,a) . defeasible(r2, (b),a) .
 that b is definitely provable. It produces a search tree, which begins with the following lines: Thus, the pruned tree remains the same in the first lines.

The other heuristic rules deal with the recursive structure of Prolog lists and the XSB X  X  caching technique is required.

In other words, the tree is very close to an explanation derived by the use of pure Defeasible Logic. 4.3. Search tree pruning: the methods 1. Pruning Definitely . When the atom of a query can be proved definitely it is either a fact, in which case we simply locate the fact clause, or there is at least one strict rule having the atom as its head and a body that is definitely provable. Thus, we locate the first such rule along with the definite proof of its body. An example of an initial search tree produced by XSB and the corresponding pruned subtree is the following: provable. An example of an initial search tree produced by XSB and the corresponding pruning subtree is the following: search tree produced by XSB and the corresponding pruned subtree is the following (the underlined ele-ments are pruned from the initial search tree): 4. Pruning Not Defeasibly . When the atom of a query cannot be proved defeasibly, it cannot be proved definitely and either there is a triggering not blocked rule supporting the negation of the atom or there is no triggering supportive rule that is not blocked or the negation of the atom can be definitely proved. An example of an initial search tree produced by XSB and the corresponding pruned subtree is the following: single depth sequence of atoms. An example of an initial search tree produced by XSB and the correspond-ing pruned subtree is the following: 6. Handling missing proofs . XSB uses a caching technique in order to avoid reevaluating already evaluated expressions. Effectively, this means that the first time it encounters a predicate, XSB provides the result along with the proof execution tree in the trace. If it comes across the same predicate again, it uses the cached value and does not show the whole execution tree. In some cases, the afore-mentioned pruning techniques may prune the first evaluation of the predicate and at some point where we actually want the predicate to be maintained we are left with the cached version. This is not desirable, so we are forced to keep a copy of the initial trace so as to recover a possibly pruned predicate evaluation sub-tree. An example of an initial search tree produced by XSB and the corresponding pruned subtree is the following: 5. Graphical user interface to the proof system
The graphical user interface Fig. 1 to the proof system, offers an intuitive way to interact with the under-the corresponding tree node. This is an optional reference to a Web address that indicates the origin of the atom.

The interaction with the graphical user interface is broken down to three or four steps, depending on out: or Add rules from file button at the right part of the interface. The Add Rule button presents a text entry dialog where a single rule may be typed by the user. Besides that, pressing the Add rules from file button visible at the bottom part of the graphical user interface. of the interface. 3. By pressing the Prune button the system executes the pruning algorithms described in the previous section to eliminate redundant information and metaprogram artifacts and thus bring the visualized search tree to a more human friendly form. 6. Agent interface to the proof system
The system makes use of two kinds of agents, the  X  X gent X  which issues queries and the  X  X ain Agent X  which is responsible to answer the queries. Both agents are based on JADE (Java Agent DEvelopment Frame-work) [24] . JADE simplifies the implementation of multi-agent systems through a middle-ware that complies be controlled via a remote GUI. The configuration can be even changed at run-time by moving agents from one machine to another, as and when required.
 Fig. 2 shows the process followed by the Main Agent in order to answer a query.

All the above steps are illustrated next: 10. Main Agent returns Answer or Proof . Finally the Main Agent sends back to the agent that issued the 7. Extension of RuleML for explanation representation
The need for a formal, XML based, representation of an explanation in the Semantic Web led us to design an extension of the Rule Markup Language (RuleML) [13] . RuleML is an XML based language that supports rule representation for the Semantic Web. In this section, we describe in detail the design of a new XML schema, extension of RuleML, for explanation representation in Defeasible Logic and in the next section we give some instructive examples. 7.1. Atoms, facts and rule representation
In our XML schema, we use a similar syntax to RuleML in order to represent Facts and Rules . Spe-cifically, we use the Atom element which refers to an atomic formula, and it consists of two elements, an ceded optionally by a not statement (in case we represent a negative literal). Fig. 3 shows the declaration of a typical Atom.

Similarly to RuleML, a Fact consists an Atom that comprises a certain knowledge. The last primitive entity of our schema is Rules . In Defeasible Logic, we distinguish two types of Rules: Strict Rules and Defeasible two parts, the Head element which is constituted of an Atom element, and the Body element which is con-stituted of a number of Atom elements. Fig. 4 shows a typical example of a Defeasible Rule. 7.2. Definitely provable explanations
The simplest proof explanation is the case of a definitely provable Atom. For that proof, we first have to denote the Atom, and then give the Definite Proof that explains why it is definitely provable. This expla-nation can come out in two ways: either a simple Fact for that Atom, or a Strict Rule with this Atom as its Head and an Atom that should be also proved definitely with the same way as its Body . If the Body con-sists of multiple Atoms, then we state the definite provable explanation for every atom of the Body. Fig. 5 shows the structure of a definite proof explanation.
 7.3. Defeasibly provable explanations
A defeasibly provable explanation arises from the Defeasible Logic specification. If an Atom is definitely Atom, that is covered by the previous section about definitely provable explanations.
Else, we denote the Atom and we have to a give a Defeasible Proof . A Defeasible Proof consists of four steps: First, we point a Defeasible Rule with the specified Atom as its Head . In the second step, we explain why the Body of that rule is defeasible provable (if it consists of many Atoms, then a separate their head (attacking rules) can be defeated. We call these attacking rules as Blocked . We characterize attacking rules as Blocked in two cases:  X  When they cannot fire, so we must prove that their body is not defeasible provable (in case of multiple
Atoms it is enough to show that only one of them is not defeasible provable). For not defeasible provable explanation, look at the Section 7.5 below.
 than the rule we first used as supportive, we also add the defeasible provable explanations for its body.
So, for every attacking rule we create a Blocked tag with the explanation of why the rule is defeated (one of the above two cases). Fig. 6 shows the structure of a definite proof explanation. 7.4. Not definitely provable explanations
The next case is the explanation of an Atom that is not definitely provable. According to our XML schema, we first denote the Atom that is not definitely provable and then we give the NonDefinitely Proof . The NonDefinitely Proof consists of all the strict rules with head equal to the negation of the nonprovable
Atom, with an explanation of why they cannot fire. Inside Blocked tags, we include each strict rule with a NonDefinitely Provable explanation for their body. Fig. 7 demonstrates an example of a nondefinitely prov-able explanation. 7.5. Not defeasibly provable explanations
Finally, we describe the case when an Atom cannot be defeasibly proved. For a NonDefeasible Proof , we need to support our explanation with one of the following three cases:  X  All rules with the specified Atom as their head do not fire. For that case, we include inside Blocked tags every supportive defeasible rule, and also a not defeasibly provable explanation for their body.  X  The negation of this Atom is definitely provable.  X  We denote a rule with the negation of the specified Atom as its head, which is Undefeated . That means that there is no attacking rule that can defeat it. So, we embody inside Undefeated tags the defeasible rule rule that supports the specified Atom is denoted inside Blocked tags either as Not Superior rule com-pared with the undefeated rule, or its body as non defeasible provable.
 Fig. 8 shows an example of a nondefeasible provable explanation.
 8. Related work
Besides teaching logic [25] , not much work has been centered around explanation in reasoning systems so standable to its users.

Work has also been done in explaining the reasoning in description logics [28,29] . This research presents a based on the logical format. 8.1. Inference web
The most prominent work on proofs in the Semantic Web context is Inference Web [30] . The Inference Web (IW) is a Semantic Web based knowledge provenance infrastructure that supports interoperable explanations providing proof metadata about sources, and explanation, by providing manipulation trace information. It also supports trust, by rating the sources about their trustworthiness.

The Inference Web consists of the following main components:  X  Proof Markup Language ( PML [31] ) is an OWL-based specification for documents representing both proofs and proof meta information. Proofs are specified in PML and are interoperable.  X  IWBase is an infrastructure within the Inference Web framework for proof meta information. It is a dis-tributed repository of PML documents describing provenance information about proof elements such as sources, inference engines and inference rules.  X  IWExplainer is a tool for abstracting proofs into more understandable formats.  X  IWBrowser can display both proofs and explanations in number of proof styles and sentence formats.
IW simply requires inference rule registration and PML format. It does not limit itself to only extracting deductive engines. It provides a proof theoretic foundation on which to build and present its explanations, but any question answering system may be registered in the Inference Web and thus explained. So, in order to use the Inference Web infrastructure, a query answering system must register in the IWBase its inference engine along with its supported inference rules, using the PML specification format. The IW supports a proof generation service that facilitates the creation of PML proofs by inference engines.
 It is an interesting and open issue how our implemented proof system could be registered in the Inference
Web, so as to produce PML proofs. This would possibly require the registration of our inference engine, that Logic proof theory and the explanations produced by our proof system.

Extra work needs to be done in Inference Web in order to support why-not questions. Current IW infra-to our system X  X  explanations when an atom is not definitely or defeasibly provable. 9. Conclusion and future work We presented a new system that aims to increase the trust of the users for the Semantic Web applications.
The system automatically generates an explanation for every answer to user X  X  queries, in a formal and useful ing system in the Semantic Web, in a more human readable way. Also, an explanation could be fed into a proof checker to verify the validity of a conclusion; this is important in a multi-agent setting.
Our reasoning system is based on Defeasible Logic (a nonmonotonic rule system) and we used the related implemented meta-program and XSB as the reasoning engine. We developed a pruning algorithm that reads the XSB trace and removes the redundant information in order to formulate a sensible proof. Furthermore, the system can be used by agents, a common feature of many applications in the Semantic Web. Another contribu-tion of our work is a RuleML extension for a formal representation of an explanation using Defeasible Logic.
There are interesting ways of extending this work. The explanation can be improved to become more intu-ported. The XML Schema should be made fully compatible with the latest version of RuleML. Finally, integration with the Inference Web infrastructure will be explored.
 Acknowledgement This work was partially supported by the REWERSE Network of Excellence.

References
