 Semantic understanding of multimedia content is critical in enabling effective access to all forms of digital media data. By making large media repositories searchable, se-mantic content descriptions greatly enhance the value of such data. Automatic semantic understanding is a very chal-lenging problem and most media databases resort to describ-ing content in terms of low-level features or using manually ascribed annotations. Recent techniques focus on detecting semantic concepts in video, such as indoor, outdoor, face, people, nature, etc. This approach works for a fixed lexicon for which annotated training examples exist. In this paper we consider the problem of using such semantic concept de-tection to map the video clips into semantic spaces. This is done by constructing a model vector that acts as a compact semantic representation of the underlying content. We then present experiments in the semantic spaces leveraging such information for enhanced semantic retrieval, classification, visualization, and data mining purposes. We evaluate these ideas using a large video corpus and demonstrate significant performance gains in retrieval effectiveness.
 Categories and Subject Descriptors: H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms: Algorithms, Design, Experimentation Keywords: Semantic Indexing, Model Vectors, TRECVID
The increasing growth of unstructured digital media con-tent in the form of video, audio, images, graphics, and speech is driving the need for more effective methods for index-ing, searching, categorizing and organizing such information. With the falling costs for media storage, higher bandwidth, and with the proliferation of affordable media production devices such as digital cameras and camcorders, media man-agement is becoming increasingly important in a variety of consumer, scientific, and business applications. Tools for efficient storage and retrieval of multimedia content are ab-solutely essential for the utilization of raw content. Recent advances in content analysis, feature extraction and clas-sification are improving capabilities for effectively search-ing and filtering of multimedia content. However, a signifi-cant gap remains between the low-level feature descriptions that can be automatically extracted, such as colors, tex-tures, shapes, motions, etc., and the semantic descriptions of objects, events, scenes, people and concepts that users de-sire. This  X  X emantic gap X  between users X  needs and systems X  abilities has often been cited as the biggest stumbling block in the successful application of media management in real world problems. The problem of automatic semantic charac-terization of multimedia content is therefore an important research problem in data management and knowledge ex-traction. To enable efficient multimedia understanding it is necessary to be able to automatically tag and index content with meta data that spans a large number of concepts. We propose a scalable framework that relies on the definition of a lexicon of semantic concepts, learning model representa-tions of these concepts, detecting these concepts in videos and then using these detection to create a semantic space. Processing in this space can lead to many new and exciting applications. We evaluate some applications in the context of the NIS T TRECVID benchmark effort.
We propose a framework that characterizes multimedia content using a semantic space and then permits search, re-trieval, indexing, classification and clustering in the seman-tic space. This results from the following processing steps: 1. Concept Lexicon Design: The first step is to design the 2. Concept Modeling: The next step is to learn low-level 3. Model Vector Construction: Once concept models cov-4. Model Vector Applications: Once a video shot is repre-
The model vector approach can be applied to any domain as long as a lexicon can be defined over concepts in the do-main that can be learnt and detected. For example, we used support vector machines (SVMs) [10] for modeling visual concepts while the same result could be achieved with any classifier that produces a confidence measure to help build the model vector. The models developed then help create the model vector representation which maps data items into a model vector space. The advantage of the model vec-tor representation is that it captures the concept labeling broadly across an entire lexicon. It also captures the un-certainty of the labels by incorporating confidence scores rather than using simple binary labels. Finally, it provides a compact storage-efficient representation that enables effi-cient indexing using straightforward computation of model vector distances. Once model vectors are extracted, complex similarity operations can be replaced by simple and inexpen-sive vector operations in the semantic space, which enhances the scalability of the database system. For example, range queries or nearest-neighbor queries with respect to complex semantic similarity can be performed using the simple Eu-clidean distance between model vectors. The model vec-tor space can further be indexed using data structures and methods designed specifically for optimized query execution in multi-dimensional spaces (see Section 1.2). This allows development of efficient and effective systems for similarity searching, relevance feedback, classification, clustering and filtering that operate at a semantic level.
The problem of multimedia semantic modeling has been addressed in a number of ways relying on manual, semi-automatic, or fully-automatic methods. The use of manual annotation tools allows humans to manually ascribe labels to multimedia documents. However, manual cataloging is a very expensive and time consuming process. It is also sub-jective leading to incomplete and inconsistent annotations. Fully-automatic approaches based on statistical modeling of low-level audio-visual features have also been investigated for detecting generic frequently observed semantic concepts such as indoors, outdoors, nature, man-made, faces, people, speech, music, etc. There are two distinct schools of thought for modeling these concepts. In one, each concept is treated uniquely and the modeling process draws heavily on domain knowledge, manually enforced constraints and other infor-mation that can only be applicable for the concept at hand. The low-level features extracted in this case are also very specific for each such concept. The literature in this area is rich. The other school of thought is to use generic machine learning algorithms coupled with standard off the shelf low-level media features and let the learning algorithm figure out the specific feature properties that help build the model for the concept [7]. The advantage with this latter approach is that it is scalable to a large number of concepts. Towards this end a variety of classification techniques have been in-vestigated in this context based on the static or temporal nature of the underlying media features extracted and the concept characteristics [1, 4, 5, 6].

Indexing of multimedia documents for fast search and re-trieval has also received much attention in the literature. Considerable amount of work has focused on efficient index-ing in multi-dimensional vector spaces. Approaches include specialized data structures, such as the R-tree and its vari-ants [3], as well as methods for indexing objects in general metric spaces [2, 9]).

In general, computational efficiency and fast query execu-tion are notoriously difficult to achieve in high-dimensional spaces, such as the model vector space we propose but a combination of sampling, dimensionality reduction and multi-dimensional indexing techniques is typically an approach that achieves reasonable scalability. While we realize that scalability is a very important issue, we note that all of the above indexing approaches can be transparently applied once we have constructed our model vector representation, and are thus considered complementary, and out of scope, with respect to this paper.
In this paper, we propose a novel framework for describing and indexing multimedia documents in terms of their mem-bership to a predetermined lexicon of semantic concepts. We investigate the extraction of semantic model vectors using statistical modeling approaches, and taking into account un-certainty, reliability, and relevance of the semantic detectors. We study the properties of the model vector representation and consider lexicon design and model vector normaliza-tion approaches. Finally, we explore the application of the model vector framework to semantic retrieval, classification and clustering. We validate the proposed approaches em-pirically and observe significant performance improvements compared to alternative state-of-the-art methods. To sum-marize, our specific contributions are as follows:
Let C = { l 1 ,l 2 ,...,l K } denote a lexicon of K concepts, where l m is the label of the m th concept. We refer to lexi-con C also as semantic basis .Let D be the set of K concept detectors, where d m is the detector corresponding to concept l m in lexicon C .Let c m [ j ] give the confidence of detection of concept l m by detector d m in item j , where without loss of generality we assume that c m  X  [0 , 1], and c m =1gives highest value of confidence of detection of l m .Wethende-fine model vectors as follows:
Definition 1. Given a semantic basis C and correspond-ing detectors D , defined as above, we define the K -dimensional model vector for item j with respect to lexicon C as
Definition 2. Given two items A and B and a semantic basis C , we define the semantic similarity between A and B with respect to C to be the fraction of semantic classes that both A and B belong to, or alternatively: 1 where Pr ( A | S m ) denotes the probability that item A be-longs to the m -th semantic class denoted by S m .
If we assume item independence and interpret the seman-tic detection scores c m [ A ]as Pr ( A | S m ), then the semantic similarity reduces simply to inner products of model vectors, as follows:
We now list several properties and advantages of the model vector representation:
There is a slight abuse of notation here since in effect A and B denote both items and random variables. However, in general the semantic similarity is well defined, and applies both to individual objects, such as multimedia documents, and to entire classes of objects, such as semantic categories
The generation of model vectors involves two stages of processing: (1) apriori learning of detectors and (2) concept detection and score mapping to produce model vectors. The output of the detectors is transformed in a mapping process to produce the model vectors.
The generic framework for modeling semantic concepts from multimedia features [5] includes an annotation inter-face, a learning framework for building models and a detec-tion module for ranking unseen content based on detection confidence for the models Positive examples for interesting semantic concepts are usually rare. The concept learning process uses ground-truth labeled examples as training data for building statistical models for detecting semantic con-cepts. We construct a set of K binary detectors, each cor-responding to the presence or absence of a distinct concept from the lexicon. We have experimented with different clas-sification algorithms and found support vector machine clas-sifiers to perform better for video concept modeling. Con-cepts in our lexicon occur at global or image levels or sub-frame levels i.e. regions. For this we extract the following setoffeaturesfromtheimageaswellasupto5mostdomi-nant regions in the image marked automatically by bounding boxes proceeding image segmentation 2 We used the follow-ing descriptors: color correlogram (166-D), co-occurrence texture (96-D), edge histogram (64-D), and moment invari-ants for shape (6-D). For more details, see [5].
We use a training set with manually annotated and marked regions to learn the SVM models. For the experiments in this paper we have reported results using the radial basis kernel function defined in Equation 3: Assuming that we extract features for color, texture, shape, structure etc. it is important to fuse information from across these feature types. One way is to build models for each fea-ture type including color, structure, texture and shape and combine their confidence scores post-detection. We also ex-periment with early feature fusion by combining multiple feature types at an early stage to construct a single model across different features. Alternately we can simply con-catenate one or more of these feature types (appropriately normalized). Different combinations can then be used to construct models and the validation set is used to choose the optimal combination. This is feature selection at the coarse level of feature types. Based on our experimentation of early feature fusion [5] we chose to combine the features mentioned in 3.1. Performance of SVM classifiers can vary significantly with variation in parameters of the models. For parameter tuning and validation purposes, we use average precision to measure the retrieval effectiveness and detec-tion performance. Let R be the number of true relevant documentsinasetofsize S ; L the ranked list of documents returned. At any given index j let R j be the number of rel-evant documents in the top j documents. Let I j =1ifthe
In this paper we only report experiments for visual concept models, learnt from visual features extracted from keyframes Concept f v Concept f v Concept f v Airplane 185 0.1296 Animal 596 0.0156 Beach 164 0.1218 Bill Clinton 192 0.0516 Building 1273 0.0509 Car 1565 0.0487 Cartoon 262 0.0294 Cityscape 427 0.0123 Cloud 282 0.0971 Crowd 899 0.2003 Desert 79 0.0880 Face 26670 0.4776 Female Face 4010 0.1788 Fire 88 0.0032 Flower 172 0.0147 Indoors 10068 0.3742 Land 199 0.0038 Male Face 6152 0.1702 People Event 756 0.1045 People 4773 0.1571 Person 18884 0.0969 Physical Violence 225 0.0014 Podium 80 0.0094 Riot 18 0.0079 Road 808 0.0293 Rock 124 0.0497 Sky 1333 0.1619 Smoke 55 0.0034 Snow 314 0.0183 Sport Event 1232 0.3774 Tree 700 0.0547 Truck 181 0.0025 Water Body 574 0.0618 Weather News 208 0.8454 set at the depth of 1000 documents is also reported as the validity v . j th document is relevant and 0 otherwise. Assuming R&lt;S , the non-interpolated average precision (AP) is defined as We reduce parameter sensitivity and dependence on any sin-gle feature type but data dependency is harder to deal with.
Table 1 shows the lexicon of 46 concepts that we use in the experiments reported in this paper listed alphabetically. An important consideration for choosing the concepts in the lexicon is that when modeled, their performance should be acceptable. Another aspect to consider is the effect of lexi-con size and model vector dimensionality on retrieval effec-tiveness (see Section 5). In many situations, it is not feasible to model and evaluate a large number of detectors and the size of the model vector lexicon is constrained from prac-tical considerations, such as computational time or storage requirements. In such scenarios, it is desirable to form a small lexicon while maximizing its effectiveness. We there-fore consider methods for studying the model vector space for the purposes of reducing overlap among the semantic concepts and maximizing their utility. We would like to pre-serve the semantic meaning of the model vector space, and for this it is more appropriate to do model selection, rather than dimensionality reduction techniques such as PCA.
We consider two approaches for prioritizing dimensions in the model vector space so that the more important ones can be selected. The first approach, frequent model selec-tion advocates selecting the models for the most frequently occurring concepts. The frequency can be measured as the number of relevant examples for the given concept in an an-notated training set. The second approach, Robust model selection , associates the priority for a given model with its performance reliability, which can be measured on an in-dependent validation set. The motivation is that the high-performing models should be preserved.
Once concept models are constructed for all the concepts in the lexicon multimedia documents can now be analyzed, classified and scored using each concept model. We base the scoring on the confidence of detection of each concept. Additionally, we allow the incorporation of detector corre-lations in the mapping process and detector reliability and concept relevance score in the matching process (through score normalization and weighting).

For each of the K detectors a confidence score s k  X  [0 ... 1] is produced for each multimedia document that measures the degree of certainty of detection of concept c k . We base the confidence score on proximity to the decision boundary for each detector, where high confidence score is given for documents far from the decision boundary and low scores given when close to the boundary. Additionally, a validity score indicates how reliable the detector is for detecting its respective concept. The validity is calculated as the average precision on a separate validation set which is different from the one used to select optimal parameters.

The confidence scores c k corresponding to the models d k are mapped to produce the model vectors. This is followed by appropriate normalization to remove bias and optionally by validity weighting to capture relative con-cept importance.
Once documents are indexed into the multi-dimensional model vector space, this enables document processing at a semantic level while using fully automated vector-space pro-cessing techniques. For example, documents can be com-pared, searched, classified, clustered, visualized, or mined by using the corresponding vector-space techniques. The benefits of performing some of the above operations in the semantic model vector space, as opposed to the original low-level feature space, are validated empirically in Section 5.
The first application includes the problem of semantic matching for similarity-based retrieval of multimedia doc-uments. In particular, the distance between model vectors is based on the similarity of the videos with respect to the detector confidence scores. Neural Networks or Gaussian Mixture Models, for example, have a natural interpretation as posterior probabilities. Alternatively, we can consider distance measures based on simple or weighted Euclidean distance of model vectors. Weights can be used to capture relative importance of concepts, reliability of concept detec-tors, or individual user preferences.
Once the model vector space is constructed, it can be treated like any other feature space and we can apply the same classification techniques that were used to learn the models that created the model vector, recursively to the model vector features. This will result in models learnt in model vector spaces. We have used such methods for rare class classification [8] and context modeling and enforce-ment [7]. The main advantage of classification in model vector space is improved classification system scalability, es-pecially with respect to large lexicons. This comes from a reduction in supervision requirements, reduction in stor-age, computational requirements, and through leveraging of inter-conceptual relationships.

Unlike clusters in low-level feature spaces, clusters in model vector spaces signify semantic homogeneity. Our clustering in this space led to the discovery of a cluster of news anchors , sport events , outdoor crowds ,etc. The experiments in this section were performed using the TRECVID 2003 Concept Detection Benchmark 3 corpus pro-vided by the National Institute of Standards and Technology (NIST). This contains a development data set of approxi-mately 60 hours of MPEG video consisting of CNN, ABC, and C-SPAN news broadcasts. We split this into one train-ing set of 36 hours and 3 validation sets: validation set I of 6 hours, validation set II of another 6 hours and finally validation set III of 12 hours. In this paper, the concept models were trained using the training set, optimized for parametric settings using validation set I of 6 hours and the validity measured over validation set II of another 6 hours. Finally, all of the model vector experiments in this section report results on the unseen validation set III. As part of the TRECVID 2003 effort, the entire development set was anno-tated collaboratively by over 100 researchers using a lexicon of more than 100 primary concepts. Of those we modeled 46 visual concepts that had sufficient support in the training set in terms of number of relevant shots.
The experiments below use average precision (as defined in Eq. 4) as the performance measure for evaluation. In the retrieval experiments, for each query topic, each rele-vant video clip is used in turn to query the database. The candidate images are ranked according to their similarity to the query image, and then average precision, AP, is cal-culated at full retrieval depth, thus effectively measuring http://www-nlpir.nist.gov/projects/tv2003/ Figure 1: Retrievaleffectivenessfor12querytopicsus-the area under the precision-recall curve for a given query. The AP numbers are then averaged over all queries for a given topic, yielding an overall average precision score for the topic. Mean Average Precision (MAP) can then be cal-culated as the average AP score across several query topics.
For evaluation, we consider 12 query topics, including ob-jects, sites, and events, and a range of frequent to rare con-cepts. The majority are outside of the 46 concepts modeled explicitly but we have also included some overlapping ones for comparison purposes. In particular, the set of concepts used as query topics is as follows (numbers in parenthesis indicate number of relevant items in validation set III): Pairwise item similarity is computed as an inner product in the feature vector space, corresponding to either low-level visual features or model vectors (see Sections 2.1 and 4.1).
The first experiment compares model vector based re-trieval (MBR) to content-based retrieval (CBR). Overall, the following descriptors are compared: 46-dimensional model vectors, 64-dimensional edge histograms, 166-dimensional color histograms, 166-dimensional color correlograms, and 332-dimensional visual features derived by concatenating and normalizing color correlogram, co-occurrence texture, and edge histogram features. Figure 1 plots the Average Precision (AP) computed for each of the 12 topics, and the overall Mean Average Precision scores are shown in Table 2. Table 2: Mean Average Precision over 12 topics for model vector-based vs. content-based retrieval.

Generally, model vectors outperform all visual features and result in a significantly higher Mean Average Precision. The performance gain in MAP ranges from 25% over the high performing 332-D visual feature to over 100% as com-pared to the simpler edge histogram features.
In the second experiment we investigate the effect of model vector dimensionality on retrieval effectiveness. As described in Section 3.2.1, we consider two main strategies for model selection X  frequent model selection and robust model selec-tion . For comparison purposes, however, we also consider the approach of selecting a random subset of the models, to serve as a baseline reference point. In the experiments below, the pseudo-random prioritization is achieved by al-phabetical ordering of the concepts.

Figure 2 (a) compares the three model selection strate-gies for dimensionality reduction purposes. Each strategy is used to generate a 10-dimensional model vector from the original 46-dimensional one, and the Average Precision is plotted for the 12 query topics. The robust model selec-tion strategy generally gives best performance, outperform-ing frequent model selection by 15% in MAP over the 12 topics, and outperforming pseudo-random selection by 30%.
Figure 2 (b) on the other hand shows the effect on retrieval performance (averaged over the 12 topics) as a function of model vector dimensionality. It is interesting to note that the two primary model selection strategies seem to get satu-rated performance at about half of the original dimensional-ity. Robust selection performs best again, and reaches 90% of top performance with merely 30% of the dimensionality.
We investigated a novel framework for capturing and lever-aging semantics in multimedia databases. The model vector approach uses a concept lexicon as a basis to provide a se-mantic descriptor that can be used in a variety of ways for multimedia indexing, including similarity-based retrieval, rel-evance feedback search and semantic concept classification.
We should note that robust/frequent model selection meth-ods have their caveats as well. In particular, both methods tend to favor models for generic concepts which occur most frequently. These concepts generally have the best perform-ing models but may not have the best discriminatory power, or may not be the most relevant, for a given query topic. This can perhaps explain why the random model selection approach slightly outperformed the other two approaches for a few specific query topics (e.g., boat, rock, and food). In practice, we have found that model reliability is crucial for good performance but model relevance to the query top-ics is just as important, and a balance between the two is therefore essential to the success of the approach. We performed an extensive empirical study to validate the proposed model vector construction and application approaches, emphasizing significant retrieval performance advantages as compared to processing in the low-level visual feature do-main. We also considered the problem of semantic-preserving dimensionality reduction for model vectors and studied the effect of dimensionality on retrieval performance. Future work includes investigating other applications of semantic model vectors, as well as automatic methods for semantic basis selection.
The IBM TRECVID 2003 team (shot segmentation, re-gion segmentation, and annotation).
