 One of the biggest bottlenecks for conversational systems is large-scale provision of suitable content. Our approach readily provides this without the need for custom-crafting. In this demonstration, we present the use of question-answer (QA) pairs mined from online question-and-answer websites to construct system utterances for a conversational agent. Our system uses QA pairs to formulate utterances that drive a conversation in addition to the answering of user questions as has been done in previous work. We use a collection of strategies that specify how and when the different parts of our question-answer pairs can be used and augmented with a small number of generic hand-crafted text snippets to generate natural and coherent system utterances. H.5.2 [ Information Interfaces and Presentation ]: User Interfaces X  Natural language ; I.2.7 [ Artificial Intelligence ]: Natural Language Processing X  Discourse Experimentation; Human Factors; Conversational System; Question-Answer Pairs;
The content used by chatbots such as ALICE [1] is custom-crafted to be as generic and deflective as possible to cover the needs of open-ended conversations. This approach reduces the amount of content that the system needs despite the relatively broad range of user inputs. For this reason, this class of conversational systems is only capable of content-free, small talk. As for systems (e.g., virtual nurse [2], intel-ligent toy [3]) that require content of reasonable depth and breadth to support content-rich conversations, the task of custom-crafting the content becomes impossible.

In this demonstration, we show the use of question-answer (QA) pairs from community-driven question-and-answer web-sites such as AskKids.com and Answers.com as content for  X  Corresponding author.
 our conversational system. By nature, the QA pairs ex-tracted from a particular source on a certain topic are dis-jointed, in that they do not have any temporal or struc-tural information that could immediately lend themselves to straightforwardly building conversations. Our system in-novatively uses the QA pairs to engage the users in coher-ent conversations using a range of different conversational strategies such as  X  X uestion asking X ,  X  X act telling X  and  X  X ues-tion answering X . The system is able to share the initiative with the human users for determining conversation content and direction using these strategies.

This work is an extension of our interactive question an-swering (IQA) system using QA pairs, which was presented as a demo in CIKM 2011 [4]. The main distinctions between our new conversational system and the IQA system are that (1) the IQA system is driven solely by the user X  X  informa-tion seeking needs, and (2) the IQA system always interpret inputs as questions and service them with answers. Overall, the key contributions of this demonstration lie in the con-versational strategies that we describe that specify how the different parts of the QA pairs can be used and combined with a small number of generic hand-crafted fragments to generate natural system utterances. These system contribu-tions, when interplayed with cooperative user inputs, pro-duce seemingly coherent conversations.

We will briefly present the system components and the conversational strategies in Section 2. We then move on to discuss how these components and strategies operate with the help of an actual conversation that took place between a human user and the system in Section 3. We conclude with a demonstration plan.
An overview of the main components of our conversational system is shown in Figure 1. The system is able to either respond to user initiated input, or alternatively, pro-actively make an utterance to initiate or maintain a conversation. A brief description of each component is provided below. Input analysis performs shallow parsing of input to extract weighted terms and the domain(s) they belong to (if appro-priate). The input is analysed to determine if a question has been asked, or a request to stop the conversation has been provided using a dictionary-based approach. Analysis of in-put utterances is relatively shallow, deliberately avoiding any attempt at sophisticated natural language understand-ing for computational efficiency. The input is tagged with parts of speech using FastTag 1 for its speed. Noun phrases are then identified using regular expression patterns. A pro-noun is resolved to the most prominent entity from previous inputs, using a method loosely based on the backward look-ing centering approach [5]. The phrases and words are then assigned weights to reflect their content bearing property using the deviation from Poisson approach [6]. Stopwords are removed by virtue of them being non-content bearing. Context management updates conversational context us-ing information obtained from the parsed input. Context, which is essentially a collection of weighted terms decayed over time, is used to select QA pairs which are sufficiently relevant to the user inputs to generate system utterances. This mechanism ensures that outputs provided by the sys-tem contribute to the appearance of coherence in a conver-sation. Each time a new input is processed, the resulting weighted terms are combined into the existing context. If a term is already present in the context, the weight associated with the recent occurrence is added to the term X  X  existing decayed weight in the context to reinforce what we perceive as an important term. If the term is absent from the con-text, the new term and its weight are added to the context. QA pair retrieval and ranking determines the most rel-evant QA pair from the QA pair collection based on the context. Initially, a set of all candidate QA pairs contain-ing at least one term from the context is retrieved. The relevance of the candidates with respect to the conversa-tional context is then determined in terms of (1) the extent of the overlap of words in the question and answer parts of QA pairs with those in the conversational context, and (2) the string similarity based on edit distance [7] between the question component and the user input. Regarding keyword overlap, the more highly weighted terms from the conversa-tional context that appear in a QA pair, the higher the pair X  X  score will be. The sum of the weights of terms from the con-text that appear in the question as well as the answer of a QA pair is determined. This sum is augmented by term-location, where term matches in the questions are scored more than matches in the answers. At the end of retrieval and ranking, the top scoring QA pair is selected for utter-ance generation.
 Strategiser uses the Conversational strategies and the markwatson.com/opensource Figure 2: The conversation between the system and one of the 11 participants (truncated for brevity). selected QA pair to build output utterances. These utter-ances are placed on a queue for use as system outputs for the current as well as subsequent iterations. A new QA pair is only selected to generate further utterances if the queue is empty or the user poses a question. An example of this is discussed in Section 3. The strategies attempt to recre-ate the types of exchange that occur in human-to-human communications. There are two reactive and five proactive strategies. They can also be divided into progression or con-clusion depending on their roles, to either progress or con-clude a conversation. The strategies also use a small number of generic hand crafted fragments which include speech dis-fluencies, prefixes and suffixes, to produce more natural con-versation [8]. A summary of the seven strategies is provided in Table 1.
We selected a conversation between the system and one of the participants from our evaluation, shown in Figure 2, to illustrate the functioning of our conversational system. The system started the conversation using the SAQ strategy (refer to Table 1) and the randomly selected topic  X  X ugong X  at line 1. The SAQ strategy only generates two system utterances, Strategy Type Role Purpose SAQ (System Asks Question) PA P The system poses questions to the users. one using the question and the second using the answer of the selected QA pair. The first utterance from this strategy was produced at line 1 and the second remained in the queue. The first user input on line 2 may appear to be a question but was not detected as one by the input analysis module. As such, the remaining one utterance in the queue was produced as the system X  X  output at line 3. The QA pair selected to generate these two system utterances is shown below: Q: What is a dugong? A: The dugong is related to the manatee. They look The question was modified using the  X  $ X . Do you know the answer? X  fragment as the system X  X  first utterance, while the answer in the QA pair was prefixed with  X  X rm... $ X . X  to form the system X  X  second utterance. The second user input at line 4 was also not recognised as a question. The strategiser again selected SAQ as the next strategy. This time, the  X  X an you tell me, $ X ? X  fragment was selected to modify the question  X  X re manatees and dugongs curious? X  from a new QA pair to create the system X  X  output in line 5. The user, not knowing what  X  X anatees X  were, posed a more explicit question at line 6, which was this time detected by the system. The remaining utterance in the queue from the SAQ strategy was dropped and the UAQ strategy was selected to generate an answer at line 7. From line 9 to 20, the exchanges between the system and the user were still shaped by the SAQ strategy. Next, the strategiser picked the SSK strategy to manipulate the selected QA pair below: Q: What do blue sharks eat A: Blue sharks, who are often called the wolves of Since there is only one sentence in the answer, this strategy produced only one system utterance at line 21.
We will start the demonstration with a few examples to illustrate the use of the seven strategies to progress and con-clude conversations. In particular, we will highlight the im-portance of context management and the diversity of strate-gies for generating coherent and natural system utterances from disjointed QA pairs. We will switch off the context management module to show to the audience the rapid de-terioration of coherence. The choice of strategies and the generic hand-crafted fragments will be reduced to demon-strate the increase in artificiality of system generated ut-terances. After the guided introduction, we will allow the audience to freely interact with the system using a desk-top browser as well as an Android application, where both are equipped with automated speech recognition (ASR) and text-to-speech (TTS) to support the option of speech-based interaction. We have prepared three videos 2 as a preview of our demonstration. The system featured in these videos uses a text-based interface. ASR and TTS were not yet fully inte-grated into the system during the recording of these videos. This work is partially supported by the Australian Research Council and Real Thing Entertainment Pty. Ltd. under Linkage grant number LP110100050. [1] R. Wallace. The anatomy of a.l.i.c.e. In R. Epstein, [2] T. Bickmore, L. Pfeifer, and B. Jack. Taking the time [3] Z. Chen, C. Liao, T. Chien, and T. Chan. Animal [4] W. Wong, J. Thangarajah, and L. Padgham. Health [5] R. Mitkov. Outstanding issues in anaphora resolution. [6] K. Church and W. Gale. Inverse document frequency [7] V. Levenshtein. Binary codes capable of correcting [8] M. Marge, J. Miranda, A. Black, and A. Rudnicky. http://www.youtube.com/watch?v=SCShDas7XD0 http://www.youtube.com/watch?v=BBSbmHmr0Nk http://www.youtube.com/watch?v=CrXXbQMbO_0
