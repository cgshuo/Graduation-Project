 1. Introduction store huge volume of data in databases containing valuable informa-tion. Evaluation of stored data may lead to discovery of trends and patterns hidden within the data wh ich could significantly enhance research and management. Data mini ng and classification algorithms are becoming increasingly common in different sectors such as banking, insurance, medicine and retailing. Since data mining is a transdisciplinary analytic proces s to explore consistent patterns and relationships, statistics, artificial intelligence techniques, machine learning are involved in the context of this research area. intelligence based predictive data modeling technique because of their predictive performance ( Abbas, 2002; Chou et al., 2004; Delen et al., 2005 ). ANNs may be able to model complex non-linear relationships. But it is not trivial to understand the mechanism hidden within its structure which results in the output. biological neural networks. It consists of interconnected group of artificial neurons. In most cases an ANN is an adaptive system that changes its structure basing on the internal and external informa-tion that flows through the network during the learning process. ANN is highly accurate in classification and prediction of output. However, classification and function approximation concepts of
ANN are usually incomprehensible to the human user. This is because of the fact that typical NN solutions consist of a large number of interacting non-linear elements, c haracterized by large sets of real-valued parameters that are hard to i nterpret. Distributed internal representations make it even harder to understand what an ANN has learned exactly and where it will fail to come up with the correct answer ( Kuttuyil, 2004 ). Because of that, many researchers tend to develop understandable representations of ANNs for human beings.
This can be achieved by extracting IF-THEN type prediction rules from trained ANNs ( Huang and Xing, 2002 ). 2. Background
Algorithmsfor ruleextractionfromANNsare grouped intothree categories named as decompositional, pedagogical and eclectic according to translucency dimension of the classification process.
Translucency is designed to reveal the relationship between the extracted rules and the internal architecture of the trained ANNs.
Decompositional approaches involve rule extraction at the level of hidden and output units, which are mapped in a binary form ( Hruschka and Ebecken, 2006 ). Pedagogical approaches try to map inputs directly into outputs and view ANNs as a black-box. The number of rules and their forms do not directly correspond to the number of weights or the structure of ANN ( Saad and Wunsch, 2007 ). Finally, eclectic approaches incorporate in elements of both pedagogical and decompositionaltechniques. In thisstudy, decom-positional approach is preferred since the main idea behind the proposed novel approach is to reveal the mechanism hidden within the black-box structure of ANNs.

In Santos et al. (2000) authors developed a method for extract-ing accurate and comprehensible rules from ANNs. The proposed method employed a genetic algorithm (GA) to find a good neural network topology. This topology is then passed to a rule extraction algorithm, and the quality of the extracted rules is then fed back to the GA. Mak and Munakata (2002) reviewed and compared the rule extraction capabilities of rough sets with ANNs and ID3. They applied the methods to analyzing expert heuristic judgments. Setiono and Thong (2004) proposed an approach to extract rules from ANNs that have been trained to solve regression problems. The extracted rules divide the data samples into groups. For all samples within a group, a linear function of the relevant input attributes of the data approximates the network output. Elalfi et al. (2004) presented a new algorithm for extracting accurate and comprehensible rules from databases via trained ANN using GA. The GA is used to find the optimal values of input attributes, which maximize the output function of output nodes. Markowska-Kaczmar and Wnuk-Lipinski (2004) presented the method of rule extraction from an ANN based on the genetic approach with Pareto optimization. They described the idea of Pareto optimization and showed the details of developed method. Li and Wang (2004) suggested a hybrid system to extract classification rules from decision table efficiently. Different from the previous works, in their system, ANNs are served only as a tool to reduce the decision table and filter its noises while the final rule set is generated from the reduced decision table by rough sets. Tokinaga et al. (2005) studied ANN rule extraction techniques based on genetic program-ming (GP) to build intelligent and explanatory evaluation systems. They utilized the GP to automate the rule extraction process in the trained ANNs where the statements changed into a binary classi-fication. Hruschka and Ebecken (2006) suggested a clustering-based approach for extracting rules from MLPs related to classifica-tion problems. Their rule extraction algorithm basically consists of two steps. First, a clustering GA is applied to finding clusters of hidden unit activation values. Then classification rules describing these clusters, in relation to the inputs, are generated. Recently Setiono et al. (2009) addressed the generation of comprehensible rule sets from trained ANNs. Their algorithm is particularly appropriate for applications where comprehensibility as well as accuracyisrequired. KahramanliandAllahverdi(2009) presenteda new method that uses artificial immune systems algorithm to extract rules from trained adaptive neural networks. The aim of their study is to develop a new adaptive activation function and a method for rule extraction from trained ANNs.

In this study a new algorithm based on binary PSO is proposed and implemented for rule extraction from trained ANNs. The proposed algorithm is designed as to use the weights of trained ANNs for extracting classification rules. The rule representation of the proposed approach is based on the work of Elalfi et al. (2004) . The presented study in Elalfi et al. (2004) is proposed as a preliminary work of the binary rule representation scheme applied on two simple data sets which have binary classes. There is no rule selection strategy, number of rules which directly affects the testing accuracy in different data sets. Ozbakir et al. (2008) embedded the binary rule representation scheme into ant colony optimization algorithm. However in the present study, various activation functions are considered and experimental design is also performed in order to determine the best parameter settings for
ANNs. Moreover, a classification fitness function is also incorpo-rated into the proposed algorithm in order to perform rule induction. And also apart from the binary classification problems, n-ary classification problems are also included in the scope of the study. Proposed binary PSO algorithm (PSO-miner) is applied to several test problems which have different characteristics to extract accurate classification rules from the trained ANNs. PSO algorithm has been successfully applied to optimization problems and neural network training due to its robustness and simplicity.
PSO has a self update mechanism by means of velocity and has a fewer parameters which must be adjusted. The application of PSO algorithm to classification in the context of data mining is a new researcharea. In thisresearch, the advantages of PSO algorithmand
ANNs are combined so as to produce comprehensible and accurate classification rules. In order to improve the efficiency of proposed binary PSO algorithm, parameters are designed in an adaptive manner. Although there are a few studies in the data mining literature, the results prove the competitiveness of different PSO algorithms in the classification area ( Wang et al., 2007; Holden and
Freitas, 2008; Sousa et al., 2003 ). The main contribution of this study is to present the capability of binary-PSO algorithm to uncover the hidden information in a trained ANN so as to produce accurate and comprehensible classification rules.

The rest of the paper is arranged as follows: Section 3 describes the binary-PSO algorithm that is applied to extracting classification rules from the trained ANNs. Section 4 explains the experimental study on employed data sets. Comparative results with traditional and some other rule based classifiers from the literature are also presented in this section. Finally, Section 5 concludes the present work. 3. Binary-PSO algorithm for classification rule extraction from trained ANNs
Among the various data mining tasks such as clustering and association rule finding, classification attracts special attention which aims to predict the classes of prospective data objects.
Classification is the process of finding a set of models or functions which describe and distinguish data classes or concepts, for the purposeofbeingabletousethemodeltopredictthe classofobjects whose class label is unknown ( Han and Kamber, 2001 ). Classifica-tion formulates a classification model based on the analysis of a set of training data. In classification, a rule generally represents discovered knowledge in the form of IF-THEN rules.

In recent years, there have been numerous attempts for apply-ing several algorithms in data mining to accomplishing classifica-tion task. ANN is one of the most widely used techniques in classification. ANN is a powerful data modeling tool that is able to capture and represent complex input/output relationships. The knowledge acquired by an ANN is codified on its connection weights, which in turn are associated to both its architecture and activation functions ( Andrews et al., 1995 ). In this context, the process of knowledge acquisition from ANNs usually implies the use of algorithms based on the values of either connection weights or hidden unit activations. The algorithms designed to perform such task are generally called algorithms for rule extraction from
ANNs ( Hruschka and Ebecken, 2006 ). The present algorithm uses binary-PSO algorithm for extracting classification rules by using weights of trained ANNs.

The proposed algorithm consists of two main stages. In the first stage, ANN is trained by using binary coded training data set in order to determine the weights of ANN. In the second stage PSO-miner algorithm tries to find the best binary particle which represents a rule so as to maximize the output of ANN by using weights of previously trained ANN. 3.1. Binary representation scheme miner, each attribute of the data set must be decoded as a binary string. Each bit of a string was either 0 or 1 depending on which sub-interval of the original value was located. As an example, if there is an  X  X  X utlook X  X  attribute which takes three values {sunny, overcast, rain}, string (0 1 0) will express that outlook is overcast.
Table 1 shows an example rule representation of binary coding scheme. For the data sets which contain continuous inputs, discretization must be carried out before coding the attribute in binary form. In this study equal-width binning algorithm within
Weka 3.5 data mining software is used for discretization of continuous attributes. After discretization, continuous attribute turns into a categorical attribute and each category can be defined by using binary coding scheme. 3.2. Multi-layer perceptron of simple neurons (called perceptrons) is used. The perceptron computes a single output from multiple inputs by forming a linear combination according to its input weights and then possibly generates the output through some non-linear activation function.
MLP is especially useful for special problems such as classification, recognition and generalization ( Hruschka and Ebecken, 2006 ). A sample MLP structure with two hidden layers is shown in Fig. 1 . two hidden layers as an example, three groups of weights can be obtained: given by w k  X  1 1  X  e t  X  1  X  t  X  x i represents the binary inputs of MLP. The function (Eq. (1)) is an exponential function and the maximum output value is equal to 1.
Finally, for extracting rules between input attributes and the related classes, it is necessary to find the input vector, which maximizesthefunction.Thisisanoptimizationproblemandcanbe 2008 )
Maximize w k x  X  0or1  X  3  X 
In Eq. (3), the objective function (Eq. (1)) is non-linear and the decision variables (Eq. (2)) are defined as binary variables. So this is a non-linear integer optimization problem and PSO algorithm can be applied for solving it. Because, best binary combination of inputs which maximizes ANN output, represents the best rule defining the related class of training data set. So PSO-miner algorithm is executed for each class of the problem in order to explore the pattern hidden within the weights of ANN. 3.3. Binary PSO-miner
PSO is a population based stochastic optimization technique which is originally developed by Eberhart and Kennedy (1995) .By introducing the inertia weight as a new concept, PSO is updated ( Shi and Eberhart 1998a, 1998b ). There are several researches in the literature focused on the development of variants of the classical PSO algorithm in order to improve its performance.
Ratnaweera and Halgamuge (2004) proposed time-varying accel-eration coefficients. Das et al. (2005) introduced a new scheme by a vector differential operator consists of weighted difference of the particles position vectors. Suresh et al. (2008) developed a variant of the basic PSO by defining a momentum factor for position updating and adaptive-inertia factor in velocity updating.
The main idea behind the PSO is motivated by social behavior of organisms such as bird flocking and fish schooling. In PSO, each member is called  X  X article X  and each particle flies around the multi-dimensional search space with a velocity, which is updated in each iteration according to the best solution of the particle achieved so far called particle best (pbest) and the best solution obtained by all particles in the swarm so far called global best (gbest). Velocity values are restricted to some minimum and maximum values. PSO hasa veryfewalgorithmparametersandsimple implementation in contrast to other optimization algorithms. PSO has no overlapping and mutationcalculation.The searchis guidedby the speed andthe direction of the particle. Because of its exploration and exploitation capability, the PSO is considered as an efficient global search algorithm.

In binary-PSO algorithm, a sigmoid function is used to force the real values between 0 and 1 in order to achieve binary solutions. Also a piece-wise linear function is used to force velocity values to be within the maximum and minimum values ( Tas -getiren and Liang, 2004 ). h  X  v Here V max V min are the maximum and minimum velocity values and v k id indicate the computed velocity value. After applying this function, sigmoid function in Eq. (5) is used to scale the velocities between 0 and 1. sigmoid  X  v k id  X  X  1
Velocity update is performed by using Eq. (6). Here r 1 and r are uniform random numbers between 0 and 1; k indicates the iteration number. w is the inertia weight which improves the convergence capability of PSO and controls the effect of previous velocity value on the current value. c 1 and c 2 are acceleration coefficients. pbest and gbest represents the particle and global best solutions, respectively V
In the early stages of the search, considerably high diversity is necessaryto allowexplorationofnew searchareas. However,inthe latter stages of the algorithm, because of the convergence to the near optimal solutions, local search is getting more important for finetuningofthesolutions.Thismeansthatthesystemshouldstart with a high inertia weight for global exploration and the inertia weight should linearly decrease to manage a local search through the end of iterations. Shi and Eberhart (1998b) improved the performance of PSO by using a linearly varying inertia weight over the iterations. w is computed depending on iteration number by using below equation: w  X  X  w 1 w 2  X  Maxiter iter Maxiter  X  w 2  X  7  X 
Here w 1 and w 2 are the constant initial and final values respec-tively. Maxiter indicates the maximum iteration number and iter is defined as the current iteration number. Through the empirical studies, Shi and Eberhart (1998b) observed that the optimal solution could be improved by varying the value of w from 0.9 at the beginning of the research to 0.4 at the end of the research for most problems. c 1 and c 2 are the acceleration coefficients which allow the particle to tune the cognition and social terms, respectively. While c ensures the particle to fly according to its own experience, c provides particle to fly basing on the other particles X  experiences in the swarm. Ratnaweera and Halgamuge (2004) proposed time-varying acceleration coefficients as a new parameter automation strategy for the PSO concept. With a large c 1 and small c beginning, particles are allowed to move around the research space, instead of moving toward the population best. On the other hand,a small c 1 and a large c 2 allowthe particle toconverge intothe global optimum in the latter part of the optimization. c 1 parameters are computed depending on iteration number by using the following equations: c c c , c 2 f and c 1 i , c 2 i denote the final and initial values for c respectively. iter is the current iteration number and Maxiter is the maximumnumber ofallowableiterations as stated before.Velocity is updated by using the piece-wise linear function (Eqs. (10), (4)) v  X  h  X  wv k 1 id  X  D v k 1 id  X  X  10  X 
Finally,positionofparticle i isupdatedbyusingEq.(11).Inorder to update positions, the value obtained by sigmoid function is to be compared with randomly generated U (0,1) value between 0 and 1. Particles obtain new binary values according to this comparison
X  X  (
In the proposed PSO-miner algorithm, binary solution strings are produced based on the quality function ( w k , output function of
ANN). The convergence of the quality value calculated by Eqs. (1) X  (2) to its maximum value 1 indicates a strong relationship between the binary particle representing a rule and its related class. So the particles having higher quality values than a user specified thresh-old value ( b ) are stored for the rule induction procedure. After the completion of PSO-miner iterations, a pool of candidate rules is constituted for the rule set composition. In the rule induction process,rulesareselectedamongthecandidaterulesbasedontheir sensitivity and specificity measures. In this step covering approach is applied for rule selection according to the sensitivity and specificity values of the candidate rules. Starting from the fittest candidate rule, a rule list is generated until all patterns in the training set are classified or there is no candidate rule to evaluate.
When a rule is used to classify a given training instance, one of the four possible concepts can be observed ( Tan et al., 2006;
BaykasogluandOzbakir,2007 ):truepositive( tp ),false positive( fp ), true negative ( tn ) and false negative ( fn ). True positive and true negative concepts express correct classifications where false positive and false negative denote the incorrect classifications.
Sensitivity ( S e ) measures the fraction of actual positive examples that are correctly classified while specificity ( S p ) measures the fraction of actual negative examples that are correctly classified ( Parpinelli et al., 2002 )
S  X  tp  X  fn  X  12  X 
S  X  tn  X  fp  X  13  X 
Using these two concepts, fitness function for composing the best rule set is defined as follows ( Parpinelli et al., 2002 ): Fitness  X  S e S p  X  14  X 
ThemainstepsofPSO-mineralgorithm,whichisusedtofindthe best rule set are given as follows: PSO-Miner algorithm Begin Transform data into binary form Conduct and analyze experimental design Train MLP with best parameter setting Generate weight groups Initialize parameters Set w k as quality function and b  X  0, 9 Set fitness Eq. (16) Randomly generate population of particles
The main stages of the proposed algorithm denoting the integration mechanism between trained ANN and binary PSO-miner are also presented in Fig. 2 . 4. Evaluation of the PSO-miner
The performance of proposed rule extraction algorithm is examined based on 12 data sets obtained from UCI (University ofCaliforniaatIrvine)MachineLearning Repository( http://mlearn. ics.edu//MLRepository.html ). These data sets are determined according to their different characteristics. The main idea behind the selection of data sets is to present the wide application area of proposed algorithm. PSO-miner algorithm can be applied on binary and n-ary classification problems which involve both categorical andcontinuousattributes.Iris,PimaandWBCconsistofcontinuous attributes. Iris and Pima are binary classification problems while
WBChas 3 classes. CRX, ECG and Heart-C consist of both categorical and continuous attributes. The remaining data sets consist of only categorical attributes. Each group of data sets includes binary and n-ary classification problems.

Some of the data sets include missing attributes, but these instances are not removed from the data, only the attribute for which the value is missing is omitted. The continuous attributes in data sets are discretized by equal-width binning approach imple-mented in Weka 3.5 data mining software. Main characteristics of the data sets are summarized in Table 2 . 4.1. Experimental design
The performance of the proposed algorithm is mainly based on the weights of trained ANN. So it cannot be expected to obtain highly accurate rule set from the weights of ANN trained ineffi-ciently. Because, the proposed approach mainly tries to uncover the hidden information within the ANN structure itself. Therefore, the best parameter setting for the ANN training stage must be determined to obtain better classification performance. For this purpose, an experimental design is conducted to identify the best parameters of ANN for each data set. Number of hidden layer { 1 , 2 }, process elements in hidden layer(s), transfer function { sigmoi-daxon , tanhaxon }, maximum number of epochs { 10,000 , 20,000 }, learning rule { momentum, conjugate gradient , quickprob } are defined as factors and corresponding levels in the experimental design. The number of processing elements in the hidden layers is calculated by using Eqs. (15 X 17) ( Johansson et al., 2006 ) h  X  2 rand h  X  h  X  rand  X 
In Eqs. (15 X 17) v is the number of input attributes and c is the number of classes. rand is a random number in the interval [0, 1]. For an ANN with one hidden layer, Eq. (15) is applied to determin-ing the number of processing elements. For ANNs with two hidden layers, the number of processing elements in the first hidden layer is determined by using Eq. (16), and second hidden layer by using Eq. (17).

Multi-layerperceptronistrained onthe binaryinputand output attributes with parameter levels previously determined by using NeuroSolutions 5 software. Best parameter settings of MLPs are obtained according to the mean square errors (MSEs) defined as response factor. Main effects and interactions between factors are taken into consideration while analyzing the effects of parameters on response factor. In order to determine significance of factor effects and interactions on the ANNs performance, ANOVA results are analyzed.Since the experimental design isnot the main focus of this research and due to the space limitations, only the best parameter settings of ANN are included within the scope of this research and presented in Table 3 . 4.2. Experimental setup
Partition of data sets : In ECG dataset, a single partitioning of the data into training and testing sets is used due to the small number of cases. Random 66% of the ECG data is used as training and remaining, 34% is used as testing set. Also single training and testing sets are used in Monks-2 and Spect problems as these were originally partitioned. For the other 9 data sets, a well-known 10-fold cross-validation procedure is applied. Each dataset is partitioned into ten data subsets and the proposed rule extraction algorithm is executed once for each partition. The training set is used to train the algorithm for good learning capability, while the testing set is applied to evaluating the generalization capability of the final rule set obtained by the PSO-miner algorithm.
Performance metrics : In this study, testing accuracy and average number of rules are determined as the performance metrics.
Accuracy measures the ability of the classifier to produce accurate results and can be computed by using equation 20. In ECG and
Monks-2datasets,predictiveaccuraciesareobtainedbyevaluating ten different executions of the algorithm on the same training and testing sets since these data sets are split into a single training and testing sets. The predictive accuracies on the test set of the 10 runs are averaged and reported as the predictive accuracies for all the data sets. Also standard deviations of the corresponding predictive accuracies are calculated Accuracy  X  tp  X  tn tp  X  tn  X  fp  X  fn  X  18  X  Parameter settings : After obtaining the weights from trained MLPs, proposed PSO-miner algorithm is applied for maximizing
Eq. (3). Inbinary-PSO algorithm,numberof particlesand numberof iterations are set to 100 and 1000, respectively. Minimum and maximum velocities are [ 4, 4]. Inertia weight is varied from 0.9 to 0.4 during the search. c 1 parameter takes the value 4 at the beginning of the research and decreases to 0 at the end of the iterations. Also c 2 parameter is varied from 0 to 4. These parameter values are applied to all data sets. 4.3. Performance comparisons The proposed PSO-miner algorithm is implemented by using Delphi 7 programming language and runs are performed on a Intel
Core 2 Duo 2.4 GHz computer with 2 GB RAM. Table 4 summarizes the predictive accuracies, average numberof rules and average CPU times produced by the algorithm.
 first part, four differentrule based algorithmsincluded in Weka 3.5, C4.5 ( Quinlan, 1993 ), PART decision list algorithm ( Frank and
Witten, 1998 ), Decision Table ( Kohavi, 1995 ), NBTree algorithm based on naive Bayes classifiers ( Kohavi, 1996 ) with their default parameter settings in Weka 3.5 are applied to all data sets. In order to be able to compare results, 10-fold cross validation is applied to the data sets except for ECG, Monks-2 and Spect data sets as explained before. Minimum, maximum, average accuracies with standard deviations and average number of rules over 10 runs are presented in Table 5 . In all data sets except Nursery, PSO-miner algorithm performed better than the compared algorithms. Aver-age classification of accuracy of PSO-miner algorithm is consider-ably higher and standard deviation is lower than the other algorithms. In Nursery data set, PART algorithm is slightly better with considerably higher number of rules in the rule set. Average
CPU times are calculated by involving the whole process of producing rule set which consists of binary-PSO algorithm execu-tion for producing candidate rules, rule set induction by using trainingdatasetand evaluationoftestingdataset.Theparticlesize, lengthofparticlewhichdependsonnumberofattributesespecially continuous attributes subject to discretization, number of itera-tions and the size of candidate rules pool are found as highly effective factors on CPU times. Reducing the size of particles and number of iterations without losing efficiency by experimental design for PSO-miner parameters may decrease the CPU times considerably.
 mally distributed, paired-t test can be applied to the compared algorithms and PSO-miner in order to determine whether the difference between the obtained results is statistically significant.
Table 6 shows the p values which present the probability of equivalence of accuracies of the compared algorithms ( a  X  0.05).
Low p -values show that accuracies between compared algorithms are not equivalent. + sign of p -values shows that proposed PSO-miner algorithm performs better while sign means that the compared algorithm has a better performance value. The bolded values in Table 6 present that the difference between results of compared algorithms could not be proved statistically by using predefined significance level. Table 6 shows that only PART algorithm performs better than PSO-miner in terms of accuracy.
In all other data sets, proposed PSO-miner resulted in better accuracy values. However, the compared algorithms produced less number of rules with lower accuracy values. The main factor affecting the size of the rule set is the selection process of the rules from candidate rule set. As described before rules are selected among the candidate rules according to their fitness values. The selection process is repeated until the all patterns in the training data set covered by a rule. In some cases, coverage of all training data causes an increased size of rule set. Decreasing the size of rule set without losing the predictive capability is still an ongoing study of this research.

In the second part of performance comparisons, some of the state-of art population based algorithms and some recently published new approaches are taken into consideration. As it is well known, there are a lot of population based algorithms applied to classification problems in the literature. Especially, the algo-rithms based on swarm intelligence such as Ant-Miner ( Parpinelli et al., 2002 ), ACO-Miner ( Wang and Feng, 2004 ), Threshold ACO-
Miner ( Thangavel and Jaganathan, 2007 ), TACO-Miner ( Ozbakir et al., 2008 ), PSO ( Wang et al., 2007 ), hybrid PSO/ACO2 ( Holden and
Freitas, 2008 ) are selected to compare results. Parpinelli et al. (2002) are the first to develope an ant colony algorithm for data mining called Ant-Miner. Wang and Feng (2004) presented an improved ant colony optimization algorithm (ACO-Miner) so as to overcome the main drawbacks of the Ant-Miner algorithm.
Thangavel and Jaganathan (2007) proposed an enhanced ant colony optimization algorithm by introducing a threshold value during the rule construction in order to reduce the rule length. As mentioned before, TACO-Miner based on touring ant colony optimization algorithm is developed by Ozbakir et al. (2008) . Wang et al. (2007) proposed a PSO based rule extraction algorithm.
Holden and Freitas (2008) introduced hybrid PSO/ACO2 in order to directly deal with both continuous and nominal attribute values. In addition to these swarm intelligence based algorithms, as men-tioned before Kahramanli and Allahverdi (2009) have recently presented an artificial immune systems (AIS) based algorithm to extract rules from trained neural networks. Because of the similar aims of this study and proposed PSO-miner, the results presented by Kahramanli and Allahverdi (2009) are also included in compar-isons. Since most of the compared studies did not present CPU times of their algorithms, comparisons are performed in terms of testing accuracies and average number of rules which are common in all results ( Table 7 ).
 As shown in Table 7 , in all data sets except LBC and Tic-tac-toe,
PSO-miner outperformed the compared algorithms in terms of average testing accuracies. But the size of rule sets mostly greater than the other algorithms. Accuracy is the primary objective in classification problems because of the cost of incorrect classifica-tionsespecially in medicaldatasets. Butthe sizeof rule setsand the rules must be taken into consideration in order to satisfy the comprehensibility. As emphasized before decreasing the size of rule set without decreasing the accuracy for improving compre-hensibility is scheduled as a future work.
 5. Conclusion
The main disadvantage of ANNs is their black-box like structure which does not reveal much about how learning is achieved. In order to overcome with this disadvantage , a new algorithm which is based on binary particle swarm optimization (PSO-miner) is proposed in this paper to discover the hidden knowl edge within ANNs. The proposed algorithm tries to explain the meaning of weights hidden in ANNs in terms of output. By this way, highly accurate, readable and comprehensible classification rul es can be obtained for human beings. In this study, a detailed experime ntal design is also performed to achieve the best ANN performance on classification. PSO-miner algorithm is also compared with traditional classification algorithms and population based algorithms in terms of two different perfor-mancemeasure,testingaccuracyandnumberofrulesinproducedrule set. The data sets are selected according to different characteristics they contain such as continuous  X  categorical attributes, binary X  X -ary classes. In spite of PSO-miner produced slightly higher number of rules, testing accuracy values show considerable difference with compared algorithms. The efficiency and accuracy of the PSO-miner integrated with ANNs are found very promising for classification problems. The reduction of rules in the rule set by using different performance criterion, analyzing the performance of PSO-miner with-out ANN integration and determin ing the best parameter setting of PSO-miner are scheduled as the future work.
 References
