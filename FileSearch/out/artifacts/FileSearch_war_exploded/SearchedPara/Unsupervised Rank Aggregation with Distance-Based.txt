 Alexandre Klementiev klementi@uiuc.edu Dan Roth danr@uiuc.edu Kevin Small ksmall@uiuc.edu Consider the scenario where each member of a panel of judges independently generates a (partial) ranking over a set of items while attempting to reproduce a true underlying ranking according to their level of ex-pertise. This setting motivates a fundamental machine learning and information retrieval (IR) problem -the necessity to meaningfully aggregate preference rank-ings into a joint ranking. The IR community refers to this as data fusion , where a joint ranking is derived from the outputs of multiple retrieval systems. For example, in meta-search the aim is to aggregate Web search query results from several engines into a more accurate ranking. In many natural language process-ing applications, such as machine translation , there has been an increased interest in combining the results of multiple systems built on different principles in an effort to improve performance (Rosti et al., 2007). One impediment to solving rank aggregation tasks is the high cost associated with acquiring full or partial preference information, making supervised approaches of limited utility. For data fusion, efforts to over-come this difficulty include applying domain specific heuristics (Shaw &amp; Fox, 1994) or collecting such pref-erence information indirectly (e.g. using clickthrough data (Joachims, 2002)). In order to address this lim-itation, we propose a general unsupervised learning framework for (partial) rank aggregation.
 Analyzing ranked data is an extensively studied prob-lem in statistics, information retrieval, and machine learning literature. (Mallows, 1957) introduced a distance-based model for fully ranked data and inves-tigated its use with Kendall X  X  and Spearman X  X  met-rics. The model was later generalized to other dis-tance functions and for use with partially ranked data (Critchlow, 1985). (Lebanon &amp; Lafferty, 2002) proposed a multi-parameter extension, where multi-ple modal rankings (e.g. expert opinions) are avail-able and use their formalism for supervised ensemble learning; they also analyzed their model for partially ranked data (Lebanon &amp; Lafferty, 2003).
 The first key contribution of our work is the derivation of an EM-based algorithm for learning the parameters of the extended Mallows model without supervision. We instantiate the model with appropriate distance functions for two important scenarios: combining per-mutations and combining top-k lists. In the context of defining distances between rankings, various metrics have been proposed and analyzed (Critchlow, 1985; Estivill-Castro et al., 1993). Distances over top-k lists, i.e. rankings over the k most preferable objects, re-ceive particular attention in the IR community (Fagin et al., 2003). (Fligner &amp; Verducci, 1986) show that a class of distance functions between full rankings, such as Kendall X  X  and Cayley X  X  metrics, decompose into a sum of independent components allowing for efficient parameter estimation of the standard Mallows model. A second key contribution of our work is the derivation of a novel decomposable distance function for top-k lists. We show it to be a generalization of the Kendall metric and demonstrate that it can be decomposed, enabling us to estimate the parameters of the extended Mallows model efficiently.
 Among recent work, (Busse et al., 2007) propose a method for clustering heterogeneous rank data based on the standard Mallows model. More directly related, many heuristics as well as a number of supervised learning approaches (Liu et al., 2007) exist for rank aggregation, although few learn to combine rankings without any supervision. (Klementiev et al., 2007) frame unsupervised rank aggregation as an optimiza-tion problem specifically for top-k lists, which relies on user-tuned parameters, a form of implicit supervision, whereas we describe a general unsupervised framework that can be instantiated to top-k lists in addition to other settings.
 The remainder of the paper is organized as follows: section 2 formalizes distance-based ranking models and introduces relevant notation. Section 3 derives our EM-based algorithm for learning model parame-ters and specifies the requirements for efficient learn-ing and inference. Section 4 instantiates the frame-work for two common scenarios: permutations (full rankings) and top-k lists. Section 5 experimentally demonstrates the model X  X  effectiveness in both cases. Finally, section 6 concludes the work and gives ideas for future directions. 2.1. Notation and Definitions Let { x 1 ,...,x n } be a set of objects to be ranked, i.e. assigned rank-positions 1 ,...,n , by a judge. We de-note the resulting permutation  X  = (  X  (1) ,..., X  ( n )), where  X  ( i ) is the rank assigned to object x i . Corre-spondingly, we use  X   X  1 ( j ) to denote the index of the object assigned to rank j .
 Let S n be the set of all n ! permutations over n items, and let d : S n  X S n  X  R be a distance function be-tween two permutations. We will require d (  X  ,  X  ) to be a right-invariant metric (Diaconis &amp; Graham, 1977): in addition to the usual properties of a metric, we will also require that the value of d (  X  ,  X  ) does not depend on how the set of objects is indexed. In other words, d (  X , X  ) = d (  X  X , X  X  )  X   X , X , X   X  S n , where  X  X  is defined by  X  X  ( i ) =  X  (  X  ( i )).
 In particular, note that d (  X , X  ) = d (  X  X   X  1 , X  X   X  1 d ( e, X  X   X  1 ), where e = (1 ,...,n ) is the identity permu-tation. That is, the value of d does not change if we re-index the objects such that one of the permutations becomes e and the other  X  =  X  X   X  1 . Borrowing the no-tation from (Fligner &amp; Verducci, 1986) we abbreviate d ( e, X  ) as D (  X  ). In a later section, when we define  X  as a random variable, we may treat D (  X  ) = D as a ran-dom variable as well: whether it is a distance function or a r.v. will be clear from the context. 2.2. Mallows Models While a large body of work on ranking models ex-ists in statistics literature, of particular interest to us are the distance based conditional models first intro-duced in (Mallows, 1957). Let us give a brief review of the formalism and elucidate some of the its properties relevant to our work. The model generates a judge X  X  rankings according to: where Z (  X , X  ) = P  X   X  X  ing constant. The parameters of the model are  X   X  R ,  X   X  0 and  X   X  X  n , referred to as the dispersion and the location parameters, respectively. The distribution X  X  single mode is the modal ranking  X  ; the probability of ranking  X  decreases exponentially with distance from  X  . When  X  = 0, the distribution is uniform, and it becomes more concentrated at  X  as  X  decreases. One property of (1) is that the normalizing constant Z (  X , X  ) does not depend on  X  due to the right invari-ance of the distance function: Let us denote the moment generating function of D under (1) as M D, X  ( t ), and as M D, 0 ( t ) under the uni-form distribution (  X  = 0). Since (1) is an exponential family, Therefore, (Fligner &amp; Verducci, 1986) note that if a distance func-tion can be expressed as D (  X  ) = P m i =1 V i (  X  ), where V (  X  ) are independent (with  X  uniformly distributed) sequently, (3) gives: We will call such distance functions decomposable and will later use (4) in section 4 in order to estimate  X  efficiently. 2.3. Extended Mallows Models (Lebanon &amp; Lafferty, 2002) propose a natural gener-alization of the Mallows model to the following condi-tional model: p (  X  |  X  ,  X  ) = where  X  = (  X  1 ,..., X  K )  X  S K n ,  X  = (  X  1 ,..., X  K R K ,  X   X  0 , p (  X  ) is a prior, and normalizing constant Z (  X  ,  X  ) = P  X   X  X  The rankings  X  i may be thought of as votes of K individual judges, e.g. rankings returned by multi-ple search engines for a particular query in the meta-search setting. The free parameters  X  i represent the degree of expertise of the individual judges: the closer the value of  X  i to zero, the less the vote of the i -th judge affects the assignment of probability.
 Under the right-invariance assumption on d , we can use property (2) to derive the following generative story underlying the extended Mallows model: That is,  X  is first drawn from prior p (  X  ).  X  is then made up by drawing  X  1 ... X  K independently from K Mallows models p (  X  i |  X  i , X  ) with the same location pa-rameter  X  .
 It is straightforward to generalize both Mallows models (Critchlow, 1985), and the extended Mallows models to partial rankings by constructing appropriate dis-tance functions. We will assume this more general setting in the following section. In this section, we derive the general formulation of Expectation Maximization algorithm for parameter es-timation of the extended Mallows models (5), and sug-gest a class of distance functions for which learning can be done efficiently. We then describe an inference pro-cedure for the model. 3.1. EM Background and Notation Let us start with a brief overview of Expectation-Maximization (Dempster et al., 1977) mostly to in-troduce some notation. EM is a general method of finding maximum likelihood estimate of parameters of models which depend on unobserved variables. The EM procedure iterates between: E step : estimate the expected value of complete data log-likelihood with respect to unknown data Y , ob-served data X , and current parameter estimates  X  0 : M step : choose parameters that maximize the expec-tation computed in the E step: In our setting, the K &gt; 2 experts generate votes  X  corresponding to the unobserved true ranking  X  . We will see multiple instances of  X  so the observed data we get are ranking vectors X = {  X  ( j ) } Q j =1 with the corre-sponding true (unobserved) rankings Y = {  X  ( j ) } Q j =1 In the meta-search example,  X  ( j ) i is the ranking of the i -th (of the total of K ) search engine for the j -th (of the total of Q ) query. The (unknown) true ranking corresponding to the j -th query is denoted as  X  ( j ) . 3.2. EM Derivation We now use the generative story (6) to derive the fol-lowing propositions (proofs omitted due to space con-straints): Proposition 1. The expected value of the complete data log-likelihood under (5) is: where the complete data log-likelihood L  X  is: and the marginal distribution of the unobserved data U Proposition 2. T (  X  ,  X  0 ) is maximized by  X  = (  X  1 ,..., X  K ) such that: That is, on each iteration of EM, we need to evaluate the right-hand side (RHS) of (8) and solve the LHS for  X  i for each of the K components. 3.3. Model Learning and Inference At first, both evaluating the RHS of (8) and solving the LHS for  X  i seem quite expensive ( &gt; n !). While true in general, we can make the learning tractable for a certain type of distance functions.
 In particular, if a distance function can be decomposed into a sum of independent components under the uni-form distribution of  X  (see section 2.2), property (4) may enable us to make the estimation of the LHS ef-ficient. In Section 4, we show two examples of such distance functions (for permutations and top-k lists). In order to estimate the RHS, we use the Metropo-lis algorithm (Hastings, 1970) to sample from (5). The chain proceeds as follows: denoting the most recent value sampled as  X  t , two indices i,j  X  { 1 ,...,n } are chosen at random and the objects  X  t ( i ) and  X  a = p (  X  0 t |  X  ,  X  ) /p (  X  t |  X  ,  X  )  X  1 the chain moves to  X  If a &lt; 1, the chain moves to  X  0 t with probability a ; otherwise, it stays at  X  t . (Diaconis &amp; Saloff-Coste, 1998) show quick convergence for Mallows model with Cayley X  X  distance. While no convergence results are known for the extended Mallows model with arbitrary distance, we found experimentally that the MC chain converges rapidly with the two distance functions used in this work (10 n steps in experiments of Section 5). As the chain proceeds, we update the distance value with the incremental change due to a single transposi-tion, instead of recomputing it from scratch, resulting in substantial savings in computation.
 Alternatively, we also found (Section 5.1) that a combi-nation of rankings  X  i weighted by exp(  X   X  i ) provides a reasonable and quick estimate for evaluating the RHS. Sampling or the suggested alternative RHS estimation used during training is also used for model inference. Overcoming the remaining hurdle (the LHS estima-tion) in learning the model efficiently depends on the definition of a distance function. We now consider two particular types of (partial) rankings: permutations, and top-k lists. The latter is the case when each judge specifies a ranking over k most preferable objects out of n . For instance, a top-10 list may be associated with the 10 items on the first page of results returned by a web search engine. For both permutations and top-k lists, we show distance functions which satisfy the decomposability property (Section 2.2), which, in turn, allows us to estimate the LHS of (8) efficiently. 4.1. Combining Permutations Kendall X  X  tau distance (Kendall, 1938) between per-mutations  X  and  X  is a right-invariant metric defined as the minimum number of pairwise adjacent transpo-sitions needed to turn one permutation into the other. Assuming that one of the permutations, say  X  , is the identity permutation e (we can always turn one of the permutations into e by re-indexing the objects without changing the value of the distance, see Section 2.1), it can be written as: where 1 V i (  X  ) = P j&gt;i I (  X   X  1 ( i )  X   X   X  1 ( j )). V dependent and uniform over integers [0 ,n  X  i ] (Feller, (Fligner &amp; Verducci, 1986), equation (4) gives: E ( D K ) is monotone decreasing, so line search for  X  will converge quickly. 4.2. Combining Top-k Lists We now propose an extension of the Kendall X  X  tau dis-tance to top-k lists, i.e. the case where  X  and  X  indi-cate preferences over different (possibly, overlapping) subsets of k  X  n objects.
 Let us denote by F  X  and F  X  the elements in  X  and  X  respectively, noting that | F  X  | = | F  X  | = k . We define Z = F  X   X  F  X  , | Z | = z , P = F  X  \ F  X  , and S = F  X  \ F  X  (note that | P | = | S | = k  X  z = r ). We treat  X  and  X  as rankings, which for us will mean that the smallest index will indicate the top, i.e. contain the most preferred object. For notational convenience, let us now define the augmented ranking  X   X  as  X  augmented with the elements of S assigned the same index ( k + 1), one past the bottom of the ranking as shown on Figure 1 (  X   X  is defined similarly). We will slightly abuse our notation and denote  X   X   X  1 ( k + 1) to be the set of elements in position ( k + 1).
 Kendall X  X  tau distance D K is naturally extended from permutations to augmented rankings.
 Definition 1. Distance  X  D K (  X   X  ,  X   X  ) between augmented rankings  X   X  and  X   X  is the minimum number of adjacent transpositions needed to turn  X   X  into  X   X  . ric, thus we will again simplify the notation denoting it as  X  D K (  X   X  ). This distance can be decomposed as:  X 
D K (  X   X  ) = where Decomposing  X  D K (  X   X  ), the second term is the minimum number of adjacent transpositions necessary to bring the r elements not in Z (grey boxes on Figure 1) to the bottom of the ranking. The third term is the minimum number of adjacent transpositions needed to switch them with the elements in  X   X   X  1 ( k + 1), which would then appear in the correct order in the bottom r po-sitions. Finally, the first term is the adjacent transpo-sitions necessary to put the k elements now in the list in the natural order.
 It can be shown that the random variable sum-mands comprising  X  D K (  X   X  ) are independent when  X   X  is uniformly distributed. Furthermore,  X  V i and  X  U j are uniform over integers [0 ,k  X  i ] and [0 ,z ], with equation (4) gives: If r = 0 (i.e. the augmented rankings are over the same objects), both the distance and the expected value re-duce to the Kendall distance results. Also, if z = 0 (i.e. the augmented rankings have no objects in common),  X  D number of adjacent transpositions needed to move the r = k objects in  X   X   X  1 ( k + 1) into the top k positions. E (  X  D K ) is decreasing monotonically, so we can again use line search to find the value of  X  . Notice that the expected value depends on the value of z (the number of common elements between the two permutations). We will compute the average value of z as we estimate the RHS of (8) and use it to solve the LHS for  X  . We demonstrate the effectiveness of our approach for permutations and top-k lists considered in Section 4. 5.1. Permutations We first consider the scenario of aggregating permuta-tions. For this set of experiments, the votes of K = 10 individual experts were produced by sampling stan-dard Mallows models (1), with the same location pa-rameter  X   X  = e (an identity permutation over n = 30 objects), and concentration parameters  X   X  1 , 2 =  X  1 . 0,  X  permutations uniformly randomly). The models were sampled 10 times, resulting in Q = 10 lists of permu-tations (one for each  X  X uery X ), which constituted the training data.
 In addition to the sampling procedure described in Section 3.3 to estimate the RHS of (8), we also tried the following weighted Borda count approximation. For each  X  X uery X  q , we took the K votes and mixed them into a single permutation  X   X  q as follows: a score for each of the n objects is computed as a weighted combination of ranks assigned to that object by indi-vidual judges. The aggregate permutation  X   X  q is ob-tained by sorting the objects according to their re-sulting scores. The weights are computed using the current values of the model parameters as exp(  X   X  The rationale is that the smaller the absolute value of  X  i , the lower the relative quality of the ranker, and the less it should contribute to the aggregate vote. Fi-nally, the RHS for the i -th component is computed as the distance from its vote to  X   X  q averaged over all Q queries.
 We also tried using the true permutation  X   X  in place of  X   X  q to see how well the learning procedure can do. At the end of each EM iteration, we sampled the current model (5), and computed the Kendall X  X  tau distance between the generated permutation to the true  X   X  . Figure 2 shows the model performance when sampling and the proposed approximation are used to estimate the RHS. Although the convergence is much faster with the approximation, the model trained with the sampling method achieves better performance approaching the case when the true permutation is known. 5.2. Top-k lists In order to estimate the model X  X  performance in the top-k list combination scenario, we performed data fusion experiments using the data from the ad-hoc re-trieval shared task of the TREC-3 conference (Har-man, 1994). Our goal here is to examine the behav-ior of our approach as we introduce poor judges into the constituent ranker pool. In this shared task, 40 participants submitted top-1000 ranking over a large document collection for each of the 50 queries. For our experiments, we used top-100 ( k = 100) rank-ings from K = 38 of the participants (two of the par-ticipants generated shorter rankings for some of the queries and were not used) for all Q = 50 queries. We replaced a specific number K r  X  [0 ,K ] of the partici-pants with random rankers (drawing permutations of k documents from the set of documents returned by all participants for a given query uniformly randomly). We then used our algorithm to combine top-k lists from K r random rankers and ( K  X  K r ) participants chosen at random.
 We measure performance using the precision in top-{ 10 , 30 } documents as computed by trec eval 2 from the TREC conference series. As a baseline, we use CombMNZ rank suggested in (Klementiev et al., 2007). It is a variant of a commonly used CombMNZ (Shaw &amp; Fox, 1994). Given a query q for each doc-ument x in the collection it computes a score N x  X  P i =1 ( k  X  r i ( x,q )), where r i ( x,q ) is the rank of the document x in the ranking returned by participant i for the query q , and N x is the number of participants which place x in their top-k rankings. The aggregate ranking is obtained by sorting documents according to their scores. Intuitively, the more component rankers rank a document highly the higher it appears in the aggregate ranking.
 Figure 3 shows that our algorithm learns to discount the random components without supervision substan-tially improving over the baseline as K r  X  K . We also compared our results with the ULARA algo-rithm (Klementiev et al., 2007). These results were not included since we found ULARA to be too sen-sitive to user-defined parameters (an implicit form of supervision) with results varying between competitive with our model to comparable with CombMNZ rank . 5.3. Model Dispersion Parameters In order to demonstrate the relationship between the learned dispersion parameters of the model,  X  , and the relative performance of the constituent rankers, we also conducted a meta-search experiment. First, we generated Q = 50 queries which result in an unam-biguous most relevant document and submitted them to K = 4 commercial search engines. For each engine, we kept the 100 highest ranked documents (10 pages of 10 documents each) after removing duplicates, and unified URL formatting differences between engines. We measure performance with Mean Reciprocal Page Rank ( MRPR ), which we define as mean reciprocal rank of the page number on which the correct docu-ment appears.
 Table 1 shows MRPR of the four search engines and their corresponding model parameters. As expected, the results suggest a correlation between the magni-tude of the dispersion parameters and the relative sys-tem performance, implying that their values may also be used for unsupervised search engine evaluation. Fi-nally, our model achieves MRPR = 0 . 92 beating all of the constituent rankers. We propose a formal mathematical and algorithmic framework for aggregating (partial) rankings without supervision. We derive an EM-based algorithm for the extended Mallows model and show that it can be made efficient for the right-invariant decomposable distance functions. We instantiate the framework and experi-mentally demonstrate its effectiveness for the impor-tant cases of combining permutations and combining top-k lists. In the latter case, we introduce the notion of augmented permutation and a novel decomposable distance function for efficient learning.
 A natural extension of the current work is to instanti-ate our framework for other types of partial rankings, as well as to cases where ranking data is not of the same type. The latter is of practical significance since often preference information available is expressed dif-ferently by different judges (e.g. top-k rankings of dif-ferent lengths).
 Another direction for future work is to extend the rank aggregation model to accommodate position de-pendence. In IR, more importance is generally given to results appearing higher in the rankings. Within our framework one may be able to design a distance function reflecting this requirement. Additionally, the quality of votes produced by individual components may depend on the rank, e.g. in the top-k scenario some rankers may be better at choosing few most rel-evant objects, while others may tend to have more rel-evant objects in the k selected but may not rank them well relative to one another. This case may be mod-eled by adding a dependency on rank to the dispersion parameters of the model.
 In addition, this framework appears promising for a number of applications. Besides the NLP problems mentioned before, such as learning to combine out-put from multiple machine translation systems, one interesting setting may be domain adaptation . Here, the task is to adapt a hypothesis trained with ample labeled data from one input distribution to a second distribution where minimal training data is available. When the hypothesis is a trained aggregate ranker, we expect the relative expertise of its components to change and can use our approach to reweigh them ac-cordingly.
 We would like to thank Ming-Wei Chang, Sariel Har-Peled, Vivek Srikumar, and the anonymous reviewers for their valuable suggestions. This work is supported by NSF grant ITR IIS-0428472, DARPA funding un-der the Bootstrap Learning Program and by MIAS, a DHS-IDS Center for Multimodal Information Access and Synthesis at UIUC.
 Busse, L. M., Orbanz, P., &amp; Buhmann, J. M. (2007).
Cluster analysis of heterogeneous rank data. Proc. of the International Conference on Machine Learning (ICML) .
 Critchlow, D. E. (1985). Metric methods for analyz-ing partially ranked data , vol. 34 of Lecture Notes in Statistics . Springer-Verlag.
 Dempster, A. P., Laird, N. M., &amp; Rubin, D. B. (1977). Maximum likelihood from incomplete data via the
EM algorithm. Journal of the Royal Statistical So-ciety , 39 , 1 X 38.
 Diaconis, P., &amp; Graham, R. L. (1977). Spearman X  X  footrule as a measure of disarray. Journal of the Royal Statistical Society , 39 , 262 X 268.
 Diaconis, P., &amp; Saloff-Coste, L. (1998). What do we know about the Metropolis algorithm? Journal of Computer and System Sciences , 57 , 20 X 36.
 Estivill-Castro, V., Mannila, H., &amp; Wood, D. (1993).
Right invariant metrics and measures of presorted-ness. Discrete Applied Mathematics , 42 , 1 X 16. Fagin, R., Kumar, R., &amp; Sivakumar, D. (2003). Com-paring top k lists. SIAM Journal on Discrete Math-ematics , 17 , 134 X 160.
 Feller, W. (1968). An introduction to probability theory and its applications , vol. 1. John Wiley and Sons, Inc.
 Fligner, M. A., &amp; Verducci, J. S. (1986). Distance based ranking models. Journal of the Royal Statis-tical Society , 48 , 359 X 369.
 Harman, D. (1994). Overview of the third Text RE-trieval Conference (TREC-3).
 Hastings, W. K. (1970). Monte carlo sampling meth-ods using markov chains and their applications. Biometrika , 57 , 97 X 109.
 Joachims, T. (2002). Unbiased evaluation of retrieval quality using clickthrough data. SIGIR Workshop on Mathematical/Formal Methods in Information Retrieval .
 Kendall, M. G. (1938). A new measure of rank corre-lation. Biometrika , 30 , 81 X 93.
 Klementiev, A., Roth, D., , &amp; Small, K. (2007). An unsupervised learning algorithm for rank aggrega-tion. Proc. of the European Conference on Machine Learning (ECML) (pp. 616 X 623).
 Lebanon, G., &amp; Lafferty, J. (2002). Cranking: Com-bining rankings using conditional probability models on permutations. Proc. of the International Confer-ence on Machine Learning (ICML) .
 Lebanon, G., &amp; Lafferty, J. (2003). Conditional models on the ranking poset. The Conference on Advances in Neural Information Processing Systems (NIPS) (pp. 431 X 438).
 Liu, Y.-T., Liu, T.-Y., Qin, T., Ma, Z.-M., &amp; Li,
H. (2007). Supervised rank aggregation. Proc. of the International World Wide Web Conference (WWW) .
 Mallows, C. L. (1957). Non-null ranking models. Biometrika , 44 , 114 X 130.
 Rosti, A.-V. I., Ayan, N. F., Xiang, B., Matsoukas,
S., Schwartz, R., &amp; Dorr, B. J. (2007). Combining outputs from multiple machine translation systems. Proc. of the Annual Meeting of the North American
Association of Computational Linguistics (NAACL) (pp. 228 X 235).
 Shaw, J. A., &amp; Fox, E. A. (1994). Combination of mul-tiple searches. Text REtrieval Conference (TREC)
