 When searching a temporal document collection, e.g., news archives or blogs, the time dimension must be explicitly in-corporated into a retrieval model in order to improve rel-evance ranking. Previous work has followed one of two main approaches: 1) a mixture model linearly combining textual similarity and temporal similarity, or 2) a probabilis-tic model generating a query from the textual and temporal part of a document independently. In this paper, we com-pare the effectiveness of different time-aware ranking meth-ods by using a mixture model applied to all methods. Exten-sive evaluation is conducted using the New York Times An-notated Corpus, queries and relevance judgments obtained using the Amazon Mechanical Turk.
 Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Experimentation, Performance Keywords Time-aware ranking, Temporal similarity
We deal with a retrieval task that a query is explicitly provided with time, i.e., containing temporal information needs. In this case, the time dimension must be incorpo-rated into a retrieval model in order to improve relevance ranking. Consider a query containing the temporal expres-sion  X  X ndependence Day 2009 X , an existing retrieval model relying on term matching will fail to retrieve a document mentioning  X  X uly 4, 2009 X , although two temporal expres-sions refer to the same date. Hence, when dealing with the time dimension, time uncertainty should be taken into ac-count because any two temporal expressions can be relevant even they are not equally written.

The previous time-aware ranking methods [1, 2, 3, 4, 5] are based on two main approaches: 1) a mixture model linearly combining textual and temporal similarity, or 2) a proba-bilistic model generating a query from the textual and tem-poral part of a document independently. It is shown that time-aware ranking performs better than keyword-based rank-ing. To the best of our knowledge, an empirical comparison of different time-aware ranking methods has never been done before. In this paper, we will evaluate the effectiveness of different time-aware ranking methods: L M T[1],L MT U[1], TS [4], TSU [4], and FuzzySet [3] using the same dataset, and we will give a brief discussion of the evaluation.
A temporal expression or the publication date of a doc-ument is represented as a quadruple [1]: ( tb l ,tb u ,te where tb l and tb u are the lower bound and upper bound for the begin boundary of a time interval respectively. Simi-larly, te l and te u are the lower bound and upper bound for the end boundary of a time interval. A temporal query q is composed of keywords q text and temporal expressions q time Adocument d consists of the textual part d text , i.e., a bag of words, and the temporal part d time composed of the publica-tion date PubTime ( d ), and temporal expressions mentioned in the document X  X  contents ContentTime ( d )or { t 1 ,...t
To be comparable, we apply a mixture model to linearly combine textual similarity and temporal similarity for all ranking methods. Given a temporal query q ,adocument d will be ranked according to a score computed as follows: where the mixture parameter  X  indicates the importance of textual similarity S ( q word ,d word ) and temporal similarity S ( q time ,d time ). Both similarity scores must be normalized, e.g., divided by the maximum scores, in order to the final score S ( q,d ). S ( q word ,d word ) can be measured using any of existing text-based weighting functions. S ( q time ,d measure temporal similarity by assuming that a temporal expression t q  X  q time is generated independently from each other, and a two-step generative model was used [1]:
Linear interpolation smoothing will be applied to give the probability P ( t q | t d ) for an unseen query temporal expression t in d . In the next section, we will explain how to estimate P ( t q | t d ) for different time-aware ranking methods.
The time-aware ranking methods we study differ from each other in two main aspects: 1) whether or not time un-certainty is concerned, and 2) whether the publication time or the content time of a document is used in ranking. L M ignores time uncertainty and it exploits the content time of d .L M T can be calculated as: where t d  X  ContentTime ( d ), and the score will be equal to 1 iff a temporal expression t d is exactly equal to t q .L MT cerns time uncertainty by assuming equal likelihood for any time interval t q that t q can refer to, that is, t q = t The simplified calculation of P ( t q | t d )forL MT Uisgivenas: where t d  X  ContentTime ( d ). The detailed computation of | t q  X  t d | , | t q | and | t d | canbereferredto[1].
TS ignores time uncertainty. P ( t q | t d ) TS can be computed lication time of d instead of the content time as computed for L
M T. TSU exploits the publication time of d as done for TS, but it also takes time-uncertainty into account. P ( t q | is defined using an exponential decay function: where t d = PubTime ( d ), DecayRate and  X  are constant, 0 &lt;DecayRate&lt; 1and  X &gt; 0, and  X  is a unit of time distance. The main idea is to give a score that decreases proportional to the time distance between t q and t d .The less time distance, the more temporally similar they are.
FuzzySet measures temporal similarity using a fuzzy mem-bership function and it exploits the publication time of d for determining temporal similarity. P ( t q | t d ) FuzzySet The parameters a 1 ,a 4 ,n,m are determined empirically.
The New York Times Annotated Corpus is used and 40 queries from [1] obtained using the Amazon Mechanical Turk. Note that, a standard dataset, e.g., TREC, is not applicable because queries are not time-related, and judgments are not targeted towards temporal information needs.
 Documents are indexed and retrieved using the Apache Lucene version 2.9.3. There are two modes for retrieval [1]: 1) inclusive and 2) exclusive .For inclusive , both query terms and a temporal expression comprise a query q text .For ex-clusive , only query terms constitute q text ,andatemporal expression is excluded from q text . The baseline is the textual similarity S ( q word ,d word ), i.e., the Lucene X  X  default weight-ing function, using inclusive mode denoted TFIDF-IN. The smoothing parameter is set to 0.1. Parameters for TSU are DecayRate =0 . 5,  X  =0 . 5, and  X  =6months. Pa-rameters for FuzzySet are n =2, m =2, a 1 = a 2  X  (0 . 25 ( a 3  X  a 2 )), and a 4 = a 3 +(0 . 50  X  ( a 3  X  a 2 )). The effectiveness is measured as the precision at 1, 5 and 10 documents (P@1, P@5 and P@10), mean average precision (MAP), and mean reciprocal rank (MRR). The sensitivity of the effectiveness to the mixture parameter  X  is depicted in Figure 1. The results show that the effectiveness of L M TandL MT Ude-creases when  X  is increased, whereas the effectiveness of all other methods slightly increases with the value of  X  . Table 1 shows the best performing results of each method. In general, all time-aware ranking methods outperform the baseline significantly, except L M T. For each time-aware rank-ing, the effectiveness when retrieved using exclusive is better Figure 1: Sensitivity of P@10 and MAP to the mix-ture parameter  X  for both retrieval modes.
 Table 1: Effectiveness of different ranking methods, in bold indicates statistically improvement over all other methods using t-test ( p&lt; 0 . 05 ).
 than inclusive . TSU performs best among all methods in both inclusive and exclusive modes, and it outperforms all other methods significantly for P@1, MAP and MRR.
Time-aware ranking methods show better performance compared to a method based on only keywords. When the time-uncertainty is taken into account, the effectiveness is improved significantly. Even though TSU gains the best performance among other methods, the usefulness of TSU is still limited for a document collection with no time meta-data, i.e., the publication time of documents is not available. On the contrary, L M TandL MT U can be applied to any doc-ument collection without time metadata, but the extraction of temporal expressions is needed.
