
Supervised learning is a classic data mining problem where one wishes to be be able to predict an output value associated with a particular input vector. We present a new twist on this classic problem where, instead of having the training set contain an individual output value for each in-put vector, the output values in the training set are only given in aggregate over a number of input vectors. This new problem arose from a particular need in learning on mass spectrometry data, but could easily apply to situations when data has been aggregated in order to maintain pri-vacy. We provide a formal description of this new prob-lem for both classification and regression. We then examine how k -nearest neighbor, neural networks, and support vec-tor machines can be adapted for this problem.
Supervised learning is a classic data mining problem where one wishes to be able to predict an output value as-sociated with a particular input vector . A predictor is con-structed via the use of a training set , which consists of a set of input vectors with a corresponding output value for each. This predictor can then be used to predict output values for future input vectors where the output values are unknown. If the output data is continuous, this task is referred to as re-gression . If the output data is nominal, this task is referred to as classification [14].

An important application that we are currently engaged in is the analysis of single particle mass spectrometry (SPMS) data. A typical SPMS dataset consists of a series of mass spectra, each one of which is associated with an aerosol particle. One important goal to the SPMS commu-nity is to be able to use the mass spectrum associated with an individual aerosol particle to be able to predict some other quantity associated with that particle. For example, we are interested in being able to identify the quantity of black carbon (BC) associated with an individual aerosol particle. While SPMS data provides detailed mass spectra for individual aerosol particles, these spectra are not quanti-tative enough to allow one to precisely identify the amount of BC present in a particle. On the other hand, filter-based machines can collect quantitative BC data, but in aggregate form. These devices allow one to determine how much BC has been observed in aggregate over a particular time span, typically on the order of an hour. SPMS data, on the other hand, may be collected for individual particles (non-aggregate data) many times per minute. Our goal is to be able to predict the quantity of BC present in an individual aerosol particle. Therefore, the mass spectra associated with individual particles become our input vectors, and the quan-tities of BC become our output values. This would appear to be a traditional regression problem, but there is a key dif-ference. The challenge that we face is that we do not have a single output value for each input vector. Instead, each output value in our training set represents the sum of the true output values (which are unknown to us) for a series of input vectors in our training set. We wish to learn a predic-tor that will still produce individual output values for each new input vector, even though the training set only contains these output values in aggregate.

We therefore present a new supervised learning problem, which we refer to as the aggregate output learning problem . We develop both a classification and a regression version of it, and show how a number of popular supervised learning algorithms can be adapted to build predictors on data of this sort. While we arrived at the need for this algorithm from a particular scientific application, this framework would eas-ily apply to training data which has been aggregated for pur-poses of privacy preservation. We should point out that tra-ditional algorithms could be used on this data if the input vectors were aggregated to the same granularity as the out-put values, but this ignores useful individual data that could be used to improve the quality of the predictor.

There are three key contributions of this paper. First, we present a formal framework for this new machine learn-ing problem. Second, we adapt three classic algorithms, namely k -nearest neighbor, neural networks, and support vector machines, for use under this scenario and show that they perform the task well. Finally, as this new machine learning problem does not seem to have been considered before, this paper opens up research opportunities for the adaptation of other popular algorithms or invention of new ones to help solve this problem.

In the next section, we examine previously related work on this subject. We then follow it by precisely defining the aggregate output learning problem, and then present the de-tails for how a number of standard supervised learning al-gorithms can be adapted to work for this problem. Finally, we present experiments on a number of datasets to show the efficacy of our approach.
The aggregate output learning problem certainly bears some similarities with other well-known learning problems, but has significant differences as well. The unsupervised learning problem has no output values at all, whereas the supervised learning problem has a distinct output value for each individual input vector in the training set [9, 18, 20]. Semi-supervised learning [2, 3] describes a scenario some-what between the two, where some of the input vectors have associated output values (as in supervised learning), but oth-ers do not (as in unsupervised learning). This is rather dis-tinct from our aggregate output learning problem where all input vectors are associated with an output value, but multi-ple input vectors map to the same output value which repre-sents the sum of the actual (unknown) output values. More-over, our problem is different from the others described above in that the granularity of the output values is different in the training set than in the test set. In the training set, output values are aggregated over multiple input vectors. In the test set, each input vector has its own output value.
Other forms of aggregate learning seem to have been ex-amined, though they differ from the form we discuss here. Arminger et. al. propose using log-linear models to disag-gregate data with a similar model to ours, but their frame-work is based on the idea of filling in missing data in the training set. Their approach does not seem to generalize easily to a test set [1]. McGrogan et. al. consider an ap-proach where the training set contains an individual output value for each input vector, but this output value is an ag-gregate over multiple measurements [13]. Yang et. al. look at learning with aggregates only in order to preserve privacy [21]. An approach by Chen et. al. examines learning from multiple aggregate tables each derived from an underlying common dataset [4]. This probabilistic approach is different from our scenario in this paper in that we do not assume that the input vectors within an individual aggregation collection
Table 1. Sample regression training and test sets. In the training set, output values are known only in aggregate. share feature values. This last difference also contrasts our approach with a number of ideas from the statistical litera-ture such as iterative proportional fitting [12].
We now move on to provide a formal framework for the problems that we consider.
Table 1 shows a sample dataset for this framework. Sup-pose that we are given a training set that consists of input vectors { x ci } , where each x ci has an unknown real-valued output value y ci . We are given, however, a set of aggre-gate output values y c , where we know that for a fixed c , y c = P i y ci . (The subscript c indicates an aggregate col-lection, and the subscript i identifies a particular data point within that collection.) The goal is the same as for the tra-ditional regression problem. We wish to learn a predictor f , using the training set only, that performs well on unseen test data drawn from the same source. In other words, for a test input vector x with output value y , we desire f ( x )  X  y . (The precise criterion varies with the learning algorithm.) Note that f operates on a single input vector and produces a single output value, though the training set contains output values aggregated over multiple input vectors. The test set contains unaggregated output values.
Though regression is perhaps the more natural approach for thinking about the aggregate output learning problem, we present a classification version of it as well.
First, we point out that the traditional classification prob-lem, in general, allows each input vector to belong to one of
Table 2. Sample classification training and test sets. In the training set, classifications are known only in aggregate. an arbitrary number of classes. We constrain ourselves in this paper to the binary classification problem, where each input vector belongs to one of two possible classes.
Table 2 shows a sample dataset for our framework. Sup-pose that we are given a training set of input vectors where each has an unknown output value (also known as the class label). This output value is a  X  X es X  or a  X  X o, X  depending on to which class its corresponding input vector belongs. The training set is divided into collections of input vectors where aggregate output values are known for each collec-tion. More precisely, we suppose that our training set con-sists of input vectors x ci , where the subscript c indicates to which collection the input vector belongs, and the subscript i identifies a particular input vector within that collection. We further suppose that we are given a set of aggregate out-put values y c and  X  y c , where for an individual collection c , y is the number of  X  X es X  values and  X  y c is the number of  X  X o X  values. The goal is the same as for the traditional classifi-cation problem. We wish to learn a predictor f , using the training set only, that performs well on unseen test data pre-sumably drawn from the same source. In other words, for a set of test input vectors { x j } with unknown output values { y j } , we desire f ( x j ) = y j often. (The precise definition of  X  X ften X  varies with the learning algorithm.) Note that f operates on a single input vector and produces a single output value, though the training set contains output values aggregated over multiple input vectors.
We now describe in detail how three popular supervised learning techniques can be updated for the aggregate output learning problem, for classification and regression scenar-ios. k -nearest neighbor is an exceedingly simple algorithm to use, and its adaptation is similarly straightforward. Sup-port vector machines require the formulation of a quadratic programming optimization problem, and so we present new reformulations of these optimization problems to address our scenario. Neural networks traditionally use the back-propagation algorithm [14, 17] to find the local minimum for a quadratic loss optimization problem. We present mod-ifications to the classic backpropagation algorithms to han-dle our new problem, and similarly show how radial basis networks can be adapted for the regression problem.
In each case, we present classification first, then regres-sion. This is for purposes of readability: for most algo-rithms, the classification approaches are more well known. However, for our particular application (described in Sec-tion 1), the regression problem is more critical.
It should be noted that we make no claims that these new approaches are optimal techniques for solving the aggregate output learning problem. We believe that one of the main contributions of this paper is the formulation of this new problem for the community as well as for our particular ap-plication, and therefore we present a first effort at solving this problem via modifications to traditional algorithms. 4.1. k -Nearest Neighbor: Classification
The k -nearest neighbor algorithm is a remarkably simple yet effective approach for classification [9, 18, 20]. The algorithm requires the choice of a parameter k , representing the number of neighbors to be used, and a distance metric for quantifying the difference between input examples. In the traditional supervised learning approach, for a particular test input vector its k nearest neighbors in the training set are determined. As each of these nearest neighbors already has an output value, the test point is assigned the output value represented by a majority of the nearest neighbors.
Our adaptation of k -nearest neighbor, in both the classi-fication and regression case, is exceedingly straightforward and perhaps obvious. We present it here as an instructive example to help reinforce our general approach before ad-dressing the more complex algorithms. We also present it for experimental comparison purposes.

For the classification version of the aggregate output learning problem, for a particular test input vector one can find a set of k nearest neighbors in the training set in pre-cisely the same way as one does for the traditional algo-rithm. The difference is that each nearest neighbor x ci be-longs to a set of training input vectors for which only an ag-gregate y c and  X  y c is known. We resolve this by creating an artificial output value for each nearest neighbor x ci , which is defined as the proportion of  X  X es X  classifications for the entire collection to which it belongs. In other words, if we define n c to be the number of input vectors x ci in aggregate collection c , we define for each input vector x ci an artifi-cial output value of  X  y ci = y c n k nearest neighbors to produce our estimated y for our test point. If this is greater than one-half, we classify the test point as a  X  X es X ; otherwise, we classify it as a  X  X o. X  Note that if one has knowledge that leads one to believe that the test set has a different ratio of  X  X es X  to  X  X o X  than the training set does, one can change the threshold accordingly.
This approach is mathematically equivalent to thinking of  X  X es X  as a 1 ,  X  X o X  as a 0 , and applying the regression technique described below. 4.2. k -Nearest Neighbor: Regression
The k -nearest neighbor algorithm can also be used for traditional regression problems. Instead of using a major-ity rule amongst the neighbors, the output values from all nearest neighbors are averaged together.

Adapting the regression form of k -nearest neighbor for our aggregate output learning problem is quite similar to the adaptation we do for classification. Again, we point out that k -nearest neighbor is a particularly simplistic approach: we demonstrate this for instructional purposes before proceed-ing to more complex algorithms. For a particular test input vector one can find a set of k nearest neighbors in the train-ing set in precisely the same way as one does for the tradi-tional algorithm. The difference is that each nearest neigh-bor x ci belongs to a set of training input vectors for which only an aggregate y c is known. We resolve this by creat-ing an artificial output value for each nearest neighbor x which is defined as the average of the output value across the entire aggregate collection to which it belongs. In other words, if we define n c to be the number of input vectors x in aggregate collection c , we define an artificial output value  X  y ci = y c n c . We then average  X  y ci over all k nearest neighbors to produce our estimated y for our test point.

This approach is mathematically equivalent to prepro-cessing the training set by assigning to each point an out-put value equal to the average output value for its aggregate collection, and proceeding with the traditional k -nearest neighbor algorithm. A considerable deficiency with using k -nearest neighbor in this way is that the algorithm does not allow the learner flexibility in distributing the aggregate output value for a collection unevenly throughout the points in that collection. This issue is addressed well, however, by our neural network and support vector machine approaches.
We first describe the traditional neural network for clas-sification [14, 17] to establish our notation. We will be changing some of the notation that we used in the k -nearest neighbor case as we define the neural networks, as our pri-mary goal is to make each algorithm as simple and under-standable as possible. We are given an input vector x , where x represents the i -th component of the vector x . Each input dimension connects to a series of hidden nodes with weights w ij . An activation function g (  X  ) , typically a sigmoid in practice, is used to process the output of each node. The out-put of each hidden node is denoted as a j . Each hidden node, in turn, connects to a series of output nodes with weights v jk . The output from each output node o k is similarly pre-processed with the same activation function g (  X  ) . A sigmoid typically has a constant threshold parameter. We adopt the usual strategy of representing that parameter via an artificial input dimension of constant value [14, 17]. More precisely, the output for a particular output node o k is determined as o k = g ( P j v jk a j ) , and the output for a particular hidden node a j is determined as a j = g ( P i w ij x i ) .
For the aggregate output learning problem, we wish to retain this traditional neural network. The test set will con-sist of individual points, so a network of this form makes sense. The training procedure must differ, however, since the training set contains outputs for aggregate collections instead of for individual points. We therefore derive an up-date to the traditional backpropagation algorithm [14, 17].
The traditional backpropagation algorithm requires, for a particular input vector x , the comparison of an output o with the actual output y k . Neural networks allow for multi-ple outputs, which we have not addressed in our framework or other algorithms in this paper. Since including multi-ple outputs is straightforward for neural networks, we leave this possibility in as we work though our derivations. We therefore define y k to be the k -th desired output. The key difference we face from the traditional approach is that we only have an output y k for an aggregate collection that con-tains a number of input vectors. For a particular aggregate collection, we will use the notation x `i to represent the ` -th input vector X  X  i -th component. Similarly, we represent the output of each hidden node for each input vector as a `j = g ( P i w ij x `i ) , and output k for an entire aggregate collection as o k = P ` g ( P j v jk a `j ) . This is similar to the traditional approach, but the presence of the summation over the subscripts ` requires us to develop modifications to backpropagation to handle this new learning problem.
In order to determine the optimal weights, we start with the output layer. For a particular aggregate collection, the error is defined as: where we define e k to be the difference between the ex-pected output and the actual. Denoting fixed indices by cap-ital letters, we find the gradient by taking the partial deriva-tive with respect to a particular weight v JK as: We therefore define the propagation update rule for v JK as: where  X  is a learning rate parameter [17]. Similarly, we can derive an update rule for each weight w IJ as: We therefore define the propagation update rule for w IJ as With these update rules, we proceed in a similar fashion to traditional neural network backpropagation. For each ag-gregate collection, we determine the output from the neural network for each point, aggregate, and compare with the expected output for that collection. The backpropagation update rules then indicate how to update the weights. We iterate over the dataset repeatedly until the error changes by less than a predefined threshold. The key difference be-tween these update rules and the traditional ones is the ap-propriate usage of the summations over ` , which represent the multiple points in an aggregate collection.

We note that in contrast with the k -nearest neighbor ap-proach described earlier, this approach does not require the total aggregate output for each collection to be averaged evenly across that collection in some fashion. Instead, this approach only attempts to constrain the total output across a collection to approximate that in the training set.
In order to use neural networks for regression, we adopt the radial basis function network approach [10]. In this sce-nario, under the traditional approach we are given an input vector x , where x i represents the i -th component of the vec-tor x . Each input dimension connects to a series of hidden nodes with weights w ij . The output of each hidden node (denoted as a j ) is the distance between the input vector x and the associated weights w  X  j , post-processed by a radial basis function. A linear combination of the outputs from the hidden nodes (with weights v j ) yields the output from the network. We adopt the usual strategy of representing the threshold term in this linear combination via an additional hidden node that always outputs a value of 1 [14].
More precisely, the output o associated with a particular input vector x is determined as o = P j v j a j , where the output for a particular hidden node a j is determined as where  X  is a parameter. For the aggregate output learning problem, we wish to use this same network structure. As in the classification case, the test set will consist of individual points, so a network of this form makes sense. The training procedure must be reexamined, however, since the training set contains outputs for aggregate collections instead of for individual points.

The traditional approach for training RBF networks is to first choose the weights for the hidden nodes via a cluster-ing algorithm. The output of each hidden node is effectively a measure of how close an input vector is to the point rep-resented by the weights for that node. Therefore, choos-ing hidden nodes whose weights represent  X  X rototypes X  for points in the training set makes sense [10]. This means that this stage of the training process does not need to change at all for our aggregate output learning problem: the differ-ence in our training set and a traditional one lies in the fact that the output values are aggregated, but not the input vec-tors. It is precisely because clustering is an unsupervised procedure that we can leverage it unchanged.

The second stage of training an RBF network, once the weights for the hidden nodes have been determined, is to find optimal values for the weights v j . We seek to minimize the error over all aggregate collections. This total error can be represented as where y c is the output value for aggregate collection c , a is the output from hidden node a j associated with the ` -th input vector in aggregate collection c , and (with a slight abuse of notation), `  X  c represents the indices of the data associated with aggregate collection c . The summation over c is understood to run over all aggregate collections.
The weights from the first layer of the network remain fixed, so the terms y c and a `j in the above error are fixed. Optimizing for the best values of v j is therefore a straight-forward unconstrained quadratic optimization problem.
As in the classification case, this new version of an RBF is quite similar to the traditional methodology, and the al-gorithms for using it are similar. But again, it should be pointed out that this new approach differs from the original in that it does not constrain the output from each individ-ual input vector to match a predetermined output, but rather constrains sums of the outputs from collections of input vec-tors to match given training set values.
In developing an SVM approach for solving the classi-fication version of the aggregate output learning problem, we observe that the problem is similar in some ways to the semi-supervised learning problem [2, 3]. The semi-supervised learning problem consists of both labeled and unlabeled training data, and the goal is to use the unlabeled data to improve classification accuracy over using just la-beled data. In our problem, none of the data is labeled in-dividually, but a count of the number of labels of each type is provided for each aggregate set. These two problems are not the same, but work by Bennett and Demiriz on the semi-supervised problem [2] yields insights on how to appropri-ately adapt linear SVMs for use with unlabeled data. Our approach heavily leverages their ideas. Therefore, we only consider linear support vector machines in this work.
We again shift our notation slightly for clarity of exposi-tion. The standard SVM for classification [6, 19] is where the subscript i ranges over all training rows, x i rep-resents a particular training input vector, and the vector w and scalar b represent the coefficients of the separating hy-perplane.  X  i is a measure of the error associated with the output from input vector x i , and C is a user chosen parame-ter that balances the tradeoff of accuracy against overfitting. y is a 1 or a  X  1 , depending on to which class the training
For the aggregate output learning problem, we do not know to which class each training point belongs. We do know how many points from each class that there are sup-posed to be in each aggregate collection, though. Therefore, similar to Bennett and Demiriz [2], we modify the above quadratic program to the following mixed integer program. Here, we use the indicator variable d i to be a 1 if the point is in class 1 and 0 if the point is in class  X  1 : The constant M is chosen to be sufficiently large so that if d = 0 , then  X  i = 0 satisfies the first constraint. Similarly, if d i = 1 , then z i = 0 satisfies the second constraint.  X  and z i represent the misclassification errors for each point, measured as a traditional SVM would. In this case, how-ever, since we do not know in advance to which class each point belongs, the error is effectively taken to be the mini-mum error for either of the two classes. The subscript c is used to represent an individual aggregate collection; `  X  c represents the indices of all input vectors associated with collection c , and y c represents the actual number of points associated with class 1 for collection c . The term  X  c works to ensure that the number of points assigned to each class is consistent with the aggregates provided for the training set.  X  c is the difference between the predicted and the ac-tual count of the number of points in class 1 for an aggregate collection c . We therefore sum this error over all points and add it to the objective function, multiplying it by a param-eter D to balance the importance of matching the desired aggregate accuracy level for each collection.

The solution to this optimization problem can be found via any mixed integer quadratic programming solver. This approach is somewhat slow, however, and we acknowledge that a faster algorithm can likely be constructed. For exam-ple, the semi-supervised work by Bennett and Demiriz was sped up in two fashions. First, they used the popular substi-This transforms this mixed integer quadratic program into a mixed integer linear program. Furthermore, Fung and Man-gasarian [8] reformulated this problem as a concave mini-mization problem and used a successive linear approxima-tion algorithm. Such an approach might work here as well. That is outside the scope of this particular paper, however, whose role is to present the framework for our new learning problem and to look at some initial efforts in solving it. We have therefore chosen to present a formulation as similar as possible to traditional SVMs. Nonetheless, leveraging ap-proximation approaches similar to the ones described above would be worthy of examining in future work.
Developing a version of support vector regression (SVR) for the aggregate output learning problem is considerably simpler than for classification. The standard linear SVR ap-proach [6, 19] is expressed as: where the subscript i represents a particular training set row, x represents a particular training input vector, and the vec-tor w and scalar b represent the coefficients of the regression surface. y i represents the desired output value for each in-put vector.  X  i and z i serve to measure how far the predicted output value is from the actual; the optimization problem ensures that for each i , either  X  i or z i is zero depending on whether the predicted value is too small or too large. C is a user chosen parameter that balances the tradeoff of accuracy against overfitting, and  X  is a user chosen parameter repre-senting the size of the  X  X one of insensitivity X  within which errors do not contribute.

The aggregate output version of SVR does not have an individual y i for each input vector x i . Instead, each ag-gregate collection contains an individual aggregate output value y c . Therefore, we can modify the SVR formulation to constrain (with slack) the outputs from all points within an
Table 3. MSE for three datasets using aggre-gate k -nearest neighbor algorithm. aggregate collection to sum to the appropriate total:
The subscript c is used to represent an individual aggre-gate collection; `  X  c represents the indices of all input vectors associated with collection c .

As in the classification case, this quadratic program can be solved by any off-the-shelf quadratic programming solver. Considerably faster algorithms for SVR are well known [5, 16], and so one or all of them might be adaptable to work with our formulation here. Similarly, our approach could likely be adapted to work with nonlinear SVMs.
The main contributions of this paper are in proposing our new machine learning problem, and in posing some initial attempts at solving it. All three of the algorithms proposed here are natural generalizations of well-known algorithms, namely variations to k -nearest neighbor, neural networks, and support vector machines. Each of these new variations applies exactly the same philosophy to the aggregate out-put learning problem that the original algorithms do to the traditional supervised learning problem. In some sense, it is somewhat unclear as to what purpose experiments would serve. Since we pose a new learning problem, there are no other algorithms in the literature which are appropriate for comparison purposes. We can compare these algorithms with each other, but it is well known that different algo-rithms perform better on different datasets. However, we do see (at least for regression) a simpler  X  X xperimental con-trol X  technique which might be appropriate for comparison purposes, which we describe later. We therefore focus our experiments on the regression case, especially as this is the one which is most appropriate for our application.
Since we are unable at the moment to release our SPMS data, we present in this paper data from three well-known publicly available datasets. The first, auto-mpg [15], pre-dicts miles per gallon based on seven variables including cylinders, origin, model year, and acceleration. Although the dataset included a car name variable, we ignored it be-cause it was not numeric. The second dataset, housing [15] is the classic  X  X oston Housing Data. X  This dataset is used to predict the median value of owner-occupied homes in Boston based on thirteen variables including the crime rate, the non-retail business acreage, the average number of rooms, and so on. The final dataset, cpu-small [7], measures the portion of time (%) that cpus run in user mode based on fourteen variables. Variables include number of reads be-tween system memory and user memory, number of writes between system memory and user memory, number of sys-tem read calls per second, and so on. There were 398 in-stances in the auto-mpg dataset, 506 in the housing dataset, and 300 in the cpu-small dataset (we chose a small subset of size 300 from the original, which had 8192 examples).
None of the above datasets have aggregate outputs. They are traditional regression datasets in that they contain an output value for each input vector. Therefore, we use them for experiments by creating aggregate training sets. Af-ter separating training data from test data under a cross-validation framework, we group together multiple input vectors in the training set and aggregate their output values together. This transforms the training set into one appropri-ate for the aggregate output learning problem, and leaves us with a traditional test set for measuring success. This tech-nique for creating artificial aggregate datasets gives us the capability to run multiple experiments, each with different characteristics. Specifically, we vary the dataset in two dif-ferent ways, each of which could potentially influence the performance of an aggregate output learning algorithm.
First, we vary the size of the aggregate sets, i.e., the number of rows in the original dataset whose outputs are summed to form each aggregate set. For the traditional su-pervised learning problem, all aggregate sets are of size 1. Note that the set size is essentially an upper bound on how much information is lost due to aggregation. For simplicity, all aggregate sets that we generate for a particular dataset have the same size (except for possibly the last one).
Second, we vary the amount of randomness in the ag-gregation. In order for us to be able to learn anything from aggregate data, we have been making the assumption that points within an aggregate set are somewhat related. If this assumption were invalid, the problem would seem unsolv-able; we would end up with aggregate sets where each col-
Table 4. MSE for three datasets using aggre-gate and control neural network algorithms. lection of input vectors varied over the range of the dataset, and each aggregate output value would therefore be approx-imately the same. Said differently, we assume that each aggregate set is different from the others in a way that pro-vides structure to help us learn from the data. We therefore vary the level of disorder in the data for experimental pur-poses in order to measure this effect. To do so, the original data is first sorted by output value. Individual data points in the training set (input vectors and output values together) are randomly chosen in pairs and swapped. After a number of random pairs have been swapped, the points are taken in order starting from the top of the dataset to create the aggregate groups. Large numbers of swaps therefore corre-spond to relatively randomized aggregate groups, whereas low numbers of swaps correspond to highly ordered aggre-gate groups. The  X  X andomness X  value seen in our exper-imental results refers to the number of pairs that we ran-domly swapped before aggregating the data.

As stated above, there are no algorithms that we know of that make sense to compare our new algorithms with, since the aggregate output learning problem is new. We can, how-ever, compare to the following simple technique. Assuming that we start with an aggregate training set (which is, of course, the problem which we are trying to solve), we cre-ate a new training set where the input vectors are the same, but each input vector is assigned its own individual output value which is the average of the known aggregate output value for the collection. This new dataset thus resembles a traditional supervised learning dataset, and thus traditional algorithms can be used on it. Of course, using traditional al-gorithms overconstrains the problem, as any such algorithm will try to find a predictor that matches each input vector in the training set individually to the average output value for its collection. Nonetheless, this technique requires no new algorithms, and so it seems as though it is a worthy experi-mental control. (We note that an alternative approach might seem to be to aggregate the input vectors within each ag-gregate set together in order to match the aggregated output values. This would work for training purposes, but not for testing, where the goal is to do prediction of output values for individual input vectors.)
For all experimental results, five-fold cross-validation was used. (We were running enough experiments that the savings in time over ten-fold cross-validation was conve-nient.) All fields in all datasets were normalized by sub-tracting the mean and dividing by the standard deviation; regression accuracy was measured via mean squared error.
In looking at our experimental results, it is tempting to compare test set accuracies across algorithms, i.e. to com-pare the results from neural networks with k -nearest neigh-bor. We emphasize that such comparisons are not valid. Our purpose in running these experiments is to show how our technique varies with different aggregate set sizes, and with varying amounts of randomness among the collections. Therefore, we pick a simple set of parameters for each algo-rithm, and generally leave them fixed throughout the exper-iments (we discuss these in more detail below). All three of these algorithms have considerable capability for being tweaked to improve the results. One could try a variety of values for k for the k -nearest neighbor algorithm, for ex-ample, or one could vary the number of hidden nodes in the neural network. In order for comparisons across algo-rithms to be valid, we would have had to make an attempt to optimize parameters across all algorithms to get the best possible results. We have not done so. Again, our purpose is to be able to look at each algorithm and observe its behav-ior on variations of the data, and to make comparisons with a control version of the algorithm with a similar set of pa-rameters. Comparisons within the support vector machine results, for example, are completely valid and worthwhile. Comparing the SVM results with the neural network results does not make sense because we have not optimized the pa-rameters for either appropriately.

First, we present the results from k -nearest neighbor, where we fixed k = 5 for all experiments. Note that for k -nearest neighbor, the control method is mathematically equivalent to our algorithm (see the end of Section 4.2). We thus only provide one set of experiments for k -nearest neighbor, whereas for the other algorithms, we show two.
Table 3 shows the results from running k -nearest neigh-bor on our three datasets. We see that regression error in-creases as aggregate set size increases, which makes sense. As the aggregate set size increases, we are throwing more information out of the training set. Similarly, we see re-gression error increase as the amount of randomness in the aggregate sets increases. This makes sense as well. For highly ordered aggregate sets, within each aggregate set the (unknown) output values are quite similar to each other. Re-placing each with the average for the aggregate set is a good approximation in this case. On the other hand, for highly random aggregate sets, assigning each point an output value which is the average of its aggregate set makes considerably less sense. As discussed earlier, these k -nearest neighbor results are a worthwhile benchmark for understanding our experimental techniques, but it is the results for neural net-works and SVMs that illustrate the power of our approach.
We therefore present results from the neural network and support vector machine experiments. For the neural net-works, we used a learning rate of 1  X  10  X  5 and a conver-gence tolerance of 0 . 001 . The hidden nodes were deter-mined via k-means clustering on the input vectors, and for each cluster  X  was determined to be the average distance from each point in that cluster to the center. We arbitrarily fixed the number of hidden nodes to be 12. For the SVMs, we used the quadratic programming solver CPLEX [11] to handle the optimization. The loss insensitivity parameter  X  was set to 0 . We varied the parameter C in order to achieve the right balance of margin separation vs. data fitting. In principle, this should have been done on a tuning set, pulled out of the training set, for each individual experiment to op-timize C . This opened up a complicated discussion as to how this should be done: in our scenario, the tuning set does not structurally mirror the test set. There are many ap-proaches we might have tried. Conveniently, by varying C by orders of magnitude of 10, it was exceedingly clear for each dataset-algorithm pair that one particular value of C optimized nearly all experimental values. Since we looked at the results for a large number of experiments simulta-neously and picked a single value of C for all of them, it was clear that we were not somehow picking C to opti-mize a single particular test set. More careful experiments might change the numbers slightly; they certainly would not change the broad conclusions we reach in understanding the nature of our algorithms.

By comparing the differences between the aggregate al-gorithm and the control algorithm for a given dataset and technique, the patterns are quite clear. For the neural net-work results shown in Table 4, we see that our aggregate al-gorithm outperforms the control algorithm for much of the table. The differences are most pronounced for moderate randomness values. For highly ordered data, our aggregate algorithm performs similarly to (and occasionally worse than) the control algorithm. As in the k -nearest neighbor experiments, this makes sense; when the data is highly or-dered, assuming that the output value for each point is the average of the output values for the aggregate set is a good approximation. For exceedingly random data (randomness value of 2000), our algorithm again performs similarly to the control algorithm. This is likely because with highly random aggregations, there is a considerable loss of in-formation. In this case, the aggregate algorithm does not have enough data to draw better conclusions than the con-trol algorithms. For most of the cases, however, the aggre-gate algorithm performs considerably better than the con-trol. The aggregate approach only rarely performs worse than the control, and not by much. This indicates that in general the aggregate algorithm is a stronger approach. We also observed that the aggregate algorithms tended to run faster than the control algorithms did, which makes sense since the amount of data used is reduced.

Finally, Table 5 shows the results for the SVM aggre-gate algorithm compared with its control. The comparison between the aggregate case and the control case is very sim-ilar to the one for the neural network algorithms, and again illustrates the outcome of our approach. One significant dif-ference appears to be in the exceedingly random cases (ran-domness value of 2000) where the aggregate approach per-forms dramatically better than the control approach. This is likely due to the fact that SVMs inherently avoid over-fitting by regularizing the separating surface, which has a more dramatic impact with noisy data.
We have proposed a new machine learning problem, known as the aggregate output learning problem, that does not seem to have been previously examined in the literature. This problem, though inspired from atmospheric data anal-ysis, could have broad ramifications in working with data masked for privacy purposes. We present a formal frame-work for this problem for both regression and classification, and provide adaptations of k -nearest neighbor, neural net-works, and support vector machines (classification and re-gression for each) to handle the aggregate problem. We summarize a series of experiments for the regression frame-work that show our approach to be highly effective.
For SVM classification, we have shown a new connec-tion between aggregate output learning and semi-supervised learning. The aggregate output learning problem may thus illustrate new insights into semi-supervised learning.
There is considerable future work that could be done. We
Table 5. MSE for three datasets using aggre-gate and control support vector machines. have also proposed algorithms for the classification frame-work: experiments testing these techniques would be worth-while. The support vector machine approaches that we have proposed are all linear, and we would like to develop nonlin-ear versions as well. The SVM community has developed fast algorithms for solving SVMs. Applying those ideas to speed up our algorithms would be worthwhile.
Most of the programming for our experiments, as well as significant assistance with the literature search, was done by a collection of undergraduates as part of a data mining course at Carleton College. We acknowledge and thank Rob Atlas, David Barbella, Deborah Chasman, Mark Dyson, Reid Gilman, Thomas Hagman, Bret Jackson, Daniel Lew, Brandy McMenamy, Peter Nelson, Charles Noneman, Jerad Phelps, Kevin Reschke, Ed Williams, Paul Wilmes, and Kelson Zawack. The efforts by these students were critical to the success of this project. Other portions of this work were funded by NSF ITR grant IIS-0326328.

