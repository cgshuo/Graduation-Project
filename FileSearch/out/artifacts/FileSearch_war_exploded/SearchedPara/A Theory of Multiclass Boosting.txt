 Boosting [17] refers to a general technique of combining rules of thumb, or weak classifiers, to form highly accurate combined classifiers. Minimal demands are placed on the weak classifiers, so that a variety of learning algorithms, also called weak-learners, can be employed to discover these simple rules, making the algorithm widely applicable. The theory of boosting is well-developed for the case of binary classification. In particular, the exact requirements on the weak classifiers in this setting are known: any algorithm that predicts better than random on any distribution over the training set is said to satisfy the weak learning assumption. Further, boosting algorithms that minimize loss as efficiently as possible have been designed. Specifically, it is known that the Boost-by-majority [6] algorithm is optimal in a certain sense, and that AdaBoost [11] is a practical approximation. Such an understanding would be desirable in the multiclass setting as well, since many natural clas-sification problems involve more than two labels, e.g. recognizing a digit from its image, natural language processing tasks such as part-of-speech tagging, and object recognition in vision. How-ever, for such multiclass problems, a complete theoretical understanding of boosting is lacking. In particular, we do not know the  X  X orrect X  way to define the requirements on the weak classifiers, nor has the notion of optimal boosting been explored in the multiclass setting.
 Straightforward extensions of the binary weak-learning condition to multiclass do not work. Requir-ing less error than random guessing on every distribution, as in the binary case, turns out to be too weak for boosting to be possible when there are more than two labels. On the other hand, requiring more than 50% accuracy even when the number of labels is much larger than two is too stringent, and simple weak classifiers like decision stumps fail to meet this criterion, even though they often can be combined to produce highly accurate classifiers [9]. The most common approaches so far have relied on reductions to binary classification [2], but it is hardly clear that the weak-learning conditions implicitly assumed by such reductions are the most appropriate.
 The purpose of a weak-learning condition is to clarify the goal of the weak-learner, thus aiding in its design, while providing a specific minimal guarantee on performance that can be exploited by a boosting algorithm. These considerations may significantly impact learning and generalization be-cause knowing the correct weak-learning conditions might allow the use of simpler weak classifiers, which in turn can help prevent overfitting. Furthermore, boosting algorithms that more efficiently and effectively minimize training error may prevent underfitting, which can also be important. In this paper, we create a broad and general framework for studying multiclass boosting that formal-izes the interaction between the boosting algorithm and the weak-learner. Unlike much, but not all, of the previous work on multiclass boosting, we focus specifically on the most natural, and perhaps weakest, case in which the weak classifiers are genuine classifiers in the sense of predicting a single multiclass label for each instance. Our new framework allows us to express a range of weak-learning conditions, both new ones and most of the ones that had previously been assumed (often only im-plicitly). Within this formalism, we can also now finally make precise what is meant by correct weak-learning conditions that are neither too weak nor too strong.
 We focus particularly on a family of novel weak-learning conditions that have an especially ap-pealing form: like the binary conditions, they require performance that is only slightly better than random guessing, though with respect to performance measures that are more general than ordinary classification error. We introduce a whole family of such conditions since there are many ways of randomly guessing on more than two labels, a key difference between the binary and multiclass set-tings. Although these conditions impose seemingly mild demands on the weak-learner, we show that each one of them is powerful enough to guarantee boostability, meaning that some combination of the weak classifiers has high accuracy. And while no individual member of the family is necessary for boostability, we also show that the entire family taken together is necessary in the sense that for every boostable learning problem, there exists one member of the family that is satisfied. Thus, we have identified a family of conditions which, as a whole, is necessary and sufficient for multiclass boosting. Moreover, we can combine the entire family into a single weak-learning condition that is necessary and sufficient by taking a kind of union, or logical OR , of all the members. This combined condition can also be expressed in our framework.
 With this understanding, we are able to characterize previously studied weak-learning conditions. In particular, the condition implicitly used by AdaBoost.MH [19], which is based on a one-against-all reduction to binary, turns out to be strictly stronger than necessary for boostability. This also applies to AdaBoost.M1 [9], the most direct generalization of AdaBoost to multiclass, whose conditions can be shown to be equivalent to those of AdaBoost.MH in our setting. On the other hand, the condition implicit to Zhu et al. X  X  SAMME algorithm [21] is too weak in the sense that even when the condition is satisfied, no boosting algorithm can guarantee to drive down the training error. Finally, the condition implicit to AdaBoost.MR [19, 9] (also called AdaBoost.M2) turns out to be exactly necessary and sufficient for boostability.
 Employing proper weak-learning conditions is important, but we also need boosting algorithms that can exploit these conditions to effectively drive down error. For a given weak-learning condition, the boosting algorithm that drives down training error most efficiently in our framework can be understood as the optimal strategy for playing a certain two-player game. These games are non-trivial to analyze. However, using the powerful machinery of drifting games [8, 16], we are able to compute the optimal strategy for the games arising out of each weak-learning condition in the family described above. These optimal strategies have a natural interpretation in terms of random walks, a phenomenon that has been observed in other settings [1, 6].
 Our focus in this paper is only on minimizing training error, which, for the algorithms we derive, provably decreases exponentially fast with the number of rounds of boosting. Such results can be used in turn to derive bounds on the generalization error using standard techniques that have been applied to other boosting algorithms [18, 11, 13]. (We omit these due to lack of space.) The game-theoretic strategies are non-adaptive in that they presume prior knowledge about the edge , that is, how much better than random are the weak classifiers. Algorithms that are adaptive, such as AdaBoost, are much more practical because they do not require such prior information. We show therefore how to derive an adaptive boosting algorithm by modifying one of the game-theoretic strategies.
 We present experiments aimed at testing the efficacy of the new methods when working with a very weak weak-learner to check that the conditions we have identified are indeed weaker than others that had previously been used. We find that our new adaptive strategy achieves low test error compared to other multiclass boosting algorithms which usually heavily underfit. This validates the potential practical benefit of a better theoretical understanding of multiclass boosting.
 Previous work. The first boosting algorithms were given by Schapire [15] and Freund [6], followed by their AdaBoost algorithm [11]. Multiclass boosting techniques include AdaBoost.M1 and Ad-aBoost.M2 [11], as well as AdaBoost.MH and AdaBoost.MR [19]. Other approaches include [5, 21]. There are also more general approaches that can be applied to boosting including [2, 3, 4, 12]. Two game-theoretic perspectives have been applied to boosting. The first one [10, 14] views the weak-learning condition as a minimax game, while drifting games [16, 6] were designed to analyze the most efficient boosting algorithms. These games have been further analyzed in the multiclass and continuous time setting in [8]. We introduce some notation. Unless otherwise stated, matrices will be denoted by bold capital letters like M , and vectors by bold small letters like v . Entries of a matrix and vector will be denoted as M ( i,j ) or v ( i ) , while M ( i ) will denote the i th row of a matrix. Inner product of two vectors u , v is denoted by  X  u , v  X  . The Frobenius inner product of two matrices Tr ( MM 0 ) will be denoted by M  X  M 0 . The indicator function is denoted by 1 [  X  ] . The distribution over the set { 1 ,...,k } will be denoted by  X  { 1 ,...,k } .
 In multiclass classification, we want to predict the labels of examples lying in some set X . Each example x  X  X has a unique y label in the set { 1 ,...,k } , where k  X  2 . We are provided a training set of labeled examples { ( x 1 ,y 1 ) ,..., ( x m ,y m ) } .
 Boosting combines several mildly powerful predictors, called weak classifiers , to form a highly accurate combined classifier, and has been previously applied for multiclass classification. In this paper, we only allow weak classifier that predict a single class for each example. This is appealing, since the combined classifier has the same form, although it differs from what has been used in much previous work.
 We adopt a game-theoretic view of boosting. A game is played between two players, Booster and Weak-Learner, for a fixed number of rounds T . With binary labels, Booster outputs a distribution in each round, and Weak-Learner returns a weak classifier achieving more than 50% accuracy on that distribution. The multiclass game is an extension of the binary game. In particular, in each round t : (1) Booster creates a cost-matrix C t  X  R m  X  k , specifying to Weak-Learner that the cost of classifying example x i as l is C ( i,l ) . The cost-matrix may not be arbitrary, but should conform to certain restrictions as discussed below. (2) Weak-Learner returns some weak classifier h t : X  X  { 1 ,...,k } from a fixed space h t  X  H so that the cost incurred is C t  X  1 h is  X  X mall enough X , according to some conditions discussed below. Here by 1 h we mean the m  X  k matrix whose ( i,j ) -th entry is 1 [ h ( i ) = j ] . (3) Booster computes a weight  X  t for the current weak classifier based on how much cost was incurred in this round.
 At the end, Booster predicts according to the weighted plurality vote of the classifiers returned in each round: By carefully choosing the cost matrices in each round, Booster aims to minimize the training error of the final classifer H , even when Weak-Learner is adversarial. The restrictions on cost-matrices created by Booster, and the maximum cost Weak-Learner can suffer in each round, together define the weak-learning condition being used. For binary labels, the traditional weak-learning condition states: for any non-negative weights w (1) ,...,w ( m ) on the training set, the error of the weak classfier returned is at most (1 / 2  X   X / 2) P i w i . Here  X  parametrizes the condition. There are many ways to translate this condition into our language. The one with fewest restrictions on the cost-matrices requires labeling correctly should be less costly than labeling incorrectly:  X  i : C ( i,y i )  X  C ( i,  X  y i ) , while the restriction on the returned weak classifier h requires less cost than predicting w ( i ) = C ( i,  X  y i )  X  C ( i,y i ) , we may verify the two conditions are the same. We will rewrite this condition after making some simplifying assumptions. Henceforth, without loss of generality, we assume that the true label is always 1 . Let C bin  X  R m  X  2 consist of matrices C which satisfy C ( i, 1)  X  C ( i, 2) . Further, let U bin  X   X  R m  X  2 be the matrix whose each row is (1 / 2 +  X / 2 , 1 / 2  X   X / 2) . Then, Weak-Learner searching space H satisfies the binary weak-learning condition if:  X  C  X  X  bin ,  X  h  X  X  : C  X  1 h  X  U bin  X   X  0 . There are two main benefits to this refor-mulation. With linear homogeneous constraints, the mathematics is simplified, as will be apparent later. More importantly, by varying the restrictions C bin on the cost vectors and the matrix U bin , we can generate a vast variety of weak-learning conditions for the multiclass setting k  X  2 as we now show. Let C  X  R m  X  k and matrix B  X  R m  X  k , which we call the baseline ; we say a weak classifier space H satisfies the condition ( C , B ) if In (2), the variable matrix C specifies how costly each misclassification is, while the baseline B fier should not exceed the average cost when weighted according to baseline B . This large class of weak-learning conditions captures many previously used conditions, such as the ones used by AdaBoost.M1 [9], AdaBoost.MH [19] and AdaBoost.MR [9, 19] (see below), as well as novel con-ditions introduced in the next section.
 By studying this vast class of weak-learning conditions, we hope to find the one that will serve the main purpose of the boosting game: finding a convex combination of weak classifiers that has zero training error. For this to be possible, at the minimum the weak classifiers should be sufficiently rich for such a perfect combination to exist. Formally, a collection H of weak classifiers is eligible for boosting, or simply boostable , if there exists a distribution  X  on this space that linearly separates the roles. It rejects spaces that are not boostable, and provides an algorithmic means of searching for the right combination. Ideally, the second factor will not cause the weak-learning condition to impose additional restrictions on the weak classifiers; in that case, the weak-learning condition is merely a reformulation of being boostable that is more appropriate for deriving an algorithm. In general, it could be too strong , i.e. certain boostable spaces will fail to satisfy the conditions. Or it could be too weak i.e., non-boostable spaces might satisfy such a condition. Booster strategies relying on either of these conditions will fail to drive down error; the former due to underfitting, and the latter due to overfitting. In the next section we will describe conditions captured by our framework that avoid being too weak or too strong. The binary weak-learning condition has an appealing form: for any distribution over the examples, the weak classifier needs to achieve error not greater than that of a random player who guesses the correct answer with probability 1 / 2 +  X  . Further, this is the weakest condition under which boosting is possible as follows from a game-theoretic perspective [10, 14] . Multiclass weak-learning conditions with similar properties are missing in the literature. In this section we show how our framework captures such conditions.
 In the multiclass setting, we model a random player as a baseline predictor B  X  R m  X  k whose rows are distributions over the labels, B ( i )  X   X  { 1 ,...,k } . The prediction on example i is a sample from B ( i ) . We only consider the space of edge-over-random baselines B eor  X   X  R m  X  k who have a faint clue about the correct answer. More precisely, any baseline B  X  B eor  X  in this space is  X  more likely to predict the correct label than an incorrect one on every example i :  X  l 6 = 1 ,B ( i, 1)  X  B ( i,l ) +  X  , with equality holding for some l .
 When k = 2 , the space B eor  X  consists of the unique player U bin  X  , and the binary weak-learning correct label, i.e., the rows of the cost-matrices should come from the set c  X  R k :  X  l,c (1)  X  c ( l ) . Then, for every baseline B  X  B eor  X  , we introduce the condition ( C eor , B ) , which we call an edge-over-random weak-learning condition. Since C  X  B is the expected cost of the edge-over-random baseline B on matrix C , the constraints (2) imposed by the new condition essentially require better than random performance.
 We now present the central results of this section. The seemingly mild edge-over-random conditions guarantee eligibility, meaning weak classifiers that satisfy any one such condition can be combined to form a highly accurate combined classifier.
 Theorem 1 (Sufficiency) . If a weak classifier space H satisfies a weak-learning condition ( C eor , B ) , for some B  X  X  eor  X  , then H is boostable. The proof involves the Von-Neumann Minimax theorem, and is in the spirit of the ones in [10]. On the other hand the family of such conditions, taken as a whole, is necessary for boostability in the sense that every eligible space of weak classifiers satisfies some edge-over-random condition. Theorem 2 (Relaxed necessity) . For every boostable weak classifier space H , there exists a  X  &gt; 0 and B  X  X  eor  X  such that H satisfies the weak-learning condition ( C eor , B ) .
 The proof shows existence through non-constructive averaging arguments. Theorem 2 states that any boostable weak classifier space will satisfy some condition in our family, but it does not help us choose the right condition. Experiments in Section 5 suggest C eor , U  X  is effective with very simple weak-learners compared to popular boosting algorithms. (Here U  X   X  B eor  X  is the edge-over-random baseline closest to uniform; it has weight (1  X   X  ) /k on incorrect labels and (1  X   X  ) /k +  X  on the correct label.) However, there are theoretical examples showing each condition in our family is too strong (supplement).
 A perhaps extreme way of weakening the condition is by requiring the performance on a cost matrix to be competitive not with a fixed baseline B  X  X  eor  X  , but with the worst of them: Condition (3) states that during the course of the same boosting game, Weak-Learner may choose to beat any edge-over-random baseline B  X  X  eor  X  , possibly a different one for every round and every cost-matrix. This may superficially seem much too weak. On the contrary, this condition turns out to be equivalent to boostability. In other words, according to our criterion, it is neither too weak nor too strong as a weak-learning condition. However, unlike the edge-over-random conditions, it also turns out to be more difficult to work with algorithmically.
 Furthermore, this condition can be shown to be equivalent to the one used by AdaBoost.MR [19, 9]. This is perhaps remarkable since the latter is based on the apparently completely unrelated all-pairs multiclass to binary reduction: the MR condition is given by ( C MR , B MR  X  ) , where C MR consists of cost-matrices that put non-negative costs on incorrect labels and whose rows sum up to zero, while B Further, the MR condition, and hence (3), can be shown to be neither too weak nor too strong. Theorem 3 (MR) . A weak classifier space H satisfies AdaBoost.MR X  X  weak-learning condition ( C MR , B MR  X  ) if and only if it satisfies (3) . Moreover, this condition is equivalent to being boostable. Next, we illustrate the strengths of our random-over-edge weak-learning conditions through concrete comparisons with previous algorithms.
 Comparison with SAMME. The SAMME algorithm of [21] requires the weak classifiers to achieve less error than uniform random guessing for multiple labels; in our language, their weak-not sufficient for boosting to be possible. In particular, consider the dataset { ( a, 1) , ( b, 2) } with k = 3 ,m = 2 , and a weak classifier space consisting of h 1 ,h 2 which always predict 1 , 2 , respec-tively. Since neither classifier distinguishes between a,b we cannot achieve perfect accuracy by combining them in any way. Yet, due to the constraints on the cost-matrix, one of h 1 ,h 2 will always manage non-positive cost while random always suffers positive cost. On the other hand our weak-learning condition allows the Booster to choose far richer cost matrices. In particular, when the cost matrix is C = ( c (1) = (  X  1 , +1 , 0) , c (2) = (+1 ,  X  1 , 0))  X  C eor , both classifiers in the above example suffer more loss than the random player U  X  , and fail to satisfy our condition. Comparison with AdaBoost.MH. AdaBoost.MH is a popular multiclass boosting algorithm that is based on the one-against-all reduction[19]. However, we show that its implicit demands on the weak classifier space is too strong. We construct a classifier space that satisfies the condition ( C eor , U  X  ) in our family, but cannot satisfy AdaBoost.MH X  X  weak-learning condition.
 Consider a space H that has, for every (1 /k +  X  ) m element subset of the examples, a classifier that predicts correctly on exactly those elements. The expected loss of a randomly chosen classifier from this space is the same as that of the random player U  X  . Hence H satisfies this weak-learning condition. On the other hand, it can be shown (supplement) that AdaBoost.MH X  X  weak-learning condition is the pair ( C MH , B MH  X  ) , where C MH has non-(positive)negative entries on (in)correct labels, and where each row of the matrix B MH  X  is the vector (1 / 2 +  X / 2 , 1 / 2  X   X / 2 ,..., 1 / 2  X   X / 2) . A quick calculation shows that for any h  X  H , and C  X  C MH with  X  1 in the first column and zeroes elsewhere, C  X  1 h  X  B MH  X  = 1 / 2  X  1 /k . This is positive when k &gt; 2 , so that H fails to satisfy AdaBoost.MH X  X  condition. In this section we devise algorithms by analyzing the boosting games that employ our edge-over-random weak-learning conditions. We compute the optimum Booster strategy against a completely adversarial Weak-Learner, which here is permitted to choose weak classifiers without restriction, i.e. the entire space H all of all possible functions mapping examples to labels. By modeling Weak-Learner adversarially, we make absolutely no assumptions on the algorithm it might use. Hence, error guarantees enjoyed in this situation will be universally applicable. Our algorithms are derived from the very general drifting games framework [16] for solving boosting games, in turn inspired by Freund X  X  Boost-by-majority algorithm [6], which we review next.
 The OS Algorithm. Fix the number of rounds T and an edge-over-random weak-learning condition ( C , B ) . For simplicity of presentation we fix the weights  X  t = 1 in each round. With f T defined as in (1), the optimum Booster payoff can be written as min Here the function L : R k  X  R is error, but we can also consider other loss functions such as exponential loss, hinge loss, etc. that upper-bound error and are proper : i.e. L ( x ) is increasing in Directly analyzing the optimal payoff is hard. However, Schapire [16] observed that the payoffs can be very well approximated by certain potential functions. Indeed, for any b  X  R k define the potential function  X  b t : R k  X  R by the following recurrence:  X  0 = L ;  X  where e l  X  R k is the unit-vector whose l th coordinate is 1 and the remaining coordinates zero. These potential functions compute an estimate  X  b t ( s t ) of whether an example x will be misclassified, based on its current state s t consisting of counts of votes received so far on various classes s t ( l ) = P proposed a Booster strategy, aka the OS strategy, which, in round t , constructs a cost matrix C  X  X  , whose each row C ( i ) achieves the minimum of the right hand side of (4) with b replaced by B ( i ) , t replaced by T  X  t , and s replaced by current state s t ( i ) . The following theorem provides a guarantee for the loss suffered by the OS algorithm, and also shows that it is the game-theoretically optimum strategy when the number of examples is large.
 Theorem 4 (Extension of results in [16]) . Suppose the weak-learning condition is given by ( C , B ) , If never increases in any round. In particular, loss suffered after T rounds of play is at most tions, and m T,k, 1 / , no Booster strategy can achieve loss less than the above bound in T rounds.
 Computing the potentials. In order to implement the OS strategy using our weak-learning con-ditions, we only need to compute the potential  X  b t for distributions b  X   X  { 1 ,...,k } . Fortunately, these potentials have a very simple solution in terms of the homogeneous random-walk R t b ( x ) , the random position of a particle after t time steps, that starts at location x  X  R k , and in each step moves in direction e l with probability b ( l ) .
 Theorem 5. If L is proper, and b  X   X  { 1 ,...,k } satisfies  X  l : b (1)  X  b ( l ) , then  X  b t ( s ) = E given by c ( l ) =  X  b t  X  1 ( s + e l ) .
 Theorem (5) implies the OS strategy chooses the following cost matrix in round t : c ( i,l ) =  X  down to computing the potentials, which is made possible by Theorem 5. There is no simple closed form solution for the non-convex 0-1 loss L ( s ) = 1 [ s 1  X  (max i&gt; 1 s i )] . However, using Theo-rem 4, we can write the potential  X  t ( s ) explicitly, and then compute it using dynamic programming in O ( t 3 k ) time. This yields very tight bounds.
 To obtain a more efficient procedure, and one that we will soon show can be made adaptive, we next focus on the exponential loss associated with AdaBoost that does have a closed form solution. e 1 + (1  X   X  ) k ( e  X  + e  X   X   X  2)  X  (1  X  e  X   X  )  X  . The cost-matrix output by the OS algorithm can be simplified by rescaling, or adding the same number to each coordinate of a cost vector, without affecting the constraints it imposes on a weak classifier, to the following form With such a choice, Theorem 4 and the form of the potential guarantee that the average loss the final loss is at most ( k  X  1)  X  (  X , X  ) T .
 Variable edges. So far we have required Weak-Learner to beat random by at least a fixed amount  X  &gt; 0 in each round of the boosting game. In reality, the edge over random is larger initially, and gets smaller as the OS algorithm creates harder cost matrices. Therefore requiring a fixed edge is either unduly pessimistic or overly optimistic. If the fixed edge is too small, not enough progress is made in the initial rounds, and if the edge is too large, Weak-Learner fails to meet the weak-learning condition in latter rounds. We attempt to fix this via two approaches: prescribing a decaying sequence of edges  X  1 ,..., X  T , or being completely flexible, aka adaptive , with respect to the edges returned by the weak-learner. In either case, we only use the edge-over-random condition ( C eor , U  X  ) , but with varying values of  X  .
 Fixed sequence of edges. With a prescribed sequence of edges  X  1 ,..., X  T the weak-learning condi-must be fixed in advance. All the results for uniform  X  and weights  X  t = 1 hold in this case as well. where f t is as defined in (1), then the following strategy is optimal: in round t output the cost matrix  X  (  X  t , X  t ) in each round. Hence the final loss will be at most ( k  X  1) Q T t =1  X  (  X  t , X  t ) . Adaptive. In the adaptive setting, we depart from the game-theoretic framework in that Weak-Learner is no longer adversarial. Further, we are no longer guaranteed to receive a certain sequence of edges. Since the choice of cost-matrix in (6) does not depend on the edges, we could fix an arbitrary set of weights  X  t in advance, follow the same algorithm as before and enjoy the same bound Q  X  . To ensure progress, the weight  X  t must be chosen adaptively as a function of  X  t . Since we do not know what edge we will receive, we choose the cost matrix as before but anticipating infinitesimally small edge, in the spirit of [7], (and with some rescaling)
