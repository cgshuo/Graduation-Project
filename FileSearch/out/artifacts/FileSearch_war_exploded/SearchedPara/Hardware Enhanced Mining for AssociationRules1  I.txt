 In several emerging applications, data is in the form of continuous data streams , as opposed to finite stored databases. Examples include stock tickers, network traffic measurements, web logs, click streams, data captured from sensor net-works and call records. Specifically, a data stream is a massive unbounded se-quence of data elements continuously ge nerated at a rapid rate. It is recognized that the data stream processing has to satisfy the following requirements. First, each data point should be examined at most once when analyzing the data stream. Second, the storage cost of related data structures should be bounded. Third, newly generated data points should be processed as fast as possible to accomplish real-time computing, i.e., the processing rate should be at least the same as the data arrival rate. Finally, the up-to-date analysis results of a data stream should be instantly available when requested.

Note that traditional database architectures that focus solely on I/O opti-mization are not designed to utilize the continued evolution of hardware infras-tructure resources, especially those o n mobile devices, efficiently to meet the demand for high-speed data stream processing. Due to the dynamic and time-sensitive nature of most data stream applications, data stream processors need to be capable of handling huge amount of data in a limited length of time window with bounded memory space. To achieve this goal, we need to exploit the charac-teristics of modern hardware technologies to design efficient hardware framework to maximize the performance of data mining algorithms. In this paper, we pro-pose a novel paradigm that comprises a hardware-enhanced framework, which exploits the massive parallelism in custom hardware to solve many high com-plexity problems in data mining tasks and to further increase the throughput and decrease the response time of the existing data mining systems. With fast increase in applications of mobile de vices where power co nsumption is a con-cern and complicated software executions a re prohibited, it is envisioned that hardware enhanced mining is an important direction to explore.

The novelty of our hardware-enhanced approach is that we transform the item transactions in a data stream into a matrix structure and efficiently map operations for discovering frequent item sets to highly efficient hardware process-ing units. The matrix structure and the corresponding operations are optimally implemented as a hardware enhancement to the existing database architectures. Our approach finds the balance of the hardware and software design to solve the high complexity issues such as the lev el-2 itemset counting to enable high performance data stream processing systems that are not attainable with tra-ditional architectures. Specifically, we realize Apriori-like algorithm within our proposed hardware-enhanced mining framework to mine frequent temporal pat-terns from data streams. Even with the quadratic increase of the size of 2-itemsets, the counts of frequent 1-item sets and 2-itemsets are obtained after one pass of the datasets through our hardware implementation. The throughput obtained with our proposed hardware enhanced framework is two orders of mag-nitude larger than that attainable by reference software implementation. It is empirically shown that the hardware enhancements provide the necessary scala-bility to many high complexity operations such as subset itemsets counting and achieve considerably higher throughput than traditional database architectures with pure software implementation.

Many sequential algorithms to discove r association rules are studies exten-sively [1][3][4][6]. Parallel and distributed schemes based on the sequential Apri-ori algorithm can be found in [2][5][10]. However, they did not focus on the scalability issues of the high complexity operations. To deal with the bottleneck of the Apriori-like algorithms, i.e., finding all frequent 2-itemsets of transaction, to mine for frequent itemsets in data s treams, FTP-DS algorithm [13] utilized the delayed pattern recognition approach to address the time and the space constraints in a data stream environment. In [8][9], even though approximation approaches are employed, it still needs e xcessive time to scan all 2-itemsets of transaction.

We mention in passing that active storage which takes advantage of processing power on individual disk drives to run application-level code is proposed in [12]. As the number of hard disk drives increases, I/O-bounded scans are benefited by the partition of the data among the large number of disks and the reduction in bandwidth by filtering. However, [12] relies on storage parallelism, i.e. the number of physical hard disks, which does not scale up with the vast amount of data. The reduction of I/O traffic by filtering will also affect the accuracies of the data mining tasks. A comme rcial FPGA coprocessor b oard is used to accelerate the processing of queries on a relational database that contains texts and images in [7]. This approach is not directly applicable to the data mining tasks. [11] builds a model to parameterize the comm unication overhead between processor and programmable logic interface and logic delays in the programmable logic device to evaluate the speedup of the addition of programmable logic to RISC machine. To our knowledge, there was no prior work either designing hardware stream processor or balancing task partitions among hardware and software, let alone conducting the corresponding performance analysis. This feature distin-guished our work from others.

The rest of the paper is organized as follows. The preliminaries of discov-ering frequent patterns over data strea ms are explored in Section 2. Hardware enhanced framework is described in Sect ion 3. Performance analysis to evaluate the advantages of exploiting the application specific hardware for data mining tasks is conducted in Section 4. Empirical studies are showed in Section 5. This paper concludes with Section 6. By following the concept of general suppor t framework [13], we briefly describe the determination of frequent temporal patterns as follows. A typical market-basket application is used here for illustrative purposes. The transaction flow in such an application is shown in Figure 1 where items a to h stand for items purchased by customers. For example, the third customer bought item c during time t=[0, 1), items c , e and g during t=[2, 3), and item g during t=[4, 5). With the sliding window model, the support of a temporal pattern is defined as follows.
 Definition 1. The support or the occurrence frequency of a temporal pattern X at a specific time t is denoted by the ratio of the number of customers having pattern X in the current time window to the total number of customers. For example, given the window size N=3, three sliding windows, i.e. w[0,3], w[1,4], and w[2,5], are shown in Figure 1(a) for the transaction flows. According to above definition, supports of the inter-transaction itemset { c , g } from TxTime t=1 to t=5 are obtained as in Figure 1(b). Because of the limited amount of instruction level parallelism (ILP) present in most of the data mining tasks [4][14], high speed data streams cannot be processed in time either by the multi-pr ocess or parallel systems to match their arrival rates. Many emerging data mining environments, such as data streams, sensor networks, and etc., demand higher throughputs and shorter response time than those attainable by traditional data mining infrastructures.

Modern VLSI technology makes it possible to pack millions of transistors in a single chip. Commercial FPGA devices provide millions of gates and also hundreds of thousands of logic elements integrated with large memory and high speed I/O interfaces. The hardware build ing blocks can be exploited for data mining tasks. Mining algorithms partitionable into independent subtasks can be executed in the hardware in a parallel fashion. Simple and frequently used rou-tines are implemented in hardware redundantly to process incoming data simul-taneously. Special purpose circuits can be implemented on field programmable gate array (FPGA) devices and interfa ced to the host data mining system as an array processors. Similar architectures are used in the design of processors for digital signal processing applications which are characterized by intensive computations and real-time requirements. Similar cop rocessors or accelerators for multimedia and networking applications have already been widely used in computing nowadays.

To achieve the throughput required in today X  X  high speed data streams, high complexity operations in data mining tasks have to be executed within a rela-tively short period of time. The time required by most of the high complexity operations, such as 2-itemset enumerat ion and counting in the discovery of fre-quent patterns, becomes impractical as the size of the data and the data arrival rate increase. From our performance mod el described later in section 4, we ex-plore a novel direction, a hardware enhanced framework, which is to exploit the massive number of parallel processing elem ents dedicated as an infrastructure for data mining tasks. 3.1 Stream Processor The computation model of our hardware enhanced mining framwork for data streams is shown in Figure 2. There are various ways to partitions a data mining task into hardware and software components depending on the nature of the task. For the problem of finding frequent temporal patterns in data streams, since the computation of L1-and L2-itemsets is the most time-consuming task in our algorithm, we can offload this operation to the hardware to enhance performance. Subsequent rule generations can be processed in software implementations for flexibility.

Let a transaction I = { i 1 , i 2 , ..., i N } be a set of items, where N is the number of items and each item belongs to { 0,1 } . Each item stands for an event according to its position in a transaction. The first item indicates the event A and the second item stands for the event B, and so on. We use a bit to represent the occurrence of the event, i.e., the event occurred if the bit is set to one. Note that the number of items is pre-defined as part of the system specification. For example, in Figure 3, each bit arrives in an interval of one time unit. The third customer bought items { 0,0,1,0,1,0,1,0 } in order during time t=[16, 24), where N is 8. Three bits are set to one to represent the occurrence of event C, E, and G, respectively.

Figure 4 shows the architecture of hardware stream processor. As the input to the stream processor, we have C customers and N distinct items that may appear in a transaction. There are four function blocks in this processor, namely, a serial/parallel converter, a sliding window buffer, a 2-itemset generator, and a frequent decision maker. N items are grouped as a transaction in a parallel form by the serial/parallel converter. The sliding window buffers the inputs of the most recent N time units. The 2-itemset gener ator enumerates all the com-binations of 2-itemsets. Each frequent decision maker determines whether its corresponding 2-itemset is frequent in the current sliding window. Here we use parallel adders and comparators to make the frequent decisions in real time. Ac-cording to Definition 1 in previous sectio n, an itemset is frequent if the number of occurrences in all customers exceeds in t he number of user-specified threshold. The characteristics of run-time behaviors are very different in hardware and software. The pipeline of hardware is achieved in register level while there is only limited instruction level pipelining in software implementations on traditional CPU-based framework. Only one task can be executed in any moment, such as calculating, scanning, and sorting. Specifically, most CPU has only one ALU to execute addition, shifting, comparis on, and so on. Our specialized hardware design can process all tasks simultaneously, including 2-itemset enumeration, occurrence counting, etc. through the massive array of simple components. The basic characteristics of functions suitable for hardware enhancements are that they take up a significant portion of overall execution time, execute in a first-in-first-out manner with minimal state memory, and exhibit simple and regular structure. In this section we develop a s imple model for the performance of the hardware enhancements to illustrate the limitation of traditional framework and the benefits of the proposed hardware enhanced framework.

Suppose that the operation i has N units of work. Each operation takes w cpu clock cycles to complete in traditional architecture and w fpga clock cycles to complete in the hardware enhan cement. The CPU clock rate is f cpu and the hardware enhancement clock rate is f fpga . The hardware enhancement has L parallel units of processing elements. To keep the model simple, we assume that the overhead in communication for each unit of work takes a constant w comm cycles. In traditional archit ecture, the execution time is and the throughput is The throughput is limited by clock rate, f cpu . Latest CPU operates at several GHz, beyond which the clock rate are no t scalable. The execution clock cycle needed per operation, w cpu , is constant for a given algorithm.

Now consider our hardware enhanced framework. For hardware enhance-ments, the execution time is and the throughput is The throughput can be increased by increasing the number of parallel processing elements L , decreasing the clock cycles needed per operation w fpga , or minimiz-ing the communication delay w comm . The density of processing elements packed into commercial FPGA devices is growing almost exponentially and thus pro-vides tremendous room for optimization of the throughput.
 Example 1: Consider the algorithm in [13] for the discovery of frequent patterns over data streams. The throughput of the algorithm is defined as the number of transactions that are processed every unit of time interval. Suppose that N is the average number of items per transaction and C is the number of customer. The amount of transaction items that our stream process can process in one unit of time is N . Note that the throughput is independent of the number of cus-tomers because the proposed hardware in frastructure can deal with all customer streams in a parallel fashion. The maximal throughput of hardware enhance-ment scales linearly with N . The bottleneck for the software implementation of Apriori algorithm is identified as the phase during which N  X  C comparisons are of the large 1-itemset. Therefore, the maximal throughput of a reference software implementation scales with 1 N  X  C  X | L 1 | 2 .Fortypicalvaluesof N ,weobservethat the throughput in our proposed hardware enhanced framework is many orders of magnitudes higher that that attainable with software implementation used in traditional database architectures. The hardware is implemented and verified with Altera X  X  design software Quar-tusII and executes on the Altera X  X  Strati x device. Software implementation of the algorithm is also executed on the same device, with a NiosII 50MHz CPU and 16MB of SDRAM. Transaction data sets are synthesized in a similar way to those in [3]. 5.1 Performance and Scalability Our experiments are conducted with synthetic data sets. In order to show the scalability of the proposed hardware enhanced framework, we measure the num-ber of clock cycles needed to obtain the f requent patterns. The results are shown in Figure 5(a) and 5(b). The hardware enhanced stream processor offers through-put that is two order of magnitudes larger than its software couterpart does. We obtain similar results when we scale the support values as shown in Figure 6. The results are consistent with our previous analysis. The throughput of the hard-ware enhancement remains at constant le vel with different parameters, such as number of items, support value, density of data while the software couterpart scales poorly. Our hardware design scales linearly with both the number of items and the number of customers, i.e., data streams. The througput of the hardware enhanced data stream processing system remains constant while the throughput of the reference software implementati on reduces exponentially as the number of items or customers increases. The feasibility of our paradigm is shown by the implementation of hardware enhancements in commercial FPGA dev ices. The hardware enhanced mining framework is a promising new approach to boost the performance of many data mining algorithms and cope with many of their inherent high complexity issues. Specifically, our approach finds the balance of the hardware and software design to solve the level-2 itemset counting in Apriori algorithms. We also point out many applications that will benefit from the new paradigm. This promising problem we have addressed here is an unexplored territory in the field of data mining research. This paper is among the very first to explore this new direction. The work was supported in part by the National Science Council of Taiwan, R.O.C., under Contracts NSC93-2752-E-002-006-PAE.
