 g @cse.ohio-state.edu With an increasing use of data mining tools and techniques, we envision that a Kno wledge Disco very and Data Mining System (KDDMS) will have to support and optimize for the follo wing sce-narios: 1) Sequence of Queries: A user may analyze one or more datasets by issuing a sequence of related comple x mining queries, and 2) Multiple Simultaneous Queries: Several users may be ana-lyzing a set of datasets concurrently , and may issue related comple x queries.

This paper presents a systematic mechanism to optimize for the abo ve cases, tar geting the class of mining queries involving fre-quent pattern mining on one or multiple datasets. We present a system architecture and propose new algorithms to simultaneously optimize multiple such queries and use a kno wledgeable cache to store and utilize the past query results. We have implemented and evaluated our system with both real and synthetic datasets. Our ex-perimental results sho w that our techniques can achie ve a speedup of up to a factor of 9, compared with the systems which do not support caching or optimize for multiple queries.
 Categorization and Subject Descriptions: H.2.8 [Database Ap-plications]: Data Mining General Terms: Algorithms Keyw ords: Frequent pattern mining, multiple query optimization, kno wledgeable cache
As the amount of data available for analysis in both scientific and commercial domains is increasing dramatically , efficienc y in the data mining process is lik ely to become the crucial issue. With an increasing use of data mining tools and techniques, we envision that a Kno wledge Disco very and Data Mining System (KDDMS) will have to support and optimize for the follo wing scenarios: Cop yright 2005 ACM 1-59593-135-X/05/0008 ... $ 5.00.

In this paper , we focus on the problem of efficiently evaluating an important class of comple x mining queries in a query intensi ve environment, where one needs to optimize multiple simultaneous queries, as well as a sequence of related queries. The class of com-ple x mining queries we tar get are the ones involving frequent pat-tern mining on one or multiple datasets. Particularly , we sho w how multiple simultaneous queries can be optimized, and how the re-sults from past mining queries can be utilized to evaluate the current ones. Due to the comple xity and characteristics of such queries, si-multaneous optimization of multiple queries and caching of their query results is challenging, and quite dif ferent from the existing work in this area.
The need for supporting and optimizing such scenarios has been well recognized in database and OLAP systems. Views have been used to optimize a sequence of database operations [5], and simi-larly , techniques such as reducing common sube xpr essions [12, 11] have been used. Ho we ver, because the nature of the mining oper -ations is very dif ferent from nature of database and OLAP opera-tions, these techniques cannot apply to a KDDMS system.

Some efforts have been made towards addressing these issues for mining environments. Nag et al. have studied how a knowledg e-able cache can be used to help to perform interacti ve disco very of association rules [9]. The y maintain a cache to record (in)frequent itemsets with their support levels, and then modify the frequent itemset mining algorithm to utilize the itemsets in the cache. The focus of their research is on frequent itemset mining without com-ple x mining conditions. Ng et al. have studied constraint associ-ation rule mining [10]. In their method, multiple queries can be mer ged as a single query for evaluation. Hipp and Guntzer have argued that execution of data mining queries with constraints can be very expensi ve [6]. Therefore, the y have proposed to use pre-computation of frequent itemsets of certain support levels to an-swer constraint itemset mining queries. Ho we ver, in these stud-ies, sequence of queries and multiple simultaneous queries have not been studied together , and the techniques involving the use of kno wledgeable cache have been restricted to deal with simple data mining queries.
Frequent pattern mining focuses on disco vering frequently ap-pearing sub-structures in datasets. The structures explored include itemsets, sequences, sub-trees, sub-graphs, and other topological structures [14, 3, 15, 4]. Frequent pattern mining has emer ged as a very useful class of techniques for analyzing datasets from a variety of domains, including retail transactions, DN A sequences, chemical compounds, XML documents, among others. An impor -tant class of frequent pattern mining tasks involv e disco vering in-teresting patterns from multiple distinct datasets.

In the follo wing, we briefly describe the major issues in express-ing as well as evaluating frequent pattern mining tasks on multiple datasets. Also, in order to simplify our discussion, we will focus on frequent itemset mining tasks. The key ideas in extending our work to other frequent patterns or structures, such as sequences, subtrees, and subgraphs, are presented in [8].
 SELECT F:I; F:A; F:B; F:C; F:D FROM Frequency ( I; A; B; C; D ) F WHERE ( F:A 0 : 1 AND F:B 0 : 1 ) SQL for Mining Multiple Datasets: Assume we have four trans-action datasets A , B , C , D , and Item is the set of all the items appearing in the four datasets. To extract the interesting patterns from these datasets, a Frequency table F is defined with a schema F requency ( I; A; B; C; D ) . The column with attrib ute all possible itemsets, i.e, the power -set of Item . The columns with attrib ute F:A; F:B; F:C; F:D store the frequenc y of the itemsets in the four datasets A; B; C; D , respecti vely . Table 1 contains a portion of this F table.

Note that the F table only serv es as a virtual table or a logi-cal vie w. A frequent pattern mining task on multiple datasets is expressed as a SQL query to partially materialize this table. The query Q 0 in Figure 1(a) is an example. Here, we want to find the itemsets that are either frequent with support level 0 : 1 and B , or frequent (with support level 0 : 1 ) in both C also frequent in either A or B (with support level 0 : 2 ). M-T able: Consider any query whose constraint condition (the WHERE clause) does not contain any negative condition, i.e., a condition which states that support in a certain dataset is belo w a specified threshold. Clearly , the constraint condition of such a query can be expressed in a tab ular format, where 1) each row of the table repre-sents a dataset, 2) each column corresponds to a conjuncti ve-clause (in volving only the AND operation) in the disjuncti ve normal form (DNF) of the constraint condition, and 3) a cell at i -th row and j -th column will have the value if the j -th conjuncti ve-clause re-quires that the support in the i -th dataset is at least . The table thus computed is referred to as an M -table. For example, Figure 1(b) illustrates the M -table for the query Q 0 .

An M -table pro vides a systematic way to describe the informa-tion required to answer a query involving multiple datasets. It turns out that M -table can be used to 1) generate efficient query plans for a given query , 2) detect common computations across multi-ple queries, and 3) summarize the results obtained from multiple queries in a cache. Thus, our presentation in the rest of this paper will be based on M -table representation of the queries. Algebra for Ev aluating Fr equent Mining Tasks: The algebra, listed in Figure 2, expresses the information required to answer a mining query over multiple datasets.

Given an M -Table, the information required for answering the corresponding query can be described as follo ws. Each nonempty cell, M i;j , maps to a SF operator , SF ( A i ; M i;j ) erators in the same column are connected by the intersection ( operation, and the expressions corresponding to each column are connected by the union ( t ) operation. The resulting expression is referred as the necessary information for the query . For example, the necessary information of Q 0 is sho wn in Figure 1(c).
Note that a query on frequent patterning mining across multiple datasets can allo w the negati ve predicate as well. For example, Query Q 1 and Q 2 are such queries. We will omit the detail of using M -Table and algebra to express such queries, and refer the reader to [8] for details.
Let us envision a KDDMS system in which there are multiple datasets and multiple users. If dif ferent users issue queries each of which involv es multiple datasets, it is quite lik ely that the queries could have a significant overlap.
 For example, consider the follo wing two queries, Q 1 and which are issued simultaneously .
 Q :SELECT F:I; F:A; F:B; F:X Q :SELECT F:I; F:A; F:B; F:Y; F:Z
These two queries overlaps on the datasets A and B . The ques-tion for us is,  X  X ow can we exploit the overlap in the two queries to gener ate query plans that are mor e efficient than the independently gener ated query plans for eac h query? X  .

Furthermore, we consider the follo wing possibility . As we had described earlier , it is very lik ely that a single user issues a sequence of related queries. For example, the system might have evaluated the query Q 0 (described in the pre vious section), before it recei ves the queries Q 1 and Q 2 . In such a case, we have the follo wing two additional questions:  X  X ow can we effectively stor e the results from the recent queries in a cac he? X  , and,  X  X ow can we efficiently utilize suc h cac hed results to speedup computation of new queries? X  .
Before discussing how we address these issues, we describe our system architecture. This architecture is sho wn in Figure 2. Our system primarily contains four components, a Query queue , a Query plan optimizer , a Query evaluation engine , and a Cac he . The queries issued by the users of the system are initially stored in the query queue. The query plan optimizer recei ves all the queries appear -ing in the queue, and then generates efficient query plans for all of them, simultaneously . In the process, the query plan optimizer uti-lizes the information in the cache, which maintains the results from a set of recent queries. The query evaluation engine evaluates the queries, based on the query plan that uses the mining operators and the operations defined in the Algebra. This component is also re-sponsible for retrie ving the necessary information from the cache. Finally , the query evaluation engine updates the cache, based upon the results of the current queries.

As we discussed abo ve, we have two major goals, which are si-multaneous optimization of multiple queries, and maintaining and exploiting a cache to optimize for a sequence of queries. In this section, we give a brief overvie w of our work. 1. Simultaneous optimization of multiple queries : The basic idea here is to reduce the common computations appearing in dif-ferent queries. This is similar to what is done for database queries. Ho we ver, our method for detecting and optimizing the common computations is quite dif ferent from the traditional database ap-proach. Our method is based on M -table. Each mining operator in the query plan is mapped to an M -table representation. The con-tainment relationships on the M -table are defined to capture the common or overlapping computations. Further , dif ferent M can be mer ged together into one lar ge table and a global query plan can be generated for the lar ge M -table.

Based on the characteristics of the M -table, we propose two dif-ferent approaches. The first approach utilizes the containment re-lationship of the M -tables to detect the overlapping computations across multiple queries. Here, each mining query will generate its own query evaluation plan. Then, we will detect and mer ge the common computations among dif ferent evaluation plans. The sec-ond approach involv es mer ging the M -tables of dif ferent queries into a single M -table, and then generating an efficient global query plan. 2. Kno wledgeable cache: Our cache stores the results of each mining operator . Compared to the pre vious effort on the use of a cache for supporting kno wledge disco very [9], an interesting as-pect of our cache is as follo ws. It not only stores the itemsets with their frequenc y, but also maintains a high-le vel knowledg e or sum-mary of the information being stored. Therefore, when a new query comes in, the cache can systematically determine which part of the query can be directly answered from the cache. Such kno wledge is maintained through the use of M -table. We sho w how we can use the M -table to summarize, update, and utilize the information in the cache.

In the next two sections, we pro vide a detailed account of these two issues. Specifically , in Section 3, we focus on the properties of the M -table which enable the abo ve optimizations. In Section 4, we discuss the detailed optimizations and cache management. In this section, we study the properties and operations of table, which form the basis for optimizing multiple mining queries and caching their results. We begin with a set of containment relationships defined on the M -tables. These relationships pro vide a simple mechanism to de-tect common computations among dif ferent queries.
 For the next two definitions, we assume we have two M -tables, M 1 and M 2 , with the same number of rows ( n ), and the same row in the two tables corresponds to the same dataset.

D EFINITION 1. If M 1 and M 2 are both single-column, M 1 contained in M 2 if for eac h corr esponding pair of cells, M 2 [ i ] ; 1 i n , either both the cells are empty , or both the cells are non-empty and M 1 [ i ] M 2 [ i ] .

If M 1 is contained in M 2 , we denote this as M 1 M 2 . For example, in Table 3, we have M 1 M 2 .

The intuition behind this definition is as follo ws. If the desired support levels are higher for the column M 1 , then the answer set for the query corresponding to M 1 is a subset of the answer set for the query corresponding to M 2 . Thus, the former can be computed from the latter by relati vely ine xpensi ve selection operations. D EFINITION 2. If M 1 and M 2 are multi-column M -tables, is contained in M 2 if eac h column in M 1 is contained by some column in M 2 .

Again, the intuition behind the definition is the same. If each column in M 1 is contained by some column in M 2 , the answer set for the query corresponding to M 1 can be obtained by the answer set for the query corresponding to M 2 , using relati vely ine xpensi ve selection operations.

Given these definitions and the mapping between mining opera-tors and M -tables, we have the follo wing lemma.
L EMMA 1. Consider two mining queries Q 1 and Q 2 , and let their associated M -tables be denoted as M 1 and M 2 , respectively . If the M -table M 1 is contained in M 2 , i.e., M 1 M 2 , the neces-sary information of Q 1 can be derived from the necessary informa-tion of Q 2 by a selection oper ation ( ).

This lemma helps us detect the common computations among queries.
 Ne xt, we study a more generalized containment relationship among M -tables, which is based on the cells of M -tables. The moti vation for this is as follo ws. In man y cases, the results of a query cannot be completely answered by one or more of the past queries, but part of its result can be deri ved from them. This containment helps answer these questions.

To facilitate our discussion, we first define the follo wing inequal-ities for empty cells. Let e be the empty cell and let r be a positi ve (non-zero) threshold. Then, our discussion assumes the follo wing inequalities, e e , r e , 0 e; and; e 0 .
 For the follo wing definition, we again assume that we have two M -tables, M 1 and M 2 , with the same number of rows ( n ), and the same row in the two tables corresponds to the same dataset.
D EFINITION 3. Consider a cell c , whic h is at the row i column C 1 of the M -table M 1 . This cell is contained in exists a column in M 2 , denoted as C 2 , suc h that: 1) C are both non-empty , and 2) C 1 [ j ] C 2 [ j ] ; 8 j; 1 j n We denote such containment as c M 2 . Intuiti vely , c is contained in
M 2 if we can use the corresponding cell in the column C 2 color the cell c . The reason we require C 1 [ j ] C 2 [ j ] pair of corresponding cells in the two columns, is that we need information in C 2 to be a superset of the information required for the cell c .

Based upon the abo ve definition, we have the follo wing defini-tion to relate one M -table to a set of M -tables.

D EFINITION 4. An M -table , M 0 , is cell-contained in the group of
M -tables, M 1 ; ; M k , if eac h non-empty cell in M 0 is con-tained by at least one M -table in the set M 1 ; ; M k . Formally , we denote this as As an example, in Table 3, we have M 5 c f M 3 ; M 4 g .
Given this definition, we have the follo wing lemma to detect if the necessary information of a query can be deri ved from a group of other queries.
 L EMMA 2. Let Q 0 be a query with an M -table , M 0 , and let Q ; ; Q k be a group of queries with the corr esponding M -tables M 1 ; ; M k , respectively . If M 0 is cell-contained in M k , then the necessary information of Q 0 can be derived from the necessary information of Q 1 ; ; Q k .
 Our discussion in this subsection has so far assumed that the tables have the same number of rows, and the same row in each table corresponds to the same dataset. Ho we ver, this is not a serious limitation. If two M -tables do not satisfy this condition, we can align them to meet this condition. Briefly , this alignment procedure is as follo ws. First, we tak e a union of the two sets of datasets. Then, we extend the two M -tables to have the same number of rows, corresponding to the union of the set of datasets. This will involv e adding rows where each cell will be empty . Finally , we shuf fle the rows in the two M -tables to let each row represent the same dataset.
We now define the mer ge operation for the M -Tables. This op-eration helps in replacing multiple queries by a single lar ge query , and also helps maintain a high-le vel summary of the contents of the cache. Again, our definition assumes that the M -tables being mer ged have been aligned , i.e., the y have the same number of rows and the same row in each table corresponds to the same dataset. D EFINITION 5. The mer ge oper ation, denoted as , on two tables, M 1 and M 2 , results in a table with the same rows, and a set of columns that is the union of the set of columns in M 1
As an example, Table 4 sho ws the mer ged table, M 1 M 2 where, M 1 and M 2 are M -tables for the queries Q 1 and Q specti vely .

Clearly , the original tables are contained in the mer ged table, that is The implication of the abo ve observ ation is as follo ws. For two M -tables M 1 and M 2 , corresponding to the queries, Q 1 and respecti vely , the answering set of both Q 1 and Q 2 can be deri ved from the result of the mer ged M table, M 1 M 2 . This fact will be used to process multiple queries, as well as to update the kno wl-edgeable cache with dif ferent mining operators.
To optimize the single query evaluation, we need a new mining operator CF . This is because using only the SF operator to evalu-ate queries can be very expensi ve.
 Frequent itemset mining oper ator with constr aints CF ( A finds the itemsets that are frequent in the dataset A j with support and also appears in the set X . X is a set of itemsets that satisfies the down-closur e property , i.e., if an itemset is frequent, then all its subsets are also frequent. This operator also reports the frequenc y of these itemsets in A j .

Note that we can also define and use other mining operators to speedup the evaluation process [7]. For simplicity , we will only use CF and SF in this paper . Using the new mining operator , we are able to generate efficient query plans for these our mining queries. Because of the space limitation, we will not discuss the detail of the query plan generation algorithm (see [7, 8] for details).
To optimize multiple simultaneous queries, this approach gen-erates local query plans for each query , and then tries to remo ve the common computations among the query plans. The common computations are cate gorized into two groups. In the first group, a mining operator in a query plan can be deri ved from another min-ing operator in one of the other query plans. In the second group, a mining operator in a query plan can be deri ved from a group of mining operators which are in other query plans, or are in the same query plan but scheduled before this operator . As discussed in Sub-section 3.1, we can detect these common computations by the con-tainment relationship defined on the M -tables.
 Input: local query plans Q 1 ; ; Q n S = f Q 1 ; Q n g ; While ( S 6 = ; ) Do Figur e 3: Gr eedy Algorithm to Remo ve Containment in Multi-ple Query Plans
The dif ficulty of this approach is that dif ferent query evaluation order will result in dif ferent ways to remo ve the common compu-tations. To find the evaluation order for n queries to achie ve the maximal savings from remo ving the common computations, a sim-ple enumeration method will have the time comple xity O ( n !) n is lar ge, this method is very expensi ve. Therefore, we propose a greedy algorithm, which is sketched in Figure 3. This greedy algorithm utilizes the follo wing property . If a query plan, scheduled after a set of query plans, S , then the contained mining operators in Q do not depend on how the contained mining oper -ators are remo ved within the set S . This is based on the transiti ve property of the containment relationships. To utilize this property , our algorithm finds the query plan which has the maximal savings when it is scheduled as the last one. Such a plan is then scheduled last, and then the order of the remaining operations is determined. Note that since the exact savings cannot typically be determined, we use simple heuristics, such as the number of mining operators, as the cost function.

Consider applying the greedy algorithm on the query plans of query Q 1 and Q 2 , which are as follo ws:
The algorithm will schedule the query Q 2 before Q 1 , and the first two mining operators in the query plan of Q 1 will be eliminated.
A dra wback of the abo ve approach is that it is very sensiti ve to the local plans, and often cannot find efficient query plans. For example, consider the new query Q 0 the sub-condition in the query Q 2 , F:B 0 : 1 by F:B 0 : 15 The query plan for Q 0
If we are evaluating queries Q 1 and Q 0 proach can not find any common computations between the two query plans, and the mining operators will be invoked 8 times.
Ho we ver, the M -table format of queries enables us to perform more aggressi ve optimizations. This new approach does not depend on the local query plans. Instead, this approach combines the local M -tables from dif ferent queries into a single lar ge M -table by the mer ge operation ( ). Then, it generates a global query plan based on this mer ged M -table. Consider the mer ged M -tables for query Q 1 and Q 0 2 in Table 5.

We can have the follo wing global query plan which needs only 6 mining operators.

Because of the space limitation, we will only briefly introduce the basic ideas to maintain the cache and how to use it to optimize the query evaluation. Interested readers should see our technical report [8] for details. The past mining results which are stored in the cache are maintained/inde xed by a big M -table. Specifically , we will map each mining operator appearing in a query plan to a specific M -table. Once the mining operator is executed, we will mer ge ( ) its corresponding M -table to the big M -table. When the new queries arri ve, we will find which cell in their corresponding M -tables has been contained in the big M -table. Note that the mining information of these contained cells can be directly deri ved from the cache, and therefore the computation can be saved.
This section briefly reports a series of experiments we conducted to demonstrate the efficac y of the optimization techniques we have developed. A more complete experimental evaluation is documented Table 6: Gr oup-1 Results on Synthetic (Quest) Datasets (All Execution Times in Seconds) in our technical report [8]. Our experiments were conducted on two groups of datasets, each of them comprising four distinct datasets. The first group of datasets (IPUMS) is deri ved from the IPUMS 1990-5% census micro-data, which pro vides information about in-dividuals and households [1]. The four datasets each comprises 50,000 records. Ev ery record in the datasets has 57 attrib utes. The second group of datasets represents the mark et bask et scenario, and is deri ved from IBM Quest X  s synthetic datasets [2]. Each of four datasets contains 1,000,000 transactions, and the number of items per transactions is 20.

Our test queries are generated from a collection of query tem-plates involving a dif ferent number of datasets, ranging from one to four . Each template involv es several dif ferent parameters corre-sponding to thresholds. To generate a query from the templates, we assign values to each threshold.
 Experimental Settings: In our experiments, we evaluate three meth-ods to deal with multiple mining queries. we denote them as (single query plan, without multiple query optimization), query plan, Subsection 4.1), and GQ (global query plan, Subsec-tion 4.2), respecti vely .

We also consider the follo wing experimental settings to study the impact of pre-computation and caching.
 Setting -I: No pre-computation and caching, Setting -II: Use pre-computation only , Setting -III: Use Caching only , and Setting -IV : Use both pre-computation and caching.

Note that in our experiments, we do not consider cache replace-ment. This is a topic for future research.
 Experimental Results: In the follo wing, we first report two groups of experimental results. The first group, ( Gr oup-1 ), assumes that queries are issued in a random fashion. Specifically , we randomly generate 24 queries from the query templates, and put them in the query queue. Our system will evaluate them in a batch fashion, where the batch size varies from 2 to 6 . The second group, ( Gr oup-2 ), emulates a mining session . Each mining session is defined as a sequence of queries with the same query template but dif ferent thresholds. This simulates the situation in which a user issues a sequence of related queries, in order to find the desired results. Specifically , we randomly pick 24 query templates, and then ran-domly generate 6 queries from each template. In our experiment, we vary the batch size to evaluate the total of 144 queries gener -ated in this fashion. Each batch contains 2, 3, 4, or 6 queries from dif ferent mining sessions.
 Table 6 sho w the Gr oup-1 experimental results. Table 7 sho w the Gr oup-2 experimental results.
The work presented in this paper is dri ven by the need to effi-ciently process a lar ge number of data mining queries, which are being issued by a number of users. To speedup the evaluation of queries in such a scenario, we need to not only evaluate each single Table 7: Gr oup-2 Results from Real (IPUMS) Datasets (All Ex-ecution Times in Seconds) query efficiently , but also need to optimize multiple queries simul-taneously . Furthermore, we need to be able to utilize mining results from past queries in a systematic fashion.

In this paper , we have presented a novel system architecture to deal with such a query intensi ve environment. We have pro-posed new algorithms to perform multiple-query optimization for frequent pattern mining queries which involv e multiple datasets. We also designed a kno wledgeable cache which can store the past query results from queries, and enable the use of these results to further optimize multiple queries. Finally , we have implemented and evaluated our system with both real and synthetic datasets. Our experimental results have demonstrated a speedup of up to a factor of 9.
