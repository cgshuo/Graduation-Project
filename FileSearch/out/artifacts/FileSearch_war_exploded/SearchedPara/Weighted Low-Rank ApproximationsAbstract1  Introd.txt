 Nathan Srebro nati@mit.edu Tommi Jaakkola tommi@ai.mit.edu Factor models are natural in the analysis of many kinds of tabulated data. This includes user preferences over a list of items, microarray (gene expression) mea-surements, and collections of images. Consider, for ex-ample, a dataset of user preferences for movies or jokes. The premise behind a factor model is that there is only a small number of factors influencing the preferences, and that a user X  X  preference vector is determined by how each factor applies to that user. In a linear fac-tor model, each factor is a preference vector, and a user X  X  preferences correspond to a linear combination of these factor vectors, with user-specific coefficients. Thus, for n users and d items, the preferences accord-ing to a k -factor model are given by the product of an n  X  k coefficient matrix (each row representing the extent to which each factor is used) and a k  X  d fac-tor matrix whose rows are the factors. The preference matrices which admit such a factorization are matri-ces of rank at most k . Thus, training such a linear factor model amounts to approximating the empirical preferences with a low-rank matrix.
 Low-rank matrix approximation with respect to the Frobenius norm X  X inimizing the sum squared differ-ences to the target matrix X  X an be easily solved with Singular Value Decomposition (SVD). For many ap-plications, however, the deviation between the ob-served matrix and the low-rank approximation should be measured relative to a weighted (or other) norm. While the extension to the weighted-norm case is con-ceptually straightforward, and dates back to early work on factor analysis (Young, 1940), standard algo-rithms (such as SVD) for solving the unweighted case do not carry over to the weighted case.
 Weighted norms can arise in a number of situations. Zero/one weights, for example, arise when some of the entries in the matrix are not observed. More generally, we may introduce weights in response to some exter-nal estimate of the noise variance associated with each measurement. This is the case, for example, in gene ex-pression analysis, where the error model for microarray measurements provides entry-specific noise estimates. Setting the weights inversely proportional to the as-sumed noise variance can lead to a better reconstruc-tion of the underlying structure. In other applications, entries in the target matrix may represent aggregates of many samples. The standard un weighted low-rank approximation (e.g., for separating style and content (Tenenbaum &amp; Freeman, 2000)) would in this context assume that the number of samples is uniform across the entries. Non-uniform weights are needed to appro-priately capture any differences in the sample sizes. Despite its usefulness, the weighted extension has at-tracted relatively little attention. Shpak (1990) and Lu et al. (1997) studied weighted-norm low-rank approxi-mations for the design of two-dimensional digital filters where the weights arise from constraints of varying im-portance. Shpak developed gradient-based optimiza-tion methods while Lu et al. suggested alternating-optimization methods. In both cases, rank-k approx-imations are greedily combined from k rank-one ap-proximations. Unlike for the unweighted case, such a greedy procedure is sub-optimal.
 We suggest optimization methods that are signifi-cantly more efficient and simpler to implement (Sec-tion 2). We also consider other measures of deviation, beyond weighted Frobenius norms. Such measures arise, for example, when the noise model associated with matrix elements is known but not is Gaussian. For example, for binary data, a logistic model with an underlying low-rank representation might be more ap-propriate. In Section 3 we show how weighted-norm approximation problems arise as subroutines for solv-ing such a low-rank problem. Finally, in Section 4, we illustrate the use of these methods by applying them to a collaborative filtering problem. Given a target matrix A  X &lt; n  X  d , a corresponding non-negative weight matrix W  X &lt; n  X  d + , and a desired (inte-ger) rank k , we would like to find a matrix X  X &lt; n  X  d rank (at most) k , that minimizes the weighted Frobe-nius distance J ( X ) = P i,a W i,a ( X i,a  X  A i,a ) 2 . In this section, we analyze this optimization problem and con-sider optimization methods for it. 2.1. A Matrix-Factorization View It will be useful to consider the decomposition X = U V 0 where U  X &lt; n  X  k and V  X &lt; d  X  k . Since any rank-k matrix can be decomposed in such a way, and any pair of such matrices yields a rank-k matrix, we can think of the problem as an unconstrained minimiza-tion problem over pairs of matrices ( U, V ) with the minimization objective This decomposition is not unique. For any invertible R  X &lt; k  X  k , the pair ( U R, V R  X  1 ) provides a factoriza-tion equivalent to ( U, V ), i.e. J ( U, V ) = J ( U R, V R resulting in a k 2 -dimensional manifold of equivalent so-lutions 1 . In particular, any (non-degenerate) solution ( U, V ) can be orthogonalized to a (non-unique) equiv-alent orthogonal solution  X  U = U R,  X  V = V R  X  1 such that  X  V 0  X  V = I and  X  U 0  X  U is a diagonal matrix. We first revisit the well-studied case where all weights are equal to one. It is a standard result that the low-rank matrix minimizing the unweighted sum-squared distance to A is given by the leading components of the singular value decomposition of A . It will be in-structive to consider this case carefully and understand why the unweighted low-rank approximation has such a clean and easily computable form. We will then be able to move on to the weighted case, and understand how, and why, the situation becomes less favorable. In the unweighted case, the partial derivatives of the objective J with respect to U, V are  X  X   X  X  = 2( U V 0  X  A ) V ,  X  X   X  X  = 2( V U 0  X  A 0 ) U . Solving  X  X   X  X  = 0 for U yields U = AV ( V 0 V )  X  1 ; focusing on an orthogonal solution, where V 0 V = I and U 0 U =  X  is diagonal, yields U = AV . Substituting back into  X  X   X  X  = 0, we have 0 = V U 0 U  X  A 0 U = V  X   X  A 0 AV . The columns of V are mapped by A 0 A to multiples of themselves, i.e. they are eigenvectors of A 0 A . Thus, the gradient  X  ( U,V ) vanishes at an orthogonal ( U, V ) if and only if the columns of V are eigenvectors of A 0 A and the columns of U are corresponding eigenvectors of AA 0 , scaled by the square root of their eigenvalues. More generally, the gradient vanishes at any ( U, V ) if and only if the columns of U are spanned by eigenvec-tors of AA 0 and the columns of V are correspondingly spanned by eigenvectors of A 0 A . In terms of the sin-gular value decomposition A = U 0 SV 0 0 , the gradient vanishes at ( U, V ) if and only if there exist matrices Q
U Q V = I  X &lt; agonal matrix rather than I ) such that U = U 0 SQ U , V = V 0 Q V . This provides a complete characterization of the critical points of J . We now turn to identifying the global minimum and understanding the nature of the remaining critical points.
 The global minimum can be identified by investigat-ing the value of the objective function at the criti-cal points. Let  X  1  X  X  X  X  X  X   X  m be the eigenvalues of A
A . For critical ( U, V ) that are spanned by eigen-vectors corresponding to eigenvalues {  X  q | q  X  Q } , the error of J ( U, V ) is given by the sum of the eigenval-ues not in Q ( P q 6 X  Q  X  q ), and so the global minimum is attained when the eigenvectors corresponding to the highest eigenvalues are taken. As long as there are no repeated eigenvalues, all ( U, V ) global minima cor-respond to the same low-rank matrix X = U V 0 , and belong to the same equivalence class. 3 In order to understand the behavior of the objective function, it is important to study the remaining critical points. For a critical point ( U, V ) spanned by eigen-vectors corresponding to eigenvalues as above (assum-ing no repeated eigenvalues), the Hessian has exactly P eigencomponent with eigenvalue  X  with an alternate eigencomponent not already in ( U, V ) with eigenvalue  X  &gt;  X  , decreasing the objective function. The change can be done gradually, replacing the component with a convex combination of the original and improved com-ponents. This results in a line between the two critical points which is a monotonic improvement path. Since there are P q  X  Q q  X  k 2 such pairs of eigencomponents, there are at least this many directions of improve-ment. Other than these directions of improvement, and the k 2 directions along the equivalence manifold corresponding to the k 2 zero eigenvalues of the Hes-sian, all other eigenvalues of the Hessian are positive (or zero, in very degenerate A ).
 Hence, in the unweighted case, all critical points that are not global minima are saddle points. This is an important observation: Despite J ( U, V ) not being a convex function, all of its local minima are global. We now move on to the weighted case, and try to take the same path. Unfortunately, when weights are in-troduced, the critical point structure changes signifi-cantly.
 The partial derivatives become (with  X  denoting element-wise multiplication): The equation  X  X   X  X  = 0 is still a linear system in U , and for a fixed V , it can be solved, recovering U V = arg min U J ( U, V ) (since J ( U, V ) is convex in U ). However, the solution cannot be written using a single pseudo-inverse V ( V 0 V )  X  1 . Instead, a separate pseudo-inverse is required for each row ( U  X  V ) i of U  X  where W i  X &lt; k  X  k is a diagonal matrix with the weights from the i th row of W on the diagonal, and A i is the i th row of the target matrix 4 . In order to proceed as in the unweighted case, we would have liked to choose V such that V 0 W i V = I (or is at least diagonal). This can certainly be done for a single i , but in order to pro-ceed we need to diagonalize all V 0 W i V concurrently . When W is of rank one, such concurrent diagonaliza-tion is possible, allowing for the same structure as in the unweighted case, and in particular an eigenvector-based solution (Irani &amp; Anandan, 2000). However, for higher-rank W , we cannot achieve this concurrently for all rows. The critical points of the weighted low-rank approximation problem, therefore, lack the eigenvector structure of the unweighted case. Another implication of this is that the incremental structure of unweighted low-rank approximations is lost: an optimal rank-k factorization cannot necessarily be extended to an op-timal rank-( k + 1) factorization.
 Lacking an analytic solution, we revert to numerical optimization methods to minimize J ( U, V ). But in-stead of optimizing J ( U, V ) by numerically searching over ( U, V ) pairs, we can take advantage of the fact that for a fixed V , we can calculate U  X  V , and therefore also the projected objective J  X  ( V ) = min U J ( U, V ) = J ( U  X  V , V ). The parameter space of J  X  ( V ) is of course much smaller than that of J ( U, V ), making optimiza-tion of J  X  ( V ) more tractable. This is especially true in many typical applications where the the dimensions of A are highly skewed, with one dimension several or-ders of magnitude larger than the other (e.g. in gene expression analysis one often deals with thousands of genes, but only a few dozen experiments).
 Recovering U  X  V using (1) requires n inversions of k  X  k matrices. The dominating factor is actually the ma-trix multiplications: Each calculation of V 0 W i V re-quires O ( dk 2 ) operations, for a total of O ( ndk 2 ) oper-ations. Although more involved than the unweighted case, this is still significantly less than the prohibitive O ( n 3 k 3 ) required for each iteration suggested by Lu et al. (1997), or for Hessian methods on ( U, V ) (Sh-pak, 1990), and is only a factor of k larger than the O ( ndk ) required just to compute the prediction U V 0 . After recovering U  X  V , we can easily compute not only the value of the projected objective, but also its gra-The computation requires only O ( ndk ) operations, and is therefore  X  X ree X  after U  X  V has been recovered. Equipped with the above calculations, we can use stan-dard gradient-descent techniques to optimize J  X  ( V ). Unfortunately, though, unlike in the unweighted case, J ( U, V ), and J  X  ( V ), might have local minima that are not global. Figure 1 shows the emergence of a non-global local minimum of J  X  ( V ) for a rank-one ap-proximation of A = 1 1 . 1 1  X  1 . The matrix V is a two-dimensional vector. But since J  X  ( V ) is invariant under invertible scalings, V can be specified as an angle  X  on a semi-circle. We plot the value of J  X  ([cos  X , sin  X  ]) for each  X  , and for varying weight matrices of the form W = 1+  X  1 1 1+  X  . At the front of the plot, the weight matrix is uniform and indeed there is only a single lo-cal minimum, but at the back of the plot, where the weight matrix emphasizes the diagonal, a non-global local minimum emerges. Despite the abundance of local minima, we found gra-dient descent methods on J  X  ( V ), and in particular con-jugate gradient descent, equipped with a long-range line-search for choosing the step size, very effective in avoiding local minima and quickly converging to the global minimum. 2.2. A Missing-Values View and an EM In this section we present an alternative optimiza-tion procedure, which is much simpler to implement. This procedure is based on viewing the weighted low-rank approximation problem as a maximum-likelihood problem with missing values.
 Consider first systems with only zero/one weights, where only some of the elements of the target matrix A are observed (those with weight one) while others are missing (those with weight zero). Referring to a prob-abilistic model parameterized by a low-rank matrix X , where A = X + Z and Z is white Gaussian noise, the weighted cost of X is equivalent to the log-likelihood of the observed variables.
 This suggests an Expectation-Maximization proce-dure. In each EM update we would like to find a new parameter matrix maximizing the expected log-likelihood of a filled-in A , where missing values are filled in according to the distribution imposed by the current estimate of X . This maximum-likelihood pa-rameter matrix is the (unweighted) low-rank approxi-mation of the mean filled-in A , which is A with miss-ing values filled in from X . To summarize: in the E xpectation step values from the current estimate of X are filled in for the missing values in A , and in the M aximization step X is reestimated as a low-rank ap-proximation of the filled-in A .
 In order to extend this approach to a general weight matrix, consider a probabilistic system with several low-rank parameter matrix X , where A ( r ) = X + Z ( r ) and the random matrices Z ( r ) are independent white Gaussian noise with fixed variance. When all target matrices are fully observed, the maximum likelihood setting for X is the low-rank approximation of the their average. Now, if some of the entries of some of the tar-get matrices are not observed, we can use a similar EM procedure, where in the expectation step values from the current estimate of X are filled in for all missing entries in the target matrices, and in the maximization step X is updated to be a low-rank approximation of the mean of the filled-in target matrices.
 To see how to use the above procedure to solve weighted low-rank approximation problems, consider systems with weights limited to W ia = w ia N with inte-ger w ia  X  X  0 , 1 , . . . , N } . Such a low-rank approxima-tion problem can be transformed to a missing value problem of the form above by  X  X bserving X  the value A ia in w ia of the target matrices (for each entry i, a ), and leaving the entry as missing in the rest of the tar-get matrices. The EM update then becomes: where LRA k ( X ) is the unweighted rank-k approxima-tion of X , as can be computed from the SVD. Note that this procedure is independent of N . For any weight matrix (scaled to weights between zero and one) the procedure in equation (2) can thus be seen as an expectation-maximization procedure. This pro-vides for a very simple, tweaking-free method for find-ing weighted low-rank approximations.
 Although we found this EM-inspired method effective in many cases, in some other cases the procedure con-verges to a local minimum which is not global. Since the method is completely deterministic, initialization of X plays a crucial role in promoting convergence to a global, or at least deep local, minimum, as well as the speed with which convergence is attained. Two obvious initialization methods are to initialize X to A , and to initialize X to zero. Initializing X to A works reasonably well if the weights are bounded away from zero, or if the target values in A have rela-tively small variance. However, when the weights are zero, or very close to zero, the target values become meaningless, and can throw off the search. Initializing X to zero avoids this problem, as target values with zero weights are completely ignored (as they should be), and works well as long as the weights are fairly dense. However, when the weights are sparse, it often converges to local minima which consistently under-predict the magnitude of the target values.
 As an alternative to these initialization methods, we found the following procedure very effective: we initial-ize X to zero, but instead of seeking a rank-k approx-imation right away, we start with a full rank matrix, and gradually reduce the rank of our approximations. That is, the first d  X  k iterations take the form: resulting in X ( t ) of rank ( d  X  t +1). After reaching rank k , we revert back to the iterations of equation (2) un-til convergence. Note that with iterations of the form X ( t +1) = W  X  A +(1  X  W )  X  X ( t ) , without rank reduc-tions, we would have X ( t ) ia = (1  X  (1  X  W ia ) t )) A (1  X  e  X  tW ia ) A ia , which converges exponentially fast to A for positive weights. Of course, because of the rank reduction, this does not hold, but even the few high-rank iterations set values with weights away from zero close to their target values, as long as they do not significantly contradict other values. 2.3. Reconstruction Experiments Since the unweighted or simple low-rank approxima-tion problem permits a closed-form solution, one might be tempted to use such a solution even in the presence of non-uniform weights (i.e., ignore the weights). We demonstrate here that this procedure results in a sub-stantial loss of reconstruction accuracy as compared to the EM algorithm designed for the weighted problem. To this end, we generated 1000  X  30 low rank ma-trices combined with Gaussian noise models to yield the observed (target) matrices. For each matrix entry, the noise variance  X  2 ia was chosen uniformly in some noise level range characterized by a noise spread ratio max  X  2 / min  X  2 . The planted matrix was subsequently reconstructed using both a weighted low-rank approx-imation with weights W ia = 1 / X  2 ia , and an unweighted low-rank approximation (using SVD). The quality of reconstruction was assessed by an unweighted squared distance from the  X  X lanted X  matrix. Figure 2(a) shows the quality of reconstruction at-tained by the two approaches as a function of the signal (weighted variance of planted low-rank matrix) to noise (average noise variance) ratio, for a noise spread ratio of 100 (corresponding to weights in the range 0 . 01 X 1). The reconstruction error attained by the weighted approach is generally over twenty times smaller than the error of the unweighted solution. Fig-ure 2(b) shows this improvement in the reconstruction error, in terms of the error ratio between the weighted and unweighted solutions, for the data in Figure 2(a), as well as for smaller noise spread ratios of ten and two. Even when the noise variances (and hence the weights) are within a factor of two, we still see a consistent ten percent improvement in reconstruction.
 The weighted low-rank approximations in this experi-ment were computed using the EM algorithm of Sec-tion 2.2. For a wide noise spread, when the low-rank matrix becomes virtually undetectable (a signal-to-noise ratio well below one, and reconstruction er-rors in excess of the variance of the signal), EM of-ten converges to a non-global minimum. This results in weighted low-rank approximations with errors far higher than could otherwise be expected, as can be seen in both figures. In such situations, conjugate gra-dient descent methods proved far superior in finding the global minimum. In certain situations we might like to capture a binary data matrix y  X  X  X  1 , +1 } n  X  d with a low-rank model. A natural choice in this case is a logistic model param-eterized by a low-rank matrix X  X &lt; n  X  d , such that Pr ( Y ia = +1 | X ia ) = g ( X ia ) independently for each i, a , where g is the logistic function g ( x ) = 1 1+ e  X  x then seeks a low-rank matrix X maximizing the like-lihood Pr ( Y = y | X ). Such low-rank logistic models were suggested by Collins et al. (2002) and by Gordon (2003) and recently studied by Schein et al. (2003). Using a weighted low-rank approximation, we can fit a low-rank matrix X minimizing a quadratic loss from the target. In order to fit a non-quadratic loss such as quadratic approximation to the loss.
 Consider the second-order Taylor expansion of log g ( yx ) about  X  x : log g ( yx )  X  The log-likelihood of a low-rank parameter matrix X can then be approximated as: log Pr ( y | X )  X   X  X Maximizing (4) is a weighted low-rank approximation problem. Note that for each entry ( i, a ), we use a second-order expansion about a different point  X  X ia . The closer the origin  X  X ia is to X ia , the better the approximation. This suggests an iterative approach, where in each iteration we find a parameter matrix X using an approximation of the log-likelihood about the parameter matrix found in the previous iteration. For the Taylor expansion, the improvement of the approximation is not always monotonic. This might cause the method outlined above not to converge. In order to provide for a more robust method, we use the following variational bound on the logistic (Jaakkola &amp; Jordan, 2000): yielding the corresponding bound on the likelihood: log Pr ( y | X )  X  with equality if and only if X =  X  X . This bound sug-gests an iterative update of the parameter matrix X ( t ) by seeking a low-rank approximation X ( t +1) for the following target and weight matrices: Fortunately, we do not need to confront the severe problems associated with nesting iterative optimiza-tion methods. In order to increase the likelihood of our logistic model, we do not need to find a low-rank matrix minimizing the objective specified by (6), just one improving it. Any low-rank matrix X ( t +1) with a lower objective value than X ( t ) (with respect to A ( t +1) and W ( t +1) ) is guaranteed to have a higher likelihood: A lower objective corresponds to a higher upper bound in (5), and since the bound is tight for X ( t ) , the log-likelihood of X ( t +1) must be higher than the log-likelihood of X ( t ) . Moreover, if the likelihood of X ( t ) is not already maximal, there are guaranteed to be matrices with lower objective values. Therefore, we can mix weighted low-rank approximation itera-tions and logistic bound update iterations, while still ensuring convergence.
 In many applications we may also want to associate external weights with each entry in the matrix (e.g. to accommodate missing values), or more generally, weights (counts) of positive and negative observations in each entry (e.g. to capture the likelihood with re-spect to an empirical distribution). This can easily be done by multiplying the weights in (6) by the external weights, or taking a weighted combination correspond-ing to y = +1 and y =  X  1.
 Note that the target and weight matrices correspond-ing to the Taylor approximation and those correspond-ing to the variational bound are different: The varia-tional target is always closer to the current value of X , and the weights are more subtle. This ensures the guaranteed convergence (as discussed above), but the price we pay is a much lower convergence rate. Although we have observed many instances in which a  X  X aylor X  iteration increases, rather then decreases, the objective, overall convergence was attained much faster using  X  X aylor X , rather than  X  X ariational X  itera-tions. To illustrate the use of weighted, and generalized, low-rank approximations, we applied our methods to a col-laborative filtering problem. The task of collaborative filtering is, given some entries of a user preferences matrix, to predict the remaining entries. We do this by approximating those observed values by a low-rank matrix (using weighted low-rank approximation with zero/one weights). Unobserved values are predicted according to the learned low-rank matrix.
 Using low-rank approximation for collaborative fil-tering has been suggested in the past. Goldberg et al. (2001) use a low-rank approximation of a fully-observed subset of columns of the matrix, thus avoid-ing the need to introduce weights. Billsus and Paz-zani (1998) use a singular value decomposition of a sparse binary observation matrix. Both Goldberg and Billsus use the low-rank approximation only as a pre-processing step, and then use clustering (Goldberg) and neural networks (Billsus) to learn the preferences. Azar et al. (2001) proved asymptotic consistency of a method in which unobserved entries are replaced by zeros, and observed entries are scaled inversely pro-portionally to the probability of them being observed. No guarantees are provided for finite data sets, and to the best of our knowledge this technique has not been experimentally tested.
 We analyzed a subset of the Jester data 5 (Goldberg et al., 2001). The data set contains one hundred jokes, with user ratings (bounded continuous values entered by clicking an on-screen  X  X unniness X  bar) for some of the jokes. All users rated a core set of ten jokes, and most users rated an extended core set of a total of twenty jokes. Each user also rated a variable number of additional jokes. We selected at random one thousand users who rated the extended core set and at least two additional jokes. For each user, we selected at random two non-core jokes and held out their ratings. We fit low-rank matrices using the following techniques: svd Unobserved values were replaced with zeros, and subset An unweighted low-rank approximation for rescaling Following Azar et al. (2001), the ratings wlra A weight of one was assigned to each observed For each low-rank matrix, the test error on the held out jokes (Figure 3) and the training error were measured in terms of the average squared difference to the true rating, scaled by the possible range of ratings. Normal-ized mean absolute error (NMAE) was also measured, producing very similar results, with no qualitative dif-ferences. Beyond the consistent reduction in training error (which is guaranteed by the optimization objec-tive), we observe that wlra achieves a better test error than any of the other methods. Not surprisingly, it also over-fits much more quickly, as it becomes possi-ble to approximate the observed values better at the expense of extreme values in the other entries. As discussed in the introduction, minimizing the squared error to the absolute ratings is not necessar-ily the correct objective. Taking the view that each joke has a  X  X robability of being funny X  for each user, we proceeded to try to fit a low-rank logistic regres-sion model. We first transformed the raw observed values into  X  X unniness X  probabilities by fitting a mix-ture model with two equal-variance Gaussian com-ponents to each user X  X  ratings, and using the result-ing component-posterior probabilities. This procedure also ensures scale and transformation invariability for a user X  X  ratings, and places more emphasis on users with a bimodal rating distribution than on users for which all ratings are clustered together. We proceeded to fit a low-rank logistic model (q.v. Section 3) using the observed posterior probabilities as empirical prob-abilities. Since the resulting low-rank model no longer predicts the absolute rating of jokes, we measured suc-cess by analyzing the relative ranking of jokes by each user. Specifically, for each user we held out one non-core joke which was rated among the top quarter by the user, and one non-core joke which was rated in the bottom quarter. We then measured the frequency with which the relative rankings of the predictions on these two jokes was consistent with the true relative ranking. Using this measure, we compared the logistic low-rank model to the sum-squared error methods dis-cussed above, applied to both the absolute ratings (as above) and the probabilities. Figure 4 shows the train-ing and test performance of the logistic method, the wlra method applied to the ratings, the wlra method applied to the probabilities, and the svd method ap-plied to the ratings (all other methods tested perform worse than those shown). Although the results indi-cate that the wlra method performs better than the logistic method, it is interesting to note that for small ranks, k = 2 , 3, the training performance of the lo-gistic model is better X  X n these cases the logistic view allows us to better capture the rankings than a sum-squared-error view (Schein et al. (2003) investigates the training error of other data sets, and arrives at similar conclusions). A possible modification to the logistic model that might make it more suitable for such tasks is the introduction of label noise. We have provided simple and efficient algorithms for solving weighted low-rank approximation problems. The EM algorithm is extremely simple to implement, and works well in some cases. In more complex cases, conjugate gradient descent on J  X  ( V ) provides efficient convergence, usually to the global minimum.
 Weighted low-rank approximation problems are im-portant in their own right and appear as subroutines in solving a class of more general low-rank problems. One such problem, fitting a low-rank logistic model, was de-veloped in this paper. Similar approaches can be used for other convex loss functions with a bounded Hes-sian. Another class of problems that we can solve us-ing weighted low-rank approximation as a subroutine is low-rank approximation with respect to a mixture-of-Gaussians noise model. This application will be treated in depth in a separate paper.
 Azar, Y., Fiat, A., Karlin, A. R., McSherry, F., &amp; Saia,
J. (2001). Spectral analysis of data. Proceedings of the Thirty Third ACM Symposium on Theory of Computing .
 Billsus, D., &amp; Pazzani, M. J. (1998). Learning col-laborative information filters. Proceedings of 15th International Conference on Machine Learning . Collins, M., Dasgupta, S., &amp; Schapire, R. (2002). A generalization of principal component analysis to the exponential family. Advances in Neural Infor-mation Processing Systems 14 .
 Goldberg, K., Roeder, T., Gupta, D., &amp; Perkins, C. (2001). Eigentaste: A constant time collaborative filtering algorithm. Information Retrieval , 4 , 133 X  151.
 Gordon, G. (2003). Generalized 2 linear 2 models. Ad-vances in Neural Information Processing Systems 15 .
 Irani, M., &amp; Anandan, P. (2000). Factorization with uncertainty. Proceedings of the Sixth European Con-ference on Computer Vision .
 Jaakkola, T., &amp; Jordan, M. (2000). Bayesian param-eter estimation via variational methods. Statistics and Computing , 10 , 25 X 37.
 Lu, W.-S., Pei, S.-C., &amp; Wang, P.-H. (1997). Weighted low-rank approximation of general complex matrices and its application in the design of 2-D digital filters.
IEEE Transactions on Circuits and Systems X  X  , 44 , 650 X 655.
 Schein, A. I., Saul, L. K., &amp; Ungar, L. H. (2003).
A generalized linear model for principal component analysis of binary data. Proceedings of the Ninth In-ternational Workshop on Artificial Intelligence and Statistics .
 Shpak, D. (1990). A weighted-least-squares matrix de-composition method with application to the design of two-dimensional digital filters. IEEE Thirty Third Midwest Symposium on Circuits and Systems .
 Tenenbaum, J. B., &amp; Freeman, W. T. (2000). Separat-ing style and content with bilinear models. Neural Computation , 12 , 1247 X 1283.
 Young, G. (1940). Maximum likelihood estimation and
