 The cross-media retrieval problem has received much atten-tion in recent years due to the rapid increasing of multime-dia data on the Internet. A new approach to the problem has been raised which intends to match features of different modalities directly. In this research, there are two critical issues: how to get rid of the heterogeneity between different modalities and how to match the cross-modal features of d-ifferent dimensions. Recently metric learning methods show a good capability in learning a distance metric to explore the relationship between data points. However, the traditional metric learning algorithms only focus on single-modal fea-tures, which suffer difficulties in addressing the cross-modal features of different dimensions. In this paper, we propose a cross-modal similarity learning algorithm for the cross-modal feature matching. The proposed method takes a bi-linear formulation, and with the nuclear-norm penalization, it achieves low-rank representation. Accordingly, the accel-erated proximal gradient algorithm is successfully import-ed to find the optimal solution with a fast convergence rate O (1 /t 2 ). Experiments on three well known image-text cross-media retrieval databases show that the proposed method achieves the best performance compared to the state-of-the-art algorithms.  X 
This work was supported in part by the National Ba-sic Research Program of China (Grant 2012CB316304), the National Natural Science Foundation of China (Grants 61272331, 91338202 and 91438105), the Strategic Priori-ty Research Program of the Chinese Academy of Sciences Grant (XDA06030200), Beijing Key Lab of Intelligent T-elecommunication Software and Multimedia (ITSM201502), Guangxi Key Laboratory of Trusted Software (KX201418). c H.3 [ Information Storage and Retrieval ]: Information Search and Retrieval Multimedia Retrieval; Cross-Modality; Similarity Learning; Nuclear Norm; Accelerated Proximal Gradient.
A large amount of multimedia data has been released on the Internet during the past decade, and it is still rapid-ly increasing. From this big amount of media data, there exist some popular but different modalities, such as im-ages, audios and documents. As a result, the requiremen-t of cross-modal retrieval becomes a new problem to both researchers and the industry. Examples include the het-erogenous face recognition (i.e. sketches and photos), cross-lingual retrieval, and the cross-media retrieval. Take the image-document cross retrieval as an example, given an im-age, the task is to find the documents that best describe it, or on the contrary, given several words, the task is to find the most related images.

Recently, Rasiwasia et al. [29] proposed a new approach to the multimedia information retrieval problem. In the research, the authors want to match features of differen-t modalities directly, although the cross-modal data is in rather different feature spaces. The key problem to this re-search is to best reduce the heterogeneity among the differ-ent modal features, or find a common latent space in which the different modal features can be matched to each other.
Classical algorithms have been applied to solve the prob-lem, such as the Canonical Correlation Analysis (CCA) [15, 29] and the Partial Least Squares (PLS) [30, 32]. Specifical-ly, the CCA aims at learning a latent space where the corre-lations between the projected features of the two modalities have been mutually maximized. Similar to the CCA, the PLS also learns a latent space, but with different formula-tions to extract latent vectors [30]. In the work of [29, 8], Rasiwasia et al. proposed a semantic correlation matching (SCM) algorithm to deal with the problem. In the algo-rithm, a semantic level matching is suggested to combine with the linear correlations among the features. They also pointed out that, the correlation matching (such as CCA) is not enough for cross-modal matching, and the semantic level matching brings much benefit in working out the prob-lem. This is consistent with that the class label information is very helpful to reduce the semantic gap, which is well known in the image retrieval field denoting the gap between the high level documents and low level images. Beyond these methods, there are some other algorithms to deal with the problem, such as the generalized multiview analysis (GMA) [32], the weakly paired maximum covariance analysis (WM-CA) [23], the deep neural network [27, 34], etc. [4, 28, 19, 42, 43, 41, 13].

Recently, metric learning algorithms have been popularly studied. The target of metric learning is to find a distance metric by using the similar constraints and the dissimilar constraints [39]. Following the work of Xing et al. [39], there are some popular algorithms like the Large Margin Nearest Neighbor (LMNN) [37], the Information-Theoretic Metric Learning (ITML) [9], the Relevance Component Analysis (RCA) [2], and the Discriminative Component Analysis (D-CA) which is based on the RCA [16]. Specifically, the LMNN was proposed to use a large margin setting to improve the k-NN classification. The ITML algorithm proposed by Davis et al. aims at minimizing the differential relative entropy between two multivariate Gaussians. However, these tradi-tional metric learning algorithms are designed for a single modality. They suffer the difficulty of learning the similari-ty/distance metrics between different modalities, especially with totaly different features.

Inspired by metric learning, we propose a novel logistic loss based cross-modality similarity function learning algo-rithm for the cross-media retrieval. The similarity formu-lation is in a bilinear form of two modalities, and a fast optimization algorithm is imported to find the optimal so-lution with a convergence rate of O (1 /t 2 ), where t is the number of iterations. Besides, the nuclear-norm regulariza-tion is imported in the formulation to explore the structures of the different modalities for robust learning. The proposed algorithm is applied to multimedia information retrieval on three popularly used multimedia databases for experiments, namely the Pascal VOC2007 database [12, 32], the NUS-WIDE database [7], and the Wikipedia database [29]. Ex-perimental results show that the proposed algorithm is effec-tive for cross-media retrieval. Especially, on the Wikipedi-a database the proposed algorithm outperforms the second best one for more than 6%.

The rest of the paper is organized as following. In Sec-tion 2, a concise review is given for the related works in the cross-modal information retrieval field and the metric learn-ing field. Then, in Section 3, after a brief introduction of the Metric Learning problem, the formulation of the proposed algorithm and how to find the optimal solution are intro-duced in detail. The experiments are described in Section 4 to validate the effectiveness of the proposed algorithm. Finally, Section 5 gives the conclusion of the paper.
Information Retrieval (IR) is an important problem in the multimedia field. However, many traditional methods to the problem belong to the unimodal algorithms, such as the doc-ument retrieval and the content based image retrieval. Due to the rapid development of Internet applications, the cross-modality information retrieval becomes a common scene. To retrieve an image, the query terms may be of various dif-ferent modalities, such as paragraphs, sketches and audios. Thus, cross-modal matching and learning algorithms which can match different modality data directly become a new research interest in the IR field.

Among these cross-modal matching algorithms, the CCA algorithm is the most widely used method in the multimedia field [15, 17, 29, 24]. The target of CCA is to learn a latent space by maximizing the correlating relationships between two modality features. Thus the different modal features can be projected to the latent space for similarity computation. The algorithm is also used as the correlation matching (CM) method by Rasiwasia et al. [29]. Beyond CCA, the PLS algorithm is another classical method for cross-modal data [30, 31, 32]. The core idea of it is very similar with that of CCA, which is to extract the latent vectors with maximal correlations.

In [29] where the cross-modal IR was suggested, Rasiwasi-a et al. proposed a supervised algorithm for the image-text cross-modal retrieval problem, namely the SCM algorithm. The SCM is one of the most famous and the current state-of-the-art algorithm. To reduce the semantic gap between images and documents, the sematic level matching is devel-oped based on the learned maximal correlation latent space by CCA. Thus, the algorithm can be separated into two steps. The correlational matching between different modal-ities by CCA is done in the first step. Then, based on it a semantic space is learned in the second step. As indicated in [29, 8], the class information is an important information to reduce the semantic gap. Thus, in order to use the class labels, Sharma et al. proposed a GMA algorithm to learn a discriminative latent space for cross-modal data and treat it as an eigenvalue problem. The algorithm shows great per-formance to the pose and lighting invariant face recognition and cross-modal retrieval problems.

In fact, some methods targeting to the heterogenous face recognition problem are available to deal with the cross-modality IR problem, such as the Multiview Discriminant Analysis (MvDA) method [20]. The MvDA algorithm aims at learning a common space where the between-class varia-tions from both inter-view and intra-view are maximized, and the within-class variations from both inter-view and intra-view are minimized. In the transfer learning field, some algorithms are also related [11, 22, 23, 33]. Such as in [23], Lampert and Kr  X  omer proposed a weakly-paired maximum covariance analysis method to deal with the not fully paired (not one-by-one paired) training data. Besides, Wang et al. [36] proposed an iterative algorithm based on sparsity to learn the coupled feature spaces for the different modal-ities. The work in [41] also proposed a greedy dictionary construction approach to select dictionary atoms for con-structing a modality-adaptive dictionary pair. In the deep learning field, the works [27] and [34] both used the restrict-ed boltzmann machine for the cross-modal feature learning.
In the literature of the metric learning field, Chechik et al. [6] imported an online similarity function learning for large-scale images. But the algorithm is designed for single-modality in a triplet ranking formulation. Kulis et al. also proposed to learn an asymmetric transformation matrix for domain adaption [22]. Besides, a metric learning algorithm for different modalities was also realized by Wu et al. [38]. The objective function in their work learns the projection-s for the different modalities, respectively, to best separate the similar points set and the dissimilar points set. How-ever, the pair-wise information is ignored in the algorithm. In [40] and [25], the authors also proposed to learn two pro-jections for each modality to minimize the distances of the two modalities in the target feature space. Zhai et al. also used the semantic information in the second step based on a unified k-NN graph. However, both of the algorithms are not convex, thus the optimal solution is not guaranteed. In contrast, the proposed formulation in this paper is a strict convex problem, and the optimal solution is achieved by the accelerated proximal gradient (APG) algorithm [26, 35, 3].
In this section, we give a brief review of the traditional metric learning problem, which was firstly studied by Xing et al. [39] to learn a distance metric according to the similar points and dissimilar points.

Suppose that there is a set of m data points { x i  X  R d } m where each data point is with a d dimensional feature. Be-sides, we are also given the binary similarity information in-dicating whether two data points are similar or not. Specif-ically, there are two sets of paired points, which can be de-scribed as follows: where S is called the must-link set containing the similar pairs and the D is called the cannot-link set containing the dissimilar pairs.

Given the two sets, the task of metric learning is to learn a distance metric in the following form, d ( x i , x j ) M = x i  X  x j M = ( x i  X  x j ) T M ( x i where M  X  R d  X  d is a Mahalanobis distance metric that should be learned. It can be easily found that M is sym-metric. Furthermore, to be a valid metric, M must satisfy the non-negativity and the triangle inequality. Thus M is required to be positive semi-definite, namely M 0.
Inspired by the metric learning formulation, we want to learn a similarity function to evaluate two modality fea-tures which are in different dimensions, for example the image, text pairs. In this way, the different modality fea-tures can be matched directly with the learned similarity function. The proposed formulation is introduced as follows.
Suppose that there is a multimedia database A = { ( x 1 ,l ( x 2 ,l x 2 ) ,..., ( x m ,l x m ) , ( z 1 ,l z 1 ) ,..., ( z two-modality data sets X and Z . Sample x i  X  R d 1 is from the modal X , such as the image, document, or audio, and z the modality X , where d 1 and d 2 are dimensions of the two modality features, respectively. The l x i and l z j are the class labels of the samples x i and z j respectively. The connec-tion between the two modalities is that they share c classes, for example, dog, shoes and buildings. The cross matching problem is how to match the cross-modal samples x i and z directly.

Similar with the metric learning, we also define two pair-wise sets on the cross-modal samples, where S is the must-link set with similar pairs from the two different modalities, and D is the cannot-link set with dissimilar pairs from the two modalities.

Based on these definitions, we want to learn a similarity function which can measure the similarity between any two different modal features. The formulation of the proposed algorithm is min where S M ( x i , z j ) is the similarity function parameterized by a matrix M  X  R d 1  X  d 2 , which is to be learned in a bilinear form,
The formulation in Eqn.(4) contains a loss function item and a regularization item. The loss function is based on the logistic sigmoid function [14],  X  ( x )=1 / (1 + exp( which is often integrated in  X  log(  X  ( x )) to approximate the hinge loss function to avoid the discontinuity of the gradient. Here, y ij  X  X  +1 ,  X  1 } is a sign indicating whether the pair is similar (positive) or dissimilar (negative). Specifically, For w ij in the formulation, it stands for the weight of the ( x i , z j ) pair, which is used to deal with unbalanced posi-tive and negative samples. In our experiments, we set the weights for positive (negative) pairs to be the reciprocal of the number of positive (negative) pairs.

As for the regularization term in Eqn.(4), the nuclear nor-m  X   X  is used, which is defined as the sum of the singular values of a matrix. The functions of the nuclear norm in the proposed formulation lie in two folds. On one fold, the constraint can be treated as a scale regularization of M .It makes the solution to Eqn.(4) in a constrained domain. On the other fold, the nuclear norm can make the learned met-ric matrix M with a low rank, which is a desirable property and has been widely used in the machine learning field. In the problem Eqn.(4), the nuclear norm may help to discover the connections between the two modalities and result in a robust learning.
In this subsection, the accelerated proximal gradient al-gorithm (APG) [26, 35] is utilized to find the optimal solu-tion of Eqn.(4). The APG algorithm is a kind of first order gradient descent method [3, 18, 26, 35], which has received popular attentions in recent years due to its fast convergence rate of O (1 /t 2 ) when dealing with the problem of convex and smooth loss function regularized by non-smooth constraints.
For convenience, the formulation in Eqn.(4) can be rewrit-ten as where Note that l ( M ) is a smooth and convex function, and the ob-jective function is convex. Accordingly, the APG algorithm canbeusedtosolvetheproposedformulation.

To find the optimal minimizer, we first construct a proxi-mal operator of the Eqn. (7), which is where { Q t } is a sequence of the search points, l ( Q t gradient of l (  X  )atthe Q t point, and  X  t istheupdatestep size at the t -th iteration. The l ( Q t )is By defining a matrix T with each entry T ij as we can conveniently compute T as where is the element-wise product of two matrices. W  X  R m  X  n is the weight matrix with w ij foreachpairofthe cross-modal samples, and Y  X  R m  X  n is the sign matrix with y ij defined in Eqn.(6). The X  X  R d 1  X  m is the data matrix containing the m samples of the modality X ,and Z  X  R d 2  X  n consists of the n samples of the modality Z .
With these definitions, Eqn.(10) can be simplified as
By removing the constant term l ( Q t ) and adding another constant term  X  t l ( Q t ) 2 2 / 2withrespectto M , the proxi-mal operator of Eqn. (9) is equal to where According to [5], the minimization of the objective func-tion Eqn.(14) can be solved by a soft-thresholding tech-nique. Firstly, the singular value decomposition (SVD) is used to find the eigenvalues for the matrix  X  M . Then, a soft-thresholding is applied on the computed eigenvalues. In summary,
Theorem 1. Assume matrix L  X  R m  X  n and the SVD decomposition of it is L = U X V T ,where U  X  R d 1  X  r and V  X  R d 2  X  r are constructed by orthogonal vectors, and  X  is a diagonal matrix with diagonal values  X  ii  X  0 and rank (  X  )= r . Then the following objective function [5] Algorithm 1: Optimization for Eqn. (4).
 1 Initialization Q t = 0 ,t =1; 2 repeat 3 Compute  X  M t as in Eqn. (12) (13) (15); 4 Decompose  X  M t = U X V T ; 6 Update Q t +1 as in Eqn. (17). 7until convergence ; has a closed-form solution C  X  ( M )= U X   X  V T ,where ( X   X  max { 0 ,  X  ii  X   X  } is the soft-thresholding result of the matrix  X  by the regularization parameter  X  .

The proof can be found in the Appendix. Accordingly, we get the M t +1 = U X   X  X  t V T . Then, the APG algorithm accelerates the proximal gradient descent by updating Q t with where  X  t +1 =(1+ 1+4  X  2 t ) / 2and  X  1 =1. Infact,the  X  can be updated in other ways if the certain conditions are satisfied [26, 35]. As for the step size  X  t ,itcanbeestimated in the algorithm by comparing the objective function and its proximal operator [3], whose derivation is omitted here due to the paper length.

It turns out that the APG algorithm updates M t and Q t iteratively to find the optimal solution, and the searching point Q t is a linear combination of the latest two solutions of M t and M t  X  1 . The steps of the proposed algorithm is summarized in Algorithm 1.
In this section, the proposed low rank bilinear similarity learning algorithm (denoted as LRBS) is compared with sev-eral popular and state-of-the-art algorithms by experiments on three famous image-text databases.

Compared Methods: To evaluate the performance of the proposed algorithm, several famous algorithms in the cross-media retrieval field were compared in the experiments, including the popular methods CCA [15, 29] and PLS [30, 31], and the state-of-the-art methods SCM [29], the Mi-crosoft algorithm (MsAlg) [38], and the Generalized Multi-view Analysis methods, including the GMLDA (Generalized Multiview Linear Discriminant Analysis) and the GMMFA (Generalized Multiview Marginal Fisher Analysis) [32]. A brief introduction of these algorithms can be found in the related work section.

Evaluation Metrics: For the evaluation, the mean av-erage precision (MAP) and the precision-recall curve met-rics were used in the experiments. In fact, both of them are popularly used in evaluation of information retrieval systems. Given one query and its N retrieved documents in a rank, the average precision is computed by AveP = documents in the retrieval, P ( r ) is the precision of the top r retrieved documents, and rel ( r ) is a binary function denot-ing whether the r -th retrieved document is relevant to the Table 1: MAP (%) results on the Pascal VOC2007 query or not. Having the AveP calculated for each query, the MAP is computed as the average AveP score of all queries. Besides of the MAP and precision-recall curve, we also dis-played the precision-scope curve for a better visualization, where the scope denotes the number of retrieved documents. Therefore, by the precision-scope curve it is more easily to see the precision of the top r documents presented to the users.
In the experiments, three famous images and texts databas-es in the multimedia retrieval field are used to evaluate the performance of the proposed algorithm, namely the Pascal VOC2007 database, the Wikipedia database, and the NUS-WIDE database.

The Pascal VOC2007 dataset consists of 9963 images from 20 categories [12], which was split into a training set with 5011 images and a test set with 4952 images. Since some of the images are with multi-labels, the images con-taining only one object were selected in the experiments [32]. As a result, there are 2808 images for the training set and 2841 images for the test set. For the features, the 399-dimensional word frequency feature [17] was used for the text, and the convolutional neural network (CNN) feature, which was trained on the ImageNet [21], was used as the image feature. The CNN source code, namely Decaf [10], can be freely downloaded on the web for research purpose 1 In the experiments, only the outputs of the sixth layer were used as the image feature, resulting in 4096 dimensions.
The Wikipedia dataset 2 is constructed from the Wikipedi-a X  X   X  X eatured articles X , which is a continually updated collec-tion selected and reviewed by the Wikipedia X  X  editors since 2009. Among the articles in the collection, Rasiwasia et al. built a dataset by selecting ten popular categories [29]. Each image in the dataset is associated with a section of at least 70 words. In total, the dataset consists of 2866 image-document pairs. In [29], the dataset was randomly split into a training set of 2173 image-document pairs and a test set of the remaining 693 pairs. The text feature was derived http://daggerfs.com/ http://www.svcl.ucsd.edu/projects/crossmodal/ Table 2: MAP (%) results on the Wikipedia database. Table 3: MAP (%) results on the NUS-WIDE database. from the Latent Dirichlet Allocation model (LDA) with 200 topics [8]. Similar as on the Pascal VOC2007 database, the CNN feature was also used for the images on this dataset.
The NUS-WIDE dataset is a large-scale real-world database where the images were crawled from the  X  X lickr X  website by the Media Search Lab in the National University of Singa-pore [7]. The database is constructed with 269,648 images associated with tags. The organizers has labeled the im-ages with 81 concepts for evaluation. They also provided all the URLs of the images on the web to facilitate further re-search 3 . In the experiment, we used 40 concepts which con-tained the most uniquely labeled images, and 250 images per concept were randomly selected for evaluation. The selected images were further randomly separated into a training set and a test set, which contain 6000 images and 3630 images respectively. Again, the CNN feature for the images was used in the experiment. As for the text feature, the provid-ed 1000-dimensional word frequency feature by the database organizers [7] was imported. http://lms.comp.nus.edu.sg/research/NUS-WIDE.htm retrieval experiment and the Text-to-Image retrieval experiment. In the experiments, we found that the CCA, PLS and G-MA algorithms all performed better with PCA dimensional reduction than without it. Thus, we displayed both the ex-perimental results with PCA and without PCA for all the algorithms. With PCA, about 99% energy were preserved for the features. As a result, the dimension of the CNN image feature was reduced to 1000 on the three databas-es. As for the text feature, it was reduced to 200 on the Pascal VOC2007 database, 180 on the Wikipedia and 800 on the NUS-WIDE database. The MAPs of the experimen-tal results are shown in Table 1, Table 2 and Table 3 for the VOC2007, the Wikipedia and the NUS-WIDE databas-es respectively, where the black bold numbers are the best performances, and the blue bold ones are the second best across the performances with PCA and not with PCA. The precision-recall and precision-scope curves are shown in Fig-ure 1, 2 and Figure 3 for the three datasets, respectively.
From Table 1, Table 2 and Table 3 it can be observed that the proposed LRBS algorithm achieves the best perfor-mance on the three databases. On the Wikipedia dataset, no matter with PCA and without PCA, the proposed method performs about 6% higher than the second best algorithm (the GMMFA algorithm with PCA and the MsAlg algorithm without PCA). The followings are MsAlg with PCA, GML-DA with PCA and the SCM with PCA, which perform com-parable to each other. This ranking is similar with that on the NUS-WIDE database. On the VOC2007 dataset, LRB-S outperforms the second best one, the GMLDA algorithm with PCA, by 1%. The followings are the SCM with PCA and the MsAlg algorithms. It can be also observed that the GMMFA and the GMLDA perform closely to each other on thethreedatasets.

It should be noted that the CCA without dimensional reduction cannot be applied since the feature matrix is not with full rank. This is the same with the SCM which needs CCA as the first step for correlation matching. Obviously, the GMA methods with PCA dimensional reduction perform better than without PCA. In contrast, for the PLS, MsAlg, and LRBS algorithms, they perform almost the same with PCA dimensional reduction and without it. The reason may lie in that the PCA dimension reduction removes part of the redundant information and noises. However, PCA may also discard some useful information at the same time. This may be the reason that the performances of the MsAlg and LRBS algorithms do not improve with PCA.

Table 1, 2 and 3 also show that the supervised algorithms (the MsAlg, GMMFA, GMLDA, SCM and LRBS algorithm-s) clearly outperform unsupervised ones (the CCA and the PLS). It is because the class information used in supervised learning could partly reduce the semantic gap between low-level image features and high-level semantic meanings. The work in [8] also found that the combination of correlation matching and semantic matching can work better.

Figure 1, Figure 2 and Figure 3 display the precision-recall curves and the precision-scope curves of the compared algorithms for the image-text cross retrieval task. The per-trieval experiment and the Text-to-Image retrieval experiment. formances of the GMA methods without PCA dimensional reduction are not shown in the figures due to the low perfor-mances. Note that the figures on show the best performance of each compared algorithm. For example, since the per-formance of the MsAlg method with PCA is slightly lower than without PCA, the figures just display the performance of the MsAlg without PCA. In these figures, it is also ob-served that the proposed algorithm has the best performance on all databases, followed by GMLDA, GMMFA and MsAl-g methods, which are comparable to each other. From the precision-recall figures, it is clearly that with the same recall rate, the proposed method gets the highest precision in all compared algorithms, especially on the Wikipedia dataset. This is similar with the precision-scope curves, which plot the precision under different numbers of the top r retrieved samples. In summary, the experimental results show that the proposed algorithm successfully learns a similarity func-tion for cross-modal matching.

In Figure 6, the singular values of the learned similarity metric matrix are shown, which contains the top 80 singular values. From the figure we can see that the learned M has a low rank, indicating that the proposed LRBS algorithm succeeds to find the similar structures in the data. It can be seen that the similarity metric of the Wikipeda dataset has the lowest rank. This is partly because the Wikipedia dataset only contains 10 categories. In contrast, the NUS-WIDE dataset contains the most categories, thus its similar-ity metric has a relatively high rank. In Figure 4 and Figure 5, some retrieved samples by the proposed LRBS algorithm Figure 6: The singular values of the learned similar-ity function matrix M on the three databases, where the values are shown in gray, and the 1 of gray value is the most lightest. (a) On the Wikipedia database; (b) On the Pascal VOC2007 database; (c) On the NUS-WIDE database. in the experiment are shown. The retrieved samples also indicate that the LRBS is an effective cross-modality infor-mation retrieval algorithm.
In this paper, we proposed a novel similarity function learning method inspired by metric learning algorithms. The similarity function is learned in a bilinear form of two dif-ferent modality features, which can handle cross-modal fea-tures with different dimensions. The accelerated proximal gradient method is successfully imported to find the optimal solution with a fast convergence rate. Besides, we also im-retrieval experiment and the Text-to-Image retrieval experiment. database. ported the nuclear-norm to explore the structures and con-nections of the two modalities. The experiments are evaluat-ed on three famous multimedia databases for the image-text cross-modal information retrieval problem, showing that the proposed algorithm has the best performance compared to the state-of-the-art algorithms.
Additional author: Chunhong Pan (Institute of Automa-tion, Chinese Academy of Sciences, email: chpan@nlpr.ia.ac.cn ). [1] F. R. Bach. Consistency of trace norm minimization. [2] A. Bar-Hillel, T. Hertz, N. Shental, and D. Weinshall. [3] A. Beck and M. Teboulle. A fast iterative shrinkage-[4] M. Bronstein, A. Bronstein, F. Michel, and [5] J.-F. Cai, E. J. Cand` es, and Z. Shen. A singular value [6] G. Chechik, U. Shalit, V. Sharma, and S. Bengio. An [7] T.-S. Chua, J. Tang, R. Hong, H. Li, Z. Luo, and [8] J. Costa Pereira, E. Coviello, G. Doyle, N. Rasiwasia, [9] J. V. Davis, B. Kulis, P. Jain, S. Sra, and I. S. [10] J. Donahue, Y. Jia, O. Vinyals, J. Hoffman, N. Zhang, [11] L. Duan, D. Xu, and I. W. Tsang. Learning with [12] M. Everingham, L. Van Gool, C. K. I. Williams, [13] Y. Gong, Q. Ke, M. Isard, and S. Lazebnik. A [14] M. Guillaumin, J. J. Verbeek, and C. Schmid. Is that [15] D. R. Hardoon, S. Szedm  X ak, and J. Shawe-Taylor. [16] S. C. H. Hoi, W. Liu, M. R. Lyu, and W.-Y. Ma. [17] S. J. Hwang and K. Grauman. Accounting for the [18] S. Ji and J. Ye. An accelerated gradient method for [19] Y. Jia, M. Salzmann, and T. Darrell. Learning [20] M. Kan, S. Shan, H. Zhang, S. Lao, and X. Chen. [21] A. Krizhevsky, I. Sutskever, and G. E. Hinton. [22] B. Kulis, K. Saenko, and T. Darrell. What you saw is [23] C. H. Lampert and O. Kr  X  omer. Weakly-paired [24] A. Li, S. Shan, X. Chen, and W. Gao. Face [25] A. Mignon and F. Jurie. CMML: a New Metric [26] Y. Nesterov. Introductory Lectures on Convex [27] J. Ngiam, A. Khosla, M. Kim, J. Nam, H. Lee, and [28] Y. Pan, T. Yao, T. Mei, H. Li, C.-W. Ngo, and [29] N. Rasiwasia, J. C. Pereira, E. Coviello, G. Doyle, [30] R. Rosipal and N. Kr  X  amer. Overview and recent [31] A. Sharma and D. W. Jacobs. Bypassing synthesis: [32] A. Sharma, A. Kumar, H. D. III, and D. W. Jacobs. [33] R. Socher, M. Ganjoo, C. D. Manning, and A. Y. Ng. [34] N. Srivastava and R. Salakhutdinov. Multimodal [35] P. Tseng. On accelerated proximal gradient methods [36] K. Wang, R. He, W. Wang, L. Wang, and T. Tan. [37] K. Weinberger, J. Blitzer, and L. Saul. Distance [38] W. Wu, J. Xu, and H. Li. Learning similarity function [39] E. P. Xing, A. Y. Ng, M. I. Jordan, and S. J. Russell. [40] X. Zhai, Y. Peng, and J. Xiao. Heterogeneous metric [41] F. Zhu, L. Shao, and M. Yu. Cross-modality [42] J. Zhuang and S. C. H. Hoi. A two-view learning [43] Y. Zhuang, Y. F. Wang, F. Wu, Y. Zhang, and W. Lu.
Proof. Considering that the objective function in Eqn. (16) is a strongly convex function, a unique solution exists. Thus we just need to prove that the optimal solution is equal to C  X  ( M ) [5]. Considering that  X  M is the optimal solution of Eqn.(16) if and only if 0 is a subgradient of the function at the point  X  M ,wehave where the  X   X  M  X  is the subgradient of the nuclear norm. Let the SVD decomposition of an arbitrary matrix A  X  R m  X  n is A = P 1  X P T 2 , then the subgradient of its nucle-ar norm is [1, 5] Denote the SVD decomposition of L in Eqn.(16) as where U 0  X  0 V T 0 is the part of SVD with singular values greater than  X  , and the U 0  X  0 V T 0 corresponds to the re-maining part. By denoting  X  M = C  X  ( M ), we have Therefore, where It turns out that U T 0 S =0, SV 0 =0,and S 2  X  1s-ince  X  1 is bounded by  X  . Finally, we have proved that L  X  C  X  ( M )  X   X  X  C  X  ( M )  X  , which shows that C  X  ( M )is the optimal solution of Eqn.(16).
