 Recommender Systems (RSs) can be vulnerable to manipulation by malicious users who successfully bias recommendations for their own benefit or pleasure. These are known as attacks on RSs and are typically used to either promote ( X  X ush X ) or disparage ( X  X uke X ) tar-geted items contained within the recommender X  X  user-item dataset. Our recent work with the Power User Attack (PUA) model, deter-mined that attackers disguised as influential power users can mount successful (from the attacker X  X  viewpoint) push attacks against user-based, item-based, and SVD-based recommenders. However, the success of push attack vectors may not be symmetric for nuke at-tacks , which target the opposite effect  X  reducing the likelihood that target items appear in users X  top-N lists. The asymmetry be-tween push and nuke attacks is highlighted when evaluating these attacks using traditional robustness metrics such as Rank and Pre-diction Shift. This paper examines the PUA attack model in the context of nuke attacks, in order to investigate the differences be-tween push and nuke attack orientations, as well as how they are evaluated. In this work we show that the PUA is able to mount suc-cessful nuke attacks against commonly-used recommender algo-rithms highlighting the  X  X uke vs. push X  asymmetry in the results. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Information filtering Recommender Systems; Power Users; Attacks; Evaluation
As with many online systems, recommenders are subject to at-tack by devious or self-interested users who enter false information to either promote items (push), disparage their competition (nuke), or simply to disrupt the RS results [7, 5, 6]. Although system oper-ators do not usually disclose detailed information about attacks on their systems, we know that real attacks on RSs are not uncommon, the most popular being the use of fake reviews known as opinion spam. 1 The problem with attacks on ratings-based Collaborative Filtering (CF) recommenders is that they can corrupt the system dataset and cause users to distrust the recommendations provided.
We have previously studied a novel category of RS attacks based explicitly on measures of influence, in particular the potential im-pact of high-influence, or power users [13]. Power users in the RS context are those that are able to influence the largest group of RS users; influence is indicated by the ability of power user i to change (positively or negatively) the RS prediction for another user j , or for power user i  X  X  target item to appear in user j  X  X  top-N list. We found that Power User Attacks (PUAs) impacted user-based, item-based, and SVD-based recommenders [13, 10, 14, 11] for push attacks .
For this study, we turned our attention to the complementary no-tion of nuke attacks to determine whether the PUA could also be successful nuking selected target items. Nuke attacks are designed to reduce the likelihood that a target item is recommended; their objective is to impact RS robustness metrics 2 by increasing Rank and causing negative Prediction Shift [5, 6]. However, while they may employ similar mechanisms for attack, the goals for push and nuke attacks are really asymmetric. Push attacks attempt to move items from a large pool not being presented to the user into the viewed recommendation list. Nuke attacks attempt to move items from the small pool of viewed recommendations into the great un-shown. And these contextual differences have implications for eval-uating the attacks. For example, if a nuke attack effectively shifts target items down the list, but all of the movement is below the threshold of visibility to the user, is that a good measure of effec-tiveness? In the nuke attack context, and using robustness metrics, the objectives of this paper are to study (1) the effectiveness of the PUA against common RSs, and (2) the effectiveness of various power user selection methods on attack results.
Attacking RSs by entering false ratings has been termed a pro-file injection attack [6] or shilling attack [5]. Burke et al provide a summary overview of RS attack models, attack detection, and al-gorithm robustness [1]. Most of the attack research has targeted the use of similarity-focused attack models that generate synthetic at-
Example nuke attack: http://www.dailymail.co.uk/travel/article-2059000/TripAdvisor-controversy-Reviews-website-launches-complaints-hotlines.html Rank indicates the ordinal position of a target item in a user X  X  top-N list sorted descending based on predicted rating value, Prediction Shift indicates the average shift in predicted values of specified tar-get items, before and after the attack. Traditionally used for evalu-ating only push attacks, Hit Ratio is percentage of users that have a target item in their top-N list, tack user profiles using random or average item ratings or a variant of these two approaches [5, 6]. Nuke attack models developed and explored in [5, 6], indicated that user-based recommenders were more vulnerable to nuke attacks than item-based.

Our research has investigated using explicit measures of influ-ence to create attack models based on the notion of influential power users [13]. In earlier work, we defined the Power User Attack model as a set of power user profiles with biased ratings that influence the results presented to other users [13, 14]. The PUA demonstrated that influential users can impact common recommender approaches [13, 10, 14, 11] with push attacks. However, the PUA model has not yet been tested in the nuke attack context.
 To evaluate nuke attacks, researchers [5, 6] have used Prediction Shift metrics to measure impacts on prediction values before and after the attack, and metrics such as Rank and Expected top-N Oc-cupancy (ExpTopN) 3 that measure the effect an attack will have on top-N recommendation lists. These studies, however, have not explicitly indicated whether or not the target items were in the top-N lists before the attack. This is important to note because, while Rank (or ExpTopN) and Prediction Shift can indicate the impact that the nuke attack has on the target items, they only really matter to an attacker if the target items are actually removed from users X  top-N lists as a result of the attack . In this study, we evaluate the asymmetric aspect of the nuke PUA and, extending prior research approaches, use Hit Ratio to explicitly indicate the extent to which target items appear in the top-N lists before and after the attack.
Nuke attacks using various attack models have previously been evaluated [6] by measuring Rank and Prediction Shift of the tar-get items. Rank was measured before the attack (as a baseline) and after the attack to measure the impact; negative Prediction Shift in-dicated that the predicted values decreased as a result of the attack. Lam and Riedl [5] used ExpTopN and Prediction Shift in their eval-uation. Results of those studies indicated that (1) user-based recom-menders were more vulnerable than item-based, and (2) effective attacks are those that increase target item Rank beyond top-N or have a negative ExpTopN, and have a negative Prediction Shift.
For this study, we introduce the use of the Hit Ratio metric in the evaluation of the nuke attacks 4 , i.e., using Hit Ratio, we measure the extent to which target items appear in top-N lists BEFORE the attack and then observe their top-N status AFTER the attack. A successful nuke attack would reduce Hit Ratio and increase Rank, in contrast to push attacks where the objective is to increase Hit Ratio and decrease Rank. To evaluate the impact of a nuke attack on users X  top-N lists, we chose Most Popular (highest number of ratings) and Most Liked (highest average rating) items as target items because they would most likely appear in top-N lists before the nuke attack, and they would be more challenging to nuke than either new or new and established items. We chose a top-N list size of 40 based on analysis in [5] that the median recommendation search ends within the first 40 items displayed.

To study the impacts of the PUA, we use power user selection methods to generate synthetic power user (SPU) profiles [14]: InDegree or ID: Based on in-degree centrality [12], power users are those who participate in the highest number of similarity neigh-borhoods. We developed this method in previous work [13, 14].
ExpTopN is the expected number of occurrences of target items in a top-N recommendation list [5].
In prior research, Hit Ratio was not used because of concerns that nuked items would drop out of the retrieval windows, making Hit Ratio differences insignificant [6].
 Number of Ratings (NumRatings or NR): Power users were de-fined in [4] as users with the highest number of item ratings. Random (Rand): To contrast with InDegree and NumRatings power users, this method selects users randomly from the entire set of users in the RS dataset.
 Two experiments were used to evaluate power user nuke attacks: Experiment 1 (E1): To compare with previous work in [6], we se-lect new and established target items, mount the nuke attack against CF RS algorithms, inject the dataset with SPU attack profiles, and evaluate the impact of the PUA using Rank and Prediction Shift. Experiment 2 (E2): To evaluate the effect of a nuke attack on top-N recommendation lists, we select Most Popular and Most Liked tar-get items, mount the nuke attack against various CF RS algorithms, inject the dataset with SPU attack profiles, and evaluate the attack impact using Hit Ratio, Rank, and Prediction Shift metrics. For this experiment, Rank after attack and Prediction Shift are based on tar-get items that were in the top-N list before the attack. For these experiments, we test two hypotheses: H1: A PUA with relatively small number of attackers ( &lt; = 5% of all users) can have significant effects on RS predictions and top-N rec-ommendations, as measured with Hit Ratio, Rank, Prediction Shift. H2: Attackers identified using InDegree power user selection will have a higher level of impact, compared to attackers identified us-ing NumRatings or Rand, on RS predictions and top-N recommen-dations, as measured with Hit Ratio, Rank, Prediction Shift. Evaluation Metrics : Evaluations were performed before and af-ter the attacks using the Apache Mahout platform 5 . For robustness metrics [6], we use Hit Ratio (HR), Average HR ( HR ), Prediction Shift (PS), Average PS ( P S ), Rank (R), and Average R ( R ); the Average metrics are averaged over all users and target items. After a nuke attack, low HR , high R , and negative P S indicate that the attack was successful (from the attacker X  X  viewpoint).
 Datasets and Algorithms : We used the public MovieLens 6 ML100K dataset. The RS algorithms used were provided in Apache Mahout and customized (except SVD) for this study. The CF user-based al-gorithms (user-based weighted or UBW [2], and user-based mean-centered or UMCP [8]) use Pearson similarity with a threshold of 0.0 (positive correlation), neighborhood size of 50, and significance weighting of n/50 where n is the number of co-rated items [3]. The item-based weighted algorithm (IBW) [9] uses Pearson similarity with a threshold of 0.0 and significance weighting of n/50. For the SVD-based algorithm (SVD), we used RatingStochasticGradient-Descent (RSGD); run-time parameter settings, number of features (=100) and number of iterations (=50), were determined empiri-cally to optimize recommender accuracy.
 Attack User Profiles : To mount the Power User Nuke Attack, SPU profiles were generated as described in [14] and converted to attack user profiles by setting target item ratings to reflect a nuke attack. Power User Selection : Methods used for power user selection are described in  X  3. Randomly-selected SPU attackers (Rand) had the following average number of ratings, average rating, and average rating entropy, respectively: 10 SPUs: 133.00, 3.451, 2.014; 50 SPUs: 126.68, 3.454, 1.964; 100 SPUs: 129.94, 3.281, 2.161. Target Item Selection : For E1, we used  X  X ew and established X  items, i.e., 50 target items were selected randomly and had the following average number of ratings, average rating, and average rating entropy for ML100K: 73.78, 3.133, 1.769. For E2, we used http://www.mahout.apache.org http://www.grouplens.org nominal 100,000 ratings, 1,682 movies, and 943 users. Most Liked items (top-50 items with highest average rating) and Most Popular items (top-50 items with highest number of ratings). Most Liked and Most Popular items had the following average number of ratings, average rating, and average rating entropy, re-spectively, for ML100K: 130.56, 4.471, 1.109 for Most Liked and 356.82, 3.864, 1.859 for Most Popular.
 Attack Parameter Selection : The Attack Intent is Nuke, i.e., target item ratings are set to the minimum rating (= 1) at run time. The Attack Size, or number of SPU attackers, was varied for these ex-periments: 1% (10 SPUs), 5% (50 SPUs), and 10% (100 SPUs). Test Variations : Three power user selection methods, 4 CF algo-rithms, 3 attack sizes. In E1 we used one target type, and in E2 we used 2 target types. Each variation was run multiple times Figure 1: Experiment 1: Average Rank Results (After Attack) for New and Established Target Items, ML100K Figure 2: Experiment 1: Average Prediction Shift Results for New and Established Target Items, ML100K
In this experiment, we select 50 new and established target items from the ML100K dataset. Attacks are conducted for three levels of attack size (1%, 5%, and 10%) for each of the three power user types (ID, NR, and Rand) and using each of the four recommender algorithms (UBW, UMCP, IBW, SVD). For each variation, we run multiple attacks 8 . The R results after attack are shown in Figure 1. Before the attack (not shown), R for UBW and UMCP ranges from 500 to 600, for IBW about 700, and for SVD about 800. In most
Each attack is run 50 times, each with a different target item; then the results are averaged over all 50 targets.
 Figure 3: Experiment 2: Average Hit Ratio Results (Before and After Attack) for Most Liked Target Items, ML100K cases after the attack, the differences in impacts between 1%, 5%, and 10% attack sizes are significant. The increase in R for each power user type varies between 1.2X to 1.75X between before and after attack, compared to 2X increase using various attack models reported by ([6] who used only UMCP. The IBW algorithm showed the least amount of R increase, indicating its robustness to this at-tack. Results for P S in Figure 2 indicate that UBW, UMCP, and SVD algorithms are vulnerable to this attack showing strong neg-ative impacts, whereas, IBW is robust to attack showing a positive shift (this positive shift in IBW was also reported by [6] for various attack models). Thus, for new and established target items, a pre-diction shift of -1.0 would reduce the average rating from 3.13 to 2.13, which could discourage some users from watching those rec-ommended movies. Hypothesis H1 is accepted for UBW, UMCP, and SVD recommenders, meaning that a relatively small number of power users (5% or less of the user base on a given dataset) can have significant effects on RS predictions and top-N lists of recom-mendations regardless of power user selection method. Hypothesis H2 is accepted for UBW, UMCP, and SVD recommenders, with In-Degree having a slight advantage over NumRatings as indicated in the R and P S results; and both methods are superior to Random.
The motivation for Experiment 2 was to evaluate the nuke attack in a manner consistent with push attacks, i.e., showing the impact that the attack has on the top-N list of recommendations provided to the users. In the case of nuke attacks, however, the attacker X  X  goal is to remove the target items from the top-N list of recom-mendations. Figure 3 indicates that Most Liked items appearing in the top-N lists before the attack did not remain after the attack for UBW, UMCP, and SVD; results also show that IBW is minimally affected by this attack. Results for Most Popular items (not shown) are similar albeit not as impactful: before the attack HR was 7% for UBW and UMCP, 10% for SVD, and slightly above 0% for IBW; Figure 4: Experiment 2: Average Rank Results (After Attack) for Most Liked Target Items, ML100K Figure 5: Experiment 2: Average Prediction Shift Results for Most Liked Target Items, ML100K after the attack HR was close to 0% across algorithms and attack sizes except for the 1% attacks. For Most Liked and Most Popu-lar targets, the 1% attacks show relatively higher HR values after attack indicating that the attack was not as successful as the 5% and 10% attacks (as expected). Although not shown, R before the attack was relatively stable and averaged 21.4 for Most Liked and 27.1 for Most Popular across all algorithms and attack sizes. Fig-ure 4 shows R results after the attack for Most Liked indicating a significant rise in R ; results for Most Popular (not shown) also rise albeit not to the same high levels. Average Most Liked high R val-ues using 10% attacks for UBW, UMCP, IBW, and SVD were 734, 747, 386, 879, respectively; they were 381, 527, 375, and 345 for Most Popular. Figure 5 shows P S results after the attack for Most Liked indicating strong results for UBW, UMCP, and SVD; results for Most Popular (not shown) also show P S &lt; 0 albeit not to the same levels of reduction. Average Most Liked low P S values using 10% attacks for UBW, UMCP, IBW, and SVD were -1.99, -1.93, -0.36, -1.59, respectively; they were -0.88, -0.94, -0.25, -0.46 for Most Popular. Based on these results, we see that Most Liked tar-gets are significantly more vulnerable to attack than Most Popular targets. With InDegree and NumRatings selection methods, predic-tion values can be reduced by about 2 points, e.g., from a 4 rating down to 2 compared to a 0.5 point reduction for Most Popular tar-get items. We also see that IBW is more robust to attack for both Most Liked and Most Popular targets. Hypothesis H1 is accepted for UBW, UMCP, and SVD recommenders. Hypothesis H2 is par-tially accepted for UBW and UMCP, and SVD recommenders. Al-though the InDegree and NumRatings both perform well at a high level, NumRatings occasionally shows slightly better results; and both methods are superior to Random.
This study evaluated power user nuke attacks mounted against various CF RS algorithms as measured by traditional robustness metrics. User-based and SVD-based algorithms are shown to be vulnerable, while item-based is more robust to nuke attacks. We showed that Most Liked target items are more vulnerable to attack than Most Popular targets, and that a relatively few NumRatings and InDegree synthetic user profiles can have significant effects on RS predictions and top-N recommendation lists. Future work includes evaluation with larger datasets and other domains. [1] R. Burke, M. P. O X  X ahony, and N. J. Hurley. Robust [2] C. Desrosiers and G. Karypis. A comprehensive survey of [3] J. L. Herlocker, J. A. Konstan, A. Borchers, and J. Riedl. An [4] J. L. Herlocker, J. A. Konstan, L. G. Terveen, and J. Riedl. [5] S. K. Lam and J. Riedl. Shilling recommender systems for [6] B. Mobasher, R. Burke, R. Bhaumik, and C. Williams. [7] M. P. O X  X ahony, N. Hurley, and G. C. M. Silvestre.
 [8] P. Resnick, N. Iacovou, M. Suchak, P. Bergstrom, and [9] B. Sarwar, G. Karypis, J. Konstan, and J. Riedl. Item-based [10] C. E. Seminario and D. C. Wilson. Assessing impacts of a [11] C. E. Seminario and D. C. Wilson. Attacking item-based [12] S. Wasserman and K. Faust. Social Network Analysis: [13] D. C. Wilson and C. E. Seminario. When power users attack: [14] D. C. Wilson and C. E. Seminario. Evil twins: Modeling
