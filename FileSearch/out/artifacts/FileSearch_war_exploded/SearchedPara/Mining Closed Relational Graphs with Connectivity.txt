 Relational graphs are widely used in modeling large scale networks such as biological networks and social networks. In this kind of graph, connectivity becomes critical in iden-tifying highly associated groups and clusters. In this paper, we investigate the issues of mining closed frequent graphs with connectivity constraints in massive relational graphs where each graph has around 10 K nodes and 1 M edges. We adopt the concept of edge connectivity and apply the results from graph theory, to speed up the mining process. Two approaches are developed to handle different mining re-quests: CloseCut , a pattern-growth approach, and Splat , a pattern-reduction approach. We have applied these meth-ods in biological datasets and found the discovered patterns interesting.
 Categories and Subject Descriptors: H.2.8 [Database Management]: Database Applications -Data Mining General Terms: Algorithms Keywords: graph, closed pattern, connectivity
Graphs are natural representations of complicated struc-tures and relationships among objects. Algorithms proposed in [9, 10, 22, 17, 1, 8] can find frequent subgraphs effi-ciently in chemical compound datasets. These algorithms have been successfully used in protein classification [8] and graph indexing [24]. There exists a specific kind of graph structure, called relational graph , where each node label is used only once per graph. Relational graph is widely used in modeling and analyzing massive networks, e.g., biologi-cal networks, social networks, transportation networks and the world wide web. In biological networks, nodes repre-sent objects like genes, proteins and enzymes while edges  X  The work was supported in part by U.S. National Science Foundation NSF IIS-02-09199, Univ. of Illinois, and an IBM Faculty Award.
 encode the relationships such as control, reaction and corre-lation between these objects. In social networks, each node represents a unique entity and an edge describes a kind of relationship between entities. For instance, the Digital Bib-liography &amp; Library Project (DBLP) records multiple social networks such as co-author relations and article-reference relations.

One particular interesting pattern is frequent highly con-nected subgraph in large relational graphs. In social net-works, this kind of pattern can help identify groups where people are strongly associated. In computational biology, highly connected subgraph could represent a set of genes within the same functional module, i.e., a set of genes partic-ipating in the same biological pathways [3, 14]. Butte et al. [3] calculates the pair-wise similarity between gene expres-sions to construct relevance networks in order to discover functional relationships between genes. Since a functional module shall be active under multiple relevance networks, a challenging problem is  X  X an we discover highly connected subgraphs conserved in multiple relevance networks? X 
The common problem in the above application scenario is to find not only frequent graphs, but also graphs that satisfy the connectivity constraint. Figure 1 depicts our problem setting: how to mine frequent highly connected subgraphs in a set of massive relational graphs . Note that the patterns we are interested in are not only groups of highly connected objects, but also the structures within these objects, which expose the relationships between the objects.
This new problem setting has three major characteristics different from the previous frequent graph mining problem defined in [9, 10, 1, 22, 17]. First, in relational graphs each node represents a distinct object. No two nodes share the same label. In biological networks, nodes often represent unique objects like genes and enzymes. Secondly, relational graphs may be very large. For example, gene relevance net-works often have thousands of nodes and millions of edges. Thirdly, the interesting patterns should not only be frequent but also satisfy the connectivity constraint. Previous studies usually interpret a frequent graph as an object and ignore its internal properties such as connectivity.

In order to handle these new challenges, two issues have to be solved: (1) how to mine frequent graphs efficiently in large relational graphs, and (2) how to handle the con-nectivity constraint. Since frequent graph mining usually generates too many patterns, as observed in [2, 25, 18, 23], it is more appealing to mine closed frequent graphs only. A frequent graph is closed if and only if there does not exist a supergraph that has the same support. Assume graphs g and g  X  are frequent subgraphs and appear in the same set of relational graphs. If g is contained by g  X  , then it is unnec-essary to present graph g to users since it does not provide new information. We say g is not closed. We develop an effi-cient algorithm, cSpan , to address the first problem. Unless specifically noted, the patterns discussed in the paper are closed frequent graphs with connectivity constraints . Since relational graphs can be represented as sets of distinct edges, we adopt the frequent itemset mining technique. However, we cannot directly cast this problem into a standard fre-quent itemset mining problem due to two reasons. First, the solution should assure the discovered graphs are con-nected. Second, we have connectivity constraints. Simply applying frequent itemset mining may immediately explode the pattern space.

Our major contribution is to tackle the connectivity con-straint. We use the minimum cut criterion to measure the connectivity of a pattern and examine the issues of inte-grating the connectivity constraint with the closed graph mining process. As suggested by many graph theoretic ap-proaches for data clustering [21, 13, 6], minimum cut mea-surement, also called edge connectivity, is good at clustering nodes based on their connectivity. The fastest determinis-tic minimum cut algorithm in practice has time complexity size and the edge set size of a given graph [4, 15]. To com-pute the edge connectivity in all subgraphs of closed graphs is equivalent to enumerating all frequent graphs and check their connectivity. Since billions of frequent graphs may ex-ist in the datasets we are dealing with, it is impossible to fin-ish the brute-force computation within limited time. Thus, we develop two graph theoretic approaches, CloseCut (a pattern-growth approach) and Splat (a pattern-reduction approach), to efficiently discover closed highly connected graphs while still preserving the completeness of the min-ing result. We apply graph condensation and decomposi-tion techniques in the design of CloseCut and Splat to improve the performance. Both of them can reduce the size of candidate graphs in terms of nodes and edges. CloseCut and Splat are targeted to handle different mining requests. Their pros and cons will be illustrated through our experi-ments.

The contribution of this study is not only providing an affordable solution to mine highly connected graphs in mul-tiple relational graphs, but also the demonstration of how frequent graph mining technology may help uncover inter-esting patterns in scientific fields like biology. We have ap-plied CloseCut and Splat in real biological datasets and found the discovered patterns very promising. Although the patterns mined by our methods need post-processing to ex-tract other variant dense graphs such as cliques, the most frequent patterns mined by our methods exhibit strong bio-logical meanings and are directly usable.

The remaining of the paper is organized as follows. Sec-tion 2 gives the problem definition. The theorems leading to the efficient design of CloseCut and Splat are intro-duced in Section 3, followed by a detailed explanation of CloseCut in Section 4 and Splat in Section 5. We re-port our performance result in Section 6. Related work is discussed in Section 7, and Section 8 concludes our study.
A relational graph set consists of undirected simple graphs, { G i = ( V, E i ) } , i = 1 , . . . , n , E i  X  V  X  V , where a com-mon vertex set V is shared by the graphs in the set. In relational graphs, there is neither loop nor multiple edges. Unless otherwise specified, all the graph patterns discussed in this paper are undirected connected relational graphs.
A relational graph G = ( V, E ) is a subgraph of G  X  = ( V, E  X  ) if and only if E  X  E  X  , denoted by G  X  G  X  ( G  X  is a supergraph of G ). Graphs G and G  X  are isomorphic if and only if E = E  X  . The testing of subgraph isomorphism between two relational graphs is easy because labels have to match exactly and each label is used only once in a graph. We denote the vertex set of a graph G by V ( G ) and the edge set by E ( G ).

In order to determine whether one set contains another set, one can first sort the two sets and then compare them in linear time. Hence, the complexity of subgraph isomorphism size of the larger graph in two graphs. We define union, intersection and difference operators for relational graphs. Definition 1 (Union, Intersection, Difference).
 Given two relational graphs, G = ( V, E ) and G  X  = ( V, E  X  ) , the union of G and G  X  , written G  X  G  X  , is ( V, E  X  E  X  ) . The intersection of G and G  X  , written G  X  G  X  , is ( V, E  X  E  X  ) . The difference of G and G  X  , written G  X  G  X  , is ( V, E \ E  X  ) .
Definition 2 (Constraint). A constraint is a func-tion, C : { G } X  X  0 , 1 } , which maps a graph G to a Boolean value. A graph G satisfies constraint C if C ( G ) = 1 .
Given a relational graph dataset, D = { G 1 , G 2 , . . . , G support ( g ) is the number of relational graphs (in D ) where g is a subgraph. Let F = { g | support ( g )  X  min sup and C ( g ) = 1 } , where min sup is an non-negative integer and C is a constraint. F is called a frequent graph set with constraint C . Often the closed set of F is more interesting: { g | g  X  F, and  X  g  X   X  F s.t., g  X  g  X  and support ( g ) = support ( g  X  ) } . The reason of mining closed graphs is to avoid the exponen-tial number of patterns in large graph datasets. In our study, we shall concentrate on implementing the connectivity con-straint and mining closed frequent graphs with connectivity constraints. As observed in our experiments, the number of such patterns is much less than closed frequent graphs.
Definition 3 (Degree). The degree of a vertex v is the number of edges that connect v , written as degree ( v ) . The average degree of a graph G is the average of degree ( v ) for all v  X  V ( G ) . The minimum degree of a graph G is the minimum of degree ( v ) for all v  X  V ( G ) , written as  X  ( G ) . Figure 2: Average Degree:3.25, Minimum Degree:3
Although average degree and minimum degree display some level of connectivity in a graph, they cannot guarantee the graph is connected in a balanced way. Figure 2 shows an ex-ample that some part of a graph may be loosely connected even if its average degree and minimum degree are high. The removal of edge e 1 will make the whole graph fall apart. One may enforce the following downward closure constraint: a graph is highly connected if and only if each of its con-nected subgraphs is highly connected. However, some global tightly connected graphs may not be locally connected well. It is a bit too strict to have this downward closure con-straint. Thus, we adopt the concept of edge connectivity, a well-known connectivity definition in graph theory. Definition 4 (Edge Connectivity). Given a graph G , an edge cut is a set of edges E c such that E ( G )  X  E disconnected. A minimum cut is the smallest set in all edge cuts. The edge connectivity of G , written  X  ( G ) , is the size of a minimum cut.
 A cut E c separates V ( G ) into two vertex sets, V and e such that all the edges in E c are only edges between V and e V , where V  X  e V =  X  and V  X  e V = V ( G ). E c is also written as V  X  e V to show that edges in E c connect V and e V . For example, Set { e 1 } is a minimum cut of the graph shown in Figure 2, which separates the graph into two equal-sized components. Edge connectivity/minimum cut is popularly used to cluster objects in a graph [21, 13, 6].

In this paper, we investigate the issues of mining all closed frequent graphs with edge connectivity (minimum cut size) at least K , where K is a natural number.
We first examine several graph theoretic concepts about edge connectivity.

Claim 1 (No Downward Closure Property). Given two graphs G and G  X  , G  X  G  X  and  X  ( G )  X   X  ( G  X  ) do not im-ply each other.
 Claim 1 says that the high connectivity of a graph does not imply the high connectivity of its supergraph, and vice versa. There is no downward closure property for edge connectivity. However, two specific kinds of graphs, clique and tree, have the downward closure property. If a graph is a clique or a tree, then all its induced connected subgraphs are cliques or trees. As one can see, cliques and trees are either too strict or too sparse. They may not catch some interesting graph patterns. In fact, the lack of downward closure in edge connectivity brings more flexibility on the kind of patterns we may find.

Wu and Leahy [21] examined the properties of edge con-nectivity. We derive two corollaries from Theorem 4 in [21] and give self-contained proofs. We are not aware of any previous work which applies these results in mining highly connected patterns through multiple graphs, which will be addressed in the next section.

Corollary 1 (Condensation). Let G be a subgraph of a graph G  X  , and G  X  be the graph formed from G  X  with all vertices in G condensed into a single vertex. If  X  ( G ) &gt;  X  ( G  X  ) , then  X  ( G  X  ) =  X  ( G  X  ) .

Proof. Let V m  X  e V m be the minimum cut of G  X  . Since  X  ( G ) &gt;  X  ( G  X  ), then V ( G ) must be a subset of V of e
V m ; otherwise,  X  ( G  X  )  X   X  ( G ). In either case, V m an edge cut of G  X  . Therefore,  X  ( G  X  )  X   X  ( G  X  ). Let V  X  be the minimum edge cut of G  X  . V  X  m  X  e V  X  m is an edge cut of G  X  . Thus,  X  ( G  X  )  X   X  ( G  X  ). Hence,  X  ( G  X  ) =  X  ( G  X  ). Example 1. Figure 3 shows an example of condensation. The edge connectivity of graphs G 1 , G 2 , and G 3 are 3 , 2 , and 2 respectively. We have  X  ( G 1 ) &gt;  X  ( G 2 ) and G 1  X  G safe to condense all the vertices of G 1 into a single vertex to form a new graph G 3 . G 3 has the same edge connectivity as G 2 .

Corollary 1 shows that we may reduce the cost of calcu-lating edge connectivity if the connectivity of its subgraph is known. This property is useful for the design of our pattern-growth approach, CloseCut . For example, sup-pose we have already discovered a highly connected graph pattern g and extend it to a new candidate pattern g  X  . We can form a new graph g  X  by condensing all the vertices of g into a single vertex in g  X  . If we want to know the edge connectivity of g  X  , we only need to check the connectivity of connectivity will be reduced. Note that g  X  is not a simple graph any more. It may have multiple edges between two vertices. Corollary 1, as well as Corollary 2, is also valid for graphs with multiple edges.

Corollary 2 (Exclusion). Let G be a subgraph of a graph G  X  and E c be an edge cut of G  X  such that | E c | &lt; K . If  X  ( G )  X  K , then E c
Proof. Let V  X  e V be the edge cut E c in G  X  . Since  X  ( G ) &gt; | E c | , then V ( G ) must be a subset of V or a subset of e V ; otherwise, E c become a superset of an edge cut of G , hence | E c | X   X  ( G ). In either case,  X  e  X  E c , e 6 X  E ( G ). Hence, E c
Example 2. Figure 4 shows an example of exclusion. G 2 is a subgraph of G 1 . G 1 has an edge cut { e 1 , e 2 } . Assume we want to find graph patterns with edge connectivity at least 3 . According to Corollary 2, if a subgraph of G 1 has edge connectivity at least 3 , it will not have edges e 1 and e the deletion of e 1 in G 2 will not lose any pattern.
Corollary 2 shows if a graph has an edge cut whose size is less than K , then none of its subgraphs with edge connec-tivity at least K will contain the edges in this cut.
If the edge connectivity of a closed frequent graph is less than K , we have to find its subgraphs that have edge con-nectivity at least K . Actually, each of them is a subgraph defined in the maximum K -decomposition (Definition 5), a variant of K -partition introduced in [21]. K -decomposition breaks a graph into non-overlapping subgraphs such that their connectivity is at least K . Using Corollary 3.2 in [21], we can prove that the maximum K -decomposition is unique.
Definition 5 (K-decomposition). The K -decompo-sition of an undirected graph G is a set of subgraphs { g g i  X  G , s.t.  X  ( g i )  X  K and g i  X  g j =  X  . The maxi-mum K -decomposition is a K -decomposition that maximizes P | E ( g i ) | .

We can construct a K -decomposition in a divide-and-conquer manner: (1) select an edge cut whose size is less than K in graph G (if there is such a cut); (2) decompose G into two subgraphs by removing the cut edges; (3) re-cursively call Steps 1 and 2 on every decomposed subgraph until its edge connectivity is at least K or it becomes a sin-gle vertex. The K -decomposition obtained in this way must be the maximum K -decomposition and the only maximum K -decomposition that G has.

Using K -decomposition to break a graph, we will not miss any subgraph whose edge connectivity is at least K . Fur-thermore, the divide-and-conquer property of K -decompo-sition makes the mining affordable. We can further apply Corollary 1 to condense a graph before we perform the de-composition. For example, if a graph G has a subgraph whose connectivity is at least K , we can condense all the vertices of this subgraph into a single vertex to form a new graph G  X  . We then decompose G  X  instead of G to obtain the highly connected subgraphs in G . Since G  X  is smaller than G , the decomposition performance will be improved.
In this section, we formulate our first algorithm, CloseCut , for mining closed frequent graphs with connectivity con-straint. CloseCut adopts a pattern-growth approach: It first finds a small frequent candidate graph and decomposes it to extract the subgraphs satisfying the connectivity con-straint. After that, CloseCut extends the candidate graph by adding new edges and repeats the above operations. Be-fore we discuss how to integrate the connectivity constraint with the mining process, we first examine how to mine closed frequent graphs from relational graph datasets.
Different from general labeled graphs, each node in re-lational graphs has a unique label per graph. Because of this special property, we can treat relational graphs as sets of edges ( v i , v j ) and use the closed frequent itemset mining technique instead of general graph mining algorithms. Algorithm 1 cSpan ( g , D , min sup , S ) Input: A graph g , a graph dataset D , a minimum support Output: The closed frequent graph set S . 1: if  X  g  X   X  S , g  X  g  X  and support ( g ) = support ( g  X  ) then 2: extend g to g  X  as much as possible s.t. 3: insert g  X  to S ; 4: scan D once, find every edge e s.t. g  X   X  X  e } is frequent; 5: for each frequent g  X   X  X  e } do 6: cSpan ( g  X   X  X  e } , D , min sup , S ); 7: return ;
Algorithm 1 ( cSpan ) illustrates the framework of our closed frequent graph mining engine. It adopts the pattern-growth approach. A new graph is first extended from a small fre-quent graph with new edges added in. Then the frequency of the new graph is checked. In each iteration, cSpan ex-tends a newly discovered frequent graph as much as possible until it finds the largest supergraph with the same support. Using this technique, many iterations that do not generate closed graphs can be skipped. For example. Suppose there is a set of frequent graphs g 1 , g 2 , ..., g n , where graph g formed from g i  X  1 by adding one new edge (1 &lt; i  X  n ). If graphs g 1 , g 2 , . . . , and g n have the same support, one could skip the search space between g 1 and g n . This strategy low-ers down the computation cost. Consequently, the graph found in Line 2 is a closed frequent graph. Lines 4-6 dis-cover the remaining supergraphs that have lower support. According to the following lemma, there is one and only one closed graph that can be extended from each frequent graph in Line 2, Algorithm 1.

Lemma 1 (Uniqueness). Given a relational graph G , there is one and only one closed relational graph G  X  such that G  X  G  X  and support ( G ) = support ( G  X  ) . Proof. Assume to the contrary that there is another closed graph G  X  X  s.t. G  X  G  X  X  and support ( G ) = support ( G  X  X  ). Let since G  X  and G  X  X  share a common subgraph G . Therefore, G  X  X   X  G  X  and support ( G  X  X  ) = support ( G  X  ), contradicting our assumption.

Lemma 1 does not hold for general labeled graphs. Be-cause multiple subgraph isomorphisms may exist between general graphs, we cannot claim in the proof that G  X  is a connected graph any more.
In the next section, we examine an issue raised by the edge connectivity constraint when we attempt to integrate this constraint with Algorithm 1. (a) Record Pattern G (b) Discard Pattern G 
Suppose we find a closed frequent graph G that does not satisfy the connectivity constraint during mining, should we record it or not? The answer depends on what we want to optimize: space or time. Figure 5 shows an example of this issue. Assume G has an exponential number of subgraphs g , g 2 , . . . , g n such that g i 6 X  g j for any i and j . Suppose G and { g i } have the same support and some graphs in { g i isfy the connectivity constraint. After we extract the highly connected graphs from G , we can either record G or discard G . If we discard G , a potential problem arises: one prob-ably has to generate g 1 , g 2 , . . . , g n individually in order to determine whether they satisfy the constraint. Since G is not recorded, the search space below g i cannot be skipped. For example, assume g 2 is expanded from g  X  2 and they have the same support. If we retain G in the memory, as shown in Figure 5(a), we can immediately stop searching any su-pergraph of g  X  2 since g  X  2 is a subgraph of G and they have the same support. However, if G is discarded, we have to grow g 2 from g  X  2 because there is no clue that the super-graphs of g  X  2 have already been checked. Considering a lot of graphs have the similar condition as g 2 , it is inefficient to generate them separately. It takes more time (by orders of magnitude) to complete the mining. Therefore, we decide to record closed graphs that do not satisfy the connectivity constraint. Although it incurs additional space cost, we be-lieve the shorter computation time is the key issue in our applications.
We build CloseCut based on Algorithm 1, incorporat-ing the connectivity constraint. When it extends a frequent graph, CloseCut attempts to remove the frequent edges that will not be part of highly connected graphs.
Algorithm 2 sketches the framework of CloseCut , which consists of four steps: (Step 1) find the closed graph of a newly discovered graph (Lines 2-3); (Step 2) condense and decompose graphs for highly connected subgraphs (Lines 5-7); (Step 3) remove frequent edges of unpromising ver-tices (Lines 8-9); and (Step 4) recursively search new graphs (Lines 10-11). According to the discussion in the previous section, we record the intermediate mining results in a set (set C in Algorithm 2). These intermediate results are used to avoid extending the same frequent graph twice. Duplicate extensions are blocked by Line 1 in Algorithm 2. Corollary 1 is used to accelerate the computation of edge connectivity in the second step, shown in Line 5. The following sections will introduce how to apply the minimum degree constraint in the third step and how to decompose graphs efficiently in the second step.
 Algorithm 2 CloseCut ( g , D , min sup , K , C , S ) Input: A graph g , a graph dataset D , a minimum support Output: The result set S . 1: if  X  g  X   X  C , g  X  g  X  and support ( g ) = support ( g  X  ) then 2: extend g to g  X  as much as possible s.t. 3: insert g  X  to C ; 4: g  X  = g  X  ; 5: if  X  g o  X  S , g  X  is extended from g o then 6: decompose( g  X  , K , S ); 7: scan D once, find frequent edge set X , s.t.  X  e  X  X 8: for each vertex v in g  X  , d deg ( v )  X  K do 9: remove all edges of v in X ; 10: for each frequent graph g  X   X  X  e } , e  X  X do 11: CloseCut ( g  X   X  X  e } , D , min sup , K , C , S ); 12: return ;
For any graph, its edge connectivity is less than or equal to its minimum degree. This property shows that if a graph satisfies the edge connectivity constraint, it must satisfy the minimum degree constraint first. We integrate the minimum degree constraint with the mining process.
 Theorem 1. [20]  X  ( G )  X   X  ( G ) .

Suppose a newly discovered frequent graph g has its min-imum degree less than K . We cannot stop searching its su-pergraphs since they may satisfy the constraint. However, we can check the maximum degree of vertex v ( v  X  V ( g )) in the largest possible frequent supergraph that may be ex-tended from g . If the degree of v is less than K , we can safely exclude v from g .

Definition 6 (Shadow Graph). Let G be a frequent graph and X be a set of edges which can be added to G such that G  X  X  e } ( e  X  X ) is connected and frequent. Graph G  X  X is called the shadow graph of G , written as b G . The degree of v ( v  X  V ( G ) ) in the shadow graph of G is written d deg ( v ) .
For any vertex v in V ( g ), d deg ( v ) is the maximum num-ber of edges that v may have for any potential frequent supergraph of g . d deg ( v ) monotonically decreases when g is extended. If d deg ( v ) is less than K , v can be excluded from g when we extend g . In our implementation of CloseCut , we do not delete v from g . Instead, we remove all the edges of v in the frequent edge set X . By doing so, v loses the ability to have new edges. Since these frequent edges do not show up in the following extensions of g , we reduce the computation time.
Once a frequent graph is generated in Line 2, Algorithm 2, we will extract highly connected subgraphs in Line 6, Al-gorithm 2. Algorithm 3 outlines the extraction procedure. Line 1 gives a termination condition to avoid duplicate de-composition. Line 3 checks whether the discovered frequent graph satisfies the constraint. If it does, we put it in the result set. Otherwise, we recursively decompose it in Lines 6-9 until it meets the stop condition.
 Algorithm 3 decompose( g , K , S ) Input: A graph g and connectivity threshold K .
 Output: The result set S . 1: if (stopDecompose(g)) then 2: return ; 3: if (  X  ( g )  X  K ) then 4: insert g into S ; 5: return ; 6: while there exists a cut in g whose size is less than K 7: break g into two parts g 1 and g 2 ; 8: decompose( g 1 , K , S ); 9: decompose( g 2 , K , S ); 10: return ;
When we break one graph into two halves, one or both of them may be decomposed somewhere else. Thus, a ter-mination condition (Line 1, Algorithm 3) is set up so that we do not decompose the same graph repeatedly. For exam-ple, assume two frequent graphs g 1 and g 2 share a common subgraph g o . If we perform a brute force decomposition on both of them, we may decompose g o twice. Therefore, be-fore g 0 is decomposed, we have to check whether this graph was or would be decomposed elsewhere. A naive solution is to maintain a database of processed frequent graphs. The database is checked to verify whether g o has been decom-posed before. Unfortunately, this approach is costly pro-vided that there are lots of frequent graphs in the dataset. We propose a better solution to serve as a termination con-dition.

Theorem 2 (Termination Condition). Let g o be a subgraph of g . If support ( g o ) 6 = support ( g ) , one can stop decomposing g o .

Proof. If the support of g o is different from g , according to Lemma 1, there must be another closed graph contain-ing g o . Thus, g o can be decomposed when we process that graph.

Theorem 2 forms a termination condition of decomposi-tion (Line 1, Algorithm 3). According to Lemma 1, given a relational graph g , there is one and only one closed graph which is a supergraph of g and has the same support. There-fore, any graph will be decomposed at most once in CloseCut .
CloseCut extends a candidate graph by inserting new edges until the candidate graph is not frequent any more. In-spired by recent work on row enumeration-based approaches [12] and intersection methods [11], we propose a pattern-reduction approach, Splat . Instead of enumerating graphs from small ones to large ones, Splat directly intersects re-lational graphs and decomposes them to obtain highly con-nected graphs.

Let pattern g be a highly connected graph in relational to mine patterns in a larger set { G i 1 , G i 2 , . . . , G Splat intersects g with graph G i l +1 . Let g  X  = g  X  G i The intersection will remove some edges in g that do not may not satisfy the constraint anymore. If so, we need to decompose g  X  into smaller highly connected subgraphs. We progressively reduce the size of candidate graphs by inter-section and decomposition. Finally, it may become zero. We call this approach a pattern-reduction approach.
Figure 6 depicts the concept of Splat . Imagine there is a parallel light casting from the right perpendicularly to relational graphs and each edge blocks some light. The fre-quent edges will be very dark on the projection plane. Since we are only concerned about highly connected graphs, fre-quent edges with low connectivity will be removed from the plane. By inserting and deleting different relational graphs between the light and the projection plane, Splat is able to discover all the graph patterns satisfying the connectiv-ity constraint. When the size of patterns on the projection plane is smaller than K , Splat stops intersecting it with new relational graphs since it will not produce new patterns. Algorithm 4 Splat ( g , D , l , min sup , K , S ) Input: A graph g , a graph dataset D , an index l , a minimum Output: The result set S . 1: check whether a discovered graph g  X  exists s.t. g = g  X  ; 2: if such pattern exists then return ; 3. if support ( g )  X  min sup then insert g into S ; 4: for each G m  X  D, l &lt; m  X  n do 5: g  X  = g  X  G m ; 6: K -decompose g  X  , put highly connected subgraphs in Q ; 7: for each graph q  X  Q do 8: Splat (q, D , m , min sup , K , S ); 9: return ;
Algorithm 4 describes the framework of Splat . Line 1 checks whether a discovered graph g exists in the result set. If g exists, Splat need not work on it since g will not generate new closed highly connected graphs, which can be proved using a similar framework in [12]. Lines 4-8 intersect the graph with the m -th relational graph and perform K -decomposition on it. For each newly discovered graph, we repeat the above procedure until we finish all the relational graphs or there is no new frequent highly connected graphs.
When the edge connectivity is higher, Splat will perform better. In that case, Splat shrinks the candidate graphs quickly by removing lots of low cut edges. However, the performance of Splat may deteriorate when the number of relational graphs increases because it has to enumerate the combination of relational graphs.
We conducted a comprehensive performance study on both synthetic and real datasets. The synthetic data is controlled by a set of parameters that allow us to test the performance under different conditions. The real dataset is obtained from microarray experiments. Through the experiments, we illus-trate the pros and cons of CloseCut and Splat according to different mining requests.

All the experiments are done on a 2.5GHZ Intel Xeon server with 3GB main memory, running RedHat 9.0. Both CloseCut and Splat are implemented in C++ with STL library support and compiled by g++ with -O3 optimiza-tion. Notation Parameter N Number of relational graphs O Number of objects S Number of seed graphs I Maximum size of seed graphs (in vertices) T Average number of seed graphs
D Average density in seed graphs d Average density of noise edges
The synthetic datasets have a set of parameters for users to specify: the number of relational graphs ( N ), the number of objects ( O ), the number of seed graphs ( S ), the average size of seed graphs ( I ), the average number of seed graphs in relational graphs ( T ), the average density of seed graphs ( D ), and the average density of noise edges in relational graphs ( d ). Density is the average degree divided by the number of vertices. Table 1 summarizes these parameters.
Synthetic data is generated as follows. First, we generate a set of seed graphs randomly. Seed graphs are used later to form the relational graphs. The total number of seed graphs is S . Their size (the number of vertices) is randomly selected between 1 and I . Let V be the number of vertices in a seed graph. We randomly label its vertices and assign kV / 2 edges to it. The seed graph does not necessarily have exactly k edges for each vertex. Variable k is a gaussian random variable with mean D . Next, we generate the relational graphs. The numbers of objects in relational graphs are the same, specified by O . We randomly select seed graphs and embed them in the relational graphs. The number of seed graphs per relational graph is determined by a normal distribution with mean T . Finally, we randomly assign a set of noise edges to each relational graph. The number of noise edges per graph also follows a normal distribution with mean d  X  O . When we increase the average number of seed graphs per graph, these seed graphs will be merged together to form larger irregular frequent graphs.

For a dataset which has 30 relational graphs of 10,000 distinct objects, 1,000 seed graphs (each seed graph has at most 40 vertices and an average density 0 . 6), 500 seed graphs per relational graph, and 100 noise edges per object (0 . 005  X  10 , 000  X  2), we represent it as N30O10kS1kT500I40 D0.6d0.005. In the following tests, we will change some ma-jor parameters including minimum support, the number of seed graphs, and average density to show the performance of CloseCut and Splat .
Figure 7 shows the runtime of CloseCut and Splat for dataset N30O10kS1kT500I40D0.6d0.005 with varied mini-mum supports. The settings of N and O are typical: a small set of graphs with large number of nodes. Each graph in this dataset has highly connected seed graphs and these seed graphs overlap with each other. The average vertex number of seed graphs is 20 in this dataset. As shown in the figure, CloseCut and Splat have the similar performance when the support is very high. The high support threshold filters out lots of infrequent edges and noise edges. Thus, both algorithms complete very fast. When the support is lowered down, CloseCut outperforms Splat because Splat has to enumerate lots of infrequent highly connected subgraphs, which will eventually be discarded. However, when the sup-port is very low, the situation is reversed. CloseCut cannot prune effectively using the minimum degree constraint. On the contrary, Splat can use the connectivity constraint to remove many frequent, but low minimum cut edges. There-fore, Splat outperforms CloseCut , although both of them take a long time to finish. This explanation is also justi-fied by the fact that the the runtime difference of K = 10 and K = 20 in Splat is greater than that in CloseCut . That means Splat takes more advantage of the connectivity constraint than CloseCut .

Having verified the runtime of CloseCut and Splat over varied supports, we then check their scalability over the number of seeds. The increment of this parameter, together with the average number of seeds per graph, will add more highly connected graphs into the dataset, thus making the mining more challenging. We increase the seed graph num-ber from 500 to 1 , 500. Figure 8 shows the runtime of these two algorithms for dataset N30O10kI40D0.6d0.005. The support threshold is 10. As shown in the figure, CloseCut and Splat are scalable to the number of seed graphs.
Figure 9 shows the scalability of these two algorithms with different density settings. When seed graphs become denser and larger in terms of edges, the number of patterns will increase and more graphs will satisfy the connectivity con-straint. Both CloseCut and Splat scale well in this case.
Figure 8: Runtime vs. Number of Seed Graphs
The real data consists of 32 microarray expression sets measuring yeast genome-wide expression profiles under dif-ferent types of perturbations, e.g., cell cycle, amino acid starvation, heat shock, and osmotic pressure. Each dataset includes the expression values of 6661 yeast genes over mul-tiple conditions. Since gene expression values generated by different platforms are not comparable, we cannot calculate their correlation across all the datasets directly. Instead, we model each dataset as a relational graph, where nodes represent genes, and we connect two genes with an edge if they have high correlation in their expression profiles [5, 16]. On average, each graph have around 600 , 000 edges. In gen-eral, genes with correlated expression profiles are likely to be functionally related. We applied CloseCut and Splat in this microarray dataset and mined recurrent graphs with different connectivity constraints.
In Figure 10, we plot the runtime of CloseCut and Splat in this microarray dataset. For this dataset, Splat outper-forms CloseCut when the absolute support is below 16. However, CloseCut has better performance when the min-imum support is high and the edge connectivity is low. For example, when the support threshold is set at 17 and the minimum connectivity is 2, Splat needs 2,748 seconds to finish the mining. If the connectivity is lowered down to 1, Splat cannot complete the task in hours. In both cases, CloseCut only takes less than 300 seconds. Compared with its performance in synthetic datasets, CloseCut does not achieve a similar speedup when the minimum cut threshold is increased. We found that this dataset has lots of large fre-quent tree patterns and many vertices in the center of these patterns have high degrees. Therefore, CloseCut cannot remove these nodes quickly using the minimum degree con-straint.

In summary, CloseCut and Splat have their own strength for different problem settings. CloseCut runs faster when the support is high and the connectivity constraint is low. On the contrary, Splat has better performance when the support is low and the connectivity is high. Figure 11: Number of Highly Connected Patterns
Figure 11 shows the number of highly connected graphs mined under different connectivity constraints. As shown in the figure, the number of patterns is reduced significantly when we change the connectivity threshold from 1 to 5. The result set produced from our algorithm is not only smaller than the set of frequent graphs, but also smaller than the set of closed frequent graphs.
Figure 12 shows the size of the largest patterns discovered for different connectivity thresholds. We have small-size pat-terns when the connectivity constraint is enhanced.
Figures 13-16 depict examples of the most frequent graphs we discovered with edge connectivity equal to 3. The sup-port of these patterns is all above 19. These patterns have strong biological meanings as verified by biologists. Figure 13: Genes Related with Subtelomerically En-coded Proteins
Except that we have no knowledge about gene YIR043C in the pattern shown in Figure 13, all of the rest seven genes be-long to a family of conserved, often subtelomerically encoded proteins. These seven genes are located closely to each other in the chromosome. Below in the parenthesis are the com-mon names of these genes, and one can see that they differ only in the last number: YML132W (COS3), YIR043C (un-known), YJR161C (COS5), YGR295C (COS6), YFL062W (COS4), YDL248W (COS7), YBR302C (COS2), and YNL-336W (COS1).
 All the five genes shown in Figure 14, YLR467W, YJL225C, YDR545W, YLL066C, and YLL067C, have helicase activ-ity. However, the exact biological pathways, in which these genes are involved, are unknown so far.
 Figure 15: Genes Involved in Ribosomal Biogenesis
The five genes in Figure 15 are mainly involved in riboso-mal biogenesis. Genes YKL009W, YNL182C, and YOL077C are involved in ribosomal large subunit assembly and main-tenance; YNL248C is involved in transcription of riboso-
Figure 16: Genes Involved in rRNA Processing mal DNA; and YDR496C has unknown function, but is pre-dicted to be involved in ribosomal RNA processing in our own study. All genes in Figure 16 are involved in rRNA processing, except that YPL146C has unknown function.
A general review on the recent progress of graph-based data mining is given by Washio and Motoda [19]. The Apri-ori property is applied to mine frequent graphs: Inokuchi et al. [9], Kuramochi and Karypis [10], and Vanetik et al. [17]. Borgelt and Berthold [1], Yan and Han [23], and Huan et al. [8] apply the pattern-growth approach to di-rectly mine frequent subgraphs. Holder et al. [7] adopt the principle of minimum description length for mining approxi-mate frequent graphs. In this paper, we introduce a different problem scenario where connectivity is used together with frequency to identify highly connected recurrent structures . Furthermore, the relational graph we studied is very special in comparison with the general graph proposed by previous work. Each node in a relational graph has a distinct label. This special property leads to a different but more efficient design in mining large graph patterns.

The minimum cut criterion in finding highly connected components has been introduced in various fields. It is pre-sented by Wu and Leahy [21] as an optimal graph theo-retic approach for data clustering in the image segmenta-tion problem. Their approach is further modified by Shi and Malik [13] using a normalized minimum cut measurement. Flake et al. discuss how to apply a framework of maximum flow/minimum cut to identify members of web communities efficiently [6]. These studies focus on clustering objects in one graph, instead of a set of graphs. It is unknown whether these techniques are still valid or applicable in the context of mining multiple graphs. For example, in the design of pattern-growth approach, it is not clear how to extend a frequent graph with concerns on the connectivity constraint and when to stop decomposing a candidate graph. So far, we are not aware of any previous work on these issues.
In this paper, we introduced a new graph mining prob-lem: finding closed frequent graphs with connectivity con-straints in relational graphs. We adopted the concept of edge connectivity and applied graph theoretic results, graph condensation and decomposition, in our algorithm design. Two approaches were developed to meet different mining de-mands: CloseCut , a pattern-growth approach, and Splat , a pattern-reduction approach. CloseCut has better perfor-mance on patterns with high support and low connectivity. On the contrary, Splat can remove frequent graphs with low connectivity in the early stage of mining, thus achiev-ing better performance for the high connectivity constraint. Our methods successfully mined interesting patterns from multiple biological networks. Through our study, we demon-strated the applicability of frequent graph mining in biolog-ical research. [1] C. Borgelt and M. Berthold. Mining molecular [2] D. Burdick, M. Calimlim, and J. Gehrke. MAFIA: A [3] A Butte, P. Tamayo, D. Slonim, T. Golub, and [4] C. Chekuri, A. Goldberg, D. Karger, M. Levine, and [5] M. Eisen, P. Spellman, P. Brown, and D. Botstein. [6] G. Flake, S. Lawrence, and C. Giles. Efficient [7] L. Holder, D. Cook, and S. Djoko. Substructure [8] J. Huan, W. Wang, D. Bandyopadhyay, J. Snoeyink, [9] A. Inokuchi, T. Washio, and H. Motoda. An [10] M. Kuramochi and G. Karypis. Frequent subgraph [11] T. Mielikainen. Intersecting data to closed sets with [12] F. Pan, G. Cong, A. Tung, J. Yang, and M. Zaki. [13] J. Shi and J. Malik. Normalized cuts and image [14] V. Spirin and L. Mirny. Protein complexes and [15] M. Stoer and F. Wagner. A simple min-cut algorithm. [16] P. Tamayo, D. Slonim, J. Mesirov, Q. Zhu, [17] N. Vanetik, E. Gudes, and S. E. Shimony. Computing [18] J. Wang, J. Han, and J. Pei. Closet+: Searching for [19] T. Washio and H. Motoda. State of the art of [20] D. West. Introduction to Graph Theory . Prentice Hall, [21] Z. Wu and R. Leahy. An optimal graph theoretic [22] X. Yan and J. Han. gSpan: Graph-based substructure [23] X. Yan and J. Han. Closegraph: Mining closed [24] X. Yan, P. Yu, and J. Han. Graph indexing: A [25] M. Zaki and K. Gouda. Fast vertical mining using
