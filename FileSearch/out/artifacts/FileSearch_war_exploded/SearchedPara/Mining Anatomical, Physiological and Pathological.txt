 The field of medical imaging has shown substantial growth over the last decade. Even more dramatic increase was ob-served in the use of machine learning and data mining tech-niques within this field. In this paper, we discuss three as-pects related to information mining in the domain of medical imaging: the target user groups ( X  X or whom X ), the infor-mation to mine ( X  X hat X ), and technologies to enable min-ing ( X  X ow X ). Specifically, we focus on three types of in-formation: anatomical, physiological and pathological, and present use cases for each one of them. Furthermore, we introduce representative methods and algorithms that are effective for solving these problems. We conclude the paper by discussing some major trends in the related domains for the coming decade. The application of machine learning and data mining tech-niques in the domain of medical imaging has gained momen-tum in the last decade. This is illustrated in Figure 1, where we show the statistics gathered through a simple data min-ing experiment on Google Scholar, by searching for terms  X  X edical image X ,  X  X achine learning X , and  X  X ata mining X , and their combinations. Comparing the period from 2005 to 2011 to the same period a decade earlier, the number of articles related to  X  X edical image X  has doubled from 14600 to 32500. However, some topics increased much more than others:  X  X edical image X  articles which are further related to  X  X achine learning X  or  X  X ata mining X  increased more than 10-fold, from 447 to 6150 and 417 to 4420, respectively. A medical image is worth a thousand words ; in some cases, a thousand dollars as well. Indeed, it can be priceless if it reveals an early sign of a disease which might be cured or at least properly managed thus increasing the quality of life if detected and treated early. However, several factors affect the ability to mine information out of medical images: 1. Medical images are most useful when acquired using a 2. There is an ever-increasing amount of data produced medical image AND medical image AND machine learning Figure 1: Increase of research activities in related fields as evidenced by the number of articles returned in Google Scholar, comparing the period 2005-2011 with a decade ear-lier 1995-2001. The exact query was formulated using a custom range and excluding patents and citations 3. There are many intrinsic subtleties and variations of 4. The lack of automatic and quantitative tools is another In this paper, we provide an overview of target user groups (Section 2), discuss what information to mine from medical images (Section 3) and highlight some of the most effective methods and algorithms for mining anatomical, physiologi-cal, and pathological information from medical images (Sec-tion 4). We discuss four major trends that will affect the domain of medical image mining in the concluding section. The improved access to medical image data using data min-ing techniques will benefit various consumers, including clin-icians (technicians, radiologists, cardiologists, etc.), patients, and researchers. As the primary interpreter and consumer of medical images, radiologists, cardiologists, and referring physicians will ben-efit from any additional meta-data or information that will help them see more , see better , or see faster . For example, for lung CT scans, it is a challenge for a radiologist to scroll through 500 or more images to look for lung nodules as small as 3-5mm. An automated algorithm can propose candidates of lung nodules to the radiologist, reducing the chance of misses. For cardiologists, an automated algorithm can de-tect and track the heart muscle in an ultrasound cardiac scan, and provide more accurate and consistent estimate for cardiac function [21].
 Technicians, operating a scanner to acquire medical images, can also benefit from information mining, since it can help in achieving faster acquisitions as well as higher consistency and quality. The acquisition of medical images is often a multi-step procedure which begins with a scout scan in-tended to provide a rough overview of the patient. An algo-rithm that can detect anatomical information in the scout image can automatically steer the scanner to the correct an-gulations and focusing for subsequent scans, thus speeding up the scanning process and improving consistency [11]. In the era of digital imaging, it is increasingly common for patients to get access to their medical images in addition to the report from clinicians. Moreover, with the explo-sion of medical and health information on the Internet, and the unprecedented accessibility through search engines and specialized web sites, patients (as well as the general pop-ulation) are becoming more proactive towards healthcare, and demanding more information and explanations. Im-age databases of skin lesions, for example, and associated matching tools can help the search of similar lesions with special appearances, and help educating the patient with regard to the underlying clinical condition. In the coming years, we believe that image mining tools can enable broader and deeper involvement of patients in more medical imaging fields. Undoubtedly, population models and statistics extracted from a large collection of medical images will be valuable for clini-cal, medical, biological, social, and public policy researchers. Large-scale population study and quantitative analysis can also provide public policy makers with adequate data for their policy decisions. For example, whether public health programs should reimburse for cancer screening using a par-ticular imaging modality is a very complex decision. Infor-mation mining from large cohorts of clinical and image data could potentially provide the necessary evidence to support the most cost-effective option [3]. In this section, we broadly discuss three classes of information X  anatomical , physiological , and pathological  X  X hat can be mined from medical images, and elaborate on their usefulness. This is not intended to be an exhaustive list. Anatomical infor-mation pertains to the structure of the human body, while Figure 2: Automatic organ segmentation based on CT data which is overlaid on PET data for quantitative analysis. physiological information is related to the function of the body. The former is directly visualized in most medical images, whereas the latter is less direct and less accessible since its manifestation and quantification are more dynamic in nature and require specific techniques. With the intro-duction of more functional imaging modalities (functional MRI, PET etc.), today we can also extract an abundance of physiological information from medical images. Patho-logical information refers to the abnormalities related to or caused by diseases that manifest in the medical images. Two basic questions can be answered related to an anatom-ical structure:  X  X here is it in the image? X  and  X  X hat is it? X . Although an expert human user can answer these seem-ingly fundamental questions with a quick glance of the im-age, automatic answers are very useful as stepping-stones to other intelligent, organ-specific post-processing and anal-ysis. Furthermore, while anatomical localization is part of the training of each physician, it may be a tedious and time consuming process. The first level of information that can be extracted from a medical image is the location and extent of organ struc-tures. This may not be useful for a radiologist initially be-cause they are trained to see such structures and further detect anomalies. However, automatic and precise 3D delin-eation can enable organ-specific quantitative analysis, and improve the reporting process. Figure 2 illustrates organs delineated using a CT image overlaid on a PET image to provide organ-specific FDG uptake statistics. This is useful in cancer detection and further follow-up [17]. In addition to general organ delineation, automatic labeling of anatomical structures such as vertebrae, ribs, or the blood vessels can speed up the reading and reporting workflow. To label such kind of repetitive (e.g., vertebrae) or complex structures (e.g., vessel tree), the relationship or configura-tion of multiple structures has to be considered in order to correctly label each component (see Figure 3). This is a rather challenging task since the variations in the popula-tion are quite high. For example, in the case of vertebrae: there are many asymptomatic variations [15], and correct la-Figure 3: Automatic spine labeling and curved reformat (of a scoliotic patient) in a MR image. beling requires a careful walk-through which can be tedious and error-prone in the cases of scoliosis or kyphosis. An automatic labeling algorithm would be a great help [18]. In addition to static anatomical information, medical imag-ing can capture dynamic, functional information. The list of capabilities and possibilities is enormous and growing. In this section we explore only a few examples. The first effective check of cardiac function is usually ob-tained through a cardiac ultrasound examination, in which cardiac contractions and relaxations are captured in a 2D or 3D  X  X ovie X . An automatic motion-tracking algorithm can quantitatively measure the speed and extent of muscle contraction and relaxation within different coronary territo-ries (see Figure 4). Since blocked coronary arteries result in reduced muscle activity, such motion analysis can aid the detection of cardiovascular disease [21]. The functioning of the brain and the body requires oxy-gen and nutrients (glucose), and there are medical imaging modalities that can capture exactly these activities. Positron emission tomography measures the concentration of glucose at various locations in the body by  X  X racing X  radioactive glucose molecules. Since cancer cells tend to consume a higher amount of glucose, they appear bright in a PET im-age. Functional MRI, on the other hand, can  X  X ead our brains X  by exploiting the fact that local concentrations of oxygen associated with changes in blood flow become mea-surable using MRI.
 For mining PET images, the challenge is the consistency and comparability of different acquisitions, even after stan-Figure 4: Automatic analysis of cardiac function using a motion tracking algorithm and an ischemia classification al-gorithm. The red section in the right image highlights an ischemic segment of the myocardium. dardization using the so-called  X  X tandardized uptake values X  or SUV. The challenge of mining functional MRI (fMRI) images is that of obtaining a large, statistically significant number of well-controlled imaging studies. MR-spectroscopy provides tissue characterization by imag-ing the metabolite status. By using color-coding, we can visualize both morphology and biochemical status in the body. Such metabolite imaging can help to characterize le-sions when a biopsy is difficult or impossible. It can also help the evaluation of therapy response before anatomical changes occur. During interpretation of medical images, clinicians typically have to search for abnormal structures and then characterize them in order to form a clinical conclusion.
 The search for abnormalities is often very challenging due to large amounts of data and the fact that some of the find-ings are subtle and thus easy to overlook. Mining algorithms can learn from a large image database of a particular type of abnormality, and prompt the clinician with candidate lo-cations in a new image. Examples of such abnormalities in-clude lesions or micro-calcifications in a mammogram; lung nodules in chest X-rays or chest CT; and colon polyps in CT colonography.
 The quantitative characterization of an abnormality can be challenging and time-consuming as well, either due to the need to compare against a normal population model X  X .g., quantitative assessment of amyloid plaque deposition and neuronal tangle formation in the brain for the analysis of Alzheimer X  X  disease using PET; or due to the 3D or 4D (i.e., 3D in time) nature of the problem X  X .g., estimating the ejec-tion fraction of the heart in echocardiogram [21]. In this section we provide examples of novel medical im-age mining algorithms, covering different aspects of the do-main, from image analysis to pattern recognition and ma-chine learning. Given a 3D medical image, an experienced radiologist is able to quickly localize a small anatomical structure, while an untrained college student might be completely clueless. The  X  X xtraordinary X  capability of radiologists comes from their knowledge of anatomical signatures, which is extracted from a large number of medical images during their medical train-ing. More specifically, anatomical signature is the anatomi-cal commonality across population in terms of appearance, shape and geometric configuration. Machine learning is an ideal tool to discover them from a large number of medical images. Appearance signature originates from low-level image infor-mation. It consists of the combination of a set of image features, which optimally identifies specific anatomical prim-itives, e.g., anatomical landmark and organ boundary. Anatomical landmarks Landmark is the most fundamen-Organ boundary In the same spirit, the signature of or-Figure 5: Some representative examples of mother functions. Blue/thick and red/thin boxes denote the non-zero ranges of 3D rectangle functions with positive and negative polarities, respectively. (Figure reprinted from [16]) Figure 6: Heterogeneous appearance characteristics along the liver boundary. Different from photographs taken in daily life, where ob-jects often have arbitrary context, e.g., a person can stand by a car, a house or another person, anatomical structures in medical image have strong geometric/shape correlations. For example, heart is located in-between two lungs. Hence, geometric/shape signatures play an important role in the in-terpretation of medical images, especially when appearance cues become weak or misleading due to severe diseases or Figure 7: (a) Hierarchy of liver surface partition. (b) Details of partitioned liver surface, where different colors denote different sub-division. (Figure reprinted from [17]) Figure 8: Schematic explanation of voting scheme. Detec-tion p i receives votes from other landmarks. imaging artifacts. In addition, geometric/shape signatures themselves are critical diagnostic evidence for various clini-cal studies.
 Spatial configurations Spatial correlation across differ-Shape Shape is a more sophisticated description of spa-Figure 9: Schematic explanation of sparse shape composi-tion. (Figure reprinted from [20]) One effective way to mine the information contained in im-ages is by explicitly computing numbers that quantify cer-tain properties of the structures of interest. This is often what is done for automatic detection of abnormalities since the abnormality is described by experts as possessing specific characteristics, or features. For example, a breast MR radi-ologist may describe a mass as a structure having definable margins with a separable distinct edge from the surround-ing glandular tissue and having no normal tissue within it. He or she may proceed to describe ductal and segmental enhancements as linear or sheet-like enhancements not defi-nitely in a duct and that cannot be otherwise characterized, probably representing the same process at two different res-olutions, with or without discernible margins and with or without branches.
 Similarly, an abdominal radiologist may describe a colonic polyp as a protuberance in the colonic wall at least 6 mm in diameter and at least 3 mm in height that can be flat, sessile or pedunculated in shape, its pattern of attenuation being characteristic of soft, non-fatty tissue, usually homogenous. In order to design features that are useful in detecting and characterizing such structures, it is often necessary to solve various intermediary problems. For example the simple fact that a colonic polyp is a structure on the colon wall implies that an automatic detection algorithm should first identify and separate (segment) the colon wall from the entire image. Without attempting to be exhaustive, we discuss specific examples of such features in the context of the detection and characterization of colonic polyps and breast MR lesions. The detection of polyps in CT images requires the segmen-tation of the colon wall from the image. In modern prepa-rations, this requires the virtual removal of tagging liquid, a process known as electronic cleansing (Figure 10). Once the colon is segmented out, a candidate-generation stage com-putes a set of geometric and texture features on each location of the wall. A cascading approach is used to progressively reduce the number of candidate locations before comput-ing more computationally expensive features. Morphologi-cal features include global shape features, analysis of curva-ture patterns and specific properties of the gradient vector fields around each candidate. A classifier is then trained to distinguish true polyps from false positive structures based on a set of annotated polyps. The segmental location of the finding can be automatically detected by counting the folds from the rectum and by distance from it. Also the size of each candidate is estimated by linear regression from a sub-set of the features. Figure 11 shows typical examples of a sessile and a flat polyp. Figure 12 illustrates some exam-ples of false-positive structures commonly misinterpreted as polyps: folds, tagged stool residuals and the ileocecal valve. Contrast enhanced MR sequences are a powerful diagnos-tic tool for the detection of lesions in breast. Typically, the diagnosis begins by identifying suspicious regions of en-hancement in post contrast acquisitions with respect to a pre-contrast one. Automating this process is therefore re-quired for a computer-aided system.
 Segmentation of vascular structures Because lesions usu-Shape characterization and pharmacokinetic analysis Figure 11: A typical sessile polyp (top row) and a typical flat polyp (bottom row). In addition to their shape, polyps are characterized by their internal texture, which is usually homogeneous non-fatty soft tissue (muscle-like), illustrated here by the red colored area under the transparent rendering of the colonic tissue.
 Figure 12: Two types of frequent false positives in the de-tection of polyps: folds and tagged stool (left) and the ileo-cecal valve (right). The small tagged stool on the left and the ileocecal valve roughly illustrate the range of sizes that are targeted for detection. From a machine learning perspective, early stage detection of cancer from medical images can be abstracted as a simple supervised binary classification problem. One could poten-tially use standard off-the-shelf classifiers like logistic regres-sion, support vector machine, neural network, etc. However most of the standard off-the-shelf supervised learning algo-rithms are generally developed for an ideal world. They of-ten make strong assumptions which make them less suitable to be applied directly to real world messy data. For example training points are often noisily labeled, training samples are not independent and identically distributed, it is difficult or impossible to acquire the objective ground truth, the desired performance metric may be quite different etc. For these reasons most of the basic assumptions in developing classi-fication algorithms have to be questioned. Suitable modifi-cations must be introducced to model these deviations from the ideal scenario which can give a significant improvement in performance over off-the-shelf standard classification al-gorithms to account for more realistic conditions. In this section we will describe some of the assumptions that can possibly break down and how we can re-engineer some stan-dard learning algorithms to suit our needs. Specifically we will discuss three non-standard learning paradigms which can deal with noisy, subjective, and partial label informa-tion. In a conventional supervised learning scenario it is always assumed that the label is provided for every instance. How-ever for many practical applications labels are available at a much higher granularity and are not available for every instance. For example in medical imaging applications the radiologist who provides us the ground truth just marks the location of the lesion. The lesions are often irregular in shape and are of different sizes. The computer algorithm designed to detect these lesions produces a lot of training examples which are spatially close to each other (see Fig-ure 16 for an illustration). All these examples point to the same ground truth. A single instance classifier considers all these examples as positive. In practice it often happens that Figure 13: Local differential features are computed that allow distinguishing locations of enhancement on vascular structures from other structures such as tumors. there will be a lot of negatives which mistakenly are labeled as positives.
 In the multiple instance learning (MIL) framework the train-ing set consists of bags. A bag contains many instances. All the instances in a bag share the same bag-level label. A bag is labeled positive if it contains at-least one positive instance. A negative bag means that all instances in the bag are negative. The goal is to learn a classification func-tion that can predict the labels of unseen instances and/or bags. Figure 16 illustrates that MIL can yield very different classifiers compared to conventional single instance learning. The single instance classifier on the left is trying to reject as many negative candidates as possible and detect as many positives as possible. The MIL classifier on the right tries to detect at-least one candidate in a positive bag and reject as many negative candidates as possible.
 There is another important reason why MIL is a natural framework for medical imagining applications. The candi-date generation algorithm produces a lot of spatially close candidates. Even if one of these is highlighted to the ra-diologist and other adjacent or overlapping candidates are missed, the underlying lesion would still have been detected. Hence while evaluating the performance of such systems we use the bag level sensitivity, that is, a classifier is successful in detecting a lesion if at least one of the candidates point-ing to it is predicted as a lesion. MIL lends itself to model our desired accuracy measure during training itself. We incorporate the definition of a positive bag to modify the link function used in logistic regression [12; 7]. Standard lo-gistic regression uses a sigmoid link function to model the probability of the positive class. For MIL since we have the notion of a positive bag the probability that a bag contains at-least one positive instance is one minus the probability that all of them are negative. The proposed algorithm se-lects features and designs the classifier jointly. One interest-Figure 14: Pharmacokinetic analysis aims to quantify the wash-in and wash-out of the contrast agent towards differ-entiating malignant and benign lesions. Figure 15: There are 2D and 3D motions resulting in promi-nent ridge-and-valley artifact, best seen on the uncorrected images. Uncorrected and 2D-corrected images each show different areas of artifactual washout, in part related to 3D motion. 3D-registered images correctly show plateau and progressive enhancement without washout. ing empirical outcome was that the multiple instance model was able to select many fewer features; almost half the num-ber of features selected by the single instance approach. In many medical imaging applications it is actually quite dif-ficult to obtain the ground truth. The actual gold standard (whether it is cancer or not) can be obtained from biop-sies, but since it is an expensive and an invasive process, often data mining systems are built from labels assigned by multiple radiologists who identify the locations of malignant lesions. Each radiologist visually examines the medical im-ages and provides a subjective (possibly noisy) version of the gold standard. The radiologists come from a diverse pool in-cluding luminaries, experts, residents, and novices and very often there is lot of disagreement among the annotations. For many tasks the labels provided by the annotators are inherently subjective and there will be substantial variation among different annotators.
 With the advent of crowdsourcing services like Amazons Me-chanical Turk it is quite inexpensive to acquire labels from a Figure 16: Illustration of multiple instance learning (left) A mammogram of the right breast illustrating the concept of multiple candidates pointing to the same ground truth. The red ellipse is the lesion as marked by the radiologist (ground truth). The blue contours are the candidates generated by our algorithm. (right) Illustration of single-instance learn-ing (top) and multiple instance learning (bottom) for a toy problem. The red circles are negative candidates. The blue shapes are positives. There are three positive bags (square, triangle, and diamond). large number of annotators (possibly thousands) in a short time. In situations like these, the performance of different annotators can vary widely (some may even be malicious), and without the actual gold standard, it may not be possi-ble to evaluate the annotators. In [13] we proposed a prob-abilistic approach for supervised learning which addresses the following three issues simultaneously: (1) how to adapt conventional supervised learning algorithms when we have multiple annotators providing subjective labels but no ob-jective gold standard?; (2) how to evaluate systems when we do not have an absolute gold-standard?; (3) how to es-timate how reliable/trustworthy each annotator is ?. The last problem is particularly relevant when there are a large number of annotators.
 The commonly used majority voting scheme uses the labels on which the majority agree as an estimate of the actual gold standard. We proposed a Bayesian approach that jointly learns the classifier, the annotator accuracy, and the un-known true label. The final estimation is performed by an Expectation Maximization algorithm that iteratively estab-lishes a particular gold standard, measures the performance of the experts given that gold standard, and refines the gold standard based on the performance measures. Experimental results indicate that the proposed method is superior to the commonly used majority voting baseline. A novel feature is that the proposed algorithm learns the classifier and the ground truth jointly in a way the classifier is allowed to influ-ence the ground truth. The method was successfully applied to a model for prediction of malignancy for breast tumors in MR with subjective assessments from multiple radiologists in the absence of biopsy results. We are often faced with a shortage of training data for learn-ing classifiers for a task. However we may have additional data for closely related, albeit non-identical tasks. For ex-ample our data set includes images from CT scanners with two different reconstruction kernels. While training the clas-sifier we could ignore this information and pool all the data together. However, there are some systematic differences that make the feature distributions slightly different. We could also train a separate classifier for each kernel, but a large part of our data set is from one particular kernel and we have a smaller data set for the other. Alternatively we could use the framework of multi-task learning [12] that tries to estimate models for several classification tasks in a joint manner. Multi-task learning can compensate for small sam-ple size by using additional samples from related tasks, and exchanging statistical information between tasks. We discussed the increased research activities in medical im-age mining in the last decade and gave examples of use cases and the methods employed. We conclude by identi-fying some trends that will shape the research directions of this domain. 1. Personalization Advances in science and medicine are 2. Specialization Highly specialized, high performance, and 3. Generalization On the other hand, advances in algo-4. Cost reduction The cost pressure on the healthcare We appreciate the comments and suggestions from the edi-tors which have helped to improve the quality and the pre-sentation of the paper.
 Zhigang Peng, Maneesh Dewan, Matthias Wolf, Yoshihisa Shinagawa, Sangmin Park, Marcos Salganicoff (Siemens Med-ical Solutions USA, Inc., 51 Valley Stream Parkway, Malvern, PA 19355, USA) and Lakshminarasimhan Raghupathi, M.S. Dinesh, Pandu Devarakota (Siemens Technology and Ser-vices, 84 Keonics Electronic City, Hosur Road, Bangalore 560 100, India) [1] P. Angelini, J. A. Velasco, and S. Flamm. Coronary [2] J. G. Fletcher, F. Booya, R. M. Summers, D. Roy, [3] T. W. Freer and M. J. Ulissey. Screening Mammog-[4] R. Guggenberger, P. Eppenberger, D. Markovic, [5] G. Hermosillo, C. Chefdhotel, K. H. Herrmann, [6] M. F. Kircher, H. Hricak, and S. M. Larson. Molecular [7] B. Krishnapuram, J. Stoeckel, V. C. Raykar, R. B. [8] H. B. W. Larsson, T. Y. Lee, N. A. Mayr, G. J. M. [9] L. Lu, J. Bi, S. Yu, Z. Peng, A. Krishnan, and X. S. [10] J. Patterson II, A. Minagar, N. Natarajan, and [11] Z. Peng, Y. Zhan, X. S. Zhou, and A. Krishnan. Robust [12] V. C. Raykar, B. Krishnapuram, J. Bi, M. Dundar, and [13] V. C. Raykar, S. Yu, L. H. Zhao, G. H. Valadez, [14] G. D. Rubin. Data explosion: the challenge of [15] G. K. Thawait, A. Chhabra, and J. A. Carrino. Spine [16] Y. Zhan, M. Dewan, M. Harder, A. Krishnan, and [17] Y. Zhan, M. Dewan, and X. S. Zhou. Cross Modal-[18] Y. Zhan, M. Dewan, and X. S. Zhou. Robust MR spine [19] Y. Zhan, X. S. Zhou, Z. Peng, and A. Krishnan. Ac-[20] S. Zhang, Y. Zhan, M. Dewan, K. Huang, D. N. [21] X. S. Zhou, A. Gupta, and D. Comaniciu. An informa-
