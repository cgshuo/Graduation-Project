 Recently, web usage mining has become an active area of re search and com-mercialization [3, 6, 10]. Often, web usage mining provides insight about user behaviors that helps optimizing the website for increased customer loyalty and e-business effectiveness. Applications of web usage mining are widespread, rang-ing from usage characterization, web site performance improvement, personal-ization, adaptive site modification, to market intelligence [1].

Generally, the web usage mining process can be considered as a three-phase process, which consists of data preparation , pattern discovery ,and pattern anal-ysis [10]. In the first phase, the web log data are transformed into sequences of events (called Web Access Sequences ( WAS s)) based on the identification of users and the corresponding timestamps [1]. Figure 1(a) shows an exam-ple of such WAS s. Here S ID represents a sequence id and a WAS such as a, b, d, c, a, f, g denotes a visiting sequence from web page a to pages b , d , c , a , f and finally to page g . Each sub-table in Figure 1(a) records the collection of WAS s for a particular month. In the second phase, statistical methods and/or data mining techniques are applied to extract interesting patterns such as Web Access Patterns (WAPs)[7]. A WAP is a sequential pattern in a large set of WAS s, which is visited frequently by users [7], that is, given a support thresh-old  X  and a set of WAS s (denoted as A ), a sequence W is a WAP if W appears as a subsequence 1 in at least  X   X |A| web access sequences of A . Lastly, these patterns are used for further analysis in the third phase, which is application dependent.
 From Figure 1(a), it is obvious that web usage data is dynamic in nature. For instance, the WAS b, d, e, a, f, g did not exist in the first and second months but appeared in the third and fourth months. The dynamic behaviors of
WAS s can be attributed to various factors, such as changes to web content and users X  interest, arrival of new web v isitors, and effects of real life events.
In particular, the dynamic nature of WAS data leads to two challenging problems in the context of web usage mining: maintenance of web usage mining results and discovering novel knowledge [11]. In this paper, we focus on discover-ing novel knowledge from historical WAS s. Particularly, we focus on clustering of
WAS s based on the characteristics of thei r evolution over time. The intuition behind this is that WAS s are event/task driven. Consequently, WAS s related to the same event/tasks are expected to be accessed in a similar way over time. For example, consider Figure 1(b), which depicts the support values ( y -axis) of Note that i in the x -axis represents a time period (e.g., day, week, month etc.) and not a particular time point. It can be observed that evolutionary pattern of the supports for A 1 , A 3 ,and A 5 are very similar over time (like the letter  X  X  X ). Similarly, the evolutionary patterns of supports for A 2 and A 4 are similar (like the letter  X  X  X ). However, the  X  X  X  and  X  X  X  clusters cannot be discovered by existing web usage mining techniques due to the fact that they focus only on knowledge discovery from snapshot data and maintenance of the knowledge with the changes to the data source. To extract those clusters, in this paper, we propose the Cleopatra ( CL ustering of E v O lutionary PAT te R n-based web A ccess sequences) algorithm.

The Cleopatra clustering results can be useful in many applications, two of whicharegivenbelow.
 Intelligent Web Site Maintenance: With the massive amount of data on the web, it is critical to maintain a well-structured web site i n order to increase customer loyalty. Recently web usage mi ning techniques have been successfully used as a key solution to this issue [3]. How ever, none of these techniques exploits the dynamic nature of WAS s to restructure web sites. The Cleopatra cluster-ing results can be used by web site admini strators to maintain a well-structured web site. For example, consider the  X  X  X  cluster of WAS s in Figure 1(b), which includes A 1 , A 3 ,and A 5 . By analyzing the evolutionary patterns, the web site administrator can figure out the possible reasons (such as promotions, release of new products, and holidays) for such patterns. Accordingly, the structure of the web site can be modified.
 User Segmentation: User segmentation is to cluster web users based on the corresponding WAS s to provide personalized services [4, 3]. Existing works ei-ther use sequence-based distance or pro bability models to measure the distance between WAS s [4, 3]. However, none of them has taken the dynamic nature of WAS s into account. For instance, two users may have the same list of WAS s that belong to two topics, T 1 and T 2 , having the same support. Using existing segmentation techniques, the two users will be grouped into the same cluster. However, they may have different preferences. For example, the first user may be currently interested in T 2 as most of the WAS sabout T 1 were accessed long time ago, while the second user may be currently interested in T 1 as most of the WAS sabout T mation into account, the user segmentation can be more accurate as users in the same group are not only expected to have similar WAS s but also evolutionary patterns of those WAS s are expected to be similar as well.

The contributions of this paper can be summarized as follows:  X  This is the first approach to cluster WAS s based on the evolutionary pat- X  We proposed an algorithm called Cleopatra for clustering WAS sbased In general, web log data can be considered as sequences of web pages with session identifiers [1]. Formally, let P = { p 1 , p 2 , ... , p m } be a set of web pages. A session S is an ordered list of pages accessed by a user, i.e., S = accessed and t i  X  t i +1  X  i =1 , 2 , 3 ,...,n  X  1. Each session is associated with a unique identifier, called session ID. A web access sequence ( WAS ), denoted as A , is a sequence of consecutive pages in a session, that is, A = p 1 ,p 2 ,p 3 ,...,p n where n is called the length of the WAS .

The access sequence W = p 1 ,p 2 ,p 3 ,...,p m is called a web access pat-tern (WAP) of a WAS A = p 1 ,p 2 ,p 3 ,...,p n , denoted as W  X  A ,ifand only if there exist 1  X  i 1  X  i 2  X  ...  X  i m  X  n such that p j = p i j for 1  X  j  X  m .

A WAS group , denoted as G ,isabagof WAS s that occurred during a specific time period. Let t s and t e be the start and end times of a period. Then, G = [ A 1 , A 2 , ... , A k ]where p i is included in visited between t e and t s . For instance, we can partition the set of WAS son a daily, weekly or monthly basis, where the timestamps for all the WAS sina specific WAS group are within a day, a week, or a month. Consider the WAS s in Figure 1(a) as an example. They can be partitioned into four WAS groups on a monthly basis, where WAS s, the timestamps of which are in the same month, are partitioned into the same WAS group. The size of G , denoted as | G | , reflects the number of WAS sin G .
 When the WAS group G is obvious from the context, the support is denoted as  X  ( A ). Similarly, when the WAS A is obvious from the context, the support is de-noted as  X  .

In our investigation, the historical web log data is divided into a sequence of WAS groups. Let H G = G 1 , G 2 , G 3 , ... , G k be a sequence of k WAS groups generated from the historical web log data. Given a WAS A ,let H A = Then, the degree of dynamic (denoted as  X  ( A )) and version dynamic (denoted as  X  ( A )) of A are defined to summarize the changes of support values in the history (defined later in Section 3.1). Moreover, an evolutionary pattern-based distance (denoted as D ) is defined as the Euclidian distance between WAS s basedontheir version dynamic values.

Given a collection of WAS s, with an evolutionary pattern-based distance D and the degree of dynamic, the objective of the Cleopatra algorithm is to partition WAS sintoclusterssuchthat WAS s within the same cluster are more similar/closer to each other than to WAS s in other clusters. Given a WAS denoted as A = p 1 ,p 2 ,p 3 ,...,p n ,inthispaper,weusean unordered tree called WAS tree to represent the WAS .A WAS tree is defined as T A =( r, N, E ), where r is the root of the tree that represents web page p 1 ; N = { p 1 ,p 2 ,  X  X  X  ,p n } is the set of nodes; and E is the set of edges in the maximal forward sequences of A .Anexampleofa WAS tree is shown in Figure 2(a), which corresponds to the first WAS shown in Figure 1(a).

As a result, a WAS group consists of a bag of WAS trees. Here, all occur-rences of the same WAS within a WAS group are considered identical. Then the WAS group can also be represented as a n unordered tree by merging the WAS trees. We propose an extended WAS tree to record the aggregated support information about the bag of WAS swithina WAS group.
 Definition 1 [Extended WAS Tree]. Let G =[ A 1 , A 2 , ... , A k ]beabagof WAS s, where each WAS A i ,1  X  i  X  k, is represented as a tree T A N , E i ). Then, the extended WAS is defined as T G =(r,N,E,  X  ), where N = N that maps each node in N to the support of the corresponding WAS .
 Consider the first WAS group in Figure 1(a). The corresponding extended WAS tree isshowninFigure2(b),wheretheva lue associated with each node is the  X  value. Next, we propose to merge the sequence of extended WAS trees into an historical WAS tree, called H-WAS tree .
 Definition 2 [H-WAS Tree]. Let H G = G 1 , G 2 , G 3 , ... , G k be a sequence of k WAS groups, where each WAS group G i ,1  X  i  X  k, is represented as an extended WAS tree, T G i =( r i , N i , E i ,  X  ). Then, the H-WAS tree is defined as H G =(r,N,E,  X  ), where r is a virtual root; N = N 1  X  N j  X  X  X  X  N k ;E= E of historical support values of the corresponding WAS .
 Note that, in the H-WAS tree there is a sequence of support values for each node; while there is only one support value for each node in the extended WAS .In this paper, rather than using the entire sequence of support values, we propose two metrics called version dynamic and degree of dynamic to summarize the history of support values.
 Definition 3 [Degree of Dynamic]. Given a WAS , A , with the corresponding denoted as  X  ( A ) , is defined as: Definition 4 [Version Dynamic]. Given a WAS , A , with the corresponding support count sequence H A =  X  1 ( A ) ,  X  2 ( A ) ,  X  X  X   X  n ( A ) , the version dynamic, Figure 2(c) shows a part of an H-WAS tree, where the associated values are the corresponding degree of dynamic value, and the sequence of version dynamic values. The degree of dynamic measures how frequently the WAS changed and the version dynamic measures how significant are the changes in the history. Furthermore, based on the version dynamic metric, we propose an evolutionary pattern-based distance to measure the relationships between WAS s.
 Definition 5 [Evolutionary Pattern-based Distance]. Given two WAS s ( A 1 and A 2 ), the evolutionary pattern-based distance between A 1 and A 2 ,denoted as D ( A 1 ,A 2 ) , is defined as:  X  ( A j ) and  X  ( A j ) are the average support count value and standard deviation of  X  ( A ) .
 Note that, the above evolutionary pattern-based distance measure is actually the Euclidean distance between the smoothed  X  ( A ) sequence using the moving average. This distance measure can handle WAS swith different baseline , scale , and time offset . Such properties are highly desired in this specific problem for the following reasons. Firstly, the average  X  ( A ), which can be viewed as the baseline for the  X  ( A ) sequence, for WAS s that are related to the same event/task may vary a lot while their evolutionary patterns are similar. Secondly, the effects of event/task on different WAS s can be different, which makes the scales of changes (  X  ( A )) to those WAS s different. Thirdly, ther e may be a different time delays for different WAS s related to the same event/task, which may cause the time offset among  X  ( A ) sequences. The Cleopatra algorithm consists of three major phases: the H-WAS tree con-struction phase, the node-based clustering phase, and the subtree-based clustering phase. The objective of the H-WAS tree construction phase is to represent the WAS s as trees and merge them into a single tree structure that records both the structural and temporal information. As the H-WAS tree construction has been discussed in [11], we focus on the clustering phases.
 Node-based Clustering Phase: The objective of this phase is to categorize individual nodes with similar evolutionary patterns in the H-WAS tree into clus-ters. Note that individual nodes represent WAS s from the root to the current nodes. Hereafter, clustering individual nodes refer to clustering WAS s that starts from the root and ends at the corresponding leaf nodes. This algorithm is shown in Figure 3 and consists of two phases, a two-level clustering phase and an iterative refinement phase. In the first phase, given an H-WAS tree, firstly, it is clustered based on the degree of dynamic associated with the individual nodes. Then, using the evolutionary pattern-based distance , the degree of dynamic based clustering results are further partitioned into sm aller clusters. In the second phase, the iterative refinement phase, the merging and splitting algorithms are used to refine the quality of the clustering results. The reason is that in the first phase, the two metrics degree of dynamic and evolutionary pattern-based distance are used separately, when the merging and splitting operations converge, the results will be more accurate.

Note that we use the DBSCAN algorithm [2] to cluster the individual nodes in the H-WAS tree in this phase for the following reasons. First, the DBSCAN algorithm needs no prior knowledge about the number of clusters in the data collection. This is an advantage of the density-based clustering algorithms. Sec-ondly, the naive DBSCAN approach has the time complexity of O ( N log N ), where N is the total number of points in the database, using spatial indexing techniques. Moreover, the DBSCAN algorithm is able to discover clusters with arbitrary shapes and is efficient for very large database. Notice that here the dis-tances between nodes in the H-WAS tree are the Euclidean d istances calculated basedonthesmoothed  X  ( A ) sequence generated using the moving average.
In the first phase, the reason for designing a two-level clustering algorithm is to avoid computational cost. In the first level, the degree of dynamic values are used for producing a preliminary results as the degree of dynamic values are easier to obtain while the cost for calculating the evolutionary pattern-based distances are relatively more expensive. By doing this, the computational cost for calculating the evolutionary pattern-based distances for nodes that are not expected to be in the same cluster can be reduced.

In the second phase, the merging and splitting operations are proposed to refine the clustering results in the first phase. The intuition behind is that it is possible that the first level of degree of dynamic based clustering results may not fully reflect the evolution pattern-based distances between the nodes. Using this iterative merging and splitting operations, which will converge to certain results, we can guarantee that node-based clustering results are accurate, which is the foundation for the sub-tree based clustering in the next phase.
Specifically, merging operation is shown in Figure 4. Firstly, for each cluster a virtual centroid is obtained. Then, the distances between those centroids are calculated using the proposed evolutionary pattern-based distance measure. For clusters whose centroids are within a distance of 2  X  will be merged together to form a new cluster, where is the radius parameter for the DBSCAN al-gorithm [2]. After that, the splitting operations is then performed on the new clustering results to split them into new clusters if possible. This splitting process is based on the DBSCAN algorithm as well.
 Subtree-based Clu stering Phase: The output of the node-based clustering phase is a set of clusters that consist of sets of individual nodes with similar change patterns. However, given a cluster, the relations between individual nodes are not captured. In this section, the individual nodes within clusters are merged together to form subtrees, which can rep resent higher level concepts or objects. Note that, the subtree construction process is guided by not only the links in the H-WAS tree , but evolution patterns of these nodes should be similar. For a given node in the cluster, to measure the number of nodes that have similar evolution patterns with it, the evolutionary degree is defined as follows. Definition 6 [Evolutionary Degree]. Let C = NodeClust ( H ) be a function that implements the node-based clustering phase where H is the H-WAS tree and C is the set of clusters returned by the function. Let B ( i, j )= Edge ( n i ,n j ) be a function that takes in two nodes n i and n j and returns 1 if there exists or C x  X  C . Then, the evolutionary degree of n i  X  C x (denoted as E  X  ( n i ) ) is defined as follows: E  X  ( n i )= | C x | j =1 B ( i, j ) ,wherei = jand 0 &lt;j  X | C x | From the above definition, it can be observed that nodes that have large evolu-tionary degree are expected to form larg e subtrees. In this section, we propose to extract the list of subtrees for each clu ster. Firstly, nodes in each cluster are ranked based on the evolutionary degree in descending order. Then, to ensure that WAS s in the same subtree have similar evolutionary patterns with each other, the intra similarity is defined as follows.
 Definition 7 [Intra Similarity]. Let C = NodeClust (H) and C = { C 1 , C 2 ,  X  X  X  , C n } .Let t j be a subtree of H and N t be the set of nodes in t j .Let K = { K where Max( K ) is the maximum value in K .
 Definition 8 [Cluster Subtree]. Let t j =( N j ,A j ) be a subtree of H such that N j  X  C x and C x  X  C where C = NodeClust ( H ) .Then t j is a cluster subtree if IS ( t j )  X   X  where  X  is a user-defined threshold.
 The algorithm for extracting subtree clusters is presented in Figure 5. The input of the subtree-based clustering algorithm is a set of clusters with sorted nodes. Firstly, the node with maximum evolutio nary degree is selected and the corre-sponding subtree that includes all the nodes that are connected to that nodes is constructed and tested against the threshold value of IS . If this subtree is a cluster subtree, then all the nodes in this subtree are eliminated from the list of subtrees in that cluster. Otherwise, if th is subtree is not a cluster subtree, then the evolutionary degree of this node is set to -1 . This process iterates till all the nodes in the subtree are tested. In this section, we evaluate our proposed clustering algorithm with two real datasets, the web log UoS and Calgary , obtained from the Internet Traffic Archive [5]. The UoS records the historical visiting patterns for University of Saskatchewan from June 1, 1995 to December 31, 1995, a total of 214 days. In this seven month period there were 2,408,625 requests. The Calgary logs were collected from October 24, 1994 through October 11, 1995, a total of 353 days. There were 726,739 requests. Both of them have 1 second resolution. The web access patterns are transformed into a sequence of extended WAS trees with a duration of one day. All the following experiments are carried out on a PC with Intel Pentium 4, 1.7Ghz CPU, and 512MB RAM.

Our experiments focus on two aspects: the quality and novelty of the clus-tering results. To evaluate the quality of the our clustering results, two quality metrics, Homogeneity and Separation [9, 8], are used. Here we review the metrics: H S A i is the i th WAS subtree; M is the total number of node pairs that are within the same cluster; C is the set of clusters in the result and | C | is the size of the set; C ( A i ) is the cluster to which A i belongs. Note that, here we transform the evolutionary pattern-based distance to the similarity measure S such that we can use the above cluster quality metrics. That is, S ( A i ,A j )= e  X  X  ( A i ,A j ) .The larger homogeneity implies a better result, while a larger separation shows a worse result.

Figure 6 shows the quality of the clustering results with different parameters for the DBSCAN algorithm, size of moving window in the moving average, and the intra similarity threshold. The reason of using the above cluster quality metrics is that, due to privacy reasons, the original URLs of web pages in the web usage dataset are not available. Therefore, the ground truth of the clusters are not available. However, from the values in Figure 6, compared with the corresponding values in other applications that using above quality metrics, the quality of our results is comparable to the results in [9, 8].

Considering the novelty of our clustering results, although there is no quan-tified measures, we have the following observations. First, in the Cleopatra clustering results, we found many WAS pairs that are in the same cluster are very far away in the H -WAS -tree while the evolutionary patterns are quite sim-ilar. Such clustering results can be useful for exploring the hidden factors that lead to the evolution of the corresponding WAS s. Second, the overall structures of the clusters are quite similar in the Cleopatra clustering result. This means that suppose we have two clusters C 1 and C 2 ,where C 1 = { A 1 , A 2 , A 3 } and C 2 = { A pairs such as { A 1 , A 4 } , { A 2 , A 5 } ,and { A 3 , A 6 } are siblings or connected. This work is motivated by the fact that existing web usage mining techniques only focus on mining snapshot web usage data and maintaining of the mining re-sults incrementally. They do not consider the dynamic nature of web usage data. In this paper, we proposed the first approach of clustering historical WAS sbased on the evolutionary patterns. Experiments with real life datasets show Cleopa-tra can efficiently produce high quality clusters that cannot be discovered using existing web usage mining techniques.
 Acknowledgements. We thank Dr Mukesh Mohania from IBM India Research Lab for the feedbacks on the initial draft of this paper.

