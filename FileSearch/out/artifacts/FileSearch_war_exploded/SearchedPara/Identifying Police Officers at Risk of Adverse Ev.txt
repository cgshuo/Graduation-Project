 Adverse events between police and the public, such as deadly shootings or instances of racial profiling, can cause serious or deadly harm, damage police legitimacy, and result in costly litigation. Evidence suggests these events can be prevented by targeting interventions based on an Early Intervention System (EIS) that flags police officers who are at a high risk for involvement in such adverse events. Today X  X  EIS are not data-driven and typically rely on simple thresholds based entirely on expert intuition. In this paper, we de-scribe our work with the Charlotte-Mecklenburg Police De-partment (CMPD) to develop a machine learning model to predict which officers are at risk for an adverse event. Our approach significantly outperforms CMPD X  X  existing EIS, increasing true positives by  X  12% and decreasing false pos-itives by  X  32%. Our work also sheds light on features re-lated to officer characteristics, situational factors, and neigh-borhood factors that are predictive of adverse events. This work provides a starting point for police departments to take a comprehensive, data-driven approach to improve policing and reduce harm to both officers and members of the public.
Recent high-profile cases of police officers using deadly force against members of the public have caused a political  X  This work was started at the 2015 Eric &amp; Wendy Schmidt Data Science for Social Good Summer Fellowship at the University of Chicago.
 and public uproar [4, 5]. They have also highlighted and fur-ther encouraged tensions between the American police force and citizens. While such violent altercations tend to capture the nation X  X  attention, there is evidence that more mundane interactions between the police and the public can have neg-ative implications as well [13]. Adverse events between the police and the public thus come in many different forms, from deadly use of a weapon to a lack of courtesy paid to a victim X  X  family. These events can have negative mental, physical, and emotional consequences on both police officers and citizens. We discuss our precise definition of  X  X dverse event X  below as an aspect of our experimental design.
Prior work has shown that a variety of factors are predic-tive of adverse events [11, 6]. While some of these factors are beyond the control of police officers and their departments, many of them can theoretically be addressed ahead of time. For example, training in appropriate use of force may reduce the odds of an officer deploying an unnecessary level of force in a particular situation.

The incidence of such factors is not randomly distributed among officers or over time [11]. Certain officers, at certain periods of time, can be identified as being more at risk of in-volvement in an adverse event than others. Because police departments have limited resources available for interven-tions, a system to identify these high-risk officers is vital. Using this kind of Early Intervention System (EIS), police departments can provide targeted interventions to prevent adverse events, rather than responsively dealing with them after such an event occurs.

The work described in this paper was initiated as part of the White House X  X  Police Data Initiative 1 launched based on President Obama X  X  Task Force on 21st Century Policing. As part of this effort, we had discussions with several US police departments and it became clear that existing EISs were in-effective in their attempts to identify at risk officers. This paper describes our work with the Charlotte-Mecklenburg Police Department (CMPD) in North Carolina to use ma-chine learning algorithms to improve their existing EIS. ht t ps://www.whitehouse.gov/blog/2015/05/18/ launching-police-data-initiative Figure 1: An illustration of five at-risk officers that will go on to have an adverse incident and their risk factors. The darker the red, the stronger the importance of that feature.
CMPD X  X  1800 officers patrol more than 500 square miles encompassing more than 900,000 people. Over the last ten years, CMPD has become a leader in data-driven policing by investing heavily in a centralized data warehouse and building its own software, including an EIS. Like most EISs, CMPD X  X  system uses behavioral thresholds, chosen through expert intuition, to flag officers. A supervisor then deter-mines whether an intervention is appropriate. Several de-partments have adopted CMPD X  X  system since it was built more than ten years ago [16]. To improve the current sys-tem, we focus on the following prediction task:
We show that a random forest model with an extensive set of features significantly outperform the department X  X  ex-isting EIS. Specifically, our model shows a relative increase of  X  12% in true positive rate and a relative decrease of  X  32% in false negative rate over the existing EIS in a tem-poral cross-validation experiment. Unlike the existing sys-tem, our approach uses a data-driven approach and can thus be used to explore officer characteristics, neighborhood and environmental factors that are predictive of adverse events.
Figure 1 shows an illustrative chart that shows the indi-vidual risk factors that are associated with a high risk of an adverse event for five anonymous officers. Each officer in Figure 1 went on to have an adverse event. These risk factors were met with substantial acceptance by CMPD -an indicator of external validity of our modeling approach.
In addition to factors we discover in our analyses of feature importances from this prediction task, we also provide an exploratory analysis of predictive features at the single event level to better understand situational factors that may play a significant role in scenarios leading to adverse events.
The system described here is the beginning of an effort that has the potential to allow police chiefs across the nation to see which of their officers are in need of training, counsel-ing, or additional assistance to make them better prepared to deal safely and positively with individuals and groups in their communities. Police departments can move from be-ing responsive to negative officer incidents to being proactive and preventing them from happening in the first place.
In summary, the contributions of this paper are the fol-lowing:
A small minority of officers account for the majority of ad-verse events, such as citizen complaints or excessive uses of force [11, 6]. EISs, which are designed to detect officers ex-hibiting alarming behavioral patterns and prompt interven-tion such as counseling or training before serious problems arise, have been regarded as risk-management tools for coun-tering this issue. The US Commission on Civil Rights [1], the Commission on Accreditation of Law Enforcement Agencies [2], US Department of Justice [3], the International Asso-ciation of Chiefs of Police, and the Police Foundation have recommended departments use EISs. Most federal consent decrees (legal settlements between the Department of Jus-tice and a police department) to correct problematic policing require an EIS to be in place [19]. A 2007 Law Enforcement Management and Administrative Statistics (LEMAS) sur-vey showed that 65% of surveyed police departments with 250 or more officers had an EIS in place [15].

Current EISs detect officers at risk of adverse events by observing a number of performance indicators and raising a flag when certain selection criteria are met. These criteria are usually thresholds on counts of certain kinds of incidents over a specified time frame, such as two accidents within 180 days or three uses of force within 90 days. Thresholds such as these fail to capture the complex nature of behavioral patterns and the context in which these events play out. For example, CMPD X  X  system uses the same thresholds for officers working the midnight shift in a high-crime area as an officer working in the business district in the morning. More sophisticated systems flag outliers while conditioning on one or two variables, such as the officer X  X  beat 2 , but still fail to include many factors. For example, CMPD X  X  indi-cators include complaints, uses of force, vehicle pursuits &amp; accidents, rule-of-conduct violations, raids and searches of civilians or civilian property, and officer injuries. Important factors, such as prior suspensions from the force, are often not included.

Empirical studies on the effectiveness of these systems have been limited, and their findings give mixed conclusions.
Roughl y , an indicator of the area the officer patrols and the time at which they patrol it Case studies focusing on specific police departments have show n that EISs were effective in decreasing the number of citizen complaints [20, 9], but it is unclear whether this de-crease arises from a reduction in problematic behavior or from discouraging officers from proactive policing [23]. A large-scale study of emerging EISs across departments con-cludes that EIS effectiveness depends on departmental char-acteristics and details of implementation, such as which in-dicators are tracked, what thresholds are assigned, and how supervisors handle the system X  X  flags [15].

Beyond their possible ineffectiveness, threshold-based sys-tems pose additional challenges. First, inconsistent use of the system creates an obstacle for threshold-based EISs. Second, threshold-based systems are difficult to customize. At least one vendor hard-codes thresholds into their EIS, making changes difficult and costly X  X hich is good for the vendor but bad for the department. Ideally, the system should improve as the department collects more data, but threshold-based systems require extensive use of heuristics, making such changes unlikely.

Third, threshold systems are easily gamed. Because thresh-olds are visible and intuitive, officers can modify their behav-iors slightly to avoid detection -either not taking an action they should have taken, or by not reporting an action they did take. Finally, output from threshold systems are limited to binary flags instead of risk scores. Risk scores enable the agency to rank officers by risk, to explicitly choose tradeoffs (e.g. precision vs. recall), and to allocate resources in a prioritized manner.

A machine learning system would be able to alleviate many of these issues. With respect to customization, ma-chine learning models can be easily retrained on new data and with new features. Furthermore, given the volume of features and feature interactions that can be used within a machine learning model, parameters are sufficiently complex that the system cannot be easily gamed. Importantly, such models return control to the department, allowing its lead-ers to choose the right mix of accuracy and interpretability. Finally, machine learning approaches can be used to gener-ate risk scores as opposed to pure binary classification. In addition to being a better fit for the resource constraints faced by today X  X  American police force, risk-score systems can identify which officers are doing well as easily as which are at risk. The department can use this information when assigning officers to partners or when looking for best prac-tices to incorporate into its training programs.
Designing an effective EIS requires knowledge of what fac-tors may be predictive of adverse events. The literature on police behavior and misconduct has focused on three broad sets of potential predictors: officer characteristics, situa-tional factors, and neighborhood factors.

More educated police officers, particularly those with four-year college degrees, tend to have fewer complaints and al-legations of misconduct compared to officers with less edu-cation [14, 22, 8]. In a study of misconduct in the New York Police Department, White and Kane [22] found that, in ad-dition to education level, prior records of criminal action, prior poor performance and a history of citizen complaints were all significant predictors of misconduct as well.
Situational factors are those specific to particular inci-dents that (perhaps) result in an adverse event. These fac-Database Num.
 Internal Affairs 20K 2002-Now Dispatch Events 14M 2003-Now Criminal Complaints 959K 2005-Now Citations 946K 2006-Now Traffic Stops 1.6M 2002-Now Arrests 350K 2005-Now Field Interviews 180K 2003-Now Employee Records 20K 2002-Now Secondary Employment 651K 2009-Now Training 1.4M 2001-Now Existing EIS 14K 2005-Now Table 1: Description of the types of data used, as well as the n umber of records and the time window over which we have data of that type tors include demographics and behaviors of the citizen(s) involved in that particular incident as well as features of the incident itself, such as time of day and location. White [21] found that certain categories of incidents, such as rob-beries and disturbance incidents, were more likely to result in police use of deadly force. However, studies examining the relationship between citizen characteristics (such as race, gender, and age) and police behavior (such as likelihood of arrests and citations, and use of force) have found mixed re-sults [17]. Research on citizen characteristics has, moreover, been limited due to lack of publicly available data.
Finally, neighborhood features have also been studied as a potential predictor of police misconduct. Sobol [17] found that incidents in high-crime neighborhoods have a greater likelihood of ending in interrogation, search and/or arrest. Similarly, Terrill and Reisig [18] found that police officers were more likely to use higher levels of force in disadvantaged and high-crime neighborhoods.

Our models incorporate features at each of these levels of analysis, finding that predictors at each level have a unique and important role in predicting officers at risk of adverse events. We are currently involved in efforts to experimen-tally distinguish causal factors. In the present work, how-ever, efforts are restricted to understanding only those fea-tures correlated with officers at risk of adverse events.
The data for this work consists of almost all employee information and event records collected by CMPD to man-age its day-to-day operations. Certain information, such as employee names, ID numbers, and military veteran sta-tus, as well as all narrative fields in the data, were redacted in accordance with North Carolina personnel laws to pro-tect employee privacy and safety. The major types of infor-mation present in the dataset, summarized in Table 1, are described in detail in this section. Almost all records are associated with one or more involved officers and include a hashed version of the ID of that officer in addition to any other information.
Internal Affairs (IA) records contain the information about adverse events that we use as our outcome variable. Every IA record pertains to a single officer. When a department emplo yee or member of the public files a complaint or when an officer uses force, engages in a vehicle pursuit, gets into a vehicle accident, commits a rule-of-conduct violation, is injured, or conducts a raid and search, CMPD creates an IA record. Each record contains additional information such as a link to the dispatch event 3 during which the incident took place. Finally, each record contains the reviewing supervi-sor X  X  decision regarding the appropriateness of the officer X  X  actions as well as the recommended intervention if interven-tion was deemed necessary.
 Figure 2: The Internal Affairs process and our definition of an adv erse incident.

IA investigations of different event types can carry differ-ent outcomes: complaints can be deemed sustained or not sustained ; accidents and injuries can be deemed preventable or not preventable ; and everything else (e.g. use of force) can be deemed justified or not justified . We define records with not justified , preventable , and sustained dispo-sitions to define the class of adverse events, with exceptions for a number of internal complaints that we consider less egregious, such as misuse of sick leave. These data serve as the positive class for our de-pendent variable. Figure 2 shows the IA process and our definition for an adverse incident, and Table 2 lists the full set of IA outcomes that we label as adverse events. Notably, we proceed with the assumption that the Internal Affairs (IA) data reasonably represent the true distribution of adverse events and officer fault. For various reasons, this assumption may be flawed. For example, many departments screen complaints before entering them into their IA system, and incidents have been reported in which officers do not faithfully record events. While CMPD encourages good data collection by punishing officers who fail to report adverse in-cidents, there is no complete guarantee of data accuracy. In addition, almost all IA cases are resolved internally without reference to an external agency. Unfortunately, without sim-ilarly comprehensive data from other police departments, it is difficult to estimate what effect these biases might have on the present work. We thus note this point as a condition on which the present analysis should be qualified and plan defined b elow Event IA Ruling Citizen Complaint * Sustained Officer Complaint * Sustained Vehicle Accidents Preventable Injuries Preventable Use of Force Unjustified Raid and Search Unjustified Pursuit Unjustified Discharge of Firearm Unjustified
Tire Deflation Device Unjustified Min or violations excluded Table 2: The types of events within the IA database that we define as representative of an adverse event to investigate this further as we expand our work to other police departments.
CMPD X  X  system creates a dispatch event every time an officer is dispatched to a scene X  X or example, in response to a 911 call X  X nd every time an officer reports an action to the department. The dispatch system is the backbone of how officer movements are coordinated, and an officer X  X  dispatches provide a rough guide to what the officer did and where the officer did it at all times they are active on the force. Dispatch records include the time and location of all events, as well as the type of event (e.g. robbery) and its priority. Dispatches are often linked in CMPD X  X  system to other types of events, such as arrests or IA cases, that occurred during that dispatch.
The criminal complaints data provided by CMPD con-tains records of criminal complaints made by citizens. Each record includes a code for the incident, the location of the incident, the type of weapons involved if weapons were in-volved, and details about victims and responding officers. It also contains flags that include information such as whether the event was associated with gang violence, domestic vio-lence, narcotics activity or hate crimes.
The citations data provides details of each citation writ-ten by officers. Each record contains the date and type of citation, a code corresponding to the division, and additional meta-data such as whether the citation was written on paper or electronically.
CMPD officers are required to record information about all traffic stops they conduct. Records include time, loca-tion, the reason for and the outcome of the stop, if the traffic stop resulted in the use of force, and the stopped driver X  X  socio-demographic profile.
CMPD records every arrest made by its officers, including when and where the arrest took place, what charges were associated, whether a judge deemed the officer to have had probable cause, and the suspect X  X  demographic information.
A  X  X ield interview X  is the broad name given by CMPD for any event in which a pedestrian is stopped and/or frisked, or any time an officer enters or attempts to enter the property of an individual. In the latter case, officers may simply be completing a X  X nock and talk X  X o request information from a citizen, or be part of a team conducting a  X  X aid and search X  of an individual X  X  property. A field interview can also be conducted as result of a traffic stop. Records contain tem-poral and spatial information as well as information about the demographics about the interviewed person.
The department X  X  employee information includes demo-graphic information on every individual employed by the department, including those that have retired or been fired. The data includes officer education levels, years of service, race, height, weight, and other persistent qualities of officers.
CMPD records all events in which officers are hired by ex-ternal contractors to provide security. These external con-tractors include, for example, financial institutions, private businesses and professional sports teams. Officers are al-lowed to sign up for these various opportunities through CMPD and are required to record all events that occur at them, such as disturbances, trespasses or arrests.
CMPD requires officers to receive rigorous training on a variety of topics, from physical fitness to how to interact with members of the public. The department records each officer X  X  training events.
We were also given the history of EIS flags going back over 10 years to 2005. Each record identifies the relevant officer and supervisor, the threshold triggered (e.g. more than two accidents in a 180 day period or more than three uses of force in an 90 day period) and the selected intervention for each flag, which can include training and counseling.
In addition to the data provided by CMPD, we also use publicly available data from 2010 and 2012 neighborhood quality-of-life studies 4 to understand the geospatial context of CMPD events. These studies collect data on many neigh-borhood features including Census/ACS data on neighbor-hood demographics and data on physical characteristics, crime, and economic vitality.
In addition to the potential bias discussed above, the dataset has a few other limitations. First, traffic stops, field inter-views, and criminal complaints are entered into the CMPD system by the officers themselves, often in the midst of busy shifts or retroactively after their shifts have ended. Times and locations are often approximate, and these types of ht t p://mcmap.org/qol/ events often fail to be properly linked to an associated dis-patch call, which limits what other information (such as IA cases) they can be linked to. Other important fields are also missing with relative frequency from the data. We take standard measures to accommodate missing data, and try to mitigate the unreliability of temporal and spatial infor-mation by aggregating the data across time and space in our feature generation.
The goal of the EIS is to predict which officers are likely to have an adverse event in the near future. We formulate it as a binary classification problem where the class of interest is whether a given officer will have an adverse event in a given period of time into the future. In discussions with CMPD and in consideration of the rareness of adverse events, we decided that one year was an appropriate prediction win-dow. Efforts were chiefly geared towards the extraction of these features -in total 432 features were used. For model-ing, we tried a variety of model types, including AdaBoost, Random Forests, Logistic Regression, and Support Vector Machines. Random searches over a standard hyperparame-ter space using 3-fold cross-validation were used to tune each model. Below, we discuss our feature extraction process and how models were evaluated.
We generated features based on our expertise as well as on discussions with experts at the Charlotte-Mecklenburg Police Department. Patrol officers, Internal Affairs investi-gators, members of our officer focus group, and department leadership suggested features that varied across the officer-and neighborhood-levels of analysis. We explore situational factors in Section 7.

At the officer level, we generate behavioral features by ag-gregating the record of incidents by each officer, establishing a behavioral history. The simplest features are frequencies and fixed-period counts of incidents the officer has been in-volved in (e.g. arrests, citations, etc.) and incident sub-types (e.g. arrests with only discretionary charges). Broad incident classes we track include arrests, traffic stops, field interviews, IA cases, and external employment.

Notably among incident sub-types, we track incidents we believe are likely to contribute to officer stress, such as events involving suicides, domestic violence, young children, gang violence, or narcotics. In addition, we incorporated features describing the number of credit hours of training officers had in topic areas of relevance: less-than-lethal weapons train-ing, bias training, and physical fitness training.
To these frequencies we add a variety of normalized and higher-order features. To account for high-crime times and locations, we include outlier features, where we compare an officer X  X  event frequencies against the mean frequencies for the officer X  X  assigned division and beat. We generate time-series features from raw event counts (e.g. a sudden increase in the number of arrests in the six-month period prior to the point of analysis) to capture sudden changes in behavior. We also use more static officer features such as demographics, height, weight, and time on the force.

We include the existing EIS thresholds as features in our model. These EIS flags will occur if a threshold number of adverse events occur within a specific timeframe, e.g. 3 Metric Existing True Positives 43 48 +12% False Positives 624 427  X  32% True Negatives 802 999 +25% False Negatives 40 35  X  8% Table 3: Comparison of model performance between the ex-isti ng threshold-based EIS and the improved predictive EIS developed in this work. uses of force within 90 days, and similarly for other potential warning signs such as complaints and sick leave use.
Finally, we include neighborhood features to capture spe-cific information about the areas where officers patrol. For example, we included the 311 call rate for CMPD patrol ar-eas, which correlates not only with conditions in the neigh-borhood but also with the residents X  willingness to report problems to city government.
We validate our models using temporal cross validation [12], meaning that if, for example, predictions were being made for adverse events in the years 2010-2012, we train our models on data from periods before 2010. With our data ranging from 2009 to 2015, we perform multiple evalu-ations over the data and aggregate them to come up with the final statistics. For each evaluation, we use precision (per-cent of officers flagged who actually have an adverse event) and recall (percent of officers with adverse events who are flagged) at various probability (or risk score) thresholds as outcome metrics. We compare various versions of our mod-els and feature sets to each other as well as to a random baseline, to a classifier that exactly replicates the current EIS, and to a logistic regression baseline model using only the officer age, sex, race, years of experience and days since last adverse event as features.
In this section we discuss results in terms of performance on the officer-level prediction problem as well as an analysis of highly predictive features.
At the officer level, about 8  X  9% of officers will have an adverse event of some type in every year. The best binary classification model to predict these events was a Random Forest with 50 estimators. Table 3 shows how our model compares with the EIS baseline in terms of false positives, false negatives, true positives, and true negatives. Our re-sults show that moving beyond the current threshold system and using a broader set of data with more complex models improves accuracy. Our best performing model is able to flag 12% more high-risk officers (true positives) while flag-ging 32% fewer low-risk officers (false positives), compared to the current system. We show the precision-recall curves for the officer-level prediction problem in Figure 3.
Figure 4 shows the features with the largest feature im-portances in our best performing random forest model. The most predictive features of the model were those relevant to Figure 3: Precision-recall curves for the Random Forest mode l. the prior IA history of the officer: officers who are routinely found to have been engaged in an adverse event are likely to engage in another such event in the future. This is fairly typical in behavioral prediction tasks.

Such indicators are complex and overlie a variety of causal factors -for example, officers who are in areas of higher rates of violent crime are more likely to use force because of the area they patrol and perhaps not because of any inherent tendencies. However, two caveats to this notion are in or-der. First, significant controls at the neighborhood level exist within the model. Such controls have an impact on prediction -for example, vacant land area rates are a sig-nificant predictor of officer risk. Second, indicators such as the rates of prior adverse incidents and sustained complaints indicate cases where IA officials previously found officers to be at fault over and above these increased risk rates.
Combined, these observations provide support for the idea that a subset of officers are at particular risk for adverse events, and that an EIS which controls for non-officer level factors may be able to find such officers so that interventions can be applied. Further, these factors are based on behav-ioral characteristics of the officer, not demographic informa-tion . While correlations are likely to exist between behavior and demographics, and causal factors may be extremely dif-ficult to untangle, it is preferable to base policy decisions on things officers can remedy (behavior) as opposed to things they cannot easily change.

To maximize the insight gained from the most prominent features, it is ideal to have information on the directionality of these features, i.e. whether the changes in one of the fea-tures correlate positively or negatively with the correspond-ing change in the predicted risk score. Such information would clarify how a feature moves the trained model, thereby allowing for a deeper understanding of the underlying phe-nomenon. Traditional approaches to feature importance in random forest models do not, however, allow us to infer the direction of a feature X  X  effect. In order to address this is-sue, we perform a Monte Carlo sampling of our model X  X  risk score surface to estimate the conditional distribution of risk scores, or the  X  X isk score curve, X  on each feature.
We begin with 100,000 Monte Carlo samples generated by drawing from a uniform distribution in the feature space spanning the entire range of feature values in the training data. To analyze the risk score curve of a feature, we di-vide the generated samples into 50 bins ranging from the minimum to the maximum value of the feature of interest found in the dataset. Finally, within each bin, the mean and the standard deviation of the risk score distribution are calculated. In Figure 5, we present the risk score curve for the number of uses of force in traffic stops over the last 15 years. It is notable that a sharp transition, or shift, in the risk score distribution occurs around seven traffic stops. This sharp transition aligns with the behavior one would expect from a random forest model, where risk scores are determined via binary selection criteria that act as sharp distributional  X  X witches X .

To construct a metric for directionality from the estimated risk score curve, we use the mean risk score difference be-tween the first and last bin. While this metric is arguably less robust for features that undergo multiple transitions of conflicting directions, it is a good first-order proxy for the directionality of the most prominent features. Further, in assessing the resulting data, such multiple transitions were rare in the feature set used for the present work.
After estimating the risk score curve for every feature used, we present in Figure 4 the most prominent direc-tionalities we found in our model. It is worth noting that while there is a strong correspondence between features with high importances and high directionalities, it is not an exact match. This is because the definition of feature importance in random forests depends not only on the strength of the directionality of a feature, but also on the exact configura-tion of the trees within the forest. We are actively looking at other ways of determining feature importance, such as using additive models [7].
 Figure 5: Risk score curve for the number of uses of force in traffic stops over the last 15 years.
As an exploratory exercise to better understand situa-tional, near-term factors that may have an impact on of-ficer risk of adverse events, we attempt to predict which dispatch calls are likely to result in an adverse event. Each dispatch call record in the data contains data that includes time, location, type of call, officers dispatched, and priority (or urgency) of the situation. These environmental factors of a given event could play a significant role in determining whether an event  X  X urns adverse X , in addition to the charac-teristics of officers involved. Furthermore, a history of dis-patch calls can be constructed for each officer, from which a general pat tern of dispatches leading to an eventual adverse event can be found. For example, overworked officers at the end of a long shift may be more likely to be involved in an adverse event, and this analysis allows us to discern whether such patterns exist.

To make predictions at the dispatch-level, we use most of the features generated for the officer-level experiment. To these we add features of the dispatch event itself, such as its priority level, features of medium and short-term officer stress, such as how many consecutive days the officer had been on duty at the time of the dispatch, and features of the location in which the dispatch takes place. In total, we examine 359 features at the dispatch level.

For this task, there is no existing baseline method anal-ogous to the EIS. Therefore, all comparisons are against a random baseline. Further, and most importantly, adverse events are extremely rare: 1 in 10,000 dispatches end in any type of adverse incident in our dataset. As an exploratory analysis, we subset the data to a ratio where feature analy-sis can be performed. This means that model performance should not be expected to hold in realistic settings .
The positive examples for this prediction task consist of every dispatch from CMPD X  X  database that can be linked to an adverse event. These 929 positive examples are con-trasted against 8,361 negative examples (i.e.  X  X on-adverse X  events) drawn randomly from the database, for a 10%-90% balanced training set of 9,290 examples. We then split the data temporally, training on all adverse events prior to 2013, and testing on those following 2013.

To understand what types of feature lend utility to this prediction model, we compare performance of different fea-ture subsets. Notable subsets we examine include dispatch features, such as the priority level of the dispatch (1 to 9) or the typecode assigned to it by the dispatcher (e.g. SUSP-SCN for suspect-on-scene), and medium-to-short-term offi-cer stress features, such as how many hours the officer has been on duty at the time of the dispatch.

Figure 6 shows the performance of a tuned random forest on predicting whether dispatch events will result in adverse interactions between the involved officer and a citizen. The full model achieves an F1 of 0.478 with respect to the posi-tive class, significantly better than the 0.18 that would result from random guessing.
 Features of the dispatch event itself dominate the model. Used alone, they achieve comparable performance to the full model. Removed from the dataset, they reduce model performance to indistinguishable from random. This sug-gests that immediate situational factors outweigh longer-term officer-or location-level factors in determining when a dispatch is likely to result in an adverse event.
Figure 7 examines which features are used to the greatest cumulative effect in reducing sample impurity in the ran-dom forest model. The clear outlier is travel time, which appears to have a major impact in predicting adverse out-comes. Other significant features include the JST-OCC dis-patch typecode, indicating an event that has just occurred, and the career arrest rates, both discretionary and overall, of the officer involved in the dispatch.

Figure 8 further examines feature importance by using the same Monte Carlo sampling method employed in figure 4. Travel time is found to have a positive sign, meaning that longer travel times are associated with a higher risk Figure 6: Comparison of model performance (f1-score w/resp ect to positive class) of feature subsets on dispatch-level adverse-outcome prediction Figure 7: Conventional unsigned feature importances in dispatc h-level random forest model of adverse outcomes in the model. The dominant positive feature by this measure of importance is the REPT-OFC dispatch typecode, indicating that the situation being ad-dressed by the dispatch was reported by the responding po-lice officer. Similar, and also positively contributing, are the OFC-INVL (officer involved) typecode and OI (officer-initiated) dispatch type. Other contributing features include the suspect-on-scene typecode, the number of hours the offi-cer has been on duty, and two features associated with how frequently that officer makes discretionary arrests
Features that contribute negatively to the risk of adverse outcomes include the height and weight of the officer, and the number of days since their last discretionary arrest. Wealth-ier neighborhoods with a higher age of death are associated with fewer negative outcomes, though interestingly, so are those with a greater number of minor nuisance violations.
Taken together, these results seem to reinforce the con-clusion that situational factors are largely, though not ex-Figure 8: Inferred signed feature importances in dispatch-lev el random forest model clusively, predictive of adverse outcomes at the individual dispatch level.  X  X ot X  dispatches initiated by officers them-selves (as opposed to citizens by way of 911 calls), seem more likely to end in adverse outcomes. Indicators of heightened officer stress (hours on duty) and aggressive policing style (discretionary arrest rate), seem to also have a positive im-pact on the risk of adverse outcomes.
Next steps include implementation and effect of interven-tions. There are several ways the risk scores could be used by a police department. However, our primary goal is to develop individually tailored interventions to ensure that each officer receives appropriate training and support. In addition, the risk scores enable the prioritization of resource allocation to the officers that are considered most at-risk.
We are exploring using our model to develop interventions for groups of officers. When risk scores are aggregated over groups defined by unit or division, we find that some divi-sions and units have a significantly higher risk than others. These divisions and units may benefit from additional group interventions such as group trainings to lower their risk.
In terms of implementation, as always, the utility of the improved EIS will be mediated by social structures within the department. Perhaps most importantly supervisors us-ing the EIS system should also be trained to treat model results similarly. Instructing supervisors on how to under-stand the meaning of risk scores and how to interpret fea-tures will be an important avenue of our implementation approach.

Our dispatch-level models take the first steps toward pre-dictive risk-based dispatch decisions, where an officer who is at higher risk of an adverse incident for that dispatch can potentially be held back and a different officer, at a lower risk score, can be dispatched. For example, in June 2015 a police officer in Texas, Cpl. Eric Casebolt, pulled his weapon on children at a pool party after responding to two suicide calls earlier that shift [10]. Most police departments would like to avoid these situations by dispatching low-risk officers to calls. Risk-based dispatching could enable improved dis-patching to match officers and dispatches while minimizing risk of harm to the public and the officer.

Finally, future work will focus on finding the appropriate balance between actionability, transparency, interpretabil-ity, and resistance to gaming by officers. A dashboard can help strike a balance between these concerns and commu-nicate model results in easy-to-use and actionable formats, which we are currently developing for use by the CMPD. The proposed system will provide the top feature importances, which will enable officers in the department to understand what factors are typically correlated with adverse incidents without providing a recipe for those that wish to game the system.
The present work uses a machine learning approach to develop an Early Intervention System for flagging police of-ficers who may be at high risk of involvement in an adverse interaction with a member of the public. Our model sig-nificantly outperforms the existing system at the Charlotte-Mecklenburg Police Department (CMPD). Our model also provides risk scores to the department, allowing them to more accurately target training, counseling, and other in-terventions toward officers who are at highest risk of having an adverse incident. This will allow the department to bet-ter allocate resources, reduce the burden on supervisors, and reduce unnecessary administrative work of officers who were not at risk.

Further, our models provide insight into which factors are important in predicting whether an officer is likely to have an adverse event. We find that, largely, intuitive officer-level and neighborhood level features are predictive of adverse events, but also that many features the department had not yet considered are also correlated with future adverse events. This information will hopefully allow this department, and potentially other police departments, to develop more effec-tive early interventions for preventing future adverse events.
To explore the immediate situational factors associated with adverse events, we also engaged in an exploratory anal-ysis at the individual dispatch event level. Results suggest that features of a particular dispatch may be highly predic-tive of whether or not a dispatch will result in an adverse outcome relative to officer-specific features. Future work will be focused on addressing how to utilize these features more effectively.

At a higher level, our goal is to take this system, devel-oped for CMPD, and extend it to other departments across the US. We already have commitments from Los Angeles Sherriff X  X  Department and Knoxville Police Department to work with us to extend this system. Several other depart-ments across the US are also in discussions with us. We have made our system open source for departments to build upon if they so choose 5 . A tool built across departments is espe-cially important for small departments, which are unlikely to have enough adverse events to build reliable models. We are also implementing the system on CMPD It systems and monitoring the model X  X  performance one year in the future, from July 1, 2015, which is the last day of data we received, to June 30, 2016.

Finally, we are discussing an intervention pilot in partner-ship with CMPD. Predicting which officers will have adverse events will only be impactful if it is possible to design inter-ventions to prevent those events. Similarly, we realize that while intervention may reduce adverse events between the ht t ps://github.com/dssg/police-eis police and the public, such interventions are only a part of a larger approach to dealing with the complex web of cogni-tive, interactional, social, and institutional factors affecting the relationship between the police and the public. We are hopeful that work at the intersection of data science, so-cial science and the practice of policing can someday help to advance the work being done in these contexts as well. We thank the Eric &amp; Wendy Schmidt Data Science for Social Good Fellowship for generously supporting this work. We also thank the leadership and officers of the Charlotte-Mecklenburg Police Department for sharing data, expertise, and feedback for this project as well as the White House Office of Science and Technology Policy for their help and support.
 [1] Who is Guarding the Guardians? United States [2] Personnel Early Warning System . Commission on [3] Principles for Promoting Police Integrity . United [4] Timeline: Recent us police shootings of black [5] Topic: Police brutality, misconduct and shootings. [6] R. Arthur. How to predict bad cops in chicago. [7] R. Caruana, Y. Lou, J. Gehrke, P. Koch, M. Sturm, [8] C. Chapman. Use of force in minority communities is [9] R. C. Davis, N. J. Henderson, J. Mandelstram, C. W. [10] M. Fernandez. Texas officer was under stress when he [11] H. Goldstein. Policing a Free Society . Ballinger Pub. [12] R. J. Hyndman and G. Athanasopoulos. Forecasting: [13] N. Jones.  X  X he regular routine X : Proactive policing and [14] J. Manis, C. A. Archbold, and K. D. Hassell. [15] J. A. Shjarback. Emerging early intervention systems: [16] A. Shultz. Early warning systems: What X  X  new? [17] J. J. Sobol, Y. Wu, and I. Y. Sun. Neighborhood [18] W. Terrill and M. D. Reisig. Neighborhood context [19] S. Walker. The new paradigm of police accountability: [20] S. Walker, G. P. Alpert, and D. J. Kenney. Early [21] M. D. White. Identifying situational predictors of [22] M. D. White and R. J. Kane. Pathways to [23] R. E. Worden, M. Kim, C. J. Harris, M. A. Pratte,
