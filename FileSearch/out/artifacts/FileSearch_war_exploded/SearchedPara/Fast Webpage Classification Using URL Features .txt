 We demonstrate the usefulness of the uniform resource locator (URL) alone in performing web page classification. This approach is faster than typical web page classification, as the pages do not have to be fetched and analyzed. Our approach segments the URL into meaningful chunks and adds component, sequential and orthographic features to model salient patterns. The resulting features are used in supervised maximum entropy modeling. We analyze our approach's effectiveness on two standardized domains. Our results show that in certain scenarios, URL-based methods approach the performance of current state-of-the-art full-text and link-based methods. Categories and Subject Descriptors : H.3.1 [ Information Storage and Retrieval ]: Content Analysis and Indexing  X  Linguistic Processing General Terms : Algorithms, Experimentation. Keywords : Uniform resource locator, webpage classification. Current webpage classification techniques use a variety of information to classify a target page: the text of the page itself, its hyperlink structure, the link structure and anchor text from pages pointing to the target page and its uniform resource locator (URL). Of this information, a web page's URL is the least expensive to obtain and one of the more informative sources with respect to classification. As the URL is short, ubiquitous (all web pages, whether or not they are accessible or even exist, have URLs) and is largely content-bearing, it seems logical to expend more effort in making full use of this resource. We approach this problem by considering a classifier that is restricted to using the URL as the sole source of input. Such a classifier is of interest as it is magnitudes faster than traditional approaches as it does not require fetching pages or parsing the text. Our implementation uses a two-step approach, in which a URL is first segmented into meaningful tokens, which are then analyzed as features for classification. We use a recursive, entropy reduction based technique to derive tokens from the URL for the first step. We focus here on the second step: deriving useful features for suitable for classification. A more complete report of these experiments and others are discussed in [2]. These features model sequential dependencies between tokens, their orthographic patterns, length, and originating URI component. A key result is that the combination of quality URL segmentation and feature extraction results in a significant improvement in classification accuracy over baseline approaches. In link recommendation , the goal is to build a classifier to recommend useful links given a current webpage in a browser. In [5][5], such a dataset was created from 176 users that examined five news web pages. We follow their published experimental procedure to extend their experiments. Table 2 shows the results of the experiment in which the classifier recommends the best 1, 3, 5, or 10 links on a page with the highest probability of similarity to user clicks on the training pages. The specialized tree learning algorithm (row TL-URL) using their URL features performs best at recommending the single most probable link, but is outperformed on the top 3, 5 and 10 metrics. Better classification is achieved by better URL feature extraction, and outweighs the gains made by using a specialized learner. This is exemplified in rows 2 and 3, where the same learner is used (Support Vector Machines (SVM), with a linear kernel) but using different features. Table 2: Number of correct recommendations (2 classes, 182K Learner Configuration Top 1 Top 3 Top 5 Top 10 TL-URL (from [5]) 385 979 1388 2149 SVM-URL (from [5]) 308 839 1268 1953 SVM (our features) 363 996 1456 2412 ME (our features) 365 1100 1682 2775 For multi-class classification , we employ the standardized subset of the WebKB corpus (ILP 98 [6]), in which each page is also associated with its anchor text. The task is identical to earlier published experiments: pages are classified as student , faculty , course and project pages, and leave-one-university-out cross-validation is done. Previous work using the full text have employed SVMs [7], maximum entropy [4], and inductive logic programming [6]. Our results are shown alongside past results. Performance is measured both by instance accuracy and macro F 1 , as both metrics are used previously. Our new URL features perform very well, boosting performance over URL-only previous work by over 30% in the best case, resulting in 76% accuracy. This is impressive as our URL-only method achieve about 95% of the performance of full text methods. Also, our URL features can supplement full text methods, as a small performance gain is observed when the two methods are combined. Note that our experiment show a best performance of ~78% accuracy using full text in contrast with [4] which showed 92% accuracy. The difference may be due to our use of leave-one-university-out cross validation, which we feel is more fair. 
