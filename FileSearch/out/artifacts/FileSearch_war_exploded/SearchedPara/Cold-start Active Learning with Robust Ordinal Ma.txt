 Neil Houlsby 1 NMTH 2@ CAM . AC . UK Jos  X  e Miguel Hern  X  andez-Lobato 1 JMH 233@ CAM . AC . Zoubin Ghahramani ZOUBIN @ ENG . CAM . AC . UK Collaborative filtering (CF) based recommender systems exploit shared regularities in people X  X  behavior to learn about entities such as users and items. The patterns learned can then be used to make predictions and decisions such as recommending new items to a user. However, CF meth-ods can perform poorly when new users or items are in-troduced and the amount of data available for such entities is minimal. This scenario is referred to as the cold-start problem (Maltz &amp; Ehrlich, 1995; Schein et al., 2002). One solution to the cold-start problem is to use features (e.g. de-mographic information) to improve predictive performance (Claypool et al., 1999; Park et al., 2006; Ahn, 2008; Park &amp; Chu, 2009). However, such features may not be avail-able, e.g. for privacy reasons. A complementary strategy is then to collect additional ratings so that the system learns as much as possible about the new entities from a minimal number of user interactions. This is an instance of active learning (Settles, 2010).
 We address the cold-start problem with a Bayesian ap-proach to active learning. Bayesian methods are becom-ing increasingly popular for CF for several reasons: i) they exhibit strong predictive performance, ii) they can deal for-mally with missing data and iii) they provide uncertainty estimates for predictions and parameter values (Salakhut-dinov &amp; Mnih, 2008; Stern et al., 2009; Paquet et al., 2012; Marlin &amp; Zemel, 2009). This last property is particularly important for the success of active learning. Obtaining cor-rect estimates of uncertainty in both the model parameters and the noise levels is essential for identifying the most informative data to collect. This is especially relevant in cold-start learning as parameters relating to the new en-tity are highly uncertain. To achieve good models of rat-ing uncertainty we propose a new probabilistic model for rating data. This model allows us to encode uncertainty both through a posterior distribution over the parameters and a likelihood function with different noise levels across users and items (heteroskedasticity). We demonstrate su-perior performance of this model on several rating datasets relative to current state-of-the-art alternatives. A drawback of Bayesian approaches to active learning is that they can be computationally expensive. They often require computing the expected change in posterior param-eter uncertainty for every candidate data instance yet to be collected. Most approaches speed up the process either by approximating the required posterior entropies directly (MacKay, 1992; Lewi et al., 2007) or by using heuristics such as selecting the data for which the current predic-tions are the most uncertain (maximum entropy sampling) (Shewry &amp; Wynn, 1987). As an alternative, we extend a new active learning framework (Bayesian Active Learn-ing by Disagreement or BALD) to the cold-start CF sce-nario (Houlsby et al., 2012). With this framework we can compute the expected change in posterior uncertainty ac-curately and we only need to re-compute the posterior after collecting new ratings.
 In cold start learning it is critical to gain maximal infor-mation from the very first sample so as not to deter a new user with multiple requests for information. We find that, after collecting a single rating with BALD, random sam-pling and maximum entropy sampling require 60% and 85% more data, respectively, to achieve the same predictive performance. An increase from one to two initial rating re-quests may be critical to whether a user stays with the sys-tem. In summary, we propose a complete Bayesian frame-work to address the cold-start problem in recommender systems. This includes a new heteroskedastic model for or-dinal matrix factorization that accurately estimates uncer-tainty and the intrinsic noisiness of the data, and a compu-tationally efficient algorithm for Bayesian active learning with this model. We are given a dataset D = { r i,j : 1  X  i  X  n, 1  X  j  X  d,r i,j  X  { 1 ,...L } , ( i,j )  X  O} of discrete ratings by n users on d items, where the possible rating values are ordi-nal, 1 &lt; ... &lt; L , for example, 1 to L  X  X tars X  assigned to a product. O denotes the set of pairs of users and items for which a rating is available (observed). We assume that the dataset D is a sample from a full n  X  d rating matrix R , where the entry r i,j in the i -th row and j -th column of R contains the i -th user X  X  rating for the j -th item. In practice, D contains only a small fraction of the entries in R . We propose a new probabilistic model for R that allows the noise levels to vary across rows and columns of R , pro-viding robustness. This is particularly important for active learning, where collecting data from users or items that are too noisy is wasteful. To capture the discrete nature and natural ordering of rating data, our model takes an ordi-nal regression approach (Chu &amp; Ghahramani, 2005; Stern et al., 2009). This is an advantage over the more common Gaussian likelihood that inappropriately assumes continu-ous entries in R . To obtain better predictions, we learn different threshold parameters in the ordinal likelihood for each column (item) of R . The model also has a low rank matrix factorization with a hierarchical prior on the latent factors. The hierarchical prior allows us to avoid specifying hyper-parameter values and increases robustness to overfit-ting. The graphical model for this new probabilistic method is shown in Figure 1. 2.1. Model Description We now describe our probabilistic model, additional details are in the supplementary material. We model the gener-ation of R as a function of two low rank latent matrices U  X  R n  X  h and V  X  R d  X  h , where h min ( n,d ) . r i,j is determined by i) the scalar u T i v j , where u i is the vec-tor in the i -th row of U and v j is the j -th row of V , and ii) a partition of the real line into L  X  1 contiguous inter-vals with thresholds, or boundaries, b j, 0 &lt; ... &lt; b b j, 0 =  X  X  X  and b j,L =  X  . The value of r i,j is a function of the interval in which u T i v j lies. Note that the interval boundaries are different for each column of R . A simple in practice, due to noise there may be no b j, 0 ,...,b j,L ings in D . Therefore, we add zero-mean Gaussian noise e i,j to u T i v j before generating r i,j and introducing the la-tent variable a i,j = u T i v j + e i,j . The probability of r  X  denotes the step function,  X [ x ] = 1 for x  X  0 and 0 otherwise. Thus, the likelihood (1) takes value that the dependence of (1) on all the entries in b just the neighboring boundaries, allows us to learn the value of b j whilst guaranteeing that b j, 0 &lt; ... &lt; b j,L . We put a hierarchical Gaussian prior on the bound-ary variables b j , p ( b j | b 0 ) = Q L  X  1 k =1 N ( b where b 0 are base interval boundaries, with prior are hyper-parameters.
 We include heteroskedasticity in the additive noise e i,j is, the noise level varies across users and items. To do this we put a a zero-mean Gaussian distribution on e i,j ify the noise level in the i -th row and j -th column of R , respectively. We define c i,j = u T i v j and assume that the conditional distribution of a i,j given c i,j ,  X  row i and  X  user and item specific noise levels we put Inverse Gamma For robustness to fixing hyper-parameter values, we use a hierarchical Gaussian prior for U and V , m
U , m V are mean parameters for the rows of U , V , re-spectively, and are given factorized standard Gaussian pri-ors. v U , v V are variance parameters for the rows of U , V and are given factorized Inverse Gamma priors.
 Finally, let C denote the set of variables c i,j for which r is observed, then p ( C | U , V ) = Q ( i,j )  X  X   X  ( c i,j Similarly we collect the variables a i,j into A , and the boundary variables b j into a d  X  ( L  X  1) ma-trix B . R O denotes the set of entries in R that are observed. The likelihood factorizes as the posterior distribution over all of the variables  X  = { U , V , B , A , C ,  X  row ,  X  col , b 0 , m U , m V , v where p ( R O ) is the normalization constant (conditioning on hyper-parameters has been omitted for clarity). The hyper-parameters values are in the supplementary material. 2.2. Inference As with most non-trivial models, the posterior (2) is in-tractable. Therefore, we approximate this distribution us-ing expectation propagation (EP) (Minka, 2001) and varia-tional Bayes (VB) (Ghahramani &amp; Beal, 2001). We use the following parametric approximation to the exact posterior: The parameters on the right hand side of Equation (3) are learned by running a combination of EP and VB. We choose EP as our main workhorse for inference because it has shown good empirical performance in the related prob-lem of binary classification (ordinal regression with only 2 rating values) (Nickisch &amp; Rasmussen, 2008). However, it is well known that for factors corresponding to the ma-trix factorizations, EP provides poor approximations (Stern et al., 2009), so for these we use VB. Implementational de-tails are in the supplementary material. 2.3. Predictive Distribution Given the approximation to the posterior in (3) we estimate the predictive probability of a new entry r ? i,j in R that is not contained in the observed ratings R O using m v 1)]  X  1 and  X  is the standard Gaussian cdf (details in the supplementary material).
 Intuitively, the above predictive distribution incorporates two sources of uncertainty. The first comes from the un-known values of the variables in  X  . This uncertainty is captured by the width (variance) of the different factors that form Q and it is summarized in  X  ( r ? i,j ) by the vari-heteroskedastic additive noise in a ? i,j . This uncertainty is encoded in  X  ( r ? i,j ) by the variance term v  X  i,j (4) allows us to take into account the uncertainty in model parameters  X  and the intrinsic noisiness of the data when making predictions. Equipped with this model we can take a Bayesian approach to active learning. We first outline our active learning strategy in its general form. In active learning, the system selects which data points it wants to be labelled, rather than passively receiving la-belled data. A central objective of Bayesian active learning is to select points to minimize uncertainty over the param-eters of interest, which we denote by  X  . Uncertainty in a random variable is most naturally captured by the Shan-non entropy of its distribution. Hence, a popular utility function for Bayesian active learning is the reduction in en-tropy of the posterior on  X  resulting from the selected point (MacKay, 1992). However, besides  X  , we may have a set of additional parameters  X  that are of lesser interest. We want to focus on actively learning about  X  and not waste data gaining information about  X  . Most Bayesian active learning algorithms do not make this distinction between parameters of interest and nuisance parameters. We make our interest on  X  explicit by integrating out  X  from the posterior distribution. The utility (information gain about  X  ) of collecting an additional rating r ? i,j from R is then where H[  X  ] denotes the entropy of a distribution. The ex-pectation with respect to p ( r ? i,j | R O ) is taken because r is unknown prior to requesting the rating. A Bayesian ap-proach to active learning selects the (user, item) pair ( i,j ) that maximizes (5). However, this can be computationally prohibitive since one must calculate the new parameter pos-terior p (  X  ,  X  | r ? i,j , R ) for every possible entry under con-sideration and each possible value of that entry. Existing methods avoid this problem by using simple models whose approximate posterior can be updated quickly, e.g. aspect and flexible mixture models (Jin &amp; Si, 2004; Harpale &amp; Yang, 2008). However, our model is more complex and running the EP-VB routine to update the posterior approx-imation Q is relatively expensive.
 To avoid having to simplify or approximate our model, we describe a more efficient approach to evaluating the util-ity function in (5). The previous objective can be recog-nized as the mutual information between  X  and r ? i,j given R
O , that is, I[  X  ,r ? the symmetry properties of the mutual information between two random variables to re-arrange (5) into The rearrangement is highly advantageous because we no longer have to compute p (  X  ,  X  | r ? i,j , R O ) multiple times (for every possible r ? i,j ), we only require the current poste-rior p (  X  ,  X  | R O ) . Therefore we only need to update the posterior once per sample after collecting the rating, as in online passive learning. Direct exploitation of this re-arrangement is uncommon in the Bayesian active learning literature. Previously, it has been used for preference elici-tation and is called Bayesian Active Learning by Disagree-ment (BALD) (Houlsby et al., 2012).
 BALD provides intuition about the most informative en-tries in R . The first term in (6) seeks entries for which the predictive distribution has highest entropy, that is, the entries we are most uncertain about. This is maximum entropy sampling (MES) (Shewry &amp; Wynn, 1987). How-ever, the second term penalizes entries with high intrinsic noise. That is, if we know  X  exactly, and the conditional predictive distribution for r ? i,j still has high entropy, then r i,j is not informative about  X  . For example, this second term will penalize selecting matrix entries corresponding to users who provide noisy, unreliable ratings. The formu-lation in (6) is particularly convenient as it allows the in-formation gain to be computed accurately whilst requiring only a single update to the posterior per active sample, as in MES.
 Equation (6) indicates that for effective Bayesian active learning we must capture both the uncertainty in the model parameters (to compute the first term), and the implicit noisiness in the data (to compute the second term). 3.1. Active Learning for the Cold-start Problem Let i be the index of a new user. We want to make good pre-dictions for this user using minimal interactions. For this, we must gain maximal information about the user X  X  latent vector u i . In this active learning scenario u i forms the pa-rameters of interest  X  and all the other model parameters  X  \{ u i } are collected into the set of nuisance parameters  X  . The BALD objective (6) involves the computation of two terms: the first one can be approximated easily by the entropy of the approximate predictive distribution (4). The second term requires the computation of where p ( r ? i,j | u i ) =  X (  X  ( r ? i,j ))  X   X (  X  ( r P u i = ( u i, 1 ,...,u i,h ) . Equation (7) includes an intractable h -dimensional Gaussian integral over u i . We approximate this integral by Monte Carlo sampling. In particular, we compute the expectation of p ( r ? i,j | u i ) using a random sam-ple from Q ( u i ) . Experimentally, this estimate converged quickly; fewer than 100 samples were required for accu-rate computation of (6). When computational time is crit-ical we use the unscented approximation which uses only 2 h +1 samples placed at fixed locations (Julier &amp; Uhlmann, 1997). This method is fast, but can generate biased esti-mates. Empirically, we found that the unscented approx-imation is sufficiently accurate to identify the most infor-mative item in most cases, see Section 5.
 We use the same method to learn about new items. In this case we draw samples from Q ( v j ) for a new item with in-dex j , where v j is the item X  X  latent vector.
 Bayesian ordinal matrix factorization is addressed in Pa-quet et al. (2012), but their model does not include het-eroskedasticity nor does it learn the boundary variables B . Both components yield substantial improvements to pre-dictive performance (see Section 5). Paquet X  X  method uses Gibbs sampling for inference, whereas our EP-VB method produces accurate and compact approximations that can be easily stored and manipulated. Heteroskedasticity has been included in a MF model with a Gaussian likelihood (Laksh-minarayanan et al., 2011). However, our experiments con-firm that the Gaussian likelihood yields poor predictions on rating data. Another alternative for discrete ratings has been proposed by Marlin &amp; Zemel (2009). This work as-sumes that each row in the rating matrix R is sampled i.i.d. from a Bayesian Mixture of Multinomials (BMM) model. This model is not as expressive or accurate as MF models. Other probabilistic approaches have been proposed for cold-start active learning (Boutilier et al., 2002; Jin &amp; Si, 2004; Harpale &amp; Yang, 2008). These methods either max-imize the expected value of information or compute poste-rior entropies directly, that is, they use the more expensive utility function in (5). To reduce computational cost they approximate (5) or perform approximate updates with sim-ple models where updates are fast, such as multiple-cause vector quantizations (Ross &amp; Zemel, 2002), naive Bayes (Boutilier et al., 2002), the aspect model (Hofmann, 2003) and flexible mixture models (Si &amp; Jin, 2003). We perform exact computations of the utility function by using the rear-rangement in (6). Furthermore, we only need to update our posterior distribution only after collecting the new data and not for each possible data entry that can be collected. Alter-native active selection criterion are investigated in MF with a Gaussian likelihood (Sutherland et al., 2013), but learn-ing specific parameters of interest is not addressed. Model-free strategies have been proposed for active data collection (Rashid et al., 2002; 2008), where empirical statistics of the data such as item popularity or rating entropy are used to select items. These heuristics are computationally cheap, but perform poorly relative to our model-based approach. Outside of collaborative filtering, methods for Bayesian ac-tive learning based on posterior entropy have been widely studied (Lindley, 1956; MacKay, 1992; Settles, 2010). However, the entropy computation is often intractable or expensive and so requires approximations. Recently the BALD formulation presented in Section 3 has been used for preference learning (Houlsby et al., 2012). However, this work makes no distinction between parameters of pri-mary interest and nuisance parameters, that is, they have  X  =  X  . This distinction is particularly important in the cold-start setting. For example, when a new user arrives, we would like to learn quickly about their corresponding latent vector but we already have ample information about the items in the system and so do not want to waste actively selected data learning about these items further.
 Like BALD, methods such as maximum entropy sampling or margin sampling (Campbell et al., 2000) are cheaper to compute than Equation (5). However, unlike BALD, these methods fail to discriminate between predictive uncertainty and inherent noise in the data. We evaluate our new model and active learning strategy on a diverse collection of rating datasets: i) MovieLens100K and MovieLens1M : two collections of ratings of movies; ii) MovieTweets : movie ratings obtained from Twitter; iii) Webscope : ratings of songs; iv) Jester : ratings of jokes; v) Book : ratings of books; vi) Dating : ratings from an on-line dating website and vii) IPIP : ordinal responses to a psychometrics questionnaire. All the matrix entries in IPIP are observed, the other datasets have many missing entries. Descriptions, links to the data, and our pre-processing steps are in the supplementary material. We first evaluate the pre-dictive accuracy of our model against a number of state-of-the-art alternatives. We then investigate the performance of our method for cold-start active learning. 5.1. Comparison to Other Models for Rating Data We compare our model for heteroskedastic ordinal matrix factorization (HOMF) against the following methods: i) the homoskedastic model with an ordinal likelihood in Paquet et al. (2012) (Paquet); ii) a method for robust Bayesian ma-trix factorization (RBMF) based on a Gaussian likelihood which includes heteroskedastic noise (Lakshminarayanan et al., 2011); iii) the Bayesian mixture of multinomials model (BMM) (Marlin &amp; Zemel, 2009); and iv) a ma-trix factorization model like RBMF but with homoskedas-tic noise (BMF). We directly evaluate the improvements in predictive performance produced in HOMF from both con-sidering heteroskedasticity and learning the boundary vari-ables B . For these evaluations we first compare to OMF, a homoskedastic version of HOMF, where the variance pa-rameters  X  row i are all constrained to be equal to each other (similarly for the  X  col j ). Secondly, HOMF-NoB uses fixed boundary parameters b j rather than learning them for each item. Finally, OMF-NoB is a homoskedastic version of HOMF that does not learn B . For all models we fix the latent dimension to h = 10 .
 We split the available ratings for each dataset randomly into a training and a test set with 80% and 20% of the ratings respectively. Each method was adjusted using the entries in the training set and then evaluated using predic-tive log-likelihood on the corresponding test set. The entire procedure, including dataset partitioning, was repeated 20 times.
 Table 1 contains the test log-likelihoods and Figure 2 sum-marizes the performance of each algorithm. The proposed model, HOMF, outperforms all the other methods in all datasets. Significance is assessed with a paired t -test. The likelihood function for ordinal data is more appropriate for ratings than the Gaussian likelihood; HOMF and Pa-quet outperform RBMF and BMF. Furthermore, predictive performance is improved by modeling heteroskedasticity across rows and across columns since HOMF outperforms OMF and Paquet, and RBMF outperforms BMF. Learning the biases also results in substantial improvements to the performance of our model. Finally, the matrix factorization models (HOMF, Paquet, RBMF and BMF) usually outper-form the mixture model BMM. 5.2. Cold-start Active Learning We selected 2000 users and 1000 items (up to the maxi-mum available) with the most ratings from each dataset. This provided the active sampling strategies with the largest possible pool of data to select from. We partitioned the data randomly into three sets: training, test and pool. For this, we sampled 75% of the users and added all of their rat-ings to the training set. These represented the ratings for the users that were already in the system . Each of the re-maining 25% test users were initialized with a single item, adding that rating to the training set. For each test user we sampled three ratings and added these to the test set. The remaining ratings were added to the pool set. Figure 4 illus-trates this set-up. We also simulated new items arriving to the system. In this case the setup was identical except that the roles of the users and items were interchanged. We de-note the new-users and new-items experiments by append-ing -U and -I to the dataset names respectively.
 HOMF was adjusted using the available ratings in the train-ing set. Then, during each iteration of active learning, a single rating was selected from the pool set for each test user using active learning. The selected ratings were then added to the training set and HOMF was incrementally re-adjusted using the new training set. We evaluated the sec-ond term in (6) using Monte Carlo sampling from Q with 100 samples. As alternatives to BALD we considered ran-dom sampling ( Rand ), maximum entropy sampling ( En-tropy ) and a model-free version of Entropy that selects the item whose empirical distribution of ratings in the train-ing data has the greatest entropy ( Emp-Ent ). After each active sample was selected, we computed the predictive log-likelihood on the test set. The entire procedure was repeated 25 times.
 Active Learning Strategies Figure 3 shows the learning curves with each strategy for each new-user experiment. The curves for the new-item experiments are in the sup-plementary material. Table 2, left hand columns, sum-marizes the results with the test log-likelihood after draw-ing 10 samples from the pool for each test user or item. With HOMF, BALD yields the best (or joint best) predic-tions in all but one cases. Both the model based and em-pirical entropy sampling algorithms often perform poorly because they ignore the inherent noisiness of the users or items. Note that in most datasets, there are only a few rat-ings available for most users. This means that BALD is restricted to sampling from a limited pool set. In particu-lar, Book, MovieTweets and Webscope are the most sparse, with only 2, 3 and 5% of ratings available, respectively. Unsurprisingly, BALD exhibits smaller performance gains on these datasets. In practice, in these domains most users would be able to provide ratings for a larger number of items; they may watch a new movie, listen to a song, read a book, etc. Consequently, in practice we would expect to see larger performance gains as in the denser datasets, IPIP and Jester. This assumption may not always hold, for example, in dating recommendation a user may not follow any recommendation and provide a rating. In this case, the probability of receiving a rating from the user should be accounted for.
 In cold start learning, it is crucial to elicit useful infor-mation from the very first sample. The average number of queries required to achieve the same predictive perfor-mance as from a single active sample chosen by BALD is 1.85 with Ent, 1.83 with Emp, and 1.59 with random sam-pling. This means that on average around 60% more ran-dom samples are required to gain the same performance as the first sample selected by BALD.
 Heteroskedasticity vs. Homoskedasticity We ran each active learning strategy with our homoskedastic model OMF and with the homoskedastic method BMM, see Table 2. With these homoskedastic models active learning sig-nificantly outperforms random sampling on fewer datasets than with HOMF. This demonstrates that accurate esti-mates of the intrinsic noisiness of the data are required to unlock the full potential of Bayesian active learning. Fig-ure 5 presents example learning curves on MovieTweets-I, where the difference in relative performance of BALD versus Rand when using HOMF and OMF is large. One can see that BALD provides much faster learning than the other strategies with HOMF, but all strategies are indis-tinguishable with OMF. This indicates that some users in this dataset provide highly noisy and unpredictable ratings. HOMF is able to model this and elicit ratings only from the useful, low noise users.
 We also evaluated each model in terms of RMSE, see Ta-ble 2 in the supplementary material. In this case, the best model is OMF, very closely followed by HOMF. Note that the ranking of these two methods was the opposite in Table 1. The reason for this is that RMSE focuses only on the predictive mean and ignores the predictive variance. Modeling heteroskedasticity largely affects the predictive variance, but barely changes the predictive mean. There-fore, OMF and HOMF are expected to perform similarly under the RMSE metric. Nevertheless, in cold-start active learning HOMF with BALD performs best overall, see Ta-ble 4 in the supplementary material. This is because, al-though heteroskedasticity does not assist in the final evalu-ation under the RMSE metric, it is still important to enable BALD to find the informative ratings. In online settings, the time available for selecting the most informative matrix entries may be limited. We can re-duce the cost of BALD by making approximations when computing the second term in the utility function in Equa-tion (6), E Q ( u We evaluate the accuracy of three approximations: Monte Carlo (MC) sampling, the unscented approximation, and evaluating the integral with a delta function located at the mode of Q . We are interested in finding the most informa-tive item, so we evaluate the estimation error using fraction information loss, measured as where I ( j ) is given by (6) evaluated on item j using the approximation and  X  I ( j ) is a gold standard obtained using MC with a separate set of 1000 samples. The results are averaged over all test users. The loss across all datasets (  X  1 s.d.) from MC with 100 samples, the unscented ap-proximation and the posterior mode approximation were 0 . 017  X  0 . 007 , 0 . 035  X  0 . 031 and 0 . 136  X  0 . 073 , respec-tively. Figure 6 depicts the loss as a function of the num-ber of evaluations of H[ p ( r ? i,j | u i )] on Movielens100k and Webscope. Results on the other datasets are similar and are in the supplementary material. With MC the integral converges rapidly, the loss falls below 5% with fewer than 50 samples on all datasets. The unscented approximation requires only 2 h + 1 evaluations, and in most cases yields a better estimate than MC with this number of samples. In practice, we found no statistical difference in predictive performance when running the experiments using the un-scented approximation or MC with 100 samples. We there-fore recommend the unscented approximation as an effi-cient solution for systems with computational constraints. We have proposed new a framework for cold-start learning based on a Bayesian active learning strategy that learns as much as possible about new entities (users or items) from minimal user interactions. To achieve strong performance we have proposed a matrix factorization model that takes into account the ordinal nature of rating data and incorpo-rates different levels of noise across the rows and columns of a rating matrix. This model uses hierarchical priors to provide additional robustness to fixing hyper-parameter values. With this model we perform efficient Bayesian ac-tive learning by extending a new framework for computing information gain (BALD) to collaborative filtering, where we only want to learn optimally about user (or item) spe-cific model parameters. This approach removes the require-ment to re-compute the parameter posterior many times per active sample, and hence permits us to use our relatively complex matrix factorization model. Our model generates state-of-the-art predictions on rating data, and when com-bined with BALD yields strong performance in cold-start active learning from the very first sample.
 This work addresses learning about a new entity as quickly as possible. An important extension for real-world systems is to trade-off exploration and exploitation, balancing infor-mation gain with recommending a user their most favored items. Possible extensions to this setting include incorpo-rating active search (Garnett et al., 2011) or strategies from Bandit Theory into our framework.
 NMTH and JMH are grateful for support from the Google European Doctoral Fellowship scheme and Infosys Labs, Infosys Limited, respectively.

