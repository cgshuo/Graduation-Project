 Exploratory searches are where a user has insu cient knowl-edge to define exact search criteria or does not otherwise know what they are looking for. Reinforcement learning techniques have demonstrated great potential for support-ing exploratory search in information retrieval systems as they allow the system to trade-o  X  exploration (presenting the user with alternatives topics) and exploitation (moving toward more specific topics). Users of such systems, how-ever, often feel that the system is not responsive to user needs. This problem is not an inherent feature of such sys-tems, but is caused by the exploration rate parameter being inappropriately tuned for a given system, dataset or user.
We present a user study to analyze how di  X  erent explo-ration rates a  X  ect search performance, user satisfaction, and the number of documents selected. We show that the trade-o  X  between exploration and exploitation can be modelled as a direct relationship between the exploration rate pa-rameter from the reinforcement learning algorithm and the number of relevant documents returned to the user over the course of a search session. We define the optimal explo-ration/exploitation trade-o  X  as where this relationship is maximised and show this point to be broadly concordant with user satisfaction and performance.
 H.4 [ Information Systems Applications ]: Miscellaneous
Exploratory search is defined as a class of search activities performed to learn or discover new information [10]. Unlike lookup search, where a discrete set of results achieves a well-defined objective, exploratory search can involve unfamiliar subject areas and uncertainty regarding search goals. For these reasons exploratory search is considered to be chal-lenging for the user and needs additional support from in-formation retrieval (IR) systems. Reinforcement learning (RL) techniques have demonstrated great potential for sup-porting exploratory search in IR systems [3, 8, 12]. RL allows the system to trade o  X  between exploitation and ex-ploration, allowing the system to gradually build the user model without getting stuck in a local search space [3, 6]. Parameterizing exploratory systems, however, is not triv-ial. Experimental results from IR systems employing RL techniques demonstrate that users often do not feel that the system is responsive to their information needs [3]. We do not believe this problem is an inherent property of RL-based systems, but is caused by inappropriately tuned exploration rate. In this sense, if the exploration rate is too low, the user may get stuck in a narrow information space. On the other hand, if it is set too high, the user will be presented with too many documents from topics perceived as irrelevant. Our hypothesis is that the trade-o  X  between exploration and ex-ploitation can be modelled as a direct relationship between exploration rate and the number of documents that are per-ceived by the user as interesting or relevant. Furthermore, we aim to show that this relationship can be maximised and at this point an optimal trade-o  X  between exploration and exploitation will be made.

In order to test this hypothesis, we first built an exploratory search system for scientific literature using LinRel [1]  X  an RL algorithm that has been used in a number of IR systems [3]. Using simulation, we identify a range of system param-eterizations that would expose the user to di  X  erent numbers of documents resulting from increasing the exploration rate. The level of exploration ranges from 0, where the user is only presented with documents related to their query, to a high level of exploration, where approximately half of the documents would allow the user to steer the search in a di  X  erent direction. We then conduct a user study to eval-uate the di  X  erent exploration rates and investigate how to infer the optimal exploration rate with a multiple regres-sion model. Furthermore, with qualitative analysis of user interviews and performance data, we confirm that the ex-ploration rate selected by this approach indeed provides the optimal balance between exploration and exploitation. Our investigation provides insights into designing and parameter-izing exploratory search systems with appropriate balance between exploration and exploitation.
The interface of the system is presented in Figure 1. After typing in the search query, the user is presented with 20 doc-uments where seven documents are visible without scrolling. We display more documents than in traditional IR systems because in exploratory tasks users examine more results [10]. The initial set of documents is ranked based on the Okapi BM25 algorithm [9]. Next, to see more documents the user can indicate which document interests them by clicking on the circle next to it and thus providing relevance score of 1 to that document. After clicking the  X  X ext X  button in the top right corner of the page, a new set of documents is displayed based on the feedback provided by the user so far. The user can provide feedback to as many or as few documents as she wishes. Documents that do not receive an explicit relevance feedback are assumed to receive relevance score of 0. The current version of the system is based on around 1 million documents obtained from the ArXiv repository.

In order to help the user explore the document space, we use LinRel [1]. Suppose we have a matrix D , where each row d is a tf-idf (term frequency-inverse document frequency) feature vector representation of documents presented so far. Let r =( r 1 ,r 2 ...r t ) &gt; be the column vector of relevance scores received from the user up to time t .Weestimate the expected relevance r i of a document d i as E [ r i ]= d where the vector w is estimated from user feedback. LinRel estimates  X  w by solving r = D  X  w and estimates relevance score for each d i as  X  r i = d i  X   X  w
In order to deal with the exploration-exploitation trade-o  X  , we present documents not with the highest score  X  r with the largest upper confidence bound for the relevance score. Thus, if i is an upper bound on standard devia-tion of relevance estimate  X  r i , the upper confidence bound of document d i is calculated as r i + i , where &gt; 0is a constant used to adjust the confidence level of the up-per confidence bound. In each iteration, LinRel calculates s = d i  X  ( D &gt;  X  D + I ) 1 D &gt; , where is the regularization parameter which is set to 1 if each of the feature vectors sums up to 1 (following [1]) and the documents that max-imize s i  X  r + 2 k s i k are selected for presentation. The first term s i  X  r e  X  ectively ranks all the documents based on their similarity to the documents the user has selected so far and thus it narrows the area of the search space (exploitation). The second term 2 k s i k ensures that the user is presented with a more diverse set of results. The exploration rate is controlled by the parameter. The higher the value of , the more diverse, or exploratory, the results are.
To find suitable values of to test in our user study, we built a simulator to understand how a  X  ects how many doc-uments are shown to the user as a result of the exploration term. To simulate searching for a particular target docu-ment, we must specify a search query that would ordinarily be provided by the user and a procedure to identify which documents will be given positive feedback.

To generate search queries, we used topic modelling on the 78,131 computer science articles from ArXiv assuming 200 clusters and manually curated the 124 unambiguous clus-ters with an appropriate label. In order to obtain the topic models, we used MAchine Learning for LanguagE Toolkit (MALLET) [7]. The search query for a given document is the label for the closest cluster.

Given a target document and its initial search query, the simulator proceeds by greedily selecting which documents to give positive feedback to in order to minimise the average euclidean distance between the results in the next iteration and the target. The simulation is performed for = 0.0 and Figure 1: Screen shot of the interface. Search query is displayed on the top. Interesting documents can be selected by clicking the icon next the document and the user can proceed to the next iteration by clicking the next button. then with di  X  erent values of . For each value of we iden-tify which of the 20 documents in the second iteration are present because of using the exploration term. The simula-tor was run for 200 randomly selected target documents. We identified the exploration rates 0.0, 0.2, 0.5, 1.0 and 2.0 as these resulted in a median number of exploratory documents of 0, 1, 3, 5 and 9, respectively.
The goals of the user study were to investigate how di  X  er-ent exploration rates a  X  ect 1. the number of documents se-lected, 2. subjective perception, and 3. overall performance. We recruited ten researchers: 5 finishing MSc students and 5 PhD students. Prior to the study we provided them with a background questionnaire to assess their experience with literature search and knowledge of the search topics. All par-ticipants reported experience in scientific literature search. As users engaged in exploratory search tasks aim to acquire new knowledge [11], we specifically selected participants not overly familiar with the search topics.
An expert researcher from the machine learning domain selected five topics that have su cient data in the ArXiv dataset: image processing, clustering, classification, natu-ral language processing, and neural networks. The machine learning domain was chosen because it was easier to find both domain experts for creating tasks and assessing perfor-mance, and a homogeneous group of participants who had taken at least an introductory machine learning course.We used a within-subject design where every participant per-formed all five search tasks and every task had a di  X  erent exploration rate. To avoid order e  X  ects, the sequence of per-forming tasks and assigned exploration rates were counter-balanced using a Latin Square design. We described the tasks using a template that places participants in a scien-tific essay writing scenario, suitable for exploratory search tasks [11]. To preserve consistency among the tasks, all task descriptions followed the same template. to write an essay about the topic X. We provide you with asearchengine. Followyournaturalliteraturesearch process and search for articles that help you to learn about this topic. You have fifteen minutes maximum and prepare an abstract of your essay at the end. X  In order to ensure that all the studies were initiated from the same starting point, we provided the initial search query. The first query was always the phrase X  X achine learning X  X ol-lowed by the the topic of search task  X  for example X  X achine learning clustering X .
All the studies were conducted in a controlled laboratory room, with a desktop computer with a 27-inch display. We allocated fifteen minutes per task and automatically termi-nated the search session at the end of this period. Prior to the study we informed the participants about the maximum duration allowed per task, introduced the search system and gave them one training task. We showed the participants how to select relevant articles and proceed to the next iter-ation. We explained that by providing feedback they allow the system to learn about their interests and retrieve more suitable results in subsequent iterations. The participants were not aware of the di  X  erent exploration rates per task. Participants were allowed to take notes using their comfort-able technique  X  using a word processing application or pen and paper. At the end of every task, we provided a web form to write the abstract of their essay as a list of 5-10 bullet points.

We logged details of all the displayed and selected doc-uments. A domain expert performed a blind review of the abstracts and rated them from 0 to 5 (0 = failure and 5 = excellent). In order to assess user satisfaction, after every task we conducted a semi-structured interview. During the interview we asked their opinion on the results and to rate how satisfied they were with the findings. Each study lasted approximately 1.5 hours. We compensated every participant with a movie ticket.
Each of the ten participants performed the five tasks using five di  X  erent exploration rates, resulting in ten observations per exploration rate. During the analysis we decided to ex-clude two participants from further study. Of the partici-pants that we excluded, one selected no relevant documents and the other selected only a single relevant document per task. Further inspection of their essay abstracts suggested that they did not engage with the tasks and their scores on the abstracts were 0 for two or more tasks according to the external reviewer. We also decided to exclude all observa-tions from the  X  X eural networks X  task because six partici-pants failed to complete the task successfully. We hypothe-sise that these failures were due to neural networks being a more advanced topic and  X  X etworks X  being a generic term, e.g. social networks, communication networks, etc. The re-maining 32 observations were used for further analysis.
The raw experimental data was investigated with box-plots to understand what features should be included in the regression model. It was noted that the total number of selected documents was maximised by the middling ex-ploration rate values tested (boxplots not shown), suggest-ing the necessity of a squared exploration rate term in the Figure 2: E  X  ect plot of exploration rate on the num-ber of relevant documents selected by the user con-trolling for all other covariates. Shaded region indi-cates 95% confidence interval. Circles indicate par-tial residuals. model. Analysis was performed using a generalised linear mixed model (GLMM). We used a mixed model to account for repeated measurements on each study participant, ex-plicitly taking into account intra-subject variation by mod-elling participants as random e  X  ects. In our model, we con-sidered the response variable to be the total number of se-lected documents. As the number of selected documents is count data, it was assumed to be Poisson distributed with a log link function. The fixed e  X  ects are the exploration rate, the exploration rate squared and the search query. Partici-pants were treated as random e  X  ects, allowing the intercepts to vary. The model was fit using the lme4 R package (ver. 1.1-7) [2]. Confidence intervals were calculated using para-metric bootstrapping. P values were calculated by compar-ison with reduced models using parametric bootstrapping from the pbkrtest package (ver. 0.4-2) [4]. The model was fit with maximum likelihood using the Laplace approxima-tion method and validated by inspection of residual plots. Over-dispersion was tested using the goodness of fit proce-dure from the aods3 package (ver. 0.4-1) [5] and we found no evidence of over-dispersion ( 2 =12.455, 25 d.f., p=0.983).
There was a significant e  X  ect on the square of the explo-ration rate (95% CI [-2.260, -0.156], p=0.028). The query did not have a statistically significant e  X  ect on how many articles the participant selected (p=0.501). The variance of the participant random e  X  ect was non-zero (0.114), sug-gesting that inclusion of the random e  X  ect was appropri-ate. Figure 2 shows an e  X  ect plot for exploration rate on the response variable controlling for both query and partici-pant. The number of articles selected as relevant appears to be maximised at an exploration rate of approximately 1.0 (0.97), and corresponds to a 51% increase in the number relevant documents than the baseline exploration rate of 0.0 (95% CI [12%, 91%]). Inspection of partial residuals reveals the presence of several outliers (at exploration rates 0.2 and 1.0) and high variability at exploration rate 2.0. The extent of the influence of these factors is di cult to assess and a larger sample size is required.
We qualitatively analyzed the user interviews to investi-gate whether the user satisfaction with search results was af-fected by di  X  erent exploration rates. Five participants (out of 8) complained that the search results were too narrow and di cult to interpret for the tasks performed with ex-ploration 0:  X  X esults are not quite satisfactory and about very specific definitions. I did not get [any] understanding of what topics are in this area. X  [Participant 3],  X  X  selected a paper on semantics, but it took me completely o  X  the way X  [Participant 8]. None of the participants made any positive comments about tasks with exploration rate 0. There were mixed comments on tasks performed with exploration rate 0 . 2 and 0 . 5. Three participants were satisfied with the search results when exploration rate was set to 0.2, while three gave negative comments:  X  initially did not show any results that I was expecting [Participant 7] X .  X  X t the beginning I had the problem to decide which way I should go. I just selected two di  X  erent topics for the second iteration and then in the second iteration it gives me mostly [results on] that topic [Participant 2] X . We received similar comments for tasks performed with exploration rate 0 . 5. However, most of the participants were satisfied when the exploration rate was set to 1. Five participants provided very positive comments while none gave any negative comments on exploration rate 1 :  X  X ay better than the other tasks. [I] got many di  X  erent results, but all related [Participant 1] X ,  X  X  went over several iterations. Results started getting way better [over itera-tions] and overall I am very satisfied [Participant 5] X . Six participants were unhappy with results for the tasks with exploration rate 2. The main reason was that the results are too diverse and not related to the main topic:  X  [results are] too scattered and many other non-related papers [Partici-pant 5] X . Overall, these interviews suggest that users noticed a di  X  erence between exploration rates and found exploration rate 1 the most appropriate, which is also the exploration rate that results in the highest number of documents selected by the users according to our regression model.

We analyzed the reviewer rating of the abstracts written by the participants to investigate whether the exploration rate has any e  X  ect on their performance. The mean score for  X  exploration rate 0 is 3 (out of 5) and standard deviation ( std.dev )is1 . 3 , exploration rate 0.2 is 2 . 6( std.dev =1 . 4), exploration rate 0.5 is 2 . 38 ( std.dev =1 . 8), exploration 1 is 3 . 2( std.dev =1 . 2), and exploration rate 2 is 3 . 2( std.dev = 1 . 1). These results confirm that user performance improves with a higher exploration rate, including the exploration rate of 1 which we earlier identified as optimal.
In this paper, we describe a method on how to set the exploration rate in an exploratory IR system. First, we ran a set of simulations to identify a possible set of exploration rates to test in a user study. Our multiple regression analy-sis of the user studies data showed that exploration rate of 1, which roughly corresponds to a quarter of the presented documents resulting from exploration, corresponds to the highest number of documents to be perceived as relevant by the user. This finding was further confirmed by the qual-itative analysis by the user perceived satisfaction with the search results and the task performance results.

The results provide an insight into optimizing RL-based exploratory IR systems and have implications for designing or self-adapting exploratory search systems. For example, by tracking documents selected, the system could automati-cally set the appropriate level of exploration rate for a given user. Our study was limited to scientific literature search in the machine learning domain with users at similar expertise level  X  MSc/PhD students. As this is an initial step towards modeling the e  X  ect of exploration rate on exploratory search task performance, we purposely controlled several other fac-tors that could also influence search performance, such as the search domain and expertise levels. Currently, we are designing a study involving researchers at di  X  erent levels of expertise to assess whether users with di  X  erent exper-tise level require di  X  erent exploration rates. Further, we are planning to incorporate more features into our model, such as scroll data or document viewing time. The ultimate goal of our current project is to design an exploratory IR systems that automatically adjust the exploration rate depending on user needs.
