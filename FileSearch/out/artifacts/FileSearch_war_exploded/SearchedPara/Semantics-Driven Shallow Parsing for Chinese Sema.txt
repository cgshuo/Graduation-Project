 In the last few years, there has been an increas-ing interest in Semantic Role Labeling (SRL) on several languages, which consists of recognizing arguments involved by predicates of a given sen-tence and labeling their semantic types. Both full parsing based and shallow parsing based SRL methods have been discussed for English and Chi-nese. In Chinese SRL, shallow parsing based methods that cast SRL as the classification of syntactic chunks into semantic labels has gained promising results. The performance reported in (Sun et al., 2009) outperforms the best published performance of full parsing based SRL systems.
Previously proposed shallow parsing takes into account only syntactic information and basic chunks are usually too small to group words into argument candidates. This causes one main defi-ciency of Chinese SRL. To partially resolve this problem, we propose a new shallow parsing. The new chunk definition takes into account both syn-tactic structure and predicate-argument structures of a given sentence. Because of the semantic in-formation it contains, we call it semantics-driven shallow parsing. The key idea is to make basic chunks as large as possible but not overlap with ar-guments. Additionally, we introduce several new  X  X ath X  features to express more structural infor-mation, which is important for SRL.
 We present encouraging SRL results on Chinese PropBank (CPB) data. With semantics-driven shallow parsing, our SRL system achieves 76.10 F-measure, with gold segmentation and POS tag-ging. The performance further achieves 76.46 with the help of new  X  X ath X  features. These re-sults obtain significant improvements over the best reported SRL performance (74.12) in the literature (Sun et al., 2009). CPB is a project to add predicate-argument rela-tions to the syntactic trees of the Chinese Tree-Bank (CTB). Similar to English PropBank, the ar-guments of a predicate are labeled with a contigu-ous sequence of integers, in the form of A N ( N is a natural number); the adjuncts are annotated as such with the label AM followed by a secondary tag that represents the semantic classification of the adjunct. The assignment of argument labels is illustrated in Figure 1, where the predicate is the verb  X   X   X  /provide X  For example, the noun phrase  X   X   X   X   X  /the insurance company X  is labeled as A0 , meaning that it is the proto-Agent of  X   X   X   X .
Sun et al. (2009) explore the Chinese SRL prob-lem on the basis of shallow syntactic information at the level of phrase chunks. They present a se-mantic chunking method to resolve SRL on basis of shallow parsing. Their method casts SRL as the classification of syntactic chunks with IOB2 representation for semantic roles (i.e. semantic chunks). Two labeling strategies are presented: 1) directly tagging semantic chunks in one-stage, and 2) identifying argument boundaries as a chunking task and labeling their semantic types as a clas-sification task. On the basis of syntactic chunks, they define semantic chunks which do not overlap nor embed using IOB2 representation. Syntactic chunks outside a chunk receive the tag O (Out-side). For syntactic chunks forming a chunk of type A* , the first chunk receives the B-A* tag (Be-gin), and the remaining ones receive the tag I-A* (Inside). Then a SRL system can work directly by using sequence tagging technique. Shallow chunk definition presented in (Chen et al., 2006) is used in their experiments. The definition of syn-tactic and semantic chunks is illustrated Figure 1. For example,  X   X   X   X   X  /the insurance company X , consisting of two nouns, is a noun phrase; in the syntactic chunking stage, its two components  X   X   X   X  and  X   X   X   X  should be labeled as B-NP and I-NP . Because this phrase is the Agent of the pred-icate  X   X   X  /provide X , it takes a semantic chunk label B-A0 . In the semantic chunking stage, this phrase should be labeled as B-A0 .

Their experiments on CPB indicate that accord-ing to current state-of-the-art of Chinese parsing, SRL systems on basis of full parsing do not per-form better than systems based on shallow parsing. They report the best SRL performance with gold segmentation and POS tagging as inputs. This is very different from English SRL. In English SRL, previous work shows that full parsing, both con-stituency parsing and dependency parsing, is nec-essary.

Ding and Chang (2009) discuss semantic chunking methods without any parsing informa-tion. Different from (Sun et al., 2009), their method formulates SRL as the classification of words with semantic chunks. Comparison of ex-perimental results in their work shows that parsing is necessary for Chinese SRL, and the semantic chunking methods on the basis of shallow parsing outperform the ones without any parsing.

Joint learning of syntactic and semantic struc-tures is another hot topic in dependency parsing research. Some models have been well evalu-ated in CoNLL 2008 and 2009 shared tasks (Sur-deanu et al., 2008; Haji  X  c et al., 2009). The CoNLL 2008/2009 shared tasks propose a unified dependency-based formalism to model both syn-tactic dependencies and semantic roles for multi-ple languages. Several joint parsing models are presented in the shared tasks. Our focus is differ-ent from the shared tasks. In this paper, we hope to find better syntactic representation for semantic role labeling. 3.1 Motivation There are two main jobs of semantic chunking: 1) grouping words as argument candidate and 2) clas-sifying semantic types of possible arguments. Pre-viously proposed shallow parsing only considers syntactic information and basic chunks are usu-ally too small to effectively group words. This causes one main deficiency of semantic chunking. E.g. the argument  X   X  X  X   X   X   X  /for the Sanxia Project X  consists of three chunks, each of which only consists of one word. To rightly recognize this A2 , Semantic chunker should rightly predict three chunk labels. Small chunks also make the important  X  X ath X  feature sparse, since there are more chunks between a target chunk and the pred-icate in focus. In this section, we introduce a new chunk definition to improve shallow parsing based SRL, which takes both syntactic and predicate-argument structures into account. The key idea is to make syntactic chunks as large as possible for semantic chunking. The formal definition is as follows. 3.2 Chunk Bracketing Given a sentence s = w 1 , ..., w n , let c [ i : j ] denote a constituent that is made up of words between w i and w j (including w i and w j ); let p v = { c [ i : j ] | c [ i : j ] is an argument of v } denote one predicate-argument structure where v is the predicate in focus. Given a syntactic tree T s = { c [ i : j ] | c [ i : j ] is a constituent of s } , and its all argument structures P s = { p v | v is a verbal predicate in s } , there is one and only one chunk set C = { c [ i : j ] } s.t. 1.  X  c [ i : j ]  X  X  , c [ i : j ]  X  X  s ; 2.  X  c [ i : j ]  X  C ,  X  c [ i v : j v ]  X   X  X  s , j &lt; i 3.  X  c [ i : j ]  X  C , the parent of c [ i : j ] does not 4.  X C 0 satisfies above conditions, C 0  X  X  .
The first condition guarantees that every chunk is a constituent. The second condition means that chunks do not overlap with arguments, and further guarantees that semantic chunking can recover all arguments with the last condition. The third condi-tion makes new chunks as big as possible. The last one makes sure that C contains all sub-components of all arguments. Figure 2 is an example to illus-trate our new chunk definition. For example,  X   X   X  /Chinese  X   X  /tax  X   X  /department X  is a con-stituent of current sentence, and is also an argu-ment of  X   X   X  /stipulate X . If we take it as a chunk, it does not conflict with any other arguments, so it is a reasonable syntactic chunk. For the phrase  X   X   X  /owing  X   X  /tax payment X , though it does not overlap with the first, third and fourth proposi-tions, it is bigger than the argument  X   X   X   X  (con-flicting with condition 2) while labeling the pred-icate  X   X   X   X , so it has to be separated into two chunks. Note that the third condition also guar-antees the constituents in C does not overlap with each other since each one is as large as possible. So we can still formulate our new shallow parsing as an  X  X OB X  sequence labeling problem. 3.3 Chunk Type We introduce two types of chunks. The first is simply the phrase type, such as NP , PP , of cur-rent chunk. The column CHUNK 1 illustrates this kind of chunk type definition. The second is more complicated. Inspired by (Klein and Man-ning, 2003), we split one phrase type into several subsymbols, which contain category information of current constituent X  X  parent. For example, an NP immediately dominated by a S , will be sub-stituted by NP X S . This strategy severely increases the number of chunk types and make it hard to train chunking models. To shrink this number, we linguistically use a cluster of CTB phrasal types, which was introduced in (Sun and Sui, 2009). The column CHUNK 2 illustrates this definition. E.g., NP X S implicitly represents Subject while NP X VP represents Object . 3.4 New Path Features The Path feature is defined as a chain of base phrases between the token and the predicate. At both ends, the chain is terminated with the POS tags of the predicate and the headword of the to-ken. For example, the path feature of  X   X   X   X   X   X  in Figure 1 is  X   X   X  -ADVP-PP-NP-NP-VV X .
 Among all features, the  X  X ath X  feature contains more structural information, which is very impor-tant for SRL. To better capture structural infor-mation, we introduce several new  X  X ath X  features. They include:  X  NP | PP | VP path: only syntactic chunks  X  V |  X  path: a sequential container of POS tags  X  O2POS path: if a word occupies a chunk 4.1 Experimental Setting Experiments in previous work are mainly based on CPB 1.0 and CTB 5.0. We use CoNLL-2005 shared task software to process CPB and CTB. To facilitate comparison with previous work, we use the same data setting with (Xue, 2008). Nearly all previous research on Chinese SRL evalua-tion use this setting, also including (Ding and Chang, 2008, 2009; Sun et al., 2009; Sun, 2010). The data is divided into three parts: files from chtb 081 to chtb 899 are used as training set; files from chtb 041 to chtb 080 as development set; files from chtb 001 to chtb 040, and chtb 900 to chtb 931 as test set. Both syntactic chunkers and semantic chunkers are trained and evaluated by us-ing the same data set. By using CPB and CTB, we can extract gold standard semantics-driven shal-low chunks according to our definition. We use this kind of gold chunks automatically generated from training data to train syntactic chunkers.
For both syntactic and semantic chunking, we used conditional random field model. Crfsgd 1 , is used for experiments. Crfsgd provides a feature template that defines a set of strong word and POS features to do syntactic chunking. We use this feature template to resolve shallow parsing. For semantic chunking, we implement a similar one-stage shallow parsing based SRL system described in (Sun et al., 2009). There are two differences be-tween our system and Sun et al. X  X  system. First, our system uses Start/End method to represent se-mantic chunks (Kudo and Matsumoto, 2001). Sec-ond, word formation features are not used.
 4.2 Syntactic Chunking Performance Table 1 shows the performance of shallow syntac-tic parsing. Line Chen et al., 2006 is the chunk-ing performance evaluated on syntactic chunk def-inition proposed in (Chen et al., 2006). The sec-ond and third blocks present the chunking perfor-mance with new semantics-driven shallow pars-ing. The second block shows the overall perfor-mance when the first kind of chunks type is used, while the last block shows the performance when the more complex chunk type definition is used. For the semantic-driven parsing experiments, we add the path from current word to the first verb be-fore or after as two new features. Line Bracketing evaluates the word grouping ability of these two kinds of chunks. In other words, detailed phrase types are not considered. Because the two new chunk definitions use the same chunk boundaries, the fourth and sixth lines are comparable. There is a clear decrease between the traditional shallow parsing (Chen et al., 2006) and ours. We think one main reason is that syntactic chunks in our new definition are larger than the traditional ones. An interesting phenomenon is that though the second kind of chunk type definition increases the com-plexity of the parsing job, it achieves better brack-eting performance. 4.3 SRL Performance Table 2 summarizes the SRL performance. Line Sun et al., 2009 is the SRL performance reported in (Sun et al., 2009). To the author X  X  knowledge, this is the best published SRL result in the liter-ature. Line SRL (Chen et al., 2006) is the SRL performance of our system. These two systems are both evaluated by using syntactic chunking de-fined in (Chen et al., 2006). From the first block we can see that our semantic chunking system reaches the state-of-the-art. The second and third blocks in Table 2 present the performance with new shallow parsing. Line SRL (C1) and SRL (C2) show the overall performances with the first and second chunk definition. The lines following are the SRL performance when new  X  X ath X  features are added. We can see that new  X  X ath X  features are useful for semantic chunking.
 Table 2: SRL performance on the test data. Items in the first column SRL [(Chen et al., 2006)] , SRL [C1] and SRL [C2] respetively denote the SRL systems based on shallow parsing defined in (Chen et al., 2006) and Section 3. In this paper we propose a new syntactic shal-low parsing for Chinese SRL. The new chunk definition contains both syntactic structure and predicate-argument structure information. To im-prove SRL, we also introduce several new  X  X ath X  features. Experimental results show that our new chunk definition is more suitable for Chinese SRL. It is still an open question what kinds of syntactic information is most important for Chinese SRL. We suggest that our attempt at semantics-driven shallow parsing is a possible way to better exploit this problem.
 The author is funded both by German Academic Exchange Service (DAAD) and German Research Center for Artificial Intelligence (DFKI).

The author would like to thank the anonymous reviewers for their helpful comments.
 Wenliang Chen, Yujie Zhang, and Hitoshi Isahara. 2006. An empirical study of Chinese chunking. In Proceedings of the COLING/ACL 2006 Main
Conference Poster Sessions , pages 97 X 104. As-sociation for Computational Linguistics, Syd-ney, Australia.
 Weiwei Ding and Baobao Chang. 2008. Improv-ing Chinese semantic role classification with hi-erarchical feature selection strategy. In Pro-ceedings of the EMNLP 2008 , pages 324 X  333. Association for Computational Linguis-tics, Honolulu, Hawaii.
 Weiwei Ding and Baobao Chang. 2009. Fast se-mantic role labeling for Chinese based on se-mantic chunking. In ICCPOL  X 09: Proceed-ings of the 22nd International Conference on Computer Processing of Oriental Languages.
Language Technology for the Knowledge-based Economy , pages 79 X 90. Springer-Verlag, Berlin, Heidelberg.
 Jan Haji  X  c, Massimiliano Ciaramita, Richard Jo-hansson, Daisuke Kawahara, Maria Ant ` onia Mart  X   X , Llu  X   X s M ` arquez, Adam Meyers, Joakim Nivre, Sebastian Pad  X  o, Jan  X  St  X  ep  X  anek, Pavel Stra  X  n  X  ak, Mihai Surdeanu, Nianwen Xue, and Yi Zhang. 2009. The CoNLL-2009 shared task:
Syntactic and semantic dependencies in multi-ple languages. In Proceedings of the 13th Con-ference on Computational Natural Language Learning (CoNLL-2009), June 4-5 . Boulder, Colorado, USA.
 Dan Klein and Christopher D. Manning. 2003. Ac-curate unlexicalized parsing. In Proceedings of the 41st Annual Meeting of the Association for
Computational Linguistics , pages 423 X 430. As-sociation for Computational Linguistics, Sap-poro, Japan.
 Taku Kudo and Yuji Matsumoto. 2001. Chunking with support vector machines. In NAACL  X 01:
Second meeting of the North American Chapter of the Association for Computational Linguis-tics on Language technologies 2001 , pages 1 X  8. Association for Computational Linguistics, Morristown, NJ, USA.
 Weiwei Sun. 2010. Improving Chinese semantic role labeling with rich features. In Proceedings of the ACL 2010 .
 Weiwei Sun and Zhifang Sui. 2009. Chinese func-tion tag labeling. In Proceedings of the 23rd
Pacific Asia Conference on Language, Informa-tion and Computation . Hong Kong.
 Weiwei Sun, Zhifang Sui, Meng Wang, and Xin
Wang. 2009. Chinese semantic role labeling with shallow parsing. In Proceedings of the 2009 Conference on Empirical Methods in Nat-ural Language Processing , pages 1475 X 1483.
Association for Computational Linguistics, Sin-gapore.
 Mihai Surdeanu, Richard Johansson, Adam Mey-ers, Llu  X   X s M ` arquez, and Joakim Nivre. 2008.
The conll 2008 shared task on joint parsing of syntactic and semantic dependencies. In CoNLL 2008: Proceedings of the Twelfth Conference on Computational Natural Language Learning , pages 159 X 177. Coling 2008 Organizing Com-mittee, Manchester, England.
 Nianwen Xue. 2008. Labeling Chinese predi-cates with semantic roles. Comput. Linguist. , 34(2):225 X 255.
