 1. Introduction
The relational data model is known to be a semantically poor model. As an illustration, the concept of gen-eralization/specialization (G/S) cannot be directly represented. The G/S concept has been introduced by Smith and Smith [27] . It has been incorporated in the Entity-Relationship (ER) model by Scheuermann et al. [24] . the designer with a semantically sound mechanism for representing IS-A hierarchies whatever the number of specializations.
 clerks, professors, etc.) in a university. We choose to define a PERSON as a generalization of STUDENT.
In the Extended Entity-Relationship (EER) model, inheritance represents the IS-A relationship:  X  X  X very stu-dent is a person X  X . It implies that every attribute relevant for PERSON instances is inherently applicable to
STUDENT instances. The relational model provides no mechanism for incorporating such semantic informa-tion. The resulting relational schema may be defined as follows:
A view representing all the instances of the generalization can be specified. Another possible implementation consists of one relation PERSON defined by all the attributes of the hierarchy. In this case, null values are introduced and existence dependencies must be specified. A third usual solution consists in implementing the following relations:
More generally, relational databases lack concepts that enable a natural representation of inheritance. As a ing null values, defining inclusion dependencies and views.

Database reverse engineering is a set of techniques allowing the designer to extract semantics from exist-ing databases in order to facilitate their maintenance and to enable their migration. This paper deals with relational database reverse engineering, especially with generalization hierarchies reverse engineering. Dis-concepts of existence and inclusion dependencies. Many algorithms have been proposed to perform a reverse engineering process of relational databases. While they share a number of features in common, only seven algorithms adopt a specific approach for eliciting generalization/specialization hierarchies [6,8,12,15,20, 23,29] .

The aim of this paper is to focus on generalization hierarchies reverse engineering. This process is inte-grated into a relational database reverse engineering global approach called MeRCI (a French acronym detection of generalization hierarchies using three common information sources explored by the reverse engineer when available: the database structure expressed as Data Definition Language (DDL) specifica-tions, the database dynamics through Data Manipulation Language (DML) queries and programs and, finally, the actual data. Another main contribution of this paper is related to the tight combination of algorithmic and heuristic rules. Our approach structures the rules described in past approaches for gener-alization hierarchies reverse engineering and enriches them with new rules, especially based on null values, homonyms and synonyms, existence dependencies and intersection constraints.

The remainder of this paper is organized as follows. Section 2 synthesizes the state-of-the-art of past approaches. Section 3 describes our reverse engineering global approach whereas Section 4 focuses on reverse concludes and discusses further research. 2. Related works
Past comprehensive approaches on relational database reverse engineering can be found in [2,5, 8 X 13,15,16,21 X 23,25,28,31] . A synthesis can be found in [10] . In this paper we focus on the specific prob-lem of generalization hierarchies reverse engineering. To the best of our knowledge, only seven techniques adopt an original approach in eliciting the G/S hierarchies [6,8,12,15,20,23,29] . They are synthesized in Table 1 . For each approach, we present the underlying assumptions and the different inputs used by the reverse engineering process, i.e. the information sources explored and the concepts used. We differen-tiate between approaches generating simple and/or multiple inheritance links. We also distinguish inheri-tance within relations from inheritance between relations. Moreover, a limited number of approaches provide the designer with totality, disjoint and/or partition constraints. 1 Depending on the approaches, the main output resulting from the reverse engineering process can be either an object-oriented (OO) model or an EER schema.

A careful analysis of this table leads us to the following comments:  X  As it can be seen, most approaches impose prerequisites on the database that may be strong. These prereq-sistent naming of attributes [8] , etc.  X  All these approaches assume that the information contained in the underlying database can be incomplete, erroneous, and not necessarily documented. Therefore, most approaches use multiple sources of informa-tion for data semantic extraction. These sources are DDL specifications, data, and knowledgeable persons (designers, users, experts, etc.). To the best of our knowledge, DML queries are not used for inheritance elicitation. the issues in reverse engineering is to recover this semantics. Most approaches described above exploit mainly the inclusion dependencies between primary keys to derive inheritance hierarchies (except [8] that exploits inclusion dependencies between candidate keys). However, our experience leads us to believe that this is far to be sufficient. Let us mention some key-based inclusion dependencies 2 leading to irrelevant inheritances.
 For example let us consider the two following relations: each department has only one project). Taking into account the key-based inclusion dependency Pro-ject.DepartmentNum Department.DepartmentNum, some approaches derive an inheritance link between
Project and Department, which is absurd.  X  Moreover, some approaches exploit null values [15,23] to exhibit IS-A inheritances. However, in legacy dat-as either inapplicability or temporary absence of a value. Consequently, the non-exploration of the data and/or a partial analysis of database semantics can lead to erroneous, incomplete or unstable inheritance hierarchies.  X  None of the past approaches derives multiple inheritances within relations. The usefulness of multiple inheritance depends on the goal of the reverse process (integration, reengineering, etc.), on the existence of an OODBMS (Object Oriented Data Base Management System) able to manage such an inheritance, and on the readability of the derived schemas. As a consequence, the reverse engineering process must be adapted to the specific needs of each project.  X  All the approaches derive several levels of inheritance between relations but, when performed, only one level for inheritance within relations. Let us mention that inheritance links within relations, when gener-ated, are only one-level depth.
Moreover, to the best of our knowledge, all the approaches do not provide any order when applying their semantically poor inheritance hierarchies, i.e. incomplete and even irrelevant hierarchies. expresses only a temporary absence. By taking into account only the inclusion dependency Woman.Person _ Id However, past approaches are unable to attach the attribute Maiden _ name only to the specific Woman.
In this paper, we propose to unify in a single method all the rules used in past approaches. Moreover, we values semantics. Thus, we avoid the elicitation of semantically poor inheritance links. This approach is embedded in our reverse engineering framework, which, in addition, enables the discovery of homonyms and synonyms, and the elicitation of keys when they are not available in database specifications [10] . 3. The MeRCI reverse engineering approach The approach allowing us to extract generalization hierarchies from relational databases is embedded in MeRCI. The latter aims at the transformation of a relational database physical schema into a conceptual schema, starting from the source codes of the application (DDL and DML specifications) and if necessary exploring the data. The analysis of the physical schema and its associated SQL programs allows us to identify relevant information. This information is stored in a knowledge base using the reverse engineering rule base. This intelligent transformation process leads to a conceptual schema.

MeRCI is a reverse engineering method based on the database system life-cycle model involving three main MeRCI are briefly described below: 3.1. Extraction of the physical schema
The aim of this step is to obtain a detailed description of the physical schema as complete as possible. This mas and even by analyzing the content of users X  outputs or input screens. 3.2. De-optimization of the physical schema
Starting from the physical schema obtained at the end of the preceding step, we apply a set of physical ations which would have transformed the logical schema, we successively examine the DDL specifications, a simplified internal representation of DML specifications and data. The embedded SQL source code is also examined to determine identifiers like primary keys and candidate keys. Finally a restructured logical schema is presented to the designer in order to validate the transformations. After validation:  X  The relations are, if necessary, transformed (split, merged, etc.).  X  The internal representations of DML specifications are reformulated for the normalized relations. 3.3. Conceptualization of the logical schema queries and validates by scanning the data of logical relations.
 place within this conceptualization phase. 4. Reverse engineering of generalization hierarchies
Let us introduce some useful notations.  X  R stands for a relation in the relational theory,  X  E stands for an entity-type,  X  t stands for a tuple of a relation.
 the same way, X , Y , Z stand for sets of attributes.

We denote by  X  I
R an extension of the relation R ,  X  t . A i the value of A i for the tuple t ,  X  R . A i the set of A i values in R ,  X  R . X the relation resulting from the projection of R onto the sequence of attributes X ,  X  t . X the set of values taken by X for the tuple t ,  X  P X ( I R ) the projection of I R onto the sequence of attributes X .

Definition 4.1. (Applicability domain of an attribute or a set of attributes) The applicability domain of an example, the applicability domain of Maiden name is limited to tuples representing women. An attribute is mandatory in a schema of a relation R if its applicability domain is R .

In the same way, we define Dom X , applicability domain of the set of attributes X , as the set of possible tuples where each attribute of X is applicable.

We have defined this concept of applicability domain to deal with null values. Let us remind that a major problem related to the semantic of the null value is due to the fact that null values can express either the temporary absence of a value (the value is temporarily unknown) or the inapplicability of this tuple).

Definition 4.2 ( Mutual existence dependency ). A mutual existence dependency, denoted Dom X = Dom Y , sion of R , " A 2 X , " B 2 Y , Dom A = Dom B .

Therefore, two attributes A and B of a relation R related by a mutual existence dependency have the same applicability domain in R .
 Definition 4.3 ( Exclusive existence dependency ). An exclusive existence dependency Dom X \ Dom Y  X   X  sion I R , " A k 2 X , " B p 2 Y , Dom Ak \ Dom Bp  X   X  :
As a consequence, two attributes A and B of a relation R related by an exclusive existence dependency have disjoint applicability domains.
 Definition 4.4 ( Conditioned existence dependency ). A conditioned existence dependency Dom X Dom Y sion I R ,
Therefore, a conditioned existence dependency Dom A Dom B between the two attributes A and B of a relation R expresses the inclusion of the applicability domain of A into this of B .
 Remark. The definitions presented above are those of [19] . Existence dependencies are a mean to deal with subset, equality and exclusive constraints [17] . As opposed to others, our definitions take into account the semantic of the null value. Completeness and soundness proofs of the defined inference rules systems related to the three kinds of existence constraints can also be found in [19] .

Our approach provides the designer with a method to discover generalization/specialization links hidden in tion 3 constraints. It combines heuristic and algorithmic techniques [18] . This process is embedded into the ter is composed of an enrichment phase, a mapping phase, and a user validation phase. The first phase allows below ( Fig. 2 ).

In the following paragraphs, we focus on the four main processes ( 4.1 X 4.4 ) of our approach performing (1) specific to the generalization elicitation problem. However, they are required for the validation phase. 4.1. Elicitation of inclusion dependencies, and intersection and exclusion constraints Unlike conceptual models, the relational model does not provide the generalization/specialization concept. Consequently, in order to implement an inheritance hierarchy, the designer has to choose between different representations: (1) only the generic concept, (2) only the specialized concepts, possibly in addition to a view expressing the generic concept, (3) both generic and specific concepts.

The first solution leads to the introduction of null values with possibly existence dependencies expressing disjoint and/or totality characteristics of the generalization. The second solution can be applied only when detection and/or elicitation is an important step. However, due to the previous considerations, existence dependencies will be considered only if they link primary and/or candidate keys.

In order to perform this constraint elicitation phase, we have defined several production rules synthesized available. Conditions are linked by the logical operator And when they originate from the same source. Con-in more details rules 1 and 7. Rule 1 can be paraphrased in the following way: If ( relation R1 has a primary or a candidate key X Then R1 and R2 are linked by an intersection constraint R1.X \ R2.Y 5 B
Rule 1 combines information on primary and candidate keys, key names, integrity constraints, queries and step, this intersection constraint, if confirmed, will lead to the elicitation of an inheritance. In the same way, rule 7 can be paraphrased as follows: If ( relation R1 has a primary or a candidate key X
Then R1 and R2 are linked by an inclusion dependency R1.X R2.Y (and this dependency will possibly lead to the elicitation of an inheritance)
Based on other combinations of the same conditions, other rules conclude either to intersection, or inclu-to space limitations, only the main rules are described in Fig. 3 .
The reverse engineering process heavily depends on the information sources. The latter may be available or
More precisely, each condition in each rule is associated Hence the conclusion is also associated with a cer-Depending on the certainty factors attached to sources used to check Rule 1 conditions, the conclusion the reverse engineering as long as their sum is equal to one.

Our experience suggests that real databases may contain erroneous data, sometimes with non-reliable que-ries, or even lacking some sources (DDL or DML). In order to face this problem, we associate certainty fac-algebra is described in [10] . 4.2. Elicitation of null values and interpretation of their semantics
Existence dependencies can, at the best, be explicitly included in the schema specifications or have to be deduced by analyzing null values in the data. However, a null value can also express a temporary absence. analysis. In order to interpret null and default values, we first analyze schema specifications and the DML code. Some heuristic rules, exploiting the three sources, are summarized in the decision table of Fig. 5 .
Analysis of a schema description, either in the DDL specifications or in the metabase, can only reveal a possible non-null constraint and/or a default value clause. Default values may mask potential null values. details rules 14 and 15. Rule 14 can be paraphrased in the following way: If ( a non-null constraint is not specified for column A Then null expresses inapplicability in column A
In other words, when a default value is associated to a column, and null values are allowed for this column, and if the exploration of the data confirms that A contains V then we can conclude that some default values V assigned to A express inapplicability.
 By performing the tasks related to step 4.2, we obtain an interpretation of all null values contain in data. This result is directly incorporated in the data (two NULL values are coded) in order to be used in further steps. 4.3. Existence dependency elicitation
The existence dependency elicitation is a mixed process. It uses both a heuristic approach and an algorith-mic approach. It is performed in three phases ( Fig. 6 ).

The first phase (a) uses heuristics in order to suspect existence dependencies. Some of these heuristics are briefly described in the decision table below ( Fig. 7 ). As an illustration, let us suppose that a table contains two columns A and B associated with the following constraint: CHECK (A IS NOT NULL AND B IS NOT NULL) OR (A IS NULL AND B IS NULL). This clause defines a mutual existence dependency (Rule 1). Otherwise, if this constraint is not defined in the schema, it can be derived from the analysis of other information sources. Thus, Rule 2 allows us to derive a mutual existence dependency by considering both the updates and the data: If at any insertion or update, a null value (or a non-null value) is assigned simultaneously to A and B then a mutual existence dependency between A and B is suspected. Moreover, if a column A contains at least one null value expressing the inapplicability and if for every tuple, when A is valued, B is also valued and vice versa, then we can assert that A and B are related by a mutual existence dependency. Let us remind that the only null values considered here are null values for inapplicability. Others have been removed as a result of the application of step 4.2.

During the second phase (b), existence dependencies are automatically extracted from a representative set of data where null values are supposed to express only the absence for inapplicability. More explicitly, tuples containing null values for unavailability are not inserted in this set. Moreover, tuples containing encountered in the table according to the absence or the presence of values for its attributes. As an illus-tration, tuples (31, v2, null, v3) and (v4, v5, null, v6) lead to the same type (1,1,0,1). A Boolean function a conjunctive form allows us to determine the existence dependencies implicitly described by the data. As an the first two attributes are mandatory and the two others are not linked by an existence dependency, due to the fact that the four combinations (0,1), (0,0), (1,0), (1,1) are in the set. This algorithmic approach has been detailed in [18] .

During the decision phase (c), the sets of constraints (one set per relation) obtained from the data are then confronted with those obtained from the heuristic phase. This confrontation is necessary since it may compen-from the data and vice versa. More specifically, three different situations may occur:  X  a mutual existence dependency Dom X =Dom Y is suspected resulting from the heuristic analysis whereas  X  a mutual existence dependency Dom X =Dom Y is suspected resulting from the heuristic analysis whereas  X  an exclusive existence dependency Dom X \ Dom Y  X   X  is suspected resulting from the heuristic analysis mic process (or vice versa).
 account certainty factors associated with each source of information. In this mode, the constraint generated from the most reliable source is confirmed. The second conflict solving mode is semi-automatic. It requires a set of existence dependencies is obtained and will be used as a basis for the elicitation of generalization links. 4.4. IS-A link derivation
Reverse engineering of generalization/specialization hierarchies is an algorithmic process. It is actually result from the enrichment process described above.

Reverse engineering of hierarchies encompasses two phases. The first phase is a merging process. A graph is dependencies. The merging process builds a unique relation from each connected component of this graph. It consists in determining both the structure and the extension of relations. Prior to computing the extensions, dencies. Dummy tuples may be introduced if it is necessary.

The second phase of the process performs a decomposition of each resulting relation into an IS-A hier-archy. For each relation we automatically extract its set of existence dependencies. The latter are used to ing into account the mutual existence dependencies. Then the sets of attributes that may coexist are com-puted by means of exclusive existence dependencies. Finally, the sets that are compatible with the conditioned existence dependencies are selected. These sets describe structures of entities embedded in the merged relation. These structures are then organized into an inclusion graph. The inversion of the arcs of the resulting graph leads to an IS-A hierarchy. This splitting approach is formally described and detailed in [26] .

Let us mention that the process described above is not limited to relations with null values. Even if a relation does not contain null values, it can be usefully decomposed. For example, in order to describe an application requirement, we can specify views or programs to manipulate hidden entities. The latter may be selected (in views or programs) according to the value taken by one or several attributes of a relation. It is interesting in such a case to represent these entities in the conceptual model. The relation having a column with only few different values can be modified by applying the following transformation rule: associated with A 1 ; ... ; A p . The transformation rule consists first in creating the relation R lowing algorithm:
For example, let us consider a relation Teaching_Staff belonging to a university management database. Let us also consider that, among the columns of Teaching_Staff, the attribute FacultyGroup describes the group associate professor), APROF (Assistant Professor), and  X  X  X ASS X  X  (for teaching assistant). described above to this table leads to the relation whose extension is described in Fig. 9 . This algorithm can be considered as a way to create a BitMap index.

Applying all the processes described in Section 4 allows us to elicit EER concepts leading to a conceptual schema as a result of the conceptualization process of MeRCI. 5. Example
This section presents an example illustrating our approach. Let us consider a subset of the transactional information system of an airline company. By performing MeRCI de-optimization step, we obtain the follow-ing schema: Airport (AirportCode , AirportName, #CountryCode) Airline_Flights (FlightNumber , #DepartureAirportCode, #ArrivalAirportCode, StartingValidityDate, EndingValidityDate) Int_Stops (#FlightNumber, StopNumbe r, #AirportCode, StopDuration) Countries (CountryCode , CountryName, Restrictiveness, TimeZone, Continent) Expected_Flights (#FlightNumber, ExpectedDepartureDate , ExpectedDepartureTime, ExpectedArrival-Date, ExpectedArrivalTime, ReservedPlaceCount, AvailablePlaceCount) Past_Flights (#FlightNumber, #ExpectedDepartureDate , RealDepartureDate, ExpectedDepartureTime, RealDepartureTime, ExpectedArrivalTime, RealArrivalTime, CancelationReason/DelayReason, OccupationRate) Flight_Crew (#FlightNumber, #ExpectedDepartureDate, #EmployeeNumber , Role) Employee (EmployeeNumber , FirstName, LastName, Occupation, LicenseNumber, FlightsHoursCount)
Note that this schema is the first source of information to be used by our reverse process. Information tries in which the airline company operates and the restrictions imposed by some countries. Expected_Flights stores information about the schedule of flights, including the number of seats available (AvailablePlace-Count) and the number of seats already booked (ReservedPlaceCount). Relation Past_flights stores informa-tion about flights that either have taken place or have been cancelled. Relation Flight_Crew is composed of tuples linking employees and flights. Finally, relation Employee summarizes the information about the com-pany workforce.

For readability and space limitation reasons, we present below only a subset of the main transactions, phrased in natural language: diate stops,  X  planning a flight,  X  canceling a flight,  X  recording information about a completed flight,  X  booking a seat in a flight,  X  retrieving information about a flight,  X  retrieving information about intermediate stops of a flight,  X  inserting information about a new flight staff,  X  inserting information related to a new ground staff,  X  inserting information about countries,  X  retrieving information about all the flight staff.

This transaction set corresponds to the second information source. The third information source is the data sample presented in Annex 1 .

We suppose that MeRCI de-optimization step has elicited homonyms and synonyms, candidate keys, pri-mary keys, foreign keys, non-null constraints. Primary keys are underlined, foreign keys are preceded by the for the columns ReservedPlaceCount and Restrictiveness and the non-null constraint has been specified for the columns AirportName, #CountryCode, #DepartureAirportCode, #ArrivalAirportCode, #AirportCode, StartingValidityDate, EndingValidityDate, StopDuration, CountryName, TimeZone, Continent, Expected-DepartureTime, ExpectedArrivalTime, ExpectedArrivalDate, AvailablePlaceCount, ReservedPlaceCount, FirstName, LastName, Occupation and Role. Finally, the constraint (FlightHoursCount is not null and
LicenseNumber is not null) or (FlightHoursCount is null and LicenseNumber is null) is specified in the schema description of the relation Employee.

We are now able to apply the different phases of our approach: 5.1. Elicitation of inclusion dependencies, and intersection, and exclusion constraints (phase 4.1) Based on Rule 7 at Fig. 3 , we can deduce an inclusion dependency between Past_Flights and Expected_ Flights relations: Past_Flights.X Expected_Flights.Y
Where X = {FlightNumber, ExpectedDepartureDate , ExpectedDepartureTime, ExpectedArrivalTime} and Y = {FlightNumber, ExpectedDepartureDate , ExpectedDepartureTime, ExpectedArrivalTime} 5.2. Elicitation of null values and interpretation of their semantics (phase 4.2)
The elicitation of null values semantics leads to the following conclusions. In the relation Countries, the default value  X  X  X one X  X  in the column Restrictiveness may be considered as a null value for inapplicability (Rule 15  X  Fig. 5 ). In the same way, Rule 22 of Fig. 5 interprets the null values appearing for LicenseNum-ber in the tuples of the relation Employee, and for CancelationReason/DelayReason, RealDepartureDate,
RealDepartureTime, RealArrivalTime and OccupationRate in the tuples of PastFlights as null values for inapplicability.
 On the contrary, the default value 0 in the column ReservedPlaceCount and the null value appearing for
FlightsHourscount in the tuples of the relation Employee mean unavailability. No existence dependency may be deduced. 5.3. Existence dependency elicitation (phase 4.3)
Let us remind that this phase is decomposed into three processes (heuristic, algorithmic and decision). (a) Application of the heuristic process Rules detecting existence dependencies conclude that all the columns whose description includes the NOT
NULL clause are mandatory (Rule 11  X  Fig. 7 ). RealDepartureDate, RealArrivalTime, RealDepartureTime and OccupationRate coexist (Rule 2  X  Fig. 7 ). In other words these attributes are linked, two by two, by a mutual existence dependency. The column FlightHoursCount and LicenseNumber also coexist (Rule 1  X  Fig. 7 ). Conditioned existence dependencies can also be derived: each of the columns RealDepartureDate, RealArrivalTime, RealDepartureTime, OccupationRate and CancelationReason/DelayReason requires
FlightNumber column of the relation Past_Flights (Rule 10  X  Fig. 7 ). (b) Application of the algorithmic process
The application of the algorithmic process to each relation enables the extraction of the following constraints: 1. All the columns of relation Airport are mandatory and coexist. 2. All the columns of relation Airline_Flights are mandatory and coexist. 3. All the columns of relation Int_Stops are mandatory and coexist. 4. All the columns of relation Countries except the column Restrictiveness are mandatory and coexist. 5. Restrictiveness requires all the other columns of the relation Countries. 6. All the columns of relation Expected_Flights are mandatory and coexist. 7. All the columns of relation Flight_Crew are mandatory and coexist. 8. All the columns of relation Employee except LicenceNumber are mandatory and coexist. 9. LicenceNumber requires all the other columns of relation Employee.
 10. Only the columns #FlightNumber, ExpectedDepartureTime, ExpectedArrivalTime, ExpectedArrival-11. RealDepartureDate, RealDepartureTime, RealArrivalTime, and OccupationRate coexist. 12. Each of the columns RealDepartureDate, RealArrivalTime, RealDepartureTime, OccupationRate and (c) Application of the decision process
By analyzing the constraints detected through the heuristic and the algorithmic processes, we can easily note that the heuristic process provides one additional constraint (FlightHoursCount requires LicenseNum-ber) that we could not deduce from the algorithmic process. This is due to the fact that column FlightHours-Count contains null values expressing both inapplicability and temporary absence. We decide to integrate this constraint into the set of constraints provided by the algorithmic process. 5.4. IS-A link derivation (phase 4.4)
Let us remind that this phase encompasses two processes (merging and splitting): (a) The merging process Due to the unique inclusion dependency, this process leads to the merging of relations Past_Flights and ExpectedFlights. The resulting relation schema is given below: Expected_Flights/Past_Flights (#FlightNumber, ExpectedDepartureDate , ExpectedDepartureTime, ExpectedArrivalDate, ExpectedArrivalTime, ReservedPlaceCount, AvailablePlaceCount, RealDeparture-Date, RealDepartureTime, RealArrivalTime, CancelationReason/DelayReason, OccupationRate)
The other relations remain unchanged. (b) The splitting process
Relations Airport, Int_Stops, and Flight_Crew remain unchanged. Relation Countries is split into two rela-tions according to the existence dependencies. In the same way, relation Employee needs to be split. Finally relational schema: Airport (AirportCode , AirportName, #CountryCode) Airline_Flights (FlightNumber , #DepartureAirportCode, #ArrivalAirportCode, StartingValidityDate, EndingValidityDate) Int_Stops (#FlightNumber, StopNumbe r, #AirportCode, StopDuration) Countries1 (CountryCode , CountryName, TimeZone, Continent) Countries2 (CountryCode , Restrictiveness) Expected_Flights/Past_Flights1(#FlightNumber, ExpectedDepartureDate , ExpectedDepartureTime, ExpectedArrivalDate, ExpectedArrivalTime, ReservedPlaceCount, AvailablePlaceCount) Expected_Flights/Past_Flights2(#FlightNumber, #ExpectedDepartureDate , RealDepartureDate, Real-DepartureTime, RealArrivalTime, OccupationRate) Expected_Flights/Past_Flights3(#FlightNumber, #ExpectedDepartureDate , Cancelation/Delay Reason) Expected_Flights/Past_Flights4(#FlightNumber, #ExpectedDepartureDate ) Flight_Crew (#FlightNumber, #ExpectedDepartureDate, #EmployeeNumber , Role) Employee1 (EmployeeNumber , FirstName, LastName, Occupation) Employee2(EmployeeNumber , LicenseNumber, FlightsHoursCount) which can be decomposed in two sub-concepts. The first sub-concept (Expected_flights/Past_flights2) charac-flights that have been delayed.

The reverse process is unable to provide entities with relevant names. Therefore, the designer must choose a meaningful name for each relation. Employee2, for example, can be changed to FlightEmployee. We suggest the name CompletedFlights for Expected_flights/Past_flights2 whereas Expected_flights/Past_flights4 can be renamed DelayedFlights. Finally, Countries2 is renamed RestrictedCountries and Expected_flights/Past_ flights2 is converted to DisruptedFlights.
 The conceptual schema derived by applying MeRCI conceptualization step is represented in Fig. 11 .
We argue that this conceptual schema would not have been obtained without using the three informa-tion sources (schema, transactions, and data). Moreover, it results from the combination of both heuristic and algorithmic processes. The resulting IS-A hierarchies are based on the declarative constraints, the main transactions, and the analysis of the data. They are not the result of a factorization process based only on null values and/or common columns. Thus, our contribution lies in the combination of the analysis of three information sources, the use of two reasoning mechanisms (heuristic, algorithmic), and the detection of truly semantic IS-A hierarchies based not only on a factorization process. 6. Conclusion and further research
This work is part of our general work on defining a relational database reverse engineering global method. In this paper, we introduced an approach for eliciting generalization hierarchies from relational databases. We analyzed past contributions to this specific problem. These contributions concentrate the analysis on one or two information sources (among the three usual ones, i.e. database schema, transactions, data). We claim that the three information sources. The combination of these processes requires a decision step which can be per-formed either automatically thanks to certainty factors associated with information sources or semi-automat-ically in order to allow the reverse engineer to refine his/her judgement on the quality of these different linked to null and default values. The third one is the central phase of this paper. It combines a heuristic and an algorithmic process to elicit existence dependencies followed by a decision process to solve potential rules to derive semantic information from the initial information sources. The paper illustrates the approach using a case study. We believe that our approach can be readily applied to real world problems. The main con-and translating them into IS-A hierarchies among entities. A prototype is under implementation. In future research, we plan to gain experience with our approach by testing real world case studies using the prototype sion of the present work would consider not only the relational databases but navigational systems as well. Acknowledgement
The authors are very grateful to the referees for their invaluable comments and suggestions about this paper.
 Annex 1. A data sample of the relations
AIRPORT Airport Code Airport Name #CountryCode AIRLINE_FLIGHTS Flight INT_STOPS Flight COUNTRIES CountryCode CountryName Restrictiveness TimeZone Continent EXPECTED_
FLIGHTS PAST_
FLIGHTS FLIGHT_CREW #Flight Number #Expected Departure Date #Employee Number Role EMPLOYEE #Employee References
