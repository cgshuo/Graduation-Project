 Wikipedia has become one of the most important sources of information available all over the world. However, the cate-gorization of Wikipedia articles is not standardized and the searches are mainly performed on keywords rather than con-cepts. In this paper we present an application that builds a hierarchical structure to organize all Wikipedia entries, so that medical articles can be reached from general to particu-lar, using the well known Medical Subject Headings (MeSH) thesaurus. Moreover, the language links between articles will allow using the directory created in different languages. The final system can be packed and ported to mobile devices as a standalone offline application.
 J.3 [ Computer Applications ]: Life and Medical Sciences; H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval Algorithms, Languages Text classification, Category ranking, Medical Subject Head-ings, Wikipedia, jQuery Mobile, PhoneGap
Some web directories have gained popularity in the last manually maintained by a large community of editors. Nowa-days this directory stores more than five million sites, which are classified on more than one million categories organized hierarchically. This thesaurus is employed by other compa-h ttp://www.dmoz.org/docs/en/about.html . http://www.alexa.com/company .
 most popular pages in a hierarchical tree, going from general to particular categories.

Wikipedia is ranked by Alexa in the sixth position glob-ally. Due to the large amount of information and the wide number of subjects contained in Wikipedia, it is quite dif-ficult to develop an automatic system to categorize all its contents into a standardized tree, such as those employed in web directories. As in ODP, currently this task is carried out manually by a large group of volunteers.

Our proposal tries to automatically identify medical Wiki-pedia articles in order to provide an interface to access this resource by categories as in a web directory. With this pur-pose, we employ machine learning techniques to train and filter relevant information on particular domains.
Our classification system takes Wikipedia articles as an input and decides whether they are inside medical scope or not, and in case they are, try to find one or several cate-gories where they could fit. To achieve this goal, we need a corpus containing a large amount of training data and a categorization algorithm.
 millions of free documents covering thousands of medical subjects. The thesaurus employed to hierarchically catego-rize every bibliographic entry in this database is known as than 2 million documents associated to more than 25,000 topics in the MeSH thesaurus. Due to the popularity and free availability of these resources, a fully functional inter-face is currently available to get all training data by means of simple queries, such as  X  X iseases category[majr] X  which retrieves all articles related to any disease (the expansion is done automatically by the system [3]). All these consider-ations have been taken into account to choose this corpus, since it may lead us to enhance the results and simplify the maintenance and future upgrades of our application.
Regarding the second requirement, we must consider the size of the data we are working with. Our proposal employs our own classification algorithm, namely NEWPAR [5], de-signed to work with large corpora. This algorithm has been http://ncbi.nlm.nih.gov/pubmed . 4 Medical Subject Headings: http://ncbi.nlm.nih.gov/ mesh . Figure 1: Navigation example to access Wikipedia p ages related to Cardiovascular Diseases. The num-ber of available articles is shown on the left and the list containing the links appears on the right. previously employed in real time applications on medical domain [6, 7].
The classification algorithm mentioned above will only handle documents written in English to complete both the training phase with the MEDLINE documents and the sub-sequent offline classification of Wikipedia articles. This pro-cess is transparent to the final user, since it is done through a batch process. To achieve this goal, each entry in the XML been transformed into plain text and classified in order to provide a ranked list of links for each particular topic.
Both Wikipedia articles and MeSH vocabulary are avail-able in different languages, and links between English ver-sions and other languages are provided in both resources, making it possible to develop a multilingual application. Al-though the documents are originally classified in English, if the user chooses another language the system only has to find the correspondences in either the MeSH entries or the pages in Wikipedia.

As it is shown in Figure 1 (left), the user selects a lan-guage and automatically gets a list of topics followed by the number of Wikipedia related articles. More particular top-ics can be accessed navigating down the MeSH tree. The user can finally get the links to each article by clicking on category name.

In order to enrich the information provided to the user, our application extracts (this is done also in an offline phase) a brief description of the suggested links to Wikipedia pages, extracted from the XML dump files of each language as shown in Figure 1 (right). Finally the whole contents can be accessed through the ranked links as shown in Figure 2.
The system is built in a way that allows being fully op-erated as a standalone offline application, that is, without h ttp://meta.wikimedia.org/wiki/Data_dumps .
 Figure 2: Example of the contents of the first two W ikipedia articles most related to Cardiovascular Diseases topic. the need for Internet connection. The interface on the client side has been developed using jQuery Mobile [4], a library which allows to write HTML and Javascript source code that can be interpreted by almost any device containing a simple browser. This ensures the possibility to use the ap-plication in most devices (both mobile and non-mobile plat-forms) and also in any of the existing operating systems. We also provide the users with the native code [2] by using the PhoneGap [1] framework, as it allows to create mobile apps using standardized web APIs. The final result is an application that can run on any kind of computers through a website ( http://www.lookforwiki.com ) and that can also be compiled and installed to get it working natively with a single codebase on systems such as Android, iOS, Windows, Blackberry, webOS and Symbian. [1] S. Allen, V. Graupera, and L. Lundrigan. Phonegap. [2] A. Charland and B. Leroux. Mobile application [3] Z. Lu, W. Kim, and W. J. Wilbur. Evaluation of query [4] J. Reid. jQuery Mobile . O X  X eilly Germany, 2011. [5] F. Ruiz-Rico, J.-L. Vicedo, and M.-C. Rubio-S  X anchez. [6] F. Ruiz-Rico, J.-L. Vicedo, and M.-C. Rubio-S  X anchez. [7] F. Ruiz-Rico, J.-L. Vicedo, and M.-C. Rubio-S  X anchez.
