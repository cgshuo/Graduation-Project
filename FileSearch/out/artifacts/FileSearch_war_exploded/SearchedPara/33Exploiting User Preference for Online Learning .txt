 ANLEI DONG and YI CHANG , Yahoo! Labs Recent years have witnessed a rapid growth of the Internet, which has become an important medium for delivering digital content to Web users instantaneously. Digital content publishers, including both portal websites (e.g. MSN 1 and Yahoo! 2 ) and home-pages of news media (e.g. CNN 3 and the New York Times 4 ), have all started providing Internet users with Web content in a timely fashion via a wide range of content mod-ules. For example, as shown in Figure 1, the Yahoo! front page presents users with a number of content modules, including today X  X  emerging events, news of various aspects, and trending queries from the search engine. However, Web users usually have a short attention span while facing the explosion of Web content, often referred as information overload . Thus, it is necessary for those Web publishers to optimize their content by recommending content items that are most attractive to users for any given time in order to retain users to their portal sites at an ongoing basis.

In general, the process of Web portal content optimization consists of gathering infor-mation about portal website users, managing the content assets, analyzing current and past user interactive actions, and based on the analyses, delivering the right content to each user at the right time. While this general process of content optimization looks similar to that of traditional personalized recommendation scenarios, it is not feasible to just simply adopt the conventional recommendation algorithms, such as content-based filtering or collaborative filtering, because the Web portal content optimization problem has a couple of unique issues, such as extremely dynamic content pool and time-sensitive user preferences. Namely, in a Web portal, the content pool, for exam-ple, the trending search queries, can vary very frequently, and each content item may have a lifetime of only several hours. Therefore, most of the traditional personalized recommendation algorithm would suffer from a severe cold-start problem. Moreover, user preferences over the content items may also vary quickly, as users who come to Web portal are usually interested in timely topics, hence a specific user may look for different types of contents depending on the time of visit.

A key challenge to addressing these issues for content optimization is to devise online learning algorithms that can quickly learn what item a user may be interested for a given time, based on a user X  X  past interactions with the content items. The main prob-lem that arises in devising such scheme is the explore-exploit dilemma, a well-studied problem in statistics and machine learning communities. That is, the content optimiza-tion system should explore the content pool enough to find out the best item for a given user at a given time and simultaneously, sufficiently exploit the best item for users so that overall user satisfaction could be maximized. Recently, some variations of the multi-armed bandit schemes, which are online learning algorithms that are designed to solve this dilemma, have been successfully applied to optimizing the content offerings for the Today module on Yahoo! front page [Agarwal et al. 2008]. 5 The main idea is to apply the -greedy strategy; namely, constantly explore to estimate the attractiveness of each content item from a small fraction of user traffic in which the items are shown in random order, then exploit the best item learned from the exploration at a given time for the rest of the user traffic. For the personalization, of course, several features that reflect user characteristics were used so that the  X  X est X  in this procedure could be found for each user. In results, when the clickthrough rate (CTR) of an item is used as a proxy for the attractiveness, this scheme significantly improved the CTR of the Today module.

Despite the practical success of this method, the approach is somewhat limited, as it is more appropriate for the setting in which the user traffic size is large and the content pool size is relatively small, like the popular Today module. In such cases, obtaining a reliable CTR estimate for each content item from the random exploration is realistic, since there will be a large number of views and clicks for any single item. However, in applications like Trending Now or the News module on the Yahoo! front page, in which users X  interactions via clicks are relatively lower while the content pool size can be larger, simply trying to estimate CTR of each item by treating every logged view and click equally could cause more problems than solutions, that is, recommending content items based on inaccurate estimates of CTRs would not make the recommendation quality any better. In order to partly remedy such low-clicks and views problem, Dong et al. [2011] recently proposed a method to effectively interpret users X  actions, that is, views and clicks, such that the estimates of CTRs of contents could become more reliable when using the data that have been appropriately interpreted.

While the online learning framework and the action interpretation just mentioned could alleviate some of the weaknesses associated with traditional recommendation techniques for the content optimization problems, there still are a few critical prob-lems that are unique to content optimization at portal websites that have not been studied in the literature. First, as shown in Figure 1, each content module usually presents a couple of content items in a limited space, thus, users X  actions can not only represent their interests on a single item but also strongly indicate user prefer-ences among displayed items. However, most of the previous online learning schemes that deal with the explore-exploit challenge only employs dedicated pointwise models, thus overlooking some invaluable user preferences between content items implied by user actions. Second, the personalization of content optimization typically happens by segmenting users into several smaller groups based on user features, and the sparse samples problem just mentioned not only would persist but would become worse. That is, since the lifetime of an item could be very short, a pointwise model would never be able to collect enough samples to obtain a reliable CTR estimate for the item before it disappears in the content pool. Such an unreliable estimate of CTR would result in unsatisfying recommendation.

In this article, to address these challenges, we propose new dynamic pairwise learn-ing methodologies for devising an online learning algorithm in the context of Web portal content optimization that deals with the explore-exploit dilemma. In particular, we will first take a deep look at user action information and explore how to extract preferences between content item pairs accordingly. Then, we introduce two specific dynamic pairwise learning algorithms that estimate the attractiveness score for each item from the extracted preferences during the exploration phase: the first algorithm applies a graph-based method, while the other introduces a general Bayesian modeling process. These two algorithms are dynamic in the sense that they both rely on users X  more recent preferences rather than old ones. We examine the effectiveness of pair-wise learning approaches by conducting experiments on two large-scale datasets from a commercial Web portal. The results demonstrate significant improvements of pair-wise methodologies in terms of the precision metric over the baseline pointwise model approach. Moreover, further analysis shows that pairwise learning approaches can be more beneficial for sparse learning samples caused by personalization than pointwise models. Finally, to complement the empirical findings, we provide a few theoretical insights that further justifying the advantages of pairwise learning approaches over pointwise ones. To summarize, our specific contributions include the following.  X  X  general pairwise learning methodology that exploits dynamic user preferences for online learning in the Web content optimization system. To the best of our knowledge, this work is an early attempt to introduce pairwise learning methodology to resolve the explore-exploit dilemma prevalent in the Web content optimization.  X  X wo specified pairwise learning algorithms, one graph-based and the other based on
Bayesian modeling, for Web content optimization using preferences.  X  X nalyses of the effects of important factors, including dynamic user preferences and user action positions, for pairwise online recommendation.  X  X heoretical insights for justifying that pairwise learning methods can benefit online learning more in recommender systems compared with pointwise models.

The rest of this article is organized as follows. Section 2 reviews the literature in pairwise learning and content optimization in recommender systems. Section 3 intro-duces our specific online learning framework for recommendation and points out the critical challenges for achieving better content optimization. To address these chal-lenges, Section 4 proposes pairwise learning approaches and introduces two specified algorithms. A large-scale evaluation and discussion based on real-world data collected from a commercial portal website are presented in Section 5. To complement our em-pirical findings, we provide a few theoretical insights about the advantages of pairwise approaches in Section 6. Finally, we conclude and point out future work in Section 7. Considerable research on pairwise learning has been conducted in the context of learn-ing a ranking function for search applications, so-called learning-to-rank. While there are vast amount of papers on this topic, some representative work include RankBoost, [Freund et al. 1998], RankSVM [Joachims 2002], RankNet [Burges et al. 2005], and GBRank [Zheng et al. 2007]. For a more comprehensive reference, one can see Liu [2009].

As mentioned in the Introduction, this article is an early attempt to introduce pair-wise learning methodology for dealing with the explore-exploit dilemma in Web content optimization. Although it looks similar, our proposed methodology is still quite differ-ent from pairwise learning-to-rank schemes in terms of several aspects of problem formulation.  X  Less rich features. For the learning-to-rank problems, content items to rank for each search query are usually represented as a rich set of features (e.g., TF-IDF or BM25) from information retrieval. Thus, the goal of the learning-to-rank is to obtain a mapping function from the feature space into the ranking scores, and it is usually solved by a discriminative learning process; however, since the query, that is, the user preference, is mostly implicit in Web portal content optimization, there are not so rich features yet to describe content items as in the learning-to-rank problems.  X  Existence of temporal dynamics of the user preferences. In learning-to-rank for search, the user preferences are usually assumed to be stationary over time, since the rel-evance between any pair of query and document does not change very frequently.
However, user preferences under Web portal content optimization may yield more dy-namics, as Web users X  interests in emerging information on Web portals can change very often. Thus, reflecting such time-varying user preferences to the recommenda-tion algorithm is one of the key challenges in content optimization.  X  Difference in learning process. Due to the essential difference in terms of necessity to update the model in real time, learning-to-rank and Web content optimization yield quite different pairwise learning processes. In particular, the pairwise learning-to-rank leverage user preferences to build the pairwise objective function, but its ranking function still uses an individual content item X  X  features as input to compute the ranking score of this item. And it takes an offline optimization process to ob-tain the parameters of the ranking function. Nevertheless, for our online pairwise content optimization, all extracted user preferences are used directly to infer the attractiveness score of each content item. As a result, the recommendation models can be updated in an online process such that the effects of user preferences can be reflected in the recommender system in real time. As mentioned in the Introduction, the Web content optimization problem is in general defined as the problem of selecting and presenting content items that may be most rele-vant to a user at a given time who intends to browse the Web for information. Depending on different applications and settings, there are many variants of the problem such as selecting articles published on portal websites [Agarwal et al. 2008, 2010], news per-sonalization [Das et al. 2007; Li et al. 2010], computational advertising [Broder 2008; Richardson et al. 2007], and many others. Since the Web content optimization problem is a variation of personalized recommendation problems, we summarize some previous work in recommender systems that are relevant to our work.

For general personalized recommendation problems, there are two major classes of standard approaches: content-based filtering and collaborative filtering. The former one reflects the scenario where a recommender system monitors a document stream and pushes documents that match a user profile to the corresponding user. Then, the filtering system uses explicit relevance feedback from users to update the user X  X  profile using relevance feedback retrieval models [Zhang and Koren 2007; Yu et al. 2004; Zigoris and Zhang 2006] or machine learning algorithms [Yang et al. 2005; Gabrilovich et al. 2004]. Collaborative filtering goes beyond merely using document content but takes advantage of information from other users with similar tastes and preferences [Konstan et al. 1997; Jin et al. 2004; Hofmann and Puzicha 1999; Herlocker et al. 1999]. Some of previous studies [Melville et al. 2002; Wang et al. 2006] have tried to combine both techniques to build more effective recommender systems.

More recently, implicit user-grouping by latent-group or factor models [Srebro et al. 2005; Koren 2008], matrix completion [Candes and Recht 2008], and Bayesian ap-proaches [Stern et al. 09] also have become popular for general personalized recommen-dation problems. Furthermore, in the similar spirit as in the pairwise learning-to-rank algorithm for search, using pairwise preferences for devising personalized recommen-dation algorithm also has been used for recommender systems (e.g., [Rendle et al. 2009; Tak  X  acs and Tikk 2012; Yang et al. 2011; Kanagal et al. 2012]). To address the problem of sparse learning samples in recommender system, some previous studies introduced factorized parametrized models which can make estimation with a small sample size. For example, Rendle et al. [2010] proposed a Markov chain model which factorizes the transition matrix such that transitions can be estimated with little or even no observations. In addition, others [Koren 2009; Xiong et al. 2010; Kanagal et al. 2012] have considered incorporating some temporal variations of user preferences in the recommender system.

There also has been many previous studies that try to explicitly build some user features that can reflect user preferences for the personalized recommendation task. For instance, many studies proposed building user profiles to support personalization in the recommender system. Billsus and Pazzani [2007] created user profiles for adap-tive personalization in the context of mobile content access. Ahn et al. built a news recommender system, YourNews [Ahn et al. 2007], which allows users to customize their interest profiles through a user model interface. In addition, a personalized ser-vice may not exactly serve the individual user. The content of the portal website can be tailored for a predefined categories of audiences, based on offline research and conjoint analysis. In very early studies [Wind 1978], homogeneous groups of consumers were entailed by the use of a priori segmentation. Chu et al. [2009] recently proposed user behavior feature-based models for personalized services at individual and segmenta-tion levels, respectively. Those personalized models are shown to outperform several demographic segmentation models.

While these various methods have seen success in practical recommender systems, our work has the following differences.  X  Online vs. Batch. Most previous work in recommender systems, including the pair-wise schemes mentioned, are tailored for somewhat stationary pools of contents and users, hence are batch learning method. Therefore, when a new user or content frequently arrives and leaves the pool, just like in the Web content optimization problems, it is not clear how to quickly update the algorithms obtained from these methods. In contrast, we follow the online learning setting in Agarwal et al. [2008] to deal with such cold-start problems and the explore-exploit dilemma, and devise pairwise learning method in that setting which has not been considered before.  X  Much faster temporal dynamics of user preferences. The schemes that deal with tem-poral variations of user preferences mentioned were mainly for capturing long-term variations of user preferences. However, in the Web content optimization problems, the time scale of user preference variations is much finer, sometimes in minutes.
Thus, we try to incorporate such fast-varying user preferences in the content opti-mization system.  X  Sparser learning samples. The user profiling techniques mentioned are suitable when there are enough learning samples so that the model for the high-dimensional space could be obtained reliably. However, there are many applications in which such abundance of learning data is not available. Our proposed methods try to combat the sparse learning data problem by considering the information that could be obtained by the pairwise preferences inferred from the users X  feedback on the whole list of content items.

In summary, our proposed methods have several similarities with previous work in search ranking and personalized recommendation, but also have significant differences, as just described. In the next section, we will describe our scheme more in detail. As we target recommendation at content modules on Web portals, our goal is to op-timize content recommendation such that a certain user engagement metric, such as overall click-through rate (CTR), is maximized. For a pool of candidate items, human editors can be employed to manually rank the candidate items according to content attractiveness and users X  interests and then recommend top-ranked items to users. However, it requires expensive human effort and cannot guarantee that the most at-tractive and relevant items are recommended to users due to the interest gap between editors and Web users. Therefore, we attempt to design a recommender system that achieves content optimization by automatically estimating candidate items X  attrac-tiveness and relevance to users X  interests. To achieve this goal, we currently employ a state-of-the-art online learning framework, which has three critical characteristics: online learning , pointwise model ,and personalization . In the rest of this section, we will discuss these three aspects in details. Then, we will point out the critical challenges of this framework, which will be addressed by our new dynamic pairwise learning methodology in the next section To attract more users to browse and click content displayed on the portal modules, an online learning methodology is necessary, as it enables us to model user behavior (i.e., clicks and views) on the content modules as implicit feedback and to adjust the recommendation model in real time (or almost real time) accordingly.

To enable online learning in our recommender system, we apply a parallel-serving-buckets framework, where  X  bucket  X  means a part of user visiting traffic on Web portal. Figure 2 illustrates the flowchart of this online learning framework. Specifically, there are two parallel buckets serving simultaneously in the system: a random learning bucket and a serving bucket . When a user visits the Web portal, this visit event will be assigned into the traffic of random learning bucket with a certain probability; otherwise, it will be assigned into the visiting traffic of serving bucket .

Within the random learning bucket , a certain number of items are randomly picked from a pool of candidates to serve as recommended items for each user visit. In our system, we limit the random learning bucket to occupy only a small fraction of the whole traffic, that is, the probability that a user visit falls into this bucket is very small. Although randomly serving candidate items is obviously not the optimal recommending strategy, this random learning bucket can benefit online learning in another way. In particular, since each item from the candidate pool has equal chance to be served to users in the random learning bucket , we can obtain an unbiased estimate of its CTR based on user feedback in this bucket. Such unbiased CTR estimates can be further used as strong signals of users X  interests on the corresponding items to improve the recommendation model in the serving bucket .

In our parallel-serving-buckets approach, as shown in Figure 2, all the models in both buckets are updated simultaneously every 5 minutes (i.e., the time interval [ t , t + 1] equals 5 minutes in Figure 2). In general, within the serving bucket , the recommenda-tion model, at a certain time point t + 1, is updated based on the observations, that is, unbiased estimated CTRs, from the random learning bucket during the time interval [ t , t + 1]. The updated model is then applied to estimate attractiveness scores of can-didate items in serving bucket during [ t + 1 , t + 2], and the items are displayed by the scores in the descending order. Pointwise model is the most straightforward approach adaptable to the online learning framework. In particular, each candidate item in the recommender system uses a ded-icated model individually to estimate its attractiveness score. In our online learning framework, as real-time user feedbacks, which imply strong signals of items X  attrac-tiveness to users, is available in the random learning bucket , the attractiveness score of an item can be estimated by its unbiased CTR obtained from the random learning bucket .

To build effective pointwise models, we employ an Estimated Most Popular (EMP) model [Agarwal et al. 2009]. Assume during the time interval [ t , t + 1], an item was CTR estimation is p t predicted by its previous model at time t ; then, for the model of this item at time t + 1, the CTR estimation of this item is updated as where  X  t is the sample size of the prior belief.

The intuition in Equation (1) is that, given its prior probability p t , the CTR estimation is updated according to new observations of clicks and views during time interval [ t , t + 1]. The sample size  X  t is used to control the balance between the prior probability and new observations. The higher the value of  X  t , the more confidence we have on the prior probability. If the value of  X  t is set lower, the CTR estimation relies more on the new observations. More details of EMP can be found in Agarwal et al. [2009]. In this article, the EMP approach is regarded as the baseline, which is to be compared with new proposed dynamic pairwise learning methods as introduced in the next section. Personalization has become more important for recommender systems, as it provides users with a customized experience of highly attractive and relevant content so as to en-hance user engagement, conversions, and long-term loyalty. To achieve personalization for content optimization, our online learning framework employs a user segmentation approach in which homogeneous groups of users are entailed by a priori segmenta-tion [Wind 1978]. Each segment has its exclusive online learning and serving process. In other words, within one user segment, the recommendation model for each item is learned based on clicks and views only from the users belonging to this user segment, and the serving results using pointwise models are also only applicable to the users belonging to the same group. There are a few other kinds of personalization approaches for recommender systems; however, the user segmentation approach yields advantages in terms of both simplicity and reliability, especially for real-world commercial recom-mender systems.

To obtain this user segmentation, we generalize a set of user features and then apply clustering techniques to group users based on extracted features. We collect two major categories of user features that is available to the portal website: (1) explicit features : the personal information explicitly requested by the portal website, such as age, gender, occupation, preferences, etc., (2) implicit features : various types of user behavior tracked by the portal website, such as browsing and purchasing patterns of users on the pages within this website, etc. In our work, each user is represented as a vector of features, and we empirically generate ten user segments by using K-means, which is a well-known clustering technique. Due to the limited space, we will not present the specific clustering process here. Although our online learning framework combined with pointwise models and person-alization has shown effectiveness for the content optimization on portal websites, there still exists a couple of critical challenges. (1) How to take advantage of rich preference information? (2) How to deal with the problem of sparse learning samples? (3) How to deal with the unsatisfying recommendation for new emerging content items?
To address these challenges, we will propose the new pairwise learning methodol-ogy for Web content optimization in the next section. The pairwise learning methods can take much advantage of rich dynamic user preferences to estimate content item X  X  attractiveness and relevance to users X  interests. The effectiveness of this new method-ology will be demonstrated via large-scale evaluations in Section 5, together with more analysis on the effects of various critical factors in this methodology. More theoretical insights justifying the advantages of new pairwise methodology will be provided in Section 6. Content modules on portal website usually present a few content items in a small space, thus user actions, in the form of clicks and views on those content items, can indicate not only the relevance signal for each clicked item but also the dynamic preferences between different items in the same module. Those preferences contain invaluable information for comparing content items X  attractiveness in a timely fashion beyond the relevance on individual content items. Hence, when there are inadequate user clicks for accurate estimation of single item X  X  attractiveness, user preferences can still supply much information about relative relevance judgments to estimate items X  attractiveness for recommendation instantaneously. Consequently, we argue that dynamic preference information extracted from user actions can effectively reduce the effects of sparse learning samples. In this section, we first explore how to extract preference information based on user actions. Then, we will propose two specific algorithms for exploring dynamic preference to achieve Web content optimization. The first one is a graph-based method, followed by a more formalized Bayesian generative algorithm. For a specific content module, the log of user actions can be represented as a sequence of sessions, and each session is defined as the set of content items presented to user u at time t , while the index of each item represents its display position; and C represents the set of positions that are clicked by the user.
 By examining each user session, we can extract preference information as follows: Note that many previous studies have investigated position-sensitive preference ex-traction (e.g.  X  skip-above  X  X nd X  skip-next  X  strategies [Joachims et al. 2005]) in the context of ranking for search. However, the content modules on portal websites are quite differ-ent from a ranked list of search results. First, unlike a long ranked list of search results, one content module usually occupies a small area of the portal webpage, the content items in which could be all browsed with quick scan. Second, the organization of content items is usually not the same as the ranked list. As shown in Figure 1, content modules could have more complex organization for presentation. In this article, we will apply the preference extraction method introduced by default. In the following experiments, we will show that position-sensitive preference extraction, especially  X  skip-above  X  X nd  X  skip-next  X  strategies, does not bring significant improvement in recommendation. As position-sensitive preference extraction is not the focus of this work, we leave this topic as future work.
 The general idea of our graph-based pairwise learning method is to build a weighted, directed preference graph G = V , E , W from user feedback. The nodes ( v  X  V ) are candidate content items, while the edges ( e  X  E ) denote the preferences. For example, the directed edge from v i to v j represents the preference v i  X  v j , and the weight of an edge e , denoted as W ( e ), measures the strength of the preference. Note that, to introduce personalization, we could build a respective preference graph for different user segments. For example, for one particular user segment C , the corresponding preference graph can be represented as G C = V , E , W C , where candidate content items V are the same across all user segments, while the preference weights W are different in various segments.

In Web portal content optimization, both content items and user preferences change over time. To capture the dynamics of content items and user preferences, we denote the set of candidate content items at time t ; W ( t ) represents the corresponding matrix of dynamic weights for each of edges, that is, for one edge E ( t ) ij = v i ,v j , the weight of it, W ( t ) C ij , equals the dynamic user preference on item v j over item v i at time t .In particular, we update such dynamic preference as in the segment C during [ t  X  1 , t ], and  X  is the time-decay factor that is used to discount the preferences which happened long time ago. We can tune this parameter based on performance on a validation dataset.

After building this dynamic preference graph, we can employ a PageRank-like algo-rithm to compute the attractiveness scores for each of items at time t , the details of which are shown as Algorithm 1.
 ALGORITHM 1 : Graph-Based Pairwise Algorithms for Content Recommendation
This graph-based algorithm is a straightforward method for dynamic pairwise learn-ing. In the following of this section, we propose a formalized probabilistic modeling algorithm for specifying pairwise learning. In this section, we propose a probabilistic model, the Bayesian hidden score (BHS) model, for dynamic pairwise learning. Some previous studies [Rendle et al. 2009; Tak  X  acs and Tikk 2012] have applied Bayesian methods to obtain personalized ranking and recommendation. However, they are tailored for somewhat stationary pools of contents and users, hence are batch learning methods. Therefore, when a new user or content frequently arrives and leaves the pool, it is not clear how to quickly update the model. In contrast, our new BHS model devise pairwise learning with the following online learning setting in Agarwal et al. [2008], which can effectively deal with the problems in terms of temporal dynamics of user preferences as well as sparser learning samples.
We let r ij ; c denote the observed preference strength between the i th and the j th item with respect to user segment c , such that, under the context of user segment c , Note that, r ij ; c can be specialized in various ways; we can define r ij ; c as the number of sessions where users choose to click the i th item instead of the j th item, which is similar to the graph-based method; we can also use the normalized edge weight in the graph to define r ij ; c .Wefurtherlet r t ij ; c denote the preference value between the i th and the j th item at time t.

We make two basic assumptions for BHS. First, each item i is associated with a hidden score s t i ; c that denotes its intrinsic attractiveness in user segment c at time t; where  X  is the parameter for the condition distribution.

Furthermore, we assume that each hidden score s t i ; c at time t is generated conditioned on the the hidden score s t  X  1 i ; c from the time t-1 such that where  X  is a parameter for the condition distribution.

Figure 3 shows the graphical model for BHS. BHS is a general model that applies to different online learning applications with different data distribution assumptions. In this study, we focus on the most popular distribution, normal distribution, to derive stochastic gradient descent based algorithm for BHS. However, the derivation can be extended to the other popular distributions.

The likelihood function of BHS can be written as follows, where D denote the observed pairwise preferences.

We assume the following normal distributions,
Substituting the density functions of (7) and (8) into (6), taking negative log, and dropping the constant terms, we obtain the following negative log-likelihood function, where  X  =  X   X  .

Our main task is learning the hidden scores s to minimize the objective function in (9). The parameter  X  can be viewed as the weight of prior distribution. In practice, we found that using cross-validation to pre-determine  X  is more efficient and effective than directly learning  X  . Therefore, our final task is We propose a stochastic gradient descent-based algorithm to solve the optimization in Eq. (10). The algorithm loops over all the observations r t ij and updates the hidden scorse by moving in the direction defined by negative gradient. The algorithm is summarize in Algorithm 2. BHS algorithm has two main advantages: (1) it can be easily parallelized to handle large scale data; and (2) it yields a much faster converging speed. Based on experiments in the next section, we can also find that BHS can achieve better performance than graph-based pairwise learning.
 ALGORITHM 2 : Bayesian Hidden Score Algorithm In this section, we design experiments to validate that our proposed pairwise learning approaches can improve the performance of Web content optimization. We first describe the datasets collected from a commercial portal website and evaluation metrics in Section 5.1. Then, we report the results of large-scale evaluations for our proposed pairwise learning approaches compared with baselines in Section 5.2. 5.1.1. Dataset. To validate our proposed pairwise learning approaches, we conduct experiments on the data from two real-world content recommendation modules, the Trending Now module and News module on the Yahoo! portal website (as shown in Figure 1). For the Trending Now module, we collected events in terms of views and clicks from its random learning bucket during ten days from April 1st, 2011 to April 10th, 2011. And, for the News module, we similarly collected events in terms of views and clicks from its random learning bucket during fourteen days from May 1st, 2011 to May 14th, 2011. For each of these two modules, the pool of candidate items may change multiple times during each day. To protect privacy, all the users are anonymized in this data set.

As introduced in Section 3.1, in the random learning bucket , candidate content items, that is, queries in Trending Now or news articles in News, are randomly selected and they are displayed at all positions with equal chance. An event records a user X  X  action on the served content items, which is either  X  view  X  X r X  click  X . More specifically, we represent each event e as a set of tuples: where u denotes the user; t represents the time stamp for this event; i is the served content item; p denotes the position at which the content item i is displayed (note that there are ten positions on both Trending Now and News module, but they are organized differently); a represents the action which is either view or click .

For the Trending Now dataset, there are a total of hundreds of millions (  X  10 8 )of events with multiple millions of unique users; while for the News dataset, there are in total tens of millions (  X  10 7 ) of events with multiple millions of unique users. The size of Trending Now dataset is about five times larger than that of News dataset. And, the average sizes of candidate content pools per five minutes for both datasets are comparable. 5.1.2. Evaluation Metrics. To evaluate the performance of our online recommendation models, we simulate the online learning procedure, as illustrated in Figure 2. In par-ticular, all pointwise models at time t are updated based on the click/view samples during the latest 5-minute interval [ t  X  1 , t ]inthe random learning bucket ; the up-dated models are then applied to compute relevance scores for the candidate items and recommend those with higher scores during the next time interval [ t , t + 1]. Similarly, the pairwise models at time t are updated by extracting new preference evidences from the click/view samples during [ t  X  1 , t ]inthe random learning bucket ; the updated pairwise models are then applied to recommend the candidate items during [ t , t + 1]. For the clicks that actually happened during [ t , t + 1] in the random learning bucket , the evaluation metric is computed by comparing these actual clicks with the predicted ranking. Intuitively, a good modeling approach should lead to high correlation between the actual clicks and the predicted ranking.

More specifically, for those clicks that actually happened at Position 1 in the random learning bucket , we define precision i as the number of the clicked items that are ranked at Position from 1 to i according to the model prediction. Table I illustrates two examples for such precision computation. Note that the reason we only use the actual clicks at Position 1 for evaluation is that the clicks on other positions might need to be counted with more weight due to position bias, so it is more straightforward to use clicks at Position 1 for evaluation. To protect business-sensitive information, we report only relative precision, instead of precision itself.

In the following experiments, we evaluate the proposed pairwise learning methods compared with the baseline pointwise models on both Trending Now and News data sets. By following the online learning simulation procedure during the 10-day period for Trending Now module and 14-day period for News module, the overall precision values are computed respectively by aggregating the precision of recommendation in each of the 5-minute time intervals. 5.1.3. Compared Methods. To evaluate the pairwise learning methods for Web content optimization, we compare the performance of the following methods.  X  EMP (baseline). In this method, we adopt the estimated most-popular model as introduced in Section 3.2.  X  EMP-seg . In this method, we incorporate personalization in terms of user segmenta-tion into EMP (Section 3.3), that is, we train EMP models for different user segments separately.  X  Graph . In this method, we use the graph-based pairwise approach and PageRank-like learning method, as described in Section 4.2.  X  Graph-seg . In this method, we incorporate personalization in terms of user seg-mentation into graph-based pairwise approach, that is, we learn pairwise models for different user segments separately.  X  BHS . In this method, we use the Bayesian hidden modeling approach as introduced in Section 4.3.  X  BHS-seg . In this method, we use the Bayesian hidden modeling approach with incorporated personalization in terms of user segmentation, that is, we learn the
Bayesian hidden models for different user segment separately.  X  PCS . In the following experiment, we will compare our proposed methods with a state-of-the-art method, that is, Personalized Click Shaping [Agarwal et al. 2012], which targets for personalized online recommendation without relying on pairwise learning.
 Note that, we applied the same user segmentation for EMP-seg , Graph-seg ,and BHS-seg . 5.2.1. Performance for Online Content Recommendation. We now compare the performance of our pairwise learning methods with other baselines for Web content optimization. We conduct experiments on both the data sets collected from Trending Now module and News module.

Figure 4(a) and 4(b) demonstrate the relative precision gain of those pairwise learn-ing methods without personalization (i.e., Graph and BHS ) compared with the base-line EMP model. These experiments are conducted on the Trending Now dataset and News dataset, respectively. From these figures, we can find that the pairwise methods, Graph and Bayesian , can outperform the baseline pointwise model EMP on both datasets. Furthermore, the Bayesian pairwise method, that is, Bayesian , can reach much better performance than straightforward graph-based pairwise method, that is, Graph .

Figure 5(a) and 5(b) demonstrate the relative precision gain of EMP-seg together with those pairwise learning methods with personalization (i.e., Graph-seg and BHS-seg ) compared with the baseline EMP model. From these figures, we can find that, while personalization can bring significant performance gain for pointwise models, pairwise learning approaches can provide even more benefit to personalized online recommendation. In particular, after applying pairwise learning methods combined with personalization in terms of user segmentation, we can observe that Graph-seg achieves about 21% and 126% precision gain on Position 1 over Graph on the Trending Now dataset and News dataset, respectively, and the BHS-seg achieves about 19% and 112% precision gain on Position 1 over BHS on the Trending Now dataset and News dataset, respectively. These figures also illustrate that the formalized Bayesian model can reach better performance than the graph-based pairwise learning method.
Note that applying pairwise learning methods can improve recommendation perfor-mance on the News dataset much more than on Trending Now dataset. We hypothesize one of the major reasons is that the size of the News dataset (  X  10 7 ) is much smaller than the Trending Now dataset (  X  10 8 ); it suffers more from sparse learning samples, and pairwise learning methods can significantly reduce the effect of this problem. We also consider this the reason that pairwise methods can benefit personalized recom-mendation more, since each user segment has fewer learning samples than the whole dataset. Using News dataset as an example, as shown in Figure 4(b) and 5(b), the relative precision gain of BHS-seg over EMP-seg , about 69%, is a bit larger than the gain of BHS over EMP , about 42%. We can observe the similar results on the Trending Now dataset or using a graph-based method instead of BHS method.

In addition, we perform another experiment to compare the performance of our proposed pairwise learning methods with one state-of-the-art online recommendation method (i.e., PCS [Agarwal et al. 2012]). Table II reports the relative precision gain of BHS-seg over PCS . From this table, we can find that BHS-seg can outperform this personalized click shaping method. In particular, the relative precision gain by BHS over PCS is 2 . 32% at position 1 and 1 . 35% at position 10. The t-test result shows that the improvement are statistically significant (p-value &lt; 0.03). It implies that, though PCS has introduced very accurate modeling for personalization, it does not leverage the preference information between different content items, which plays a more important role in Web content optimization. Actually, in real commercial content recommendation system, 1% increment in terms of click precision is already a big improvement, which in practice can drive additional millions of clicks per day. 5.2.2. Robustness to Sparse Learning Samples. To verify that our new pairwise learning methodology is more robust to the problem of sparse learning samples, we conduct experiments to compare the precision decline against decreasing amount of learning samples for different recommendation models. Specifically, we reduce the amount of learning samples by randomly picking varying percentages of the whole dataset and evaluate the performance of different models on the reduced dataset.

Figure 6 reports the relative precision decline for both pointwise model ( EMP-seg ) and pairwise learning method ( Graph-seg and BHS-seg ) against varying percentages of learning samples. From the figure, we can find that the performance of EMP-seg decreases drastically even when we remove only 20% learning samples, while Graph-seg and BHS-seg stays higher performance until we remove more than 80% learning samples. Based on these results, we can find that pairwise learning methods are more robust to sparse learning samples than pointwise models, which indicates that pairwise learning methods are a better choice for personalized recommendation, since there are sparser samples for learning personalized models. 5.2.3. Effects of Dynamic Preferences. As mentioned before, we have modeled the tempo-ral dynamics of user preferences in both graph-based and Bayesian pairwise learning algorithms. In this experiment, we show the influence of modeling temporal dynam-ics of user preferences on the performance of these two algorithms. In particular, we compare the performance of Graph-seg and BHS-seg modeling temporal dynamics of preferences to the performance of corresponding algorithms without modeling such temporal dynamics, respectively. With no consideration of temporal dynamics of user preference in Graph-seg , we can merely set  X  = 1 in Eq. (2), while in BHS-seg ,we can employ a simplified BHS model, as shown in Figure 7.

Figure 8 demonstrates relative precision gain of Graph-seg and BHS-seg modeling temporal dynamics of user preferences compared with the same algorithms without modeling such temporal dynamics over the two datasets, respectively. From the figure, we find that modeling temporal dynamics of user preference can give rise to increasing performance for both pairwise learning algorithms, and the t-test shows that the dif-ferent is significant (p-value &lt; 0.05). We can also find that BHS-seg is more sensitive to temporal dynamics of user preference. All of these imply that it is necessary to model the temporal dynamics of user preferences into the pairwise learning for Web content optimization. 5.2.4. Effects of Position-Sensitive Preferences. We now investigate the effects of apply-ing position-sensitive preferences on pairwise learning methods. As mentioned in Section 4.1, we employ all preferences without considering the difference in click po-sition in our pairwise learning methods. However, many previous works have stud-ied position-sensitive preference extraction (e.g.,  X  skip-above  X  X nd X  skip-next  X  strate-gies [Joachims et al. 2005]), which are effective in the context of ranking for search. In this experiment, we study if such position-sensitive preferences are effective as well for Web content optimization on Web portals. Specifically, we compare the performance of our proposed pairwise learning algorithms using all preferences with the same al-gorithms using only preferences based on  X  skip-above  X  X nd X  skip-next  X  strategies.
Figure 9 illustrates relative precision gain of Graph-seg and BHS-seg using only preferences based on  X  skip-above  X  X nd X  skip-next  X  strategies over the same algorithms using all preferences. From the figure, we can find that using merely preferences generated by  X  skip-above  X  X nd X  skip-next  X  strategies cannot increase the performance of content optimization but even results in declining recommendation performance. We hypothesize the reasons. First, unlike a long ranked list of search results, one content module usually occupies a small area of the portal webpage, the content items in which could be all browsed with quick scan; second, as shown in Figure 1, content modules may have more complex organization for presentation rather than an ordered list; moreover, using only preferences based on  X  skip-above  X  X nd X  skip-next  X  could cause insufficiency of learning samples. Therefore, traditional position-sensitive preference extraction in search may not be effective in content optimization on Web portals. Exploring better methods for position-sensitive preference extraction is not the focus of this work; we leave this topic as future work.

In summary, our experimental results have demonstrated that (1) pairwise learning methodology can achieve much better performance for online recommendation than pointwise modeling methodology; (2) pairwise learning methods are more robust to sparse learning samples than pointwise models, which indicates its advantage to be applied for personalized recommendation since there are sparser samples for learning personalized models; (3) temporal dynamics of user preferences are important factors to improve pairwise recommendation models; (4) straightforward position-sensitive strategies, popular in Web search, are not quite effective to select preferences that are more critical to build pairwise recommendation models. To complement the empirical findings in the previous section, this section aims at pro-viding theoretical insights that further justify the advantages of pairwise approaches over pointwise ones. To make the discussion concrete and free from notation clutter, we take a more careful look at the EMP method with the simplification of w = 1; the validity of our conclusions should not be affected when w&lt; 1.
 Robustness to Sparse Learning Samples. The first issue with pointwise methods like EMP is the need for large amounts of training data in order to obtain reliable CTR estimates. To see this, consider an item with CTR p , which is estimated by  X  p = c / n in EMP, where c and n are the observed clicks and views of that item in the data. While  X  p is unbiased in the sense that E [ X  p ] = p , standard results from statistics and learning theory (e.g., [Kearns and Vazirani 1994]) imply that the relative error, | p  X   X  p | / p ,ison the order of 1 /
Now suppose we have two items whose CTRs are p 1 and p 2 , and the relative difference is  X  =| p same order as p 1 and p 2 (so that the right recommendation can be made), roughly in the previous section, CTRs are usually quite low, and the relative difference  X  can be small as well. All these factors contribute to the requirement of large data size, and provide insights that predict when EMP is likely to suffer when data is sparse.
In contrast, pairwise methods are able to take advantage of the implicit preference information from clicks, which can be used to refine a recommendation models even in the PageRank-like algorithm indicates the probability a user prefers item j over some attractiveness scores x (  X  ) that is not necessarily the CTR, we can prove that the computed PageRank score s ( i ) will be proportional to x ( i ). Furthermore, how fast the condition number that describes how sensitive s is to errors in the transition matrix [Cho and Meyer 2001]. While it is nontrivial to compare to EMP, preliminary simulation (not reported here) verifies the greater robustness of pairwise methods. Finally, the  X  parameter in Algorithm 1 may also be used to control the bias/variance trade-off in our graph-based method.

Robustness to Inconsistency Caused by Interaction of Displayed Items.. An even more serious problem is the inconsistency of EMP caused by interaction of displayed items. As an example, when a user visits the TrendingNow module and sees a list of recommended queries, she would compare the candidate queries subconsciously and click on the most interesting one (if she decides to click at all). Clearly, the CTR of an item can depend on what other items are displayed in that module; in other words, there is a competition for user attention among displayed items.

Suppose we have two items i and j , whose CTR estimates in EMP are robustly obtained from a large amount of data and satisfy  X  p i &gt;  X  p j . Can we then infer item i is better than j ? The answer is no, unfortunately X  X t may just be the case that i has been displayed with good items more often than j . Thus, a direct comparison between  X  p i and  X  p j in EMP can be misleading, since the critical interaction information is missing. It should be noted that the use of a random learning bucket (Section 3.1) does not eliminate the inconsistency, since an item can be added to or removed from the candidate pool at any moment.

In contrast, pairwise methods do not suffer the same problem. The ( i , j )entryin the transition matrix captures the relative quality between i and j , which is indepen-dent (or at most weakly dependent) of what other items are displayed. Computing the PageRank score from the transition matrix becomes the process of identifying individ-ual items X  quality measure from pairwise ranking results, a problem closely related to the NP-hard minimum feedback arc set problem [Alon 2006]. In this article, we have proposed a new pairwise learning methodology for Web portal content optimization, where the pairwise preferences are extracted based on users ac-tions on content items. With thorough analysis and discussions, we gained a deeper understanding of the advantages of this new methodology over state-of-the-art meth-ods. To apply this pairwise learning approach to real online recommender system, we introduced two specific pairwise learning algorithms, a straightforward graph-based al-gorithm and a more formalized Bayesian modeling one. Experiments on two large-scale datasets, collected from content modules of a real-world portal website, demonstrated that the pairwise learning methods can achieve significant improvement in terms of a precision metric over the baseline pointwise models. Further analysis illustrated that the new pairwise methods can be more beneficial to personalized recommendation than pointwise model, since the pairwise methods are more robust to the problem of sparse learning samples.

In the future, we are interested in exploring more user-behavior-based features to build the pairwise learning methods. We also aim at studying how to better interpret user actions into preference by considering the position bias and users X  browsing habits. Moreover, we plan to explore other common model assumption other than Gaussian for building the Bayesian hidden score model. Last but not least, we will explore how to replace the proposed scoring model by a factorization model.

