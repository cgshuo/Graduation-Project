 It is widely believed that one of the main principles underlying functional organization of the early visual system is the reduction of the redundancy of relayed input from the retina. Such a transforma-tion would form an optimally efficient code, in the sense that the amount of information transmitted to higher visual areas would be maximal. Sparse coding refers to a possible implementation of this general principle, whereby each stimulus is encoded by a small subset of neurons. This would allow the visual system to transmit information efficiently and with a small number of spikes, improving the signal-to-noise ratio, reducing the energy cost of encoding, improving the detection of  X  X uspi-cious coincidences X , and increasing storage capacity in associative memories [1, 2]. Computational models that optimize the sparseness of the responses of hidden units to natural images have been shown to reproduce the basic features of the receptive fields (RFs) of simple cells in V1 [3, 4, 5]. Moreover, manipulation of the statistics of the environment of developing animals leads to changes in the RF structure that can be predicted by sparse coding models [6].
 Unfortunately, attempts to verify this principle experimentally have so far remained inconclusive. Electrophysiological studies performed in primary visual cortex agree in reporting high sparseness values for neural activity [7, 8, 9, 10, 11, 12]. However, it is contested whether the high degree of sparseness is due to a neural representation which is optimally sparse, or is an epiphenomenon due to neural selectivity [10, 12]. This controversy is mostly due to a lack of reference measurement with which to judge the sparseness of the neural representation in relative, rather than absolute terms. Another problem is that most of these studies have been performed on anesthetized animals [7, 9, 10, 11, 12], even though the effect of anesthesia might bias sparseness measurements (cf. Sec. 6).
 In this paper, we report results from electrophysiological recordings from primary visual cortex (V1) of ferrets at various stages of development, from eye opening to adulthood, and of rats at different levels of anesthesia, from awake to deeply anesthetized, with the goal of testing the optimality of the neural code by studying changes in sparseness under different conditions. We compare this data with theoretical predictions: 1) sparseness should increase with visual experience, and thus with age, as the visual system adapts to the statistics of the visual environment; 2) sparseness should be maximal in the  X  X orking regime X  of the animal, i.e. for alert animals, and decrease with deeper levels of anesthesia. In both cases, the neural data shows a trend opposite to the one expected in a sparse coding system, suggesting that the visual system is not actively optimizing the sparseness of its representation.
 The paper is organized as follows: We first introduce and discuss the lifetime and population sparse-ness measures we will be using throughout the paper. Next, we present the classical, linear sparse coding model of natural images, and derive an equivalent, stochastic neural network, whose output firing rates correspond to Monte Carlo samples from the posterior distribution of visual elements given an image. In the rest of the paper, we make use of this neural architecture in order to predict changes in sparseness over development and under anesthesia, and compare these predictions with electrophysiological recordings. The diverse benefits of sparseness mentioned in the introduction rely on different aspects of the neural code, which are captured to a different extent by two sparseness measures, referred to as lifetime and population sparseness . Lifetime sparseness measures the distribution of the response of an individual cell to a set of stimuli, and is thus related to the cell X  X  selectivity. This quantity characterizes the energy costs of coding with a set of neurons. On the other hand, the assessment of coding efficiency, as used by Treves and Rolls [13], is based upon the assumption that different stimuli activate small, distinct subsets of cells. These requirements of efficient coding are based upon the instantaneous population activity to stimuli and need to take into consideration the population sparseness of neural response. Average lifetime and population sparseness are identical if the units are statistically independent, in which case the distribution is called ergodic [10, 14]. In practice, neural dependencies (Fig. 3C) and residual dependencies in models [15] cause the two measures to be different.
 Here we will use three measures of sparseness, two quantifying population sparseness, and one lifetime sparseness. To make a comparison with previous studies easier, we computed population and lifetime sparseness using a common measure introduced by Treves and Rolls [13] and perfected by Vinje and Gallant [8]: where r i represents firing rates, and i indexes time in the case of lifetime sparseness, and neurons for population sparseness. TR is defined between zero (less sparse) and one (more sparse), and depends on the shape of the distribution. For monotonic, non-negative distributions, such as that of firing rates, an exponential decay corresponds to TR = 0 . 5 , and values smaller and larger than 0 . 5 indicate distributions with lighter and heavier tails, respectively [14]. For population sparseness, we rescale the firing rate distribution by their standard deviation in time for the modelling results, and by q we discard bins with no neural activity, as population TR is undefined in this case. TR does not depend on multiplicative changes firing rate, since it is invariant to rescaling the rates by a constant factor. However, it is not invariant to additive firing rate changes. This seems to be adequate for our purposes, as the arguments for sparseness involve metabolic costs and coding arguments like redundancy reduction that are sensitive to overall firing rates. Previous studies have shown that alternative measures of population and lifetime sparseness are highly correlated, therefore our choice does not affect the final results [15, 10].
 We also report a second measure of population sparseness known as activity sparseness ( AS ), which is a direct translation of the definition of sparse codes as having a small number of neurons active at any time [15]: where n t is defined as the number of neurons with activity larger than a given threshold at time t , and N is the number of units. AS = 1 means that no neuron was active above the threshold, while AS = 0 means that all of all neurons were active. The threshold is set to be one standard deviation for the modeling results, or equivalently the upper 68th percentile of the distribution for neural firing rates. AS gives a very intuitive account of population sparseness, and is invariant to both multiplicative and additive changes in firing rate. However, since it discards most of the information about the shape of the distribution, it is a less sensitive measure than TR . The sparseness assumption that natural scenes can be described by a small number of elements is generally translated in a model with sparsely distributed hidden units x k , representing visual elements, that combine linearly to form an image y [3]: where K is the number of hidden units, G is the mixing matrix (also called the generative weights ) and  X  2 y is the variance of the input noise. Here we set the sparse prior distribution to a Student-t distribution with  X  degrees of freedom, with  X  chosen such that the distribution has unit variance. This is a common prior for sparse cod-ing models [3], and its analytical form allows the development of efficient inference and learning algorithms [16, 17].
 The goal of learning is to adapt the model X  X  parameters in order to best explain the observed data, i.e., to maximize the marginal likelihood with respect to G . We learn the weights using a Variational Expectation Maximization (VEM) algorithm, as described by Berkes et al. [17], with the difference that the generative weights are not treated as random variables, but as parameters with norm fixed to 1 , in order to avoid potential confounds in successive analysis.
 The model was applied to 9  X  9 pixel natural image patches, randomly chosen from 36 natural images from the van Hateren database, preprocessed as described in [5]. The dimensionality of the patches was reduced to 36 and the variances normalized by Principal Component Analysis. The model parameters were chosen to be K = 48 and  X  = 2 . 5 , a very sparse, slightly overcomplete representation. These parameters are very close to the ones that were found to be optimal for natural images [17]. The input noise was fixed to  X  2 y = 0 . 08 . The generative weights were initialized at random, with norm 1. We performed 1500 iterations of the VEM algorithm, using a new batch of 3600 patches at each iteration. Fig. 1 shows the generative weights at the start and at the end of learning. As expected from previous studies [3, 5], after learning the basis vectors are shaped like Gabor wavelets and resemble simple cell RFs. In order to gain some intuition about the neural operations that may underlie inference in this model, we derive an equivalent neural network architecture. It has been suggested that neural activity is best interpreted as samples from the posterior probability of an internal, probabilistic model of the sensory input. This assumption is consistent with many experimental observations, including high trial-by-trial variability and spontaneous activity in awake animals [18, 19, 20]. Moreover, sampling can be performed in parallel and asynchronously, making it suitable for a neural architecture. As-suming that neural activity corresponds to Gibbs sampling from the posterior probability over visual elements in the sparse coding model, we obtain the following expression for the distribution of the firing rate of a neuron, given a visual stimulus and the current state of the other neurons representing the image [18]: where R =  X  G T G . Expanding the exponent, eliminating the terms that do not depend on x k , and noting that R kk =  X  1 , since the generative weights have unit norm, we get Sampling in a sparse coding model can thus be achieved by a simple neural network, where the k -th neuron integrates visual information through feed X  X orward connections from input y i with weights G ik / X  2 y , and information from other neurons via recurrent connections R jk / X  2 y (Fig. 2A). Neural activity is then generated stochastically according to Eq. 9: The exponential activation function gives higher probability to higher rates with increasing input to the neuron, while the terms depending on x k and f ( x k ) penalize large firing rates. Fig. 2B shows the mode of the activation probability (Eq. 9) as a function of the total input to a neuron. A simple, intuitive prediction for a system that optimizes for sparseness is that the sparseness of its representation should increase over learning. Since a sparse coding system, including our model, might not directly maximize our measures of sparseness, TR and AS , we verify this intuition by analyzing the model X  X  representation of images at various stages of learning. We selected at random a new set of 1800 patches to be used as test stimuli. For every patch, we collected 50 Monte Carlo samples, using Gibbs sampling (Eq. 9) combined with an annealing scheme that starts by drawing samples from the model X  X  prior distribution and continues to sample as the prior is deformed into the posterior [21]. This procedure ensures that the final samples come from the whole posterior dis-tribution, which is highly multimodal in overcomplete models, and therefore that our analysis is not biased by the posterior distribution becoming more (or less) complex over learning. Fig. 3A shows the evolution of sparseness with learning. As anticipated, both population and lifetime sparseness increase monotonically.
 Having confirmed our intuition with the sparse coding model, we turn to data from electrophysio-logical recordings. We analyzed multi-unit recordings from arrays of 16 electrodes implanted in the primary visual cortex of 15 ferrets at various stages of development, from eye opening at postnatal day 29 or 30 (P29-30) to adulthood at P151 (see Suppl Mat for experimental details). Over this maturation period, the visual system of ferrets adapts to the statistics of the environment [22, 23]. For each animal, neural activity was recorded and collected in 10 ms bins for 15 sessions of 100 seconds each (for a total of 25 minutes), during which the animal was shown scenes from a movie. We find that all three measures of sparseness decrease significantly with age 1 . Thus, during a period when the cortex actively adapts to the visual environment, the representation in primary visual cor-tex becomes less sparse, suggesting that the optimization of sparseness is not a primary objective for learning in the visual system. The decrease in population sparseness seems to be due to an increase in the dependencies between neurons: Fig. 3C shows the Kullback-Leibler divergence between the joint distribution P of neural activity in 2 ms bins and the same distribution, factorized to eliminate (Spearman X  X   X  = 0 . 73 , P &lt; 0 . 01 ), indicating an increase in neural dependencies. The sparse coding neural network architecture of Fig. 2 makes explicit that an optimal sparse coding representation requires a process of active sparsification : In general, because of input noise and the overcompleteness of the representation, there are multiple possible combinations of visual elements that could account for a given image. To select among these combinations the most sparse solution, a competition between possible alternative interpretations must occur.
 Consider for example a simple system with one input variable and two hidden units, such that y = x 1 + 1 . 3  X  x 2 + , with Gaussian noise . Given an observed value, y , there are infinitely many solutions to this equality, as shown by the dotted line in Fig. 4B for y = 2 . These stimulus X  X nduced correlations in the posterior are known as explaining away . Among all the solutions, the ones com-patible with the sparse prior over x 1 and x 2 are given higher probability, giving raise to a bimodal distribution centered around the two sparse solutions x 1 = 0 , x 2 = 1 . 54 , and x 1 = 2 , x 2 = 0 . From Eq. 9, it is clear that the recurrent connections are necessary in order to keep the activity of the neurons on the solution line, while the stochastic activation function makes sparse neural responses more likely. This active sparsification process is stronger for overcomplete representations, for when the generative weights are non-orthogonal (in which cases | r ij | 0 ), and for when the input noise is large, which makes the contribution from the prior more important.
 In a system that optimizes sparseness, disrupting the active sparsification process will lead to lower lifetime and population sparseness. For example, if we reduce the strength of the recurrent connec-tions in the neural network architecture (Eq. 9) by a factor  X  , the neurons become more decoupled, and try to separately account for the input, as illustrated in Fig. 4C. The decoupling will result in a reduction of population sparseness, as multiple neurons become active to explain the same input. Also, lifetime sparseness will decrease, as the lack of competition between units means that individual units will be active more often.
 Fig. 5 shows the effect of reducing the strength of recurrent connections in the model of natural im-ages. We analyzed the parameters of the sparse coding model at the end of learning, and substituted the Gibbs sampling posterior distribution of Eq. 9 with the one in Eq. 10 for various values of  X  . As predicted, decreasing  X  leads to a decrease in all sparseness measures.
 We argue that a similar disruption of the active sparsification process can be obtained in electrophys-iological experiments by comparing neural responses at different levels of isoflurane anesthesia. In general, the evoked, feed-forward responses of V1 neurons under anesthesia are thought to remain largely intact: Despite a decrease in average firing rate, the selectivity of neurons to orientation, frequency, and direction of motion has been shown to be very similar in awake and anesthetized animals [24, 25, 26]. On the other hand, anesthesia disrupts contextual effects like figure-ground modulation [26] and pattern motion [27], which are known to be mediated by top-down and recur-rent connections. Other studies have shown that, at low concentrations, isoflurane anesthesia leaves the visual input to the cortex mostly intact, while the intracortical recurrent and top-down signals are disrupted [28, 29]. Thus, if the representation in the visual cortex is optimally sparse, disrupting the active sparsification by anesthesia should decrease sparseness.
 We analyzed multi-unit neural activity from bundles of 16 electrodes implanted in primary visual cortex of 3 adult Long-Evans rats (5-11 units per recording session, for a total of 39 units). Record-ings were made in the awake state and under four levels on anesthesia, from very light to deep (cor-responding to concentrations of isoflurane between 0.6 and 2.0%) (see Suppl Mat for experimental details). In order to confirm that the effect of the anesthetic does not prevent visual information to reach the cortex, we presented the animals with a full-field periodic stimulus (flashing) at 3.75 Hz for 2 min in the awake state, and 3 min under anesthesia. The Fourier spectrum of the spikes trains on individual channels shows sharp peaks at the stimulation frequency in all states. We measured the response to the signal by the average amplitude of the Fourier spectrum between 3.7 and 3.8 Hz, and defined the amplitude of the noise, due to spontaneous activity and neural variability, as the average amplitude between 1 and 3.65 Hz (the amplitudes in this band are found to be noisy but uniform). The amplitude of the evoked signal decreases with increasing isoflurane concentration, due to a de-crease in overall firing rate; however, the background noise is also suppressed with anesthesia, so that overall the signal-to-noise ratio does not decrease significantly with anesthesia (Fig. 6, ANOVA, P=0.46).
 We recorded neural responses while the rats were shown a two minute movie recorded from a cam-era mounted on the head of a person walking in the woods. Neural activity was collected in 25 ms bins. All three sparseness measures increase significantly with increasing concentration of isoflu-rane 2 (Fig. 5B). Contrary to what is expected in a sparse-coding system, the data suggests that the contribution of lateral and top-down connections in the awake state leads to a less sparse code. We examined multi-electrode recordings from primary visual cortex of ferrets over development, and of rats at different levels of anesthesia. We found that, contrary to predictions based on the-oretical considerations regarding optimal sparse coding systems, sparseness decreases with visual experience, and increases with increasing concentration of anesthetic. These data suggest that the high sparseness levels that have been reported in previous accounts of sparseness in the visual cortex [7, 8, 9, 10, 11, 12], and which are otherwise consistent with our measurements (Fig. 3B, 5), are most likely a side effect of the high selectivity of neurons, or an overestimation due to the effect of anesthesia (Fig. 5; with the exception of [8], where sparseness was measured on awake animals), but do not indicate an active optimization of sparse responses (cf. [10]).
 Our measurements of sparseness from neural data are based on multi-unit recording. By collecting spikes from multiple cells, we are in fact reporting a lower bound of the true sparseness values. While a precise measurement of the absolute value of these quantities would require single-unit measurement, our conclusions are based on relative comparisons of sparseness under different con-ditions, and are thus not affected.
 Our theoretical predictions were verified with a common sparse coding model [3]. The model as-sumes linear summation in the generative process, and a particular sparse prior over the hidden unit. Despite these specific choices, we expect the model results to be general to the entire class of sparse coding models. In particular, the choice of comparing neural responses with Monte Carlo samples from the model X  X  posterior distribution was taken in agreement with experimental results that report high neural variability. Alternatively, one could assume a deterministic neural architecture, with a network dynamic that would drive the activity of the units to values that maximize the image probability [3, 30, 31]. In this scenario, neural activity would converge to one of the modes of the distributions in Fig. 4, leading us to the same conclusions regarding the evolution of sparseness. Although our analysis found no evidence for active sparsification in the primary visual cortex, ideas derived from and closely related to the sparse coding principle are likely to remain important for our understanding of visual processing. Efficient coding remains a most plausible functional account of coding in more peripheral parts of the sensory pathway, and particularly in the retina, from where raw visual input has to be sent through the bottleneck formed by the optic nerve without significant loss of information [32, 33]. Moreover, computational models of natural images are being extended from being strictly related to energy constraints and information transmission, to the more general view of density estimation in probabilistic, generative models [34, 35]. This view is compatible with our finding that the representation in the visual cortex becomes more dependent with age, and is less sparse in the awake condition than under anesthesia: We speculate that such dependencies reflect inference in a hierarchical generative model, where signals from lateral, recurrent connections in V1 and from feedback projections from higher areas are integrated with incoming evidence, in order to solve ambiguities at the level of basic image features using information from a global interpretation of the image [26, 19, 27, 20].

