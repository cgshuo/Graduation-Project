 With the rapid development of science and technology, international technical e x-changes are more and more frequent. As the carrier of scient ific and technological concepts, the translation of technical terms has attracted much attention. It can not only be applied to cross -language information retrieval, but also to bilingual dictio n-ary compilation.
 These methods cannot deal with out -of -vocabulary (OOV) terms, which is the focus of this paper. Previous work on OOV term translation mainly makes use of the cha r-acteristics of terms to extract some new features and c ombine them into the traditional statistical machine translation (SMT) framework. The new features include the cha r-acter similarity between Japanese and Chinese[3], the part -of -speech (POS) sequence similarity between Chinese and Korean[4], the morphologic al correspondence b e-tween English and Chinese[5], the phonic correspondence between English and Jap a-nese katakana[6] .
 information to improve term translation accuracy, and the semantic relations within the term are seldom considered. However, such semantic information plays an impo r-tant role for lexical reordering and word selection in term translation. For example, "  X  X  X  (umbrella)  X  X  (automatic)  X  X  (bagging)  X  (machine)" is transla ted into "automatic umbrella bagging machine" by the NiuTrans SMT system[7]. But if we know that "  X  X  (automatic)" depends on "  X  X  (bagging)", then the words in the translation should be reordered and adopts the preposition structure as " automatic bagging mach ine for umbrella " . Another example is "  X  X  X  (cutting)  X  X  X  (tool)". This term is translated into "cut tools" by NiuTrans, but through semantic analysis we can see that the semantic relationship between "  X  X  X  (cutting)" and "  X  X  X  (tool)" is pro p-erty -host instead of pat ient -event. So this term should be translated into "cutting tools".
 as an additional feature to improve the translation performance [8] . However, there are too many types of semantic relationships in the translation of sentences and it is diff i-cult to define them in a uniform framework . In contrast, the semantic relationship type s with in terms are much less and more specific. Besides , the h ead word of a term is always the last word, which also reduced the difficulty of analyzing terms. Ther e-fore the dependency and semantic analysis result of terms can be more accurate than sentence s, and the term semantic structure will be helpful for term translation. term semantic analysis. First we use word s , part of speech (POS) tags , word distance s , word contexts and the first sememe of a word in HowNet [9] as features to tr ain a dependency analysis model by SVM . The model is used to identify dependencies embedded inside a term. A CRF model is used afterwards to incorporate the depen d-encies and acquire the semantic structure of the Chinese term. Next, three semantic -based fea tures (lexical reordering feature , word selection feature and POS selection feature) are extracted and integrated into the phrase -based SMT translation system. Experimental results show that our method is effective.
 nese -English term translation system. In section 3 we introduce the Chinese term semantic analysis method. In section 4 the three features based on semantic structure for term translation are described. Experimental results are shown in section 5. Finally, we draw conclusions in section 6 .
 The framework of the Chinese -English term translation system is shown in Figure 1. In the pre -processing stage, Chinese word segmentation and POS tagging are pe r-formed. Then the labelled term is input to the term semantic analysis module, which is divided into two parts. First ly, the dependency analysis module identifies the d e-pendency relationships within the term as shown in figure 2. tween each two dependent words as shown in Figure 3. tran s lation. On the basis of the semantic structure within the term, three additional features for lexical reordering , word selection and POS selection are extracted through matching the semantic template library. Then the new features are integrated into the SMT model together with the traditional machine translation features to achieve the optimal translation. In order to use semantic structure to improve Chinese -English term translation, we should analy ze the Chinese terms in semantic level. However, existing dependen cy analysis tools like Stanford p arser 1 do not perform well on Chinese terms. This is b ecause Chinese term s have some special characteristics such as (1) there are many out -of -vocabulary words in terms; ( 2 ) most te rms are noun phrase s without head verbs; (3) there is few appropriate corpora designed for terms. Due to the above re a-sons , a general parser is incapable of dealing those dependencies in a term. In order to solve the se problems, we propose a term semantic analysis approach in this paper. 3.1 Dependency Analysis Based on SVM Through analyzing the characteristics of Chinese terms, we select the following cha r-acteristics to train the SVM based dependency analysis model: information as basic features. degree among words in a term. Total 643,908 term s are computed for mut ual inform a-tion. presenting the semantic categories of a word . First sememe of two words can be used to compute their semantic relations.
 in the term and returns a real value. This value indicates the probability that there is dependency between the two words. Therefore, each word w i in the term is scanned from left to right and the word with highest valu e returned by SVM is selected as the word that w i depends on. According to the dependency axiom, the re should be no cross dependen cy , so the algorithm performs backtracking until there is no interse c-tion. 3.2 Semantic Analysis Based on CRF Th r ough analyzing th e characteristics of technical terms, this paper defined 14 types of semantic relationships as shown in Table 1 and two syntactic level relationships which include the structure of "  X  (of)" and the structure of "  X  (with)". In order to reflect the semantic re lationships between words inside a term, we further divide the relationship type "property -host" into seven subtypes, namely "measurement", "a p-pearance", "situation", "nature", "quantity", "category" and "function".
 lected features are shown in table 2.
 Traditional statistical machine translation methods use the source -channel mod el, which is shown in formula 1. It allows an independent modelling of target language mula 3: we obtain formula 4 : tures based on the semantic st ructure of the Chinese term to improve the lexical reo r-dering , word selection and POS selection in the term . This section will describe the features in detail. 4.1 Lexical Reordering Feature This feature aims at modelling the influence of semantic relationship s on the order of words within the scope of a phrase. Suppose there is a Chinese phrase c and the corr e-sponding English phrase e , we calculate the lexical reordering probability between c and e . This probability is estimated through the semantic relationsh ips of the word pairs. If there are N dependent word pairs, then we examine the word alignment and versed order to construct set R 2 . And the lexical reordering probability can be co m-puted with formula 5. that w 1 and w 2 has straight order when they have a semantic relationship of r . The third component in the numerator refers to the number of words whose dependent word is out of the scope of the current phrase.  X  is a scaling fac tor and is empirically set to 0.1. If c has only one word, then we set the probability to a co nstant 1  X  . shown . ( , , ) c w w r is the total frequency. Through the formula we get the lexical reordering relationship of " function " , then the corresponding English part of the word pair has the probability of 83.81 percent to be in straight order.
 4.2 Word Selection Feature This feature aims at modeling the influence of semantic relationships on word sele c-their corresponding translations ( t 1 | t 2 ) if they have the semantic relationship of r . The probability is st ored in the word selection template as follows : puted by maximum likelihood estimation. We give some examples of word selection template in figure 5 .
 word pair "  X  X  X  |  X  " has higher probability to be translated into "storage | box". Ho w-ever, with the above templates, if we know that the semantic relationship between "  X  translated into "for storing | box".
 calculate the word selection probability between c and e . This probability is estimated through the word pairs with semantic relationships. If in the Chinese phras e c , word which matches a word selection template, then we use the probability in the template as the translation probability of the word pair. We add all the N probabilit ies whic h match a word selection template as the word selection probability of the phrase c . Formula 7 shows the calculation. If c has only one word, then we set the probability to a constant 2  X  . 4.3 POS Selection Feature Because many words in technical terms do not appear frequently in the corpus, so it may be difficult to match the template if we follow the template style in section 4.2. To solve this data sp arseness problem, we use POS sequence instead of the word itself in the POS selection template . Suppose there is a Chinese word pair ( w 1 | w 2 ) , we ca l-c u late the probability of their corresponding POS ( POS 1 | POS 2 ) if they have the s e-mantic relationship of r . The probability is stored in the POS selection template as follows : also computed by maximum likelihood estimation. We give some examples of POS selection template in figure 6.
 of "function" then the probability of its corresponding English POS sequences being "JJ | NN" is 0.785 , and "NN | NN" is 0.21 5 .
 the candidate English translation has a POS sequence ( POS 1 | POS 2 ) and matches a POS selection template, then we use the probability in the template as the translation probability of the word pair. We add all the N probabilit ies which match a POS sele c-tion template as the POS selection probability of the phrase c . Formula 8 shows the calculation. If c has only one word, then we set the probability to a constant 3  X  . State Patent Office of China to extract the templates. Our trained SVM model and CRF model are applied to perform semantic analysis on these terms. The Stanfo rd postagg 2 is applied for POS tagging a nd GIZA++ is applied for word alignment. In this section, we describe the experiments which we carried out to test the perfor m-ance of the improvements presented in the previous section s . 5.1 Data Setup A. Data Setup for Term S emantic Analysis Our experiments are carried out on 642,908 terms extracted from patent documents. The term dependency analysis model and the semantic analysis model are trained with 3000 manually labelled terms and we choose 238 terms as a test ing corpus. Each term has an average length of 5.07 words.
 B. Data Setup for Term Translation Our term translation experiments are carried out on the 45 1 , 5 00 terms mentioned in the above section. Table 3 shows some statistical characteristics of the corpus f or term translation. terms are tokenized, lowercased and POS tagged by the Stanford tool. The GIZA++ tool is used to perform bilingual word alignment, and NiuTrans is taken as the bas e-line system.
 5.2 Results A. The result of semantic analysis. We build two baseline systems for comparison. In the first system, all words depend on the head word in the term. In the second system, all words depend on the right nearest neighbour. Table 4 gives the performances of the baseline systems and our systems with "basic feature"(system1), "basic feature + mutual information" (sy s-tem2)and "basic feature + mutual information + first sememe in HowNet" (system3). Word pair accuracy ( wpa p ) and term accuracy ( ta p ) are used to evaluate the system s  X  performance s. W ord pair accuracy is calculated by formula 9 , and term accuracy by formula 10 . The results are shown in table 4. number of correct terms and t c is the total number of terms.
 38.11% higher than baseline1, which indicates that the probability of dependency between nearest words is better than that between a word and its head word. On the other ha nd, the word accuracy and term accuracy of system2 increase by 1.19% and 4.38% over system1 respectively. Therefore mutual information is a good measure to identify the strength of association between two words. However, due to the large number of unknown words, the effect is not obvious. After adding the feature of first sememe in HowNet, the word pair accuracy and term accuracy have increased 5.3% and 9.76% respectively, which shows that the interdependence between two words highly depends on their semant ic. We can also see that the accuracy of word pairs is nearly 80% , and the lexical reordering template s, word selection template s and POS selection template s are extracted on word pair level, which can guarantee the accuracy of the templates.
 B. The result of term translation . First ly , we will determine the values of 1  X  , 2  X  and 3  X  mentioned in section 4 . Ta k-experiments with diff er ent value s of 1  X  varying from 0 to 1 on the development set , and the result is shown in figure 7. cided by the same method. 2  X  is set to 0.2, and 3  X  is set to 0.5.
 systems: NiuTrans(baseline), "NiuTrans + lexical reordering feature "(system1), "N i-uTrans + word selection feature"(system2), "NiuTrans + POS selection fe a-ture"(system3), and "NiuTrans + lexical reordering feature + POS selection fe a-ture"(system4), and "NiuTrans + lexical reordering feature + word selection feature + POS selection feature"(system5) .W e use BLEU and NIST for evaluation. Experime n-tal results are shown in table 5. In order to describe the experiment more clearly , we us e f 1 , f 2 and f 3 to represent the lexical reordering feature, word selection feature and POS selection feature.
 lexical reordering feature, the BLEU score increased by 0.85 percent . However, ad d-ing the word selection feature makes the BLEU score improve d by 0.32 percent . But using the POS selection feature , the BLEU scor e improves 0.76 percent , because the POS template s are easier to be matched than the word template s . So we add the word selection feature and lexical reordering feature together, and the system performance is improved by 1.12 percent. Final ly we add the th ree feature s all together, and the BLEU score increased by 1.58 percent. This proves that semantic information plays a positive role in term translation.
 into "cake music decorative card" by the baseline system. B ut according to the lexical reordering templates, when the semantic relationship between word pair (  X  X  X  |  X  ) is "category", the probability of inversed order is higher than that of straigh t order. Therefore after adding the semantic features it is translated into "music decorative card for cake". Another example, "  X  X  X  X  X  X  X  "(novel decorative light) is translated into "novel decorate light" by the baseline system. But according to the POS select ion templates, when the semantic relationship between word pair (  X  X  X  |  X  ) is "category", the probability of POS sequence "JJ NN" is higher than that of "VB NN", therefore the system after adding semantic features translated it into "novel decorative light". C . Error Analysis .
 By analyzing the experimental results of semantic analysis, we find that the main reasons that lead to the errors in semantic analysis are: (1) word segmentation error; (2) many words in terms are quite difficult to understand even for h uman beings. Moreover, the boundaries between some semantic relation ship s are not clear.
 mantic analysis errors which are produced by the above work; (2) the type s of sema n-ti c relationships we defined in this paper cannot co ver all the internal relationships of terms. In this paper, we presented a Chinese -English term translation method based on s e-mantic structure . We use a SVM model with features of mutual information and the first sememe in Hownet for dependency analysis, and then use a CRF model for s e-mantic analysis. Then we extracted three features on the basis of term semantic stru c-ture and integrated them into the phrase -based statistical machine trans lation fram e-work. Experimental showed the effectiveness of the semantic analysis method as well as the term translation method, which illustrates that the internal semantic structure of terms is important information for term translation. This paper i s funded by National Key Technology R&amp;D Program of China ( 2012BAH14F0 5) .

