 The concept of Web 2.0 is characterized by community-based collaboration and infor-mation sharing [Ankolekar et al. 2007]. Wikis are probably some of the most repre-sentative examples following this trend, and one of the best known among them is Wikipedia, the largest free online encyclopedia. Authored by a broad community of volunteers, Wikipedia takes benefit from the Web 2.0 principles to harness the collec-tive intelligence of its contributors.
 The organized knowledge accumulated in Wikipedia aroused the interest of the Semantic Web community. When considering categories as classes and articles as class instances, the encyclopedia appears as an inherent taxonomic system [Voss 2006], opening a wide range of potential applications. A further step, consisting in incorporating explicit semantics into the Wikipedia link system, led to the Semantic MediaWiki project [V  X  olkel et al. 2006], designed to combine wikis and Semantic Web technologies to make the knowledge accessible to machines (e.g., agents, services) be-yond mere navigation.

Since its launch in 2001, Wikipedia has grown at a tremendous speed and counts more than 3,500,000 articles for the sole English version, 1 with a quality sometimes comparable to that of editorially compiled encyclopedias [Giles 2005]. This success and this surprisingly high quality are believed to be due to the famous  X  X iki way, X  charac-terized by its openness, its collaborative nature, and its absence of hard restrictions or constraints. However, it has been surprisingly reported that 80% of the articles were in fact edited by only 10% of the contributors [Goldman 2010; Zlati  X  c et al. 2006]. It appears that although the  X  X iki way X  was supposed to easily attract new contributors, the huge task of building and maintaining the enormous Wikipedia knowledge base is the work of a very limited number of contributors.
 The reasons that can possibly explain the lack of contributors seem to be multiple. A sociological point of view [Swartz 2006] pointed out the lack of reward resulting from a contribution, and proposed to set up a reputation mechanism similar to those exist-ing for eBay or Amazon.com [Wales 2004]. It also appeared that contributors might be repelled by the difficulty of adopting the neutral point of view policy 2 required by the encyclopedia. Such considerations are, however, beyond the scope of this article, and we will consider another perspective concerned with the actual difficulty of contribut-ing in an efficient way. Although wiki authoring is full of flexibility and autonomy, creating high-quality articles is not as easy as we may first think. The first obstacle is related to the wiki syntax or the Semantic Web technologies (in the case of the Se-mantic MediaWiki) that may not be familiar to the user. The second obstacle comes from the difficulty of using existing knowledge. For example, how to make sure if a given topic has not already been covered by existing articles when creating this new one, how to find which links should be provided for existing contents, how to determine the categories the given article should be classified into, and how to choose the appro-priate semantic properties to model the relations or attributes of an entity. Missing annotations (such as missing links [Adafre and de Rijke 2005] or missing categories) will affect the knowledge access and reuse, while blind annotations (arbitrary and un-reasonable annotations) will harm the content consistency.

The Wikipedia community is aware of these problems and has planned to launch a project to improve usability for the editing interface for Wikipedia, 3 with the purpose of attracting more contributors. In this article, we describe our proposal, that aims at bringing to the front the  X  X isdom of the crowds X  already accumulated Wikipedia by including different suggestion mechanisms in the editing interface without adding new difficulties to the wiki way. By doing so, we are achieving the goals of 1) im-proving the usability of Wikipedia and lightening the burden of both contributors and administrators; 2) improving the quality of articles, and 3) facilitating the creation of semantic descriptions about entities and making Wikipedia more semantic. A uni-fied recommendation model is proposed and applied to provide the current Wikipedia with three enhancements: link, category, and semantic relation suggestions. Specif-ically, in the proposed solutions, we make full use of the synonym and polysemy fea-tures to allow our link suggestion approach to effectively support the prefix based auto-completion capability as well as retrieve articles semantically related to the query phrase rather than exact title match. The proposed category recommendation algorithm has achieved significantly better results in predicting category values, com-pared with the document classification baseline using the vector space model with the full text of an article as features. Moreover, the results produced for category refine-ment of existing articles are impressive. These were observed from the system X  X  per-formance in recommending missing categories, discovering previously improper cate-gorizations, and categorizing an article into multiple levels of abstractions. Semantic relation recommendation module has also been extensively evaluated on datasets from different domains, which demonstrates the effectiveness and efficiency of the proposed method in property recommendation. Our prototype system, EachWiki, 4 is presented and comprehensive evaluations (including offline and online) are conducted, showing its effectiveness, efficiency and usability.

The rest of this article is organized as follows. In Section 3, we will first present the key features of the encyclopedia that will be used by our proposal. Section 4 will describe our semantic vision of Wikipedia and our proposed solution. A prototype will be presented in Section 5 and evaluated in Section 6. We will investigate the related work in Section 2. Semantic Wikis 5 try to extend the traditional wikis with Semantic Web technolo-gies (e.g., Semantic MediaWiki [V  X  olkel et al. 2006], OntoWiki [Hepp et al. 2006] IkeWiki [Schaffert 2006]). They have an underlying model of the knowledge described in their pages. Such wikis can be used to enable collaborative, community-driven ontol-ogy engineering (e.g., myOntology [Siorpaes and Hepp 2007]). Like Wikipedia, Seman-tic Wikis face the problem of a small number of contributors. Our work is particularly aiming at improving the situation by providing intelligent recommendations directly in the wiki interface. These aspects are widely studied in the Semantic Web community. DBpedia 6 is one of the most prominent examples of modeling Wikipedia as an RDF graph, consider-ing Wikipedia articles as instances, their categories as concepts and the associated infobox items as descriptions of their relations and attributes. The Resource Descrip-tion Framework (RDF) is a family of World Wide Web Consortium (W3C) specifications originally designed as a metadata data model. RDF is a standard model for data in-terchange on the Web. You can refer to http://www.w3.org/RDF/ for details.
Due to its domain independence and wide coverage, Wikipedia has also been used to compute semantic relatedness. WikiRelate! [Strube and Ponzetto 2006] was the first work to follow this idea, and ESA [Gabrilovich and Markovitch 2007] went further. Both methods used the full text of articles as features, which resulted in poor efficiency for online recommendation tasks.

Another related work [Milne 2007] proposed to calculate relatedness by consider-ing only Wikipedia structure, which achieved results comparable to ESA. We follow this principle and combine it with other lightweight semantic features to deal with different recommendation tasks efficiently. To the best of our knowledge, no tightly integrated solution has been proposed to han-dle three suggestion tasks together in a unified way: links, categories and semantic relations.

Adafre and de Rijke [2005] addressed the problem of missing links, but only concen-trated on improving the existing link structure and was not integrated into the author-ing interface. Other related work includes several Wikipedia search engines. However, they only support prefix search over article titles, as mentioned in Section 4.2.1, and do not provide semantic search capabilities. Existing document classification approaches are not proper for the category recommendation task due to their poor effectiveness and efficiency when dealing with large-scale category systems [Liu et al. 2005]. Oren et al. [2007] compared both classification-based and cooccurrence-based approaches for semantic relation recommendation, and concluded that classification-based meth-ods are more suitable for recommendation tasks of large scale but low complexity.
In this work, we extend our previous effort [Fu et al. 2007] as follows. First, we add a semantic relation recommendation module to boost the development of a semantic version of Wikipedia. Furthermore, we model the three recommendation tasks under a unified framework, and finally conduct extensive experiments to comprehensively evaluate the proposed solutions. In this section, we introduce the different Wikipedia features that will be useful for our proposed semantic services. Figure 1 shows them in an example.
  X  X eonardo da Vinci X  for the Wikipedia entry http://en.wikipedia.org/wiki/Da_ Vinci .
 as the definition of the topic entity. For example, the definition of the article  X  X eonardo da Vinci X  is  X  Leonardo di ser Piero da Vinci (April 15, 1452 C May 2, 1519) was an Italian polymath: painter, sculptor, architect, ... X . The definition features denote the classes to which the described entity belongs. Here, the features are:  X  X talian poly-math, X   X  X olymath, X   X  X ainter, X  etc.
 or outgoing links (entries that the current article links to). They form an implicit se-mantic network and are used to navigate Wikipedia. In the wiki code, a wikilink is written between two double brackets  X  X [ X , like  X  X [Helen Gardner (art historian) | Helen Gardner]] X . Note that we ignore external links which point to Web pages outside Wikipedia. In the rest of this article,  X  X ink X  means  X  X ikilink X  unless otherwise specified.
 article that transfers to an equivalent entry. For example,  X  X a Vinci X  redirects to the article  X  X eonardo da Vinci. X  The emphasized phrase (bold phrase) in the definition is a self-reference to the topic entity.  X  X eonardo di ser Piero da Vinci X  is the full name of  X  X eonardo da Vinci. X  An Anchor Text is the name of a wikilink that is visible on the page. For  X  X [Leonardo da Vinci]] X  and  X  X [Leonardo da Vinci | Da Vinci]] X , the anchor texts are, respectively,  X  X eonardo da Vinci X  and  X  X a Vinci. X  Redirects, emphasized phrases, and anchor texts build up the synonym features of an article.
 phrase) or signs to have multiple meanings. In Wikipedia, polysemy is represented in form of disambiguation pages. A disambiguation page links to different articles that could use the same title. From the page  X  X a Vinci (disambiguation), X  we can see that  X  X a Vinci X  might refer to an Italian Renaissance polymath or an Italian sculptor. Thus,  X  X a Vinci X  serves as a disambiguation feature for both articles.
 are usually noun phrases and most of them represent the classes to which the current article X  X  topic entity belongs. We heuristically consider them to represent classes if heads of their names are plurals. For example,  X  X talian civil engineers X  is a class for  X  X eonardo da Vinci, X  while  X 16th century in science X  is not. We can extract  X  X talian civil engineers X  and  X  X ngineers X  as category features .
 topic entity. The section headings are the most representative identifiers among them. For example, the article  X  X eonardo da Vinci X  has  X  X ife X  and  X  X elationships and influ-ences X  as section headings.
 entity. For example, the article  X  X eonardo da Vinci X  has an infobox containing fields common to  X  X erson X  entities, such as  X  X ationality X  and  X  X irth name X . The former has a value in the wikilink form of  X  X [Italy | Italian]], X  associating  X  X eonardo da Vinci X  with  X  X taly X  through the  X  X ationality X  relation. The latter can be regarded as an attribute of Leonardo da Vinci with the text value  X  X eonardo di ser Piero da Vinci. X  Our vision can be summarized in two main directions that we believe to be able to bring new enhancement possibilities. (1) Exploit the existing Wikipedia elements to regulate and/or enrich the Wikipedia (2) Automatically extract semantic information from existing Wikipedia pages to ex-
When looking further into the Wikipedia elements, we realized that they were not independent from the others, as shown in Figure 2. In the context of three recommen-dation extensions proposed in this article, link completion underlies all others, while semantic relation extraction partially depends on the results of category refinement.
Therefore, the provision of the semantics reuse in our approach should follow the or-der: links, categories, semantic relations, which is also the order we decide to organize the content of the following section. Inspired by collaborative filtering [Resnick et al. 1994], which uses the ratings from other like-minded users to predict the behavior of the current user, we propose a uni-fied classification-based approach to make suggestions from similar resources. This unified algorithm is described in Figure 3, which is composed of two major steps: 1) a classification step to discover resources R ( q ) similar to q according to a given similarity function sim ( q , e )with e being a candidate and 2) a ranking step to find the best suggestions. The general ranking function is given in Equation (1). An annota-tion represents a link, a category or a semantic relation. RankFunc ( a ) measures the accumulation of all contributions from similar resources that share the annotation a . The function contribution ( e , a ) denotes the contribution of the resource e with respect to the annotation a .

Using different measures for contribution ( e , a ), different ranking functions can be defined for different purposes.
  X  Direct Count (DC): contribution ( e , a ) = 1. We assign the same importance to each resource and rank the annotations based on the number of resources that share them.  X  Weighted Count (WC): contribution ( e , a )= sim ( q , e ). The DC mechanism is extended to consider the similarity between resources. Annotations shared by the resources more similar to q are ranked higher.  X  Boosted Weighted Count (BWC): contribution ( e , a )= sim ( q , e )  X | R ( q ) | / Rank e . We add a boost coefficient | R ( q ) | / Rank e , where | R ( q ) | denotes the number of relevant re-sources for the query q and Rank e denotes the ranking position of the resource e , ranked by similarity scores to the current query.

Our experiments show that BWC achieves the best performance and is insensitive to the type of features considered, be it a link, a category or a semantic relation. Hence, it is adopted for the rest of this article. 4.2.1. Link Recommendation. Link suggestion can be seen as a functionality similar to auto-completion provided by Wikipedia in the search field. However, there is one significant difference: the search for each query in our context is more than just prefix matching over page titles. For instance,  X  X WW X  will match the article title  X  X orld Wide Web X  in our approach, thanks to the exploitation of multiple features (title, redi-rect, emphasized phrase, anchor text, and disambiguation).

Inspired by information retrieval techniques, the similarity measure for link rec-ommendation is given in Equation (2), which defines the similarity between a query q (typed phrase) and an article a . Each Wikipedia feature involved can be represented as a vector f and the article is then modeled as a virtual document D a containing these feature vectors. The overall similarity between q and a is the weighted sum of the sim-ilarity scores on all feature vectors. The predefined weight w f assesses the importance of vector f . where score ( q , f ) denotes the tf-idf (term frequency-inverse document frequency) value computed for the query q in the feature vector f . The value increases proportion-ally to the number of times q appears in the vector f (tf) but is offset by the frequency of q in the Wikipedia corpus (idf). 4.2.2. Category Recommendation. We observe that articles sharing the same categories tend to share other types of features defined, that is, infobox properties, definitions, section headings, incoming links and outgoing links. In the case of category recom-mendation, the query considered is the current article. We use the similarity measure defined by Equation (3) to find similar articles along with the categories they belong to. D q and D a represent the virtual document representations of the query article and a resource article respectively, and the similarity between them is the weighted sum of the cosine similarities [Baeza-Yates and Ribeiro-Neto 1999] between their respective feature vectors.
The score function returns the cosine similarity value between vectors f q and f a . 4.2.3. Semantic Relation Recommendation. We also observe that similar articles tend to contain similar semantic relations. According to Auer and Lehmann [2007], a quarter to one third of Wikipedia pages already contain such semantic relations, mainly in the form of infobox items. This fact is the basis of our semantic relation recommendation module. The principle involved is similar to that used for the category recommenda-tion, except that features considered in this case to find articles similar to the cur-rent one are categories, definitions and infobox properties, and best semantic relations will be suggested to the user for the given article. The same similarity function as in Equation (3) is used. Based on the proposed solution, we have built a prototype system called EachWiki, which will be described in this section. The EachWiki interface was built on top of an index able to scale to real Web environ-ments. For the needs of the application, we have crawled the entire English Wikipedia (by June 2007), which represents about 1,800,000 articles and 200,000 categories. Arti-cles were parsed and semantic features were extracted by leveraging OpenNLP. 8 These features were further indexed using the Lucene API. 9 Within EachWiki, suggestion re-sults were retrieved and ranked using Lucene search functionalities.

Being a dynamic environment, it is needed to update the Wikipedia index when a contributor adds an article or modifies an existing one. This operation is time con-suming since global information such as incoming links should be re-collected. This prevents a real-time update at a large scale, so our index is instead periodically up-dated.

As the purpose of the system is to attract new contributors without repelling them due to a complex interaction style, EachWiki functionalities are seamlessly integrated into the existing editing interface. This is made possible thanks to the AJAX tech-nology (and more precisely the Dojo JavaScript toolkit 10 ). EachWiki is developed as a plugin of Semantic MediaWiki 11 which is a free and open source extension to Medi-aWiki by additionally allowing manual semantic annotations in form of RDF triples. MediaWiki 12 is the wiki software that powers Wikipedia. The implementation archi-tecture is presented in Figure 4. As the user inputs a phrase (that can be incomplete) in the Wikipedia editing interface, the EachWiki link recommendation module will be triggered and the suggested results pop up. An example is provided by Figure 5. The input phrase here is  X  X he Microsoft Win X  (EachWiki is configured by default to consider the last three input words) and several propositions of corresponding linked articles are provided. This module aims at  X  X uessing X  what resources the user has in mind when typing and recommending them in real time.

The suggestion list has two columns, the first one being the title (the unique ID) of the article targeted by the proposed link (e.g.,  X  X indows XP X ), whereas the second column being the most frequently used anchor(s) to refer to this article (e.g.,  X  X icrosoft Windows XP Professional X ).

After the selection of a suggestion by the user, the corresponding link annotation is generated and replaces the original input phrase in the text. For instance, after the user selects the  X  X indows XP X  link, the typed phrase  X  X icrosoft Win X  is replaced by the link annotation  X  X [Windows XP | Microsoft Windows XP Professional]] X . If the user presses the  X  X uggest categories X  button located at the bottom of the edit-ing interface, the category recommendation module is activated. An example is given by Figure 6. A ranked list of potentially related categories are provided (e.g.,  X  X ulti-national companies X ), along with examples of articles similar to the current one that belong to this category (e.g.,  X  X onsanto, X   X  X yson Foods, X  etc.).

The user can select one or several of these categories. After validating the informa-tion given in the popup window, the wiki code for the chosen categories will be gener-ated and inserted in the edit area (e.g.,  X  X [Category: Multinational Companies]] X ). When the user presses the  X  X uggest properties X  button, the semantic relation recom-mendation module is triggered and an input window is displayed on the screen, featur-ing a list of suggested semantic relations (e.g.,  X  X ompany Name X ). The user has then the possibility to fill in the values for the relations he wants to add (e.g.,  X  X icrosoft Corporation X ). We can see from Figure 7 that users can choose to input links and/or text values.

Validating and submitting the information in this popup window will cause the an-notations to be generated and inserted into the edit area under the form of typed links supported by the Semantic MediaWiki [V  X  olkel et al. 2006] (e.g.,  X  X [Company Name:= Microsoft Corporation]] X ).

The rendered semantic relations are shown in Figure 8. Each relation is converted into a RDF triple (subject, predicate, object) where the subject is the topic entity of the current article, and the predicate and the object corresponds to the typed link introduced above. For instance, a converted RDF triple is (Microsoft, Company Name, Microsoft Corporation). Such triples are stored in a native triple store integrated in Semantic MediaWiki. Evaluations were separately carried out on the three recommendation modules to as-sess the EachWiki prototype from three points of view: usability, effectiveness, and efficiency. All the experiments were run on a moderate 3.2GHz personal computer with 1.5GB of physical memory. 6.1.1. Automatic Evaluation. We parsed the articles and collected all their links. For each link, we used the anchor text to construct the query and treated the target article as its answer. After filtering the red links (empty links), we extracted 26.5 million valid links and 3 million distinct ones (distinct anchor-target pairs). We classified the data according to two dimensions: (1) the number of words of the anchor text (anchor length as AL), that is, one word, two words, or more than two words; (2) the relation between the anchor text and the target article title, that is, exact match (EM), not exact but prefix match (PM), or neither exact nor prefix match (NP). From the statistics in Table I, we can see that a large proportion of links were annotated with anchor texts that were different from the target page titles (12.4% + 41.3% = 53.7%).

To test the improvement brought by our solution over the existing title matching ap-proach, all the queries (anchor texts) were not only fed to our link suggestion algorithm (LS) but also to a baseline that only titles as features for matching (title matching as TM). The effectiveness of the two systems was measured by using the Mean Recipro-cal Rank (MRR) [Baeza-Yates and Ribeiro-Neto 1999], which is a widely used metric to evaluate retrieval performance when there is only one correct answer for the query. From the results in Table II, we can see that in all cases the simple TM algorithm can work, the LS algorithm had comparable performance. But in the case the query was not the prefix of or was totally different from the title of the target article, the TM strategy did not work at all, whereas the LS algorithm performed well. In the proposed solution, we make full use of the synonym and polysemy features, to allow the LS algo-rithm to find articles semantically related to the query phrase, whether the page title and the query match or not. The fact that the overall MRR of LS (MRRLS) is 0.828 and that of TM (MRRTM) is 0.521 demonstrates the link suggestion algorithm greatly outperforms the title matching algorithm on the whole test data set. Regarding the efficiency of our algorithm, the average popup time was 0.089 seconds.

To further evaluate the auto-completion effect of our system, we constructed the new queries by using the prefixes of the queries containing more than one word from Table I, and considered different query lengths (QL). For each two-word anchor text, we used the first word as the query (QL = 1/AL = 2). For each anchor with more than two words, we respectively used the first word (QL = 1/AL  X  3), and the first two words (QL = 2/AL  X  3). The two algorithms were also compared by the MRR metric. Again, the results in Table III validate the improvements of LS over TM (i.e., comparable when doing exact match, consistently better for prefix match, and still worked well in the not EM nor PM situation). In the case the typed phrases are not completed, our algorithm can accurately predict the target links. The more words typed, the more accurate the results are (i.e., see the MRR values along any of the three columns). 6.1.2. User Evaluation. To test the usability and efficiency of link recommendation, we made a comparison of link annotations with and without the integrated link suggestion functionality. We randomly extracted ten articles from different domains as our gold standard and manually made up some missing links in them. Missing links are links that should be in one article but are not explicitly labeled by users. Each article had two versions, the wiki text version and the free text version (obtained by replacing link annotations with the corresponding anchor texts). Each article had 268.3 words and 37.5 links on average. We invited ten students from our lab to edit the articles according to their free text version. The following three scenarios were evaluated.  X  Scenario 1. The students were asked to author the articles without any link recom-mendation or search utility;  X  Scenario 2. The students were asked to author articles without using the link recom-mendation, but could take advantage of the keyword search functionality provided by Wikipedia to find any existing target article for the typed expression;  X  Scenario 3. The students were asked to author articles with our link recommenda-tion utility.

To eliminate the effects of bias and knowledge transfer, each student was asked to create the wiki text version from the free text version of three different articles in three different scenarios. The results are shown in Table IV. We can see that in Scenario 1, authoring without resorting to the search functionality saves a lot of time but has low accuracy because of the high probability of missing links and error links. In Scenario 2, the search utility increases the accuracy but costs more time. However, with the help of link recommendation in Scenario 3, the students can not only annotate the links accurately but also efficiently finish the authoring. Some further metrics of evaluat-ing link recommendation were recorded: the average time for one recommendation was 0.089 seconds; the frequency of recommendations was 113.7 per article; the effec-tive recommendation rate (the proportion of necessary recommendations) was 32.8%; the MRR of all the recommendations was 0.835. The experiment showed that link recommendation greatly improved the quality of the Wikipedia articles and the us-ability of the system. To evaluate the category recommendation algorithm, we randomly chose 5,515 existing articles from the following domains in the dataset.  X  Company: IBM, Microsoft, McAfee, Casio, etc.  X  Jargon: Support Vector Machine, Web Ontology Language, PHP, etc.  X  Location: Europe, United Kingdom, London, etc.  X  People: Bill Gates, Isaac Newton, Michael Jordan, etc.

The article number (AN) and the average category count (ACC) of each domain are listed in Table V. Before the experiment, the parameters m (the number of top rele-vant articles) and n (the number of categories to recommend) of the recommendation algorithm from Figure 3 needed to be specified. We decided to return the top 10 cat-egories as the recommendation results ( n = 10). The number of top ranked relevant articles ( m ) directly impacted the recall value. However, there were little influence observed when m exceeded 200, while a large m decreased the efficiency of the ranking algorithm. To strive for a balance between recall and efficiency, we set m to 200 in the further experiments. The same m value was applied for semantic relation recommen-dation as well. We used the existing document classification system as the baseline, that is, the full text of an article was used as its feature, and articles were treated as term weight vectors and the similarity was measured by the cosine of the angle between the document and the query vectors.

The retrieval performance was measured by the following metrics: MAP (Mean Av-erage Precision), P@n (Precision at n, for n = 1, 2, 3, 5, 7, 10), R-P (R-Precision), R@10 (Recall of top 10 results), RSMRR (MRR in the rerecommendation mode). In the rere-commendation mode, our evaluation was based on the prediction of deleted category values. For each article, we randomly removed one of its associated categories (the rest of categories were treated as input features of the article) and analyzed whether and at which rank the removed category was rerecommended. Except the evaluation based on the RSMRR metric, other metrics were evaluated in a zero-category mode, where we assumed that articles were newly created. In that case, no category was annotated as the input feature of the recommendation algorithm.

The results of MAP, R@10, R-P, and REMRR are shown in Table V. Figure 9 also shows the histogram of P@n on different datasets. The results validated the effective-ness of our algorithm, which performed better than the baseline based on document classification algorithm in all metrics. From the table, we can see that the precision values (MAP and R-P) and the RSMRR value of category recommendation had little difference across domains, but the R@10 values differed in different domains. The obvious reason is: the ACC values vary by domain but the parameter n is fixed. The results of domains with larger ACC have lower recalls (e.g., People) and vice versa (e.g., Jargon).

Furthermore, we found that incorporating incoming links always helped to improve the quality of category recommendation, and that the result with outgoing links was almost comparable. This would particularly affect newly created articles because of their lack of incoming links. Moreover, the experimental result also encourages the management of red links because they will provide helpful hints ( X  X hat links here X  13 ) to the category recommendation task when the desired article is eventually being cre-ated. The efficiency of our system and that of the baseline were also compared. The average time cost using the proposed category recommendation for an article was 0.355 seconds, whereas for the baseline document classifier, the time needed was 129.2 sec-onds, which is not tolerable in an online authoring process.

In addition to category recommendation for newly created articles, our approach was also able to facilitate the category refinement of existing articles. Scrutiny of the experimental results revealed several interesting findings, which showed that our al-gorithm can achieve the following.  X  Recommend missing categories. When category recommendations are carried out on older versions of some articles, some missing categories are recommended in the list: they were not annotated in the old versions, but have been added in the current ones. For example, in the recommendation list for  X  X ameloft, X  there exist two cate-gories named  X  X ideo game developers X  and  X  X ideo game publishers, X  whose evidence articles consist of  X  X ethesda Softworks, X   X  X lectronic Arts, X   X  X ega, X  etc. These two categories were not associated with  X  X ameloft X  in the previous version of Wikipedia, but they have been added in the current version, which implies that our algorithm successfully found two missing categories in the snapshot of Wikipedia taken a few months earlier. Another example is the category  X  X ompanies listed on the Frank-furt Stock Exchange X  for the  X  X okia X  article, which was also missing in an earlier version of Wikipedia and has been added in the current one.  X  Discover improper categorization. In the experiment on  X  X eb Ontology Language X  in the Wikipedia version of early 2006, for instance, our algorithm failed to suggest the category  X  X ML-based programming languages, X  which is a  X  X orrect X  category for the article according to the ground truth. However, it is not proper to categorize
Web Ontology Language (i.e., OWL) as an XML-based programming language. The elimination of this category in the current version appears to support our viewpoint.  X  Categorize an article to the proper level of abstraction. Taking the article  X  X asio, X  for example, our algorithm recommended both categories  X  X lectronics companies of
Japan X  and  X  X anufacturing companies of Japan, X  with the former ranked higher than the latter. By consulting the category hierarchy, we found that  X  X anufactur-ing companies of Japan X  is a super-category of  X  X lectronics companies of Japan. X 
Compared with the ground truth which contains  X  X lectronics companies of Japan X  as the standard answer, our algorithm, in addition to find its immediate belonging category, can also identify more abstract categories for an article. To evaluate the semantic relation recommendation module, we extracted 7,642 arti-cles with various infobox templates and treated the properties in the infoboxes as the ground truth. The datasets from different domains are listed in Table VI, together with the number of test articles (AN) and the average property count (APC) of each domain. Since the average property count of the articles was larger than the average category count (ACC) in category recommendation, we chose to return the top 20 prop-erties ( n = 20). The experimental results in Table VI and Figure 10 are promising in all domains except the  X  X ity X  domain with a relatively low recall value. The reason is that the average property count (APC) of this domain is relatively large: 45.79 properties per article, whereas we only suggest top 20 of them. In this article, we proposed an integrated solution to address some challenges faced by users willing to contribute to Wikipedia. Our approach is based on a unified algo-rithm to support intelligent recommendations, and three suggestion modules: links, categories and semantic relations are integrated into the framework. These facilities are built on semantic features extracted from Wikipedia articles. A prototype has been designed to embed this solution into the editing interface of Wikipedia. According to our evaluation, this approach has achieved promising results in terms of effectiveness, efficiency, and usability.

Our proposal aims not only at lowering the barriers that prevent users from edit-ing high-quality Wikipedia articles, but also at transforming the encyclopedia into a semantic version by adding semantic annotations. Our future work includes improv-ing the recommendation modules by exploiting more semantic features extracted from Wikipedia articles. Moreover, we plan to help users filling in the semantic relation values to speed up the conversion of Wikipedia into its semantic counterpart.
