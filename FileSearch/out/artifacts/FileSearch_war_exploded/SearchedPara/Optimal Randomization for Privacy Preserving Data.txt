 Randomization is an economical and efficient approach for privacy preserving data mining (PPDM). In order to guaran-tee the performance of data mining and the protection of in-dividual privacy, optimal randomization schemes need to be employed. This paper demonstrates the construction of op-timal randomization schemes for privacy preserving density estimation. We propose a general framework for randomiza-tion using mixture models. The impact of randomization on data mining is quantified by performance degradation and mutual information loss, while privacy and privacy loss are quantified by interval-based metrics. Two different types of problems are defined to identify optimal randomization for PPDM. Illustrative examples and simulation results are reported.
 H.2.8 [ Database Management ]: Database Applications X  Data mining ; H.2.0 [ Database Management ]: General X  Security, integrity, and protection Theory, Algorithms, Security mixture model, randomization operator, individual privacy
In today X  X  world, huge amounts of data are frequently collected, processed and stored. In order to extract useful information from these data, various data mining tools have been developed and used. Meanwhile, there arise serious concerns over individual privacy in data collection, process-ing and mining [4]. [13] predicted the making of a conflict between data mining and privacy. [2] and [10] proposed the concept of privacy preserving (PP) data mining (DM) aimed at alleviating this conflict.

The setting of PPDM can be described by a sever-client model [5]. It consists of a sever S and n clients C 1 , C C . S needs to collect data from the clients to conduct a certain data mining task. For simplicity, we assume that the data includes only one attribute X .Let x i bethevalue of X for C i with 1  X  i  X  n .When X is privacy sensitive, the clients may not want to reveal their individual data and thus create a dilemma between data mining and privacy. There exist two general approaches to solving this dilemma, which are the secure multi-party computing approach and the randomization approach. The former relies on secure multi-party computing protocols that can perform compu-tation without revealing each party X  X  private data [10, 14], while the latter perturbs each individual data and reveal the perturbed data for data mining. In this paper, we focus on the randomization approach.
 The randomization approach was first introduced by [2]. Each client ( C i ) adds noise ( z i ) generated from certain dis-tribution to his/her true data ( x i ) and sends the sum ( y x + z i ) to the server. Denote the randomized data by y = { y i } n i =1 . Empirical results showed that data mining can be conducted with satisfaction using y instead of x .[9] raised concerns over the capability of randomization to pro-tect individual privacy. Clearly, on one hand, randomiza-tion protects individual data and allows data mining; on the other hand, it also results in information loss as well as privacy loss due to the revelation of randomized data. Hence, the central question in randomization is to construct randomization schemes that can achieve a balance between sharing information and preserving privacy.

The proper quantification of privacy and privacy loss is crucial for PPDM. Several privacy metrics were proposed in the literature. Based on information theory, [1] used the differential entropy to measure the amount of privacy of a random variable X , and the mutual information between X and Y to measure the privacy loss for X caused by dis-closing Y . [5] and [6] introduced a concept called privacy breach and proposed the amplification method to limit pri-vacy breaches. However, most existing results are either ad hoc or empirical. The connections between information and privacy, especially individual privacy, are still not clear. Many questions remain open. For example, how random-izations exactly affect PPDM? how to discriminate different randomization schemes, and how to construct optimal ran-domization for various PPDM tasks? This paper is intended to build up a general framework to address these questions.
We focus on privacy preserving density estimation only in the current paper, because it is one of the most fun-damental tasks in data mining. The rest of the paper is organized as follows. Section 2 introduces a general frame-work for randomization. Section 3 presents various density estimators. Section 4 includes several numeric methods for calculating the estimators. Section 5 formally discusses in-formation loss due to randomization, develops metrics to quantify individual privacy and proposes two optimization problems to identify optimal randomization for PPDM. Sec-tion 6 presents experimental results. Section 7 summarizes the main contributions of this paper.
In the server-client model, the attribute X can be consid-ered as a random variable with distribution G ( x ) and density function g ( x ). The original data x = { x 1 ,x 2 ,... ,x random sample drawn from G , but the server only receives the randomized data y = { y 1 ,y 2 ,... ,y n } . In Section 1, y is derived from x by adding noise. In fact, more general ran-domization schemes exist. For C i , randomizing x i can be regarded as randomly drawing an observation from a den-sity f ( y | x i , X  ) that depends on x i and some other parameter  X  .Wecall f ( y | x,  X  )the randomization operator following [5]. y can be viewed as a random sample of a random variable Y with the following distribution, h ( y ;  X , G )= where  X  is either the Lebesgue measure or the counting mea-sure. Then privacy preserving density estimation is to re-construct G or g based on y and the randomization operator f . In statistics, (1) is known as the mixture model and g the mixing distribution. General mixture models have been well studied in statistics. The existing theory and methods for mixture models can be employed to facilitate the construc-tion of optimal randomization for PPDM. Next, we discuss two randomization schemes proposed in the PPDM litera-ture and show that they are special cases of (1). Example 1 . A discrete version of (1) was considered in [5], where both x and y arediscreteand f ( y | x,  X  ) was written as p [ x  X  y ]. [6] and [5] employed a scheme called select-a-size randomization to pertur bitemsets for mining association rules. Let I is a set of n items and T = { x i } 1  X  i  X  a collection of N transactions with each being a subset of items. For convenience, the transactions are assumed to have the same size. For given  X   X  [0 , 1] and a multinomial distribution  X  = {  X  j } m j =0 , f ( y | x,  X ,  X  1 ,... , X  m )=  X  j where y is a transaction of m items and j is the number of items shared by x and y . Hence, the select-a-size random-ization is equivalent to sampling an item subset from the space of all possible subsets according to f ( y | x,  X  ), where  X  =(  X ,  X  1 ,... , X  m ). Readers are referred to [5] for a de-tailed description of the randomization procedure. Example 2. In [1] and [2], y i are obtained by adding noise z i to the original data x i ,thatis, y i = x i + z 1  X  i  X  n . Assume the noise follows a distribution with den-and g .Toestimate g based on h is called deconvolution. If f ( z |  X  )= 1  X  2  X  X  exp { X  z 2 2  X  2 } , then adding z i to x lent to randomly drawing y i from a normal distribution with mean x i and variance  X  2 .If f 0 ( z |  X  )= 1 2  X  I (  X   X , X  form distribution over (  X   X ,  X  ), then adding z i is equivalent to randomly drawing y i from a uniform distribution over ( x i  X   X , x i +  X  ).

Theoretically, (1) represents an extremely flexible frame-work for randomization. The variables x and y can be dis-crete or continuous, and do not have to be of the same type. We will focus on the case where both are continuous in this paper. f ( y | x,  X  ) can be a general density function that de-pends on x and  X  . In practice, however, one may want to restrict f to be in a family of distributions F . For example, in Example 2, F is the family of normal distributions with variance  X  2 . In general, the exponential family can be con-sidered. How to choose an optimal f  X  X  for randomization is crucial for the success of PPDM.

Mixture models naturally arise from a variety of appli-cations and form an important type of model in statistics. Readers can consult [11] for a comprehensive account of this topic. As it will be shown later on, many existing theory and methods can be used for PPDM directly. An important dif-ference, however, does exist. In statistics, f is considered to be fixed thought it may not be completely known; while in PPDM, a central question is how to construct or identify an optimal f that can best facilitate both data mining and privacy preserving. In Sections 3-4, we will focus on the re-construction of G or g using existing theory and methods from mixture model.
In this section, we present two main approaches to esti-mating G 0 or g 0 , which denotes the original distribution, and emphasize on the role played by f .When f is chosen,  X  is known. So, it is suppressed in both h and f .
Let M be the class of all possible distributions over the range of X , denoted by  X . Because y is a random sample from h ( y | G ), the likelihood function of G  X  X  is l ( G )= i =1 log h ( y i ; G ) The nonparametric maximum likelihood estimator (NPMLE) is defined as  X  G n =argmax G  X  X  l ( G ) . Under fairly general regularity conditions on f ,itisknown that  X  G n exists and converges to G 0 asymptotically [11].
There exists a nice geometric description of how  X  G n is determined by y and f ( y | x ). For convenience, we assume that y i are different from each other. Define the likelihood in  X , L ( x ) forms a likelihood curve  X  = { L ( x ) ,x  X  in R n .Foragiven G , define L ( G )= VM = { L ( G ) ,G  X  X } . It is not difficult to see that VM is the convex hull of  X . Consider the upper sets U ( c )= { p : p  X  R n such that that U ( c ) is convex and there exists a unique  X  c such that VM X  X  ( X  c )= { L (  X  G n ) } . In other words, the likelihood vec-tor corresponding to the NPMLE  X  G n is on the boundaries of
VM and U ( X  c ). Furthermore,  X  G n is a discrete distribution with a finite number of support points, that is, where  X  x =(  X  x i ) denotes the support set and  X  q 1 ,... ,  X  q the corresponding probabilities  X 
G n can be further characterized by the gradient function of l ( G ). For any two distributions G 1 and G 2 , define G (1  X  t ) G 1 + tG 2 . Clearly, G t belongs to M if t  X  [0 , 1] and l ( G t ) is a function over [0 , 1]. The derivative of l ( G respect to t at 0 is defined to be the gradient of l from G G ,whichis D ( G 1 ; G 2 )= point mass at x , it becomes D ( G 1 ; x )= Assume that f ( y i | x ) are nonnegative and bounded, we have G is a MLE estimator if and only if (P1) D ( G ; x )  X  0for x  X   X ;(P2) D (  X  G n ;  X  x )=0for  X  x in  X  x .P1andP2canbe used to derive algorithms for calculating  X  G n .
The kernel method is popularly used to estimate nonpara-metric functions. A typical kernel estimator of g 0 based on y has the following form where K ( x )isthekerneland b n the bandwidth. The choices of K and b n are crucial for  X  g n .When f ( y | x )= f ( y the mixture model is called the convolution model. For the convolution model, the properties of  X  g n have been well un-derstood [7].
 of g , f and h respectively. Because h ( y ; G )= Fourier transform, g ( x )= 1 2  X  y ,  X  y ( t ) can be approximated by its empirical characteristic function  X   X  yn ( t )= 1 n kernel function m ( x ) with characteristic function  X  m ( t )sat-isfying some necessary conditions [7]. Then the kernel esti-mator of g 0 is  X  g n ( x )= 1 2  X  where K n ( x )= 1 2  X  continuous density function and it converges to g as n  X  X  X 
The calculation of  X  g n is relatively straightforward, but the calculation of  X  G n is not trivial. There exist two types of algorithms for computing  X  G n . The first type is based on P1, P2 and other properties of  X  G n discussed in Section 3.1 and is called the gradient method. Due to limited space, readers are referred to [3] for a comprehensive review. This section focuses on discussing the second type, that is, the EM algorithm.
 The EM algorithm is often used to calculate parametric MLEs when explicit solutions are not available. Although  X  G n is a nonparametric MLE, the EM algorithm can still be used because  X  G n is discrete with finite support points. The only difficulty is that the exact number of support points is unknown. Momentarily, we assume that it is known to be m . This issue will be further discussed later. Since  X  G m support points, we only need to consider all the discrete distributions with m support points in M .Let If G is restricted to M m , then (1) becomes a finite mix-ture model, h ( y | G )= function becomes l ( G )=  X  G n =argmax G  X  X  m l ( G ) . The standard EM algorithm for finite mixture models was developed a long time ago. It starts with an initial distribution, then alternates between an expectation step and a maximization step to update the estimates of z i and q i so that they converge to  X  x i and  X  q spectively. In the following, a pseudo-code of the algorithm is given. For the derivation, readers can consult [12]. EM Algorithm : (1) Initialize G o with { z o j } m j =1 and { q o j } 1  X  (2) For 1  X  i  X  n and 1  X  j  X  m ,calculate  X  ij = q where h ( y i | G o )= (3) For 1  X  j  X  m ,update z j and q j : q n j = 1 n z j =argmax z (4) Replace z o j and q o j with z n j and q n j , respectively, for 1  X  j  X  m andgoto(2). (5) Stop when some stopping criterion is met.
 For given f ( y | z ), the maximization in the third step usu-ally has explicit solutions, so the EM algorithm is a highly automatic procedure. One approach to overcoming the dif-ficulty caused by an unknown m is to start with a small m . When the algorithm converges, one step of any gradi-ent method is employed to add more points to the support and the EM algorithm is run again until it converges to  X  The algorithm in [1] is a special case of the EM algorithm described above.
Randomization is an economical and efficient approach for PPDM. However, there are also concerns. First, ran-domization can result in information loss or performance degradation in data mining. Second, the randomized data contain information about the original data, thus they may compromise individual privacy.
If f ( y | x ) does not depend on x ,then y contains no infor-mation about g 0 ,thatis, Y and X are independent. This im-mediately fails any attempts to conduct data mining based on y .Some f ( y | x ) can cause the so-called nonidentifiabil-ity problem in estimating g 0 [11]. Therefore, great caution should be exercised to avoid using those randomization op-erators. The major concern over randomization is that it may reduce the accuracy of data mining. This is evident by comparing the performance of the estimators based on y and based on x . We use the kernel estimator as an ex-ample. Let g n ( x ) be a kernel estimator based on x .Using the integrated mean squared errors (IMSE) as metric, the distance between g n and g 0 is usually of order O ( n  X   X  where  X  depends on the smoothness of g 0 . The accuracy of  X  g n , which is the kernel estimator based on y ,canbere- X  and  X  are parameters related to the types and degrees of smoothness of g 0 and f 0 [8, 7]. Hence, based on some prior knowledge about g 0 , we need carefully choose f to avoid severe deterioration in accuracy. Due to limited space, we refer interested readers to [8, 7] for details.

For a given g 0 , suppose F is a family of proper randomiza-tion operators. Intuitively, in order to guarantee the perfor-mance of data mining based y , we need select f to make y and x ,or Y and X , as dependent as possible. And the mu-tual information I ( X, Y ) is a natural measure of the depen-dence. Based on (1), I ( X, Y )= d X  ( y )  X  I ( X, Y ) &lt; +  X  with I ( X, Y )=0,when X and Y are inde-pendent, and I ( X, Y )=+  X  ,when X = Y .Foraspecific data mining task, direct performance measures can also be derived, which are usually complicated. I ( X, Y ) can act as a simple surrogate for these performance measures. In the literature, I ( X, Y ) was proposed to be a privacy loss mea-sure [1]. The reason why we use it as an information measure will be discussed in Section 5.2.1 and Section 5.2.3. Example 3 . Suppose g 0 follows N (  X ,  X  2 ). The random-ization is to add noise drawn from N (0 , X  2 ) to the original N (  X ,  X  2 +  X  2 ). So I ( X, Y )= log  X  2 changes from 0 to +  X  , I ( X, Y ) decreases from +  X  to 0, where  X  = 0 corresponds to revealing the original data. This implies that if no privacy constraints are imposed, the original data is the best. In PPDM, however, privacy con-straints must be considered and guaranteed. Then a trade-off between information and privacy need be carried out.
Privacy is the most important concept in PPDM, but its quantification turns out to be difficult. In this section, we define different levels of privacy and examine their connec-tions to information. We emphasize that it is the individual privacy that we need to preserve in PPDM. Based on several privacy measures proposed in literature, we further define or develop metrics to quantify individual privacy in the context of density estimation.
Recall that the primary goal of PPDM is to share popula-tion information (or aggregate information) while protecting individual privacy. The individuality aspect of privacy has not been well emphasized in the literature. For a given pop-ulation, privacy can be defined at different levels or scales. Let X  X  consider a hypothetical example. Suppose we are in-terested in estimating the salary distribution of professors in a private university. Let X denote the amount of annual salary made by a professor. There exist at least three hier-archical levels for the privacy of salary, which are the indi-vidual, the departmental and the university levels. Because the individual level is related to every possible values of X , while the other two levels are related to collections of possi-ble values of X , we refer to the former as individual privacy and the latter two as aggregate privacy. In PPDM, generally one can specify the level of privacy one need protect. In this paper, we assume we want to preserve individual privacy.
A close connection exists between privacy and informa-tion. Similarly, information can also be defined at various levels. At the same level, privacy and information could be regarded as the two sides of the same coin, because both of them are directly related to randomness and uncertainty. If this is true, sharing information must result in privacy loss, even when secure computing is employed. Then, we must ask how can PPDM be possible? A careful examina-tion concludes that the properties (information) we want to mine and the privacy we want to protect are usually at dif-ferent levels. This is exactly how PPDM was defined at the first place, which is mining aggregate properties while pro-tecting individual privacy. This definition can be generalized to mining properties at level i while protecting privacy at level j , where the levels should be well defined and j is usu-ally lower than i . Although mining aggregate properties can still cause the decrease in individual privacy, individuals are willing to participate a data mining process because (1) the decreased privacy is above certain tolerable level and (2) the potential benefits can be huge relative to the small loss in privacy.

In summary, PPDM is possible because one can trade ag-gregate privacy for aggregate information while the individ-ual privacy is maintained to be above some tolerance level. Next, we consider possible measures to quantify individual privacy.
The idea of using intervals to measure privacy was origi-nally suggested in [2]. However, [1] criticized this approach and suggested information-based measures instead. The counterexample in [1] was in fact not against the idea itself, it rather showed that the original definition was not enough and information regarding posterior distributions needs also to be taken into consideration. We modify the original defi-nition and show that it is indeed a quite legitimate approach.
Suppose X is a random variable with density g over  X  where g ( x ) &gt; 0. For x  X   X , we define its individual privacy at level  X  , denoted by  X   X  ( x ), to be min {  X  (( a, b )  X   X ) : x  X  ( a, b )and P ( X  X  ( a, b )) where  X   X  (0 , 1) and  X  is the Lebesgue measure. If  X  is the whole real line, the privacy of x is the width of the narrowest interval that contains x and has probability  X  .
 Example 4 . Suppose X follows a uniform distribution over (  X  (  X  a, a ),  X   X  ( x )=2 a X  .Notethatevery x in (  X  a, a )hasthe same amount of privacy.  X   X  ( x ) increases from 0 to 2 a as  X  increases from 0 to 1.
 Example 5 . Suppose X follows N (  X ,  X  2 ). Define  X   X  to be X   X  1 ( 1+  X  2 ). It can be shown that  X   X  ( x )= We introduce a function to characterize individual X  X  privacy tolerance. Let t (  X  ):[0 , 1]  X  (0 , +  X  ) be an nonnegative and increasing function. If an individual has X = x and  X   X  ( x )  X  t (  X  ), then he/she is comfortable with his/her in-dividual privacy at level  X  , otherwise, the individual will consider his/her privacy being breached. Individuals in a population are willing to reveal their population distribu-tion, when their individual privacy can be above their tol-erance, that is,  X   X  ( x )  X  t (  X  ) for all x  X   X andagiven  X  .

In randomization, because the randomized data are re-vealed in addition to the data mining results, individual pri-vacy will be further affected. For a give data x , we assume its randomized data is y . From (1), the posterior distribu-tion of X given Y = y is p ( x | y )= f ( y | x ) g ( x ) support of p ( x | y ). For x  X   X  y , the privacy of x after PPDM, called the posterior privacy , is defined to be  X   X  ( x | min {  X  (( a, b )  X   X  y ): x  X  ( a, b )and P ( X  X  ( a, b ) If there is a pair of data x and y such that  X   X  ( x )  X  t (  X  ) and  X   X  ( x | y ) &lt;t (  X  ), we claim that a privacy breach occurs at x .Forafixed x , the difference between its privacy and posterior privacy is which measures the impact of randomization on the privacy of x .Notethat X ( x ) is not necessary to be positive, because individual privacy can increase or decrease due to random-ization.
 Examples 3 &amp; 5 (Continued). Suppose we use a normal distribution with mean 0 and variance  X  2 as the randomiza-tion operator. So f ( y | x )= 1  X  2  X  X  exp { X  ( y  X  x ) 2 posterior distribution p ( x | y ) is also a normal distribution with mean  X  is  X   X  ( x | y )= where  X   X  = X   X  1 ( 1+  X  2 ). Note that the minimum posterior privacy is 2  X   X  X   X  , which is less than the minimum prior pri-vacy 2  X  2  X   X  .But X ( x ) can be positive or negative depends on the randomized data y .When  X  goes to zero, the pos-terior privacy will go to zero and result in serious privacy breach. On the other hand, when  X  goes to infinity, the posterior privacy converges to the prior privacy, that is,  X   X  ( x | y )  X   X   X  ( x ) for any x , y and  X  . In PPDM, a proper  X  should be chosen between 0 and +  X  .
Another type of privacy measure proposed in the litera-ture is based on information theory. Again, we assume X is a random variable with density g over  X . [1] defined the privacy of X to be h ( X )=  X  the differential entropy of X . Entropy was originally used to measure the randomness as well as the information of a random variable and it represents an aggregate property of X . We can have two random variables that have the same entropy but are entirely different. So, h ( X )isnotdirectly related to the values of X , thus is not a proper measure of individual privacy. In an extended version of this paper, we explore the possibility to  X  X ndividualize X  entropy and pro-pose entropy-based privacy measures. Interested readers can request the paper from the authors.
In the previous sections, we discussed the impacts of ran-domization on data mining, e.g., density estimation, and privacy protection, and proposed several metrics to quan-tify them. We argued that the success of PPDM hinges on the proper choice of randomization operators. Next, we define two types of problems for constructing optimal ran-domization.

Suppose T is a data mining task. Let L DM ( T ; f, g ; x , y ) be a measure of the discrepancy between the results of T based on y and x . The average discrepancy is defined to timation, the distances between the NPMLE  X  G n and the ordinary empirical distribution G n , or between  X  g n and g canbeusedas L DM .When f is already restricted to be in a family F of proper distributions, we advocate to use some surrogate measures such as the mutual information for choosing optimal randomization operators, that is, let L
DM =  X  I ( X, Y ). Let L PP ( x ; T ,f,g ) denote the privacy of x after randomization and data mining. In density estima-tion, the worst-possible posterior privacy of x can be used, which is L PP ( x ; T ,f,g )=min y  X   X  ( x | y ).
There are two types of problems in PPDM one need solve in order to choose optimal randomization operators. The first one is to maximize data mining performance under the constraint that posterior privacy for all x is above certain specified tolerance level ( C PP ). The second is to maximize privacy protection under the constraint that data mining performance is guaranteed to be above certain satisfaction level ( C DM ). These two types of problems are summarized below.
 Problem 1 : Problem 2 :
In this section, an example is used to show how to identify optimal randomization from a family of operators. Assume g tors is F = { N (0 , X  2 ) } X  X   X  2 exp { X   X  | z |}} . The randomized value y is obtained by adding noise z to x ,where z follows f chosen from F . We will use the definition of optimality in Problem 1 of Section 5.3 only.

Let L DM ( T ; f, g )=  X  I ( X, Y ). Let L (1) PP ( f, g )=min minimum lowest-possible privacy and the average lowest-possible privacy, respectively. We calculated L DM , L (1) L
PP for normal and double exponential randomization op-erators with different variances and plotted them in Figure 1. The left is the plot of  X  L DM (i.e. I ( X, Y )) versus vari-ance, in which the solid curve is for normal operators while the dot-dashed curve for double-exponential operators. The dot-dashed curve is above the solid one consistently. This indicates that the double-exponential operators caused less information loss. The right plot contains two pairs of curves. The pair on top is for L (2) PP ( f, g ), in which the long-dashed curve represents normal operators while the dotted curve represents double-exponential operators. The long-dashed curve is slightly above the dotted curve. This indicates that, on average, normal operators preserve slightly more individual privacy. The pair at bottom is for L (1) PP ( f, g ), in which the dashed curve corresponds to double-exponential operators while the two-dashed curve corresponds to normal operators. The two-dashed curve is quite flat. In fact, for normal operators, L (1) PP is always zero. It is positive in the plot because we computed it with y in a fixed finite interval. Small L (1) PP implies that when normal distributions are used, there always exists possibility of privacy breaches due to low posterior privacy. But the double-exponential operators do not have such a drawback. One can show that there exists a positive lower bound for the posterior privacy when double exponential distributions are used. Based on Figure 1, we conclude that double-exponential operators outperformed normal operators and should be employed for randomiza-tion. The particular choice of variance 2 / X  2 depends on the tolerance threshold C PP . For example, if we set C PP =1 . 0, then the variance should be larger than or equal to 2.25. Since the mutual information monotonically decreases with the variance increases, we should choose 2.25 as the optimal variance, so the optimal  X  = optimal operator for this example is a double exponential distribution with  X  = . 9428. Figure 1: Mutual Information and Privacy Measures
In this paper, a general framework based on mixture mod-els is proposed for randomization in PPDM. We advocate the use of mutual information between the randomized and original data as a surrogate measure of the performance of PPDM and redefine the interval-based privacy measure. Furthermore, two types of optimization problems are intro-duced for the identification of optimal randomization oper-ators.
Our thanks go to Professor Chris Clifton for many valu-able discussions, help and encouragement. [1] D. Agrawal and C. Aggarwal. On the design and [2] R. Agrawal and R. Srikant. Privacy-preserving data [3] D. Bohning. A review of reliable maximum likelihood [4] The Economist. The end of Privacy . May, 1999. [5] A. Evfimievski, J. E. Gehrke, and R. Srikant. Limiting [6] A. Evfimievski, R. Srikant, R. Agrawal, and [7] J. Fan. Global behavior of deconvolution kernel [8] J. Fan. On the optimal rates of convergence for [9] H. Kargupta, S. Datta, Q. Wang, and K. Sivakumar. [10] Y. Lindell and B. Pinkas. Privacy preserving data [11] B.G. Lindsay. Mixture Models: Theory, Geometry and [12] R. A. Redner and H. F. Walker. Mixture densities, [13] K. Thearling. Data mining and privacy: a conflict in [14] J. Vaidya and C. Clifton. Privacy preserving
