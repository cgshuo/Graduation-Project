 ORIGINAL PAPER Sherif Abdel Azeem  X  Hany Ahmed Abstract In this paper, we present a novel segmentation-free Arabic handwriting recognition system based on hidden Markov model (HMM). Two main contributions are intro-duced: a new technique for dividing the image into nonuni-form horizontal segments to extract the features and a new technique for solving the problems of the skewing of char-acters by fusing multiple HMMs. Moreover, two enhance-ments are introduced: the pre-processing method and feature extraction using concavity space. The proposed system first pre-processes the input image by setting the thickness of the input word to three pixels and fixing the spacing between the different parts of the word. The input image is divided into constant number of nonuniform horizontal segments depend-ing on the distribution of the foreground pixels. A set of robust features representing the gradient of the foreground pixels is extracted using sliding windows. The input image is decomposed into several images representing the verti-cal, horizontal, left diagonal and right diagonal edges in the image. A set of robust features representing the densities of the foreground pixels in the various edge images is extracted using sliding windows. The proposed system builds character HMM models and learns word HMM models using embed-ded training. Besides the vertical sliding window, two slanted sliding windows are used to extract the features. Three dif-ferent HMMs are used: one for the vertical sliding window and two for the slanted windows. A fusion scheme is used to combine the three HMMs. The proposed system is very promising and outperforms all the other Arabic handwriting recognition systems reported in the literature.
 Keywords Arabic handwriting recognition  X  Effective features  X  Fusion  X  Hidden Markov models 1 Introduction A handwriting recognition system can be either online or offline. The offline handwriting is based on optical char-acter recognition (OCR) and is usually applied on scanned documents. On the other hand, in online handwriting, the pressure is applied on digital instrument and sequence of points traced out by the pen. Offline handwriting recogni-tion involves the automatic conversion of text in an image into letter codes which are usable within computer and text-processing applications, and it is generally observed to be harder than online handwriting recognition. In the online case, features can be extracted from both the pen trajectory and the resulting image, whereas in the offline case only the image is available.

In recent years, some research has been done on the problem of offline Arabic handwriting recognition [ 2  X  5 , 8 ]. Despite this fact, offline Arabic handwriting recognition is still very challenging because of the varying writing style from person to person, difficulty of segmentation because of the cursive nature of the Arabic writing. Moreover, the Arabic alphabet contains 28 letters. Each has between two and four shapes, and the choice of which shape to use depends on the position of the letter within its word or sub-word. Ligatures between consecutive letters are of variable lengths as well as inter-and intra-word spaces. The problem of diacritical points, known as delayed strokes, can change the meaning of the word or sub-word. More details about Arabic writing characteristics can be found in [ 16 ].

Due to the advantages of hidden Markov models (HMM), many researchers have used them for Arabic handwriting recognition [ 1  X  4 , 6 , 8 , 13 ]. Since these are stochastic models, they can cope with noise and variations in the handwriting, and also the observation sequence that corresponds to fea-tures of an input word can be of variable length, and most importantly, word HMMs can solve the problem of segmen-tation implicitly.

Specific HMM models are used for each character, and word models are built by concatenating the compound char-acter models. HMMs on any recognition task require tem-poral information of the input signal. For this purpose, we generally use a sliding window in the direction of the writing (right to left in the Arabic language). In this paper, three con-tinuous HMM classifiers are used. The reference classifier is a left-to-right HMM. Another two HMMs have the same topology as the reference classifier, but the bounding boxes, frames, and cells of each one are slanted. The three classifiers are fused to make a final decision.

In this paper, we introduce:  X  Enhancement in the pre-processing stage  X  Enhancement in extracting concavity features from the  X  A new scheme for extracting features by dividing the  X  A solution for the problem of the skewing of characters Our target is to study the recognition of offline handwritten Arabic words of the IFN/ENIT database [ 23 ]usingHMM theory.

This paper is organized as follows: Sect. 2 introduces the decoding stage overview. Section 3 describes the pre-processing stage. In Sect. 4 , we present the designed recog-nition system with the use of HMM. In Sect. 5 ,theword modeling is presented followed by the feature extraction algorithm. Section 7 describes the fusion stage. Section 8 reports the experiments carried out on the IFN/ENIT data-base of handwritten city names. In Sect. 9 , some conclusions and perspectives are discussed. 2 Decoding process overview An overview of the proposed decoding stage is shown in Fig. 1 . The different blocks of the architecture are going to be explained in detail in the following sections of this paper. In this section, we present the decoding stage in a general way and describe what happens to the test word from the moment it enters the system until the output word is resulted from the system. Firstly, the test word goes through a pre-processing stage that reduces the distance between parts of words (POWs) and normalizes the thickness of the word to pre-determined number of pixels. Then, the pre-processed image goes through the feature extraction stage to extract a set of features by using overlapping frames from right to left. Three HMMs receive the features and recognize the possible words. The last step in this system is the fusion between the output words produced by the three HMMs. 3 Pre-processing The pre-processing step is intended to increase the ease of extracting the features and to decrease the noise in the image and decrease the variability of writing style from one person to another. The pre-processing step involves changing the thickness of the word to a fixed number of pixels and reducing the distance between the parts of word (POWs) if it is greater than a pre-determined threshold. 3.1 Changing the thickness of the word to a pre-determined The fact that there are differences in the thickness of the words in the database has been detected. It has been discov-ered after several experiments that the rate of recognition increases after normalizing the thickness of the input image.
Normalizing the thickness of a word in the input image goes through two stages as explained in [ 11 ]: 1. Thin the input word [ 26 , p. 879-Bottom of first column 2. Dilate the binary image with 3-pixels surrounding the
Table 8 , in the experiments section, describes the influence of changing the number of dilating pixels on the performance of the whole system. 3.2 Reducing the distance between parts of words (POWs) Vertical projection of the input image has been used to find the places where there are no pixels and then the width ( d ) of each empty place is calculated, as shown in Fig. 3 a. If the width is greater than a pre-determined threshold (6 pixels, empirically), then ( d -threshold) will be removed from this place to guarantee fixed separation between POWs as shown in Fig. 3 b.

It has to be noted that the main difference between the algorithm used to solve the problem of empty space proposed in this paper and another presented in [ 8 ] lies in the method used. In [ 8 ], they used the information of Arabic language to predict the places which may contain the white spaces such as between word white spaces, between word and within word white spaces and no white spaces. These white-space models are added to the character transcriptions in the lexicon. HMM model was used for these spaces.

In the proposed system, we detect the empty spaces auto-matically within the word as mentioned before and then reduce the distance of these empty spaces as shown in Fig. 3 b.
Table 9 describes a comparison between two systems: one that reduces the spaces between POWs and another without reducing the spaces between POWs.

Table 6 shows that the performance of the proposed system without the pre-processing stage drops by 3.6 %. 4 Hidden Markov model classifier The hidden Markov model is a double stochastic process, which can efficiently model the generation of sequential data. The HMM used in this paper is a continuous HMM with one HMM for each character. In this paper, we use the same HMM classifier without modification as imple-mented in HTK Speech Recognition Toolkit [ 14 ]. However, we implement our own parameters of the HMM. We allowed transition to the current and to the next state only. HTK mod-els the feature vector with a mixture of Gaussians. It uses the Viterbi algorithm in the recognition phase, which searches for the most likely sequence of a character given the input feature vector.

The hidden Markov model is a finite set of states in which the transitions among the states are governed by a set of prob-abilities called transition probabilities. In a particular state, an observation can be generated according to the associated probability distribution. Given an observation sequence, an HMM process deals with all feature observations in all states and then emits probability distribution indicating the con-fidence of the object represented by the model. Based on the extracted feature sequence from an unknown pattern, the classification is achieved by finding a model which generates a maximum probability.

In the training phase, an iterative optimization of the model with respect to the training data is performed, and we used Baum X  X elch algorithm, a variant of the expectation max-imization (EM) algorithm, for optimization of the HMM model depending on the training data.

To achieve high recognition rates, the character HMMs have to be fitted to the problem. In particular, the num-ber of states, the possible transitions, and the type of the output probability distributions have to be carefully chosen. HTK is principally concerned with continuous density mod-els in which each observation probability distribution is rep-resented by a mixture Gaussian density. In this case, for state j , the probability b j ( o t ) of generating observation o by: b ( o where M js is the number of mixture components in state j for stream s (1-stream used), the exponent  X  s is a stream weight and its default value is one, C jsm is the weight of the m  X  X h component, and ( o ;  X , ) is a multivariate Gaussian with mean vector  X  and covariance matrix , that is, ( o ;  X , ) = 1  X  where n is the dimensionality of o .

Sixty-four mixtures have been chosen to give a robust model for each character and high recognition rate. Figure 4 displays the case of an eight-state HMM in total, showing that we allowed transition to the current and the next states only. Six of these are emitting states and have output probability distributions associated with them. The transition matrix for this model has 8 rows and 8 columns. Each row will sum to one except for the final row which is always all zero since no transitions are allowed out of the final state.

The influence of varying the number of states on the sys-tem is shown in the result section in Table 16 . Also, the influence of the number of mixtures per character HMM on the performance of the system is shown in Table 17 . 5 Word modeling and dictionary building The character shape in Arabic is context sensitive, that is, depending on its position within a word (isolated, start, mid-dle, or end). Also, Arabic characters are rich in diacritic marks and delayed strokes (dots, Shadda, Hamza, etc.), as shown in Fig. 5 . Also, there are four ligatures found in the IFN/ENIT database, which increase the difficulty of recog-nition.
 A dictionary of all the different unique words in the IFN/ENIT database along with their delayed strokes and dia-critic marks has been constructed by tracing the ground truth of each image in IFN/ENIT database. A total of 166 charac-ter models has been generated by taking into consideration the fact that an Arabic character may have different shapes according to its position in a word as found in the database. Other models are created to model characters with special marks such as shadda (). 6 Feature extraction The input image in binary format as given in the IFN/ENIT database is used to extract a feature vector after the pre-processing stage. The background pixels of the image are labeled by logic  X 0 X  and the foreground pixels by logic  X 1 X . 6.1 Vertical overlapping frames The extracted features are divided into concavity and gradient features as explained in the following subsections. 6.1.1 Concavity features In this section, we introduce an enhancement of the concavity feature extraction already existing in the literature [ 1  X  3 ]. We introduce new directions of extracting the concavity features. To extract the concavity features, the following algorithm is applied: 1. Find the  X 0 X  pixels which have neighboring  X 1 X  pixels
Each one of the eight images shown in Fig. 7 is divided into vertical overlapping frames. The sliding window is shifted along the word image from right to left and a feature vector is calculated for each frame. The width of the frame is six pixels. There is a three-pixel overlap between the vertical frames. (a) feature1 (f1): (b) feature2 (f2): where r ( i ) is the number of  X 1 X  pixels in the i th row of a frame, H is the height of the image, and 100 H is the normalizing ratio.

A feature vector of length 2 is generated (1(f1) + 1(f2)) per frame per image. Thus, a 16-dimensional feature vector per frame results from the above algorithm for the 8 images representing the edges of the original image (2  X  8). 6.1.2 Gradient features The input image is segmented into n horizontal nonuniform segments with approximately equal number of foreground pixels in each segment. The total number of pixels in the image is counted and then divided by n which results in the required number of pixels per segment. In Table 11 ,we describe the effect of changing the number of segments on the proposed system. Figure 8 shows different cases of dividing the image into different number of segments.

The input image is then divided into vertical overlap-ping frames. Each frame is divided into small cells with fixed width, while the cell X  X  height depends on the word X  X  image and the distribution of foreground pixels in the images. The sliding window is shifted along the word image from right to left, and a feature vector is calculated for each frame as shown in Fig. 9 .

Where  X  H  X  is the height of the image,  X  W  X  is the width of the image,  X  w  X  is the width of the vertical frame, and  X  o  X  X s the width of overlapping of the vertical frames. Features are then extracted as follows. (c) feature3 (f3) [ 25 ]:
The gradient operator [ 17 ] is applied to the image to give two gradient components: strength and direction for all the points of the image. This is done by applying the Sobel operator [ 12 ] on the image to extract the ver-tical and horizontal gradient components. Only the direc-tion is used in the computation of our feature vector, and this direction can range from 0  X  to 360  X  . This range is split into 8 nonoverlapping regions of 45  X  as shown in Fig. 10 .

In each sampling region, a histogram of gradient directions is taken at each pixel of the region. Each histogram value corresponds to the count of each gradient direction in the region. To extract the gradient features, we used three cells (empirically) with nonuniform heights per frame as shown in Fig. 11 . For each cell, the eight gradient direction histograms are used to form 24 features per frame (8 features per cell nonuniform cells per frame).

A feature vector of length 40 is generated [16 (concav-ity features) + 24 (Gradient features)] per frame. Delta and acceleration [ 7 , 25 ] were calculated and then concatenated with the extracted features. 6.2 Slanted overlapping frames The different styles of Arabic handwriting are found in the IFN/ENIT database and can be summarized as follows: 1. City names that are written straight without any skewing 2. City names that may be skewed to the right or to the left 3. City names that may contain shifted or slanted delayed 4. City names that may contain slanted characters as shown
The most widely used technique to deal with the skewing in a handwritten image is through skewing correction. The baseline of the image is estimated and the whole image is rotated based on the estimated slope of the baseline. This approach may solve some, but not all, of the skewing prob-lems of a handwritten word. For example, the skew correction does not deal with the problems of the shifted positions of the delayed strokes and the slanted characters. Sometimes, as shown in Fig. 13 , the handwritten word is not skewed but the characters are slanted. Some handwritten words, as shown in Fig. 14 , suffer from slanted characters as well as slanted connections between the characters after the skew correction.
In this paper, a new approach to solve the previous prob-lems without skew correction is introduced. Two slanted bounding boxes with slanted sliding windows, one bound-ing box to the right and another one to the left, are used in addition to the straight bounding box with vertical sliding windows (explained in Sect. 6.1 ). The new slanted bounding boxes are shown in Fig. 15 . In each slanted bounding box, a sliding window is shifted along the bounding box of the word image from right to left in the same direction of orientation of the bounding box and a feature vector is calculated for each frame.

As shown in Fig. 15 , H 1 and H 2 are the heights of the slanted bounding boxes of the word image, W 1 and W 2are the widths of the slanted bounding boxes of the word image, h 1 and h 2 are the heights of one chosen cell in the frame, and  X  w  X  is the width of the frame ( w = 6 pixels). There is a three-pixel overlap between the sliding windows. The slant-ing angles of the two bounding boxes have been empirically set to + 4  X  and  X  4  X  . Table 13 shows the effect of different values of the slanting angle on the proposed system.
Features f1, f2, and f3 are calculated for each frame of the slanted bounding boxes in the same way done with the straight bounding box as explained in Sect. 6.1 . Thus, a feature vector of length 40 is generated [16 (con-cavity features) + 24 (Gradient features)] per frame. An HMM is used as a classifier for the features obtained from each of the three bounding boxes. The outputs of the three HMM classifiers are fused to produce the final recognized city name as explained in the following sec-tion. 7 System fusion The idea of combining the different systems is based on the assumption that the fusion of multiple classifiers gives better results than single ones. The fusion is applied at the classifier level using the confidences produced by the dif-ferent systems. Fusion methods can be divided into three main categories: label based, rank based, and soft margin or fuzzy-based methods. The label-based method is usually based on the final label of base classifiers like the majority voting fusion. The rank-based method uses the decision val-ues of base classifiers to rank using various fixed rules to get the final decision for the system. The soft margin and fuzzy-based methods use the output decision values of the base classifiers as a pattern recognition problem and try to detect the correct pattern. Methods like Bayes and neural network fusion are considered the most widely used fusion methods based on this type. In the proposed system, we com-bined sum, majority vote, and maximum rules to decide the recognized words.

The fusion is applied at the classifier level using the confi-dences produced by the different systems. The confidence of any candidate word is divided by the number of frames in the word to produce a normalized confidence. These normalized confidences are used to combine the different HMMs. Fusion goes through two stages as follows.

Get the top two candidates (according to their normalized confidences) from the main HMM-1 (vertical frames) and then apply the following algorithm: 1. If the difference between the normalized confidences of 2. If the difference between the normalized confidences 8 Validation and experiments 8.1 System parameters validation In our validation experiments, we used four sets (a, b, c, and d) for the training total of 26,459 words and 1,000 words from set e for validation. The following system parame-ters have been determined through validation: stroke thick-ness normalization, separation between different POWs by distance  X  d  X , number of Gaussian mixtures per HMM, num-ber of states per HMM, width of the vertical sliding win-dow for extracting the features, overlap between the sliding windows, number of segments for horizontal division, orien-tation angles of the bounding boxes, and the fusion threshold. 8.2 Experiments and results To evaluate the performance of the proposed recognition sys-tem, experiments have been conducted on the publicly avail-able subsets of the benchmark IFN-ENIT database.

Table 4 describes the final results of the whole system and compares with other systems using sets a, b, c, d, and e for training and two sets f and s for testing under the same conditions of the last competitions on Arabic handwriting recognition ICDAR 2007, ICDAR 2009, IFCHR 2010, and 2011.

As evident in Table 4 , the proposed system outperforms most of the 41 systems that have been tested in ICDAR 2007, ICDAR 2009, ICFHR 2010, and ICDAR 2011. The results in Table 4 show that the proposed system comes in the second place when testing set f after the MDLSTM (2009) [ 19 ] and comes in the first place when testing set s. When the results of sets f and s are averaged, the proposed system outperforms all of the other systems with average recognition rate 91.83 % (of the total of the 10,244 images representing sets f and s), while the average result of the MDLSTM over sets f and s is 91.48 %. This proves that the use of the proposed new tech-nique of pre-processing, dividing the image into nonuniform horizontal segments, using two slanted bounding boxes in addition to the vertical one, and extracting concavity as well as gradient features is very effective and very promising.
Table 5 describes a comparison of the performance of the proposed system with other word recognition systems pub-lished in the period between 2003 and 2011 outside the com-petitions of the ICDAR and ICFHR. The performance of the proposed system is very competitive and outperforms the best known systems in the literature.

The previous table shows that the proposed system out-performs all other systems reported in the literature on the two test sets (d and e).

In the following sections, we will show the effect of the different contributions and enhancements presented in the paper. As described before, we have presented two main contributions and two main enhancements that improve the performance of the whole system. In the following sections, we are going to show how each of them affects the results (on the system trained with sets a, b, c, and d and tested with set e). 8.3 Effect of pre-processing stage Our pre-processing stage plays an important role in enhanc-ing the performance of the whole system because of two main reasons. First, normalizing the thickness of the letters enhances the HMM characters models and makes them not sensitive to different thicknesses. Second, fixing the width of the empty spaces in a given image avoids the problem of the different sizes of spaces in the image which negatively affects the HMM performance. Table 6 describes the effect of the pre-processing stage.

The recognition rate of our system without the pre-processing stage is 89.84 (dropped by 3.6 %). Figure 16 describes some images that could not be recognized with-out the pre-processing stage.

In Fig. 16 a, the problem of large spaces with different widths between the POWs appears. This problem is the rea-son why the proposed HMM-based system could not recog-nize the shown words without the proposed pre-processing stage.

In Fig. 16 b, the problem of the different thickness of the written words appears. This problem affects the extracted features which depend on the distribution of the foreground pixels.

Table 7 describes comparison between our proposed sys-tem and another one without normalizing the thickness of words.

Comparing the results clearly reveals the significance of the proposed system which improved the performance by 1.34 %.

Table 8 describes the effect of varying the thickness of the dilation around the original thinned pixels.

As shown in Table 8 , three dilating pixels give the highest recognition rate.

Table 9 describes a comparison between our proposed system and another one without reducing the empty spaces between different POWs.

The results show that the recognition rate of the proposed system without reducing the empty spaces drops by 0.94 %. 8.4 Effect of segmenting the image horizontally with nonuniform segments Segmenting the image horizontally with nonuniform heights depending on the distribution of the foreground pixels enhances the recognition rate of the whole system when com-pared with segmenting into uniform heights while using the same features and the same number of segments as shown in Table 10 .

The results show that the proposed system using nonuni-form heights outperforms the system with uniform heights by 3.96 %.

Varying the number of horizontal segments affects the recognition rate of the whole system as shown in Table 11 .
Figure 17 shows some images that have been correctly recognized when using nonuniform heights and could not be recognized when using fixed heights per frame.

As shown in the previous figure, the nonuniform segments focus on the places with concentration of pixels unlike uni-form segments which do not take care of the distribution of pixels in the image. The above results show that more atten-tion should be given, in the feature extraction stage, to the locations in the input image with high density of pixels. 8.5 Effect of concavity features Concavity features in different directions have been used before by several researchers [ 2 , 3 ]. In this paper, we intro-duced an enhancement of these features by adding new direc-tions to get robust features.

Table 12 shows a comparison between the results of the proposed system without the concavity features and another system that uses the concavity features.

Comparing the results clearly reveals the significance of the proposed concavity features which improved the perfor-mance by 0.69 %. 8.6 Effect of the fusion stage In this part, we study the performance of the system after using fusion of three systems using slanted bounding box and slanted frames with orientation angle  X  B  X . Table 13 describes the recognition rate of each system separately and describes the enhancement of recognition rate after the fusion stage.
Comparing the results clearly reveals the significance of the proposed fusion stage which improved the performance by 1 %.

Varying the orientation angle affects the recognition rate of the whole system as shown in Table 14 .

Table 15 shows some words for which the correct class could be estimated by the combination of the three classifiers. For those words, the correct class is found by at least the classifier oriented in the same direction. 8.7 Effect of HMM parameters In this section, we are going to show influence of varying HMM parameters on the whole system and show how these parameters affect the recognition rate of the whole system.
In Table 16 , we show the influence of varying the number of states per character on the whole system.

AsshowninTable 16 , the best number of states was chosen to be 8 states to achieve the best recognition rate.
Table 17 shows the effect of number of mixtures per char-acter on the whole system.

The previous table shows that choosing 64 mixtures per character outperforms all other number of mixtures. 9 Conclusion In this paper, an HMM-based offline Arabic handwriting recognition system has been proposed. We introduce two enhancements and two contributions in this paper. The first main enhancement of the proposed system is the pre-processing stage. In the pre-processing, the thickness of the input word is fixed to three pixels, and the spacing between the different parts of the word is fixed to an empirical thresh-old. The pre-processing stage has improved the performance of the overall system by 3.6 %. The first main contribution is a new technique of splitting the image into nonuniform seg-ments which has improved the performance of the system by 3.96 %. The second main enhancement is decomposing the image into multi-concavity layers, adding new concavity spaces, and then extracting features from each layer which proved to be effective in improving the recognition rate. The second main contribution of this paper is solving the prob-lem of skewing and slanting in the handwritten word by using a combination of classifiers. Three individual classifiers are combined at the decision level. Each classifier observes the image from a given orientation. Combining those classifiers significantly increases the recognition rate.

The results achieved by the proposed system are very promising and show that the proposed contributions and enhancements, along with, careful choice of the extracted features as well as the HMM parameters can achieve higher recognition rates compared with the other systems in the lit-erature.
 References
