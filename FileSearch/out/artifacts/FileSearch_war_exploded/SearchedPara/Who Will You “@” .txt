 In Twitter-like social networking services, people can use the  X  X  X  symbol to mention other users in tweets and send them a message or link to their profiles. In recent years, social media services are rapidly growing with thousands of millions of users participating in them every day. When the  X  X  X  symbol is entered, there should be an automatic suggestion function which recommends a small list of candidates in order to help users to easily identify and input usernames. In this paper, we present our work on building a recommendation system for the mention function in microblogging services. The recommendation strategy we used takes into consideration not only content of the microblog but also histories of candidate users. To better handle these textual information, we propose a novel method that extends the translation-based model. Experimental results on the dataset we collected from a real world microblogging service demonstrate that the proposed method outperforms state-of-the-art approaches.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval -Information Search and Retrieval; H.3.7 [ Digital Libraries ]: Collection, Systems Issues Microblog; Recommendation; Topical Model
In Twitter-like services, the  X  X  X  symbol, which means what it appears to mean:  X  X t X , representing a connection, is one of the most important and common components. Once we put the  X  X  X  symbol in front of a username, an alert will be sent to that user signifying that a microblog is commenting directly to him. Since microblogging services have become one of the most important communication c  X  Figure 1: An example of username candidates given by Twitter. methods for people, there are a huge number of active users in real online services. According to a statistic on Twitter, there are 284 million monthly active users and the average number of followers for each account is 208 1 . Thus, if a recommendation system could recommend a smaller list of candidates, it would help users to efficiently identify and input usernames.

Along with the development of social media, a variety of recommendation tasks have been proposed for different problems, such as content recommendation [4, 7, 11, 16, 35], community recommendation [22, 25, 27, 47], tag recommendation [8, 33], music recommendation [3, 15, 37], news recommendation [19, 38], and so on. Information used for recommendations can be roughly divided into the following types: textual information [8], structural informa-tion [16, 25], spatial information [36, 45], and temporal information [18, 46]. However, only a few of attention has been paid on the task of recommending usernames when users input the  X  X  X  in microblog posts [42]. The recommendations given by online microblogging services are usually based on either partial inputs or recent histories of users. Figure 1 illustrates an example of username candidates when user input  X  CIKM  X  after the  X  X  X  symbol. We can see that although the text input has clearly indicated the microblog to connect to CIKM 2015, the username  X  CIKM2015  X  is not in the top candidates. https://about.twitter.com/company
In this paper, we focus on the task of recommending usernames for users, when they try to use the  X  X  X  symbol to mention other users in their posts. To be able to make this task a reality we have to face several challenges. First, as we mentioned above, there are a huge number of active users in microblogging services. This means that the recommendation target space is extremely large. Second, personalization is an inherent requirement of this task. Since users have their specific preferences, different usernames should be recommended even when the microblog posts have the exact same content. Third, due to the limitation of character length in microblog posts, there is brevity in information and inadequate context and structure [6]. Wang et al. [42] formulated the task as a learning to rank problem and studied several features describing the interest of users, content-dependent user relationship, and user influence. However, the main aim of that work is to recommend the users who may retweet the microblog. Different from it, the aim of mention actions we focused on are not limited to the spread of a microblog. We analysed and evaluated on the microblogs posted by real online users.

Motivated by the advantage of translation based methods in capturing the content information in different recom-mendation tasks [14, 46], in this work, we also follow this framework and assume that the usernames and textual content in a microblog are parallel descriptions of the same thing in different languages. Hence, the username recom-mendation task can be regarded as a translation process from the content of microblogs to the usernames. Since the existing translation model is sometimes vague without the aid of background knowledge, we integrated latent topical information into the translation model to facilitate the translation process. As we mentioned above, users have their own preferences, histories of users are important factor in this task, so we also incorporated the posts of both the user and candidates into the model. To evaluate the proposed method, we constructed a dataset which contains more than 10 million microblogs from an online microblog service and selected a subset from it as golden standards. We compared the proposed method with several state-of-the-art methods on the constructed dataset. Experimental results demonstrate that the proposed approach can achieve significantly better performance than the other methods.
The contributions of this work can be summarized as follows:
The proposed method relates to the following two research areas: recommendation on social medias and topic model. In this section, we briefly describe the related works on these areas.
In twitter-like services, users usually have to scan mi-croblogs presented in chronological order to find what they are interested in. Hence, the task of recommending microblogs has received considerable attentions in recent years [4, 7, 11, 16, 30, 35, 44]. Chen et al.[4] proposed to use collaborative ranking to capture personal interests. They incorporate the topics of tweets, social relations factors and some explicit features (such as authority of the publisher and quality of the tweet) to perfrom the task. Guy et al. [11] proposed to use both related people and related tags to recommend social media items. Pan et al.[30] introduced a joint model to combine collaborative filtering and diffusion processes for recommending microblogs. They also studied several diffusion features to capture the characteristic of diffusion processes. Graph based method was also proposed to perform the microblog recommendation task [44]. Microblogs and authors were ranked following a co-ranking algorithm.

Social interaction among people is the essential character of social media. To help users efficiently find their interested communities or friends, many studies have been proposed to perform the task [5, 22, 25, 27, 47]. Lo and Lin [22] proposed a weighted minimum-message ratio (WMR) method, which uses the real message interaction number among members, to generate personalized friend lists. Hao et al. [25] employed the opinions of trusted friends to make recommendations for the users under a probabilistic matrix factorization framework. In [47], the task of event-based group recommen-dation was introduced. They proposed a matrix factorization method, which considers location features, social features, and implicit patterns, to perform the task. Chen et al. [5] proposed a collaborative filtering based method to perform personalized community recommendations by considering multiple types of co-occurrences in social data at the same time.

Due to the usefulness of tag recommendation, a variety of methods have been proposed from different perspectives [12, 17, 34, 21, 8]. Heymann et al. [12] investigated the tag recommendation problem using the data collected from social bookmarking system. They introduced an entropy-based metric to capture the generality of a particular tag. In [39], a Poisson Mixture Model based method is introduced to perform the tag recommendation task. Krestel et al. [17] introduced a Latent Dirichlet Allocation to elicit a shared topical structure from the collaborative tagging effort of multiple users for recommending tags. Based on the observation that similar webpages tend to have the same tags, Lu et al. proposed a method taking both tag information and page content into account to perform the task [24]. Ding et al. proposed to use translation process to model this task [8]. They extended the translation based method and introduced a topic-specific translation model to process the various meanings of words in different topics. In [40], discriminative-term-weights were used to establish topic-term relationships, of which users X  perception were learned to suggest suitable hashtags for users. To handle the vocabulary problem in keyphrase extraction task, Liu et al. proposed a topical word trigger model, which treated the keyphrase extraction problem as a translation process with latent topics [21].

The most similar work to ours is that of Wang et al. [42] which proposed the work of whom-to-mention . They are hidden variables. try to find the users who have big influences and high probabilities to retweet the microblog. The main goal of their recommendation is to make the microblog to spread more quickly. Hence, they formulated the task as a learning to rank problem, and studied several features describing the interest of users, content-dependent user relationship, and user influence. Different from them, in this work, we use the microblogs which contain mention users and are posted by real users. Hence, we need to process different kinds of motivations when users input  X  X  X  in a microblog.
Topic models, such as probabilistic latent semantic in-dexing (pLSI) [13], latent Dirichlet allocation (LDA) [1], hierarchical dirichlet processes (HDP) [41], and so on, have proven to be useful in various tasks. In [1], latent Dirichlet allocation (LDA), a three-level hierarchical Bayesian model, was described for modeling collections of discrete data. Griffiths and Steyvers proposed a Markov chain Monte Carlo algorithm for inference LDA and used it to analyze abstracts of scientific papers [9]. Teh et al. [41] described Hierarchical dirichlet processes (HDP), a nonparametric approach, to model of groups of data. Each group was characterized by a mixture model and was desirable to allow mixture components to be shared between groups. Mcauliffe and Blei [26] introduced supervised latent Dirichlet allocation (sLDA) to model labelled documents.

Due to the capability of representing document themes, topic models have also been successfully used in natural language processing, image annotation, and various other applications [20, 32, 21, 8]. In [20], LDA-based image representation is proposed to classify the patches of the large image into the semantic concepts. To handle the vocabulary problem in keyphrase extraction task, Liu et al. [21] proposed a topical word trigger model, which treated the keyphrase extraction problem as a translation process with latent topics. Pennacchiotti and Gurumurthy [31] introduced a LDA based method to recommend friends with similar interests for users. For analysing text streams such as a sequence of posts from the same author, Wang et al. proposed Temporal-LDA to model the topic transitions that naturally arise in these data [43].

In this work, we also incorporate LDA with translation models to integrate topical information into them. The most similar work to ours is that of Lu et al. [23], which use translation methods to recommend citations. However, they did not take the topical information into consideration.
Given a microblog d and its author u , the  X  X  X  recom-mendation task is to discover a list of candidate authors. In this work, we first use generative models to learn the joint distribution of the topics z , the microblogs w and the mentioned users a , p ( z , w , a ). Then, we can use the probability p ( a | z ,w d ), which can be influenced based on the learned joint distribution, to generate candidate lists. The notations to be used throughout this paper are as follows. We use W and U to denote the word vocabulary set and the user set respectively. D u denotes the set of microblogs posted by the user u . Q denotes the set of users who have been mentioned in one or more microblogs in the corpus. D a is the set of microblogs which are posted by the mentioned user a , r d is the rank of microblog d in the extracted microblogs which is based on the time of the microblog. Let T denote the topic set, and  X  z w be the probabilistic distribution over words for each topic. We use  X  z,w a to denote the probabilistic distribution over users for each topic and each word which indexes the probability of a user being mentioned given a word and a topic. At the microblog level, we assume that each microblog has one topic and each user contains a mixture of topics. Let  X  u and  X  d denote the topic distribution of user u and topic distribution of microblog d respectively, w d = { w m } M d m =1 are the words in microblog d , M number of words in microblog d . a d = { a n } N d n =1 users mentioned in microblog d , N d is the number of users mentioned in microblog d . x d = { x m } M d m =1 are the topic word or background word indicate variables. Fig. 2 illustrates the graphical model representation of the proposed models.
The  X  X t X  Topic Translation Model (A-TTM) assumes that each microblog contains a mixture of topics. For the generation of the words in the microblog, each topic corresponds to a multinomial distribution over words. For the generation of the users mentioned in the microblog, each topic and word corresponds to a user distribution matrix  X  z,w . The A-TTM is based on the following assumptions. When a user posts a microblog, she first chooses the words of the microblog and then selects the users she wants to mention. For each word, she first chooses a topic from the topic distribution and then chooses a word from the topic-word distribution. Finally, she chooses users to mention according to the topics and words in the microblog. The generation process of A-TTM is shown in Alg. 1.
 Algorithm 1 The generation process of A-TTM model for each topic z  X  T do end for for each user u  X  U : do end for
The A-TTM assumes that a microblog contains a mixture of topics, and each topic corresponds to a multinomial distribution over words. While this assumption is reasonable for long documents, for short microblog posts, a single post is most likely to be about a single topic. Therefore, in the  X  X t X  User Topic Translation Model (A-UTTM), we assume that a user contains a mixture of topics, represented by a topic distribution, and each microblog has a single topic label. The A-UTTM is based on the following assumptions. When a user posts a microblog, she first chooses a topic from her topic distribution and then chooses a sequence of words from the topic-word distribution or the background-word distribution one by one. Finally, she chooses a user to mention according to the topic and topic words in the microblog. The generation process of the A-UTTM is described in Alg. 2.
 Algorithm 2 The generation process of A-UTTM
Draw  X  B  X  Dir (  X  ),  X   X  Beta (  X  ) for each topic z  X  T do end for for each user u  X  U : do end for
In the A-UTTM, we use a user level topic model to model the original microblogs. Although the A-UTTM takes into account the content of the original microblogs, usually the microblogs of the mentioned user are also important factors in influencing the mention behavior of the user. Hence, we incorporate the microblogs of the mentioned users into the A-UTTM, and we propose the  X  X t X  User-User Topic Translation Model (A-UUTTM). In the A-UUTTM, we assume that when a user posts a microblog, she first generates the words in the microblog. The generation process is similar as A-UTTM. She then chooses a user to mention based on not only the topic and topic words in the microblog, but also the microblogs of the mentioned user. The generation process of the A-UUTTM is described in Alg. 3. To learn the parameters of all the models (A-TTM, A-UTTM and A-UUTTM), we use collapsed Gibbs sam-pling [10] to obtain samples of hidden variable assignment.
According to the generation process of Alg. 1, we can factorize the joint probability distribution of the topic z , the microblog words w and the mentioned users a as follows: Algorithm 3 The generation process of A-UUTTM
Draw  X  B  X  Dir (  X  ),  X   X  Beta (  X  ) for each topic z  X  T do end for for each user mentioned in any microblog, a  X  Q : do end for for each user u  X  U : do end for Let N w,a z denote the number of co-occurrence times of user a and word w under topic z . According to the multinomial assumption on occurrences users, we obtain: where  X  z,w a is proportional to the probability that user a to be mentioned with the topic z . The target posterior distribution for user generation, i.e. p ( a | z , w , X  ), can be obtained by integrating over all possible values of  X  : p ( a | z , w , X  ) =
A similar derivation holds for p ( w | z , X  ) and p ( z |  X  ) leading to the expression for joint distribution:
For Gibbs sampler, we need to derive p ( z i = k | z  X  i , w , a ), where z  X  i denotes the entire state space of z except the i th token and i iterates over each word in the corpus.

The sampling probability of a latent topic for word w m in the microblog d of the user u is sampled from: where N w m k,  X  m is the number of word w m assigned to topic k . N k,  X  m is the number of word w m and mentioned user a co-occurrence in the same microblog under the topic k . N k,  X  m is the total number of topic k . All the count with  X  m is calculated without considering the current word w m in the microblog d . And ( . ) represents the count is calculated of all
The sampling probability of a latent topic for the mentioned user a n in the microblog d is sampled from:
According to the generation process of Alg. 2, we can factorize the joint probability distribution of the topic z , the microblog words w , the topic or background word indicate variable x and the mentioned users a as follows:
The derivation in previous section applies here which leads to following algebraic expression: p ( w , a , z , x |  X , X , X , X  ) =  X ( N  X  +  X  )
Given the other variable state except the variable x m , the sampling probability is calculated as follows: where l = B if p = 0 and l = z if p = 1. N  X  m, 1 is a count of topic words and N  X  m, 0 is a count of background words. N  X  m,B is the times of word w m assigned to background word. N w m  X  m,z is the times of word w m occurs as a topic word.  X  m represents taking no account of the current word w m .
Given the other variable state except the hidden topic z d of microblog d in user u , the sampling probability is calculated as follows: where N u k,  X  d is the number of microblogs assigned to topic k of user u .  X  d denotes the count is calculated without taking account of the microblog d .
According to the generation process shown in Alg. 3, we can factorize the joint probability distribution of the topic z , the microblog words w , the topic or background word indicate variable x and the mentioned users a as follows: The derivation in previous section applies here which leads to following algebraic expression: p ( w , a , z , x |  X , X , X , X  ) =  X ( N  X  +  X  ) original microblogs. N Q  X  z , w are the counts calculated in the microblogs of mentioned users with decay factors, which can be calculated as follow: where N d w i is the number of word w i in microblog d .  X  is the indicator function.

The inference process of A-UUTTM for the latent variables in the original microblogs is similar to A-UTTM model. Due to the space limit, we only show the inference process of the latent variables in the microblogs extracted from the mentioned users.

Given the other variable state except the variable x  X  i , the sampling probability is calculated as follows: where  X  i represents taking no account of the current word w .

Given the other variable state except the topic z j microblog j in user a , the sampling probability is calculated as follows: p ( z j = k | w , a , z  X  j , x )  X  where N w i ,a U,k is the times of word w i and user a co-occurrence under the topic k in the recommending users. N w i ,a Q,k calculated by the equation N w i ,a Q,k = P d  X  D k ).
We first run the inference algorithm of all the methods as described in previous section using the training set. Then we extend the Gibbs sampler state with the samples from the test set with following updates: where ( . t ) denotes the count calculated in the test set. p ( z d = k | w , a , z  X  d , x )  X  (17)
The parameters  X  and  X  can be estimated as follows: and the parameter  X  can be obtained as:
The possibility table  X  has a potential size of | W | X | Q | X  | T | . The data sparsity problems may cause difficulties in estimating  X  k,w a . Hence, we employ a linear interpolation with the topic-free word alignment probability p ( a | w ) to reduce the problem:
To estimate the topic-free alignment probability p ( a | w ), we explore IBM Model-1 [2] here.  X  is trade-off of two probabilities ranging from 0.0 to 1.0. When  X  = 0 . 0,  X  will be reduce to topic-free word alignment probability; and when  X  = 1 . 0, there will be no smoothing in  X .

In A-UUTTM, we perform the user recommendation as follows. Suppose a is the user to be mentioned and w d are the words in the microblog d . We can calculate the score for user a by: where p ( w m | w d ) is the weight of the word w m microblog d , which we use the IDF score of the word. We can recommend the top-ranked users for the microblog according to the ranking scores.
To examine the effectiveness of the proposed method, we constructed a dataset from Sina Weibo 2 , which is one of the most popular websites providing a Twitter-like microblogging service in China. It also allows users to follow each other. If user A follows user B, user A is called the follower of B and B is called the followee of A. We collected both microblogs and following-followee relations of users. We constructed the dataset in the following way. First, we randomly selected 200 users as the central users. Then we collected the 2-ego network for all the central users based on their followees 3 . Through these steps, the crawling process produced a total of 2.07 million users and 299.6 billion following relationships. For each user, we collected the 2,000 most recent microblogs, resulting in 84.8 million microblogs in total.

In this paper, we focus on the  X  X  X  behavior. Hence, we randomly selected 10 users from the total sample of 200 central users. All of the microblogs were collected to construct the data set in accordance with the following requirements: 1) they were posted by the selected 10 central users or their followees; 2) the posting date lies between Jan. 1, 2013 and Dec. 31, 2013; 3) at least one  X  X username X  is included in each microblog. Using these criteria, we gathered 178,841 microblogs. For each mentioned user in the set of microblogs, we extracted 4 microblogs matching the information of the mentioned user from the time line. Although the number of followees of the selected 10 central users is 1,286, there are in total 240,191 users involved in the constructed data set. Table 1 lists the statistics of the constructed dataset. We use the microblogs posted from Jan. 1, 2013 to Oct. 31, 2013 as training data. The others are used as test data.
 Data Set #Users #Relations #Microblogs For the evaluation metrics, we use Precision, Recall and F-score to evaluate the performance of user recommendation methods for the highest ranked result. To evaluate whether candidates with the top n highest scores contain the correct result, in this study, we use Hits@3 and Hits@5, which means percentage of usernames can be correctly identified from the top n results. Since the rank of the results is usually important, we use the common metrics detailed below to measure the rank of the results: http://www.weibo.com
According to Sina Weibo X  X  constraints, we can get only the top 200 followees of each user.
For comparison with the proposed model, we evaluated the following methods on the constructed corpus: We run all of the topic-based models with 500 iterations of Gibbs sampling. We set the number of topics to 30 after trying a few different number of topics. We use  X  = 50 . 0 /T and  X  = 0 . 1 as [10] suggested. We set parameter  X  to 0.01. The smoothing parameter  X  is set to 0.8. For all compared methods, we use the parameter settings mentioned in Section 4.2, which are designed to give the best performance.
Table 2 shows the comparisons of the proposed method with the state-of-the-art methods on the constructed eval-uation dataset. From the results, we observe that the A-UUTTM outperforms all the other methods on the dataset across the different evaluation metrics and significantly improves the user X  X  recommendation robustly. The relative improvement of A-UUTTM over CTM is about 15.7% on MRR. The Precision, Recall and F-Score show us that the proposed method delivers the best result. The Bpref and MRR metrics show that the proposed method generates recommendations which are consistently ranked by users
The toolkit scikit-learn 0.16.1 is used. as being superior. The results of Hits@3 and Hits@5 demonstrate that more than 41% of the original users can be found in the top 3 recommendations and around 45% of the original users can be found in the top 5 list.

From the results of CTM and Link-PLSA-LDA, we observe that the topic model and the translation model are effective for this task. Through comparing the results of the LDA-based model with CTM and Link-PLSA-LDA, we see that the A-TTM achieves better performance than either CTM or Link-PLSA-LDA on all the metrics. The results demonstrate that incorporating the topic into the translation model can impact the performance of the recommendation. The performances of ranking based method are worse than CTM. We think that the main reason may caused by the features which are more suitable for predicting who will retweet it. From the results of the A-TTM and A-UTTM, we observe that the A-TTM, based on the standard LDA, does not perform very well on the short microblogs. On the other hand, the A-UUTTM inherits the advantages of A-TTM and A-UTTM. Viewing the single microblog as one topic and each user corresponding to a topic distribution can improve LDA performance for short microblogs. Comparing the metrics of the A-UTTM with the A-UUTTM, we see that possessing the information of the candidates is helpful for the recommendation task. Figure 3 shows the performance of different methods on Precision, Recall and F-Score varying with the number of recommended users by the various methods. In these figures, x-axis denotes the number of users recommended and the y-axis indicates the results of Precision, Recall, and F-Score respectively. From the results, we observe that the A-UUTTM achieves consistently better performance than the other methods with different number of recommendations.
Intuitively, since heavy social media users post a variety of microblogs and often mention other users in their microblogs, recommendation for them should be much more easily when then input  X  X  X  symbol in a microblog. To investigate this intuition, we split the users into three groups based on the number of occurrence of  X  X  X  in their microblogs. Group 1 consists of the users whom microblogs mentioned the other users less than 300 times. The users in whom microblogs the number of mentioned users is more than 300 times and less than 600 times are included in the Group 2. Group 3 includes heavy social media users whom microblogs contains more than 600  X  X  X . Figure 4 shows the results of A-UUTTM on different groups. We see that the more frequently users mention others, the better performance the model can achieve. The relative improvement of A-UUTTM achieved in Group 3 over the results achieved in Group 1 is around 66.3% in MRR. The main possible reason is that the model can be better estimated with more training data.
In our model, there are two important parameters, the smoothing parameter  X  and the number of topics | T | . In this section, we show how the performance of our model varies as  X  changes from 0 . 0  X  1 . 0 and | T | changes from 10  X  50. When analyzing one parameter, we keep other parameters fixed to the settings mentioned in the previous section. Experimental results validate that the proposed methods can achieve stable and superior performance under a wide range of parameter values.

Figure 5 shows the results of A-UUTTM when the smoothing parameter  X  varies from 0 . 0  X  1 . 0. From the figure, we observe that our model obtains the best Figure 4: The results between heavy social media users and normal users. performance when  X  = 0 . 8. Furthermore, when the smoothing parameter  X  is from 0 . 2  X  0 . 8 we can achieve better performance than baseline methods. When  X  equals to 1.0, the performance decrease. This demonstrates that it is necessary to reduce the sparsity problem by exploiting smoothing in our model. Table 3 shows the influences of topic number, we see that when the topic number changes from 10  X  30, the performance of our model is much better than that of baseline methods, and we can obtain the best performance when | T | is around 30. However, as the number of topics increases, the data sparsity problem will be more serious when estimating the topic-specific probability matrix  X  , so the performance of our model will decrease accordingly. We can choose the topic number | T | from 10  X  30 and  X  from 0 . 2  X  0 . 8 to reduce the difficulty of parameter selection. Table 3: The influence of topic number | T | in the A-UUTTM. Figure 6 shows the influence of the size of training data. According to the description, we used the posting date lies between Jan. 1, 2013 and Oct. 31, 2013 as training data. We trained A-UUTTM with several subsets selected based on the posting date. Comparing the result achieved by the model trained with the whole data set and part of it, we observe that A-UUTTM can achieve better performance with more training data. However, with only 2 months training data, A-UUTTM can achieve satisfactory results. This means that the more recent microblogs can make the greater contribution to the performance. Microblogs from more than 10 months ago offer little help for the recommendation. We also observe that the proposed method (A-UUTTM) achieves the best performance among all the methods when using only 5 months training microblogs. Figure 5: The influence of the smoothing parameter  X  in the A-UUTTM. Figure 6: F-Score curve of different training size on this task.
In this paper, we studied the task of recommending usernames when users input the  X  X  X  symbol in their microblogs. We incorporated both the content of the microblog and histories of candidate users into translation based methods to perform the task. A-TTM incorporated the topical information into the translation method. To tackle the short text problem, we proposed the A-UTTM model, which assumed that one microblog has a single topic and each user corresponds to a topic distribution. Furthermore, we proposed the A-UUTTM to incorporate the microblogs posted by the mentioned users. We evaluated the relative performance of the proposed methods based on a dataset collected from real world microblogging services. The experimental results demonstrated that our proposed algorithms can significantly outperform baseline methods.
The authors wish to thank the anonymous review-ers for their helpful comments. This work was partially funded by National Natural Science Foundation of China (No. 61473092 and 61472088), the National High Technol-ogy Research and Development Program of China (No. 2015AA011802), and Shanghai Science and Technology Development Funds (13dz2260200  X   X ij  X  N13511504300).
