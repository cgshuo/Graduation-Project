 1. Introduction
Prolific research has taken place in recent years on face recogni-tion for its application in problem s of biometrics, pattern recogni-tion, and computer vision applications ( Chellappa et al., 1995 ;
Wechsler et al., 1996 ; Zhao et al., 2000 ; Gong et al., 2000 ). The reason behind the burgeoning of this field of research is that there is a large number of security and forensic applications involving facial recognition. Some of these appli cations include automated crowd surveillance, face reconstruction , design of human computer inter-faces (HCI), multimedia communication (e.g., generation of synthetic faces), and content-based im age database management ( Lu, 2003 ).
Although there are a number of face recognition algorithms which work well in constrained environments, face recognition is still an open and very challenging problem in real applications.
Many problems arise because of the variability of many para-meters: face expression, pose, scale, lighting, and other environ-mental parameters ( Oh, 2005 ). In this context, many innovative techniques have been formulated for face recognition throughout the scientific world. The face has been widely accepted as an effective biometric indicator owing to its advantage over other biometric indicators in the context of intrusiveness, accuracy, cost and ease of sensing ( Lu, 2003 ).
 sub-problems. The first issue to be answered is: (a) face verifica-tion, and the second is (b) face identification ( Hjelmas, 2000 ). acquired facial image during a security procedure matches with the template facial image already preexisting in the database.
Thus, the parameters which are used to gauge the performance in this type of problem are the verification rate (i.e., the rates at which legitimate users are granted access) as well as the false accept rates (the rate at which impostors are granted access). ing evaluator. In this problem, the technique is used to identify to whom the facial image belongs from among a database of varying facial images. In this case, a large number of factors affect correct identification, namely the angle from which the sensor image is obtained, the lighting condition during image acquisition, facial expression, facial hair and others. In this problem, existing approaches provide scores to different images based on the qualitative similarity of the image acquired to the template image, and subsequently the scores are sorted. The template image corresponding to the highest score is then selected as the match for the acquired image.

In recent times, two major approaches have been proposed for face recognition problems. They are appearance-based and model-based approaches. Fig. 1 shows an overview of the facial recognition techniques that are currently available in a pictorial form. Among face recognition algorithms, a ppearance-based approaches have been successfully developed and tested as a reference. These approaches utilize pixel intensit y or intensity-derived features.
However, these methods may not perform well if the test images are significantly different from the training face data, due to variations in pose, illumination or expression. In contrast, model based approaches are more robust and can incorporate variations in test data sets as their operation does not require incredibly detailed side information ( Kumar et al., 2009 ). This facial recognition problem contains an intrinsic nonlinear optimization procedure, which is almost impossible to solve for global optima using conventional derivative based optimization algorithms. In such situations, a class of global optimization techniques called evolu-tionary optimization methods can be popularly employed as they have been proved to perform well under several similar situations.
Some of the significant works where such evolutionary algorithms have been successfully employed involve the use of bio-inspired optimization, e.g., a bacterial foraging algorithm has been used to solve a circle detection problem in noisy images without the use of Hough transforms ( Dasgupta et al., 2010 ). In ( Das and Konar, 2009 ;
Das et al., 2008 ), the authors proposed a differential evolution based approach to automatically perform fuzzy clustering on noisy images.
Further applications of pattern recognition involving stochastic optimizers may be found in ( Das and Abraham, 2010 ).

In this paper, a new methodology is proposed which would fall loosely in the first category of face recognition using appearance-based methods and yet be claimed to possess the robustness of the second category of face recognition using model-based methods. The present work describes how optimal Volterra filter-based kernels can be utilized to develop a suitable method for face classification. These second order Volterra kernels are so optimized that inter-class L2 distance maximization and intra-class L2 distance minimization are achieved simultaneously ( Kumar et al., 2009 ). This optimization problem is solved with a contemporary stochastic optimization algorithm called artificial bee colony (ABC) algorithm ( Karaboga and Basturk, 2007 ), which is developed mimicking the intelligent behavior of honeybee swarm. These optimal Volterra kernels are utilized in conjunction with a nearest neighbour classifier followed by a voting procedure to arrive at a recognition result. The Volterra kernel approach is used in order to preclude any bias towards preexisting kernels like the Gaussian or the radial basis functions (RBFs) ( Kumar et al., 2009 ).

The performance of the proposed method is extensively tested for two popular benchmark image data sets (Yale A and Extended Yale B) vis-a-vis other popular algorithms used for similar problems and it has been shown that our proposed method could outperform most of these competing algorithms.

The rest of the paper has been arranged as follows. Section 2 discusses the theory of Volterra kernels and their application in biometric recognition as a face recognition tool popularly known as Volterrafaces ( Kumar et al., 2009 ). Section 3 discusses the artificial bee colony (ABC) optimization procedure and details the algorithm used to compute the optimal Volterra kernel. Section 4 presents the evaluation of the performance of the proposed approach in comparison to previous approaches as well as the comparison of ABC as an effective stochastic optimization tech-nique when compared to existing stochastic search techniques such as genetic algorithms and bacterial foraging optimization. Finally, the conclusions inferred from the results are presented in Section 5 . 2. Volterra kernels
Recent advances in signal and image processing have often involved the use of non-linear system modeling and identification tools. One such widely utilized modeling tool is the Volterra series, which is discussed in detail in ( Schetzen, 1980 ). This section briefly describes the salient features of the second-order truncated Volterra series and how it is employed in our present facial recognition problem. 2.1. Second-order Volterra (SOV) filters
The ideal Volterra series model, used in the modeling and analysis of nonlinear systems, is represented in the following infinite series form, y n k  X  X  where h n ( ) is the n th order Volterra kernel. Although such an ideal representation would result in a highly accurate nonlinear model, it is not physically realizable to employ an infinite number of kernels and, in most practical cases, a choice of an order higher than two results in objectionable computational complexity ( Kumar et al., 2009 ). Instead, truncation up to second-order terms are often found in the literature ( Kumar et al., 2009 ; Singh and Chatterjee, 2011 ), which provides sufficient accuracy without an exponential increase in required computational effort. This second-order approximation is referred to as the second-order Volterra (SOV) series or filter. The mathematical expression for the truncated SOV filters ( Zhang and Zhao, 2010 ) is given by: y n  X  X  h 0  X  order kernels, respectively. Here, N denotes the system memory size. In matrix form, (2) can be written as follows: y  X  n  X  X  H T  X  n  X  X  X  n  X  X  3  X 
Here, H ( n ) comprises the SOV filter coefficients corresponding to the zero-order, first-order and second-order kernels. X ( n ) represents the expansion of the input signal in terms of constant, single terms and cross-product terms. The expression given in (3) shows how a nonlinear SOV filter can be finally converted to an expanded linear form where the output is given as a weighted linear combination of the entries in the expanded X ( n ) vector. The the H ( n ) and X ( n ) vectors is of length L  X  1  X  N  X  NN  X  1  X  X  2  X  4  X  Here,
H  X  n  X  X  X  h 0  X  n  X  , h 1  X  n  X  , ... , h N  X  n  X  , h 0 , 0
X  X  n  X  X  X  1 , x  X  n  X  , ... , xn N  X  1  X  X  , x 2  X  n  X  , ... , x
The formulation presented in (2) X (6) shows how SOV kernels can be utilized as systems/filters for a one-dimensional input signal time series x ( n ). This methodology can be similarly employed for expansion of this concept of employing SOV kernels for two-dimensional signals i.e., for image processing problems, as is carried out in this face recognition problem. 2.2. 2-D quadratic Volterra filters
In the literature, it has already been established that the one-dimensional (1-D) discrete Volterra series can be extended to the
M -dimensional ( M  X  D ) case ( Singh and Chatterjee, 2011 ; Ramponi employed for the facial recognition problem in R 2 -space. This quadratic filter, with finite support can be represented by the equation, y n 1 , n 2  X  X  X  h 0  X  h 1  X  xn 1 , n 2  X  X  X  h 2  X  xn 1 , n 2  X  X   X  7  X  where, h 0 is a constant term, and the linear and quadratic vectors consisting of the coefficients of the kernels of this nonlinear filter ( h 1 and h 2 ), respectively are, h  X  xn 1 , n 2  X  X  X  h  X  xn 1 , n 2  X  X  X 
The finite support of this filter is the 2-D space defined by the regions intersected by 0 r i , k r N 1 1 0 r j , l r N 2 1  X  9  X  In matrix form, the filter operations may be represented by
Ramponi et al. (1988 ), h  X  xn 1 , n 2  X  X  X  tr  X  H 1 X T 1 h  X  xn 1 , n 2  X  X  X  tr  X  H 2 X T 2  X  10  X  where H 1 is the matrix of the filter coefficients of h 1 the N 1 N 2 matrix of pixels whose ( i , j )th element corresponds to the ( n 1 i , n 2 j )th input image pixel. X 2 is an N 2 1 derived by calculating the Kronecker product of the original window of pixels i.e., X 1 X 1 . 2.3. Posing the kernel optimization problem
The next objective is to calculate the values of the n Volterra kernels, which would involve the evaluation of multiple integrals.
Instead, the authors of Kumar et al. (2009) have suggested a goodness functional which objectively evaluates the effectiveness of a particular kernel on the basis of its classification ability in feature space.
 eration is to classify a set of images I  X  { g i }, where i  X  {1,2, into a set of classes C  X  c k , where k  X  {1, 2, y , N c } such that the classification occurrence is as high as possible. To achieve this optimal performance, a goodness functional is defined that can simultaneously achieve minimization of intra-class distance and maximization of inter-class distance ( Kumar et al., 2009 ). the intra-class distances can be computed by deriving the scatter matrix, which is a measure of the variance of the data ( Kumar et al., 2009 ; Fisher, 1936 ). If S W is this scatter matrix, then, S i  X  S W  X  where, N c is the number of classes and o denotes data corre-sponding to each class.
 matrix using the differences in the means of the i th class and j th class for all classes in N -dimensional feature space, or, be written as: J  X  K  X  X  K vector, formed by integrating the first order kernel coefficients and the second order kernel coefficients of the Volterra kernel. S is the matrix of intra-class distances, or within-class distances, and
S B is the matrix of inter-class or between-class distances. The convolution operation in image processing is utilized here to transform the image I i into a new representation A i such that the two dimensional convolution operations can be represented as Kumar et al. (2009) :
I i K  X  A i K  X  15  X  where K is the transformed Volterra kernel vector corresponding to the original second order Volterra kernel approximation K . Similarly, S W and S B can be formed as Kumar et al. (2009) : S B  X 
S W and S B are symmetric matrices with sizes ( l 4  X  l 2 where l is the size of the original 2-D kernel mask. K is of the size ( l 4  X  l 2 ) 1. Thus, the face recognition problem using Volterra kernels is essentially an optimization problem. 3. Artificial bee colony (ABC) optimization 3.1. Conventional ABC algorithm algorithm and its application in the design of optimal Volterra kernels. Population based optimization techniques have attracted attention of researchers in the recent past to achieve global optimum solution for various problems. Swarm intelligence, which can be considered as one of the emerging branches in evolutionary computing, provides researchers an effective tool for solving optimization problems. Swarm intelligence can be broadly defined as an attempt to design an algorithm based on the collective behavior of social insect colonies or other animal societies. The classical example in evolutionary computing used for solving optimization problem is the genetic algorithm (GA) ( Goldberg, 1989 ). Later, many swarm intelligence algorithms are proposed for solving optimization problems such as the particle swarm optimi-zation (PSO) ( Kennedy and Eberhart, 1995 ), the ant colony opti-mization (ACO) etc. In 2005 D. Karaboga introduced a bee swarm algorithm called artificial bee colony algorithm (ABC) ( Karaboga and Basturk, 2007 ) for numerical optimization problems. ABC has been employed by several researchers to solve various problems in different research areas ( Basturk and Karaboga, 2006 ; Karaboga and BasturkAkay, 2007 ; Karaboga, 2009 ).

The ABC algorithm has been developed inspired the behaviors of the real bees in finding the food source, called the nectar, and sharing the information of food sources with the bees in the nest ( Karaboga and Basturk, 2007 ). In ABC, the artificial agents are defined and classified into three types, namely, the employed bee, the onlooker bee and the scout. Each of them plays different role in the process: the employed bees stay on a food source and provides the neighborhood of the source in its memory; the onlooker gets the information of food sources from the employed bees in the hive and select one of the food source to gather the nectar; and the scout is responsible for finding new food, new nectar, sources. In ABC algorithm, the position of a food source represents a possible solution for the optimization problem and the nectar amount corresponds to the quality or fitness of the associated solution. The number of employed bees or the onloo-ker bees is equal to the number of solutions in the population. The
Basic ABC algorithm has three control parameters, namely the size of the colony (NS), number of cycles or iterations (MAXN) and the value of the limit for termination criteria ( x ). These para-meters are suitably chosen for a given problem.

The probability of the food source p i is calculated as p  X  where J i is the quality or fitness of the solution i , proportional to the nectar amount, is present in the food source for this solution position.
 The choice of a food source by an onlooker bee is guided by
Eq. (17) . A possible food position or solution x i is initialized as: x  X  min j  X  rand  X  0 , 1 max j min j  X  18  X  where j A {1, 2, y , D } and D is the number of optimization para-meters. A new food position is evaluated from its old position i.e., the new position of solution i is obtained as: v
Here, k is a randomly chosen solution ( k a i ). The complete bee colony optimization algorithm has been presented in Algorithm 1 . 3.2. Levy-mutated ABC algorithm
A variety of additional probabilistic methods for selecting new food sources have been recently presented in the literature, aiming to balance the exploitation and exploration required for swift convergence in global optimization algorithms. It is a common notion that the basic ABC algorithm tends to suffer from exhaustive exploration instead of desired exploitation, and thus the need has been felt to introduce variations of the basic ABC algorithm which will attempt to introduce required trade-off between the exploration and exploitation strategies. The authors in ( Rajasekhar and Abraham, 2011 ) introduced a mutation opera-tor into the ABC algorithm based on an alpha-stable distribution known as Levy-distribution, or the Inverse Gaussian distribution. The distribution can be written in closed form as, L a , g z  X  X  X 
Due to its characteristic tail region, it has a particular property of generating offsprings much further away from the parent. The Levy-mutation is introduced in the ABC algorithm at the step where a new food source is generated from the old one. Instead of the generating equation given in (19) , the equation used is of the form, x where, L a ,0 ( z ) signifies a vector, of required dimension, of Levy distributed random numbers or a Levy distributed random sequence in the parameter space. The paper demonstrates how ABC algorithms can be effectively utilized to solve face detection problems using two-dimensional Volterra kernels, and, in parti-cular, how a new variant of ABC algorithm, called Levy-mutated ABC (named in this work as L-ABC) can be utilized for the said purpose to achieve significantly superior performance. Algorithm 1. Algorithm of artificial bee colony optimization
Initialize the population of honeybees in the search space, x Evaluate the fitness of the population J Initialize cycle number  X  1 Start while loop continue until error function o x or number of iterations 4. Performance evaluation of the proposed method
In this section, the proposed ABC optimization algorithm based system is implemented on the Yale A and Extended Yale B standard face recognition datasets and the goodness functional in
Eq. (14) is minimized in order to obtain the optimal Volterra kernel. This aims to provide conclusive evidence of the superiority of the proposed approach over all existing approaches. 4.1. Methodology The Yale A and Extended Yale B datasets are downloaded from
Yale , Yale , and horizontal eye alignment is carried out before utilizing these datasets in the proposed approach. Finer details of the two popular benchmark datasets are tabulated briefly in
Table 1 . Unlike many previous approaches developed, no further cropping of the Yale A dataset was required for our proposed method to successfully classify the patches. Each image is further preprocessed by performing un-sharp masking. The un-sharp masked versions of each image in each dataset (165 images in the Yale A dataset and 2432 images in the Extended Yale B dataset) are then, respectively, stored as revised datasets in order to evaluate the performance of the proposed technique. The dynamic range of the intensity values are also exponentially expanded to cover the entire gray-level intensity range of the 8-bit resolution images (i.e., from 0 to 2 8 1). The preprocessing techniques result in sharpened high contrast images. Algorithm 2 and Fig. 2 shows how ABC algorithm has been utilized in conjunction with Volterra kernels to develop the proposed face recognition system.
 Algorithm 2. The proposed face recognition algorithm Preprocess the image as required.

Split original facial image into patches of pre-decided size ( N Select training set size.

Randomly select patches for training set and the remaining 4.2. Encoding the ABC algorithm meters. The number of onlooker bees and employed bees was considered to be 20 each, thus a total of 40 bees was created. The food source position in parameter space was analogous to each of the elements in a kernel of size K , hence each food source was a vector of size 1 ( K 4  X  3 K 2 )/2, i.e., the number of the coefficients to be independently determined for the transformed kernels of 2D-Volterra filter. The number of times a bee can explore within a neighborhood of its starting point before it becomes a scouting bee is set to 10. The objective function is evaluated by first converting each row vector into a suitable Volterra-Kernel and then computing the objective function value using the Eq. (14) .
The problem is configured as a minimization problem i.e., the objective is to minimize (14) .
 4.3. Results
The optimization search space for each element of the kernel was chosen as 1to  X  1 and the numbers of iterations were considered to be 2000. This value was chosen after several trials as the optimal iteration number which was required to produce satisfactory classification performance withou t adversely affecting the computa-tional speed. Results are reported on the basis of 10 test runs using randomly selected training sets and vote-based testing routines.
Average and standard deviations of classification error percentages are accordingly computed and tabulated using the proposed ABC algorithm for optimization. These results are compared to other similar stochastic search techni ques employed such as genetic algorithms (GA) ( Goldberg, 1989 ) and bacterial foraging optimiza-
Volterra kernels to evaluate the cl assification error as the perfor-mance evaluation parameter, and it was observed that the ABC algorithm-based face recognition system outperforms the others as is tabulated in Tables 2 and 3 . These tables also show performance comparisons with other face det ection algorithms proposed in
Kumar et al. (2009) . From these results, one can conclude that our proposed ABC based Volterrafaces algorithm is superior to most of these candidate contemporary algorithms. Furthermore, it has been also demonstrated that the L-ABC algorithm was successful in achieving better results than conventional ABC algorithm on several occasions, while conventional ABC proved to be a winner for the other occasions.

Tables 2 and 3 demonstrate these results in a mean/standard deviation format for 10 test runs. While a lower mean value indicates highly accurate face recognition systems with low errors and lower standard deviation justifies the inherent robustness of the system developed. In most cases, our proposed system not only produced the lowest error percentage, but also showed high robustness because of lower standard deviation values with random training sets. One interesting observation can be made from these results is that the L-ABC tends to improve the more difficult scenarios, when the number of training sets is miniscule, whereas conventional ABC tend to slightly outperform L-ABC for relatively larger training sets. From Tables 2 and 3 , it can be easily observed that, in general, the errors of the ABC algorithm and the L-ABC algorithm are less than those reported for several compet-ing algorithms, as shown. These results conclusively demonstrate the utility of using ABC based algorithms for solving these face recognition problems.

The improvement of the performance with the increment of training sets is also demonstrated in the pictorial representation given in Figs. 3 and 4 which is representative of the fact that the rate of decrease of error with the increase of the number of training sets is much higher for the proposed ABC-Volterra approach than the other approaches compared in this paper.
The results reported in Tables 2 and 3 and Figs. 3 and 4 are computed with 3 3 Volterra kernels employed. Next we make a detailed analysis of the performance of the proposed ABC-
Volterra system and the computation time taken with variation in the kernel size. The classification performances for different training sets in different kernel sizes are represented graphically in Figs. 5 and 6 for the two benchmark image datasets. The corresponding computation times involved in these system implementations are presented in Figs. 7 and 8 , respectively. It may be noted that computational times have been mentioned for the conventional ABC only, because the L-ABC works in identical computational time. It is apparent from these results that the general trend of the classification error is higher for increased kernel size, which is an added advantage since the average classification computation times (shown in Figs. 7 and 8 ) of the 3 3 kernel is significantly lower (almost 1/10th) than the average classification computation times of the 5 5 kernel for both datasets. Facial recognition requires in online situations, quicker processing speeds, and so the small kernel size is conducive to facial recognition applications for its accuracy as well as its processing speed.
 5. Conclusion
The present paper proposes an improved Volterrafaces metho-dology for face recognition by employing a modern stochastic optimization algorithm called the Artificial Bee Colony optimization technique for the minimization of a pre-defined goodness func-tional, where the decision variables correspond to elements of a non-linear mapping functional called the Volterra kernel. The optimal kernel designed is then used for classification in two standard face recognition probl em datasets known as Yale A and
Extended Yale B datasets, an d the proposed method has been proven to outperform many existing technologies reported so far ( Kumar et al., 2009 ). Also, the bee colony optimization technique has outperformed the other commonly used stochastic optimization techniques such as the genetic algorithm, and the bacterial foraging optimization, used for similar optimization of Volterra kernels. An additional Levy-mutated modification of the ABC has been imple-mented and comparison has been made to the conventional ABC.
Further scope exists in attempting to select an optimal itera-tion number as well as termination criteria in order to apply this work to future on-line face recognition systems for quicker and more accurate classification.
 Acknowledgements
The authors would like to thank Professor Stanislaw _ Zak for his tremendously helpful insights on the improvement of this paper. Professor _ Zak is associated with the Electrical and Computer
Engineering department at Purdue University. His interests are in control, intelligent systems, and optimization.
 References
