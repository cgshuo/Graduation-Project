 Venture capitalists (VC X  X ) face the challenge of choosing a few outstanding in-vestments from a sea of thousands of potential opportunities. A VC funds a startup company with cash in exchange for an equity stake. From this point of view, it may appear that the dynamics of the transaction are similar to that of an investor buying shares of a publicly traded company. Such appearances are false. When a VC funds a startup, the VC often takes an active role in managing the startup, providing expertise and advice in both managerial and technical ar-eas. In this way, the experience and wisdom of the VC X  X  who invest in a startup directly influence the startup X  X  trajectory.

When confronted with a company they have not seen before, one question that potential investors would like to be able to answer is: how will this company eventually exit the private equity space? In this study, we assume that the final outcome of a private company will be one of five outcomes. The private company can (1) go bankrupt, (2) proceed via an initial public offering (IPO) to become a publicly traded company, (3) be subject to a leveraged buyout (LBO), (4) merge with or be acquired by another company, or (5) stay private.

Our goal in this paper is to use information about who invests in a pri-vate company and when these investments are made to predict how the com-pany will exit. Our prediction is generated by a statistical model inferred from data available through the Private Equity module of ThomsonONE, a data set formerly known as VentureXpert. Nume rous academic libraries have access to this database, and it is often used as a source of data for research papers in the VC/PE space X  X ee [2, 6, 5, 12, 13]. Here we develop a method for convert-ing each VC-or PE-backed company in the database into a list of numeri-cal and nominal attributes with a class label corresponding to one of the five possible states; we then use this list of labeled instances to train and test a classifier.

The random forest algorithm [3], [10, Chap. 15] and other machine learning algorithms such as support vector machines and boosting are available as free codes, implemented in a variety of languages and environments. Such algorithms have proven useful in a wide variety of applications. Though it seems very natural to leverage machine learning algorithms and large databases to model the exits of VC-/PE-backed companies, to the bes t of our knowledge, this is the first study to do so. As such, this paper represents a first attempt at solving the problem.

Our analysis shows that a late-stage investor may be able to use knowledge of a company X  X  first three rounds of funding together with a random forest clas-sifier to assess the probability that the company will not go bankrupt, and also to assess the probability that the company will eventually make an exit of some kind (and no longer remain private). For both of these two-class classification problems, our models X  average success r ate across all sectors is 75% and the average area under the ROC curve is 0 . 83.

In what follows, we discuss the details of our procedure, starting from the data, proceeding to issues of representation, inv estor ranking and instance resampling, andthenontospecificworkingmod els and their associated results. For this study, we focused on the following attributes:  X  The year in which the company was founded. See the right panel of Figure 1  X  The company X  X  sector, encoded as a four-digit number.  X  The rounds , i.e., dates on which the company received funding.  X  A list of historical investors in the compa ny. This list includes each investor X  X   X  The company X  X  exit status.

All of these attributes have to do with who invested in the private company and when the investment was made. Notably, the amount of money invested by the investor in each round of funding, as well as the pre-and/or post-money val-uations of the companies are absent. In short, our study makes use of qualitative rather than quantitative features of a private company X  X  investment history.
Let us elaborate on a few of the attributes mentioned above. The company X  X  exit status is, in the original data set, a nominal attribute with 12 possible values. Since exit status is the class variable, we group a few of these categories together to reduce the number of classes from 12 to five. We list here the five class labels in italics together with the original exit types contained in each class: 1. Bankrupt: Defunct, Bankruptcy -Chap. 7, Bankruptcy -Chap. 11 2. IPO: Went Public 3. LBO: LBO 4. M&amp;A: Acquisition, Merger, Pending Acquisition 5. Private: Active, Other, In Registration, and Private Company (Non-PE) The company X  X  market sector is encoded as a four-digit number. The first digit of this four-digit number gives us a broad sector categorization, as seen in the left-most column of Table 1, which also shows the breakdown of exits by sector. One can readily see two trends. First, the classes are imbalanced, necessitating the use of a resampling procedure described in Section 3.1.

Second, different sectors behave differently:  X  For sector 2xxx, only 3.23% of compan ies had an LBO exit, while for sector  X  For sector 6xxx, 16.60% of exits are IPO and 13.77% of exits are M&amp;A. For It is plausible that the reason the percentages differ so much from one sector to the next is that the factors influencing success/failure differ greatly from one sector to another. For these reasons, in the present study, we shall segregate the data by the broad sectors indicated in Table 1. 2.1 Social Network Ranking Here we explain how we turn the investor name into an attribute. The social network of coinvestment plays a key role. There are 9545 unique investors in our data set, so we seek a mapping from the set of all investor names to the set of integers P = { 1 , 2 , 3 ,..., 9545 } .

Let each investor be a node, and join two nodes by an edge if the two investors both invested in the same company at some point of time. To repeat, the coin-vestment need not occur at the same ti me. Once we form the adjacency matrix for this social network, we sort investo rs by degree. Ties are broken simply by using the order in which we encounter the investor as we parse the data. Once the investors are sorted by degree, we have our mapping: the investor is mapped to its position p  X  P in the sorted list.

In the sorted list, the top two investors, Undisclosed Firm and Individuals, are placeholders that do not correspond to any one firm. The next 10 investors are: J. P. Morgan Partners (FKA: Chase Capital Partners), New Enterprise Associates, Inc., Intel Capital, Kleiner Perkins Caufield &amp; Byers, Oak Investment Partners, Sequoia Capital, Goldman, Sachs &amp; Co., Mayfield Fund, HarbourVest Partners LLC, and Bessemer Venture Partners. These names should be familiar to those who follow the VC/PE space, indicating that even a rough social network ranking does correspond to intuitive/anecdotal rankings of VC X  X  and PE funds.
Next we turn to the investor type. This is a nominal attribute with 18 pos-sible values: Development, Buyouts, Seed Stage, Balanced Stage, Recap, Un-known, Energy, Early Stage, Expansion, Fund of Funds, Mezzanine Stage, Later Stage, Turnaround, Distressed Debt, Real Estate, Other Private Equity, Sec-ondary Funds, and Generalist. There is effectively a 19th possible value when the type of the investor is not listed, i.e., the datum is missing. We let Q be the set of 19 possible investor types. 2.2 Mapping Companies to N -tuples In what follows, we use the term vector to mean an N -tuple x =( x 1 ,x 2 ,...,x n ); one N -tuple represents one company. All the ingredients are in place to define a function that maps companies to vectors. One issue is that the number of rounds of funding enjoyed by a private company varies from one company to the next. Let n ( x ) be the number of companies that have received precisely x rounds of funding; Figure 1 shows log 10 n ( x )versus x . The graph is approximately linear, indicating an exponential decay of n ( x ). There are two considerations to make:  X  The maximum number of rounds for any company is 27, yet 92 . 5% of  X  From the point of view of applicability, a model that predicts exit type Based on both considerations, we develop a round-by-round representation of the data. We find that there are a maximum of 31 investors in any round of funding. One round of funding then corresponds to a vector ( p , q )  X  P 31  X  Q 31 , where P and Q were both defined in Section 2.1. We have p =( p 1 ,p 2 ,...,p 31 ), and each p j is the result of mapping the j -th investor name to P using social network ranking. We also have q =( q 1 ,q 2 ,...,q 31 ), and each q j  X  Q is the investor type for investor j .

We see, then, that the representation of a company consists of a number of distinct rounds. We use superscripts to denote the round number. Then, in a model where we retain only the first five rounds of funding, a company C is
Besides the information contained in the investor lists, we have a relatively small amount of information that we represent by a vector h . For the model with k rounds of funding, we have h  X  Z 3+ k ,with h 1 equal to the precise four-digit sector code, h 2 equal to the year in which the company was founded, h 3 = k , and h 4 through h 3+ k equal to integer representati ons of the dates on which the k rounds of funding occurred.

Note that entry-wise addition of two N -tuples generally results in an N -tuple that is not a meaningful representation of any possible company. This lack of linearity excludes a host of statistical methods. This is in contrast to a  X  X ag of words X  representation of our data, where we would represent the investor list for one company by a vector v  X  R 9545 ,where v k represents the number of times that investor k participated in a round of funding for that company. This representation of the data does have a linear structure and lends itself to models based on matrix factorizations such as the SVD, yielding latent semantic analysis-type models [7]. Tho ugh linear models based on the SVD have performed very well on other problems, w e found through detailed testing that for our problem, such models suffered from poor predictive power and extremely long computation times. The latter was due to the higher-dimensional spaces incurred by the bag of words representation. For this reason, we moved away from a linear representation of the data to the ( p , q ) structure described above. 2.3 Missing Entries The most striking thing about our representation of the data set is the relatively large number of missing entries incurred. To see how this arises, consider that one company X  X  first round may involve three investors while another company X  X  first round may involve 30. In the first instance, only the first three components of p 1 and q 1 would be populated with meaningful information X  X he remaining 28 components are missing. In the second instance, there would be only one missing component in each of p 1 and q 1 . As long as we wish to retain as much information per round as we have on hand, our representation of the data will lead to missing entries.

Both the missing entries and the lack of vector space structure point to random forests as an appropriate class of models for this problem. Classification/decision tree algorithms upon which random forests are based contain natural methods for estimating missing data. Breiman X  X  tests [3] indicate that random forests can yield accurate models even with 80% missing data. In this work, we focus on two two-class problems: distinguishing companies labeled as  X  X ankrupt X  from those that are not, and distinguishing companies labeled as  X  X rivate X  from those that are not.

We develop models that make predictions using only the first three funding rounds. We discard all rounds later than round three, and we cap the  X  X umber of rounds X  entry h 3 of h so that it is at most equal to three. 3.1 Resampling and Cross-Validation As can be seen from Table 1, the bankrupt vs. non-bankrupt problem will be highly imbalanced regardless of sector. The imbalance causes problems for all classifiers that we have tried. The problem manifests in a classifier that always predicts  X  X on-bankrupt X , yielding an area under the ROC curve close to 0 . 5, i.e., a perfectly useless model, even if its overall accuracy is anywhere from 70  X  90%. To avoid this issue, for any training set that we feed to the random forest, we sample with replacement from the training set to form a new training set with uniform class distribution. We do not touch the test set. To summarize: 1. Let X = collection of all labeled vectors for one of the two-class problems 2. Randomly partition X into K disjoint subsets { S i } K i =1 . 3. For i =1: K , 4. Aggregate the test results from all K folds of cross-validation.
 Similar approaches have been discussed by Breiman et al [4]. The imbalance is not as acute but still exists for the private vs. non-private problem, so we employ the resampling procedure for that problem as well. 3.2 Results All results will be for random forests with 80 trees per forest and 25 randomly chosen attributes per tr ee. The results are computed using Weka RandomForest [9]. We have found that the test results X  X oth overall correctness and area under the ROC curve X  X re relativel y insensitive to the parameters chosen. For example, varying the number of trees from 35 to 160 in steps of 10 yields ROC areas and overall correctness within 5% of the results quoted below.

In Weka, we have built models using a number of different classifiers appro-priate for the attributes and instances in our data set. Even with the resampling procedure described above, the followi ng methods yielded models with poorer predictive power than random forests: logistic regression, support vector ma-chines (with standard kernels), and neural networks. Meta-classifiers such as boosting and bagging performed well and deserve investigation in future work. Bankrupt vs. Non-Bankrupt Problem. Across all sectors, we find our model performs best for companies in the energy sector (sector 6). The classifier X  X  over-all accuracy is 83 . 4%. The confusion matrix in this case is as follows: Here the positive class is  X  X ankrupt X  and the negative class is  X  X on-bankrupt. X  Let T/F denote true/false and P/N denote positive/negative. Then we define We compute these metrics to assist with decision-making. Each quantity is an estimate of a conditional probability: Pos Precision = P (truly + | predict +) Pos Recall = P (predict + | truly +) Neg Precision = P (truly -| predict -) Neg Recall = P (predict -| truly -) What we notice for Sector 6 is high negativ e precision, i.e., when the model says that a company is not going to be bankrupt, there is a 97 . 2% chance it will not go bankrupt. However, when the model says that a company is going to go bankrupt, there is only a 40% chance that it will truly go bankrupt. There are two reasons why this happens:
First, the original data set is rich with examples of non-bankrupt companies, and poor with examples of bankrupt companies. This is purely a function of how the data was gathered X  X ompanies that have gone bankrupt already have no incentive to give their historical det ails to ThomsonONE, and because infor-mation on private companies need not be reported publicly, ThomsonONE has no way of finding out about all past bankrupt companies.

Second, given that positive and negative recall are above 0 . 8, it may well be the case that if our trained models wer e merely tested on data sets with a much larger number of bankrupt companies, the performance would be much improved. Right now our algorithm predicts bankrupt in over 80% of the cases where the company truly is bankrupt (positive recall = 0.819), but unfortunately, our data set is only 11% bankrupt.

Added together, the two reasons just presented indicate that if the model were trained on a data set that included a more rich set of bankrupt companies, the positive precision would increase.

In addition to the above metrics, there is the ROC curve, formed by accounting for not only the classifier X  X  prediction but also the value of its margin function for each instance X  X or more details about the construction of ROC curves, see [8]. The curve indicates that a practical decision-making system can be designed based on the margin. When the margin is high, i.e., when we are at the part of the ROC curve near (0 , 0), the classifier is consisten tly correct, giving the curve a large positive slope. This implies that when the margin is high, the classifier gives a useful and trustworthy prediction.

Similar results can be noted across all sectors, as shown in Table 2. ROC curves for all 9 sectors are plotted in the left and right panels of Figure 2. We have separated the ROC curves into two panels merely to enable the reader to distinguish them.
 Private vs. Non-Private Problem. Here the model performs much more uniformly across all sectors. This time, let us examine the performance for the largest sector, Sector 2, co mprising companies in the general area of computers. The confusion matrix is: We use the same definitions as given above in (1-2), but now the positive class is  X  X rivate X  and the negative class is  X  X on-private. X  All four metrics are very close to each other: positive precision = 0 . 751, positive recall = 0 . 751, negative precision = 0 . 743 and negative recall = 0 . 743. The classifier correctly classifies 74 . 7% of all instances, and the area under the ROC curve is 0 . 828.
Very similar results can be noted across all sectors, as shown in Table 3. ROC curves for all 9 sectors are plotted in the left and right panels of Figure 3. Again, we have separated the ROC curves into two panels merely to enable the reader to distinguish them. Ranking the Covariates. As detailed by Breiman [3], random forests provide estimates of variable importance. In Weka, the built-in RandomForest module does not include this feature; we have utilized an extension of the module devel-oped by Livingston [11]. In the table below, we rank our attributes (or covariates) by their importance in the random forest. The importance is given as a RawScore averaged across 10 rounds of cross-validation. For reasons of space, we include in Table 4 only the top 10 attributes for Sector 6: results for other sectors show the same general grouping of attributes.

There are several clear trends to discern from the ranking. Early rounds of funding matter more than later rounds of funding. The type of an investor mat-ters just as much if not more than its identity. Finally, the rankings for both two-class problems show remarkable similarity, both in terms of the order of the ranking and the clustering of the RawScore values in certain intervals. The top four most important attributes are the same for both two-class problems. Having performed this study, we see three main ideas for improving the model using currently available data.

First, from Table 4, we see that the identity of the first investor in round one is one of the most important attributes for the random forest models built in this paper. Since this identity consists of the investor X  X  social network ranking, we are left to believe that a more informative social network may lead to better predictions of company exits. The network used in this study ignores temporal details such as the fact that investor A may be completely divested from a startup company by the time that investor B decides to invest. In this case, our network prescribes a connection bet ween the two investors that is not present in reality. Another point is that we have formed one network for all investors/companies; forming different networks for each sector may yield better models.

Second, based on our knowledge of the data set, when we view the rankings in Table 4, we infer that attributes that have very low percentages of missing entries (such as the dates of the rounds of funding, which are never missing) are much more important for the model X  X  predictive power. We therefore believe that a better understanding of missing entries may yield a more predictive model. Indeed, there may be something significant to learn from (a) the number of investors in each round and (b) which investors do and do not participate in a given round of funding. This is anal ogous to wisdom from the winners of the Netflix prize, who found that modeling which movies were and were not rated by a user improved their predictions [1].
Finally, as hinted above, we have only b egun to explore other ensemble clas-sifiers such as boosting and bagging. It is likely that combining random forests with other models will yield a model that beats our current results X  X he only question is how to search for this combination in a principled fashion.
We form two main conclusions: (1) applying resampling and random forests to qualitative data in the VC/PE-space does indeed yield models with useful predictive and explanatory power; and (2) a late-stage investor who has purely qualitative knowledge of a company X  X  first three rounds of funding can use this information to improve his/her understanding of that company X  X  future trajec-tory. Overall, the results indicate that data mining can be used to provide both predictive and explanatory power for VC decisions.

