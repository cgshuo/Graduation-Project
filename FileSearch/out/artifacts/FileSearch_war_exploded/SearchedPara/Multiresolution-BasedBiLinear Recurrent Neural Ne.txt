 Predicting a chaotic time series is equivalent to approximating an unknown non-linear function mapping of a chaotic signal. Various models have been proposed to model and predict the future behavior of time series. Statical models such as moving average and exponential smoothin g methods, linear regression models, autoregressive models (AR), autoregressive moving average (ARMA) models, and Kalman filtering-based methods have been widely used in practice [1].
In recent years, various no nlinear models have been proposed for time series prediction [2,3]. One group of models that has garnered strong interest is neural networks(NN)-based models, because of their universal approximation capabili-ties [4,5]. As shown in a wide range of engineering applications, NN-based models have been successfully applied and well a ccepted in numerous practical problems. Among these NN-based models, the feed-forward neural network, also known as the MultiLayer Perceptron Type Neural Network (MLPNN), is the most popu-larly used, and has been applied to solve many difficult and diverse problems. A recurrent neural network (RNN) model with consideration of the internal feed-back was proposed to overcome the inherent limitations of the MLPNN. The RNN has been proven to be more effi cient than the MLPNN in modeling dynamical systems and has been widely used for time series prediction [5]. In this paper, we propose a Multiresolution-based BiLinear Recurrent Neural Network (M-BLRNN) for time series prediction. The proposed M-BLRNN is based on the BLRNN that has been proven to have robust abilities in modeling and predicting time series [6,7]. The proposed M-BLRNN is verified through application to network traffic predictio n. The experiments and results show that the proposed M-BLRNN is more efficient than the traditional MLPNN and the BLRNN with respect to long-ter m prediction of network traffic.

The remainder of this paper is organized as follows: Section 2 presents a review of multiresolution analysis with a wavelet transform. A brief review of the BLRNN is given in Section 3. The proposed M-BL RNN is presented in Section 4. Section 5 presents some experiments and results on a network traffic data set including a per-formance comparison with the traditional MLPNN and BLRNN models. Section 6 concludes the paper. The wavelet transform [8], a novel technology developed in the signal process-ing community, has received much attent ion from neural network researchers in recent years. Several NN models based o n a multiresolution analysis using a wavelet transform have been proposed for time series prediction [9] and signal filtering [10]. The aim of the multiresolution analysis is to analyze a signal at different frequencies with different resolutions. It produces a high quality local representation of a signal in both the time domain and the frequency domain. The calculation of the ` a trous wavelet transform can be described as follows: First, a low-pass filter is used to suppress the high frequency components of a signal while allowing the low frequency components to pass through. The scaling function associated with the low-pass fi lter is then used to calculate the average of elements, which result s in a smoother signal.

The smoothed data c j ( t ) at given resolution j can be obtained by performing successive convolutions with the discrete low-pass filter h , where h is a discrete low-pass filter associ ated with the scaling function and c ( t ) is the original signal. A suitable low-pass filter h is the B 3 spline, defined
From the sequence of the smoothing of the signal, the wavelet coefficients are obtained by calculating the difference b etween successive smoothed versions:
By consequently expanding the original signal from the coarsest resolution level to the finest resolution level, the original signal can be expressed in terms of the wavelet coefficients and the scaling coefficients as follow: where J is the number of resolutions and c J ( t ) is the finest version of the signal. Eq.(3) also provides a reconstruction formula for the original signal. The BLRNN is a simple recurrent neural network, which has a robust ability in modeling dynamically nonlinear systems and is especially suitable for time-series data. The model was initially proposed by Park and Zhu [6]. It has been successfully applied in modeling time-series data [6,7].
 In the following, we explain about a simple BLRNN that has N input neurons, M hidden neurons and where K = N  X  1 degree polynomials is given. The input signal and the nonlinear integration of the input signal to hidden neurons are: where T denotes the transpose of a vector or matrix and the recurrent term is a M  X  K matrix.
 where w p is the weight of bias neuron. A p is the weight vector for the recurrent portion, B p is the weight matrix for the bilinear recurrent portion, and C p is the weight vector for the feedforward portion and p =1 , 2 ..., M . More detailed information on the BLRNN and its learning algorithm can be found in [6,7]. The multiresolution-based learning algorithm attempts to improve the learning process by decomposing the original signal into a multiresolution representation. As stated in Section 2, the original signal is decomposed into a multiresolution representation using the wavelet transform. The representation of the signal at a resolution level j can be calculated as follows: where r j is the representation of the signal at resolution level j , J is the number of resolution levels, c J is the scaling coefficients at resolution level J , x is the original signal, and w j is the wavelet coefficients at resolution level j .Fig.1shows an example of different representations of a signal obtained using the wavelet transform, where r 0 is the original signal, and r 1 ,r 2 ,and r 3 are representations of the signal at resolution levels 1 , 2, and 3, respectively. The figure plots 100 samples from each representation of the signal for easy visualization.
The learning process is performed through J learning phases according to the number of resolution levels J : where L j ( r j ) denotes the learning pha se at resolution level j using representation r .

The learning phase at each resolution level j , L j ( r j ), uses the representa-tion signal r j to update the network weights. The first learning phase L J ( r J ) begins with randomly initialized network weights and the subsequent learn-ing phase L j ( r j ) begins with the updated weights from the previous learning phase L j  X  1 ( r j  X  1 ). It should be noted that only a single BLRNN model is em-ployed to learn the information from the representation at different resolution levels. Fig. 2 shows the learning process using the multiresolution-based learning algorithm. The proposed M-BLRNN is examined and evaluated in terms of its application to the long-term prediction of network traffic. Real-world Ethernet traffic data sets collected at Bellcore in August 1989 [11] are used to conduct experiments. The Ethernet traffic data set is network traffic data measured at each 0.01(s) over two normal hours of traffic corresponding to 10 6 samples of data. The data were downsampled with a time scale of 1(s), resulting in 10,000 data samples. Fig. 3 shows the first 1,000 samples from the network traffic data and Fig. 1 shows an example of different representations of the network traffic data used in the experiments.

In order to measure the long-term prediction performance, the normalized mean square error (NMSE) is employed. The NMSE is calculated by the following formula: where x n represents the true value of the sequence,  X  x n represents the predicted value, and  X  represents the variance of the orig inal sequence over the prediction duration N .

Fig. 4 shows the prediction performan ce over 100 steps of prediction for the traditional MLPNN, the BLRNN, and the proposed M-BLRNN in terms of the NMSE. The performance of the MLPNN is obtained using a MLPNN model with a structure of 24-10-1, where 24, 10, and 1 are the number of input neu-rons, hidden neurons, and output neurons, respectively. The performance of the BLRNN is obtained using a BLRNN model with a structure of 24-10-1 and 3 recursion lines. The result of the proposed M-BLRNN is obtained using a M-BLRNN model with a structure of 24-10-1, 3 recursion lines, and 3 resolution levels. The MLPNN and the BLRNN are trained with 3,000 iterations while the M-BLRNN is trained with 1,000 iterations at each learning phase. As can be seen from Fig. 4, the proposed M-BLRNN outperforms both the traditional MLPNN and the BLRNN. Moreover, when the number of steps increases, the performance of the traditional MLPNN and the BLRNN degrades significantly while the proposed M-BLRNN suffers from a minor degradation of performance. This implies that the proposed M-BLRNN is more robust than the traditional MLPNN and the BLRNN for long-term prediction of time series. A Multiresolution-based BiLinear Recurrent Neural Network (M-BLRNN) for time series prediction is proposed in this paper. The proposed M-BLRNN em-ployed the wavelet transform to decompose the signal into a multiresolution representation. The learning process based on the multiresolution-based learn-ing algorithm is performed by learning from each representation of the signal at each level of resolution. The proposed M-BLRNN is applied to the network traffic prediction. The experiments and results verified that the proposed M-BLRNN is more efficient than the traditional MLPNN and the BLRNN with respect to long-term prediction of time series. The promising results from this paper provide motivation to utilize the proposed M-BLRNN in other practical applications.

