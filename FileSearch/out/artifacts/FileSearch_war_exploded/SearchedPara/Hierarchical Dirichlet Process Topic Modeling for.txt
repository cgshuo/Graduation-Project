 [4,5]. 
Answer type is the type of the information that a u ser wants to find; it sets a bo u n-wife? X  and classifies the answer type as  X  P ERSON X . B u t this LS P approach is based answer type trainin g data when classifyin g the answer type [8,9,10]. IBM Watson showed some new approaches that g enerate a candidate answer witho u t types increases or if the answer type is not predefined, the classification acc u racy of answer type problem. O u r new method works reasonably well with UIUC data and is data. 2.1 Unsupervised Model: Hiera rchical Dirichlet Process We propose a model that u ses HD P [13], which is widely-u sed for topic modelin g to overcome lar g e scale and the problem of u ndefined answer types. A topic is a m u lti-u sed for doc u ment cl u sterin g . We adapted HD P to sentence cl u sterin g . that are u sef u l for answer -g enerated from an u nlimit e the answer type. The ans w q u estion. Unlike Latent D defined n u mber of possible 
O u r model consists of fi a Griffiths-En g en-McClos k distrib u tion  X  . P rocess (2) distrib u tion  X  to g enerate distrib u tion of  X  to g enera t as a feat u re vector f by e a cl u ster ID, which is the mo is the m u ltinomial distri b g enerate emission probabil i a certain cl u ster ID. In th e cl u sterin g is u sed to assi g n type. 2.2 Similarity Measur e Similarity is comp u ted to d sine similarity (1): where A and B are feat u re v the vector, n is the size of val u e in the feat u re vectors .
 We combined the HD P an d sifier (Fi g . 2). We represen in this vector are similar t o feat u re. We divided the m o and a testin g answer-type c l
In the trainin g part, the inp u t feat u re vectors into H ives a cl u ster ID ta g , i.e., a trainin g . After classifier tra i inp u t feat u re vectors, we g e
We u sed the classifier m the cl u ster ID of each feat u feat u re vector and the trai n same cl u ster ID in the HD P to the test data and classifi e ity of these n -best answer t y
We u se these methods model HD P with comp u t a classes. Also, we can u se u sification model. Most clas s sify a lar g e n u mber of cla s n u mber of classes. We compared o u r answer-t y a discriminative model a n in this field, and Yahoo! answers data which is more familiar than UIUC data and has work reasonably well with both UIUC data and Yahoo! answers data. 3.1 Data g rained answer, or as one of 50 types of fine-g rained answer. The data consist of 500 Conference) 8 and TREC 9 q u estions, and 500 q u estions from TREC 10 which serves as a test set. cate g ory of u ser q u estions as an answer type. 3.1.1 Features  X  Foc u s : We extracted the foc u s which is the head of the q u estion type.  X  Ex) What is the lon g est river in New So u th Wales? LAT: river  X  Sometimes the LAT in a sentence is diffic u lt to detect. Ex) What did Br u ce Carver die from? 
The answer type is maybe death ca u se or somethin g else, so the exact LAT is diffi-r u le based approach. It can be f u rther improved. 3.1.2 Evaluation data, and we u sed ~25,000 Yahoo! answers q u estions data. The n u mber of main cate-relative lack of trainin g data compared to the n u mber of labels. We provide only the cation). 3.2 Data Flow represents mod u le (Fi g . 3). 3.3 Experimental Result  X  Gibbs samplin g , a stochastic proced u re that prod u ces samples from the posterior dis-trib u tions. The cl u sterin g res u lts were obtained after 500 iterations. al g orithm: HD P and LDA (Fi g . 4 and Fi g . 5). 
We u sed UIUC Answers data with vario u s answer type cate g ories. As the n u mber cl u ster. The recall is almost 1. those methods (Table 1) beca u se o u r model achieved acc u racy that was independent types. 
When we u sed UIUC data, we compared the acc u racy of o u r method with existin g methods to show that o u r method works reasonably well compared to the state-of-the six coarse classes and the 50 fine classes. [10] u sed SVM and CRF; compared to [10] classes. tracted by the NL P tool (clear NL P ) feat u res can have many errors. than other methods, especially when the n u mber of answer types is lar g e. O u r method was 9.8 % more acc u rate than the ME classifier in 235 Yahoo! answer types, beca u se the ME classifier is sensitive to the n u mber of answer types (Table 3). 
Usin g HD P topic modelin g , we devised a classifier model that needs neither a list fy a real answer type. The acc u racy of the proposed method is almost independent of systems are becomin g increasin g ly complex [12], [14], so the n u mber of answer types to classify is increasin g . However, many other methods have low acc u racy when clas-problem. We showed a novel approach to find answer type by applyin g an HD P topic model to achieves reasonable acc u racy in a small set of answ er type compared to previo u s me-answer for u ser q u estion in real time. However, when an extremely lar g e answer type is needed, o u r method can be a valid alternative to the existin g methods. IBM Watson findin g appropriate n . has the same acc u racy as the one that u ses ta gg ed trainin g data. MSI P /IIT P [10044508, Development of Non-Symbolic Approach-based H u man-tion of Korean (NRF) [ NRF-2014R1A2A1A01003041, Development of m u lti-party anticipatory knowled g e-intensive nat u ral lan gu a g e dialo g system]. 
