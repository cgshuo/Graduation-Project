 1. Introduction
Nowadays, large organizations typically have a wide variety of process models [17] . Some examples are: reference models (e.g., the EPC models in the SAP R/3 reference model [24] ); workflow models (e.g., models used for enactment in systems like Staffware, FLOWer, FileNet, Oracle BPEL, etc. [2] ); business process mod-(e.g., the Partner Interface Processes in RosettaNet [30] , the abstract BPEL processes in the context of web services [9] , choreography descriptions using WSCDL [23] , or other ad hoc notations [33] ); and/or process models discovered using process mining techniques [5,6] . Given the co-existence of different models and dif-ferent types of models, it is interesting to be able to compare process models.
This comparison of process models applies to different levels ranging from models at the business level to models at the level of software components (e.g., when looking for a software component matching some spec-ification). To compare process models in a meaningful manner, we need to assume that these models have semantics. Moreover, we need to assume some equivalence notion (When are two models the same?). People working on formal methods have proposed a wide variety of equivalence notions [1,19,26] , e.g., two models may be identical under trace equivalence but are different when considering stronger notions of equivalence able to put more emphasis on the frequently used parts of the model.

To clarify the problem, let us consider Fig. 1 where four process models (expressed in terms of Petri nets over, the Petri net in Fig. 1 d allows for ACDFDE which is not possible in any of the other models. Note that be to simply compare the sets of transition labels, e.g., nets (a) and (b) have the same transition labels: Another approach could be to consider the state spaces or sets of possible traces of both models. However, in that case the problems are that there may be infinitely many traces/states and that certain paths are more probable.

In this paper, we investigate these problems and propose a completely new approach. The main idea is to comparing different models. Even models having infinitely many execution sequences can be compared and automatically the relevance of each difference can be taken into account. Moreover, as we will show, we can capture the moment of choice and analyze causalities that may not be explicitly represented in the log. sents an execution sequence that may or may not fit in the models at hand. Moreover, frequencies are given, moreover, this Petri net does not allow for any execution sequences not present in the log. In this paper, we model, but to compare models in the presence of some event log as shown in Fig. 1 f. Compare for example ilarity although none of the traces still fits (they all contain D ).

To quantify differences between two models, we introduce precision and recall measures. Precision measures are used to define whether the second model X  X  behavior is possible according to the first model X  X  behavior. Recall measures are used to quantify how much of the first model X  X  behavior is covered by the second model.
This paper extends the results presented in [4] in three ways. Firstly, we investigate what can be inferred about the values of the defined precision and recall measures for two models  X  say model and some typical behavior  X  say log  X  when we know the measure values for these models when compared to another model  X  say model 2  X  with respect to log . In other words, if the precision and recall values for and recall measures defined in this paper indicate that these models have the same behavior with respect to a to compare models in an approximate manner. Moreover, in this domain the assumption of having example behavior in terms of event logs is very natural.

The remainder is organized as follows. After providing a brief overview of related work, we introduce some preliminaries required to explain our approach. Although we use Petri nets to illustrate our approach, any other process model with some local execution semantics (e.g., EPCs, activity diagrams, BPMN, etc.) could be used. In Section 4 , we present two naive approaches (one based on the static structure and one based containing typical behavior. These notions have been implemented in ProM [16] . In sections 6and7 we reason and conclude the paper. 2. Overview of various equivalence notations and related work
In the literature, many equivalence notions have been defined for process models. Most equivalence notions focus on the dynamics of the model and not on the syntactical structure (e.g., trace equivalence and bisimu-lation [1,19,26] ).

This paper uses Petri nets as a theoretical foundation [14,22,29] .In [28] an overview is given of equiva-nets. Most authors translate a Petri net to a transition system to give it semantics. However, there are also authors that emphasize the true-concurrency aspects when giving Petri nets semantics. For example, in [13] the well-known concept of occurrence nets (also named runs) are used to reason about the semantics of Petri nets.

Any model with formal/executable semantics (including Petri nets) can be translated to a (possibly infinite) transition system. If we consider transition systems, many notions of equivalence have been identified. The weakest notion considered is trace equivalence : two process models are considered equivalent if the sets of and (2) trace equivalence does not capture the moment of choice. The first problem can be addressed in var-ond problem requires stronger notions of equivalence. Bisimulation and various kinds of observation equivalence [26] attempt to capture the moment of choice. For example, there may be different processes hav-finer equivalence notion than the well-known observation equivalence [26] . A comparison of branching bisim-ilarity, observation equivalence, and a few other equivalences on processes with silent behavior can be found inheritance relations in [1] are based on branching bisimilarity.

All references mentioned so far, aim at a  X  X  X rue/false X  X  answer. Moreover, they do not take into account that some parts of the process may be more important than others. Few people (e.g., [15] ) have been working on an excellent overview of this work and also links to the probability theory community working on metrics on spaces of measures. In this paper, we use a different approach. We do not assume that we know any proba-bilities. Instead we assume that we have some example behavior than can serve as a basis for a comparison of two models. Also related is the work on metric labeled transition systems where the  X  X  X ehavioral difference X  X  between states is a non-negative real number indicating the similarity between those states [11] . This way one can define a behavioral pseudometric to compare transition systems as shown in [11] . Note that this approach very much depends on an explicit notion of states and it is not clear how this can be applied to a practical, mainly activity oriented, setting.

As far as we know, this paper and our work in [4] are among the first to propose the use of  X  X  X ypical behav-mentioned in this section. Moreover, we show that this can be used in the context of process mining [3,5,6] . 3. Preliminaries
This section introduces some of the basic mathematical and Petri net related concepts used in the remainder. 3.1. Multi-sets, sequences, and matrices defined in a straightforward way and they can handle a mixture of sets and multi-sets. The operators are also robust with respect to the domains of the multi-sets, i.e., even if X and Y are defined on different domains, X + Y , X Y , and X 6 Y are defined properly by extending the domain where needed. j X j X  the size of some multi-set X over A .
 ping r 2 {1, ... , n } ! A . Such a sequence is represented by a string, i.e., r = h a sequence.
Every multi-set can be represented as a vector, i.e., X 2 B  X  A  X  can be represented as a row vector ( X ( a 1 ), X ( a 2 ), ... , X ( a n )) where a 1 , a 2 , ... , a the corresponding column vector ( T transposes the vector). Assume X is an k  X   X  matrix, i.e., a matrix with k rows and  X  columns. A row vector can be seen as 1  X   X  matrix and a column vector can be seen as a k  X  1 vector. X ( i , j ) is the value of the element in the i and Y an  X   X  m matrix. The product X  X  Y is the product of X and Y yielding a k  X  m matrix, where X Y  X  i ; j  X  X  X + Y .

For any sequence r 2 {1, ... , n } ! A over A , the Parikh vector ~ r maps every element a of A onto the num-ber of occurrences of a in r , i.e., ~ r 2 B  X  A  X  where for any a 2 A : ~ r  X  a  X  X  3.2. Petri nets
This subsection briefly introduces some basic Petri net terminology [14,22,29] and notations used in the remainder.
 ( P \ T = ; ), and F ( P  X  T ) [ ( T  X  P ) is a set of arcs (flow relation).
 Fig. 1 shows four Petri nets. Places are represented by circles and transitions are represented by squares.
For any relation/directed graph G A  X  A we define the preset  X  a ={ a a  X  ={ a 2 j ( a , a 2 ) 2 G } for any node a 2 A . We use  X  p 5={ D }, A  X  ={ p 2, p 3},  X  A ={ p 1}, etc.

At any time a place contains zero or more tokens , drawn as black dots. The state of the Petri net, often nets shown in Fig. 1 only one place is initially marked ( p 1). Note that more places could be marked in the initial state and that places can be marked with multiple tokens.
 B or C ). In the following definition, we formalize these notions.

Definition 2 ( Firing rule ). Let N =( P , T , F )bea Petri net and M 2 B  X  P  X  be a marking.  X  enabled ( N , M )={ t 2 T j M P  X  t } is the set of enabled transitions,  X  result ( N , M , t )=( M  X  t )+ t  X  is the state resulting after firing t 2 T , ing M 0 (i.e., M 0 = result ( N , M , t )). can extend this notion to firing sequences. Suppose r = h t some Petri net N with initial marking M .( N , M )[ r i ( N , M h M 0 , M 1 , ... , M n i where M 0 = M , M n = M 0 , and for any 0 6 i &lt; n :( N , M we define the set of reachable markings R ( N , M ) as follows: R  X  N ; M  X  X f M Note that M 2 R ( N , M ) because M is reachable via the empty sequence.
 becomes clear when considering the incidence matrix of a Petri net.

Definition 3 ( Incidence matrix ). Let N =( P , T , F )bea Petri net and M 2 B  X  P  X  be a marking.  X  e N is the incidence matrix of N , i.e., e N is a j P j  X  j T j matrix with  X  result  X  N ; M ; r  X  X  M  X  e N ~ r is the state resulting after firing r 2 T * ,
The incidence matrix of a Petri net can be used for different types of analysis, e.g., based on ( N , M )[ r i ( N , M 0 ), then result ( N , M , r )= M a negative number of tokens. The reason we need such concepts is because we will later compare Petri nets even if they were not enabled. 4. Naive approaches
In this paper we propose to compare two processes on the basis on some event log containing typical behav-ior. However, before presenting this approach in detail, we first discuss some naive approaches. 4.1. Equivalence of processes based on their structure
When humans compare process models they typically compare the graphical structure, i.e., do the same from the precise split and join behavior (i.e., we do not distinguish between AND/XOR-splits/joins). In other words, we derive a simple graph where each node represents an activity and each arc some kind of connection. of view the models are not equivalent but similar. When quantifying the overlap relative to the whole model recall as specified below. 2
Definition 4 ( Structural precision and recall ). Let N 1
Using C 1  X f X  t 1 ; t 2  X 2 T 1 T 1 j t 1 N 1 \ N 1 t 2 6  X ;g and C precision S ( N 1 , N 2 ) is the fraction of connections in N high because all connections in the second model exist in the first model. recall model appear in the second model. Note that here we think of N  X  X  X ew model X  X  that we want to compare with the original one.

Let N a , N b , N c , and N d be the four Petri nets shown in Fig. 1 .
Note that precision S ( N 1 , N 2 )= recall S ( N 2 , N 1 only list some precision values: precision S ( N a , N b ) = 0.6, precision 8 = 0.75, precision S ( N b , N a ) = 3/6 = 0.5, precision
If we consider N a to be the initial model, then N c has the best precision of the other three models because all connections in N c also appear in N a . Moreover, if we consider N the best recall because all connections in N a also appear in N
The precision and recall figures for the four process models in Fig. 1 seem reasonable. Unfortunately, mod-els with nearly identical connections may be quite different as is shown in Fig. 2 . Let N four Petri nets shown in Fig. 2 . 3 Although precision S ( N ferent. In N a transitions B and C are executed concurrently while in N transitions. However, although N a and N c are structurally different ( precision identical behaviors. These examples show that Definition 4 does not provide a completely satisfactory answer when it comes to process equivalence. Nevertheless, precision indicators for selecting a similar model, e.g., in a repository of reference models. 4.2. Equivalence of processes based on their state space or traces
Since process models with a similar structure may have very different behaviors and models with different firing sequences of two marked Petri nets.

Definition 5 ( Naive behavioral precision and recall ). Let N firing sequences be finite: do not explicitly mention these, i.e., precision B ( N 1 , N recall B (( N 1 , M 1 ),( N 2 , M 2 )).

Let N a , N b , N c ,and N d be the four Petri nets shown in Fig. 2 and S firing sequences. S a ={ h A , B , C , D i , h A , C , B , D i }, S because there are no identical full firing sequences possible in both models. However, precision and recall B ( N a , N c ) = 1 and precision B ( N b , N d
We can also consider the four process models in Fig. 1 . The fourth model ( N firing sequences. Therefore, we focus on the first three models: N
N : precision B ( N a , N b ) = 2/2 = 1 and recall B ( N a , N in N a but not the other way around. Although N c differs from N when comparing with N a , i.e., precision B ( N a , N c )=1and recall
These examples show that Definition 5 provides another useful quantification of equivalence quite different from Definition 4 . However, also this quantification has a number of problems:
Petri net shown in Fig. 1 d. For such models, the metric becomes useless. 2. The models need to be terminating , i.e., it should be possible to end in a dead marking representing the completion of the process. Note that models may have unintentional livelocks or are designed to be non-terminating. For such models, we cannot apply Definition 5 in a meaningful way. It also does not make because this would include the prefixes of both terminating and non-terminating sequences. As a result, new problems are introduced, e.g., more emphasis on the behavior typically contained in prefixes and possibly infinite sets. 3. Definition 5 does not take into account differences between important paths or parts versus unimportant paths or parts of the model. For example, certain full firing sequences may have a very low probability in comparison to other sequences that occur more frequent . There may be parts of the process model that (earlier named  X  X  X rocess arteries X  X ). Clearly this should be taken into account. sequence. In Fig. 2 precision B ( N a , N b ) = 0 and recall and end with D . criterion. Many authors [1,19,26] have emphasized the importance of preserving the moment of choice by defining notions such as observation equivalence, bisimilarity, branching/weak bisimilarity, etc. To illus-trate the importance of preserving the moment of choice, consider N cesses. In N b in Fig. 2 b there is no state where only B or just C is enabled. However, such states exist in
N d in Fig. 2 d, e.g., there can be a token in p 2 enabling only B . Suppose that B and C correspond to the receipt of different messages sent by some environment. In this case, N possible in N b .

The problems listed above show that similarity metrics based on criteria directly comparing all possible where states are related in such a way that any move of one process model can be followed by the other one and vice-versa [1,19,26] . However, this would only solve some of the problems listed above. Moreover, 5. Equivalence of processes in the context of observed behavior
To overcome the problems highlighted so far, we propose an approach that uses exemplary behavior to compare two models. This exemplary behavior can be obtained on the basis of real process executions (in case the process already exists), user-defined scenarios, or by simply simulating one of the two models (or both). We assume this exemplary behavior to be recorded in an event log .
 Definition 6 ( Event log ). An event log L is a multi-set of sequences on some set of T , i.e., L 2 B  X  T  X  . sequences may exist independent of some model and the same sequence may occur multiple times. inspired by earlier work on genetic mining and conformance checking [25,31] .

Definition 7 ( Fitness ). Let ( N , M ) be a marked Petri net and let L 2 B  X  T  X  be a multi-set over T . strange cases occur (empty event log or an empty sequence), then we can simply assume that 0/0 = 0.
As an example, consider the event log L shown in Fig. 1 f containing 160 traces. Clearly, fitness ( N because all sequences in L can be reproduced by N a (15 * 3/4) + (20 * 3/4))/160 = 0.945, fitness ( N c , L ) = ((40 a particular sequence can be  X  X  X artly fitting X  X , e.g., if we parse sequence h A , B , D , E i using N the sequence fits. When forcing the execution of h A , B , D , E i using N after firing D , the last event in the sequence ( E ) is not enabled. Hence, only two of the four events in rather than considering whole sequences like in Definition 5 . Using Definition 7 , fitness ( N ever, if we would focus on completely fitting sequences, fitness ( N considerably lower because partly fitting are ignored.

Inspired by the definition of fitness, we would like to compare two models on the basis of a log. A straight-forward extension of Definition 7 to two models is to compare the overlap in fitting or partially fitting sequences. However, in this case one only considers the actual behavior contained in the log. Therefore, we point in the sequence . This idea results in the following definition of precision and recall.
Definition 8 ( Behavioral precision and recall ). Let ( N
L 2 B  X  T  X  be a multi-set over T . 6 shown in Fig. 2 . precision ( N a , N b , L ) = ((2/4 * 3 = 0.75 and recall ( N a , N b , L ) = ((2/4 * (1/1 + 2/2 + 0/1 + 1/1)) + (1/4 precision ( N a , N c , L )= recall ( N a , N c , L )=1.
 ( N a , N b , L ) = ((40/4 * (1/1 + 2/2 + 1/1 + 1/1)) + (85/4 1/1)) + (20/4 * (1/1 + 2/2 + 2/3 + 1/1)))/160 = 0.98 and recall ( N 1)) + (85/4 * (1/1 + 2/3 + 1/1 + 1/1)) + (15/4 * (1/1+2/3+2/2+1/1))+(20/4 frequent. Let us now compare N a and N d in Fig. 1 using L . precision ( N 1 + 1/2)) + (85/4 * (1/1 + 3/3 + 1/1 + 1/2)) + (15/4 * (1/1 + 3/3 + 2/3 + 1/2)) + (20/4 2)))/160 = 0.75 and recall ( N a , N d , L ) = ((40/4 * (1/1 + 3/3 + 1/1 + 1/1)) + (85/4 (15/4 * (1/1 + 3/3 + 2/2 + 1/1)) + (20/4 * (1/1 + 3/3 + 2/2 + 1/1)))/160 = 1. Note that N not present in log L (i.e., executing F ). Nevertheless, as we can see from precision ( N enabling of F is taken into account. It is also easy to see that Definition 8 takes into account the moment Hence, we can distinguish N b and N d in Fig. 2 . 7 addresses each of these problems: traces. 2. Models do not need to be terminating. 3. Differences between frequent and infrequent sequences can be taken into account by selecting a represen-tative log. 4. Partial fits are taken into account, i.e., small local differences do not result in a complete  X  X  X isfit X  X . 5. The moment of choice is taken into account because the focus is on enabling.
Given the attractive properties of the precision and recall metrics defined in Definition 8 , we have imple-mented these metrics in the ProM framework [16] . 8 Here it has been applied to a variety of process models as will be discussed in Section 8 .
 We propose to use existing event logs or to generate artificial logs using simulation .
Existing logs can be extracted from information systems but can also be obtained by manually describing events. For example, any user action is logged in ERP systems like SAP R/3, workflow management systems like Staffware, and case handling systems like FLOWer. Classical information systems have some centralized record the interactions between web services (e.g., in the form of SOAP messages). Moreover, today X  X  orga-nizations are forced to log events by national or international regulations (cf. the Sarbanes X  X xley (SOX) Act [32] that is forcing organizations to audit their processes).

An example application scenario where existing event logs are used is the comparison of an existing process and a set of possible redesigns. For each of the redesigns, we can measure the precision and recall taking an ity of the initial model. Then, if the quality is acceptable, each of the redesigns can be compared with the existing process using this log.

Another approach would be to use simulation. This simulation could be based on both models or just the initial model. Note that the generated logs do not need to be complete, because Definition 8 also takes the in the  X  X  X rocess veins X  X  are of less importance than differences in the  X  X  X rocess arteries X  X . 6. When are behavioral precision and recall metrics  X  X  X ransitive X  X ? behavioral precision and recall metrics (cf. Definition 8 ) for three models and a log. In other words, given that you have (i) three process models N 1 , N 2 and N 3 with the respective initial markings M
M , (ii) an event log L and (iii) the values for the precision and recall metrics for N
N and N 3 over the same log L and using the respective initial markings, we analyze what can be said in Table 1 .

To understand Table 1 , we formulate our main question as follows. Suppose we have three marked nets ( N and recall metrics are known: precision (( N 1 , M 1 ),( N sion (( N 2 , M 2 ),( N 3 , M 3 ), L )= x and recall (( N values of the precision((N 1 ,M 1 ),(N 3 ,M 3 ),L) and the recall((N are motivated in the remainder. Note that rather than providing formal proofs we give core arguments. How-ever, first we provide an obvious lemma (cf. Lemma 1 ). Using the insights from this lemma, we show the rea-soning behind the 16 scenarios in Table 1 .
Lemma 1. Let (N 1 ,M 1 ) and (N 2 ,M 2 ) be two marked Petri nets and let L be a log.  X  If precision (( N 1 , M 1 ),( N 2 , M 2 ), L ) = 1.0 then " ( N 2 , M 2 , hd ( r , i ));  X  If recall (( N 1 , M 1 ),( N 2 , M 2 ), L ) = 1.0 then " ( N 2 , M 2 , hd ( r , i ));  X  If precision (( N 1 , M 1 ),( N 2 , M 2 ), L )= recall (( N hd ( r , i )) = enabled ( N 2 , M 2 , hd ( r , i )).
 and recall values will be less then 1 . h
Scenario 13, 14, 15 and 16. Since N 1 and N 2 have the exact same enabled transitions while replaying the log (i.e, precision (( N 1 , M 1 ),( N 2 , M 2 ), L ) = 1.0 and recall (( N the enabled transitions of N 1 and of N 3 while replaying the log will be the same as for N we can conclude that precision (( N 1 , M 1 ),( N 3 , M 3 ( N 3 , M 3 ), L )= recall (( N 2 , M 2 ),( N 3 , M 3 ), L ).

Scenarios 4, 8 and 12. Scenarios 4, 8 and 12 are similar to scenarios 13, 14 and 15. Just swap the models N and N 3 in Fig. 3 to get the scenarios already explained for 13, 14 and 15.

Scenario 6. For this scenario, recall (( N 1 , M 1 ),( N 3 sitions that are enabled in N 1 are also in N 2 (i.e., recall (( N that are enabled in N 2 are also in N 3 (i.e., recall (( N transitions that are enabled in N 1 are also going to be enabled in N because these transitions are contained in the set of transitions that were enabled for N the value of recall (( N 2 , M 2 ),( N 3 , M 3 ), L ). precision (( N because, since recall (( N 1 , M 1 ),( N 2 , M 2 ), L ) = 1.0 and precision (( N between the enabled transitions in N 3 and N 1 (cf. numerator for the precision formula in Definition 8 ) can same number (i.e., the denominator  X  X  j enabled ( N 3 , M clude that precision (( N 1 , M 1 ),( N 3 , M 3 ), L )&lt; precision (( N Scenario 11.

Scenario 10. Since all transitions enabled for N 2 during the log replay are also enabled in N sion (( N 1 , M 1 ),( N 2 , M 2 ), L ) = 1.0) and in N 3 (cf. recall (( N fewer intersecting transitions that are enabled at a given moment than the enabled transitions for N ever, since we do not make any assumptions about the transitions in these models, it is possible that N
N 3 have more enabled transitions in common while replaying the log than they have with N can conclude that precision (( N 1 , M 1 ),( N 3 , M 3 ), L ) P precision (( N ( N 3 , M 3 ), L ) P recall (( N 1 , M 1 ),( N 2 , M 2 ), L ).

Scenario 9. For this scenario, precision (( N 1 , M 1 ),( N while replaying the log, in the worst scenario, N 3 will have at least as many elements in common with
N 1 as it has with N 2 . Note that N 3 allows for more behavior than N sion (( N 2 , M 2 ),( N 3 , M 3 ), L )= x ), but all the behavior enabled in N than it has with N 2 . However, nothing can be said about recall (( N more or fewer enabled transitions than N 3 . Therefore, recall (( N between 0 (inclusive) and 1 (inclusive).

Scenario 5. For this scenario, precision (( N 1 , M 1 ),( N recall (( N 1 , M 1 ),( N 3 , M 3 ), L ) 6 1. precision (( N since (i) all enabled transitions in N 1 are also enabled in N recall (( N 1 , M 1 ),( N 2 , M 2 ), L ) = 1.0) and (ii) N has with N 2 . However, note that N 3 can have fewer transitions in common with N because N 2 has behavior that is not in N 1 (cf. precision (( N ( N 3 , M 3 ), L ) 6 1 because, while replaying the log, N in N 3 . Note that, although recall (( N 1 , M 1 ),( N 2 , M not intersect with the enabled ones for N 3 because recall (( N
Scenario 2. In this scenario, we can infer that recall (( N and precision (( N 1 , M 1 ),( N 3 , M 3 ), L ) &lt; 1. Let us first have at look at why recall (( N recall (( N 1 , M 1 ),( N 2 , M 2 ), L ). From the value of the recall metric for N ( N 3 , M 3 ), L ) = 1), we know that all transitions enabled in N log. Thus, when assessing the recall metric for N 1 and N
N 1 has at least as many enabled elements in common with N cision (( N 2 , M 2 ),( N 3 , M 3 ), L ) 5 1 (i.e., some of the enabled transitions in N be that N 1 has more elements in common with N 3 than with N ( N 3 , M 3 ), L ) P recall (( N 1 , M 1 ),( N 2 , M 2 ), L ). Now, let us analyze why precision (( N This happens because we cannot be sure if N 3 will have more or less enabled elements in common with
N 1 than it has with N 3 . We only know that N 3 cannot have all enabled transitions in common with N because precision (( N 1 , M 1 ),( N 2 , M 2 ), L ) 5 1 and recall (( N sion (( N 1 , M 1 ),( N 3 , M 3 ), L ) can assume any value but 1.

Scenario 3. The recall (( N 1 , M 1 ),( N 3 , M 3 ), L ) 6 recall (( N transitions for N 3 are also enabled for N 2 (cf. precision (( N have more enabled transitions with N 1 than it has with N in common with N 3 than with N 2 . That is why recall (( N precision (( N 1 , M 1 ),( N 3 , M 3 ), L ) 6 1.0 because the fact that precision (( N not prevent that all enabled transitions in N 3 are also enabled in N can assume any value between 0 (inclusive) and 1 (inclusive).

Scenario 7. In this scenario, we know that all the enabled transitions for N are also enabled for N 2 because recall (( N 1 , M 1 ),( N
However, since we do not know how much behavior of N 2 intersects with the behavior of N be that N 1 and N 3 have the same enabled transitions or that they do not have a single transition in common while replaying the log. In other words, precision (( N 1 assume any value between 0 (inclusive) and 1 (inclusive).

Scenario 1. In this scenario, the precision and recall metrics for N (inclusive) and 1 (inclusive) because the fact that precision (( N ( N 2 , M 2 ), L ) 5 1, precision (( N 2 , M 2 ),( N 3 , M vent N 1 and N 3 of having precision (( N 1 , M 1 ),( N 3 illustration, just think of the situation in which the two models N behavior than the model N 2 .
 these values. 7. Behavioral precision/recall and process equivalence in general this imply that these two models are behaviorally equivalent? In other words, does this mean that all the section we illustrate situations in which precision ( N 1 capture the exact same behavior. The situations are: equal to 1 (i.e., fitness (( N 1 , M 1 ), L )&lt;1or fitness (( N tion. Note that none of the models in Fig. 4 fit the log, but they always have the same enabled transitions when replaying the traces of the log in 4 c and with the respective initial markings in 4 aand 4 b. same enabled transitions when parsing the log. Furthermore, both models completely fit the log. However, these models are not behaviorally equivalent. If the log would contain any trace with the tasks C or E, the behavioral differences would have been captured by the precision and recall metrics in Definition 8 .
The reason is that the log may not contain enough behavior such that the precision and recall metrics can capture differences between models. This situation is illustrated in Fig. 6 .
Our aim with showing the three situations above is to make the reader aware of the  X  X  X imitations X  X  of the 8. Application to genetic mining
Process mining aims at extracting information from event logs to capture the business process as it is being enforcing people to work in a particular way. Consider for example a hospital where the diagnosis and treat-the  X  X  X areflow X  X . A variety of process mining algorithms have developed [5 X 7,12,21] , including our approach based on genetic process mining [3,8,25] .
Unfortunately, existing approaches for mining the process perspective have problems dealing with issues such problem because it is no longer clear to which activity some event refers. The problem with hidden activities problematic because it is not possible to separate choice from synchronization. We consider two sources of goal of genetic process mining [3,25] is to overcome these problems.

Genetic process mining is the application of genetic algorithms to process mining. Genetic algorithms are main steps of our genetic approach. Once the log is read (Step I), the algorithm randomly builds an initial the log. Populations evolve by selecting the fittest individuals and generating new individuals using genetic operators such as crossover (combining parts of two of more individuals) and mutation (random modification criteria (like maximum number of generations) are met (Step IV). The  X  X  X est fitting X  X  discovered model that for the parsing of too much extra behavior that cannot be derived from the behavior observed in the log).
Fig. 8 shows a screenshot of the Genetic algorithm plug-in in the ProM framework. The ProM framework can be downloaded from www.processmining.org and supports the development of plug-ins to mine event logs.
 approach we do not only take real-life logs (e.g., from SAP, Staffware or FLOWer) but also generate logs from logs from) with the  X  X  X iscovered model X  X  (i.e., the one obtained using process mining). Experience shows that instance, there is more than one complete and precise model that can be discovered for a given log, or simply as a basis for comparison.

Figs. 8 and 9 show some results obtained by applying the genetic algorithm to the log L = rithm in ProM. Fig. 9 shows the precision and recall values over 50 runs. The results show that the genetic algorithm found a model with the same structure and behavior as the original model for most of the runs. The Petri net representation of the mined model for these runs looks like the one in Fig. 8 c. Note that this in the log tell us that the task F is only executed when the task C has been executed. A similar observation and 8, the genetic algorithm found a model that is a substructure of the original model ( precision recall S = 0.875) and allows for more behavior than the original model ( precision = 0.933 and recall = 1).
The mined model for both runs was exactly the same. The Petri net representation for this mined model is shown in Fig. 10 a. Fig. 10 b shows the mined model for runs 19, 22, 41 and 45. Note that, as indicated by the metrics, this mined model has the same behavior as the original one ( precision = 1 and recall = 1) and sion/recall metrics allows us to measure how well the genetic algorithm is doing when mining process models.
The metrics make it possible to analyze the similarity of the original and mined models in terms of possible behavior and thus quantify their differences. 9. Conclusion
This paper has presented a novel approach to compare process models. Existing approaches typically do not quantify equivalence, i.e., models are equivalent or not. However, for many practical applications such an approach is not very useful, because in most real-life settings we want to distinguish between marginally different processes and completely different processes. We have proposed and implemented notions of fitness , event log with typical execution sequences as a starting point. This allows us to overcome many of the prob-lems associated with approaches directly comparing processes at the model level. Although our approach is BPMN, or UML activity diagrams.

We have applied the approach in the context of process mining. However, the notions of precision and recall can be applied in a wide variety of situations, e.g., to measure the difference between an organiza-tion (e.g., PIPs or abstract BPEL), or to compare an existing process model with some redesign. In our future work, we would like to explore more of these applications, e.g., comparing clinical guidelines.
References
