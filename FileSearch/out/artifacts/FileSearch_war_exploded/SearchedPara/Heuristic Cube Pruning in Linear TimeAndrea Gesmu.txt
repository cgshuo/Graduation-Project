 Since its first appearance in (Huang and Chiang, 2005), the Cube Pruning (CP) algorithm has quickly gained popularity in statistical natural language pro-narios in which we have the k -best solutions for two input sub-problems, and we need to compute the k -best solutions for the new problem representing the combination of the two sub-problems.

CP has applications in tree and phrase based ma-chine translation (Chiang, 2007; Huang and Chi-ang, 2007; Pust and Knight, 2009), parsing (Huang and Chiang, 2005), sentence alignment (Riesa and Marcu, 2010), and in general in all systems combin-ing inexact beam decoding with dynamic program-ming under certain monotonic conditions on the def-inition of the scores in the search space.
 Standard implementations of CP run in time put/output beams (Huang and Chiang, 2005). Ges-mundo and Henderson (2010) propose Faster CP (FCP) which optimizes the algorithm but keeps the O ( k log( k )) time complexity. Here, we propose a novel heuristic algorithm for CP running in time O ( k ) and evaluate its impact on the efficiency and performance of a real-world machine translation system. Let L = h x an ordered sequence of real numbers, possibly with repetitions. We write |L| = k to denote the length of L . We say that L is descending if x and L over R . We write L list with elements x k and 0  X  j &lt; k  X  .

In cube pruning (CP) we are given as input two descending lists L k , and we are asked to compute the descending list consisting of the first k elements of L
A problem related to CP is the k -way merge problem (Horowitz and Sahni, 1983). Given de-scending lists L lists L from the lists L
For  X   X  R we define shift ( L ,  X ) = L X  X   X  i . In words, shift ( L ,  X ) is the descending list whose ele-ments are obtained by  X  X hifting X  the elements of L by  X  , preserving the order. Let L ing lists of length k , with L Then we can express the output of CP on L the list truncated after the first k elements. This shows that the CP problem is a particular instance of the k -way merge problem, in which all input lists are related by k independent shifts.
Computation of the solution of the k -way merge problem takes time O ( q log( k )) , where q is the quired by the CP problem, we can further reduce to O ( k log( k )) . This is the already known upper bound on the CP problem (Huang and Chiang, 2005; Ges-mundo and Henderson, 2010). Unfortunately, there seems to be no way to achieve an asymptotically faster algorithm by exploiting the restriction that the input lists are all related by some shifts. Nonethe-less, in the next sections we use the above ideas to develop a heuristic algorithm running in time linear in k . Consider lists L that L assume that L an (exact) linear time algorithm for solving the CP problem under this assumption.

For each i  X  0 , let I ( x 0  X  ( i + 1)  X   X  , x 0  X  i  X   X  X  empty) sublists  X  that each  X  all elements from L down one segment in L moving down one element in L Let t = min { k, s } ; we define descending lists M shift (  X  0 , y 0 ) , and for 1  X  i &lt; t we let We claim that the ordered concatenation of M M is exactly the output of CP on input L
To prove our claim, it helps to visualize the de-scending list L L whose j -th column is shift ( L L fine the i -th segment of the j -th column, written  X  as the descending sublist consisting of all elements of that column that belong to shift ( I have  X 
For any d with 0  X  d &lt; t , consider now all segments  X  antidiagonal in L . We observe that these segments contain all and only those elements of L that belong to the interval I duction that these elements are exactly the elements that appear in descending order in the list M in (2).

We can then directly use relation (2) to iteratively compute CP on two lists of length k , under our as-sumption that one of the two lists has constant slope. be computed in time linear in the size of the output list, it is not difficult to implement the above algo-rithm to run in time O ( k ) . In this section we further elaborate on the exact al-gorithm of section 3 for the constant slope case, and develop a heuristic solution for the general CP prob-lem. Let L and 3. Despite the fact that L stant slope, we can still split each column of L into segments, as follows.

Let e I ( x of section 3, intervals e I now. Let also e I For each i, j with 0  X  j &lt; k and 0  X  i &lt; k  X  j , we define segment e  X  consisting of all elements of the j -th column of L that belong to e I of L is split into segments e I we have a variable number of segments per column. Note that segments e  X  contain all and only those elements of L that belong to the left-open interval e I
Similarly to section 3, we define descending lists f M 1  X  i &lt; k , by letting Note that the function path ( f M turn shift ( f M 1: Algorithm 1 ( L 1 , L 2 ) : e L  X  2: e L  X  .insert( L [0 , 0] ); 3: referColumn  X  0; 6: C X  CircularList( [0 , 1] ); 7: C -iterator  X  X  .begin(); 8: while | e L  X  | &lt; k do 11: if C -iterator.current()= [0 , 1] then 12: referColumn++; 13: [ i, j ]  X  X  -iterator.next(); 14: x follow  X  L [ i, referColumn + j ] ; 15: else 18: C -iterator.insert( [ i,  X  referColumn ] ); case of (2). This is because input list L rithm, path ( f M list L  X  not know how to compute such a i -way merge with-out introducing a logarithmic factor.

Our solution is to define path ( f M way that it computes a list e L tation of the correct solution L  X  consider the  X  X elative X  path starting at x we need to follow in L in order to collect all the el-ements of f M such a path starting at x collected elements. Finally, we compute the output list e L  X  as the concatenation of all lists f M first k elements.

It is not difficult to see that when L slope we have f M lem. When L e L  X  might depart from the exact solution in two re-of local variations in the ordering of the elements; and it might not be a permutation of the exact so-lution, because of local variations at the end of the list. In the next section we evaluate the impact that our heuristic solution has on the performance of a real-world machine translation system.
 Algorithm 1 implements the idea presented in (3). L denotes the combined value x computed on demand.

We encode a relative path (mentioned above) as a sequence of elements, called displacements , each and  X  represents the relative displacement needed to reach the next column, to be summed to a variable why only the second coordinate is a relative value is that we shift paths only horizontally (row indices are preserved). The relative path is stored in a circu-ing point (paths are always shifted one element to the right). When merging the list obtained through the path for f M in (3), we update C accordingly, so that the new rel-ative path can be used at the next round for f M merge operator is implemented by the while cycle at lines 8 to 19 of algorithm 1. The if statement at line 9 tests whether the next step should follow the relative path for f M else depart visiting an element from e  X  column of L (lines 16 to 19). In the latter case, we update C with the new displacement (line 18), where the one currently pointed to. The function next() at line 13 moves the iterator to the next element and then returns its value.
 A running example of algorithm 1 is reported in Figure 1. The input lists are L L 2 = h 9 , 6 , 3 , 0 i represents the state of the algorithm when the test at line 9 is executed. The value in the shaded cell in the first column is x shaded cell is x We implement Linear CP (LCP) on top of Cdec (Dyer et al., 2010), a widely-used hierarchical MT system that includes implementations of standard CP and FCP algorithms. The experiments were ex-ecuted on the NIST 2003 Chinese-English parallel corpus. The training corpus contains 239k sentence pairs. A binary translation grammar was extracted The model was tuned using MERT (Och, 2003). The algorithms are compared on the NIST-03 test set, which contains 919 sentence pairs. The features used are basic lexical features, word penalty and a 3-gram Language Model (Heafield, 2011).

Since we compare decoding algorithms on the same search space, the accuracy comparison is done the score-loss relative to standard CP average score. Note that the FCP loss is always &lt; 3% , and the LCP of a baseline linear time heuristic algorithm which and that scans L along parallel lines whose steep The baseline greatly deteriorates the accuracy: this shows that finding a reasonable linear time heuristic algorithm is not trivial. We can assume a bounded loss in accuracy, because for larger beam size all the algorithms tend to converge to exhaustive search.
We found that these differences in search score resulted in no significant variations in BLEU score (e.g. with k = 30 , CP reaches 32.2 while LCP 32.3).
The speed comparison is done in terms of algo-rithm run-time. Figure 3 plots the relative speed gain of LCP over standard CP and over FCP. Given the log-scale used for the beam size k , the linear shape of the speed gain over FCP (and CP) in Figure 3 em-pirically confirms that LCP has a log( k ) asymptotic advantage over FCP and CP.

In addition to Chinese-English, we ran experi-ments on translating English to French (from Eu-roparl corpus (Koehn, 2005)), and find that the LCP score-loss relative to CP is &lt; 9% while the speed relative advantage of LCP over CP increases in aver-age by 11 . 4% every time the beam size is multiplied by 10 (e.g. with k = 1000 the speed advantage is racy loss and log( k ) speed advantage of LCP.
