
Practitioners [9, 33] as well as researchers [S, 11, 30] have observed that IDSs can easily trigger thousands of alarms permission and/or a fee. SIGKDD '02 Edmonton, Alberta, Canada 
Copyright 2002 ACM 1-58113-567-X/02/0007 ...$5.00. for using data mining to support alarm investigation. Sec-tion 4 investigates episode rules in this framework. Section 5 describes a new conceptual clustering technique, and Sec-tion 6 uses it to validate our data-mining-based approach to alarm investigation. Section 7 offers our conclusions. IDSs trigger alarms to report presumed security violations. 
We model alarms as tuples over the Cartesian product DAax ... XDA,, where {Az,... , A~} is the set of alarm attributes and DA~ is the domain (i.e. the range of possible values) of attribute Ai. The alarm attributes capture intrinsic alarm properties, such as the alarm source, the alarm destination, the alarm type (which encodes the observed attack), and the time-stamp. We denote the Ai value of an alarm a by a.Ai. The idea of using data mining to support alarm investiga-tion is not new. Manganaris et al. mine association rules over alarm bursts [33]. Subsequently, alarms that are con-sistent with these association rules are deemed "normal" and are discarded. The risk of losing relevant alarms is not considered in this work, whereas bounding this risk is cen-tral to our approach. Clifton and Gengo [11] use episode mining to guide the construction of custom-made filtering rules. Although Section 4 pursues the same idea, it offers new insights into the value of this approach. Also related is our earlier work [30], which introduces the clustering tech-nique of Section 5. Here, we extend this work in three ways: We motivate the design decisions that lead to said cluster-ing technique, we discuss its theoretical properties, and we evaluate it by means of extensive experiments. Other related work comes from Barbar X  et al., who use in-cremental data mining techniques to detect anomalous net-work traffic patterns in real time [3, 5]. Lee and Stolfo use data mining for feature construction and training of classi-fiers that detect intrusions [32]. The goal of these research projects is to construct IDSs more systematically and to overcome limitations of existing IDSs. Our work, by con-trast, aspires to use existing IDSs more efficiently. There are many other research projects that also applied data min-ing to intrusion detection. An overview of these projects and a general treatment of data mining in computer secu-rity can be found in a recent book edited by Barbara and Jajodia [4]. Data mining for fraud detection is investigated by Fawcett and Provost [15], and by Chan and Stolfo [10]. Alarm correlation systems [12, 14, 40, 42] try to group alarms so that the alarms of the same group pertain to the same phenomenon (e.g. the same attack). In that way, they offer a more condensed view on the security issues raised by an IDS. The work by Dain and Cunningham [12] is notewor-thy as it uses data mining techniques to learn correlation rules from hand-labeled training examples. This approach assumes that there is a human expert who (implicitly) knows the correlation rules, so the machine can learn them from him or her. By contrast, we advocate exploratory data min-ing techniques that assume no prior knowledge on the side of the user. More generally, we employ data mining to under-stand how to handle alarms more efficiently, be it by means of correlation, filtering, patching of flawed IDS signatures, blocking of attackers at the firewall, or something else. In the world of telecommunication networks, Klemettinen uses association rules and episode rules to support the de-velopment of alarm correlation systems [31]. Hellerstein and Ma pursue the same goal by means of visualization, period-icity analysis, and m-patterns (a variant of association rules requiring mutual implication) [26]. Garofalakis and Ras-togi investigate bounded-error lossy compression of network management events [18]. Note that a priori, it is not clear how well these techniques work in intrusion detection. Here, we address this question for episode rules and for a new clus-tering technique that we derived specifically for intrusion detection. This section introduces our framework for using data mining to support alarm investigation. Moreover, the data used in the experiments is described. Our data mining philosophy can be described as "learning from the past to master the future." More precisely, we ap-ply data mining techniques to historical intrusion detection alarms to gain new and actionable insights. These insights are subsequently used to reduce the future alarm load that the human analyst has to handle. This can be done in at least two ways: By eliminating alarm root causes so that no more alarms are triggered, or by writing filtering and correlation rules that automate alarm processing. Figure 1 illustrates this process. Figure 1: Using data mining for alarm investigation. Let us first consider how one can eliminate alarm root causes. In one case we observed a misconfigured secondary DNS server that did half-hourly DNS zone transfers from its pri-mary DNS server. The deployed IDS would trigger "DNS Zone Transfer" alarms because DNS zone transfers can be used to "spy out" a target network. By correctly setting up the secondary DNS server, we eliminated the alarm root cause and all its associated alarms. In another case, we fixed a broken TCP/IP stack that generated fragmented traffic and thereby triggered "Fragmented IP" alarms. Similarly, an attacking machine can be sanitized or shunned at the firewall, both of which eliminates the alarm root cause. On occasion, alarm root causes are not under our control or they are expensive to eliminate. Then, custom-made filter-ing rules (which automatically discard alarms) or correlation rules (which intelligently group and summarize alarms) can be an alternative. The primary problem with filtering and correlation is that it can destroy valuable information. For example, filtering can discard important alarms and corre-lation can group alarms in meaningless ways. Our approach addresses this problem as it uses data mining as a supporting technology that enables a human expert to understand why alarms are triggered and how they should be handled in the future. Based on his or her understanding, the human ex-pert can then devise custom-made filtering and correlation rules that axe safe to use. 
Note that the framework of Figure 1 does not stipulate any particular data mining technique. However, to be of value, a prospective data mining technique should satisfy the fol-lowing requirements: 
Scalability: IDSs can trigger well over a million alarms per 
Noise tolerance: Intrusion detection alarms can be very 
Multiple attribute types: Intrusion detection alarms can 
Ease of use: The people using the data mining techniques 
Interpretability ~ relevance of patterns: The data min-
To appreciate the importance of the last point ("Interpretabil-ity &amp; relevance of patterns"), recall that the results of the data mining step are interpreted and acted upon by a human expert. This raises the need for highly interpretable and rel-evant patterns as otherwise , the human cost of learning from these patterns would become too high. Moreover, the pro-cess of Figure 1 is iterative and site-specific, which further re-inforces the interpretability and relevance requirement. The process is iterative as it has to be repeated roughly once a month to keep up with changes in the alarm behavior of 
IDSs. Such changes occur, for example, as the result of new attacks, updates to the IDS software, or system reconfigura-tions. Similarly, the process is site-specific as each site gen-erally has a very unique alarm mix [36]. As a consequence, each site must be treated individually. 
A preliminary remark on intrusion detection terminology is in order: IDSs are classified into knowledge-based and behavior-based systems [13]. Knowledge-based systems such as STAT [27] use knowledge accumulated about attacks to detect instances of these attacks. Behavior-based systems (e.g. IDES [29]) use a reference model of normal behavior and flag deviations from this model as anomalous and po-tentially intrusive. Another dichotomy splits IDSs according to their audit sources. Specifically, host-based IDSs analyze host-bound audit sources such as operating system audit trails, system logs, or application logs, whereas network-based IDSs analyze network packets that are captured from a network. 
The experiments in this paper use alarms from network-and knowledge-based commercial IDSs that were deployed in op-erational (i.e. "real-world") environments. We consider it a Table 1: Overview of IDSs used in experiments. 
IDSIType Location Min I Max Avg I 1 A Intranet 7643 67593 39396 2 A Intranet 28585 1946200 270907 3 A DMZ 11545 777713 310672 4 A DMZ 21445 1302832 358735 5 A DMZ 2647 115585 22144 6 A Extranet 82328 719677 196079 7 A Internet 40061 43773 20178 8 A Internet 10762 I 266845 62289 9 A Internet 91861 257138 152904 10 B Intranet 18494 228619 90829 11 B Intranet 28768 977040 292294 12 B DMZ 2301 289040 61041 13 B DMZ 3078 201056 91260 14 B Internet 14781 1453892 174734 15 B Internet 248145 1279507 668154 16 B Internet 7563 634662 168299 strength of our validation that it uses alarms from real-world environments rather than from simulated or laboratory en-vironments, which can have significant limitations [36]. We are not in possession of extensive data collections from host-or behavior-based IDSs and therefore exclude experiments with these IDS types. However, our experiments with the data available for these IDS types gave results comparable to the ones presented in this paper. 
Table 1 introduces the sixteen IDSs we use throughout this paper. Our selection criteria was to offer a representative mix of IDSs from different vendors in different operational environments. The sixteen IDSs are deployed at eleven dif-ferent companies, and no two IDSs are deployed at the same geographic site. The "IDS" column contains a numerical identifier that will be used throughout the paper to refer-ence the IDSs. The "Type" column indicates the IDS type, namely "A" or "B", both of which are leading commercial 
IDSs. To avoid unintended commercial implications, we do not reveal the product names or vendors of "A" and "B". For each IDS, we employ all alarms that were triggered in the year 2001. The minimum, maximum, and average number of alarms per month are listed for each IDS in the "Min", "Max", and "Avg" columns, respectively. Finally, the "Lo-cation" column indicates where the IDSs are deployed: 
Intranet: Denotes an IDS on an internal corporate network 
DMZ: Designates an IDS on a perimeter network that is 
Extranet: Denotes an IDS on a network that is shared be-
Internet: Indicates an IDS that is deployed before the ex-
Note the generally large difference between the minimum and maximum number of alarms per month. This difference reflects changes in the alarm mix over time. Analogously, the vastly varying alarm loads between IDSs provide intu-itive evidence of the uniqueness of each site. This illustrates our earlier point that the alarm investigation process of Fig-ure 1 has to be applied iteratively and site by site. Finally, for confidentiality reasons, we cannot provide more detailed information on the sites where the IDSs are deployed. 
Episode rules are a data mining technique that was devel-oped to find patterns in event sequences [34, 35]. Intuitively, episode rules are implication rules that predict the occur-rence of certain alarms based on the occurrence of other alarms. For example, an episode rule might state that in 50 percent of all cases, an "Authentication Failure" alarm is followed within 30 seconds by a "Guest Login" alarm. 
In network management, researchers have successfully used episode rules in a framework like ours [31]. Therefore, episode rules are a natural candidate for the data mining step of 
Figure 1. In this section, we report our experience with this approach. In addition, we summarize the insights we gained into the nature of intrusion detection alarms. 
To formally define episode rules, we need the following ter-minology [34, 35]: An alarm predicate is a boolean expres-sion that tests certain alarm properties such as the alarm type or source. A serial (parallel) episode is a sequence (multi-set) a =&lt;Pi&gt;x&lt;_i&lt;, of alarm predicates. Note that the predicates of a serial episode are ordered, whereas they have no order in parallel episodes. Given a parallel episode occurrence of a if it contains a distinct alarm a for each 
Pi such that Pi(a) holds. For occurrences of serial episodes, the alarm order must additionally match the predicate order (i.e. the alarm a satisfying Pi must occur before the alarm a' satisfying Pi+l). The interval [t~, tel is a minimal occur-rence of a if there is no proper subinterval of Its,tel that would also be an occurrence of a. Finally, episode rules are implication rules of the form two episodes are either both serial or parallel. The param-eters s, c, and W are called support, confidence, and win-dow width and their interpretation is the following: Episode &lt;Pi&gt;l&lt;i&lt;n has s minimal occurrences in sequence S. More-over, if t~ -t8 &lt; W and Its, t~] is a minimal occurrence of 
Variations of the above definitions are described in [34, 35]. 
We have used episode rules for the data mining step in Fig-ure 1. In our experiments, we have mined the alarms from our experimental IDSs (cf. Table 1) for serial and parallel episode rules. The set of admissible alarm predicates was restricted to predicates of the form P(a) ~ (Aia.Ai = ci), where a is an alarm, Ai are attributes, and cl are constants. 
The episodes and episode rules discovered contained many interesting patterns, including the following ones: 
Figure 2: An attack tool being run against three targets. 
Clearly, these patterns are of direct relevance to alarm han-dling. For example, knowing the episodes that correspond to legitimate system operations, it is easy to filter them out in the future. Similarly, if an alarm systematically entails other (redundant) alarms, then one can reduce the overall alarm load by fusing these alarms into a single, semantically richer meta-alarm. Finally, episodes that result from attack tools can be used to detect future attacks in a more reliable and timely manner. 
Nevertheless, episode mining has two important drawbacks in the framework of Figure 1. First, the attainable degree of automation is very low. In our experiments, less than one percent of alarms could be handled automatically thanks to previously mined episodes and episode rules. The remain-ing 99% of alarms still had to be investigated manually. The second drawback is that episode mining tends to produce a large number of irrelevant or redundant patterns [31]. More-over, many of these patterns were difficult to interpret in terms of real-world phenomena. Thus, given a large number of not always easy to interpret episodes and episodes rules, locating the truly interesting ones became a time-consuming activity. All in all, we felt that the benefit of a one-percent reduction in alarm load did not compensate for the cost of locating the interesting episodes and episode rules. Therefore, we do not use episode rules as a data mining technique in our frame-work. Despite this negative result, our experiments with episode rules have been important for two reasons: First, we have come to appreciate the difficulty of finding a data mining technique that works well in our framework. As a re-sult, we have tailored a data mining technique to our needs (cf. Section 5). Second, we have gained important new in-sights into the nature of intrusion detection alarms. These insights are summarized in the following subsection. An important lesson that episode mining has taught us is that intrusion detection alarms are extremely monotonous and repetitive. Specifically, we noticed that almost all high-support episode rules consisted of multiple instances of the same predicate, i.e. P~ = Pj generally held for all i and j in equation (1). The monotony of intrusion detection alarms is illustrated more clearly by the following experiment: Let us randomly choose an IDSs and a source host that has triggered alarms at this IDS. This source host might have triggered many alarms throughout the year 2001, but with a probability of 96% they were all of the same type! More-over, the probability for all alarms to hit the same target port (target host) is 95% (69%). These probabilities were calculated using the 16 IDSs in Table 1, but we have con-firmed them (give or take a few percentage points) using over 90 million alarms from more than 50 different IDSs. The above observation inspires two ideas for making alarm investigation more efficient. First, source hosts that display diverse behavior, e.g. by triggering alarms of many different types, deserve closer investigation. In fact, hackers gener-ally have little a priori knowledge about their targets and therefore resort to trying different reconnaissance and attack techniques until they are successful or exhausted. In doing so, hackers tend to trigger diverse alarm streams that involve many different alarm types and targets. Given that this kind of diverse behavior is generally rare, it is a rewarding heuristic to investigate it more closely when it occurs. Note, however, that perfectly monotonous behavior (e.g. password guessing) can still constitute an attack. Therefore, zooming in on diverse behavior helps in finding real attacks, but not all attacks are diverse. The second idea is to automate alarm investigation for the case where a source host keeps triggering alarms of the same type against the same target. Given that this case is so fre-quent, automating it will vastly relieve the human analyst. Moreover, the dominance of homogeneous and repetitive alarms suggests that intrusion detection alarms have a nat-ural clustering tendency. This leads us to the next section. Clustering seeks to group objects into categories (so-called clusters) so that members of a category are alike, whereas members of different categories are different [19, 28]. In most clustering techniques, it is an afterthought to represent clusters in an intelligible manner that supports understand-ing and decision making [19, 28]. Conceptual clustering, by contrast, puts cluster representation in the foreground and searches for clusters that have "good" representations in a given description language [16, 37, 39]. Examples of descrip-tion languages include variants of predicate logic [7, 37] as well as probabilistic languages that list attribute probabili-ties [16, 41]. Conceptual clustering has two important advantages in the framework of Figure 1. First, by deriving intelligible descrip-tions of clusters: it facilitates cluster interpretation. The im-portance of this point follows from the "Interpretability &amp; relevance of patterns" requirement of Section 3.2. Second, conceptual clustering is particularly good at handling cate-gorical attributes such as IP addresses, port numbers, and alarm types. This strength matters as categorical attributes are known to pose problems for many other clustering tech-niques [17, 20]. In this paper, we use a variant of the classic Attribute-Oriented Induction (AOI) technique [21] as our conceptual clustering tool. AOI was initially introduced as a data sum-marization technique, but its link to conceptual clustering was subsequently established [23, 25]. Section 5.1 introduces the classic AOI algorithm, and Section 5.2 shows why and how we modified it. The properties of the modified AOI al-gorithms are discussed in Section 5.3. Our experiments are presented in Section 6. Attribute-oriented induction operates on relational database tables and repeatedly replaces attribute values by more ab-stract values. The more abstract values are taken from user-defined generalization hierarchies, which, for example, might state that IP addresses can be generalized to networks, time-stamps to weekdays, and port numbers to port ranges. Be-cause of generalization, previously distinct alarms become identical and can be merged. In this way, huge relational tables can be condensed into short and highly comprehensi-ble summary tables. For a more formal treatment, we extend all alarms by a new integer-valued pseudo-attribute, the so-called count C. Thus, we henceforth model alarms as tuples over the Carte-sian product DA~x...xDA,xDc. The count attribute is used by the AOI algorithm for book-keeping, only. The alarm attributes Ai are as before. A generalization hierarchy is a tree-structured/s-a hierarchy that shows how concepts are organized into more general concepts. Figure 3.a shows a sample generalization hierarchy for IP addresses. Alarms whose attributes assume non-leaf concepts such as ~ or Net-A in Figure 3.a are also called generalized alarms. Inputs to the AOI algorithm are a relational table "T over the attributes {At,... , An, C}, as well as generalization hierar-chies ~ and generalization thresholds dl for all attributes A~ (i = i,... , n). The first step of the AOI algorithm (cf. Fig-ure 4) is to assign the value 1 to the count attribute of each alarm. Subsequently, the main loop (steps 2-8) is iterated: Step 3 selects an attribute Ai and the steps 4 and 5 replace the Ai values of all alarms by their parent values in 7/~. By doing so, previously distinct alarms can become identical. Two alarms a and a' are identical if a.Ai = a'.Ai holds for all attributes A~ (but a.C # a'.C is possible). Steps 6 and 7 merge identical alarms into a single one whose count value My~IPs Extemal-lPs~ 
WWW DNS Net-A ...Net-Z ipl ip2 ip3 ip4 ipA1.., ipZl... a) Generalization hierarchy for IP addresses. Figure 3: A generalization hierarchy and sample ta-ble. equals the sum of constituent counts. In this way, the count attribute always reflects the number of original alarms that are summarized by a given generalized alarm. Note that each alarm a represents a cluster of size a.C. Moreover, the elements of a cluster a are the original (ungeneralized) alarms that were merged into a. One key aspect of the classic AOI algorithm has been left open, namely, how the attributes Ai are selected in step 3. The selection criterion is that any attribute Ai that assumes more than di distinct values in table 7" can be selected. (Recall that dl, the generalization threshold, is an input parameter to the algorithm.) The main loop terminates in step 2 if no such attribute exists. To summarize, an attribute A~ is generalized until it assumes at most d~ distinct values (i = 1,...,n). This strategy guarantees that the final generalized table contains at most Hi=x ...... dl generalized alarms. This strategy of bounding the number of distinct attribute values can lead to excessive generalization, in which too much detail is lost (so-called over-generalization). This section illustrates the problem of over-generalization and shows how we modified the classic AOI algorithm to mitigate it. Figure 3.b shows a sample table having the alarm attributes "SrcIP" (the source-IP) and "DstIP" (the destination-IP). Note that the first tuple in the table represents 1000 oc-currences of the alarm (ipl ,:i.p4). We use the generaliza-tion hierarchy of Figure 3.a for both alarm attributes, and we assume that both generalization thresholds have been set to 10 (i.e. dl = d2 = 10). Given that both alarm at-tributes assume 27 distinct values, they are both general-ized once. This yields a new table whose alarm attributes still have 27 distinct values. Therefore, both attributes are generalized again. The resulting table, which contains the generalized alarms (MyCompany-IPs ,MyCompany-IPs, 1000), MyCompany-IPs.26), is the final result of classic AOI. Note that this result is (over-)generalized to a point where im-portant details have been lost. In fact, instead of the above result we had rather obtained the alarms (ipl,ip4,1000), which are more specific and informative. 1: [or all alarms a in 7" do a.C := 1;//Init counts 2: while table 7" is not abstract enough do { 3: Select an alarm attribute Ai; 4: for all alarms a in 7" do //Generalize Ai 5: a.Ai := father of a.Ai in ~i; 6: while identical alarms a, a' exist do //Merge 7: Set a.C := a.C + a'.C and delete a ' from 7"; A major source of over-generalization is "noise". Indeed, noise forces up the number of distinct attribute values and thereby controls the generalization process. In the above ex-ample, there was one main signal (the tuple (ipl, il:gt, 1000) of Table 3.b) and five percent of "noise" (the remaining 52 tuples). However, the noise dominated the generalization process and caused the alarm (ipl,ip4,1000) to be gener-alized four times, so it became (MyCompaay-IPs ,MyCompany-IPs,1000). Noise-induced over-generalization is a serious problem in intrusion detection (cf. Section 3.2), and it mo-tivates our first modification of the classic AOI algorithm. 
MODIFICATION 1. We abandon the generalization thresh-olds di as well as the associated strategy of bounding the number of distinct attribute values. Our new strategy tries to find generalized alarms that cover "many" of the orig-ina~ (ungeneralized) alarms. Formally, we search alarms a E T that have a count bigger than rain_size (i.e.a.C &gt; min_size), where rain_size E N is a user-defined constant. Whenever such an alarm is found, it is removed from table T and reported to the user. Processing continues with the table T' := 7" \ a. [] Recall that each alarm a represents a cluster of size a.C. The above modification has two effects: First, by imposing a minimum cluster size of rain_size, it forces the AOI algo-rithm to find "large" clusters. Second, by preventing further generalization of an alarm a that satisfies a.C &gt; min_size, it tries to avoid over-generalization. The combined effect is to bias the algorithm towards large clusters that nonethe-less have specific representations in the form of generalized alarms. Finally, Modification 1 also raises the need for a new attribute selection criteria" for step 3 of Figure 4. To coun-teract over-generalization, we use the following heuristic cri-teria, which tries to minimize the total number of attribute generalizations: 
MODIFICATION 2. For each alarm attribute Ai, let Fi := max{fi(v)l v E DA,} be the maximum of the function fi(v) := SELECT sum(C) FROM T WHERE A, = v, which sums the counts C of all alarms a E T with a.Ai = v. Step 3 of Figure ~ selects an attribute Ai whose Fi value is minimal, i.e. F~ &lt; Fj must hold for all j. [] The motivation for this heuristic is that an alarm a with a.C &gt; rain_size cannot exist unless Fi &gt; min.size holds for all attributes Ai. Therefore, we use it as a heuristic to increase the smallest Fi value by generalizing its correspond-ing attribute A~. Other heuristics are conceivable, but the one given here works well in practice (cf. Section 6). 
Figure 7: Average alarm load reduction over the year 2001. 
