 A foreign word is usually tran slated to a local word accord ing to their phonetic simi-different Chinese words, referred to as synonymous transliterations, especially proper different Chinese transliterations as  X   X  X  X  X   X  (binladeng) and  X   X  X  X  X   X  (benladeng). Note that we use Hanyu pinyin for the Romanization of Chinese transliterations. 
Synonymous transliterations would raise obstacles in reading articles as well as communicating with other people. More importantly, search engines will generate retrieve the Web pages that use  X   X  X  X  X   X  instead as the transliteration. 
This research aims at mining synonymous transliterations from the Web. Our re-which can then be used to alleviate the problem of incomplete search of Web pages. 
Three major difficulties in extracting synonymous transliterations from huge Web pages are concerned. The first question is target documents collection : how to collect appropriate pages which contain synonymous transliterations from the huge collection small number of, but related, documents which contain probable synonymous translit-words as synonymous transliteration candidates from noisy search-result pages; and the last is confirming synonymous transliterations : how to recognize those identified candidates as true synonymous transliterations. 2.1 Observation Chinese transliterations may come with their original foreign words. One approach to pages. However, most commercial search engines limit the number of Web pages returned to the user. For example, Google, Altavista, and Goo return only 1,000 pages even though more pages match the query [4]. Due to this limitation, a user inputs an original foreign word with the search scope limited to Chinese Web pages. The user there are a few dominant transliterations which appear more frequent than the others, the retrieved pages may contain only those dominant transliterations. For instance, the transliteration  X   X  X  X  X   X  appear less frequent than  X   X  X  X  X   X . 
Another alternative is to use associated words which are in terms of context highly submit to search engines, and then we got some Web pages containing the term  X   X  X  X  X   X  (Bin Laden) as shown in Fig. 1. Therefore, identifying appropriate associated literations. 2.2 Collecting Candidate Web Pages Fig. 2 depicts the process of identifying candidate pages which may contain synony-mous transliterations. First, some seed Web pages are downloaded by the input trans-keywords to be submitted to a search engine for candidate pages, but also be regarded ment will be described in Section 2.3. 
Third, for each significant associated word which is used as a search keyword, we download a fixed number of Web pages. Four, because the Web consists of pages on diverse topics, na X ve queries by users may find matches in many irrelevant pages [4]. So, we use a method to filter out irrelevant Web pages. Specifically, if the Web pages contain many highly weighted associated wo rds of the transliteration (i.e., the charac-search-result page of Fig. 3. In contrast, we can discard the Web page which doesn X  X  contain significant associated terms, such as that of Fig. 4. 2.3 Associated Words Computation Several statistic methods have been proposed for estimating term association based on co-occurrence analysis, including mutual information, DICE coefficient, chi-square tion time. 
We take the initial step of downloading a fixed number of Web documents for the input transliteration. Then we extract all known words w i from the set of downloaded pages Q using term segmentation. The vector space model VSM is employed, in which each element represents a word with a value of 1 when the document contains ments containing the word w i . Pr(w i )= W represents the size of the extracted vo cabulary from the downloaded documents the document d j contains w i or 0 otherwise. 
We consider a word w i is more important if w i co-occurs frequently with the trans-literation TL. Therefore, the significance of an associated word is proportional to the obtain the returned page counts without downloading and processing the Web pages. weight ( w i ) = Pr( w i ) in documents without TL. 2.4 Sifting the Collected Pages Each of significant associated words is submitted to obtain a small set of Web pages. Due to the diversity of the Web, some of the collected pages might not be relevant to the content of the input transliteration. A filtering step is needed to discard irrelevant pages. defined as Eq. (3), the aggregated weight of the top-consider documents with high scores as candidate pages which might contain syn-onymous transliterations and discard the other pages. For those candidate Web pages, some preprocess is performed to extract unknown words. We first identify and eliminate known words with the help of a dictionary. We strings. N is set between the length of TL minus and plus one, i.e., |TL| -1  X  N  X  |TL| equal to one. 
The number of the extracted N-grams units is usually quite large. We use SPLR al-gorithm [7] to help reduce the size. The SPLR algorithm is effective to detect an un-word  X   X  X  X   X  (Bin Laden) is a subsequence of the 4-characters unit  X   X  X  X  X   X  (of Bin Laden). Once the subsequence is determined an unknown word, its supersequences can be discarded. 
The process of recognizing and confirming the unknown words as the synonymous  X   X  X  X  X   X  (binladeng) and  X   X  X  X   X  (benladeng). Therefore, we use speech sound com-parison to identify synonymous transliterations. However, a candidate unknown word which scores high in speech sound comparison is not always a synonymous translit-matching is performed. 3.1 Speech Sound Comparison approach to comparing the phonetic similarity of two Chinese words. Our approach character sounds and the other for the 37 Chinese phonetic symbols used in Taiwan. The advantage of this digitalized sound comparison approach over the conventional statistic-based approaches is that it does not require a corpus for computing the pho-netic similarity between two words and thus avoids potential bias inherent in the col-lected corpus. 
We employee the speech sound comparison approach to compare the similarity be-tween the extracted N-grams unknown word and TL. Highly similar pair is likely synonyms. The approach looks at the patterns of similarity in Chinese phonemes as a For example, the Taiwan X  X  phonetic symbols  X  (p) and  X  (b) are both initials and are highly similar in pronunciation. In particular, we first recorded in digitalized form the two sets of sounds including the 412 basic Chinese character sounds and the 37 Tai-wan X  X  phonetic symbols. We then adopted speech recognition technique to compare the similarity between every pair of two sounds in each set of the digitalized sounds. phonetic symbols, respectively. Note that the complete set of Chinese character sounds is about 5*412 which considers character X  X  tone. However, the tone does not affect much in terms of comparing phonetic similarity between two Chinese words reduce the size of the set. 
Given the two sound similarity matrices, a dynamic programming based algorithm is used to measure the similarity between the N-grams word and TL. Specifically, the recording, we include a weight on the initia l consonant of the character to balance the bias in the computation. The recursive formula for the dynamic programming algo-follows. gives the similarity between two Chinese character sounds by retrieving the correspond between the two initial consonants of the two characters by retrieving the entry in the 37 phonetic-symbol similarity matrix. The weight w can be set to 0.5, which experimentall y leads to a good result. The initial conditions are T( i ,0) = 0 and T(0, j ) = 0. score is T( m , n ) and the score is further normalized by the average length of the two words. In other words, the similarity between UW and TL is defined by sim (UW, TL) = 2/( m + n ) *T( m , n ). 3.2 Context Comparison Some unknown words which are not a synonym of the transliteration might happen to have a high similarity score with respected to TL by sound comparison. For instance the unknown word  X   X  X  X  X  X  X   X  (jiubaqinian, meaning 987 years  X  has high similarity score when compared to the transliteration  X   X  X  X  X  X  X   X  (gebaqifu) of Gorbachev but clearly it is not a synonymous transliteration. Therefore, a confirmation step is needed to reduce false positives by the sound comp arison approach in the previous step. 
The basic idea of the confirmation technique is that a true synonymous translitera-performed as follows. We retrieve some Web pages by using the candidate synony-mous transliteration, which is an N-grams unknown word having high similarity score with the input transliteration. If the retrieved pages have similar content with those of Again, the previously extracted associated wo rds of TL can be used in this similarity computation. 
For example, given a transliteration  X   X  X  X  X  X  X   X  (gebaqiaofu) of Gorbachev and its candidate synonymous transliteration N-grams words  X   X  X  X  X  X  X   X  (gebaqifu) and  X   X  X  X  X  X  X   X  (jiubaqinian), a search-result page is shown respectively in Fig. 6 and Fig. 7. Although both  X   X  X  X  X  X  X   X  and  X   X  X  X  X  X  X   X  have high similarity scores to  X   X  X  X  X  X  X   X  in speech sound comparison to  X   X  X  X  X  X  X   X , we can see that the snippet in Fig. 6 by  X  page of  X   X  X  X  X  X  X   X  (jiubaqinian) has nothing to do with  X   X  X  X  X  X  X   X . 3.3 The Combined Approaches The speech sound comparison measures the similarity of pronunciation whereas context comparison measures the similarity of context between Chinese terms. It might be bene-ficial to take the advantages of both approaches. Thus, an alternative is to combine these two methods. We use a combined ranking scheme to determine the similarity between a transliteration TL and its synonymous transliteration candidate t as follow: where mi represents the different methods. mi ranking of true synonymous transliterations among other noise terms. 4.1 Associated Words Extraction engine. Determining the associated words of th e transliteration is the core of the qual-ity of content focused crawling. We limit the initial downloaded Web data to transliteration. We use the 80K CKIP dictionary from Academia Sinica of Taiwan to determine known words in the downloaded Web pages and to extract the associated the associated words works well. 4.2 Synonymous Transliterations Extraction We show some experiments about synonymous transliterations extraction from the Web. We manually collected 18 transliterations and perform the approach to identify synonymous transliterations via searching and retrieving only a subset of the WWW 3,000 pages, and then retain only 900 pages after the filtering. 
We perform the context comparison step as mentioned in Section 3.2 to top-200 ranked words after speech sound comparison. Table 2 shows the results. newspapers. Column 2 shows the extracted synonymous transliterations from the Web. Column 3 SSC (speed sound comparison) shows the ranking of the identified synonymous transliterations among other segmented N-grams words via the speech sound comparison approach while Colu mn 4 SSC+CC (speed sound comparison followed by context comparison) shows the ranking by further comparing the context of extracted synonymous transliterations with those of the input transliteration. 
The experimental results verify that we can get synonymous transliterations well even thought we only retain 900 pages via content focused crawling for a translitera-tion. It also reveals that context comparison help greatly raise the ranking of some of synonymous transliterations, such as  X  X  X  (bushe) and  X  X  X  (xini). However, the method will reduce the ranking of some synonyms a little. The combined approach shown later will alleviate the problem. 
More analysis on the SPLR values is followed. The parameter setting of SPLR of-has less possibility of missing synonymous transliterations. On the contrary, a stricter parameter for unknown words extraction will cause damage, leading to significant number of identified synonymous transliterations. 
As mentioned in Section 3.3, the combined ranking from the results of the speech sound comparison and the speech sound comp arison followed by context comparison would be better than those of using a single approach. The resultant average rank of the synonymous transliterations by the combined approach is shown in Fig. 9, where stricter SPLR value generates better ranking since it eliminate more unknown words. 
As we can see in Fig. 9, equal weights on each of the two approach results in the best result in which the average rank of synonymous transliterations is lowest. That is, we shall place a weight 0.5 on the speech s ound comparison as well as on the speech sound comparison plus context comparison. Therefore, the speech sound comparison method and the context comparison method are quite complementary to each other. The best average rank of a synonymous transliteration is around six. 
Table 3 shows the inclusion rate of the synonymous transliterations, which indi-cates the percentage of synonymous transliterations, acquired under different SPLR the average amount of collected synonymous transliterations for each input data. When SPLR is set to 0.1, an average count of 1.74 synonymous transliterations can be retrieved. Among these retrieved, 85% are ranked within top 10 under the combined approach. The results show that the linear combination of SSC and SSC+CC can help to improve the inclusion rate. The preliminary results showed the approach is appealing. However, more experi-ments, especially on a large set of test data , is needed to further verify and fine-tune many applications, including help to construct a database of synonymous translitera-tions which can alleviate the incomplete search problem, and help to detect and track news articles. This research is supported by National Science Council, Taiwan under grants NSC94-2416-H-224-007 and NSC 96-2416-H-224-004-MY2. 
