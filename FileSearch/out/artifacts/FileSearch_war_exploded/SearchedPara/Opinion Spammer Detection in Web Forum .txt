 web forum is presented. We e xplore user profiles, maximum spamicity of first posts of users, burstiness of registration of user accounts, and frequent poster set to build a model with SVM with RBF kernel and frequent itemset mining. The proposed model achieves 0.6753 precision, 0.6190 r ecall, and 0.6460 F1 score. The result is promising because the ratio of opinion spammers in the test set is only 0.98%. H.3.3 [ INFORMATION STORAGE AND RETRIEVAL ]: Information Search and Retrieval  X  Information filtering. Algorithms, Design, Experime ntation, Human Factors. Fake Web Review, Opinion Spa mmer Detection, Web Forum. Experience sharing is a common activity on the web. Users are often willing to contribute their experiences through various platforms. Genuine personal opinions will help users make right decisions. In contrast, fake opi nions commonly used to promote specific targets will mislead users. Opinion spam and spammer detection aim at identifying fake review and reviewers. Jindal and Liu [4] addressed the importance of opinion spam detection and proposed models to deal with this problem. Subsequently, the researches were extended to identify individual opinion spammers [2][5][9] and group opinion spammers [6][7]. Reviewers X  behaviors, text similarity, linguistic features, rating patterns, relationships among revi ewers, reviews and stores, and burstiness in reviews have been explored. Evaluation is indispensable for this task, but no  X  X rue X  ground truth data spam and non-spam ar e available. Jindal and Liu [4] amazon.com for model development and performance evaluation. Duplicate and near-duplicate reviews were regarded as fake reviews. The researches [2][5][7] were based on the this dataset for opinion spammer detection. Wang et al. [9] collected a large amount of store reviews from resellerratings.com for their experiments. The evaluation methodologies are always based on human. Lim et al. [5] proposed a rigorous human evaluation procedure to examine a pool of ranked revi ewers from different spammer detection methods. Mukherjee et al. [6] conducted a user study, and Mukherjee et al. [7] employed 8 expert judges for their work. Wang et al. [9] claimed suspici ous reviewers who should have significant number of reviews satisfying three proposed subjective, and proposed a complementary evaluation. They assumed that if a reviewer was labelled as a spammer, then all his/her reviews were considered as spam reviews. The above work showed some degrees of annotator agreement in human evaluation. Different from the previous studies, this paper is based on a set of internal records of opinion spams leaked from a shady marketing campaign (see Section 2). To the best of our knowledge, it is the first research to study the beha viors of opinion spammers in web forum. The subtle nature of forum posts, low spam post of spammers, different types of sp ammer accounts, and interaction between forum posters are key issues. This paper is organized as follows . Section 2 describes a real case in web forum. Section 3 shows so me observations in the datasets. Section 4 proposes an opinion spammer detection model and discusses the experimental re sults under the real case study. Section 5 concludes the remarks. This paper studies a real case, Samsung probed in Taiwan over  X  X ake web reviews X  , reported by BBC on 16 April 2013. A covert marketing campaign was carried out by a consulting firm that was a subsidiary company of one of the biggest IT companies in the world. In this campaign, hired posters were asked to promote a certain brand and denounce its rivals on web forums. The Fair Trade Commission (FTC) in Taiwan, investigated into the event and announced a decision on October 31, 2013 based on the leaked information and other documents,  X  X he Samsung Taiwan, OpenTide Taiwan, and Sales &amp; Profit International Co. concealed their identity and pretended to be regular private citizens to market their products on the Internet by making comparisons with and comments on the products of other enterprises. X  The three companies were imposed administrative fines of NT$10 million, NT$3 million and NT$50,000, respectively. The relevant articles describing the campaign were disclosed on Taiwansamsungleaks 1 . The leaked spreadsheets, which provide spam posts and spammers, are cons idered as ground truth for this threads, respectively. A thread in a web forum is composed of a first post or replies by users. Firs t post and reply are called posts. uid id of the user reg_time time of registration on the site login_time last time the user logged in n_threads number of threads initialized by the user n_eff_posts number of effective posts n_posts number of all posts n_replies number of replies, i.e., n_posts -n_threads karma score karma given by other users to the threads p_phone proportion of posts made on the smart phone thid id of the thread to which the post belong time submission tim e of the post uid id of the poster who made the post uname username of the poster nfloor position relative to other posts in the thread pnum page number on which the post is content structured content in HTML thid id of the thread fid id of the forum (board) in which the thread is title title of the thread pages number of pages in the thread clicks number of clicks (views) on this thread time submission time of the thread (=first post time) the posts: (1) 2011-post-set: Jan 2011-Dec 2011, and (2) 2012-post-set: Jan 2012-May 2012. the 2011-post-set. To avoid the effects of writing styles of users on the performance of opinion spam/spa mmer detection, we remove all the posts by users who have posts in the 2011-post-set from the 2012-post-set. Table 4 lists the statis tics of the remaining posts after removal. We also assign user accounts to the 2011-user-set and 2012-user-set according to the submission time of their posts. Users who 
Table 4. Statistics of posts in 2011-post-and 2012-post-sets http://taiwansamsungleaks.org/. have submitted posts during the firs t period, but not the second one are put into 2011-user-set. Similarly, users who have submitted user-set. Now the question is in which set the users who have submitted posts in both periods shoul d be put. Since we will use the opinion spam detection for first posts to assist opinion spammer words, these users are assigned to 2011-user-set. Table 5 shows the statistics of the datasets for sp ammer detection. The dataset is available at http://nlg.csie.ntu.edu.tw/m01-corpus/. 
Table 5. Statistics of users in 2011-user-and 2012-user-sets 2011-user-set 215 17,216 1.25% Spammers are the posters who had submitted any spam posts in web about 33% of the posts by spammers in the 2011-user-set are spams. The low spam post ratio of spammers specifies that some  X  X pammers X  actually rarely spammed. Spammers usually deliver their opinions in such a subtle way that brands. Their purpose is to keep the discussion alive and bumping to attract more attention to the specific topics of the thread. There are two types of spammer accounts in the dataset: (1) quality long post to promote the brand, and (2) throwaway accounts shared internally among the spammers to synthesize public opinions. Throwaway accounts are often created in mass within a short period of time, as it takes much more effort to spread out the daunting task of registering throwaway accounts. Because making spam posts is a job rather than a leisure activity for spammers, we observe that a highe r percentage of spam posts are submitted during work time, compared to non-spam posts. either spam replies or non-spam replies. We further examine 2011-post-set, and note that some threads contain multiple spam posts subm itted by different accounts. It indicates collusion goes on between multiple spammers. These spammers usually express similar opinions in the same thread to reinforce the credibility, or to bum p the thread to attract more attention to it. exploring various learning algorithms. In this section, we present the features used in opinion spammer detection. We scale each feature to zero mean and unit variance. In the latter experiments, we downsample the non-spammers in 2011-user-set by randomly removing 60% of them. The remain ing forms a training set. The 2012-user-set is consider ed as a test set. set to facilitate a grid search on C and  X  with F1 score as the metric to optimize. The grid to search is represented below. Table 6 summarizes the experimental results of five models, M0-M4. Precision ( P ), Recall ( R ), and F-measuere ( F1 ) are listed. M0 is an absolute baseline with random guessing. Intuitively, its performance is very bad due to very low spammer ratio, 0.98%. The detail of M1-M4 will be discussed in the following sections. M0: random baseline 0.0091 0.4588 0.0178 M1: user profile 0.0275 0.2262 0.0491 M3: M2+burstiness of reg. 0.6731 0.4167 0.5147 M4: M3+frequent poster set 0.6753 0.6190 0.6460 The last six attributes in user profile defined in Table 1 are used. We measure their usefulness in dis tinguishing the spammers from non-spammers by computing symmetric KL divergence as follows. where P spammer and Q hammer are the distributions of an attribute under all spammers and non-spammers, re spectively. Figure 1 shows the usefulness of these features. Spammers are more productive and reputable posters according to the number of the threads they make (n_threads), and the  X  X arma scores X  they have. than non-spammers, and (2) on web forums, there are a lot of lurkers who regularly login and read posts, but barely participate in discussions. Figure 3 further depict s that some spammers tend to have higher  X  X arma scores X  than non-spammers. Table 6 shows employing features from user profile, i.e., M1, increases F1 score compared with M0, but profile only is not sufficient to distinguish spammers from non-spammers effectively. 
Figure 2. Number of threads initialized by spammers and non-This section proposes a model to detect opinion spams from first posts, and consider the results as an additional feature. We propose the following features, and employ 2011-post-set and detect opinion spams from first posts. This model achieves 0.6667 precision, 0.5714 recall, and 0.6154 F1 score. (1) Bag of Words Next, rare words with less than 5 occurrences are removed to avoid overfitting. Besides, words appearing in over 30% of the posts are regarded as stop words and also filtered. After the vocabulary is set up, we represent each post as a weighted word normalized by the length of the post. reduce the dimension. The desire d number of dimension is tuned by the average F1 score with 5-fold cross-validation on training set. The average F1 score is the best when the bag-of-words is reduced to 150 components. Beside s the contents of posts, the titles of threads are also informative. Thus we create another 50 bags-of-word features based on th e titles, and combine these with the content parts to yield 200 features. (2) Content Characteristics contents of the post is introdu ced in Table 7. We compute symmetric KL divergence to find which features exhibit the most different distributions between spams and hams, and add these 17 numerical features that characterize the contents of first posts. (3) Submission Time make use of this observation, we add a binary feature for each hour in a day and each day in a week, in total 24+7=31 features. corresponds to, then its value is 1; otherwise it is 0. (4) Thread Activeness post as a feature, which measures the activeness of the thread. A feature, max_spamicity_fps , is computed by taking the maximum of the spamicity estimat es of all first posts submitted by a specific user. Because the definition of spammer is  X  X hoever makes one or more spam posts X , taking the maximum is a more sensible choice, compared to taking the mean or the median. n_all number of characters used in the post n_words number of words in the post n_hyperlinks number of hyperlinks in the post n_img number of images added to the post n_emoticon number of emotic ons used in the post n_quote number of quotations from previous posts p_digit proportion of digits p_english proportion of English characters p_punct proportion of punctuation characters p_special proportion of non-alphanumeric characters p_wspace proportion of white space characters p_immediacy proportion of first person pronouns p_ntusd_pos proportion of positive words in NTUSD p_ntusd_neg proportion of negative words in NTUSD p_emoticon_pos proportion of positive emoticons p_emoticon_neg proportion of negative emoticons The model for first post spam det ection in Section 4.2.1, which misses a spam first post of a specific spammer due to recall, it is still contrary, if the model misiden tifies a non-spam first post by a normal user as spam, i.e., low pr ecision and high recall, and gives it a high spamicity estimate, then the value of max_spamicity_fps will be high for that user, who is t hus likely to be misclassified as a evaluation. Table 6 shows the performance is significantly improved by almost 50% in F1 score when the max_spamicity_fps feature is introduced in M2. Further analysis finds that 54 out of the 84 spammers in test set, i.e., 64.3%, have submitted a sp am post which is a first post in a thread. In principle, it is the maximum number of spammers that could be identified with this feature. In Section 3, we observe most of the throwaway spammer accounts are registered in bursts. Here, we propose a feature, burstiness_reg , which counts the number of accounts registered 20 days within the shows adding this feature (i.e., M3) increases 0.0629 precision with the penalty of 0.0119 recall. This section models the beha vior of the collusion between spammers discussed in Section 3 with frequent itemset mining in data mining. Applying the shopping analogy to our scenario, user id  X  X asket X . Each frequent poster set denotes a group of users that itemset mining is conducted with the Orange library [1]. Rather than being incorporated the cue as a feature in our model, the mined frequent poster sets are us ed to examine the prediction outputs of the model M3 further. For each 3-element frequent poster set, we add up the spamicity prediction output by M3. If the sum is poster set to be spammers. The model integrating the mined fre quent poster sets, M4 shown in precision, and achieves 0.6460 F1 sc ore. The result is promising because the ratio of spammers in the test set is only 0.98%. quality model for spammer detection is proposed. In addition, leveraging the collusion between spammers significantly boosts the performance. This research was partially supported by National Taiwan University under grant NTU-ERP-104R890858, and Ministry of Science and Technology, under grant 102-2221-E-002-103-MY3. [1] Janez Dem X ar, Toma X  Curk, Ale X  Erjavec,  X  rt Gorup, et al. [2] Geli Fei, Arjun Mukherjee, Bi ng Liu, Meichun Hsu, Malu [3] Nathan Halko, Per-Gunnar Mar tinsson, and Joel A Tropp. [4] Nitin Jindal and Bing Liu. Opinion spam and analysis. In [5] Ee-Peng Lim, Viet-An Nguyen, Nitin Jindal, Bing Liu, and [6] Arjun Mukherjee, Bing Liu, Junhui Wang, Natalie Glance, and [7] Arjun Mukherjee, Bing Liu, and Natalie Glance. Spotting fake [8] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. [9] Guan Wang, Sihong Xie, Bing Liu, and Philip S Yu. Review 
