 Many small and mid-sized e-businesses use the services of recommender system (RS) provider companies to outsource the construction and maintenance of their RS. The fees that RS providers charge their clients must cover the computation costs for constructing and updating the recommendation model. By using anytime algorithms, a RS provider can control the computation costs and still offer a system capable of delivering reasonable recommendations. Thus, a RS provider should be able to stop the construction of a recommendation model once the cost for computing it reaches the amount the customer has agreed to pay . In this research we suggest anytime algorithms as a possible solution to a problem that RS providers face. We demonstrate how certain existing recommendation algorithms can be adjusted to the anytime framework. We focus on the case of item-item algorithms, showing how the anytime behavior can be improved using different ordering methods of computations. We conduct a comparative study demonstrating the benefits of the proposed methods for top-N item-item recommenders.
 H.4 [ Information Systems Applications ]: Miscellaneous Anytime Algorithms, Collaborative Filtering, Item-Based, Locality Sensitive Hashing Many e-commerce businesses record users X  activities in order to enable personalization and to recommend items to view or purchase. The decision of an e-business to apply personalization and integrate recommendations into their existing systems can be challenging and even risky since the expected return on investment (ROI) is difficult to predict. As for small and medium e-businesses, the required knowledge, expertise, and resources needed for implementing a personalized recommender system may be beyond the ir reach. To minimize the investment and risk, many small or medium e-businesses, prefer to purchase the recommender system as a service. Such services allow an e-business to request recommendations online for the active customer through a remote server, which the e-business neither owns nor operates. In case of an unsuccessful deployment in which the system does not meet the goals of the e-business owner, t he service can be easily terminated without any major financial losses to the business owner. In other words, recommender system services can reduce the required initial investment and present very little risk to the e-business. The providers of such services, often called recommender system (RS) providers, offer a set of pre-made solutions that can be adjusted to specific website needs at a low cost. The solutions offered by the RS providers are generally hosted on remote servers, where the website data is also maintained, prediction models are constructed, and recommendation queries are handled. While the RS provider may own and operate these servicers, growing cloud computing framework services [1], such as Amazon and Microsoft providing, are offering alternative storage and computation possibilities. In such a case, building models for customers may incurs substantial costs to the RS provider. We are motivated by that specific problem that RS providers face , namely, the balancing of model computation costs and quality. One possible approach for controlling the balance between computation cost and recommendation quality is through the use of anytime algorithms (AA) [5]. An anytime algorithm provides a trade-off between computation time and the quality of the solution it provides. The more the computation time, the better the predictive performance that is achieved. Such algorithms can be stopped at any point in the course of the computation and still yield solutions. Given sufficient time, the solution becomes optimal. This research makes two contributions to the field of RS . First, it is presenting the RS provider business model and the problems that these providers face. Second, it shows how anytime algorithms can address some of these problems by presenting two techniques for adapting nearest neighborhood CF algorithms to act as anytime algorithms. Experiments show that these techniques can be used to provide a better time-quality trade-off In the past, recommender systems were employed mainly by large scale e-businesses, such as Amazon. The main reasons for this phenomenon are that implementing recommendation algorithms can involve substantial investments; require certain expertise; programming effort ; high computational power; and suitable infrastructure. In many cases, particularly for mid-sized and sma ll e-b usinesses, these substantial investments cannot be justified by the added value. That is because the cost of realizing such a solution will be much larger than the income which will come out of it. On the other hand, the integration of a ready-made recommender engine into a website requires a set of skills that are commonly found in companies constructing web pages, and less initial investment, except for the needed integration, is required. Consequently, a feasible RS alternative is to outsource the RS to a company that specializes in this area and consume it as a service . Companies providing recommendation systems as a service are often called RS providers. By exposing application program interface (API), the RS providers are storing recorded users X  activities, computing models, and delivering list of recommendations on demand. Since recommendation services should be inexpensive , a RS provider must be able to support many clients to be profitable. It cannot afford to offer its clients a tailor-made solution. Providers typically select the most suitable solution for a customer from a set of pre-made generic methods. While the quality of the recommendations may vary, an obvious restriction is that the on-line recommendations have to be provided very rapidly. It is unacceptable for a system to wait more than a fraction of a second for the computation of a recommendation. To ensure that, the RS providers is using Model-Based [2] approach and typically sign a service level agreement (SLA) that defines the required response time. The RS provider may build its own infrastructure for computing recommendation models and answering recommendation requests rapidly. The cost of this infrastructure and its maintenance, however, may become too high for a RS provider given the low fees it charges its clients. Another alternative is to use cloud computing services [1]. Amazon, as well as other companies, maintain large server farms, and allow users to store data and to run computation processes on these servers. The users pay a fee proportional to the amount of storage, time and computation power they use. Given such cloud computing services, it is easy for the RS provider to estimate the cost of the required computations, such as models building, and charge the e-business accordingly. To maintain profitability when using existing recommender methods, RS providers can offer either simple, low-cost models which are optimal but can be trained rapidly e.g., a Na X ve Bayes Classifier, or expensive more popular models (such as SVD) that require heavy computational resources. However, those existing methods do not allow direct control over the accuracy-cost trade-off. Given the RS provider scenario, that provides RS as a service, it is difficult or even impossible to determine in advance the required time and computational resources needed to generate models offering a suitable level of cost and accuracy for handling unseen data of an e-business. A more compelling approach would be to make use of an algorithm to be constructed in such a way so that it builds the best model possible under the constraint of limited computation time. Standard algorithms for model building do not offer this option. Many of the algorithms for model building in RS, when interrupted before termination, will not have an available model to return. To enable interruption, an algorithm must be designed to allow intermediate result snapshots. Such algorithms are typically called anytime algorithms [5 ].The accuracy that anytime algorithms provide always improve or stay the same over the time, but never decrease. In this research we propose that applying anytime algorithms to the recommendation problem is adequate for RS provider business model. Anytime algorithms have been used in various areas such as data mining [4] decision support systems [8]; and for various intelligent systems [ 11 ]. Little research exists on the application of anytime algorithms to recommender systems. One particularly interesting line of research has been the application of efficient anytime methods to sequential association rules models [3]. In such a models, the anytime approach was used to limit the latency of computing recommendations online and not to the model building process. While this approach is interesting, especially in the case of memory-based algorithms, it is different from the scenario that we are interested in, where the approach is model-based and the recommendations must be computed in constant time. In the neighborhood-based item-item model, the goal is to find the nearest neighbors of each item. A neighborhood is defined as being based on similarity score between items. These similarities are cached in a model that is, in turn, used online to provide recommendations. In a CF approach for implicit datasets, two items may be considered to be similar, if users tend to consume them together. A simple example of a similarity function for implicit datasets is the Jaccard coefficient [9 ]: where U i and U j are the sets of users that consumed items i , and j respectively. In an anytime setting, we can compute item pair statistics until a predefined time limit has been reached. When computing recommendations online, the recommendation algorithm can only use the statistics it has computed within the given time. As we show below, in such a setting, the order by which item pairs are investigated can greatly influence the quality of the recommendations. We suggest two methods for deciding on the order of pairwise simil arity computation. An essential property of such methods is that they must be computed very rapidly. Otherwise, we might spend more time on the initialization of the method than on constructing the model. We use a data structure that allows us to rapidly access all the users who have used an item and all the items that a given user has used. Lo cality sensitive hashing (LSH) [6] is a technique for rapidly computing the similarity of items. We apply the LSH technique to provide us with an anytime approach for the item pair computations. To generate our signatures matrix (reduced representation of the user-item input matrix) over the data, we adapt ed the idea of LSH Google news personalization [5] where the hash value for an item in a given dimension in the signature of an item, is the first user ID that consumed this item in a random permutation of the user ID list. We generated P permutations over the user IDs and applied this hash function on each permutation to end up with an item signatures matrix of the size . This P defines the number of dimensions in the signatures matrix. We now wish to split the item signatures set into two disjoint subsets such that the items in each subset will most likely be more similar to one another than to items in the other subset. We split the items in the signatures matrix based on the medians of the various dimensions. Given an item signature matrix, we first compute a median for each dimension independently. Then, for each item in the set, we compute the portion of its dimension entries whose value is higher than the median of that dimension. If this portion is lower than 0.5, the item is placed in the left child subset; otherwise it is placed in the right child subset. We use a top-down approach, starting with all item signatures and splitting them into equally sized subsets. We continue recursively until we reach a predefined minimum number of items in a subset. This splitting approach creates a balanced binary tree, where every two disjoint subsets created through the splitting process are always construction and the number of items in each node and leaf. Beginning with the leaves of the tree, we first compute for each leaf the pairwise Jaccard similarities of items in the leaf. After all leaves are computed, we move up a level, and compute the pairwise similarities of items that belong to sibling leaves. Moving up levels in the tree, the process is continued, until all pairwise similarities have been computed. Assuming that the signatures matrix maintains the Jaccard similarities and that the median splits the items into two homogenous groups during the construction of the tree, we expect that items with high similarity will be computed first with high probability, and that a good anytime performance will be achieved. The second method is based on the assumption that popular items provide information to the model, and thus should be computed first. As popular items appear in many users X  profiles, they can be utilized for rapidly computing personalized recommendations for most users. This approach can be implemented efficiently by sorting items according to decreasing consumption set cardinality (i.e., popularity). We then compute for each item its similarity to the most popular item, its similarity to the second most popular item, etc. Following is a pseudo code of the popular first approach. L  X  items sorted by decreasing popularity For i = 1 to |L| For each user U who consumed item i For each item j consumed by user U Let I be the number of items, A be the average number of users who have chosen each item, and P be the reduced dimension in the LSH reduction. The initialization complexity for the  X  LSH Tree X  requires O(P  X  I  X  A) for computing the signatures matrix. Then, constructing the tree requires O(I  X  PlogI) operations, for finding the medians in each level in the tree, and there are at most O(logI) levels. Hence, assuming that A and P are much smaller than I , the computation time is dominated by O(I  X  logI).
 The initialization complexity of the  X  Most Popular  X  method is O(I  X  logI) for sorting the items by the number of users who consumed them. In the results below this initialization time is included, but for both methods it required no more than a few hundreds of milliseconds and is therefore negligible. To compare and analyze the anytime behavior of the  X  LSH Tree  X  and the  X  X ost Popular X  method, we carried out a series of experiments. As a baseline we present the Amazon approach [ 10 ] that computes item pairs in an arbitrary order. All three methods for ordering the items pairs leverage the symmetry in the Jaccard coefficient. That is, if was computed, then is also known, and not computed again. The algorithms compute the similarities only for pairs of items which were consumed together by at least one user yielding a score greater than zero. The baseline method, the Amazon approach, is somewhat anytime in nature due to its iterative computation. We conducted experiments on three datasets: buying events from a music web shop: buying events from a software games web shop; and Movie-Lens, described in Table 1.For Movie-Lens, we attempt ed to recommend movies that the user might rate, given other movies she has rated. To model this scenario, we ignored the actual ratings and used a dataset where users either rated or didn X  X  rate a movie. The music dataset contains real data, capturing buying events in a music portal over several consecutive months during 2010. The games dataset is also a real dataset and derives from an online shop selling software games over the past few years. In the music and the games datasets we computed a list of recommended items given other items that the user has bought. Each users X  consumption set is divided randomly into a train and test set. We executed the three algorithms on all three datasets, stopping them at each predefined interval time to measure the performance of the currently computed model. The interval time was 5 seconds for the Movie-Lens; 30 seconds for the games dataset; and 60 seconds for the music dataset. Since the task is to provide top-N recommendations, we found precision@N [7] to be the most appropriate metric for evaluating model performances. Below, we provide results for N=5 , i.e., we directed the algorithm to supply us with 5 recommendations. We also experimented with different values of N (10, 15, and 25), but found no sensitivity to N . We ran all algorithms 5 times, and report the average results. The standard error of the 5 runs was well below 10 -5 and is not shown in the graphs. All algorithms use the same train-test split, allowing us to measure paired statistical significance over the different users. Figures 2, 3, and 4 present precision as a function of computation time for the Movie-lens, Music and Games datasets respectively. Each point in a curve represents the average precision of a model at a certain time during the learning phase, and is averaged over five different train-test splits. The  X  X ost Popular  X  technique shows superiority in the Movie lens and in the music datasets, while the  X  LSH Tree X  shows superiority also in the Movie-Lens and in the games datasets. The Amazon baseline method demonstrates moderate anytime performance. Table 2 presents the area under the curve (AUC) for all three approaches on the three datasets. Each value in the table is the average over the five different train-test splits. The standard deviation of each value is also presented. AUC provides a comparison of the entire running process. These results demonstrate that the anytime behavior of standard recommendation approaches can be improved. Simple technique, such as the  X  X ost Popular X  orders the item pairs so that the models present better precision faster than standard methods. While the  X  LSH Tree  X  method may not seem the best in our experiments, we believe that compared to the popularity technique, it is more general and less tailored to the Jaccard-based similarity algorithm that we employ. We described the problem of RS providers who need to balance the computation time of recommendation models with the fees they collect from customers. We have suggested that anytime algorithms, which support interrupting the computation after a given time, may provide an adequate solution to this problem. RS providers can stop the algorithm once the cost for computation time reaches the payment the RS provider agreed upon with the customer. We claim that typical model-based CF algorithms display poor anytime behavior. Using public and real life buying events datasets, we demonstrat ed this on the well-known Amazon approach. Consequently it is necessary to either construct new algorithms or to adapt existing algorithms to provide better anytime behavior. We view this research as the starting point for further exploration of anytime algorithms for constructing recommendations models. In the future we will investigate anytime techniques for the gradient descent SVD, improving on both the latent factors learning phase as well as the recommendation computation phase. I would like to thank my advisors, Prof. Lior Rokach and Prof. Bracha Shapira for their valuable instruction, ideas and feedbacks on this work, and to Dr. Guy Shani for the insightful discussions. [1] M. Armbrust, A. Fox, R. Griffith, A. D. Joseph, R. H. Katz, [2] J.S Breese. D. Heckerman, C. Kadie (1998). Empirical [3] A. Brun, A. Boyer (2009). Towards Privacy Compliant and [4] D. Dash, M. Druzdzel (1999). A hybrid anytime algorithm [5] T. Dean (1987). Intractability and Time-Dependent Planning. [6] P. Gionis, P. Indyk, R. Motwani (1999). Similarity search in [7] J.L. Herlocker, J.A. Konstan, L.G Terveen, J.T. Riedl [8] M.C. Horsch, D. Poole (1998). An anytime algorithm for [9] P. Jaccard (1901).  X tude comparative de la distribution [10] Linden, B. Smith, J. York (2003). Amazon.com [11] S. Zilberstein (1996). Using anytime algorithms in intelligent 
