 We introduce a novel document clustering approach that overcomes those problems by combining a semantic-based bipartite graph representation and a mutual refinement strategy. The primary contributions of this paper are the following. First, we introduce a new representation of documents using a bipartite graph between documents and co-occurrence concepts in the documents. Second, we show how to enhance clustering quality by applying the mutual refinement strategy to the initial clustering results. Third, through the experiments on MEDLINE documents, we show that our integrated me thod significantly enhances cluster quality and clustering reliability compared to existing clustering methods. Our approach improves on the average 29.5% cluster misclassification index, over Bisecting K-means with the best parameters. H.3.3 [ INFORMATION STORAGE AND RETRIEVAL ]: Information Search and Retrieval  X  Clustering. Algorithms, Experimentation. Document Clustering, Ontology, Bipartite Graph Representation, Mutual Refinement Strategy Document clustering was initially investigated for improving information retrieval (IR) performance because similar documents grouped by document clustering tend to be relevant to the same user queries [20] [21]. Document clustering, however, has not been widely used in IR systems [7] because document clustering algorithms were too slow or infeasible for very large document sets in the early days. As faster clustering algorithms have been introduced, they have been a dopted in document clustering. Document clustering has been recently used to facilitate the nearest-neighbor search [3], to support an interactive document browsing paradigm [7] [10] [26] and to construct hierarchical topic structures [14]. Thus, as information grows exponentially, document clustering plays an important role for IR and text mining. In this paper, we introduce a novel document clustering approach that overcomes those problems by introducing a novel semantic-based bipartite graph representation method for documents. Instead of depending on the traditional vector space model, our method models a set of documents as a bipartite graph, where the two sets on the graph are documen ts and corpus-level significant semantic features that are the selected co-occurrence concepts based on Mutual Information. This bipartite graph has been used in text mining field such as [18] and [28]. Our bipartite graph representation method is different from the traditional methods in that we use co-occurrence concepts as a bipartite graph node while [18] and [27] used words and terms, respectively. The use of co-occurrence concepts has several advantages. First, the co-occurrence concepts have been regarded as more im portant than the single word/term [11] [13] [17] because they capture potential relationships between two co-occurring concepts in text. Second, the use of co-occurrence concepts prevents noise terms, which are unrelated to the topic of a document but are found in the document, from affecting the similarity measur es during document clustering (to be discussed in more detail in Section 3.2). After selecting co-occurrence concepts as significant semantic features, they are classified according to their relationships with documents and their semantic similarities in a concept hierarchy in an ontology. Then the documents are clustered based on each document X  X  contribution to each significant semantic feature group. To refine the initial docum ent clustering, we developed a new spectral co-clustering algorithm that uses the mutual-refinement relationship between the significant semantic feature groups and the document groups so that the two groups are mutually recursively refined. The rest of the paper is organi zed as follows. Section 2 surveys the related work. In Section 3, we propose a novel graph-based document clustering method that integrates bipartite graph representation of documents and th e mutual refinement strategy. An extensive experimental ev aluation on MEDLINE articles is conducted and the results are repor ted in Section 4. Section 5 concludes our paper. In this section, we present our novel clustering method that integrates a bipartite graph representation of documents and the mutual refinement strategy . We call our method COBRA ( C lustering O ntology-enriched B ipartite Graph Representation with Mutual R efinement Str a tegy). COBRA consists of the following three main steps: (1) representing documents as a bipartite graph between the documents and co-occurrence concepts in the documents, (2) initial clustering by grouping co-occurrence concepts, and (3) applying the mutual refinement strategy to the initial clustering results. The first step of all document cl ustering methods is to convert documents into a proper format. We recognize documents as a set of concepts that have their complex internal semantic relationships. We assume that doc uments could be clustered based on the significant semantic features (i.e., co-occurrence concepts) in the documents. Therefore, we represent a set of documents as a bipartite graph to disclose the relationships between the documents and co-occurrence c oncepts among th e documents. The complete procedure of constructing a bipartite graph from a set of documents requires the following three steps: (1) the concept mapping in documents, (2) the selection of corpus-level co-occurrence concepts as significant semantic features of the documents, and (3) the construction of a bipartite graph representation with significant se mantic features. First, the concept mapping matches the terms in each document to the Entry terms in MeSH and then maps the selected Entry terms into MeSH Descriptors. We now explain the process. Instead of searching all Entry terms in the MeSH against each document, we select 1 to 3-gram words as the candidates of MeSH Entry terms after removing all stop words from each document. We select those candidate terms that only match with MeSH Entry terms. We then replace those semantically similar Entry terms with the Descriptor term to remove sy nonyms. We next filter out some MeSH Descriptors that are t oo general (e.g. HUMAN, WOMEN or MEN) or too common in ME DLINE articles (e.g. ENGLISH ABSTRACT or DOUBLE-BLIND METHOD); see [12] for details. We assume that those te rms do not have distinguishable power in clustering documents. Hen ce, we have selected a set of only meaningful corpus-level concepts, in terms of MeSH Descriptors, representing the documents. We call this set Document Concept Set ( DCS ) , where DCS = { C 1 , C 2 C is a corpus-level concept. In the second step, significant seman tic features to be used as a basis for clustering are generate d from a set of documents. These significant semantic features indi cate the semantic components or the intrinsic meanings of the w hole document collection. In order to extract significant semantic features from a set of documents, we take advantage of term co-occurrence in documents. Co-occurrence terms have long been used in document retrieval systems to identify indexing te rms during query expansion [6] [13]. For example, in the biomedical domain, co-occurrence has been used to capture potential relationships between genes, proteins and drugs in biomedical literature [22]. In this way, we use co-occurrence concepts as significant biomedical semantic features in the biomedical literatu re that have been regarded as more important than single term [11] [13] [17]. Given DCS , we define a co-occurrence concept , CC = { C i , C j are two corpus-level concepts in the DCS . A set of co-occurrence concepts for a document set V D is represented by V CC 2 , CC 3 , ..., CC m }, where m is the number of corpus-level co-occurrence concepts for V D.
 In order to select co-occurrence concepts from many concept pairs, the Mutual Information [8] is employed. According to the information theory, the Mutual Information of two random comparing the joint probability of x and y with the probabilities of x and y independently. A higher Mutual Information between x and y means that x (or y ) is non-randomly associated with y (or x ). In this way, the Mutual Information has been widely used to identify lexical dependencies [5], e.g., in finding functional genomic clusters in RNA expre ssion data [4] and in extracting features from large text databases [6][22]. The Mutual Information is defined as follows. Mutual Information x y number of documents that contain both x and y concepts. Because the Mutual Information may be  X  X nstable X  if f(x,y) is very small, we consider only concept pairs with f(x,y) &gt;0.05* N , where N is the number of documents [5]. Co-occurrence concepts are mirrored as edges on the graph and their co-occurrence counts are used as edge weights. In addition, the use of co-occurrence concepts prevents the noise concepts, which are unrelated to the topic of a document but are found in the document (e.g.  X  X ancer X  in this paper), from affecting the similarity m easure process during document clustering. For exampl e, suppose a document D x , that belongs to a document cluster (say DC1), has the concepts {C 1 , C 2 , C however, is not relevant to the topic of D x (as this paper contains many cancer terms) and C 4 is a very important concept in other document cluster (say DC2). In that case, traditional document clustering approaches may assign D x to the wrong document cluster (i.e. DC2) because D x contains C 4 as important concepts of DC2. However, if we consider co-occurrence concepts, the concept pairs with C 4 (as co-occurrence term candidates) would not become co-occurrence concepts due to their very low frequencies over documents. Thus , the irrelevant concept C be removed from the term set of D x and would not lead D irrelevant document cluster DC2. In the third step, we construct a bipartite graph. A bipartite graph G for a given set V D of n documents and a set V corpus-level co-occurrence concepts is represented as G = (V D +V CC , E) , where E indicates the relationships between V V
CC . Weights can be optionally specified on edges. In that case one should provide a sophisticated weight scheme to measure the contribution of concepts to each document. However, such a weight scheme may not be appropriate especially for small sized documents, such as Medline abstracts. In addition, the scheme requires | V D | * | V C | complexity. Thus, we draw an un-weighted bipartite graph. Algorithm: Initial Clustering Algorithm: Mutual Refinement Strategy
Figure 2. The Mutual Refinement Strategy Algorithm Here, COBRA generates initial clusters by combining co-occurrence concepts. Since similar documents share the same or semantically similar co-occurre nce concepts, COBRA combines co-occurrence concepts and then clusters documents based on combining them there are two ways to measure the similarity between co-occurrence concepts: thei r semantic similarity within the MeSH concept hierarchy ( sim cc ) and their documents coverage similarity ( sim doc ), shown in Equations (2) and (3), respectively. The semantic similarity between two co-occurrence concepts ( CC of four concept pairs (i.e., the product of CC i and CC Equation 2 indicates the set of parent concepts of C concept in the concept hierarchy. The document coverage similarity ( sim the overlap rate of document coverage zones by CC This similarity is based on the information theoretic based measure [16]. Formally, it is de fined as the ratio between the amount of information needed to state the commonality of co-occurrence concepts and the information needed to fully describe what the co-occurrence concepts are in terms of the number of relevant documents. sim CC CC sim CC CC Here, occurrence concept. We integrate the two measures with weights into the Co-occurrence Concept Similarity (CCS) . Given two co-occurrence concepts ( CC i and CC j ), the CCS is defined in Equation (4) as follows: (  X  =0.5 in the experiments) sim CC CC sim CC CC sim CC CC = X  + X   X  with  X  [0,1] as weights  X  Based on the average-link clustering algorithm that uses the integrated similarity function, COBRA combines co-occurrence concepts until we get k co-occurrence concept groups. The cost function of the average-link clustering algorithm is shown in Equation (5). ||| | Here, S i is a co-occurrence concept cluster. For initial document clusters COBRA links each document to k co-occurrence concept clusters based on its similarity to k clusters. This similarity is si mply measured by the number of times co-occurrence concepts in each document appear in each of k clusters. A document is assigned to the most similar co-occurrence concept cluster. For example, suppose there are two co-occurrence clusters: (S 1 ={CC 1 , CC 2 , CC 3 }, S and a document has CC 2 , CC 3 , and CC 5 . Then, the document is assigned to S 1 . Figure 1 shows the pseudo-code of the initial clustering algorithm. Through the procedures discu ssed above, COBRA generates initial clusters. However, this cl ustering cannot correct erroneous decisions as in hierarchical cl ustering methods. In other words, once clustering procedure is perfo rmed, the clustering results are never refined further even if the procedures are based on local optimization. In our method, COBRA  X  X urifies X  the initial document clusters by mutually refining k co-occurrence concept groups and k document clusters. The basic idea of the mutual refinement strategy for document clustering is stated:  X  A co-occurrence concept should be linked to the document  X  A document cluster should be related to co-occurrence For this mutual refinement stra tegy we draw another bipartite graph from k document clusters to a set of co-occurrence concepts. Given the graph G = (V DC +V CC , E) , V document clusters ( V DC = {DC 1 , DC 2 , ..., DC co-occurrence concepts ( V CC = {CC 1 , CC 2 , CC 3 , ..., CC is the relationships between V DC and V CC . We specify weights on edges so that we measure the contribution of co-occurrence concepts to each document cluster. This contribution is defined as the ratio between the amount of in formation needed to state the co-occurrence concepts in a document cluster and the total information in the document clus ter in terms of the number of documents. The above statement is mathematically rendered as cntrb CC DC Here, Size function returns the number of relevant documents, docs represents a set of documents with co-occurrence concept ( CC i ) in the document cluster ( DC k ). After each refinement, using k new co-occurrence concept groups, each document is reassigned to the proper document cluster in the same way used for generating th e initial clusters. This mutual refinement iteration continues until no further changes occur on the document clusters. Figure 2 shows the pseudo-code of the mutual refinement strategy algorithm. In this section, we present our test corpora, evaluation measures, and the results of performance evaluation. In order to measure the pe rformance of COBRA, we conduct experiments on public MEDLINE doc uments (abstracts). For the extensive experiments, first we co llected document sets related to various diseases from MEDLIN E. We use  X  X ajorTopic X  tag along with the disease-related MeSH terms as queries to MEDLINE. After retrieving the ba se data sets, we generate various document combinations whos e numbers of classes are 2 to 10 by randomly mixing the docum ent sets. The document sets used for generating the combinations are later used as answer keys on the performance measure. Clustering approaches have been evaluated by comparing clustering output with known classe s as answer keys. There have been a number of comparison metrics, such as mutual information metric [23], misclassification inde x (MI) [27], cluster purity [29], confusion matrix [1], F-measure [15], and Entropy (see [9] for more examples). Among them we use misclassification index (MI), cluster purity, F-measure, and normalized Entropy. See [25] for more discussion on these evaluation metrics. In order to evaluate our approach we compare its effectiveness with a leading document clusteri ng approach BiSecting K-means as well as traditional K-means, hierarchical clustering algorithms (single-link, complete-link, and average link), and Suffix Tree Clustering (STC). Two recent document clustering studies showed that BiSecting K-mean s outperforms both hierarchical clustering methods and K-means on various document sets from TREC, Reuters, WebACE, etc, [19] [2]. A recent comparative study showed CLUTO X  X  v cluster [31] (with default options) outperforms several model-based document clustering algorithms [30]. This clustering program is an implementation of Bisecting K-means with optimization for large datasets. In addition, the program uses the optim ized cluster selection method and a special criterion function that leads to the best overall clustering results in the comparison study of a total seven different clustering criterion functions [29]. According to our previous clustering study [24], CLUTO X  X  v cluster is significantly superior to the original implementation of Bis ecting K-means [19] in terms of clustering quality and scalability. We provided all the clustering algorithms except STC and COBRA with (word*document) matrixes (i.e. vector representation) as input that are generated by doc2mat Perl script [31]. For STC, we input both a word string and a concept string (we detected MeSH Entry terms in each string and replaced them with MeSH Descriptors). The implementations of STC are based on [26]. We use BiSecting K-means, K-means, and hierarchical clustering algorithms in the CLUTO clustering package [31]. Because BiSecting K-means and K-means may produce different results for each run due to their random initializations, we ran them five times and averaged the clustering evaluation measure values. In addition to the comparative experimental evaluation, we also evaluated how much using co-occurrence concepts and the mutual refinement strategy affects the overall clustering quality. In Table 1, we averaged the clustering evaluation metric values for the overall cluster quality meas ure and showed the standard deviations for them to indicat e how consistent a clustering approach yields document clusters (simply, the reliability of each approach). The standard devia tion would be a very important document clustering evaluation factor because document clustering is performed in the circumstance where the information about documents is unknown. Table 2 shows the relative superiority of COBRA to each clustering approach in terms of cluster quality and clustering reliability. From the tables, we notice the following observations:  X  COBRA outperforms the eight document clustering  X  COBRA has a stable clustering performance (see its  X  The cluster selection method of BiSecting K-means (see  X  Hierarchical clustering methods have a serious scalability  X  STC does not scale well.  X  The performance of STC can be considerably improved by We evaluate the mutual refinement strategy (MRS) and the use of co-occurrence concepts to check if each of them is able to improve overall clustering quality. For these evaluations we run COBRA with and without MRS process, and on the uses of co-occurrence concepts or just concepts on the test datasets. Table 3 shows the overall improvements of COBRA through MRS and the use of co-occurrence concepts. We notice that MRS greatly improves the performance of COBRA . The main reason for this result is that MRS, as a variant of EM-type procedure, purifies the initial document clusters by mutually refining k co-occurrence concept groups and k document clusters. In addition, we observe that the use of co-occurrence concepts significantly improves and considerably affects the overall clustering quality. In this paper, we introduced a novel document clustering approach that represents a set of documents as a bipartite graph structure and demonstrated how much the mutual refinement strategy and the use of significant semantic features (i.e. co-occurrence concepts) improve th e document clustering results. The primary contributions of this paper are the following. First, we introduced a new representation of documents using a bipartite graph between documents and signi ficant semantic features (i.e. co-occurrence concepts) in the documents. In addition, using co-occurrence concepts allows us to use more semantically enhanced terms than single-word terms a nd to remove noise terms in document similarity calculation. Second, we showed that using mutual refinement strategy (MRS) significantly enhance clustering quality. As shown in Table 3, MRS improves cluster quality by up to 47.3% in MI. Third, our extensive experiment results indicates that our approach is superior to all the traditional document clustering approaches and yields the most stable clustering results regardless of test corpora. Our approach showed on the average 29.5% cluster quality improvement and 26.3% clustering reliability improvement, in terms of MI, over Bisecting K-means with the best parameters . Fourth, one should notice that only COBRA supplies the summaries of each document cluster through significant semantic features. [1] Aggarwal, C. C., Wolf, J. L., Yu, P. S., Procopiuc, C., and [2] Beil, F., Ester, M. and Xu, X. Frequent term-based text [3] Buckley, C. and Lewit, A. F. Optimization of inverted vector [4] Butte, A.J. and Kohane, I.S. Mutual information relevance [5] Church, K.W. and Hanks, P. Word association norms, [6] Conrad, J and Utt, M. A system for discovering relationships [7] Cutting, D., Karger, D., Pedersen, J. and Tukey, J. [8] Fano, R. Transmission of information. MIT Press , [9] Ghosh, J. Scalable clustering methods for data mining . In N. [10] Hearst, M. A. and Pedersen, J. O. Reexamining the cluster [11] Hristovski, D. et al, Supporting discovery in medicine by [12] Hu, X. Mining novel connections from large online digital [13] Jenssen, T.K., et al. A literatu re network of human genes for [14] Koller, D. and Sahami, M. Hierarchically classifying [15] Larsen, B. and Aone, C. Fast and effective text mining using [16] Lin, D. An information-theoretic definition of similarity. In [17] Perez-Iratxeta, C., Bork, P. a nd Andrade, M.A. Association [18] Slonim, N. and Tishby, N. Do cument clustering using word [19] Steinbach, M., Karypis, G., and Kumar, V. A comparison of [20] van Rijsbergen, C. J. Information Retrieval, 2nd edition , [21] Willett, P. Recent trends in hi erarchical document clustering: [22] Wren, J.D. Extending the mutual information measure to [23] Xu, W. and Gong, Y. Document clustering by concept [24] Yoo I., Hu X., and Song I.Y., Clustering Ontology-enriched [25] Yoo, I. and Hu, X., A Comprehensive comparison study of [26] Zamir, O., and Etzioni O. Web document clustering: a [27] Zeng, Y., Tang, J., Garcia-Frias, J. and Gao, G.R. An [28] Zha, H. Generic Summarizati on and keyphrase extraction [29] Zhao, Y. and Karypis, G. Criterion functions for document [30] Zhong, S. and Ghosh, J. A co mparative study of generative [31] http://www-users.cs.umn.edu/~karypis/cluto/download.html This research work is supported in part from the NSF Career grant (NSF IIS 0448023), NSF CCF 0514679 and the research grant from PA Dept of Health 
