 One of the challenges faced by Facebook users is that privacy settings change not only the visibility of the information, but also impact actions other users can take on a piece of information. These actions on their turn can also create changes to the visibility of that piece of information, sometimes granting access to people originally unintended by the user who posted the information. In this paper we investigate how a simulator that allows users to explore the different situations that can result from privacy settings may support them in anticipating the impact of their decisions. To do so, we have implemented a privacy setting simulator prototype, and evaluated it through a qualitative case-study which involved 12 regular Facebook users. Our findings indicate that the simulator im proved users understanding of the effects of their privacy settings and allowed them to identify misunderstandings they had about the visibility of their information. H.1.2. [ Information Systems ]: User/Machine Systems -human factors, human information processing ; K.4.1. [ Computers and Society ]: Public Policy Issues -privacy .
 Human Factors, Design, Experimentation. Privacy; Facebook; social network sites; user experience; collaborative systems; configur ation; settings; simulation. Social network sites are nowadays one of the most popular applications among internet users. People use them to stay in touch with friends, to find people to date, to meet new people [11, 12] or to collaborate amongst them selves [8]. In other words, these systems are used to achieve a broad range of goals [11, 12]. Facebook is currently the most popular social network site, according to alexa.com (http://www.alexa.com). In June 2014 it (http://newsroom.fb.com/company-info/). However, this broad use of social network sites brings new challenges to researchers of social sciences and collaborative systems [2]. One of the issues that researchers have focused on is privacy, which has been investigated under different perspectives, such as analyzing users X  concern with privacy issues [7, 13] and which aspects (e.g. gender or age) impact privacy setting [17, 21] or even inferring new information about users based on public information [14, 22]. One of the reasons that privacy raises so much interest is because it falls into what Ackerman has coined as the social-technical gap of collaborative systems [1]. The social-technical gap has been defined as the divide between what we know we must support socially and what can be done to support it technically. One of the issues regarding privacy is that socially people make decisions based on who is involved and in which context, making fine distinctions between people and situations and switching between them. Social network sites have been trying to create flexible settings in order to accommodate these different situations. For instance, in Facebook, users can define access to information to all people in a role (e.g. friends or friends of friends) or for a specific piece of information (e.g . only one specific friend can see a photo). Although the flexibility of privac y settings have increased and included some of the suggestions of earlier works [1], it still presents challenges to users, developers and researchers. In an investigation that included an an alysis of feedback issues, de Souza et al. [5] have pointed out that the feedback regarding the meaning of configuration parame ters in collaborative systems requires users to be able to anticipate how their decisions influence group processes. In order to do so they suggest that users should be able to simula te the communicative and social processes affected by such decisions. We believe that one of the challenges regarding privacy is the difficulty users have in anticipa ting the effects their decisions regarding the parameters associated to privacy will have on the available access to their inform ation. Taking Facebook as an example, access to information depends not only on configuration of privacy settings, but also on act ions that others can take over pieces of information. Therefore, in this paper we intend to investigate: (1) Can users understa nd the effects of their privacy settings on the access they grant other users to their information? (2) Would a simulator that presented the impact of their settings in the access to their information increase their understanding of the effects of their decisions? In order to answer these questions we have chosen to investigate Facebook through a case study. The reason for choosing Facebook is its high popularity, as well as the large number of articles analyzing its privacy. The case study focused on privacy regarding photos, since this has been identified as one of the pieces of information users are mo st worried about [15]. The case study involved two steps. The first one required Facebook users to interact with Facebook and perfor m certain privacy settings and explain what they believed the impacts of their decisions were. In the second moment they interacted with a Facebook Privacy Simulator developed for this i nvestigation and simulated the impact of the settings they had defined in step one in Facebook. The case study involved 12 Facebook users, half of them with background in technology. The results showed that users had great difficulties in understanding the effe cts of privacy settings on the access they granted to their information. Sometimes they realized they were not sure of what the impacts were, but in other situations they believed they knew what the effects were, only to find out through the use of the simulator that it was not what they had expected. Our results show that users in fact have great difficulty in translating the combination of settings into the actual social situation it creates for them. Allowing users to simulate the range of situations that may result from their decisions supports their understanding of the systems X  rule s. This solution does not intend to close the social-technical gap in collaborative systems X  settings, but to show its potential as a to ol to help users bridge it. In the next section, we present recent works regarding privacy in Facebook. Then we discuss the problem we are focusing on in this paper. Next we present the Fa cebook Privacy Simulator (PrivSim) developed for our case study. We then describe the case study and discuss the results obtained. Finally, we go over the paper X  X  contribution and next steps in this research. Recently, a number of studies that investigate different problems and issues related to privacy have been published. The issues vary from the difficulties that users have in representing the level of privacy desired [17] or understanding how the settings affect the availability of information [13] to legal aspects of privacy policies [10] or the generation of new information about users by crossing public information available about them [14, 22]. Since our goal is to analyze the challenge of anti cipating impacts of configuration settings, in this section we will focus on the articles related to the difficulties users have in setting privacy and understanding their effects. Some works have shown that users often tend to keep the default settings provided by the system, without making any changes to increase their privacy [7, 13]. Even when users claim to be concerned about their privacy they do not take the necessary measures to ensure the privacy of their information [17]. Furthermore, privacy concerns ma y differ according to users X  profiles, for instance according to their genre [15, 20]. Women tend to worry more about privacy, but they post more often and with less attention to access to these posts than men [14]. Besides, types of information people are willing to share may also differ according to genre [21]. Lack of concern is not the only problem regarding privacy. Often users will try to define settings to achieve the desired privacy, but have difficulties managing th em [13]. Sometimes specific situations or pieces of inform ation require users to define differentiated settings for them. J ohnson et al. [9] have collected data about contents that users had posted and their levels of comfort in sharing content with randomly selected people from their friendship network. Results indicated that users could set privacy to prevent access by people who were not among their friends, but they failed when defining different access to subgroups of friends, for instance, defining that only a subgroup of their friends could see a pos t. Furthermore, other outside factors may add to the complicating factors, such as when a new update restores the original settings [19]. Facebook privacy settings provide users with the possibility to create different access levels to people or to a specific piece of information. However, Liu et al. [13] have shown that users do not always understand how the se ttings impact access to their information, and that there are disparities between the levels of privacy users expected to have and their actual privacy settings. Results show that only in 37% of the cases do users succeed in setting privacy correctly to achieve the desired effect on access to their information. In the remaining cases users often reveal more information than expected. Furt hermore, the authors explored whether friend lists could be automatically populated using community detection algorithms as a potential way for assisting users in managing their privacy. Razavi &amp; Iverson [16] argue that a better model to the common public/private model would be to let users create their own classification of their contac ts. To do so, they proposed a mechanism that allows users to categorize their social network into groups by using tags. These tags are then used to control access to certain pieces of information in their personal space. Besmer &amp; Lipford [3] examined users X  privacy concerns regarding photo tagging on Face book. To do so, they conducted three focus groups and, based on the results, they suggest nine design considerations regardi ng photo tagging. They then developed a tool called Restrict Others that allows users tagged in a photo to open a negotiation with the user who posted the photo about people they would not like to have access to the photo. The photo is untagged while the negotia tion takes place. According to them, the tool complements the untag feature available at Facebook and helps users get a mo re desired level of privacy while maintaining the social value of sharing photos. de Paula et al. [4] argue that the effectiveness of security systems, such as those that ensure privacy, do not depend only on cryptographic algorithms and advanced computers, but rather involve technical, human and social resources. Therefore, they attempt to understand what would be the best approach to design usable technologies to support secu rity. According to the authors, users must (1) view the status of the system, and (2) understand the integration of configuration and action. To support their proposal, they developed an app lication called Impromptu. It provides users with a space for sharing peer-to-peer files. Each user X  X  files are represented by points in a slice of a circular region. Users move their files in the circle to define access to the file, ranging from not shared (outer ring) to for persistently available to read and write (inner ring). Any ch anges are quickly perceived by the whole group. Thus, the real-time visualization of system state and integration between configuration and action can create a collective experience of sharing information. That way people can understand the activities of a distri buted system and anticipate the consequences of their acti ons within that system. Gilbert [6] goes beyond visibility and argues that although social translucence has shown its relevance in supporting the design of social technologies, social networ k sites have not been able to incorporate it, due to their structure. To deal with the challenge, he proposes a way to incorporate social translucence concepts in triadic relations. Using the triad relation associated to awareness he implements a web-based applic ation (Link Different) that lets Twitter users know how many of their followers have already seen a link from someone else th ey follow. The high adoption of Link Different by users indicates the value of including social translucence in social network s ites. Nonetheless, how to apply the proposed triads to higher orde r structures that connect more people is still an open challenge. The works discussed in this section focus on analyzing the difficulties users have in setting the desired privacy and some of them propose a solution on how to support users in dealing with this difficulty. Liu et al. [13] have suggested that users can use automatically generated list of friends X  as a way to facilitate managing privacy. Razavi &amp; Iverson [16] on their turn suggest that users create their own classification by the use of tags. Although these solutions may support users in managing the many levels of privacy, it does not s eem to help them understand the impact of their privacy settings. Gilbert X  X  [6] solution provides awareness on how many users related to the posting user have seen a piece of information in Tweeter, helping him/her decide wh ether or not share it. Besmer &amp; Lipford X  X  [3] tool focuses on preventing undesirable impacts of photo sharing to tagged users, by allowing users to negotiate its visibility. Their solutions support users taking into consideration their social relations when d eciding upon specific actions, but not in anticipating different scenarios that can be generated by their decisions. de Paula et al. [4] propose a visual interactive solution for users to define and understand sharing levels of files. However, in this case, the sharing definition de pends only upon the decision made by the file owner, and is not imp acted by other users X  actions on the file. In Facebook, often visib ility of a piece of information depends not only on settings de fined by the user posting the information, but also on actions other users are entailed (by these settings) to take on that piece of information. In this work, we focus on allowing users to preview what access other users may have to their information by exploring how users X  roles and actions may change this access. The challenge in understanding the effects of users X  decisions in many collaborative system se ttings, including Facebook privacy settings, is that the available parameters are not the only aspects considered in the final outcome. For instance, in Facebook users can choose who they would like to have access to a photo by choosing a category of users (e.g. Friends) or specific individuals. The interface in this case could be considered straightforward, as shown in Figure 1. However, what is not clear in the interface is that there are other aspects involved in the final visibility of that piece of information. In this example, if someone who has access to the photo (the user who posted it or someone he/she has granted access to) tags someone who had not been given pe rmission to see it, that person immediately gains access to the phot o. Thus, often the final result of a specific parameter depends not only on the value chosen for it, but also on other parameters or actions taken by the users themselves or other users th ey have relationships with. Thus, we believe that in such situations allowing users to simulate the different scenarios that may be generated by considering the different combination possibilities would be an efficient way for them to understand and anticipate the possible effects of their decisions regarding settings. The Facebook Privacy Simulator (Pri vSim) is a prot otype created specially to investigate whether a simulator would support users in having a better understanding of the impact of settings and actions on the access others have to their information prototype focused on photos and their visibility by others, since photos seem to raise more con cerns from users regarding their access by others [15]. Photos we re also chosen because their visibility in Facebook depends on settings defined by users, but also on actions that other user s who have given access to the photo can take on it, as illustrated in the example in the previous section. The prototype uses a model re lationship network in which it represents possible roles users may have in the network. The relationship network depicts role s that are present in Facebook friendship network (e.g. friends or friends of friends). Since the model network does not represen t users X  real network, known character names were chosen to represent users. Figure 2 (a) shows how the network is depicted in the prototype X  X  interface 2 . PrivSim was modeled based on Facebook X  X  functionalities available to users from February to April 2013. It included all the possible scenarios that could be generated based on combination of possible photo privacy settings and actions performed on photos. To identify all these possible scenarios a systematic inspection of Facebook was conducted and experimentation of the possible di fferent scenarios made. In the prototype the user does not actuall y post a photo, but simulates it. He takes the role of the user depicted as the root node of the relationship network and defines the privacy settings he would like for a photo. Based on the set ting, the prototype visually indicates (through the use of colors) which members of the network would be able to see the photo. If the user clicks on one of these users, he would also s ee what actions this other user could take regarding the photo (e.g. like or tag). The user may explore the various scenarios by simulating actions the different users in the network could take and visualizing their impact. The prototype also presents explanati ons regarding the impact of the simulated actions. Figure 2 presents the interface for PrivSim. The user always takes the role of the root node of the relationship network, in the case Mickey. He can then explore the different scenarios considering distinct settings for the photo, as well as actions he or others who have access can take on the photo. To do so, he will interact with PrivSim interface that provides him with: Notice that PrivSim is a single-user system, not integrated to Facebook which was developed for the sole purpose of this investigation. It is worth emphasizing that th e prototype X  X  interface is in Portuguese, and was translated to English for this article. (a) Visual representation of the relationship network using (b) Options of possible privacy set tings that the user can choose (c) Indicates which user of the network is selected and the (d) Presents the actions available for the selected user. By (e) Presents explanation in natura l language of all actions that (f) If users X  actions generate inconsistencies according to the (g) Short step-by-step about how to use PrivSim. As the user In order to simulate and explore scenarios of how privacy settings and possible actions impact access to information, users interact with PrivSim as if they were posting a photo. They can choose different members of the network st ructure and select actions they could take and see their impact . Users can only choose members who have access to the photo (node color different from grey), since only they can take any action on the photo. It is interesting to note that the action that grants a member of the network access to the photo, also defines the actions that are available to him/her regarding the photo. For instance, a member who has been tagged (e.g. Daisy in Figure 2) will be able to edit its date, whereas others with whom the picture has been sh ared (e.g. Goofy) will not have that action available to them. Figure 3 illustrates the actions Mickey took that have defined the actions Daisy and Goofy would have available to them regarding the photo, and the difference between the set of actions available to each one of them. Furthermore, when an action th at involves other members is chosen by a member of the network, PrivSim indicates which other members can be involved in the action. For instance, in Figure 2 both Minnie and Donald can tag a photo, however, the set of people they can tag in the photo is different (e.g. Minnie can tag Clarabelle, but Donald cannot). Besides, the natural language explanation describes the conse quences of an action, involving other aspects that are not shown vi sually. For instance, if Mickey chose a  X  X ublic X  setting for his photo, and selected the Share action, PrivSim would present the following explanation:  X --&gt; Share: you (Mickey) can share your photo on your own timeline or on the timeline of your friends (Minnie, Donald, Goofy, etc.). The users who you share your photo with can remove it from their timeline without inform ing you. Your friends (Minnie, Donald, Goofy, etc.) can share y our photo on their timelines with their friends. You have no control over the sharing of your photo, but you receive a warning whenever it is shared. X  Notice that the explanation presen ts not only who he could choose to share the photo with, but what other actions it would, as consequence, entail other members to take. In the example, when Mickey chooses to share a photo, it informs him about users being able to remove the photo from their timeline or to share it with their friends. The number of combinations of possible settings and possible actions is considerable, even just for the model network. Thus, by simulating different scenarios, settings and actions, users can understand the impact of their actions. PrivSim allows users to explore what-if questions regardi ng the impact of the combination of settings and actions. In Facebook X  X  interface users can only see the privacy settings they can choose from (see Figure 1) . They have to actually set them in order to try and understand their effects. Once they have set the privacy settings, they can see what actions they can take on it. To understand how a specific friend or the general public (a member that has no relation to the user) would see the photo, users may use the  X  X iew as X  functionality. However, they still would not be able to simulate other user s X  actions and their impacts, but rather visualize the actual effects of their decisions. Thus, if they identify some undesirable effect, it might have already generated unwanted consequences. For instance , if users notice in the  X  X iew as X  that they have unwillingly granted access to a photo to someone they did not intend to, they could go back and change their settings. However, there are no guarantees that in that time frame (between defining the setti ngs and checking their effects) the unintended person would not have already seen the photo. Furthermore, the  X  X iew as X  functi onality does not allow users to explore the consequences of other users X  actions. That is, Mickey may view his info as Donald woul d, but not the consequences of Donald tagging Daisy in a photo he (Mickey) has posted. The information is also available at the help system, but reading the descriptions of all the possibl e scenarios may not be very appealing to users, and may not be easily understandable. In order to investigate how a simulator, such as PrivSim, can support users in understanding the impact of configuration in settings that affect group social processes, we conducted a case-study for Facebook. We next describe the methodology used and the results obtained. PrivSim allows Facebook users to simulate various scenarios relating how photos  X  privacy settings and possible actions upon these photos impact who would have access to them. Thus, PrivSim allowed us to make an initial evaluation of how the availability of simulations coul d support users in understanding the many possible scenarios involved in the combination of settings and possible actions. In this section, we present the methodology that was used in this case study and the results obtained from it In this case study we contrasted the understanding regarding information access that users had from using only Facebook, from what they perceived with the help of PrivSim. The study had two steps, in the first step participan ts interacted with Facebook, and in the second with PrivSim. The goal of the first step (interacting with Facebook) was to collect data to answer our first research question  X   X  Can users understand the effects of their privac y settings on the access they grant other users to their information? X  . Whereas the second step (interacting with PrivSim) aimed at collecting data to our second question  X   X  Would a simulator that presented the impact of their settings in the access to their information increase their understanding of the effects of their decisions? X . For that reason, we chose participants who were frequent Facebook users, and thus could be considered to have a good knowledge of Facebook interface and functionality. All participants performed the steps in the same order, since the goal of step 2 was to investigate whether the simulator could improve the understanding of privacy settings effects in Facebook that users already had based on their former experience with Facebook. In other words, we were more interested to see if there were impacts users could not perceive through the interaction with Facebook, and that PrivSim conveyed to them. Twelve real Facebook users participated in the evaluation performed in May 2013. All of them were previously informed of the goal and conditions of the eval uation, participated voluntarily and signed a consent form. An in itial interview about users X  privacy concerns and their experience with Facebook was conducted. Participants were Brazilians and had their accounts on Facebook for at least one and a half years. They were all undergraduate or graduate students with ages ranging from 19 to 29 years old. Of these, six people had a background in information technology (IT) and six had backgrounds in other fields. The reas on for selecting these two user groups was to be ab le to verify whether people with an IT background had a better understanding of how Facebook behaved regarding access to information, and if PrivSim could help improve their understanding of the impacts of privacy settings and actions on Facebook. Al so participants were equally distributed between males and females. Regarding users X  experience wi th Facebook, the time they had been using the system varied from one and a half to four years. All users access Facebook at least once a day and seven of them claimed to enter the system more than ten times a day. Furthermore, only four participan ts reported never having changed their privacy settings on Facebook and only two said they do not post personal photos and that they have in their accounts only profile pictures or photos in which they have been tagged. # Tasks / Questions 1 Post a photo with privacy setting  X  X riends X . 1.1 Who can view the photo after posted? 1.2 With whom can your friend Donald share the photo? 1.3 Who can Donald tag in the photo? 2 Tag Minnie in the photo posted in the first task. 2.1 After tagging your friend Mi nnie, someone besides you 2.2 Can Minnie tag people who did not gain access to the 3 Post a photo to only yourself and "Minnie". 3.1 May Minnie (who has access to photo) tag her friends? 4 Post a picture with the se tting "Friends of Friends". 4.1 Could Minnie tag her friend Clarabelle, who is not 4.2 Could Minnie share the photo with Horace, who is a 4.3 Could Clarabelle, a friend of a friend of yours, tag For the evaluation, a scenario was prepared, and a test profile for Facebook was created, which made use of the same characters used in PrivSim, with the user taking the role of Mickey. The evaluation consisted basically of a set of tasks related to photo posting and defining their privacy settings. The tasks chosen represented privacy settings and actions users frequently perform on photos (posting to friends or friends of friends, tagging Facebook has acknowledged the popularity of tagging and sharing photos. See: http://www.facebook.com/notes/ facebook/making-photo-tagging-easier/467145887130 and sharing), and also that could generate changes to the original settings. After each task, the participant was asked to answer an electronic form containing multiple choice and open-ended questions regarding their understa nding of who would have access to the photo and the expected impact of certain actions on this access. Audio of the whole test was recorded, as well as users X  interaction with the systems. Table 1 shows a summary of the tasks and the questions related to them. Before interacting with Facebook, users were informed that during the test they could ask about any doubts that might come up regarding how to perform the requested tasks on Facebook interface. They were also told that they could explore any of Facebook X  X  features and when answering questions they could go back to the system if they wanted to. After executing the tasks in Facebook, users were interviewed br iefly to know if they had had trouble answering the questions related to the tasks. In the next evaluation step, PrivSim X  X  interface was explained in a brief presentation, which lasted about 5 minutes. Once again, users were informed that they could ask for help if they had doubts about PrivSim X  X  interface or about how to execute any of the tasks on PrivSim. At the end of their interaction with PrivSim, a post-test interview was conducted, regarding their opinion about PrivSim and which moments of the whole test they felt they had had more difficulties in answering the questions. In the next section, we present the results obtained for the interaction with each one of the systems. In order to reference tasks and questions presented in Table 1 we will use task number  X  X  X  to reference tasks, and the questions will be referenced by the format  X  X .Q X , where  X  X  X  is the task number and  X  X  X  the question number for that task, for instan ce  X 1.2 X  refers to the second question of the first task. From the nine questions users we re asked, there were only two that all participants got righ t: question 1.1 and 4.1. Whereas question 1.1 they all responded pr omptly, in answering question 4.1 five participants said they we re not sure if their answer was correct. Table 2 presents the informati on on the successes and doubts users had in each of the questions an swered by them. The first two columns show the number of correct answers in each question grouped by participants background (or not) on IT. Column  X  X ad no doubts but were wrong X  shows the total number of participants in each question who felt confident about their answer, but were wrong. Finally, in column  X  X ad doubts X  indicates, for each question, the total number of pa rticipants who expressed their doubts about the correct answer, or did not know how to answer. An independent-samples t-test was conducted to compare the hit rate between non-IT and IT background groups. There was not a significant difference in the hit rate for non-IT (M=2.1111, SD=2.36878) and IT groups (M=3.0, SD=2.17945); t (16)=-0.828, p = 0.42. These results suggest that users, independently of their IT background, had equivalent diffi culties to answer the questions asked. Column  X  X ad doubts X  draws attention to the fact that with the exception of question 1.1, in all other questions at least half of https://www.facebook.com/notes /facebook-data-science/the-anatomy-of-large-facebook-cascades/10151549884868859 the participants felt insecure a bout how Facebook would behave in the situation at hand. Comments such as  X  I have doubts . X  or  X  I don X  X  know  X  followed by pauses in which users thought about what to expect were common during the test. One participant (IT background) to try and find out the answer for a couple of questions explored the explicative texts available at the privacy settings interface, but claimed that they did not help him answer the questions. # Non-IT Hits IT Hits Had no doubts but were wron g Had doubts 1.1 6 6 0 0 1.2 0 0 4 8 1.3 0 2 5 6 2.1 1 1 5 6 2.2 1 3 2 10 3.1 1 5 0 10 4.1 6 6 0 5 4.2 3 2 3 8 4.3 1 2 0 11 One other important aspect identified is that in several cases participants felt confident about their answer, but the answer was actually wrong, as is shown in the column  X  X ad no doubts but were wrong X . This situation is ev en worse than the participants being aware that they did not know how Facebook would behave, because it means that users have a misunderstanding about the system X  X  behavior, but do not reali ze it. This combination is prone to lead to undesired situations, such as people who are not meant to have access to a piece of information accessing it, or not everyone who is supposed to access it being aware of it. Both cases could potentially lead to social inconveniences or problems for users. During the tests, an example of such a situation was observed regarding question 2.2. This qu estion was whether someone who had been tagged in a photo could tag someone else who was not in the set of people who the photo pos ting user had given access to. Eight of the participants got the answer wrong, that is they believed that the tagged user w ould not be able to tag someone who did not already have access to the photo (when in fact he would be able to tag any of his friends or friends of friends, regardless of them having acce ss to the photo or not). Among them, two were certain of their answers and that only the users who the photo posting user had intended would be allowed to have access to the photo, independently of who was tagged. In other words, in this case users were not aware that unintended users could gain access to that piece of information as a result of other users X  actions. In the interview, after having interacted with Facebook, all participants reported having had difficulties in answering the questions. They referred to the tag or share features as a major source of doubt. When asked about what they thought could be the cause of these difficulties, some stated that they had never thought about it, or had never sought to find out, or even that it could be a problem of lack of practice. For instance, one of the participants said  X  Because I never looked it up, nor is it clear anywhere, you X  X  have to look it up, and I never did  X  4 . When we asked him and two others, who had given a similar answer, where they thought they could find this information, if it would be through the interface, or through the help page, they all said they believed they would only be able to find it at Facebook X  X  Help system. However, none of them used the help system to try and answer the questions. Another participant, when asked about where he expected to find explanations regarding the doubts he had, answered that  X  With just one account I could not [find out], maybe I would need to have an extra Facebook profile or ask a brother, a cousin or a friend X  . In addition, seven users also indicated explicitly that Facebook X  X  interface is not clear regarding its behavior on users X  privacy such as the situations that were addressed in the questions. For instance, another participant said  X  Actually the interface is not very clear. At least if it had some warning messages [...]. Sometimes you end up doing something that is not quite what you want due to the lack of knowledge, then it becomes trial and error, you do it and see what happens  X  . It is interesting to notice that participants X  comments were not about how to do what had been asked of them, but rather about the difficulties they have in getting information about the impact of privacy settings and actions. One of them said he resorts to a strategy of simulation to understand the impact of these settings. To do so he either uses a dummy profile for testing or counts with another user who is willing to help him understand the effects of his actions. Notice, however, that this strategy would not be enough to cover all the possible scenarios, since doing so would require involving several people or several fictitious accounts, each having a different relationship to his actual profile. One other user acknowledges using a trial a nd error strategy. Nonetheless, this strategy may cause problems in situations in which by the time the user realizes the effect achieved was not the desired one he had already disclosed more in formation than he would have wished to or to people he had not intended to. In analyzing the execution of the same tasks with PrivSim, it is noticeable that none of the partic ipants had doubts in answering the questions and the accuracy of responses was approximately 97%. There were only three errors throughout the test apparently due to some difficulty in unders tanding PrivSim X  X  interface. The results of the evaluation with PrivSim are depicted in Table 3. After the evaluation with PrivSim, a post-test interview was conducted. In this interview all pa rticipants said they had more difficulties in answering the que stions when interacting with Facebook than with PrivSim. Also, they all stated that PrivSim had helped them understand the im pact of privacy settings and actions, and thus, answer the que stions. Some of them also commented that during the interaction with PrivSim they had realized that some of the answers they had given during the interaction with Facebook were wrong. One participant said:  X  X  know what will happen [with the us e of PrivSim]. I realized that Facebook is full of mistakes, full of things that make no sense. I think I have gotten right most of the questions that I had gotten wrong before. So I know who will be able to see the photos and what possibilities the person will have X . Another participant  X s This quote was actually said in Portuguese, the participant X  X  first language, and was translated by authors. This is the case for all quotes presented in the article. comment indicated that PrivSim allowed her to become aware of how she might be more exposed than she had thought. In answering whether she would use PrivSim she said:  X  X  would be interested in using it [PrivSim] once I have found out today that I am not as safe as I believed I was. X  . # Non-IT Hits IT Hits Had no doubts but were wron g 1.1 6 6 0 0 1.2 6 5 1 0 1.3 5 6 1 0 2.1 6 6 0 0 2.2 6 6 0 0 3.1 6 6 0 0 4.1 6 5 1 0 4.2 6 6 0 0 4.3 6 6 0 0 Except for three of the users who said that they are not concerned with privacy, all the others said they would like if Facebook had a simulator of the effects of privacy configurations and that they Facebook and not an app, because they tend not to trust apps. At the end of the interview, participants were asked if they would like to use a simulator if it was available on Facebook. Those participants who had declared to worry about privacy on social networks sites showed more in terest in using the feature. Furthermore, some of them answered that they would use it, since during the experiment they had realized they did not quite understand all the possible impacts of the settings. The others said that they would not use it or would use it only in specific cases. For instance, one user said that one specific situation he would be interested in using PrivSim woul d be when he wanted to post photos he would not want his gi rlfriends X  relatives to see. The first research question we were set out to investigate in this work was  X  X an users understand the effects of their privacy setting in the access others have to their information? X  The reason for raising this question is motivated by the fact that access to information depends not exclusiv ely on the privacy settings defined by users. One of the results of the setting is the definition of the subset of actions that wi ll be available for all users who have access to the information. Furthermore, the actions themselves, if taken by users, ca n generate changes to the group of people who have access to the phot o. In other words, privacy settings in fact define a number of paths (or social processes) that are possible to be taken. Different paths may or may not give access to a distinct set of people. Therefore, making this process and all possible resulting scenarios clear to users at the interface is a very hard task, if not impossibl e. Of course, a description in natural language of all of them could be a way to explain all scenarios to users, but it would re quire users to be interested in reading the whole text. The results described in the previ ous section showed that not only did users have doubts about how Facebook would behave, but also they had misunderstandings that they were unaware of. As discussed, the latter is even a less desirable situation than the former. However, these results do not come as a surprise. Understanding how decisions rega rding configuration settings made at a given moment will impact group processes and access rights along a period of time is a complex problem. This is even more the case when other conditions (e.g. other users X  actions) can change the final results. We believe that this problem is not specific to Facebook privacy settings or interface, but that it is faced whenever a set of parameters is used to configure group collaborative processes [5]. In order to deal with this challe nge, it would be necessary to allow users to simulate the processes and how they are impacted by parameter configuration and ac tions. Thus, our second question was  X  X ould a simulator that presente d the impact of their settings in the access to their information increase their understanding of the effects of their decisions? X . PrivSim interaction results showed that users had a thorough understanding of how the settings and actions associated with them could impact photo visibility. Furthermore, they realized during the use of PrivSim that many of the expectations they had built through Facebook interface were wrong. Notice that these expectati ons were based not only on their interaction during the test, but on their whole experience with Facebook. Graph 1 shows a comparison between the correct responses obtained through the interaction with Facebook and PrivSim. These results can be taken as a sign of how an interface that allows users to simulate and explore the possible scenarios (before making decisions) could be a good solution for the problem raised. A paired-samples t-test was co nducted to compare the hit rate using PrivSim and Facebook. To do so, the total number of hits for each question was compared. There was a significant difference in the hit rate for PrivSim (M=11.6667, SD=0.5) and Facebook (M=5.1111, SD=4.28799); t(8) = 4.6, p = 0.002. These results suggest that when using PrivSi m, users had a mean value of correct answers greater than when they interacted with Facebook. Although our study has generated interesting findings supporting the usefulness of a simulator in c onveying to users impact of their privacy settings in Facebook, some limitations of the study should be noted. First of all, some participants reported using the  X  X iew as X  function to understand the effect s of privacy settings, as well as accessing Facebook through diffe rent accounts or through the support of friends. In our case-st udy none of them made use of such strategies, even though they could explore the interface to find out. Th e decision not to use th ese strategies could be due to the controlled setting of the experiment. First of all, there were no real effects that mattered to the participants, since a test profile was being used. Second, they mi ght not have had at the time access to their usual resources  X  ot her accounts that related to the test profile that they could use to understand the impact of their settings or friends they could ask. Furthermore, some participants said they expected the information about the impact of the settings to be available at Facebook help. Once more, although one user inspected the local explicative texts at the privacy settings interface, none of them interacted with the help system to answer the questi ons. Again this could have been because they did not really care about the final results of the settings or even that it may not have been clear to them that they could resort to the help system in case of doubts. In the methodology, in cases where user s expressed doubts they could have been explicitly asked to do whatever they would normally do to solve them. Evaluating whether the information was in the help system and if users could find it was not releva nt in determining whether the simulator could or not support users in anticipating the impact of settings configuration. Nevert heless, having found that the simulator can be an interesting solution to the problem, comparing the user experience and efficiency in using it versus the help system could be relevant in an alyzing its cost and benefits. One may argue that another limitation would be the small size and simplicity of the network used in the evaluation. However, in the first step in which participants interacted with Facebook, as our results showed, even for such a simplified network users had little understanding of the impacts photo settings and actions. Furthermore, participants were frequent Facebook users for over an year, and most posted photos (even the two who said they did not post photos said that they had shared photos in which they had been tagged) so they could have obtained this knowledge from their previous experience with Facebook in real context. Even if the simplified network depicted could have acted in favor of the understanding of the simulation in PrivSim, results still mean that the simulator improved users X  understanding of configuration and actions impact s. Furthermore, it was not our goal to explore what would be the best way to represent the simulation (in the prototype or real systems). In order to evaluate whether a simplified version of the network would be able to allow users to generalize Facebook behavior and apply it to their own network would require further investigation to be conducted. In this article we have investigated the challenges for users to understand the possible impacts of Facebook privacy settings. We also examined the proposal to offe r as a solution a simulator that can emulate the impacts generated, and that allows users to explore the different scenarios. Through the case-study in Facebook we have illustrated through users X  experience that often they are not sure of what to expect as results of privacy settings taki ng into account the actions they enable, or they have misunders tandings about it. Also, their interaction with PrivSim has show n that given the opportunity to simulate the different scenarios resulting from specific settings and actions, users were able to understand rules of how Facebook worked, and even discuss whether they believed they were adequate or not. The case-study involved 12 users a nd was not intended to generate quantitative results about the issues at hand, but rather allow for qualitative and interpretative investigation of them. The tasks and scenarios chosen to be investigated were representative of situations in which access permissions could change along time according to what actions were performed upon the pieces of information, and thus were challenging for users to anticipate. The results obtained were able to illustrate the difference in the perception of the cause-effect relation between settings, actions and information access provided by the interface and with the help of the simulator. As discussed, we argue that the problem is not specific to Facebook interface, but is faced in any situation in collaborative systems in which parameter setting is used to define how social processes will work. The gist of the problem is at the social-technical gap that is inherent to collaborative systems [1]. According to Ackerman, technology may never account for all nuances that are involved in social processes. A solution to deal with this problem is providing user s with systems that are highly configurable. If on the one hand, this allows users to narrow the social-technical gap, on the othe r, it creates a large number of resulting scenarios that users should be able to anticipate in order to achieve the desired results. Allowing users to simulate and explore the effects of parameter configuration supports them in anticipating all of the possible scenarios. Nonetheless, simulation does not close the social-technic al gap, but supports users in understanding the rules created in th e system to represent social processes, that is supports them in bridging the existing gap. The results of this article contri bute to the investigation of the challenges involved in making clea r to users the cause-effect of configuration and the impacted pr ocesses. Although PrivSim itself was not meant to be directly integrated to an existing system, the results indicate that a simulator is a viable solution that could be incorporated by designers of collaborative systems. We do not claim to contribute to a discussion about what would be the best way to incorporate simulation to social network sites or collaborative systems in general. Nonetheless, we have come across indicators of aspects to be considered in such an effort. First of all, the simulation should be incorporated into the system, so that whenever the system behavior is changed, the simulation would automatically change as well . Besides, regarding privacy in social network sites, some partic ipants of our study pointed out that they probably would not trust an application that was not native to the system. Also we have not explored what would be the best representation to depict the social relations network. In our study users understood well the simplified netw ork and, as a result of their interaction with PrivSim, the rules of Facebook behavior. An interesting next step would be to investigate whether users would be able to transfer this understanding of Facebook behavior to their real relationships X  network. If so, a model network could be an interesting option to avoid an overly complex visualization of the users X  real networks [18]. In this paper it was not our goal to compare different ways to convey Facebook behavior rules to users. Nonetheless, it might also be interesting to investigat e other possible representations of systems X  behavior rules and compare how each one of them impacts users X  u nderstanding. The results have shown that simulation supported users in understanding the social processes. As a next step in our research we are developing a simulator as an integrated part of a collaborative system (in a differe nt domain than social network sites). Our goal is to analyze if a nd how users interact with it in a real context of use. Although we discussed in this articl e the challenges faced by users of collaborative systems, it is interesting to note that a similar challenge is faced by collabora tive system designers. Designers must choose the parameters, and the rules that define which aspects of collaboration they will impact and how. Often, the large number of possible combinations means that a broad range of scenarios is possible. Anticipating these scenarios at design time is not an easy task. Therefore, crea ting a modeling language and tool that would allow designers to desc ribe their decisions and explore the possible scenarios that they w ould entail could be useful to support their decision making. We believe that the results discussed in this paper are valuable to advancing in this direction. Authors are grateful to all participants of the case-study. They also thank INWeb (MCT/CNPq/ grant 57.3871/2008-6) for partially supporting this work. [1] Ackerman, M. 2000. The In tellectual Challenge of CSCW: [2] Bernstein, M.S., Ackerman, M.S., Chi, E.H. and Miller, R.C. [3] Besmer, A. and Richter Li pford, H. 2010. Moving beyond [4] de Paula, R., Ding, X., Dourish, P., Nies, K., Pillet, B., [5] de Souza, C.S., Leit X o, C.F., Prates, R.O., Am X lia Bim, S., da [6] Gilbert, E. 2012. Designing soci al translucence over social [7] Gross, R. and Acquisti, A. 2005. Information revelation and [8] Hamidi, F. and Baljko, M. 2012. Using social networks for [9] Johnson, M., Egelman, S. a nd Bellovin, S.M. 2012. Facebook [10] Johnston, A. and Wilson, S. 2012. Privacy Compliance Risks [11] Joinson, A.N. 2008. Look ing at, looking up or keeping up [12] Lampe, C., Ellison, N.B. and Steinfield, C. 2008. Changes in [13] Liu, Y., Gummadi, K.P., Kr ishnamurthy, B. and Mislove, A. [14] Pontes, T., Magno, G., Vascon celos, M., Gupta, A., Almeida, [15] Rauber, G., Almeida, V. an d Kumaraguru, P. 2011. Privacy [16] Razavi, M.N. and Iverson, L. 2009. Improving personal [17] Reynolds, B., Venkatanathan, J., Gon X alves, J. and Kostakos, [18] Shen, Z., Ma, K.-L. and Eliassi-Rad, T. Visual analysis of [19] Strater, K. and Lipford, H. R. 2008. Strategies and struggles [20] Stutzman, F. and Kramer-D uffield, J. 2010. Friends only: [21] Tufekci, Z. 2007. Can Y ou See Me Now? Audience and [22] Zheleva, E. and Getoor, L. 2009. To join or not to join: the 
