 SALSA is a link-based ranking algorithm that takes the re-sult set of a query as input, extends the set to include ad-ditional neighboring documents in the web graph, and per-forms a random walk on the induced subgraph. The station-ary probability distribution of this random walk, used as a relevance score, is significantly more effective for ranking purposes than popular query-independent link-based rank-ing algorithms such as PageRank. Unfortunately, this re-quires significant effort at query-time, to access the link graph and compute the stationary probability distribution . In this paper, we explore whether it is possible to perform most of the computation off-line, prior to the arrival of any queries. The off-line phase of our approach computes a  X  X core map X  for each node in the web graph by performing a SALSA-like algorithm on the neighborhood of that node and retaining the scores of the most promising nodes in the neighborhood graph. The on-line phase takes the results to a query, retrieves the score map of each result, and re-turns for each result a score that is the sum of the matching scores from each score map. We evaluated this algorithm on a collection of about 28,000 queries with partially labeled results, and found that it is significantly more effective tha n PageRank, although not quite as effective as SALSA. We also studied the trade-off between ranking effectiveness and space requirements.
 H.3.3 [ Information Search and Retrieval ]: Information Storage and Retrieval X  search process, selection process Algorithms, Measurement, Experimentation SALSA, link-based ranking, retrieval performance, web sea rch has an off-line and an on-line phase. During the off-line phase, we compute a  X  X core map X  for each vertex in the web graph, which assigns scores to the vertex and some or all of its neighbors. During the on-line, query-time phase, we retrieve the score map for each result of the query, look up each result in all score maps and add up its scores, and use the sum as the total score of the result.

We evaluated this algorithm using the same data sets and the same retrieval performance measures that were used in earlier comparisons of PageRank, HITS and SALSA [3, 11, 12]. We found that our new algorithm is significantly more effective than PageRank and HITS, although not quite as effective as the best on-line version of SALSA known to us. We also explored the tradeoff between the size of the score map and retrieval performance. Given that any commercial deployment of our algorithm would require the score maps to be distributed over multiple servers and kept in main memory on each, the size of a score map governs the number of required servers. We found that it is possible to limit the size of the score map quite substantially without giving up too much in terms of effectiveness.

The remainder of this paper is structured as follows: Sec-tion 2 describes the data sets and the performance measures we used. Section 3 briefly reviews the on-line SALSA al-gorithm and its effectiveness, as measured against our data sets. Section 4 motivates the X  X core map X  X oncept by demon-strating that singleton-seed SALSA is not very effective if w e retain only the score of the seed itself. Section 5 defines a version of SALSA that starts from a single seed document and captures the scores of the seed and its neighbors in a score map; this algorithm outperforms PageRank and HITS. Section 6 shows that we can improve effectiveness further by using a wider definition of neighborhood inspired by Dean and Henzinger X  X  Companion algorithm. Section 7 examines the efficiency-effectiveness tradeoff when retaining only the k highest scores in the score map. Section 8 studies the effectiveness of our approach for queries with varying de-grees of specificity. Section 9 surveys related work. Finall y, section 10 offers concluding remarks and avenues for future research.
The evaluations presented in this paper were conducted on the same two data sets used in several earlier studies [3, 11, 12]. These two data sets are a large web graph and a substantial set of queries with associated results, some of which were labeled by human judges.

The web graph was obtained by performing a breadth-first search web crawl that retrieved 463,685,607 pages. These pages contain 17,672,011,890 hyperlinks (after eliminati ng duplicate links embedded in the same web page), which refer to a total of 2,897,671,002 distinct URLs. The mean out-degree of a crawled web page is 38.11; the mean in-degree of discovered pages (whether crawled or not) is 6.10.
The query set was produced by sampling 28,043 queries from the Live Search query log in a frequency-biased fash-ion, and retrieving a total of 66,846,214 result URLs for these queries, or about 2,838 results per query on average. It should be pointed out that our web graph covers only 9,525,566 pages or 14.25% of the result set. 485,656 of the results in the query set (about 17.3 results per query) were rated by human judges as to their relevance to the given query using a six point scale, the ratings being  X  X efinitive X  , mutually enforce each other: a page receives a high author-ity score if it is linked to by pages with high hub scores, and a page receives a high hub score if it links to pages with high authority scores. Concretely, if A is the adjacency matrix of the neighborhood graph, then the authority scores of the base set are the principal eigenvector of the matrix A T A , and the hub scores of the base set are the principal eigen-vector of the matrix AA T (modulo normalization). These eigenvectors can be computed using the standard power it-eration method.

Lempel and Moran X  X  Stochastic Approach to Link-Sensiti-vity Analysis [6, 7] is a variation of Kleinberg X  X  algorithm. SALSA takes a result set R as input, and constructs a neigh-borhood graph from R in precisely the same way as HITS. Similarly, it computes an authority and a hub score for each vertex in the neighborhood graph, and these scores can be viewed as the principal eigenvectors of two matrices. How-ever, instead of using the straight adjacency matrix that HITS uses, SALSA weighs the entries according to their in-and out-degrees. If we define the inverse in-degree matrix I such that I u,v is in ( v )  X  1 if the neighborhood graph contains an edge ( u, v ) and 0 otherwise, and we define the inverse out-degree matrix O such that O u,v is out ( u )  X  1 if the neigh-borhood graph contains an edge ( u, v ) and 0 otherwise, then the SALSA authority scores are the principal eigenvector of the matrix I T O , and the SALSA hub scores are the principal eigenvector of the matrix OI T .

The SALSA computation can be viewed as a stochastic process (hence the name), or more precisely as perform-ing two independent random walks over the neighborhood graph, an authority walk and a hub walk . The authority walk starts out at any node with at least one incoming link; and each transition consists in choosing an incoming link at ran -dom, following it to reach some ancestor, and then selecting one of the ancestor X  X  outgoing links at random and follow-ing it. Likewise, the hub walk starts out at any node with at least one outgoing link; and each transition consists in choosing an outgoing link at random, following it to reach some descendant, and then selecting one of the descendant X  X  incoming links at random and following it. In this view, the SALSA authority vector is the stationary probability dis-tribution of the authority walk, and the hub vector is the stationary probability distribution of the hub walk.
In earlier work [11, 12], we evaluated the effectiveness (the retrieval performance) of both HITS and SALSA, comparing them to BM25F [14] (a state-of-the art ranking algorithms based on textual features, including anchor text) and PageR -ank [13]. We found that HITS and SALSA hub scores are not particularly useful for ranking purposes, and that HITS authority scores are slightly more effective than PageRank scores, but that SALSA authority scores are substantially more effective than either. We note that the highest effec-tiveness is achieved by combining BM25F, our best single feature, with a link-based feature. We also found, quite sur -prisingly, that SALSA performed best when sampling be-tween 3 and 8 ancestors per result (depending on the per-formance measure), as opposed to the 50 ancestors suggested by Kleinberg and Lempel &amp; Moran.

In subsequent work [3], we discovered that the perfor-mance of SALSA can be improved further by selecting the neighbors of results using consistent sampling instead of ran-dom sampling. Consistent sampling is deterministic, and it preserves set overlap  X  if two sets overlap by a certain frac-a \ b 0 1 2 3 4 5 0 0.1707 0.1713 0.1715 0.1705 0.1699 0.1689 1 0.1727 0.1803 0.1799 0.1793 0.1789 0.1781 2 0.1761 0.1820 0.1816 0.1811 0.1811 0.1806 3 0.1753 0.1810 0.1809 0.1804 0.1805 0.1801 4 0.1736 0.1797 0.1801 0.1801 0.1803 0.1799 5 0.1722 0.1793 0.1800 0.1801 0.1801 0.1799 a \ b 0 1 2 3 4 5 0 0.0705 0.0711 0.0714 0.0706 0.0702 0.0695 1 0.0688 0.0743 0.0744 0.0741 0.0738 0.0734 2 0.0703 0.0745 0.0743 0.0741 0.0740 0.0737 3 0.0697 0.0737 0.0736 0.0732 0.0732 0.0729 4 0.0688 0.0726 0.0726 0.0726 0.0727 0.0723 5 0.0679 0.0720 0.0721 0.0721 0.0720 0.0719 a \ b 0 1 2 3 4 5 0 0.2499 0.2519 0.2518 0.2493 0.2480 0.2458 1 0.2456 0.2570 0.2563 0.2555 0.2546 0.2533 2 0.2480 0.2557 0.2554 0.2544 0.2542 0.2531 3 0.2454 0.2521 0.2520 0.2508 0.2505 0.2498 4 0.2421 0.2486 0.2488 0.2484 0.2483 0.2474 5 0.2395 0.2470 0.2473 0.2469 0.2470 0.2464 Table 1: Effectiveness of CS-SALSA, sampling (up to) a ancestors and b descendants of each result using consistent sampling. The remainder of this paper introduces the singleton-seed SALSA algorithm and various refinements. The original SALSA has two stages at query time: neighborhood expan-sion for a results set and eigenvector calculation. SS-SALS A involves an offline calculation, finding a separate neighbor-hood expansion for each document in the corpus, giving it a score vector based on eigenvector calculation. Then at quer y time the score vectors are summed to give the overall SS-SALSA scores. It should be noted that the summed scores are not mathematically equivalent to the original SALSA scores. However, this SALSA-like algorithm has the advan-tage of query-time efficiency, because graph expansion and eigenvector calculation happen before query time.
The first variant of singleton-seed SALSA we present is a  X  X trawman X : it literally treats every vertex in the web grap h as a singleton result set and applied CS-SALSA to it. This means that for each eigenvector calculation we keep only the score of the seed vertex. As we will see, this algorithm is quite ineffective; the main reason for presenting it is to motivate the concept of a score map later on.

The off-line phase of our strawman algorithm SS-SALSA-0 takes a web graph ( V, E ), a link selection predicate P , and ancestor and descendant sampling parameters a and b , and returns a global authority scoring function g : V  X  R mapping vertices to real-valued scores: For all x  X  V :
Having shown that computing a single score per vertex in the web graph is ineffective, we now present a refined version of singleton-seed SALSA that computes a score map for each vertex that captures the score of the seed itself and all its neighbors. This means that the presence of a page in the results set can confer a score on some other page. We will use the notation [[  X  7 X  x ]] to denote a function that maps every key to x , and as before, we will write s [ k ] := v to indicate that s is extended to map k to v .

The off-line phase of this algorithm SS-SALSA-1 takes a web graph ( V, E ), a link selection predicate P , and ancestor and descendant sampling parameters a and b , and returns a global authority scoring function g : V  X  ( V  X  R ) mapping vertices to score maps, which in turn map vertices to real-valued scores: For all x  X  V : 1. Set the neighborhood vertex set: 2. Set the neighborhood edge set: 3. Let B A be { u  X  B : in ( u ) &gt; 0 } . 4. s := [[  X  7 X  0]] 5. For all u  X  B : s [ u ] := 6. Repeat until s converges: 7. g [ x ] := s
Given a result set R  X  V , the on-line phase of SS-SALSA-1 assigns the score P v  X  R g [ v ][ r ] to each r  X  R . In a reason-able implementation, the score maps of the entire result set are retrieved first, and then the summation iterates for each result over the cached score maps.

Table 3 shows the effectiveness of SS-SALSA-1 for the id link selection predicate and ranging values of a and b , using the same data sets and performance measure as used previ-ously. The SS-SALSA-1 algorithm is significantly more effec-tive than SS-SALSA-0; in fact it outperforms both PageR-ank and HITS. The highest NDCG@10 value shown in the table is for the sampling parameters a = 0 , b = 5. Under this parameter setting, each score map has 6 key-value pairs: the seed, no ancestors, and 5 descendants. If we represent score maps as association lists of 8-byte integer URL identifiers and 4-byte floating-point scores, then each map requires 72 bytes. It is also worth noting that the highest NDCG@10 value is in the rightmost column of the table; as we will see below, effectiveness continues to increase as we go beyond b = 5. and d ancestors of descendants of each result. 4. s := [[  X  7 X  0]] 5. For all u  X  B : s [ u ] := 6. Repeat until s converges: 7. g [ x ] := s The on-line phase of SS-SALSA-2 is identical to that of SS-SALSA-1.

Note that SS-SALSA-2 has four free parameters. Evalu-ating any single parameter combination is quite expensive (multiple days on the hardware available to us), so we were not able to probe the entire space. Instead, we explored the effectiveness of the algorithm across one parameter dimen-sion at a time, and fixed that parameter at the locally op-timal setting when switching dimensions. It is possible and Table 4: Effectiveness and space requirements of SS-SALSA-3, sampling no ancestors, all descendants, no siblings, and 75 mates of each result, and using the k highest scores in the neighborhood of each result for ranking. For comparison, the table also shows the space requirements and effectiveness of PageRank and  X  X pproximate SALSA X . scendants from each seed (see Table 1). If the role of neigh-borhood expansion is to include certain nodes that are  X  X se-ful X  for SALSA computation, it seems that finding useful hubs and authorities from a singleton seed requires a differ-ent strategy.

In the non-singleton case, an algorithm like CS-SALSA ex-pands from a result set that might already contain multiple useful hubs and authorities. Then neighborhood expansion gives it multiple chances to find further useful nodes. By contrast SS-SALSA must find a graph with multiple use-ful hubs and authorities from a single seed. This explains why relatively aggressive expansion is required, taking ma ny nodes via parameters b =  X  and d = 75.

When expanding aggressively from a single seed, there is a greater risk of suffering from noise or drift. This might be the reason that ancestors and descendants are treated differently ( a = 0 and b =  X  ). Web authors create inter-domain links for a variety reasons, so the ancestors of a node may contain a mixture of hub pages and other types of page. Perhaps ancestor expansion yields useful pages at too low a rate, and the SALSA calculation suffers. It may be that single-seed expansion succeeds more reliably for a seed tha t is a useful hub, because a hub page has a coherent set of descendants yielding useful authorities at a sufficient rate for the SALSA computation to succeed. Overall, sampling of descendants might be a more reliable strategy.
We leave it to future work to design an experiment to test this explanation. This would involve identifying pages as hubs or authorities, then testing whether the score maps of hubs make a greater contribution to the overall effectivenes s of SS-SALSA.
Increasing the number of sampled descendants per result and including its mates into the neighborhood graph leads to significant gains in effectiveness, but at a crippling cost: t he more neighbors we include in each score map, the larger the size of the map. In order to be useful to a commercial search engine, ranking needs to be very fast; so if singleton-seed score map sizes and therefore a manageable hardware ex-pense. For example, a search engine could maintain a dis-tributed in-memory table mapping 10 billion URLs to 120 byte score maps each using a cluster of around 80 comput-ers with 16 GB of RAM each. By comparison, the approach described by Gollapudi et al. [3] produces an NDCG@10 of 0.1826 on the same web graph and query set, but associates a 379-byte feature vector with each URL in the web graph.
Finally, we investigated the correlation between the speci -ficity of a query and the effectiveness of SS-SALSA-2 and SS-SALSA3. Our definition of specificity is purely syntactic: we do not attempt to capture whether one query is more specific than another query in any semantic sense; rather, we just compare the cardinalities of the result sets produced by the various queries. We view queries with large result sets (for which good ranking algorithms are all the more important) as general, and queries with small result sets as specific.
Unfortunately, our query set does not contain the size of the entire result set. Therefore, we adopt our previous ap-proach [11, 12] and approximate query specificity by the sum of inverse document frequencies of the individual query terms. The inverse document frequency of a query term t with respect to a document collection C is defined to be taining t . This approach assumes that the individual terms of a multi-word query occur independently of each other; the fact that this assumption is unwarranted means that we may over-estimate the specificity of a query. Although not perfect, using query term IDF as a measure of specificity is at least directionally accurate.

We broke our query set down into 13 subsets according to specificity, and ranked the queries in each subset using CS-SALSA with a = 2 and b = 1, 4 SS-SALSA-2 with a = 0, b =  X  , c = 0 and d = 75, and SS-SALSA-3 with the same sampling parameters and k = 10. For comparison, we also include the performance of PageRank [13] and BM25F [14].
Figure 2 shows the performance of each feature for each query subset. The figure shows three graphs, one per per-formance measure. The lower horizontal axis of each graph shows query specificity (the most general queries being on the far left); the upper horizontal axis shows the size of each of the 13 query subsets. The vertical axis denotes re-
Note that the CS-SALSA curve differs from the curve shown in [12] due to the use of consistent sampling and dif-ferent and better sampling parameters. line (indexing-time) and an on-line (query-time) stage [3] . The off-line stage computes a summary of the neighborhood of each web page; the summaries are stored in a summary server. The on-line stage retrieves the summaries of each result to a query (using a single round of remote procedure calls), uses them to construct an approximate neighborhood graph, and computes SALSA on that approximate graph.
The work described in this paper is similar to the ap-proximate SALSA algorithm. The main difference is that in approximate SALSA , the eigenvector computation that is at the heart of SALSA is performed at query-time, whereas in our approach, it is performed off-line, further reducing the amount of computation that has to be performed at query time. Inherent to both algorithms is a tradeoff be-tween effectiveness and space requirements. Compared to approximate SALSA , the algorithm described in this paper performs particularly well in the space-restrained portio n of the spectrum; it is possible to achieve decent effectiveness at a storage expense of, say 120 bytes per web page.
This paper describes a novel approach to link-based rank-ing that represents an interesting trade-off between effecti ve-ness and efficiency. The algorithm described in this paper is a more effective ranking feature than PageRank, HITS authority scores, or simple in-degree; but it is somewhat less effective than SALSA authority scores. The algorithm consists of an off-line stage and an on-line stage. Most of the computation happens during the off-line stage; the on-line stage simply consists in retrieving a  X  X core map X  for each result to a query, and adding up scores for each re-sult from each score map. In this respect, the algorithm is similar to PageRank (the off-line phase of which requires a very expensive eigenvector computation over the entire web graph; whereas the on-line phase merely looks up a sin-gle score for each result). By contrast, the original SALSA algorithm is performed entirely on-line, and introduces a substantial latency into the query processing pipeline, mo st of it attributable to assembling the neighborhood graph of the result set. A recent variant [3], Approximate SALSA, eliminates some of that latency by summarizing the neigh-borhoods of each web page off-line. However, the summaries require 379 bytes per page and must be stored in memory for fast query-time access. This means that a large search engine would require a cluster of  X  X ummary lookup X  servers to use the approximate SALSA technique. The SS-SALSA technique described in this paper also requires lookup serv ers, but the score maps are one-third the size, so hardware costs are also one third. This increase in efficiency is associated with a drop in effectiveness. Therefore SS-SALSA occupies a point on the efficiency-effectiveness tradeoff curve where efficiency is important, but effectiveness is maintained. The effectiveness of SS-SALSA is still better than PageRank or HITS.
