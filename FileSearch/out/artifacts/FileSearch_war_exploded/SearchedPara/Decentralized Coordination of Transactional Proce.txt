 Business processes executing in peer-to-peer environments usually invoke Web services on different, independent peers. Although peer-to-peer environments inherently lack global control, some busi-ness processes nevertheless require global transactional guarantees, i.e., atomicity and isolation applied at the level of processes. This paper introduces a new decentralized serialization graph testing protocol to ensure concurrency control and recovery in peer-to-peer environments. The uniqueness of the proposed protocol is that it ensures global correctness without relying on a global serializa-tion graph. Essentially, each transactional process is equipped with partial knowledge that allows the transactional processes to coor-dinate. Globally correct execution is achieved by communication among dependent transactional processes and the peers they have accessed. In case of failures, a combination of partial backward and forward recovery is applied. Experimental results exhibit a signif-icant performance gain over traditional distributed locking-based protocols with respect to the execution of transactions encompass-ing Web service requests.
 H.2.4 [ Systems ]: Concurrency, Transaction processing Measurement, Performance, Reliability DSGT, Decentralized Coordination, Global Correctness, Peer-to-Peer Communication, Transactional Processes, Partial Rollback. With the proliferation of e-business technologies, service-oriented computing is becoming increasingly popular. Access to data and dation within the project MAGIC.
 Copyright 2005 ACM 1-59593-140-6/05/0010 ... $ 5.00. documents is provided by services which can range from simple read/ write operations on data items to complex business functions like booking a trip. An important challenge is to combine service invocations into a coherent whole by means of processes [13, 3]. Workflow and process technologies support this kind of service composition, usually provided by sophisticated system infrastruc-tures like IBM X  X  WebSphere [6]. However, such systems require a global coordinator (or a set of such coordinators replicated for performance reasons). While this can be easily enforced for well-established business interactions, it is no longer true when interac-tions rather follow an ad-hoc style.

In peer-to-peer (P2P) environments, each peer provides a set of services that can be composed to processes. These processes might run over several peers. An important task in such environments is to ensure a globally correct execution of these processes, i.e., to provide atomicity and isolation applied at the level of processes. This demands for a concurrency control and recovery technique that respects the P2P style of communication between the system components and that is able to scale to large networks of peers.
Conventionally, isolation and atomicity are enforced using a lock-ing protocol like the strict two-phase locking (2PL) in combination with a global commit protocol like the two-phase commit (2PC) [1, 11]. Such protocols are usually applied to short living transac-tions and are state-of-the art in application domains which allow centralized approaches. However, for P2P environments concepts from distributed transaction processing are required, i.e., S2PL is combined with a distributed deadlock detection protocol like [10, 12, 7]. Other options are optimistic protocols or timestamp order-ing protocols, respectively. Optimistic protocols, such as proposed in [8], can be applied in P2P environments without modifications. They execute transactions completely and check directly before the commit whether the transaction is allowed to commit. Thus, op-timistic approaches come along with a high number of rollbacks when the duration of transaction execution is high. Timestamp or-dering protocols are often used in distributed environments since they do not require coordination of different resources [1]. Instead, each transaction is associated with a timestamp reflecting its en-trance into the system. The ordering of executed service invoca-tions of different transactions on each peer must reflect this order. Thus, a high number of transactions are unnecessarily aborted. In distributed environments, the additional problem of global time and clock synchronization arises.

In this paper, we present a new protocol for ensuring concur-rency control and recovery especially in P2P environments. Es-sentially, the protocol ensures globally correct executions without involving a global coordinator. The main idea of the protocol is that dependencies between transactions are managed by the transactions themselves. A core aspect is that globally correct executions can be achieved even in case of incomplete knowledge by communication among dependent transactions and the peers they have accessed. The protocol relies on a decentralized serialization graph, where each peer logs local conflicts and each transaction maintains a local serialization graph. While the local conflict information of a peer reflects the dependencies among the transactions that invoked ser-vices on that peer, the serialization graph of a transaction includes the dependencies in which the transaction is involved.

Since synchronous updates are not appropriate for any kind of distributed environment due to performance reasons [4], the update of the local serialization graphs is performed in a lazy manner. In consequence, the serialization graphs will not necessarily be up-to-date. If at commit time a transaction is able to deduce out of its local serialization graph that does not depend on another active transaction, it is allowed to commit. Conversely, if a transaction detects a cycle in the serialization graph, the cycle has to be re-solved by rolling back one or more transactions involved in this cycle. Here, combining partial backward and forward recovery al-lows to significantly reduce the amount of work needed to recover from such a failure.

The paper is organized as follows: Section 2 introduces our de-centralized serialization graph (DSGT) protocol for ensuring con-currency control and recovery in P2P environments. Section 3 presents results we achieved from experiments with our protocol. Section 4 reviews related work and Section 5 concludes.
As illustrated in Figure 1, we assume a P2P network where each peer P i offers a set of services O P i = { s P i vices of a peer can be invoked within transactions T k = ( O using the service interface of that peer. In the following, notes the set of services to be invoked by transaction T k the partial order defined over O T
A transaction may fail due to several reasons. To ensure atomic executions, the effects of the transaction X  X  service invocations must be compensated. This compensation is done by invoking compen-sation services in reverse order (cf. [13]). Following usual prac-tice in semantic concurrency control, we also assume that the peers provide for each service s j they offer an inverse service semantically undoes the effect of the invocation of s j . Note that the effects of an inverse service strongly depend on the semantics of the original service. It might also be an  X  X mpty service X .
For correctness, we rely on the criterion conflict preserving se-rializability [1]. Following [15], a schedule (the services invoked by the transactions of the system and the order between them) is correct, if and only if the serialization graph of the schedule is acyclic. In this case, the schedule is called serializable . A seri-alization graph contains a dependency between two transactions, if there is at least a pair of service invocations of both transactions that is in conflict, i.e., changing the order of these service invo-cations results in a different final system state or different system outputs (a formal definition for conflicts between semantically rich operations can be found in [15]).

Enabling the peers to detect conflicts between service invoca-tions performed by them requires to equip each peer with its local conflict matrix. This matrix contains information which services of that peer pairwise conflict (and under which conditions). To con-centrate on the main aspects of DSGT, we assume here that service invocations on different peers are not in conflict. However, results presented in [14] are applicable to remove this restriction. In ad-dition, each peer has to store in its local log which service invoca-tions of which transactions it has executed. Using this information together with the local conflict matrix, a peer detects conflicts be-tween local service invocations of different transactions. Note that the peers do not maintain serialization graphs but only local logs.
In contrast, each transaction owns a local serialization graph which comprises the conflicts in which the transaction is involved. Essentially, the graph contains at least all conflicts that cause the transaction to be dependent on other transactions. This partial knowl-edge is sufficient for transactions to decide whether they are al-lowed to commit. Note that a transaction can only commit after all transactions on which it depends have committed.

But reasoning whether a transaction is allowed to commit is not sufficient. Additionally, the system must be able to recover from failures. In what follows, we use the notion of recoverability [1] as criterion for correct failure handling. It is important to note that our system model does not require a component that maintains a global serialization graph.
The decentralized serialization graph test (DSGT) protocol relies on the following observations: Algorithm 1: Peer Protocol Following these observations, DSGT guarantees that a transaction only commits after all its pre-ordered transactions have committed. A transaction receives the information about its pre-ordered trans-actions from the peers where it has invoked services. Essentially, each peer attaches a list of conflicting services and their associated transactions to the results of each service invocation. The trans-action maintains these dependencies in its local serialization graph and is then able to decide autonomously whether or not it is allowed to commit. If at commit time a transaction detects that there is an active transaction on which it depends, it waits until it receives in-formation about the commit of the other transaction. Thus, it is part of the protocol that each transaction informs all its post-ordered transactions about its commit. The transaction receives the infor-mation about its post-ordered transactions at commit time from the peers on which it has invoked services.

It is important to stress that DSGT is an optimistic variant of a distributed serialization graph testing protocol. Services are ex-ecuted without checking for conflicts, i.e., conflicts are detected afterwards and  X  in contrast to the pessimistic centralized serializa-tion graph testing  X  (cascading) rollbacks may be needed to resolve cyclic dependencies. To reduce the recovery costs, DSGT applies partial rollback by executing compensation services until the point where the cyclic dependencies disappear. Then, DSGT continues the forward execution of the services from that point on.
Figure 2 illustrates the states of the DSGT protocol with a special focus on the part running on the transaction side.
 The part of the protocol that runs on each peer reacts on requests Algorithm 2: Transaction Protocol from transactions. Each peer awaits requests from transactions: Algorithm 2.2 defines the part of the protocol that runs on each peer.

The part of the protocol that runs on each transaction consists of two threads. The proactive execution thread is always in one of the following states: Forward Execution: The transaction invokes services according Backward Execution: The transaction rolls back partially by in-Validation: The transaction waits until the corresponding node in Inform Peers: The transaction informs all peers on which it has Inform Txs: Finally, the transaction informs all its post-ordered The following state transitions can take place: Forward Execution  X  Validation: If the transaction has executed Validation  X  Backward Execution: If the transaction detects that Forward Execution  X  Backward Execution: This transition hap-Backward Execution  X  Forward Execution: As soon as all re-Validation  X  Inform Peers: This transition occurs when the val-Inform Peers  X  Inform Txs: This transition happens as soon as
Algorithm 2 describes the part of the protocol that runs on the transactions to detect cycles in the local serialization graph.
In the following subsection, we show how DSGT ensures global correctness.
The main execution thread of the transaction protocol consists of three phases. Phase 1 is the execution phase. In this phase, a trans-action invokes services in an optimistic manner without requesting any locks (cf. t = 1 and t = 4 in Figure 3). Then, the peers exe-cute the services according to Algorithm 2.2. The peers determine the emerging conflicts ( t = 2 resp. t = 5 ) and return them to the transaction ( t = 3 resp. t = 6 ). As soon as the transaction has executed all services, the main execution thread enters the valida-tion phase. The transaction now has to wait until it does not (or no longer) depend on any other active transaction. As soon as this condition is fulfilled, the main execution thread enters the commit phase, in which the peers are informed about its commit. Addition-ally, the transaction informs its post-ordered transactions about its commit. This is necessary since these transactions might wait for this commit in order to commit as well. The serialization graph up-date thread of the other transactions receives this information and changes the corresponding local serialization graph accordingly.
To sum up, transactions invoke services without determining on the spot the corresponding effects on the serialization graph. Nev-ertheless, at least prior to the commit, a validation is performed that checks whether the transaction has been executed correctly and whether it is therefore allowed to commit. This is closely re-lated to well-established optimistic concurrency control protocols like backward-oriented concurrency control [8] and to serialization graph testing protocols [16]. As in all other cases, transactions are allowed to commit in DSGT only if they do not depend on an active transaction. Transactions get this information from the peers they invoke services on. We thus can state, that no transaction commits before all its pre-ordered transactions have committed , which guar-antees a serializable schedule (formal proofs are presented in [5]).
Secondly, an important aspect of the commit phase is that trans-actions willing to commit eventually succeed when all pre-ordered transactions have committed (the proof can also be found in [5]). Consider again Figure 3. T 1 does not know about the conflict with T . However, in order to be able to commit, T 2 must be informed when T 1 commits. Therefore, since the dependency with T 1 known to T 2 , we cannot require the latter to query T 1 for its state. Rather, T 1 has to actively notify all peers it has accessed during its execution about its commit ( t = t c ). Each peer checks for rele-vant conflicts ( t = t c + 1 ) and returns this information to the issu-ing transaction ( T 1 ) before removing the entries of the committing transaction from the log (at time t c = t + 2 ).
A transaction involved in a cycle must detect this. To detect a cycle, a transaction must have the relevant conflict information. Therefore, transactions have to exchange their local knowledge on conflicts. Since synchronous updates of local serialization graphs are not appropriate for any kind of distributed environment due to performance reasons [4], the update has to be performed in a lazy manner. In consequence, the serialization graphs will not necessar-ily be always up-to-date.

A cycle in the serialization graph implies the following: 1. None of the involved transactions can commit due to cyclic 2. The cycle will not disappear without any intervention. 3. Cycles might be caused by conflicts of more than two trans-The implementation of the information exchange for detecting cy-cles covers three aspects: i.) If a transaction causes a new conflict, it updates its local graph and propagates the graph to its pre-ordered transactions. ii.) A transaction uses a graph received from another transaction to update its local serialization graph. If this leads to changes, it propagates its updated graph to its pre-ordered transac-tions (Certainly, other approaches work theoretically as well, e.g., distributing conflict information to all other transactions in the sys-tem or to all other ones of the same partition of the serialization graph. The other extreme  X  no communication at all between trans-actions  X  would correspond to a timeout heuristic: A transaction not being able to commit assumes after some time to be involved in a cycle and rolls back. However, due to lack of space, we concentrate in this paper on the path-pushing approach which turned out to be the most efficient one in our experiments). iii.) If the transaction detects a cycle and the victim selection strategy selects itself as the victim, it aborts.

This approach is heavily inspired by distributed deadlock detec-tion algorithms, especially by path pushing approaches such as pre-sented in [10]. Of course, the semantics of serialization graphs and wait-for-graphs are different. Figure 4 illustrates the graph propa-gation mechanism of DSGT. The figure shows the local graphs of the transactions T 1 and T 3 . At time t = 1 , T 1 invokes a service on the peer, which causes a conflict with T 3 . The peer returns this information at t = 2 . T 1 updates its local serialization graph with this information ( t = 3 ). Then, T 1 propagates its graph to the pre-ordered transactions T 2 and T 3 . At t = 4 , T 2 receives this message. It updates its local graph. After updating its graph, T 3 the changes to T 4 .
DSGT uses partial rollback to reduce the costs of rollbacks. Ba-sically, a transaction does not roll back completely, but only to the point at which the (isolation) failure is resolved, i.e., where the cyclic dependencies have disappeared. This concept is applicable for all kinds of protocols, but it is especially useful for reducing the effect of cascading aborts which may appear in DSGT. Figure 5 illustrates this. There are five transactions whose service invoca-tions lead to a cycle in the serialization graph. Assume that is chosen as victim. Using complete rollback implies that undo-( s compensated requiring to undo also T 5 and T 3 . Choosing instead of T 1 as victim would lead to the same result. So, obviously, a cycle in case of serialization graph testing implies to rollback all transactions forming the cycle plus all post-ordered transactions.
Partial rollback may reduce this drawback: Choosing T 1 as the victim to be rolled back completely implies that T 2 compensates s s compensations are not necessary and especially s T 2 touched, so that T 3 and T 5 do not have to rollback. Thus, this ex-ample shows how the avalanche of cascading aborts can be stopped by using partial rollback.

To express in a schedule how far a transaction has to be compen-sated, we introduce the partial rollback operator r T that service invocations should be rolled back until (and including) service s b of T v .

Following the ideas of the unified theory of concurrency control and recovery [15], an abort is replaced by a sequence of compen-sation service invocations of the associated forward execution in reverse order. This is called expansion . In here, we assume perfect commutativity behavior [15]. The expanded schedule S 0 comprises (1) the  X  X ld X  service invocations, (2) the service invocations of the victim transactions which have to be undone, and (3) all cascading compensation service invocations.

Partial rollback can be used for recovering a schedule from an isolation failure. The following rule states how and where to insert note the service invocations of T 1 as s 1 be the schedule, in which the transactions T 1 ...T n form a cycle. Let T v be the victim transaction selected out of T 1 ...T the resulting schedule S 0 = ( O 0 ,&lt; 0 ) is constructed as following: A schedule containing a partial rollback operator is correct, if the expansion of this schedule can be reduced to a serial one using an arbitrary sequence of the following transformation steps: 1. Commutativity Transformation: Two service invocations of ever, our experiments show that choosing the youngest transaction is usually the best approach. 2. Undo Reduction Transformation: Two service invocations We conclude this section with highlighting an important property of our operator placement strategy. If a set of transactions forms a cycle in the serialization graph, the rollback operation placement leads to an acyclic serialization graph after the expansion and re-duction of the schedule (proof see [5]). We have evaluated DSGT in an application server environment. The experimental setup consists of client hosts, on which trans-application server follows a three-tier architecture. The upper layer is the Web Container which constitutes a full-fledged HTTP server. The Web Container hosts Web service servlets handling SOAP ser-vice calls on the client hosts. Every time a SOAP request arrives, the Web service servlet in the Web container invokes a stateless session bean in the EJB container. The EJB container forms the middle layer of the application server. Besides the session beans, this layer also manages persistently stored entity beans. The en-tity beans are mapped onto a relational database (we have used IBM Cloudscape), which forms the lowest level of the application server. The EJB-based three tier architecture is the most common approach to support a service-oriented environment. Therefore, we have chosen this architecture for the evaluation of DSGT.
On the client side, the transactions run in Java 2 (Standard Edi-tion) Virtual Machines following DSGT and S2PL, respectively (S2PL has been chosen since it is the most commonly used pro-tocol). To have a fair comparison, we implemented S2PL as good as possible (note that the common transaction processing standards like JTS include two-phase-commit but do not address locking of resources at service level). We even realized the deadlock detection in an optimal way by implementing a centralized deadlock detec-tion component. This component checks immediately for cycles as soon as new dependencies emerge in the system. The communica-tion between transactions for graph exchange (serialization graph testing protocol) as well as between transactions and the central-ized deadlock detection component (S2PL) is based on Java RMI.
In the experimental evaluation, we varied the number of services between 2000 and 10000 to parameterize the conflict probability. The higher the number of services, the less is the conflict probabil-ity. On each of the five client hosts we used, there are always 20 tions but not on communication between peers. Thus, we can eval-uate our P2P-approach with only one application server, but with many client servers. active transactions making a total of 100 active transactions . The length of the transactions is 8 to 12 service invocations. This value is uniformly distributed.

To simulate complex services, we introduce a delay on the appli-cation server side . The application server defers the return message sent to the transactions after the service has been executed for two seconds. The delay on the client side when receiving a return mes-sage from the application server is also set to two seconds to simu-late user interaction. The object size of the entity beans is 16 MB. In other words: Invoking a service implies that the session bean will call one entity bean such that 16 MB data is read and written back. In case of a deadlock or of a cycle in the serialization graph, the youngest involved transaction is chosen as victim and has to compensate completely. Afterwards, to prevent running into the same failure situation repeatedly, a transaction defers the first ser-vice invocation by 0 to 20s (uniformly distributed) after changing from backward execution again to forward execution.

The configuration of the client hosts and the application server host has been chosen as follows: Processor: Dual Intel Xeon 3.2GHz with Hyperthreading RAM: 2GB Network: 1 Gigabit Fiber Operating System: Microsoft Windows 2003 Server Client JVM: J2SE 1.3.1, IBM Classic VM with JITC Application Server: IBM WebSphere Application Server 5.1.1
Our first experiment investigates the impact of the conflict prob-ability on the throughput of DSGT and S2PL, respectively. To vary the conflict probability, we have modified the number of services in the system. Figure 6 shows the results of the experiment including measurements for a conflict-free environment. Measurements for S2PL were impossible for 2000 services (high conflict probability) due to many messages which the Java RMI-based Infrastructure was not able to handle.

Since more services imply a lower conflict probability, one would expect that the throughput increases with the number of services. However, the throughput falls in the conflict-free environment dra-matically. The explanation for this is that the increasing number of services leads to an increasing number of entity beans. The man-agement of the entity beans bounds the resources of the WebSphere server and thus lowers the response times. To eliminate this effect from the results, Figure 7 shows the throughput of DSGT and S2PL relative to the throughput of the conflict-free environment.
Here, we see that the throughput of S2PL decreases dramatically Figure 7: Throughput Relative to a Conflict-Free Environment for going down to less than 7000 services, whereas DSGT with partial rollback remains on a high level also down to 5000 or 4000 services, although the decrease then is much higher compared to that of S2PL and will drop down to 0 for a high conflict probability. Thus, the experiment shows the superiority of DSGT for medium conflict probabilities.

To understand these results better, we have also examined the execution times for transactions in both cases, S2PL and DSGT, for 4.000 services as well as for 10.000 services. The results in Figure 8 show two aspects: 1. The peak of the experiments with 4.000 services is achieved 2. There is one peak for 4.000 services and S2PL for more than One might assume that the results might be improved  X  especially for S2PL  X  by rolling back a victim transaction not completely but only as far as required, for instance to resolve the cycle. How-ever, we know how much work a transaction has to redo in average (summarized in Table 1). Table 1: Percentage of Redo Operations in DSGT and S2PL
Certainly, this value must be doubled to achieve the influence on the overall throughput, because the services have to be com-pensated before they are invoked again. Thus, for medium conflict probability, this will not change much. It is only relevant for high conflict probabilities. But in this case S2PL is preferred anyway.
Moreover, we investigated the impact of the transaction length on the throughput. We have run experiments where we have cho-sen the transaction length out of the intervals [4;8], [6;10], and [8;12] (equally distributed). Figure 9 shows the results normal-ized by the average transaction length for the measurement point. Thus, we have considered that the absolute throughput values are not meaningful, because the longer the transactions are, the more time a single transaction needs even without conflicts. The nor-malized results show that the throughput of both protocols is more or less equal for short transactions consisting of 4 to 8 service in-vocations. However, increasing the average transaction length by choosing transaction lengths out of the interval of [6;10] or even [8;12] leads to a tremendous decrease in the throughput of both DSGT and S2PL. Nevertheless, DSGT performs much better than S2PL. For instance, in case of the interval [8;12] the throughput of DSGT is more than 100% higher than of S2PL.

The explanation is simple: Transactions being blocked because they cannot get a lock might itself block subsequent service invoca-tions of other transactions. The DSGT protocol, in contrast, allows the transactions in the same situation to optimistically continue the execution of subsequent service invocations.

Finally, we have compared the partial and the complete rollback case for both DSGT and S2PL. The results in Figure 10 show the impact on partial rollback for cascading aborts.

In case of complete rollbacks, DSGT is only working for very low conflict probabilities: For 6000 services, the throughput is quite low, but it is important to understand that the result marked with (2) appeared. After some time, the throughput falls down to zero making further experiments impossible. In case of 4000 ser-vices, the Java RMI problem appeared again (marked with (1)). Thus, this experiment proves that partial rollback is helpful when serialization graph testing is not only used for low but also for medium conflict probabilities.
Figure 9: Influence of Transaction Length on Throughput
Figure 10: S2PL vs. DSGT (Complete vs. Partial Rollback)
In principle, protocols developed for distributed and federated database systems are applicable to P2P systems, but all have (some even severe) drawbacks. Optimistic protocols execute transactions without any validation [8]. Therefore, they potentially come along with a large number of rollbacks when the duration of transactions and thus the number of conflicts increases. Distributed variants of optimistic protocols (e.g., [9]) however, stick to a global coordina-tor, which makes them of limited use for P2P environments.
Our approach fundamentally differs from known distributed seri-alization graph approaches as presented in [2, 16]. In the latter, the behaviour is distributed, but nevertheless a global graph is main-tained. In contrast, in DSGT transactions only maintain parts of the graph knowledge and nevertheless ensure isolation. Due to cy-cle checking, the complexity of DSGT is linear in the number of transactions in this graph. Compared to a locking protocol like S2PL, this is too expensive for traditional application scenarios. Therefore, serialization graph testing was used in the past only as a formal method to explain serializability theory. Interestingly, our experiments have shown that cycle checking is only then a problem if it is expensive compared to the execution cost / execution time of operations . This might be the case for short living transactions, but not in the context of long-running processes in distributed and especially P2P networks that we consider in our approach. In this paper, we presented the DSGT protocol (Decentralized Serialization Graph Testing), which is designed for decentralized transaction processing in peer-to-peer environments where no cen-tral components can be assumed. The protocol distributes the task of coordinating transactions to the set of transactions in the system. In cooperation with the peers they access for executing services, they ensure globally correct executions. Each transaction maintains relevant conflicts in a local serialization graph. Although these graphs usually do not contain full global knowledge, DSGT guar-antees serializable schedules. Cyclic dependencies are detected by propagating conflicts along the edges of the local serialization graph like distributed deadlock detection protocols do. These cy-cles are resolved using a partial rollback approach without losing too much work done by cascading aborts. The experimental eval-uation has shown that DSGT significantly outperforms S2PL for medium conflict probabilities and longer transactions composed of expensive services. In case of low conflict probabilities, however, the protocols do not show significant differences. For high conflict probabilities, S2PL is the better choice. Hence, besides the DSGT protocol and the concept of partial rollback for handling isolation failures, this paper has shown that serialization graph testing is well appropriate in service-oriented architectures following a peer-to-peer style of interaction.

In future work, we plan to examine how DSGT can trade fresh-ness of the serialization graph for the quantity of messages. The latter implies to collect changes of the graph and send them in one message instead of immediately propagating each single change. [1] P. A. Bernstein, V. Hadzilacos, and N. Goodman.
 [2] Y. Breitbart, H. Garcia-Molina, and A. Silberschatz. [3] D. Georgakopoulos, M. Hornick, and F. Manola.
 [4] J. Gray, P. Helland, P. O X  X eil, and D. Shasha. The Dangers [5] K. Haller, H. Schuldt, and C. T  X  urker. A Fully Decentralized [6] IBM. WebSphere Application Process Choreographer. [7] N. Krivokapic, A. Kemper, and E. Gudes. Deadlock [8] H. Kung and J. Robinson. On optimistic Methods for [9] E. Levy, H. Korth, and A. Silberschatz. An Optimistic [10] R. Obermarck. Distributed Deadlock Detection Algorithm. [11] M. T.  X  Ozsu and P. Valduriez. Principles of Distributed [12] M. Roesler and W. A. Burkhard. Resolution of Deadlocks in [13] H. Schuldt, G. Alonso, C. Beeri, and H.-J. Schek. Atomicity [14] C. T  X  urker, K. Haller, C. Schuler, and H.-J. Schek. How can [15] R. Vingralek, H. Hasse-Ye, Y. Breitbart, and H.-J. Schek. [16] G. Weikum and G. Vossen. Transactional Information
