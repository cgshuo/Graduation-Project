 Discovering of frequent patterns in large databases is an important data mining problem. The problem was introduced in [1] for a sales transaction database. Frequent Frequent patterns are commonly used for build ing association rules. For example, an association rule may state that 80% of customers who buy fish also buy white wine. This rule is derivable from the fact that fish occurs in 5% of sales transactions and set {fish, white wine} occurs in 4% of transactions. Patterns and association rules can be generalized by admitting negation. A sample rule with negation could state that 75% of customers who buy coke also buy chips and neither beer nor milk. Admitting negation usually results in abundance of mined patterns, which makes analysis of the discovered knowledge infeasible. It is thus preferable to discover and store a possibly small fraction of patterns from which one can derive all other significant patterns when required. This problem was addressed in [3-4], where a generalized disjunction-free literal sets representation (GDFLR) was offered as a lossless representation of all frequent patterns, both with and without negation. GDFLR is by orders of magnitude lossless representation of frequent patterns with negation was proposed. In this paper, we offer new algorithm GDFLR-SO-Apriori for discovering the GDFLR represent tation and evaluate it against the GDFLR-Apriori algorithm proposed in [3]. positive patterns and patterns with negation, as well as methods of inferring frequencies (or supports) of patterns from frequencies of other patterns. Section 3 recalls the GDFLR representation and the GDFLR-Apriori algorithm. Our main theoretical contribution is presented in Section 4, where we first propose an ordering for groups of patterns with negation, then examine the properties of patterns following this ordering, and finally use these properties to construct the GDFLR-SO-Apriori algorithm. The performance of the GDFLR-SO-Apriori and GDFLR-Apriori algorithms is evaluated in Section 5. Section 6 concludes the obtained results. 2.1 Frequent Patterns use throughout the paper. Each row in this database reports items that were purchased by a customer during a single visit to a supermarket. 2.2 Positive Pattern, Pattern with Negation, Variations of a Pattern interested in identifying frequent cases when purchase of some items excludes { ab }, { a ( X  b )}, {( X  a ) b }, {( X  a )( X  b )}. 2.3 Calculating Supports of Patterns with Negation One can note that for a pattern X and an item x , the number of transactions in which X occurs is the sum of the number of transactions in which X occurs with x and the number of transactions in which X occurs without x . Hence sup ( X  X  {( X  x )}) = sup ( X )  X  sup ( X  X  { x }) [6]. Multiple usage of this property enables calculation of the supports of patterns with any number of negated items from the supports of positive patterns [7]: 
Nevertheless, the knowledge of the supports of only frequent positive patterns may be insufficient to derive the supports of all frequent patterns with negation [6-7]. 2.4 Reasoning About Positive Patterns with Generalized Disjunctive Rules { x m +1 , ..., x n } = violating rule r will be called its error and will be denoted by err ( r ). It was shown in 
The following equation follows immediately from Eq. 1 and Eq. 2: 
Hence, the error of a generalized disjunctive rule based on a positive pattern X equals the support of X  X  X  particular (exactly one) variation with negation. are based on a superset of { x 1 , ..., x n }, are also implications. 
The knowledge of such implications can be used for calculating the supports of patterns on which they are based. For example, ac  X  b  X  f implies that the number of occurs with b plus the number of transactions in which { ac } occurs with f minus the number of transactions in which { ac } occurs both with b and f . Hence, sup ({ abcf }) = sup ({ abc }) + sup ({ acf })  X  sup ({ ac }), which means that the support of pattern { abcf } from the supports of its proper subsets [5]. Each such pattern is called a generalized disjunctive set . Otherwise, it is called a generalized disjunction-free set . 3.1 Generalized Disjunction-F ree Literal Representation GDFLR A generalized disjunction-free literal representation (GDFLR) was introduced in [3] as a concise representation of all frequent patterns, both with and without negation. 
GDFLR consists of the following components:  X  the main component ( Main ) containing each positive pattern (stored with its support) that has at least one frequent variation and is neither generalized disjunctive nor has support equal 0;  X  the infrequent border ( IBd  X  ) containing each positive pattern all variations of which are infrequent and all proper subsets of which belong to Main ;  X  the generalized disjunctive border ( DBd  X  ) containing each positive pattern (stored with its support and/or implication) that is either generalized disjunctive or has support equal 0, has at least one frequent variation, and all its proper subsets belong to Main . 
GDFLR is a lossless representation of all frequent patterns. A formal presentation of this model and its properties can be found in [3]. In particular, it has been proved there that each element in GDFLR has all its proper subsets in the main component. Another important property of GDFLR is that its elements are guaranteed to contain no more than  X  log 2 (| D |  X  minSup )  X  + 1 items [3]. 3.2 Sample Usage of the GDFLR Representation illustrate how to use this representation to evaluate unknown patterns. Let us consider evaluated pattern, has subset { cef } in the infrequent border. This means that all infrequent. Now, we will consider pattern { bef ( X  h )}. The positive variation { befh } of { bef ( X  h )} does not have any subset in the infrequent border, so { bef ( X  h )} has a chance { be } in the generalized disjunctive border, the implication of which is e  X  b . Hence, ef  X  b is an implication for { bef }. Thus, sup ( bef ) = sup ( ef ) = 2 (please, see the main Summarizing, sup ({ bef ( X  h )}) = 2  X  0 = 2, and thus { bef ( X  h )} is a frequent pattern. 3.3 Discovering the GDFL R Representation with the GDFLR-Apriori Algorithm In this section, we recall the GDFLR-Apriori algorithm [3], which discovers GDFLR. Creation of candidate elements and calculation of their supports in GDFLR-Apriori frequent positive patterns. GDFLR-Apriori , however, differs from such algorithms by components, respectively. In the algorithm, we apply the following notation: 
After initializing the GDFLR components, the GDFLR-Apriori algorithm checks whether the number of transactions in database D is greater than minSup . If so, then  X  performed level-wise for all k item candidates, for k  X  1:  X 
Supports of all candidates in X k are determined during a pass over the database.  X  based on X are calculated from the supports of X  X  X  subsets in accordance with Eq. 2. Since { X . sup }  X  Errs equals the set of the supports of all variations of X (by 
Eq. 3), the condition max ({ X . sup }  X  Errs )  X  minSup checks if all variations of X are infrequent. If so, X is found an element of the infrequent border IBd  X  . Otherwise, at element of the border DBd  X  . Otherwise, it is found an element of Main .  X 
After all candidates in X k were classified to respective components of GDFLR, element in GDFLR must belong to the Main component, the creation of k +1 item candidates is restricted to merging of pairs of k item patterns in Main . In addition, not valid GDFLR elements, and thus are discarded from X k +1 . The algorithm ends when there are no more candidates to evaluate. 
Please note that the most critical operation in the GDFLR-Apriori algorithm is the calculation of errors of a given candidate pattern X . As follows from Eq. 2, the consequent, requires the knowledge of the supports of X and its 2 n  X  1 proper subsets. Taking into account that one can built  X   X  n items in their consequents, the calculation of the errors of all rules based on X that may have 1 to | X | items in their consequents requires  X  n =1..| X |  X   X  proper subsets of X . Our goal is to speed up the discovery of GDFLR by efficient re-use of the information of the supports of subsets when calculating the errors of rules built from a candidate pattern. Since, the calculation of the errors of rules built from negation, we will focus only on the latter task. First we will propose an ordering of X  X  X  variations. Based on this ordering, we will propose a new method of calculating the support of each variation from the supports of two patterns. Eventually, we will offer new GDFLR-SO-Apriori algorithm, which will apply this method for fast discovery of GDFLR. 4.1 Enumerating, Clustering and Calculating Supports of Pattern Variations In this paper, we define the following ordering of the variations of pattern X : that differs from X on all and only bit positions with value 1 in the binary of X such that i is the leftmost bit position with value 1 in the binary representation of their ordering numbers. Please note that X , which is 0 th variation of X , does not belong does not contain any bit position with value 1. { V V (111) 2 ( X )}. Note that the ordering numbers of variations in cluster C i ( X ), i | X |-1}, can be expressed as 2 i + j , where j  X  {0, ..., 2 i  X  1} (see Table 2). C ( X ) (or relative ordering number ). variations in the clusters C i ( X ), where i  X  {0, ..., | X |  X  1}: differ from X on positions greater than i . These observations imply Theorem 1. Then: sup ( V 2 i + j ( X )) = sup ( V j ( X \ { X [ i ]}))  X  sup ( V j ( X )). Corollary 2. Let X be a non-empty pattern and i  X  {0, ..., | X |  X  1}. The support of each variation in C i ( X ) is determinable from the support of a variation of X \ { X [ i ]} l &lt; i . 
Table 3 illustrates a systematic way of calculating the supports of consecutive item subsets of X suffices to calculate the supports of all variations of X in this way. 4.2 Algorithm GDFLR-SO-Apriori In this section, we offer new GDFLR-SO-Apriori algorithm for discovering GDFLR. It differs from GDFLR-Apriori only in that it determines and uses the The differences between GDFLR-SO-Apriori and GDFLR-Apriori are highlighted in the code below. 
In particular, the Errors-of-rules function was replaced by the Calculate-supports-of-variations procedure. Calculate-supports-of-variations determines the supports of variations of candidate pattern X in two loops. The external loop iterates over clusters The supports of variations are determined in accordance with Theorem 1. As follows from the code, the Calculate-supports-of-variations procedure requires only | X |  X  rules function in the GDFLR-Apriori algorithm. The GDFLR-SO-Apriori and GDFLR-Apriori algorithms were implemented in C++. The experiments were carried out on the benchmark mushroom and connect-4 data sets. mushroom contains 8124 transactions; each of which consists of 23 items; the total number of distinct items in this data set is 119. connect-4 contains 67557 transactions of length 43 items; the total number of distinct items is 129. The runtime results for both algorithms are presented graphically in Fig. 2 in logarithmic scale. 
We observe that GDFLR-SO-Apriori performs faster than GDFLR-Apriori on these mushroom , GDFLR-SO-Apriori performs faster than GDFLR-Apriori by two orders of magnitude for minSup = 10%, while in the case of connect-4 , GDFLR-SO-Apriori performs faster than GDFLR-Apriori by an order of magnitude for minSup = 40%. 
Fig. 3 shows the duration of particular phases of the algorithms in logarithmic scale. The common phases in both algorithms are: calculating supports of positive patterns (PPS), merging (M) and pruning (P). In addition, the GDFLR-SO-Apriori algorithm performs the phase of calculating supports of variations (VS), while GDFLR-Apriori carries out the analogous phase that calculates errors of rules (E). As and less than 60% for connect-4 , respectively), phase (E) is most time consuming; phase (P) is longer than phase (VS), and (VS) is longer than phase (M); phase (PPS) is least time consuming for both algorithms. Concluding, for low threshold values, the performance of GDFLR-Apriori depends mainly on the performance of phase (E), which is longer than phase (P), while the performance of GDFLR-SO-Apriori depends mainly on the performance of phase (P), which is longer than analogous to (E) phase (VS). For high threshold values, the runtime of phase (PPS) strongly dominates the runtimes of all other phases. Hence, for high threshold values, GDFLR-SO-Apriori is faster than GDFLR-Apriori in lower degree than in the case of low threshold values. We have offered new GDFLR-SO-Apriori algorithm for discovering the GDFLR representation of all frequent patterns. The experiments prove that GDFLR-SO-Apriori is faster than the GDFLR-Apriori algorithm by up to two orders of magnitude for low support threshold values. The speed-up was obtained by replacing time-with efficient operation of calculating the supports of variations of candidate patterns. 
