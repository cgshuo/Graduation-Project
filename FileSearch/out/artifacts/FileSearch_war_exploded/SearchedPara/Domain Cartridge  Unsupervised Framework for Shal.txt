 In this work we propose an unsupervised framework to construct a shallow domain ontology from corpus. It is essential for Infor-mation Retrieval systems, Question-Answering systems, Dialogue etc. to identify important concepts in the domain and the relation-ship between them. We identify important domain terms of which multi-words form an important component. We show that the incor-poration of multi-words improves parser performance, resulting in better parser output, which improves the performance of an existing Question-Answering system by upto 7% . On manually annotated smartphone dataset, the proposed system identifies 40 . 87% of the domain terms, compared to 22% recall obtained using WordNet, 43 . 77% by Yago and 53 . 74% by BabelNet respectively. However, it does not use any manually annotated resource like the compared systems. Thereafter, we propose a framework to construct a shal-low ontology from the discovered domain terms by identifying four domain relations namely, Synonyms ( X  X imilar-to X ), Type-Of ( X  X s-a X ), Action-On ( X  X ethods X ) and Feature-Of ( X  X ttributes X ), where we achieve significant performance improvement over WordNet, Ba-belNet and Yago without using any mode of supervision or manual annotation.
 H.0 [ Information Systems ]: General Knowledge Extraction, Ontologies Ontology; Unsupervised Framework; Relation Extraction; Distri-butional Similarity
An ontology can be viewed as a data structure that specifies terms, their properties and relations among them for a richer knowl-edge representation [47]. Such a knowledge representation makes an information retrieval system aware of a domain, so that it can capture domain concepts and associations well, to perform tasks like answering queries, conducting dialogue more efficiently. We show that a domain-aware Question-Answering system can have a 7% boost in recall by just knowing the multi-word domain terms (like  X  X amsung Galaxy S IV X ,  X  X ony Experia X ).

In this work, we present a framework to automatically construct a shallow domain ontology from a set of knowledge articles and pdf manuals in a given domain. We view this domain ontology as a graph, where the nodes are domain concepts and the edges depict relations among these concepts. Figure 1 shows a snapshot of a smartphone domain ontology, with the important domain concepts as nodes and a set of relations among these concepts as directed edges. The relations include the most commonly used Type-Of or hyponymy relation (denoted as the edge label T ), Feature-Of (de-picted as the label F , e.g.  X  X perating-system X  is a feature of  X  X e-vice X ), Action-On (depicted as the label A , e.g.  X  X nstall X  is an action on  X  X perating-system X ) and Synonym (depicted as the label S , e.g.  X  X evice X  is synonymous to  X  X andset X ). Although, there may be more fine-grained relations possible in a given domain (e.g. temporal, spatial), we believe that these four relations are common across do-mains and can be used to represent domain knowledge efficiently, as in an object oriented programming methodology (e.g. JAVA) where  X  X bjects X  are defined to have a set of  X  X ttributes X  (features F ),  X  X ethods X  (actions A ) and  X  X uperclasses X  (type T ). Figure 1: An example ontology from the smartphone domain.
At first we are interested in discovering the important concepts in a given domain, of which multi-word terms form an important component (a task referred to as Domain Term Discovery (DTD) in this work). Incorporation of such domain terms can improve a parser X  X  performance. The following example depicts the utility of the DTD process for a parser. Consider the string  X  X ransfer files via USB cable". First, the DTD process allows the tokenizer to recog-nize  X  X SB-cable X  as a single token. Secondly, the domain knowl-edge that  X  X iles X  is typically a noun in the smartphone domain and not a verb, leads to a correct and complete parse of the string. Since these steps are the basic building blocks of a Question-Answering system [10, 13], we show that its performance can be improved by improving the parser performance.

Thereafter, we want to determine the relations between the dis-covered domain terms (referred to as Domain Relation Discovery (DRD) in this work). We show that once the parser becomes aware of the domain concepts in the first phase, it generates refined out-put, in terms of better parser relations, which helps in the DRD process. The discovered relations can be used for query expan-sion (e.g. by considering Synonyms along with the original query), interactive dialogue systems (e.g. for the user query  X  X he battery of my device depletes very fast", a DRD inference that  X  X attery X  is a Feature-Of  X  X hone X  as well as a  X  X ablet X  device -enables the system to clarify about the type of device). Similarly, Type-Of re-lations can help in query re-formulation. E.g. for the user query  X  X creen freezes E5150", the DRD inference that  X  X 5150 X  is a type-of  X  X rror X  can result in the query re-formulation  X  X creen freezes error E5150". Query re-formulation improves the performance of Question-Answering system by increasing its recall.

Overall we focus on discovering all the domain concepts and relations efficiently in an automated way, and construct a shallow domain ontology. Our work differs in the ontology construction process from related works [49, 16] in the usage of an unsuper-vised framework for ontology generation, domain term and relation discovery, where we do not make use of any manually created re-source such as WordNet [32], Wikipedia [50], ConceptNet [18] or other readily available ontologies [49].

An issue with such manually created resources with annotations is that they mostly contain generic concepts and miss out on many domain specific concepts and associated relations. In addition to the labor cost involved in constructing such resources, they are not updated frequently and as a result lack the newly coined concepts in the domain (e.g.  X  X TC Desire X ,  X  X okia Lumia 1020 X ). On the other hand our system extracts domain concepts and relations from tuto-rials and manuals in a given domain, which are readily available, that creates a richer knowledge representation. As the approach is unsupervised, requiring no manual annotation, human labor in creating and maintaining the ontology is markedly reduced. We compare our approach to other state-of-the-art systems like BabelNet [36] and Yago [48]. These systems harvest knowledge from manually created resources like WordNet and Wikipedia. Yago and BabelNet perform better than our system in domain-term dis-covery with a recall of 43 . 77% and 53 . 74% respectively. Although our system obtains 40 . 87% recall in discovering domain terms, it does not make use of any world knowledge or human annotated re-source. On the other hand, we perform much better than BabelNet, WordNet and Yago in discovering domain relations. For instance, WordNet, BabelNet and Yago do not give Feature-Of or Action-On relations. Our system significantly outperforms them on relations available to all the systems.
In this section we give a high level overview of the proposed Do-main Cartridge framework (refer to Figure 2). The input to the sys-tem is a corpus consisting of knowledge articles, manuals, tutorials etc. in a variety of formats in a given domain. Suitable adaptors are then used to bring the information in plain text form such that the documents can be parsed by a slot grammar parser (ESG) [30].
The ESG parser is used due to its speed. It is 50  X  100 times faster than the Charniak parser [7]. Simple transformations over the ESG parser output and encoding alternate variants of common expressions provide Shallow Semantic Relationship (SSR) (referred to as Prismatic in Figure 2) annotations. A detailed discussion on the types and constituents of these relations is presented in [10].
The first phase consists of discovering important domain terms, referred to as Domain Term Discovery (DTD) in this work (refer to Section 3). In this phase, domain multi-words are discovered using noun phrase chunking on the parser output, which is used to bootstrap the parser. This results in the parser generating better SSR as it becomes domain-aware.

The Lucene index called the Primary Index contains all SSR and associated concepts in the corpus. The Secondary Lucene Index created from the primary index bears only unique SSR. The indices provide easy access to all SSR, concepts and documents in corpus to incrementally build the Domain Cartridge, as well as help in scalability. During domain migration, only primary index needs to be changed as other indices are derived from it. Section 4 discusses the index construction process in details.
 To discover more fine-grained multi-word concepts and relations, HITS algorithm [23] is used over the now-refined parser output (re-fer to Section 4.4), after the noun phrase chunking process. The newly discovered domain terms by HITS are incorporated in the parser lexicon, further enriching it. The parser is run again to gener-ate better relations, and previous steps are iterated till convergence. The HITS algorithm takes its input from the secondary index.
In order to identify similar domain concepts, a dimensionality re-duction technique called Random Indexing [45] is used leveraging relational distributional similarity of the candidate concepts (refer to Section 4.3). The Random Index is created out of the secondary index containing similar neighbors for a concept.

The output of HITS and Random Index is used to discover re-lations between the domain terms (referred to as Domain Relation Discovery or DRD in this work; refer to Section 5). A classifier is built for each of the 4 relation types, which takes as input a word pair and uses SSR features to predict the relation type existing be-tween them.
The first step in gathering insight about a new domain is to dis-cover a list of important domain concepts. For example, in the smartphone domain, terms like  X  X amsung-Galaxy-Tab X ,  X  X all-log X ,  X  X all-forwarding X ,  X 4g-connection X  can be considered important con-cepts. Similarly in a finance domain, terms like  X  X ompany X ,  X  X rans-action X ,  X  X ales-Tax X  etc. can be considered as domain terms.
An important characteristic feature of domain terms are the multi-word tokens. In one of the experiments, with a manually designed list of financial domain terms, we observed that as many as 50% of the important tokens were multi-words out of 7000 domain terms.
We make use of the parse tree output of the slot grammar parser (ESG) [30] to discover important domain terms. Figure 3 shows an example parse tree with various parser relations connecting differ-ent concepts.

First, all the knowledge sources such as knowledge articles (HTML), manuals (PDF) etc. are appropriately pre-processed to obtain simple text documents. The pre-processing stage itself in-volves a lot of issues related to formatting, extracting information from pdf etc.

The documents are parsed using the slot grammar parser. Noun phrases are extracted from the parses and processed to discover do-main terms. Figure 3 shows the parse tree corresponding to the sen-tence  X  X urn the Wi-Fi radio on or off" . We consider all the terms which have part-of-speech (POS) tags as  X  X ouns X . These terms now become candidates for domain terms. Furthermore, we also con-sider the sub-tree of which this noun term is the root and make them candidates for domain terms. In the example shown in Fig-ure 3, such a sub-tree is  X  X he Wi-Fi radio" .
 Figure 3: Parse tree for the title  X  X urn the wi-fi radio on or off" .
This approach results in long candidates like  X  X ssues related to receiving calls" . Although such patterns are valid noun-phrases, we want to recognize only atomic units in our list of domain terms. In this example, we would like to keep  X  X ssues" and  X  X eceiving calls" as separate tokens. Hence, we perform a subsequent post-processing where the candidates are split into atomic domain terms based on the presence of verbs and stop words . Finally, only those domain term candidates are retained for which the count is greater than a threshold. Table 1 shows a snapshot of the domain terms discovered using the noun phrase chunking approach.

In our analysis, this approach results in a highly precise set of domain term candidates. We generated approximately 2900 and 3400 domain terms in the financial domain and smartphone domain from 9k and 16k titles, respectively. samsung blackberry device software novatel software-version application htc-evo wi-fi memory-card bluetooth motorola kyocera browser voicemail microsoft-exchange lg-optimus elite samsung-m400 samsung-galaxy-victory software-updates samsung-array text-messaging wallpaper synchronization face-book iphone htc aircard touchscreen gps blackberry-bold ipad motorola-xprt htc-evo-3d sanyo-vero Table 1: Snapshot of multi-word domain terms discovered us-ing noun phrase chunking.
The ESG parser maintains a lexicon of multi-word entries which are used by the parser in the subsequent phases as a single unit re-sulting in a better parser output. For example, if the ESG parser has the prior knowledge that  X  X ouch screen X  is a multi-word from the do-main term lexicon, then it will parse  X  X ouch screen of the mobile" with  X  X ouch screen X  as a noun . Without this domain knowledge,  X  X ouch X  will be treated as a verb and  X  X creen X  as a noun , result-ing in a different parse; and in many cases a noisy or incomplete parse. The domain term discovery process adds domain terms to the parser lexicon. Subsequently, the parser uses the multi-words as a single token (e.g.  X  X print navigation X  will be considered as a noun concept, and not processed separately as a verb and a noun) and the unigrams are favored as nouns (e.g.  X  X iles X  will be pro-cessed as a noun during ambiguity). The DTD process results in the parser generating better quality output as the number of incom-plete or noisy parses is reduced. Since the lexicon is core to the functionality of the parser, we would like to keep it as clean as possible (high precision). Hence we use the noun phrase chunking approach only on the document titles for the following three rea-sons: 1) The extraction of titles is invariably easy and precise. 2) The titles do not suffer from arbitrary formatting, references to pic-tures etc. present in the body of the text, and therefore the parsing of titles is almost always correct. 3) In our end-application of a QA system, the titles represent the information need that the body of the text is providing.

However, this leads to low recall for domain term discovery and is only used to bootstrap the parser. In order to further enrich the lexicon with more fine-grained domain terms, we use another algo-rithm called HITS on the refined parser output. This is explained in details in Section 4.4. The newly discovered domain terms by HITS are again incorporated in the parser lexicon, further enrich-ing it, and previous steps are iterated till convergence.
Once the domain terms are identified and refined parser relations generated, the relationship between the terms need to be discovered to construct the ontology. Since we want to discover domain rela-tions across all possible pairs of domain concepts which would be computationally costly and involve a lot of redundant computation, we describe an efficient framework that indexes all parser relations and creates a random projection for every domain concept in a rel-atively lower dimensional space. This facilitates fast computation of similarity between candidate domain terms as well as different relation discovery.
In this section, we present the index creation module of our framework that helps in dimensionality reduction as well as identi-fying dominant domain terms and relations that are used as features in the remaining part of the system.

After the discovery of domain terms, as explained in Section 3, they are provided as an input lexicon to the slot grammar parser. Multi-word tokens are now identified as single tokens by the parser resulting in better parser output. In the example in Figure 3,  X  X i-Fi radio X  will be parsed as a single token.

Shallow semantic relationship (SSR) [10] annotation is done over the ESG parser output which consists of rules to generate projec-tions for all the frames in the corpus and generate normalized parser relations. SSR detects alternative syntactic contexts expressing the same semantic relationship between two or more entities. For ex-ample, the sentences  X  X amsung has a battery" and  X  X amsung X  X  bat-tery died" will both generate the same relation  X  X nMod:samsung_ battery X , where  X  X nMod" represents the type of the SSR relation (noun modifier), and  X  X amsung" and  X  X attery" represent the associ-ated concepts.

As we process the domain corpus, SSR annotations over ESG parser output are discovered across various domain terms and other terms. We index these SSR to use them later for finding distri-butional similarity, and querying for other statistics such as  X  X ow many documents contain a relationship between the term  X  X nstall X  and other terms". For each document D in the domain corpus, we index the SSR R d = { r 1 , r 2 , ..., r N } in the primary index using Lucene. Each SSR r i has a type (e.g. verb-object, noun-adjective etc.) and as-sociated concepts. The Lucene analyzer was changed to produce a tokenstream that consists of regular tokens, their Part-of-Speech tags and the SSR shared between the tokens as opposed to the de-fault white space tokenizer that produces a tokenstream consisting of words or regular tokens. For example, a document with text con-tent as  X  X se this cable to connect iPhone to your computer and sync changes" , the following tokenstream is produced by the analyzer:  X  use cpt:verb:use rel:dm_obj:use_cable this cable cpt:noun: cable to connect cpt:verb:connect rel:dm_comp:connect_computer rel:dm _obj:connect_iphone iphone cpt:noun:iphone to your computer cpt: noun:computer to sync cpt:verb:sync and charge cpt:verb:charge... "
In the example above, the SSR relations are marked with  X  X el:" prefix and the concepts associated with these relations are separated by an underscore. Accordingly, the token  X  X el:dm_obj:use_cable" means that this is a relation token with  X  X m_obj" type (verb object pair) and  X  X se" and  X  X able" are the associated concepts. The token-stream maintains the order of the concepts and SSR in which they appear in the documents. Such tokenization and indexing allows us to retrieve information such as tokens (or SSR) in the neighborhood of a querying token (or SSR), all the corpus documents containing a specific SSR, document frequencies of SSR etc.
After the primary index has been created, we traverse over its indexed tokens to create the secondary index. Note that in this index, we store only the unique SSR (i.e tokens starting with  X  X el: X  prefix). This index allows us to retrieve unique SSR based on their types or based on one of the constituents. For example, the query  X  X et all the  X  X m_comp X  relations, where  X  X onnect X  is one of the constituents" can be effectively answered by this index.
Each SSR in the secondary index is of the form rel : word _ word 3 , where word 1 and word 3 are domain terms ( nouns ) and word 2 belongs to verbs or prepositions and rel  X  X  svo, dm _  X  , nnMod , npo } . The SSR in the secondary index are of the following form: 1. svo depicts a subject-verb-object tuple. For example: rel:svo:phone _offer_feature, rel:svo:phone_show_message etc. 2. nnMod depicts noun-noun modifications. For example: rel:nnMod:iPhone_battery, rel:nnMod:screen_icon etc. 3. dm depicts actions on entities. For example: rel:dm_obj:use_ phone, rel:dm_comp:plug_iPhone etc. 4. npo depicts terms connected by prepositions. For example: sub-scription_to_service, battery_on_phone etc.
 We traverse the indexed SSR in this secondary index for discover-ing domain terms and building the distributional similarity matrix as explained in the next section.
In this section, we explain our random indexing framework for computing distributional similarity [31] between two terms, which suggests that terms sharing similar contexts are likely to be simi-lar. Random Indexing (RI) [45] is a word co-occurrence based ap-proach to statistical semantics. RI uses statistical approximations of the full word co-occurrence data to achieve dimensionality re-duction, resulting in much quicker running time and fewer required dimensions.

In most co-occurrence models, a word-by-word matrix is con-structed, where the values denote how many times the column X  X  word occurred in the context of the row X  X  word. RI instead rep-resents co-occurrence by assigning each word a high dimensional index vector and keeping a running sum of all the index vectors for words that co-occur. The index vectors are very sparse reducing chances of a sparse match.
 Random Indexing can also be seen as an alternative to Latent Semantic Analysis [9]. Random Indexing is more scalable and al-lows for the incremental learning of context information. Although LSA is efficient, it suffers from scalability issues. It starts by gen-erating a termXdocument matrix which grows with the corpus. For finding the final LSA model, Singular Value Decomposition (SVD) is commonly used for factorization of the term-document matrix, which is computationally costly. Also, the LSA model can-not be implemented easily and efficiently in an incremental or out-of memory fashion.

To find the most likely candidate terms for a given term requires computing similarity between all possible pairs of words. The quicker running time and reduced dimensionality features of the random indexing approach allow us to do this efficiently.
However, as opposed to most of the previous works that con-sider raw neighborhood of a term as context (say, preceding and following N terms) for random indexing [14, 39], we use only those neighboring terms to define the context for a target term that share a syntactic dependency (given by the slot grammar parser) with the target term. These syntactic dependencies are represented in Figure 3 by connecting edges between nodes. We traverse over the indexed SSR in the secondary index and for each SSR, we add the index vectors of a constituent term to all the other constituent terms.

In the distributional similarity computation, we consider all SSR to be important. However, some SSR (like  X  X nMod:samsung_charger, dm_obj:charge_samsung") are more important to certain domain terms (like  X  X amsung X ) than others (like  X  X nMod:samsung_color, dm_obj:use_samsung"). In order to discover the dominant domain SSR as well as additional domain terms we use another algorithm, as explained next.
In order to discover the dominant domain SSR and terms from corpus, we use a graph based algorithm on the secondary index. The earlier DTD process (refer to Section 3) used noun phrase chunking only on document titles, in order to keep the lexicon as clean as possible to bootstrap the parser.

Any SSR can be visualized as a hub generating features to create the domain terms. Any domain term can be visualized as an au-thority influenced by incoming features from the hubs as depicted in Figure 4. A good hub or domain SSR is the one generating a lot of important domain terms. A good authority or domain term is the one being influenced by a lot of domain SSR. The link strength between the hub and authority is taken as the number of SSR in the Primary Index in which both of them participate. We apply HITS algorithm [23] on the hub-authority graph to discover domi-nant SSR and domain terms, and add them to the HITS index.
In this algorithm the authority and hub scores are defined in terms of each other recursively. An authority score is computed as the sum of the hub scores of each node that points to it. A hub value is the sum of the authority scores of each node that point to it. This is done iteratively for all nodes until convergence. In our case, the scores are weighed by the link strength connecting 2 nodes. Table 2 shows a snapshot of the domain words discovered by HITS, that are not detected earlier by the domain term discovery approach using noun phrase chunking on titles. The dominant SSR are used in the latter stages for relation discovery.

The newly discovered domain terms by HITS are incorporated in the parser lexicon, further enriching it, which makes the parser generate a refined output. The parser is run again and previous steps are iterated till no additional domain terms are discovered with high authority score.
 Table 2: Snapshot of multi-word domain terms discovered by HITS (not found by noun phrase chunking on titles).
The previous sections discuss the approach for domain term dis-covery from corpus and creation of the indices namely, Primary, Secondary, Random and HITS . In this section, we outline the method for identifying relations between the discovered domain concepts using the indices.

Random index is used to get a set of similar candidates for a word based on similar SSR distribution in the corpus. The HITS index consists of dominant domain terms and SSR discovered from the secondary index. We categorize the SSR discovered by HITS into the following 2 types: 1. 1 -hop neighbor SSR of a word denotes the SSR that the target word participates in. For example :  X  X hone -{ rel:svo:instruction_ phone_press, rel:dm_arg:keep_phone, rel:dm_subj:screen_phone rel:npo:port_on_phone }" 2. Mutual SSR of a word pair denotes the SSR in which the word pair participates together. For example :  X  X phone &amp; mobile -{ rel:nnMod:iphone_mobile-data, rel:nnMod:iphone_mobile-hotspot, rel:nnMod:iphone_mobile-charger }"
We define two words to be similar if they appear in a similar context. Here, we follow the notion of relational distributional similarity [31]. Only those word pairs whose part-of-speech tags are the same are retained ( X  X oun-noun X  or  X  X erb-verb X ). Word pairs, whose members participate in any SSR together, are filtered out. As we will see later, such mutual SSR shared by a word pair are indicative of Action-On , Type-Of and Feature-Of relations.
Let w i and w j be a candidate word pair extracted from the ran-dom index. Feature vector for w i is defined as: F w i = { rel w i } , where rel l i is any 1-hop neighbor SSR of w i in the HITS index, connecting w i and w k i . The relational distributional simi-larity between 2 words is given by: where, f w i ,p is the p th element of F w i and I is an indicator func-tion.

The numerator of the above equation counts the number of times any word w k i appears in both the feature vectors F w i and F SSR rel l i . The denominator counts the number of times the word w i appears in the feature vector of any other word with the SSR rel l i . For example, consider the feature vector of the words  X  X e-vice X  and  X  X andset X  and the feature  X  X nMod:charger X  that appears in both the feature vectors. Now, if  X  X harger X  appears only in the context of  X  X evice X  and  X  X andset X  with the SSR  X  X nMod X  it will con-tribute 1 to the similarity score. But if it appears a large number of times with other words, the contribution will be less indicating that it is a frequently occurring word in the corpus (e.g. prepositions or frequently occurring verbs ). Word pairs with similarity scores greater than a threshold are added to the Synonym list.
This process results in high recall but low precision, as words like  X  X older X  and  X  X ab X  have a high relational distributional similar-ity due to overlapping context words like  X  open, close, minimize, shortcut, multiple " etc. that can act on both of them. To alleviate this, we use another parser feature to increase the precision. The ESG parser tags a word with a set of attributes like noun, animated, physical object, device etc. . We constrain a word pair to have over-lapping ESG parser attributes in order to be deemed similar, which increases the precision of the classifier. For example:  X  Folder: noun cn sg physobj artf capped creation Photo: noun cn sg physobj artf capped creation Tab: noun cn sg physobj abst artf inst capped doc comm "
In the above example, the relational distributional similarity is high for all the word pairs. However, the parser feature distin-guishes between  X  X older X  and  X  X ab X , but cannot distinguish between  X  X older X  and  X  X hoto X .
Action-On represents any activity or  X  X ethod X  on the domain term. For example,  X  X harge X  can be an activity on  X  X attery X  and  X  X Phone X ,  X  X isplay X  can be an activity on  X  X enu X  and  X  X con X  etc. By definition, an Action-On relation pair consists of a  X  X erb X  that acts on a  X  X oun X . The SSR dm and svo help in Action-On identification.
The dm SSR can be classified as dm_subj, dm_obj, dm_prep, dm_comp and dm_arg which depict scenarios where the noun is the subject or object of the verb, the verb is connected to the argument with a preposition etc.

The svo SSR represent subject-verb-object tuples.
E.g.  X  rel:svo:tap_ add _ account , rel:svo:phone_ access _ internet , rel:svo:mobile_ sync _ phone , rel:svo:account_ use _ phone etc. " The verb-object (vo) SSR is extracted from the  X  X vo X  SSR which repre-sents action-on activities.

HITS index is traversed to extract all the dm and vo SSR. Each word pair in the index is ranked according to the number of such mutual SSR (dm and svo) directly shared by them. Those with a count greater than a threshold are added to the Action-On list.
Type-Of relations depict Is-A hierarchy i.e. a parent-child rela-tion. For example:  X  X amsung is a Type-Of mobile, Internet Ex-plorer is a Type-Of browser, Angry Birds is a Type-Of application etc.". In order to discover the Type-Of clues, the svo SSR in the HITS index are grouped by the verbs, and npo SSR are grouped by the prepositions.

The svo SSR having the verb include and npo relations having prepositions like, such-as and as are found to be most informative, and are used to discover Type-Of relations from the HITS index. E.g.  X  rel:svo: devices _include_ HTC , rel:npo: applications _ such-as_ WhatsApp , rel:npo: device _like_ computer , rel:npo: features _like_ call rel:npo: contact _such-as_ address , rel:svo: location _include_ address etc. ".

Type-Of candidates are also discovered from the dominant do-main terms from the HITS index, where the words are connected by or and especially. These keywords are taken from the Hearst [19] patterns. E.g. service_or_process , prev_or_next , messages_especially_sms_and_ mms etc.
Feature-Of relations depict components or functionalities of a domain term. For example:  X  X creen is a Feature-Of mobile",  X  X i-fi is a Feature-Of network",  X  X ife is a Feature-Of battery" etc. In order to discover Feature-Of relations we use 2 primary SSR. 1. nnMod SSR that depict noun-noun modifications. For example:  X  rel:nnMod: network _ life , rel:nnMod: account _ settings , rel:nnMod: iPhone _ battery etc." 2. svo SSR (Section 5.2) that depict subject-verb-object tuples. The subject-object (so) word pairs are extracted from  X  X vo X  SSR as Feature-Of candidates, excluding the feature include used for Type-Of discovery. E.g.  X  rel:svo: motorola-photon-4g _run_ device-software , rel:svo: router _decrease_ signal-strength , rel:svo: find-a-store _open_ locator etc. "
We collected 5000 articles, tutorials and manuals from the smart-phone domain. We consider WordNet [32] as the first baseline. We also compare our system to other existing semantic knowledge bases like BabelNet [36] and Yago [48]. Both of them harvest knowledge from manually created lexicons and encyclopedia like WordNet and Wikipedia.
We used the back-of-the-book index of manuals, which contains pointers to relevant topics in the book, to create the ground truth for domain term discovery. The set of relevant topics extracted from manuals represents the set of terms one would like to dis-cover from corpus. Thus terms discovered through the proposed technique should cover as much as possible of this set.
Table 3 compares the recall of the 2 approaches for domain term discovery (using NP chunking on titles and by using HITS) with WordNet, Yago and BabelNet on this set. It is observed that the HITS approach discovers a number of new multi-words and dis-cards many of the multi-words discovered by noun-phrase chunk-ing from titles, with scores less than the threshold. Recall of Word-Net is low as it mostly misses out on the multi-words and detects only unigrams. BabelNet and Yago use world knowledge acquired from manually constructed WordNet and Wikipedia, and obtain a better recall in identifying domain terms.

To align the domain term discovery evaluation process with our end goal of improving a QA system, we evaluated the performance of a QA system [13] trained in the smartphone domain, with and without such automatically discovered domain term lexicon. Ta-ble 4 presents the comparison of the two scenarios.
 Table 4: Performance of a QA system with and without domain term lexicon.
For relation discovery, the performance of all the systems, in terms of recall and precision, is computed with respect to the an-notation statistics provided by two annotators. We extracted 3000 domain terms from the secondary index and 100 similar neighbors for each term from the random index generating 0 . 6 million word pairs. From these word pairs, we retained word pairs such that one of the members belong to the titles. As the titles contain most of the important domain terms, this constraint ascertains that most of the extracted word pairs would be relevant ones in the domain. The word pairs are partitioned into two sets. We further divided word pairs in Set 1 as  X  X oun-noun X  and  X  X erb-noun X  word pairs. T wo annotators (Ann) were asked to annotate 500  X  X oun-noun X  word pairs in Set 1 as Feature-Of or none and 500  X  X erb-noun X  word pairs in Set 1 as Action-On or none . They were further instructed to annotate 1000 randomly picked word pairs from Set 2 as Synonyms, Type-Of or none . Since Feature-of and Action-On relations are pretty straightforward to detect, the annotators worked on disjoint sets; whereas for Type-Of and Syn-onyms each of them annotated the entire Set 2 .
 Table 5 shows the annotator agreement for the Synonyms. The Kappa Score [5] is high at 0 . 92 due to the large number of word pairs the annotators agree are not Synonyms. Table 6 shows the an-notator agreement for Type-Of. The Kappa Score is 0 . 70 due to the large number of word pairs the annotators agree are not Type-Of. Table 7 shows the annotation statistics for Feature-Of and Action-On, with  X  X rue X  denoting the number of word pairs that the annota-tors agree belong to the given relation type. Table 8 shows the precision-recall figures for Feature-Of, Action-On and Type-Of. Table 9 shows the precision-recall figures for Synonym discovery using only Random Indexing (RI) approach with different features. Table 10 shows the precision-recall com-parison of the full Domain Cartridge (using RI + HITS + Similarity Eqn.) with other systems for Synonym discovery.

Relations in BabelNet come either from Wikipedia hyperlinks or WordNet. However the relations obtained from Wikipedia are unlabeled. Therefore, the performance of BabelNet is the same as WordNet for relation discovery (ignoring the unlabeled relations). Yago uses  X  X ikipedia:redirect X  links to detect synonymous con-cepts.  X  X  redirect is a page which has no content itself, but sends the reader to another page, usually an article or section of an arti-cle. X  [50]. Possible reasons for re-directions are misspellings, alter-native names, closely related names, abbreviations etc.
WordNet contains a number of relations defined over the taxon-omy from which we pick the following relations: 1. Hyponymy: X is a hyponym of Y if X is a (kind of) Y. 2. Hypernymy: Y is a hypernym of X if X is a (kind of) Y. 3. Meronymy: X is a meronym of Y if X is a part of Y. 4. Holonymy: Y is a holonym of X if X is a part of Y.

Hyponyms and Hypernyms are same as Type-Of in our work, whereas Meronyms and Holonyms form a subset of Feature-Of re-lations in our work (which could detect only 1 Feature-Of relation in our experiment). BabelNet, WordNet and Yago do not have any category similar to Action-On in our work. Yago has Type-Of cate-gories derived from WordNet hyponymy and hypernymy relations, as well as from the Wikipedia categories intended to group together pages on similar subjects in Wikipedia. Table 11 shows the re-call comparison of all the systems for the discovery of Type-Of, Feature-Of and Action-On relations.
 A number of similarity measures have been defined over the WordNet taxonomy that exploit distributional similarity to find the relatedness of 2 concepts. We consider the following similarity measures from [38] as our baseline for Synonym discovery by the distributional similarity approach: 1. HSO -Two lexicalized concepts are semantically close if their WordNet synsets are connected by a path that is not too long and that  X  X oes not change direction too often" 2. LCH -This measure relies on the length of the shortest path be-tween two synsets for their measure of similarity. They limit their attention to  X  X S-A X  links and scale the path length by the overall depth  X  X  X  of the taxonomy 3. LESK -The relatedness of two words is proportional to to the extent of overlaps of their dictionary definitions Table 7: Annotation statistics for feature-of and action-on. Table 8: Precision-Recall of Domain Cartridge for 3 relations. Table 9: Precision-Recall of Domain Cartridge for synonyms using only random-indexing. 4. WUP -The Wu &amp; Palmer measure calculates relatedness by con-sidering the depths of the two synsets in the WordNet taxonomies, along with the depth of the LCS 5. RES -Resnik defined the similarity between two synsets to be the information content of their lowest super-ordinate (most spe-cific common subsumer) 6. JCN -It uses the notion of information content, but in the form of the conditional probability of encountering an instance of a child-synset given an instance of a parent synset: 1 /jcn _ distance , where jcn _ distance = IC ( synset 1 ) + IC ( synset 2 )  X  2  X  IC ( lcs ) 7. LIN -The math equation is modified a little bit from JCN: 2  X  IC ( lcs ) / ( IC ( synset 1 ) + IC ( synset 2 )) , where IC ( x ) is the information content of  X  X  X . One can observe, then, that the relat-edness value will be greater-than or equal-to zero and less-than or equal-to one
Table 12 shows the F-score comparison of different WordNet similarity measures with Domain Cartridge. Figure 5 shows a snap-shot of constructed smartphone domain ontology with our system.
Domain term discovery, of which multi-words form an important component, forms the primary module of the Domain Cartridge framework. Domain terms extracted using noun phrase chunk-ing on the document titles are used to enrich the parser lexicon to bootstrap the parser which attains 32% recall on ground-truth con-structed from the back-of-the-book index. Furthermore, domain terms are extracted using HITS on a bipartite graph representa-tion of the SSR and concepts on the entire corpus, which further improved the recall by 8% . The domain term discovery process achieves 18% improvement in recall over WordNet, which lacks most of the multi-word tokens. In fact, the ESG Parser + HITS dis-covers 1586 multi-word domain terms in the corpus, in contrast to 46 multi-word tokens identified by WordNet. However, BabelNet and Yago that incorporate both WordNet and Wikipedia informa-tion obtain a better recall at the cost of human annotation.
The newly discovered domain terms, mostly multi-words, result in 7% and 4% improvement at recall@1 and recall@2 respectively, in an in-house Question-Answering system on the same corpus. System Precision Recall F-Score Yago 37.67% 31.60% 34.37% BabelNet, WordNet 83% 31% 45.14% Domain Cartridge (DC) 58% 41% 47.6% DC + WordNet 62% 40% 49% DC + ESG Parser Features 65% 39% 49.14% Table 10: Precision-Recall comparison of Domain Cartridge (random-indexing, HITS and sim. eqn.) with other systems. System Type-Of Feature-Of Action-On BabelNet, WordNet 19.27% --Yago 25.12% --Domain Cartridge 77% 85.7% 68% Table 12: F-Score comparison of WordNet similarity measures with Domain Cartridge.

This results from a better parser performance, as the multi-words are used to enrich the parser lexicon, which is evident from less number of incomplete parses and reduction in the parse cost. The number of incomplete parses went down by 73% after incorporat-ing the multi-word domain terms in the parser lexicon. For exam-ple, the sentence  X  X se Sprint Zone" is parsed as  X  Use-Noun Sprint-Verb Zone-Noun " in absence of multi-word information resulting in an incomplete parse. Once the parser has the knowledge that  X  X print Zone" is a multi-word domain term, the parse is complete ( X  Use-Verb &amp; Sprint Zone-Noun ").

We primarily focus on 4 relations in the constructed ontology us-ing Domain Cartridge framework namely, Synonyms ( X  X imilarity X ), Type-Of ( X  X ierarchical X ), Action-On ( X  X unctional X ) and Feature-Of ( X  X ttributes X ) . The Synonym discovery approach uses Random In-dexing (RI) for dimensionality reduction and computes the top K neighbors of a given word based on relational distributional simi-larity of the word with the candidate terms using ESG parser fea-tures. This method achieves a high recall ( 79% ) but low precision ( 14% ) due to sparse matches, as many neighboring words sharing similar or direct SSR are treated as similar. For example, given the target word  X  X rowser X , RI retrieves  X  X pera-mini, ebook, apps, messaging, load, application" etc. as candidate similar terms due to overlapping SSR in the context. In the second stage for Syn-onym discovery, we use a weighted relational distributional sim-ilarity measure on these candidate terms using dominant domain SSR extracted using HITS. This significantly increases precision, as we consider the discriminative power of the matched SSR in the similarity equation, and consider only dominant SSR as given by HITS, achieving an F-Score of 47 . 6% .

It is observed from the annotated data in the smartphone domain that 84% instances are not Synonyms, which indicates the chal-lenge in Synonym discovery. The performance is further improved to 49 . 14% using parser features in the form of attributes. A num-ber of similarity measures (Lin, Lesk, LCH, Res, Path, WUP etc.) have been built over WordNet, using the path between concepts, taxonomy depth, information content of nodes etc. All the meth-ods achieve a high recall but low precision; due to less coverage but more accurate due to manual construction of the taxonomy, with the best F-Score attained at 45% (prec/recall -83% / 31% ). Yago achieves an F-Score of 34 . 37% in discovering Synonyms; whereas Domain Cartridge achieves an F-Score of 49% for Synonym dis-covery, without any supervision at all.

BabelNet uses only the semantic relations in WordNet, and there-fore has the same performance as WordNet in relation discovery. Figure 5: Snapshot of constructed smartphone domain ontol-ogy using Domain Cartridge.
 Yago and WordNet do not contain any relation similar to Action-On in Domain Cartridge. The only relations corresponding to Feature-Of in WordNet i.e. Meronymy and Holonymy, that form a subset of Feature-Of, hardly detect any positive examples in the annotated data. Yago does not have any Feature-Of relation category. The WordNet relations, Hyponymy and Hypernymy, that correspond to Type-Of in our framework have a recall of 20% . Yago has a recall of 25% for Type-Of corresponding to the  X  X ikipedia:redirect X  links and the WordNet relations, in contrast to the Domain Cartridge re-call of 77% . Overall Domain Cartridge achieves an F-Score of 80% , 66% and 65 . 5% for Feature-Of, Action-On and Type-Of re-spectively. The SSR features prove to be very effective in capturing direct relation between domain terms. The Type-Of relations are typically detected using a modification of the Hearst [19] patterns on the ESG parser output.
An ontology can be seen as a data structure that specifies terms, properties and relations among them for a richer knowledge repre-sentation. Many of the existing approaches to create ontology rely on manual or supervised techniques. Due to supervision they are time-consuming, resource-demanding and difficult to scale.
YAGO [48] is a light-weight, extensible ontology, with concepts discovered from Wikipedia and unified with WordNet, using a care-fully designed combination of rule-based and heuristic methods.
BabelNet [36] is a large multilingual semantic network that in-corporates lexicographic and encyclopedic knowledge from Word-Net and Wikipedia. It connects concepts and named entities in a very large network of semantic relations. It uses machine transla-tion to enrich resources from all languages. Relations in BabelNet come either from Wikipedia hyperlinks or WordNet. However, the relations obtained from Wikipedia are unlabeled.

A deep NLP-based system is described in [35] that automatically extracts and populates domain-specific ontologies from morpho-logical structures in free text. It starts with a small seed of domain concepts, performs a graph-based pattern discovery from text and finds taxonomic relations between the concepts in the current on-tology. The authors manually provided 48 patterns for identifying type-of and part-of relations, together with WordNet and Wikipedia for synonym discovery. Jaguar [2] automatically builds domain-specific ontologies from text. It uses well-formed procedures to im-pose a hierarchical structure on the discovered concepts using the semantic relations discovered by Polaris [33] and WordNet [32].
Terminae method [4] is used for building ontological models from text using linguistic analysis. An expert is required to se-lect the most important concepts for the targeted ontology from the list of candidate terms discovered by the tool. Lexical knowledge resources are used to generate domain ontologies from text docu-ments in [29]. User intervention is required at the end of the process to select the relevant concepts and relations. The authors in [21] generate an ontology based on an analysis of a set of texts followed by the use of WordNet. The analysis of the corpus retrieves words as concepts. These words are then searched in WordNet to find concepts associated with these words. A modified version of SOTA algorithm is used to extract terms from documents grouped hierar-chically in [22]. Concepts are assigned to the tree nodes based on WordNet hyponymy relation. The authors in [24] use WordNet as a general ontology to discover a subset of concepts to build a domain ontology; whereas [34, 1] use WordNet and a supplementary mod-ule to look for missing or associated concepts in the Web. User intervention is required to remove noise. A method for ontology merging based on concepts using WordNet is described in [8].
The USP system [41] can extract formulas from corpus but is limited to extractions for which there is substantial evidence in the corpus. The knowledge extracted is simply a large set of formu-las without ontological structure. They build further on the USP semantic parser by adding the capability to form hierarchical clus-terings of logical expressions, linked by IS-A relations [42].
As we can see, most of the automatic methods for ontology cre-ation heavily depend on some manually created lexical resources like WordNet, or a seed set of manually provided terms and re-lations which are expanded to form the full domain ontology, or highly rule-based (as we will also see in the next section). Most of the approaches do not deal with multi-word domain terms. In this work, we propose a framework that does not rely on any form of supervision. In the following subsection, we talk of the different approaches to discover specific type of relations for ontology.
The most common method of discovering similar words from text uses the principle of distributional hypothesis [17] which says that words which occur in similar contexts tend to have similar meanings. There have been many proposals for computing dis-tributional similarity of words [20, 40, 28]. Our approach of iden-tifying the context is similar to [15, 20, 44, 28] in the usage of a parser, which identifies the context of a word to consist of words connected to the target word by important parser relations. How-ever, our similarity computation differs in the following way: 1) Random Indexing is used for dimensionality reduction which is scalable (in contrast to Latent Semantic Indexing [27]) 2) The simi-larity computation of the context vectors uses a specialized scoring mechanism on dominant domain relations extracted from a bipar-tite graph representation of the parser relations and domain terms.
Inference rules from text are automatically discovered using sim-ilar paths in dependency trees in [28]. The authors in [26] used re-lations extracted from [6] to discover concepts from corpus. Simple patterns are used to discover taxonomic relations from Web in [25].
The authors in [19] use manually discovered lexical patterns to detect Hypernyms. These patterns ( Hearst ) suffered from limited recall, and local nature of the patterns introduced errors. The recall is improved in [43] by refining the rules to increase coverage and using supervised classification on the Hearst patterns. The authors in [46] discovered a large number of weak patterns to detect Hyper-nyms, using WordNet, from a corpus of NewsWire sentences. They achieved a high precision but low recall with an F-score of 0 . 348 . More recently, the authors in [37] applied the techniques described in [46] to detect Hypernyms of Named Entities ( i.e. Proper Nouns) to improve performance of Question Answering systems. They ob-tained 53% MAP and the automatically discovered Hyponyms re-sulted in a 9% performance boost on a TREC Question Answering data set. A method of discovering Hyponymy relation is described in [51] by combining Wikipedia and other Web documents using distributional similarity and hierarchical distances in the Wikipedia database.
 The authors in [3] use a method similar to [19] for obtaining Meronym and Holonym relationships, whereas the work in [11, 12] use a set of manually devised patterns to discover part-whole rela-tionships from text.

Most of the works, discussed so far, either use a manually con-structed resource to bootstrap the classifier, or manually provided lexical patterns which suffer from the sparsity of patterns in real life texts, and noisy output due to sparse matches. Although, we do use some rules on the parser output for relation discovery (in the form of shallow semantic relations from the parser), they are limited in nature and work at the conceptual level rather than at the lexical level.
In this work, we propose an unsupervised framework for con-structing a shallow domain ontology from corpus. Unlike many other existing approaches like Yago and BabelNet, we do not make use of external knowledge resources like WordNet, Wikipedia etc. or manually provided data in the form of seed words or relations. The first part of this work deals with discovering domain terms from corpus using noun phrase chunking and a bipartite graph of shallow semantic relations and domain terms. Multi-words form an important component of the domain term discovery process. We show that the incorporation of these multi-words in the parser lex-icon improves the parser performance, with 73% reduction in the number of incomplete parses and better parser output, which im-proves the performance of an in-house Question-Answering system by upto 7% .

The second part of this work focuses on creating a shallow ontol-ogy using domain terms, and relations like Synonyms ( X  X imilar-to X ), Type-Of ( X  X s-a X ), Feature-Of ( X  X ttributes X ) and Action-On ( X  X eth-ods X ) . We show that the Synonym discovery approach, using a modified relational distributional similarity measure on dominant domain SSR and weighted evidence measure, performs better than most of the existing approaches to Synonym discovery using Word-net, BabelNet, and Yago. All the discovered domain terms and rela-tions (using SSR) are evaluated on manually annotated data, where we achieve better performance over the compared resources, with-out using any mode of supervision.

An important future work is to measure the reduction in cus-tomization time required to adapt the QA system from one domain to another by integrating Domain Cartridge in its pipeline. The advantage of the framework is that we need to change only the Primary Index for migrating to some other domain, keeping the re-maining part of the framework intact. [1] E. Agirre, O. Ansa, E. H. Hovy, and D. Martinez. Enriching [2] M. Balakrishna, D. I. Moldovan, M. Tatu, and M. Olteanu. [3] M. Berland and E. Charniak. Finding parts in very large [4] B. Biebow and S. Szulman. Terminae: A linguistic-based [5] J. Carletta. Assessing agreement on classification tasks: the [6] A. Carlson, J. Betteridge, B. Kisiel, B. Settles, E. H. Jr., and [7] E. Charniak. A maximum-entropy-inspired parser. NAACL [8] M. Cho, H. Kim, and P. Kim. A new method for ontology [9] S. T. Dumais. Latent semantic analysis. Annual Review of [10] J. Fan, A. Kalyanpur, D. Gondek, and D. Ferrucci. [11] R. Girju, A. Badulescu, and D. Moldovan. Learning semantic [12] R. Girju, A. Badulescu, and D. Moldovan. Automatic [13] D. Gondek, A. Lally, A. Kalyanpur, J. W. Murdock, P. A. [14] J. Gorman and J. R. Curran. Random indexing using [15] G. Grefenstette. Explorations in Automatic Thesaurus [16] B. Hajian and W. Tony. A method of measuring semantic [17] Z. Harris. Distributional structure. Word , 10(23), 1954. [18] C. Havasi, R. Speer, and J. Alonso. Conceptnet 3: a flexible, [19] M. A. Hearst. Automatic Acquisition of Hyponyms from [20] D. Hindle. Noun classification from predicate-argument [21] H. Hu and D.-Y. Liu. Learning OWL ontologies from free [22] L. Khan and F. Luo. Ontology construction for information [23] J. Kleinberg. Authoritative sources in a hyperlinked [24] H. Kong, M. Hwang, and P. Kim. Design of the automatic [25] Z. Kozareva and E. Hovy. A semi-supervised method to learn [26] J. Krishnamurthy and T. Mitchell. Which noun phrases [27] A. Kumaran, R. Makin, V. Pattisapu, S. E. Sharif, [28] D. Lin and P. Pantel. Dirt  X  discovery of inference rules from [29] D. Lonsdale, Y. Ding, D. W. Embley, and A. Melby. [30] M. C. McCord, J. W. Murdock, and B. K. Boguraev. Deep [31] S. Mcdonald and M. Ramscar. Testing the distributional [32] G. A. Miller. Wordnet: A lexical database for english. [33] D. Moldovan and E. Blanco. Polaris: Lymba X  X  semantic [34] D. I. Moldovan and R. Girju. Domain-specific knowledge [35] H. Mousavi, D. Kerr, M. Iseli, and C. Zaniolo.
 [36] R. Navigli and S. P. Ponzetto. ACL  X 10. [37] P. S. Paul McNamee, Rion Snow and J. Mayfield. Learning [38] T. Pedersen and S. Patwardhan. Wordnet::similarity -[39] J. K. Pentti Kanerva and A. Holst. Random indexing of text [40] F. Pereira, N. Tishby, and L. Lee. Distributional clustering of [41] H. Poon and P. Domingos. Unsupervised semantic parsing. [42] H. Poon and P. Domingos. Unsupervised ontology induction [43] A. Ritter, S. Soderland, and O. Etzioni. What is this, anyway: [44] G. Ruge. Experiment on linguistically-based term [45] M. Sahlgren. An introduction to random indexing. Methods [46] R. Snow, D. Jurafsky, and A. Y. Ng. Learning syntactic [47] S. Staab and R. Studer. Handbook on Ontologies . Springer [48] F. M. Suchanek, G. Kasneci, and G. Weikum. Yago: a core [49] O. V. and A. P. Ontology based semantic similarity [50] Wikipedia. Wikipedia, the free encyclopedia, 2013. [51] I. Yamada, K. Torisawa, J. Kazama, K. Kuroda, M. Murata,
