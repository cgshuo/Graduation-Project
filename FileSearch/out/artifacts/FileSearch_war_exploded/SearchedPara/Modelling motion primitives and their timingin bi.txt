 Movement planning and control is a very difficult problem in re al-world applications. Cur-rent robots have very good sensors and actuators, allowing a ccurate movement execution, however the ability to organise complex sequences of moveme nt is still far superior in bi-ological organisms, despite being encumbered with noisy se nsory feedback, and requiring control of many non-linear and variable muscles. The underl ying question is that of the representation used to generate biological movement. Ther e is much evidence to suggest that biological movement generation is based upon motor primitives , with discrete muscle synergies found in frog spines, (Bizzi et al., 1995; d X  X vell a &amp; Bizzi, 2005; d X  X vella et al., 2003; Bizzi et al., 2002), evidence of primitives being loca lly fixed (Kargo &amp; Giszter, 2000), and modularity in human motor learning and adaption (Wolper t et al., 2001; Wolpert &amp; Kawato, 1998). Compact forms of representation for any biol ogically produced data should therefore also be based upon primitive sub-blocks. Figure 1: (A) A factorial HMM of a handwriting trajectory Y t . The parameters  X   X  m t indicate There are several approaches to use this idea of motion primi tives for more efficient robotic movement control. (Ijspeert et al., 2003; Schaal et al., 200 4) use non-linear attractor dy-namics as a motion primitive and train them to generate motio n that solves a specific task. (Amit &amp; Matari  X c, 2002) use a single attractor system and gen erate non-linear motion by modulating the attractor point. These approaches define a pr imitive as a segment of move-ment rather than understanding movement as a superposition of concurrent primitives. The goal of analysing and better understanding biological data is to extract a generative model of complex movement based on concurrent primitives which may s erve as an efficient represen-tation for robotic movement control. This is in contrast to p revious studies of handwriting which usually focus on the problem of character classificati on rather than generation (Singer &amp; Tishby, 1994; Hinton &amp; Nair, 2005).
 We investigate handwriting data and analyse whether it can b e modelled as a superposition of sparsely activated motion primitives. The approach we ta ke can intuitively be compared to a Piano Model (also called Piano roll model (Cemgil et al., 2006)). Just as piano music can (approximately) be modelled as a superposition of the so unds emitted by each key we follow the idea that biological movement is a superposition of pre-learnt motion primitives. This implies that the whole movement can be compactly repres ented by the timing of each primitive in analogy to a score of music. We formulate a proba bilistic generative model that reflects these assumptions. On the lower level a factorial Hi dden Markov Model (fHMM, Ghahramani &amp; Jordan, 1997) is used to model the output as a com bination of signals emitted from independent primitives (each primitives corresponds to a factor in the fHMM). On the higher level we formulate a model for the primitive timing de pendent upon character class. The same motion primitives are shared across characters, on ly their timings differ. We train this model on handwriting data using an EM-algorithm and the reby infer the primitives and the primitive timings inherent in this data. We find that the i nferred timing posterior for a specific character is indeed a compact representation for th e specific character which allows for a good reproduction of this character using the learnt pr imitives. Further, using the timing model learnt on the higher level we can generate new mo vement  X  new samples of characters (in the same writing style as the data), and also s cribblings that exhibit local similarity to written characters when the higher level timi ng control is omitted. Section 2 will introduce the probabilistic generative mode l we propose. Section 3 briefly describes the learning procedures which are variants of the EM-algorithm adapted to our model. Finally in section 4 we present results on handwritin g data recorded with a digi-tisation tablet, show the primitives and timing code we extr act, and demonstrate how the learnt model can be used to generate new samples of character s. Our analysis of primitives and primitive timings in handwri ting is based on formulating a corresponding probabilistic generative model. This model can be described on two levels. On the lower level (Figure 1(A)) we consider a factorial Hidd en Markov Model (fHMM) where each factor produces the signal of a single primitive a nd the linear combination of factors generates the observed movement Y t . This level is introduced in the next section and was already considered in (Williams et al., 2006; Willia ms et al., 2007). It allows the learning and identification of primitives in the data but doe s not include a model of their timing. In this paper we introduce the full generative model (Figure 1(B)) which includes a generative model for the primitive timing conditioned on t he current character. 2.1 Modelling primitives in data Let M be the number of primitives we allow for. We describe a primit ive as a strongly constrained Markov process which remains in a zero state mos t of the time but with some probability  X   X   X  [0 , 1] enters the 1 state and then rigorously runs through all sta tes 2 , .., K before it enters the zero state again. While running though i ts states, this process emits a fixed temporal signal. More rigorously, we have a fHMM compos ed of M factors. The state of the m th factor at time t is S m t  X  X  0 , .., K m } , and the transition probabilities are This process is parameterised by the onset probability  X   X  m t of the m th primitive at time t . The M factors emit signals which are combined to produce the obser ved motion trajectory Y t according to where N ( x, a, A ) is the Gaussian density function over x with mean a and covariance matrix A . This emission is parameterised by W m s which is constrained to W m 0 = 0 (the zero state does not contribute to the observed signal), and C is a stationary output covariance.  X  can be compared to the sound of a piano key. The parameters  X   X  m t  X  [0 , 1] could be compared to the score of the music. We will describe below how we learn the primitives W s and also adapt the primitive lengths K m using an EM-algorithm. 2.2 A timing model Considering the  X   X   X  X  to be fixed parameters is not a suitable model of biological movement. The usage and timing of primitives depends on the character t hat is written and the timing varies from character to character. Also, the  X   X   X  X  actually provide a rather high-dimensional representation for the movement. Our model takes a different approach to parameterise the primitive activations. For instance, if a primitive is a ctivated twice in the course of the movement we assume that there have been two signals ( X  X pikes  X ) emitted from a higher level process which encode the activation times. More forma lly, let c be a discrete random variable indicating the character to be written, see Figure 1(B). We assume that for each primitive we have another Markovian process which generate s a length-L sequence of states G l  X  X  1 , .., R, 0 } , The states G m l encode which primitives are activated and how they are timed , as seen in Figure 2(b). We now define  X  m t to be a binary random variable that indicate the activation of a primitive at time t , which we call a  X  X pike X . For a zero-state G m l = 0 no spike is a Gaussian component to the probabilities of  X  m t = 1 centred around a typical spike time  X  Gaussian density. Additionally, we restrict the Markovian process such that each Gaussian component can emit at most one spike, i.e., we constrain P ( G m l | G m l triangular matrix. Given the  X   X  X , the state transitions in the fHMM factors are as in equati on (1), replacing  X   X  by  X  .
 To summarise, the spike probabilities of  X  m t = 1 are a sum of at most L Gaussian components centred around the means  X  m l and with variances  X  m l . Whether or not such a Gaussian component is present is itself randomised and depends on the states G m l . We can observe at most L spikes in one primitive, the spike times between different pr imitives are dependent, but we have a Markovian dependency between the presence and t iming of spikes within a primitive. The whole process is parameterised by the initia l state distribution P ( G m 1 | c ), the transition probabilities P ( G m l | G m l these parameters will be learnt using an EM-algorithm.
 This timing model is motivated from results with the fHMM-on ly model: When training the fHMM on data of a single character and then computing the M AP spike times using a Viterbi alignment for each data sample we find that the MAP sp ike times are roughly Gaussian distributed around a number of means (see Figure 2( b)). This is why we used a sum of Gaussian components to define the onset probabilities P (  X  =1). However, the data is more complicated than provided for by a simple Mixture of G aussians. Not every sample includes an activation for each cluster (which is a source of variation in the handwriting) and there cannot be more than one spike in each cluster. There fore we introduced the constrained Markov process on the states G m l which may skip the emission of some spikes. In the experiments we will compare both the fHMM without the t iming model (Figure 1(A)) and the full model including the timing model (Figure 1(B)).
 In the fHMM-only model, inference in the fHMM is done using va riational inference as described in (Ghahramani &amp; Jordan, 1997). Using a standard E M-algorithm we can train the parameters W , C and  X   X  . To prevent overfitting we assume the spike probabilities are stationary (  X  m t constant over t ) and learn only a single mean parameter  X   X  m for each primitive.
 In the full model, inference is an iterative process of infer ence in the timing model and inference in the fHMM. Note that variational inference in th e fHMM is itself an iterative process which recomputes the posteriors over S m t after adapting the variational parameters. We couple this iteration to inference in the timing model in b oth directions: In each iteration, the posterior over S m t defines observation likelihoods for inference in the Markov models G m l . Inversely, the resulting posterior over G m l defines a new prior over  X   X  X  (a message from G m l to  X  t ) which enter the fHMM inference in the next iteration. Stand ard M-steps are then used to train all parameters of the fHMM and the timing model. In ad dition, we use heuristics to adapt the length K m of each primitive: we increase or decrease K m depending on whether the learnt primitive is significantly different to zero in the last time steps. The number of parameters used in the model therefore varies during learni ng, as the size of W depends upon K m , and the size of G depends upon the number of inferred spikes.
 In the experiments we will also investigate the reconstruct ion of data. By this we mean that we take a trained model, use inference to compute the MAP spikes  X  for a specific data sample, then we use these  X   X  X  and the definition of our generative model (including the learnt primitives W ) to generate a trajectory which can be compared to the origin al data sample. Such a reconstruction can be computed using both the fHMM-only model and the full model. 4.1 Primitive and timing analysis using the fHMM-only We first consider a data set of 300 handwritten  X  X  X  X  recorded u sing an INTUOS 3 WA-COM digitisation tablet http://www.wacom.com/productin fo/9x12.cfm , providing trajec-tory data at 200Hz. The trajectory Y t we model is the normalised first differential of the data, so that the data mean was close to zero, providing the re quirements for the zero state assumption in the model constraints. Three dimension al data was used, x-position, y-position, and pressure. The data collected were separate d into samples, or characters, allowing each sample to be separately normalised.
 Our choice of parameter was M = 10 primitives and we initialised all K m = 20 and con-strained them to be smaller than 100 throughout learning.
 We trained the fHMM-only model on this dataset. Figure 3(a) s hows the reconstruction of a specific sample of this data set and the corresponding poster ior over  X   X  X . This clean posterior is the motivation for introducing a model of the spike timing s as a compact representation Figure 4: (a) Reconstructions of  X  X  X  X  using the full model. (b) Histog ram of the reconstruction of the data. Equally the reconstruction (using the Viterbi a ligned MAP spikes) shows the sufficiency of the spike code to generate the character. Figur e 3(b) shows the primitives W m (translated back into pen-space) that were learnt and impli citly used for the reconstruction of the  X  X  X . These primitives can be seen to represent typical parts of the  X  X  X  character; the arrows in the reconstruction indicate when they are activat ed.
 The fHMM-only model can be used to reconstruct a specific data sample using the MAP  X   X  X  of that sample, but it can not  X  X utonomously X  produce charac ters since it lacks a model of the timing. To show the importance of this spike timing infor mation, we can demonstrate the effects of removing it. When using the fHMM-only model as a generative model with the learnt stationary spike probabilities  X   X  m the result is a form of primitive babbling , as can be seen in Figure 3(c). Since these scribblings are generate d by random expression of the learnt primitives they locally resemble parts of the  X  X  X  cha racter.
 The primitives generalise to other characters if the traini ng dataset contained sufficient variation. Further investigation has shown that 20 primiti ves learnt from 12 character types are sufficiently generalised to represent all remaining nove l character types without further learning, by using a single E-step to fit the pre-learnt param eters to a novel dataset. 4.2 Generating new characters using the full generative mod el Next we trained the full model on the same  X  X  X -dataset. Figur e 4(a) shows the reconstruc-tions of some samples of the data set. To the right we see the re construction errors in velocity space showing at many time points a perfect reconst ruction was attained. Since the full model includes a timing model it can also be run auton omously as a generative model for new character samples. Figure 4(c) displays such n ew samples of the character  X  X  X  generated by the learnt model.
 As a more challenging problem we collected a data set of over 4 50 character samples of the letters a , b and c . The full model includes the written character class as a ran dom variable and can thus be trained on multi-character data set s. Note that we restrict the total number of primitives to M = 10 which will require a sharing of primitives across characters. Figure 5(a) shows samples of the training data s et while Figure 5(b) shows reconstructions of the same samples using the MAP  X   X  X  in the full model. Generally, the reconstructions using the full model are better than using t he fHMM-only model. This can be understood investigating the distribution of the MAP  X   X  X  across different samples under the fHMM-only and the full model, see Figure 6. Coupling the t iming and the primitive model during learning has the effect of trying to learn primit ives from data that are usually in the same place. Thus, using the full model the inferred spike s are more compactly clustered at the Gaussian components due to the prior imposed from the t iming model (the thick black lines correspond to Equation (4)). Figure 5: (a) Training dataset, showing 3 character types, and variat ion. (b) Reconstruction of Figure 6: (a) Scatter plot of primitive onset spikes for a single chara cter type across all samples Finally, we run the full model autonomously to generate new c haracter samples, see Figure 5(c). Here the character class, c is first sampled uniform randomly and then all learnt parameters are used to eventually sample a trajectory Y t . The generative samples show interesting variation while still being readably a charact er. In this paper we have shown that it is possible to represent ha ndwriting using a primitive based model. The model consists of a superposition of severa l arbitrary fixed functions. These functions are time-extended, of variable length (dur ing learning), and are superim-posed with learnt offsets. The timing of activations is cruci al to the accurate reproduction of the character. With a small amount of timing variation, a dis torted version of the original character is reproduced, whilst large (and coordinated) di fferences in the timing pattern produce different character types.
 The spike code provides a compact representation of movemen t, unlike that which has pre-viously been explored in the domain of robotic control. We ha ve proposed to use Markov processes conditioned on the character as a model for these s pike emissions. Besides con-tributing to a better understanding of biological movement , we hope that such models will inspire applications also in robotic control, e.g., for mov ement optimisation based on spike codings. An assumption made in this work is that the primitives are lea rnt velocity profiles. We have not included any feedback control systems in the primitive p roduction, however the presence of low-level feedback, such as in a spring system (Hinton &amp; Na ir, 2005) or dynamic motor primitives (Ijspeert et al., 2003; Schaal et al., 2004), wou ld be interesting to incorporate into the model, and could perhaps be done by changing the outputs o f the fHMM to parameterise the spring systems rather than be Gaussian distributions of velocities.
 We make no assumptions about how the primitives are learnt in biology. It would be interesting to study the evolution of the primitives during human learning of a new character set. As humans become more confident at writing a character, t he reproduction becomes faster, and more repeatable. This could be related to a more a ccurate and efficient use of primitives already available. However, it might also be t he case that new primitives are learnt, or old ones adapted. More research needs to be don e to examine these various possibilities of how humans learn new motor skills.
 Acknowledgements
