 1. Introduction
The network traf fi c of video streaming can be self-similar ( Dai et al., 2009 ) due to video encoding algor ithms (codec), where the frame sizes vary according to the information that the frames carry.
In a network architecture based on packet switching, the burstiness of network traf fi c can cause congestion in the router queues, leading to a possible loss of packets. The packet discard could occur even at low average utilization levels, as a consequence of traf fi leading to a temporary decrease in the quality of experience (QoE).
The delivery of high-quality video is a complex issue, particularly for networks based on packet-switching techniques. Even the slightest packet loss in a video stream may result in a severe degradation of quality ( Szymanski and Gilbert, 2009 ), and 1% or less of packet loss could severely affect the quality of image, reducing the QoE ( Greengrass et al., 2009 ).

Among them, MPEG-2 and MPEG-4 are currently the most used standards. MPEG-4 is a family of open international standards that provides tools for use in multimedia applications ( Van der Auwera et al., 2008a ). The tools include codecs for encoding audio and video. MPEG-4 has the advantage of requiring lower transmission rates compared with its predecessors, MPEG-1 and MPEG-2. Thus,
MPEG-4 allows an improvement in terms of bandwidth utilization, as well as a decrease in the amount of space for video storage ( Marpe et al., 2006 ). The MPEG algorithm addresses the temporal redundancy of videos by representing the sequence of images with a group of pictures (GOP) that consists of a speci fi c sequence of frames. The GOP starts with an intra frame (I-frame), which can be decoded without other frames, followed by bidirectional frames (B-frames) and predictive frames (P-frames). The P-frames depend on information from the nearest previous I-or P-frames and the
B-frames use both past and future I-or P-frames as references for image representation.

The H.264/MPEG-4 part 10 Advanced Video Coding (AVC) standard presents improvements in compression ef fi ciency and is widely used in multimedia application standards and industry consortia speci fi cations ( Seeling and Reisslein, 2012 ; Maisonneuve et al., 2009 ) and for this reason it is the codec we choose to use.
Hereinafter, for brevity, the H.264/MPEG-4 Part 10 AVC standard shall be referred to as  X  H.264  X  . However, although the encoding used was the H.264, we expect that the proposed method can also be applied to MPEG-4 or MPEG-2.

Fig. 1 shows the transmission sequence of I-, P-and B-frames for a video encoded with H.264. The GOP always starts with an
I-frame, followed by B-and then P-frames. The sequence of frames depends on the encoding settings. The common notation uses the pair ( Y , Z ), where Y indicates the number of frames in the GOP and
Z represents the number of B-frames between the P-frames. Fig. 1 illustrates the frame sequence for the (12,2) con fi guration. As the
I-frames include all the information needed to decode the image without information from other frames, they are usually of a larger size than the others. Therefore, more IP packets are needed to transport an I-frame than to carry other frames, as shown in Fig. 2 . The effects of packet loss in viewer QoE are analyzed in
Greengrass et al. (2009) . Discarded packets carrying I-frames could result in image impairments propagated to all frames in that GOP.
This could last a long time (typically from 0.5 to 1 s); video quality is recovered only when the decoder receives an unimpaired
I-frame. This kind of distortion happens because the H.264 decoder uses the I-frame as reference to decode the other frames in the GOP. Depending on which packet is lost, the distortions may result in several degrees of severity, e.g. the loss of a single IP packet at the beginning of an I-frame, which contains the frame header, might have the same effect as losing a whole I-frame.
Greengrass et al. (2009) also indicate that the higher the number of frames in a GOP, the greater the impairments caused by a packet loss.

To improve the viewer's QoE, Hong and Won (2010) proposed the implementation of a packet scheduler algorithm, adjusting the time intervals between packets based on their signi fi cance. The signi fi cance is de fi ned as the importance of a packet to the image reconstruction and is obtained through analyses of the conse-quence of loss for each pixel transported by the packet, consider-ing the GOP structure. This concept was applied to implement a packet scheduler called the Signi fi cance-Aware Packet Scheduler (SAPS). With SAPS the packets with higher signi fi cance will take a longer inter packet time interval than the less signi fi cant packets.
From the network perspective, when the technique is applied, the resulting traf fi c has its burstiness modi fi ed. This allows routers to free up some space on their buffers before the next packet arrival.
The most signi fi cant packets wait a longer time to be transmitted and are likely to be preserved in case of network congestion. As a result, according to the authors, the QoE perceived by the viewers is improved. SAPS can also process the Explicit Congestion Noti fi cation ( Ramakrishnan et al., 2001 ) to collaborate with net-work congestion and discard the less signi fi cant packets to reduce the impairments to the QoE. The entire implementation of SAPS is done at the streaming server. The evaluation of signi fi cance requires payload processing, with high computational complexity, making it prohibitive to implement in routers.

An algorithm that combines packet scheduling and queue management is proposed in Huang et al. (2006) . The algorithm improves the transmission of video streams over networks with bandwidth constraints. Called Active Drop Queue (ADQ), the algorithm implements three distinct queues: one for the traf within the bandwidth limit (conformant queue), one for the traf exceeding the bandwidth limit (excess queue), and the last one for the best-effort traf fi c. Each packet in queue is associated with a time stamp. This allows the evaluation of an excess delay beyond a speci fi ed deadline where the transmission of packet is useless. In case of network congestion, the ADQ removes, from excess queue, the packets with its deadline expired, freeing the queue to receive new packets.

An active queue management algorithm based on priority dropping (PD) and a proportional-integral-derivative (PID) con-troller is proposed in Xiaogang et al. (2007) using the control theory, called PID_PD, which fi rst drops the least important packets when network congestion arises. The packet is marked by the application layer, writing the priority number to the priority fi eld of the IP packet. The B-frames receive the least priority and I-frames receive the higher priority. The results show that the schema can prevent the high-priority layer or frame from drop-ping, thus preserving viewer QoE in case of network congestion.
Another strategy to preserve viewer QoE in situations of net-work congestion is proposed in Schier and Welzl (2009) . The packet classi fi cation is based on macroblock distortion estimation, requires super fi cial decoding of the video bitstream, and takes in account important indicators such as the macroblock composition of frames, temporal dependencies and potential scene cuts. The results show an increase of perceived video quality by an average of 3  X  4 dB in terms of peak signal-to-noise ratio (PSNR).
A survey on methods for Internet traf fi c identi fi cation, using information available in the network layer to classify the payload of packets is presented in Callado et al. (2009) and Nguyen and Armitage (2008) . The goal of these methods is to identify the application protocol without relying on well-known TCP or UDP port numbers or processing the packet payload. The main applica-tions are in quality of service (i.e., different applications get different service from the network), fi ltering (i.e., threats/attacks can be blocked), and billing (i.e., per-application charging rates) ( Callado et al., 2009 ). The methods available for classi based on heuristics and use the time interval between packets, the size of packets, and the length of session as input. The effective-ness of classi fi cation varies greatly, depending on the application protocols and the real-time capacity of the method.

In this paper, we analyze the use of a selective packet discard (SPD) strategy to preserve the QoE in H.264 transmission over congested IP networks. The idea is to preserve the packets that carry more relevant information for image reconstruction in case of network router congestion. To implement the SPD, the packets of video traf fi c should be classi fi ed. The fi rst and natural alter-native is to perform the packet marking jointly by the video encoder and packetization components at the streaming server. This information can be stored as DiffServ Code Point (DSCP) in the IP header, eliminating the need to classify packets in the routers at real time. This strategy is possible if the network facilities and streaming server can be con fi gured jointly to collaborate. In some cases, however, the streaming server administrator cannot control the network facilities and vice-versa. In this case, one can imple-ment a strategy in the server or in the network routers, indepen-dently. SAPS was designed to be implemented at the server side, without the collaboration of network routers. Thus, in this paper we analyze two alternatives: (i) performing the packet classi tion and SPD at network routers using only information available at network layer  X  the goal is to investigate if this can be done without the cooperation of the servers, using arti fi cial neural networks (ANN) due to their low computational complexity, thus allowing their implementation in routers; and (ii) a collaborative setting, with servers marking the packets and routers implement-ing the SPD. The latter alternative was implemented as a perfor-mance reference and will be referred to as the golden standard . The main bene fi t is the preservation of the viewer's QoE in case of network congestion.

The rest of this paper is structured as follows. Section 2 describes the ANN topologies used for the packet payload classi-fi cation, the origin of the data set under study, and the classi tion results. Section 3 presents the proposed packet discard strategy. Section 4 shows the method evaluation for several network congestion scenarios. Section 5 presents the conclusions. 2. Packet classi fi cation
We choose to employ ANN to perform the packet payload classi fi cation, because ANNs are noted for being capable of solving complex problems of forecasting and recognition of time series and can be implemented in real-time systems because of their low computational complexity. According to Basu et al. (2010) , ANNs provide a suite of nonlinear algorithms for feature extraction and classi fi cation, and can be ef fi ciently implemented in hardware, including the implementation of sigmoid activation functions ( Szab X  and Horv X th, 2004 ; Mishra et al., 2007 ).

Particularly in the case of video traf fi c encoded with H.264, with variable bit-rate characteristics due the variation of frame size, we expect that the training of the ANN is capable of capturing the characteristics of packet fl ow and relating these with the type of frame they carry.

As a basic premise, the video streams should be pre-classi in separate queues, as illustrated in Fig. 3 . This pre-classi could be implemented based on IP address and port numbers. The effects of misclassi fi cation at this stage are not analyzed in this paper. However, a misclassi fi cation at this stage would negatively affect the proposed method. We consider the development of methods to prevent this problem a topic of future work, because we are interested in fi nding out whether it is possible to imple-ment a packet classi fi er with ANN associated with an SPD mechanism exclusively on routers.

Several approaches have been proposed to model MPEG traf fi ( Dai et al., 2009 ; Van der Auwera et al., 2008a , 2008b ; Klein Junior and Pedroso, 2013 ). The high variability of the video traf short-and long-range correlations, and the sudden scene changes make it dif fi cult to perform the payload classi fi cation with traditional methods. In this scenario, the use of ANN may be appropriate, because the training process can capture the char-acteristics of the system without the use of a particular traf model.
 through metrics known as false positives (FP), false negatives (FN), true positives (TP), and true negatives (TN) ( Nguyen and Armitage, 2008 ). TP is de fi ned as the percentage of members of class X correctly classi fi ed as belonging to class X and TN is the percentage of members of other classes correctly classi fi ed as not belonging to class X. FN and FP are given respectively by 1-TP and 1-TN. packets carrying I-frames, avoiding to discard them and (b) X carrying B-frames, which would be the fi rst to be discarded in case of network congestion. With approach (b), the false negatives could be packets carrying I-frames or P-frames, and they would be prioritized to be discarded. With approach (a), the false negatives could be the packets carrying the P-frames or B-frames, and they would be preserved from discarding. As our goal is to preserve I-frames because their importance to image decoding, we choose approach (a). Thus, X represents the packets carrying I-frames.
 between packets,  X  k A R , and the packet sizes,  X  k A N n within a past time window with N observations. The index k represents a particular observation. Therefore, the input consists of considering the two input variables and the window size. x  X  1and x  X  0 represent respectively the presence and the non-presence of a packet carrying an I-frame in the input window. As x is a real number, it will be used as a con fi dence level of the ANN output.
 dually, and one can observe that, with our proposal, achieving a true positive classi fi cation of 100% would be almost impossible due to the uncertainty about the type of all packets in the window. In a approach, we attempted to identify the packets individually.
We realized, however, that it would be very dif fi cult to achieve a good success rate this way. Nonetheless, considering the application, the queue sizes, and the maximum packet loss to the video decoding still being possible, we realized that a false positive identi acceptable,aslongasasuf fi cient number of packets transporting
B-and P-frames were marked as priority candidates to discard. Thus, the ANN topology was designed to improve the chances of success in the identi fi cation of packets carrying I-frames, without much pre-occupation with false negatives, since this approach improves the percentage of true positives. 2.1. On the use of ANN to packet classi fi cation prediction and identi fi cation of time series: feed-forward (FF), cascade-forward (CF), feed-forward with tapped delay (FFTD), radial basis (RB), general regression (GR) and Elman recurrent with tapped delay (ERTD) ( Principe et al., 1999 ). We choose to employ two neural networks topologies: (i) FFTD and (ii) ERTD, mainly due to the simplicity of FFTD and the good results reported for ERTD in time series recognition ( Abdennour, 2006 ). networks FFTD and ERTD. Both architectures have 2 N inputs, one hidden layer and one output layer with one neuron whose output reports if the packets within window N carry I-frames or not.
Additionally, ERTD has a context layer with the same number of neurons of the hidden layer. The number of neurons in the hidden layer was established by the arithmetic average between the number of inputs and outputs,  X   X  2 N  X  1  X  = 2  X   X  N .
For the neural network training, the video coded data were split into two sets. The fi rst consisting of 70% of the total, was used for training; the remaining 30% was used for the validation.
According to Haykin (1998) , in practice, the training can achieve a good generalization with training set T given by T  X  O  X  where W is the total number of free parameters (i.e., synaptic weights) of the network, E denotes the fraction of classi errors allowed, and O  X  X  denotes the order enclosed within. Considering the worst case for neural network topology, for the
ERTD network, the number of free parameters is given by 3 N 2  X  2 N , where N represents the window size. Considering the use of N  X  12, which is the maximum GOP length for this video and the maximum value for N , the training set has 6543 situations and the fraction of errors allowed for Salesmen video can be calculated as E  X  6.9%. The error for all other videos is lower than this, what ensure a good generalization for all training.

The window size N is fundamental to the success of the classi fi cation. If N is lower than the number of packets necessary to transport an I-frame, the neural network cannot recognize the presence of an I-frame due to the lack of input data. If N is greater than the GOP size, the window will necessarily contain an I-frame, making the planned approach worthless, because the output of the neural network would be always 1.

Thus, tests were performed using N greater than the minimal number of packets to carry an I-frame and lower than the average number of packets of the GOP. With these restrictions, we seek the smallest possible window size N . 2.2. Data source The videos employed for the tests are publicly available at
Video Trace Library (2012) , with resolution of chrominance sub sampling of 4:4:4, resolution of 352 288 pixels and 25 fps. The GOP con fi guration was (12,2). Other authors have often used these videos in the study of image and transmission systems, as in Greengrass et al. (2009) , Van der Auwera et al. (2008b) , Abdennour (2006) and Bouras et al. (2009) . All videos were encoded with H.264 through the use of the ffmepg ( Niedermayer, 2012 ) tool, which is also publicly available. The ffmpeg tool allows the adjustment of several parameters, such as the GOP con tion, image size, quality/compression, and frame rate, among other settings.

Table 1 summarizes the main video characteristics, showing total and average frame sizes, and total and average packet sizes. The videos were chosen because of their characteristics, ranging from static to dynamic images, resulting in several levels of traf burstiness. The movies Star Wars Ep. IV (SW), Jurassic Park (JP) and Silence of the Lambs (SL) were included to provide a range of different behaviors, caused by scene changes.

As the movies have a large length, they were separated into smaller sets, typically two minutes long, to facilitate the analysis and reduce the computational effort to evaluate the results. The subsets were named JP, JL, SW-1, SW-2, and SW-3; JP, JL, SW-2, and SW-3, represent scenes with moderate motion whereas SW-1 has sudden scene changes, which is the worst case for the packet SW-1, SW-2, and SW-3.

To collect  X  k and  X  k , the videos were transmitted over a non-congested Ethernet network, and the data were captured with traf fi c monitoring tools tcpdump ( Richardson and Fenner, 2012 ; Wireshark, 2012 ). 2.3. Training and validation of classi fi er The training and the validation of ANNs were done with the Java Neural Network Simulator (javaNNS), developed by Wilhelm-Schickard-Institute for Computer Science ( Fischer et al., 2001 ). The javaNNS was chosen because of its reliability, the large number of available topologies and training algorithms supported, and the ability to generate source code in C language, facilitating the later implementation of the queue simulator.

The neural networks were trained with the Backpropagation algorithm. During the training process using this algorithm, the network operates a sequence of two steps. The fi rst consists in presenting a set of patterns to the network input. Data are processed and fl ow through the network, layer by layer, until the response is propagated to the output layer. This procedure is called the forward propagation phase. In the second step, the ANN output is compared with the training data set. If the outputs values are not equal, the error is computed and propagated from the output layer to the input layer, changing the values of the connection weights of internal layers of the network. This procedure is known as the backward propagation. The Error
Backpropagation algorithm is the most famous among the learning algorithms, being particularly useful in cases of large training sets with many similar examples ( Zell et al., 2011 ). The parameters of the training algorithm are dmax , i.e., the maximum difference between target value and the value obtained by the output of the neuron, and  X  , i.e., the learning rate. Typically, dmax should range from 0 to 0.2, according to the desired error, and was set at 0.01 to get a small error. The  X  parameter indicates the step size for the adjustment of synaptic weights between neurons connections for each training cycle. The lower the learning rate, the lower the adjustment of synaptic weights, which will provide a gradual update of the weights, but a considerably longer time of training.
Thus, increasing the learning rate will result in the acceleration of the training time, but the adjustment in the weights between connections will be more signi fi cant. The learning rate parameter was set to 0.1. This was done because the time for training is not critical for the application under consideration and the training is performed of fl ine. The amount of training cycles was set to 50,000 due to the observation of a signi fi cant reduction in error after 5000 training cycles. All neurons were con fi gured with the sigmoid activation function, which has many interesting features, including its capacity to capture the non-linear characteristics of the process ( Principe et al., 1999 ). 2.4. Classi fi cation results
This section shows the results of the tests employing the ANN topologies described in Section 2.1 . The window size was con ured with size of N  X  15, 25, 35, 45, and 55, for Coast-Guard ,
Highway , Bridge Far , Paris , and Soccer . For SW -1, SW -2, SL , and JP , the window size was con fi gured with N  X  10, 13, 16, 21, 24, and 27.
The window size N was chosen due the GOP structure of the videos, the average number of packets to carry an I-frame and the
GOP, and considering the maximum transfer unit (MTU) of 1500 bytes. Suppose the average number of packets for transport I-, P-and B-frames are denoted by  X  I ,  X  P , and  X  B , respectively.
Coast-Guard , Highway , Bridge Far , Paris , and Soccer present  X  10 and  X  B  X  10. SW -1, SW -2, SL , and JP present  X  I  X   X  5 and  X  B  X  3.

Tables 2 and 3 show the percentage of true positives for the videos Coast-Guard , Highway , Bridge Far , Paris and Soccer , for the training sets, for the FFTD and ERTD topologies, respectively. These results show that the FFTD and ERTD topologies could be trained with a good degree of accuracy. It is possible to see the growing of true positive percentage as N increases. The poor performance of
N  X  15 can be seen as well, because it is the average number of packets necessary to carry an I-frame in those videos, and the neural network does not have an enough number of parameters to identify the transition between frames. With N  X  25, the training achieves a true positive percentage average of 98.2% and 94%, for
FFTD and ERTD, respectively. The N  X  25 should be enough to obtain a suf fi cient number of packets eligible to discard, as the average packet number of the GOP is 125 packets. The use of a larger window size implies a reduction of the number of packets identi fi ed as non-I, decreasing the number of packets eligible for discard in case of network congestion.
 videos Coast-Guard , Highway , Bridge Far , Paris , and Soccer , for the validation sets for the FFTD and ERTD topologies, respectively. For
N  X  25, FFTD achieves an average of 55% and ERTD 58%. However, considering the larger windows, the performance of ERTD was consistently better than FFTD. The hit rate in the validation set is compatible with the classi fi cation results reported for the IP traf classi fi cation methods.
 as the videos presented before, with 70% for training and 30% for validation. For the SW-3, however, we took another strategy: SW-3 were used only for validation, with the ANN trained with the SW-2 set. We are interested in whether a trained ANN can produce good results in the classi fi cation of an arbitrary movie subset. Tables 6 and 7 present the true positive percentage for training SW -1, SW -2, SL ,and JP for the topologies FFTD and ERTD, respectively. From N  X  16, both ANN topologies could be trained with good results: the averages of true positive were 99% and 97%, respectively. The results show a better performance for larger window size, as in the videos before.
Tables 8 and 9 present the true positive percentage for the validation sets of movies, as well as the true positive percentage for SW-3 submitted to an ANN trained with SW-2. SW-1 presents sudden scene changes, and the classi fi er achieves 58% of success for N  X  13 for both FFTD and ERTD. For the more regular scene pattern of SW-2, SL, and JP, the true positives using FFTD for
N  X  13 were respectively 68%, 64%, and 58%. Using ERTD with
N  X  13, the true positives were respectively 71%, 63%, and 67%. The average performance of the classi fi er for SW-3 with N  X  64% and 71%, for the FFTD and ERTD, respectively. For SW-3, with
N  X  27, FFTD and ERTD achieve 95% and 100%, respectively.

It is important to notice the increasing hit rate with larger window sizes. This behavior was observed in all validation sets. One can observe in Tables 8 and 9 that the averages considering all movies are quite similar for FFTD and ERTD, varying from 58% with N  X  10 to 78% with N  X  27.

As the minimum size of the window is speci fi ed by the number of packets carrying I-frames and the maximum size is limited by the number of packets in the GOP, we suggest the use of the following relation for determining the window size: N  X   X  I  X   X   X  A  X  P  X  B  X  B  X  ; 0 o  X  o 1  X  1  X  where  X  I ,  X  P and  X  B represents the number of packets, on average, to carry I-, P-and B-frames, respectively. A and B represent, respectively, the number of P-and B-frames of GOP. The results suggest good performance of classi fi cation with  X   X  0 :
The video salesman was employed to compare the results with a different quality and GOP con fi guration. The video coding was made in the same way as performed in Hong and Won (2010) . We employed a window size of 7, 8, 9, 11, and 12. Table 10 presents the results for training and validation, which indicate that the classi fi cation could be performed with a good true positive percentage -for instance, with N  X  8, the true positive is 97% for FFTD and 93% for ERTD. 3. Selective packet discard
The Packet Discard Algorithm (PDA) manages the queues of a network element and is responsible for discarding the packets in case of queue congestion. Among the available queue management methods, the most known is the drop tail. The drop tail is a simple queue management algorithm: when the queue is occupied to its maximum capacity, the newly arriving packets are discarded. Other popular options are Random Early Detection (RED) and Weighted RED (WRED), which could drop packets even before the queue is totally fi lled, as a warning to the congestion control mechanisms on the traf fi c sources, to reduce their transmission rate and help the network. However, only protocols like TCP (Transmission Control Protocol) and SCTP (Stream Control Trans-mission Protocol) are able to dynamically adjust its transmission rate based on the packet loss rate. Time-sensitive applications, as video streaming, often use UDP (User Datagram Protocol) because dropping packets is preferable to waiting for delayed packets. None of these can perform a selective packet discard based on information of application. The performance of H.264 with active queue management (AQM) was investigated in Torres et al. (2012) .
We propose a priority packet discard mechanism to drop packets according to the classi fi cation made by the ANN. The method has three steps: 1. The time between successive arrivals of packets and the size of the last N packets received are stored and used as input of the ANN.
 2. Packet classi fi cation is performed according to the output of neural network, x k .If x k 4 Lim 1 the presence of packets carrying information about an I-frame is assumed, and in this case the packets will be marked as green . The mark is done in an auxiliary data structure, without changing any values in the
IP header. If x k o Lim 2 , it is assumed that the packets in the window do not carry information about I-Frames and they will be marked as red . If the output is in the range Lim 2 r x , the packets will be marked as yellow . 3. If the queue capacity reaches its limit, the proposed method discards the red packets fi rst, then the yellow, and fi nally the green. In the tests, Lim 1 and Lim 2 were con fi gured, respectively, with 0.1 and 0.9.

In the method we propose, the computational complexity depends almost on the packet classi fi er, which has the worst-case computational complexity given by O ( n ), n being the window size. 4. Results
The ef fi ciency of the proposed method was measured through a queue simulator, developed in C language, to evaluate the perfor-mance of a queue fed by real traf fi c. The queue simulator was carefully validated by comparing the results with known analytical models, as indicated in Banks et al. (2001) , accordingly the
M =
M = 1 = 1 and M = M = 1 = B queue systems, and the simulated results are consistent with the analytical models.

In the fi rst test, the bottleneck link rate was con fi gured at 90% of queue utilization and the maximum queue size was varied.
In this case, the burstiness of video could cause packet discard for a limited length of time. In the second test the queue depth was kept constant and the queue utilization varied. For all tests, the number of discarded packets carrying I-frames was observed and compared with drop tail and the golden standard. The golden standard represents the best possible performance in a given network congestion situation.

The mean opinion score (MOS) is a subjective evaluation of the quality of a video transmission; it depends on the impression a human observer has on the delivered video, as described in ITU-T recommendation BT 500 ( Recommendation ITU-T BT.500, 2012 ). The MOS is one of the most commonly used metrics to estimate
QoE and is expressed by a number, 1 being the worst and 5 the best perceived quality. In contrast, objective video quality metrics are calculated by computers. The most relevant metrics in the area of video quality assessment are PSNR and Structural Similarity (SSIM) ( Serral-Graci X  et al., 2010 ). Recent results show that SSIM presents better approximation of human subjective evaluation of quality ( Silpa and Mastani, 2012 ). However, we need to evaluate the relative quality, allowing comparison of between golden standard , drop tail , and the proposed method. A study presented in Hore and Ziou (2010) indicates that both PSNR and SSIM are capable to capture the degradation of video quality, and that a simple analytical link exists between the PSNR and the SSIM. Thus, the simple metric of PSNR is still adequate to compare the ef fi ciency of proposed method and will reduce the computational overhead of quality evaluation.

Thereby, MOS was estimated employing the Evalvid tool ( Klaue et al., 2003 ). The Evalvid compares the original video image with the video received to estimate MOS, through the evaluation of
PSNR. The PSNR is calculated frame by frame using the mean squared error (MSE) given by
MSE  X  1 rc  X  r
 X  where r and c represent, respectively, the number of rows and columns of image, Y o  X  i ; j  X  and Y r  X  i ; j  X  represent the luminance of pixel  X  i ; j  X  of original and received frame, respectively. The PSNR can be obtained using PSNR  X  20 log 10 MAX I ffiffiffiffiffiffiffiffiffiffi where MAX I represents the maximum value of pixel intensity. For the videos in consideration, MAX I  X  255.
 convention presented in Table 11 . The PSNR of video was com-puted with an average of PSNR of all video images.
 server, in cooperation with the application, was also implemented. In case of network congestion, the SPD fi rst drop packets carrying
B-frames, followed by packets carrying P-frames fi nally packets carrying I-frames. This strategy was implemented as a reference and is called the golden standard.

I-frames dropped as a function of maximum queue size, with link utilization of 90%, for the videos Highway and Bridge Far . For each fi gure, three lines are presented: for the proposed method, drop tail, and golden standard. The proposed method presents a better performance than drop tail for both videos. Fig. 6 (c) and (d) presents the MOS evaluation for the same videos. It can be seen that the method prevents QoE degradation, e.g. drop tail achieves a MOS of 2.8 and the proposed method 4.5 when queue size is 6000 bytes for the video Bridge Far . For the golden standard, the packets carrying I-frames were preserved and the degradation of
MOS is consequence of delay and jitter. Additionally, when the queue depth increases, the performance of the proposed method approaches the golden standard.
 percentage of packets carrying I-frames discarded and the MOS evaluation for several queue utilization levels, with a fi size, for the video Highway . The proposed method outperforms drop tail in all cases, preventing I-packets from being dropped and thus increasing the MOS.
 the movies subsets SW-1, SW-2, SW-3, SL, and JP. These movies have different characteristics from the other videos analyzed earlier. The sudden scene changes of movies cause variation on the frame sizes, decreasing the ef fi ciency of the classi subsets were submitted to the queue simulator. Fig. 8 shows the percentage of packets carrying I-frames discarded for each subset with several values of queue maximum queue depth, for utiliza-tion of 90%. In all cases, the ANN achieves a good success rate in preserving the packets carrying I-frames, with a performance similar to that of the golden standard for the higher values of queue depth. Fig. 9 shows the MOS estimation. The MOS improved for the SW-1, SL, and SP, respectively, presented in Fig. 9 (b)
For the SW-2, with sudden scene changes, the method seems to have a worse MOS than drop tail, as shown in Fig. 9 (a). However, the ANN was actually able to identify the packets carrying
I-frames, as presented in Fig. 8 (a). With the sudden scene changes, the P-and B-frames become important because the aggressive changes in scenes decorrelate the fi rst image of GOP with subsequent images, and in this case, the proposed SPD strategy does not bene fi t the quality of experience.

The ANN previously trained with SW-2 was employed to verify the feasibility of using a standard trained ANN to traf fi tion. The transmission of SW-3 subset was simulated. Fig. 10 (a) presents the percentage of packets carrying I-frames discarded and Fig. 10 (b) shows the MOS evaluation for this case. The results show an improvement of MOS compared with drop tail, with good results for N  X  13. In order to extend this test we randomly selected two sequences from Star Wars Ep. IV. Both sequences are 2 min long. The percentage of packets carrying I-frames discarded is shown in Fig. 11 , respectively, for the two sequences. Its possible to see that ANN successfully preserves from discarding a good number of packets carrying I-frames, and this results in an improvement of QoE. This indicates that it is possible to employ a standard trained ANN to implement the strategy in routers.
Even if the buffers of routers are large enough to avoid dropping packets, a deadline could be establish for the transmis-sion of each packet in queue, and the packets that exceed this deadline could be considered lost. From this point, the proposed method can be applied.

Another important result is the performance of golden stan-dard. For all scenarios, the estimated MOS was greatly improved for golden standard, and this indicates that the use of this method is possible to provide a good quality with higher network utiliza-tion levels. This implies in lower infrastructure costs for video transmission networks if compared to the scenario where the proposed method is not used. Additionally, the use of the golden standard should be preferred compared to the method using classi fi cation with ANNs. However, in the situations where it is not possible to perform the jointly con fi guration required to imple-ment the golden standard, this alternative results in a performance improvement for the system. 5. Conclusions
In this paper we propose a selective packet discard strategy, at network routers, to preserve user QoE in case of network conges-tion. Even if the transmission network is well planned, packet loss can occur due the burstiness of video traf fi c. A packet that has exceeded its delay in a maximum threshold may also be consid-ered a loss.

The impact of packet loss on QoE can have several degrees of severity, depending on which packet is discarded. The most relevant packets are those that carry information about I-frames, because they are used by the decoder as references for decoding other frames. Thus, if the queue becomes congested and packet discard is unavoidable, the preservation of these packets leads to a better QoE. The standard method for packet discard is drop tail, but this method is not aware of the payload of the discarded packet.

We proposed the use of neural networks to classify the packets using only information about their size and time interval. We simulated a priority discard queue where packets classi fi
I-frames are preserved and packages classi fi ed as P-and B-frames are preferably discarded. This resulted in an improvement of user perceived QoE. We showed how much improvement can be obtained in many videos used as examples. We also compared the video quality improvement due to neural network classi tion with the ideal scenario where all packets were correctly classi fi ed at the source. The proposed classi fi cation scheme can be performed with available information in network layer protocol, without the decoding of higher protocol layers.
 References
