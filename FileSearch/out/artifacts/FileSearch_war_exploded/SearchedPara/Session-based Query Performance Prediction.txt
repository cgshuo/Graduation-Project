 Search sessions are known to be a rich source of diverse valu-able information for individual query analysis. In this pa-per, we address the problem of query performance prediction by utilizing the entire logical search sessions containing the given query. Guided by the intuitions based on the observa-tions made after the analysis of the search sessions X  proper-ties and performance of the queries they contain, we propose a number of features that significantly advance the existing query performance prediction models. Some of them specif-ically allow to focus on tail queries with sparse click-through statistics.
 Categories and Subject Descriptors: H.3.3 [Informa-tion Search and Retrieval]: Search Process General Terms: Algorithms, Performance Keywords: query performance prediction, query flow graph, user sessions
The prediction of query performance has proven to be a very important tool for tuning retrieval systems. From the other hand it is established that users interact with a search engine not via a single query, but by the means of search sessions  X  sequences of queries unified by a common information need. There is a number of studies on predic-tion of session success or session termination. The major part of this research could be considered as an interesting counterpart to the search effectiveness estimation problem. Nevertheless it does not deal with the performance of an individual query.

Our paper is devoted to the analysis of dependence of query performance on different session characteristics and on the variance of its complexity over the session. This al-lows us to construct new powerful features for the prob-lem of query performance prediction and significantly im-prove state-of-the-art methods. It is important to note that new features considerably improve prediction accuracy for queries with sparse click data by extracting the evidence about their performance from the logical sessions they be-long to. To sum up, our main contributions include:
The rest of this paper is organized as follows. In Section 2 we discuss related work concerning query complexity predic-tion and session analysis. In Section 3 we describe explicitly the organization of our data, in 4 formulate and confirm ex-perimental observations. Features derived from the session data are described in Section 5. In the Section 6 we discuss experimental results and, finally, in Section 7 we conclude our work.
In the last decade it was realized that predicted query complexity provides valuable information for the search en-gine, so many papers addressing the problem were published. The paper [2] presents a model trained on the aggregated re-sult page features, such as mean BM25, PageRank etc. Au-thors study correlation of a linear regreesion model trained on various subsets of features: in particular click-based fea-tures proved to be the most important for the prediction of DCG of a query. In [4] authors solve the same problem (prediction of the final DCG@3) by applying a decision tree model learned on several types of features. They study con-tribution of each feature into the final model, and analyze accuracy of prediction for queries with different popular-ity. The types of implemented features include aggregated data from result pages, log-based user interactions features, query-based features. Again, click-based features are shown to be among the most important. The novelty of our ap-proach as compared with these methods lies in the employ-ment of session data for the similar task.

Substantial study of search sessions started several years ago. In the paper [8] Ryen White and Susan Dumais ex-plore and predict search engine switch. More precisely, they predict probability of a switch for a given session of a given user with the help of query-based, session-based and user-based features. We emphasize that sessions are derived sim-ply using temporal cut-off of 30 minutes. Similar problem is Figure 1: Average query performance over all ses-sions of the fixed length l . solved by Guo et. al. in [5], where authors classify all switch cases into several classes (dissatisfaction, coverage, user pref-erences) and learn a classifier for each class. The features employed could be divided into query-based, pre-switch and post-switch. Another field of research concerns the estima-tion of the probability of a user having his information need satisfied during a given session. In [6] the authors manually extract logical sessions ( goals ) and predict successfulness of a session. They build Markov models for successful and unsuccessful sessions with transition probabilities depend-ing on the time between events. The main subject in [1] is rather similar to the one in [6]: authors predict search success of a logical session. Implemented models for success estimation include Markov model and Conditional Random Field model and the latter outperforms the former.
There are several approaches for session extraction from raw query logs. The simplest one just uses some temporal cut-off (typically 30 min) and divides stream of queries into consecutive series. This method is rather popular for its simplicity, however it does not suit for our task since we need logically connected queries. So we use not only time constraints, but different features relying on texts of queries to identify logical sessions.

To be more precise, we follow the approach presented in [3] and construct a classifier to identify pairs of queries with the same or similar search task (e.g time in America now and time zone in USA ). By the means of this classifier we define a so-called query-flow graph , whose vertices V correspond to queries submitted by a given user and edges E join related queries. Connected components of this graph are logical sessions. If user reissues a query, we start new logical session and do not affect previous session. Following this strategy we gather logical sessions for 12K queries, i.e. there is at least one session for each query in the sample set. Here is an example of a possible session 1) CIKM 2012 program , 2) Hawaii CIKM , 3) Hawaii airplane .

Each logical session contains the following information: series of queries submitted by a given user, clicks on the URLs in the search results and dwell times for these queries and clicks. Each document, retrieved for one of original 12K queries has one of the five editorial labels: { perf ect, excellent, good, f air, poor } , whose corresponding Figure 2: Average query performance over all ses-sions of the length l , containing the query at posi-tion i . scores rel ( q, d ) are { 5 , 4 , 3 , 2 , 0 } , so for each initial query we compute DCG @ k score: to predict the DCG @ k of a query relying on various infor-mation including features derived from click logs.
Prior to presenting our method for predicting query per-formance we collect some statistics on the data provided by user sessions. This helps us to advance and verify some ob-servations on query performance across the session.

First, for all sessions of the given length 2 6 l 6 11 we compute average DCG @10 score of queries in these sessions. Intuitively more complex or poorly formulated queries cause longer logical sessions, since user continues her session until she gets dissatisfied or tired. In general, a long session indi-cates either high degree of user X  X  interest in the subject or its complexity for the search engine. Figure 1 justifies our observation: increasing the length of the session leads to the degradation of the average query performance.

Second, we collect information on change of query perfor-mance during one session. The situation in this case is not as clear. On the one hand, the user obtains new information by examining the result page, what might help to improve the next query. For example, too general or ambiguous query is easy to specify at the first sight on SERP. On the contrary, an overspecified query results in very few documents and that helps to reformulate the query. On the other hand, having obtained a partial answer to an original question the user can slightly change her field of interest and sub-mit a more complex query on a similar topic. Just the same terminal query in the session does not necessarily have the best performance in the session: the session could be given up due to the final degradation of the result page quality, though often termination of the query still indicates satis-faction of the information need. To understand which effects become apparent and outweigh on the real data we restrict our attention to the sessions of fixed length l and compute average DCG @10 score over i -th queries in these sessions (1 6 i 6 l ). Plots on Figure 2 demonstrate DCG @10( i ) curves for 3 6 l 6 7. We choose DCG @10 for the plot, since it could be considered as the most representative met-ric among DCG @ k , k = 1 , . . . , 10.
Information that could be extracted from these plots con-firms the expected existence of the relation between query complexity and length of sessions: the longer the session we consider the less its performance. Now we note that, accord-ing to the first assumption, query performance increases in the course of the session, i.e. usually users tend to submit less and less complex queries. Even the frequent pattern, when user gives up the search being frustrated, does not significantly affect the performance of the last query in the session.

These findings provide the evidence that even very simple information derived from sessions containing the given query has a potential to improve query prediction methods.
M BM 25 Maximal BM 25 score of the retrieved doc-
Existing solutions of the query complexity prediction problem usually belong to two classes.. Approaches of the first type use all available information including all docu-ment features (e.g. BM25) and are evaluated offline. Scores of this type are used for estimating the overall search engine performance, for offline evaluation of the quality of rank-ing algorithms and tuning various parameters of the sys-tem. Approaches of the second type use only information available at the pre-retrieval time and require efficient pre-diction algorithms. For instance, these scores could be used for implementation of different retrieval and ranking strate-gies for queries of various predicted performance. See [7] for the detailed discussion. We focus on the prediction of the first kind, i.e. we use result, query and interaction-based features. However, our session-based features fit into the second approach as well.

The features we construct could be divided into two classes: session statistics , i.e. information aggregated over all sessions containing a given query q , and features built using query-flow graph based propagation , i.e. information appro-priately gathered from the neighbouring queries of q in the query-flow graph. All features are listed in Table 1.
We start with features based on session statistics. Av-erage click position for a given query was shown in [4] to be very important for query performance prediction. So we expect that its session analogue  X  mean reciprocal rank of all first clicks in queries co-occurring in one session with a given query carries a strong signal. Statistical observations reported in Section 4 provide some evidence for importance of the average session length and the average position in the session as features describing given query. Moreover, we compute several time-based statistics, e.g. the fraction of the session duration spent on the given queries: usually user quickly reformulates ambiguous or ill-formed queries and continues the logical session.

Now let us discuss in detail the features based on the query-flow graph. Information extracted from the user X  X  ac-tions on the result page is known to be very useful for various problems in information retrieval and, in particular, for our task. However, this data is rather noisy and absent or sparse for a large part of the query stream. This drawback of click data motivates the search for new sources of similar data and development of some methods for noise filtering in click logs. We propose a technique for extracting and smoothing user-interaction-based features for queries with a few or no clicks. Let q be an arbitrary query; consider correspond-ing vertex in the query-flow graph. Let q 1 , . . . , q k -neighbours of q in the graph, i.e. all queries co-occurring in one session with q at the distance of 6 k queries. Then one may consider all clicks that were made on the result pages for queries q i as the clicks for a query q . For instance, the smoothed average click count per submission would be queries. Such propagation of click data along edges of query-flow graph allows to collect additional information for rare queries. The exact way of feature extraction heavily depends on the problem being solved: there is a number of ways of aggregating click data of adjacent queries. In the present pa-per we take k = 2 and just average user-interaction features over all k -neighbour queries.All these methods fit in a gen-eral graph random-walk model. Given a query-flow graph we associate each vertex (query) with some initial feature value, each edge with some weight (e.g. relatedness of cor-responding queries) and start random walk with certain pa-rameters to spread the initial features across the vertices of the graph. In many cases the resulting features carry some new information as compared with the initial ones. Since in our setup we are dealing with pre-collected logs, we use not only preceding queries, but all subsequent queries as well. Figure 3: Actual DCG@10 score vs. predicted.
 Table 2: Decrease of mean square error of DCG @ k predictor learned on various sets of features as com-pared with the baseline (all differences are statisti-cally significant with p -value &lt; 0 . 01 ).
Performance of the session-based features described in the previous section was studied using the set of 12K queries with known DCG @ k score. We have chosen query-based, user-interaction-based and result-based features combined together as our baseline, since they were already presented in the paper [4] and demonstrated the best performance for the similar task. We use multiple additive decision tree model (MART) as a machine learning algorithm. By minimizing mean square error of the predictor on the data described in Section 3 we test various sets of implemented features. The relative MSE decrease using 10-fold cross-validation is reported in Table 2. Columns in the table correspond to the models learned on three sets of features: baseline features + all session features, baseline features + session statistics fea-tures, baseline features + query-flow graph based features.
Interestingly, the performance of our method almost does not depend on the chosen metric, though intuitively click-based features reflect mostly quality of several top result and estimation of DCG @ k for a larger k should be more complicated.

The resulting function is represented on Figure 3: each point corresponds to a single query and its coordinates are real DCG@10 score and the predicted score (so ideally all points should lie on the line y = x ), actual values are nor-malized into a [0;1] segment.

As in the previous papers [2],[4], user-interaction features have shown the best performance. Query popularity QP turned out to be the strongest feature according to the con-tribution to the final predictor, though in [4] feature simi-lar to average reciprocal rank RR has maximal importance score. Probably its importance is reduced, since its session analogues ( SRR and QF G RR ) somewhat weaken position-based features. For example, session reciprocal rank SRR outperforms other session-based features and is ranked at the 6th position among all features.
We have presented a method for incorporating session-based features into the model for query performance predic-tion. User interaction data was already known for providing very powerful features for tasks of this kind, however gener-ally it is sensible only for the queries with sufficient amount of click data. Use of logical sessions allows to reduce this threshold and construct reasonable features in the case of insufficient ordinary click data. In addition, the data ex-tracted from various statistics aggregated over all sessions containing the given query turns out to be a source of valu-able query features. We plan to continue our research in two directions. First, we are going to construct a statistical model explaining behaviour of query performance along the session, second, we plan to develop some methods for accu-rate propagation of click data along query-flow graph and improve the approach presented in this paper.
