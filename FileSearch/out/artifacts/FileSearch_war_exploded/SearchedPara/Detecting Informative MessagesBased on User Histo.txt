
Chang-Woo Chun 1 , Jung-Tae Lee 2 Seung-Wook Lee 1 ,andHae-ChangRim 1 Regarded as one of the most popular social networking services, Twitter, is becoming a new media where people communicate with each other, and dissemi-nate news [1]. Recently, Twitter has become an alternative source of information, and has also inspired many researchers to develop methods for discovering use-fulposts,knownas tweets , from huge amount of data that it serves. However, most of tweets produced everyday are gen erally not worthwhile to read, because many people use the service mainly for daily chattering and posting their status updates [2]. Some previous studies propose to use retweeted number of the tweet as a measure of the tweet X  X  importance [5]. However, Suh et al. [4] note that the users number of followers strongly affects the retweetability of tweets. And it means that important tweets posted by unpopular users have less chance of getting retweeted. For these reasons, detect ing generally informative tweets from the massive Twitter stream becomes a crucial task.

In this paper, we formulate the task into a binary classification problem, and investigate a wide spectru m of features to study which of them can effectively discriminate informative tweets from mundane tweets. The features used conven-tionally in related studies can be categorized mainly into three following types: 1) features from tweeting and retweeting pra ctices of users, 2) features from tweet texts, and 3) features from metadata of users. Additionally, we propose a novel set of features that we refer to as User Hi story features. Most of conventional features have a common defect which is the fact that they are affected by influ-ence level of users within the Twitter network. Our key idea behind leveraging User History is to normalize influence of individual user using tweets that they posted in the past. By analyzing how someones new tweet differs from his/her previous tweets, we can make a probabilistic prediction of its informativeness in a fair, quantitative way regardless of how influential the author is in the Twit-ter network. We demonstrate the effectiv eness of the proposed feature set, User History, on a Twitter dataset, by comparing them with conventional feature sets. There are several works in literature that aim at finding important messages in Twitter. Naveed et al. [3] apply document l ength normalization technique, which is important to measure the quality of existing web document, for assessing a short text quality in Twitter. However, it is not appropriate for tweets, since too short text do not have enough clues to fulfill information needs.

On the other hand, Sriram et al. [7] try to classify short texts with domain-specific features to overcome the data spa rseness problem. Their filtering-based method classifies incoming tweets by considering information of the author and features within the tweets. They show that authorship plays a crucial role in tweet classification.

In recent years, numerous studies have attempted to use message propagation across the social network. These approaches are assuming that widely spread-ing messages are important. Information propagation on Twitter is mainly per-formed via retweeting, which is a behavi or of a user taking a tweet someone else has posted and re-posting the same tweet to the user X  X  own followers. Retweeted number is the most simple and straightforward indicator for interest of users on a particular tweet [9], so some studies concentrate on predicting retweet-ability. Suh et al. [4] investigate the relationship of retweeted number against several features like the number of URLs and hashtags in a tweet, the number of followers and followees of the author and so on. They report that following relationships and the presence of URLs and hashtags are strong indicators for predicting retweetability. Hong et al. [5] observe that the features, such as user X  X  degree distribution and the fact whether a message has already been retweeted at least once before, contribute significantly to the classification performance.
Uysal and Croft [8] propose a new task which involves personalized tweet ranking. By considering retweeting preference of individual user, their method is adequate for specific users rather than g eneral users. Even though such approach is merely beyond the scope of this study which is identifying generally informa-tive tweets, we use their feature categories to group our features. There are four feature classes: author-based, tweet-based, content-based, and user-based.We ex-clude the last class, user-based, since it is introduced for perso nalized tweet rank-ing purpose. To summarize, the conventio nalfeaturesusedinpreviousworkscan be divided into three main categories which can be seen in Table 1.

While the studies mentioned above focus on investigating computationally measurable features, Andre et al. survey what people really want to read in Twitter using questionnaires [2]. Their surveys reveal that informative tweet is among the ones that users feel worth reading. This result strongly motivated us to develop a general framework for identifying informative tweets. The next section presents a clear definition of info rmativeness and our method to identify informative tweets in details. Our aim is to automatically detect informative tweets as valuable messages. This task is simply formulated into a binary classification problem, determining whether a tweet is informative or not. To define informative tweets, we follow the work of Ni et al. [6] that investigates informative articles in blogs. Although the approach they propose is not suitable for directly processing tweets with extremely short lengths, their concept o f informative articles can be applied to tweets. We adapt their definition of informative articles for our classification. To identify tweets effectively, we propose a new feature class, User History, and we show how it works on detecting informative tweets.
 3.1 Definition of Informative Tweets To define informative articles, Ni et al. [6] process surveys which topics and what kind of contents people prefer to read. A ccording to their survey, informative articles are those which have contents of certain specific genres. Since the concept of informativeness is invariant, we define informative tweets based on their work. The contents of informative tweets include following genres:  X  News  X  Technical descriptions  X  Commonsense knowledge  X  Objective comments on the events  X  Opinions We bring their definition almost as it is, with slight modification in details to fit characteristics of social networkin g services. All genres presented in their work are also used in this study. As recency is the most important characteristic in News X  genre, not only fresh news tweets but also urgent news tweets are considered as informative tweets. Twitter allows users to post only 140-character-long messages, which are called tweets. Because of the length limit, a tweet can hardly contain enough information, especially in case of two genres, Technical descriptions and Commonsense knowledge. Thus, we additionally take web pages linked by URLs as well as text in tweets into account to determine whether the tweet is informative or not. We add Op inions genre because many recent works on tweets consider opinions as another type of information [7]. In our work, in order to detect generally informative m essages, tweets of Objective comments on the events or Opinions genres are treated as informative tweets only when they refer to serious social problems or hot issues.

While building data for our experiments, annotators were asked to read each tweet and first, decide whether it belongs to one of these five predefined genres. Even if, it belongs to one of the genres, annotators could have marked it as not informative in case it has too short text to contain sufficient information or to understand without any specific background. For example, in spite of hot issues, a tweet,  X   X   X   X  X  !! X  (earthquake in Japan!!), is regarded not informative because its text is too short text and does not have any further information, such as links to news articles or pictures. In contrast, the tweet,  X   X   X   X  X   X   X   X   X   X   X   X   X   X   X  !  X   X   X   X   X   X   X  X  X   X   X   X   X   X   X   X  http://yfrog.com/gyhobshj(nuclear power plants collapsed by Japan earth-quake! This link shows you the impact of radiation on the human body. http://yfrog.com/gyhobshj), was marked as informative. 3.2 User History Features To estimate informativeness of a tweet , we devise a new feature class, namely User History, with novel cha racteristics derived from the tweeting behavior of users. It consists of two categories of fea tures: Distinctiveness of tweets and User tendency. We descript these categories with motivations and roles in the next subsections. The whole features of User History class are shown in Table 2. Distinctiveness of Tweets. Since informative tweets are considered as the most worthwhile tweets to read, they w ill receive far more attention from other users than the users mundane tweets. Other users interest in a tweet is shown through Retweets 1 , Replies 2 , and Repliers 3 of that tweet. Therefore, between informative tweets and not-informative tweets would be distinct differences of Retweets, Replies, and Repliers. We utilize these differences as features to classify tweets.

The level of attention which each user attract from others is various. From crawled Twitter corpora, we can obtain i ndividual user X  X  tweeting records, such as Retweets, Replies, and Repliers. Our premise is that these records reflect how the community of Twitter users perceives the informativeness of individual tweets. However, to estimate influence of individual user, it may be not fair to directly use sheer statistics of Retw eets, Replies and Repliers without any processing, since less influential users tend to receive fewer responses on their tweets. It is why we model each users influence by using tweets that he/she posted in the past.
To model each users influence, we define a users history as a set of the entire tweets which belong to that user. Since ea ch users history contain the statis-tics of Retweets, Replies, Repliers and Length 4 , it is possible to calculate each users means and variances of Retweets, Re plies, Repliers and Length. Assuming that the statistics of each element (Retweets/Replies/Repliers/Length) follows a normal distribution, we can construct multiple Gaussian functions as mod-els of users influence. These functions provide important features for measuring distinctiveness of an incoming tweet, s uch as the deviation of Retweets and the probability of Length.
Figure 1 shows shapes of each users history model and how they work. There are four different normal distribution graphs of four users who have different means and variances of Retweets. When each tweets Retweets is regarded as a random variable x , from each users history, we can build a Gaussian function of Retweets using the following equation: To measure the distinctiveness of a new t weet, we can easily calculate its devia-tion and probability to use the Gaussian functions of the author. When we are supposed to compare the distinctivenes s of different users X  tweet, we transform each user X  X  normal distribution functions into the standard normal distribution through the following equation: As shown in Figure 2, when four tweets R etweets are all 5, user#2 X  X  tweet has higher probability than those of user#3 and user#4. It indicates that even when tweets Retweets are same, distinctiveness of tweets can differ because of the authors different influence. In case of the high influential users like celebrities, among their tweets which are usually retweeted a lot, only the extraordinarily retweeted ones show the distinctivene ss. These procedures allow us to directly contrast different users tweets through es timating personalized distinctiveness. In other words, our method can normalize influence of individual user on tweets.
There is an exceptional case, users wi thout posted tweets. In this case, we cannot build normal distribution models. For users who have empty users his-tory, we initialize all values of features in User History class to be 0 to prevent erroneous learning and predicting while the distinctiveness of a new tweet is estimated.
 User Tendency. We have discovered the fact that specific users, such as mass media, frequently post informative tw eets. Also there are certain users who al-ways retweet informative tweets. There are fairly distinguished from general users. Above facts can be helpful to identify informative tweets. So, to capture tendencies of users tweeting, we additionally leverage several features which are associated with individual u sers tweeting behaviors.

First, we assort tweets into three type s: Normal, Retweeting, and Replying tweets. Normal tweet means a tweet wri tten by user him/herself in an open space. Retweeting tweet means a tweet wh ich user has retweeted someone elses message, and Replying tweet is a tweet written to reply someones tweet. Each user has various tweeting behavior. Ge nerally, Twitter accounts of the mass media post news and issue tweets deemed as informativeness. But they do not post Retweeing or Replying tweets. Some users called social hubs usually retweet informative tweets, nonetheless hardly w rite their tweets. Although chatty users post a lot of Normal and Replying tweets, almost the whole their tweets are not retweeted. So we propose some proportion al features representing which types of tweets are mainly posted and which ty pes of tweets are mostly retweeted and replied. All of the features in this category are shown in Table 2. 4.1 Dataset and Training Instances We conduct our experiments on Korean Twitter dataset collected from Novem-ber 2010 to March 2011. The whole dataset contains 337,028,356 tweets and 3,662,778 users.

Though we first had randomly picked samples from the entire dataset to build training and testing instances, we found that the portion of informative tweets was surprisingly low; only 0.5% of randomly sampled tweets were judged to be informative by human annotators. As it is very challenging to learn a useful classifier when training data is highly skewed, we need to use alternative sampling method in order to increase th e proportion of informative tweets. By our intuition, we devise a simple sampling algorithm like the following formula:
Priority ( x )=# Retweet ( x )+# Reply ( x )+# Replier ( x )+# URL ( x )+ where x denotes a tweet .

First, all the tweets were ranked in descending order of the priority. Then three annotators were asked to determine the informativeness of the top 1,000 tweets. Tweets are labeled in a way tha t more than two annotators agree. The average of each annotator agreement is 0.86 and over.

With this sampling method, we could get a result with much higher portion (21.7%) of informative tweets. Among the 1,000 labeled tweet instances, the 200 most recently created tweets are chosen as a testing set whereas the remaining tweets are used as a training set. The portions of informative tweets in the training set and testing set are 20% and 29%, respectively. We build User History models to gather four-month X  X  data of the users. For experiments, we use the maximum entropy model as the classifier. 4.2 Informativeness Classification and Ranking We investigate the usefulness of each conventional feature set separately, and then integrate them as a unified baseline. Our proposed method is the com-bination of the baseline features and the selection of features in User History class. To select useful features from User history, we arrange them in descending order of an absolute correlation coeffici ent between feature values and classes in the training set, and chose features over the threshold (0.3). Our selection shows the highest classification performance on 10-fold cross validation in the training set. In User History class, the d eviation of Retweets and standardized Retweets especially play a key role in cla ssification perfomance, with more than 0.4 correlations.

We have experimented on the testing set with each conventional feature classes, the unified baseline, and the proposed method in order to know how much each method is helpful for classifying informative tweets. Table 3 shows the classification performance. We use A ccuracy, Precision, Recall and F1 as evaluation metrics.

On the classification task, proposed method outperforms almost all of mea-sures. As we can see, Message class is con siderably helpful for precision, and shows strangely better performance than a baseline that includes it. We expect that this is because user influence interferes while retrieving some tweets written by unpopular users. Even though our method shows slightly low performance than the message class in terms of precision, our method significantly improves recall. Compared to the bas eline, proposed method im proves Accuracy, Preci-sion, Recall, and F1 by 8%, 7%, 45% and 27%, respectively. These results mean that User History features, such as deviations of retweets and replies, are par-ticularly helpful to find candidates of informative tweets.

We also have conducted more experiments in terms of ranking to evaluate the effectiveness of method for detecting inf ormative messages. For ranking, we sort tweets by descending order of the probability given by the maximum entropy classifier. Precision@k, R-Precision, and Average Precision are used as evaluation measures. Since there are 58 informativ e tweets in testing data, R-precision is identical with Precision@58. The results are shown in Table 4 and Figure 3.
As well as on the classification task, our proposed method is still the best on the ranking task. Although the Message class shows high precision on the classification task, it frequently fails to locate informative tweets in the high rank position compared to the baseline. This means that non-informative tweets hold the high ranks when message-based features are only used. In contrast, pro-posed method using User History consistently shows outstanding performance especially in terms of average precision . The proposed method achieves very high average precision which improves 18% comp ared to the baseline. This indicates that User History, which normalize each users influence and estimate importance of a tweet, makes informative messages hold a high rank. So our method is avail-able to apply to information retrieval system and we can also expect promising performance on searching informative m essages in social networking services.
Additionally, the improvement of our method is statistically significant (at the level of p-value less than 0.05). This demonstrates that our method based on User History is effective for detecting i nformative tweets which are worthwhile to read. 4.3 Normalizing Effects of User History Figure 4 shows the retweets statistics of tweets with regard to the influence of the author, measured by the number of followers. We can observe that most of the tweets written by highly influential users are more frequently retweeted regardless of the tweets informativeness. If we use a sampling methods utiliz-ing retweet frequency to gather instances from Twitter corpus, most of tweets necessarily belong to a small number of specific users, such as celebrities and sports stars. This is the inherent defect of conventional features like Retweets and Replies. Figure 5 shows the standardized retweet statistics of tweets. Note that the retweet values for authors with relatively less followers are promoted, and the values of influential users are degraded. These two figures demonstrate how our method affects history statistics of users.
 In this paper, we define a new task involving detection of informative messages which can extend the benefits to the general users in the Twitter stream. We pro-pose a novel feature set, named User Histor y, focused on tweets X  distinctiveness and users X  tendencies. Experimental results on Twitter dataset show that the proposed method improved the performance of both classification and ranking of informative tweets, especially in te rms of Recall and Average Precision. This approach can contribute to the improvement of information retrieval system on the social media, and also can be utili zed by contents curators [10] who select and organize valuable posts to diffuse th em over the social networking services.
Though our method is appropriate to detect informative tweets, our model has some limitations, such as too simple parameter estimation for unseen users. For future work, we plan on improving the model by adapting and investigating the other probability distributions, such as Poisson and Beta distributions, for more reliable probability estimation.
 Acknowledgment. This work was supported by the National Research Foun-dation of Korea(NRF) grant funded by the Korea government(MEST) (No. 2012033342).

