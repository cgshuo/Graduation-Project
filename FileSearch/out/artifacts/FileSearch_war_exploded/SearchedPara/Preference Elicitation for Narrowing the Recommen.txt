 A group may appreciate recommendations on items that fit their joint preferences. When the members X  actual preferences are unknown, a recommendation can be made with the aid of collaborative filtering methods . We offer to narrow down the recommended list of items by eliciting the users' actual preferences. Our final goal is to output top- X  preferred items to the group out of the top- X  recommendations provided by the recommender system (  X  X  X  ), where one of the items is a necessary winner. We propose an itera tive preference elicitation method, where users are required to provide item ratings per request. We suggest a heuristic that attempts to minimize the preference elicitation effort under two aggregation strategies. We evaluate our methods on real-world Netflix data as well as on simulated data which allows us to study different cases. We show that preference elicitation effort can be cut in up to 90% while preserving the most preferred items in the narrowed list. H.3.3 1 [ Information Storage and Retrieval ]: Information Search and Retrieval Algorithms, Human Factors, Experimentation Preference Elicitation, Group Recommender Systems Group recommendation may be useful in various common daily scenarios. For example, a group who wishes to dine together may appreciate recommendations on releva nt restaurants that fit their joint preferences [11]. Given the list of recommended restaurants, the group's members often interact among themselves to narrow down the possible options and choos e a restaurant [10]. When the members X  actual preferences re garding the recommended items are known, some aggregation strategy can be used to compute the most preferred restaurant out of the list of recommended items. However, often full preferences are not readily available, mainly because it can be tiresome or difficult for users to determine all of their preferences in advance. Consider for example a setting of 30 optional dinner locations for a group. The group members might be reluctant to provide input on each of the restaurants. The problem we investigate in th is paper is how to narrow down the list of items recommended by the system by eliciting the users' actual preferences. Since preference elicitation requires time and effort, the goal is to stop elicitation as soon as possible. We borrow from the closely related doma in of social choice [2], where preference elicitation has been examined under different voting preferences are needed in order to determine a winner [3]. However, in practice it has been shown that the required information for determining a winner can be cut in more than 50% [6, 8, 10]. Given partial preferences, it is possible to define the set of necessary winners, i.e., items which must necessarily win given a certain aggregation strategy, as well as the set of possible winners, i.e., items which can still possibly win [7]. These definitions enable the elicitor to determine whether enough information about the users X  preferences is available, and iteratively request for more user ratings. Once a necessary item is identified, it is recommended to the group. An additional benefit of this process is that the output is not a predicted item, but rather an item that certainly fits the group X  X  joint preferences. Although outputting a definite winne r is the most accurate result, there are advantages in providing top- X  items (where one of them is a necessary winner) out of the top- X  recommendations list (  X  X  X  ). outputting one necessary winner (i.e.,  X 1 X  ). Thus issues such as elicitation costs are reduced. Also, users might prefer to receive a few unavailable, the group can quickl y switch to another alternative without applying an additional preference elicitation process. For example, if the system recommends only a fish restaurant as the winner item, but one of the group members dislikes fish, the group might prefer to switch to another alternative recommended by the system rather than to perform another elicitation round. Of course, the top- X  winners list depends on the applied aggregation strategy. The aggrega tion strategy should be a fair one. In his famous work, Arrow shows that there is no perfect aggregation system [1]. One of the major differences between aggregation strategies is the social environment in which they are used. The emphasis can be either on mindfulness toward the individual user or on mindfulness toward the majority of the group [5]. Two state-of-the-art aggregation strategies that hold this tension in between are the Majority Based Strategy and the Least Misery Strategy . In the Majority Based Strategy the users X  ratings of the different items are aggregated and the item with the highest total value is the winner. In the Least Misery Strategy the chosen item cannot be the least preferred by any of the users [9]. Preferences elicitation methods usually assume that the Majority based strategy is employed [6, 8, 10]. We show that the aggregation strategy affects the effort required in the preference elicitation and evaluate two state-of-the-art aggregation strategies. the top-N recommendations provided by the recommender system (k&lt;N), where one of the items is a necessary winner. We propose an iterative preference elicitation method, where users are required to provide item ratings per request. We suggest a heuristic that attempts to minimize the preference elicitation effort under two aggregation strategies, while still outputting a necessary winner. We evaluate our methods on real-world Netflix data as well as on simulated data which allows us to study different cases. We show that the preference elicitation effort can be cut in up to 90% in some cases. We focus on the Range voting protocol which requires users to submit ratings to items. Applicati ons that ask for ratings are quite common, for example Amazon and Netflix 1 . We assume that users X  preferences are unknown in advance, but can be acquired during the able to submit it. We also assume a user submits her true preferences and thus in this paper we do not consider manipulation. Lastly, we assume an approximate distribution of each user X  X  preferences for each item exists, as in [10]. Both [9] and [13] study how different strategies affect group members. However, the aggregation strategies have not been studied in the context of preference elicitation . Practical preference elicitation is gaining interest recently. In [6] it is assumed that each user holds a predefined decreasing order of the preferences. In an iterative process, the users are requested to submit their highest preferences; the request is for the rating of one item from all the users. However, requiring the users to predefine thei r preferences can be inconvenient to the users. In [10] two practical heuristics that attempt to minimize preference elicitation effort are presented for the Range voting protocol. However both output one definite item and not top- X  items. In [8] a practical elicitation proces s is proposed for the Borda voting protocol. The output is multiple winners. However the authors did not consider the Range protocol. In all of the above, the authors considered only the majority based aggregation strategy. The algorithm proposed in [8] lacks details and the authors did not provide us with explanations so we cannot expand it to the Least Misery strategy or to the Range voting protocol. In this paper we expand the preference elicitation algorithm for the Range voting protocol suggested in [10]. To the best of our knowledge the issue of preference elicitation and returni ng one or more items under the Least Misery strategy has not been investigated before. Let us define a set of users (voters) as  X  X  X  X  X   X   X ,  X   X ,..., of candidate items as  X  X  X  X  X   X   X ,  X   X ,...,  X   X  . When queried, the users assign ratings to the items from a discrete domain of values  X  X   X  X   X  X  X  X   X ,...,  X  X  X  X   X  where  X   X  X  X  X  and  X   X  X  X  X  are the lowest and highest values, respectively. User  X   X   X  X  preferences are represented by the rating function  X  X   X  X  X : X  X  X  X  X  . For abbreviation we denote  X  single preference of  X   X  for a single item  X   X  . The user-item rating not necessarily known to the voting center. Let for her ratings on one item. The preferences are aggregated according to a predefined aggregation strategy. The process terminates once a predefined termination condition is reached. We denote the applied aggregation strategy  X  X  X  . The item score depends on the strategy used. As mentioned, in the Majority based aggregation strategy th e mindfulness is towards the majority of the group. The user rating for an item are added: is fairly common, a disadvantage of this strategy is that it can be unfair towards users with the minority view. In fact, the authors in [14] state that their system works well for a homogenous group. However, when the group is heterogeneous, dissatisfaction of the minority group occurs. In the Least Misery strategy, the chosen item cannot be the least preferred by any of the users. The items score is the score of the least preferred item:  X  example. The disadvantage is th at the minority opinion can dictate the group  X  if all users but one really want some item to win, it will not be chosen [9]. Let  X  be the number of alternatives that will be presented to the goal is to determine whether the iterative process can be terminated. The termination condition is that the winner item is computes the possible maximum rating for item  X   X  known user preferences. Similarly, the function of the possible Definition 1. (Possible Maximum): given the set of responses  X  and an aggregation strategy str, the possible maximum score of Definition 2. (Possible Minimum): give n the set of responses  X  and an aggregation strategy str, the possible minimum score of A necessary winner  X  X  is a set of items whose possible minimum aggregated rating is equa l or greater than the possible maximum aggregated rating of all the others. Formally: Definition 3. (Necessary Winners set):  X  X  X  X   X  X   X   X  X  X  X |  X   X   X  Although the necessary winner set may contain more than one item, we assume that there is only one necessary item. In the case of a few winning items, the first item is selected lexicographically. In order to decide on the next query, the elicitor considers the rating distribution of the user-item preferences. The distribution can be inferred from rankings of similar users using collaborative filtering methods [10]. Formally the rating distribution is: Definition 4. (Rating Distribution): the voting center considers  X  as a discrete random variable distributed according to some rating distribution  X  X   X   X  , such that  X  X   X   X   X  X   X   X  X  X  all the rating probability distributions. The example presented in Table 1 shows the rating distribution of three users for two items in the domain  X  X  X 1,2,3 X   X  . E.g., the probability that  X   X  will assign a rate of 1 to item  X  We assume independence between the probability distributions. While the independence assumption is naive, it can be used for approximating the actual probability. An attempt to address dependency will yield probabilities that are too complex for a system. When facing the tradeoff between the models accuracy and practicality, we chose to model a practical system. However, note that the precise probability value is not required if the queries are still sorted correctly according to the value of the information they hold (their informativeness). In the closely related domain of machine learning, a similar naive assumption is known to provide accurate classification, though the independence assumption is not always true [4]. We therefore argue that the decrease of accuracy, if at all exists, is not significant. The initial rating distribution is calculated before the heuristics are applied. Both heuristics iter atively reveal one new rating upon request. This allows updating th e distribution every time a new rating is added. The accuracy is expected to grow with the number of ratings acquired. Note that the proposed algorithm can be used when no history of rati ngs is available (this is known as cold start). In such a case, the initial distribution will be uniform, and will be updated as we proceed. The Extended Dynamic Information Gain ( EDIG ) Heuristic is an iterative algorithm based on the DIG algorithm proposed in [10]. It uses a greedy calculation in or der to select a query out of the possible  X  X  X  queries. The chosen query is the one that maximizes the information gain. The information gain of a specific query is the difference between the prior and the posterior probability of the candidates to win given the possible responses to the query. The algor ithm terminates once a winner is within the requested top- X  items. In order to select a query, the heuristic calculates the information gained from each one of the optional queries and then selects the one that maximizes it. To compute the information gain, th e winning probability of each item is calculated. The score  X  that the candidate can achieve depends on the strategy: Let us denote the probability an item has a certain score The probability of an item to win is: Definition 5. (Item Winning Probability): Under the independence of probabilities assumption, the probability that item c j is a winner is the aggregation of  X   X   X  X  probabilities to win over the possible ratings s:  X  X   X  X  X  X  X   X   X  X   X   X Pr X  To compute the probability that an item will receive the score s , and to compute the probability that an item will receive a score of at most s , for the majority base d strategy we use: For the Least Misery strategy we use: Next, the heuristic calculates the information gain of the  X  X  X  possible queries. The information gain of a query is the difference between the prior entropy and the posterior entropy, given the possible responses to the query: Definition 6. (Information Gain): The Information Gain (IG) of a  X  where  X  X  X  X  X  X   X   X   X  X   X   X  represents the entropy of NW given the possible values by querying user v i on item c j . The query that maximizes the information gain is selected:  X  X  X  X  X  X  X  X   X , X   X | X  X  X   X   X   X  . The query selection process continues until the termination condition is reached. We examine the performance of the EDIG algorithm, under two aggregation strategies: Majority and Least Misery. The tradeoff between the number of items outputted (top- X  ) to the group and the number of preference elicita tion required is investigated. Performance is measured in terms of elicitation effort, i.e., the required number of queries (reque sts for the user to provide ratings), in order to reach the termination condition. As mentioned in the related work, to the best of our knowledge there are no other algorithms that operate (or can be expanded to operate) under the same settings. Therefore the baseline for measuring the effectiveness of our method is a random procedure (RANDOM), which randomly selects the next query. To account for the randomness in RANDOM, ea ch experiment was repeated 20 times. We present an evaluation on simulated data as well as on a real-world dataset, the Netflix prize dataset. The Netflix dataset (http://www.netflixprize.com) c onsists of ~100,000 users and ~16,000 items. We consider a setting of a group of 10 members and 10 items. The users in the group are drawn randomly from a subset of Netflix where all users gave rating to 100 items. 90 items are used to create the initial rating distribution. The 10 remaining items are the items in question. To account for randomness, each experiment was repeated 10 times. We simulate a cold start scenario where no history of ratings is available. We consider a setting of a group of 10 members and 10 items where the users rate their preferences on a scale of 1-4. We set the user-item distribution to a Uniform distribution. For example, the initial distribution for any user-item pair is: {0.25,0.25,0.25,0.25}, indicating that item  X   X  has a 25% probability to be rated 1-4 by user  X   X  . Similarly, we simulated a problem where one item is suspected to be more favorable and has a skewed distribution skewed to the right (Right-Skew), and a problem where one item is suspect ed to be less favorable and has a distribution skewed to the left (Left-Skew). The distribution {0.011,0.011,0.147,0.832} and {0.832, 0.147,0.011,0.011}. In all cases, we cast lots to set the user-item ratings. To account for randomness, each experiment was repeated 10 times. We compared the two strategies: Majority (MAJ) and Least Misery (LM) combined with ED IG and RANDOM heuristics. We examined different term ination conditions, from  X 1 X  , i.e., requiring one definite winner, to  X 9 X  , i.e., requiring the winner to be one of the top 9 items. The results on the Netflix data are displayed in Figure 1. Axis x presents the termination condition k=1,...,10, Axis y presents the number of queries required in order to find a winner within the top- X  . As expected, all combinations (of heuristics with strategies) drop in the amount of elicitation effort required as the termination condition includes a larger number of  X  items. The best results are received for EDIG combined with MAJ strategy. This combination reduces the elicitation effort in up to 35%. All the results were found significant with a 95% confidence level using a one-tailed t-test. Figure 1. Preference Elicitation effort on the Netflix dataset For the simulated data with different skewness levels: Right-Skew, Uniform (cold-start problem) and Left-Skew, EDIG significantly outperformed RANDOM with a confidence level of 95% using a one-tailed t-test. For a cold-start problem (Uniform skewness, columns 4-5 in Ta ble 2) LM outperforms MAJ reducing the preference elicitation effort in 22%-93%. For a Left-Skew (columns 6-7 in Table 2) , again LM outperforms MAJ for every  X  . The trend changes for the Right-Skew (columns 2-3). Here MAJ outperforms LM. All of these results were found significant with a confidence level of 95% using a one-tailed t-test. The results indicate that it is advised to consider the users assumed behavior. If the user preferences are assumed to be skewed towards some favorable item, as is the case with the Netflix dataset and with the simulated data with a right skew, it is best to use a heuristic that employs the Majority based strategy. If the results are uniformly skewed or it is assumed that some item or items are less preferred (left skew), it is best to choose a heuristics that employs the Least Misery strategy. Reducing the preference elicitation effort can also be achieved by changing the preference elicitation termin ation condition and requiring a winning item within top  X  instead of a definite item. We propose an iterative preference elicitation method, where users are required to provide item ratings per request. We suggest a heuristic that attempts to minimize the preference elicitation effort under two aggregation strate gies. The goal is to output top- X  preferred items, where one of the items is a necessary winner, out of the top- X  recommendations provided to the group by the recommender system (  X  X  X  ). We show that the aggregation strategy affects the effort required in the preference elicitation and evaluate two state-of-the-art aggregation strategies. We demonstrate that the preference elicitation effort can be cut in up to 90% in some cases, while a necessary winner is still outputted. Since different aggregation strategies are used in different situations, in the future we plan to investigate other aggregation strategies and heuristics that combine a few strategies. [1] Arrow, K. J. 1951. Social Choice and Individual Values. [2] Brandt, F., Conitzer, V. and Endriss, U. Computational social [3] Conitzer, V. and Sandholm, T. 2005. Communication [4] Domingos, P. and Pazzani, M. 1997. On the optimality of the [5] Jameson, A. and Smyth, B. 2007. Recommendation to groups. [6] Kalech, M., Kraus, S., Kaminka , G. A. and Goldman, C. V. [7] Konczak, K. and Lang, J. Voting procedures with incomplete [8] Lu, T. and Boutilier, C. Multi-winner Social Choice with [9] Masthoff, J. 2011. Group recommender systems: Combining [10] Naamani Dery, L., Kalceh, M ., Rokach, L., Shapira, B. 2014. [11] Naamani Dery, L., Kalech, M., Rokach, L. and Shapira, B. [12] O X  X onnor, M., Cosley, D., Konstan, J. A. and Riedl, J. 2001. [13] Senot, C., Kostadinov, D., Bouzid, M., Picault, J. and [14] Yu, Z., Zhou, X., Hao, Y. and Gu, J. 2006. TV program 
