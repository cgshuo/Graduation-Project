 ORIGINAL PAPER Mudit Agrawal  X  David Doermann Abstract The paper presents a clutter detection and removal algorithm for complex document images. This dis-tance transform based technique aims to remove irregular and independent unwanted clutter while preserving the text content. The novelty of this approach is in its approximation to the clutter X  X ontent boundary when the clutter is attached to the content in irregular ways. As an intermediate step, a residual image is created, which forms the basis for clut-ter detection and removal. Clutter detection and removal are independent of clutter X  X  position, size, shape, and connectiv-ity with text. The method is tested on a collection of highly degraded and noisy, machine-printed and handwritten Arabic and English documents, and results show pixel-level accura-cies of 99.18 and 98.67% for clutter detection and removal, respectively. This approach is also extended to documents having a mix of clutter and salt-and-pepper noise. Keywords Clutter removal  X  Noise border removal  X  Margin removal  X  Image enhancement  X  Pixel-based noise removal 1 Introduction Observed images of documents often deviate from the ideal images that were produced by the source. These deviations may manifest themselves on the physical document during production, scanning, transmission, storage, or conversion from one form to another and are commonly referred to as noise. Irrelevant content can also be viewed as noise, making the problem of detection and removal very much application-dependent.

Mass data scanning and the transmission of document images through low-bandwidth networks for storage and accessibility may require high-speed scanning and data reduction in the form of reduced resolution, reduced image depth, and image compression. High-speed scanners often produceartifactssuchaspageborders,skew,orintensityvari-ations. Many images produced are automatically thresholded and saved as binary images, instead of gray scale or color. Generic thresholding often amplifies problems in subsequent phases, introduces various forms of noise, allows background patterns to flow into foreground contents, exacerbates touch-ing and broken characters, and leads to an overall degradation in document quality. Document analysis algorithms such as page segmentation and character recognition typically work best on clean documents and often rely on connected com-ponents as basic units, which unfortunately, are sensitive to various types of noise.

State-of-the-art automated enhancement often assumes noise to be  X  X isconnected X  from content in one or more feature spaces, like gray scale (for bleed through), linear boundary separability (marginal noise), or sparseness (for salt-and-pepper). Techniques like region growing and mor-phological analysis have proved to be sufficient for noise removal only in the latter cases. As degradation becomes more severe, these assumptions no longer hold. 1.1 Characterizing noise Noise in binary document images can be viewed as depen-dent or independent with the underlying document content. Ink blobs, salt-and-pepper [ 8 ], stray marks, and marginal noise [ 10 ] are, in general, independent of location, size, or other properties of text data in the document image. Recorded images that have this type of noise can be expressed as the sum of the true image I ( i , j ) and the noise N ( i R ( ized as independent with respect to the content. On the other hand, when the noise is included inside the spatial frequency domain of the image and cannot be suppressed without a pri-ori knowledge of the content, it is referred to as dependent ifest themselves differently depending on the content. Such dependent noise is comparatively more difficult to model, is mathematically nonlinear, and often multiplicative.
Clutter: In our work, clutter refers to unwanted fore-ground content that is typically larger and much denser than text in binary images. It can result from numerous sources. While some forms of clutter like punched holes (Fig. 1 a), ink seeps (Fig. 1 b), ink blobs (Fig. 1 c), and copier borders typ-ically are present before the scanning process, other types of marginal noise may result from the scanning of bound or skewed documents (Fig. 1 a, f). For example, the gap between the gutter and scanner or between edges of paper and scanner bed can cause lighting variations. Other scan-ning and binarization artifacts may also give rise to clutter (Fig. 1 d,e).Clearly,clutterispredominantlyindependentand irregular.

Clutter removal: One of the major challenges with clutter comes from its connectivity with text. Many state-of-the-art document image processing algorithms work on the assump-tion of the availability of characters (or words) as separate components. Clutter, on the other hand, often touches or over-laps some parts of the text. In the case of ruled line documents with clutter, a single connected component connecting clut-ter, ruled lines, and text may be present (Fig. 2 ). Complete removal of the clutter component in such cases may result in tremendous loss of content, while morphological erosion can degrade the text because the density of noise is higher than that of the text. Instead of dealing with clutter noise removal at the component level, clutter X  X ontent interaction calls for a pixel-based noise removal approach. The bigger challenge (and the goal), therefore, is to determine the clutter X  X ontent boundary accurately so the clutter is fully removed without leaving any traces and the attached text is preserved. While aggressive clutter removal may lead to content loss, conser-vative removal may leave traces of clutter behind, giving rise to dependent noise (Fig. 3 ). 1.2 Previous and related work Document cleaning can be performed in two fundamental ways. In one approach, the information content is extracted from an image, leaving non-content as noise [ 24 , 28 , 29 ], while the other approach detects and removes noise from an image, resulting in a clean document. The former approach is often used where a limited number of content types occur. In particular, there has been a lot of research in extracting text fromimages[ 24 , 25 , 28 , 29 ].However,forvariedcontentsuch as text, logos, figures, stamps, diagrams, equations, draw-ings, or halftones, individual extraction processes may be required [ 9 , 18 , 24 , 32 ], which makes this approach less prac-tical. In addition, these individual extraction processes typi-cally depend on zone layout analysis, which in turn depend on a clean document for good results.

Detecting and removing noise is generally based on its properties like its shape, position, frequency, gray val-ues, density, or periodicity of occurrence in the document. Unwanted punched holes exhibit regularity in their shapes, marginal noise [ 10 ] shows regularity in its position, and ruled lines [ 30 , 31 ] show periodicity in their positions and consistency in direction. Noise such as ink blobs, complex background binarized patterns is denser than text, whereas salt-and-pepper [ 2 , 8 ] is impulsive noise and sparser than con-tent pixels. If noise shows a consistent behavior in terms of these properties, it is easier to detect and separate it from con-tent. Ozawa and Nakagawa [ 17 ], Wang and Tang [ 26 ], and Negishi et al. [ 16 ] use gray level to distinguish foreground from background. Fan et al. [ 10 ] assume length, position, and neighborhood of noise to detect and remove it. Liang et al. [ 14 ] depend on periodicity of noise to delete it. However, little work has been reported on the removal of noise that does not adhere to a consistent shape, position, or size and that tends to interact with text in the foreground in irregular ways. In this paper, we will consider noise in binary doc-uments which appears as unwanted foreground content and tends to interact directly with text in irregular ways. The chal-lenge is to detach and preserve text and eventually remove noise from the document.

As far as we know, no collective work has been published on the detection and removal of all forms of clutter, without removing or further degrading the attached text, in binary document images. Fan et al. [ 10 ] detect and remove marginal noise regions based on the assumptions on shape, length, and position. Image resolution is first reduced to remove text pixels, and regions of marginal noise are detected using shape, length, and position requirements. The noisy region is then enclosed in an approximate rectangular shape, which is then enlarged in consecutive steps until it encounters the first background pixel in the original resolution image. The enclosing portion of the polygon is the maximum portion of marginal noise that can be removed without removing the attached content. The technique performs fairly well at removing only the marginal noise without the attached text, but it assumes a linear boundary of separation between marginal noise and content. Another problem is that the footprint or shape of the clutter boundary may differ from (c) ( d ) (e) (f) the one obtained after image down-sizing or morphological erosion.

Figure 4 illustrates the difference. The line 1 is the actual clutter X  X ontent boundary. The line 2 is the boundary of the clutter obtained after aggressive erosion or down-sizing the image. If we were to enlarge (dilate) this eroded clutter up to the first encountered background pixel, we will end up on the boundary shown by line 3. The removal of clutter up to this boundary will leave parts of clutter along with content. These chunks left behind become dependent with text, making them extremely difficult to remove.

Shafait and Breuel [ 21 ] use black-and-white filters along with the positions of the connected components to remove border noise from document images. Rectangular windows are moved in specific corner areas of a document image, and the percentage of black pixels is calculated. Whenever the percentage is above (black filter) or below (white fil-ter) a given threshold, window areas are classified as border noise or gutters between borders and text regions, respec-tively. Decisions to remove border noise are then based on the positions of these classified areas. Parameters like rec-tangular window size, thresholds for black-and-white filters, and expected areas of border noise make this approach spe-cific to a given resolution, font size, and border-type clutter. This approach also assumes a linear white-gutter boundary separating clutter and text regions.

Stamatopoulous et al. [ 22 , 23 ] rely on vertical and horizon-tal projection profiling methods to determine a linear bound-ary of separation between clutter (in form of border) and text. Unfortunately, any text attached to the border is removed in the process. Le et al. [ 13 ] use rule-based classification of blank, textual, and non-textual blocks based on the percent-age of black pixels, locations, projection profiles, and cross-ing counts. They also assume a linear white-gutter boundary separating clutter and text regions, failure of which results in text loss during noise removal. Both of these approaches also rely on the average character heights determined from the document image based on connected components. For the noisy documents depicted in Fig. 2 , characters may not appear as individual components.

Avila and Lins [ 3 ] remove marginal noise regions by using a restrictive flood-fill algorithm. The basic algorithm moves outside in from the noisy surrounding border toward the doc-ument. In order to restrain the flow into the content, a pre-defined stroke width threshold and a predefined text size threshold are used. Although the algorithm tries to iden-tify a nonlinear boundary between noise and content, the predefined thresholds restrict its usage across diverse docu-ments of varying resolution, scripts, and font sizes. Table 1 summarizes the state-of-the-art algorithms, their basic tech-niques, and the assumptions they make toward clutter noise removal.

In contrast, our technique aims to determine the clutter X  content boundary precisely on all forms of clutter. The advantages of our approach over the prior art include the following: 1. Position independence: Our approach is not limited to the 2. Size independence: In accordance with the definition of 3. Shape independence: Unlike marginal noise, clutter can 4. Precise clutter X  X ontent boundary: Minimal dependent 5. Minimal content degradation: Our intermediate step of
The remainder of this paper is organized as follows. Sec-tion 2 describes the problem definition, our approach to clut-ter detection and removal. It also extends the basic approach to propose a generic clutter noise removal model in which several sizes of clutter can be removed iteratively, without interfering with text. This is followed by experiments and evaluation in Sect. 3 , a discussion in Sect. 4 , and by the con-clusion and future work in Sect. 5 . 2 Clutter detection and removal Morphological operations are known to degrade text. They also depend on the shape and size of the structuring ele-ment, which in turn depends on the image resolution. Dis-tance transforms, on the other hand, are generic and accurate, and the map obtained after distance transforms can be used to perform image analysis in one pass, unlike morphology. For efficiency, clean documents should bypass the noise removal process. If an image contains clutter, only the clutter com-ponents are extracted (Sect. 2.3 ) and passed through clutter removal (Sect. 2.4 ) to ensure that non-clutter components are not processed for noise removal, preserving their quality and enhancing the efficiency of this approach. 2.1 Background: distance transform approach As illustrated in Fig. 4 , it is important to determine the best boundary approximation between clutter and content. A bad approximation can result in dependent noise or content deletion. Our proposed algorithm is based on histograms of distance transforms to predict the best approximation to clutter X  X ontent boundary. The histograms are based on inte-gerbins,whichrequireintegerapproximationstothedistance transform. Let p be a pixel in the document image I , located at ( x , y ) position. Let d ( p metric,andtriangularmeasureofthedistancefrompixel p i to p , such as the Euclidean distance. Rosenfeld and Pfaltz [ 20 ] showed that octagonal distance d o better approximates to the Euclidean distance than city block, square, hexagonal , and ceil of Euclidean distance functions. Furthermore, nearest integer to Euclidean and floor of Euclidean are not distance functions as they violate the triangular property. Octagonal distance is defined as: d The distance transform [ 6 ] associates distances to every pixel of a set P from other sets as follows: D where initially, f ( q ) =
For binary images, only two sets of pixels exist, depending on foreground (fg) background (bg) pixels: I ={ P , P } , P ={ p | I ( p ) = fg } , P ={ p | I ( p ) = bg } .
 The distance transform is used for both detection and removal. We define D I as the foreground distance transform of image I , where foreground pixels are labeled by their dis-tance to the closest background boundary and all background pixels are labeled 0. D I is defined as the background distance transform of image I, where background pixels are labeled by their distance to the closest foreground boundary and all foreground pixels are labeled 0. The distance transform can be computed efficiently with a two-pass algorithm presented in [ 19 ]. 2.2 Pre-processing Unfortunately, clutter does not always form a smooth bound-ary with the background. This means, as we move from the center of clutter toward a point on its boundary, the clut-ter may have a fragmented appearance (Fig. 5 a) instead of a contrasting edge (clean step function in terms of fore-ground and background). Distance transformations on the foreground pixels label each pixel with its nearest distance to the background. With the goal of finding the optimal bound-ary between clutter and attached content, presence of any small opening inside clutter will affect the distance transform map inside it (Fig. 5 b). Figure 5 c shows distance transform values along a path from the left edge to the right edge of the clutter, in the presence of fragmentation. The distance transform produces an appearance of phantom clutter edges due to this fragmentation that affects later stages of clutter detection and removal.

Two prominent methods are worth considering but have shortcomings: 1. Median filtering [ 8 ]: The fragmentation is a continuous 2. Morphological closing: This is challenging due to the
We use a distance transform based closing. A background distance transform ( D Io ) is first applied to the original image Io . Each opening is labeled with its maximum distance, referred to as the radius of the opening. The most frequent radius is chosen from the histogram, and all background pix-els with distances less than this radius are converted to fore-ground producing an image Ip .
Figure 5 d shows the result of our pre-processing on the clutter in Fig. 5 a. Figure 5 e, f show better distance transform maps on the pre-processed image ( Ip ) . This process may also affect and thicken the text in Ip . However, Ip is used only to detect the clutter pixels. Once the appropriate pixels are detected, they are later removed from the original image Io , keeping the text unaffected. 2.3 Clutter detection Clutter, by definition, is larger than the maximum text stroke width present in the document, whereas thickness of ruled lines, salt-and-pepper, stray marks, or bleed through can be of the order of text stroke width. It is by design that this property of clutter differentiates it from other types of noise and text.

The clutter detection process is independent of the gen-eral shape and requires only that the size is twice as large as the text. The foreground distance transform labels each fore-groundpixelwithadistancetotheclosestbackgroundbound-ary. The foreground pixels, with associated distances less than half of the maximum transform distance in the image, are converted to background. This results in an image called the residual (Fig. 6 c). It can be computed as follows: 1. Perform distance transform D Ip on the pre-processed 2. Calculate the maximum value dt Max = max ( D Ip ) 3. Set all pixels p with D Ip ( p )&lt; dt Max / 2 to background.
Clean and clutter documents can be differentiated on the basis of the kind of residual image they produce. In a clut-tered image, the residual process will remove all text and non-clutter noise pixels from the document and leave behind only a core of each clutter component. On the other hand, in the absence of any clutter, text strokes will be reduced to half their maximum width, maintaining a text-like pat-tern (albeit broken). The basic properties that differentiate a clean from a clutter image are thus enhanced through this residual process, producing better differentiating features. The features of these residual images are calculated using the properties of their connected components, shown in Table 2 . These properties of residual images, Ih , are used as features to detect if the original image, Io , contains clutter. We train a two-class SVM on two sets of residual images from clean and clutter documents. Since the number of instances number of features , we use an RBF Kernel [ 7 ] with the described six features. The residual of the test image is then classi-fied as having or not having clutter. Figure 9 shows the clut-ter detection and removal model. Once a residual image Ih is classified as having clutter, its components are replaced with the corresponding (and larger) connected components from the pre-processed image Ip . The resulting image Ic has only these candidate clutter components (pre-processed) from their original image Io . 2.4 Clutter removal Our goal is to identify those pixels of the clutter compo-nents that belong to the clutter and to isolate the non-clutter (text) pixels if any exist. During clutter removal, however, we reverse the process to determine the point at which the clutter boundary meets the text-like pixels. We observe that if we  X  X egenerate X  the clutter from the residual components obtained in the previous step by introducing the pixels from the original component for successive distances, then the clutter pixels will be encountered at roughly the same rate in every step, as when we removed them. This is evident when we examine the number of regeneration steps that would be required to encounter each unique foreground distance contour.

As we approach the boundary of the clutter, this no longer holds true because we encounter text contours. The num-ber of steps required for regeneration increases significantly where the text protrudes from the clutter. Alternatively, for an original removal step (i.e., foreground distance contour), we can consider how many regeneration steps (from the resid-ual image) would be required to regenerate it. The origi-nal removal step (or distance contour) at which this number decreases sharply is the minimum distance  X  from the clut-ter X  X  boundary at which all the text is completely removed and the shape of the boundary is best preserved (Fig. 7 ).
This process can be summarized as follows: 1. Compute D Ic , foreground distance transform on the clut-2. Compute D Ih , background distance transform on the 3. P ={ p : D Ih ( p )&gt; 0 and D Ic ( p )&gt; 0 } 4. for i = 1to max ( D Ic ( P )) do AsshowninFig. 8 , moving inwards, a sharp drop occurs in f ( i ) at  X  . The function f ( i ) is a monotonically decreasing function. f ( i ) is the rate of change of the function, which slows down at  X  .If g ( x ) = f ( i ),  X  is the index of the first maxima of g(x). The value of  X  can be computed by solving for x in d d
It is not important that residual components maintain the exact shape of the clutter. The point of first significant drop in the function can predict the distance from the real bound-ary. The depth of the drop is proportional to the length of the text branch. Once this distance  X  is obtained, shrinking and expanding the clutter component by this distance iden-tifies the clutter without its text branches. If  X  is zero, these operations are not performed, as no text is attached to the clutter and the clutter component can directly be removed. 1. Image Id is obtained by removing all pixels p from Ic 2. Compute D Id . MP = MP  X  X  p Id : D Id ( p )  X   X  } 3. From Io ,set MP to background. Clutter from Io is It is important to note that since the identified clutter pixels are eventually removed from the original image Io instead of the pre-processed image, any effect on text pixels due to pre-processing (Sect. 2.3.2) is not reflected in the final image. The final image has no text degradation and is clean of clutter that was originally present in the image. 2.5 Iterative model It is important to note that the proposed clutter detection and removal model is an iterative model, which may need suc-cessive iterations to remove clutter components of varying sizes. In cases, where several clutter components of sizes in multiples of each other occur in the same document, the first residual process may remove the smaller clutter components (along with the text), and may leave only the core of the bigger clutter components in the residual image. The clutter removal process, following that, is oblivious to the smaller clutter components and cleans only the biggest clutter com-ponent. The resulting image retains the text attached to the bigger clutter components, but may also retain the smaller clutter components. This image is again checked for clutter (through residual process and clutter detection). This process is performed iteratively until a residue of a clean document is detected, as shown in Fig. 9 .

As long as the smallest clutter size is larger than twice the largest text stroke width, the clutter can be removed through the proposed iterative process. Theoretically, the iterative process stops when it first observes a text-like pattern in a residual image. This means, however, an image with few text strokes having widths larger than the clutter can leave a text-like pattern in the residual process. This can abort the clean-up process and still retain the smaller clutter compo-nents. However, we have not yet observed this in any of the processed documents. 3 Evaluation and results We use two approaches to evaluate our clutter removal. The first is a pixel-based metric based on the percentage of clutter pixels removed. The second is purposive, where we evaluate the improvement in successive stages of document process-ing due to clutter removal. 3.1 Data sets To evaluate our approach across a diverse set of data, we aim at data sets having three different forms of text X  X lutter interactions. 1. No text interaction: Clutter that appears as marginal 2. Word-level interaction: Ink seeps, smudges, and blobs 3. Content-level interaction: When clutter appears over the We use a total of five different data sets to evaluate our approach. Three of them ( D 1  X  D 3 ) have varying forms of text X  X lutter interaction for pixel-based metric evaluation, and two ( D 4 , D 4 ) are clean data sets for purposive evaluation. 1. Arabic Noisy Handwritten ( D 1 ) : This data set consists 2. English Machine-Print ( D 2 ) : The second data set is from 3. Complex English ( D 3 ) : The third data set consists of 4. Arabic Clean Handwritten ( D 4 ) : The data set is clean 5. Arabic Clean Mixed ( D 5 ) : The data set consists of textual Note: We have provided access to portions of our data at http://lampsrv02.umiacs.umd.edu/projdb/project.php and hope to release the remaining Arabic data through the Lin-guistic Data Consortium in the near future. 3.2 Pixel-based evaluation In pixel-based evaluation of our proposed iterative clutter removal algorithm (Sect. 2.5 ), we perform three sets of eval-uation on 300 randomly sampled documents from data sets D ics editor GNU Image Manipulation Program (GIMP), clut-ter pixels are manually removed from these images to create their respective cleaned ground truth. For evaluation, a pixel-based mapping algorithm is used between the original clutter images, the cleaned ground truths, and the cleaned images obtained after our clutter removal algorithms. 3.2.1 Clutter detection In order to evaluate our clutter detection algorithm, we feed these 300 images and their cleaned images (total 600 images) into the clutter detection module to classify each document as clean or noisy. We divide the data into training and testing sets using percentage split (80:20) and cross-validation (4 folds) methods. The reported accuracies for these methods are 99.18 and 94.24% respectively (Table 3 ). 3.2.2 Clutter removal For the second set of evaluation, we perform clutter removal on the above set of 300 clutter images. However, after each clutter removal iteration, the image is observed manually (instead of the clutter detection module) and is fed for another round of removal if some forms or parts of clutter persist (Sect. 2.5 ). This is repeated until a clean image is obtained. This solely evaluates our clutter removal algorithm without introducing any detection errors.

Since the clutter regions are typically much bigger than the text components, clutter pixels occupy 72.5% of the pixels in the collective image set. Precision and recall are calculated as: Precision N = Noise Pixels Removed Total Pixels Removed TP TP + FP where TP equals the number of true noise pixels removed, FP equals the number of text pixels removed, and FN equals the noise pixels remaining after removal.

Precision and recall accuracy of 98.9 and 98.75%, respec-tively, are achieved for clutter pixels. The results are depicted in Fig. 10 and Table 4 . The high value of precision highlights the restrictive nature of our approach which does not con-sume text pixels during removal. 3.2.3 Clutter detection and removal: complete iterative Finally, we evaluate our end-to-end system with automated detection and removal algorithms. Out of the chosen 300 clutter images, 40% of the images (and their cleaned ground truth images) are used for training. After every clutter removal iteration, this trained clutter detection model detects if a clean image has been obtained, then subsequently sends the noisy image for another round of clutter removal. We achieve precision and recall of 98.67 and 97.26%, respec-tively (Table 4 ).

Figure 2 c shows the removal of clutter after precise detec-tion of nonlinear clutter X  X ext boundary. Figure 11 shows the clutter removal results of images in Fig. 1 . A sample doc-ument from each data set along with its removal result is shown in Fig. 12 . 3.3 Script evaluation In order to do comparative analysis of the effects of vari-ous scripts, their varying font sizes, and other graphical ele-ments on clutter removal, we perform evaluations on the data sets D 1 (Arabic) and D 2 (English) separately. D 2 is the only publicly available data set [ 11 ]. For evaluation purposes, we randomly chose 150 images from D 1 and all images with filenames starting with  X  X  X  from D 2 (count = 121).
Table 5 shows the discriminating aspects of the two data sets, and Fig. 13 shows our algorithms achieve similar results on both. Comparable results on English data sets, containing larger fonts and headings, also prove that larger fonts do not affect clutter detection accuracy. 3.4 Purposive evaluation A second evaluation measures the impact of clutter removal in successive stages of the document processing chain. In document processing, the next step after noise removal is often text extraction, followed by word segmentation and finally character recognition. Clearly, text extraction or line segmentation is the stepping stone to the later stages and can be quite susceptible to noise especially in handwritten documents. Any error in this stage will affect successive ones. To evaluate the effect of clutter noise in documents, we compare in-house line segmentation algorithms on clean and clutter documents. We use a component-based handwritten Arabic text line segmentation algorithm using Affinity prop-agation [ 12 ]. This is a graph-based method for extracting handwritten text lines in monochromatic Arabic document images.

Unfortunately, the handwritten noisy data set ( D 1 ) does not have text line annotation for purposive evaluation. Data sets D 4 , D 5 have text line annotation, but are clutter-free. Hence, we add clutter to these data sets in two forms: 1. Border clutter 2. Random number of clutter blobs of random sizes at ran-
After adding the various forms of clutter, we randomly sample 250 images of handwritten Arabic data containing mainly textual content ( D 4 ) and 200 images of handwritten Arabic data containing textual content, stamps, signatures, and noise in the form of rule lines and speckle ( D 5 ) . Clut-ter detection and removal is performed on these images to produce cleaned images. Text line segmentation is then per-formed on the clutter-added and clutter-removed ( cleaned ) documents, and the accuracies are compared.

Sample documents from each data set are shown in Fig. 14 after line segmentation on clutter and cleaned images. As shown, the line segmentation algorithm either skips parts of a line when border clutter interacts with the text (Fig. 14 a) or incorrectly combines multiple lines due to a blob clutter (Fig. 14 c, e, g). On cleaned documents, we note an improve-ment of 8% in the case of the pure handwriting data set ( while an improvement of approximately 2% in the inherently noisy mixed data set ( D 5 ) . This also underlines the sensitiv-ity of the line segmentation algorithm on other forms of noise (ruled line, speckle) as well (Table 6 ). 4 Discussion Clutter removal performance was measured across different image resolutions and foreground content for 200 document images from the above data sets. We verified that the per-formance varies linearly with these two parameters and does not grow exponentially for better quality or dense content images (Fig. 15 ). On average, the clutter removal algorithms ( a ) (b) (c) ( d ) (e) (f) take 14 seconds per page on an Intel 3.00GHz (single core), 1GB RAM system under normal usage conditions.

The clutter removal process cleans up the majority of the clutter from a document image. However, errors occur pri-marily from three sources, which affect clutter removal accu-racy. The first two affect its recall, and the third one affects the precision.
 1. Stroke-like noise protrusions: The restrictive nature of 2. Fragmentation: Fragmented boundaries of clutter pro-3. Halftones: One of the drawbacks of the approach is in
Cleaning of clutter does not guarantee removal of smaller noise type like salt-and-pepper or SPN, as shown in Fig. 11 . Noise types in binary documents, which are of magni-tude (size) similar to that of text diacritics and tend to directly affect text in the foreground in irregular ways, are termed as stroke-like pattern noise (SPN) [ 15 ]. This noise may be formed due to the degradation of underlying page rule lines that interfere with the foreground text. These degraded rule lines are severely broken, not straight, and interact significantly with text. (Fig. 2 c). Stray marks in handwritten documents (Fig. 11 f) and some highly degraded background content (Fig. 11 e) can be other sources of such noise. The blurring edges (fragmented boundaries) of the clutter can also generate SPN after restrictive clutter removal (Figs. 2 c, 11 b).

We further process these images for fine removal of smaller noise types using SPN removal algorithms. For details, the reader is referred to Agrawal and Doermann [ 1 ]. 5 Conclusion and future work We have presented a novel approach toward clutter detection and removal for complex binary documents. Our distance transform-based approach aims at removing irregular and non-periodic clutter noise from binary document images and is independent of clutter X  X  position, size, shape, and connec-tivity with text. Residual image creation, as an intermediate step, helps in detecting clutter and determining the clutter X  content boundary precisely. Clutter detection and removal accuracies were reported greater than 95% on machine-printed and handwritten documents of English and Arabic scripts.

The novelty of this approach arises from its restrictive nature to remove clutter, as text attached to the clutter is nei-ther degraded nor deleted in the process. Additionally, any text components not attached to the clutter remain untouched during the cleanup process. A two-pass distance transform approach ensures that its order of complexity is O ( n ) making it a linear time pixel-based noise removal algorithm. Frag-mented boundaries and stroke-like noise protrusions, how-ever, remain the weakness of our approach. The absence of a text detection module inhibits the removal of stroke-like pattern noise during clutter removal. Another shortcoming of our approach is in its clutter detection algorithm which is based on the size of the clutter and the residual image pattern. This sometimes leads to the classification of badly binarized half-tones as clutter and eventually leads to their removal.

We would like to extend this approach to incorporate vari-ous other noise models to achieve our goal of a generic noise removal system. Better feature extraction and classification schemes for clutter detection will present another direction to enhance accuracy. Specifically, we can built the features to detect SPN removal algorithms [ 1 ] into the proposed clutter removal approach to achieve more precise noise removal. References
