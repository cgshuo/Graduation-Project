 In this paper, we describe POLESTAR (POLicy Explanation using STories and ARguments), an integrated suite of knowledge management and collaboration tools for intelligence analysts. POLESTAR provides built-in support for analyst workflow, including collection of textual facts from source documents, structured argumentation, and automatic citation in analytic product documents. Underlyi ng POLESTAR is a scalable dependency repository, which provides traceability from product documents to source snippets. The repository X  X  notification engine allows POLESTAR to al ert analysts when dependent sources are discredited and aid them in repairing affected arguments. The paper then discusses recent extensions to POLESTAR to support collabor ative analysis through community-of-interest finding, portfolio sharing, and peer review of arguments. We conclude with a preview of future research and summary of POLESTAR X  X  primary benefits from the point of view of its deployed users. H.4.1 [ Office Automation ]: Groupware, Workflow Management, I.2.1 [ AI Applications and Expert Systems ]: Office automation General Terms : Algorithms, Management, Human Factors Knowledge Management, Intelligence Analysis, Collaboration, Argument Structuring, Sensemak ing, Workflow Management, Knowledge Representation Accurate and timely intelligence analysis is essential to countering the asymmetric threat of terrorism, both abroad and in the homeland. Threats today fluidly move across geographic boundaries, exploit the openness of our society, and leave minimal traces of their presence scattered across vast amounts of structured and unstructured data. As recent intelligence failures have demonstrated, our current information systems inhibit collaboration and stifle insight with antiquated processes that encode Cold War compartmentalization and a posture better suited to dealing with nation-state adversaries. A new kind of anal ytic environment is needed X  X ne that promotes the formation of ad hoc collaborative teams that span multiple agencies and jurisdictions to rapidly find the fragments of a particular needle buried in haystacks of needles. The POLESTAR (POLicy Explan ation using STories and Arguments) system makes significant strides toward this new analytic environment by integr ating a sophisticated knowledge management infrastructure with co llaborative sensemaking tools. POLESTAR provides tools for intelligence analysts to help them individually and collaboratively construct more deeply reasoned intelligence reports in less time. POLESTAR does this by making the structure of the argument visible, in terms of claims that are supported by evidence and tempered by caveats. Make the structure explicit, and it X  X  far easier to zero in on its weak spots and evaluate its strengths. POLESTAR also tracks every piece of information that flows through the system, in a repository of links that enables the system to disc over emergent collaborations, put analysts working on similar problems in touch with each other, and find patterns in the use of intelligence information that would otherwise remain invisible. Taken to its logical extent, POLESTAR could be the catalyst for converting a highly stovepiped and rigid intelligence community into a fluid, adaptive system that seamlessly shifts and connects resources around emergent threats, facilitating early identification and disruption. The POLESTAR system, described in the subsequent sections, comprises the analytic tools a nd supporting software components enabling the end-to-end analytic process illustrated in Figure 1. The next section provides an overview of the evidence marshalling and knowledge struct uring capabilities. Section 3 describes the dependency repository that serves as POLESTAR X  X  knowledge management infrastructure. It also illustrates how it is used in several end-user appli cations, including alerting analysts of discredited source documents. Section 4 discusses recent enhancements to POLESTAR to support collaborative analysis. The paper concludes with a disc ussion of POLESTAR X  X  deployed capabilities and future research directions. This section summarizes POLESTAR X  X  workflow support for individual analysts. The analytic process in POLESTAR begins with fact collection. POLESTAR minimizes the additi onal workload of computer-assisted collection through seamle ss integration with the same tools analysts already use to view source documents. BAE Systems has developed a set of Fact Collector plug-ins embedded in Microsoft Word and Internet Explorer. These plug-ins allow users to highlight text snippets of interest and drag-and-drop them into the Portfolio Browser for s ubsequent analysis. Optionally, users may enter meta-data about the collected intelligence and its source as well as their own interp retation of the fact within a Fact Card dialog. Figure 2 shows this Fact Card with the user X  X  interpretation of a fact collected from Internet Explorer. analysts to gather evidence of interest from common desktop The Portfolio Browser (also called the Portfolio Browser in our deployed system) is the immediate point of storage for all collected facts. It is designed much like the familiar Windows Explorer, with named folders on the left side and facts arrayed in a list view on the right side. These named folders allow users to organize evidence according to categories of their own choosing. For example, users may place snippets relating to a particular person or country of interest in a folder named for them. Alternatively, a user may name folders after a particular analytic deliverable that is in progress, ranging from a short Special Intelligence Report (SIR) to a longer National Intelligence Estimate (NIE). 
Figure 3. The Portfolio Browser (aka Portfolio Browser) The Portfolio Browser is the user X  X  interface to the dependency-tracking repository backend of the system. When a user captures a snippet of information, the Ar gument Engine Core, which is the in-memory object cache and middleware infrastructure for POLESTAR, automatically acquires the snippet and stores it in the POLESTAR repository. POLESTAR also stores metadata associated with the snippet, including its source document identifier, source organization, and classification. Dragging a snippet from the Portfolio Browser into a working draft analysis document in Microsoft Word causes the Argument Engine Core to automatically insert a citation to the source document of that snippet. The Portfolio Browser is also the launch point for several knowledge structuring tools that help the user spatially, chronologically, or logically arrange evidence collected from the Portfolio Browser. The POLESTAR Wall of Facts, s hown in Figure 4, is a blank workspace onto which the analyst can drag and drop snippets of information that they have collected. Dragging snippets to the edges of the space causes them to shrink, enabling one to work with up to 200 snippets on a single screen. Snippets in the center of the screen are full-size, so analysts typically work in this region with their most current snippets of interest. Analysts may optionally add from scratch a claim textbox , which is the building block of an argument (see Section 2.3.3). Evidence relating to a particular claim may be clustered near it spatially. Furthermore, snippets can be grouped into hierarchically nested sub-workspaces. The intent is to enable analysts to rapidly sort through many snippets by sorting them spatially and/or hierarchically into groups, without having to commit to a formal categorization system. The wall of facts includes a timeline view (see Figure 5), which arrays snippets linearly in order of dates that users add to the metadata of each snippet. Seeing this arrangement can clarify relationships that are hard to detect when looking at a series of textual dates. For example, a tim eline of terrorist attacks on US interests over the ten years leading up to 9/11 very clearly shows an increase in the frequency of attacks. Much like the Wall of Facts, analysts may create sub-timelines to cluster events into separate stages or categories. 
Figure 5. Chronological ordering and grouping of facts is After spatially or chronologically organizing evidence, analysts formulate hypotheses as argumen ts. POLESTAR uses a graphical approach to argument structuring, based on methods for analyzing legal documents formulated by Wi gmore [10] and Toulmin [7]. POLESTAR represents arguments as a tree structure of claims, each supported by at least one piece of evidence (i.e., information drawn from a primary source). Claims may also have caveats that weaken or restrict their force, and subclaims that act as supports or caveats. The general representation for POLESTAR arguments is shown hierarchically in Figure 6. includes supporting and rebutting claims with supporting A specific example of a POLESTAR argument is shown in the screenshot in Figure 7. The Graphical Argument Editor at the lower-left enables analysts to use the Wall of Facts to construct a boxes-and-lines picture of such an argument structure. Argument structures can get quite large, so this interface is of most use when drilling down to look at a particular portion of an argument. To get a better sense of the overall structure of an argument, the Outline-based Argument Editor (right) indicates substructures of the argument via indentation, in e ffect presenting it as an outline. Supporting claims and facts are preceded by green bullets with upward pointing arrows superim posed on them, and caveats are preceded by red bullets with downward arrows. Because each claim is hyper-linked to a corresponding sentence in the product document, users are able to switch fluidly between these Argument Tree Editors and the document view provided by Microsoft Word. Figure 7. Analysts elaborate arguments via a tree structure of POLESTAR has been developed with a multi-tier architecture, as shown in Figure 8. The tools desc ribed in Section 2 constitute the application tier, comprised of stand-alone user interface applications such as the Portfolio Browser, and plug-ins to third party applications, such as the Fact Collector. The Argument Engine Core is the middle tier, wh ich also runs on the client. It enables message-based communica tion among client applications and provides rapid access to in-memory storage of POLESTAR objects and their dependencies. It also interfaces with the third tier, the Dependency Repository. The Dependency Repository supports the POLESTAR clients via a web application server that makes POLESTAR compatible with Service Oriented Architectures (SOAs). It also provides persistent storage of POLESTAR objects and depende ncies via a lightweight knowledge representation layer synchronized with a relational database. The repository has built-in support for atomic transactions with optional rollb ack. It has been successfully tested for scalability up to 1,000 users and 5,000,000 objects. Finally, it has been integrated with both lightweight open source and leading COTS industrial stre ngth relational databases, and exploits emerging RDBMS capabilities such as fast text search. communication among POLESTAR X  X  client tools and the One of the guiding principles of POLESTAR is traceability back to source documents from any stage of analysis or internal object in the dependency network. Th is allows POLESTAR to provide affordances for calling up source doc uments at key points in the analytic workflow, for example, at a citation in a product document or a snippet entry in the Portfolio Browser. Another tenet of POLESTAR is tr ansparency. By revealing to analysts the dependency network underlying their workflow, POLESTAR can provide insights into their effectiveness. For example, users can discover how much of the evidence they collect is actually used in product documents and accordingly narrow or widen their net. Users can directly examine their own dependency network of source doc uments, snippets, portfolios, and product documents using the Dependency View. This view is a graphical iconic representation of the network built in i2 Inc. X  X  Analyst X  X  Notebook  X  , which is widely used in the intelligence community for link analysis [3]. Here, instead of analyzing suspicious links among crime su spects, POLESTAR applies it to self-reflection of links in the analytic workflow by the analysts themselves. Figure 9 shows a simple example in which user mrogers has collected two facts from a single source document, placed them in the portfolio named korea, and cited one of them in a product document named  X  X IR -Al-Qaeda.doc. X  As we will see later, broadening the scope of the Dependency View to include other users can be used to help discover effective teams for collaborative analysis. Figure 9. The Dependency View provides a global picture of a In addition to individual analyst activities, the Dependency Repository allows for reporting of aggregate metrics of analysts X  activities. Having access to the metadata for each piece of information used in the argument structure of a document enables the Qualitative Argument Evaluator to provide reports on the diversity and adequacy of sourci ng. This Evaluator computes statistics, such as number of evidence snippets per claim, the temporal distribution of evidence snippets, and diversity in both sourcing and classification of s ource information. The resulting report highlights any of these statistics that deviates from qualitative norms for sound analysis, providing a means for analysts and managers to rapi dly assess the overall quality of reports. The Evaluator is implem ented as a web browser plug-in that displays analytic metrics within basic business chart graphics (bar, pie, line, etc.). These graphics themselves may be easily exported into product documents to convey to policymakers the depth of arguments and variety of sources used for a major activity. The screenshot in Figure 10 shows a notional organization that is currently reliant on Saudi Intelligence for 70% of its sources. 
Figure 10. The Qualitative Argument Evaluator provides 
Figure 11. POLESTAR alerts users of products and citations As shown in Figure 11, the POLESTAR dependency-tracking repository records links among us ers, the information they manipulate, the source documents they draw from, and the finished reports they produce. POLESTAR can exploit this link structure to notify analysts of source document recalls (e.g. from sources now considered unrelia ble) and automatically call up POLESTAR provides two levels of recall notification: affected product documents and affected claims (citations) within each product. For each affected item, the author may either mark the recall as leading to rejection or acceptance (no impact) of the item, optionally typing in an explanation of the degree of impact. These annotations are available in the permanent record of the product and eventually may be automatically transmitted to known consumers of the products to ensure policy-makers have an up-to-date understanding of the quality of the analysis. Figure 11 conceptually illustrates this process. A particular source document has been labeled as discredited. This triggers the antecedent of a rule registered in the repository X  X  notification engine . The consequent portion of the rule is a sequence of actions. First, the repository follows the dependency network forward to find in this case two product documents citing snippets collected from the recalled source. Then, the repository looks up the author of each product. The third and final repository action is to send a notification message to each author, which includes information on the affected produc t documents and citations. The POLESTAR Argument Engine Core contains a notification queue, which receives the incoming messages. At this point, POLESTAR displays a hyperlinked al ert to the user, appearing as a popup window in the lower-right corner of their desktop (see Figure 12). Figure 12. Alerting a user of a recalled source document. Clicking on the text in the popup window invokes the  X  X ffected Products X  dialog, shown in Figur e 13, which lists all products containing snippet citations stemmi ng from the discredited source. POLESTAR can find this information because it continually logs the user X  X  insertion of snippets into Microsoft Word documents via drag and drop from the Portfolio Browser (see Section 2.2). Figure 13. POLESTAR reveals product documents dependent When the user opens an aff ected product document from this dialog, POLESTAR drills down one level further, listing the affected claims (citations) in a secondary dialog. The affected citations are also highlighted dir ectly in the text via POLESTAR X  X  citation-handler plug-in to Microsoft Word (see Figure 14). The density of highlighted citations gives the analyst an immediate sense of how deeply the analysis is affected by the recalled source. The analyst may then use the Affected Claims dialog to enter a comment for each affected citation, typically to summarize the local impact of the discredited citation on the argument. These comments are automatically inserted into the document margin as Microsoft Word comment bubbles, and hence are visible to any future readers of the analysis. Finally, the user may mark both individual citations a nd entire analysis documents as retracted or repaired via the Retract/Repair buttons in the corresponding dialog. The capabilities in the previous s ections were mainly aimed at helping individual analysts make sense of evidence and write more deeply reasoned arguments. In this section we turn our discussion to collaborative argument evolution , via three new capabilities: community-of-interest finding, portfolio sharing, and peer review. Traditionally, POLESTAR has rest ricted views of dependency data to show only the current use r X  X  activities, or to anonymously summarize aggregate metrics of analysts X  activities. This is consisted with the mainly co mpartmentalized approach to intelligence sharing used throughout the Cold War. Given the 9/11 commission X  X  recent mandate to the intelligence community to increase its knowledge sharing to more rapidly detect asymmetric threats from terrorist or ganizations or rogue states [5], the POLESTAR dependency linkage structure may be exploited to discover useful teams for community-of-interest formation . By analyzing the common source depende ncies and textual content of snippets being collected by all users, it is possible to identify users who are working on simila r problems, and put them in contact with each other. For example, Drug Enforcement Agency staff working on a money launderi ng ring might discover that CIA analysts are interested in the same individuals because they are funding terrorist activities. As an initial proof of concept, we expanded the Dependency View to include artifacts and dependencies created not only by the current user, but also by othe r users to whom a direct path exists in the dependency network. Typically, this direct path flows through one or more common source documents from which both users have collected snippets. Figure 15 extends Figure 9 to include a second notional user collecting snippets from the same source document. Through this view, the user mrogers may surmise that user asmith has overlapping interests and may decide to make contact and potentially collaborate by pooling their knowledge. 
Figure 15. The Dependency View reveals users that have For a more advanced demonstration of this capability, we have teamed with 21 st Century Technologies to integrate POLESTAR with their Terrorist Modus Oper andi Discovery System (TMODS) social network analyzer. POLESTAR passes its meta-data and dependency information on all user s, facts, source documents, and portfolios to TMODS. Using group detection algorithms that trace the current user to other users through connections to common source documents, TMODS provides a recommendation of related users in a graphical display that also highlights non-overlapping source documents of interest from which the other users have collected facts. This interface is similar to recommendation agents popularized by amazon.com for recommending books or movies purchased by other customers with overlapping interests [1] [4 ]. For details on the underlying group detection algorithms used here, see [2]. 
TMODS to analyze and display related users and source To test the advanced community-finding capability, we developed a more in-depth scenario involvi ng ten fictional users, each with one or more named portfolios with varying degrees of overlap. Each user has also collected between three and ten snippets from a mid-2003 Foreign Broadcast Information Services (FBIS) corpus of hundreds of short text doc uments. The  X  X urrent user X  in the demonstration is hmifflin , who is collecting information for a global terrorism survey. As depicted in the ground truth diagram in Figure 17, several other user s are also investigating more specific terrorism topics, including jsmith, investigating Al Qaida; zdavis, focusing on Iraq terrorism; rcrusoe, focusing on terrorism in Israel; and jbond, looking at terrorism in Europe. Only the users in Group 1 form a cohesive group that includes hmifflin , where a group is defined as a set of users in which each user X  X  source documents overlap with at least one other user in the group. The scenario also includes a smaller group of two users investigating reaction to the Iraq War, and three  X  X tand-alone X  users that do not overlap with anyone else. Figure 17. Ground truth for the advanced Community-of-Comparing the TMODS results in Figure 16 to the ground truth in Figure 17, we see that the system has correctly discovered the four related users jsmith, zdavis, rcrusoe, jbond, their portfolios, and their overlapping source docum ents, shown in the bottom pane. This ability of the TMODS group detection to find indirectly related users like jsmith transcends the capability of the Dependency View, which was lim ited to finding only directly related users. In the top pa ne, TMODS lists the non-overlapping source documents from which these users collected snippets and highlights the path of the currently selected document to hmifflin. This path includes the other user X  X  containing portfolio, which can be used by hmifflin to filter for relevance. For example, doc2112.txt is a non-overlapping document under rcrusoe X  X   X  X srael X  portfolio, so hmifflin can judge whether or not Israel is a region of interest for the global survey . Once a collaborative team has been identified, the team needs a mechanism to collaboratively marshal evidence. Previously, POLESTAR X  X  Portfolio Browser was designed such that facts Now the Open Source Center at https://www.opensource.gov/ were kept private to the original user who collected them. To encourage collaboration and sharing of intelligence among users, the Portfolio Browser has been extended with a new portfolio sharing capability to define named groups of users and create shared portfolios that may be viewed and modified by anyone in the group. When one adds a fact or subordinate folder to the group X  X  shared portfolio, the Portfolio Browser automatically updates in real-time for all othe r users in the group. POLESTAR also allows for embedding hyper-links to shared snippets inside text messages or peer review comments, in order to provide specific guidance on their usage. To ensure integrity of shared objects in the repository, we have extended the Argument Engine Core to allow for centralized locking, updating, and notification of changes on portfolio objects. These changes also lay the foundation for enabling collaboration in other POLESTAR tools, such as the Wall of Facts. The portfolio-sharing process begins with the creation of a new shared portfolio within the Port folio Browser. The user is prompted to invite either a subs et of registered users or a pre-defined named group of users to contribute to the new portfolio. Internally, POLESTAR then a dds an association in the Dependency Repository between the shared portfolio and the chosen group of users. Finally, as with regular portfolios, the inviting user defines a name for the portfolio that is displayed next to the folder icon in the Portfolio Browser. The next time an invited user l ogs into POLESTAR, he or she will receive a popup notification, similar to that in Figure 12, but with a message inviting the user to contribute to the shared portfolio. Clicking on the hyperlinked text in the popup causes POLESTAR to automatically add the shared portfolio to the Portfolio Browser under a special shared root folder. Any user in the group that accepted the invitation may drag and drop copies of their existing snippets from their private portfolios into the shared portfolio. Whenever a new snippet is added, a special rule fires in the repository. The rule consequent is to send another notification message to each user announcing the change. Figure 18 illustrates this step for user jbond , who clicks on the popup message announcing a new sni ppet has been added to the Global Terrorism shared portfolio. This causes POLESTAR to automatically update the contents of that portfolio and browse to it in the Portfolio Browser. 
Figure 18. A user receives a notification of an update to a It is important to note that if multiple users in a group are logged into POLESTAR simultaneously, these notifications occur in real time , much like familiar collaborative chat or whiteboard tools such as Microsoft X  X  Groove or AOL X  X  Instant Messenger. Also, any updates made to a snippet X  X  me tadata within the Fact Card will be broadcast to the other users and displayable in the Portfolio Browser or Fact Card. Current practice for coordination of review of analytic products entails sending out a draft via email and merging the resulting comments, which come back in multiple formats. Some reviewers send comments in email, whereas others send back the document marked up, either directly in the text or via Microsoft Word X  X  Track Changes feature. In POLESTAR, as the final stage in the collaborative argument evolution process, we have developed a unified interface for reviewers to attach comments and rebuttals to the document text itself. The author has a separate comment summary interface for stepping through and addressing each of these comments in turn. Managers can readily check that all rebuttals have been resolved prior to report distribution. POLESTAR maintain s a record of all comments and changes to the document over time, enabling analysts to reconstruct their thinking at an y point in time. POLESTAR X  X  peer review plug-in is integrat ed with Microsoft Word, allowing reviewers to rapidly make in-line comments close to the actual text. In addition, POLESTAR allo ws multiple reviewers to work in parallel, with comments automati cally merged into the author X  X  view as they are submitted. Peer review is implemented as a Microsoft Word plug-in whose actions are available through a new Collaboration Toolbar that appears in Word. Like portfolio sharing, the initial step of the peer review process is to invite a group of users, with an extra optional step of providing guidance to the reviewers in a textfield. Figure 19. A user invites peers to review a product document. Later, when one of the invite d reviewers logs in, POLESTAR presents another popup invitation me ssage similar to that of a shared portfolio. However, in this case, accepting the invitation causes POLESTAR to open a reviewer-private copy of the product document in Microsoft Word. The reviewer may select any subset of text in Word and invoke a new POLESTAR right-click menu action,  X  X nter POLESTA R Comment. X  This in turn invokes a special POLESTAR comment dialog pointing to the selected text. The dialog provides a text field to enter specific feedback as well as a choice box specifying the type of feedback. This type can be one of the following: After entering each comment, it is added to the document margin as a Microsoft Word comment bubble. 
Figure 20. A reviewer enters categorized feedback that later When the reviewer is finished entering comments, he or she clicks the Submit Feedback button in the Collaboration Toolbar. Because each reviewer works with a separate copy of the document, an arbitrary number of reviewers may enter feedback in parallel. This is a distin ct advantage over certain COTS groupware and document management systems that enforce a sequential chain of review, leading to a lengthy review process prone to bottlenecks. In addition, many of these knowledge management portals are limited to external annotation methods in which comments are entered and di splayed in a web-based form or table far removed from the corresponding document text. By wrapping around Word X  X  embedded comment feature, reviewers can enter and view their comments in-line at the point of the relevant text, with the entire document itself available for further context. Next we turn our attention back to the author. For each reviewer who submitted feedback, the author receives a popup notification. Clicking on the latest popup will cause POLESTAR to automatically merge the comments submitted by all reviewers so far and open the original document with these merged comments shown in the margin. Furt hermore, POLESTAR provides a Feedback Summary window showing a consolidated tabular summary of comments received to date (see Figure 21). For each comment, the table shows the or iginating reviewer, timestamp, comment type, and comment text . The window becomes semi-transparent when other windows are moved in front of it, so that the author may easily read both the document in Microsoft Word and the consolidated summary without sacrificing screen real estate. 
Figure 21. The author views co nsolidated feedback from all The POLESTAR development team is considering several short-term enhancements and new capabilities for Collaborative Argument Evolution:  X  Extend the Community-of-Interest Formation capability to  X  Extend the Peer Review process to allow annotations directly  X  Enable real-time collaborative information sharing and Next year and beyond, POLESTAR is planning to research advanced search, analysis, and reporting capabilities that operate on the aggregate recorded collabora tive activity within an agency, including:  X  A restricted natural language dependency query interface  X  Automated agents that find relevant information in source  X  New management views similar to the Qualitative Argument  X  Visualizations that summarize how collaborative groups and In addition, we plan to inte grate POLESTAR with an existing BAE Systems testbed of intelligence link discovery and visualization tools, described in [6]. We have presented POLESTAR, a suite of tools for collaborative sensemaking and knowledge ma nagement to support the intelligence analysis workflow. POLESTAR X  X  principles of transparent source traceability a nd seamless integration with existing desktop editors and have led to early transition of selected capabilities to a government agency, where the currently operational system now supports well over 200 users. The key benefit of the system is the automation of metadata handling in the workflow, allowing users to spend more of their time on task and less on administrative overhead. Users are vocally enthusiastic about the system, saying that it saves them hours of time in the course of their work week. POLESTAR X  X  recent collaborative analysis capabilities s how strong potential to foster ad-hoc team formation and inform ation sharing within and across intelligence agencies. We plan to deliver an information-sharing version of our deployed system later this year, even as we continue to evolve our research agenda toward more advanced collaborative search, analys is, and reporting capabilities. This material is based upon work supported by the United States Air Force Research Laboratory under Contract No. F30602-03-C-0005. Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the United States Air Force. [1] Chen, A., and McLeod, D., Collaborative Filtering for [2] Coffman, T., Greenblatt, S., and Marcus, S. Graph-based [3] http://www.i2inc.com/Products/A nalysts_Notebook/default.a [4] Linden, G., Smith, B., &amp; Yo rk, J. (2003). Amazon.com [5] National Commission on Terrorist Attacks. The 9/11 [6] Pioch, N., Barlos, F., Fournelle , C. and Stephenson, T. A [7] Toulmin, S. The Uses of Argument. Cambridge University [8] Wang, X. and McCallum, A. Topics over Time: A Non-[9] Wang, X., Mohanty N., and Mc Callum, A. Group and Topic [10] Wigmore, J. H. The Science of Judicial Proof: as Given by 
