 H.3.1 [ Content Analysis and Indexing ]: Linguistic pro-cessing Algorithms, Experimentation Information Extraction, Pattern Representation Model
A recent approach to the information extraction is not only to improve the performance, but also to reduce the cost of the extraction process. In order to solve the cost problem, several approaches have been developed for the automatic acquisition of patterns for information extraction. One of the most important factors in acquiring reliable patterns is to select which model is used to represent the contextual information.

A number of pattern representation models have been ap-proached. Most of them are based on the result of depen-dency analysis. The predicate-argument model is based on a syntactic relationship between a predicate and its argu-ments [1]. The chain model represents extraction patterns as a chain-shaped path from each relevant entity to the root node in the dependency tree [2]. The chain patterns are utilized for representing linked-chains model by pairing of chain patterns which share the same verb but no direct de-scendants [3]. The subtree model regards any subtree of a dependency tree as an extraction pattern candidate [4]. In these prior approaches, the extracted pattern candidates are ranked by their own scoring measure, and only highly-ranked candidates are used for the iterative learning process.
In this paper, we propose an alternative pattern represen-tation model and the effective method of utilizing it. While the previous pattern representation models completely de-pend on the result of dependency analysis, our approach is basically based on the lexical alignment and considers the result of dependency analysis only as a meaningful feature of the alignment process. In this way, we can cope with the errors of incomplete dependency analysis. An evaluation of a scenario template task shows that our proposed model outperforms the previous syntax-dependent models.
 ment algorithm only as a lexical pattern matching. In this work, we will replace a simple lexical sequence pattern for the prior alignment-based method by a new model men-tioned in section 2.

There are several changes of the specific alignment scheme for replacing the pattern model of the method. While the prior method has performed only word-based alignment, we consider not only words but also base noun phrases as a unit of alignment. In order to reflect term weights of our proposed model to the alignment method, we multiply the similarity function and the gap penalty parameter by each term weight on the computation process of alignment ma-trix. The higher term weight means the higher importance for the alignment task. Due to the changes of alignment scheme, the alignment score is newly defined as where P T N is a pattern, RAW is a raw sentence, M is the alignment matrix which is computed by the task of align-ment between them, and w i is the weight of i -th term in P T N .
The experiment is focused on comparing the performance of the previous pattern models to the proposed alignment-based pattern model. The compared models are the predicate-argument (SVO) model [1], the linked-chain model [3] and the subtree model [4]. For the experiment, we used the MUC-4 [6] data which is for the scenario template task about the terrorism events. We defined a simpler template structure than the MUC-4 scenario template with four slots: &lt; perp ind, perp org, phys tgt, hum tgt &gt; , and converted each template on the answer keys into several corresponding instances consisting of values for the defined slots.
For each pattern model, we extracted a set of correspond-ing pattern candidates for the dev set of MUC-4 data. In order to compare not the pattern scoring or ranking method but the representative performance of the pattern models, we selected all pattern candidates for testing without pat-tern filtering. The only pattern selection criterion we used is whether the pattern contains one or more perpetrator terms and one or more target terms. If a pattern candidate has no perpetrator term or no target term, then it is rejected.
The selected patterns were used for extracting relevant in-stances for the test set of MUC-4 data. For each pattern can-didate of the prior pattern models, we found out the relevant sentences which contain the pattern as substructure of the dependency tree, and extracted the terms which are located at the same locations to the slot values on the pattern. For our proposed model, we performed pair-wise alignment be-tween each pattern and sentence, and extracted terms that are aligned to the slot values on the pattern from the align-ment results which have higher score than the predefined threshold value. The extracted terms from a sentence are integrated into an instance, and the performance of the task is measured by the precision and recall of the instances for each document.

For the alignment-based pattern model, we performed sev-eral experiments on the training set with various threshold values, and we discovered the best result with the thresh-old value, 0.75. Table 1 shows the experimental result for each pattern model. Our proposed model achieved much
