 Children spend significant amounts of time on the Internet. Recent studies showed, that during these periods they are often not under adult supervision. This work presents an au-tomatic approach to identifying suitable web pages for chil-dren based on topical and non-topical web page aspects. We discuss the characteristics of children X  X  web sites with respect to recent findings in children X  X  psychology and cognitive sci-ences. We finally evaluate our approach in a large-scale user study, finding, that it compares favourably to state of the art methods while approximating human performance.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Information Filtering ; H.1.2 [ Models and Principles ]: User/Machine Systems  X  Human Factors Human Factors Web Search, Children, Suitability, Filtering, Classification
In recent years children X  X  age of first contact with the In-ternet has decreased significantly [24]. At the same time their overall Internet consumption is growing. This tendency is accompanied by a growing number of children who, even at very young ages, search the Internet without any form of adult supervision. A recent UK study [21] found that up to 40% of British children aged 5-15 years regularly access the Internet without parental guidance. Regularly exposing children to potentially unsuitable web resources can become a significant danger to their well-being and development. Although popular web search engines such as Google and Yahoo! offer a wide range of  X  X afe search X  settings to pro-tect users from confrontation with undesired content, most of them state in their terms of service that their search func-tionality should not be used by minors. 1
State of the art search engines could greatly benefit from an automatic means of identifying suitable web pages. The current means of child-friendly information access are typ-ically listings of manually selected resources. Examples of this type of hand-picked web directories are Yahoo! Kids [5] and Ask Kids [2]. Because of the high demand for man-ual labour in its maintenance, this approach is less flexible and has a lower coverage than an automatic method could achieve. It is important to note that ensuring suitability of web pages exceeds merely filtering out erotic material. Well-studied topical approaches are capable of identifying such web pages reliably. Notions of text difficulty and age-appropriate web site design are however largely independent of the page topic and should strongly contribute to the de-cision of showing a particular page to a child. In this work we will demonstrate how the use of non-topical web page as-pects can enhance state of the art topical methods in making the suitability decision.

The contributions of this work are threefold: 1) We iden-tify the criteria of good children X  X  web sites and show how to encode them in features. 2) We conducted a large-scale user study to measure human performance for web page suitabil-ity assessment. The results are used to give a frame of ref-erence to an automatic approach X  X  performance evaluation. 3) We describe an automatic web site classification method, showing how purely topical models can be outperformed by models augmented by non-topical features.

The remainder of this work is structured as follows: We begin with a brief review of related research in Section 2. In Section 3, we introduce a range of web page features, that are combined in the classification scheme described in Section 4. Section 5 presents a comparison of our method against a state of the art approach as well as human perfor-mance. Finally, Section 6 concludes the paper with a discus-sion of our experimental results as well as their implications on future work in the field of accessible search.
To the best of our knowledge, there has not been any prior research on determining a web page X  X  suitability for children. There are however various threads of work in closely related fields that should be mentioned. Since the early 1950 X  X  lin-guists have devised formal means of assessing a given text X  X  http://www.google.com/accounts/TOS and http://info.yahoo.com/legal/us/yahoo/utos/ reading level [14]. These early readability measures are typi-cally linear combinations of several shallow textual features. In 2004, Collins-Thompson and Callan described a language modelling approach to measure readability [9]. Subsequently the research community focused on more and more sophis-ticated ranges of features [7, 22, 10], using machine learning techniques such as SVMs [23].
 Previous work on topical classification using the Open Directory Project X  X  large-scale web taxonomy reported the  X  X ids and Teens X  branch of the directory [4] to be among the most challenging categories with respect to classification [6, 20]. Some research projects even excluded the category from their scope [12], as they could not find a homogeneous un-derlying topical distribution. This tendency is already a first indicator that purely topical classification is not appropri-ate to distinguish web resources for children from those for adults.

Non-topical classification has been an active research field with advances in weblog identification [15], spam detection [8] and sentiment analysis [17]. In this work we will show that neither readability measures nor language modelling, when used in isolation, are strong predictors of a web page X  X  suitability for children. We present a more appropriate method that considers a combination of topical and non-topical web page aspects.
In this section we will discuss the cognitive specifics of children and how they can be encoded in features for clas-sification. We investigate suitability along two dimensions, child-friendliness and focus towards child audiences . The first dimension we will inspect with respect to suitability of web pages for children is child-friendliness. Its core con-cerns are ensuring children X  X  safety while providing a frus-tration free search environment [19, 16]. Child-friendliness of web pages is expressed in the page X  X  complexity of text, its presentation style as well as navigational aspects. Shallow features (12) 2 . Children X  X  text is commonly syn-tactically simpler than text for adults. To measure this we use a range of shallow textual features such as the total num-ber of words in the text or the average word length. Readability (8). An alternative approach towards mea-suring the syntactical complexity of a text computes several well-known readability scores such as SMOG or ARI [14] and uses them as suitability features.
 Parts of speech (5). A more high-level notion of the differ-ence in syntactical complexity between web sites for adults and those for children is expressed through this feature cat-egory. POS parse statistics are employed in the form of e.g., the average number of proper nouns or adjectives per sen-tence.
 Named entities (6). Typically, children X  X  texts are also semantically simpler than those for adults. This is for ex-
The numbers in brackets refer to the number of features in each category. ample expressed through the lower number of named entities per sentence in children X  X  stories [11]. We detect the entity types person , location and organization and use their counts as features.
 Out of vocabulary rates (8). In addition to the previ-ously mentioned aspects of text simplicity, children X  X  texts typically also use a more basic choice of words. To reflect this, we built 7 dictionaries of basic English words to com-pute the OOV rates of web pages. Adult pages are assumed to yield higher shares of unknown terms than children X  X  pages. An additional dictionary of academic terms is cre-ated for which the opposite tendency is expected.
 Wiktionary features (4). An alternative way of mea-suring textual complexity makes use of the Wiktionary free on-line dictionary. Basic terms are assumed to have short, unambiguous definitions. For each word the number and size of the definitions in Wiktionary are looked up. The page-wide averages are reported as features.
 Child-friendly web sites do not only display simpler con-tent, they should also present it accordingly. Recent studies pointed out how important appealing presentation and gen-eral fun were for children X  X  web portals [16].
 HTML features (10). In this category, we inspect the distribution of various HTML elements such as scripts and animations. They are assumed to occur with significantly different frequencies on children X  X  and adult pages. Visual features (8). Due to their comparably low lexical skills children often prefer visual content over textual re-sources. This category collects counts and size distributions of web page images and reports them as features.
 Neighbourhood analysis (2). Topical web classification tasks have been widely shown to benefit from an analysis of a page X  X  link neighbourhood. A page is obviously not bound to contain only topically related links. However, we expect this tendency to hold true for suitability. A good web portal for children will not link to adult pages. We use our classifier to determine each linked page X  X  suitability and report the share of pages that were classified as adult/kid with a given threshold confidence c threshold .
 During our manual assessment of web pages in the course of this work we frequently encountered pages that would clas-sify as child-friendly according to the previously discussed features but that did not convey the impression of having been designed for children specifically. To account for these pages we introduce the second dimension of suitability, focus towards child audiences.
 Language models (9). Language models are widely ac-cepted predictors of topical affiliation. We built several mod-els of different order (word-internal character trigram, un-igram and trigram) of ODP children X  X  web sites (ensuring disjointness with training and test sets), as well as textual re-sources from simple Wikipedia (http://simple.wikipedia.org) and simple Wiktionary (http://simple.wiktionary.org). The language model score P LM ( T | cat ) is computed as the max-imum likelihood estimate of the observed text T given the category X  X  language model.

For each term the number of occurrences within the cate-gory count ( t , cat ), divided by the overall number of category terms | cat | is computed. An interpolated character-n-gram model P backoff ( t ) serves for smoothing purposes in Jelinek-Mercer fashion with smoothing factor  X  .

Each web page is scored against these models and the re-sulting language model scores are reported as features. This method is able to detect topical patterns that occur fre-quently on children X  X  web pages.
 Reference analysis (2). To identify children X  X  web sites we investigated the occurrences of clue words such as  X  X id X  or  X  X hild X . We found that many pages mentioning children were actually meant for child audiences. There was however a significant number of educational pages, targeting parents and educators. Those pages deal with children as a subject rather than as an audience. In order to distinguish these two types of pages, we analysed text windows around clue word occurrences and created n-gram distribution statistics. We expect to find a different way of referring to children on adult pages where children are talked about (e.g.,  X  X our child X  or  X  X he average child X ) and children X  X  pages, where they are talked to (e.g.,  X  X s kids X ). We use the relative share of about-mentions and to-mentions on a page as features.
Where M n , page denotes the set of text windows of size n around the page X  X  clue word occurrences. p ( kids | w ) ex-presses whether the term w is a to-reference. c rel ( w ) is the ratio of n-gram w  X  X  occurrences on children X  X  pages versus its general frequency.  X  threshold is the threshold value of c Only terms w that reach this threshold are considered rele-vant. Best results could be achieved for a window size of 2 words (one before and one after the actual clue word) and a  X  URL features (5). Recent studies [16] found, that a page X  X  URL and domain name play a significant role in how well the page will be received by child audiences. Children typically struggle with remembering long and complex domain names. To account for this fact we measure features such as URL length or the maximum likelihood estimate of possible URL terms according to Wiktionary.
 Previous research [13] found splitting web pages into seg-ments beneficial for classification. We follow this idea by segmenting each page into title, headlines, anchor texts and main textual content. The previously introduced features are computed for each of these segments, (HTML, visual and
Term frequency  X  X id X  number of words (title) Kid X  X  pages 3-gram LM OOV Academic (title)
Average word length kid X  X  1-gram LM (title) neighbourhood features are still only considered globally per page.) thus greatly expanding the feature space from 79 to 241 dimensions. An exhaustive overview of all considered features can be found at http://blackboard.tudelft.nl/ bbc-swebdav/users/ceickhoff/ features.xls. Our training data was acquired from the ODP [4]. The di-rectory X  X   X  X ids and Teens X  branch contains non-exclusive age labels that identify a web page X  X  suitability for kids (up to 12 years), teens (13-15 years), mature teens (16-18 years) and adults. In order to keep a broad age mar-gin between children X  X  web pages and those for general au-diences we excluded the pages for teenagers and mature teenagers. Since several of the previously introduced fea-tures are language-dependent, we also exclude the  X  X orld X  and  X  X egional X  branches of the directory as these cover mostly non-English resources. The resulting training corpus con-tains 20,778 web pages. (6,225 for children and 14,553 for general audiences.) After an initial performance comparison of several state of the art learning methods on the training set we decided for a Logistic Regression model to combine our features. To reduce computational complexity we used an evolutionary method to evaluate feature subsets that would retain the predictive power and feature diversity while projecting the data into a lower-dimensional space. Due to the high dimen-sionality of the original feature space an exhaustive search was not feasible. The heuristically determined optimal set is described in table 1.

We can note, that while features from most categories are included, the majority of them originate from either the full page or its title, making these two segments the most important sources of information of page suitability. Our test collection is a set of 1800 real web sites (900 for children and 900 for adults) from the ODP. They were ran-domly sampled from all categories ensuring disjointness with the training data. All non-English web sites were excluded. We asked human judges to annotate the collection through the crowdsourcing platform CrowdFlower [3]. In order to overcome subjectivity in these labels we collected 5 inde-pendent judgements for each page and assigned the major-ity decision. The results of this user study give a frame of reference to the previously unstudied task of identifying web sites that are suitable for children.
 To measure our method X  X  performance we will compare it to a state of the art approach of topical classification. We follow Liu et al. [18] in using a Support Vector Machine classifier (C-SVM, radial basis kernel, cost = 1, = 0 . 001,  X  = 0 . 01) with unique terms as dimensions and their tf/idf-weighted counts as values. In order to limit computational complexity and reduce data noise we only considered those terms that occurred in at least 3 distinct training documents. The final performance of our classification method was de-termined by a single run against the previously unseen test set. The evaluation was done in terms of precision, recall as well as their harmonic combination in the F 0 . 5 -measure. We decided for the precision-biased version of the F-measure since in a filtering scenario an unsuitable page being shown to a child should be penalized more strongly than a missed children X  X  page. In order to give an impression of the clas-sifiers judgement confidence we additionally report the area under the ROC curve for each method. Table 2 shows our re-sults in comparison with both the text classification baseline as well as the majority labels assigned by human annotators. The exclusively topical SVM performs solidly and provides correct predictions most of the time. Our combined top-ical/ non-topical method however was able to outperform this baseline at  X  &lt; 0 . 05 significance level. (Determined using a paired two-sided Wilcoxon Signed Rank Test.) We could achieve an improvement of 14% over the SVM baseline while approximating human performance.
In this work we presented a combined topical/ non-topical approach to determining the suitability of web pages for children. Previous work on topical classification along web taxonomies either excluded age-dependent categories or re-ported low result scores. We show that with careful con-sideration a topical approach augmented by non-topical fea-tures is able to reliably predict web page suitability. Our method achieved significant improvements over a state of the art topical classification model while approximating hu-man performance. An especially challenging task for our classifier was to decide upon the suitability of pages that relied heavily on graphical elements such as Flash anima-tions while not providing accessible textual content. Future work on web site suitability should pay close attention to analysing actual image content in terms of image suitability or even image  X  X uteness X  in order to overcome this problem. This research is part of the PuppyIR project [1]. It is funded by the European Community X  X  Seventh Framework Programme FP7/2007-2013 under grant agreement no. 231507.
