 Categories and Subject Descriptors: H.2.8 [Database Management]:Database Applications-data mining General Terms: Algorithms Keywords: microeconomic data mining, catalog segmen-tation, clustering.
So far, onl yfew theoretical frameworks for mining useful knowledge from data have been proposed in the literature. The microeconomic framework for data mining [7] is con-sidered as one of the most promising of these models [9]. This framework considers an enterprise with a set of possi-ble decisions and a set of customers that, depending on the decision chosen, contribute different amounts to the overall utilit yof a decision from the point of view of the enterprise. It is assumed that the contribution of a customer is a possi-bl ycomplicated, function of the data available on that cus-tomer. The enterprise chooses the decision that maximizes the overall utilit yover all customers.

The microeconomic framework for data mining has in par-ticular been investigated for segmentation (clustering) prob-lems where the enterprise does not make an optimal decision per individual customer but chooses one optimal decision per customer segment. Catalog Segmentation, a specialized segmentation problem, has received considerable attention [6, 7, 10]: the enterprise wants to design k product catalogs of size r that maximize the overall customer purchases after having sent the best matching catalog to each customer 1 .
The Catalog Segmentation problem measures the util-it yof a customer in terms of catalog products purchased. But there are man yapplications where a customer, once attracted to an enterprise, would purchase more products beyond the ones contained in the catalog. In the case of tra-ditional brick-and-mortar retailers, for example, a customer typically would purchase additional products if the catalog has attracted him to visit the store. In the case of electronic commerce companies, as another example, there is still a substantial overhead involved in visiting a company X  X  web-site, and customers that have done so are likel yto purchase other products from that website that match their interests. Therefore, we investigate an alternative formulation where we measure the overall utilit yb ythe number of customers that have at least a specified minimum interest t in the cat-alog sent to them. A similar problem has been mentioned as an open problem in [6]. We call the new problem Customer-Oriented Catalog Segmentation problem. The major contri-butions of this paper are as follows:  X  We formall yintroduce several versions of the Customer-Oriented Catalog Segmentation problem and discuss its com-plexity. This problem was not analyzed in [6, 7].  X 
We present efficient algorithms for the Customer-Oriented Catalog Segmentation problem, exploring the paradigms of greed yand randomized algorithms.  X 
Our experimental evaluation on synthetic and real data demonstrates that the new algorithms yield catalogs of sig-nificantl yhigher utilit ycompared to classical Catalog Seg-mentation algorithms.

The rest of this paper is organized as follows. Section 2 reviews related work. In section 3, we formall yintroduce the Customer-Oriented Catalog Segmentation problem and an-alyze its complexity. Section 4 presents efficient algorithms for the Customer-Oriented Catalog Segmentation problem. Section 5 reports the results of our experimental evaluation and comparison. The paper concludes with a summar yand directions for future research in section 6.
The microeconomic approach to data mining has been in-troduced b yKleinberg et al [7] formalizing the optimization problem of enterprises based on data allowing the enter-prise to predict the utilit yof a customer w.r.t. a chosen decision. [7] focuses on a special class of such optimiza-tion problems, so-called segmentation problems, and shows that all discussed segmentation problems are NP-complete. The Customer-Oriented Catalog Segmentation problem was not analyzed. [6] also shows how sensitivity analysis of the microeconomic optimization problem can distinguish inter-esting from uninteresting changes of the decision of the en-terprise. In [7], the same authors investigate segmentation problems in more details. As an approximate algorithm for the Catalog Segmentation problem, the youtline a sampling-based algorithm (enumerating and measuring all possible partitions of the customers in the sample) and prove prob-abilistic bounds for its result qualit yand runtime.
Subsequently, approximate algorithms for the Catalog Seg-mentation problem have received considerable attention in the algorithms community. Asodi and Safra [2] proved that a polynomial time ( 1 2 + )-approximation algorithm, for any constant &gt; 0, would imply NP = P . Xu et al [13] de-veloped an approximation algorithm based on semi-definite programming that has a performance guarantee of 1/2 for general r and of strictl ygreater than 1/2 for r  X  n 3 .Inpar-ticular, 2-Catalog Segmentation can be approximated b ya factor of 0.67 when r = n/ 2.

In the data mining community, the Catalog Segmentation problem has been treated as a clustering problem. Stein-bach et al [10] show that the sampling-based enumeration algorithm[6] is infeasible for realistic problem sizes. Instead, the ypropose two alternative heuristic algorithms and a h y-brid algorithm (HCC) combining both of them. The first al-gorithm, Indirect Catalog Creation (ICC), groups together similar customers using the k-means algorithm and then de-termines the optimal catalog for each cluster. The second one, Direct Catalog Creation (DCC), iterativel yoptimizes k catalogs in a manner similar to the EM paradigm. The experimental evaluation demonstrates that DCC and HCC obtain higher overall profit than ICC.

Another research direction that has been inspired b ythe microeconomic view of data mining is the extension of asso-ciation rule mining to take into account the indirect profit of products that are frequentl ypurchased together with some other products. Brijs [3] proposes PROFSET to model the cross-selling effects b yidentif ying  X  X urchase intentions X  in the transactions. Lin et al [8] introduce a value added model of association rule mining where the value could represent the profit, the privac yor other measures of the utilit yof a frequent itemset. Wang et al [14] present a method for proposing a target item whenever a customer purchases a non-target item. This method maximizes the total profit of target items for future customers. Wang et al [12] ap-pl ythe principle of mutual reinforcement of hub/authorit y web pages in order to rank items taking into account their indirect profits. Addressing a similar problem, Wong et al [11] stud ythe problem of selecting a maximum profit sub-set of items based on modeling the cross-selling effects with association rules. While all these approaches incorporate the notion of utilit yinto the process of association rule min-ing, the yanal yze the relationships between sets of products without considering which customers have purchased these products. These methods aim at suggesting products to individual customers or selecting subsets of (globally) prof-itable items, but not at Catalog Segmentation or clustering customer databases.
In the microeconomic framework for data mining, there is an enterprise with a set of possible decisions and a set of customers that, depending on the decision chosen, con-tribute different amounts to the overall utilit yof a decision from the point of view of the enterprise. It is assumed that the contribution of a customer can be determined based on the data available on that customer. In our case, these data represent the set of products that a customer is interested in. The customer interest can be obtained either from aggre-gating the histor yof transactions of that customer or from obtaining explicit customer votes on the set of products. We assume that the (possibl yver ylarge) collection of customer data is stored in a Customers Database (Customers DB ).
In order to formall yintroduce our problem and for the presentation of our algorithms, we choose to represent the Customers DB as a bipartite graph. We distinguish two sets of vertices, one for the customers and another one for the products, and an edge denotes the fact that the correspond-ing customer is interested in the corresponding product. In the following, we introduce the graph-based representation and the related notations.
 Notations:
The original Catalog Segmentation problem can be de-fined in a more illustrative graph-based manner (partition version) as follows [13]: given a bipartite graph G =( P,C,E ) with | P | = m and | C | = n , find a partition of C = C 1  X  C 2  X  ...  X  C k ,and k subsets P 1 ,P 2 ,...,P k of P ,such that | P i | = r and any i , j , i = j , | P i  X  P j | does not have to be empty.
In the following, we formalize our Customer-Oriented Cat-alog Segmentation model. We first introduce MEC ( Maxi-mum Element Cover ), a well known combinatorial problem, whose goal is to find one catalog such that the maximum number of customers is interested in at least one of its prod-ucts.
 Definition 1. (Maximum Element Cover) Given any bipartite graph G = { P,C,E } and a positive in-teger r ,findasubset P  X  P with size r such that |  X  ( P ) maximized.

We generalize the problem for the case of k catalogs and call it k -MEC ( k -Maximum Element Cover) problem. Definition 2. ( k -Maximum Element Cover) Given any bipartite graph G = { P,C,E } and positive inte-gers r, k , find k subsets P 1 ,...,P k  X  P , each with size r , such that |  X  ( P 1 )  X  ...  X   X  ( P k ) | is maximized.
Finally, we introduce a threshold t representing the min-imum interest in a catalog necessar yto attract a customer, and extend k -MEC to k -MECWT ( k -Maximum Element Cover With Threshold t ).
 Definition 3. ( k -Maximum Element Cover With t ) Given any bipartite graph G = { P,C,E } and positive inte-gers r, k, t , find k subsets P 1 ,...,P k  X  P ,eachwithsize r , such that |  X  ( P 1 ,t )  X  ...  X   X  ( P k ,t ) | is maximized.
The task of the k -MECWT problem is to find k catalogs maximizing the number of distinct customers who have at least t interesting products in the catalog that is sent to them.

MEC is a well known NP-Complete problem and can be easil yreduced from Set Cover [5]. In [4], Feige proved that the simple greed yalgorithm, iterativel yselecting the next product that covers the largest number of uncovered cus-tomers, approximates MEC b ya ratio of at least 1  X  1 /e  X  0 . 632. He showed that this ratio cannot be further improved b yan yconstant number unless P = NP . More generally, by a simple Turing reduction we can show that the k -MECWT problem is NP-Complete for any k,t  X  1. Thus, k -MECWT is even harder than the classical Catalog Segmentation prob-lem which is NP-complete onl yfor k  X  2. As an example, for k =1,thereisan O ( | P | X | C | ) algorithm solving the Cata-log Segmentation problem that simpl ypicks the r products with the largest number of interested customers. But for k -MECWT and k = 1, the simple algorithm enumerating and testing all combinations of r products has a runtime complexit yof O ( | P | r  X | C | ).

From the point of view of clustering, k -MECWT can be understood as follows. The task of k -MECWT is to find k clusters of customers where each cluster is described b ya set of products and each customer is assigned to the cluster with the most similar cluster description. There are two constraints for acceptable clusterings: (1) the cardinalit yof each cluster description is r and (2) customers can onl ybe assigned to a cluster if the yhave a minimum similarit yof t to the cluster description. The clustering objective is to maximize the number of customers assigned to some cluster.
Since the Customer-Oriented Catalog Segmentation prob-lem is NP-complete, in this section, we present several ap-proximate, efficient algorithms. All algorithms are based on the graph representation of the Customers DB .Weem-plo yadjacenc ylists as our major data structure: for each product, the corresponding adjacenc ylist contains all cus-tomers interested in that product. The list head records the total number of customers in the list. The Customers DB is read once and transformed into the (main memory) adjacenc ylists that efficientl ysupport the manipulation of the graph structure from the point of view of products. For each customer, we need a counter denoting the number of additional interesting products that this customer requires to be attracted b ythe current catalog. This data structure is much smaller than the adjacenc ylists, and the overall space complexit yis O ( | E | + | C | )= O ( | E | ), i.e. proportional to the number of edges in the graph G. In subsection 4.1, we explore different greedy, deterministic algorithms. In partic-ular, the Best-Product-Fit algorithm constructs one catalog at a time b ychoosing the next product for that catalog based on some heuristic qualit ycriteria. The Best-Product-Fit al-gorithm is ver yefficient but, due to its greed ynature, ma y return a solution which is onl ylocall yoptimal. Therefore, we also investigate randomized algorithms (subsection 4.2) that iterativel yoptimize the result of a greed yalgorithm, e.g. the Random-Product-Fit algorithm. The basic idea of greed yalgorithms for the Customer-Oriented Catalog Segmentation problem is as follows: one catalog is constructed at a time b ychoosing the  X  X est X  next product for the current catalog. The  X  X oodness X  of a prod-uct is measured b ycriteria such as the number of customers interested and the products alread ychosen for the catalog.
Since our objective is to maximize the overall number of customers that have enough interests in at least one of the catalogs, a naive greed yalgorithm would alwa ys pick the re-maining product with the largest number of interested cus-tomers. Customers that are alread yinterested in at least t products from the current catalog cannot increase the over-all number of customers attracted b ythat catalog and are not considered b ythe calculation of this product goodness.
While the naive greed yalgorithm is ver yefficient, it does not take the threshold t into account. This decreases the qualit yof its resulting solutions whenever the product with the maximum number of interested customers does not cover (a good number of) customers that have alread ybeen cov-ered b ycatalog products.

Since the naive greed yalgorithm does not take the thresh-old t into consideration when choosing the next product, it ma ychoose products interesting for customers whose over-all interests in the catalog ma ynever reach the specified threshold. To avoid this waste of resources, we need to increase the priorities of products connected to customers which are alread yinterested in other catalog products. The Best-Product-Fit algorithm, that will be introduced below, assigns a score to each product based on the (remaining) customers interested in that product and the number of ad-ditional interesting products that these customers need to be attracted to the current catalog. Before stating our al-gorithm, we define some notions based on a Customers DB in graph representation G =( P,C,E ).

CustomersCovered = { customers who have already t in-terests in one of the catalogs } ; C := C  X  CustomersCovered .

Counter ( c ) =the counter associated to customer c .Ini-tially, Counter ( c )= t .

We define the score of product p w.r.t the current catalog cat b ythe following equation:
Score ( p )= + { c  X  C | X  p  X  cat, ( p ,c )  X  E, ( p,c )  X  E } .
The score depends on two terms. The first term represents the weighted number of all customers interested in product p , where the weight of the customer is the inverse of its counter (the weight is the higher, the more interests the customer alread yhas in the current catalog). The second term focuses onl yon customers that are alread yinterested in at least one of the current catalog products and measures how man yof these customers are also interested in p .As an optimization, for the second term, we do not count the customers who need more than r  X  X  cat | further products to be full ycovered. The pseudocode of the Best-Product-Fit algorithm is as follows:
The runtime complexit yof the Best-Product-Fit algorithm is O ( kr | E | )where | E | is the total number of edges in the graph, i.e. the total number of interests over all customers.
The algorithm requires onl yone scan of the database if the memor ycan hold the necessar ydata structures. Other-wise, we can adopt the divide-and-conquer approach to scale up the Best-Product-Fit algorithm. First, we partition the Customers DB into several subsets DB 1 , DB 2 ,..., DB p that each can fit into the memory. Then we apply the Best-Product-Fit algorithm to each subset DB i to determine k catalogs and combine those k  X  p catalogs into k final catalogs. This algorithm still requires onl yone database scan.
Greed yalgorithms find a local optimum onl y. The yma y include products into their catalogs that are interesting for man ycustomers that ultimatel yma ynot have enough inter-est (i.e. t interesting products) in the catalog. This weak-ness is due to the heuristic nature of the qualit ycriterion for individual products and to the deterministic nature of the algorithm. The proposed greed yalgorithm has no means of backtracking from some suboptimal choice of a catalog prod-uct. This problem is illustrated b ythe example in Figure 1with k =2, t =2and r = 2. The Best-Product-Fit al-gorithm would pick Diaper first since it has largest number of interested customers and then select Beer as the second product of Catalog 1 because it covers two customers who have alread ybeen interested in Diaper . Diaper is still the product with the largest number of interested customers who have not yet been covered by the Catalog 1 and is therefore chosen as the first product of Catalog 2 . As the second prod-uct, VCR is chosen because it is interesting for customer 7 (that is alread yinterested in the first catalog product) and for customer 8 and 9. In this solution, onl ycustomer 7 meets the interest threshold, while Catalog 2 = { VCR,Coke } cov-ers three customers (7,8,9). Due to the lack of a look-ahead mechanism, the choice of Diaper as the first product of Catalog 2 leads into a local optimum that cannot be escaped b ythe greed ymethod.
 Figure 1: Customers DB in Graph Representation
In order to overcome these limitations, randomized algo-rithms seem to be promising. Since the performance of ran-domized algorithms cruciall ydepends on appropriate initial solutions, we propose to combine the greed ydeterministic algorithm with a randomized algorithm in a two-step ap-proach (Random-Product-Fit):  X 
A greed ydeterministic algorithm (e.g. Best-Product-Fit) is used to efficientl ydetermine a good solution of the Cus tomer-Oriented Catalog Segmentation problem.  X 
The resulting catalogs and corresponding clusters are iter-ativel yoptimized b yrandoml yreplacing one catalog product b ya non-catalog product (Random-Product-Switch).
There are different alternatives for the second random-ized step with more or less deterministic aspects. A fully randomized algorithm would randoml yselect one of the cat-alogs, one of its products and one non-catalog product for replacement. More deterministic versions would select the catalog and the product to be replaced in a deterministic way, e.g. in a round robin fashion. There are two major types of termination conditions for randomized algorithms. The ycan terminate either after a user-specified number of iterations or as soon as the number of customers covered no longer increases. For simplicity, we propose a fully random-ized algorithm with a user-specified number of iterations.
To efficientl ysupport our randomized algorithm, we in-troduce an additional data structure for each customer c consisting of a customer id ( Id ) and one list of products for each of the catalogs recording the interesting products (CatalogInterests[ k ]). This data structure enables us to ef-ficientl ycalculate the gain (  X  ) in the number of customers covered caused b ythe replacement of catalog product p by p . The space requirement of this additional data structure is 4 k  X | C | bytes. The pseudocode of the Random-Product-Switch algorithm is as follows:
The runtime complexit yof the Random-Product-Switch method is O ( sk | C | ) since in the second step, in each itera-tion, for each customer we need to access all k elements of CatalogInterests[ k ] in order to update the number N customer of all covered customers. As the two-step Random-Product-Fit approach consists of (1) Best-Product-Fit (2) Random-Product-Switch methods, the overall runtime complexit yof Random-Product-Fit is O ( kr | E | )+ O ( sk | C | ).
In this section, we report the results of our experimental evaluation using synthetic as well as real datasets. The syn-thetic datasets were generated using the well-known IBM data generator [1] with different parameter settings. The real dataset records the purchasing transactions of the cus-tomers of a large Canadian retailer over a period of several weeks. Since the Customer-Oriented Catalog Segmentation problem has not yet been addressed in the literature, we compare our proposed algorithms with one of the state-of-the-art algorithms [10] for the related Catalog Segmentation problem. We choose DCC as our comparison partner be-cause of the following two reasons. First, the experimental evaluation in [10] showed that DCC, together with HCC, achieved the highest qualit yresults. Second, DCC scales better to large customers databases than HCC because DCC can, different from HCC, use storage efficient adjacenc ylists instead of an adjacenc ymatrix. Due to the limitation of space, we onl yreport the results of the algorithms w.r.t. utility(quality) and omit the efficiency results.
We evaluate the qualit yof the catalogs obtained b your algorithms Best-Product-Fit and Random-Product-Fit as well as DCC. Since DCC has been developed for a related, but different problem formulation, we measure the result-ing qualit yw.r.t. both the objective functions of classi-cal Catalog Segmentation (catalog products purchased) and Customer-Oriented Catalog Segmentation (customers cov-ered). To demonstrate the extra profit achievable b yCust omer-Oriented Catalog Segmentation, we also measure the number of non-catalog products that are additionall ypur-chased b ycustomers interested in their corresponding cat-alogs. We have experimented with several different syn-thetic datasets, but here we onl yreport results for a dataset with | C | =50 , 000, | P | =7 , 374 and | E | = 376 , 713 that seems to be representative for a medium-sized customers database. For the real dataset, | C | =45 , 394, | P | =23 , 182 and | E | = 355 , 908.

We compare the numbers of the customers covered (i.e., interested in at least t catalog products) w.r.t. t, k and r on the synthetic dataset. The impact of different values of t w.r.t. the numbers of customers covered is depicted in Fig-ure 2(a) in the case of r =80and k = 3, both Best-Product-Fit and Random-Product-Fit yield higher coverages of cus-tomers than DCC, while Random-Product-Fit always covers more customers than Best-Product-Fit.

While the effects of different k values on the total number of covered customers in the case of r =60and t =2shown in Figure 2(b), reflects the fact that more customers will be covered if more catalogs are created. Random-Product-Fit method always covers the largest number of customers since it has more chances to check and switch more catalog prod-ucts to cover more customers. Best-Product-Fit still covers more customers than DCC. These results are confirmed by our experiments on the real dataset. The corresponding numbers of covered customers in Figure 5(a) shows the cor-responding numbers of covered customers for r =30and t = 2. It also illustrates that the advantage of Random-Product-Fit compared to Best-Product-Fit grows with in-creasing k values.

The relationship between the size r of the catalog and the number of covered customers with k =3and t =2 provided in Figure 3(a), has similar results as Figure 2(b). For example, for r = 100, the catalog generated b yRandom-Product-Fit attracts 2,700 (22%) more customers than the DCC catalogs. (a) Customers covered vs. t (a) Customers covered vs. r
The profit in terms of the total numbers of catalog prod-ucts and the numbers of extra products (beyond the cata-logs) w.r.t. t, k and r are also investigated on the synthetic dataset. When measuring the number of catalog products (a) Products covered vs. k (a) Customers covered vs. k covered, these experiments favor DCC due to the different objectives of the comparison partners.

We observe the numbers of products covered w.r.t differ-ent values of t in the case of r =80and k =3inFig-ure 3(b). It is expected that DCC covers more products in the catalogs than our methods, but both Best-Product-Fit and Random-Product-Fit have higher extra profits on non-catalog products than DCC. Finally, Random-Product-Fit always covers more extra products than Best-Product-Fit.
It is clear to see the effects of different k values on the same qualit ymeasures for r =60and t = 2 in Figure 4(a). All three methods have similar performance w.r.t. the profit on catalog products. However, both of our methods clearly outperform DCC w.r.t. the extra profit from non-catalog products. For example, for k = 5, Random-Product-Fit achieves an extra profit of 40,000 products (30%) compared to DCC. We obtain similar results on the real dataset, e.g. with r =30and t = 2 ( Figure 5(b)). Figure 4(b) shows how the size r of the catalog affects the number of covered catalog products and extra products with k =3and t =2. The results are comparable to the results in Figure 4(a).
The microeconomic view of data mining is one of the most promising theoretical frameworks capturing the notion of utilit yof the discovered knowledge. This data mining framework has in particular been investigated for segmen-tation problems such as the Catalog Segmentation problem. In this paper, we have investigated an alternative problem formulation measuring the overall utilit yb ythe number of customers that have at least a specified minimum interest t in the catalog. We have formall yintroduced several versions of the Customer-Oriented Catalog Segmentation problem and analyzed its complexity. We have presented efficient, approximate algorithms adopting the paradigms of greedy and randomized algorithms. Our experimental evaluation on synthetic and real data showed that the new algorithms yield catalogs of significantly higher utility compared to clas-sical Catalog Segmentation algorithms. Our best algorithm, Random-Product-Fit, achieves an excellent tradeoff between qualit yand runtime b yoptimizing a greedil ydetermined ini-tial solution in a randomized manner.

We believe that this research does not onl yhave man y promising applications, but also indicates several interest-ing directions that deserve further investigation. In order to better judge the relative utilit yvalues obtained b ydif-ferent algorithms, it is necessar yto develop methods to es-timate the utilit yof the optimal solution. The optimum can onl ybe approximated since k -MECWT is NP-complete even for k =1 ,t =1. Tomakethe k -MECWT model even more realistic, it could be generalized b yreplacing the crisp threshold b ya probabilistic threshold, i.e., a customer would be attracted to a catalog with some probability. The Customer-Oriented Catalog Segmentation model should also be studied in the case that the number of catalogs is not set in advance, but there is a fixed cost for each catalog. Finally, Customer-Oriented Catalog Segmentation could be combined with association rule mining techniques to find novel types of customer purchase patterns.
 Acknowledgements We thank Dr. Pavol Hell for valuable comments and sug-gestions on this study. [1] R.Agrawal. IBM synthetic data generator. 1994. [2] V.Asodi and S.Safra. On the complexity of the catalog [3] T.Brijs, B.Goethals, G.Swinnen, K.Vanhoof and G.Wets. A [4] U.Feige. A threshold of ln n for approximating set cover, J. [5] M.R.Garey and D.S.Johnson. Computers and [6] J.Kleinberg, C.Papadimitriou, and P.Raghavan. [7] J.Kleinberg, C.Papadimitriou, and P.Raghavan. A [8] T.Y.Lin, Y.Y.Yao and E.Louie. Mining values added [9] H.Mannila. Theoretical Framework for Data Mining. In [10] M.Steinbach, G.Karypis and V.Kumar. Efficient [11] R.C.W.Wong, A.W.C.Fu and K.Wang. MPIS: [12] K.Wang and M.Y.Su. Item selection by  X  X ub-authority X  [13] D.Xu, Y.Ye, and J.Zhang. Approximate the 2-Catalog [14] K.Wang, S.Q.Zhou and J.W.Han. Profit Mining: From
