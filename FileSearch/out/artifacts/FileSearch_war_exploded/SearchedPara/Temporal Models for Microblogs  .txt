 Time information impacts relevance in retrieval for the queries that are sensitive to trends and events. Microblog services particularly focused on recent news and events so dealing with the temporal aspects of microblogs is essential for providing effective retrieval. Recent work on time-based retrieval has shown that selecting the relevant time pe riod for query expansion is promising. In this paper, we suggest a method for selecting the time period for query expansion ba sed on a user behavior (i.e., retweets) that can be collected easily. We then use these time periods for query expansion in a pseudo-relevance feedback setting. More specifically, we use the difference in the temporal distribution between the top retr ieved documents and retweets. The experimental results based on the TREC Microblog collection show that our method for selecting periods for query expansion improves retrieval performance compared to another approach. H.3.3 [ Information Search and Retrieval ]: Information Search and Retrieval Algorithms, Experimentation Time-based model, microblogs, query expansion Time information impacts relevance in retrieval for queries that are sensitive to trends and even ts. A microblog (e.g., Twitter) is a medium where users post short messages to broadcast current events or their personal opinions. In particular, microblog services focus on recent issues, since users in a microblog community can express opinions and discuss soci al issues with other users immediately. Due to this highly temporal nature, incorporating time information into ranking is crucial in microblog retrieval. Microblog ad-hoc retrieval, in gene ral, aims to find relevant and the most recent content for the queries that are related to social issues [18]. The TREC 2011 microblog track pursued a similar goal where TREC provided topics with each query's timestamp that indicates when this query was issued. According to the guidelines, no documents newer th an a given query's timestamp should be retrieved and the fina l ranking should be sorted in descending chronological order (from the latest to the oldest). Given these assumptions, modeli ng the temporal aspects of microblog queries is a significant issue for this task. In previous work, researchers focused on identifying recency-sensitive (or temporal) queries and incorporating time into the retrieval model. For example, Li and Croft [10] defined two types of time-based queries in TREC vol umes that contain many news documents and proposed a time-based language model. Diaz and Jones [3] proposed a temporal profile of the query to predict retrieval performance in a TREC news collection. They then used the temporal profile to classify the query into three temporal query classes [6]. The advent of social media (e.g., blogs, microblogs) has increased the interest in time-based retrieval models. Recent studies on time-based models in IR have focused on using temporal distributions of retrieved documents in the pseudo-relevance feedback setting [2,7,12,15]. This work has shown that selecting a relevant time period for a specific query, and then extracting expanded te rms by using weights derived from the relevant time can improve retrieval performance. Here, we hypothesize that a user behavior (i.e., retweeting) can indicate the relevant time period for a query. As we mentioned, microblog services mostly invol ve inter-communication between users. In particular, information propagation through forwarding other users X  content is well-know n as a prominent characteristic of microblog services. Indeed, we found that retweeting can be used for identifying the relevant time period for temporal queries. Figure 1: The temporal distribution ( X  X exico drug war X ) For example, in Figure 1, we disp lay the temporal distribution of relevant documents, top retrieve d documents, and retweets (RT) for a TREC query  X  X exico drug war X . This graph shows us that RT (bold line) tends more closely follow the occurrence of the relevant documents. More specifi cally, we use the difference in the temporal distribution between the top retrieved documents and retweets to find the relevant time period. We then do query expansion from the top retrieved documents in that time period. We evaluated with TREC Microblog track data, and the results show that our approach improves the retrieval performance against strong baselines. Further analysis shows that our method extracts more relevant terms for the query by selecting relevant time periods and using only the doc uments in thos e time periods. Previous work has studied time-ba sed models and our approach is related to some of this work. Li and Croft [10] defined two types of time-based queries in TREC collections that contain news archives: one always favors the most recent documents and the other has relevant documents within a specific period in the past. To incorporate time information into retrieval models, they proposed a time-based language m odel using a prior based on an exponential or a normal distribution depending on the types of recency queries. Efron and Golovchinsky [4] proposed an estimator for the rate parameter of an exponential distribution that incorporates query-specific inform ation. They also suggested a time-smoothing language model that uses a time fact or to estimate the mixing parameter for language model smoothing. Diaz and Jones [3] proposed a te mporal query model, denoted P(t|Q) , which is defined as the normalized sum of the relevance scores of retrieved documents that are published at time t for query Q . They used temporal features for query performance prediction [3] and temporal query classification [6] tasks. Keikha et al. proposed a time-based rele vance model [7] for blog feed retrieval, which uses the P(t|Q) introduced in [3] as a weight of the terms in the pseudo-relevance feedback setting. In this work, we extend the framework of the time-based relevance model to incorporate the temporal factor into ranking. That is, we estimate P(t|Q) by using the temporal distribution of retweets instead of using the normalized sum of the relevance scores. Dakka et al. [2] suggested a general framework to estimate P(t|Q). They arranged the top retrieved doc uments into bins and assigned estimated relevance value to these bins. Peetz et al. presented an adaptive temporal query modeling [15] for blog feed retrieval, in that they analyzed the top retrieved documents in terms of temporal histogram to find the bur sts. They used documents with the highest scores from the bur sts for query expansion and weighted each feedback document with the distance from the peak that contains most documents. Massoudi et al. [11] proposed a query expansion model for microblogs, which selects terms te mporally closer to the query submission time. Their model is supposed to work well for finding documents related to events currently happening but, not as well for past events. We found that many topic queries were related to events occurring in the past rather than the query time. Metzler et al. [12] proposed a temporal query expansion method for microblogs based on the temporal co-occurrence of terms in a timespan. They first performed ps eudo-relevant timespan retrieval for an event query (e.g., earthquake ) and used those timespans for query expansion. Although their goal was retrieving a ranked list of historical event summaries, the temporal query expansion method showed that selecting re levant timespan is crucial for query expansion for microblog documents. If the temporal query expansion works for an event query, it might be useful for ad-hoc search queries. Our temporal model for microblogs builds upon a time-based relevance model [7] that incorporates time factors into the language model framework. In this section, we first introduce the time-based relevance model in detail and then, suggest a method for selecting the relevant time using retweets for the query. Microblog documents contain many cases of word variations, hashtags, and internet slangs. This increases the vocabulary mismatch problem [12] in microblog retrieval. In our preliminary experiments, we found that releva nce modeling [9] is helpful for this problem, since it can potentially address issues related to synonymy and polysemy. The pse udo-relevance model generates expansion terms based on the top k retrieved documents (denote R ) as Eq. (1) Keikha et al. [7] proposed a time-based relevance model which incorporates time factor into relevance model framework. They introduced a generative model of the query that first selects a time and then selects a term based on the time and query as Eq. (2) P(w|t,Q) can be computed by product sum of P(w|d) and P(d|t,Q) over all relevant docum ents published in time t (denoted R Unlike P(d|t,Q) was set to be uniform [7], in this work, we extend their framework. Based on a simplifying assumption, P(d|t,Q) can be equal to P(d|Q) since the time t is already encoded in choosing d . Therefore, we get the Eq. (3) by using Bayes rule and independence assumption between the query terms, where P(Q) is eliminated based on the rank equivalence. When we substitute the Eq. (3) into Eq. (2), we get the following final equation, Eq (4). This formulation allow us to extract the expanded terms from the relevant documents published in time t , weighted by P(t|Q), an arbitrary temporal model of the query. In next section, we suggest a novel method for estimating P(t|Q) . Microblog users often quote or forward other users X  content (e.g., retweeting). We might think of some influences on retweeting such as content, network, and temporal influence [16]. For example, a famous celebrity X  X  tweet can be retweeted often due to the popularity of the user (network influence). People also tend to broadcast newsworthy tweets (content influence). A recent study [8] reported that 75% of retweets occur within a day (temporal influence) after posting. In other words, old content is unlikely to be retweeted. One possible reason for this behavior is because microblog documents can be written in a very short time and also tend to be ephemeral, in contra st, other user-generated content (e.g., blog) or news needs enough time to be published. Indeed, retweeting can be done by a simple click. Due to these properties of retweets, we can estimate the time period when an event happened and people discussed that issue heavily in the past, and we can then consider this as a relevant time period for the query. To identify the relevant time period for the query, we need the top N retrieved documents returned by an initial retrieval model. We found that our method performs well when N =500. We compute P(t|RT,Q) and P(t|D,Q) as described in Eq. (5) and Eq. (6), respectively, where #docs(t,RT,Q) is the number of retweets posted at time t in top N retrieved documents returned by query Q and #docs(t,D,Q) is the number of doc uments posted at time t in top N retrieved documents returned by query Q . In this work, the unit of temporal granularity is a day. Given these probabilities, we de fine an indicator function that has the value 1 if P(t|RT,Q) is higher than P(t|D,Q), and 0 otherwise. We normalize it by sum of for all time t and get the P(t|Q) as Eq. (7). Note that substituting Eq. (7) into Eq. (4) indicates that only the document posted in that time t will be used for query expansion. In other words, we construct th e pseudo-relevance feedback set with the documents occurred in the most active days in terms of retweeting. We exclude the retweets from the pseudo-relevance feedback set on purpose, since TREC assessors explicitly judged all retweets as non-relevant. The number of the documents considered in the expansion (i .e., fbDocs) and the number of expanded terms (i.e., fbTerm) are tuned in 5-fold cross-validation in our experiments. If there is no relevant time period for a query, that is, all P(t|Q) equals to zero for all time t , we use all feedback documents for query expansion, just as the original pseudo-relevance model (back-off model). We used the TREC 2011 Microblog collection for evaluation. This collection consists of approximately 16 million tweets and 49 topics (MB050 topic omitted due to the absence of relevant tweet). Since TREC judged non-English tweets as non-relevant, we filtered out non-English tweets by using both the language property (i.e., lang=en) and characters-set (i.e., ASCII). We also constructed an English word dictionary from the WSJ 87-92 newswire collections, and elimin ated documents whose fraction 46.1% tweets were removed in total. To satisfy the constraint in terms of final ranking order, we first rank the top k results based on the relevance score and re-sort them in descending chronological order based on tweet id. We index all tweets using the Galago retrieval system, and stem with the Porter2 stemmer. We use a stopword list which is constructed from web corpus [1]. To tune the language model parameters (e.g.,  X  ), we used a training corpus with 59 topics and approximately 5,900 relevance scores that were manually judged by twelve computer science students. The training corpus c onsists of 17M tweets that had been crawled using the Twitter API. We found that there were no common tweets between the training and the evaluation data. We annotate retweets in two ways. First, we match RT signatures , (i.e., RT @username) on the tweet cont ent [5,14]. Second, we use the retweet count in the metadata provided in JSON format. This retweet count is counted only when the retweet button in the Twitter service is clicked. We do not consider the number of times a document is retweeted in this work. We exclude the retweets that contain few query terms, for example, the retweet should contain all query terms if the number of query terms is less than two. If the number of query term is more than two, the retweet should not omit more than one query term. We use six variants of language models as our baselines: a query likelihood language model with Dirichlet smoothing ( QL ), a sequential dependence model ( SDM ) [13], a full dependence model ( FDM ) [13], a relevance model ( RM ), a relevance model based on SDM ( SDRM ), and a relevance model based on FDM ( FDRM ). We denote the performance of our approach based on a relevance model as RM-T . Accordingly, SDRM-T and FDRM-T stand for the performance of our approach based on SDRM and FDRM respectively. In addition, we add a time-based relevance model ( TBRM ) [7] as our strong baseline. Similarly, TBRM-SD and TBRM-FD stand for the performance of the time-based relevance model based on SDRM and FDRM respectively. To evaluate the performance, we used two measures, MAP and precision at 30 (P@30). P@30 was used as the official measurement in the TREC 2011 Microblog track ad-hoc task. We display the performance of the baselines and our approach in Table 1. The results show that pseudo-relevance feedback models (e.g., RM, SDRM, and FDRM) perfo rm better than other baseline language models (e.g., QL, SDM, and FDM). This supports our hypothesis that a relevance model can potentially address the vocabulary mismatch problem. The results also show that our approach improves retrieval performance in all cases. An asterisk denotes significant difference compared to pseudo-re levance model baselines and a plus denotes significant difference compared to time-based relevance model baselines by two sided paired randomization test [17] (p-value&lt;0.05). Significant differences in precision at 30 were observed in RM-T, SDRM-T, and FDRM-T compared to RM, SDRM, and FDRM respectively. We note that our approach outperforms time-based relevan ce models (i.e., TBRM, TBRM-SD, and TBRM-FD). Significant differences in MAP were observed in FDRM-T compared to FDRM and TBRM-FD. In Table 2, we display sample terms of query expansion for the query  X  X eith Olbermann new job X  in RM (left) and in RM-T (right). As we can see, more relevant terms such as  X  X oin X ,  X  X iberal X , and  X  X ontroversial X  appear in our approach. Table 2: Expanded terms for  X  X eith Olbermann new job X  We also display the query-wise performance comparison of the all queries that are affected (46.9%) by our approach compared to RM baseline in Figure 2. This s hows that our approach improves the performance by a large margin for some topic queries; whereas it decreases the performance by a small margin for a smaller number of topic queries. Figure 2: Query-wise performance comparison  X  the increase (+) / decrease (-) of the number of relevant document at 30 of RM-T compared to RM In this work, we suggested a method for selecting the time period based on a user behavior (i.e., retweets) that can be collected easily. We incorporated these time periods for query expansion in a pseudo-relevance feedback setting. To that end, we extended the previous work on a time-based relevance model. More specifically, we used the difference in the temporal information from the top retrieved documents and retweets to capture time periods with many relevant docum ents. The experimental results based on the TREC Microblog track collection and query analysis showed that our approach for que ry expansion improves retrieval performance compared to the language model baselines and another approach incorporating time into a ranking criteria. This work was supported in part by NHN Corp. and in part by the Center for Intelligent Information Retrieval. Any opinions, findings and conclusions or reco mmendations expressed in this material are those of the authors X  and do not necessarily reflect those of the sponsor. [1] T. Brants and A. Franz. We b 1T 5-gram Version 1, 2006. [2] W. Dakka, L. Gravano, and P. Ipeirotis. Answering general [3] F. Diaz and R. Jones. Using te mporal profiles of queries for [4] M. Efron and G. Golovchinsky. Estimation Methods for [5] L. Hong, O. Dan, and B. D. Davison. Predicting popular [6] R. Jones and F. Diaz. Tempor al profiles of queries. ACM [7] M. Keikha, S. Gerani, F. Crestani, Time-based Relevance [8] H. Kwak, C. Lee, H. Park, a nd S. Moon. What is Twitter, a [9] V. Lavrenko, W. B. Croft. Relevance-based language [10] X. Li and W. B. Croft. Time-based language models. In [11] K. Massoudi, E. Tsagkias, M. de Rijke, and W. Weerkamp. [12] D. Metzler, C. Cai, E. Hovy, Structured Event Retrieval over [13] D. Metzler, W. B. Croft. A Markov random field model for [14] N. Naveed, T. Gottron, J. K unegis, and A. Che Alhadi. [15] M-H. Peetz, E. Meij, M. de Rijke, W. Weerkamp, Adaptive [16] H.K. Peng, J. Zhu, D. Piao, R. Yan and Y. Zhang. Retweet [17] M. D. Smucker, J. Allan, B. Carterette, A Comparison of [18] J. Teevan, D. Ramage, and M. Morris. #Twittersearch: A 
