 The analysis of large scale data logged from complex cyber-physical systems, such as microgrids, often entails the discovery of invari-ants capturing functional as well as operational relationships under-lying such large systems. We describe a latent factor approach to in-fer invariants underlying system variables and how we can leverage these relationships to monitor a cyber-physical system. In partic-ular we illustrate how this approach helps rapidly identify outliers during system operation.
 H.2.8 [ Database Applications ]: Data mining Regression, Latent Factors, System Invariants, Outlier Detection.
In recent years, with the rapid growth in data logged from mod-ern devices in a distributed system, the need for having stronger knowledge discovery methods has attracted significant attention [28]. Concomitantly, the size and complexity of these systems have be-come a burden for administrators in detecting failures and repair-ing them [13, 25]. These challenges inspired us to characterize and track anomalies in cyber-physical systems by correlating all moni-tored data across the system.

According to [15],  X  detecting anomalies that occur only within individual variables is often trivial, while detecting correlation anoma-lies is much harder and is practically important in fault analysis of complicated dynamic systems  X . In a complex cyber-physical sys-tem, such as a smart grid (Fig.1), while some of the relationships between time series can be directly observed, other mutual depen-dencies are significantly complex to extract computationally. A typical cyber-physical system may include tens of time series with hundreds of mutual dependencies, where a large number of them are not directly observable. In the past, researchers have tried to infer existing linear relations using regression models [17] or by c  X  harnessing the structure of causal networks [4]. However, due to the complexity of modern systems, we must go beyond direct lin-ear correlations in understanding them.

In this paper, we aim to use a more realistic approach to dis-cover hidden patterns and indirect relationships among devices by employing latent variables in regression models. Specifically, we harness hidden factors derived by factor analysis and use them in regression models. We perform various experiments on synthetic and real datasets including wireless sensor networks and microgrid datasets. Furthermore, we use graph representations for better vi-sualization of relationships which aids in discovering system-wide anomalies. Results show that the use of invariants derived with latent factors helps us to monitor large scale complex systems and discover outliers more precisely. We also propose a ranking method to score system-wide anomalies.

Our key contributions are thus:
The high complexity of modern distributed cyber-physical sys-tems urges us to enhance the self-management capabilities of these systems. Cyber-physical systems such as microgrid systems have a high degree of heterogeneity (in terms of shape, trend, and peri-odicity) that requires us to have a general tool to profile a variety of behaviors. Moreover, due to the nature of these systems, we may observe abrupt regime changes, seasonal patterns, and pair-wise relationships among time series [11]. Ding et al. proposed an ensemble of different approaches to tackle these problems in [11]. As stated in [28], traditional computational techniques cannot be used to model complex cyber-physical systems for data analytic purposes in a straightforward manner. There have been multiple research efforts to model complex dynamic systems such as infer-ring/visualizing the input-output relationships or predicting state switches/changes [28].

Guofei et al. [16] proposed a concept named flow intensity and used the ARX (autoregressive exogenous) model to quantify the relationship between each pair of flow intensities. If such a rela-tionship holds all the time, they are considered as invariants of the underlying system. This model has been successful in characteriz-ing complex systems and in supporting different system manage-ment tasks such as fault detection and localization. However, one of the main disadvantages of this method, as cited in [13], is that the complexity of algorithm in order to find all invariants is high. In this model, they look at two flow intensities (timeseries) where one of them is considered as input and the other one as output sig-nal. Note that the differentiation of input and output time series are unknown and such labeling can occur only after examining both directions and evaluating which assignments lead to higher scores. The ARX model posits the following relationship between two flow intensities of y (output) and x (input): y ( t ) + a 1 y ( t  X  1) + ... + a u y ( t  X  u ) where u , v , and l are the order of the model and determine the num-ber of previous steps that are affecting the current output. a b  X  X  are coefficient parameters that reflect how strongly a previous step is affecting the current output. Equation 1 can be solved using a least squares method (LSM) and the fitness score will indicate whether the model fits the observed data appropriately [16]. Let us assume that we have observed a set of n time series, more cyber-physical systems. For a time series x i ( t ) , we represent the vector of samples at time steps t k , ... , t k + w as follows: Furthermore, we use X i to represent the time series x i ( t ) as a ran-dom variable. In other words, x i ( t ) is a time series whose samples are drawn from a random distribution represented by random vari-able X i .

In any type of cyber-physical system, there are various corre-lations and inter-dependencies among time series. In large cyber-physical systems, having sufficient level of knowledge about these inter-dependencies is crucial to preform accurate system manage-ment tasks. In the following definition, we formally define what we mean by dependency between two time series.

D EFINITION 1. (Approximate Dependency): At time step t m time series x j ( t )  X  X  approximately depends on x i ( t )  X  X  , if and only if, there exists a function f : R  X  R that for appropriately small &gt; 0 : and We depict this dependency by x j ( t )  X  x i ( t )
When the dependency between two time series does not change over time, we say that these two time series are system-invariants. D EFINITION 2. (System Invariants): Two time series, x j ( t )  X  D and x i ( t )  X  D , are system-invariant up to time T within range of if and only if at least one of the following rules satisfied:  X  f : R  X  R and  X  0  X  t  X  T : x j ( t )  X  x i ( t ) or  X  f : R  X  R and  X  0  X  t  X  T : x i ( t )  X  x j ( t ) We show invariant time series by x i ( t ) x j ( t ) .
 Based on the nature of the system, dependencies between time se-ries can be linear or nonlinear and this is modeled by the function f . In complex cyber-physical systems, when we have a large num-ber of time series, it is appropriate to represent the invariants in the form of a graph.

D EFINITION 3. (Invariant Graph): Graph G = ( V , E ) , with the set of vertices V = { v 1 ,...,v n } and the set of edges E = { e 1 ,...,e m } , is called an invariant graph of a system with ob-served time series D = { x 1 ( t ) ,...,x n ( t ) } , where e = ( v E if and only if x i ( t ) x j ( t ) .

From Definition 3 it is obvious that the vertex v i is equivalent to the time series x i ( t ) . It should be noted that system invariants and invariant graph represent features of a system under its nor-mal condition. However, in the presence of anomalies, when the behavior of system deviates from its normal condition, these de-pendencies may disappear. In other words, while two times series, x ( t ) and x j ( t ) , may be invariant under normal conditions, the in-variant feature may not hold when an anomaly condition appears in the system.

D EFINITION 4. (Broken Invariants): We say that system in-variant x i ( t ) x j ( t ) is broken at time T = t m , if and only if, time series x i ( t ) and x j ( t ) satisfy the following conditions: x j ( t )  X  x i ( t ) or x i ( t )  X  x j ( t )
In some cases, the existence of unseen factors has an impact on the observed values of the system which cause them to have a spe-cific behavior. However, uncovering those hidden factors behind all the underlying electro-mechanical devices is a challenging task. Characterizing these factors can help us to reveal the hidden rela-tionships between potential time series whether they have indirect or complex relationships. Figure 2 (a) shows an example of re-lationships among a set of time series, ( x 1 ,x 2 ,  X  X  X  ,x ity, the relationships can be direct (solid lines) or indirect (dashed lines). Previous works tried to reveal the direct relationships among time series (which is shown in Figure 2 (b)). However, despite the simplicity of these linear methods, sometimes they result in a sparse graph of invariants where tracking all time series is impos-sible. Moreover, these methods are not able to capture the under-lying hidden relationships and results in poor detection of system outliers. In this paper, we aim to uncover those hidden relationships Figure 2: Different models of relationships: (a) Relationships in reality, (b) Relationships in the ARX model and (c) Relation-ships in ARX with a latent model. with the help of hidden factors as latent variables. Hidden factors, ( f ,f 2 ,  X  X  X  ,f n ), are considered as a higher level in hierarchy of the system and have an impact on the whole observed variables. An example of relationships in a system with hidden factors is il-lustrated in Figure 2 (c).

D EFINITION 5. (Latent Variable): In a cyber-physical system with the set of observed time series D = { x 1 ( t ) ,...,x unobserved time series h ( t ) is a latent variable when two or more observed time series are functions of h ( t ) . In other words, where similar to Eq. 2, H 1: m is defined as follows: It should be noted that each cyber-physical system may have more than one latent variable. Also, existence of a latent variable does not mean that all the observed time series should be directly related to that variable.
In this section, we describe a framework for invariant graph dis-covery and anomaly detection. For this purpose, we first extract la-tent variables using factor analysis and incorporate hidden factors into the regression model. Then we construct the invariant graph using a search algorithm. Finally, we use the constructed graph as a normal invariant graph and deploy it for the purpose of anomaly detection in the system. By discovering the broken invariants and ranking them, one may be able to find fault(s) and localize them.
Let us assume that we have a set of n random variables (input variables), denoted by X 1 , ..., X n . Also, assume that there are k hidden (latent) factors in the system, denotes by H 1 , ..., H thermore, assume that the observed variables are modeled as linear combinations of latent variables. Then we derive latent variables using the factor analysis method. Factor analysis is a well-studied field and is used to determine the main latent sources behind the observed data variation [9]. Although factor analysis is similar to principal component analysis (PCA), it is used more in predictive models due to its generalizability (e.g., factor loadings can remain consistent for different subsets of variables) [29]. Some might think of the factor model as generative models where the data is produced based on factors.

In factor analysis, for one sample of data extracted from random variable distributions, we have: where  X  i is the expected value of X i , H j  X  X  are unobserved random variables and  X  ij  X  X  are unknown constants ( i  X  1 ,  X  X  X  ,n and j  X  1 ,  X  X  X  ,k where k &lt; n ). Also,  X  i  X  X  are independently distributed error terms with zero mean and finite variance ( V ar (  X  other words, by Eq. 6, each of the X i  X  X  random variables is related to k hidden random variables, known as latent factors.
 In matrix notation, we have: where X = ( X 1 ,  X  X  X  ,X n ) T is a data sample vector,  X  is the ex-pected values of data samples,  X  is an n  X  k matrix named as loading matrix, H = ( H 1 ,  X  X  X  ,H k ) T is a vector of latent factors, and Z = (  X  1 ,  X  X  X  , X  n ) 0 is the vector of error.
 It is assumed that H and Z are independent, and E ( Z ) = 0 , E ( H ) = 0 , Cov ( Z ) = Diag (  X  1 ,..., X  n ) =  X  , and E ( HH  X  . Furthermore, it is assumed that the data has a multivariate nor-mal distribution, X = N (  X ,  X  ) . Based on these assumptions, we will have:
Since X has a multivariate normal distribution, the actual distri-bution function of elements of sample covariance matrix, S , can be expressed as a Wishart distribution with m  X  1 degrees of freedom, m S  X  X  n (  X  ,m  X  1) , where m is the number of samples.
The log-likelihood of the Wishart distribution can be expressed as follows: where the terms independent of  X  are dropped.

It is obvious that maximization of L is equivalent to minimizing the following function:
One can find the latent variables by taking the partial derivatives of Eq. 10 with respect to the elements of loading matrix and errors constrained by Eq. 8. For simplicity, it is convenient to assume that  X  = I and  X  T  X   X  1  X  is diagonal.

There are different types of criteria to determine the number of factors such as criteria based on eigenvalues, discrepancy of ap-proximation, or overall discrepancy [24]. Here, we use the Kaiser criterion which drops those with eigenvalues of less than 1 . Indeed, the number of factors, must be lower than the number of observed variables, k &lt; n . More details can be found in [14, 19].
Having n time series, D = { x 1 ( t ) ,  X  X  X  ,x n ( t ) } , related to a cyber-physical system, similar to the ARX model [16], we can rewrite Eq. 1 as: where x i ( t ) ,x j ( t )  X  X  .

As acknowledged widely [16, 13, 6, 5, 27], a drawback of ARX is that relationship discovery is done based on the existence of di-rect linear relationships between two observed time series. In other words, at each time ARX considers a pair of time series without considering the underlying relationships and hidden patterns. To address this issue, we deploy latent factors in the ARX model to recover the complex relationships. If we use latent factors in the Algorithm 1: Invariant Search Algorithm
Input : x i , i  X  X  1 ,..,n } : set of time series,  X  : ARX
Output : G : Invariant Graph. 1 S ARX = {} ; 3 for i = 1 to n do 4 for j = 1 to n do 5 if i == j then 6 Continue; 7 end 8 foreach t s  X  t  X  t e do 9 Learn an ARX model,  X  ARX ji , using Eq. 11; 10 Calculate  X  x ARX j ( t ) using  X  ARX ji ; 11 Compute F ARX ji ( t ) with Eq. 15; 12 Learn an LFRX model,  X  LFRX ji , using Eq. 12; 13 Calculate  X  x LFRX j ( t ) using  X  LFRX ji ; 14 Compute F LFRX ji ( t ) with Eq. 15; 15 end 18 end 21 end 22 end 23 end 24 Construct Graph, G = ( V,E ) , using S ARX and S LFRX ; 25 return G ; above regression model, we will have:  X  x ( t ) = where h p ( t )  X  X  are the latent factor time series that have been built based on the latent factor random variables, as discussed in the pre-vious subsection (Eq. 6). Also, a p  X  X , b p  X  X , and c pq  X  X  are the regres-sion weights that are determined in the learning phase. Note that in Eq. 12, in addition to the regression weights, latent factors are also unknown and should be estimated in the learning phase.

It should be noted that here we incorporate the previous values of x j ( t ) as well as values of exogenous variable, x i den variables, h q ( t )  X  X , to estimate new value of x j notation, Eq. 12 will change to: Also, H ( w +1)  X  k is a matrix that represents all the latent factors, u = v = w and their values are estimated using cross-validation. Also, due to the lack of delay in our datasets, we assume l is zero. In order to solve Eq. 13, first we derive latent factors, H , using factor analysis of Subsection 4.1 and then we incorporate them into the regression model to estimate the weights.
Based on Definition 2, in order to discover system invariants we need to identify time series that have persistent approximate de-pendencies. While time series may have nonlinear dependencies, in this paper we consider linear relationships and use ARX and LFRX for this purpose.
 The search algorithm that extracts system invariants is shown in Algorithm 1. In this algorithm, for each pair of time series, we first assume that they have a direct linear relationship and we fit them using an ARX model (Eq. 11). The ARX model for time se-there might be an indirect relationship through latent variables and hence, we use LFRX model to learn  X  LFRX ij . As defined in Defini-tion 1, to determine if x j ( t ) depends on x i ( t ) , we need to compare the estimation error with an acceptable threshold, . However since in a specific cyber-physical system different time series have differ-ent range of values, it is more appropriate to use normalized error measurements. For this purpose, when we estimate x j ( t ) based on x ( t ) , we can evaluate the relative absolute error (RAE) defined by the following equation: based on x i ( t ) , and  X  x j is the sample mean of observed values.
According to [17] for each pair of time series, x i ( t ) and x we calculate a score to measure their dependencies. The following normalized score may be used for the evaluations: A higher score indicates stronger dependency between the time se-ries. It should be noted that RAE is a specific example of normal-ized error measurement and one can easily extend the algorithm to use other error measurement approaches including RMSE, specifi-cally when time series have the same range of variations.
In Algorithm 1, lines 8 to 15 are dedicated to estimate individual values of x j ( t ) based on x i ( t ) and calculate the scores for ARX and LFRX models. In order to discover invariants and choose between direct or indirect relationships, we consider the following criteria:
When calculated scores satisfy Eq. 16, we will say that x and x j ( t ) are invariant and based on Eq. 17, the type of invariant is chosen to be direct (ARX) or indirect (LFRX). The resulted in-variants are added to the sets of ARX and LFRX invariants denoted by S ARX and S LFRX , respectively. In Algorithm 1, lines 16 to 21 are dedicated to this process. Algorithm 2: Alerting Algorithm Input : x i ( t ) , i  X  X  1 ,..,n } : set of time series, 1 foreach t &gt; t e do 2 foreach e i,j  X  E do 3 Use Definition 4 to check if e i,j is broken; 4 if e i,j is broken then 5 cnt ij  X  cnt ij + 1 ; 6 else 7 cnt ij  X  0 ; 8 end 9 if cnt ij &gt;  X  then 10 Invoke an alert; 11 cnt ij  X  0 ; 12 end 13 end 14 end
After finding system invariants, the final step (line 24 in Algo-rithm 1) is to construct the invariant graph, G = ( V,E ) . This is a straightforward task which is performed based on Definition 3. The total number of iterations of this algorithm is O ( tn 2 ) where t is the length of time series. At each iteration (lines 9 to 14), models are learned with a time complexity which is a function of t 2 ious constants ( w,v,u,  X  X  X  ). This results in an overall complexity of O ( Cn 2 t 3 ) .
After constructing the invariant graph (in Subsection 4.3), we can use this graph for detecting abnormalities in the system. For this purpose, using Definition 4, at each time step we check whether each of the graph edges is broken or not. We then rank the time series in order to localize the source of abnormality. In what fol-lows we first describe the alerting algorithm, followed by a metric for alerting threshold estimation and finally the ranking method for fault localization.
 Anomaly alerting algorithm: The alerting algorithm is illustrated in Algorithm 2. In this algorithm, in order to prevent generations of multiple alerts consecutively, we use an alert filtering mechanism by imposing a counting strategy with alert threshold of  X  . When the number of consecutive violations of a specific invariant goes beyond  X  , the algorithm invokes an alert to the system administra-tor, who may use this for further investigations. Time complexity of this algorithm is O ( | E | ) at each time-step.
 Anomaly detection threshold: According to model-based FDI methods used in control theory and similar to [27], in order to reduce false alarms the following approach is used for detection of broken invariants. The difference between the predicted value,  X  x ( t ) , and the actual value, x j ( t ) , is recorded and whenever this difference deviates more than a predetermined threshold, 0 variant will be broken: The threshold 0 can be estimated based on the observed values in the training period. According to [27], 0 is assumed to be 10% larger than the tolerance of deviations from the actual values: Figure 3: (a) Invariant graph of synthetic data (b) Correlation matrix of synthetic time series. where r is greater than 99.5% of the residuals observed in the train-ing data.
 Ranking time series for fault localization: In complex cyber-physical systems with a large number of invariants, one single fault in the system may lead to a large number of broken invariants. Hence, for fault localization we need to rank the invariant graph vertices according to the number of their broken edges. Similar techniques have also been used in [12]. For this purpose, we use the following score to rank the vertices after the occurrence of an alarm. Assuming that an alarm is generated at time t , for each ver-tex, v j , we calculate the following score: where d normal j is the degree of v j in normal condition and d is the degree of v j after alarm generation at time t . It is obvious that higher value of  X  j indicates v j has lost more edges which may potentially be due to the occurrence of a fault at x j ( t ) .
We perform our experiments on several datasets. We aim to show how our method (ARX + LFRX) can discover the invariants, how it can improve the accuracy of system, and how it can find the anoma-lies happening throughout the network. First, we perform our anal-ysis on a synthetic dataset to recover indirect invariants. Next, we use two datasets from real cyber-physical systems: a wireless sen-sor network and a microgrid system. In these datasets, there are multiple factors and measurements with various temporal and spa-tial dependencies. Dataset Description: At the first step, we perform our experiment on a synthetic dataset to verify our method for the discovery of indirect hidden relationships. For this purpose, we generate eight signals and compare the results of ARX with our method (integra-tion of ARX and LFRX). In this experiment, we add a Gaussian noise with zero mean and standard deviation of 0 . 1 to one of the time series in order to test the invariant graph under abnormalities. The ground truth graph and its corresponding correlation matrix are shown in Fig. 3 (a) and (b), respectively. As Fig. 3 (a) shows, V and V 7 are correlated to each other. V 8 is isolated and all the re-maining nodes are correlated to each other. However, the hidden relationship between signals is not observable in Fig. 3 (a). In fact, V ,V 4 ,V 5 are generated using V 1 and V 2 . The relationship between signals is given in the following equations: V ( t ) = 0 . 9 V 1 ( t  X  1)  X  0 . 02 V 1 ( t  X  2)  X  0 . 01 V V ( t ) = 2( V 1 ( t  X  1)  X  V 1( t  X  2)) + 0 . 5( V 2 ( t  X  1) + V 2( t  X  2)) V ( t ) = V 1 ( t  X  1)+ V 2 ( t )  X  V 1 ( t ) , V 4 ( t ) = 3 V where R ( t,T ) is a rectangular function of t , oscillating between  X  1 and 1 with period of T and  X  is a Gaussian noise with zero mean and standard deviation of 0 . 01 .

In order to consider various situations, with and without presence of hidden relationships, we perform multiple experiments with dif-ferent subset of the above signals.
 Results and Discussion: Recovered graph for both methods in normal and abnormal condition are shown in Figure 4. In this fig-ure, each row denotes an experiment involving a subset of syn-thetic time series, where white nodes represent the one with in-jected noise. As it is shown, in all cases the ARX + LFRX method has recovered the planted invariants and the recovered graph matches the ground truth. In both methods, in the presence of an anomaly, the invariants attached to the corrupted signal (white node) are bro-ken. However, in some cases such as (a) and (b) where the ARX method cannot recover the existing relationships, at the time of (d), time series V 1 and V 2 are not measured and hence, time se-ries V 3 , V 4 , and V 5 have indirect relationships. It is obvious from Fig. 4 that the proposed method (ARX + LFRX) is able to discover the corresponding invariants while ARX, with the same parameter settings, has failed to discover them. Dataset Description: The sensor motes dataset contains measure-ments from wireless sensors at Intel Berkeley Research lab. There are a total of 54 sensors located at a lab measuring temperature, humidity, light, and voltage between February 28th and April 5th, 2004 [10]. Each sensor was able to record different variables every 31 seconds. Fig. 5 (a) shows the location of each node as well as different part of the lab.
 Results and Discussion: Fig. 5 (b) shows the clustering of sensors in the loading matrix (i.e.  X  in Eq. 7) of light measurements. For this purpose, we used a k-means algorithm with k = 6 . It is in-teresting to note that the sensors are clustered in a way that reflects their spatial distributions.

We performed invariant graph analysis on each variable (light, temperature, humidity, and voltage), separately. Overall results are illustrated at Table 1. It is obvious from this table that the proposed method results in lower average estimation error on test datasets, compared to the ARX approach. Also, the number of discovered invariants using the proposed method is higher than the one us-ing ARX. This is due to the deployment of latent factors in LFRX method which is beneficial in anomaly detection. In fact, for the purpose of anomaly detection using invariant graphs, anomalies in vertices with a small number of edges cannot be discovered eas-ily. One might think that by increasing the value of (in Eq. 4) at the time of invariant discovery, we can find larger number of invariants. However, by increasing , the estimation accuracy de-creases dramatically which results in having false invariants. Table 1 shows that the proposed method discovers more invariants with higher accuracy.

Fig. 6 shows an invariant graph of temperature under the normal condition and in the presence of abnormalities. In this figure, direct Figure 4: Invariant graphs discovered using ARX and the pro-posed method (ARX + LFRX) under normal and abnormal conditions. First column shows the ground truth. In the ab-normal condition, an anomaly is injected into each graph at one variable (white node). Rows (a) to (f) shows different com-binations of time series in Fig. 3. Direct invariants are shown in solid lines and indirect invariants are shown in dashed lines. Table 1: Performance evaluation result of ARX and (ARX + LFRX) for the Sensor Motes dataset.
 and indirect invariants are illustrated by blue and red edges, respec-tively. Fig. 6 (a) shows the invariant graph under the normal con-dition with 183 edges where 140 of them are derived using LFRX. As we expected, geographic placement of sensors has an effect on the result. Fig. 6 (b) shows the invariant graph at the presence of anomalies. In this figure, the top ten sensors based on the ranking of Eq. 20 are highlighted with red circles. Larger circles repre-sents higher rank of vertices. As this figure shows, variations of environmental temperature in the lab result in distortions in nearby sensors. As an example, sensors 12 to 17 are in the top ten ranking list. Sensors 16 and 37 are both among the highly ranked ones that are susceptible to be the source of anomaly. In Fig. 6(b), we can observe that the LFRX edge between these two vertices is broken. Fig. 7 depicts the corresponding time series of these two sensors. We can easily observe that these two time series have almost simi-lar behavior and are expected to be system invariant. As this figure illustrates, the relationship between these sensors is broken at time t = 1300 . Abnormal conditions are shown in darker colors. Figure 5: (a) Geographical location of wireless sensors (taken from [1]). (b) Clustering of sensors based on latent factors of light measurement indicating a high degree of spatial correla-tion. Figure 6: (a) Invariant graph of sensors based on temperature at normal condition (with 183 edges). ARX-based and LFRX-based invariants are shown with red and blue edges, respec-tively. (b) Invariant graph with broken edges in the presence of an anomaly (162 edges). Top ten sensors based on the ranking of Eq. 20 are shown with red circles. Dataset Description: We performed our experiments on a micro-grid system where several devices are operating in a distributed set-ting (Fig. 8). In this setting, the control unit tries to minimize the amount of energy based on various criteria and hence the micro-grid shows a complex behavior in the logged measurements. This dataset which is provided by NEC labs contains logged data from multiple sources such as loads (primary, secondary), battery, PMU Figure 7: Temperature of sensors 16 (blue) and 37 (red). Out-liers are shown in darker color.
 Figure 9: Three different time series of NEC microgrid dataset during one week. (measurement unit outside of the microgrid), solar system (PV), weather (inside and outside parameters), and air cooling unit. There are total of 84 features measured from July 7th to August 7th, 2014. Due to the different sampling rates of each device, time series are re-sampled with a unique rate to be aligned to a specific window-time. Figure 9 shows a sample plot of three time series from differ-ent units during one week.
 Results and Discussion: The invariant graph derived by our pro-posed method is represented in Fig. 10 (a). In this figure, each node represents one of the features and the set of features that belong to a specific device are illustrated using the same color. Also, the size of each node is proportional to its degree. Furthermore, invariants derived by ARX and LFRX methods are shown by red and blue edges, respectively. The total number of invariants that ARX + LFRX discovered is 2285 where 797 of them are indirect and 1488 of them are direct invariants.

The average estimation errors of traditional ARX and the pro-posed method are compared in Table 2. As this table shows, the av-erage error of the proposed method for each device is dramatically lower than the error resulted by ARX approach. This means that invariants are selected with higher accuracy using ARX + LFRX. Also, Table 2 compares the proposed method with ARX in terms of the number of invariants between devices (Inter-Device) and within each device (Intra-Device). Inter-Device edges are visualized in Fig. 11(a) where edge thickness represents the total number of in-variants between devices. From this figure, we can observe the high complexity of inter-dependencies between measurements of devices. For example, energy produced by photovoltaics (PV) has effect on battery, PMU, loads, and the temperature of environment.
After occurrence of an abnormal behavior, the topology of the invariant graph changes (i.e., depending on the nature of anomaly, some edges are removed from the graph). By comparing consecu-tive graphs, one is able to detect outliers in the system. We detect changes in the invariant graph in two different situations: when an additional device is switched off/on and when secondary load is turned off. Results are shown in Fig. 10 (b) and (c), respectively. As we may observe from Fig. 10 (b), two edges connecting the sec-ondary load to PMU and PV are broken. This is due to the change in the energy consumption behavior of the system. On the other hand, as Fig. 10 (c) depicts, a large number of invariants between secondary load and other devices are broken. This is due to the disconnection of the secondary load. It should be noted that mea-surements of the secondary load were among the top five anoma-lies returned by our outlier ranking method. Also, the number of remaining invariants between devices are shown in Fig. 11 (b) and (c).

Figure 12 shows some examples of anomalies in the microgrid system. Each figure shows a pair of time series that under normal condition are invariant. Abnormal conditions are shown in darker colors. The gap between occurrence of anomalies and normal time series depicts the time difference between them. As an example, Fig. 12 (a) shows the detection of sudden change in the red curve which is the State of Health (SOH) of the battery. This change is detected using the broken link between SOH and Reactive power in Channel C of the PMU. Detecting such anomalies is crucial for microgrid operators.

It should be noted that since we do not know the labeling of real dataset, we are unable to evaluate our method using precision and recall metrics. Nevertheless, we calculated precision and recall under different scenarios. As an example, when 10 nodes have ran-dom injected noise, by looking at the top 10 ranked results, preci-sion and recall were equal. This value is 0.51 for the ARX method, whereas for ARX + LFRX, it is 0.68. Smart Grid and Power System Analytics: Power grids com-prise a large number of elements and processes that are highly dy-namic and complex. Traditionally power system operational stud-ies are primarily based on a quasi-steady-state assumption, with static and explicit models that largely ignores dynamic characteris-tics of loads and control devices. The classic weighted least square (WLS) estimator, combined with methods such as largest normal-ized residual test and hypothesis testing identification, is exten-sively used for system diagnosis and outlier identification [2]. Re-cent developments in smart grids have revealed to us insight into stochastic operating behaviors and dynamics that we were never able to observe before. In particular, the widespread deployment of smart meters, renewable generation, smart load controls, en-ergy storage, and plug-in hybrid vehicles will require fundamental primary load. changes in the operational concepts and principal components of the grid, in order to achieve real-time operation and control.
Fraud detection and particularly detection of energy theft is one of most important concerns in the smart grid [18, 22]. Data ana-lytic methods can play an important role in identifying abnormal consumption trends and possible malicious activities in such sys-tems. Daisuke et al. [22] used ARMA and LOF methods in an adversarial environment to detect attacks in data collected using advanced meter infrastructure (AMI). Rong et al. [18] compared classification-based, state-based, and game theory-based methods in energy-theft detection schemas.

One area that has witnessed significant developments is in the use of phasor measurement units (PMUs). Chen et al. [7] use PCA for online monitoring of PMU data for the purpose of early event detection. Khan et al. [20] proposed a parallel fluctuation approach using MapReduce techniques. At the lower level, Momtazpour et al. [23] proposed an integrated data-driven framework to study the behavior of battery systems in microgrids using clustering, regres-sion, and spectral clustering of time series for the purposes of high level characterization of usage behavior and online parameter esti-mation.
 Invariant Discovery and Structure Learning: Sharma et al. [27] used ARX for invariant discovery in distributed systems and dis-cussed the challenges in fault localization for data centers. Shan et al. [26] have extracted overlay invariants based on pairwise invari-ant networks for fault detection and capacity planning in distributed systems. Due to the time complexity of invariant discovery of large scale systems, Ge et al. [13] developed an effective pruning tech-niques based on the identified upper bounds. In some applications, the existence of anomalies in invariant graphs yields many broken links which makes it difficult for a system expert to manually in-spect each broken link. Hence, Ge et al. in [12] proposed two dif-ferent methods of ranking metrics according to the anomaly levels occurring in invariant networks.

In a closely related area, viz. causal modeling of time-series data, Arnold et al. [4] used the concept of Granger causality to infer the structure of the causal network given set of time series. These authors compared performance of the exhaustive Granger method and a Lasso-Granger method with benchmark methods including the VAR and SIN methods. However, in [4], the main goal was to construct causal graphs instead of addressing data with correlated variables. Subsequently, Liu et al. [21] used a hidden Markov ran-dom field regression framework to infer temporal causal structures. Cheng et al. [8] use time order relationships to capture temporal dependence structures underlying multivariate time series. Anomaly Detection in Graphs: Akoglu et al. [3] provide an ex-tensive survey of anomaly detection methods in graphs spanning different settings: unsupervised, (semi-) supervised approaches, static, dynamic, attributed, and plain graphs. In dependency graphs, for the purpose of anomaly detection, Ide et al. [15] used sparse structure learning to compute correlation anomaly scores of each variable using neighborhood selection approaches.
Invariant discovery is an exciting research field which aims to discover underlying relationships in cyber-physical systems. We used latent factor regression analysis and combined it with the ARX model (ARX + LFRX) to recover underlying direct and indirect re-lationships. These invariants are helpful in decision making and monitoring processes such as outlier detection. We tested our mod-els on several datasets and results showed that with the help of la-tent factors, the accuracy of discovered invariants was higher than traditional methods. Investigating other topologies involving latent variables (such as a mesh network) and heuristic search algorithms to reduce the computational complexity are some of the directions for future research. [1] Intel Lab Data. http://select.cs.cmu.edu/data/ [2] A. Abur and A. G. Exposito. Power system state estimation: [3] L. Akoglu, H. Tong, and D. Koutra. Graph-based anomaly [4] A. Arnold, Y. Liu, and N. Abe. Temporal causal modeling [5] H. Chen et al. Exploiting local and global invariants for the [6] H. Chen, G. Jiang, K. Yoshihira, and A. Saxena. Invariants [7] Y. Chen, L. Xie, and P. Kumar. Dimensionality reduction and [8] D. Cheng, M. T. Bahadori, and Y. Liu. Fblg: A simple and [9] J. C. F. De Winter and D. Dodou. Common factor analysis [10] A. Deshpande, C. Guestrin, S. Madden, J. Hellerstein, and [11] M. Ding, H. Chen, A. Sharma, K. Yoshihira, and G. Jiang. A [12] Y. Ge, G. Jiang, M. Ding, and H. Xiong. Ranking metric [13] Y. Ge, G. Jiang, and Y. Ge. Efficient invariant search for [14] H. Harman. Modern Factor Analysis . University of Chicago [15] T. Ide, A. C. Lozano, N. Abe, and Y. Liu. Proximity-based [16] G. Jiang, H. Chen, and K. Yoshihira. Discovering likely [17] G. Jiang, H. Chen, and K. Yoshihira. Efficient and scalable [18] R. Jiang, R. Lu, Y. Wang, J. Luo, C. Shen, and X. S. Shen. [19] K. Joreskog. Some contributions to maximum likelihood [20] M. Khan, M. Li, P. Ashton, G. Taylor, and J. Liu. Big data [21] Y. Liu, A. Niculescu-mizil, A. C. Lozano, and Y. Lu. [22] D. Mashima and A. A. Cardenas. Evaluating electricity theft [23] M. Momtazpour, R. Sharma, and N. Ramakrishnan. An [24] K. J. Preacher, G. Zhang, C. Kim, and G. Mels. Choosing the [25] I. Shafer, K. Ren, V. N. Boddeti, Y. Abe, G. R. Ganger, and [26] H. Shan, G. Jiang, and K. Yoshihira. Extracting overlay [27] A. Sharma, H. Chen, M. Ding, K. Yoshihira, and G. Jiang. [28] A. B. Sharma, F. Ivancic, A. Niculescu-Mizil, H. Chen, and [29] D. Suhr. Principal component analysis vs. exploratory factor
