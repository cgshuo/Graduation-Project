 In this paper, we have proposed a novel framework to enable hierarchical image classification via statistical learning. By integrating the concept hierarchy for semantic image con-cept organization, a hierarchical mixture model is pro-posed to enable multi-level modeling of semantic image con-cepts and hierarchical classifier combination. Thus, learning the classifiers for the semantic image concepts at the high level of the concept hierarchy can be effectively achieved by detecting the presences of the relevant base-level atomic im-ageconcepts. Toeffectivelylearnthebase-levelclassifiersfor the atomic image concepts at the first level of the concept hi-erarchy, we have proposed a novel adaptive EM algorithm to achieve more effective model selection and parameter es-timation. In addition, a novel penalty term is proposed to effectively eliminate the misleading effects of the outlying unlabeled images on semi-supervised classifier training. Our experimental results in a specific image domain of outdoor photos are very attractive.
 Categories and Subject Descriptors H.2.8 [ Database Management ]: Database Applications -image databases .
 General Terms Algorithms, Measurement, Experimentation Keywords: Imageclassification, hierarchicalmixturemodel, adaptive EM algorithm.
As high-resolution digital cameras become more afford-able and widespread, high-quality digital images have ex-ploded on the Internet. With the exponential growth on high-quality digital images, the need of mining image data-base on semantics is becoming increasely important to en-able semantic image retrieval via keywords [1-5]. Seman-tic image classification is a promising approach for mining large-scale image database on semantics and has attracted the interest of researchers from a variety of fields [1-16, 28].
To enable image mining on semantics, it is very important to achieve a middle-level understanding of image semantics (i.e., bridging the semantic gap between image semantics for human interpretation and low-level visual features ex-tracted by computers for image content representation) [10-11]. Thus, the following inter-related problems should be addressed jointly: (1) What are the suitable image patterns that are able to achieve a middle-level understanding of the semantics of image contents? (2) What are the underlying concept models for accurately interpreting the semantic im-age concepts of particular interest? (3) What is the basic vocabulary of semantic image concepts of particular interest in a specific image domain? (4) Given the basic vocabulary of semantic image concepts, how can we learn the underlying concept models more accurately?
To address the first issue, two approaches are widely used for image content representation and feature extraction: (a) Image-based approaches that use the whole images for fea-ture extraction. (b) Region-based approaches that take the homogeneous image regions as the underlying image pat-terns for feature extraction. One common weakness of the region-based approaches is that the homogeneous image re-gionshavelittlecorrespondencetotheimagesemantics, thus they are not effective to support semantic image classifi-cation [12]. Without performing image segmentation, the image-based approaches may not work very well for the im-ages that contain individual objects, because only the global visual features are used for image content representation [15]. To enable more accurate interpretation of various se-mantic image concepts, we have recently developed a novel technique for semantic image classification and automatic annotation by using salient objects [5].

Toadressthesecondissue, Gaussianmixturemodel(GMM) has been widely used for semantic image concept interpre-tation with a pre-defined model structure [7-8]. However, different semantic image concepts may relate to different numbers and types of various image blobs, and thus auto-matic techniques for model selection are strongly expected.
Unfortunately, there is no existing works in the literature to effectively address the third and fourth issues. Most ex-isting techniques for semantic image classification ignore the hierarchical relationships between the semantic image con-cepts at different semantic levels [4]. They independently learn a set of flat classifiers for various semantic image con-cepts of particular interest. However, the semantic image concepts at the high level of the concept hierarchy may have larger hypothesis variance, and directly learning the flat classifiers for these high-level semantic image concepts may result in low prediction accuracy. Some pioneer works have shown that the accuracy of text classifiers can be sig-nificantly improved by taking advantage of concept hierar-chy such as WordNet and training the classifiers for mul-tiple concepts hierarchically [21-26]. This observation also encourages us to integrate the concept hierarchy to enable more effective image classification.

Another major difficulty for most existing image classifi-cation techniques is that a large number of labeled images are required to learn the concept models accurately. Unfor-tunately, labeling a large number of training images is very expensive and time-consuming. Given this costly labeling problem, it is very attractive to design the semi-supervised classifier training techniques that can take advantage of un-labeled samples [29-32]. However, there are two basic as-sumptions for most existing semi-supervised classifier train-ing techniques: (a) each unlabeled image originates from one of the known image context classes (i.e., existing mix-ture components that have already been used for semantic image concept interpretation); (b) all these relevant image context classes can be effectively learned from the available labeled images. When only a limited number of labeled images are available for classifier training, these two basic assumptions are not satisfied because of concept uncer-tainty (i.e., presence of new concept, outliers, and unknown image context classes). Considering that many image con-text classes and new concept have not even occurred in a limited number of available labeled images, using the outly-ing unlabeled images will corrupt the density estimation and lead to worse performance rather than improvement when the model structure is incorrect [29].

Based on these observations, we have proposed a novel framework to enable hierarchical image classifier training. This paper is organized as follows: Section 2 presents a novel framework for hierarchical organization and model-ing of semantic image concepts; Section 3 proposes a novel algorithm for hierarchical image classifier training; Section 4 introduces our technique for semantic image classification via partial matching; Section 5 shows our work on algorithm evaluation; We conclude the paper in Section 6.
The success of most existing techniques for semantic im-age classification is often limited and largely depends on the discrimination power of the low-level visual features for image content representation (i.e. attributes for image de-scription) [10]. On the other hand, the discrimination power of the low-level visual features also depends on the capabil-ity of the underlying image patterns to capture sufficient semantics of image contents.

Because the image blobs have the capability to character-ize the relevant dominant image compounds, they are able to capture the middle-level image semantics and thus extract-ing the visual features from the image blobs can enhance the discrimination power of visual features and may result in more effective image classification [10].

To enable more effective image classification, the concept hierarchy is used for semantic image concept organization and hierarchical classifier combination as shown in Fig. 1 and Fig. 2. The concept hierarchy defines the basic vocab-ulary of the semantic image concepts and their contextual Figure 1: The hierarchical framework for semantic im-Figure 2: The concept hierarchy for organizing outdoor and logical relationships. The lower the level of a seman-tic image concept node, the narrower is its coverage of the subjects, and the semantic image concepts at a lower level of the concept hierarchy characterize more specific aspects of image semantics. Thus, the hypothesis variances for the semantic image concepts at the lower level of the concept hi-erarchy may be smaller and can be interpreted effectively by using the low-level visual features. As a result, the concept nodes at the first level of the concept hierarchy are named as atomic image concepts as shown in Fig. 1. One example of the concept hierarchy, that is used in our experiments for a specific image domain of outdoor photos , is given in Fig. 2.

As shown in Fig 2, one certain atomic image concept C j at the first level of the concept hierarchy can be interpreted accurately by using a finite mixture model (FMM) to ap-proximate the class distribution of the relevant image blobs: where ter set for model structure, weights and model parameters, P ( X | C j , S l ,  X  s l )isthe l th mixture component to character-ize the class distribution for the l th type of image blobs,  X  is the model structure (i.e., the optimal number of mixture components),  X  c j = {  X  s 1 ,  X  X  X  ,  X  s  X  j } is the weight set for  X  mixture components,  X  s l is the relative weight for the l th mixture component to characterize the relative importance of the l th type of image blobs for accurately interpreting the given atomic image concept C j ,  X  c j = {  X  s 1 ,  X  X  X  is the set of model parameters,  X  s l is the model parame-ters for the l th mixture component, X =( x 1 ,  X  X  X  ,x n )is the n -dimensional visual features to characterize the visual properties for the relevant image blobs.
At the second level of the concept hierarchy, the class distribution for a given semantic image concept C i can be interpreted by using a hierarchical mixture model to ap-proximate the underlying class distributions for the relevant sibling atomic image concepts: where set for model structure, weights and model parameters, and  X  i is the set of weights for the gate networks that are used to define the relative importance of the  X  i sibling atomic image concepts for accurately interpreting their parent node C i [19].

Through a similar hierarchical approach, the class distri-bution for a given semantic image concept C k at the n th level of the concept hierarchy can be interpreted by using a hierarchical mixture model to approximate the class distri-butions of the ( n  X  1)th sibling semantic image concepts: P ( X,C k ,  X  c k )= where ter set for model structure, weights, and model parameters, and  X  c m is the set of weights for the gate networks that are used to define the relative importance of the sibling se-mantic image concepts at the ( n  X  1)th level of the concept hierarchy [19].

Ourproposedframeworkforhierarchicalclassifiertraining has the following advantages : (a) By using the hierarchical mixture model for classifier combination, it is able to enable more effective learning of the classifiers for the high-level se-mantic image concepts. Thus, the concept models for the high-level semantic image concepts can be adapted by the observations of the relevant base-level atomic image con-cepts. In addition, learning the high-level semantic image concepts hierarchically is able to reduce the size of covari-ance matrices being inverted. (b) It is able to enable a nat-ural approach for achieving discriminative learning of finite mixture models by jointly learning the concept models for the sibling semantic image concepts under the same parent node, and thus the positive images for one certain seman-tic image concept can be treated as the negative images for its sibling semantic image concepts under the same parent node. By using the negative images to maximize the mar-gins among the sibling semantic image concepts, our pro-posed hierarchical classifier training technique can achieve higher prediction accuracy. (c) By using the concept hi-erarchy for semantic image concept organization, our pro-posed framework is able to facilitate more effective image database indexing, searching and navigation. To support concept-oriented image database indexing, the finite mix-ture models for semantic image concept interpretation can be used to enable density-based database node representa-tion [33]. After all the images are classified into the semantic image concepts at different semantic levels, the underlying concept hierarchy can further be incorporated to construct the hierarchical image database indexing structure, where the concept nodes become the relevant database nodes at different semantic levels, upon which the root node of the image database can be constructed automatically.
To accurately learn the hierarchical mixture model for se-mantic image concept interpretation, the semantic labels for a set of training images are manually labeled for each atomic image concept. We use the one-against-all rule to organize the labeled images  X  c j = { X l ,C j ( S l ) | l =1 ,  X  X  X  positive images and negative images for a given atomic image concept C j , X l is the set of attributes (i.e. visual features) that are used to describe the training image S l . The unla-beled images  X  c j = { X n ,S n | n =1 ,  X  X  X  ,N u } canbeusedto improve the density estimation by reducing the variance of mixture density and discovering the unknown image context classes. For the given atomic image concept C j ,wethende-fine the mixture training image set as  X  =  X  c j The labeled images for the sibling atomic image concepts are further combined as the joint training images for their par-ent node at the concept hierarchy.

The visual features for image content representation in-clude 1-dimensional coverage ratio (i.e., density ratio) for a coarse shape representation, 6-dimensional locations of im-ageblobs(i.e., 2-dimensionsforblobcenterand4-dimensions to indicate the rectangular box for a coarse shape represen-tation of image blob), 7-dimensional LUV dominant colors and color variances, 7-dimensional Tamura texture, and 12-dimensional wavelet texture features.

The atomic image concepts at the first level of the concept hierarchy have low hypothesis variances and thus they can be accurately interpreted by using the relevant image blobs. Based on this understanding, we propose a bottom-up ap-proach for hierarchical image classifier training.
To learn the model-based classifier for the given atomic image concept C j , maximum likelihood criterion can be used to determine the underlying model parameters. To avoid the overfitting problem [20], a penalty term is added to deter-mine the underlying optimal model structure. The optimal parameters (i.e., model structure, weights, and model pa-concept C j are then determined by: where L ( C j , X  c j )=  X  is the objective function,  X  is the likelihood function, and log p ( X  c j )=  X  n +  X  j length (MDL) term to penalize the complex models with a large number of mixture components [20], N is the to-tal number of training samples, and n is the dimensions of visual features X .

The estimation of maximum likelihood described in Eq. (4) can be achieved by using the EM algorithm with a pre-defined model structure  X  j [17-18]. However, pre-defining the model structure  X  j is not acceptable for semantic im-age classification. Thus, there is an urgent need to develop new techniques that are able to select the optimal model structure automatically.

To automatically select the optimal model structure and estimate the accurate model parameters, we have proposed Algorithm 1: Adaptive EM Algorithm Inputs: Training Images  X  c j ,  X  j =  X  max Outputs:  X   X  c j Initialization is done by k -mean clustering; for each  X  j do J m ( i, k,  X  s ik )= JS ( C j , X  s ik )+  X JS ( C j , X  s i , X  J for each image { X l ,S l } X   X  c j do  X   X  end for end for an adaptive EM algorithm for classifier training. To incorpo-rate the negative images for discriminative learning of finite mixture models, we have taken advantage of the concept hi-erarchy for hierarchical classifier training, where the finite mixture models for interpreting the sibling atomic image concepts under the same parent node are learned jointly. Thus, the positive images for the given atomic image con-cept C j can be used as the negative images for the sibling atomic image concepts under the same parent node. By learningthesesiblingatomicimageconceptsjointly, itisable to achieve discriminative learning of finite mixture models by incorporating the negative images to maximize the mar-gins among different concept models.

To achieve more accurate model selection and parame-ter estimation, our adaptive EM algorithm performs auto-matic merging , splitting ,and elimination to re-organize the distribution of mixture components and modify the op-timal number of mixture components according to the class distribution of the available training images [5].
To exploit the most suitable image context classes for accurately interpreting the atomic image concept C j ,our adaptive EM algorithm starts from a large value of  X  j and takes the major steps as shwon in Algorithm 1 .Withthe given  X  j , k -mean clustering technique is used to select the reasonable and robust initial values for the model parame-ters (i.e., mean and covariance for each cluster).
To determine the underlying optimal model structure, we use two criteria to perform automatic splitting, merging, and elimination of mixture components: (a) fitness between one specific mixture component and the distribution of the relevant training images; (b) overlapping between the mix-ture components from the same atomic image concept or the mixture components from the sibling atomic image concepts under the same parent node.

OuradaptiveEMalgorithmusessymmetric Jensen-Shannon (JS) divergence (i.e., intra-concept JS divergence) JS ( C  X  ,  X  s k ) to measure the divergence between two mixture components P ( X | C j , S l ,  X  s l )and P ( X | C j , S the same concept model C j .
 where H ( P (  X  )) =  X  non entropy,  X  1 and  X  2 are the weights. In our experiments, we set  X  1 =  X  2 = 1 2 .

Ifthe intra-concept JS divergence JS ( C j ,  X  s l ,  X  s k these two mixture components are strongly overlapped and may overpopulate the relevant training images; thus they are merged into a single mixture component P ( X | C j , S  X  lk ). In addition, the local JS divergence JS ( C j ,  X  s used to measure the divergence between the merged mix-ture component P ( X | C j , S lk ,  X  s lk ) and the local density of the training images P ( X , C j ,  X  ). The local density P ( X , C ,  X  ) is modified as the empirical distribution weighted by the posterior probability [5]. Our adaptive EM algorithm tests  X  j (  X  j  X  1) 2 pairs of mixture components that could be merged and the pair with the minimum value of the local JS divergence is selected as the best candidate for merging .
Two types of mixture components may be split :(a)The elongated mixture components which underpopulate the rel-evant training images (i.e., characterized by the local JS di-vergence); (b) The tailed mixture components which overlap with the mixture components from the concept models for the sibling atomic image concepts (i.e., characterized by the inter-concept JS divergence ). To select the mixture compo-nent for splitting, two criteria are combined: (1) The local JS divergence JS ( C j , S i ,  X  s i ) to characterize the divergence between the i th mixture component P ( X | C j , S i ,  X  s the local density of the training images P ( X, C j ,  X  ); (2) The inter-concept JS divergence JS ( C j , C h ,  X  s i ,  X  s m acterize the overlapping between the mixture components atomic image concepts C j and C h .

Ifonespecificmixturecomponentisonlysupportedbyfew training images, it may be removed from the concept model for the C j . To determine the unrepresentative mixture com-ponent for elimination , our adaptive EM algorithm uses the local JS divergence JS ( C j ,  X  s i ) to characterize the rep-resentation of the mixture component P ( X | C j , S i ,  X  the relevant training images. The mixture component with the maximum value of the local JS divergence is selected as the candidate for elimination.

To jointly optimize these three operations of merging, where  X  is a normalized factor and it is determined by: The acceptance probability to prevent poor operation of merging, splitting or elimination is defined by: where L ( C j ,  X  1 )and L ( C j ,  X  2 ) are the objective functions for the models  X  1 and  X  2 (i.e., before and after performing the merging, splitting or elimination operation) as described in Eq. (4),  X  is a constant that is determined experimentally. In our current experiments,  X  is set as  X  =9 . 8. By optimizing these three operations jointly, our adaptive EM algorithm is able to automatically select the optimal model structure to capture the essential structure of the im-age context classes. In addition, our adaptive EM algorithm is able to escape the local extrema by re-organizing the dis-tribution of mixture components and modifying the optimal number of mixture components according to the class distri-butions of the training images. By integrating the negative samples to maximize the margin among the concept models for the sibling atomic image concepts, our adaptive EM algo-rithm is also able to enable discriminative learning of finite mixture models and result in high prediction accuracy.
When only a limited number of labeled images are avail-able for classifier training, it is difficult to select the optimal model structure and estimate the accurate model parame-ters. In addition, incorporating the outlying unlabeled im-ages for classifier training may lead to worse performance rather than improvement. Thus, it is very important to de-velop new techniques able to eliminate the misleading effects of the outlying unlabeled images.
 The weak classifier for the given atomic image concept C j is first learned from a limited number of available train-ing images, and the Bayesian framework is used to achieve  X  X oft X  classification of the unlabeled images. For the given atomic image concept C j , the confidence score for an unla-beled image is defined as: where  X   X  ( X l ,C j ,t ) is the posterior probability for the un-labeled image { X l ,S l } with the given atomic image concept C value of the unlabeled image { X l ,S l } with the given atomic image concept C h . For the unlabeled image { X l ,S l } ,its confidence score  X  ( X l ,C j ,t ) can be used as the criterion to indicate its possibility to be taken as an outlier of the C
For the given atomic image concept C j , the unlabeled images are first categorized into two classes according to their confidence scores: (a) certain unlabeled images with high confidence scores may originate from the known im-age context classes (i.e., mixture components) that have al-ready been used for interpreting the given atomic image con-cept C j ;(b) uncertain unlabeled images with low confidence scores may orginate from outliers and unknown image con-text classes that have not occurred in a limited number of available labeled images.

The certain unlabeled images are first incorporated to im-prove the estimation of the mixture density (i.e. regular updating of model parameters without changing the model structure)incrementallybyreducingthevarianceofthemix-ture density. By integrating the certain unlabeled images to update the statistical model, the confidence scores for some uncertain unlabeled images may be changed over time if they originate from the unknown image context classes that can-not be directly learned from the available labeled images. Thus, the changing scale of the confidence score for the un-labeled image ( X l ,S l ) is defined as: where y l  X  0,  X  ( X l ,C j ,t )and  X  ( X l ,C j ,t + 1) indicate its confidence scores with the atomic image concept C j before and after model updating.

The informative unlabeled images with a large value of y may originate from the unknown image context classes, and thus they should be incorporated for classifier training. On the other hand, the outlying unlabeled images with a y value close to zero may originate from outliers and should be removed from the training set. In order to incorporate the informative unlabeled images for discovering the unknown image context classes , one or more new mixture components are added to the residing areas for the informative unlabeled images with a large value of y l (i.e. birth ).
 where  X  s  X  j +1 is the weight for the (  X  j +1)th mixture compo-of unknown image context class.

To eliminate the misleading effects of the outlying unla-beled images, a penalty term  X  l is defined as:  X  where 0  X   X  l  X  1,  X  l =0if y l = 0. The penalty term  X  is able to select only the certain unlabeled images and informative unlabeled images for semi-supervised classifier training, thus the joint likelihood function is defined as: where the discount factor  X  = N u N is used to control the rela-tivecontributionoftheunlabeledimagesforsemi-supervised classifier training, N = N u + N L are the total number of training images (i.e., unlabeled images N u and labeled im-ages N L ). Using the joint likelihood function to replace the likelihood function in Eq. (4), our adaptive EM algorithm is performed on the mixture training image set, both originally and probabilistically labeled, to learn the image classifiers accurately.
To learn the model-based classifier for the given second-levelsemanticimageconcept C i , westillusemaximumlikeli-hood criterion to determine the underlying model structure and model parameters. Thus, the optimal parameter set (i.e. model structure, weights, and model parameters)  X   X  =( X   X  i , X   X  c i ,  X   X  c i ) is then determined by: Figure 3: Our experimental results for statistical im-where the objective function L ( C i ,  X  c i ) for the second-level semantic image concept C i is defined as: where L ( C j , X  c j ) is the objective function for the C dren node C j that has been obtained by using Eq. (4), N is the total number of the joint training images from all the sibling children nodes (i.e., sibling atomic image concepts under the same parent node C i ),  X  c j is the weight parame-ter to define the relative importance of the atomic image concept C j for accurately interpreting the second-level se-mantic image concept C i . Based on this understanding, we use the posterior probability to infer the logarithmic weight parameter  X  c j .

Because the model structures and the model parameters for the sibling atomic image concepts have already obtained, a simple but effective solution is developed to determine the finite mixture model for accurately interpreting their par-ent node at the second level of the concept hierarchy. Our classifier combination framework takes the following steps: (a) The mixture components from the  X  i sibling atomic image concepts are combined to achieve a better approxi-mation of the underlying class distribution of their parent node at the second level of the concept hierarchy (i.e., the second-level semantic image concept C i ). In addition, the training images for these sibling atomic image concepts are also combined as the joint training samples for their parent node C i . (b) Based on the available finite mixture models for interpreting the  X  i sibling atomic image concepts, our adaptive EM algorithm is used to select the optimal model structure and estimate the model parameters for the given second-level semantic image concept C i by performing au-tomatic merging , splitting ,and elimination of mixture com-ponents. (c) The mixture components with less prediction poweronthe joint training images are eliminated. The over-Figure 4: Our experimental results for statistical im-lappedmixturecomponentsfromdifferentsiblingatomicim-age concepts are merged into a single mixture component. The elongated mixture components that underpopulate the joint training images are split into multiple representative mixture components.

If one mixture component, P ( X | C j , S m ,  X  s m ), is elim-inated, the concept model for accurately interpreting the given second-level semantic image concept C i is then refined as:
P ( X,C i ,  X  c i )= 1 where  X  = ponents for the C i ,  X  i is the number of the relevant sibling atomic image concepts, and  X  j is the optimal model struc-ture for its children node C j .

Iftwomixturecomponents P ( X | C j , S m ,  X  s m )and P ( X S ,  X  s l ) from two sibling atomic image concepts C j and C are merged as a single mixture component P ( X | C j , S ml  X  ml ), the concept model for accurately interpreting the second-level semantic image concept C i is refined as: where  X  s ml is the weight parameter for the merged mixture component P ( X | C j , S ml ,  X  s ml ).

If one mixture component, P ( X | C j ,S h , X  s h ), is split into twonewmixturecomponents, P ( X | C j , S r ,  X  s r )and P ( X S ,  X  s t ), the concept model for accurately interpreting the second-level semantic image concept C i is refined as:
After the finite mixture models for the sibling second-level semantic image concepts are available, they are then inte-grated to obtain the finite mixture model for their parent Figure 5: The classification results for the second-level semantic image concept  X  X arden X  and the rel-evant first-level atomic image concepts. node at the third level of the concept hierarchy. Through a hierarchical approach, the hierarchical mixture models for accurately interpreting the higher-level semantic image con-cepts can be obtained effectively.
Given a test image I i , its image blobs I i = { S 1 ,  X  X  X   X  X  X  , S n } and the relevant visual features X = { X 1 ,  X  X  X   X  X  X  , X n } are detected automatically by using statistical im-age modeling, where the class distribution for each dominant image compound (i.e., image blobs) is charcterized by one or multiple mixture components. Some experimental results on statistical image modeling are given in Fig. 3 and Fig. 4.

The l thimage blobs S l in the test image I i is first classified into the most relevant atomic image concept C j with the maximum value of posterior probablity: P ( C j | X l ,S l ,  X  c j )= max P ( X
After the image blobs in the test image I i are classified into the most relevent atomic image concepts, the statistical modelsforinterpretingtheseatomicimageconceptsarethen integrated to characterize the semantics of the test image I By combining different number of these atomic image con-cepts and their statistical models to approximate the real class distribution of the test image I i ,itisabletoachieve multi-level representation of image semantics with different details. Because the semantic similar images may consist of different numbers and types of atomic image concepts, our framework for multi-level image representation can provide a natural way for partial image matching . Thus, semantic image classification is finally treated as a model matching problem, i.e., macthing the statistical model for interpret-ing the semantics of the test image I i with the finite mixture models for interpreting the semantic image concepts of par-ticular interest.

Toachievepartialimagematchingeffectively, theBayesian approach is used to calculate the posterior probability be-Figure 6: The classification results for the second-level semantic image concepts  X  X cean view X ,  X  X raire X  and the relevant first-level atomic image concepts. tween the statistical model for interpreting the semantics of the test image I i and the finite mixture models for interpret-ing the semantic image concepts of particular interest, the test image I i is then classified into the most relevant seman-tic image concept C h with the maximum value of posterior probability.

Our current experiments focus on mining the image se-mantics on the first level and the second level of the concept hierarchy, such as  X  X unset X ,  X  X cean view X ,  X  X each X ,  X  X ar-den X ,  X  X ountain view X ,  X  X lower view X ,  X  X ater way X ,  X  X ail-ing X , and  X  X kiing X , which are widely distributed in a specific image domain of outdoor photos . Some semantic image classification results are given in Fig. 5, Fig. 6, Fig. 7 and Fig. 8., where the unknown atomic image concepts are shown in white color in the images.

It is important to note that the text keywords for semantic image concept interpretation can be used to support multi-level image annotation effectively. The text keywords for interpreting the first-level atomic image concepts (i.e., dom-inant image compounds) provide the annotations of the im-ages at the content level. The text keywords for interpreting the relevant high-level semantic image concepts provide the annotations of the images at the concept level.
Our experiments are conducted on two image databases: the image database from the Google image search engine and the Corel image database. The image database from Google image search engine consists of 9,000 pictures. The Corelimage databaseincludes morethan3,800 pictures with different image concepts. Our works on algorithm evaluation focus on: (a) evaluating the performances of our adaptive EMalgorithmwithdifferentcombinationsofmergring, split-ting and elimination; (b) evaluating the performance of our classifier training technique by using different sizes of unla-beled images; (c) comparing the performances of our hier-archical classifier with other flat classifiers under the same classification objective (i.e., classifying the images into a set of semantic image concepts with or without using the con-cept hierarchy for classifier training). Table 1: The average performance of our classifiers for some atomic image concepts at the first level of concept hierarchy (precision  X  versus recall + ). concepts brown horse grass purple flower concepts red flower rock sand field concepts water human skin sky concepts snow sunset/sunrise waterfall concepts yellow flower forest sail cloth concepts elephant cat zebra
The benchmark metric for algorithm evaluation includes classification precision  X  and classification recall + .Theyare defined as: where  X  is the set of true positive images that are related to thegivensemanticimageconceptandareclassifiedcorrectly,  X  is the set of true negative images that are irrelevant to the given semantic image concept and are classified incorrectly, and  X  is the set of false positive images that are related to the given semantic image concept but are misclassified.
The average performance (precision vs. recall) of our clas-sifiers for some atomic image concepts are given in Table 1. The atomic image concepts at the first level of the concept hierarchy can be directly interpreted by using the relevant image blobs. The average performance of our classifiers for some second-level semantic image concepts are given in Ta-ble 2. The semantic image concepts at the second level of the concept hierarchy can be interpreted by using the rele-vant atomic image concepts at the first level of the concept hierarchy. For each atomic image concept, we currently use 100 labeled images for weak classifier training.

In our adaptive EM algorithm, multiple operations, such as merging, splitting, and elimination, have been integrated tore-organizethedistrbutionsofmixturecomponents, select the optimal number of mixture components and construct more flexible decision boundaries among sibling semantic image concepts according to the real class distributions of the training images. Thus, our adaptive EM algorithm is expected to have better performance than the traditional EM algorithm and its recent variants.

In order to evaluate the real benefits of the integration of these three operations (i.e. merging, splitting, and elim-ination), we have tested the performance differences of our adaptive EM algorithm with different combinations of these three operations. As shown in Fig. 9 and Fig. 10, we have tested the performances of the classifiers under dif-Figure 7: The classification results for the second-level semantic image concepts  X  X aterway X ,  X  X oun-tain view X  and the relevant atomic image concepts. ferent combinations of three operations: SM + Neg repre-sents combining three operations of merging, splitting and elimination of mixture components, SM indicates combin-ing two operations of merging and splitting, Split is for only operation of splitting, Merge is for only one operation of mergring, Borman is for the EM algorithm developed by Borman et al. [27].

From Fig. 9 and Fig. 10, one can find that integrating negative images for discriminative learning of finite mixture models (i.e., splitting by using negative images) can improve the classifiers X  performance significantly.

For the same purpose to classify the images into a set of pre-defined semantic image concepts, we have also compared the performance differences between our hierarchical classi-fier and the flat classifiers (i.e., training the classifier for each semantic image concept independently). The test results are given in Fig. 11. Above the yellow line, our hierarchi-cal classifier has better performance than the flat classifiers. Below the yellow line, our hierarchical classifier has worse performance than the flat classifiers. By using the hierar-chical mixture model for concept interpretation and clas-sifier training, our hierarchical classifier has improved the performance significantly and the high-level semantic image concepts can be determined by detecting the presences of the relevant atomic image concepts.

For some high-level semantic image concepts, our hierar-chical image classification technique may have worse perfor-mance than the corresponding flat classifiers (under yellow line as shown in Fig. 11). The reason is that the classifica-tion errors for some low-level semantic image concepts may transmit to the relevant high-level semantic image concepts. Shrinkage may be used to address this problem.

Given a limited number of labeled images, we have tested the performance of our classifiers by using different sizes of unlabeled images for classifier training (i.e. with different size ratios  X  = N u N L between the unlabeled images N u and the labeled images N L ). The average performance differ-ences for some semantic image concepts are given in Fig. 12.

One can find that the unlabeled images can improve the classifier X  X performancesignificantlywhenonlyalimitednum-Table 2: The average performance of our classifiers for some semantic image concepts at the second level of concept hierarchy. Figure 8: The classification results for the second-level semantic image concept  X  X lower view X ,  X  X ork ship X  and the relevant atomic image concepts. beroflabeledimagesareavailableforclassifiertraining. The reasons are: (a) The certain unlabeled images ,thatorigi-nate from the existing image context classes for concept in-terpretation, are able to improve the density estimation by reducing the variances of mixture density. (b) The infor-mative unlabeled images , that originate from the unknown image context classes, have the capability to provide addi-tional image context knowledge to learn the concept mod-els more accurately. By modifying the concept models to be more representative for the data resources, the concept models that are learned incrementally are able to obtain the accurate classifiers with higher prediction accuracy. (c) The outlying unlabeled images , that originate from outliers, can be predicted and their misleading effects on classifier training can be eliminated automatically by using a novel penalization framework.
Tosupportsemanticimageretrievalviakeywords, wehave proposed a novel framework for hierarchical image classifi-cation. By integrating the concept hierarchy and negative images for discriminative classifier training, our proposed framework has achieved very convincing results in a specific image domain of outdoor photos. In addition, an adaptive Figure 9: The relationship between the classifier per-Figure 10: The relationship between the classifier per-EM algorithm is proposed to select the optimal model struc-ture and estimate the accurate model parameters, and thus the misleading effects of the outlying unlabeled images can be eliminated effectively. Obviously, our proposed classifier training technique may be very attractive for other data do-mains. Our future works will focus on addressing the error transmission problem for hierarchical image classifier train-ing. [1] O.R. Zaiane, J. Han, Z.-N. Li, S.H. Chee, J.Y. Chiang, [2] S.J. Simoff, C. Djeraba, O.R. Zaiane,  X  X DM/KDD [3] C. Djeraba,  X  X hen image indexing meets knowledge [4] C. Breen, L. Khan, A. Ponnusany,  X  X mage [5] J. Fan, Y. Gao, H. Luo,  X  X ulti-level annotation of [6] G. Sheikholeslami, W. Chang and A. Zhang, [7]E.Chang,K.Goh,G.Sychay,G.Wu, X  X BSA: Figure 11: The classification error rate (percentage) [8] K. Barnard, P. Duygulu, N. de Freitas, D. Forsyth, [9] R. Zhang, Z. Zhang, S. Khanzole,  X  X  data mining [10] C. Carson, S. Belongie, H. Greenspan, J. Malik, [11] Y. Wu, A. Zhang,  X  X daptive pattern discovery for [12] A. Natsev, M. Naphade, J.R. Smith,  X  X emantic [13] W. Wang, Y. Song, A. Zhang,  X  X emantic-based image [14] J. Pun, H. Yan, C. Faloutsos, P. Dugulu,  X  X utomatic [15] J. Huang, S.R. Kumar and R. Zabih,  X  X n automatic [16] A. Aslandogan, C. Their, C. Yu, J. Zon, N. Rishe, [17] G. McLachlan and T. Krishnan, The EM algorithm [18] N. Ueda and R. Nakano, Z. Ghahramani, G. E.
 [19] M. Jordan, R. Jacobs,  X  X ierarchical mixtures of [20] M. Figueiredo and A.K. Jain,  X  X nsupervised learning [21] A. McCallum, R. Rosenfeld, T. Mitchell, A.Y. Ng, Figure 12: The classifier performance (i.e., precision  X  ) [22] T. Hofmann,  X  X he cluster-abstraction model: [23] D. Koller and M. Sahami,  X  X ierarchically classifying [24] S. Chakrabarti, B. Dom, R. Agrawal, P. Raghavan, [25] C. Fellbaum, WordNet: An electronic lexical database , [26] G.A. Miller,  X  X ordNet: A lexical database for [27] C.A. Bouman, M. Shapiro, G. Cook, C. Atkins, H. [28] C. Djeraba, Multimedia Mining: A highway to [29] F. Cozman, I. Cohen,  X  X nlabeled data can degrade [30] M.R. Naphade, X. Zhou, and T.S. Huang,  X  X mage [31] K. Nigam, A. McCallum, S. Thrun, T. Mitchell,  X  X ext [32] M. Szummer and T. Jaakkola,  X  X nformation [33] K.P. Bennett, U. Fayyad, D. Geiger,  X  X ensity-based
