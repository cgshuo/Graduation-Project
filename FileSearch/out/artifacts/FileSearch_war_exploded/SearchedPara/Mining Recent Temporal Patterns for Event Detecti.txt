 Improving the performance of classifiers using pattern mining tech-niques has been an active topic of data mining research. In this work we introduce the recent temporal pattern mining framework for finding predictive patterns for monitoring and event detection problems in complex multivariate time series data. This framework first converts time series into time-interval sequences of temporal abstractions. It then constructs more complex temporal patterns backwards in time using temporal operators. We apply our frame-work to health care data of 13,558 diabetic patients and show its benefits by efficiently finding useful patterns for detecting and di-agnosing adverse medical conditions that are associated with dia-betes.
 I.2.6 [ LEARNING ]: General Temporal Pattern Mining, Temporal Abstractions, Time-interval Patterns, Event Detection, Patient Classification.
Advances in data collection and data storage technologies led to emergence of complex temporal datasets, where the data instances are traces of complex behaviors characterized by time series of multiple variables. Designing algorithms capable of learning clas-sification models from such data is one of the most challenging topics of data mining research.

The majority of existing classification methods that work with temporal data [12, 6, 4, 24, 8, 28] assume that each data instance (represented by a single or multiple time series) is associated with a single class label that affects its entire behavior. That is, they assume that all temporal observations are equally useful for classi-fication.

However, the above assumption is not the best when considering monitoring and event detection problems. In this case, the class label denotes an event that is associated with a specific time point (or a time interval) in the instance, not necessarily in the entire instance. The goal is to learn a model that can accurately iden-tify the occurrence of events in unlabeled instances (a monitoring task). Examples of such problems are the detection of adverse med-ical events (e.g. drug toxicity) in clinical data [10], detection of the equipment malfunction [9], fraud detection [23], environmen-tal monitoring [16], intrusion detection [7] and others.
Given that class labels are associated with specific time points (or time intervals), each instance can be annotated with multiple labels 1 . Consequently, the context in which the classification is made is often local and affected by the most recent behavior of the monitored instances.

The focus of this paper is to develop a pattern mining technique that takes into account the local nature of decisions for monitoring and event detection problems. We propose the Recent Temporal Pattern ( RTP ) mining framework, which mines frequent tempo-ral patterns backward in time, starting from patterns related to the most recent observations. Applying this technique, temporal pat-terns that extend far into the past are likely to have low support in the data and hence would not be considered for classification. In-corporating the concept of recency in temporal pattern mining is a new research direction that, to the best of our knowledge, has not been previously explored in the pattern mining literature.
We study our RTP mining approach by analyzing temporal data encountered in Electronic Health Record (EHR) systems. In EHR data, each record (data instance) consists of multiple time series of clinical variables collected for a specific patient, such as laboratory test results and medication orders. The record may also provide in-formation about patient X  X  diseases and adverse medical events over time. Our objective is to learn classification models that can accu-rately detect adverse events and apply it to monitor future patients.
The task of temporal modeling for EHR data is challenging be-cause the data are multivariate and the time series for clinical vari-ables are irregularly sampled in time (measured asynchronously at different time moments). Therefore, most existing times series classification methods [6, 24], time series similarity measures [29, 20] and time series feature extraction methods [4, 13] cannot be directly applied on the raw EHR data.

This paper proposes a temporal pattern mining approach that can
I n the clinical domain, a patient may be healthy at first, then de-velop an adverse medical condition, then be cured and so on. handle complex data such as EHR. The key step for this approach i s defining a language that can adequately represent the temporal dimension of the data. Our approach relies on 1) temporal abstrac-tions [21] to convert numeric time series variables to time-interval sequences and 2) temporal relations [3] to represent temporal in-teractions among the variables. For example, this allows us to de-fine complex temporal patterns (time-interval patterns) such as  X  X he administration of heparin precedes a decreasing trend in platelet counts X .

After defining patterns from temporally abstracted data, we need to design an efficient mining algorithm for finding patterns that are useful for event detection. Mining time-interval data is a relatively young research field that extends sequential pattern mining [2, 31, 18, 30] to the more complex case of time-interval pattern mining Most existing methods mine frequent patterns in an unsupervised way in order to find temporal association rules [22, 11, 17, 14, 26, 27, 15]. Our objective is different because we are interested in min-ing temporal patterns that are potentially important for the event detection task. To address this, we present an efficient algorithm for mining RTPs (see above) from time-interval data.

We test and demonstrate the usefulness of our framework on real-world EHR data collected for 13,558 diabetes patients. Our task is to learn classification models that can correctly diagnose disorders associated with diabetes, such as cardiological, renal or neurological disorders. We first show that incorporating the tempo-ral dimension is beneficial for this task. In addition, we show the following advantages of our framework: 1. RTP mining focuses the search on temporal patterns that are 2. The number of frequent RTPs is much smaller than the num-3. Our mining algorithm is much more efficient than other tem-
Let D = { &lt; x i ,y i &gt; } n i =1 be a training dataset such that x is a multivariate temporal instance up to some time t i and y is a class label associated with x i at time t i . The objective is to learn a function f : X  X  Y that can label unlabeled instances. This general setting is applicable to different monitoring and event detection problems, such as the ones described in [23, 7, 9, 16].
In this work, we test our method on data from electronic health records (EHR), hence we will use the EHR application as exam-ple throughout the paper. For this task, every data instance x record for a specific patient up to time t i and the class label y notes whether or not this patient is diagnosed with an adverse med-ical condition (e.g., renal failure) at t i . Figure 1 shows a graphical illustration of an EHR instance with 3 clinical temporal variables. The objective is to learn a classifier that can predict well the studied medical condition and apply it to monitor future patients.
Learning the classifier directly from EHR data is very difficult because the instances consist of multiple irregularly sampled time series of different length. Therefore, we want to apply a space transformation  X  : X  X  X  X  that maps each instance x i to a fixed-size feature vector x  X  i , while preserving the predictive tem-poral characteristics of x i as much as possible.
S equential pattern mining is a special case of time-interval pattern mining, in which all intervals are instantaneous (with zero dura-tions).
 Figure 1: A n example of an EHR data instance with three temporal
One approach to define  X  is to represent the data using a prede-fined set of features and their values (a static transformation ) as in [10]. Examples of such features are  X  X ost recent platelet measure-ment X ,  X  X ost recent platelet trend X ,  X  X aximum hemoglobin mea-surement X , etc. Our approach is different and we learn transfor-mation  X  from the data using temporal pattern mining (a dynamic transformation ). This is done by applying the following steps: 1. Convert the numeric time series variables into time interval 2. Mine recent temporal patterns from the time interval data. 3. Transform each instance x i into a binary indictor vector x
After applying transformation  X  , we can use a standard machine learning method (e.g. support vector machines, decision tree, or logistic regression) on { &lt; x  X  i ,y i &gt; } n i =1 to learn function f .
In the following, we explain in details each of these steps.
The goal of temporal abstraction [21] is to transform the nu-meric time series variables to a high-level qualitative form. More specifically, each clinical variable (e.g., series of white blood cell counts) is transformed into an interval-based representation h v e ] , ..., v n [ s n ,e n ] i , where v i  X   X  is an abstraction that holds from time s i to time e i and  X  is the abstraction alphabet that represents a finite set of permitted abstractions.

For the EHR data, we segment all laboratory variables based on their values into the following abstract states: Very Low ( VL ), low ( L ), Normal ( N ), High ( H ) and Very High ( VH ), i.e.,  X  = { VL , L , N , H , VH } . We use the 10th, 25th, 75th and 90th percentiles of the lab values to define these 5 states: a value below the 10th percentile is very low ( VL ), a value between the 10th and 25th percentiles is low ( L ), and so on.
Let a state be an abstraction for a specific variable . We denote a state S by a pair ( F,V ) , where F is a temporal variable and V  X   X  is an abstraction value. Let a state interval be a state that holds during an interval . We denote a state interval E by a 4-tuple ( F,V,s,e ) , where F is a temporal variable, V  X   X  is an abstrac-tion value, and s and e are the start time and end time (respectively) of the state interval ( E.s  X  E.e ) 3 . For example, assuming the time granularity is days, ( glucose ,H, 5 , 10) represents high glucose val-ues from day 5 to day 10.

After abstracting all time series variables, we represent every in-stance x i in the database D as a Multivariate State Sequence (MSS) Z i . Let Z i . end denote the end time of the instance.
I f E.s = E.e , state interval E corresponds to a time point.
For notational convenience, we represent an MSS Z i a s a series of state intervals that are sorted according to their start times Z i = h E 1 ,E 2 ,...,E l i : E j .s  X  E j +1 .s : j  X  X  1 ,...,l  X  1 }
Note that we do not require E j .e to be less than E j +1 the state intervals are obtained from different temporal variables and their intervals may overlap.

E XAMPLE 1. Figure 2 shows an MSS Z i with two temporal variables: creatinine (C) and glucose (G). Assuming the time gran-ularity is days, this MSS represents 24 days of the patient X  X  record ( Z i .end = 24 ). For instance, we can see that the creatinine val-ues are normal from day 2 until day 14, then become high from day 15 until day 24. We represent Z i as: h E 1 = ( G,H, 1 , 5) , E 2 = ( C,N, 2 , 14) , E 3 = ( G,N, 6 , 9) , E 4 = ( G,H, 10 , 13) , E 5 =( C,H, 15 , 24) , E 6 =( G,VH, 16 , 23) i .
 Figure 2: A n MSS representing 24 days of a patient record. In this
The temporal relation between two instantaneous events (time points) can be easily described using three relations: before , at the same time and after . However, when the events have time durations (state intervals), the relations become more complex. Allen [3] described the temporal relation between two state intervals using 13 possible relations (Figure 3). But it suffices to use the following 7 relations: before , meets , overlaps , is-finished-by , contains , starts and equals because the other relations are simply their inverses. Allen X  X  relations have been introduced in artificial intelligence for temporal reasoning and have been used later in the fairly young research of time interval data mining [22, 11, 17, 26, 15].
A s we can see, most of these relations require equality of one or two of the intervals X  end points. That is, there is only a slight differ-ence between overlaps , is-finished-by , contains , starts and equals relations. When the time information in the data is noisy, which is the case for EHR data, using Allen X  X  relations may cause the prob-lem of pattern fragmentation 5 [14] .
I f two state intervals have the same start time, we sort them by their end time. If they also have the same end time, we sort them by lexical order (see [11]).
Having many different temporal patterns that describe a very sim-ilar situation in the data.

Therefore, we opt to use only two temporal relations: before ( b ) and co-occurs ( c ), which we define as follows: Given two state intervals E i and E j :
In order to obtain temporal descriptions of the data, basic states are combined using temporal relations to form temporal patterns (time interval patterns). In the previous section, we defined the relation between two states to be either before ( b ) or co-occurs ( c ). In order to define relations between k states, we use H X ppner X  X  representation of temporal patterns [11].

D EFINITION 1. ( Temporal Pattern ) A temporal pattern is de-fined as P = ( h S 1 ,...,S k i ,R ) where S i is the i th state of the pattern and R is an upper triangular matrix that defines the tem-poral relations between each state and all of its following states: i  X  { 1 ,...,k  X  1 } X  j  X  { i +1 ,...,k } : R i,j  X  { b,c } specifies the relation between S i and S j .

The size of a temporal pattern P is the number of states it con-tains. If P contains k states, we say that P is a k-pattern . Hence, a single state is a 1-pattern (a singleton). We also denote the space of all temporal patterns of arbitrary size by TP .

Figure 4 shows a graphical representation of a 4-pattern h S ( C,H ) ,S 2 = ( G,N ) ,S 3 = ( B,H ) ,S 4 = ( G,H ) i , where the states are abstractions of temporal variables creatinine (C), glucose (G) and BUN (Blood Urea Nitrogen) (B). The half matrix on the right represents the temporal relations between every state and the states that follow it. For example, the first state S 1 co-occurs with the third state S 3 : R 1 , 3 = c .

D EFINITION 2. Given an MSS Z = h E 1 ,E 2 ,...,E l i and a temporal pattern P = ( h S 1 ,...,S k i ,R ) , we say that Z contains P , denoted as P  X  Z , if there is an injective mapping  X  from the states of P to the state intervals of Z such that:  X  i  X  X  1 ,...,k } : S i .F = E  X  ( i ) .F  X  S i .V = E  X  ( i )  X  i  X  X  1 ,...,k  X  1 } X  j  X  X  i +1 ,...,k } : R i,j ` E  X  ( i )
The definition says that checking whether an MSS contains a k-pattern requires: 1) matching all k states of the pattern and 2) checking that all k ( k  X  1) / 2 temporal relations are satisfied. As an example, the MSS in Figure 2 contains the temporal pattern P = ( h ( C,N ) , ( G,N ) i , R 1 , 2 = c ) (normal creatinine co-occurs with normal glucose). To improve readability, we usually write 2-patterns of the form ( h S 1 ,S 2 i ,R 1 , 2 ) simply as S is, we can write P =( C,N ) c ( G,N ) .
In the event detection setting, each training temporal instance x (e.g. an electronic health record) is associated with class label y at time t i (e.g. whether or not a medical condition is detected). Consequently, recent measurements of the variables of x i t ) are usually more predictive than distant measurements, as was shown in [25] for clinical data. In the following, we present the definitions of recent state intervals and recent temporal patterns.
D EFINITION 3. Given an MSS Z = h E 1 ,E 2 ,..., E l i and a maximum gap parameter g , we say that E j  X  Z is a recent state interval in Z , denoted as r g ( E j , Z ) , if any of the following two conditions are satisfied:
The first condition is satisfied if E j is the most recent state in-terval in its variable ( E j .F ) and the second condition is satisfied if E j is less than g time units away from the end of the MSS ( Z.end ). Note that if g =  X  , any E j  X  Z is considered to be recent.
D EFINITION 4. ( RTP ) Given an MSS Z = h E 1 ,E 2 ,...,E a maximum gap parameter g , we say that temporal pattern P = ( h S 1 ,...,S k i ,R ) is a Recent Temporal Pattern (RTP) in Z , denoted as R g ( P, Z ) , if all the following conditions are satisfied: 1. P  X  Z with a mapping  X  from the states of P to the state 2. S k matches a recent state interval in Z : r g ( E  X  ( k ) 3.  X  i  X  { 1 ,...,k  X  1 } , S i and S i +1 match state intervals not The definition says that in order for temporal pattern P to be an RTP in MSS Z , 1) P should be contained in Z (Definition 2), 2) the last state of P should map to a recent state interval in Z (Definition 3), and 3) any pair of consecutive states in P should map to state intervals that are  X  X lose to each other X . This forces the pattern to be close to the end of Z and to have a limited temporal extension in the past. Note that g is a parameter that specifies the restrictiveness of the RTP definition. If g =  X  , any pattern P  X  Z would be considered to be an RTP in Z . When an RTP contains k states, we call it a k-RTP .

E XAMPLE 2. Let Z i be the MSS in Figure 2 and let the max-imum gap parameter be g = 5 days. Temporal pattern P 1 = ( C,N ) b ( G, VH ) is an RTP in Z i because P 1  X  Z i , ( G, VH , 16 , 23) is a recent state interval in Z i , and ( C,N, 2 , 14) is  X  X lose to X  ( G, VH , 16 , 23) ( 16  X  14  X  g ). On the other hand, P 2 ( G,N ) is not an RTP in Z i because ( G,N, 6 , 9) is not a recent state interval.

D EFINITION 5. ( Suffix ) Given temporal patterns P = ( h S S P is a suffix subpattern of P  X  , denoted as Suffix ( P, P  X  i  X  X  1 ,...,k 1 } X  j  X  X  i +1 ,...,k 1 } :
If P is a suffix subpattern of P  X  , we say that P  X  is a backward-extension superpattern of P .

P ROPOSITION 1. Given an MSS Z and temporal patterns P and P  X  , R g ( P  X  ,Z )  X  Suffix ( P,P  X  )  X  R g ( P,Z ) The proof directly follows from Definition 4.

E XAMPLE 3. Assume that P =( h S 1 ,S 2 ,S 3 i ,R 1 , 2 ,R is an RTP in Z . Proposition 1 says that its suffix subpattern ( h S R 2 , 3 ) must also be an RTP in Z . However, this does not imply that ( h S 1 ,S 2 i ,R 1 , 2 ) must be an RTP (the second condition of Defini-tion 4 may be violated) nor that ( h S 1 ,S 3 i ,R 1 , 3 ) must be an RTP (the third condition of Definition 4 may be violated).

D EFINITION 6. ( Frequent RTP ) Given a dataset D of MSS, a maximum gap parameter g and a minimum support threshold  X  , we define the support of an RTP P as RTP-sup g ( P, D ) = |{ Z D  X  R g ( P,Z i ) }| . We say that P is a frequent RTP in D given  X  if RTP-sup g ( P,D )  X   X  .

Note that Proposition 1 implies the following property of RTP-sup , which we will use in our algorithm for mining frequent RTPs .  X  P,P  X   X  TP , Suffix ( P,P  X  )  X  RTP-sup g ( P,D )  X  RTP-sup In this section, we present the algorithm for mining frequent RTPs . We chose to utilize the class information and mine frequent RTPs from each class label separately using local minimum sup-ports as opposed to mining frequent RTPs from the entire data us-ing a single global minimum support. The approach is reasonable when pattern mining is applied in the supervised setting because 1) for unbalanced data, mining frequent patterns using a global mini-mum support threshold may result in missing many important pat-terns in the rare classes and 2) mining patterns that are frequent in one of the classes (hence potentially predictive for that class) is more efficient than mining patterns that are globally frequent.
The algorithm takes as input D y : the MSS from class y , g : the maximum gap parameter and  X  y : the local minimum support threshold for class y . It outputs all temporal patterns that satisfy:
The mining algorithm performs a level-wise search. It first scans the database to find all frequent 1-RTPs (recent states). Then it ex-tends the patterns backward in time to find more complex temporal patterns. For each level k , the algorithm performs the following two phases to obtain the frequent (k+1)-RTPs : 1. The candidate generation phase: Generate candidate (k+1)-2. The counting phase: Obtain the frequent (k+1)-RTPs by This process repeats until no more frequent RTPs can be found.
In the following, we describe in details the candidate generation algorithm. Then we proposed techniques to improve the efficiency of candidate generation and counting.
We generate a candidate (k+1)-pattern by appending a new state ( 1-pattern ) to the beginning of a frequent k-RTP . Let us assume that we are backward extending pattern P =( h S 1 ,...,S k state S new to generate candidates of the form ( h S  X  1 ,...,S  X  First of all, we set S  X  1 = S new , S  X  i +1 = S i for i  X  { 1 ,...,k } and i +1 ,j +1 = R i,j for i  X  { 1 ,...,k  X  1 } X  j  X  { i + 1 ,...,k } . This way, we know that every candidate P  X  of this form is a backward-extension superpattern of P : Suffix ( P,P  X  ) .
In order to fully define a candidate, we still need to specify th e i.e., we should define R  X  1 ,i for i  X  { 2 ,...,k + 1 } . Since we have two possible temporal relations ( before and co-occurs ), there are 2 k possible ways to specify the missing relations, resulting in 2 different candidates. Let L denote all possible states and let F note all frequent k-RTPs , generating the (k+1)-candidates naively in this fashion results in 2 k  X | L | X | F k | different candidates.
This large number of candidates makes the mining algorithm computationally very expensive and limits its scalability. Below, we describe the concept of incoherent patterns and introduce a method that generates fewer candidates without missing any real pattern from the mining results.
D EFINITION 7. A temporal pattern P is incoherent if there does not exist any valid MSS that contains P .

Clearly, we do not have to generate and count incoherent can-didates because we know that they will have zero support in the data. We introduce the following two lemmas to avoid generat-{ 2 ,...,k +1 } in candidates of the form P  X  = ( h S  X  1 { 2 ,...,k +1 } : R  X  1 ,i = c and S  X  1 .F = S  X  i .F .
Two state intervals from the same temporal variable cannot co-occur because temporal abstraction segments each variable into non-overlapping state intervals.
 { 2 ,...,k +1 } : R  X  1 ,i = c  X  X  X  j  X  X  2 ,...,i  X  1 } : R  X 
P ROOF . Let us assume that there exists an MSS Z = h E 1 where P  X   X  Z . Let  X  be the mapping from the states of P  X  to the state intervals of Z . The definition of temporal patterns and the fact that state intervals in Z are ordered by their start values im-plies that the matching state intervals h E  X  (1) ,...,E  X  ( k +1) ordered by their start times: E  X  (1) .s  X  ...  X  E  X  ( k +1) E  X  ( j ) .s  X  E  X  ( i ) .s since j &lt; i . We also know that E E ever, since R  X  1 ,i = c , then E  X  (1) .e  X  E  X  ( i ) .s , which is a contra-diction. Therefore, there is no MSS that contains P  X  .
 E X AMPLE 4. Assume we want to extend P = ( h S 1 = ( C,H ) , S 2 = ( G,N ) , S 3 = ( B,H ) , S 4 = ( G,H ) i , R ) in Figure 4 with state S new = ( G,H ) to generate candidates of the form ( h S  X  ( G,H ) , S  X  2 = ( C,H ) , S  X  3 = ( G,N ) , S  X  4 = ( B,H ) , S  X  R  X  ) . The relation between S  X  1 and S  X  2 is allowed to be either before or co-occurs: R  X  1 , 2 = b or R  X  1 , 2 = c . However, according to Lemma 1, R  X  1 , 3 6 = c because both S  X  1 and S  X  3 belong to the same temporal variable ( G ), which in turn implies that R  X  1 , 4 6 = c and R  X  according to Lemma 2. By removing incoherent patterns, we reduce the number of candidates that result from adding ( G,H ) to 4-RTP P from 2 4 =16 to only 2.

T HEOREM 1. There are at most k + 1 coherent candidates that result from backward extending a single k-RTP with a new state. corresponds to a specific assignment of R  X  1 ,i  X  { b,c } for i  X  { 2 ,...k +1 } . When we assign the temporal relations, once a re-lation becomes before , all the following relations have to be before as well according to Lemma 2. We can see that the relations can be co-occurs in the beginning of the pattern, but once we see a before relation at point q  X  { 2 ,...,k +1 } in the pattern, all subsequent relations ( i&gt;q ) should be before as well: R  X  1 ,i = c : i  X  X  2 ,...,q  X  1 } ; R  X  1 ,i = b : i  X  X  q,...,k +1 }
Therefore, the total number of coherent candidates cannot be more than k +1 , which is the total number of different combina-tions of consecutive co-occurs relations followed by consecutive before relations.

In some cases, the number of coherent candidates is less than k + 1 . Assume that there are some states in P  X  that belong to the same variable as state S  X  1 . Let S  X  j be the first such state ( j  X  k +1 ). According to Lemma 1, R  X  1 ,j 6 = c . In this case, the number of coherent candidates is j  X  1 &lt; k +1 .
 Algorithm 1 illustrates how to extend a k-RTP P with a new state S new to generate coherent candidates (without violating Lemmas 1 and 2).

C O ROLLARY 1. Let L denote all possible states and let F note all frequent k-RTPs. The number of coherent (k+1)-candidates is always less or equal to ( k + 1)  X | L | X | F k | .
Even after eliminating incoherent patterns, the mining algorithm is still computationally expensive because for every candidate, we need to scan the entire database in the counting phase to deter-mine its RTP-sup . The question we try to answer in this section is whether we can omit portions of the database that are guaran-teed not to contain the candidate we want to count. The proposed solution is inspired by [32] that introduced the vertical format for itemset mining and later applied it for sequential pattern mining [31].

Let us associate every frequent RTP P with a list of identifiers for all MSS that have P as an RTP (Definition 4): Clearly, RTP-sup g ( P,D y ) = | P. RTP-list | .
 Let us also associate every state S with a list of identifiers for all MSS that contain S (Definition 2): Now, when we generate candidate P  X  by backward extending RTP P with state S , we define the potential list ( p-RTP-list ) of P  X  as follows:
P R OPOSITION 2. Let P  X  be a backward-extension of RTP P with state S : P  X  . RTP-list  X  P  X  . p-RTP-list
P ROOF . Assume Z i is an MSS such that R g ( P  X  ,Z i ) . By defi-nition, i  X  P  X  . RTP-list . We know that R g ( P  X  ,Z i S  X  Z i  X  i  X  S.list . Also, we know that Suffix ( P,P  X  ) (Definition 5)  X  R g ( P,Z i ) (Proposition 1)  X  i  X  P. RTP-list . Therefore, i  X  P. RTP-list  X  S.list = P  X  . p-RTP-list
Putting it all together, we compute the R TP-lists in the count-ing phase (based on the true matches) and the p-RTP-lists in the candidate generation phase. The key idea is that when we count candidate P  X  , we only need to check the instances in its p-RTP-list because according to Proposition 2: i 6 X  P  X  . p-RTP-list  X  i 6 X  P  X  . RTP-list  X  P  X  is not an RTP in Z i . This offers a lot of compu-tational savings because the p-RTP-lists get smaller as the size of the patterns increases, making the counting phase much faster.
Algorithm 2 outlines the candidate generation. Line 4 gener-ates coherent candidates using Algorithm 1. Line 6 computes the p-RTP-list for each candidate. Note that the cost of the intersec-tion is linear because the lists are always sorted according to the order of the instances in the database. Line 7 applies an additional pruning to remove candidates that are guaranteed not to be frequent according to the following implication of Proposition 2: | P  X  . p-RTP-list | &lt;  X  y =  X  X  P  X  . RTP-list | = RTP-sup
I n this section, we summarize our approach for learning clas-sification models for event detection problems. Given a training stance up to time t i and y i is a class label at t i , apply the following steps: 1. Convert every instance x i to an MSS Z i using temporal ab-2. Mine the frequent RTPs from the MSS of each class label 3. Convert every MSS Z i into a binary vector x  X  i of size equal 4. Learn the classification model on the transformed binary rep-
In this section, we present our experiments on large-scale elec-tronic health record (EHR) data collected for diabetic patients. We test our approach on the problem of detecting various types of dis-orders that are frequently associated with diabetes.
The diabetes dataset consists of 13,558 records of adult diabetic patients (both type I and type II diabetes). Each patient X  X  record consists of time series of 19 different lab values, including blood glucose, creatinine, glycosylated hemoglobin, blood urea nitrogen, liver function tests, cholesterol, etc. In addition, we have access to time series of ICD-9 diagnosis codes reflecting the diagnoses made for the patient over time. Overall, the database contains 602 different ICD-9 codes. These codes were grouped by our medical expert into nine major categories: cardiovascular disease, renal dis-ease, peripheral vascular disease, neurological disease, metabolic disease, inflammatory disease, ocular disease, cerebrovascular dis-ease and hypertension. These disease categories are frequently as-sociated with diabetes. Our objective is to learn models that are able to accurately diagnose these diseases. More specifically, at any point in time, we are interested in assigning a label for the disorder the patient with the diabetes suffers from. We omit the hy-pertension category from the analysis because it occurred in almost all patients, making it difficult to find negative examples.
The experiments are performed separately for each of the 8 major diagnosis categories (diseases). For each category, we divide the data into cases (positives) and controls (negatives) as follows:
To avoid having uninformative training data, we discard instances that contain less than 10 lab measurements or that span less than 3 months (short instances). We choose the same number of con-trols as the number of cases for each category to make the datasets balanced. Table 1 shows the number of cases for each diagnosis category (the number of controls is the same).

To construct the features, we consider both the laboratory tests and the diagnosis codes. Note that the diagnosis of one or more disease categories may be predictive of the (first) occurrence of an-other disease, so it is important to include them as features. Lab-oratory tests are represented as numeric time series. We abstract them using value abstraction (see Section 3.1). Diagnosis cate-gories, when used as features, are represented as intervals that start at the time of the diagnosis and extend until the end of the record.
In this section, we test the ability of our RTP mining framework to represent and capture temporal patterns important for the predic-tion task. In particular, we compare the classification performance of the following feature construction methods: 1. Last_values: The features are formed from the most recent
T he features are numeric for the laboratory variables (e.g., last creatinine value is 2.2) and binary for the disease categories (whether or not the disease was diagnosed). Table 1: T he eight major diagnosis categories (diseases) used in the 2. TP: The features correspond to all frequent temporal pat-3. TP_sparse: The features correspond to the top 50 discrimi-4. RTP: The features correspond to all frequent RTPs . 5. RTP_sparse: The features correspond to the top 50 discrim-
The first method is atemporal and only considers the most recent values for defining the classification features (a static transforma-tion). On the other hand, methods (2-5) use temporal patterns (built using temporal abstractions and temporal relations) as their features (a dynamic transformation). For TP ( TP_sparse ), the feature value is one if the corresponding temporal pattern occurs anywhere in the instance (Definition 2), and zero otherwise. For RTP ( RTP_sparse ), the feature value is one if the corresponding temporal pattern occurs recently in the instance (Definition 3), and zero otherwise.
For methods (2-5), we set the local minimum supports (  X  y 15% of the number of instances in the class. For the RTP mining methods (4-5), we set the maximum gap parameter ( g ) to 6 months. The reason for including methods 3 and 5 is to test the ability of TP and RTP to represent the target disease using only a limited number of temporal patterns (50 patterns in our case).

We judged the quality of the different feature representations in terms of their induced classification performance. More specifi-cally, we use the features extracted by each method to build a linear SVM classifier and evaluate its performance using the classifica-tion accuracy and the area under the ROC curve (AUC). We did not compare against other time series classification methods because most methods [24, 6, 28, 4] cannot be directly applied on multi-variate irregularly sampled time series data.
 Below, we show the classification accuracy (Table 2) and the AUC (Table 3) for each feature representation method on each clas-sification task (major disease). All classification results are re-ported using averages obtained via 10-folds cross validation .
The results show that features based on temporal patterns are beneficial for the classification task, since they outperform fea-tures based on most recent values (see for example the NEURO , OCLUR and CARDI datasets). The results also show that RTP and RTP_sparse mostly outperform TP and TP_sparse . It is impor-tant to note that although patterns generated by TP subsume the ones generated by RTP (by definition, every frequent RTP is also a frequent TP ), the induced binary features are often different. For Dataset Last_values TP TP_sparse RTP RTP_sparse CARDI 67.41 71.82 71.62 71.82 71.98 RENAL 77.71 76.38 76.66 78.08 78.33 PERIP 66.82 68.55 68.38 70.01 69.91 NEURO 64.66 68.95 68.33 69.18 69.68 METAB 72.83 74.64 73.61 73.3 73.09 INFLM 64.6 66.73 66.69 67.5 67.94 OCULR 65.83 70.8 70.71 68.82 69.22 CEREB 65.21 66.64 66.7 67.93 66.98 Table 2: The classification accuracy for the different featur e representation methods (SVM is used for classification). Dataset Last_values TP TP_sparse RTP RTP_sparse CARDI 75.1 80.13 79.61 80.18 80.52 RENAL 85.45 84.8 84.97 86.13 86.23 PERIP 74.38 76.08 75.95 77.88 78.31 NEURO 72.25 76.43 75.81 77.34 76.98 METAB 80.64 82.67 81.66 82.52 82.97 INFLM 71.04 73.62 73.43 74.39 74.92 OCULR 72.12 78.34 78.28 76.11 76.85 CEREB 72.23 73.46 74.42 75.37 75.18 Table 3: The area under the ROC curve (AUC) for the different f eature representation methods (SVM is used for classification). instance, a pattern that is not discriminative when considered in the entire records may become more discriminative when considered as a recent pattern. This can be seen clearly for the RENAL dataset, where TP and TP_sparse perform poorly because the discrimina-tive signal is mostly contained in the recent values.
Figure 5 compares the number of temporal patterns that are ex-tracted by frequent temporal pattern mining ( TP ) and by frequent RTP mining ( RTP ). Similar to the previous setting, we set the local minimum supports for both methods to 15% and we set the maxi-mum gap parameter for RTP to 6 months.
 The results show that the number of temporal patterns mined by RTP is at least an order of magnitude smaller than the number of patterns mined by TP for all datasets. This can facilitate the process of reviewing and validating the patterns by human experts. Figure 5: T he number of temporal patterns of TP and RTP on all
Table 4 shows some of the top predictive RTPs according to their precision (confidence) 7 . The first three RTPs ( P 1 , P predicting renal (kidney) disease. These patterns relate the risk of renal problems with very high values of the BUN test ( P 1 crease in creatinine levels from normal to high ( P 2 ), and high val-ues of BUN co-occurring with high values of creatinine ( P shows that an increase in glucose levels from high to very high may indicate a metabolic disease. Finally, P 5 indicates that patients who were previously diagnosed with cardiovascular disease and exhibit an increase in glucose levels are prone to develop a cerebrovascular disease. These patterns, extracted automatically from data without incorporating prior clinical knowledge, are in accordance with the medical diagnosis guidelines.
 RTP prec recall
P 1 : B UN=VH  X  Dx=RENAL 0.97 0.17
P 2 : C reat=N before Creat=H  X  Dx=RENAL 0.96 0.21
P 3 : B UN=H co-occurs Creat=H  X  Dx=RENAL 0.95 0.21
P 4 : G luc=H before Gluc=VH  X  Dx=METAB 0.79 0.24
P 5 : D x=CARDI co-occurs ( Gluc=N before Table 4: P redictive RTPs with their precision ( prec ) and recall. Ab-
In this section, we study the efficiency of different temporal pat-tern mining methods. In particular, we compare the running time of the following methods: 1. TP_Apriori: Mine frequent temporal patterns by extending 2. RTP_no-lists: Mine frequent RTPs backward in time as de-3. TP_lists: Mine frequent temporal patterns by extending the 4. RTP_lists: Our proposed method for mining frequent RTPs .
To make the comparison fair, all methods apply the techniques we propose in Section 4.2.2 to avoid generating incoherent candi-dates. Note that if we do not remove incoherent candidates, the execution time for all methods greatly increases.

The experiments are conducted on a Dell PowerEdge R610 server with an Intel Xeon 3.3GHz CPU and 96GB of RAM. Similar to the previous settings, we set the local minimum supports to 15% and the maximum gap parameter to 6 months (unless stated otherwise).
M ost of the highest precision RTPs are predicting the RENAL category because it is the easiest prediction task. So to diversify the patterns, we show the top 3 predictive RTPs for RENAL and the top 2 predictive RTPs for other categories.

Figure 6 shows the execution time (in seconds) of the above methods on all major diagnosis datasets. We can see that our pro-posed RTP_lists method is much more efficient the other methods. For instance, on the INFLM dataset, RTP_lists is around 5 times faster than TP_lists , 10 times faster than RTP_no-lists and 30 times faster than TP_Apriori .
 Figure 6: T he mining time (in seconds) of TP_Apriori , RTP_no-lists ,
Figure 7 compares the execution time (in seconds) of the meth-ods on the CARDI dataset for different minimum support thresh-olds. Note that the difference in the execution time between RTP_lists and the other methods becomes larger when the minimum support is low (10%).
 Figure 7: T he mining time (in seconds) of TP_Apriori , RTP_no-lists ,
Finally, let us examine the effect of the maximum gap parameter ( g ) on the efficiency of recent temporal pattern mining. Figure 8 shows the execution time (in seconds) of all methods on the CARDI dataset for different values of g (the execution time of TP_Apriori and TP_lists does not depend of g ).

Clearly, the execution time of both RTP_no-lists and RTP_lists increases with g because the search space becomes larger (more temporal patterns become RTPs ). The figure shows that when the maximum gap is 21 months, RTP_no-lists becomes slower than TP_Apriori . The reason is that for large values of g , applying the Apriori pruning [1] in candidate generation becomes more efficient (generates less candidates) than the backward extension of tem-poral patterns (see Example 3). On the other hand, RTP_lists in-creases much slower with g and maintains its efficiency advantage over TP_lists for larger values of g . Figure 8: T he mining time (in seconds) of TP_Apriori , RTP_no-list ,
The increasing availability of large temporal datasets prompts the development of scalable and more efficient temporal pattern mining techniques. Methods for mining sequential (time-point) data were first introduced in the literature starting in the mid-1990 [2, 31, 18, 30]. Since then, these methods have been extended to mining time interval data [22, 11, 17, 14, 26, 27, 15]. Unfortu-nately, mining the entire set of temporal patterns (sequential pat-terns or time-interval patterns) from large-scale datasets is inher-ently a computationally expensive task. To alleviate this problem, temporal constraints (e.g., restricting the total pattern duration or restricting the permitted gap between consecutive events in a pat-tern) have been proposed to scale up the mining [19].

In this paper, we proposed a new class of temporal constraints for finding Recent Temporal Patterns ( RTPs ), which are particu-larly important for monitoring and event detection problems. We presented an efficient algorithm that mines time-interval patterns backward in time, starting from patterns related to the most recent observations. Our experimental evaluation on EHRs for diabetes patients showed that the RTP framework is very useful to efficiently find patterns that are important for predicting various types of dis-orders associated with diabetes.
