 Many applications in structure matc hing require the abilit y to searc h for graphs that are similar to a query graph, i.e., similarity graph queries . Prior works, especially in chemoin-formatics, have used the maxim um common edge subgraph (MCEG) to compute the graph similarit y. This approac h is prohibitiv ely slow for real-time queries. In this work, we prop ose an algorithm that extracts and indexes subgraph features from a graph dataset. It computes the similarit y of graphs using a linear graph kernel based on feature weights learned o X ine from a training set generated using MCEG. We show empirically that our prop osed algorithm of learn-ing to rank graphs can achieve higher normalized discoun ted cumulativ e gain compared with existing optimal metho ds based on MCEG. The running time of our algorithm is or-ders of magnitude faster than these existing metho ds. H.3.3 [ Information Storage and Retriev al ]: Information Searc h and Retriev al| Query formulation,R etrieval models Algorithms, Design, Experimen tation Learn to rank, graph kernel, similarit y graph searc h
Graphs have been used to represen t structured data for a long time. Increasingly , massiv e complex structured data, such as chemical molecule structures [6], social networks [1], and XML structures [12], are identi X ed and studied in many areas. E X cien t and e X ectiv e access of the desired structure information is crucial in many areas from generic and verti-cal researc h engine [8, 9, 7].

Usually a typical query to searc h for desired graph infor-mation is a subgraph query that searc hes for graphs contain-ing exactly the query graph, i.e., the support [10]. However, su X cien t knowledge to select subgraphs to characterize the desired graphs is required and sometimes no supp ort exists, so the similarity graph query searc hing for all graphs sim-ilar to the query graph is desired to bypass the subgraph selection. To measure the similarit y of two graphs, previous metho ds [5, 10] usually use the size of the maxim um common edge subgraph (MCEG) between two graphs, i.e., the num-ber of edges in MCEG. The crux of similarit y graph searc h lies in the complexit y of the MCEG isomorphism algorithm for similarit y measuremen t. However, since the MCEG iso-morphism problem is NP-hard [10], it is prohibitiv ely expen-sive to scan all graphs in real time to  X nd MCEG. Previous works [10, 5] use di X eren t  X lters to prune out unsatis X ed graphs given a user speci X ed minim um MCEG size. If users need more searc h results, the minim um MCEG size has to be reduced and more graphs are retriev ed. However, previ-ous metho ds are still slow because MCEG isomorphism tests have to be executed on the  X ltered graph set, which usually is still large. Rather than executing MCEG isomorphism tests on the  X  X , we prop osed to index the graphs o X ine us-ing subgraph features to enable fast graph searc h.
The goal of using MCEG sizes to measure the graph sim-ilarit y is to rank searc h results. Instead of using MCEG, we prop ose a novel approac h that uses a linear graph kernel function to rank retriev ed graphs using the indexed sub-graph features and feature weights learned from a training set. Our metho d generates a training set o X ine using MCEG isomorphism, a training query set, and a graph set. Our approac h avoids MCEG isomorphism online and is more ef- X cien t computationally than previous metho ds [10, 5]. Ex-perimen tal results also show that our metho d can achieve a reasonably high normalized discoun ted cumulativ e gain [13] in a signi X can tly shorter time in comparison to existing metho ds. Moreo ver, because our metho d learns the ranking function from a training set, it can be applied to other sim-ilarit y metrics, including similarit y scores labeled by human experts or extracted from user logs.
In this work, we consider labeled undir ected graphs and conne cted labeled undir ected subgraph features, where a path exists for any pair of vertices on the subgraph. Notations are given as follows:
De X nition 1. Labeled Undirected Graph: A labeled undirected graph is a 5-tuple, G = f V; E; L V ; L E ; l g , where V is a set of vertices, each v 2 V is an unique ID represen ting this vertex, E  X  V  X  V is a set of edges with each e = ( u; v ) 2 E; u 2 V; v 2 V , L V is a set of vertex labels, L E is a set of edge labels, and l : V [ E ! L V [ L E is a function assigning labels to vertices and edges on the graph. The size of a graph G , j G j , is de X ned as the edge coun t of G . De X nition 2. Subgraph and Frequency: A subgraph G 0 of a graph G is also a graph where V G 0  X  V G and E G 0 E
G , i.e. G 0  X  G . G is the supergraph of G 0 . An embedding of a subgraph G 0 in a graph G , i.e., E G 0  X  G , is an instance of G 0  X  G . We say that in a graph G , two embeddings E 9 v; v 2 G 0 ^ v 2 G 00 . The frequency of a subgraph G 0 in a graph G , i.e., F G 0  X  G , is the embedding number of G 0
De X nition 3. Graph Isomorphism: An isomorphism between two graphs G and G 0 is a bijectiv e function f : V
G ! V G 0 mapping each vertex on G to a vertex on G 0 , such that 8 v 2 V G ; l G ( v ) = l G 0 ( f ( v )), and 8 e = ( u; v ) 2 E
G ; ( f ( u ) ; f ( v )) 2 E G 0 and l G (( u; v )) = l G 0 Since it is a bijectiv e function, a bijectiv e function f V G exists with the same of reverse one to one mapping of f . De X nition 4. Canonical labeling: A canonical labeling CL ( G ) is a string to represen t a graph G , where given two graphs G and G 0 , G is isomorphic to G 0 i X  CL ( G ) = CL ( G De X nition 5. Maxim um Common Edge Subgraph: A graph G 0 is a common edge subgraph of G i and G j , if G 0 is isomorphic to subgraphs of G i and G j . A common edge subgraph G 0 of G i and G j is a maximum common edge subgraph , i.e., M CEG ( G i ; G j ), i X  no common edge subgraph G 00 of G i and G j exists that j E ( G 00 ) j &gt; j E ( G coun t on G 00 is larger than that on G 0 . The size of a MCEG, j M CEG ( G i ; G j ) j , is de X ned as its edge coun t. Note that an MCEG is not necessarily a connected graph. To make the similarit y scores comparable between di X er-ent sizes of query graphs in our researc h, we normalize the MCEG sizes into the interval [0 ; 4], where 4 means the query graph is a subgraph of the retriev ed graph, while 0 means no edge matc hed. These normalize d MCEG sizes are used as the similarit y scores for training and test in our experimen ts.
Discoun ted cumulativ e gain (DCG) is the most widely used metric to evaluate the performance of ranking func-tions. Given a query q and n ordered results , it is computed as follows [3], where y i ; i = 1 ; :::; n are the real relev ance scores of the n ordered results, c i is a non-increasing function of i , typically c = 1 =log ( i + 1), and f ( y i ) is a non-decreasing function of y , typically f ( y i ) = 2 y i + 1, or sometimes f ( y i ) = y is higher, the result i is more relev ant. If y i 2 f 0 ; 1 g , only relev ance and irrelev ance are considered. Normalized dis-coun ted cumulativ e gain (NDCG) is a score that normalize DCG scores into the interval of [0 ; 1] using the maxim um DCG that can be achieved. The average NDCG, N DCG Q , for the whole query set Q is used for evaluation.
In this section, we describ e our searc h algorithm and the weighted linear graph kernel to measure the graph similarit y. Then we describ e how to learn the weights.
A naive approac h to similarit y graph searc h is to scan all the graphs to  X nd MCEGs of the query and each graph, which is prohibitiv ely expensiv e to be executed in real time. Usually previous metho ds  X rst  X lter out graphs with lower MCEG sizes than a given threshold. Then they determine the size of the MCEG between the query graph hand each candidate graph. This size is used as the similarit y score [10, 5] for ranking the result graphs. Detecting MCEG iso-morphism is NP-hard [10], and all existing algorithms for MCEG isomorphism are extremely expensiv e. This makes online similarit y graph searc h prohibitiv ely slow for large graph databases. We prop ose a new e X cien t similarit y graph searc h algorithm shown in Algorithm 1. It  X rst returns all the graphs in the supp ort of the query that have the max-imum MCEG size, and then use a fast graph ranking func-tion to compute a heuristic similarit y score. To return the supp ort of the query , subgraph isomorphism tests are re-quired. Algorithms for subgraph isomorphism are signi X -cantly faster than those for MCEG isomorphism [10]. Our prop osed fast graph ranking function uses a weighted kernel between vectors constructed from subgraph features. Thus, our prop osed metho d is signi X can tly faster for online queries in comparison with metho ds using MCEG.

First, we assume we have built an index of graphs using their subgraph features. Subgraph features can be disco v-ered from those graphs using any previous metho ds [10, 4]. Then, as illustrated in Algorithm 1, given a query graph G , the algorithm  X nds the support of G q , D G q (Line 1-11). Thus, all the graphs in the supp ort should be returned as the top-most candidates in the result list. If G q is indexed, it is simple to  X nd D G q using the index. Otherwise, candi-dates containing all the indexed subgraph features of G q returned and subgraph isomorphism is performed to remo ve graphs that do not contain G q . Second, if more results are required, similar graphs with lower similarit y scores are re-turned (Line 12-19). Our prop osed metho d uses a weighted kernel as the similarit y function. All the graphs containing at least one indexed subgraph feature of G q is returned as candidates except supp ort graphs found at the  X rst stage. For each candidate and the query G q , a similarit y score is computed using a weighted linear graph kernel based on the indexed subgraph features and corresp onding weights. This similarit y score computation is fast and can be computed during searc h. Finally , graphs are sorted based on the simi-larity scores and the top results are returned. A graph kernel is de X ned as follows, De X nition 6. Graph Kernel: Let X be a set of graphs, R denotes the real numbers,  X  denotes set product, the func-tion K : X  X  X ! R is a kernel on X  X  X if K is symmetric , i.e. 8 G i and G j 2 X , K ( G i ; G j ) = K ( G j ; G i ), and K is positive semi-de X nite , i.e. 8 N  X  1 and 8 G 1 ; G 2 ; :::; G the N by N matrix K de X ned by K ij = K ( G i ; G j ) is pos-itive semi-de X nite , i.e. P ij c i c j K ij  X  0 ; 8 c 1 ; c Equiv alently, a symmetric matrix is positiv e semi-de X nite if all its eigen values are nonnegativ e [2].

The MCEG sizes of two graphs is also a graph kernel, but expensiv e to compute. We de X ne a time-e X cien t and learn-able weighted linear graph kernel based on indexed subgraph features and corresp onding frequencies as follows,
W ( G 0 ) are the learnable parameters in this kernel. Thus, our goal is to learn the kernel function to appro ximate a target function for ranking, but not necessarily the same as the function of MCEG sizes. Algorithm 1 Similarit y Graph Searc h
Our learning task also su X ers from the data sparsit y prob-lem [11], i.e., many features appearing in the test set may not have appeared in the training set. With the goal to make the space dense, we use a feature extraction metho d to generate features from subgraphs, and cluster subgraphs with the same feature vector together into a single dimen-sion. Let us denote the many-to-one mapping function from a subgraph G 0 to a subgraph cluster using the prop osed fea-ture exaction metho d as Clu ( G 0 ). Then, we can rewrite the linear graph kernel as follows, K ( G i ; G j ) = X We extract the following features of a subgraph: the number of edges, the number of vertices with a speci X c label, the number of branc hes, and the number of cycles.
Supp ose we have a training set with N instances, T = f G ( q;n ) ; G n ; y n g N n =1 , where each instance is a pair of a query graph G ( q;n ) and a retriev ed graph G n , and y n is the similar-ity score between them. As mentioned before, if y n 2 f 1 ; 0 g , it represen ts only relev ance or irrelev ance between G ( q;n ) G n ; Otherwise, it represen ts the similarit y between G ( q;n ) and G n . This training set can be generated by arbitrary similarit y functions that take in two graphs G ( q;n ) and G as inputs and output a similarit y score y n . In our work, we use the normalized MCEG sizes as the similarit y scores, y
Our eventual goal is to  X nd the optimal linear weighted graph kernel that maximizes the NDCG function that is the metric to evaluate the ranked retriev ed results. However, the objectiv e function of NDCG cannot be represen ted by the parameters of the graph kernel in a closed form, so we cannot optimize the NDCG function directly and  X nd the optimal graph kernel. Instead, we optimize a speci X c loss function f ( y n ), the non-increasing function in Equation 1, using regression. Previous work [3] showed that regression on f ( y n ) can achieve a better NDCG of the ranked searc h results than regression on y n . Thus, one of the key issue is to choose the loss function. We choose a weighted L 2 loss function, where f ( y n )  X  f (^ y n ) is the error of the instance n , w weight of Instance n , and ^ y n is the predicted value of y Instances with higher relev ance scores are considered more importan t, so that they have higher weights. However, no previous work determined that what the value of the in-stance weights should be. Empirically we de X ne the weights as the normalized MCEG sizes. In our work, we use an un-weighted loss function but a weighted sampling metho d to generate a training set rather than using the weighted loss function. Using this metho d, we can have a smaller training set than using uniform sampling but weighted loss function.
In this section, we evaluate our prop osed approac h by comparing with two heuristics and the metho d using MCEG isomorphism in terms of NDCG and response time of queries. We use the real data set and test query set used by Yan, et al., [10]. It is a NIH HIV antiviral screen data set that con-tains 43905 chemical structures. The experimen tal subset contains 10000 chemical structures selected randomly from the whole data set and the query set for evaluation contains 6000 randomly generated queries, i.e., 1000 queries per query size, where Size ( G q ) = f 4 ; 8 ; 12 ; 16 ; 20 ; 24 g . Although we only use chemical structures for experimen ts, our approac h is applicable to any structures that can be represen ted by graphs, such as DNA sequences and XML  X les.

In our experimen t, rather than using a weighted loss func-tion, we use a weighted sampling metho d to generate a train-ing set o X -line based on the MCEG isomorphism algorithm. We  X rst generate 6000 queries with the same distribution of the test query set describ ed above. Then for each query graph, we randomly select graphs from the 10000 chemical structures with corresp onding conditional sampling proba-bility given the normalized MCEG sizes (as mentioned be-fore, they are normalized between [0,4]) between the query and the graph. Finally we use the normalized MCEG sizes as the target similarit y scores y n for the n th query-graph pair. Since we only care top 20 searc h results, we remo ve all the query-graph pairs with low normalized MCEG sizes. We also remo ve query-graph pairs where the query is a sub-graph of the graph. Since  X nding the MCEG between the query and the selected graph is time-consuming, to speed up the training instance generation, we do as follows: 1) given a query , to searc h all graphs using the Algorithm 1, and the similarit y function is to use the linear graph kernel with uniform feature weights, 2) to pick only the top 1000 returned graphs and remo ve graphs among them that are supergraphs of the query , and 3) to compute the normalized MCEG sizes y n between each surviv ed graph and the query and sample the pair using the probabilit y of ( y n = 4) = 10.
The  X nal training set contains instances of query and graph pairs with a similarit y score y n , and each instance has a subgraph feature vector where each entry is the min-imum one of the subgraph frequency on the query and on the graph (shown in Equation 2). Finally , in our experimen t, we generate a training set with a total of 459,047 pairs of queries and graphs. Any previous subgraph feature selection metho ds can be applied to select a dense subset of frequen t subgraphs [10, 4]. Then we cluster subgraphs using feature extraction to get 300 features  X nally .

Besides comparing di X eren t feature weights, we also use two di X eren t sizes ( j S j = 9855 subgraph features v.s. j S j = 50475 subgraph features) of indexed subgraph sets to show the e X ect of the number of the indexed subgraph set, S . In the experimen ts, we compare the following metho ds: 1) linear graph kernel with subgraph feature weights learned using regression on f ( y n ) with the L 2 loss function and weighted sampling ( lear n in Table 1), 2) linear graph kernel using subgraph sizes as feature weights ( size in Table 1), 3) linear graph kernel with uniform subgraph feature weights ( unif orm in Table 1), 4) linear graph kernel using subgraph sizes as feature weights with a larger subgraph feature set ( size L in Table 1), and 5) linear graph kernel with uniform subgraph feature weights with a larger subgraph feature set ( unif orm L in Table 1). Note that the metho d using MCEG always has the perfect NDCG, because it is assumed to be the gold standard. For the query response time in Figure 1, since the prop osed metho d has similar online response time no matter what kind of subgraph feature weights it uses, we only evaluate the learned weights and called it graph kernel . We applied the techniques in [5] to optimize the algorithms of the MCEG isomorphism.

In the experimen ts, we evaluate all queries for di X eren t query sizes together. Average experimen tal NDCG results of top 1, 3, 10, and 20 searc h results are shown in Ta-ble 1. We can see all the metho ds achieve NDCGs above 93%, which are signi X can tly higher than the NDCGs for web searc h [3]. the average NDCGs are impro ved by about 1% for all queries. Especially the 1% impro vemen t is based on such high NDCGs above 93%. From the previous work [3], for the case of a standard deviation = 24 and a sample size = 10000, roughly speaking, the di X erence of two NDCGs is considered as \signi X can t" if it is larger than 0 : 47%. Hence, the impro vemen ts of NDCGs after learning are roughly sta-tistically signi X can t for all NDCGs.

Finally we compare the average online response time for using the prop osed linear graph kernel and MCEG isomor-phism. As in the prop osed Algorithm 1, to return top n similar graphs using MCEG isomorphism, two cases exist: 1) If the top n similar graphs all contain the query , only sub-graph isomorphism tests are executed rather than running MCEG isomorphism tests. In this case, the response time of a query is the same as our prop osed metho d. 2) If only part of or none of the top n similar graphs contain the query , the MCEG isomorphism algorithm has to be executed to  X nd more similar graphs. However, applying the MCEG isomor-phism test to scan all the graphs is prohibitiv ely expensiv e. As mentioned above, previous metho ds [10, 5] use  X lters to remo ve part of graphs containing smaller MCEGs than the MCEG size threshold before preforming the MCEG iso-morphism algorithm. However, no previous work prop osed metho ds to  X nd top n similar graphs containing the largest MCEG sizes. To simplify the situation for time complexit y comparison, we assume that we have a  X lter to return only 100 graph candidates to execute the MCEG isomorphism test. That is, the curve in Figure 1 is the response time that at most 100 MCEG isomorphism tests are performed. Ac-tually for most cases, more than 100 graph candidates are returned to perform MCEG isomorphism tests [10], which means in practice, using the MCEG isomorphism algorithm requires even a longer average response time than the cases shown in our experimen ts. Figure 1 shows the curves of average response time of similarit y graph queries using two ranking metho ds: graph kernel using weighted linear graph kernel, and MCEG using the MCEG isomorphism test to rank graphs. It shows that our prop osed metho d graph ker-nel is signi X can tly more time e X cien t than MCEG , and can achieve high NDCGs above 94%.
We acknowledge the partial supp ort of NSF Gran t 0535656 and 0845487.
