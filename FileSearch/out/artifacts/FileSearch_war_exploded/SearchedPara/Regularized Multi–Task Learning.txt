 Past empirical work has shown that learning multiple re-lated tasks from data simultaneously can be advantageous in terms of predictive performance relative to learning these tasks independently. In this paper we present an approach to multi X  X ask learning based on the minimization of regu-larization functionals similar to existing ones, such as the one for Support Vector Machines (SVMs), that have been successfully used in the past for single X  X ask learning. Our approach allows to model the relation between tasks in terms of a novel kernel function that uses a task X  X oupling param-eter. We implement an instance of the proposed approach similar to SVMs and test it empirically using simulated as well as real data. The experimental results show that the pro-posed method performs better than existing multi X  X ask learn-ing methods and largely outperforms single X  X ask learning us-ing SVMs.
 I.2.6 [ Artificial Intelligence ]: Learning.
 Algorithms, Theory.
 Multi X  X ask Learning, Support Vector Machines, Regular-ization, Kernel Methods.
In many practical situations a number of statistical mod-els need to be estimated from data. For example multi X  modal human computer interface requires the modeling of both, say, speech and vision; machine vision problems may themselves require the estimation of multiple models, for example one for detecting each object, i.e. a face, from a pool of similar objects; in finance forecasting models for predicting the value of many possibly related indicators si-multaneously is often required; in marketing modeling the preferences of many individuals simultaneously is common practice [1, 2].

When there are relations between the tasks to learn, it can be advantageous to learn all tasks simultaneously instead of following the more traditional approach of learning each task independently of the others. There has been a lot of experimental work showing the benefits of such multi X  X ask learning relative to individual task learning when tasks are related, see [4, 11, 15, 22]. There have also been various attempts to theoretically study multi X  X ask learning, see [4, 5, 6, 7, 8, 15, 23].

In this paper we develop methods for multi X  X ask learning that are natural extensions of existing kernel based learn-ing methods for single task learning, such as Support Vec-tor Machines (SVMs) [25]. To the best of our knowledge, this is the first generalization of regularization X  X ased meth-ods from single X  X ask to multi X  X ask learning. We test an in-stance of the proposed methods experimentally using both simulated and real data. The experiments show that the proposed method performs better than existing multi X  X ask learning methods and largely outperforms single X  X ask learn-ing.
A statistical learning theory based approach to multi X  X ask learning has been developed in [5, 6] and [8]. In [6] the prob-lem of bias learning is considered, where the goal is to choose an optimal hypothesis space from a family of hypothesis spaces. In [6] the notion of the  X  X xtended VC dimension X  (for a family of hypothesis spaces) is defined and it is used to derive generalization bounds on the average error of T tasks learned which is shown to decrease at best as 1 T .In [5] the same setup was used to answer the question  X  X ow much information is needed per task in order to learn T tasks X  instead of  X  X ow many examples are needed for each task in order to learn T tasks X , and the theory is developed using Bayesian and information theory arguments instead of VC dimension ones. In [8] the extended VC dimension was used to derive tighter bounds that hold for each task (not just the average error among tasks as considered in [6]) in the case that the learning tasks are related in a particular way defined.

The problem of multi X  X ask learning has been also stud-ied in the statistics literature. Breiman and Friedman [9] propose the curds&amp;whey method, where the relations be-tween the various tasks are modeled in a post X  X rocessing fashion. Brown and Zidek [10] consider the case of regression and propose an extension of the standard ridge regression to multivariate ridge regression. Finally, a number of ap-proaches for learning multiple tasks or for learning to learn [22] are Bayesian, where a probability model capturing the relations between the different tasks is estimated simultane-ously with the models X  parameters for each of the individ-ual tasks. In [1, 2] a hierarchical Bayes model is estimated. First, it is assumed that the parameters of the T functions to be learned are all sampled from an unknown Gaussian distri-bution. Then, an iterative Gibbs sampling based approach is used to simultaneously estimate both the individual func-tions and the parameters of the Gaussian distribution. In this model relatedness between the tasks is captured by this Gaussian distribution: the smaller the variance of the Gaus-sian the more related the tasks are. Finally, [4, 15] suggest a similar hierarchical model. In [4] a mixture of Gaussians for the  X  X pper level X  distribution instead of a single Gaussian is used. This leads to clustering the tasks, one cluster for each Gaussian in the mixture.
We consider the following setup. We have T learning tasks and we assume that all data for the tasks come from the same space X  X  Y . For simplicity we assume that X  X  R d and Y  X  R . For each task we have m data points sampled from a distribution P t on X  X  Y . So the total data available is:
We assume that P t is different for each task but that the P are related  X  as, for example, considered in [8]. The goal is to learn T functions f 1 ,f 2 ,...,f T such that f t ( x it ) case T = 1 is the standard (single X  X ask) learning problem.
There are various versions of this setup. A simpler version is when the same input data x it are used for all the tasks. That is, for every i  X  X  1 ,...,m } the vector x it is the same for all t  X  X  1 ,...,T } , but the output values y it differ for each t . This is for example the standard setup in marketing applications of preference modeling [1, 2] where the same choice panel questions (the same  X  x  X  X  X ) are given to many individual consumers, each individual provides his/her own preferences (the  X  y  X  X  X ), and we assume that there is some commonality among the preferences of the individuals (the  X  f t  X  X  X ). We consider this preference modeling application in the experiments section below.

Clearly one can consider other scenarios, too. For ex-ample: a) the case of having the same output ( X  y  X  X  X ) and different inputs ( X  x  X  X  X ), which corresponds to the problem of integrating information from heterogeneous databases [7]; or, b) the case of multi X  X odal learning or learning by com-ponents, where the ( x ,y ) data for each of the tasks do not belong to the same space X  X  Y but data for task t come from a space X t  X  Y t  X  this is for example the machine vision case of learning to recognize a face by first learning to rec-ognize parts of the face, such as eyes, mouth, and nose [14]. Each of these related tasks can be learned using images of different size (or different representations). The methods we develop below may be extended to handle such scenarios, for example through the appropriate choice of a matrix X  X alued kernel [20] discussed in section 2.2.
For simplicity we first assume that function f t for the t task is a hyperplane, that is f t ( x )= w t  X  x ,where X   X  notes the standard inner product in R d . The generalization to nonlinear models will then be done through the use of Reproducing Kernel Hilbert Spaces (RKHS), see for exam-ple [20, 25, 26]. In the case of classification each y it the values  X  1, and f t is the sign of w t  X  x .Belowweconsider this case  X  regression can be treated similarly.

All previously proposed frameworks and methods for multi X  task learning (i.e. those discussed in the introduction) are based on some formal definition of the notion of relatedness of the tasks. This relatedness is then formalized through the design of a multi X  X ask learning method. For example, hierarchical Bayesian methods [1, 2, 4, 15] assume that all functions w t come from a particular probability distribution such as a Gaussian. This implies that all w t are  X  X lose X  to some mean function w 0 (the mean of the Gaussian).
We follow the intuition of Hierarchical Bayes [1, 2, 15]. In particular we assume that all w t can be written, for every t  X  X  1 ,...,T } ,as where the vectors v t are  X  X mall X  when the tasks are similar to each other. In other words we assume that the tasks are related in a way that the true models are all close to some model w 0 (playing the role of the mean of the Gaussian used for Hierarchical Bayes [1, 2]). We then estimate all v as well as the (common) w 0 simultaneously. To this end we solve the following optimization problem which is analogous to SVMs used for single task learning:
Problem 2.1. subject, for all i  X  X  1 , 2 ,...,m } and t  X  X  1 , 2 ,...,T constraints that In this problem,  X  1 and  X  2 are positive regularization param-eters and the  X  it are slack variables measuring the error that each of the final models w t makes on the data. We therefore impose a regularization constraint on the  X  X verage X  model w 0 and control how much the solutions w t differ from each other by controlling the size of the v t .Intuitively,forafixed value of  X  2 a large value of the ratio  X  1  X  2 ,say  X  1  X  2 tend to make the models to be the same model (that is, the v t are nearly equal to zero), while for a fixed value of  X  make all the tasks unrelated ( w 0 nearly equal to zero). In particular, when  X  1 tends to infinity problem 2.1 reduces to solving one single X  X ask learning problem (finding w 0 ,hav-ing v t =0forevery t  X  X  1 ,...,T } ). On the other hand when  X  2 tends to infinity problem 2.1 reduces to solving the T tasks independently (finding the v t ,having w 0 =0).
Let w  X  0 and v  X  t be the optimal solution of problem 2.1 and w  X  t := w  X  0 + v  X  t . Our next observation shows a relation between these quantities.

Lemma 2.1. The optimal solution to the multi X  X ask opti-mization method (3) satisfies the equation
Proof. This result follows by inspecting the Lagrangian function for problem 2.1. This is given by the formula  X  where  X  it and  X  it are nonnegative Lagrange multipliers. Set-ting the derivative of L with respect to w 0 to zero gives the equation Thesameoperationfor v t gives, for every t  X  X  1 ,...,T } , the equation By combining these equations we obtain that The result now follows by this equation and equation (1).
This lemma suggests that we can replace w 0 in equation (3)withanexpressionof v t andobtainanoptimization problem which involves only the v t  X  X . Replacing w t  X  X  for the v t  X  X  and choosing appropriate regularization parameters instead, leads to the following lemma:
Lemma 2.2. The multi X  X ask problem 2.1 is equivalent to solving the following optimization problem:
Problem 2.2. subject, for all i  X  X  1 , 2 ,...,m } ,t  X  X  1 , 2 ,...,T } constraints that where the parameters  X  1 and  X  2 are related to  X  1 and  X  the equations and
Proof. Using equations (1) and (4), we rewrite the sta-bilizer in the objective function J in equation (2) as On the other hand the stabilizer in equation (6), can be rewritten as The result now follows by observing that equations (9) and (11) coincide provided that  X  1 and  X  2 satisfy equations (7) and (8).

Thus our regularization method finds a trade off between small size parameter vectors for each model and closeness of these model parameters to the average of the model param-eters. In SVMs language we are finding a trade off between each SVM having large margin (this quantity is defined as 1 / w t ) and having each SVM close to the average SVM.
We now derive the dual of problem 2.1. To this end, one may follow the standard duality theory approach, see e.g. [19] to optimize the Lagrangian function (5). However, the following observation allows us to directly link the dual of problem 2.1 to the standard SVM dual problem, see e.g. [25].

The set of functions f t ( x )= w t  X  x , t =1 ,...,T can be identified by a real X  X alued function defined as Learning this function requires examples of the type (( x ,t ) ,y ), where ( x ,t )  X  X  X { 1 ,...,T } and y  X  X  X  1 , 1 } .
We assume that the reader is familiar with the notion of feature map and of kernels , see e.g. [25] for a discussion. We note that F can be represented by means of the feature map where we have denoted by 0 the vector in R d whose coor-dinates are all zero,  X  = T X  2  X  1 , and we are now estimating a vector By construction we have that and It is then clear that solving the SVM multi X  X ask problem (1) is equivalent to learning the function F in equation (12) with a standard SVM which uses the kernel associated to the feature map (13). Consequently, using the standard SVM dual problem, see e.g. [25], we have the following theorem:
Theorem 2.1. Let C := T kernel The dual problem of 2.1 is given by
Problem 2.3. subject, for all i  X  X  1 , 2 ,...,m } and t  X  X  1 , 2 ,...,T constraints that the constraint that In addition, if  X   X  it is a solution to the above problem, the solution to problem 2.1 is given by
It is therefore required to select two parameters: the pa-rameter C for the training error as in the standard SVM case, and the parameter  X  that captures the similarity be-tween the tasks. These two parameters can be selected for example using a validation set or using some form of cross-validation. For example one may select  X  through a task-cross-validation process where instead of leaving train-ing points out as done for the typical cross validation case, tasks are left out. We do not have any theoretical justifi-cation for doing this or any theory that can lead to some method for selecting parameter  X  , and we leave this as an open question. In the experiments below we either report the performances for all the parameters we tested (to see their effects) or simply selected both C and  X  among a small number of choices (less than 20 pairs ( C, X  ) in total) based on the actual test performance. As observed in [13] when the number of test data is large (for all experiments below we have more than 2800 test data in total for all the tasks) then model selection among only a small number of models leads to a choice that has actual test performance similar to the one observed on the test data used.

Moreover, notice that solving the optimization problem 2.3 requires solving a standard SVM problem with Tm train-ing data. Assuming that a standard SVM training method is used which requires O([number of training data] 3 ]) time, this implies that to solve problem 2.3 we need O( T 3 m 3 time. Instead, if we were to solve each task independently we would only need O( Tm 3 ) time. In the experiments be-low, since we had only relatively small T sand m s, we did not have any significant differences in the training time of single versus multi-task SVM training. In many practical applications, however, this may be an issue. Optimizing the running time of the multi-task learning method we propose is therefore an important practical issue that we leave as an open problem. We conjecture that with an appropriate choice of kernels and parameters C for each task it may be possible to solve T independent SVMs that will lead to the same solutions as the ones found using the proposed multi-task learning method.
An important characteristic of SVM is that they can be used to estimate highly non-linear functions through the use of kernels [25]. We can clearly generalize the linear multi-task learning method outlined above to the non-linear case using kernels as is done for SVM. Morevoer, the above ob-servation in theorem 2.1 can be generalized to include non X  linear multi X  X ask learning. We simply learn F by using a nonlinear feature map where H is a separable Hilbert space (the feature space). The kernel associated to  X  is where  X  ,  X  is the inner product in H . In general we can also consider situations where each task is trained on differ-ent number of examples. That is, we sample our examples learn the coefficients  X  i for the function by solving the standard SVM dual problem with kernel G , namely
Problem 2.4. max subject to the constraint that  X  i  X  [0 ,C ] for every i . In particular problem 2.3 reduces to problem 2.4 if we set N = mT ,define,for i  X  X  1 ,...,N } and use the kernel where K is given by equation (14) where we can replace the dot product x  X  z with a nonlinear kernel as is done for standard SVM. We note that the above ideas appear in greater generality in [20] where the notion of operator X  valued kernels is derived.
We run two types of experiments. The first one is with simulated data in order to study the behavior of the pro-posed approach under varying conditions. We then tested the method on a real dataset.
We tested the proposed method using data that capture the preferences of individuals (consumers) when they choose among products. This is the standard problem of conjoint analysis [1, 2] for preference modeling. It turns out [12] that this problem is equivalent to solving a classification problem, therefore the results we report below can be seen as results for a classification problem.

We followed the basi csimulation design used by other researchers in the past. In particular we simply replicated the experimental setup of [3, 12, 24]. For completeness we briefly describe that setup.

We generated data describing products with 4 attributes (i.e. size, weight, functionality, and ease X  X f X  X se of a prod-uct), each attribute taking 4 values (i.e. very high value (1000), high value (0100), low value (0010), very low value (0001)). Therefore each product was represented by a 4  X  4= 16 dimensional binary vector. Each question given to an in-dividual consumer consists of 4 such (vectors) products to choose from. Each question was subsequently transformed into 6 data points (twice the number of comparisons of the  X  X inner X  product among the four and the remaining 3  X  X oser X  products) of 16 dimensions each that were used for the classification learning problem corresponding to this preference modeling problem [12]. Therefore the training data for each task are 16-dimensonal vectors with elements that take values only { +1 ,  X  1 , 0 }  X  the outcome of taking the difference between two binary vectors describing two prod-ucts. The questions were generated randomly. We generated 16 questions per individual, hence the individual classifica-tion problems used 16  X  6 = 96 16 X  X imensional training data. We simulated 100 or 30 individuals, hence we had a total of 100 (or 30) tasks: one task for each individual in order to es-timate the  X  X tility function X  of that individual using his/her responses to the 16 questions given represented with the  X  labels (prefer or not prefer one product from another) of the 96 training data used for the classification problem for that individual.

The four utility function coefficients (corresponding to the four values an attribute can take) for each of the four attributes were generated randomly from a Gaussian with mean We used the same Gaussian for each of the four attributes. The actual utility function w t was therefore a vector where ( w t 1 , ..., w t 4 ), ( w t 5 ,..., w t 8 ), ( w t 9 ( w t 12 ,..., w t 16 ) are four 4 X  X imensional vectors sampled from the aforementioned Gaussian. Notice that the functions w t we are estimating are real-valued, while the training data are vectors with values only { +1 ,  X  1 , 0 } as described above. It turns out that parameter  X  controls the noise of the data (i.e. the response accuracy of the individual consumers) which is modeled according to the assumptions of Hierarchial Bayes (HB), see [1, 2]. As in [3, 12, 24] we used  X  =3forlownoise in the data and  X  =0 . 5 for high noise in the data. We mod-eled the similarity among the 100 (or 30) individuals, hence the similarity among the 100 (or 30) tasks to be learned, by varying the variance  X  2 of the Gaussian from which the true utility functions w t were generated. The covariance ma-trix of the Gaussian was a diagonal matrix with all diagonal elements being  X  2 . We modeled low similarity among the tasks using  X  2 =3  X  , and high similarity using  X  2 =0 . 5  X  , like again in [3, 12, 24]. As discussed in [3, 12, 24] these parameters are chosen so that the range of average utility functions, noise, and similarities among the preferences of the individual consumers found in practice is covered.
Therefore in this experiment we tested all 2  X  2scenarios in terms of: a) the amount of noise in the data (low versus high), and b) the similarity among the tasks to be learned (low versus high). All experiments were repeated five times  X  so a total of 500 (or 150) individual utility functions w estimated  X  and the average performance is reported. We used two measures of performance: a) the Root Mean Square Error (RMSE) of the estimated utility functions relative to the true (supposedly unknown) utility functions  X  an error measure typically used for preference modeling [3, 12, 24]; b) the average hit errors (misclassification) of the estimated functions on a test set of 16 questions per individual  X  hence a total of 96 test data per individual for the corresponding classification problem solved leading to 2880 and 9600 test data for the 30 and 100 tasks cases, respectively. We note that the conclusions are qualitatively the same for both error measures, as also observed by [12, 24].

We compared our method with Hierarchical Bayes (HB) [1, 2] which is considered to be a state of the art method for preference modeling of a population of individual consumers. It is important to note that in all cases we generated the data in a way that gives an advantage to HB  X  X hatis,the data were generated, as described above, according to the probability distributions assumed by HB.

We tested various values (namely, 0.1, 0.5, 1, 2, 10, 1000) of the task X  X oupling parameter  X  used in the definition of kernel (14) to examine its effects. We also tested the case of using one SVM for all tasks as if we assume that all data come from the same task  X  which corresponds to the limit  X   X  0. We did these for C =0 . 1and C =1. InFigures1 and 2 we show the effects of  X  for C =0 . 1andfor30and 100 tasks, respectively  X  the plots are similar for C =1. We report the results for RMSE  X  which are similar for the hit test error. The left-most point at each graph is for solving one SVM only for all tasks as if we assume that there is only one task, corresponding to  X   X  0  X  clearly we do not log the  X  = 0 in the figure and we use instead a small  X  to visualize the results.

Firstly, the results show the importance of the parameter  X  , and that a wrong selection of  X  may some times decrease performance relative to solving T SVMs. This is for example the case when the tasks have low similarity (the right side of Figures 1 and 2) and we use a very small  X   X  where, in the limit, using only one SVM for all the data as if there is only one task (  X  = 0) can hurt performance a lot. Moreover, the optimal  X  can have a significantly better performance than, for example, a very large or a very small  X  corresponding to having T SVMs or 1 SVM for all tasks, respectively. It is therefore important to select  X  correctly, an issue for which we do not have currently a method as discussed in section 2.1.

The results also show clearly the benefits of solving all tasks simultaneously using the proposed method. The ad-vantage of the proposed method relatively to learning each task independently (estimating one utility function per in-dividual) is higher when there is more similarity among the tasks (similarity among the true utility functions of the in-dividuals). Moreover, the proposed method performs sim-ilarly or better than HB when  X  is selected appropriately. In Tables 1 and 2 we report the average performance of the T independent SVMs, the performance of having a single SVM for all tasks (as if we assume all data come from the same task), the performance of HB, and the performance of the proposed method for the best pair ( C, X  ) (from Figures 1 and 2) for both 30 and 100 tasks. Given that we have a large test set (2880 and 9600 test data for the 30 and 100 tasks, re-spectively) and we choose ( C, X  )amongonly2  X  6=12pairs ( C, X  )  X  X  (0 . 1 , 1)  X  (0 . 1 , 0 . 5 , 1 , 2 , 10 , 1000) 2valuesof C (0 . 1 , 1) for the T independent SVMs and for the 1 SVM), the test performances we report are very close to the actual test performances, as we discussed in section 2.1. Notice also that when there are few tasks (30 in this case) the proposed method is relatively better than HB than when there are many tasks (100 in this case).
 Noise Similar HB  X  =0 . 1 T SVMs 1SVM Table 1: Comparison of methods using RMSE and hit error rates. There are 30 individuals. The C of both the T individual SVM sand the propo sed method i s0.1. Bold indicate sbe st or not signif-icantly different than best at p&lt; 0 . 05 .A  X  indi-cates best or not significantly different than best at p&lt; 0 . 10 . Figure 1: Horizontal axi si sthe log(  X  ) (  X  = 0 . 1 , 0 . 5 , 1 , 2 , 10 , 1000 ) of the proposed method. As in Table 1, the C of both the T individual SVM sand the propo sed method i s0.1. The Vertical axi si sthe average RMSE of the estimated functions. Dashed straight line is the RMSE of HB. Dotted horizon-tal line i sthe average RMSE when we e stimate one SVM per individual. The solid line is the average RMSE of the proposed method -the left-most point at each graph i sfor solving one SVM only for all tasks as if we assume that there is only one task -the limit of  X  =0 (we don X  X  log  X  =0 clearly). There are 30 individuals. The C of both the individual SVMs and of the proposed method is 0.1. Top: Noise is low. Bottom: Noise is high. Left: Similarity of tasks i shigh. Right: Similarity of ta sk si slow.

We also tested the method using the  X  X chool data X  from the Inner London Education Authority available at multilevel.ioe.ac.uk/intro/datasets.html .
 We selected this dataset to compare our method directly with the work of [4] where a number of multi-task learn-ing methods are compared using this dataset. This data consists of examination records of 15362 students from 139 secondary schools. The goal is to predict the exam scores of the students based on the following inputs: year of the exam, gender, VR band, ethni cgroup, per centage of students eli-gible for free school meals in the school, percentage of stu-dents in VR band one in the school, gender of the school (i.e. male, female, mixed), and school denomination. We represented the categorical variables using binary (dummy) variables, so the total number of inputs for each student in each of the schools was 27. Since the goal is to predict the exam scores of the students we run regression using the SVM "  X  X oss function [25] for the multi X  X ask learning method pro-posed. We consider each school to be  X  X ne task X . Therefore we had 139 tasks. We made 10 random splits of the data into training (75% of the data, hence around 70 students per school on average) and test (the remaining 25% of the data, hence around 40 students per school on average) data and we measured the generalization performance using the Figure 2: Horizontal axi si sthe log(  X  ) (  X  = 0 . 1 , 0 . 5 , 1 , 2 , 10 , 1000 ) of the proposed method. As in Table 1, the C of both the T individual SVM sand the propo sed method i s0.1. The Vertical axi si sthe average RMSE of the estimated functions. Dashed straight line is the RMSE of HB. Dotted horizon-tal line i sthe average RMSE when we e stimate one SVM per individual. The solid line is the average RMSE of the proposed method -the left-most point at each graph i sfor solving one SVM only for all tasks as if we assume that there is only one task -the limit of  X  =0 (we don X  X  log  X  =0 clearly). There are 100 individuals. The C of both the individual SVMs and of the proposed method is 0.1. Top: Noise is low. Bottom: Noise is high. Left: Similarity of tasks i shigh. Right: Similarity of ta sk si slow. explained variance of the test data as a measure in order to have a direct comparison with [4] where this error measure is used. The explained variance is defined in [4] to be the total variance of the data minus the sum X  X quared error on the test set as a percentage of the total data variance, which is a percentage version of the standard R 2 error measure for regression for the test data. Finally, we used a simple linear kernel for each of the tasks.
 The results for this experiment are reported in Table 3. For comparison we also report the performance of the task clustering method reported in [4]. We show the results for all the parameters C and  X  we tested, other than  X  =0cor-responding to having 1 SVM for all tasks. We let the ratio  X  = T X  2  X  1 vary to see the effects. As with the previous exper-iments, when  X  is large we get the performance of solving one SVM regression model per school (per task).

The results, although still preliminary, show the advan-tage of learning all tasks (for all schools) simultaneously in-stead of learning them one by one. Moreover, even the sim-ple linear kernel (14) significantly outperforms the Bayesian method of [4], which is in turn better than other methods as compared in [4]. It turns out that for this dataset 1 SVM for all tasks performs the same as the best performance we report here for  X  =0 . 5, hence it appears that the particular Noise Similar HB  X  =0 . 1 T SVMs 1SVM Table 2: Comparison of methods using RMSE and hit rates. There are 100 individuals. The C of both the T individual SVM sand the propo sed method i s 0.1. Bold indicates best or not significantly different than best at p&lt; 0 . 05 .A  X  indicate sbe st or not significantly different than best at p&lt; 0 . 10 dataset is close to being from a single task (despite this ob-servation, we use this dataset for direct comparison with [4])  X  this indicates that when the tasks are the same task, using the proposed multi-task learning method does not hurt as long as a small enough  X  is chosen. Table 3: School Data: first column shows the ex-plained variance of the proposed method with C = 0 . 1 and second column with C =1 . The last row is the explained variance for the Bayesian task cluster-ing method of [4].
We presented a new method for multi X  X ask learning using a regularization approach. This is a natural extension of ex-isting regularization based learning methods, such as SVMs, from single X  X ask to multi X  X ask learning. We tested the ap-proach using both simulated and real data, and compared it with existing multi X  X ask learning methods. The results a) show the strength of the proposed approach relative to other multi X  X ask learning methods, and b) verify, in agree-ment with past experimental work [4, 11, 15], the advantage of multi X  X ask learning relative to single task learning. The proposed method also reduces to standard single X  X ask learn-ing when we set the task coupling parameter  X  appearing in the matrix X  X alued kernel (14) to be very large: hence there is no risk using this multi X  X ask learning method even when the tasks are not related. It is a matter of choosing the appropriate parameter  X  , which may be possible to do for example using some form of cross X  X alidation or a validation set [25]. How to select  X  is currently an open problem which we believe is also related to the general question of how to model and measure the relatedness between tasks  X  e.g. how do we know a priori that tasks are related?
A number of extensions of the methods discussed above are possible. These concern for example the use of different loss functions (i.e. square loss) and, especially, the use of more general matrix X  X alued kernels. We discuss some of these below.
We leave the exploration of matrix X  X alued kernels for dif-ferent types of multi X  X ask learning applications as part of future work. On the theoretical side another important problem will be to study generalization error bounds for the proposed methods. In particular, it may be possible to link the matrix X  X alued kernels to the notion of relatedness between tasks discussed in [8].
 We wish to thank Sayan Mukherjee, Tomaso Poggio, and especially Charlie Micchelli for useful discussions. [1] G.M. Allenby and P.E. Rossi. Marketing Models of [2] N. Arora G.M Allenby, and J. Ginter. A Hierarchical [3] N. Arora and J. Huber. Improving parameter [4] B. Bakker and T. Heskes. Task clustering and gating [5] J. Baxter. A Bayesian/Information Theoreti cModel of [6] J. Baxter. A Model for Inductive Bias Learning. [7] S. Ben-David, J. Gehrke, and R. Schuller. A [8] S. Ben-David and R. Schuller. Exploiting Task [9] L. Breiman and J.H Friedman. Predicting [10] P.J. Brown and J.V. Zidek. Adaptive Multivariate [11] R. Caruana. Multi X  X ask Learning. Machine Learning, [12] T. Evgeniou, C. Boussios, and G. Zacharia.
 [13] T. Evgeniou, M. Pontil, and T. Poggio. Regularization [14] B. Heisele, T. Serre, M. Pontil, T. Vetter, and [15] T. Heskes. Empirical Bayes for learning to learn. [16] M.I. Jordan and R.A. Jacobs. Hierarchical Mixtures of [17] J. Kim, G.M. Allenby, and P.E. Rossi. Modeling [18] G.R.G. Lanckriet, T. De Bie, N. Cristianini, [19] O.L. Mangasarian. Nonlinear Programming . Classics [20] C.A. Micchelli and M. Pontil. On Learning [21] D.L. Silver and R.E Mercer. The parallel transfer of [22] S. Thrun and L. Pratt. Learning to Learn. Kluwer [23] S. Thrun and J. O X  X ullivan. Clustering Learning Tasks [24] O. Toubia, D.I. Simester, J.R. Hauser, and E. Dahan. [25] V. N. Vapnik. Statistical Learning Theory . Wiley, New [26] G. Wahba. Splines Models for Observational Data .
