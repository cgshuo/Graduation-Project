 In numerous everyday domains, it ha s been demonstrated that in-creasing the number of options beyond a handful can lead to pa-ralysis and poor choice and decrease satisfaction with the choice. Were this so-called paradox of choice to hold in search engine use, it would mean that increasing recall can actually work counter to user satisfaction if it implies choice from a more exten-sive set of result items. The existence of this effect was demon-strated in an experiment where us ers (N=24) were shown a search scenario and a query and were re quired to choose the best result item within 30 seconds. Having to choose from six results yielded both higher subjective satisfaction with the choice and greater confidence in its correctness than when there were 24 items on the results page. We discuss this finding in the wider context of  X  X hoice architecture X  X  X hat is, how result presentation affects choice and satisfaction. H.1.2 [ User/Machine Systems ]: Human information processing. H.3.3 [ Information Search and Retrieval ]: Information filtering. Design, Human Factors. Search engines, relevance judgments , satisfaction, user interfaces. If you type in your favorite pop singer X  X  name to Google, you will be presented with a result set of possibly millions of items. Items within a single page may have perceivable differences, yet the better the engine has done its job, the greater the number of items that will appear relevant. In such a case, can you be content with the link you finally choose, given that you could not consider even an iota of the full number of results available? At the time of writing, Google offered 99,500,000 results for the query  X  X ritney Spears. X  The situation is not that different from what Westerners face daily in the offline domain: massive choice. For example, wanting to buy breakfast cereal at a grocery store forces a choice from among some 273 products [28]. sented? Six-item (left) versus 24-item (right) result listings in 
Google, materials used in the experiment. Note: In the 24-item Recent research in cognitive psychology has revealed an interest-ing effect of choice overload: 
The paradox of choice : providing more options X  X articularly if they are highly relevant and success is personally important X  X ill lead to poorer choice and degrade satisfaction [28].
 Experimental demonstrations of this paradox are quite compelling and bespeak its generality. For example, passersby are more likely to buy jams on display, and more satisfied as customers when there are six jams to choose from than 24 [15]. University students are more likely to write an extra-credit essay, and write better essays, when they have six topics to choose from than 30 [15]. Employees are more likely to participate in 401(k) retire-ment plans when there are two rather than 59 funds to choose from [16]. But would the same apply to Google with, say, six ver-sus 24 items? Figure 1 illustrates the situation. The existence of this phenomenon could have important implica-tions for how we think about sear ch engine use. One presumption has been that if the user has the persistence to go through the re-list indicates greater likelihood that (s)he has encountered an item of higher relevance as the end is reached. Ergo, the more results, the higher the effectiveness. If this assumption turns out to be questionable, we can ask whethe r search engines should be less like slavish  X  X eporters X  and more akin to personal assistants who guide customers to the most reasonable options in a store. However, anyone can imagine a number of reasons for the effect not appearing in search engine use. For example, if users jump to the first-ranked items (e.g., [10][12][24][26][31]), they may ig-nore others, no matter how many there are left. Or, if users are effective in using cues such as snippets (e.g., [9][10]), they may narrow down their options to one or two candidates. This paper presents the first experi ment to directly test the exis-tence of this paradox in information retrieval. We focus on search engines as a major category of pr esent-day information retrieval, and Google in particular. The expe rimental paradigm to study the paradox in consumer choice (e.g., [ 15]) was  X  X ranslated X  into the context of search engine use. Pa rticipants were given a realistic search task (three types) and asked to mark from a search result list the item that best answers th e question, within 30 seconds. In half of the trials, 24 items were presented, and six were used in the rest, a situation similar to that depicted in Figure 1. After choosing the best item (and without seeing the actual page), the participants then evaluated thei r choice in four dimensions, in-cluding satisfaction and confidence. Two search engine layouts were used: Google (with some cues removed) and a fake engine ( X  X CD4000 X ). The results follow the pattern predicted according to the paradox: When provided with only six items to choose from, users are more satisfied with their choice, more confident that it is pertinent to the task, and more likely to think they were more careful. To conclude the paper, we frame the discussion with the notion of  X  X rchitecture of choice. X  In this section, we discuss why the paradox of choice would emerge in search engine use. Before we present the hypothesis, let us first describe the choice situati on in more concrete terms. First, objective descriptors of the number of result items must distin-guish among:  X  Result set , the set of all search result items (total  X  X its X ). The  X  Presentation set , the total set of items the user can view.  X  Page set , the set of items presented on an individual page. Second, subjective descriptors must distinguish the following:  X  Perceived set , the set of items perceived by the user during  X  Consideration set , the set of alternatives the user considers  X  Remembered set , the set of items remembered after the The paradox of choice refers to the effect of increasing the con-sideration set size, not the presen tation set size. Given that most searches produce more than a handf ul of items, it is more rule than exception that users cannot consider presentation sets ex-haustively but must narrow them dow n. However, since this vari-able sets a ceiling to consideration set size, the effect is likely to be associated with it. The paradox manifests itself as an inverse U-shaped relationship between consideration set and s ubjective satisfaction with choice [30]. Having a few options is ofte n not enough, and is thus associ-ated with lower satisfaction; then there is an intermediate range where subjective satisfaction is higher (say, 4 X 10 items); and the final part shows decreasing satisf action as the number of options increases. In the present study, we are not interested in charting the whole continuum but focus on a sample of two points, one from the middle and the other from the end portion. According to a recent theory, the paradox of choice is caused not by a single factor but by the interplay of many [28]. These can be broken down into three chronologically ordered phases. When one first sees a result page, a large presentation or page set size can actually bear two positive effects: 1. Increased attraction to a page: Seeing more items on a dis-2. Increased expectations : Seeing that there are more items However, negative effects emerge when the user enters the phase in which the choice is made. According to the theory, increasing consideration set size can: 3. Paralyze the user in the process of entertaining alternatives. 4. Result in poorer choice : As a result of the choice task being Increasing remembered set size can do the following in relation to evaluation of the chosen item: 5. Cause dissatisfaction by creating a discrepancy with expec-6. Cause regret by increasing the perceived opportunity cost: Research on information retrie val has addressed two problems that are closely related to the paradox of choice: 1) how many items should be presented and 2) in which order. Roughly speak-ing, there are two categories of theories. Both predict diminishing returns for increasing presentation set size, yet they do not predict negative returns as the paradox of choice. The first category predicts a decrease in subjective relevance as one advances in a list. For ex ample, Brookes [6] proposed that perceived utility of a document list should decrease in going through the result list, because the more documents one has seen, the lower the informational value of each new item will be. The second category predicts that judgments of relevance will fluctuate between positive and negative according to a standard that is held and updated in mind as one traverses the list. General theories from cognitive psychology have been referred to in dis-cussions of possible explanations for order effects in the use of information retrieval results [14]. For example, the social psy-chologist Asch [1] was the first to propose that reordering items in a list could change how they are judged (see also [23]). The ex-planation was that initial appraisal (or impression) would shape the judgment of subsequently pr ocessed items. Hogarth and Ein-horn [13] proposed an anchoring-adjustment hypothesis: people hold a primary belief (anchor) that guides the processing of the subsequent items in the list. This anchor is continually adjusted with new conflicting or compleme ntary information. Clancy and Wachsler [8] discussed a phenomenon that would lead to incon-sistent and inaccurate judgments toward the end of a list: fatigue. As people process more and more items, they would be too fa-tigued to make proper judgments toward the end of the list. Both theories entail, in the case where the user has the persistence to go through the results, greater likelihood as the end is reached of the user having encountered an item of higher relevance as the number of items in the list increases. Hence, a larger presentation set should yield better choice, a lthough with high costs. We sus-pect that this kind of logic may underlie the intuitive appeal of making the presentation set as large as the result set. Why is it that the paradox of choice points to an opposite predic-tion? Several reasons can be iden tified. The experimental para-digm for studying order effects has been based on a step-by-step relevance judgment task , where the participant is to provide a relevance rating to all documents presented one at a time [14]. However, in real-life choice, people think about not  X  X elevance X  but the suitability of an item for a goal or action. Therefore, the assessment of options is often multidimensional. The consequence of multidimensional choice is that the user can be overwhelmed with a comparison of only two items, if the number of choice-relevant dimensions is large. Anyone who has bought a PC or car knows this issue. Moreover, each item examined can reveal new aspects that were not previously considered, which may require revisiting the earlier items (see also [20]). As users may be unable to keep in their minds all inte rmediate results of comparisons, their search is often not linear. Indeed, eye-movement studies of search use have shown that users do not examine results in a linear fashion but go back and forth between items (e.g., [24]). Interestingly, the only two studies known to us that vary presenta-tion set size in conjunction with order effect provide tentative support for our prediction. The original study reported by Eisenberg and Barry [11] showed that when documents are reor-dered according to relevance (low to high), users overestimate the importance of the documents. More interestingly, in a later study, Parker and Johnson [27] showed that order effects do not appear with fewer than 15 documents. Huang and Wang [14] found that with only five items, there are no order effects, whereas with more items (15 X 75) there are. Th ese studies utilized the step-by-step paradigm, in which the users were, however, able to see all items on a page. To sum up, when the presentation set has been varied, the order effect disappears with small set size. The study is based on a direct  X  X  ranslation X  of the experimental paradigm used to study the paradox of choice. In a nutshell, the core choice task consists of three pages presented to a participant: Page 1, a search scenario/task and the associated search query; Page 2, the result page; and Page 3, evaluation. On Page 2, par-ticipants have to mark the item ( X  click X ) that best corresponds to the scenario. They do not need to explain their choice or provide an answer to the question. Three kinds of tasks were used: simple fact-finding, problem-solving, a nd subjective opinions. To better simulate search engine use, whic h tends to be rapid [9][12], we guided the users to make their choice within 30 seconds. The critical manipulation was the number of results presented: in half of the trials, 24 items were presented and in the other half only six (Figure 1). To ensure that the results did not reflect a familiar-ity/preference effect, fake search engine RCD4000 (Figure 2) was used in addition to a Google replica. Had we obtained a negative result (no effect), it could have been due to users being skilled with Google no matter how many re sults are presented. Moreover, including two engines, familiar vs. unfamiliar, gave us a way to assess the effect X  X  generalizability. Paper form was used for technical difficulties in replicating the performance of Google in RCD4000 in real-time. However, pre-vious studies have used paper fo rm as well [14], and there is no effect reported that casts into doubt the validity of paper form. With three exceptions who were recruited via personal networks, all 25 participants (13 M, 11 F) were recruited on-site on two uni-versity campuses in Helsinki. Th e participants were between 19 and 28 years of age, with an average of 22.1. They had the fol-lowing majors: 6 physics, 5 chemistry, 4 geography, 2 humanities, 1 mathematics, 1 computer scien ce, 1 biology, 1 biochemistry, 1 astronomy, 1 craft science, 1 agricultural politics. One participant was excluded because of unwillingness to follow instructions. No compensation was given other than the option of obtaining one X  X  own data later. All particip ants were native speakers of Fin-nish, the language used in the study materials. The experiment followed a 2 (number of result items: 6 vs. 24) x 2 (search engine: Google vs. RCD4000) within-subjects design. The 24 search tasks were divided into four blocks of six tasks each, each block with the same engine but with the number of result items alternating. For count er-balancing, the order of these blocks was rotated over the set of participants. The dependent variables are reported upon belo w in subsection 3.3.4. The set of papers handed out to a participant consisted of 99 A4 pages in total, including the followi ng: 1) welcome, 2) task intro-duction, 3) practice, 4) preparati on for the experiment, 5) blocks of tasks and questionnaires, 6) post-block questionnaires, 7) post-experiment questionnaire. 
Figure 2: An additional fake search engine was used to test for effects of familiarity or expecta tions. The same content was used Each search task consisted of the task page, the search results page(s), and a satisfaction questi onnaire. There were three differ-ent types of search tasks, each with two topics: 1. Simple facts , with a short and unambiguous answer (a fac-2. Problems , with ambiguous answers. These require under-3. Preferences , addressing subjective opinions. Topics: Where All search result listings were generated via the Google search engine. However, after piloting, we decided to remove the follow-ing elements: blogs, ne ws, sponsored links, related articles, cited by, items without quotes, tabbed menus, YouTube videos, Google books, Wikis, indented material s, advertisements,  X  X id you mean? X  prompts, tips. These change s were made firstly to remove information that is not useful or necessary for the given task and secondly with the purpose of decr easing variance in data due to individual strategic differences. A lthough we realize that this sim-plification may seem to compromise the ecological validity of the materials, an issue we return to in the  X  X iscussion X  section, we believe that the materials were realistic enough to retain the crux of search engine use. In fact, none of the participants spontane-ously complained about missing cues. In the six-item condition, the lis ting was manually stripped down. In the case of 24 items, typically only 20 X 21 items fit on the first A4 page, and the rest were prin ted on a second page. This means that there are probably more relevant items in the 24 item condi-tion than in the 6 item condition. Turning a paper page introduces a break that is somewhat analo-gous to loading the second result page by clicking  X  X ext X  on the first result page [12]. Many search engine users never go to the next page [9], and doing so was ve ry rare in our experiment also. Two search engine  X  X eplicas X  were used: Google and RCD4000. They used the same search resu lt contents; only layout differed. In creating the layout of RCD4000, we aimed for recreating the look and feel of an engine that could seriously compete with Google. Google was used as the ba sis for the design. The layout was similar to Google X  X  with th e following exceptions (see Figure 2): different colors, fonts, a nd logo were used. Moreover, we changed some of the terminology, such as  X  X esults X  -&gt;  X  X ages, X   X  X o X  -&gt;  X  X ind, X  and  X  X references  X  -&gt;  X  X ettings. X  The positions of elements were the same as in Google. After each choice, the following claims were rated on a Likert scale (1 X 7):  X  Satisfaction :  X  X  am satisfied with my choice. X   X  Confidence :  X  X  am confident that my choice is correct. X   X  Carefulness :  X  X  made my choice carefully. X   X  Suitability :  X  X  think that the search results were suitable for In addition, at the end of each task block (six tasks with the same search engine), slightly modified items were rated, as follows, but this time they referred to the search engine (see Figure 3).  X  Satisfaction:  X  X  am content with the search results. X   X  Confidence:  X  X  am confident that my choices were correct. X   X  Suitability:  X  X  think that the search results were suitable for  X  Preference:  X  X  would choose this search engine for my use. X  After the tasks, we used the br ief version of the Maximization Scale, which is a 13-item scale to measure tendency to try to maximize the outcomes of one X  X  choices. This scale presents sev-eral questions about everyday choice behavior. For example, those people who are likely to search for an even better radio sta-tion though already listening to a satisfactory one are more often  X  X aximizers X  than  X  X atisficers. X  Previous work has associated high score with decreasing overall happiness and subjective well-being. Satisficers, by contrast, are generally happier with their choice, although they do a little less well in objective terms [28][29]. The prediction here is that maximizers would be more suscep tible to the choice overload ef-fect than satisficers. An analogous idea has been explored re-cently in an eye-movement study of search engine use [3]. Potential participants were appr oached with the pretext of doing research on search engine attitude s. The experiments were run in a campus cafeteria, lobby, or student lounge table environment while other people and variable background noise were present. However, care was taken to prevent direct interruptions. RCD4000 was introduced as  X  X  new, exciting engine that can pro-vide results as good as or better th an Google X  X . X  Participants were not told that RCD4000 was in fact Google in disguise. After brief practice, the 24 tasks were carried out. The experi-menter X  X  instruction explained th at the scenario, query, and result page are provided  X  X s is X  and cannot be changed, and that it may feel that the items are not the best for the scenario. After provid-ing the answer, and without seeing the result page anymore, the participants rated their experience before turning to the next task. Post-block questionnaires were administered at the end of each block of six tasks. To prevent unusually long thinki ng times, the timeframe was lim-ited to 30 seconds, after which choice was forced. A timing pro-gram for mobile devices (Egg Timer) was used, allowing preci-sion of about one second. Notwithstanding a handful of excep-tions, all participants fo llowed this instruction. To eliminate multi-experimenter bias, the second author ran all the participants. Each experiment lasted about 35 X 45 minutes. The main results are reported in section 4.2 and in Figure 3. The results follow the pattern predicted by the paradox of choice: us-ers were less satisfied with their choice when there were 24 items in the search result listing th an when there were six. For statistical testing, we utilize a 2 x 2 repeated measures analysis of variance (RM-ANOVA) with Number of Results and Search Engine as the two factors. Throughout, we use an alpha of .05. With fewer items, users tended to choose an item appearing marked, on average, the 2.8th item (SE 0.1), but with 24 items the 6.0th item (SE 0.4). This differen ce was statistically significant, F 1,23 =61.3, p &lt;.001. The effect of Search Engine was non-significant, F 1,23 =.3, p =.62, as was the interaction between the two, F 1,23 =2.8, p =.11. The main results follow the pattern of the paradox of choice as presented in Figure 3:  X  Satisfaction. Participants were more satisfied with their  X  Confidence. Participants were more certain about the cor- X  Carefulness. Participants thought they made their choice  X  Suitability. Users thought they had as good a pool to choose We did not find any effect of search engine; the effects reported above held for both Google and RCD4000. Analysis of effect sizes positions the findings in a small-to-medium size range. Following the recommendation of Keppel and Wickens for a two-factor within-subject design [22], omega-squared was used for estima tion of effect sizes. Ranges for effect sizes by significant variable are as follows.  X  Satisfaction: .18 &lt;  X  2 &lt; .30, indicating a small to medium  X  Confidence: .12 &lt;  X  2 &lt; .21, indicating a small effect size  X  Carefulness: .36 &lt;  X  2 &lt; .53, indicating a medium effect size Echoing previous results (e.g., [21]), task type had an effect on evaluation. The preferences task type was associated with the highest absolute scores for all four variables. For satisfaction, the mean for preference tasks was 5.5 (SE .14), 3.9 (SE .15) for prob-lems, and 4.3 (SE .16) for simple fact-finding tasks. To examine whether the paradox-of-choice effect holds for the three task types, we ran a 2 (number of results) x 3 (task type) RM-ANOVA. The effect of task type was significant on satisfac-tion ( F 2,46 =50.9, p &lt;.001), confidence ( F 2,46 fulness ( F 2,46 =9.6, p &lt;.001), and suitability ( F The interaction effect was borderline-significant for satisfaction ( F 2,46 =3.0, p =.06) but non-significant for confidence ( F p =.15), carefulness ( F 2,46 =.5, p =.64), and suitability ( F p =.39). Although there were no reliable interaction effects for any of the dependent variables (DVs), post hoc tests with Bonferroni correction on the borderline-significant variable  X  X atisfaction X  showed that both simple facts a nd problems task types manifest the paradox of choice (both p &lt;.005), but the preferences type does not ( p =.93). This was a little surprising, given that most research on the paradox of choice has been done in consumer domains where the tasks are very subjective. However, since the omnibus interaction effect was only borde rline-significant, and the same effect was not repeated for the other DVs, we do not explore the finding further here. In questionnaires positioned after each block (of six tasks), we asked about satisfaction with the particular search engine used in that block . Overall, we found no differences between the two en-gines in satisfaction, confidence, or suitability. While suitability and choice were in favor of Google, this trend was not statistically significant; both F 1,23 &lt;3.1, p &gt;.09. However, the preference vari-able manifested a difference: participants felt that they would choose Google for their tasks; F 3,63 =7.7, p &lt;.001. There were no practice effects on the variables of interest, all F 3,69 &lt;.32, p &gt;.80. None of the participants was a maximizer (max. 4.6, M=3.7, SD=.73) if compared against criteria used by Schwartz (e.g., maximizer group M=5.3 in Study 2 of [29]). Nevertheless, a post hoc median split was done to divide participants into high-and low-score groups. A t-test revealed no difference between the groups in satisfaction ( t 22 =1.6, p =.47) nor any of the other vari-ables. We correlated all DVs w ith this score but found nothing hardly surprising, since the subject pool was so homogenous on the Maximization Scale. We know from cognitive psychology that choice overload can have three unfortunate effects: it can paralyze, it can lead to poor choices, and it can lead to dissa tisfaction with even good choices. The power of modern search tools is extraordinary, but if they result in users feeling paralyzed and powerless, they become self-defeating. Putting  X  X ll the world X  X  information X  in front of people may solve one problem, but it creates another. Virtually all of the research on choice overload done thus far has been in connection with consum er goods. The present study ex-tends the phenomenon to the domai n of information. We found that a six-item search result list was associated with higher satis-faction, confidence, and perceive d carefulness than a 24-item list. The effect was robust; it held for all three task types and for 22 out of the 24 participants, although none was a maximizer [29]. Why the effect has not been reported before may be due to the effect size: Our effect size analysis revealed that the phenomenon is perhaps too small to be obvious to the naked eye, though it still is large enough to have ecological significance. But will the effect occur outside th e confines of the laboratory, or is it more a small blemish on the face of search engine use? The experimental method, as does any la b study, subscribes to a set of assumptions that may or may not hold water in real-world situa-tions. We have tried to summarize key factors X  X nown and yet unexplored X  X n Figure 4. These may pose boundary conditions for generalizability. However, we do wish to note that, in the pre-sent experiment, para lysis was essentially precluded by the de-mands of the experiment, and par ticipants got virtually no feed-back to inform them of whether their choices were good or bad. In real life, we might expect paraly sis and poor choices to contribute to dissatisfaction. Therefore, we believe that our results, if any-thing, may understate the magnitude of the choice overload effect, since we show effects on satisfaction even when paralysis and poor-choice information are not available. We suggest that, instead of pooling of results from disconnected lab experiments, the question of generalizability is ideally tackled in a large-scale, controlled online experiment that correlates pres-entation set size with subjective satisfaction and objective behav-ior (e.g., clickthrough curves). Interestingly, recent results on search behavior point toward choice overload, although the issue has not been put on the table. One such signal is users X   X  over-reliance X  on ranking information. A recent study found that although users spend about the same amount of time looking at the second abstract in results as the first one, they nevertheless choose the fi rst almost three times as often [12]. Something akin to paralysis has been reported when top-ranked items are not perceived as reliable: When top-ranked items were put at the end of the list, users spent more time checking each item, exhibited diffuse click patterns, and were less likely to eventually locate the best items [26]. But these effects are what one would expect as a consequen ce of choice overload: It is only natural to rely on extraneous in formation suggested by other peo-ple and authoritative sources X  X hese can provide the only avail-able means out of paralysis. The paradox of choice has important implications for the design of search engine results. It calls for distinguishing result set from presentation set in search engine development (see also [6]). The study indicates that increasing recall can hamper user experience, unless considered in conjunction w ith presentation of items. What if, instead of 99.5 million Britney Spears links, the user were to be given only, say, six? However, we want to avoid the simplistic conclusion that six would be so mehow optimal. We sampled only two points on the continuum of presentation set size, and there are unknown factors at play (Figure 4). It may turn out that Google X  X  default page set size of 10, combined with effective ranking and additional cues, is good enough to prevent choice overload in most searches. Future work will have to address this issue. Beyond the obvious implication of limiting the page/presentation set, the next generation of s earch result design should focus on what others have called choice architecture [33]. We do not have room to examine the full argument here, but the general points are to 1) help narrow the considerati on set, 2) aid in spotting diagnos-tic features of items, and 3) make comparisons more effective. For example, it is known that  X  X efau lts, X  such as  X  X  X  X  Feeling Lucky, X  can be powerful, especially in the context of almost lim-itless choice. And the result page can be designed flexibly so that users can  X  X pt in X  to however many hits they want. In addition, there is evidence that the amount of choice people perceive is governed not only by the actual number of tokens that are present but also by how the tokens are organized into categories [25]. Through introduction of categorical structure into search results, small numbers of hits may be ma de to seem large or vice versa (see also [4]). In addition, more diagnostic cues can be designed. A recent study indicates that information in general-purpose cues like snippets may help to overc ome the problem of over-reliance on ranking [9]. We thank Miikka Miettinen, Pette ri Nurmi, Martti M X ntyl X , Matt Wallaert, and Ken Rimey for comme nts. This work was supported by the Academy of Finland project ContextCues and the Fulbright Technology Industries Finland Grant for a Junior Scholar. [1] Asch, S. Forming Impressions of Personality . Taylor &amp; [2] Aula, A., Jhaveri, N., and K X ki, M. Information search and [3] Aula, A., Majaranta, P., and Raiha, K. Eye-tracking reveals [4] Beitzel, S., Jensen, E., Chow dhury, A., Grossman, D., and [5] Broder, A. A taxonomy of web search. SIGIR Forum 36 , 2 [6] Brookes, B. Measurement in in formation science: objective [7] Byrne, M., John, B., Wehrle, N., and Crow, D. The tangled [8] Clancy, K., and Wachsler, R. Positional effects in shared-[9] Clarke, C., Agichtein, E., Dumais, S., and White, R. The in-[10] Cutrell, E., and Guan, Z. What are you looking for?: an eye-[11] Eisenberg, M., and Barry, C. Order effects: A study of the [12] Granka, L., Joachims, T., and Gay, G. Eye-tracking analysis [13] Hogarth, R., and Einhorn, H. Order effects in belief updat-[14] Huang, M., and Wang, H. The influence of document presen-[15] Iyengar, S., and Lepper, M. When choice is demotivating: [16] Iyengar, S., Jiang, W., and Huberman, G. How much choice [17] Jansen, B., and Spink, A. An analysis of web documents re-[18] Jansen, B., Spink, A., and Pede rsen, J. A temporal compari-[19] Kahneman, D., and Tversky, A. Prospect theory: An analysis [20] Katzer, J., and Snyder, H. Toward a more realistic assess-[21] Kellar, M., Watters, C., and Sh epherd, M. A goal-based clas-[22] Keppel, G., and Wickens, T.D. Design and Analysis: A Re-[23] Kochen, M. Principles of information retrieval . Los Angeles, [24] Lorigo, L., Pan, B., Hembrooke, H., Joachims, T., Granka, [25] Mogilner, C., Rudnick, T., and Iyengar, S. The mere catego-[26] Pan, B., Hembrooke, H., Joachim s, T., Lorigo, L., Gay, G., [27] Parker, L., and Johnson, R. Does order of presentation affect [28] Schwartz, B. The Paradox of Choice: Why More Is Less . [29] Schwartz, B., Ward, A., Mont erosso, J., Lyubomirsky, S., [30] Shah, A., and Wolford, G. Buying behavior as a function of [31] Silverstein, C., Marais, H., Henzinger, M., and Moricz, M. [32] Teevan, J. How people recall search result lists. In Proc. [33] Thaler, R., and Sunstein, C. Nudge . New Haven: Yale Uni-
