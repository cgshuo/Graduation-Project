 Abstract This article describes the enrichment of the AnCora corpora of Spanish and Catalan (400 k each) with coreference links between pronouns (including elliptical subjects and clitics), full noun phrases (including proper nouns), and discourse segments. The coding scheme distinguishes between identity links, predicative relations, and discourse deixis. Inter-annotator agreement on the link types is 85 X 89% above chance, and we provide an analysis of the sources of dis-agreement. The resulting corpora make it possible to train and test learning-based algorithms for automatic coreference resolution, as well as to carry out bottom-up linguistic descriptions of coreference relations as they occur in real data. Keywords Coreference Anaphora Corpus annotation Annotation scheme Reliability study 1 Introduction Producing a text requires us to make multiple references to the entities the discourse is about. Correspondingly, for a proper understanding of the text, we have to identify the entity each linguistic unit refers to and link those that are coreferent , that is, those that stand in an identity of reference relation. Following Webber X  X  ( 1979 ) discourse model, coreference does not take place between real-world entities but between discourse entities, i.e., the (mental) entities in a listener X  X  evolving model of the discourse, which may or may not correspond to something in the outside world.
 Although often treated together with anaphora, coreference is different (van Deemter and Kibble 2000 ). Coreference involves the semantico-referential level of language, since in order to identify those expressions (whether anaphoric or non-anaphoric) that refer to the same discourse entity, we must first understand their semantics and find their referents; while anaphora occurs at the textual level: in order to interpret an empty (or almost empty) textual element X  X n anaphor X  X ike el cicle  X  X he cycle X  in (1-a), 1 we need to go back in the text to find its antecedent ( el seu primer cicle de concerts  X  X heir first cycle of concerts X ). Thus, anaphora and coreference work independently, although they can co-occur. We distinguish anaphoric coreference (1-a) from definite coreference (1-b), where the last expression ( Endemol, productora del programa Gran Hermano  X  X ndemol, the production company for the Big Brother programme X ) is understood without the need of going back in the text. Finally, (1-c) shows that not all anaphoric relations are coreferent: les de moros i cristians  X  X hose of Moors and Christians X  is anaphoric, since the lexical head festes  X  X estivals X  is retrieved from the previous expression festes de lluita de classes  X  X lass struggle festivals, X  but each expression refers to a different entity, i.e., they do not corefer. (1) a. (Cat.) Els integrants del Cor Vivaldi assagen les peces d el seu primer cicle The goal of anaphora resolution is to fill the empty (or almost empty) expressions in a text, i.e., to find an antecedent for each anaphoric unit so that the latter is linked to the mention its interpretation depends on. Coreference resolution, on the other hand, aims to establish which (referential) noun phrases (NPs) in the text point to the same discourse entity, thus building coreference chains. Hence, while the outputs of anaphora resolution are antecedent X  X naphor pairs, the outputs of coreference resolution are collections of mentions 2 of different types (referential pronouns and their antecedents, proper nouns, definite NPs, discourse segments, etc.) that refer to the same discourse entity. Solving coreference can imply solving anaphora, i.e., anaphoric coreference. This article presents a language resource that can be used for coreference resolution as well as for limited anaphora resolution. 3
Given its cohesive nature, coreference is a key element in the comprehensive interpretation of a text and, by extension, an interesting object of study both in computational and theoretical linguistics. By building the coreference chains present in a text, we can identify all the information about one entity. From a computational perspective, the identification of coreference links is crucial for a number of applications such as information extraction, text summarization, question answering, and machine translation (McCarthy and Lehnert 1995 ; Steinberger et al. 2007 ; Morton 1999 ). From a linguistic point of view, capturing the way a discourse entity is repeatedly referred to throughout a discourse makes it possible to obtain the different ways an entity can be linguistically expressed. Besides, empirical data on hypotheses about the cognitive factors governing the use of referring expressions such as those suggested by Ariel ( 1988 ) and Gundel et al. ( 1993 ).

The importance of the coreference resolution task in information extraction led to its inclusion in two Message Understanding Conferences (MUC) X 1995 and 1998 X  and in the more recent ACE evaluation programs, as well as the Anaphora Resolution Exercise (ARE) (Orasan et al. 2008 ). It will also be one of the tasks at SemEval-2010 (Recasens et al. 2009b ). Due to the complexity inherent in coreference, limitations of rule-based approaches (Hobbs 1978 ; Baldwin 1997 ; Lappin and Leass 1994 ; Mitkov 1998 ) may be overcome by machine learning techniques, which allow to automate the acquisition of knowledge from annotated corpora (Soon et al. 2001 ; Ng and Cardie 2002 ; Luo et al. 2004 ). The information extraction conception which is behind MUC and ACE is basically interested in finding all the information about a particular entity, thus conflating referential and predicative links, for example. Since this lack of precision in defining coreference (against predicative links and other related phenomena) is problematic, one of our goals was delimiting the boundaries of the concept of  X  X  X oreference X  X  to annotate a corpus in a systematic and coherent way.
This article describes the annotation of the Spanish and Catalan AnCora corpora (Sect. 2 ) with coreference information. Currently, AnCora-CO comprises two 400,000-word corpora annotated with coreference links (distinguishing identity from discourse deixis and predicative relations) between pronouns, full noun phrases (including proper nouns), and discourse segments. AnCora-CO makes it possible to train corpus-based coreference resolution systems for Spanish and Catalan, as well as to infer linguistic knowledge about the way coreference relations occur in real data. Three main assets make AnCora-CO a valuable language resource: its size, its target languages, and the quality of its annotation X  X he coding scheme is the result of a study that takes into account linguistic evidence and schemes previously proposed for English (Sect. 3 ). The following sections provide details about the coding scheme (Sect. 4 ), the annotation tool (Sect. 5 ), statistics on the tags (Sect. 6 ), and inter-annotator agreement (Sect. 7 ). The article concludes with a discussion of the results (Sect. 8 ). 2 The corpora Corpora annotated with coreference information are scarce. Those most widely used have been developed for English within the MUC and ACE evaluation programs (Hirschman and Chinchor 1997 ; Doddington et al. 2004 ). However, both datasets call for improvement from a linguistic perspective: the former has been criticized for the underlying theoretical implications of the coding guidelines (van Deemter and Kibble 2000 ), whereas the latter restricts coreference to relations between seven specific entity types. 4 Other domain-specific corpora have also been or are being developed for English within ongoing annotation tasks (Mitkov et al. 2000 ; Poesio 2004a ; Hovy et al. 2006 ; Poesio and Artstein 2008 ).
 Coreferentially annotated corpora are even scarcer for languages other than English. Among these few we find Czech, German and Dutch (Kuc  X  ova  X  and Hajic  X  ova  X  2004 ; Hinrichs et al. 2004 ; Stede 2004 ; Hoste 2005 ). For Spanish, there is the coreferentially annotated corpus developed for ACE-2007, 5 but again the coreference links annotated are limited to the set of ACE-like entity types. There are also two small corpora of Spanish oral narratives and dialogues (Blackwell 2003 ; Taboada 2008 ), but they are highly restricted to pronominal references for the purpose of studying the neo-Gricean maxims and centering theory, respectively.
The annotation of coreference in AnCora constitutes an additional layer added on top of existing in-line annotations (Taule  X  et al. 2008 ): morphological (POS and lemmas), syntactic (constituents and functions) and semantic (argument structures, thematic roles, semantic verb classes, NEs, and WordNet nominal senses). The AnCora-CO corpus is split into two datasets: the Spanish corpus (AnCora-CO-Es), and the Catalan corpus (AnCora-CO-Ca). Each consists of 400,000 words derived from newspaper and newswire articles: 200,000 words from the Spanish and Catalan versions of El Perio  X  dico newspaper, and 200,000 words from the EFE newswire agency 6 in the Spanish corpus, and from the ACN newswire agency 7 in the Catalan corpus. AnCora-CO is the largest multilayer annotated corpus of Spanish and Catalan. It is freely available from http://clic.ub.edu/ancora . 8 3 Linguistic issues Given that coreference is a pragmatic linguistic phenomenon highly dependent on the situational context, it does not fall under the topics traditionally dealt with by descriptive Spanish or Catalan grammars apart from some occasional references (Bosque and Demonte 1999 ; Sola ` 2002 ). When analysing real data, we come across a wide range of units (e.g., pronouns in quoted speech) and relations (e.g., metonymic relations) which cannot easily be identified as coreferent or otherwise. Besides, although there are theoretical linguistic studies for English, coreference shows certain language-specific patterns. For instance, Spanish and Catalan make extensive use of elliptical pronouns in subject position, whereas English uses overt pronouns and shows a different distribution of definite NPs.

This endeavour at annotation met two needs X  X hat of delimiting the boundaries of the concept of  X  X  X dentity of reference, X  X  and the need to deal with specific aspects of Spanish and Catalan. The design of the annotation scheme for AnCora-CO began by considering corpus data and listing problematic issues which the scheme needed to address specifically. Our approach was to develop a coding scheme with sufficient criteria to decide which tags had to be used and for what; that is, a scheme from which the corpora could be consistently annotated. Following is a discussion of key issues concerning coreference annotation X  X llustrated with real data from the two languages X  X roviding an overview of the coreference annotation in AnCora-CO by explaining how each of them was dealt with in the actual annotation. 1. Elliptical pronouns . Spanish and Catalan are pro-drop languages that allow
Since elliptical subjects were inserted when AnCora was syntactically annotated (they have their own NP node), it is easy to include them when coding a coreference link. Elliptical subjects that are pleonastic X  X hich are not as frequent as they are in English X  X re not annotated, as in the Catalan pattern  X  e  X  s que ...  X  It is that ...  X  2. Clitic pronouns . Object personal pronouns appear as clitic forms in the two
Clitic pronouns are generally referential, except for inherent clitics that form a single unit of meaning with the verb (e.g., Sp. juga  X  rsela , Cat. jugar-se-la  X  X o risk it X ). For spelling reasons, incorporated clitics do not have their own token in AnCora-Es. Hence, the verbal node is annotated for coreference, 10 while Catalan clitics have their own NP node. 3. Quoted speech . Deictic first and second person pronouns (4-a) become anaphoric 4. Possessives . Possessive determiners and possessive pronouns might have two 5. Embedded NPs . Coreference often involves NPs embedded within a larger NP. 6. Split antecedent . Plural NPs can refer to two or more individuals mentioned
Cases like (6-a) are resolved by building an entity resulting from the addition of two or more entities: entity1 ? entity2 ... The converse (6-b), however, is not annotated: mentions that are subentities of a previous entity are not linked, since this implies a link type other than coreference, namely part-of or set-member. 7. Referential versus attributive NPs . Not all NPs are referential, they can also be To be loyal to the linguistic distinction between referential and attributive NPs, nominal predicates and appositional phrases are not treated as coreference in AnCora-CO. However, given that NPs identifying an entity by its properties can be useful for automatic coreference resolution, such relations are kept under the identical and appositive types followed in the OntoNotes annotation (Pradhan et al. 2007 ). Keeping referential and attributive links apart makes it possible to use AnCora-CO at the user X  X  discretion: either under a fine-grained definition of coreference or under a coarse one, obliterating the distinction between the two links in the latter case. 8. Generic versus specific NPs . Coreference links can occur on a specific or a 9. Metonymy . The referent referred to by a word can vary when that word is used Metonymy within the same newspaper article is annotated as a case of identity, since, despite the rhetorical device, both mentions pragmatically corefer. It is just a matter of how the entity is codified in the text. The transitivity test (see Sect. 4.2 below) helps annotators ensure that the identity of reference is not partial but complete. 10. Discourse deixis . Some NPs corefer with a previous discourse segment (9). 14 11. Bound anaphora . Although this relation has been treated as coreference in In contrast, coreference is allowed in (10-b) since, by being distributed into each of the components, cada equipo  X  X ach team X  results in a whole that equals the sum of the parts. 12. Bridging reference . Bridging relations (Clark, 1977 ) are also left out of 4 Annotation scheme Despite the existence of a few coreference annotation schemes, there is no standard as yet, a shortcoming largely accounted for by the complexities of the linguistic phenomenon (see Sect. 3 ). Due to space constraints, we will not go into detail about the various annotation schemes used in former annotation endeavours. Instead, Table 1 sums up three of the most widely-used existing schemes by showing whether or not they include ( 4 ) the issues outlined in Sect. 3 . The first two were used to encode the corpora for the MUC and ACE programs (Hirschman and Chinchor 1997 ; Doddington et al. 2004 ); the MATE meta-scheme (Mengel et al. 2000 ; Poesio 2004b ) is different in that it is not linked with a specific corpus but constitutes a proposal for dialogue annotation with a wide range of potential tags from which the designer can build his own scheme. The final column in Table 1 sets the coding scheme used in the AnCora-CO corpora against the other two, highlighting the arguments put forward in the previous section.

The MUC and ACE schemes depend to a great extent on the evaluation tasks for which the corpora were originally developed, which makes them either inconsistent or MATE meta-scheme and its proposals for languages other than English has prompted us to adopt it X  X aking into account subsequent revisions and implementations (Poesio 2004b ; Poesio and Artstein 2008 ) X  X s the model on which we base our annotation scheme for the AnCora-CO corpora. 16 Our aim is for AnCora-CO to be used to train/ test coreference resolution systems as well as for linguistic enquiries and research on coreference. Consequently, the annotated features in our scheme are not only thought of as useful learning features but also linguistically motivated.

In order to set limits to render the annotation task feasible, we elected to restrict it to: (a) Coreference links, ruling out any consideration of bound anaphora and (b) NP reference. Other expressions like clauses and sentences are only encoded if
The task of coreference annotation involves two types of activities: marking of mentions and marking of coreference chains (entities). 4.1 Mentions Given that AnCora already contains other annotation layers, the starting point for the marking of mentions was the existing rich hierarchical syntactic annotation. On the one hand, identifying mention candidates by using the output of the manual syntactic annotation freed coders from worrying about the exact boundaries of NPs. On the other hand, the existing syntactic tags constrained some decisions concerning coreference annotation. Nine types of syntactic nodes were eligible to be mentions: (a) sn (NP) (b) grup.nom (nominal group in a conjoined NP) (c) relatiu (relative pronoun) (d) d (possessive determiner) 17 (e) p (possessive pronoun) 17 (f) v (verb) 18 (g) grup.verb (verbal group) (h) S (clause) (i) sentence Units (a) X (f) are those considered as potential mentions in a coreference chain, while units (g) X (i) are only included in a coreference chain if they are subsequently referred to by one of the other units. To indicate whether (a) X (f) mentions are identify the set of referential mentions, i.e., mention candidates to participate in a coreference link (see Sect. 4.2 below). 1. Named entity ( X  X  X e X  X ). The concept of named entity (NE) has its origins in the 2. Specific ( X  X  X pec X  X ). Specific mentions corefer with an NE and have the form of 3. Non-named entity ( X  X  X ne X  X ). This value identifies mentions that refer to an entity 4. Lexicalized ( X  X  X ex X  X ). Lexicalized mentions are non-referential mentions that are 5. No entityref attribute indicates that the mention is non-referential (and other
A second attribute, homophoricDD , is meant to identify Halliday and Hasan X  X  ( 1976 ) homophoric definite descriptions, which are proper-noun-like and generic definite NPs that refer to something in the cultural context or world view, e.g., (Cat.) la ira  X  X he anger X , l X  X ctualitat  X  X he present time X , les dones  X  X omen. X  A test for homophoricity is whether the mention can be the first mention of an entity in a text, i.e., requiring no previous introduction. The NEs that appear in newspaper articles are usually assumed to be already hearer-old and, if not, they are accompanied by a relative clause or an appositive. Therefore, this attribute is not specified for NEs, but only for mentions that are entityref= X  X  X ne X  X  and definite (introduced by the definite article). Notice that, unlike English, generic NPs in Spanish and Catalan are introduced by the definite article.

The third attribute specific to mentions is title . It is assigned the value  X  X  X es X  X  if the mention is part of a newspaper headline or subheading. 4.2 Coreference chains Coreferent mentions are assigned an entity attribute whose value specifies an entity number ( X  X  X ntity# X  X ). Hence, the collection of mentions referring to the same discourse entity all have the same entity number. Our set of coreference relations restricts those proposed in MATE to three, which correspond to the three values that the coreftype attribute can take. A coreftype is specified for all mentions coreferent with a previous one. Additionally, mentions linked either by a discourse deixis or a predicative relation contain a corefsubtype attribute with semantic information. The different coreference types and subtypes are now commented and exemplified, thus highlighting the range of relations contemplated by our scheme. The annotation guidelines explicitly went for high precision at the expense of possibly low recall: coders were told to avoid any dubious link.  X  Identity ( X  X  X dent X  X ). This tag marks referential mentions that point to the same  X  Discourse deixis ( X  X  X x X  X ). Following the terminology proposed by Webber ( 1988 ),
Since discourse-deictic mentions can make reference to different aspects of a previous discourse segment, they take a corefsubtype attribute, which can be of three types:  X  Token (16-a). The mention refers to the same event-token (i.e., same spatial and  X  Type (16-b). The mention refers to an event of the same type as the segment, but  X  Proposition (16-c). The mention refers to the segment as a linguistic object, i.e.,
Existing corpora annotated with discourse deixis are small (Eckert and Strube 2000 ; Navarretta 2007 ). The coreference annotation in the ongoing OntoNotes project X  X eveloping three large corpora for English, Chinese and Arabic X  X ncludes discourse deixis but only considers the heads of VPs as possible antecedents (Pradhan et al. 2007 ). This is the most straightforward solution, but it might fail to capture the precise extension of the antecedent. The coreference annotation of AnCora-CO is done on top of the already existing syntactic annotation, which conditions in some cases the coreference annotation because a discourse segment can be considered to be the antecedent from a linguistic perspective, but the segment might not be a syntactic constituent.
Predicative link types contain a corefsubtype that indicates a semantic distinction, specifying whether the attribution is:  X  Definite. A definite attribution occurs in both equative and identificational clauses,  X  Indefinite. A characterizing but non-identificative feature of the mention (17-a,c)
Negated or modal predicates (18) are not annotated since they either say what the mention is not, or provide a description dependent on a subjective perspective. 5 Annotation tool The corpus was created using AnCoraPipe (Bertran et al. 2008 ), an annotation tool developed at the University of Barcelona for the purpose of accommodating and unifying the attribute-value pairs of each coding level. To this end, the tool uses the same XML data storage format for each stage (Fig. 1 ). Given that the previous annotation layers of AnCora were already encoded in an in-line fashion, AnCoraPipe employs this format, unlike other similar tools, such as MMAX2 (Mu  X  ller and Strube 2006 ), which support standoff markup. Although the advantages of standoff coding are well known (Ide 2000 ), especially in resolving the conflict of overlapping hierarchies of data elements, the conversion of AnCora-CO to a standoff data architecture remains a project for the future.

The tool efficiently handles annotation on multiple linguistic levels, and coders can easily switch from one level to another (e.g., to correct mistakes found in another layer). In this way, the required annotation time is reduced and the integration of the coders X  work is seamless. The corpora in the local machine are associated with a server so that, as soon as an annotator modifies a file, the latter is uploaded to the server before other users add further annotations.

AnCoraPipe provides an additional tool for coreference annotation that makes the process faster and more user-friendly (Figs. 2 , 3 ). Mentions that are annotated with an entity number appear highlighted in the text in different colours. Attribute-values can easily be added, changed, or removed. Figure 2 shows the left side of the screen and Fig. 3 shows the right side of the screen. The screen is divided into four panels:
Top left (Fig. 2 , top). The raw text contained in one file (i.e., one newspaper article).
 Bottom left (Fig. 2 , bottom). The syntactic selected nodes that are being labelled. Top right (Fig. 3 , top). The attributes-values information Bottom right (Fig. 3 , bottom). The collection of annotated multi-mention entities.
In Fig. 2 , the NP El nou Pla General que aquesta nit ha d X  X provar el ple is the mention currently considered as a potential coreferent mention. In order to add it to an entity (i.e., a coreference chain), the coder clicks on the corresponding entity in the window bottom right (Fig. 3 ). The values of the rest of attributes for this mention are selected in the window top right (Fig. 3 ). All mentions with the same entity number ( X  X  X ntity1 X  X  in this example) corefer.

A total of seven annotators contributed to the process of enriching AnCora with coreference information, although throughout the process the average number of coders working at any given time was never more than three. They were all graduates or final-year undergraduates of linguistics, and were paid for their work. The annotation process was divided into two stages: a first pass in which all mention attributes and coreference links were coded, and a second pass in which the newly annotated files were revised. 6 Distributional statistics This section provides distributional statistics for the coreference tags in the corpora, which are very similar for the two languages under consideration. AnCora-CO-Es (422,887 tokens) contains 134,247 NPs, of which 24,380 (18.16%) are not marked as referential mentions. AnCora-CO-Ca (385,831 tokens) contains 122,629 NPs, of which 24,906 (20.31%) are non-referential. Table 3 shows the distribution of mentions, and provides details of the number of mentions sorted by POS. We distinguish between isolated, first, and subsequent mentions. It emerges that about 1/2 of the mentions are isolated, 1/6 are first mentions, and 1/3 are subsequent mentions. Coreferential mentions are split into pronouns (1/3) and full NPs (2/3). The number of entities, including those containing a single mention, is 89,206 in Spanish, and 81,386 in Catalan. The distribution of coreftype and corefsubtype tags over mentions marked as coreferent is presented in Table 4 . These are pairwise links, which means that 17,884 non-single-mention entities include 45,909 links (AnCora-CO-Es), and 16,545 non-single-mention entities include 41,959 links (AnCora-CO-Ca). Table 5 shows the distribution of entities according to their size (i.e., the number of mentions they contain).

These statistics reveal interesting linguistic issues which could open up many avenues for future research. Notice, for instance, the high percentage of definite NPs that are isolated or first mentions, which confirms the findings of the studies conducted by Fraurud ( 1990 ) and Poesio and Vieira ( 1998 ) in Swedish and English, respectively. The number of first-mention definites in Spanish and Catalan is even higher (see Recasens et al. 2009a for a more detailed exploration). 7 Inter-annotator agreement There is widespread agreement on the fact that coders X  judgments in semantic and pragmatic annotation tasks such as coreference are very subjective and, consequently, annotator agreement is assessed. Consistency can only be achieved if the coding instructions are appropriate for the data, and annotators understand how to apply them. A reliability study on a sample of the corpus makes it possible to pinpoint both the strengths and weaknesses of the coding scheme, and make the necessary changes before proceeding to the annotation of the entire corpus.

Different agreement coefficients have been used by the discourse processing community, but there is no standardized metric for agreement on coreference. In their survey, Artstein and Poesio ( 2008 ) point out the main problems in using percent agreement and the kappa coefficient (Siegel and Castellan 1988 ; Carletta 1996 ). On the one hand, percent agreement does not yield values that can be compared across studies, since some agreement is due to chance, and the amount of chance agreement is affected by two factors that vary from one study to another: (a) The number of categories (the fewer categories, the higher the agreement (b) The distribution of items among categories (the more common a category, the
On the other hand, kappa is corrected for chance agreement, but it is not appropriate for all types of agreement because it assumes that all disagreements are equal. A third coefficient, alpha ( a ), overcomes the two previous limitations by being both chance-corrected and weighted (Krippendorff 1980 ). 7.1 Reliability study In this section we present a reliability study on the annotation scheme presented in Sect. 4 , as applied to data from AnCora-CO. Given the high cost of conducting such studies, time, budget and personnel constraints prompted us to limit the scope of the experiment to the core tag of the coreference coding scheme (the coreftype attribute) and to data from the Spanish corpus as a representative sample. Taking into account that most work on reference is limited to pronominal anaphors and has used kappa, we were mainly interested in analyzing to what extent coders agreed on assigning identity versus non-coreference relations for both pronominal and non-pronominal NPs. Specifically, we set out to: 1. Examine the coverage and tag definitions of the coding scheme. 2. Test the adequacy and clarity of the annotation guidelines. 3. Identify cases raising significant issues, with a view to establishing a typology
The results show that the annotation of AnCora-CO is reliable to an acceptable degree. 23 Thus, the corpora can serve as a valuable language resource on which to base studies of coreference in Catalan and Spanish, as well as reference on a more general level. 7.1.1 Subjects Six volunteer undergraduates (with no previous experience in corpus annotation) and two linguistics graduates (two of the annotators who had worked on the corpus) participated in the experiment, all of them students at the University of Barcelona and native bilingual Spanish-Catalan speakers. 7.1.2 Materials A total of four newspaper texts from the AnCora-CO-Es corpus were used: two 24 (838 tokens, 261 mentions) in the training stage, and the other two 25 (1,147 tokens, 340 mentions) in the testing stage. In both cases, the second text was more complex than the first one, being longer and including a higher number of ambiguities and discourse-deictic relations. Given the shortage of time, the chosen texts were short, but each one included at least two instances of every link type.
 7.1.3 Tools The annotations were performed on three computers with Windows XP using the PALinkA annotation tool (Orasan 2003 ). 26 7.1.4 Procedure The experiment was run in four ninety-minute sessions: two training sessions and two testing sessions. Annotators were given the set of mentions (NPs) and had to decide for each of them whether it was coreferent or not. If so, the appropriate value for the coreftype attribute had to be selected, in addition to the entity. During the first two sessions, coders familiarized themselves with the annotation tool and guidelines, and feedback was provided to each of them after the mock annotation of two texts. In the last two sessions, they annotated the two test texts separately from each other. 7.1.5 Results Artstein and Poesio ( 2008 ) make the point that coreference encoding differs from other annotation tasks in that coders do not assign a specific label to each category but create collections of coreferent mentions. Passonneau ( 2004 ) proposes using the emerging coreference chains (i.e., entities) as the labels, and recommends the MASI (Measuring Agreement on Set-valued Items) distance metric (Passonneau 2006 )to allow for partial agreement. In our experiment, it turned out that disagreements emerged from different decisions on the link type assigned to a mention rather than on the same mention being assigned to different entities by different coders. As a result, we decided to use two agreement values to separate the two aspects: (a) link type (treating non-coreference as a type), and (b) entity number. The first was measured by Krippendorff X  X  a , as disagreements are not all alike. The second was measured by kappa, as there was no need for weighted agreement.

To measure link type, the four coreftype links (non-coreference, identity, predicative, discourse deixis) were used as the possible labels that could be assigned to each mention. Passonneau ( 2004 ) employs a coder-by-item agreement matrix where the row labels are the items (mentions), the column labels are the coders, and the cell contents indicate the value that a specific coder assigned to a specific item. This kind of matrix was used to enter the results of the experiment (Table 6 ), where a numerical value identifies each link type. Krippendorff X  X  a was computed with the freely available KALPHA macro written for SPSS (Hayes and Krippendorff 2007 ), yielding the following results: a = .85 ([.828,.864] 95% CI) for Text 1, and a = .89 ([.872,.896] 95% CI) for Text 2. Krippendorff X  X  a ranges between -1 and 1, where 1 signifies perfect agreement and 0 signifies no difference from chance agreement (rather than no agreement).
To measure entity number, a coder-by-item agreement matrix similar to the previous one (Table 6 ) was used, but in this case the row labels only contain the mentions that were linked by an identity or predicative relation, 27 and the cells contain the entity number they were assigned. In fact, there was just a single case in which coders disagreed (see (19), below, in Sect. 7.2 ). Thus, high kappa values were obtained: j = .98 for Text 1, and j = 1 for Text 2. 7.1.6 Discussion In the observed coincidence matrix (Table 7 ) for link type, the disagreements between observers cluster around the diagonal containing perfect matches. The expected coincidence matrix (Table 8 ) can be interpreted as what would be expected under conditions of chance. The delta matrix (Table 9 ) shows how a weights the coincidences: a mismatch between non-coreference and discourse deixis is less penalized X  X ubtler decision X  X han one between non-coreference and predicative, while the stiffest penalization is for disagreement between non-coreference and identity, which are the labels at either end of the spectrum.
Even now, according to Artstein and Poesio ( 2008 ), it is  X  X  X he lack of consensus on how to interpret the values of agreement coefficients X  X  that accounts for  X  X  X he reluctance of many in Computational Linguistics to embark on reliability studies. X  X  In his work, Krippendorff ( 1980 ) suggests a = .8 as a threshold value, which is supported by more recent efforts (Artstein and Poesio 2005 ). In both texts, we obtained an a coefficient above .8, which is high enough to claim good reliability as far as the four-way distinction between is concerned. Contrary to our expectations, Text 2 yields a higher reliability score, which is possibly due to the different size: Text 1 contains 152 mentions, and Text 2 contains 188 mentions. Even though the second text contains some tricky coreference relations, it also contains many clear cases of non-coreferential mentions, which increase the intercoder agreement. The high alpha results from the fact that the coding guidelines define precisely the relations covered by each link type, thus separating identity from predicative links and ruling out less well-defined relations such as bridging. Likewise, the preference expressed in the annotation manual for excluding any link in case of doubt or ambiguity X  X s in cases of only partial identity X  X ccounts for the almost full agreement obtained for entity number. The guidelines discuss how to deal with recurrent non-prototypical cases of coreference, although there will always be new cases not covered by the manual, or obscure to coders, which account for the margin up to full agreement.

The general pattern is that two out of the eight coders (which can already be seen from the agreement matrix, Table 6 ) account for the majority of disagreements, and they do not deviate in the same direction, which provides further support of the validity of the guidelines as most mistakes can be attributed to certain coders X  poorer understanding of the annotation task. If these two outliers are removed and a is recomputed with the other six coders, the results improve up to a = .87 ([.857,.898] 95% CI) for Text 1, and a = .90 ([.882,.913] 95% CI) for Text 2. The remaining disagreements are broken down in the next section. 7.2 Sources of disagreement A reliability study informs about intercoder agreement and also enables disagree-ments to be analyzed so as to improve data reliability and better understand the weaknesses of the annotation guidelines, the complexity of the linguistic phenomenon under analysis and the aptitude of the coders. After computing the exact reliability agreement, we compared qualitatively the output of the eight coders, going into more detail than with the four-way distinction of the coreftype attribute. We grouped the major sources of disagreement under seven headings. 1. Different metonymic interpretation. Metonymy accounts for the only case of 2. Violations of the maximal NP principle. Three disagreements were caused by 3. Idiolinks. Each coder produced at least one link that none of the rest did. They 4. Referential versus attributive NPs. The divide between referential and 5. Discourse deixis. Even though the computation of Krippendorff X  X  a only took into 6. Missed links. Each coder missed one or two links. The reason for this was either 7. Misunderstandings. The two coders that produced the most na X   X  ve annotations
In a nutshell, most of the problems can be attributed to a lack of training (i.e., familiarity with the guidelines) on the part of the coders, as well as oversights or ambiguities left unresolved in the discourse itself. After carrying out the study, it became clear that the guidelines were clear and adequate, and that, assuming coders go through a period of training, many disagreements that were just a matter of error or misapplication could be resolved through revision. Therefore, we decided that a two-pass procedure was required to annotate the whole corpus: each text was annotated twice by two different coders, thus always revising the links from the first pass and checking for missing ones. The qualitative analysis of the sources of disagreements shows the subtleties of the task of coreference annotation and hence the need for qualified linguists to build a reliable language resource, in line with Kilgarriff ( 1999 ). 8 Conclusions We presented the enrichment of the AnCora corpora with coreference information, which heralded the advent of the AnCora-CO corpora. The Spanish and Catalan corpora constitute a language resource that can be used for both studying coreference relations and training automatic coreference resolution systems. The AnCora-CO corpora contain coreference annotations for Spanish and Catalan conjoined with morphological, syntactic and semantic information, thus making it possible to rely on a wide range of learning features to train computational systems. This can be especially helpful for coreference resolution, which is known to be a very challenging task, given that many sources of knowledge come into play. In this respect, AnCora-CO opens new avenues for carrying out research on the way coreference links X  X oth between pronouns and full NPs X  X re established by language users.

Given the subjectivity of discourse phenomena like coreference, there is a need to understand the linguistic problem so as to produce thorough and useful annotation guidelines (Zaenen 2006 ). This was our main guiding principle. The annotation scheme designed to annotate coreference draws on the MATE/GNOME/ARRAU scheme, but restricting it to coreference. Special attention was paid to finding a balance between the hypothetical requirements of a machine-learning coreference resolution system and the way in which the linguistic reality allows itself to be encoded. The key to our approach lies in three central factors. First, relations are split into three kinds: identity of reference, discourse deixis, and predication. Other relations such as bridging are not included in order to keep a consistent definition of coreference. Second, what is meant by  X  X  X dentity of reference X  X  is clarified with the help of real examples to reduce ambiguities to a great extent. The transitivity test is used as an indicator of coreference. Third, mentions are individually tagged with three attributes containing information (entity reference, homophoric definite description, title) that can be used to group mentions into referential/non-referential, and first/subsequent mentions.

The quality of the scheme was assessed by computing intercoder agreement in a reliability study with eight coders. We used kappa to measure agreement on entity which is the core of the scheme as it separates non-coreferential from identity, predicative and discourse-deictic mentions. Once a mention was chosen as being coreferent, the choice of entity was widely agreed upon. The high inter-annotator agreement demonstrated the reliability of the annotation, whereas the dissection of the disagreements served to suggest a typology of errors and determine the best procedure to follow. We leave for future work a large-scale reliability study that explores further issues such as the identification of antecedents in discourse deixis.
In order to do the markup, the AnCoraPipe annotation tool was customised to meet our needs. Since the XML format enables the corpora to be easily extended with new annotation levels, AnCora-CO can be further extended to include, for example, coding of nominal argumental structures, discourse markers, etc. In addition, we intend to convert the current in-line annotation to a standoff format. By developing the AnCora-CO corpora we have provided Spanish and Catalan with two new language resources.
 References
