 CHUNG-CHIAN HSU, CHIEN-HSING CHEN, TIEN-TENG SHIH, and CHUN-KAI CHEN National Yunlin University of Science and Technology 1. INTRODUCTION
The Internet has speeded up information exchange and knowledge sharing. In this environment, a large quantity of foreign documents and information can be easily accessed from local countries. To be widely understood, these must be translated into domestic languages. In particular, Chinese is the domestic language that is the subject of this article.

Different translators have differences in understanding when they read for-eign documents, and a certain proportion of what they are translating is neolo-gisms for the ideas or the trend. Unfortunately, there is no dedicated domestic governing body to set translation standards. As a result, different translators may translate the same thing differently, especially proper nouns. Proper nouns are usually the names of people, places, or organizations. When translators tackle proper nouns, they generally seek phonetically similar Mandarin ver-sions of the foreign originals. We call this kind of translated noun a transliter-ation . Note that in this article, we deal exclusively with Mandarin transliter-ations, not with Cantonese transliterations or transliterations into any other Chinese dialect or language.

Given different translators and situations, there are two possibilities in the transliterations: same sounds, different characters or different sounds, differ-ent characters. The former indicates that different character strings are used to transliterate a proper noun, but these strings have identical sounds. For exam-ple, the name of the former president of the United States Bill Clinton is trans-lated using different characters (ke lin dun) and (ke lin dun) with the same sounds. The latter means that a foreign word is transliterated using dif-ferent character strings, and the different strings have different sounds. For ex-ample, the former Soviet president Mikhail Gorbachev is translated to (ge er ba qiao fu) and (ge ba qi fu). Note that the lengths of these two transliterations are also different.

When a proper noun is transliterated in different ways, we call the results synonymous transliterations . Synonymous transliterations cause at least three problems. First, they may generate confusion for the reader and are thus an obstacle to comprehension. Second, in the larger community of language users, synonymous transliterations cause problems in communication. Third, and more seriously, is that Chinese search engines may fail to provide complete search results when only one transliteration, rather than all the synonyms, is used for the query.

This article investigates how to compare transliterations, a process which will serve as a first step for overcoming the problems caused by synony-mous transliterations. We devised a digitized sound comparison technique, that makes use of the patterns of similarity and difference in the sounds of Chinese (or Hanzi). Based on this technique, we developed a two-stage approach to comparing transliterations as follows: during the training stage, we used a procedure to compile data on patterns of similarity in Chinese speech sounds.
This data was used to construct a similarity database. During the recognition stage, transliterations were first changed into phonetic notation, and then the database was applied to the similarity comparison of the pronunciations of en-tire transliterations. In addition, we designed four other methods adapted from the approaches used in the CLIR literature. We compared these methods on the capability of identifying synonymous transliterations from a set of noise words extracted from Web pages.

The rest of the article is organized as follows. Section 2 reviews some re-lated work in the CLIR literature. Section 3 gives some background on Chinese phonology. Section 4 presents the detailed process of the Chinese character sound comparison approach and the other four methods. Extensive experiments have been conducted, and the results are given in Section 5. Finally, Section 6 gives conclusions and future directions. 2. RELATED WORK
Cross-lingual information retrieval (CLIR), whose aim is to retrieve documents in one language given queries in another language [Chen 1997], has long been studied. Much CLIR research focused on the issue of handling proper noun transliterations, especially identifying pairs of corresponding proper nouns from bilingual corpora [Collier and Hirakawa 1997; Brill et al. 2001; Lin and
Chen 2002; Tsuji 2002; Virga and Khudanpur 2003]. Transliteration can be classified into two directions. Forward transliteration is the process of phoneti-cally converting an original proper noun in the source language to a transliter-ated word in the target language [Wang et al. 1997; Lee et al. 2006]. Backward transliteration works in the opposite direction, that is, from a transliterated word to its original source word [Stalls and Knight 1998; Chen et al. 1998; Lin and Chen 2000, 2002].

The work in handling proper noun transliterations in CLIR is relevant to our issue, in particular the algorithms for calculating the phonetic alignment and/or similarity between two words. We briefly review some pertinent approaches.
More material can be found in [Kondrak 2003], [Chen et al. 2006], and [Lee et al. 2006].

Word similarity can be measured at three different levels, namely, phys-ical sounds, graphemes, and phonemes [Lin and Chen 2002]. For example,
Soundex [Knuth 1973] measures similarities at the grapheme level. The tech-niques based on phonemes have been shown to outperform the grapheme-based methods. The similarity between phonemes can be assigned manually or learned automatically. The manual assignment is based on the similarity of articulatory features, such as place or manner of articulation, tone, and word accent. Essentially, the more common aritculatory features two phonemes have, the more similar the two phonemes are. Some work, for example, Gildea and Jurafsky [1996] and Nerbonne and Heeringa [1997], treated an articula-tory feature as a binary variable, indicating whether the feature is presented. However, in a strictly binary system, sounds that are similar often differ in a disproportionately large number of features. Many studies, for example,
Ladefoged [1975], Somers [1998], and Lin and Chen [2000], adopted a mul-tivalued features scheme which allows features to have several possible values resulting in a more natural and phonetically adequate system. Nevertheless, not all features are equally important in classifying sounds. For instance, the features place and manner should be assigned significantly higher weights than other features. Kondrak [2003] proposes a phonetic alignment and similarity calculation approach, ALINE, which considers multivalued articulartory fea-tures and assigns different weights on the features according to their relative importance.

The phonetic similarity can be learned from a training corpus with or with-out a pronunciation dictionary. In Lin and Chen [2002], a pronunciation dic-tionary with a modified Widrow-Hoff learning algorithm was used to deter-mine the similarity between 97 phonemes used to represent 1,574 training pairs of English and transliterated Chinese names. Lee and Chang [2003] proposed an approach based on a statistical machine-transliteration model to exploit the phonetic similarities between English words and correspond-ing Chinese transliterations. Their method does not require a pronunciation dictionary. The parameters of the model are automatically learned from a bilin-gual proper name list. The learning-based approaches have disadvantages as mentioned in Kondrak [2003]. Any selection of the training data would bias the similarity function towards particular languages, and, moreover, establish-ing the correct alignment of cognates by hand for a large corpus is very time-consuming.

Our work differs from the previous transliteration work in CLIR in two as-pects. First, we compare the similarity between transliterated words against noise words, rather than comparing transliterated words to their source words. Our work has several significant applications such as retrieving all the documents containing the identical as well as synonymous translitera-tions given a single query transliteration, and topic tracking of news con-taining transliterations. Second, we propose an approach based on compar-ing physical sound. To the best of our knowledge, we are the first to ex-plore the application of speech signal processing to comparing transliterated words. The idea is that physical sound comparison is the most natural and intuitive approach to measuring the similarity between words. Moreover, un-like the learning-based approaches, the proposed approach does not require a training corpus, avoiding potential bias. It does not involve manual align-ment of cognates either. Therefore, it is worthwhile to investigate the feasibil-ity and performance of the approach applied to the transliteration comparison issue. 3. PRELIMINARIES
We briefly introduce Mandarin Phonetic Notation [NTNU 2002], a work which describes Taiwan X  X  approach to teaching children the sounds of characters us-ing phonetic symbols. In addition, pinyin schemes which romanize Chinese characters to the English alphabet are also introduced.
 3.1 Chinese Phonology
In Mandarin Chinese phonology, every character X  X  pronunciation is composed of single component sounds and is monosyllabic. Every monosyllabic character X  X  pronunciation has three parts, an initial, a final, and a tone, which is usually considered a supersegmental feature since it applies not to a single phoneme but to an entire word. Mandarin has four regular tones plus the so-called half-tone.

In Taiwan, each Mandarin phoneme can be represented by a phonetic sym-bol. There are 37 phonemes in Mandarin and thus 37 phonetic symbols. These 37 symbols considered together constitute a system of phonetic notation. One or more symbols will be used to represent the pronunciation of a character. In
China, a different system, Luoma pinyin or romanization, is used. We will use romanization alongside the Taiwan system to represent the sounds of phonemes and characters in this article. For example, (bang; ) indicates that the character has the romanization  X  X ang X  and the phonetic notation  X   X .
In Mandarin, there are 21 initial symbols and 38 finals, including 16 base finals and 22 combinations of 2 symbols, as shown in Figure 1. Their corre-sponding Hanyu romanization letters are listed in Table I. Some symbols have two representations depending on whether they are used alone or with other symbols. For instance, for (poem) is romanized by shi , while for (book) by shu , of which sh for and u for .

Initials (if a character has an initial, it will be a consonant) are categorized into six types according to where they are articulated and what the articulator is (with what part of the tongue they are articulated): labial, apical (tip of the tongue), velar, palatal, retroflex, and dental. Finals are usually vowels, though the compound finals are glides and both base and compound finals have nasal consonant finals in some cases. Finals are either base finals (represented by a single phonetic symbol) or combination finals (represented by a combination of two phonetic symbols). Base finals divide into five types: Monopthongs 1 are high single vowels; Monopthongs 2 are nonhigh single vowels; Dipthongs are dual vowels. The nasal finals are m, n, and ng; these are always preceded by a nonhigh vowel. The retroflex vowel is like an English  X  X  X .

Compound finals are those that use two symbols to represent the pronunci-ation. The glides are considered part of the final. The glides are all compound finals, meaning that it takes two symbols to represent them. The characters used for the glides are also used as proper vowels. For example in  X   X (ya in
Pinyin),  X   X  functions as a glide. But  X   X  can also be a regular vowel, as in  X   X  (bi), an initial plus a final. The y-glides use  X   X  and sound like an English  X  X  X .
The w-glides use  X   X  and sound like an English  X  X  X . The  X  u glide uses  X   X  and has no counterpart in English.  X   X  exists as an umlauted  X  X  X  in French and German.
It is produced by making an English long-e sound and rounding the lips. The  X  u glide is the consonant version of this vowel.

There are four tones for each character sound in standard Mandarin, which are yinping (1st tone, high level), yangping (2nd tone, rising), shangsheng (3rd tone, falling-rising), and qusheng (4th tone,  X  X eparting X  or falling). 3.2 Pinyin Schemes
The language symbol can be broken into three categories, namely, words and phrases, syllable, and phoneme. The Chinese language belongs to words and phrases, Japan kana is syllable, and the English and German languages are all phoneme. Pinyin is a process which transfers word and phrase into phoneme.
The transferred symbol is similar to the English alphabet, and it easier to pronounce for English speakers. Several pinyin schemes are available today including Yale, Hanyu, Mandarin Phonetic Symbols II, Tongyong, and Wade-
Giles [WiKiCity 2006]. Among the schemes, Hanyu is popularly used world-wide. Therefore, we use Hanyu pinyin along with the Chinese characters in this article. In addition, a universal translation rule, International Phonetic Al-phabet (IPA), was proposed to transcribe the sounds of speech for representing the sounds of any language in the world [MacMahon 1986]. An example of the various pinyins for the former Soviet president Gorbachev is shown in Table II. 4. RESEARCH METHODOLOGY
We propose to measure the similarity between two transliterations by compar-ing physical sounds. The idea is based on the observation that most translit-erations are chosen according to phonetic closeness to their foreign originals.
Therefore, most synonymous transliterations has a high degree of phonetic similarity. For example, although having different lengths, the synonymous transliterations of Gorbachev (ge er ba qiao fu) and (ge ba ci fu) sound more similar to each other than to other ordinary transliterations, such as (shih tao de mai er) representing an original name Stoudamire.
Moreover, comparing physical sounds is the most natural and intuitive way to measuring the phonetic closeness of two words. Based on the observation and intuition, the proposed character sound comparison method (or CSC) was di-vided into two parts as shown in Figure 2, a training stage and a recognition stage. In the training stage we followed a procedure to construct the Chinese speech sound similarity database, which includes two similarity matrices. The database served as the foundation for comparing the phonetic similarity of
Chinese characters. In the procedure followed during the recognition stage, the transliterations were switched to phonetic notation. Then the similarity matrices were applied to calculate the similarity of different transliterations. 4.1 Constructing the Similarity Database
The Chinese character sound similarity database consisted of similarity ma-trices of the 37 phonetic symbols and 412 basic character pronunciations in the Guoyu zidian s(Chinese dictionary). The construction procedure was in two steps, speech sound feature extraction and similarity matrix construction. 4.1.1 Speech Sound Feature Extraction. We adopted a speech processing procedure to transform analog sound data (human speech waves) into a digital distance matrix. A brief description of our speech processing is given in the following. For more details, please refer to the literature such as Young [1996], Fu et al. [1996], Wang et al. [1997], and Huang et al. [2001].
 The process included sound recording, feature extraction, and comparison.
A directional microphone was used to record the speech sounds, and then the analog speech signals were digitalized and stored as sound files for use in later comparison. Each sound consisted of six sets of recording samples. An aver-age was calculated, followed by normalization. Outliers were eliminated and rerecording was performed. The speech signal was recorded and stored as an 8000Hz, single-channel, 8-bit WAV file.

Feature extraction on a speech signal was further divided into a number of steps which include in order, frame segmentation, endpoint detection, and speech feature extraction. The size of a frame was set to 256 points with a third of them overlapping. For each frame, sound features (MFCC or mel-frequency cepstrum coefficients) were extracted to form a vector with dimension 26, in-cluding 12 cepstral, 12 delta-cepstral coefficients, energy, and delta-energy.
There are three relevant endpoint detection methods. The simplest and most widely used is time-domain endpoint detection, but the shortcoming of this ap-proach is that it has a lowered immunity to static and noise. The other two are frequency-domain endpoint detection and hybrid-parameter endpoint de-tection, which yield higher accuracy and are more successful at reducing noise but require a lot more calculation [Rabiner and Juang 1993]. In this research, time-domain endpoint detection was used. After this process, each sound was represented by a set of vectors of sound features.

In the process of comparing speech, the most important issue is how to com-pare signal sequences of different time lengths. Different people will pronounce the same character shorter or longer, so the length of the extracted feature vec-tors will be different. A dynamic programming technique, dynamic time warp-ing (DTW) [Sakoe and Chiba 1978], was used. It is one of the most widely used methods for handling the issue. DTW expands or contracts test data to find the least inaccurate nonlinear correspondence with the reference data so as to estimate the distance of the feature parameters of the two sound samples. 4.1.2 Constructing Similarity Matrices. For constructing the two matrices one-by-one, we took the phonetic feature vectors of each character obtained during the previous step and compared them with the phonetic feature vectors of other characters.

DTW was used to find the shortest distance between two phonetic feature vectors. The local path constraint of the DTW algorithm was set to 27-45-63 degrees or window width 2, which can reduce the impact of noise. Formally, the recurrent distance equation for two digitalized sounds, s where d ( i , j ) is a local distance measure between frame i of s s . The minimum distance between s 1 and s 2 can then be obtained at D [ I , J ], where I and J are the numbers of frames of s 1 and s 2 , respectively.
After comparing the recorded sound waves, we obtained a distance matrix for the 37 phonetic symbols and a distance matrix for the 412 pronunciations.
The min-max normalization was performed so that each value was in the range [0, 1]. A conversion is then followed. If distance = d , then the similarity 1  X  d . Finally, we obtained two similarity matrices which served as the foun-dation for comparing two complete transliterations. 4.2 Method Based on Character Sound Comparison
According to our experience, final sound heavily influences speech sound com-parison. Faced with this problem, we adopted an initial-weighted comparison approach, which weights the initial consonants of the characters to balance the bias caused by the final sounds. The 37 phonetic symbol similarity matrix was used to provide the similarity data between the initials of the characters. We devised a dynamic programming-based approach to obtain the similarity of two transliterations, S 1 and S 2 . The recurrence formula is defined as follows, where sim ( S 1 ( i ), S 2 ( j )) = w  X  sim s 37 ( S 1 ( i ) ( S 1 ( i ), S 2 ( j )) i th character of S 1 and the j th character of S 2 obtained from the similarity matrices of the 37 phonetic symbols and 412 character pronunciations. For example, both sim s 37 ( (d), (t)) and sim s 412 ( (dwen), (twen)) have high scores due to high similarity in their speech sounds. w represents a trade-off measure between the initial consonant and the whole character. The base condition and null sound comparison are defined by T ( i ,0) and sim ( S x ( y ),  X  X ) = 0. Normalized similarity can then be obtained by dividing
T ( | S the denominator significantly influences similarity comparison when noises are present. The details are given in the experiment section which follows. 4.3 Other Methods Based on Grapheme and Phoneme
We further designed four other methods which were taken or adapted from ex-isting methods in the CLIR literature. The first one is grapheme-based which translates transliterations by the use of pinyin schemes (or romanization) and then compares the romanized words by counting the number of common sub-sequences. The recurrence formula in Equation (2) can be adapted with the revised sim(  X  ,  X  ) as shown in Equation (3).
The other three methods are phoneme-based in which articulatory features are taken into consideration. For the first one, we use the feature scheme sug-gested in Connolly [1997], and which is also adopted in Somers [1998]. The scheme identifies two perceptual features or axes, namely, friction strength (FS) and pitch (P), and divides the consonant phones into six groups differ-entiated by their score on each of these axes. For instance, bilabial plosives while alveolar fricatives consonants (e.g., s, z) have scores 1.0 and 1.0, respec-tively. The normalized similarity score between two consonant phones can be obtained by Equation (4). When comparing a phone to a vowel, we set the sim-ilarity score to 1 if they are identical, otherwise it is 0. The recurrence formula in Equation (2) can be adapted again by using the new sim ( comparing two romanized transliterations. The total score is normalized by dividing by the length of the longer string. sim ( i , j ) = The second phonetic method is based on the similarity scoring scheme of
ALINE [Kondrak 2003]. The scheme considers a set of operations including insertions/deletions, substitutions, and expansions/compressions. Multivalued features are used for comparing similarity of phonetic segments. In their de-fault setting, two identical consonants get 35 points, while identical vowels get 15. To compare two transliterations, we use a dynamic programming algorithm such as Equation (2) to compare the two strings obtained from the romanized transliterations. The sim (  X  ,  X  ) function in Equation (2) is replaced by the ALINE scoring scheme with their default setting. ALINE considers multivalued artic-ulartory features and assigns different weights on the features according to their relative importance. Readers can refer to Kondrak [2003] for the details.
Normalization can be performed by dividing the final score by 35 | v | , where | c | and | v | are the numbers of consonants and vowels, respectively, in the longer string.

The third phonetic method is based on the scoring scheme in Lin and Chen [2000] which is designed for comparing a transliteration to its original word (English). We adapt the scheme to comparing two transliterations. The com-parison is performed on the two strings consisting of Taiwan phonetic symbols obtained from two transliterations. Again, Equation (2) is adapted with a re-vised sim ( i , j ), where i (or j ) represents a Taiwan phonetic symbol. The new sim ( i , j ) is defined as follows. A matched consonant pair is assigned 10 points and otherwise  X  10. A matched vowel pair is assigned 5 points and otherwise 0. Matching with a null phone (or inserting a null) is assigned
Lin and Chen [2000], to consider articulatory similarity, we assign some con-sonant pairs 8 points and vowel pairs 4 points. The pairs are determined by their articulatory features found from their corresponding symbols in the IPA.
The consonant pairs include { (b), (p) } , { (d), (t) } , (zhi), (chi) } , { (zi), (ci) } , { (shi), (si) } , { (chi), (ci) (zhi), (zi) } . The vowel pairs include { (yi), (  X  u) } and { (en), (eng) } . The maximum and the minimum similarity score of com-paring two strings can be obtained by 10  X | c |+ 5 where | c | and | v | are the number of consonants and of vowels, respectively, in the longer string. This range can be used to normalize the total score. For instance, T ( (guo), (kou)) = 8  X  5 + 4 = 7 and the normalized score is 0.74 (i.e., (7  X  (  X  30))/(20  X  (  X  30))). 4.4 Data Reduction
This section investigates reduction of recording samples without compromising accuracy too much. In the Guoyu zidian (Chinese dictionary), there are in total 1,353 possible character sounds which are an excessive number of samples and would increase the complexity of processing speech data. This research chose to ignore tone differences of characters. The result was the selection of 412 basic Chinese character sounds.

English is not a tonal language, and there are no hard-and-fast rules to describe how translators translate words from a nontonal language into a tonal language like Chinese. Sometimes special choices will be made simply to make the result more readable in Chinese. The experiment described in this section was designed to investigate whether there was a significant difference in overall similarity between characters with the same sound but different tones.
From 200 single sound samples, several sets of sounds with which to carry out the experiment were randomly drawn. There were four sets, based set were (1) (ai 1 )-(ai 2 )-(ai 3 )-(ai 4 ), (2) (ha (qiao 2 )-(qiao 3 )-(qiao 4 ), (4) (bi 2 )-(bi 3 )-(bi ities of a transliteration to the other four transliterations with different tones.
The data obtained through this experiment showed that the impact of tone on transliteration similarity was small. Differences in tone were not found to have a significant effect as they produced differences in similarity on the order of 0  X  0 . 05. As a result, these same sound, different tone strings would very likely still be grouped into the same sets even without the consideration of tone.
Thus it is possible to ignore the impact of tone on similarity. After eliminating the factor of tone, the initial set of 1,353 possible pronunciations shrank to 412. 4.5 Improving Recording Quality
Each step in the speech processing X  X ecording, endpoint detection, feature ex-traction, and similarity comparison X  X s interconnected with the other steps, so recording quality will impact the final step of comparison. We used three means to improve the quality: directional microphones, control through endpoint de-tection, and the elimination of abnormal values. Directional microphones were used in recording to cut down on background noise. The endpoint detection function is integrated in the recording process such that recording quality can be confirmed instantly after each individual recording. In our experience, there were three common situations which indicated bad samples: (1) the number of frames of a single sound &gt; 50, (2) the number of frames of a single sound and (3) a single sound got segmented into two parts. Bad samples were removed and re-recording was performed. 5. EXPERIMENTS
MATLAB which offers many speech signal and matrix processing routines was used to develop a CSC prototype. The other methods were implemented in C++. 5.1 Phonetic Symbol Similarity Tree
Using a hierarchical clustering algorithm [Jain and Dubes 1988] with the dis-tance matrix for the 37 phonetic symbols, a hierarchical tree was constructed.
The cluster distance in the clustering algorithm was set to the commonly adopted average link. The 37 phonetic symbol similarity tree results are shown in Figure 3. Generally, the results confirm our general understanding, for ex-ample, each group of { (o), (ou) } , { (j), (q), (x) } considered highly similar. This is in exact agreement with the phonological structure assumed by the standard Taiwan phonetic notation in Figure 1.
However, not all of the arrangement in Figure 1 is based on sound simi-larity. For example, two quite different sounds , (yi) and (wu), are placed in the same group Monopthongs-1, while two similar sounds, (ei) and (  X  e), are in Dipthongs group and Monopthongs-2 group, respectively. In our similarity tree, these four symbols, numbered 22, 23, 28, and 30 are placed in better simi-larity groups. In particular, that (wu) is in the same cluster with (o) and (ou) is quite reasonable since the ending pronunciation of (o) and (ou) is nearly identical to (wu). 5.2 Experimental Data Gathering
We gathered via search engines a total of 200 transliterations translated from 64 unique foreign names. Some of the transliterations are synonymous. The foreign names are drawn from two major types of proper nouns, namely, loca-tions and personal names. For the personal names, our collection can be roughly categorized into several fields based on the general perception of local people in
Taiwan including entertainment, sport, politics, and others. The length of the transliterations ranges from two to five with a count distribution of 29, 83, 59, and 29 respectively, and an average length of 3.45.

A total of 568 synonymous transliteration pairs were established by the com-bination of the 200 transliterations. For a group of n synonymous transliter-ations, n ( n  X  1) transliteration pairs can be formed. The distribution of the categories is shown in Table IV. Most synonymous transliteration pairs have a character length discrepancy of at most 1 and a few have two.

To measure performance of the similarity comparison methods, we com-pute a similarity ranking of each pair of synonymous transliterations against noise datasets. Since we are interested in applying our research results to Web searches in the future, the noise datasets were constructed from Web pages.
We used two noise datasets, one (DIC) consisting of known words and the other (NGT) consisting of N -gram words since known words and N -gram seg-mentations are the two most popular methods for segmenting Chinese words. Each dataset consists of 5,000 words randomly drawn from a collection of 1,000
Chinese pages. In the NGT N -gram dataset, N was set to 2, 3, 4, 5 and 6, to resemble the lengths of most transliterations. 5.3 Evaluation Metrics ity rank of t target to t source against the noise words of the DIC (or NGT) dataset was computed, and finally the measures were calculated using the ranks of all the target transliterations. Specifically, for each pair ( t compared to the set of t target plus 5,000 noise words, and three measures are used including average ranking (AR), average reciprocal rank (ARR), and the top-N inclusion rate defined by (1/ n ) i r i , (1/ n ) i spectively, where n is the total number of synonymous Chinese transliterations pairs; r i represents the rank of t target of the i th pair against the noise data. ARR puts more stress on top ranks. 5.4 Parameter Test
Two parameters are involved in the experiments, including initial-consonant weight w , and normalization methods of aggregated similarity score. We first perform parameter test to determine better settings. 5.4.1 Normalizing the Similarity Score. The string lengths of compared transliterations by CSC are shorter than those by the pinyin-based methods, which translate a Chinese transliteration into a string of English letters. As a result, different normalizations of the similarity score have significant impact on the normalized score and thereby the similarity ranking against noise data.
Three commonly used methods were investigated in our experiments, in-cluding the maximum, the minimum, and the average. The maximum method means the similarity score is normalized by dividing by the maximum length of two compared strings, that is, max ( | string1 | , | string2 malized similarity scores of { (ge er ba qiao fu), (ge ba qi fu) by CSC with the three variants are 0.68, 0.85 and 0.75, and their rankings against the DIC noise data are 2, 6, and 1, respectively. Note that the minimum normalization generates a larger similarity score. However, this does not imply better similarity ranking against noise data because the same minimum nor-malization is also applied to the comparison with noise data and their scores are raised in similar way.

Experimental results in Figure 4 indicate that for CSC the average normal-ization gave the best performance in both the AR and the ARR score against both DIC or NGT. The AR scores of CSC appear in Figure 4 is under w
Other w values generated similar outcomes. For the pinyin methods, the maxi-mum normalization gave better similarity ranking except for IPA for which the maximum and the average gave close performances.
 5.4.2 Determining Weight. In Section 4.2, we mentioned that a weight on the initial consonant of each character in the CSC method might improve com-parison performance of synonymous transliterations. For example, the simi-larity scores of { (hai shan; ), (hu sheng; ) } of former Iraq president Hussein with and without weighting ( w = 0.5) are 0.59 and 0.8, re-spectively. The similarity ranking of the pair with weighting against a noise dataset improves dramatically from 1,463 to 21. Our experimental results in-dicated that the optimal weight is usually between 0.3 to 0.6 for each of the subsets, and 0.4 for the entire dataset. Figure 5 demonstrates the AR scores of
CSC under different initial consonant weightings. 5.5 Comparison Test
We will first compare CSC with the grapheme-based method and then further compare CSC with three phoneme-based methods. The performances are mea-sured on the AR and the ARR score and the top-N inclusion rate. 5.5.1 Grapheme-Based Method. The grapheme-based method compares two transliterations by essentially counting the common subsequence between the two romanized strings. We use the method along with the six pinyin schemes for romanization.

Experimental results for AR and ARR are summarized in Figure 6, which shows the best performance of each method under its favorite parameter set-ting. CSC outperformed the grapheme-based method in the DIC dataset on both measures. For the NGT dataset, CSC performed the best in AR, while the methods with the Mandarin Phonetic Symbols II and the Tongyoung pinyin scheme did slightly better in ARR, indicating those two schemes achieved good rankings in the top portion of the similarity list.

For the top-N inclusion rate, CSC consistently outperformed the method with various pinyin schemes when tested against DIC as shown in Figure 7.
Note that the scale of the x -axis is different. Higher resolution before the top 50 was used for easier comparison. Among the pinyin schemes, Tongyong, Yale, and Mandarin Phonetic Symbols II achieved relatively better results than the others. For the NGT dataset, CSC, Tongyong, Yale, and Mandarin Phonetic Symbols II generally performed better than the other three. Mandarin Phonetic
Symbols II performed the best until the top 5. As indicated in Figure 7, after the top 50 until the top 500, CSC consistently outperformed the pinyin-based approaches. The results are consistent with that shown in the right of Figure 6 where MPS has the best ARR against NGT. Recall that ARR puts more stress on the top ranks. 5.5.2 Phoneme-Based Methods. This section compares CSC with other phoneme-based methods mentioned in Section 4.3. The notation is described as follows. ALINE.XX denotes the ALINE-based method along with the six pinyin schemes in which transliterations are romanized with the XX pinyin scheme and then compared by the ALINE-based algorithm. FSP denotes the method based on Somers X  algorithm [Somers 1998]. LC denotes the method based on the algorithm in Lin and Chen [2000]. LCS denotes the method based on the longest common subsequence (i.e., grapheme) which is used in the previous section. Some results of the previous section are included in Figure 8 for com-parison, including LCS.TY (i.e., LCS with Tongyong), and LCS.HY due to the fact that Tongyong obtained the best performance among the pinyin schemes and Hanyu is popularly used worldwide.
 Generally, CSC performs better than the other approaches as shown in
Figure 8. The ALINE-based approaches come in second place. In particular, the grapheme-based LCS with TY performed better than some phoneme-based methods including FSP and LC. Moreover, when compared to the NGT noise dataset, the ALINE and LCS-based methods performance was comparable to
CSC in ARR. In other words, these methods have about the same performance in the top tier of the ranking. This can be verified from the results of the inclusion rate measure (shown on the right side of Figure 9) where the rates of the top 10 of those approaches are close.

For the inclusion rate, compared against DIC, CSC consistently outperforms the others as shown in Figure 9. In Figure 9, for the sake of clarity, we omit the results for the HY scheme which was outperformed by its TY counterpart. When compared against NGT, CSC outperforms others after the 50th rank.
LCS.TY performs better than ALINE.TY untill the top 50 although ALINE.TY performs overall the second best among the methods. 5.6 Error Analysis The main reason that some synonymous transliterations ranked worse under
CSC is that the target transliteration does not sound very similar to their source counterpart. The top 10 worst-ranking of the target transliterations against the DIC noise dataset under CSC are shown in Table V. For instance, the worst pair { (hou sai yin); (ha shan) } with the converted Taiwan phonetic symbols { ( ); ( ) } does not sound very close. Their similarity score for CSC is 0.54. In fact, the vowels (ou) and (a) are fairly distant in the phonetic similarity tree (Figure 3). Moreover, the length of the transliterations is also a factor. Table VI shows the average lengths of those transliterations ranked the best and the top 50 ranked as the worst. In particular, CSC is more sensitive to the length than the others because the similarity comparision is on the character level instead of the individual phoneme level. For those pairs of short lengths, a small discrepancy exaggerates their ranking. As shown in
Table V, most of the pairs are short. It is worth noting that some of the other approaches might obtain good rankings on those in which CSC did worse such as  X  X ash X  and  X  X isher X , suggesting a future work of designing an ensemble scheme for those approaches to improve the overall rankings.

The pair of { (nai hu), (na shi) } for Nash is particularly worth men-tioning. (hu) and (shi) are both poyin , that is, a character has different pro-nunciations. Other pronunciations include sh  X  u for and she for , which are better translations for the case of Nash. However, to translate thousands of transliterations, an automatic translation is desired. We wrote a program that automatically picked up the first pronunciation from a list of pronunciations of a word from an electronic dictionary. Determining the best-fit pronunciation automatically from the list is possible but not trivial and is not in the scope of this research. Fortunately, the number of poyin cases in the transliterated proper nouns is limited to only a few. 5.7 Analysis on Similarity of Individual Characters
The advantage of CSC comes from its ability in distinguishing the difference between character pronunciations since more discriminative information is con-tained in the sound vectors. We conducted an analysis on the 82,215 distinct sound pairs formed from 406 character sounds (excluding 6 sounds which have no correspondingly meaningful characters). The numbers of distinct similarity scores in those pairs by CSC, ALINE.TY, ALINE.HY, FSP.TY, FSP.HY, LCS.TY,
LCS.HY and LC are 52,230, 680, 659, 256, 167, 13, 13 and 30, respectively. In other words, one score by ALINE.TY, the best other than CSC, is mapped to an average 121 sound pairs, while that of CSC, is mapped to only 1.6 pairs.
Table VII shows the AR and ARR of 80 similar and dissimilar sound pairs (e.g., { (ha), (hai) } and { (yin), (bo) } ) drawn from synonymous and nonsynony-mous transliteration pairs, respectively. CSC with an initial consonant weight w = 0.4 or w = 0.5 ranked the similar pairs better than ALINE.TY and ALINE.HY. Note that the rank of a pair by the methods other than CSC would have on average a difference of several hundreds to even several thousands depending on whether the pair was ranked at the top or the bottom in the equivalent group in which the pairs have the same similarity score. This im-plies that the others have less discriminative ability than CSC. 6. CONCLUSIONS
We tackle the problem of transliteration comparison by the use of a method based on physical sound comparison which has several advantages, including requiring neither a training corpus nor manual alignment of cognates. This method is compared, via various measures including top-N inclusion rates, av-erage ranking, and average reciprocal ranking, with four other methods on the performance of identifying synonyms against known-word and N -gram noise data. The experimental results indicate that the method based on comparing physical sounds performs mostly better or comparable depending on noise data and measures used. The advantage of the sound comparison-based method comes from its ability to distinguish the difference between character pronun-ciations since more discriminative information of phones is contained in the sound vectors. ALINE-based approaches come in second place for a similar rea-son, that is, more deliberate considerations on utilizing articulatory features, including using multivalued features and placing different weights on the fea-tures. Among the six pinyin schemes, the method with the Tongyong scheme outperforms the same method with other pinyin schemes. Parameters signifi-cantly impact the performance of the physical sound comparison method. Better performances can be gained when the initial consonant weight is set to 0.4 or 0.5 and the similarity score of two compared transliterations is normalized by their average length. Moreover, that some methods performed well on translit-eration pairs in which the other methods gave bad ranking suggests future work of devising an ensemble scheme for improving allover performance. The authors would like to thank the reviewers for their insightful suggestions.
