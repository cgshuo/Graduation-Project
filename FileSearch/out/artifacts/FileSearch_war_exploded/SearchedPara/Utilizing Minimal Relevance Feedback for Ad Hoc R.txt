 Using relevance feedback can significantly improve (ad hoc) retrieval effectiveness. Yet, if little feedback is available, ef-fectively exploiting it is a challenge. To that end, we present a novel approach that utilizes document passages . Empirical evaluation demonstrates the merits of the approach.
The effectiveness of ad hoc (query-based) retrieval can sig-nificantly improve if relevance feedback is available and ex-ploited. Often, terms that are common in the relevant docu-ments  X  but not very common in the corpus  X  are used for query expansion [7]. Since a document can be deemed rele-vant even if only a small part of it contains query-pertaining information, utilizing the commonalities between relevant documents is important. Indeed, using very few relevant documents, which reflects practical settings wherein rele-vance judgments are scarce, can sometimes fall short [8].
We present a novel retrieval method that addresses the challenge of utilizing very little relevance feedback; specifi-cally, a single relevant document. This is a query-by-example task performed in a query-dependent context. We tackle the uncertainty about what makes the document relevant, and more specifically, which terms can represent the underlying information need, by using document passages in two capac-ities. First, rather than treat the relevant document as one unit, its passages are used so as to better focus on the doc-ument parts that presumably contain query-pertaining in-formation. Second, to enrich the basis for performing query expansion, passages from documents in an initially retrieved list that are similar to the relevant document (and to its passages) are used as pseudo relevant units. Empirical eval-uation demonstrates the merits of our method with respect to various reference comparisons.
Suppose that some search algorithm is employed in re-sponse to query q so as to rank documents d in corpus D by their presumed relevance to information need I expressed by q .Let D init denote the list of documents that are the highest ranked by the induced initial ranking ( initial in short), and d rel denote the highest ranked relevant document in D init
Naturally, we can employ a relevance-feedback-based ( RF ) method using q and d rel to create an expanded query form [7]. Since only a single relevant document is available, we opt to enrich the basis for creating this form; e.g., by employing a pseudo-feedback-based ( PRF ) approach that regards all documents in D init as pseudo relevant. Indeed, recent work [6, 10] has demonstrated the potential merits of integrating true and pseudo relevance feedback ( RF+PRF ).

A potential drawback of such approaches is that they often treat a document as one unit. For example, it could be that all the information in the relevant document d rel that pertains to I is confined to a single short passage g of d Moreover, the terms in g need not be the most dominant (e.g., frequent) in d rel , and hence, might not be assigned with high enough weight by the relevance-feedback-based method. The same observations hold for documents in D init { d rel } for which no (positive) feedback is available. Thus, we use the passages in documents in D init (the set of which is denoted G ) as pseudo relevant units for performing query expansion. To that end, we estimate p ( g | I ), the probability that passage g (  X  G ) contains information pertaining to I .
As q and d rel are the only  X  X ignals X  about I ,weestimate ter. Assuming a uniform prior for passages, we can score P The goal of using this estimate is addressing the potential vocabulary mismatch between passage g (which could be part of d rel )thatpertainsto I and q by using d rel  X  X  pas-sages ( g )asproxiesfor g ; the impact of g is based on its  X  X irect match X  with q , which potentially reflects to some ex-tent the likelihood that g contains information pertaining to I as it is part of d rel . 1 Using the estimates just described results in our PsgF method that scores g (  X  G )by: S ( g ) def =  X p ( d rel The highest scoring passages are used for query expansion.
Inter-passage relations were also utilized, for example, for text summarization [3], finding documents similar to a given document [9], and re-ranking search results [4].
Experiments were conducted with TREC corpora (disks, queries): AP (1-3, 51-150), TREC8 (4-5, 401-450), WSJ (1-2, 151-200), WT10G (WT10G, 451-550). Titles of TREC topics served for queries. Tokenization, Porter stemming and language model induction were performed using the Lemur toolkit (www.lemurproject.org). Half overlapping 150-terms windows in documents serve for passages [4].
We use exp in Equation 1; D is the KL divergence; p Dir [  X  ] z ( Dirichlet-smoothed unigram language model induced from z with smoothing parameter  X  .

The initial list, D init , is set to the 50 highest ranked docu-ments d in the corpus by p ( q | d )with  X  set to optimize MAP (at 1000) so as to have an initial list of reasonable quality.
We use relevance model number 3 (RM3) [1] as a query expansion method that assigns the probability  X p JM [0] q (1  X   X  ) or documents; p JM [  X  ] x (  X  ) is the Jelinek-Mercer smoothed lan-guage model induced from x with smoothing parameter  X  ;  X  is a free parameter; and, W ( x )is x  X  X  weight ( 1). Methods that use d rel assign it with either a weight 1 (RF) or  X  (RF+PRF), which is a free parameter; in the lat-ter case, the weight (1  X   X  ) is distributed among the pseudo-relevant documents. For any method, except PsgF, that uses pseudo-relevant units f (  X  F  X  X ), p ( q | f ) P as f  X  X  relative weight; for PsgF the (normalized) scores as-signed in Equation 1 are used. The set X in RM3 is set to (i) d rel for RF, (ii) k highest ranked documents in D init PRF, (iii) d rel and the k  X  1 highest ranked documents d in D init ( d = d rel ) for RF+PRF, and (iv) the k highest ranked passages by Equation 1 for PsgF.
 We use two additional passage-based baselines that utilize RM3. TopPDrel sets X def = { g  X  } ( W ( g  X  ) def =1); g passage with the highest p ( q | g )[2]. AllPDrel uses all d passages ( X def = { g | g  X  d rel } ) as pseudo relevant units.
For evaluation, d rel is not considered (i.e., the residual corpus approach is employed); MAP(@1000) and p@5 are reported. The two-tailed paired t-test (95% confidence level) serves for determining statistically significant differences.
The following free-parameter-values X  ranges are used:  X  = 2000 except in p Dir [  X  ] d ( q ) where we use the value used to cre-ate D init to maintain consistency with the initial ranking; k  X  X  5 , 10 , 20 , 30 , 40 , 50 } ;  X   X  X  0 , 0 . 1 ,..., 1 } 0 . 8 } ; the number of terms used by RM3 is set to { 25 , 50 , 75 , 100 , 500 , 1000 , 5000 ,ALL } ( X  X LL X : all terms in the vocab-ulary);  X   X  X  0 , 0 . 1 , 0 . 3 , 0 . 5 , 0 . 7 , 0 . 9 } ;  X  T o give the  X  X est chance X  to the reference comparisons RF, PRF, TopPDrel and AllPDrel, their free-parameter values are set to optimize MAP over all queries per corpus. For RF+PRF and PsgF, RM3 X  X  parameters are set to the val-ues used by RF and AllPDrel, respectively; the other free parameters are set using leave-one-out cross validation per-formed over queries (MAP is the optimization criterion). Results, conclusions, and future work . Table 1 shows that all methods outperform the initial ranking used to cre-ate D init . (Most of these improvements are statistically sig-nificant; hence, they are not marked to avoid cluttering.) The MAP performance of our PsgF method is superior (of-ten, statistically significantly so) for most corpora to that of the reference comparisons. Specifically, PsgF always MAP-Table 1: Performance numbers;  X  X  X ,  X  X  X ,  X + X ,  X  X  X  and  X  X  X  mark statistically significant differences with RF, PRF, RF+PRF, TopPDrel and AllPDrel respec-tively. The best result in a column is boldfaced. outperforms RF (often, statistically significantly), which is the standard approach of using d rel as a whole unit. PsgF also outperforms RF+PRF in most relevant comparisons. As both methods integrate true and pseudo feedback, we see that using passages (by PsgF as opposed to RF+PRF) is of merit. We also see that TopPDrel is often inferior to AllP-Drel and PsgF, which suggests that using several (weighted) passages rather than a single one is beneficial. Finally, ex-cept for WT10G, PsgF is MAP-superior to AllPDrel and posts more statistically significant MAP improvements over the other methods than AllPDrel does. This implies that using passages not in, as well as in, d rel can be more effec-tive than using just those in d rel . However, in terms of p@5, PsgF is often outperformed by AllPDrel. Thus, integrat-ing these two methods, along with utilizing term-proximity models [6, 5], is an interesting future venue.
 Acknowledgments This paper is based upon work sup-ported in part by the ISF under grant no . 557/09, and by IBM X  X  SUR award. Any opinions, findings and conclusions or recommendations expressed here are the authors X  and do not necessarily reflect those of the sponsors.
