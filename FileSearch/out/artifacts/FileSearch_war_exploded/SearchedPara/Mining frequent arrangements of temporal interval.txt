 Panagiotis Papapetrou  X  George Kollios  X  Stan Sclaroff  X  Dimitrios Gunopulos Abstract The problem of discovering frequent arrangements of temporal intervals is occurs during a time-interval. The goal is to mine temporal arrangements of event intervals that appear frequently in the database. The motivation of this work is the observation that in practice most events are not instantaneous but occur over a period of time and different events may occur concurrently. Thus, there are many practical applications that require mining such temporal correlations between intervals including the linguistic analysis of annotated data from American Sign Language as well as network and biological data. Three efficient methods to find frequent arrangements of temporal intervals are described; the first two are tree-based and use breadth and depth first search to mine the set of frequent arrangements, whereas the third one is prefix-based. The above methods apply efficient pruning techniques that include a set of constraints that add user-controlled focus into the mining process. Moreover, based on the extracted patterns a standard method for mining association rules is employed that applies different interestingness measures to evaluate the significance of the discovered pat-terns and rules. The performance of the proposed algorithms is evaluated and compared with other approaches on real (American Sign Language annotations and network data) and large synthetic datasets.
 Keywords Sequential pattern mining  X  Data mining  X  Temporal mining  X  Arrangement mining  X  Constraint-based mining  X  Arrangement rule mining  X  American sign language 1 Introduction instantaneous events which satisfy some user-specified constraints. These constraints can vary from just a support threshold, that defines frequency, to a set of gap, window [ 59 , 74 ], or regular expression constraints [ 18 ], that apply more user-controlled focus into the mining process. Despite advances in this area, nearly all proposed algorithms concentrate on the case where events occur at single time instants. However, in many applications events are not instantaneous; they instead occur over a time interval. Furthermore, since different temporal events may occur concurrently, it would be useful to extract frequent temporal patterns of these events. In this paper the goal is to develop methods that discover temporal arrangements of correlated event intervals which occur frequently in a database.

There are many applications that require mining such temporal relations. One potential application is for analysis of the multiple gestures that occur, in parallel, on the hands and on the face and upper body, to express linguistic information. In signed languages, lexical information is expressed primarily through movements of the hands and arms, whereas crit-ical grammatical information is expressed non-manually, through such behaviors as raised or lowered eyebrows, modifications in eye aperture or gaze, repeated head gestures (nods, shakes) or head tilt, as well as expressions of the nose or mouth. For example, the canoni-cal marking of a wh-question (a question containing a word such as  X  X ho X ,  X  X hat X ,  X  X hen X ,  X  X here X , or  X  X hy X ) includes lowered brows slightly squinted eyes occurring over a predictable domain (either the question sign or the whole clause constituting the question), and there is frequently a slight rapid head-shake co-occurring with the wh-phrase [ 47 ]. An example of a wh-phrase is shown in Fig. 1 . Although much is known about the linguistic significance of certain non-manual markings carrying critical syntactic information, there are others whose functions remain to be studied and more fully understood. Pattern detection could ultimately contribute to discovery of the significance of some of these non-manual behaviors. The anno-tated ASL corpus used for this research was produced by linguists as part of the American Sign Language Linguistic Research Project [ 45  X  47 ] using SignStream(TM) [ 43 , 48 ]. The annotations identify start and end times for: the manual ASL signs (represented by English-based glosses), part of speech for those signs, plus grammatical interpretive labels indicating clusters of non-manual expressions that serve to mark particular syntactic functions (such as wh-questions, negation, etc.) as well as the gestures themselves (e.g., raised eyebrows, conventions that were used.

Another application is in network monitoring, where the goal is to analyze packet and router logs. Consider Fig. 2 for example, which shows two groups of machines communicating with each other via two routers. In this case an event label is the source or destination IP and the event interval corresponds to the duration of the communication between the two machines. Multiple types of events occurring over certain time periods can be stored in a log, and the goal is to detect general temporal relations of these events that with high probability would describe regular patterns in the network, that could be used for prediction and intrusion detection.
 Moreover, interval-based events can be identified in the human gene. More specifically, DNA is a sequence of items (nucleotides) defined over a four-letter alphabet, i.e., = {
A , C , G , T } . Regions of high occurrence of a nucleotide or combination of nucleotides, known as poly-regions , can be defined over DNA. The detection of frequently overlapping evolution of different genes and their contribution to protein construction. To the best of our knowledge, the first approach to mine frequent arrangements of poly-regions in DNA is discussed in [ 51 ].

Most existing sequential pattern mining methods are hampered by the fact that they can only handle instantaneous events, not event intervals. Nonetheless, such algorithms could be retrofitted for the purpose, via converting a database of event intervals to a transactional database, by considering only the start and end points of every event interval. An existing sequential pattern mining algorithm could be applied to the converted database, and the extracted patterns could be post-processed to produce the desired set of frequent arrange-ments. However, an arrangement of k intervals corresponds to a sequence of length 2 k . Hence, this approach will produce up to 2 2 k different sequential patterns. Moreover, post-processing will also be costly, since the extracted patterns consist of event start and end points, and for each event interval all the relations with the other event intervals must be determined. There-fore, it is essential to develop interval-based algorithms that can efficiently mine frequent patterns and rules from interval-based data.

The main contributions in this paper include:  X  a robust definition of temporal relations between two event intervals that is noise tolerant  X  a formal definition for the problem of mining frequent temporal arrangements and  X  a prefix-based approach and an efficient algorithm for mining frequent arrangements of  X  a further improvement of the mining process with the incorporation of temporal con- X  an efficient algorithm for mining arrangement rules from the extracted patterns based on  X  an extensive experimental evaluation of these techniques and a comparison with a stan-2 Background Some basic definitions on temporal logic are presented, followed by a sufficient background on interestingness measures for association rules and finally the problem formulation. 2.1 Ambiguity issues Most existing interval-based mining algorithms use Allen X  X  scheme [ 6 ] to describe relations between event intervals. Figure 3 shows the twelve main types of relations between two event intervals A and B studied in [ 6 ]: before/after, meets/met by, overlaps/overlapped by, starts/started by, during/contains, finishes/finished by . Because of the limit in the accuracy of demarcating the temporary boundaries of events, there can be variability in these boundaries caused by noisy data. Unfortunately, Allen X  X  relations are hampered by the fact that they cannot capture this variability and thus the representation of a relation might have more than one meaning. This issue has also been addressed in [ 41 ] and is illustrated in Fig. 4 . Consider, for instance, the case where the actual relation between two event intervals is Meets , but due to noise it appears as O v er laps (Fig. 4 a) or After (Fig. 4 b). Similarly, the relation between two concurrent events could appear as O v er laps (Fig. 4 c) or Contains (Fig. 4 d), and also, a Starts or Finishes could show up as Contains (Fig. 4 e, f). Such errors can occur due to noisy data and may have a negative influence on the extracted patterns.

In this paper we extend Allen X  X  relations to a more robust scheme that introduces a thresh-old to achieve relaxation on the boundaries of the relations and eliminates the aforementioned ambiguities. 2.2 Event interval temporal relations Seven types of temporal relations between two event intervals are considered. Using these relations, general arrangements can be defined. However, the methods presented in this paper are not limited to these relations and can be easily extended to include more types of temporal relations.

Consider two event-intervals A and B , and assume that the user specifies a threshold to define more flexible matchings between two time intervals. The following relations can be defined (see also Fig. 5 ):  X  Meet( A , B ): B follows A , with B starting at the time A terminates, i.e., t e ( A ) =  X  Match( A , B ): A and B are parallel, beginning and ending at the same time, i.e., t s ( A ) =  X  Overlap( A , B ): the start time of B occurs after the start time of A ,and A terminates after  X  Left-Contain( A , B ): A and B start at the same time and A terminates after B , i.e.,  X  Right-Contain( A , B ): A and B end at the same time and the start time of A precedes  X  Contain( A , B ): the start time of B follows the start time of A and the termination of A 2.3 Robustness By adding to our interval relations definition all the aforementioned relations are mutually exclusive and at the same time noisy intervals can be handled efficiently. In some applica-tions, however, the user may not want to consider some of the above relations as mutually exclusive. Table 1 shows how these relations cannot be mutually exclusive. For example, a match could also be counted as a left-contain , right-contain , contain and/or overlap . Also, a left-contain or right-contain could be counted as a contain or an overlap as well. Finally, a meet could also be counted as a follow or overlap . Thus, depending on the application, a user might desire to: (1) collapse some relations, e.g., count left-contain and right-contain as contain , or count each meet as follow , etc., (2) count them multiple times, e.g., each overlap is also counted as left-contain and right-contain , or each match is also counted as contain , or each meet is also counted as follow ,etc.

Thus, the user has flexibility with respect to which of these options get chosen and clearly it would be application specific. 2.4 Arrangements and arrangement rules event start time and t i end is the end time. The event intervals are ordered by the start time. If k-e-sequence . For example, let us consider the 5-e-sequence shown in Fig. 6 . In this case e-sequences.
In an e-sequence database there may be patterns of temporally correlated events; such patterns are called arrangements . The definitions given in Sect. 2.2 can describe temporal relations between two event intervals but they are insufficient for relations between more than two. Consider for example the two cases in Fig. 7 .Case ( a ) can be easily expressed using the current notation as: A | B  X  C . This is sufficient to determine that A overlaps with B , C insufficient, since it gives no information about the relation between A and C .Thus,weneed to add one more operand to express this relation concisely. In order to define an arrangement of more than two events we need to clearly specify the temporal relations between every pair of its events. This can be done by using the  X  X ND X  operand denoted by . Therefore, the above example can be expressed as follows: A | B A | C B &gt; C . Based on the previous analysis, the relations between interval-based events handled in this paper can be expressed using the set of operands: R ={| , || ,&gt;, | &gt;, &gt; | ,  X  ,  X  X  and .

Consequently, an arrangement A of n events is defined as A = { E , R } ,where E is the set of R ( the temporal relation between E i and E j . The size of an arrangement A = { E , R } is | E | .An arrangement of size t is called a t -arrangement . For example, consider arrangement S of size 3 shown in Fig. 7 a. In this case E ={ A , B , C } and R ={ R ( A , B ) =| , R ( A , C ) = X  , R (
B , C ) = X  X  . Given an arrangement A ={ E , R } ,a sub-arrangement A j is an arrangement defined from A as A j ={ E j , R j } ,where E j  X  E and R j  X  R . Notice that R j includes all the relations between the event labels in E j that also exist in R .The absolute support of an arrangement in an e-sequence database is the number of e-sequences in the database that contain the arrangement. The relative support of an arrangement is the percentage of e-sequences in the database that contain the arrangement. Given an e-sequence s , s contains an arrangement A ={ E , R } , if all the events in A also appear in s with the same relations between them, as defined in R . Consider again arrangement S in Fig. 7 a and e-sequence s in Fig. 6 . We can see that all the event intervals in S appear in s and further, they are similarly correlated, i.e., Overlap ( A , B ), Follow ( B , C ), Follow ( A , C ). Thus, S is contained in or supported by s . Given a minimum support threshold min _ sup , an arrangement is frequent in an e-sequence database, if it occurs in at least min _ sup e-sequences in the database.
Based on previous work on itemset and sequence association rules [ 3 , 22 , 59 ], associa-tion rules for arrangements can be defined. Given two arrangements A i and A j that have been mined from an e-sequence database D , r : A i  X  R ij  X , D A j defines an arrangement rule between A i and A j , based on an interestingness measure  X  . Consider an arrangement A E and E j , whereas R i and R j are defined based on R , and describe the temporal relations between the event intervals in E i and E j respectively. Also, R ij defines the set of relations of the event labels E i with those in E j . 2.5 Interestingness measures The use of interestingness measures, also known as quantitative measures, plays a very important role in the interpretation of the discovered arrangement rules. Many interesting-ness measures have been proposed and studied [ 24 , 30 , 62 ], each of them capturing different characteristics. In this section we give a brief overview of the most common quantitative measures and show how they can be used for mining arrangement rules.

Given a rule A  X  R AB  X , D B , two significant properties of interestingness measures are: monotonicity and anti-monotonicity [ 3 ]: 1. Monotonicity of an interestingness measure  X  : An interestingness measure  X  is mono-2. Anti-monotonicity of an interestingness measure  X  : An interestingness measure  X  is
Given an arrangement rule: r : A  X  R AB  X , D B ,wedefine co v er ( A ) to be the number of e-sequences in D that contain arrangement A over the size of the e-sequence database D , and co v er age ( r ) to be the cover of the antecedent arrangement A .Inthispaper,wefocus on two anti-monotone interestingness measures: (1) support (both for an arrangement and an arrangement rule), (2) all-confidence, and four non anti-monotone: (1) confidence, (2) leverage, (3) lift, and (4) conviction. 2.5.1 Anti-monotone interestingness measures Next, the definitions of two anti-monotone measures are given with respect to an arrangement A and an event interval database D . Due to the anti-monotonicity property, these measures can be applied on each node and can be used for efficient pruning. Thus given two arrangements A and B , and an arrangement rule r : A  X  R AB  X , D B :  X  supp ( A ) = co v er ( A )  X  supp ( r ) = co v er ( A  X  B )  X  all -con f i dence ( A ) = supp 2.5.2 Non anti-monotone interestingness measures There has been a great number of interestingness measures proposed and studied, that are not anti monotone. In this paper we consider four of them. Next, we give their definitions with respect to an arrangement rule r implied from an arrangement A that has been mined from an event interval database D . Note, that since these measures are not anti-monotone, they cannot be used for early pruning during the mining process. Thus, given an arrangement rule r : A  X  R AB  X , D B ,wehave:  X  con f i dence ( r ) = supp ( r )  X  le v er age ( r ) = supp ( r )  X  supp ( A )  X  supp ( B )  X  li f t ( r ) = supp ( r )  X  con v iction ( r ) = 1  X  supp ( B ) 2.6 Temporal constraints Frequency does not always imply interestingness. A pattern can occur frequently in the database but may not hold interesting information to every user. In addition to the support threshold, the user can also specify a set of temporal constraints C T including:  X  A gap constraint C g : two event intervals that take part in a follow relation should be  X  A pair of overlap constraints C o ={ C l  X  A pair of contain constraints C ct ={ C l  X  A duration constraint C d : each event interval should have a duration of at most C d
The set of constraints C T is applied during the frequent arrangement extraction. 2.7 Problem formulation Based on the above definitions we can now formulate the problem of constraint-based mining of frequent arrangements of temporal intervals as follows: Problem I Given an e-sequence database D , a set of temporal constraints C T , and a support threshold min _ sup , our task is to find set F ={ A 1 , A 2 ,..., A n } ,where A i is a frequent arrangement in D and satisfies the constraints in C T .

We can further extend the previous formulation to extract arrangement rules given an interestingness measure  X  . Incorporating interestingness measures and the aforementioned constraints we can formulate the problem of constraint-based mining of the top-K interesting association rules as follows: Problem II Given a set { D , C T , X , K , min _ sup } ,where D is an e-sequence database, C T is a set of constraints,  X  is an interestingness measure, K is an integer and min _ sup is the minimum support threshold that implies frequency, we want to mine the top K frequent arrangement rules that satisfy C T and maximize  X  . 3 Related work In this Section, we present the existing work on sequential and temporal pattern mining along with a brief overview of the existing interestingness measures that can be applied during the mining process. 3.1 Sequential pattern mining The first family of sequential pattern mining algorithms are the Apriori-based algorithms and their main characteristic is that they apply the Apriori principle [ 3 ]. The problem of sequential pattern mining was introduced in [ 4 ], along with three Apriori-based algorithms (AprioriAll, AprioriSome and DynamicSome). At each step k , a set of candidate frequent sequences C k of size k is generated by performing a self-join on F k  X  1 .Noticethat F k con-tains all those sequences in C k of size k that satisfy a user-specified support threshold. The efficiency of support counting is improved by employing a hash-tree structure. A more effi-cient approach, Generalized Sequential Patterns (GSP), was developed in [ 59 ], where time and window constraints are pushed into the mining process. At the same time, Mannila et al. [ 40 ] introduced the idea of mining frequent episodes, i.e., frequent sequential patterns in a single long input sequence, using a sliding window to cut the input sequence into smaller segments, and employing a mining algorithm similar to that of Apriori. Notice, however, that in our formulation we focus on finding frequent patterns across a set of input sequences (that constitute a sequence database) and not across a single sequence.

Discovering all frequent sequential patterns in large databases is a very challenging task since the search space is large. Consider for instance the case of a database with m attributes. If we are interested in finding all the frequent sequences of length k ,thereareO( m k ) poten-tially frequent ones. Increasing the number of objects might definitely lead to a paramount computational cost. Apriori-based algorithms employ a bottom-up search, enumerating every single frequent sequence. This implies that in order to produce a frequent sequence of length tial complexity is limiting all the Apriori-based algorithms to discover only short patterns. A faster and more efficient candidate generation can be achieved using a tree-like structure ( set-enumeration tree )[ 10 ] and traversing it in a depth-first search manner to enumerate all the candidate patterns applying efficient pruning techniques. The idea was initially introduced for mining frequent itemsets, but was extended for sequential patterns. SPAM [ 7 ], employs a sequence enumeration tree to generate all the candidate frequent sequences given the set of event labels. The root node of the tree is empty, and each level l contains the complete set of sequences of size l (with each node representing one sequence) that can occur in the database. The nodes of each level are generated from the nodes of the previous level and all candidate sequences are enumerated by traversing the tree using depth-first search. For efficient support counting, a bitmap representation of the database is used.

Another family of sequential pattern mining algorithms employ a lattice structure [ 16 ] for efficient sequence enumeration. The main characteristics of SPADE [ 72 ] include: (1) a vertical representation of the database using id-lists , where each pattern is associated with a list of database sequences in which it occurs; all frequent sequences can be enumerated via temporal joins on the id-lists, (2) a lattice-based approach to decompose the original search space into smaller subspaces, which can be processed independently in main memory, (3) within each sub-lattice, two different search strategies (breadth-first and depth-first search) are used for enumerating the frequent sequences. An extension of SPADE, cSPADE [ 74 ], allowed a set of constraints to be placed on the mined sequences. GO-SPADE [ 32 ] introduced the idea of generalized occurrences . The intuition behind GO-SPADE is that in a sequence database certain items can occur in a consecutive way, i.e., they may appear in consecutive itemsets in the same sequence. To reduce the cost of the mining process, GO-SPADE mainly tries to compact all these consecutive occurrences. Another class of sequential pattern mining algorithms includes the prefix-based ones [ 55 , 65 , 71 ]. In this case, the database is projected with respect to a frequent prefix sequence and based on the outcome of the projection, new frequent prefixes are identified and used for further projections until the support threshold mining. The tree captures the content of the original database and can efficiently update itself when there is a change in the database content (insertions, deletions, updates).

Ignoring slight differences in the problem definition, the vast majority of the former algo-rithms aim at the discovery of frequent sequential patterns based on only a support threshold, which imposes a lack of user-controlled focus on the shape of the pattern during the mining process that may sometimes lead to an overwhelming volume of potentially useless patterns. The family of SPIRIT algorithms [ 18 ] solves this problem by pushing a set of syntactic constraints into the mining process along with a support threshold.

Further studies and works have presented convincing arguments that only closed frequent sequences should be mined targeting more compact results and higher efficiency [ 53 , 54 , 65 , 71 , 73 ]. Two of the most efficient algorithms for mining frequent closed sequences BIDE [ 65 ] and CloSpan [ 71 ] are based on the notion of the projected database and use special techniques to limit the number of frequent sequences and finally only keep the closed ones. CloSpan follows the candidate maintenance-and-test approach, i.e., it first generates a set of closed sequence candidates which is stored in a hash-indexed tree structure and then prunes the search space using Common Prefix and Backward Sub-Pattern pruning [ 71 ]. The main drawback of CloSpan is the fact that it consumes much memory when there are many closed frequent sequences, since pattern closure checking leads to a huge search space; thus, it does not scale very well with respect to the number of closed sequences. In order to face this weakness, BIDE employs a BI-Directional Extension paradigm for mining closed sequences, where a forward directional extension is used to grow the prefix patterns and check their clo-sure and a backward directional extension is used to both check the closure of a prefix pattern and prune the search space. In overall, it has been shown that BIDE has surprisingly high efficiency, regarding speed (an order of magnitude faster than CloSpan) and scalability with respect to database size. Recently, an efficient algorithm for mining maximal sequences has been developed [ 38 ]. This algorithm applies both downward and upward closure properties as well as sampling to achieve faster and more efficient pruning. Last but not least, in ConSGap-Miner [ 28 ] a prefix-based framework is employed and a set of gap and length constraints are applied during the mining process for efficient pruning. The algorithm targets patterns that occur frequently in one class of sequences and are infrequent in sequences of other classes. 3.2 Temporal mining and association rules several approaches on discovering intervals that occur frequently in a transactional database [ 35 , 36 ]. In most cases, however, the intervals are unlabelled and no relations between them are considered. Villafane et al. [ 64 ] extends the sequential approach by also including the contain relation introduced previously. To efficiently mine the arrangements, it employs a containment graph representation that imposes a partial order on the event intervals. In [ 19 ] temporally annotated sequential patterns are considered: these are mainly sequential patterns where each transition from one event to another has a time duration. A graph-based approach is presented in [ 27 ], where each temporal pattern is represented by a graph. In this case however, only two types of relations are considered ( follow and overlap ).

Extending earlier work on mining frequent episodes in a single sequence of events [ 39 , 40 ], there have been various approaches that consider interval-based events. In [ 31 ], a generalized interval-based framework is proposed along with improved support counting techniques for mining interval-based episodes. Correlations between the interval-based events or any pos-sible association rules, however, are not being considered. Hoeppner [ 25 ], Hoeppner and Klawonn [ 26 ], and Mooney and Roddick [ 42 ] employ apriori-based techniques to find tem-poral patterns that occur frequently in the input event sequence. Along with the frequent patterns, they extract association rules and the latest applies some interestingness measures to evaluate their significance. These measures, however, are not pushed into the mining process; they are applied to the set of frequent patterns after the mining process has been completed. Another approach that considers sequences of interval-based events in a database is discussed in [ 29 ]. However, the framework used to represent arrangements is limited to certain forms; thus the method is limited to discover certain patterns. A recent BFS-based approach [ 68 ] introduces a maximum gap time constraint that can be used to eliminate insignificant pat-terns. It also employs a straightforward strategy for discovering arrangement rules based on a minimum confidence threshold. The rules are extracted after the completion of the mining process and the only interestingness measure applied is the minimum confidence threshold. No further constraints are employed and there is no generalization of the arrangement rule extraction.

Notice that the aforementioned approaches are Apriori-based and do not consider any temporal or structural constraints for the extracted arrangements. Furthermore, the event interval relations used are not robust and cannot efficiently handle noisy data, i.e., noise at the start and end-points of the intervals. To the best of our knowledge, the first tree-based approach was proposed in [ 52 ], where a tree-like structure was used to enumerate the set of arrangements and efficiently mine the frequent ones. In [ 69 ], a non-ambiguous event-interval representation is defined that considers the start and end points of each e-sequence and converts the interval-based representation to a sequential representation. Based on this conversion, a prefix-based algorithm is developed that is similar to [ 55 ]. The problem of this approach is that it cannot scale well as the database size increases, since the proposed representation doubles the size of the database; as a result the number of extracted patterns will be increased in a similar manner as described in Sect. 1 .

In the interim, there has been significant work on discovering association rules on sequen-tial and temporal data. Association rules among items that belong to a frequent itemset are defined in [ 3 , 59 ]. Similar definitions are given in [ 22 ] for sequence association rules, and in [ 25 , 26 ] for association rules among interval-based events. In the above works, the evalu-ation of the rules is achieved by the usage of interestingness measures. The most common ones (introduced in [ 3 ]) are support and confidence . Using a non Apriori-based technique that avoids multiple database scans, Winarko and Roddick [ 17 ] achieved to efficiently mine arrangements and rules in a temporal database. These methods, however, do not consider any constraints for the temporal relations and do not examine any measures for their rules other than the commonly used confidence. Temporal association rules combine traditional association rules with temporal aspects by using time stamps that describe the validity, period-icity, or change of an association. Oezden et al. [ 49 ] studies the problem of mining association rules that hold only during certain cyclic time intervals. It is argued that reducing the temporal granularity can lead to the extraction of more interesting rules. In a same fashion, Chen and Petrounias [ 14 ], and Abraham and Roddick [ 1 ] consider the discovery of association rules in temporal databases and thus the extraction of temporal features of associated items. The support of the rules is measured only during these intervals. Moreover, in [ 5 ], the lifetime of an item is defined as the time between the first and the last occurrence and the temporal support is calculated with respect to this interval. In this way, the extracted rules are only active during a certain time, and outdated rules can be pruned by the user. Finally, Lu et al. [ 37 ] studies inter-transaction association rules by merging all itemsets within a sliding time window inside a transaction, whereas in [ 63 ] efficient techniques for mining spatiotemporal patterns are proposed. 3.3 Interestingness measures There has been a variety of studies on other interestingness measures [ 61 ] that provide more accurate results by removing redundancy and limiting the number of extracted rules to the most interesting ones. Omiecinski [ 50 ] proposes alternative association rule measures for evaluating the importance of association rules in transactional databases, whereas [ 30 ]intro-duces some efficient techniques for evaluating the interestingness of rules. An alternative definition of confidence for error-tolerant itemsets and continuous data is described in [ 60 ]. Hilderman and Hamilton [ 23 ] carried out a survey on the existing interestingness measures and their significance in association rule mining. In [ 24 ], a study on the performance of different association rule measures is presented, where different measures are being used to rank the extracted rules and determine the appropriate measure for each dataset. Moreover, properties that determine an effective rule measure. Webb [ 66 ] proposed generic techniques that provide effective control over the mining process and restrict the number of insignifi-cant rules. Finally, in [ 70 ] the mining process is guided by the user X  X  interactive feedback; a user-specific interestingness measure is employed, which consists of a ranking function and a model of prior knowledge that has been defined by the user. Finally, there has been some work on constraint-based mining of frequent itemsets, where the goal is to mine the top K patterns that maximize an interestingness measure (other than the typical support threshold) and satisfy a set of constraints [ 67 ].

Despite all the aforementioned studies there has been yet no approach that considers interestingness measures on interval-based rules other than the traditional support and confidence.

To recap, there have been various approaches on mining frequent arrangements of tem-poral intervals; most of them, however, are Apriori-based, in some cases [ 29 ] the extracted patterns are limited to certain forms, and no constraints are considered. Furthermore, in most cases the extraction of arrangement rules is performed after the detection of the frequent patterns and no attempt has been made to push it into the mining process. Also, no other measure is used, except for the traditional support and confidence, to evaluate the interest-ingness of each rule. Current algorithms target all rules that satisfy the desired measures and do not incorporate any constraints regarding the form of each rule. In this work, we present a constrained-based approach that employs a  X  X ree-like X  structure to mine frequent arrange-ments of temporal intervals. Furthermore, the problem of extracting arrangement rules is being considered, and in our case, efficient pruning techniques are applied and the notion of arrangement rules is generalized by including constraints and other interestingness measures except for the traditional support and confidence. 4 Algorithms A straightforward approach to mine frequent patterns from a database of e-sequences D is to reduce the problem to a sequential pattern mining problem by converting D to a transactional database D . Without any loss of information, we can keep only the start and end time of event e i starting at t s and ending at t e ,weonlykeep t s and t e in D . Now, we can apply an efficient existing sequential pattern mining algorithm, e.g., SPAM [ 7 ], to generate the set of frequent sequences FS in D . Every pattern in FS should be post-processed to be converted to an arrangement. However, this approach has two basic drawbacks, regarding cost and effi-ciency: (1) the patterns in FS will carry lots of redundant information due to the nature of the sequential pattern mining algorithm. In particular, for each extracted frequent pattern, all its sub-patterns will be included in FS . Some of these sub-patterns, however, will hold incom-plete arrangements and thus FS will include redundant results. Consider for example the fol-in D and thus it is included in FS . Then the sequential pattern algorithm will also gener-f ={ A start , B start , B end } , etc. These sub-patterns correspond to incomplete arrangements and they constitute redundancy for the result set. As shown in Sect. 5 for small supports a sequential pattern mining approach can yield up to 70% redundancy; (2) post-processing can be costly, since each frequent pattern f should be converted to an arrangement. For the arrangement representation scheme presented in this paper, the complexity for post-process-in the sequence. This cost can be reduced if more efficient representations are used, however, the problem of redundancy remains.

Next, we describe three efficient algorithms for mining frequent arrangements of temporal intervals that address the previous problems. The first two, employ a tree-based enumera-tion structure, like the one used in [ 7 , 10 , 72 ]. The first algorithm uses BFS to generate the candidate arrangements, whereas the second uses DFS. Although the BFS-based approach is equivalent to Apriori and [ 68 ], the algorithm is further extended to include temporal and structural constraints. The third algorithm employs a prefix-growth approach, similar to [ 55 ]. In our approach the interval-based representation of the database is retained as opposed to [ 69 ]; thus we achieve a better scalability. 4.1 The arrangement enumeration tree The tree-based structure used by the first two algorithms is called arrangement enumera-tion tree . An arrangement enumeration tree is shown in Fig. 8 .The r oot of the tree con-the complete set of k -arrangements. Let n k i denote node i on level k ,where i indicates arrangements that can be defined using those labels and all the available types of relations. These arrangements are enumerated using a set of intermediate nodes M k ( n k i ) . Each node defined by the labels in n k i and R is one of all the possible combinations of relations for the labels in E . For the case shown in Fig. 8 , E ={ A , B , C } andonlevel1 , N ( 1 ) = {{
A } , { B } , { C }} , i.e., we have one node for every item in E . Then, performing temporal joins on the nodes of level 1, the set of the 2-arrangements of Level 2 is generated, with N ( 2 ) = {{ n N ( The arrangement enumeration tree is created as described above, using the set of operands defined in Sect. 2 and it is traversed using either breadth-first or depth-first search. 4.2 BFS-based approach In this section we consider an event interval mining algorithm that uses the arrangement enu-meration tree described above to generate the set of candidate arrangements and then prunes those that are not frequent or cannot lead to any frequent arrangement if expanded. The algo-Apriori-based approaches described in Sect. 3 . The main characteristic of this algorithm is that a set of constraints has been incorporated into the mining process. 4.2.1 The mining process To accelerate the mining process, the ISIdLists (Interval Sequence Id Lists) structure is intro-duced, that attains a compact representation of the intervals and a relatively low join cost. More specifically, an ISIdList is defined for every arrangement generated by this process. The head of the list is the representation of the arrangements using R and the event labels comprised in it; each e-sequence is of type ( id , int v -List ), where id is the e-sequence id in D that supports the arrangement, and int v -List (interval List) is a double-linked list of all the time intervals during which the arrangement occurs in the corresponding e-sequence in D .

Consider, for example, an e-sequence database D with three unique items A , B and C , as in Fig. 10 . The ISIdLists of A and B are shown in Fig. 9 .Let F k denote the complete set of frequent k -arrangements and C k the set of candidate frequent k -arrangements. Our algorithm will first scan D to find F 1 , i.e., the complete set of 1-arrangements. To achieve this, a scan will be performed on D for every event type e i . If the number of e-sequences in ISIdList will be updated accordingly.

In order to generate the candidate 2-arrangements, we use the arrangement enumeration tree described above to get the nodes of level 2, along with the set of their corresponding intermediate nodes. These nodes are generated based on F 1 found in the previous step. The way this is done in [ 52 ] is too naive: all possible combinations of 2 event intervals would be checked by making multiple scans (one per candidate 2-arrangement) on the ISIdLists of each event label; the ones satisfying the minimum support threshold constraint would be added to F 2 . In this paper we follow a more efficient approach which is based on the Apriori principle: for any 2-arrangement that is frequent in D , each of the two event intervals that form the arrangement should occur in at least min _ sup number of transactions. Thus, once we get the event labels of the frequent 1-arrangements, we check which pairs of these event labels co-occur in at least min _ sup transactions. If a pair of event labels does not satisfy the above criteria, then there is not need to check the intermediate nodes for any potential frequent temporal relations. This technique introduces additional pruning and is applied at each candidate generation step, resulting in a significant acceleration of the mining process, as shown in the experimental section.

Moving to the next levels, i.e., generating the set of frequent k -arrangements, we tra-( k  X  1)-arrangements. For every node n k  X  1 mentioned pruning technique is also applied here: given a node on level k  X  1 and a new event label, we check whether the number of transactions where they co-occur is above min _ sup . If so, the set of intermediate nodes M k ( n k i ) is generated, one for every type of correlation for every type of 2-relation a pointer to the intermediate nodes on Level 2 that correspond to that 2-relation. Also, note that if an arrangement is found to be infrequent, then the node in the tree that corresponds to that arrangement is no further expanded.

For efficient support counting we adopt a  X  X itmap-like X  representation [ 7 ]. Each ISIdList contains an array T of size | D | ,where T ( j ) = 1 if the arrangement represented by the ISIdList is contained in e-sequence j ,and T ( j ) = 0 otherwise. When two ISIdLists are joined, a logic AND is performed on the two bitmap arrays and the bitmap array for the new node is determined. The support of each arrangement is determined by summing its bitmap array.

The above process is more clear through the following example: consider database D in Fig. 10 and assume that min _ sup = 2. Scanning D and filtering with min _ sup ,we get F 1 ={{ A } , { B } , { C }} . Based on F 1 and the enumeration tree, set F 2 of the frequent 2-arrangements is generated. In our case, we get all the possible pairs of the 1-arrangements types of relations between them, i.e., M 2 . If these relations satisfy the support threshold they a breadth-first search traversal, along with the set of intermediate nodes. Every node in M 3 that satisfies min _ sup is added to F 3 , which in our case consists of only one arrangement: { ( are described in Algorithm I, considering an input database D , a minimum support threshold min _ sup , an interestingness measure  X  , a set of constraints C and an integer k . 4.2.2 Applying constraints The most naive way of applying the set of constraints C T is to do so after the generation of each arrangement and before the application of any interestingness measure. Applying constraints, however, is meant to speed up the mining process and the degree to which C T is applied for pruning determines the efficiency of pruning. Gap, overlap and contain constraints are applied during the second step of the algorithm, when the set of frequent 2-arrangements is created. Finally, the duration constraint is applied at the first step when the set of frequent 1-arrangements is created. 4.2.3 Generating arrangement rules Regarding the rule generation, two approaches can be followed: one is to extract the rules after the mining process is completed, i.e., given the complete set F of frequent arrange-ments and the user-specified interestingness measure  X  , we apply a technique similar to the one proposed in [ 3 ] to extract the rules implied from F and maximize  X  . The second and more efficient approach is to prune using  X  with optimistic estimates. This means that dur-ing the mining process we are going to use  X  for pruning as aggressively as possible. This, however, depends on whether  X  satisfies the anti-monotonicity property. If so then it can be incorporated into the mining process; if not then the first approach is employed. More details on this step are given in Sect. 4.6 . 4.3 DFS-based approach In the BFS approach the arrangement enumeration tree is explored in a top-bottom manner, i.e., all the children of a node are processed before moving to the next level. On the other hand, when using a depth-first search approach, all sub-arrangements on a path must be explored before moving to the next one. A DFS approach for mining frequent sequences has been proposed in [ 63 ]. Based on this, the previous algorithm can be easily modified to use a depth-first search candidate generation method. This can be done by adjusting function generate _ candi dates () so that it follows a depth-first search traversal. Consider then n 2 1 ={ A , A } followed by M ( n 2 1 ) , and so on. Again, the constraints are applied in a similar fashion as in BFS; the rule extraction is described in Sect. 4.6 .

The advantage of DFS over BFS is that DFS can very quickly reach large frequent arrange-ments and therefore, some expansions in the other paths in the tree can be avoided. For exam-ple, say that a k -arrangement A is found to be frequent. Then, the set of all sub-arrangements of
A will also be frequent according to the Apriori principle. Thus, those expansions can be skipped, reducing the cost of computation. To do so, one more step is added to Algorithm 1 : when a node is found to contain a frequent arrangement, each sub-arrangement is added to F . However, this approach has a significant drawback: in BFS each node in M k for k  X  3 con-tains pointers to its corresponding nodes in M 2 . In DFS this is not possible since M k is not completely generated due to the type of traversal. Therefore, in the current case, DFS needs to scan through D multiple times to determine the frequency of each 2-relation contained in a candidate arrangement. On the other hand, BFS already had this information available in M 2 . Knowing the set of 2-arrangements before constructing the set of 3-arrangements can prevent us from making expansions that will lead to infrequent arrangements. 4.4 Hybrid DFS-based approach A hybrid event interval mining approach is considered, based on the following observation: since the ISIdLists contain pointers to the nodes on the second Level of the tree, a DFS approach would be inappropriate since for every node n k i we would have to scan the data-base multiple times to detect the set of 2-relations among the items in that node. In the BFS approach these nodes will already be available, since they have been generated in the second step of the algorithm. Thus, we use a hybrid DFS approach that generates the first two levels of the tree using BFS and then follows DFS for the rest of the tree. This would compensate for the multiple database scans discussed above, since the set of frequent 2-arrangements will already be available thereby eliminating the need for multiple database scans. 4.5 A prefix-based approach A prefix-based algorithm for mining frequent arrangements of temporal intervals is pre-sented. We will show that in the case of interval-based events, a prefix-growth approach is quite inefficient, especially when the size of the e-sequences is large and there is repetition of the same event labels in the same e-sequence.

Consider an arrangement A ={ E , R } and an e-sequence S .The projection of S with respect to A is the remaining part S of S ,ifthe first occurrence of A in S is removed. Figure 12 shows an example of a projection. Next, we define the projection of an e-sequences database with respect to an arrangement. Using the definition given in [ 55 ] for the sequen-tial approach, we can define the projection of an e-sequence database D with respect to an arrangement A as the e-sequence database D produced from D , if each e-sequence in D is projected with respect to A . However, this definition is incomplete. The problem is illus-trated by the example shown in Fig. 13 , where an e-sequence database of two e-sequences is considered. Following the basic steps of the prefix-growth mining algorithms with support threshold min _ sup = 2, we have: 1. Scan D for frequent 1-arrangements: in our case we detect A and C . 2. Project the database with respect to each of the arrangements found at Step 1. 3. The projection with respect to A isshowninFig. 13 and will yield one new locally 4. The result of Step 3 is the detection of A  X  C in the first e-sequence and A | C in the 5. Another projection follows with respect to C , but it produces an empty e-sequence data-
As it can be seen, we failed to get A | C with support 2. In fact, A | C was produced after the first projection, as shown in Fig. 13 , but it was not considered frequent since its sup-port was erroneously calculated as 1. This example shows that when an e-sequence database is projected with respect to a prefix arrangement, finding only the first occurrence of the arrangement may hide some patterns and prevent the mining algorithm from detecting them.
Thus, given an e-sequence database D and an arrangement A ,the projected e-sequence database D with respect to A can be obtained from D , if from each e-sequence in D we find e v er y occurrence (not just the first one) of A and project with respect to each one of them. It can be seen that such an approach can lead to a huge computational cost, since for each e-sequence in the database, all the combinations of the occurrences of a prefix should be examined and not just the first one.

In our experimental evaluation we show the performance of the prefix-growth approach and compare it with the BFS and DFS approaches presented previously. 4.6 Applying other interestingness measures In the previous sections, three efficient methods are presented for mining the complete set F of frequent arrangements of an e-sequence database D . What remains to be done is to discover the set of top K arrangement rules that maximize the given interestingness measure  X  in D . A very important issue here, is how optimistic can our pruning be using  X  .This,in fact, depends on the properties of  X  and more specifically on anti-monotonicity. Next, we present two approaches to handle  X  based on whether it is anti-monotone or not. 4.6.1 Handling interestingness measures that do not preserve anti-monotonicity If an interestingness measure  X  does not preserve the anti-monotonicity property, we have two options: (1) infer the arrangement rules from the extracted frequent arrangements after the mining process is completed (this process is similar to the one described in [ 3 ] for mining association rules), (2) find an upper or lower bound for  X  and apply pruning with optimistic estimates.
 The first option is quite straightforward. Given F and D , for each A i  X  F , with A i ={ E , R } : 1. E is split into two sets E 1 and E 2 , such that E 1  X  E 2 = E and E 1  X  E 2 = NULL . Based 2. Apply  X  on r : A 1  X  R 12  X , D A 2 . 3. If r satisfies  X  add it into the set of valid rules, else discard r . 4. If the set of rules has reached the desired size K , the rule with the smallest  X  value (let
The above algorithm will produce the complete set of top K arrangement rules that max-imize  X  . Moreover, based on the mining process and the constraints applied during the extraction of the frequent patterns we have ensured that these rules will satisfy the set of constraints C T .

However, it would be more efficient if  X  could guarantee early and optimistic pruning dur-ing the mining process. The only problem is that  X  is not anti-monotone. One way to overcome this issue and achieve some pruning is to find a bound value (upper or lower) bound _  X  for  X  , such that when an arrangement A is reached on the tree, if  X ( A )&lt; Upperbound _  X &lt; X  , then none of the rules implied by A can lead to an arrangement that satisfies  X  and thus these rules can be pruned. In a similar fashion, if  X ( A )&gt; Lo w er bound _  X &gt; X  , then all rules implied by A can lead to an arrangement that satisfies  X  ; thus all these rules are immediately added to the result. One such bound was used in [ 9 ] for association rules and the following claim extends it for the case of arrangement rules: Claim 1 If all -con f i dence ( A )  X   X  , then all rules implied by A can lead to an arrangement that satisfies con f i dence . Thus these rules are not considered any further and are immediately added to the result set.
 Proof Since all -con f i dence of an arrangement is the minimum confidence of any rule inferred from it, the Claim is straightforward.

Another sort of pruning would be to find a way to imply whether a rule satisfies  X  by calculating a simpler form of the rule that reduces the computational cost. There have been several works on bounding interestingness measures for frequent itemset mining [ 9 , 50 , 67 ]. These bounds were used to prune the search space during the rule extraction process. In this paper we borrow some of those bounds and infer some new ones to incorporate some of the non anti-monotone measures into the mining process. 1. Bounding confidence: Proof Straightforward from the definition of confidence. 2. Bounding leverage: not satisfy  X  .
 Proof Shown in [ 67 ] for association rules and it can be easily extended for arrangement rules. 4.6.2 Handling interestingness measures that preserve anti-monotonicity In this subsection we consider the case where the interestingness measure  X  preserves the anti-monotonicity property. If  X  is anti-monotone, it can be used for pruning very early dur-ing the mining process. When an arrangement A is reached on the enumeration tree, if there exists no rule r inferred from A satisfying  X  , then the subtree of the node representing A is pruned, since it cannot produce any interesting rule. However, if there exists a set of rules R A for which  X  holds, then the mining process continues with the subtree. In this case though, the rules that are going to be discovered in the subtree depend on R A , based on which, the rule extraction process can be accomplished faster by excluding those rules that will definitely ment C ={ E , R } , we follow the same process as in the previous section to discover the new arrangement rules, however, the search is limited by R A as follows: 1. E is split into two sets E 1 and E 2 . 2. If there is no arrangement A i ={ E i , R i } in the antecedent part of any rule in R A ,such
As it can be seen, an anti-monotone interestingness measure  X  can be used for more effi-cient and optimistic pruning (meaning that it can be used to prune as aggressively as possible) and thus lead to a faster rule extraction. Algorithm II shows how we can extract the set of top K rules, given set of frequent arrangements. 5 Experimental setup Experiments that compare the performance of our algorithms with SPAM [ 7 ] are presented. 1 All experiments have been performed on a 2.8 Ghz Intel(R) Pentium(R) 4 dual-processor machine with 2.5 GB main memory, running Linux with kernel 2 . 4 . 20. The algorithms have been implemented in C++, compiled using g++ along with the -O3 flag, and their run time has been measured with the output turned off. Note that for SPAM, the post-processing time of converting the sequential patterns to arrangements has not been counted. Also, as mentioned in Sect. 4 , SPAM is tuned as follows: for every event interval we keep only the start and end time; as for the postprocessing phase, the frequent arrangements are extracted from the sequential patterns as described in the same section. The patterns found by SPAM consist of a set of start and end points of event intervals, which are converted to arrangements at the postprocessing phase. SPAM manages to discover the same patterns extracted by our algorithms, but, as expected, it produces a great number of redundant patterns.

For our experimental evaluation we have used both real and synthetic datasets. Next, we present an analysis of our experimental evaluation, first by comparing our algorithms with respect to their run time and then by showing their performance for each of the interestingness measures described in Sect. 2.5 . 5.1 Experiments on real data We have performed a series of experiments on two real datasets. One was an annotated data-base of ASL utterances, which is available online at: http://www.bu.edu/asllrp/ . The other was a sample network dataset of ODFlows taken from Abilene, which is an Internet2 back-bone network, connecting over 200 US universities and peering with research networks in Europe and Asia. 5.1.1 Experiments on the ASL signstream database The first series of experiments have been performed on the ASL database created by the National Center for Sign Language and Gesture Resources at Boston University. The Sign-Stream(TM) database used in this experiment consists of a collection of 884 utterances, where each utterance associates a segment of video with a detailed transcription. Non-manual mark-ings play a crucial role in the grammar of ASL [ 8 , 15 , 34 , 46 ], thus for our experiments we focused only on: specific non-manual gestures (e.g., raised eyebrows, head tilt forward), functional identification of clusters of these non-manual gestures that carry syntactic mean-ing (e.g.,  X  X h-question X ,  X  X egation X ), and part-of-speech identifications of manual signs (e.g., verb, wh-word), each one occurring over a time interval. The overall list of field names and labels included in the database are given in Table 2 .

We first tested our algorithms on subsets of sentences from the database: those that con-tained marking of a wh-question, and another that contained marking of negation. Our goal was to detect all frequent arrangements that occurred during wh-questions and negative sen-tences. In these two datasets, called Dataset 1and Dataset 2 respectively, the number of e-sequences was 73 and 68, with an average number of items per sequence equal to 32 and 26 respectively. Since all four algorithms produce the same results, in our experiments we compare their run time. As shown in Fig. 17 a and b, Hybrid DFS outperformed both BFS and SPAM for supports less than 30%. Note that for a support threshold of 3%, SPAM produced 25,628 patterns as opposed to 7,574 arrangements produced by Hybrid DFS, which induces 70% redundancy in the results, and for a support threshold of 5% the redundancy was 63.4%. On average, Hybrid DFS was approximately 1.5 X 2 times faster than BFS and almost three times (or more) faster than SPAM. In many cases, the performance of the prefix-growth approach was very poor, as it was predicted in the analysis of Sect. 4 . We tested the quali-tative performance with respect to the setting of parameter , where varied between 2 and 6 instants. In our case, low values of gave the most meaningful results, since the amount of noise in the ASL dataset was limited to a small number of frames. For higher values of ,the detected relation types changed, and as a result the number of extracted frequent arrange-ments decreased, hiding many of the interesting patterns. For all experiments presented in this section, = 3.

Next, our algorithms were tested on the whole Signstream(TM) database that contained 884 utterances with an average e-sequence size of 29 items per e-sequence. We refer to this as Dataset 3. The algorithms have been tested for various supports and have been compared in terms of run time. The experimental results in Fig. 17 c show that in terms of run time, the Hybrid DFS-based approach outperforms the BFS-based especially in small supports. SPAM starts with a run time between that of BFS and Hybrid DFS and for small supports the run time increases dramatically. The prefix-growth approach is again very poor.
The results produced by our algorithms have been examined and evaluated by linguists who had been involved in collecting the ASL data and producing the annotations for this data-set. 2 According to their feedback, our algorithms managed to detect a set of ASL patterns that have been already known: for example, the strong correlation between wh-question marking and lowered eyebrows. Similar correlations were found between the occurrence of what had been labelled as  X  X egative X  marking and the non-manual behaviors that com-prise this marking (such as side-to-side head shake). Similarly, it was unsurprising that wh-words co-occurred with the non-manual markings associated with wh-questions. Nonethe-less, it is good that our approaches independently found known correlations. Also, some other discovered patterns were considered to be trivial (e.g., that the onset of a behavior preceded the behavior itself) or in some cases, an artifact of the selection criterion used to define the sample of data under consideration. For example, within the set of negative sentences, verbs frequently co-occurred with marking of negation (whereas this would not be true of verbs in non-negative sentences). For example, a  X  X erb X  would always occur in a  X  X egation X , or a  X  X h-word X  is always included in a  X  X h-question X . Linguists have evaluated and confirmed the correctness of the patterns and rules discovered by our algorithms. In Fig. 14 we can see some of the most frequent arrangements detected in Datasets 1 , 2, and 3. In terms of mem-ory requirements, Hybrid DFS outperformed the rest, as shown in Fig. 15 for Dataset 3. The other two ASL datasets had similar behavior. For all three datasets Hybrid DFS outperformed SPAM by a factor of 2.4 and BFS by a factor of 1.8. 5.1.2 Applying interestingness measures on the ASL datasets The main motivation behind the application of interestingness measures during the mining process was to reduce the number of extracted patterns to the most interesting ones (for the user), removing most of the trivial cases described previously. All six interestingness mea-sures presented in Sect. 4 have been applied to the ASL Datasets, leading to the discovery of different sets of rules that maximize each one of them. The basic observation from the extracted patterns on the ASL database was that applying only the support threshold yielded a huge number of redundant patterns that do not provide any useful information. There-fore, except for the support we applied all the interestingness measures described previously. Ta b l e 3 shows the number of rules extracted by our algorithms for each of the three ASL Datasets. As we can see, lift, confidence and conviction produced an interesting number of rules, whereas the number of rules that maximize leverage and all-confidence was pretty small. In Fig. 16 we present some of the top patterns in the ASL dataset with regard to each interestingness measure. Notice that the first column of the figure gives the complete arrangement that takes part in the rule, the second column shows the antecedent arrangement, the third column shows the consequent arrangement and the fourth column gives the value of each interestingness measure.

The application of interestingness measures managed to remove trivial cases and preserve those already known to the linguists. In our case li f t and con v iction had the best perfor-mance among all the measures we examined. Le v er age also did a very good job in removing trivial rules, however, it also removed a great number of known rules, and in many cases the number of extracted rules was extremely small. Our experimental evaluation showed that the combination of interestingness measures and the efficient arrangement mining algorithms can potentially provide more meaningful results. Nonetheless, an evaluation by experts is always needed to determine the most effective measure for a given application. 5.1.3 Experiments on network data Our algorithms have also been tested on a network dataset of 960 e-sequences with an average e-sequence size of 100 items per e-sequence. The data has been obtained from a collection of ODFlows obtained from Abilene, that consists of 11 Points of Presence (PoPs), spanning the continental US. Three weeks of sampled IP-level traffic flow data were collected from every PoP in Abilene for the period 8 X 28 December 2003. We have selected two routers that were shown to have a high communication rate with each other, and have monitored the IP connections from one (LOSA: router in LA) to the other (ATLA: router in Altanta) for 3 days. An e-sequence in our dataset is the set of IP connections from LOSA to ATLA for every 15 min. Due to the huge number of IP addresses, we have selected 200 IPs that appear most frequently in these 3 days. The dataset that resulted from the above process is called Dataset 4.

Our experiments focused only on run time for the same reasons described earlier. In a qualitative experiment, the parameter was tuned to vary between 3 and 15. Due to the nature of the dataset, the number of extracted patterns was huge since the average e-sequence size was too high. As before, the number and type of extracted patterns varied with respect to ; unfortunately, no interesting or surprising patterns were found. In this case,  X  X nterestingness X  means that the patterns were meaningful (from a network point of view), and described an expected communication behavior of the two routers. The run time comparison of the four algorithms is shown in Fig. 17 d, and it is quite similar to that of the ASL datasets; again Hybrid DFS outperforms the other algorithms in low supports. In terms of memory require-ments, the trends are the same as those for the ASL datasets. In Fig. 15 we can see that for low (a) (b) (c) (d) supports , BFS consumes twice as much memory as Hybrid DFS, whereas the Prefix-based approach requires four times the memory used by Hybrid DFS. 5.1.4 Applying interestingness measures on the network dataset As far as the arrangement rules are concerned, all six interestingness measures have been applied and a great number of rules have been extracted, most of which were interesting (from the point of view described earlier). In Table 3 we can see the number of rules gener-ated by each interestingness measure. The main observation here is that the number of rules generated for the network dataset by each measure is greater than that for the ASL datasets. This is expected due to the nature of the network dataset, i.e., the average e-sequence size is larger, and the number of relations (and thus arrangements) is greater, due to the high communication rate in the network. 5.2 Applying temporal constraints The usage of temporal constraints is application specific. Depending on the patterns that the user is targeting and also on the nature of the dataset, an optimal setting can be defined for the temporal constraints. This setting will result in the elimination of undesired patterns and at the same time provide further pruning. Temporal constraints have been applied to both real datasets (Dataset 3 and the Network dataset) and achieved efficient pruning. Temporal constraints have been set according to the mean duration of the intervals in each dataset. Ta b l e 4 provides a summary of the impact of these constraints on Dataset 3 (the support threshold has been set to 3% and the mean interval duration is 19.5 s). It can be seen that as constraints get tighter, the number of extracted patterns decreases and at the same time the run time improves. The same behavior has been observed with the Network dataset. In general, the effectiveness of temporal constraints highly depends on the nature of the dataset and the user requirements. If for example, the event intervals in a dataset are spread apart then the gap constraint should be set to a high value; if on the other hand they are too close to each other then the gap constraint should be low. The best way of setting these constraints is to first extract some statistics on the given dataset, i.e., mean, standard deviation, etc., and then consult with the experts to determine what type of constraints and what thresholds should be applied to that specific dataset; this way we can achieve further pruning at a lower run time and at the same guarantee meaningful results. 5.3 Experiments on synthetic data Due to the relatively small size of the current SignStream database, we have generated numer-ous synthetic datasets to test the efficiency of our algorithms. 5.3.1 Synthetic data generation The following factors have been considered for the generation of the synthetic datasets: (1) number of e-sequences, (2) average e-sequence size, (3) number of distinct items, (4) density of frequent patterns. Using different variations of the above factors we have generated several datasets. In particular, our datasets were of sizes 200, 500, 1,000, 2,000, 5,000 and 10,000, with average sequence sizes of 3, 10, 50, 100 and 150 items per e-sequence. Moreover, we have tried various numbers of distinct items, i.e., 400, 600 and 800. Also, we have consid-ered different densities of frequent patterns. We first created a certain number of frequent patterns that with medium support thresholds of 20% (sparse), 40% (medium density) and 60% (dense) would generate a lot of frequent patterns and then added random event intervals on the generated sequences. 5.3.2 Experimental results The experimental results have shown that Hybrid DFS clearly outperforms BFS, and espe-cially in low support values and large database sizes Hybrid DFS is twice as fast as BFS. Regarding the performance of SPAM, we have concluded that in medium support values and small database sizes SPAM performs better than BFS but worse than Hybrid DFS, whereas in small support values and large datasets BFS outperforms SPAM. We compared the four algo-rithms on several small, medium and large datasets for various support values. The results of these tests are shown in Fig. 18 . As expected, SPAM performs poorly in large sequences and small supports. This behavior is expected since for every arrangement produced by BFS and Hybrid DFS, SPAM generates all the possible subsets of the start and end points of the events in that arrangement. As the database size grows along with the average e-sequence size, SPAM will be producing a great number of redundant frequent patterns that yield to a rapid increase of its run time. In all cases, the prefix-growth algorithm performs very poorly. In medium supports and small datasets it can still do better than SPAM, but in smaller supports and larger datasets its performance decreases dramatically.

In terms of memory requirements, Hybrid DFS outperformed SPAM by a factor of 2.6 and BFS by a factor of 2.1. Some results are shown in Fig. 19 . For all the other cases (dif-ferent e-sequence sizes, number of items per e-sequence and average number of items per e-sequence) the trends are similar and thus further results are omitted. It can be seen that despite the fact that SPAM needs only one integer to represent an item of a sequence whereas BFS and Hybrid DFS need three integers (one for the item, one for the start and one for the end point), the later still outperform by an order of magnitude. This proves the inefficiency of SPAM on interval-based event sequences. Also, the efficiency of our algorithms has been tested with respect to different number of items and different e-sequence size. The perfor-mance of the four algorithms is shown in Fig. 20 . It can be seen that Hybrid DFS outperforms BFS by at least an order of magnitude. SPAM and the Prefix-based approach perform much worse, as expected. 6 Conclusions In this paper, we have formally defined the problem of constraint-based mining of frequent temporal arrangements of event interval sequences and presented three efficient methods to solve it. The first two approaches use an arrangement enumeration tree to discover the set of frequent arrangements. The DFS method further improves performance over BFS by reaching longer arrangements faster and hence eliminating the need for examining smaller subsets of these arrangements. The prefix-growth approach is poor in performance, since the number of projections can be really huge, especially when the input e-sequences have repetitions of the same event label. We further extended our algorithms by applying con-straints during the mining process. These constraints provide a more user-specified focus on the structure of the extracted patterns. Moreover, except for the support threshold, we have applied other interestingness measures and focused on mining the top k arrangement rules that maximize a given interestingness measure. Our experimental evaluation demonstrates the applicability and usefulness of our methods. (a) (b) (a) (b)
An interesting direction for future work is to adjust the definition of support to capture multiple occurrences of an arrangement within a database sequence. Furthermore, we could develop an efficient algorithm for mining closed arrangements. In this case, however, a pre-fix-based approach, like BIDE [ 65 ], would be extremely costly. Therefore, we should come up with a method to produce the complete set of closed arrangements that will employ more efficient projections or use different techniques to prevent the paramount cost of multiple projections. Another direction for future work is to mine partial orders of temporal arrange-ments and closed temporal arrangements. The notion of mining partial orders of sequential patterns has been introduced in [ 39 ] and an interesting approach has been recently proposed for closed sequential patterns in [ 13 ]. However, these methods again assume that the events are instantaneous. Last but not least, our algorithms could be applied on biological data, such as genes of different organisms [ 51 ]. The ultimate goal would be to extract frequent arrangements of nucleotide regions and produce interesting rules. These patterns could be further used to determine various features of different groups of organisms and possibly detect mutations or tandem repeats. References Author Biographies
