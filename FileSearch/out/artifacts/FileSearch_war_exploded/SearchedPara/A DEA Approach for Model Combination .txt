 This paper proposes a novel Data Envelopment Analysis (DEA) based approach for model combination. We first prove that for the 2-class classification problems DEA models identify the same convex hull as the popular ROC analysis used for model combination. For general k -class classifiers, we then develop a DEA-based method to combine multiple classifiers. Experiments show that the method outperforms other benchmark methods and suggest that DEA can be a promising tool for model combination. H.2.8 [ Database Management ]: Applications  X  Data Mining ; I.2.6 [ Artificial Intelligence ]: Learning Algorithms, Experimentation Model Combination, Data Envelopment Analysis, ROC Combining multiple models has attracted interest across a variety of fields including management science, statistics, data mining and machine learning [1, 4, 6, 9, 12]. Studies have shown that combined models consistently outperform individual models for classification tasks [4, 9]. However, most methods for model combination are still ad-hoc in nature. How individual models are related to each other and how they s hould contribute to combination remain active research questions. Recently Provost and Fawcett [13] addressed the above problems for classification models by using ROC (Receiver Operating Characteristics) analysis. An ROC space is specified by the misclassification matrix along two dimensions  X  the TP (True Positive Rate) and FP (False Positive Rate) of the classifiers. Conversely, a particular classifier is represented by a pair of TP and FP in the ROC space. In [13] a set of classifiers is mapped into the ROC space specified by TP and FP. By combining the models lying on the convex hull formed by the individual classifiers in the ROC space it is shown that the combined classifiers yield a robust hybrid classifier that theoretically could outperform all individual classifiers in terms of the TP and FP tradeoff. However one aspect of their approach is that traditional ROC analysis can only deal with two-class (binary) classification problems. It was pointed out that ROC analysis theoretically can be extended to k -dimension classification problems [14]. For a k -class problem, the misclassification cost matrix for a particular classifier represents a point in a ( k 2 -k ) dimensional space. The set of potentially optimal classifiers forms a convex hull in this space. Optimal classifiers can then be located via linear optimization where the facets of the ROC convex hull (ROCCH) define the optimal constraints. Thus as [11] concluded, in principle, it should be possible to apply ROC type of analysis techniques to multi-class cases. In this paper, we introduce a method from the Operations Research field called Data Envelopment Analysis (DEA) and show how it can be used to select and combine models. At its core, DEA addresses the key issue of determining the efficiencies of various producers or DMUs (Decision Making Units) in converting a set of inputs into a set of outputs [2, 8]. Each DMU corresponds to a data point, the attributes of which can be programming approach to determine how efficient each DMU is in converting inputs into outputs. The points lying on the convex hull are termed as efficient DMUs. DEA deals with not only 2-class problems, but k -dimensional problems (multiple inputs and multiple outputs) as well. We show that for a 2-class problem, the convex hull identified by the ROC analysis is equivalent to the efficient frontier identified by DEA. More importantly, we show that DEA can nicely extend ROCCH to k -class problems. The main contribution of this paper is that it presents a new method for model combination using DEA analyses. We propose a novel way of formulating a classification problem into a DEA formulation by identifying the inputs and outputs for DEA. This approach can be used to combine classifiers for the more general k -class classification problems extending the ROCCH [13] approach. We show that model combination using DEA significantly outperforms conventional approaches for a variety of classification problems. In the following section, we first review the relevant literature in model combination. In section 3 we prove the equivalence of the ROCCH and DEA approaches in dealing with 2-class classification problems. We develop a DEA-based method to combine k -class classifiers in section 4. Experiments and results are presented in section 5. The problem of combining multiple models has been addressed across a variety of fields including management science, statistics, forecasting and machine learning. For the lack of space, we only describe the ROC analysis [13] and the DEA approach [2, 8]. Readers are referred to [1, 4, 6, 9, 12] for further review. ROC (Receiver-operating characteristics) analysis deals with two-class classification problems. One class is normally referred to positive and the other negative . A particular classification model (TP) and false positive rate (FP) are defined as: An ROC space thus is two-dimensional, normally specified by FP as x -axis and TP as y -axis. Each data point in this space represents a tradeoff of between TP and FP yielded from a particular model. The convex hull (frontier) of this ROC space forms a curve that represents the most efficient TP and FP tradeoff. Models lying on the frontier are the best since they convert FP into TP in the most efficient fashion. The models inside the convex hull are dominated by the models on the convex hull. In [13] an algorithm, ROC Convex Hull (ROCCH), is developed to identify the best models on the frontier and then [13] used the convex hull to construct a hybrid classifier. Users first make a cost assumption (e.g. TP is 4 times more important than FP) with respect to TP and FP. A hybrid classifier consists of the set of points where the iso-slope implied by the cost matrix is tangential to the ROC hull. It is also shown in [13] that under any target cost and class distributions, a robust classifier will perform at least as well as the best classifier. Here we briefly discuss DEA, the problem it was developed to address and the basic model it uses. DEA is a linear programming based approach that constructs an efficient frontier (envelopment) over the data, and calculates each data point X  X  efficiency relative to this frontier [8]. DEA assumes that the variables of the data can be logically divided into inputs and outputs. Each data point corresponds to a decision making unit (DMU), or a producer in practice. The  X  X ecision X  of a unit is to convert inputs into outputs as efficiently as possible. DEA uses a linear programming approach to identify the efficient DMUs, those units that make the most efficient use of inputs to produce outputs. The efficient units consist of a frontier among all DMUs. The efficiencies of the DMUs are measured by projecting to this frontier. The DEA model in its original form represented the performance or efficiency of the DMU as the ratio of weighted outputs to weighted inputs [8]. To date, the DEA literature has developed numerous models and detailed discussions can be found in [7, 8]. Essentially, various models for DEA seek to establish which subset of DMUs determines an envelopment surface and address how to characterize each DMU by an efficiency score. One of the classic model formulations, the BCC input-oriented model [2], is presented below. Suppose N data points (DMUs) are to be evaluated. Each data point consists of K inputs and M outputs. The K  X  N input matrix, X , and the M  X  N output matrix, Y , represent the data. Note that in this formulation, the columns represent the data points and the outputs in the case of Y ). Hence for the i th vector y i . A good account of the BCC model can be found in [2], we directly present the formulation below: Where 1  X  is an 1  X  N vector of ones,  X  is a scalar and vector of constants. In the BCC model formation,  X  and only two variables to be optimized. All the other values ( X , Y ) are given by the data. A linear program for optimizing this essentially identifies a convex hull for all the data points and computes an efficiency score  X  for each individual data point. The value of bounded between 0 and 1, with 1 indicating a point on the frontier. Note that the linear programming problem must be solved N times, once for each DMU in the sample. DEA has been successively applied to a variety of applications such as studying the efficiency of commercial banks, to anticipate the consequences of school reforms and to investigate online customers shopping efficiency [8]. This paper, however, is the first attempt to apply DEA to study model combination. Both ROCCH and DEA identify a convex hull. In this section we show that the two convex hulls indeed are identical for a 2-class classification problem. ROC Convex Hull [13] has several distinct characteristics: Two-dimensional convex hull algorithms, are essentially variants of the  X  X riangle test X  -for a data point to be on the convex hull, it must not be within the triangle formed by any three data points [3]. But the computation complexity for this test is O( N records. ROCCH uses an algorithm similar to the Quickhull algorithm [3, 13], the complexity of which reduces to O ( N logN ). The property of monotonicity further simplifies the core of the algorithm as follows: It is not immediately clear how to represent an ROC problem by a DEA model. Here we take the approach that a classifier can be considered to be a DMU that makes tradeoffs between TP and FP. A classifier can be perceived as a decision maker that attempts to maximize the output, TP, at the expense of the input, FP. Thus the ROC problem can be formulated into a DEA problem as follows: a 2-class classifier is a DMU in DEA that takes FP as inputs and TP as outputs. We choose the classic BCC formulation [2] as the DEA model. As mentioned before note that the formulation below has to be solved for each classifier separately to get its efficiency score. Among a set of N classifiers for evaluating a particular classifier i (with FP= x i and TP= y i ) the one-input one-output BCC model simplifies as: i.e. when a na X ve model classifies all instances as negative or positive respectively. A literal summarization of the algorithm as described in the perl script for ROCCH [13], available at http://www.hpl.hp.com/personal/Tom_Fawcett/ROCCH. According to [8], the i th DMU is to be on the efficiency frontier, if whether ROCCH identifies the same convex hull, we just need to prove one of the two cases: We will show that the second holds. We prove in this section that DEA identifies the same convex hulls as ROCCH, for a 2-class classification problem. We do this by using the second test: an inefficient point in the ROC space has efficiency score  X  &lt;1 in DEA. The best way to show this is to prove it graphically (see Figure 3.1). Suppose a convex hull has been identified by ROCCH. Without loss of generality, assume ( X j , Y j ) and ( X points on the curve. And ( x i , y i ) is an inefficient point, X X j+1 , that is below the line in Figure 3.1 (FP as x -axis and TP as y -axis.) Now the test simplifies as: is the value  X  of point ( x than one in a DEA model? Figure 3.1: An inefficient point in the ROC space It is easy to see that this is indeed the case. Clearly point ( x satisfies the first condition of the BCC model (see formulation model projects a point to the left. Thus ( x i  X , y i ) is the projection of ( x to the property of linear combination, x i  X  must be equal to i.e., x i  X =  X   X  j X j . Thus  X   X  j X j &lt; x i or equivalently The converse of the statement also holds, establishing the iff assertion: i.e. a DMU with  X  &lt;1 is an inefficient point in the ROC formulation, then  X   X  j X j &lt; x i and  X   X  j Y j point ( x i , y i ) is below the two adjacent classifiers ( X , Y j +1 ) on the convex hull, where X j &lt; x i &lt; X Based on the equivalence of the two tests described in 3.2, the following two propositions are also true: 1) A point on the convex hull of the ROC space has efficiency score  X  =1 in DEA and 2) A DMU with  X  =1 is an efficient point in the ROC space. In summary, for 2-class problems, the convex hull identified by ROCCH is identical to the one identified by a DEA model. An important observation that will significantly help address model combination for multi-class problems is that DEA is not limited to 2-dimension problems. DEA X  X  ability to deal with many inputs and many outputs suggests that DEA could extend ROCCH to k -class problems. In this section, we develop a DEA approach to combine classifiers for this general case. The method extends ROC analysis to multi-class classification tasks. The first step of a typical DEA application is to identify the inputs and outputs. As discussed for the 2-class problem, we model a classifier as a DMU that attempts to produce TP at the expense of FP. However, it is not as clear what makes inputs and outputs for a general k -class classification problem. classifier could be represented by a k 2 confusion matrix (or misclassification cost matrix). Let C denote the k  X  k confusion misclassified as j, i  X  j and i , j  X  (1, k ); and when i = j, c particular cell can be represented either by the actual number of misclassified instances or by a row percentage of them. Hence, a classifier can be perceived as a DMU that attempts to classifier can be viewed as a decision maker that attempts to produce diagonal elements c ii at the expense of off-diagonal elements c ij . As such, c ij can be interpreted as the inputs and c the outputs in a DEA model. Notice that the actual degree-of-add up to a fixed value. This is evident if we take off the K diagonal elements. In our experiments, we actually remove the K column since we need to use diagonal elements as outputs in k )} is a DMU in DEA that takes c ij as inputs and c where C is the k  X  ( k-1) confusion matrix for the classifier f . Once the inputs and outputs are specified, we need to choose a specific DEA formulation. We chose the classic BCC model [2]. In general, the choice of a particular DEA model determines 1) the implicit returns-to-scale properties, i.e., constant returns-to-scale (CRS) or variable returns-to-scale (VRS) 3 ; 2) the geometry of the envelopment surface, with respect to which efficiency measurements will be made and 3) the efficient projection, i.e., 
CRS and VRS are economic concepts. CRS means the same additional amount of inputs will produce the same proportional additional amount of outputs. While in VRS cases, the proportion might change. the inefficient DMU X  X  path to the efficient frontier. Over the past three decades, the DEA literature has developed a variety of formulations. A nice overview of those different formulations can be found in [8]. As argued in [8] a particular DEA model carries with it an implicit choice among the above three aspects. BCC model is an appropriate choice here for two reasons. First it is piecewise linear as ROC convex hull is. Second its VRS property loses the implicit assumption that all DMUs are operating at an optimal scale, as assumed by CRS. VRS condition is specified by the third constraint (1  X   X  =1) in formula (1) of section 2. This condition guarantees the linearity of the efficient frontier. Here we propose one method based on the efficiency score derived from the DEA model. Since the inefficient DMUs are dominated by the efficient ones according to DEA formulation, we select and combine only the efficient models. And we refer to the method as EMO (efficient models only). EMO first selects only the efficient models (  X  = 1) identified by the DEA model and then applies majority voting [4, 12] among these efficient models. Suppose in total M models are built. efficient models where  X  j =1 and let |S| be the number of efficient k  X  (1... K ), where K is the number of classes. We denote this prediction as Y ij , Y ij  X  (1... K ). Define a function C k and 0 otherwise. Define probability p ik of record i being k vote k . Finally, the majority prediction of these | S | models can be expressed as follows: As we know, the performance of a combined classifier relies upon the strength of individual classifiers. By combining only the efficient models, we would expect a performance improvement of the hybrid classifier. EMO enriches the model combination literature along two dimensions: In this section we empirically test if EMO performs well. We first describe the experiment setup: datasets used, the classification models chosen and the benchmarks against which the combing methods are compared. Then we present the experimental results. We test our methods on 20 datasets for classification problems. Thirteen of these were chosen from the 37 datasets publicly available in the Weka repository 4 [15], along with detailed descriptions of each dataset. All these 13 datasets entail classification tasks and were commonly used in machine learning and data mining fields [4, 5]. The other seven are web usage datasets provided by a market data vendor. Each dataset predicts online customers X  purchases based on their demographics and online searching history. Each of the 20 datasets is divided into an in-sample dataset for training and an out-of-sample dataset for testing. All the seven web usage datasets have a common split, 40% in-sample and 60% out-of-sample. The thirteen Weka These datasets are originally maintained by the UCI repository for machine learning [5] and reformatted into Weka format by [15]. Weka is a popular and open-source data mining package that implements most current data mining algorithms in Java. datasets were already divided into in-sample and out of sample datasets in the Weka repository and we use these datasets. The first three columns of Table 5.1 reports the number of classes and the number of out-of-sample records of each dataset. We then build classification models on the in-sample datasets. All the models are from Weka X  X  classifier class, which implements most of the popular classifiers including decision trees (J48 algorithm), neural networks, support vector machines, na X ve Bayes, Stumps, DecisionTB, Kstar, IBK, OneR, Logistic Regression, IBMDK5, IB1, ZeroR and PARK [15]. In addition, some models have small variants based on different parameterization of the model (e.g. Algorithm J48Part and J48-x5 are both variants of algorithm of J48.) We consider them as different models. We attempted to make use of all these available models. However, for some of the bigger datasets it is computationally expensive to build models such as neural networks. As such, we built 29 models for smaller datasets (size &lt;1000) and fewer models for those bigger ones. The actual number of models we built for each dataset (between 17 and 29) is presented in column 4 of Table 5.1. After the models are built, we then apply two common model-combining methods as the benchmarks. The first one is the simple un-weighted average method and the second one is a weighted average method. Un-weighted average ( UWA ) simply averages the predictions made by each model (same as majority vote for classification tasks). It is a commonly used benchmark and has been found to be robust and accurate as compared to other combining methods [1, 6, 12]. The second benchmark ( VBW ) is a weighted average method that combines forecasts inversely proportional to the prediction variance [6]. The DEA software we use is DEAP 2.1 developed by [7]. For each classifier of each dataset, we input the confusion matrix to the DEA Model. In order to conform to the TP/FP convention, here each element in the confusion matrix represents a row percentage. DEAP 2.1 then reports efficient scores for each classifier. Finally we build EMO . We present the results in Table 5.1. Columns 2-6 are summary statistics of each dataset including the number of records (out-of-sample), the number of classes, the number of models applied to that dataset, the number of efficient models identified by DEA and the average efficiency scores across all models. The last three columns represent the three different combining methods: the first two are the two benchmark methods ( UWA and VBW ); and the last one is our proposed method -EMO . The values of these three columns are the mean squared errors (MSE) in the out-of-sample data. Based on a simple count, the best combining method is EMO (13 out of 20 datasets), followed by UWA (7/20) and VBW (6/20). Note that for quite a few datasets there are  X  X ies X  in the sense that multiple combining approaches are equally good. The average MSE these three methods are 0.188, 0.197 and 0.196 respectively. Further note that EMO uses far fewer models (8.8 vs. 25.4 on average) in combination and it still outperforms the two benchmark methods. These results suggest that DEA can be a promising method for model combination. Further this approach is attractive given the availability of tools [7] to easily implement DEA for combing models. In this paper we presented a DEA approach to combine models. We proved that for the 2-class classification problems, DEA models identify the same convex hull as the popular ROC analysis. We further develop a DEA-based method to combine k -class classifiers. Experiments using 29 classifiers on 20 datasets suggest that the method outperforms two other benchmark methods for model combination. Further, we present a detailed literature review and based on this review identify the broader areas in which DEA contributes to the model combination literature. In future work we plan to further investigate the value of a DEA-based approach for model combination. In particular we plan to study additional weighting schemes and to also use the method to combine multiple models learned from a given classifier. [1] Ali, K. M., M. J. Pazzani. 1996. Error reduction through [2] Banker, R. D., A. Chanes, W.W. Cooper. 1984. Some [3] Barber, D., P. Dobkin, H. Huhdanpaa. 1996. The Quickhull [4] Bauer, E., Kohavi, R. 1999. An Empirical Comparison of [5] Blake, C., C, Merz. 1998. UCI Repository of Machine [6] Clemen, R. T. 1989. Combining Forecasts: A review and [7] Coelli, T. 1996. A Guide to DEAP Version 2.1: A Data [8] Cooper, W., Lawrence Seiford, Kaoru Tone. 2002. Data [9] Dietterich, T. 2000. Ensemble Methods in Machine [10] Kim, Y., J. Kim, J. Jongwoo. 2002 Convex hull machine for [11] Lane, T. 2000. Position Paper: Extensions of ROC Analysis [12] Opitz, D. 1999. Popular Ensemble Methods: An Empirical [13] Provost, F. and T. Fawcett. 2001. Robust Classification for [14] Srinivasan, A. 1999. Note on the Location of Optimal [15] Witten, I., E. Frank. 1999. Data Mining: Practical Machine 
