 Microblogs play an important role for Online Reputation Management. Companies and organizations in general have an increasing interest in obtaining the last minute informa-tion about which are the emerging topics that concern their reputation. In this paper, we present a new technique to cluster a collection of tweets emitted within a short time span about a specific entity. Our approach relies on transfer learning by contextualizing a target collection of tweets with a large set of unlabeled  X  X ackground X  tweets that help im-proving the clustering of the target collection. We include background tweets together with target tweets in a Twit-terLDA process, and we set the total number of clusters. In practice, this means that the system can adapt to find the right number of clusters for the target data, overcom-ing one of the limitations of using LDA-based approaches (the need of establishing a priori the number of clusters). Our experiments using RepLab 2012 data show that using the background collection gives a 20% improvement over a direct application of TwitterLDA using only the target col-lection. Our data also confirms that the approach can effec-tively predict the right number of target clusters in a way that is robust with respect to the total number of clusters established a priori.
 H.3.3 [ Information Search and Retrieval ]: Clustering; I.2.7 [ Artificial Intelligence ]: Natural Language Process-ing X  Text analysis Algorithms,Experimentation Short Text; Transfer Learning; Unsupervised Learning; Clus-tering; Background Knowledge
With the growing popularity and influence of online social media, organizations and individuals are increasingly inter-ested in monitoring emergent topics that may impact their reputation. Twitter is one of the most popular media chan-nels, and is also one of the most challenging from a research perspective: it demands real-time natural language process-ing, texts are very short and codified, and it is very noisy.
In Twitter, state of the art text mining systems, which are designed and tested over large collections of documents, are compelled to deal with a collection of noisier texts in which little contextual information is available and with a generally sparse representation [9]. This calls for a revisit of many fundamental text mining techniques. For cluster-ing tasks in particular, short texts do not provide sufficient word co-occurrence or context shared information for ef-fective similarity measure, which is the basis of clustering methods. Therefore, the conventional text clustering meth-ods may fail to achieve satisfactory results when they are directly applied to short text tasks [7].

Most existing approaches try to enrich the representation of a short text using additional semantics. The semantics could be derived from a collection of much longer documents in a similar domain as the short texts [14], by sending the input short texts as queries to a search engine to retrieve a set of most relevant results [11] , or by exploiting external resources such as Wikipedia 1 [9] and WordNet 2 [5]. Once the auxiliary data is obtained, it is often used to expand the original texts, which are then processed by traditional text mining models. These type of approaches may improve per-formance in laboratory conditions, but in general external resources are not well synchronized with real time informa-tion, which is the very nature of Twitter.

In this paper we take a different approach: instead of ex-panding individual tweets with contextual information, we simply incorporate large amounts of additional (unlabeled) tweets to the target set to be clustered. Then we apply a conventional topic modeling approach adapted to Twit-ter (TwitterLDA [15]). With this technique we intend to capture and transfer the knowledge of the large dataset to improve the clustering of the target tweets. This strategy has a number of advantages a priori: (i) it does not require costly processing of external resources and error-prone tweet expansion; (ii) it does not require any type of labeled or man-ually acquired data; (iii) the number of clusters is fixed for the whole, expanded collection, but the number of clusters h ttp://en.wikipedia.org/ http://wordnet.princeton.edu fo r the target data is open and can be discovered by the algorithm (unlike a straightforward use of topic modeling approaches).
While the traditional topic models deal with regular docu-ments, there are some recent proposals to adapt topic mod-els for short text media, such as Twitter. Latent Dirichlet Allocation (LDA) [4] and its extensions [12] can be applied to discover topics from tweets by treating each tweet as a single document, but it does not work as well as with regular documents, because tweets are typically one sentence long and very focused. To overcome this difficulty, some studies proposed to consider all the tweets of a user as a single doc-ument [12]. However, the aggregated tweets of a single user may have a diverse range of topics, so this model does not exploit the fact that a single tweet is usually about a single topic.

For our experiments, we adopt a modified author-topic model called TwitterLDA introduced by [15]. The model is based on the following assumptions: there is a set of topics K in Twitter, each represented by a word distribution. Each user has her topic interests modeled by a distribution over the topics. After applying the TwitterLDA model, a topic is represented as a vector of probabilities over the space of words and a single topic is assigned for an entire tweet.
As we said earlier, our approach to topic modeling in Twit-ter consists of, instead of expanding individual tweets with contextual information, incorporating large amounts of ad-ditional (unlabeled) tweets to the target set to be clustered, and then applying TwitterLDA.
 Our problem can be considered as an instance of Transfer Learning (TL) [8]. TL makes use of knowledge gained from one learning task to improve the performance of another, but most existing work in this area is focused on supervised [13] or semi-supervised settings [10]. The unsupervised transfer learning [6] approach can be particularly useful when the amount of target data is too small, but other raw data from the same  X  X ype X  or  X  X odality X  are sufficiently available. Us-ing this idea, clustering performance could be improved by simultaneous clustering of both the target and auxiliary raw data.

Our proposal is, therefore, an instance of unsupervised transfer learning. Formally, unsupervised transfer learning is described as follows: we assume a source domain D s and a target domain D t , with no labeled data available in any of them. Unsupervised transfer learning aims to improve the clustering of target domain D t with the help of source domain D s .

We want to cluster a small set of tweets emitted within a short time span about a specific entity. For us, the source domain (hereafter called  X  X ackground X ) is a large auxiliary collection of tweets, and the target domain is a smaller col-lection of tweets for which we have a manual cluster labeling (a gold standard annotation).

The background data set is expected to cover many terms/words and term relations that are not present in the set of target tweets. Some aspects that we need to investigate are: (i) how much additional data is necessary to effectively improve topic detection; (ii) how sensitive is the process to the initial number of clusters set for the topic model approach; (iii) to what extent the additional set of tweets must be topically related to the target set in order to optimize the final cluster.
We train the TwitterLDA model simultaneously over all the tweets in the target set and the background, that is, we apply the clustering to D s UD t , and fix the target number of clusters (as required by LDA) for the whole set. Note that TwitterLDA labels each tweet with only one topic, so we will have a non-overlapping clustering. Once we have obtained the clustering, we extract all clusters that contain at least one target tweet, and remove non-target tweets from those clusters. The result is then compared with the gold standard clustering of target tweets.

Note that, although the number of clusters for D s UD t is set a priori, the final number of clusters is not prede-fined. Compared with a straightforward application of Twit-terLDA, our setting allows the topic model process to adapt to the most suitable number of clusters for the target set.
In order to evaluate our approach, we conduct experi-ments over the RepLab 2012 Monitoring Task [1]. Systems receive a stream of tweets containing the name of an entity, and their goal is to (i) cluster the most recent tweets in top-ics, and (ii) assign relative priorities to the cluster. For our experiments, we will ignore relative priorities and focus on the topic detection (clustering) task.
 The test data consists of tweets crawled for 31 companies. The tweets were crawled using the canonical company name as query, for a total of between 19 ; 400 and 50 ; 000 tweets in English and Spanish (the amount and language distri-bution depending on the company name). For each com-pany, 300 tweets (approximately in the middle of its time-line) are manually annotated by reputation management ex-perts. The rest (tweets before and after the annotated set), is distributed as additional unlabeled data.

The official evaluation measures used in RepLab are Reli-ability (R) and Sensitivity (S) [2] and their harmonic mean F ( R;S ). These metrics have been recently proposed as two complementary measures to evaluate document organization tasks involving classification, clustering and ranking [3]. In the context of clustering tasks, Reliability and Sensitivity are nearly equivalent to BCubed Precision and BCubed Re-call, respectively.
Here we test the suitability of our approach as a way of im-proving a direct use of LDA models. We present results for five different runs: TLDA: is the TwitterLDA model without including any additional data in the set to be clustered (we simply use the target tweets for each company); TLDA BE: th is run incorporates as background, for each company, addi-tional tweets from the same company extracted from its un-labeled data; TLDA B OE: for each company, uses as back-ground unlabeled tweets from a different company; finally, TLDA BE BO E: uses as background the union of background tweets in TLDA BE and TLDA B OE.

Results are shown in Table 1. Using background tweets outperforms the TwitterLDA baseline by a margin of around 20% for all background configurations. Differences are sta-T able 1: Effect of adding background to TwitterLDA on RepLab 2012 data TLD A 0 : 855 0 : 372 0 ; 473 TLD A B E 0 : 809 0 : 471 0 ; 552 TLD A B OE 0 : 686 0 : 538 0 ; 565
TLD A B E BO E 0 : 751 0 : 507 0 ; 567 ti stically significant for all backgrounds according to a t-test ( p&lt; 0 : 0005). This result strongly supports the convenience of enlarging the target set of tweets to be clustered.
Note that the availability of additional tweets increases the possibility of finding relations between terms and, there-fore, between tweets: that makes reliability (precision) lower in all cases where background is used, and sensitivity (re-call) remarkably better. Precision is substantially better when we use background data from the same entity, com-pared to using background from a different entity (0 : 809 for TLDA B E vs 0 : 686 for TLDA B OE). In practice, although the harmonic mean of R and S gives similar results for all backgrounds, TLDA B E is possibly more useful -at least for reputation experts -as it contains less noise. Therefore, in the rest of experiments reported here we only show results for variants of TLDA B E.
As we have mentioned, with our approach it is not neces-sary to prescribe the final number of topics/clusters of the target set: we have to prescribe the global number of topics (target plus background), and the number of target topics is derived from the output of the global topic model. We now want to investigate how well the approach predicts the number of topics in the target output.

Figure 1 shows the correspondence between the number of topics in the gold standard and the prediction made by TLDA B E. Each dot in the figure represents an entity in the RepLab 2012 test set; the number of topics is weighted by the number of tweets to get figures between 0 and 1. The Pearson correlation between the real number of topics and the predicted number of topics is 0.90, which is remarkably high, particularly considering that plain TwitterLDA needs to know the number of topics as an input to the algorithm. Fi gure 1: LDA-based model vs. GoldSatandar num-ber of clusters
How much background data is needed to obtain a substan-tial improvement over plain TwitterLDA? Figure 2 displays how performance changes with growing amounts of back-ground data. Note that the biggest gain is obtained from 500 to 5,000 background tweets per company: the approach gives substantial benefits with a relatively small number of addi-tional tweets. From 5,000 tweets (which represents roughly ten times the size of the target data), the increase in perfor-mance seems to stabilize, although the size of RepLab data is not enough to reach a solid conclusion about this. Fi gure 2: Effect of the size of the background data set
In our approach, the global number of topics (for the union of background and target data sets) needs to be fixed a priori as in any other topic model approach. We want to investi-gate to what extent this parameter may influence on how well the algorithm works. Figure 3 shows performance (in terms of reliability and sensitivity) of the approach for dif-ferent values of the global number of topics K . Remarkably, the approach is relatively stable in both metrics, Reliability and Sensitivity.
Our experiments show that incorporating background tweets to the topic model process (i) gives a 20% improvement com-paring to the direct application of the topic model to the target data only; (ii) allows the topic model to predict the number of topics in the target data, with an accuracy of 0.90 (correlation between the number of topics in the gold stan-dard and the number of topics in the output of the system); (iii) the amount of background data needed to get a sub-stantial improvement is relatively moderate -5,000 tweets already give near optimal results in our data set; (iv) the ap-proach is relatively robust to the initial setting of the global number of clusters.

The incorporation of background tweets into topic model processes for online reputation monitoring has two initial ad-vantages over other approaches: it is simpler and less expen-sive computationally, and it is able to accomodate real-time information about fresh topics/conversations than using ex-ternal resources such as Wordnet or Wikipedia. In addition to this advantages, our results show that the approach is Fi gure 3: The performance with different K for the Reliability and Sensitivity scores able to provide substantial improvements on the results of a TwitterLDA baseline, and it also gives, as a byproduct of the process, a prediction of the number of clusters, some-thing that it is not possible with a direct application of topic models on the target data.

Our plans for future work include testing this technique over different unsupervised clustering algorithms, larger test collections, and to explore the combination of this simple technique with other competing approaches.
This research was partially supported by the Spanish Min-istry of Education (FPI grant nr BES-2011-044328), the Spanish Ministry of Science and Innovation (Holopedia Project, TIN2010-21128-C02) and the European Community X  X  FP7 Programme under grant agreement nr 288024 (LiMoSINe). [1] E. Amig  X o, A. Corujo, J. Gonzalo, E. Meij, and [2] E. Amigo, J. Gonzalo, and F. Verdejo. Reliability and [3] E. Amig  X o, J. Gonzalo, and F. Verdejo. A general [4] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent [5] M. Chen, X. Jin, and D. Shen. Short text classification [6] W. Dai, Q. Yang, G.-R. Xue, and Y. Yu. Self-taught [7] D. Metzler, S. Dumais, and C. Meek. Similarity [8] S. J. Pan and Q. Yang. A survey on transfer learning. [9] X.-H. Phan, L.-M. Nguyen, and S. Horiguchi.
 [10] R. Raina, A. Battle, H. Lee, B. Packer, and A. Y. Ng. [11] M. Sahami and T. D. Heilman. A web-based kernel [12] J. Weng, E. P. Lim, J. Jiang, and Q. He. TwitterRank: [13] G.-R. Xue, W. Dai, Q. Yang, and Y. Yu.
 [14] S. Zelikovitz, W. W. Cohen, and H. Hirsh. Extending [15] W. X. Zhao, J. Jiang, J. Weng, J. He, E.-P. Lim,
