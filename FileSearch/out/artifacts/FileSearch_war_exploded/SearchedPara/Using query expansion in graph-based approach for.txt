 1. Introduction
Query-focused multi-document summarization (i.e., topic-focused multi-document summarization) is a particular kind a summary which can answer the information need expressed in the query. Compared to generic summarization, query-fo-cused summarization requires the summary biased to a specific query besides the general requirement for a summary.
Query-focused multi-document summarization has drawn much attention in recent years due to its applicability in real-query example). Such complex questions make the summarization task more difficult and the big challenge is how to under-stand the question well and thus bias the answer towards it.

Currently most of the query-focused summarization systems base their work on generic summarization systems. By rization system can be easily adapted to a query-focused one. Other typical query-focused summarization methods such as maximal marginal relevance (MMR) combine query relevance with information novelty in text summarization ( Carbonell &amp; a query can express, some systems also expand the query using some external resources such as WordNet, synonyms of the query words can be obtained as expansion words (Zhou, Lin, &amp; Hovy, 2005 ). However, such approaches to query expansion are restricted in what they can expand, because they cannot be applied to words not in WordNet such synonyms. Due to these limitations, we decided to expand the query based on the information in the document cluster rather than the external resources.
 Recently, graph-based ranking algorithms have been successfully used in text summarization ( Erkan &amp; Radev, 2004; of web search and have been proved successful. When applied to the task of text summarization, these approaches can make full use of the relationships between sentences and find the most important sentences to be extracted into the summary.
Wan et al. (2007b) proposed a graph-based method for simultaneous text summarization and keyword extraction by using not only relationships between sentences, but also relationships between words, and relationships between words and sen-effectiveness.

Inspired by the success of graph-based ranking, we propose an approach of combining query expansion in the graph-based algorithm for query-focused multi-document summarization. In our approach, we use both sentence-to-sentence rela-tions and sentence-to-word relations to find the query biased informative words in the document set and use them as query expansions to improve the sentence ranking result. Compared to previous query expansion approaches, our approach does not rely on any external resource such as the web or semantic dictionaries, but only the information in the document set from which the summary is to be created. We believe such kind of query expansion is able to capture more relevant infor-mation with less noise. Our experiments on the data from DUC 2005 and DUC 2006 show that the summarization results with query expansion are much better than that without query expansion, achieving the state-of-the-art performance. we present in detail our graph-based summarization algorithm combined with query expansion. Section 4 gives the exper-imental results, including the system comparison and parameter tuning. Finally, Section 5 concludes our presentation. 2. Related work A variety of multi-document summarization methods have been developed over the years, most of which are extractive.
They assign salience scores to sentences of the documents and extract the sentences with the highest scores. Abstractive summarization is also explored by some systems, which usually involves information fusion, sentence compression and reformulation. In our study, we focus on extractive summarization. Most extractive summarization methods score sentences Support Vector Machine, Maximum Entropy or Conditional Random Field to get an overall ranking score for each sentence. methods to reduce information redundancy.

As mentioned in Section 1, motivated by the success of PageRank-like ranking algorithms in webpage ranking, a number of graph-based approaches have been applied to automatic text summarization. Erkan and Radev (2004) proposed LexRank for generic text summarization. They construct a connected similarity graph where nodes represent sentences and edges performing random walk. Mihalcea and Tarau (2004) independently proposed another graph-based random walk model marization which can simultaneously make full use of both the relationships among all the sentences in the documents and the relationships between the given query and the sentences.

Recently much more focus has been put on the query-focused summarization task compared to the generic one. The ini-tial focus on the query-focused task was SUMMAC which was the first large-scale, developer-independent evaluation of difference between generic summarization and query-focused summarization is that for the latter the information expressed
Based on these requirements, most query-focused summarizers are extended from generic summarizers by incorporating query word weighting, key word extraction or synonym expansion. Our query-focused multi-document summarizer em-ploys both graph-based sentences ranking and sentence-to-word relations to implement query expansion, and then uses the expanded query to further improve the graph ranking process. 3. Query-focused summarizer with query expansion 3.1. System overview
In this section, we give a brief overview of our query-focused multi-document summarization system, as follows: 1. Use a graph-based ranking algorithm to rank all the sentences in the documents where the original query is used. 2. Perform our query expansion method based on the ranking results in step 1, and update the query. 3. Use the newly expanded query to perform graph-based ranking algorithm again for sentence ranking. 4. Impose a redundancy penalty on the ranked sentences to obtain their final overall scores, which are used for summary generation.

We will describe in detail the above four steps in the following sections. 3.2. Graph-based ranking algorithm
We use the graph-based ranking algorithm similar to the topic-sensitive LexRank in Otterbacher et al. (2005) as our first step to rank sentences in the documents, which is also used for comparison as our baseline without query expansion. The and other sentences in the documents. Furthermore, sentence importance can be spread to its nearby neighbors via a weighted affinity graph, and the spread process can be repeated until a stable state is achieved. Then all the sentences are ranked according to their final ranking scores to generate a query-biased informative summary. determined as the sum of its similarity with the query and the similarities with the other sentences in the document set, as denoted by the following formula: tence similarity compared to sentence-to-query similarity. The denominators in both terms are for normalization. The ma-trix form of formula 1 can be written as
The whole procedure of the ranking algorithm goes as follows: calculated using the tf t * isf t formula, where tf t is the frequency of term t in the sentence and isf frequency of term t , i.e. 1 + log( N / n t ), where N is the total number of sentences and n ing term t . Given two sentences s i and s j , their cosine similarity sim( s the corresponding term vectors. Also calculate the cosine similarities between each sentence and the query, denoted as sim( s i , q ). 2. Define an affinity matrix A by A ij = sim( s i , s j ). Note that we set A matrix B by B ij = sim( s j , q ). Normalize both A and B to make the sum of each row equal to 1. threshold (0.00001 in our experiments). 4. Let p * denote the converged result. Now each sentences s 3.3. Query expansion algorithm
In the above ranking algorithm, both sentence-to-sentence relation and sentence-to-query relation are taken into ac-count. However, since the query description is often short and therefore cannot provide enough information in ranking, we decided to expand the query and use the expanded query for sentence ranking. Compared to the previous query expan-sion methods used in text summarization that usually take word synonyms as expansions, we select from the document set updated query to perform graph ranking again. Our query expansion approach goes as follows: 1. Build a sentence by word matrix W , where the entry W ij is calculated using the tf t * isf t formula as described in Section 3.2 W is a N and M is the number of all various content words in the documents. (By content words we mean noun, verb, adjective and adverb. Stop words are ignored and all the words are transformed to their base forms by morphological analysis.) to the sum of the i th row of W . rithm described in Section 3.2, and y represents the word scores. generate an expanded query q 0 . c is a parameter representing the number of expansion words, which is set in the experiments.

In the above algorithm, the third step is the key step. Our purpose is to make use of both the sentence importance and sentence-to-word relationships to select the expansion words. By this step, salient words occurring in the important sen-ments and the latter is left for later work. 3.4. Graph-based summarizer with query expansion
Now we have obtained the expanded query q 0 and we use it to perform the graph-based ranking algorithm again, in order the updated score vector p * for all the sentences and use it to rank sentences. 3.5. Redundancy penalty 2
Since different sentences may contain similar content, in order to remove redundancy and increase the information cov-erage in the summary, we use a greedy algorithm similar to Zhang et al. (2005) to impose redundancy penalty to the sen-tences and compute the final overall ranking scores. The algorithm is as follows: score, i.e. RankScore  X  s i  X  X  p i , i =1,2, ... , N . 2. Sort the sentences in S 2 by their current ranking scores in descending order. 3. Suppose s i is the highest ranked sentence in S 2 . Move s sentences in S 2 by imposing redundancy penalty as follows:For each sentence s where A is the normalized similarity matrix defined in Section 3.2. 4. Go to step 2 and iterate until S 2 = / or the iteration reaches a predefined maximum count.
 from the most informative one. The more a sentence is similar to the most informative one, the more penalties it receives tences with the highest scores are selected to create a summary according to a predefined summary length limit (250 words in our case). 4. Experiments 4.1. Experimental data
Our data is from DUC 3 2005 and DUC 2006 in which query-focused multi-document summarization is the only task. Given a description of the two data sets.

In our preprocessing step, we performed sentence segmentation and POS tagging for each sentence in the documents and the query. We utilized both query title and query narrative. When computing the sentence similarities, stop words were removed and only the content words (i.e., noun, verb, adjective and adverb) were used after the morphological anal-ysis based on WordNet. 4.2. Evaluation metrics
We use the ROUGE toolkit ( Lin, 2004; Lin &amp; Hovy, 2003 ) for evaluation which is adopted by DUC as the official eval-uation metric for text summarization. It measures how well a machine summary overlaps with human summaries using n -gram co-occurrence statistics. Multiple ROUGE metrics are defined according to different n and different strategies, such as ROUGE-1 (unigram-based), ROUGE-2 (bigram-based), ROUGE-S (skip-bigram-based), ROUGE-SU4 (skip-bigram-based with maximum skip distance of 4, plus unigram), and ROUGE-L (longest common subsequence-based), etc. In our experiments, we report the recall value of ROUGE-1, ROUGE-2 and ROUGE-SU4 since they have been shown to be highly correlated with human judgments and taken as the official metrics in DUC 2005 and DUC 2006 ( Dang, 2005, 2006). 4.3. Experimental results 4.3.1. System comparison
In the experiments, our system of graph-based summarizer with query expansion was compared with the baseline (i.e., graph-based summarizer without query expansion, named as No-expansion baseline ) to show the effectiveness of our query ipated in DUC 2005 and 2006 for comparison.

For further comparison of our query expansion, we have implemented another query expansion method which expands exists in WordNet, its synonyms are added into the query as expansions. Note that since word sense disambiguation is not performed, all senses of a word are taken into account. This query expansion method is combined in the graph-based sum-marizer as another baseline system (named as Synonym baseline ).
 Tables 2 and 3 show the system comparison results on the data of DUC 2005 and 2006, respectively. In the tables, S10 X  and the baselines.
 ranking algorithm and c is the number of word expansions used in the query expansion).

From Tables 2 and 3 , we can see that on the data of DUC 2005, our system outperforms all the top systems and the base-line systems on all the ROUGE scores. On the data of DUC 2006, our system performs worse than only S24 but much better than other systems on ROUGE-2. On ROUGE-1 and ROUGE-SU4, our system is among the top performing systems. When compared to the baselines, we can see that after adding query expansion, the system performance is significantly improved on both DUC 2005 and DUC 2006, which proves the effectiveness of our query expansion algorithm.

Furthermore, from the result of Synonym baseline , it is obvious that expanding the query by word synonyms is not very helpful. The possible reasons are that on one hand, the synonyms that we can expand are limited, and on the other hand, without word sense disambiguation, many noisy words may be introduced in this way, which is certainly not help-ful to the performance. While our system extracts word expansions from the document contexts which is more reason-able and beneficial. 4.3.2. Influence of parameter tuning
In this section, we show the results of our system on the data of DUC 2005 and DUC 2006 under different values of the parameters, i.e., the weight d used in the graph-based ranking algorithm and the expansion number c used in our query expansion algorithm. We only report the performance on ROUGE-2 for it is representative.
Fig. 1 demonstrates the influence of the weight d to the performance of our system when c = 100. d reflects the relative decreases obviously, which shows that both terms are important.

Fig. 2 demonstrates the influence of the parameter c to the system performance when d = 0.6. We set its range from 0 to observe that before reaching 100 words, expanding more words results in evidently better performance, while after exceed-ing 100 words, the performance gets no improvement or improved less obviously, which shows that a certain number of words are enough for the query expansion.
 5. Conclusion and future work
In this paper, we propose a query expansion algorithm used in the graph-based ranking approach for query-focused mul-ti-document summarization. Our approach makes use of both sentence-to-sentence relationships and sentence-to-word relationships to select expansion words from the documents. By this method, the expansion words satisfy both information richness and query relevance. Our experimental results show that this query expansion method significantly improves the system performance and makes our system comparable to the top performing systems in DUC.

Our future work will be applying the query expansion to other summarization approaches and furthermore, employing machine learning algorithms to automatically learn the parameters.
 Acknowledgement This work was partly supported by the Natural Science Foundation of China under grant No. 60435020, and Committee of
Science and Technology of Shanghai Municipal Government. We would like to thank the anonymous reviewers for their valuable comments and suggestions on this paper.
 References
