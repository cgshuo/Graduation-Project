 We focused on taxonomy modification algorithms for grad-ually improving the relevance performances of large-scale hierarchical classifiers of web documents. Considering the research results of Tang et al. [5, 4], who took the same ap-proach, we investigated and implemented two heuristic tax-onomy modification algorithms for performing practical cla s-sification processes for large-scale taxonomies. Although a taxonomy modification algorithm continuously improves the relevance performances of hierarchical classifiers, it inc reases the computational costs of those classifiers for training an d predicting processes. We developed an improved taxonomy modification algorithm for reducing computational costs by preventing child node concentration. Although the relevan ce performances of the algorithm-modified taxonomy classifier s improved without increasing computational costs until the fourth generation by spreading the set of predicted classes , their relevance performances and behaviors went in opposit e directions from the fifth generation.
 H.3.3 [ Information Search and Retrieval ]: Information Filtering; I.2.7 [ Natural Language Processing ]: Text analysis Design, Experimentation Hierarchical Classification, Taxonomy Modification, Web Do c-ument Classification, Evaluation Measures
A document classifier with a larger set of classes has the potential to enable more precise predictions than one with fewer classes. Hierarchical structures are commonly appli ed to large sets of classes to increase the usability of the clas ses. A hierarchical structure for a classifier is called a taxonomy . Most taxonomies are constructed manually and provide nat-ural and smooth methods for users to access categorized documents. Classification systems that classify documents into hierarchical taxonomies are called hierarchical classi-fiers . There are two approaches for improving hierarchical classifier performances: 1. clustering approach  X  decomposing a taxonomy into 2. gradually modifying approach  X  gradually modifying The first approach can obtain the best performing hierar-chical structure because there is no restriction in arrangi ng structures. The second approach makes it easier to control the balance of modified hierarchical structures. Unbalance d hierarchical structures tend to hold many classes, which ha ve a large number of child classes. Multi-class classifiers of these classes increase the computational costs for trainin g and testing.

We implemented a classification system, which uses the gradually modifying approach for taxonomy modification processes. We selected the Yahoo! Japan categorized guide investigation. The classification system consists of hiera r-chically configured linear-kernel multi-class support vec tor machine (SVM) classifiers that provide efficient classifica-tion performance by using the pachinko search (hierarchi-cal) method [1, 3]. It can classify about 200,000 web doc-uments, each of which has already been translated into a bag-of-words (BOW) feature vector, in a few days. Users can access a categorized document using the original taxon-omy because the taxonomy modification processes keep the mappings of modified taxonomy elements.
Tang et al. [5, 4] proposed novel taxonomy modification methods for improving the classification relevance of hier-archical document classifiers. While these methods were Algorithm 1 Modification algorithm for large-scale tax-onomies Algorithm 2 Accumulate demote and merge operation can-didates designed and found to robustly improve taxonomies, exten-sions to these methods were required for the taxonomy mod-ifier to operate efficiently on large-scale taxonomies contai n-ing tens of thousands of branching nodes, even though the extensions weaken the robustness improvement in classifica -tion relevance.
All Tang et al. X  X  methods require training and evalua-tion processes for each taxonomy modified by an operation candidate before the operation is actually applied to the taxonomy. While they robustly improve classification per-formance, their computational cost increases drastically ac-cording to the scale of the taxonomy. The cost of training processes might be reduced by limiting the training node classifiers to only those affected by single taxonomy modifi-cation operations. Nevertheless, the cost of evaluation pr o-cesses cannot be easily reduced. Hierarchical classificati on results might be affected by modifications of distantly lo-cated nodes, especially if those nodes belong to the upper scribed in the Empirical Results section shows that local classification performances do not always reflect the genera l hierarchical classification performance. Therefore, we de vel-oped an algorithm for modifying large-scale taxonomies by extending Tang et al. X  X  methods to drastically reduce train -ing and evaluation costs.

The modification algorithm for large-scale taxonomies show n in Algorithm 1 is an iteration of processes, each of which located nearer to the root node.
 Algorithm 3 Select and apply primitive operations Algorithm 4 Modification algorithm for large-scale tax-onomies by preventing child concentration finds promote and demote operation candidates from all nodes in the initial taxonomy, solves conflicts among them, immediately applies those operation candidates to produce next-generation taxonomies, and performs training and eva l-uation processes. The loop process is repeated until the cla s-sification system based on the modified taxonomy obtains a satisfied performance condition. A typical condition might be that the classification system stops to improve the values of several evaluation metrics. One iteration of the loop pro -duces a new taxonomy generation T and consists of three sequentially connected  X  X or X  loops, each of which processe s a node in the taxonomy.

The first  X  X or X  loop accumulates promote operation can-didates in node set N promote . Functions high miss( n ) and low miss(n) return high miss and low miss scores of node n , respectively. The loop corresponds to Heuristic 4.2 of Tang et al. X  X  methods [4]. The parameter  X  has the same meaning as the one in those methods.

The second  X  X or X  loop shown in Algorithm 2 accumulates demote operation candidates in node set N demote . The loop further includes another  X  X or X  loop that processes all node pairs a and b that are different children of node n . The in-ner loop stores the pair with the maximum ambiguity scores in variable N max and in variable N as . The statistical val-ues P ab and P ba are directed ambiguity scores that appear in  X  X efinition 4.3 X  of Tang et al. X  X  methods [4]. The outer  X  X or X  loop corresponds to Heuristic 4.4 of the methods. The parameter  X  has the same meaning as the one in those meth-ods.

The third  X  X or X  loop shown in Algorithm 3 consistently applies promote and demote operations. The loop applies candidate operations to nodes that are candidates for eithe r promote or demote operations and applies demote opera-tions to nodes that are candidates for both promote and demote operations. Figure 1: Commonly used relevance metrics of Al-gorithm 1 Figure 2: Commonly used relevance metrics of Al-gorithm 4
Although Algorithm 1 improved the efficiency of taxon-omy improvement processes, it worsened the efficiency of the training and testing processes. Precise results are shown i n the Empirical Results section. The child concentration ob-served on taxonomies was generated using the taxonomy modification algorithm. Nodes holding many classes and training documents require enough memory to hold support vectors and computational time in the training and predict-ing processes of multi-class SVM classifiers. Therefore, we developed Algorithm 4 to prevent the concentration phe-nomena by amending Algorithm 1. The difference is that the new algorithm has an additional condition in selecting promote candidates. Function num of child( n ) returns the number of child nodes of node n . Function parent( n ) re-turns the parent node of node n . Constant  X  means the ideal maximum number of child nodes. Thus, Algorithm 4 prevents such concentration by limiting the promote opera-tions of nodes, of which the parents already have enough of child nodes.
All local multi-class SVM classifiers were trained using 50% of the corpus data and tested using the remaining 50%. The reason for choosing this ratio is that many classes had little corpus data attached, and our taxonomy modifica-tion algorithms requires classification results for nodes t o be moved. For these classes, it was difficult to divide the corpus data in any other ratio. The cost parameters for Figure 3: Structural changes of Algorithm 1. Two units are assigned in this figure. Metrics  X  X oot # doc. X ,  X  X vg. # chi. X ,  X  X vg. # doc. X  and  X  X vg. depth X  show values using right Y-axis units. Only metric  X  X oot # chi. X  shows values using left Y-axis units. Figure 4: Structural changes of Algorithm 4. Two units are assigned in this figure. Metrics  X  X oot # chi. X ,  X  X oot # doc. X ,  X  X vg. # chi. X  and  X  X vg. # doc. X  show values using left Y-axis units. Only metric  X  X vg. depth X  shows values using right Y-axis units. training linear-kernel SVM classifiers were 0.4 in all cases because that gave the best performance in the preliminary experiments. Both taxonomy modifiers used the parameters  X  = 0 . 9 and  X  = 0 . 1, which are the same as in Tang et al. X  X  experiments [4]. The Algorithm 4 taxonomy modifier used the parameters  X  = 100 after investigating classifier ef-ficiencies of nodes with typical child-class sizes and train ing documents in a version of the modified taxonomy.

Commonly used relevance metrics of classifiers whose tax-onomies are modified using Algorithms 1 and 4 are shown in Figure 1 and 2, respectively. T 2, T 3, T 4 , . . . on the X-axes denotes classifiers for the second-, third-, fourth-, . . . taxonomies, respectively. Because the first taxonomies were significantly modified from the original taxonomies in both algorithms, we considered the first generation taxon-omy classifiers as base classification systems. All the value s in these figures are the relative percentages of metrics of those base systems. The metric  X  X ocal avg. prec. X  means the average precision of node classifiers with more than one child-class predicted in the training corpus. Real computa -tional times for train and test process of Algorithms 1 and 4 are shown in Figure 5. Because we were not able to record T1 taxonomy classifier values, the train and test computa-tional time of the T2 taxonomy classifier was used as the Figure 5: Computational time for train and test pro-cesses base time. Iteration of both taxonomy modification algo-rithms caused structural changes in the taxonomies shown in Figures 3 and 4.
Figure 1 shows that each application of the Algorithm 1 taxonomy modifier improved the relevance performance of the hierarchical classifier. Unlike Tang et al. X  X  methods , there is no assurance that the performance will always be improved with our algorithms. This result indicates that our operation accumulation algorithm has the potential to greatly improve the relevance of hierarchical classificati on systems. The taxonomy modification algorithm, a version of Tang et al. X  X  methods [4], achieved by applying many op-erations at once and resolving the inconsistencies produce d by the applications. Inconsistencies are resolved by givin g demote operations priority over promote operations, as de-scribed in Algorithm 3. While each promote operation can-didate is determined by considering only statistical value s of the target node, each demote operation candidate is se-lected from the target X  X  sibling nodes by comparing ambi-guity scores. Despite this prioritization, we observed tha t nodes were concentrated on specific nodes that already had many child nodes. For example, the number of child nodes of the root node is presented in the metric  X  X oot # chi. X  in Figure 3. The number of corpus documents trained for the root node classifier is presented in the metric  X  X oot # doc. X  in the same figure. This concentration increases the computational costs of the training and evaluation corpus generator, trainer, and predictor. Computational costs fo r training and classification processes are presented using t he metrics  X  X PO (train) X  and  X  X PO (test) X  in Figure 5. These increased computational costs prevented hierarchical cla ssi-fication systems to perform practical training and predicti ng processes on common computer systems.

We developed a taxonomy modification algorithm (Algo-rithm 4) to reduce computational costs by preventing the child node concentration. This reduction can be observed using the metrics  X  X CC (train) X  and  X  X CC (test) X  in Figure 5. Although the time efficiency performances of hierarchi-cal classification systems were improved as discussed above , their relevance performances were not much improved, as shown in Figure 2. The peak values of micro averaged pre-cision ( X  X icro avg. prec. X ) and macro averaged precision ( X  X acro avg. prec. X ) were recorded by the hierarchical clas -sifier using the fourth ( T 4) and sixth ( T 6) generation tax-onomies, respectively.

The Algorithm 4-modified taxonomy classifiers monoton-ically increase the average node depth ( X  X epth X ) metric de-picted in Figure 4. The average node depth of the eleventh generation classifier was about 1,200% larger than the first generation classifier. The averaged node depth values can be increased by applying demote or merge primitive operations more than promote primitive operations. This phenomena might be resolved by adjusting  X  and  X  parameters in Algo-rithm 4 or by amending the algorithm.

The metric  X  X ocal avg. prec. X  in Figure 2 continues to improve its values until the eleventh generation taxonomy classifiers in contrast to other metrics stopping their im-provements at the fourth or sixth generation classifiers. Th is indicates that the taxonomy modification Algorithm 4 con-tinues to improve relevance performances of each node clas-sifier, but the algorithm does not continue to improve perfor -mances of hierarchical classifiers by changing taxonomies t o deep depth structures. Our future work is to determine the  X  and  X  parameters or develop new taxonomy modification algorithms.
We developed a taxonomy modification Algorithm 4 to reduce computational costs by preventing child node con-centration. Although the relevance performances of the Al-gorithm 4-modified taxonomy classifiers improved until the fourth generation by spreading the set of predicted classes , their performances and behaviors went in opposite directio ns from the fifth generation. It might be feasible to implement practical large-scale hierarchical classifiers on common P C servers, although parameter tunings or logical condition fi xes to these taxonomy modification algorithms are required. [1] D. Koller and M. Sahami. Hierarchically classifying [2] T. Li, S. Zhu, and M. Ogihara. Hierarchical document [3] T.-Y. Liu, Y. Yang, H. Wan, H.-J. Zeng, Z. Chen, and [4] L. Tang, H. Liu, J. Zhang, N. Agarwal, and J. J. [5] L. Tang, J. Zhang, and H. Liu. Acclimatizing taxonomic
