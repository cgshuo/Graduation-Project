 The goal of Information Extraction (IE) is to extract desired information from natural relevant facts and representing them in some useful form. In the past decade, IE technology has become an important branch of Nature Language Processing (NLP) technology. IE systems have been developed for writing styles ranging from structured text, semi-structured text and free text [1]. The desired information can easily be correctly extracted form the structur ed text. But for the free text this process is more complex and difficult. The output of IE system would be represented as hierarchical attribute-value structures called Templates. 
These days, the Chinese IE system is generally limited to extract structured text and semi-structured text only. The words in these texts are ungrammatical and often following a predefined format or style. The research of IE system for Chinese free text is still in the stage of beginning. 
There are two basic approaches [2] to design the modules of an IE system, which can be called the Knowledge Engineering approach , and the Machine Learning approach . The Knowledge Engineering approach [3] can be hand crafted. But the development of this approach is very laborious and time-consuming. The Machine learning approach [4][5] is relied on the annotated corpus providing examples on which learning algorithms can operate. Statistical machine learning techniques, while well proven in fields such as speech recognition, have become increasingly popular in the last several years. Hidden Markov model (HMM) [6] is a powerful statistical machine learning technique that is just beginning to gain use in information extraction tasks. HMM offers the advantages of having strong statistical foundations that are computationally efficient to develop and evaluate. 
The CAJ network( www.chinajournal.net.cn ) is the biggest Chinese Sci-Tech journal full text data in the world at present. It embodies almost 8000 kinds of important full text of Sci-Tech journal now. The Chinese Sci-Tech documents are stored separately in the data according to the topic of document, abstract, author information, full text and so on. 
To each of Sci_Tech journal, the abstr act is the summarized introduction and includes lots of important information. And the words in these abstract texts are grammatical and syntactical. It has differ ent description ways for the same fact representational and actual for the research of IE algorithm for the abstract of Chinese Sci_Tech journal. W
CA -Selection Chinese free-text HMM IE algorithm. Then we X  X l introduce the extraction task. Before the introduction to extraction algorithm, firstly, we introduce the extraction Sci-Tech journal in the same field as the extraction object and extract the information using Semi-surprised statistical method. Then, we create the output template of information extraction of its field by using characteristic information. We use slot_i to denote the relevant information that is supposed to be extracted and matches to slot_i . The area where the relevant information is supposed to be extracted is called as extraction area. We use E-A to denote the extraction area. 
In the following, we give an introduction to the designed structure of extraction model. HMM is a double embedded stochastic process with an underlying stochastic process stochastic processes that produce the sequence of observations. An HMM can be specified by a five-tuple  X  (S,V,  X  ,A,B) [7], where S and V are the set of states and the output observation symbols, and  X  ,A,B are the probabilities for the initial state, state transitions, and symbol emissions, respectively. 
In the designed model of HMM extraction algorithm, the limited set of observation value is the same type adjacent character string, called as Same_Str. We conduct the same type merge to the adjacent character string in the text. The types of the character string are differentiated based on the following types: Chinese word, number string, English character string, all-shape punctuation string and half-shape punctuation string. 
In the designed extraction algorithm model, the limited set of state is denoted as below: Where the explanation for each of state is in table 1: 
After the introduction to designed model structure of extraction algorithm, we take a look to the training process of algorithm. The training process of designed IE algorithm is mainly divided into 3 steps: training process of model. Step 1: the statistical process of W CA. 
Firstly, we give the definition of W CA , W CA (Co-Appearing-Word) is the same type adjacent character string which appears together with the extraction fact, info_i , in the same sentence. According to the relative position between W CA and info_i , we divide W CA into two types: W T (Triggering-Word) and W P (Positioning-Word). W T is the W CA which appears inside of E-A and W P is the W CA which appears outside of E-A. So, we conduct the statistics to the each sentence of the abstract text of Chinese Sci-character information, slot_i . Step 2: the training process of model state parameters 
In this training process, the extraction m odel is divided into two states only: state s i initial extraction model, called as  X  0 . Then, we can make sure how many states information by using the extraction results of initial model. Step 3: the training process of extraction model 
We obtain the final state parameter from the extraction model which is trained in algorithm to train the train text, and obtain the final extraction model. 
In the extraction processes, we select the Veterbi algorithm as the decoding algorithm. We use the high power solid laser as the subject to search the Chinese journal full text database and obtain 213 different records. We take the abstract part of Sci-Tech document in 110 records whose content is laser experiment as the object text, taking 81 records as training text and taking 31 records as testing text. We can get information extraction template which has 5 slots in this field by using the method of semi-supervised word frequency statistic. It is shown in table 2. 
Firstly, in our designed Word-based Chinese Document Experimental System [8], the training text and testing text are transformed into the text of CDM format. Then, for the 5 slots of output template, we can obtain the 10 sets of triggering word W T and positioning word W P from training text by using the method of semi-supervised word frequency statistic separately. 
Then, we go to the training stage of extraction model state value. We use the initial out that the states of slot2 and slot3 are easily mixed up in the error analysis. So, we process of training. We choose the largest differentiation degree w Pi in the W P set of process. So, there are totally 12 states in the training process of extraction model. 
Next, we go to the process of W CA selection model re-optimization. We conduct the re-optimization to the parameter of extraction model in training text by using the designed W CA selection strategy. During this process, the changing of F value with the W
CA selection is shown in figure 1: 
From the figure, we can see that the whole optimization process is divided into 3 processes which are shown as A, B, C. The process A is the first stage of increasing word strategy. We set a threshold and choose the word frequency of W CA whose value order of word frequency in 10 sets of W CA , and in every training round we choose a W
CA which makes F value increase fastest as the observation value to be kept in the set of observation value of extraction model. After F value stop increasing with 5 W CA increasing, the process A is end and go to process B, there are 70 W CA to be selected at this time. 
The process B is the second stage of increasing word strategy. In this stage, we put the rest of W CA in the 10 sets of W CA as the observation value into the training process and choose a W CA which makes F value increase fastest as the observation value process C, there are 86 W CA to be selected at this time. Process C is the stage of decreasing word strategy. During this process, we delete W
CA from the set of observation value one by one according to the opposite order in decreasing some W CA to cause F value decrease, the process C is ended and the whole 42 W CA kept for the extraction model after finishing the whole optimization process. 
Then, we use the extraction model after optimizing to do the extraction for the testing text and get the values of R, P, F-means for R=96.38%, P=88.67%, F-means=92.39% respectively. 
From the analysis above, we can see that both process A and B are the processes to optimize the extraction model by increasing W CA in every training round. With the increasing of W CA more extraction area can be found in the process of decoding. So, W
CA increasing. At same time, for the process A and B, the word frequency selected in the process A is higher than that of process B so that the speed of increasing for F already obtained the most optimized F value in the training text, but the parameter of extraction model is not the most optimized at this moment. We need to do the optimization to the dimension of observation layer of extraction model under the situation of keeping F value invariable by using decreasing word strategy. In the process C, for A,B,C three W CA , because the information provided by A and C already made some extraction area to be found in the process of decoding, the decreasing of B will not cause F value to decrease. We take the Chinese Sci-tech journal abst ract text as the object and design the W CA -Selection Chinese free-text HMM IE algorithm And then, we proposed the idea of W
CA selection model re-optimization and concrete selection optimization strategy according to the features of W CA . 
Then, we conduct the experimental verifi cation to the abstract texts which belong to the same subject in CAJ network and get the satisfied result: Recall ratio is 96.38%, Precision ratio is 88.67%, and F-means value is 92.39%. The experiment results show that the designed extraction algorithm and W CA selection optimization strategy have good performance in the Chinese free text with less redundancy information. 
Next, we will do some research separately to 2 kinds of W CA for the different effect during the process of information extraction and the different influence to the extraction result so that we can further complete the designed W CA selection strategy. 
