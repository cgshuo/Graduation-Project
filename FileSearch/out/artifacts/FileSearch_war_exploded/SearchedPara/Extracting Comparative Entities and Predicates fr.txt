 Almost every day, people are faced with a situ a tion that they must decide upon one thing or the other. To make better decisions, they probably attempt to compare entities that they are interes t ing in. These days, many web search engines are helping people look for their interesting entities. It is clear that getting information from a large amount of web data retrieved by the search e n gines is a much better and easier way than the tradi tio n al survey methods. However, it is also clear that directly reading each document is not a pe r fect solution. If people only have access to a small amount of data, they may get a biased point of view. On the other hand, investigating large amounts of dat a is a time -consuming job. Therefore, a comparison mining system, which can automatically provide a summary of compa r ison s between two (or more) entities from a large quantity of w eb documents , wou l d be very useful in many areas such as ma r keting .

We divi de our work into two tasks to effe c tively build a comparison mi n ing system. The first task is related to a sentence classification problem and the second is related to an information e x traction problem.
 Task 1. Classifying comparative sentences into one non -comparative class and seven comparative classes (or types); 1) Equality, 2) Sim i larity, 3) Difference, 4) Greater or lesser, 5) 
Superlative, 6) Pseudo, and 7) Implicit comparisons. The purpose of this task is to eff i ciently perform the following task.
 Task 2. Mining comparative entities and pred i cates taking into account the characteristics of each type. For example, from the sentence  X  Stock -X is worth more than stock -Y.  X  belon g ing to  X  4) Greater or lesser  X  type, we extract  X  stock -
X  X  as a subject entity (SE),  X  stock -Y  X  as an object entity (OE), and  X  worth  X  as a co m parative predicate (PR). These tasks are not easy or simple problems as described below. 
Classifying comparative sentences (Task 1): For the first task, we extract comparative se n tences from text documents and then class i fy the extracted comparative sentences into s even co m parative types. Our basic idea is a k eyword search. Since Ha (1999 a ) categorized d o zens of Korean co m parative keyword s , we easily build an initial keyword set as fo l low s: In addition, we easily match each of these keywords to a particular type anchored to Ha X  X  r e search, e.g.,  X   X  ( [gat] : same)  X  to  X  1) Equality  X ,  X   X  X  X  ( [bo -da] : than )  X  to  X  4) Greater or les s er  X  . However, any method that depend s on just these linguistic -based keywords ha s obvious limit a tions as follows: 1)  X  ling is insufficient to co v er all of the actual 2) T here are many non -comparative sentences 3) There is no one -to -one relatio n ship between Mining comparative entities and predicates (Task 2): Our basic idea for the second task is s e lecting candidates first and finding answers from the c andidates later. We regard each of noun words as a candidate for SE/OE, and each of a d jective (or verb) words as a candidate for PR. However, this candidate detection has serious problems as fo l lows: 4) T here are many actual SEs, OEs, and PRs that 5) There are many sentences with no OE, We focus on solving the above five problems. We perform var ious experiments to fin d relevant fe a tures and proper machine learning techniques . The final exper i mental results in 5 -fold cross validation show the overall accuracy of 88.59% for the first task and the overall accuracy of 86.81% for the second task.

The remainder of the paper is organized as fo l lows. Section 2 briefly introduces related work . Section 3 and Section 4 describe our first task and second task in detail, respectively. Section 5 reports our experiment al results and finally Se c tion 6 co n cludes . Linguistic r esearchers focus on defining the sy n tax and semantics of compa r ative constructs. Ha (1999 a; 1999b ) classified the structures of K o rean comparative sentences into several classes and arranged compar i son -bearing words from a linguistic perspective. Since h e summarized the modern Korean co m parative studies, his research helps us have a linguistic point of view. We also refer to Jeong (2000) and Oh (2004). Jeong classified adjective superlatives using certain measures, and Oh discussed the gradability of co m p aratives.

In computer engineering, we found five pr e vious studies related to comparison mining. Ji n dal and Liu (2006a; 2006b) studied to mine co m parative relations from English text documents . They used comparative and superlative POS tags, and some a d diti onal keywords . The ir methods applied Class Sequential Rules and Label S e quential Rules . Yang and Ko (2009; 2011) st u died to extract comparative sentences in K o rean text documents. Li et al. (2010) studied to mine comparable entities from English compar a tiv e questions that users posted online. They f o cused on finding a set of comparable entities given a u s er X  X  input entity. 
O pinion mining is also related to our work because many compar a tive sentences also contain the speaker X  X  op i nion/sentiment. Lee et al. (2008) surveyed various techniques that have been d e veloped for the key tasks of opinion mining. Kim and Hovy (2006) introduced a methodology for analyzing judgment opinion . Riloff and Wiebe (2003) presented a bootstrapping process that learns li n guistical ly rich extraction patterns for subjective expre s sions. 
In t his study , three learning techniques are employed : the maximum entropy method (MEM) as a representative probabilistic model, the su p port vector machine (SVM) as a kernel model , and tran s formation -based learning (TBL) as a rule -based model . Berger et al. (1996) pr e sented a Maximum Entropy Approach to natural la n guage processing . Joachims (1998) introduced SVM for text classification. Various TBL studies have been pe r formed. Brill (1992; 1995) first introduced TBL and pr e sented a case study on part -of -speech tagging. Ramshaw and Marcus (1995) applied TBL for locating chunks in tagged texts. Black and Vas i lakopoulos (2002) used a modified TBL technique for Named Entity Recogn i tion. We first classify the sentences into compar a tives and non -comparatives by extracting only co m paratives from text documents. Then we classify the co m paratives into seven types. 3.1 Extracting comparative sentences from O ur strategy is to first detect Comparative Sentence candidates (CS -candidates) , and then eliminate non -comparative sentences from the cand i dates. As mentioned in the introduction section, we easily construct a linguistic -based keyword set,  X  ling . However, we observe that  X  ling is not enough to capture all the actual comparison e x pressions. Hence, we build a comparison lexicon as follows:  X  Comparison L exicon =  X  ling U {Additional This lexicon is composed of three parts. The first part includes the elements of  X  ling and their sy n onyms . The second part consists of idioms. For example, an idiom  X  X  X   X  X  X   X  X  X  X  [X -ga meon -jeo u -seot -da ]  X  commonly means  X  The winner is X  X  while it literal ly mean s  X  X  laughed first  X . The last part consists of l ong -distance -words s e quence s, [da] &gt; X  . This sequence means that the sentence is formed as &lt; S(X) + V + but + S(Y) + V &gt; in English (S: su b ject phrase; V: verb ph rase; X, Y: proper nouns) . We could r e gard a word,  X   X  X  ( [ ji -man ] : but), X  as a single keyword. However, this word also c aptures n u merous non -comparative sentences. Namely, the precision value can fall too much due to this word . By u s ing long -distance -words sequences instead of single ke y word s , we can keep the precision value from dropping s e riously low.

The comparison lexicon finally has a total of 177 elements. We call each element  X  X K X  h e reafter. Note that our lexicon does not include comparative/superlati ve POS tags. Unlike En g lish, there is no Korean compa r ative/superlative POS tag from POS tagger commonly. Our lexicon co v er s 95.96% of the comparative sentences in our corpus. It means that we successfully d e fined a comparison lexicon for CS -candidate d e te ction . However, the lexicon shows a relatively low pr e cision of 68.39%. While detecting CS -candidates, the lexicon also captures many non -comparative se n tences , e.g., following Ex1: rise tomorrow .) This sentence is a non -comparative sentence even though it contains a CK,  X   X  [gat] . X  This CK ge n erally means  X  same , X  but it often expresses  X  conjecture . X  Since it is an adjective in both ca s es, it is difficult to di sti n guish the difference.
To effectively filter out non -comparative se n tences from CS -candidates, we use the sequences of  X  continuous POS tags within a radius of 3 words from each CK  X  as features. Each word in the sequence is replaced with its POS tag in o r der to reflect various expressions. However, as CKs play the most important role, they are represented as a combination of their lexicaliz a tion and POS tag, e.g.,  X   X  /pa 1 . X  Finally, the fe a ture has the form of  X  X  X  y  X  (  X  X  X  means a s e quence and  X  y  X  means a class ; y 1 : comparative, y 2 : non -comparative ). For i n stance,  X  &lt; pv etm nbn  X  /pa ef sf 2 &gt;  X  y se n tence. Finally , we achieved a n f1 -scor e of 90.23% using SVM. 3.2 Classifying comparative sentences into As we extract comparative sentences successfu l ly, the next step is to classify the comparatives into different types. We define seven compar a tive types and then employ TBL for compar ative sentence cla s sification. 
We first define six broad comparative types based on modern Korean linguistics : 1) Equality, 2) Similarity, 3) Difference, 4) Greater or lesser, 5) S u perlative, 6) Pseudo comparisons . T he first five types can be understood i ntuitively, whereas t he sixth type needs more explanation.  X  6) P seudo  X  co m parison includes comparative sentences that compare two (or more) properties of one entity such as  X  Smartp hone -X is a computer r a ther than a phone.  X  This type of sentence is o f ten cl assified into  X  4) Greater or lesser .  X  Ho w ever, since this paper focuses on comparisons between different entities, we separate  X  6) P se u do  X  type from  X  4) Greater or lesser  X  type. 
The seventh type is  X  7) I m plicit  X  comparison. It is added with the goal of c overing literally  X  implicit  X  comparisons. For example, the se n tence  X  X hopping Mall X guarantees no fee full refund, but Shopping Mall Y requires refund -fee  X  does not directly compare two shopping malls . It i m plicitly gives a hint that X is more beneficial to use than Y. It can be cons i dered as a non -comparative sentence from a li n guistic point of view. However, we conclude that this kind of sentence is as important as the other explicit comparisons from an engineering point of view. 
After defining the seve n comparative types, w e simply match each sentences t o a particular type based on the CK types; e.g., a sentence which contains the word  X   X  X  ( [ga -jang ] : most ) X  is matched to  X  Superlative  X  type. Howe v er, a method that uses just the CK info r mation has a seri ous problem . For example, although we eas i ly match the CK  X   X  X  X  ( [ bo -da ]: than) X  to  X  Grea t er or lesser  X  without doubt , we observe that the type of CK itself does not gua r antee the correct type of the sentence as we can see in the follo w ing three sentences: ta] : The quality of X is neither better nor worse than that of Y.)  X  It can be interpreted as  X  X he quality of X is similar to that of Y. X  ( Similarity ) jil -I jo -ta ] : The quality of X is better than that of 
Y. )  X  It is consistent with the CK type ( Greater or lesser ) t a]: X is better than any other cameras in quality .)  X  It can be interpreted as  X  X  is the best camera in quality . X  ( Superlative ) If we only rely on the CK type, we should l a bel the above three sentences as  X  Greater or lesser  X  . However, each of the se three sentences b e longs to a different type. This fact addresses that many CKs could have an ambiguity problem just like the CK of  X   X  X  X  ( [bo -da]: than) .  X  To solve this ambiguity pro b lem, we employ TBL. We first roughly annotate the type of sentences using the type of CK itself. After this in i tial annotating, TBL generates a set of error -driven transformation rules, and then a scoring f unction ranks the rules. We define our scoring function as Equation (1): Here, r i is the i -th transformation rule, C i is the number of corrected sentences after r i is a p plied, and E i is the number of the opp osite case. The ranking process is executed iteratively. The iter a tions stop when the scoring function reaches a certain threshold. We finally set up the thr e shold value as 1 after tuning. This means that we use only the rules whose score is 2 or more. This section explains how to extract comparative ent i ties and predicates. Our strategy is to first detect Comparative Element candidates (C E -candidates) , and then choose the answer among the candidates.

In this paper, we only present the results of two types:  X  Greater or lesser  X  and  X  S u perlative .  X  As we will see in the experiment section, these two types cover 65.8% of whole comparative sentences. We are still studying the ot h er five types and plan to report their r e sults soon. 4.1 Comparative elements We extract three kinds of comparative el e ments in this paper : SE, OE and PR In Ex5 sentence,  X  X  X  X  X  (Pie X) X  is a SE ,  X  X   X  X  X  (Pie Y) X  is an OE, and  X   X  X  X   X  X  X  X  (cheaper and more delicious) X  is a PR. In Ex6 sentence,  X  Z  X  is a SE,  X   X  X   X  X  X  X  ( the presidential candidates) X  is an OE, and  X   X  X  X  X  X  X  X  ( trustwo r thy ) X  is a PR. 
Note that comparative elements are not l i mited to just one word. For example,  X   X  X  X   X  X  X  X  (cheaper and more delicious) X  and  X   X  X   X  X  X  X  (the preside ntial candidates) X  are composed of multiple words. After investigating numerous actual comparison e x pressions, we conclude that SEs, OEs, and PRs should not be limited to a single word. It can miss a considerable amount of important information to restric t comparative elements to only one word. Hence, we define as fo l lows:  X  Comparative elements (SE, OE, and PR) are composed of one or more consec u tive words.
 It should also be noted that a number of superlative sentences are expressed wit h out OE. In our corpus, the percentage of the Superlative se n tences without any OE is c lose to 70%. Hence, we define as follows:  X  OEs can be omitted in the Superlative se n tences. 4.2 Detecting CE -candidates As compar a tive elements are allowed to have multiple words, we need some preprocessing steps for easy detection of CE -candidates. We th us apply some simplification processes. Through the simplification processes, we represent potential SEs/OEs as one  X  X  X  and p o tential PRs as one  X  X  X . The following process is one of the simplific a tion processes for making  X  X  X  -Change each noun (or each no un co m pound) to And, the following two e x ample processes are for  X  X  X . -Change  X  X a (adjective) X  and  X  X v (verb) X  to a -Change  X  X  + ecc (a suffix whose mea n ing is In addition to the above examples, several processes are performed. We regard all the  X  X  X  X  as CE -candidates for SE/OE and all the  X  X  X  X  as CE -candidates for PR. It is possible that a more analytic method is used instead of this simplif i cation task, e.g., by a syntactic parser. We leave this to our future work. 4.3 Finding final a n swers We now generate features. The patterns that co n sist of POS tags, CKs, and  X  X  X / X  X  X  sequences within a r a dius of 4 POS tags from each  X  X  X  or  X  X  X  are considered as f eatures. 
Original s e n tence
After POS tagging
After si m plification process Patterns for 
SE Patterns for 
OE Patterns for 
PR Table 1 : F eature examples for mining comparative 
T able 1 lists some examples. Since the CKs play an important role, they are represented as a combination of their lexicalization and POS tag. After feature generation, we calculate each pro b ability value of all CE -candidates using SVM. For example, if a se n tence has three  X  X  X  X , one  X  X  X  with the highest probability value is s elected as the a n swer PR. 5.1 Experime n tal Settings The experiments are conducted on 7,384 se n tences collected from the web by three trained h u man labelers. Firstly, t wo labelers annotated the corpus. A Kappa va l ue of 0.85 showed that it was safe to say that the two labelers agreed in their judgments. Secondly, the third labeler ann o tated the conflicting part of the co rpus. A ll three labelers discussed any conflict, and finally reached an agreement. Table 2 lists the distrib u tion of the corpus .
 Compar a tive 5.2 Classifying comparative sentences Our experimental results for Task 1 showed an f1 -score of 90.23% in extracting comparative se n tences from text documents and an accuracy of 81.67% in classifying the comparative se n tences into seven compar ative types. 
The integrated r e sults showed an accuracy of 88.59%. Non -comparative sentences were r e garded as an eighth comparative type in this integrated r e sult. It means that we classify entire sentences into eight types (seven comparative types and one non -comparative type). 5.2.1 Extracting comparative sentences.
 Before evaluating our proposed method for co m parative sentence extraction , we conducted four experiment s with all of the lexical unigrams and b i grams using MEM and SVM. Among these four case s, SVM with lexical unigrams showed the highest pe r formance , an f1 -score of 79.49%. W e regard this score as our baseline pe r formance.
Next, we did experiments using all of the co n tinuous lexical sequences and using all of the POS tags sequences within a r adius of n word s from each CK as features ( n =1,2,3,4,5). Among these ten cases,  X  the POS tags sequences within a radius of 3 X  showed the best performance. B e sides, a s SVM showed the better performance than MEM in overall experiments, we employ SVM as our p roposed learning technique. Table 3 summari z es the overall results.
 comparison le x icon comparison le x icon As given above, w e successfully d e tected CS -candidates with considerably high r e call by using the comparison lexicon . We also successfully filtered the candidates with high precision while still pr e serving high recall by applying machine learning tec h nique. Finally, we could achieve an outstanding pe r formance , an f1 -score of 90.23%. 5.2.2 Classifying comparative se n tences into seven types.
 Like the previous comparative sentence extra c tion task, we also conducted experiments for type classification using the same features ( cont i nuous POS tags sequences within a r a dius of 3 words from each CK ) and the same learning technique (SVM). Here, we achieved an accur a cy of 73.64%. We regard this score as our baseline perfo r mance.
Next, we tested a completely different tec h nique, the TBL method. TBL is well -known to be relatively strong in sparse problems. We o b served that the performance of type classification can be influenced by very subtle differen ces in many cases. Hence, we think that an error -driven a p proach can perform well in comparative type classific a tion. Experimental results showed that TBL actually performed better than SVM or MEM. 
In the first step, we roughly annotated the type of a sen tence using the type of the CK itself. Then, we gene r ated error -driven transformation rules from the incorrectly annotate d sentences . Transformation templates we defined are given in T a ble 4. Numerous transformation rules were generated on the basis of the templates. For example,  X  X hange the type of th e current sentence from  X  Greater or lesser  X  to  X  Superlative  X  if this se n tence holds the CK of  X   X  X  X  ( [ bo -da ]: than)  X  , and the second pr e ceding word of the CK is tagged as mm  X  is a transformation rule generated by the third template.

For evaluation of threshold va l ues, we performed experiments with three options as gi v en in Table 5. Threshold 0 1 2 Accuracy 79.99 81.67 80.04 We achieved the best performance with the threshold option 1. Finally, we class ified compar a tive sentences into seven types using TBL with an accuracy of 81.67%. 5.2.3 Integrated results of Task 1 We sum up our proposed method for Task 1 as two steps as follows; 1) The comparison lexicon detects CS -candidates 2) TBL then classifies the sentences placed in the The integrated results showed an overall accur a cy of 88.59% for the eight -type classification. To evaluate the effectiveness of our two -step processing, we pe r formed one -step processing experiments using SV M and TBL. Table 6 shows a compar i son of the results. (classifying eight types at a time) As shown above, Task 1 was successfully d i vided into two steps. 5.3 Mining comparative entities and For the mining task of comparative ent i ties and predicates, we used 460 comparative se n tenc es ( Greater or lesser : 300, Superlative : 160). As previously mentioned, w e allowed mu l tiple -word comparative elements. Table 7 lists the po r tion of multiple -word comparative el e ments. Multi -word rate SE OE PR Greater or lesser 30.0 31.3 8.3 Table 7 : Portion (%) of multiple -word compar a tive As given above, each multiple -word portion, e s pecially in SEs and OEs, is quite high. This fact proves that it is absolutely necessary to allow m ultiple -word comparative elements. Rel a tively lower rate of 9.4% in Superlative -OEs is caused by a number of omitted OEs. If sentences that do not have any OEs are excluded, the portion of multiple -words becomes 32.6% as written in p a rentheses.

Table 8 sho ws t he effectiveness of simplific a tion processes. We calculated the error rates of CE -candidate detection before and after simplif i cation processes. 
Greater or Superl a t ive Table 8 : Error rate (%) in CE -candidate dete c tion Here, the first value of 34.7% means that the real SEs of 104 sentences (among total 300 Greater or lesser sentences) were not d e tected by CE -candidate detection before simplification processes. After the processes, the error rate d e creased to 4.7%. The significant differences b e tween before and after indicate that we succes s fully detect CE -candidates through the simplif i cation processes. Although the Superlative -OEs still show the s e riously high rate of 75.6%, it is also caused by a number of omitted OEs. If se n tences that do not have any OEs are excluded , the error rate is only 6.3% as written in pare n theses . 
The final results for Task 2 are reported in T a ble 9. We calculated each probability of CE -candidates using MEM and SVM. Both MEM and SVM showed outstanding performance; there was no significant difference b e tween the two machine learning methods (SVM and MEM). Henc e, w e only report the results of SVM. Note that many sentences do not contain any OE. To ide n tify such sentences, if SVM tagged every  X  X  X  in a se n tence as  X  X ot OE X , we tagged the sentence as  X  X o OE X  . Greater or lesser 86.00 89.67 92.67 Table 9 : Final results of Task 2 (A c curacy, %) As shown above , we successfully e x tracted the comparative entities and predicates with outstanding performance, an ov erall accur a cy of 86.81%. This paper has studied a Korean comparison mining system. Our proposed system achieved an accuracy of 88.59% for classifying compar a tive sentences into eight types (one non -comparative type and seven c omparative types), and an accuracy of 86.81% for mining compar a tive entities and predicates. These results demo n strated that our proposed method could be used effectively in practical applications. Since the comparison mining is an area of increasing inte r est around the world, our study can contribute greatly to text mining r e search.
 In our future work, we have the following plans. Our first plan is to complete the mining process on all the types of sentences. The second one is to conduct more experiments f or obtaining better performance. The final one is about an i n tegrated system. Since w e perform Task 1 and Task 2 separately, we need to build an end -to -end system. This research was supported by Basic Science Research Program through the N ational Research Foundation of Korea (NRF) funded by the Mi n istry of Education, Science and Technology (2010 -0015613)
