 Recent advances in smart metering technology enable util-ity companies to have access to tremendous amount of smart meter data, from which the utility companies are eager to gain more insight about their customers. In this paper, we aim to detect electric heat pumps from coarse grained smart meter data for a heat pump marketing campaign. However, appliance detection is a challenging task, especially given a very low granularity and partial labeled even unlabeled data. Traditional methods install either a high granularity smart meter or sensors at every appliance, which is either too ex-pensive or requires technical expertise. We propose a novel approach to detect heat pumps that utilizes low granularity smart meter data, prior sales data and weather data. In par-ticular, motivated by the characteristics of heat pump con-sumption pattern, we extract novel features that are highly relevant to heat pump usage from smart meter data and weather data. Under the constraint that only a subset of heat pump users are available, we formalize the problem into a positive and unlabeled data classification and apply biased Support Vector Machine (BSVM) to our extracted features. Our empirical study on a real-world data set demonstrates the effectiveness of our method. Furthermore, our method has been deployed in a real-life setting where the partner electric company runs a targeted campaign for 292,496 cus-tomers. Based on the initial feedback, our detection algo-rithm can successfully detect substantial number of non-heat pump users who were identified heat pump users with the prior algorithm the company had used.
 H.2.8 [ Database Management ]: Database Applications-Data Mining Algorithms, Experimentation Smart Meter Data Mining, Feature Extraction, Heat Pump Detection, Positive and Unlabeled Learning
Recently smart metering infrastructure is being rapidly deployed in the United States and elsewhere. Smart meter data mining and related data management system have been popular in data management [13, 21, 26, 31] and data mining communities [14, 7, 28], e.g., energy disaggregation [14, 24], power theft detection [3, 20], etc. The smart meter data investigated therein is typically fine grained with a relatively small scale.

Unlike the studies in research communities, utility com-panies are the major entities that have access to tremendous amount of smart meter data. They are eager to utilize the data to know more about their customers. A typical exam-ple originates from marketing perspective, in which utility companies aim to detect a particular appliance. The reason is that many electric companies run various energy efficient marketing campaigns and try to encourage their customers replace inefficient appliances with more efficient alternatives. In general, marketing departments of the electric companies are required to run these campaigns through various com-munication channels such as bulk mail, direct phone calls, and so forth. However, the cost of reaching out to their large customer pool is significant. For instance, there are over 3 million household in Los Angeles, California. A rough cost per a bulk mail campaign is close to 1 USD (0.60 USD for a bulk mail and 0.40 USD for printing, sorting, and other labor cost), which costs more than 3 million USD for each marketing campaign. This type of campaign can run more efficiently if the electric companies could identify target cus-tomers who own and operate targeted appliances.

A fundamental functional block for the above example is an effective appliance detection algorithm. There are numer-ous methods that have been introduced by research commu-nities [21, 28, 31]. However, the existing algorithms and approaches rely on special sensors at every device or a sin-gle sensor at power outlet [21]. For example, Weiss et al. [31] designed a system in which smart meter data sampled at high frequency (1 hz), an appliance signature database and a single sensor monitoring the state of household cur-rent are integrated to disaggregate the total consumption into appliance level. Srinivasan et al. [28] applied several classifiers, e.g. Neural network and support vector machine to uniquely identify various types of devices using their dis-tinct harmonic  X  X ignatures X . All these works require data with a high sampling rate and prior domain knowledge of appliance signatures.

Unfortunately, it is nontrivial to adopt the existing ap-proaches to solve the emerging appliance detection prob-lem that the utility companies encounter. On one hand, they may not have fine grained data and appliance signa-tures. Given fine grained data, a simple clustering based approach can achieve very good performance [10]. However, given very coarse grained data such as daily consumption, it is very challenging to extract relevant features for build-ing high quality and meaningful clusters hence utility com-panies have to design a more sophisticated approach. On the other, fully labeled data and/or controlled experimental setting may not be available in real-world applications. In other words, the available data to the utility companies is mostly partially labeled, which prevents them from adopting the state-of-the-art supervised algorithms, such as support vector machine (SVM) [30] and random forest [5].
 To alleviate the requirement of high sampling frequency, Kolter et al. [14] used hourly consumption data and utilized discriminative sparse coding to model each device X  X  power consumption over one week, then combine learned models to predict the power consumption at device level to unseen households. Therefore, the device categories, such as TV, re-frigerators and electrical water heaters, can be inferred from different consumption level. But this approach assumes the individual device readings are available in the training phase, which is impractical in most cases. Besides, the granular-ity of data is still relatively high compared with daily data, which is available to vast population.

In this paper, we propose a novel approach to detect a par-ticular appliance:  X  X eat pump X  1 from coarse grained data with daily consumption and partial labeling information. More specifically, we utilize low granularity smart meter data, prior sales data and weather data to extract relevant features related with heat pump usage. Our approach does not have any assumption about the access to individual de-vice consumption or the prior knowledge of any appliance signature, but correlates the daily consumption with tem-perature and extracts features specific to heat pump usage. Given the fact that only a small portion of heat pump users are available from prior sales record (a.k.a partially positive labeled data), such a problem is characterized by positive and unlabeled data learning, in which  X  X ositive X  represents the small portion of users with heat pumps and  X  X nlabel X  means the rest large population that may or may not have heat pumps. We applied the state-of-the-art learning al-gorithm, biased SVM [18] that is designed specifically for positive and unlabeled data classification to our extracted features and achieved very competitive performance.
To summarize, our contributions in this paper are mul-tifaced. At the conceptual level, we take the first step to detect a particular appliance from coarse grained data com-pared with other methods which depend on fine grained
This is one particular campaign that we partnered with an electric company in the United States. data. At the system level, we integrate different data sets from different sources, including smart meter data, prior sales record and weather data, to perform feature extraction and heat pump detection. At the modeling level, we formu-late the problem as a positive and unlabeled data classifica-tion problem and apply the state-of-the-art method to our extracted features, including temperature dependent fea-tures related with heating and wavelet features from heating period (typically from November to February). To our best knowledge, we present the first case of performing a partic-ular appliance detection at a very coarse granularity smart meter data by integrating data sets from different sources. Experimental results show that our approach significantly improves prediction accuracy using real world data sets.
The rest of the paper is organized as follows: we first intro-duce related works in Section 2. We formalize the problem, and describe the details of our solution in Section 3. We present the experimental results in Section 4, and finally conclude the paper.
There are two research areas which are closely related to our work: appliance deteciton/recognition and positive and unlabeled learning.
The research topics on appliance detection problem can be classified into two categories based on the difference of hard-ware and software deployment. One is using single sensor to monitor the power outlet [21] or multiple sensor to mea-sure the electrical information of individual appliance [27]. The major problem is that it requires special technical ex-pertise for single sensor deployment or incurs huge expense for multiple sensor installation and maintenance.
The other utilizes data mining techniques to disaggregate overall consumption data into individual device level and associate different levels of consumption to existing appli-ance feature database [14, 24, 28]. The consumption data is typically sampled at high frequency, e.g. 1 second and 15 minutes. For example, Srinivasan et al. [28] extracted fea-tures from the input current waveform and applied several classifiers, such as Neural network and support vector ma-chine to uniquely identify various types of devices. Kolter et al. [14] developed discriminative sparse coding to learn a model for the power consumption of each device. Therefore, the device categories, such as TV, refrigerators and electrical water heaters, were inferred from different power consump-tion level. However, the prior knowledge about appliance consumption is difficult to obtain due to the rapid chang-ing world. In addition, hidden factors such as weather that affect energy consumption were ignored.

Our work is different from previous researches in the fol-lowing sense. First, instead of detecting all appliances from a very fine granularity data, we detect a particular appliance:  X  X eat pump X , which is a major energy consuming appliance in residential household. Second, we do not assume any prior knowledge about the appliance signature, e.g. power consumption, on or off state current et al. Hence our method is totally data driven without incurring extra cost. Finally, we integrate different data sources into a unique system, in which sales record and weather data are utilized to guide more effect heat pump detection.
Positive and unlabeled learning (PUL) is extensively stud-ied in data mining and machine learning communities from different perspectives, e.g. text categorization [18], Bioinfor-matics [9], Cheminformatics [34], collaborative filtering [22] et al.

Different from traditional supervised and semi-supervised learning where both positive and negative data are specified, the training data of PUL are composed of a set of positive data and a large amount of unlabeled data which can be positive or negative. Considering the heat pump detection problem, we only know a small portion of users having heat pumps from sales record data. For the rest large amount of users, they may or may not have heat pumps. Hence PUL is suitable tool since it aims to fully exploit the unlabeled data together with the limited positive data to learn more precise predictive models.

Two general approaches of PUL have been proposed. One is a two-step approach [19, 32], in which a certain reliable negative samples are iteratively identified from the unlabeled data first and then traditional classifiers (e.g. SVM, Naive Bayes) are applied to the reliable negative set and positive set. However, the performance of such a two-step approach highly depends on the quality of the identified negative sam-ples. The other is a one-step approach [9, 18], in which all the unlabeled samples are treated as negative and the model is trained only once. For example, biased SVM [18] is ob-tained by introducing different misclassification cost of the positive and negative samples to ordinary SVM [30]. The underlying principle is that if the sample size is large enough, minimizing the number of unlabeled examples classified as positive while constraining the positive examples to be cor-rectly classified will give a good classifier. Another exam-ple is logistic regression for positive and unlabeled learning (LRPU) [9], which estimates the conditional probability of the positive class given input samples directly. Though the marginal probability of the positive class and the conditional probability of the labeled positive samples have to be esti-mated as an intermediate step [35], it provides competitive performance as biased SVM as studied in [9].

In this paper, we adopt biased SVM (BSVM) [18] for heat pump detection after extracting features from daily consumption and weather data. Our experimental studies shows that BSVM outperforms LRPU on a real-world data set.
In this section, we describe the proposed heat pump de-tection framework. As mentioned earlier, our framework can be divided into two phases: feature extraction and heat pump classification. Before introducing them in detail, we first outline the notation of this paper.

We use lowercase letters to represent scalar values, lower-case letters with bold font to represent vectors (e.g.  X  ), uppercase letters to represent matrices, and uppercase cal-ligraphic letters to represent sets. Unless stated otherwise, all vectors in this paper are column vectors.
Given a smart meter data set P with daily consumption fromknownheatpumpusers 2 as well as another set of daily either from prior sales record or other reliable sources consumption data U from unknown users over the same time period, our aim is to build a predictive model that detects heat pump users.
The energy consumption data over a time period can be naturally modeled as a one-dimensional time series. With-out loss of generality, assume x  X  X P X  X } is the consumption over discrete time stamps t 1 ,t 2 ,  X  X  X  ,t n for one particular user, then x i is the consumption at time t i .

A naive way to learn with time series data is to treat the value at each time point as a feature. However, a major problem of such a way is that the dimensionality of feature space is very high. The high dimensionality will introduce the curse of dimensionality and cause problems in distance metrics [4]. Fortunately, consecutive values of a time series are usually dependent, highly correlated and contain a lot of redundancy. Therefore we seek a good feature represen-tation of time series that not only speeds up the learning algorithm, but has better performance.

First of all, we seek to choose some key empirical fea-tures that can capture key characteristics of the heat pump detection problem. The key underlying assumption is as fol-lows. If there is an electric heating and cooling system in a building, daily average electric energy consumption will be higher if the outdoor temperature is low, or the indoor set temperature is high, or the building has high heat loss, and so forth. Our potential empirical feature candidates are: temperature dependent heating parameter, temperature de-pendent cooling parameter, the ratio between the average energy consumption during the cooling period 3 and the average energy consumption during non-cooling and non-heating period, and the average energy consumption during the heating period 4 and the average energy consumption during non-cooling and non-heating period. We will discuss how to calculate them empirically based on energy consump-tion in the next subsection.

In addition, we use generic features of time-series data to capture additional characteristics between heat pump and non-heat pump users. Popular feature extraction techniques for time series include the Discrete Wavelet Transform (DWT) and the Discrete Fourier Transform (DFT). Both transfor-mation methods divide up time series data into different frequency components and then study each component with a resolution matched to its scale [17]. The main difference is that wavelets are localized in both time and frequency whereas the standard Fourier Transform is only localized in frequency. Another difference is that DWT is less computa-tionally complex with O ( n )timeascomparedto O ( nlogn ) for the fast Fourier transform, where N is the length of time series. In this paper, we adopt the DWT not only because DWT is fast, but DWT has produced competitive or better results in a bunch of time series data mining tasks, such as clustering [12, 33], classification [8, 29] and similarity search [23, 16]. A more comprehensive survey can be found in [17].
Temperature dependent heating features include average consumption in the heating period, ratio between the aver-age energy consumption during the heating period and the
June to September
November to February average energy consumption during non-cooling and non-heating period and temperature dependent heating param-eter. The first two are obvious hence we introduce the third term and explain why we focus on heating related features rather than cooling.

Space heating and cooling systems run to maintain in-door temperature at desired temperature levels. An electric heat pump system heats up and cools down a space with a bi-modal heat exchange mechanism. When outdoor temper-ature is lower than indoor temperature, heat travels through the building envelop, walls, windows, and ceilings to outside. This heat is lost by conduction. Also, heat travels through leaks, which is called infiltration. When outdoor tempera-ture is higher than indoor temperature, heat travels into the building by conduction, infiltration, radiation, people activ-ities, and appliances activities. Roughly speaking, indoor temperature is settled when (1) heat gain and transferred heat from indoor to outdoor are balanced in summer during summer and (2) heat loss and supplied heat are balanced during winter.

Once a building is built, building characteristics such as building envelop, walls, windows, ceilings, and openings do not change significantly over time. Only the outdoor tem-perature changes significantly day-by-day. Both conductive and infiltrative heat loss and gain are proportional to tem-perature difference between two thermal mass, which means that the space heating and cooling system consumes more energy when outdoor temperature is lower during winter and outdoor temperature is higher during summer.

Figure 1 illustrates the drybulb temperature 5 v.s. elec-tric energy consumption of a building where an electric heat pump is installed. As we can see that there is a clear cor-relation between the outdoor temperature and electric en-ergy consumption. In Figure 1, a and b are the heating and cooling slopes, which represent cooling and heating energy requirement per temperature drop (kWh/degree).

This correlation is used to quantify heating and cooling efficiency of a building and to predict heating and cooling energy consumption. One of the widely used model to iden-tify this correlation is a piece-wise linear regression model [2, 25], which can be written as follows: where J is a daily energy consumption in kWh, T is dry-bulb outdoor temperature, J bh is nominal energy consump-tion during heating required days, J bc is nominal energy consumption during cooling required days, J b is nominal en-ergy consumption during heating required days,  X  is a ran-dom variable that has a certain probability distribution with bounded second moment, a and b are heating and cooling consumption slopes.

In buildings where there is no electric heating nor cooling system, a and b are close to zero whereas in buildings with electric heat pump systems, a is a noticeable negative slope and b is a positive slope. In this paper, we also call the drybulb temperature is the temperature measured freely in the air without radiation and moisture, which is considered to be the most important variable for building energy loss and gain Figure 1: Energy Consumption in a House with an Figure 2: Histogram of Heating Slopes: Customers heating slope a as temperature dependent heating parameter and b as temperature dependent cooling parameter .
A natural question is whether we should use both a and b for prediction. Intuitively, high consumption in summer or winter may not be from heat pump only. Other appli-ances, such as windows AC unit and electric heater, can have correlation between temperature and energy consump-tion, though the slope may not be steep. To validate the effectiveness of them, we plot the distribution of a and b in Figures 2 and 3 with two sets of customers who own elec-tric heat pumps and other systems. Figure 2 shows a clear distinction between the electric heat pump customers and other customers. One possible reason is that majority of space heating systems use gas or heating oil, thus the cus-tomerswhodonotownanelectricheatpumpsystemtend to consume more gas or oil other than electricity.
It is worthwhile to inspect whether the temperature de-pendent cooling parameter b has similar characteristics to a . Figure 3 shows the histograms of the temperature de-pendent cooling parameter. As we can see, two groups have similar distributions. One possible reason is that majority of Figure 3: Histogram of Cooling Slopes: Customers non-heat pump users use electricity based cooling systems, e.g. windows AC unit. Though without heat pump us-age, the total energy consumption still have high correlation with drybuld temperature, which makes the temperature de-pendent cooling parameter b useless to distinguish between heat pump users and non-heat pump users. Based on the comparison between Figure 2 and 3, we conclude that the temperature dependent heating parameter a is more useful. Hence, we only extract heating related features.

In addition to the temperature dependent heating param-eter a , we also collect the average consumption in the heating period, the ratio between the average energy consumption during the heating period and during non-cooling and non-heating period. These two parameters are added to deal with electric heat pump users who have high variability in energy consumption during the heating period.
Though these temperature dependent heating features have a certain discriminative power to differentiate between heat pump and non-heat pump users, we argue that they can not capture all the characteristics of heat pump usage, especially in the time and frequency domain. Therefore, we still need to extract a set of generic features from energy consumption time series.

As discussed previously, we utilize discrete wavelet trans-form (DWT) to extract generic features. In this paper, we use Haar transform, which is a simple but powerful mother wavelet functions. Haar transform can be viewed as a series of averaging and differencing operations on the time series. The averaging part captures the trend of time series called approximation, and the differencing part depicts the sur-prise named detail coefficients. To illustrate the procedure, we compute the averages and differences between every two adjacent values of x =(8 , 6 , 2 , 10) T as shown in Table 1. The level 0 gives the original time series. In level 1, (7 , 6) are ob-tained by taking the average of (8 , 6) and (2 , 10) respectively. (  X  1 , 4) are the differences of (8 , 6) and (2 , 10) divided by 2 respectively. This process is repeated until level 2 (only one approximation coefficient left) is reached. The final Haar transform H ( x )=(6 . 5 ,  X  0 . 5 ,  X  1 , 4) is obtained. From the Table 1: Haar wavelet transform on a four element time series with different levels.
 Haar transformation, one can fully recover the original signal [17]. Figure 4: Tree structure of two-level Haar transfor-mation. x is the input time series, AX i is the i th level approximation and DX i is the detail coefficients.
The multi-level decomposition can be conveniently mod-eled as a tree shown in Figure 4, in which the root mode represents the original time series, and left/right child rep-resents approximations/detail coefficients respectively. Note that we just show two-level decomposition, there may be even more deeper decomposition for high dimension time series. Suppose k th level DWT produces the best perfor-mance on validation set, then the transformed feature vector from x is given by ( AX k ,DX k ,DX k  X  1 ,  X  X  X  ,DX 1 ). k can be tuned by cross-validation and we fix k = 2 throughout the paper. Our empirical study shows that k =2givesthebest performance.

Instead of applying DWT on the whole time period in-cluding four seasons, we specifically consider two specific seasons: summer and winter. The reason is that the two seasons require heating or cooling, which triggers a lot of consumption as a result of heat pump usage. As discussed beforehand, there may be a lot of consumption in cooling pe-riod, but it may be as a result of central AC or window AC unit. Therefore, the consumption in cooling period is not quite useful for determining heat pump usage. Similarly, for the time period without cooling or heating, there is no or seldom heat pump usage and the consumption is useless as well. Considering the above factors, we only extract wavelet features from heating period, e.g. November to February.
Once features are extracted from heat pump users and unknown users, the problem is converted to a classifica-tion problem with positive and unlabeled data. To tackle the problem, we utilize the state-of-the-art algorithm biased SVM [18].

Followed the convention in [18], suppose training sets are { ( x 1 ,y 1 ) , ( x 2 ,y 2 ) ,  X  X  X  , ( x n ,y n ) } ,where x i is the i th input vector and y its class label, y i  X  X  1 ,  X  1 } . Assume that the first l examples are positive examples (labeled 1), while the rest are unlabeled examples, which we label as -1. It was shown in [19] that if the sample size is large enough, minimizing the number of unlabeled examples classified as positive while constraining the positive examples to be correctly classified will give a good classifier [18]. In particular, consider the following objective: where C p and C u are regularization parameters to control the fitness for positive and unlabeled samples. We can vary C p and C u to enforce which part to be correctly classified. Intuitively, we give a big value for C p and a small value for C u because the unlabeled set, which is assumed to be negative, also contains positive data. The objective (2) is convex and a unique global solution exists. In this paper, we use the standard convex optimization package cvx [11] to solve the objective.

To choose C p and C u , a typical approach is to use a sep-arate validation set or cross validation to verify the perfor-mance of the resulting classifier with the selected values for C p and C u . A widely used metric is the F 1 score defined as F 1 =2 pr/ ( p + r )where p is the precision and r is the recall.
Unfortunately, it is impossible to evaluate precision with-out knowing negative examples. Hence we follow the psudo-F 1 metric: whichisproposedin[15],where Pr ( f ( x )=1)istheprob-ability that a user is classified as heat pump user. r can be estimated using the positive examples in the validation set and Pr ( f ( x ) = 1]) can be estimated from the whole valida-tion set. As explained in [18], this criteria works because it behaves similarly to the F 1 score in the sense that it is large when both p and r are large and is small if either p or r is small.
We have conducted a rigorous evaluation of our method in terms of detection accuracy using a set of real-world data, including smart meter consumption data, prior sales record data and local weather data collected from an anonymous utility company 6 . We implemented a prototype of our method in Matlab and compared our method with other two state-of-art models including ordinary Support Vector Machine (OSVM) [30], logistic regression for positive and unlabeled data classification (LRPU) [9].
To evaluate our method, we utilized a smart meter data set (daily consumption from 01/01/2011 to 09/23/2012) and a heat pump sales data set from an anonymous utility com-pany. In the data set, there are around 300k users residing in 6 regions. Based on the sales record, we single out 4565 electrical heat pump users who purchased heat pump in 2009
Due to the confidentiality agreement, the company X  X  infor-mation is anonymized. or 2010 and 1821 non-heat pump users before March 2012 . We also obtained the weather data for each region in the same time period as smart meter data. For evaluation pur-pose, we treat all 1821 non-heat pump users as unlabeled samples and randomly sample 10% (456) heat pump users named Q as additional unlabeled samples. Let P be positive samples and U be the unlabel samples and N be the nega-tive samples, it is clear that P has the cardinality of 4100 and U = N  X  Q has the cardinality of 2277.

As described in Section 3, our method extracts features specific to heating. The features include temperature depen-dent heating parameter, average daily consumption during heating period, the ratio between average consumption dur-ing heating period and other time periods other than heat-ing or cooling period and 2-level wavelet transform coeffi-cients from the time series of consumption in heating period. There are two heating periods given the time span, including 01/01/2011-02/28/2011 and 11/01/2011-02/28/2012. We ignore the consumption after March 2012 since the nega-tive set is valid only before that time and the total number of features is 139.

Besides the small data set with ground truth that can be used for model evaluation, we also have a large smart meter data set with 292,496 users without labels. Since there is no ground truth, we only provide prediction result and match any existing knowledge about heat pump sales or market share.
We use standard 10 fold cross validation to generate train-ing and testing data sets. For ordinary SVM, we use the libsvm [6] package with linear kernel. The C parameter is tuned from 1 , 10 , 20 , 30  X  X  X  , 100. For biased SVM, there are two parameters C u and C p . The first parameter, C u is to control the fitness of unlabeled set. The second pa-rameter, C p , is to control the fitness on positive labeled set. As suggested by [18], we choose C p from a set of larger numbers than C u . More specifically, we tune C p from 20 , 25 , 30 ,  X  X  X  , 50 and C u from 1 , 3 , 5 ,  X  X  X  , 17. Below we sum-marize the model construction and model evaluation.
Model Construction and Selection. For each data set, we partition the data set into 10-folds to perform 10-fold cross-validation (CV) with 9 folds for training and 1 fold for testing. We use an internal 5-fold CV on the training data set to select the optimal parameters for ordinary SVM and biased SVM based on the pseudo-F1 score defined in 3. We then generate a single model from the entire training set with the selected parameters and apply the model to the testing data set for prediction. For logistic regression proposed in [9], there is no additional parameter to tune hence the model is obtained from entire training data without interval cross validation. Furthermore, all methods treat positive labeled samples as positive and unlabeled data as negative.
Model Evaluation. For model evaluation, we collect the precision: ( TP/ ( TP + FN )), recall: ( TN/ ( TP + FP )), F score: (2*precision*recall/(precision+recall)) and accuracy: (( TP + TN ) /S ) of the trained model. Note that since the  X  X eal positives X  are positive samples and a few unlabeled samples in test set, the confusion matrix is a little different from binary classification. For each trial i, i =1 , 2 ,  X  X  X  a classifier is applied to the test set and yield the following They purchased heat pumps not for replacement after March 2012 5HFDOO $FFXUDF\ confusion matrix: where TP stands for true positive, FP Table 2: The confusion matrix for one cross valida-tion trial. P i , Q i and N i are subsets from P , Q and N respectively.
 stands for false positive, TN stands for true negative, FN stands for false negative, and S stands for the total number of samples.

All the values reported are collected from the testing data set only and are averaged across 3 replicates of the 10-fold cross validation in a total of 30 experiments. In this subsection, we show the performance of biased SVM (BSVM) compared with ordinary SVM (OSVM) and logistic regression for positive and unlabeled data mining (LRPU) [9]. The precision, recall, F 1 score and accuracy is shown in Figure 5. Since the standard deviation is around 1%-2% for each method, we omit them for simplicity.
From the lower right subfigure in Fig 5, we observe that the accuracy of ordinary SVM with linear kernel performs the worst. It is understandable since ordinary SVM imposes the same penalty on both positive and  X  X egative X  data set but the  X  X egative X  data set is not purely negative. Com-paring BSVM with LRPU, BSVM performs slightly better than LRPU. The possible reason is that biased SVM focuses predicting positive samples correctly while controlling the number of samples classified as negative. When the data set has many more positive samples, BSVM outperforms LRPU, though the latter approach has one step of proba-bility adjustment in training phase. To the contrary, LRPU performs slightly better when the data set has more under-lying negative samples. More detailed comparison between BSVM and LRPU can be found in [9].

To better understand the accuracy differences, we plot the average precision, average recall and average F 1 score of all methods in Fig 5. Similar to accuracy, OSVM performs worst in terms of precision, recall and F 1 score. The perfor-mance of LRPU is a little inferior to BSVM for precision and F 1 score, though the performance gap is not that significant. BSVM has a very high recall (a.k.a. the algorithm predicts most positive samples correctly) and a reasonable precision, which is supportive to the analysis beforehand. Such a per-formance of BSVM is desirable in a few applications such as heat pump marketing campaigns, because utility companies may not want to target too many customers who have heat pumps already.
We have demonstrated the classification performance of three classifiers on our extracted features. A natural ques-tion is how useful of the heating specific features. To validate the usefulness of extracted features, we apply biased SVM (BSVM) classifier to our features (HFeature) and general wavelet features (GFeature) extracted from all time period up to March 12.
In Table 3, it is clear that BSVM with our extracted fea-tures (HFeature) is superior to general wavelet coefficient features. For simplicity, we do not report standard deviation since it is around 1%-2% for each feature set. The general features (GFeature) that are extracted from all time periods not only contain the heating period, but encompass cooling and no cooling/heating period, in which the consumption is either from AC system for cooling or regular appliance without heat pump usage. Therefore, it is difficult to obtain an accurate classifier from such a feature set.
 Table 3: Performance comparison between our ex-tracted features (HFeature) and general features (GFeature).

As discussed before, the large data set with 292,496 users has no labeling information. The best result that we can deliver with this data set is to run our algorithm on it and match the result with existing knowledge of heat pump sales or market share. We trained a BSVM model from all the 4565 users applied it to the large data set.

Although rigorous assessment of the performance of pro-posed algorithm cannot be conducted on this data set, two evidences show the proposed algorithm work reasonably well. First, the proposed algorithm identified 129,238 (44.2%) as heat pump users from the 292,496 users. The result is con-sistent with the market share of heat pump in that region [1]. In addition, the classification result has been used by the partner electric company which had an existing algo-rithm to identify electric heat pump users. During the pre-campaign phase, the partner company randomly singled out 20 customers who are predicted as non-heat pump users by our algorithm for evaluation purpose. Among the 20 cus-tomers, 12 customers were identified as heat pump users by their algorithm, which is simply based on the overall energy consumption and the correlation with temperature. To val-idate the effectiveness of two models, We went through a validation process and found that the result of our method was indeed more accurate than the existing algorithm of our partner company. All the 12 customers are  X  X eal X  non-heat pump users.
In this paper, we propose a heat pump detection method for a targeted energy efficient marketing campaign. This simple yet practical problem has two unique challenges: (1) the input data is only partially labeled with only a subset of positive samples; and (2) only the extremely coarser grained energy consumption data is available for the detection algo-rithm due to the current smart meter reading infrastructure.
To tackle the two challenges, we formulate the detection problem as a positive and unlabeled data learning prob-lem and adopt biased SVM to solve it. Besides, we ex-tract both empirical features and generic features relevant to heat pump usage in heating period for classification. We have evaluated the performance against 4565 users X  data and showed our approach achieves better accuracy than other competitive methods.

Our method has been implemented and deployed in a real-life setting where the partner electric company runs this tar-geted campaign for 292,496 customers without prior sales record. Based on the initial feedback, our detection algo-rithm can successfully detect substantial number of non-heat pump users who were identified as heat pump users with the prior algorithm the marketing department had used.
The future work will focus on two directions: (1) create a good user interface to make the analytics easier for util-ity companies; (2) improve the scalability of the method. For example, for this simple task, the analytics needed to process approximately 970 million data points for approxi-mately 300k customers and run a couple of hours in a sin-gle machine. This number can be easily over multi-million customers served by a single grid operator. Therefore, the scalability and latency consideration of the algorithm need to be improved. [1] Ground source heat pumps: Overview of market [2] O. Balaca, H. Bulut, and T. Yilmaz. Analysis of [3] C. Bandim, J. Alves, J.E.R., J. Pinto, A.V., F. Souza, [4] K. Beyer, J. Goldstein, R. Ramakrishnan, and [5] L. Breiman. Random forests. Machine Learning , [6] C. Chang and C. Lin. Libsvm: a library for support [7] S.chiangLee,G.yuanLin,W.rongJih,andJ.Y.jen [8] G.V.Dijck,M.Wevers,andM.M.V.Hulle.
 [9] C. Elkan and K. Noto. Learning classifiers from only [10] H. Goncalves, A. Ocneanu, and M. Berges.
 [11] M. Grant and S. Boyd. CVX: Matlab software for [12] H. Guo, Y. Liu, H. Liang, and X. Gao. An application [13] T.Kato,H.S.Cho,D.Lee,T.Toyomura,and [14] J.Z.Kolter,S.Batra,andA.Y.Ng.Energy [15] W. S. Lee and B. Liu. Learning with positive and [16] Y. leh Wu, D. Agrawal, and A. E. Abbadi. A [17] T. Li, Q. Li, S. Zhu, and M. Ogihara. A survey on [18] B.Liu,Y.Dai,X.Li,W.S.Lee,andP.S.Yu.
 [19] B. Liu, W. S. Lee, P. S. Yu, and X. Li. Partially [20] D. Mashima and A. A. C  X  ardenas. Evaluating [21] F. Mattern, T. Staake, and M. Weiss. Ict for green: [22] R. Pan, Y. Zhou, B. Cao, N. Liu, R. Lukose, [23] I. Popivanov and R. J. Miller. Similarity search over [24] J. Powers, B. Margossian, and B. Smith. Using a [25] M. T. R Lindberg, A Binamu. Five-year data of [26] T. Saitoh, Y. Aota, T. Osaki, R. Konishi, and [27] H. Serra, J. Correia, A. Gano, A. de Campos, and [28] D. Srinivasan, W. Ng, and A. Liew.
 [29] A. Subasi. Eeg signal classification using wavelet [30] V. Vapnik. Statistical Learning Theory . John Wiley, [31] M. Weiss, A. Helfenstein, F. Mattern, and T. Staake. [32] H. Yu, J. Han, and K. C.-C. Chang. Pebl: positive [33] H. Zhang, T. B. Ho, Y. Zhang, and M. song Lin. [34] Y. Zhao, X. Kong, and P. Yu. Positive and unlabeled [35] J. T. Zhou, S. J. Pan, Q. Mao, and I. W. Tsang.
