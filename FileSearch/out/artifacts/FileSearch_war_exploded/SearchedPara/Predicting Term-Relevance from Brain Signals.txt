 Term-Relevance Prediction from Brain Signals (TRPB) is proposed to automatically detect relevance of text infor-mation directly from brain signals. An experiment with forty participants was conducted to record neural activity of participants while providing relevance judgments to text stimuli for a given topic. High-precision scientific equip-ment was used to quantify neural activity across 32 electro-encephalography (EEG) channels. A classifier based on a multi-view EEG feature representation showed improvement up to 17% in relevance prediction based on brain signals alone. Relevance was also associated with brain activity with significant changes in certain brain areas. Consequently, TRPB is based on changes identified in specific brain areas and does not require user-specific training or calibration. Hence, relevance predictions can be conducted for unseen content and unseen participants. As an application of TRPB we demonstrate a high-precision variant of the classifier that constructs sets of relevant terms for a given unknown topic of interest. Our research shows that detecting relevance from brain signals is possible and allows the acquisition of rele-vance judgments without a need to observe any other user interaction. This suggests that TRPB could be used in com-bination or as an alternative for conventional implicit feed-back signals, such as dwell time or click-through activity. H.3.3 [ Information Search and Retrieval ]: Relevance feedback; H.5.2 [ User Interfaces ]: Evaluation/Methodology Brain Signals; Relevance Prediction; EEG Relevance prediction is a central challenge of Information Retrieval (IR) research as it determines the information pre-sented to the user. In this paper, Term-Relevance Prediction from Brain Signals (TRPB) is proposed to automatically de-tect relevance of information directly from brain signals. Re-search has begun to build an understanding of the neural ac-tivity associated with relevance detection [25], but 1) the ex-act brain areas associated with relevance judgments remain unknown and 2) the methods to non-intrusively quantify the neuronal activity can be very noisy [19]. Nevertheless, the advantages of using brain signals to predict relevance are 1) that recording brain signals does not require any explicit user interaction, and 2) the signals can be captured with high throughput. That is, TRPB only requires participants to examine text stimuli (e.g., text displayed on the screen), and the signals can be continuously recorded. Consequently, TRPB can be used in combination with or even as an al-ternative for conventional implicit feedback signals, such as dwell time or click-through activity, that have been shown to be unreliable and are tightly connected to conventional user interfaces and explicit user interaction [13].
We use multi-view machine learning to solve the predic-tion problem and to cope with the uncertainties related to active brain areas and signal noise. The multiple kernel learning approach [9, 37] allows us to incorporate the tra-ditionally complementary approaches to electroencephalog-raphy (EEG) X  X ime-based (event-related potentials, ERPs) and frequency-based X  X imultaneously in order to maximize TRPB predictive power. We demonstrate that predicting relevance judgments is possible from brain signals alone, i.e., without any explicit user interaction or brain-computer in-terface (BCI) training. The high throughput of brain signals enables the capture of a huge number of relevance judgments for text stimuli in a relatively short time. In practical ap-plications it is possible to sacrifice recall and target high precision to take advantage of the high throughput. We demonstrate a high-precision variant of a relevance predic-tor, which is able to detect terms of the users X  given topics of interest.

We conducted an experiment in which EEG signals of 40 participants were recorded when they judged relevance of text stimuli. The main findings of TRPB using these data are the following:
Equal contributions; authors in alphabetical order 1. EEG signals can be used to automatically predict rel-2. Relevance prediction can be done independently of the 3. A high-precision variant of the classifier can automati-We were also able to confirm that the learned parameters of the classifiers (kernel weights) gave pointers to significant changes in brain activity. In an extended analysis we find significant activity in brain areas that have previously been found responsible for recognition and memory recall, and for organizing, maintaining, and implementing intentions [18]. This supports TRPB from a cognitive science perspective.
The rest of the paper is organized as follows. Section 2 re-views the related work ranging from mind-reading to brain-computer interfacing and using sensory signals as relevance feedback. Section 3 describes the experiment that was con-ducted to record participants X  neural activity. Section 4 presents the term-relevance prediction experiment, and Sec-tion 5 discusses the results of the experiments dividing them into classification results (5.1) and physiological findings (5.2). Section 6 demonstrates the effectiveness of TRPB in prac-tice with a high-precision classifier. We conclude and discuss the future work in Section 7.
Our work is related to a range of research from under-standing relevance as it is associated with brain activity, operationalizing these associations as sensory input for pre-dicting relevance as in relevance feedback research, interfac-ing between a computer and a human brain, and detecting patterns form brain activity without explicitly looking for a pre-known activity, as in mind-reading research.

Relevance. In information retrieval, relevance is a widely operationalized concept. A huge body of research exists that attempts to make use of relevance in practical systems, such as relevance feedback for improving retrieval, or rel-evance judgement to produce ground truth for evaluation purposes [36]. Cognitive scientists have long been inter-ested in mapping basic cognitive functions that are highly related to perceiving relevance (e.g., recognition and mem-ory recall [32, 42]) and reacting to relevant stimuli (e.g. implementing intentions [18]). The wealth of knowledge from various fields underlines the fundamental complexity of relevance, which may be the reason why the question of  X  X ow does relevance happen in the brain X  remains unan-swered [25].

Relevance prediction. In information retrieval, rele-vance judgments of the presented information can be ac-quired from user interaction and behavior data. Previously, researchers have made use of explicit [16], implicit [13], or affective [1, 24] user signals and then used features extracted from these signals to build models that can be used to auto-matically predict relevance of information. Among explicit interactions, such as typing queries, implicit monitoring of user actions has been found the most practical source of user signal, since it is less intrusive for the user and does not re-quire users to explicitly provide relevance judgments [13]. While previous research has found evidence that implicit behavioral signals, such as dwell time and click-through ac-tivity, can be predictors of users X  information needs, they can be noisy and unreliable [14, 40]. Collecting evidence of click-through activity and dwell time also requires previous explicit interaction between the user and the information retrieval system as well as monitoring of the users over a substantial amount of time. Explicit interaction is thus in-creasingly challenged by new information access media, such as augmented reality interfaces, which can make collecting conventional implicit feedback impractical, but allow wear-able sensors to be used to capture additional user signals.
Sensory signals. Recently, sensory signals have been utilized to measure human emotion and map emotional states to predict relevance [27, 28]. Such sensors can detect changes often expressed through a psychophysiology. Psy-chophysiology is reflected via cues, such as facial expressions, changes in the electrodermal activity [2], or variations in the skin temperature [6]. These physiological signals have pro-vided researchers with additional sources of information not previously available, and their effectiveness has been empir-ically studied [1, 2]. However, the results seem to be contra-dictory and validated only for image or video stimuli. These media allow measuring users for extended periods of time, which in itself is known to cause emotional responses and more substantial physiological responses [24, 25].

Brain-Computer interfacing. A related research field that has made use of EEG signals to allow (non-invasive) in-terfaces to control computers is brain-computer interfacing (BCI). The key difference that sets BCI apart from our re-search is its requirement for user-specific memorizing. BCI typically involves a user-specific training step in which the user is required to memorize a motoric action, for instance, pulling the left arm. The BCI system is then trained to explicitly detect such previously established behavior [41] in the control phase. Therefore, BCI does not detect the associated, natural brain patterns related to relevance as such, but creates an additional,  X  X rtificial X  pattern requir-ing extensive, conscious training. Given that a detection of relevance may also appear subliminal, the methods used in BCI are of limited use for the present study.

Mind-Reading. Mind-reading aims to use neuroimag-ing, typically functional Magnetic Resonance Imaging (fMRI), to learn specific patterns of brain activity with la-beled object stimuli in order to predict each of these differ-ent labels on an instance-by-instance basis from the fMRI data [23]. For example, when humans think of an object, many different areas of the brain activate. This pattern can then be learned by a machine learning system (based on the blood-oxygen-level-dependent activity). Conversely, the conventional neuroimaging research aims at finding corre-lates to external regressors such as task condition with ac-tivity in specific brain areas. The present approach to term-relevance prediction is similar to mind-reading in that we likewise aim to directly associate brain patterns with users X  subjective perception of stimuli. However, the prediction of relevance does not require association of specific patterns to specific objects but rather abstracting of a general pattern of brain activity in order to predict relevance for a stimulus.
Unique contributions. To our knowledge, our work is the first to predict term-relevance from brain signals for an IR scenario. What sets our research apart from the related research is the following: 1) we use brain signals captured via EEG alone without any other user signal, 2) we use text (see Section 3.5). stimuli, 3) we aim to learn brain patterns that are naturally associated with relevance judgments rather than to detect artificial, memorized patterns or pre-seen objects, 4) we aim for generalization over participants such that we can learn the underlying patterns of brain activation and use them for an unseen content and unseen participants.
We recorded the EEG signals of participants when they assessed relevance in response to term stimuli shown on a screen. The term stimuli were associated with a pre-determined topic. For example, participants were asked to judge relevance of terms  X  X nowmelt X  and  X  X ardware synchro-nization X  for a topic  X  X limate change and global warming X  (the first term is relevant, the second term is irrelevant). Terms were chosen to represent real search situations where terms are not always clearly discriminative. For example, the term  X  X orse code X  is not clearly irrelevant for the topic  X  X raq war X , and participants might differ in their relevance judgments. We used a highly controlled experimental setup to avoid possibly confounding effects related to hemispheric lateralization, eye-movements, and motor activity. For ex-ample, moving the eyes to read a word or moving the arm to give the relevance judgment are visible in the brain signals and can result in a classifier that learns, for example, the ef-fect of the arm-movement and not the effect of the relevance judgment.
Each participant judged relevance for six terms in six top-ics, for a total of 36 trials. The terms were randomly drawn from a pool of relevant (for each topic) and irrelevant (for all topics) terms defined by experts (column  X  X opic X  in Table 4 lists all six topics; column  X  X redicted top 5 relevant terms X  gives an excerpt of the terms). We used a balanced setup, i.e., for each topic three relevant and three irrelevant terms were shown to the participant. We randomized the order of the topics and the terms over participants. In addition, the relevance-key assignment was balanced (right or left hand used) between blocks of 12 trials to avoid possibly confound-ing hemispheric effect. The presented items were balanced to be apriori 50% relevant and 50% irrelevant. This ran-dom baseline, although not entirely realistic, ensures that we measure signals and effects related to relevance judg-ments and not, for example, related to the well-known P300 effect in an oddball-paradigm based experiment [10]. The re-coded data reflect the user X  X  subjective relevance judgment of the items (i.e., if a participant assessed the apriori irrel-evant  X  X orse code X  relevant for the topic  X  X raq war X , it was recoded as relevant), as this is the user X  X  real assignment and the corresponding effect is what we would also expect to predict from the brain signals.
Forty participants, 34 males and 6 females, took part in the study. The age of the participants ranged from 21 years to 47 years (Mean = 28.17, Median = 26.5). Most of them were post-graduate (37), and the rest were undergraduate students. Only two of the participants reported to be En-glish native speakers, seventeen different mother tongues being reported. Nevertheless, English reading skills were overall reported as advanced (Mean = 4.55, Median = 5; on a scale from 1 to 5). Six of the participants were left-handed. Participants reported themselves as physically and mentally healthy. Participation was compensated with two movie tickets. Table 1: The outcome of the neural-activity record-ing experiment: For each term presented to a par-ticipant, we collected its binary relevance judge-ment. Then, seven views were computed with fea-tures based on the recorded EEG signal during a certain period of time from term stimulus onset un-til corresponding relevance judgments. The 20 fea-tures represent the 20 most central channels F3, Fz, F4, FC5, FC1, FC2, FC6, C3, Cz, C4, CP5, CP1, CP2, CP6, P3, Pz, P4, O1, Oz, and O2.
 Relevance judgement view :
Relevance A binary relevance judgement provided Frequency-band-based views : Gamma1 4 Gamma2 5 Event-related-potential-based view :
At the beginning of the session the participants were briefed as to the procedure and purpose of the experiment. Then they were asked to sign an informed consent. They were furthermore informed on their right to withdraw from the experiment at any moment without any adverse conse-quence. The task was explained in more detail prior to the execution. The participants were instructed to rate the text stimulus either relevant or irrelevant by pressing either the M-key (using the right hand) or the X-key (using the left hand), on a QWERTY keyboard. They were instructed to provide the relevance judgement by pressing the key as soon as they were able to make the judgement. The next term was presented as soon as the participants pressed the relevance key. After the experiment, the participants were asked to fill out an online questionnaire regarding their background information.
A QuickAmp (BrainProducts GmbH, Gilching, Germany) amplifier recorded EEG at a sample rate of 100 Hz. EEG was recorded from 30 Ag/AgCl scalp electrodes, positioned using EasyCap elastic caps (EasyCap GmbH, Herrsching, Germany) on equidistant electrode sites of the 10% system excluding FT9/FT10. Figure 1 shows a participant with the full EEG sensor setup. Processing of EEG was conducted in EEGLAB [31] and included re-referencing to the common average reference and filtering of the data between 1 and 80 Hz with a notch filter between 46 and 54 Hz to reduce DC interference. After that, an automatic artifact correc-tion, based on the Efficient Independent Component Anal-ysis algorithm [17], as implemented in the AAR toolbox [8], was carried out in order to eliminate noise and potential confounds of common artifacts such as eye movements and blinks (see Figure 1).

Visual inspection of the raw data revealed extreme noise levels for two participants (possible, for example, because of loose electrodes or a cap which does not fit exactly). These participants X  data were removed from further analysis, which left us with S = 38 participants. In addition, we only con-sidered judgments that conformed with the ground truth to reduce noise induced by judgments possibly done by chance when participants were not sure about their judgement.
Frequency-band-based features (FBF) and event-related-potential-based features (ERPF) were extracted from the pre-processed signals. FBFs capture the change in the sig-nals for the whole time window when the user was shown the stimulus. ERPFs capture the changes in the signals for a specific short time window when a participant makes the relevance judgement X  X hich can be a much shorter time window and not necessarily at the time of giving the explicit relevance judgement but, e.g., a few (milli)-seconds after the term was shown on screen.

As no consensus exists on where and how binary relevance judgments of text stimuli affect neural activity, it was not possible to focus on, e.g., one specific frequency band or brain area. Therefore, we engineered a set of different FBFs and RPRFs in order to capture all the data that are po-tentially related to the relevance judgement. In both cases, the EEG was time-locked to the start (i.e., term shown on screen) or end (i.e., participant gave the relevance judge-ment) key events in the experiment. Table 1 gives a sum-mary of the seven views and the corresponding features.
In order to maximize the cortical activity signal and min-imize muscle-related activity and other artifactual noise, we included only the 20 centrally located electrodes. To obtain features, we calculated the power of the segment of 1 second following the term onset using the fast Fourier transform and applying log-transformation to normalize the signal. From this, a baseline was subtracted by the same procedure over the 1 second prior to the term onset.

Frequency-band-based views . An essential aspect of electroencephalography (EEG) is that different types of os-cillations, from the very slow theta (4 X 8 Hz) to the higher gamma (80 Hz), have been associated with various psycho-logical functions. For example, alpha activity has been re-lated to attentiveness [3], theta activity to attention [22], and alpha desynchronisation with semantic memory perfor-mance [15]. Possibly, decisions regarding relevance or ir-relevance, through acts of motor imagery [21] and motor control [38], would trigger activity in the beta frequency. Finally, given previous indications of the role of gamma ac-tivity in consciousness [4], one might expect relevant search results to be particularly accessible to consciousness and thus be associated with gamma activity. Further evidence for this comes from the observation that gamma-band os-cillations have been associated with attentional information processing through the salience of stimuli [12].

Furthermore, combinations of multiple frequency bands have also been shown to account for cognitive functions. For example, a combination of theta, alpha and beta bands has been found to be an index of engagement [31], which we therefore include here as another candidate. Other combi-nations of frequency bands were also tested from within the multi-view model as will be discussed further on.

Event-related-potential-based view. Event-related-potentials (ERPs) are brain responses resulting from spe-cific sensory, cognitive or motor events as measured using EEG. Generally, as stimuli are sensed, the modality-specific sensory areas in the brain are activated early, appearing in the EEG as peaks with a specific topography, latency and direction (negative or positive).

A set of ERPs have been associated with cognitive func-tions [20]. For example, the negative, fronto-central N2 has been associated with uncertainty and cognitive control [7], which could be related to the task of information retrieval. The P3 potential occurs generally after 300 ms and is com-monly separated in two sub-components called the P3a and P3b. The P3a has more frontal topography than the P3b and is associated with orientation and attention while the P3b is related to memory processing and retrieval [30]. The P3 is also one of the earliest potentials to be used for the purposes of BCI [5].

As with the frequency analyses, no apriori decision was made to exclude specific potentials. Instead, we calculated the cross-individual average of the ERP and defined the in-tervals, based on the literature and visual inspection, to oc-cur at 80 X 150 ms (P1), 150 X 250 ms (N1/P2), 250 X 450 ms (N2 or P3a) and 450 X 800 ms (N4 or P3b) for all the 20 elec-trodes mentioned earlier, relative to the 200 ms prior to the onset of the term, thus constituting 80 features in total.
Given the feature representation of the collected neural-activity data, we studied: 1. How well can we predict relevance judgments on terms 2. Which EEG views are important for the prediction? The first question is motivated by real search situations in which no user-specific training or calibration is necessarily possible. The second question is motivated by the currently unknown brain areas associated with relevance judgments; an answer to this question allows us to draw some conclu-sions about the cognitive basis of the brain areas that are found to be important for relevance prediction.

To answer these questions we have devised a set of bi-nary relevant/irrelevant classification experiments based on a multi-view learning method and a leave-one-participant-out strategy. Multi-view learning is the task of learning from two or more data sets with co-occurring observations. This concept perfectly suits our scenario, and we used it by treat-ing the different representations of the EEG signals as dif-ferent views of a relevance judgement given by a participant. Formally, each relevance observation r i = ( y i , v 1 ,..., v described by the binary relevance judgment y i and by K dif-ferent feature vectors v  X  (i.e., views). For each participant s , we have N s relevance observations, i.e., R s = { r s 1 ,...,r is the set of relevance observations pertaining participant s . The R = { R 1 ,...,R S } is the set of all relevance observations across all participants.
We use multiple kernel learning (MKL) support vector machines [37] as a multi-view learning method to learn clas-sification models of the form given a set of relevance observations { r i } N i =1 data. Here y denotes the binary relevance judgement,  X  X  ,  X  X  the scalar product, w k the weight vector of the observa-tions,  X  k ( v k ) the feature map of the view v k ,  X  k the kernel weights, and b the bias. The learning problem is to esti-mate the optimal kernel weights  X  k along with w k and b from the given data. Using different feature maps (and con-sequently different kernels) allows us to represent the fact that the different EEG signals can have different measures of similarities, and we can capture nonlinear relationships between features. The estimated kernel weights  X  k can be used as an indication for the importance of the different views [37], which, consequently, allows us to draw conclu-sions on the importance of individual EEG signals in pre-dicting relevance.

For the concrete estimation of the classification models, we use a Bayesian MKL algorithm with an efficient infer-ence based on variational approximation [9]. Among other advantages, the Bayesian formulation of MKL estimates the predictive distribution of the class labels. We will later on utilize the predictive distributions when constructing the high-precision classifier (Section 6). For concrete details, es-pecially on the actual model specification, the distributional assumptions, and the formulation of the deterministic vari-ational approximation, we refer to [9].
Our prediction setup is based on the data of S = 38 par-ticipants and K = 7 views v k with features described in Table 1. We computed models with different combinations of views. We applied a leave-one-participant-out learning strategy as follows. For each participant s we learned a clas-sification model f s using the other participants X  data (i.e., the learning set R  X  s = R \ R s ) with the views that were selected for the particular model (e.g., All views and Al-pha+ERPs). The prediction accuracy was then computed on the participant X  X  relevance observations, i.e., the test set R . The learning of the models results in estimated obser-vation weights w  X  s k , kernel weights  X   X  s k , and the bias b
We used an automatic feature selection procedure on each view v k , whereby the features were ranked according to the t -statistic (computed between the relevant and irrele-vant observations) and the highest ranking features were selected [35] X  X n our case the top ten features. Given the selected features for each view v k , we normalized the data and computed a Gaussian kernel with the kernel width de-fined as the median distance between the observations [11].
The number of relevance observations N s varies slightly for each participant because we used only observations that conformed to the ground truth. We established balanced data by randomly drawing the learning set and the test set from the set of relevant and the set of irrelevant observations, each with the number of observations defined by the smaller set. This reassembles our original experimental design and is a simple but well-established strategy to exclude possi-Table 2: Classification results based on all 38 partic-ipants for different sets of views. The table lists the mean classification accuracy, the p -value indicating a significant better mean classification accuracy than the random baseline, and the corresponding mean improvement. Because of our experimental design, the random baseline prediction of whether a term is relevant or irrelevant is 0 . 5 . Bold entries denote that improvements are statistically significant at a level of  X  = 0 . 01 , p -value &lt;  X  with correction for multiple testing.
 Individual views: Gamma1 (Ga1) 0.5143 0.1445 2.86% Selected combined views: ble problems of the classification method with imbalanced classes. To eliminate a possible observation sampling bias we repeated this procedure five times; i.e., for a participant s we estimated five models f i s ( i = 1 ,..., 5) and consequently five estimations of model parameters. We report averaged results, unless otherwise noted.
In this section, we first present results from classification experiments with various combinations of EEG views. We discuss the importance and influence of the various EEG views and X  X ncouraged by the well-known  X  X CI illiteracy X  X  we show that there exists a restricted set of participants for which we can further improve the prediction accuracy. We then show physiological findings that map the important views to effects that can be localized to certain brain areas.
Table 2 summarizes the classification accuracies for differ-ent sets of views. We report the mean classification accu-racy, improvement over the random baseline, and the p -value of a t -test for significance corrected for multiple testing us-ing the Bonferroni correction. The t -test was applicable be-cause the Shapiro-Wilk test showed no significant difference from the normal distribution. The classifiers using all seven EEG views (All) predicted relevant and irrelevant terms for an unseen participant significantly better than the random baseline, and achieved a mean improvement of 8.30%.
Importance and influence of EEG views. The es-timated kernel weights  X  k of all learned classification mod-els using all seven views gave us a first indication of the Figure 2: Individual classification accuracy for each of the 38 participants with all seven views based on training on the data of the remaining participants and ordered according to the accuracy. TBRP gen-eralizes for about 70% of the participants which fol-lows the BCI illiteracy.
 Table 3: Classification results for a restricted set of participants motivated by the well-known  X  X CI illit-eracy X . Bold entries denote that improvements are statistically significant at a level of  X  = 0 . 01 , p &lt;  X  with correction for multiple testing.
 Al+Ga1+Be 25 0.5490 0.0019 9.81%
Al+Ga1+E 28 0.5545 0.0005 10.89% importance of each EEG view. Alpha and Gamma1 have the highest weights, then Beta, then Gamma2, Theta and ERPs, and finally Engage. To study the influence of dif-ferent views on the classification accuracy, we built mod-els for each view separately. The corresponding results are shown in the middle block of Table 2. These single-view runs indicated that none of the individual views alone led to significant improvements. However, we found that Al-pha and ERPs showed good performances (0.52/4.83% and 0.53/6.24%, respectively), which was in line with the kernel weights. Influenced by these results, we also computed clas-sification models by combining the best-performing views and the views with highest kernel weights.

The corresponding classification results with combined sets of views are shown in the lower block of Table 2. The best set of views was found to be the one with the Alpha, Gamma1, and ERPs (0.56/11.72%). Other significant im-provements were achieved with classification models based on Alpha and ERPs, and Gamma1 and ERPs. Even though Beta had a high kernel weight, it did not significantly im-maximizing at 747 ms. prove the classification accuracy when combined with Alpha and Gamma1. In summary, this suggests that changes in Alpha, Gamma1, and ERPs activities are associated with term-relevance judgments. The physiological findings pre-sented in the next section support these results for Alpha and ERPs.  X  X CI illiteracy X  analogy. Motivated by the well-known  X  X CI illiteracy X , which means that BCI control does not work for a non-negligible proportion of participants (ca. 15-30%, [39]), we were interested to find out whether a simi-lar effect could be observed in TRPB. In detail, we stud-ied whether we could achieve a better classification accu-racy for a specific group of participants. Figure 2 shows the classification accuracy of the classification models us-ing all views; the horizontal line at 0 . 5 marks the random baseline. 26 participants are above, and 12 participants are below the random baseline. This proportion suggests that capturing the relevance effect is generalizable for 70% of the participants and not generalizable for about 30% of the par-ticipants, which follows the BCI illiteracy rate mentioned in [39].

A screening of the EEG signals of the 12 participants did not show a higher noise level, which would explain the worse-than-random prediction accuracy. Given that the learning data for these cases are the other participants (leave-one-participant-out strategy), there may be a group of partici-pants with similar brain signals. There seems, however, to be a group of participants with possibly different brain sig-nals. In order to investigate if we could achieve further clas-sification improvements, we investigated an additional set of classification models for a restricted set of participants. The restricted set was determined via a simple trial-and-error procedure: i.e., we included all participants with an accuracy above the random baseline.

Table 3 shows the corresponding classification results for the restricted set of participants. The results indicate that it is possible to increase the mean prediction accuracy and therefore the mean improvement in all cases; in the best case up to 17% (Alpha and ERPs). Because the simple trial-and-error procedure, these analyses do not provide generaliz-able results over all participants. This procedure, however, allowed us to demonstrate an analogy to the well-known  X  X CI illiteracy X  effect.
The views that were found most effective for the classifica-tion (Alpha and ERPs) were investigated from a physiologi-cal point of view. We present brain mappings of the average Alpha effect across all 38 participants and the topography of the strong ERP effect.

Alpha. We attempted to localize the intracranial source of the Alpha using exact low resolution electromagnetic to-mography (eLORETA, [29]). eLORETA is a discrete dis-tributed linear weighted minimum norm inverse solution to the source localization of scalp recorded activity, yielding images with exact localization, at a cost of a low spatial res-olution. For each participant, two large 1024 ms segments of relevant versus irrelevant terms were used to calculate the cross spectra across all electrodes resulting in 6000 voxels for both relevant and irrelevant terms for each participant. In order to localize the Alpha change associated with rele-vance, we used a pairwise log of F -ratio test across voxels using spatial normalization to find a maximally significant source localization (with correction for multiple testing [26]). as irrelevant.
 The analysis based on the obtained corrected critical two-sided F  X  = . 37 results in an area of 10 voxels, all located in the left frontal lobe, specifically in Brodmann Area 10 and a peak localization at MNI coordinates (  X  25 , 55 , 25) with a corrected p &lt; 0 . 02; see Figure 3(a, top). The source local-ization of the effect on alpha oscillations supports the key role of the frontal lobe. The Brodmann Area 10 has previ-ously been related to recognition [32], memory retrieval [33], and the evaluation of working memory [42].

ERPs. To investigate which components of the ERP con-tribute most to the model, we analyzed the average differ-ence between relevant and irrelevant terms also in a more traditional manner. Average relevant and irrelevant ERPs were computed for each participant over a minimum of 8 and a maximum of 16 correctly classified epochs in each condition. The main significant areas were observed in the Cz, Pz, C4, and P4 channels, with the peak difference in Pz beginning at 477 ms ( p &lt; . 05) and peaking at 757 ms ( p &lt; . 0001); see Figure 3(a, bottom) and Figure 3(b). The latency and topography of the potential suggest the involve-ment of a P3-like potential. The high latency and parietal topography coincide with the P3b, thus suggesting that rel-evance does not affect an early change in orientation, but a later, memory-related effect [30].
In a practical information retrieval application that can benefit from relevance prediction, the target is to detect true positive examples of terms that represent user X  X  search in-tent [34]. In such applications, a classifier that trades recall for the benefit of precision can be used to maximize user experience. In other words, a classifier predicts a term as relevant only if the estimated probability of being relevant is very high, i.e., above a certain threshold (high precision). Obviously, the classifier will miss a lot of true relevant terms (low recall). However, we can take advantage of the fact that brain signals can be captured continuously and with high throughput X  X ompared to implicit signals that require explicit user interaction. As a result, a large number of rele-vance judgments can be observed in a relatively short time. We demonstrate such a high-precision variant of the TRPB classifier and show that it can construct meaningful sets of terms for unknown topics and unseen participants.
One of the advantages of the Bayesian MKL algorithm introduced in Section 4.1 is that its outcome for an unseen term y is not simply the binary decision to relevant or ir-relevant, but the predictive distribution of the term being relevant, i.e., p ( y = relevant |  X  ) with  X  the estimated model parameters. We built a high-precision TRPB variant by predicting a term to be relevant only if the probability was higher than 0 . 99. We used the same prediction setup as in Section 4.2; the models are based on all 38 participants and all seven views. The learned classification models were used to predict the relevance of the terms for an unseen partic-ipant and an unknown topic. We then quantified the pre-dicted relevant terms per topic over all unseen participants, which let us to compute the top relevant terms per topic for an average unseen participant.
The results of the high-precision classifier in predicting relevant terms are shown in Table 4. For each of the six topics, we show the number of observations used in the pre-diction, precision, and recall achieved by the high-precision classifier, and the terms predicted relevant by the classifier.
While the overall classification problem is still hard, the high-precision classifier achieves a mean precision of 0.62 with an improvement of 25% from the baseline while still sustaining feasible recall of 0.13. However, there are dif-ferences in precision across the topics ranging from 0.52 up to 0.8. This suggests that some terms in some topics may have been more difficult for the participants than others. For example, for the  X  X ntrepreneurship X  topic, the classifier was used to classify 199 samples, of which 110 were rele-vant and the rest were irrelevant. The high-precision clas-sifier reconstructed 29 terms from these samples, of which 20 were relevant and 9 irrelevant, and achieved a precision of 0.69 and recall of 0.18. The top five terms for this topic were  X  X usiness risk X ,  X  X tartup company X ,  X  X usiness creation X ,  X  X hopping X , and  X  X irtual relationships X . While  X  X hopping X  and  X  X irtual relationships X  were not relevant for the topic in the strict sense (in the ground truth), they were still pre-dicted relevant by the high-precision classifier. One may argue that these terms are still somewhat relevant for the topic. Similar is the effect of the classifier picking a term that was classified relevant, but assessed irrelevant in the ground truth, is for example the term  X  X orse code X  for the topic  X  X raq war X  or the term  X  X irtual relationships X  for the topic  X  X recarious employment X . This suggests that the classifier can possibly detect the correct brain pattern of a participant first thinking that the term may be relevant, even when the participant still ends up assessing it irrelevant.
In essence, relevance judgments happen in the brain and therefore the most intriguing way to predict relevance is to directly use the brain signals. Brain signals also have ad-vantages over the more conventional sources of user signals from a practical IR point of view. The recording of the relevance judgments do not require any explicit user inter-action, such as user actively clicking on items. The signals can be captured with higher throughput than from explicit user interaction signals. Most practical information retrieval systems assume the interface between the content and the user to be based on user X  X  expression of the information need using a term representation. Therefore, in order to opera-tionalize brain signals as a part of a real IR system, a central challenge is to predict the relevance of terms based on the brain signals.

We showed that term-relevance prediction using only brain signals captured via EEG is possible. The classifi-cation results showed significantly better performances than the random baseline. As a practical application of TRPB, we demonstrated a high-precision relevance predictor and showed that it can construct meaningful sets of terms for unknown topics and unseen participants. To our knowl-edge, this is the first work utilizing only brain signals as a source for relevance in an IR scenario. Our approach does not require users to explicitly memorize an artificial pattern or a pre-seen object as in BCI or mind-reading research. Moreover, our approach is based on well-established meth-ods, both for the EEG processing and the prediction task, and we were able to support the classification results with physiological findings. The localized brain areas have pre-viously been associated with cognitive functions important for relevance judgments.

While our results show significant improvements, we see several future research directions in order to utilize TRPB as a part of a real IR system. First, our experimental design is balanced between relevant and irrelevant terms in order to ensures that we measure signals and effects related to rel-evance judgments. In a real IR setting, however, it is likely that the two classes are imbalanced with the majority of the terms being irrelevant. Experiments with more realistic data and larger amount of observations are needed to show how our results generalize to such scenarios. Second, our classi-fication results already generalize over unseen participants, but more sophisticated EEG processing steps and advanced detection methods are needed to automatically cope with the detected  X  X CI illiteracy X  analogy. Third, an obvious next step is to use the predictions as relevance feedback and to quantify the effectiveness of EEG-based relevance feed-back as a part of a real interactive IR system. Fourth, we recognize a need for studies that could more specifically re-veal the areas of the brain that are activated when users conduct relevance judgements. This could help to reveal the plurality of different mental operations potentially associ-ated with relevance and allow to build non-intrusive wear-able EEG systems that could rely on a small number of electrodes at specific positions.

In conclusion, our findings open a horizon for adaptive information retrieval systems that can detect relevance di-rectly from brain signals without requiring users to engage with any particular interaction technique or user interface. With the current trend of wireless, light weight, and portable EEG sensors, our findings can enable systems, which analyze relevance as it happens as a part of our everyday information seeking activities. This work has been partly supported by the Academy of Finland (Multivire, 255725; and the Finnish Centre of Excel-lence in Computational Inference Research COIN, 251170), Re:Know funded by TEKES, and MindSee (FP7  X  ICT; Grant Agreement # 611570).
