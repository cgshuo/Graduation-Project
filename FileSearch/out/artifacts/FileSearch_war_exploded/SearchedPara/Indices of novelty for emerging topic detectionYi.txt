 1. Introduction
Tracking the evolution of a discipline and detecting the emergence of a main stream is important to researchers and scholars ( Lee, Gosain, &amp; Im, 1997 ). Knowledge in these areas can be accumulated based on experience and state-of-the-art techniques can be used to investigate trends and identify new research topics. However, before a new research topic to attract the attention of many researchers. This is always a lag behind index and as the number of papers discussing the same topic increases, their influence decreases. Consequently, in this study we develop some novel topic detection indices using automatic approaches which are designed to help researchers detect upcoming topics and make decisions about pur-suing them before they become popular. 1.1. Research background
Topic detection and tracking (TDT) is an important field that tracks the evolution of a topic. TDT was developed in 1996 by the Defense Advanced Research Projects Agency (DARPA). A pilot study in by Allan, Carbonell, Doddington, Yamron, and Yang (1998) laid the groundwork for this field, generated a small corpus of information and established a durable system.
Although TDT research flourished from 1998 X 1999 ( Lee, Lee, &amp; Jang, 2007 ), many studies are conducted in new areas.  X  journals and magazines is on different themes, with the former focused on conceptual and abstract models, while the latter is focused on specific applications. It should be noted that academic themes show a tendency to vary more over time. in time than at other times. Kleinberg proposed a method for analyzing document streams ( Kleinberg, 2002 ). Morinaga and Yamanishi improved Kleinberg X  X  approach ( Morinaga &amp; Yamanishi, 2004 ).

Related work can be roughly divided into three groups, those that use: (1) text mining and data mining approaches principal task of time-line burst detection of feature terms and measurement is to determine when or whether a topic is emerging, whereas others focus on detecting the burst of a new topic.

There has been some work extending tracking or detecting techniques to such areas as literature-related discovery papers but also to determine new technologies and new patents for industry, organizations and governments. 1.2. Research Issues
As we know, the lifecycle of a research topic can be expressed as an S-curve with five stages, which are the initial stage, tant for researchers to discover potential research topic as they emerge in the expansion stage of their developmental life time.

This study develops a set of novel indices for identifying such emerging topics to help researchers to determine whether a then the impact of a new paper on the same topic can be calculated to be 1/11 = 0.0909. IN contrast, when there are 1000 papers in which a topic is discussed, the impact of an additional paper can be calculated to be 1/1001 = 0.000999. The concept of novelty as applied by Zhang, Callan, and Minka (2002) and aging theory as developed in a TDT by Chen,
Chen, Sun, and Chen (2003) are of assistance when constructing an index for detecting emerging topics. Chen et al. (2007) used aging theory and term frequency to solve the problem of topic detection, and proved that aging theory was the best we try to use these newly developed indices to examine, from the novelty and published volume, the stage in the life cycle (expansion, maturation or decline) and to determine the topic X  X  research potential based on these conditions. This method gives researchers internal as well as external suggestions to consider the potential of an emerging topic.
Based on the proposed indices we can determine whether the topic of a conference or journal paper is representative of a leading trend, and how long the trend will continue. This will help researchers make decisions about whether they should
This study develops a detection table to solve this problem. Novelty, aging theory and the curve representing accumulative relative frequency are all used to develop an appropriate set of indices for detecting emerging topics. 1.3. Research approach
Inductive learning and deductive prediction methods of machine learning help in constructing predictable indices and That is, the volume of published studies on a topic helps determine whether it is important.
 published on a topic are important indices for determining it has potential to become a hot new emerging topic. The novelty in this period of time.
 conferences and in journals can help in determining whether conferences or journals are the leading trend of the topic.
The remainder of this paper is organized as follows. Section 2 discusses the extension of the theory application, and the development of TDT techniques and aging theory utilized in the method. Section 3 describes how to develop and construct indices in order to detect emerging topics. Section 4 presents the experimental design, execution and experimental results.
Section 5 discusses the implications and contributions of the study. Section 6 gives Applications and Implications of this work. Section 7 summarizes the concluding remarks. 2. Related works
The availability of large linked document collections, such as the World Wide Web, and specialized literature archives present new opportunities for mining knowledge about community activities. Topic discovery is an example of such knowl-as the basic building blocks in knowledge discovery. Once discovered, topics can be utilized in various ways, including for three steps: (1) topic structure identification to identify the main topic types and their importance; (2) topic emergence detection to detect the emergence of a new topic and determine how it grows; and, (3) topic characterization to identify the characteristics of each main topic ( Morinaga &amp; Yamanishi, 2004 ). 2.1. Topic detection and tracking
The dissemination and exchange of documents has become commonplace with the recent growth of the Internet, thus raising the significance of content analysis techniques. Topic analysis of, say, e-mails and news articles is an important topic-based text segmentation and related issues. In addition to TDT, Malone, McGarry, and Bowerman (2006) utilized data in news streams.

TDT is a recently developed information retrieval technology. It was developed in 1996 when the DARPA (Defense Ad-vanced Research Projects Agency) was searching for a technique that could function without human intervention to detect generating a small corpus of knowledge and establishing a durable system. TDT research continued to flourish ( Lee et al., 2007 ).

Makkonen et al. described the prevailing techniques applied in TDT such as formation extraction, retrieval and filtering, text clustering and text categorization and natural language processing. A TDT system that is implemented on-line does not have knowledge of unseen documents, which makes a case for clustering. Some studies have utilized retrospective topic detection and tracking when a system shows all data simultaneously; however, these studies focus mainly on on-line envi-ronments ( Makkonen et al., 2004 ).

Allan, Papka, and Lavrenko (1998) described problems related to new event detection and event tracking within a stream of broadcasted news stories. They focused on an on-line setting, i.e., one in which the system makes decisions about one story before analyzing subsequent stories. They used a single-pass clustering algorithm and novel threshold model with event attributes as a major component. Their tracking approach is similar to typical information filtering methods. They determined the value of unique terms that had unusual occurrence characteristics, and applied on-line adaptive filtering to identify the evolution of events in the news. New event detection and event tracking are TDT initiatives.
Subsequent studies have improved TDT techniques. For instance, Walls, Jin, Sista, and Schwartz (1999) developed a sys-tem for TDT detection tasks for unsupervised groups of stories in the news and on web pages based on topics. Their system used an incremental k -means algorithm to cluster stories. A probabilistic document similarity metric and conventional vec-tor space model was adopted to compare stories ( Salton, Wong, &amp; Yang, 1975 ).

Schultz and Liberman (1999) proposed approaches for detecting and tracking which are based on the well-known idf -weighted cosine coefficient similarity metric. They achieved excellent tracking results using a very simple term-selection method that did not involve word stemming or score normalization. However, their detection task results were poor, prob-ably due to the poor performance of the clustering algorithm rather than that of the underlying similarity metric.
Some have found that while existing learning techniques must be adapted or improved to manage difficult situations in which each event has very few positive training instances, most training documents are unlabelled, and most events have short durations. Yang, Ault, Pierce T., and C. W. (2000) combined several supervised text categorization methods, namely, several new variants of the k -Nearest Neighbor (KNN) algorithm and the Rocchio approach, to track events. Their approach, based on a traditional parameter optimization solution, significantly decreased variance in the performance of their event-tracking system for different data collections.

Kleinberg (2002) proposed a method for analyzing document streams. Although the main objective was to detect bursts of topics, the method can be adopted for topic activation analysis. However, Kleinberg X  X  method only considers document arrival rates, and disregards document relevance. Furthermore, the Kleinberg method is a  X  X  X atch-oriented X  X  approach. Cui and Kitagawa (2005) presented a solution to these problems. Although many studies have improved TDT techniques, these techniques are generally applied to time-sensitive documents (e.g., real-time news and e-mails) and have not been widely applied to identify new topics in academic papers. 2.2. Emerging topic detection An emerging trend is a topic area that is growing in interest and utility over time. For instance, Extensible Markup
Language (XML) emerged as a trend in the mid-1990s. Knowledge of emerging trends is particularly important to individuals and companies that monitor developments in a particular field or industry. For example, a market analyst specializing in the biotech industry may want to review technical and news-related literature for recent trends that will impact biotech companies. Manual review of all available data is simply not feasible. Human experts who must identify emerging trends must rely on automated systems as the amount of information available in digital resources is consid-erable ( Berry, 2004 ).

Zhang et al. (2002) extended an adaptive information filtering system to make decisions regarding the novelty and redun-dancy of documents. They argued that relevance and redundancy should be modeled explicitly and separately. They devel-oped a set of five redundancy measures which they evaluated in experiments with and without redundancy thresholds.
Experimental results demonstrated that the cosine similarity metric and a redundancy measure based on a mixture of lan-guage models effectively identified redundant documents. Their research focused on the novelty and redundancy of docu-ments, but did not address research topics.

Yang et al. (2002) proposed a novel two-stage approach that used (1) a supervised learning algorithm to classify on-line document streams into pre-defined broad topic categories and (2) performed topic-conditioned novelty detection for docu-for novelty detection, but did not discuss when a topic is emerging.

Jo et al. (2007) generated unique approach that used correlation between the distribution of a term representing a topic and the link distribution in a citation graph in which nodes are limited to documents containing the term. This tight coupling between a term and graph analysis differed from other approaches such as those using language models.
They applied a topic score to each item using the likelihood ratio of binary hypotheses based on a probabilistic descrip-tion of graph connectivity. Their approach was based on the assumption that if a term is relevant to a topic, documents containing that term have a stronger connection than randomly selected documents. They applied the algorithm to de-tect a topic represented by a set of terms based on the assumption that if the co-occurrence of terms represents a new topic, the citation pattern should exhibit a synergy. They tested the algorithm on two electronic literature collections, arXiv and Citeseer. Their evaluation results showed that their approach was effective and revealed some novel aspects of topic detection. However, the curve which they only used term frequency to develop was still a lag behind index for detecting. 2.3. Aging theory
Capturing variations in a distribution of key terms on a time line is critical when extracting hot topics. Therefore, document stream can be identified via a simultaneous temporal burst of related documents. There has been research applying Aging Theory to model the life span of a news event. In this respect a news event can be considered a life form span. The energy of an event increases as it becomes popular and decreases as its popularity wanes. Hence, Aging Theory is suitable for tracking variations in term frequency, which we consider critical to successful hot topic extraction ( Chen et al., 2007 ). 2.4. Tech mining
Tech mining has been considered a new and import field since 2006 ( Cunningham, Porter, &amp; Newman, 2006 ). The topic of mining techniques to inform or manage the knowledge obtained from searching electronic science and technology
Cunningham, 2005 ). These techniques not only improve the decision-making processes of research studies but also can study, we track emerging topics in research work finding the indices for tech mining.

Zhu and Porter (2002) also discussed the automated extraction and visualization of technological intelligence and fore-casting problems. They described a process for generating a technology family map and also describe a method to produce their innovation indicators. Their work can help researchers and decision makers realize the situation about the technology they are concerned with. The indications are developed as a composite concept.

Compare to his research, their relative accumulated frequency was set up different from ours, and they did not consider the detection point concept and growth analysis of a topic in this research.
 ery (LRD) methods involve the linking of two or more concepts that have heretofore not been linked by text mining procedures, in order to produce novel, interesting, plausible, and intelligible knowledge. LRD has two components: (1)
Literature-based discovery (LBD) which generates potential discovery through literature analysis alone; (2) literature-assisted discovery (LAD) which generates potential discovery through a combination of literature analysis and interactions among selected literature authors. In turn, there are two types of LBD and LAD: (1) open discovery systems (ODS), where and a solution, then determines the mechanism(s) that links them.

Compared to this research, Kostoff extends the basic idea and combines the text mining and information retrieval tech-from what we are doing in this current study. In this work we develop indices to identify a topic or new science whether it is during an emerging period in its lifecycle.

In related work, Shibata and Kajikawa and others ( Shibata et al., 2007, 2008, 2010 ) analyzed the topology of the citation the migrating phenomenon in which the activated center of research shifts from an existing domain to a new emerging domain.

This is different from the view in this current research which is aimed at discovering a new emerging domain. They used identifying.
 sion makers to generate useful information. They use three emerging technologies of scenario planning, growth curves and analogies, and data sources such as bibliometric, patent analysis and the modeling tool as system dynamics to present fore-cast tools to determine an emerging technology. Their works demonstrated that integrating multiple methodologies can im-case of emerging technologies.

Daim et al. X  X  works helped the researcher to integrate multiple techniques to produce an assessment tool for forecasting and assessment tool for choosing problems. Novelty and popularity are two important concepts in these indices which can provide a tool for considering the important properties in emerging technologies. 2.5. Summary
The research focuses on the second task in TDT, emerging topic detection. We attempt to detect the emergence of a new topic and determine its growth stages. The concepts of novelty concepts, aging theory and traditional frequency are applied work where only the frequency term was used. Instead we use a curve indicating accumulative relative frequency to develop the PVI to create the emerging topic detection indices.
 3. Developing the Indices for detecting emerging topics
The theoretical basis and experimental design for evaluating the effectiveness of the indices for emerging topic detection duced by these indices. Section 3.4 shows how the emerging topic detection table is constructed using the emerging topic detection indices. 3.1. Novelty of emerging topics
We create an NI and a PVI, which are related to the development of the emerging topic detection indices, to construct an approach for investigating the novelty of a research topic, that is, whether it is emerging. 3.1.1. Term, candidate research topic, research topic, hot topic and emerging topic
Before discussing the NI and the PVI, this study defines a set of terminologies: term, candidate research topic, research times in the same conference or journal publications in the same year. This threshold is based on the work of Joachims as terms that are composite words or an abbreviation of a proper noun as extracted from conference or journal publications. A candidate research topic indicates that a term may be an important research topic.

A research topic is defined as the intersection set between a candidate research topic in conferences and journals. These sets are of assistance when examining the leading relationship between research topics that appear simultaneously in con-ference and journal papers. Additionally, this study considers overlapping candidate research topics (in conferences and growth stage but still not a hot topic. This study extracts emerging topics using the proposed indices. 3.1.2. Novelty index
Before defining the NI, we should define what the potential development year is. The potential development year (PDY) is well known and established topic researchers in the field have reached a consensus in terms of the lifecycle of its emergence.

Table 3-1 presents the datasets collected from the ACM database. The column entitled Type separates conference and the published volume of each paper type and each year separately. The value of type J in 2008 is 12, indicating that there were 12 journal papers focused on XML in that year. Comparatively, there were 114 conference papers focused on XML ever, no paper discussed XML from 1990 X 1993. There was a paper in 1994 but none from 1996 X 1998, indicating that if the first paper caught the attention of researchers, it cannot be considered the start of an emerging topic.
Hence, if the PDY is 1989, it does not have the deterministic evidence in the research. However, after 1999, XML was the main topic in a considerable number of papers. Furthermore, we assert that if a topic is not discussed in any paper during development year, the NI is 1/ n . We use the proposed Algorithm 3 X 1 to identify first PDY.
 Algorithm 3-1 : Identifying which year is the C F for the research topic Input: C i , the published volume of conference papers in the i th year
Output: C F , the first PDY in conference papers for a research topic 1 For i = 2008 X 1989 2If C i &gt; 0 then 3 C F = i 4 Else 5 Return C F = i +1 6 Break 7 End If 8 Next where
C i is defined as the published volume of conference papers in the i th year. For XML, i = 1989, ... , 2008.
J j is defined as the published volume journal papers in the j th year. For XML, j = 1999, ... , 2008.
 C F is defined as the first PDY in conference papers for a research topic.
 J F is defined as the first PDY in journal papers for a research topic.
 CNI k ( Topic ) is defined as the NI for the k th year for a research topic in conference papers.
 JNI k ( Topic ) is defined as the NI for the k th year for a research topic in journal papers.

We assume that a research topic is new when it is first published; thus, NI should be normalized to 1 = 100%. In its second year, the NI should be 1/2 = 50%. The value of the NI should be normalized to 0 X 1. By Algorithm 3 X 1, the formula for CNI Topic ) is as follows: Furthermore, the formula for JNI k ( Topic )is Taking XML ( Table 3-1 ) as an example, C F is 1999 and, using Algorithm 3 X 1, we start from the year 2008. When
C 2008 = 114 &gt; 0, C F will be 2008 temporarily. Next keep searching using i = 2007 until i = 1998 while C PDY, so actually C F is next year of i as i +1.

After determining that 1999 is the C F year for XML, then CNI
Novelty Index (CNI) for 2008, we take k = 2008 in Formula (3 X 1), obtaining a CNI of 2008. CNI (3 X 2). 3.1.3. Published volume index
The NI is a measurement of novelty. This study can determine whether a research topic is emerging or hot based on the volume of papers published in the same period. Conversely, if a topic is discussed over a long period in a vast number of of published papers, one cannot determine whether the topic has potential research value. Notably, as the volume of papers increases, topic impact decreases. The conventional frequency curve method for determining the volume of published papers topic. The traditional frequency curve is a backward index.

We not only consider the volume of published papers but also a topic X  X  hotness over time. The accumulative relative fre-accumulative relative frequency of the k th development year normalized to 0 X 1. Algorithm 3 X 2 is used to compute the PVI for the k th year, and Formula (3 X 3) comprises the equations for the CPVI.
 Algorithm 3-2 : Compute the PVI, taking the JPVI k ( Topic ) as an example Input: Sum J , Sum i , J i
Output: JPVI k ( Topic ) 1 For i = J F to k 2 Sum J = Sum J + J i 3 Next 4 For i = J F to k 5 Sum i = Sum i 1 + J i 6 JPVI i  X  Topic  X  X  Sum i Sum 7 Next where Sum C is the accumulated number of conference papers from C Sum J is the accumulated number of the journal papers from J Sum i is the accumulated number of papers from first year to the i th year for the same paper type.
 CPVI k ( Topic ) is the PVI for a topic in the k th year in conference publications and formulated as follows: JPVI k ( Topic ) is the PVI of a topic in the k th year in journal publications and formulated as follows: question of concern to researchers is when a topic becomes an emerging topic with no break in subsequent years. The first time a research topic is discussed is not necessarily an important point. 1999 is identified as the first year in which XML appeared in journals using Table 3-1 . We use Algorithm 3 X 1 to find J 2001 + 1 = 8. Table 3-3 is used with Algorithm 3 X 2 to compute the PVI for each year. For 2003, J
Sum 2003 = Sum 2002 + J 2003 = 14 + 7 = 21. For 2008, Sum 2001 to 2008. Hence, JPVI 2003  X  XML  X  X  Sum 2003 Sum and recorded in Table 3-3 . 3.1.4. Detection point
According to the two proposed detection indexes, NI and PVI, when the PDY is early compared to its lifecycle, the NI is high ( Table 3-2 ). For example, J F = 2001 and JNI 2001 ( XML ) = 1. Compared to JNI the published volume reveals the amount of discussion a research topic receives, the PVI reflects the relative degree of growth in volume. The two indices can use the values in Table 3-4 to determine the development of XML.
Using the data in Table 3-4 we can draw the curves for JPVI (Journal PVI), JNI (Journal NI), CPVI (Conference PVI) and CNI topic detection index for XML.

The DP is defined as the point at which the NI and PVI intersect. We suggest that the DP can be used to determine whether arates the conference detection point (CDP) and journal detection point (JDP). Algorithm 3 X 3 shows how to compute the DP for JPVI and JNI.
 Algorithm 3-3 : How to compute the DP ofor JPVI and JNI Input: present year, JPVI i , JNI i , JPVI i +1 , JNI i 1
Output: J -detection point 1 For i = present year To C F 2If JPVI i = JNI i Then 3 Return to the J -detection point = i 4 Else If JPVI i &gt; JNI i and JPVI i +1 &lt; JNI i 1 6 End If 7 Next 3.2. Information produced by the emerging topic detection indices
According to the DP indices, if a topic has been published in both conference and journal papers, then, based on the pub-the year for the DP (YDP) and value of the DP.
 3.2.1. Year of the detection point
The YDP is the X -axis value of the DP. The YDP indicates that a topic has reached the emergence threshold in its devel-represents the year. Although the YCDP is near 2002, the graph shows that this is not a DP. The topic does not become an emerging topic until 2003. Consequently, this study takes 2003 as the YCDP and 2004 as the YJDP. 3.2.2. The detection point value
The value of the DP (VDP) is the value at which the DP intersects the Y -axis. This value indicates both the NI and PVI for can be expressed by the NI and PVI. Additionally, the VDP also means that the NI and PVI are equal at the DP. However, the the Y -axis for conferences and is the same value as the CPVI and CNI. The VJDP is the value at which the DP intersects the exactly at one year, it must be between two years. The VCDP is between 2002 and 2003, and the value is affected by
CPVI 2002 = 0.227, CPVI 2003 = 0.348, CNI 2002 = 0.250 and CNI of those 4 points and is calculated as follows: Likewise, we compute VJDP = 0.293. Hence, if the YDP is the i th year, Formula (3 X 5) can be used to compute the VDP 3.3. The properties of emerging topic detection indices
After creating the NI and PVI to construct the emerging topic detection indices and detection table, we can analyze the academic publications and forecast the trend. 3.3.1. Novelty index properties Since it is supposed that regardless of conferences or journals there exists a relationship between them. Furthermore, the
NI will produce the same result for the relationship of conferences and journals with any validated index. Nevertheless, we assert that the NI is a reasonable and convenient index. To determine the entire lifecycle of a topic, one must obtain process continues until the last year. However, one cannot determine when a topic terminates until it is terminated. There-3.3.2. Published volume index properties
As mentioned, comparing the PVI and the traditional frequency measure can improve the forward effect. Here, XML is of XML.

The curve for Original-2006 in Fig. 3-2 is derived from journal data for XML during 2001 X 2006. The curve Decrease-2008 the amount of data in 2007 is 2 times that in 2006 (40) and that in 2008 is 2 times that in 2007 (80). Thus, PVI-2006, PVI-2008-decrease and PVI-2008-increase are the indices for Original-2006, Decrease-2008 and Increase-2008, respectively.
While the volume of PVI increases relative to that in the past, like PVI-2008-increase, an upward opening concave curve downward opening curve forms. Consequently, as the volume of PVI is comparatively larger compared to the value in 2006 between PVI-2008-decrease and PVI-2008-increase, and the curve will rise from year 2006, indicating that the topic is of topic exists after 2006  X  so the curve is relatively flat in 2006, indicating that topic has not yet become a hot topic. 3.3.3. Detection point properties
The DP is the intersection of the NI and PVI, and produces the YDP and VDP. The discussions in Sections 3.2.1 and 3.3.2 refer to the properties upon which the YDP is based. The accumulated relative frequency is used to determine the DP prop-erties and validate the effectiveness.
PVI-2008-increase. Regardless of whether the amount of data increases or decreases, as long as a topic keeps developing (published volume is not 0), the curve will delay the intersect point. This makes sense because a later YDP means the topic 2006 when the YDP is 2004. cle. The highest volume in its lifecycle was reached in 2008. The delayed DP indicates that the topic is not hot. ing topic produced as the DP is always in front of the present point and is a trade-off between the NI and the PVI.
We use the proposed emerging topic detection indices to examine the relationship between conferences and journals. If same. The DP of XML in this database is 2004, which is before the highest amount of data in 2006. Although we cannot deter-mine whether XML has reached the highest volume in its history and could have a higher volume later, the DP is in 2004, which matches the expected date. Hence, the PVI has a better ability to predict an emerging topic than does the traditional frequency method.
 is emerging. We assert that the DP must exist before the topic becomes hot. Consequently, the DP must exist during period more than 2 years) using the proposed indices. Hence, this study uses the YDP and VDP indexes to identify the situation in which a topic is hot. The emerging topic detection table is used to detect the value of retaining a research topic.
Observing the detection period, we discover that the DP will move while papers on the topic continue to be published tinue extending by the potential developed year and the DP cannot make the YDP delay, which means cannot keep developing.
 elty and popularity (published volume) are high during this period of time. When the DP is moving and the intersection de-layed by the following published volume, it means that the topic is continuing to grow, and emerging for a period of time. 3.4. The emerging topic detection table
The emerging topic detection table helps in identifying the DP, which includes the YDP and VDP. By comparing confer-nals, respectively, to develop the emerging topic detection table. Take the XML at conferences as an example. From C compute another YDP and VDP at that time. This study uses the properties of VDP to construct the emerging topic detection the ACM database and computes their VDPs for each year. The median VDP is used to avoid confounding by extreme data and to generate the emerging topic detection table.

The VDP represents a new topic. Although the volume is small, the PVI is high. For instance, if the PDY is 2 years and the first and second year volumes are 1, then PVI 1 = 0.5 and PVI or PVI, the curve will easily delay the DP. For instance, in the third year, 2 papers were published so PVI
PVI increases, a topic warrants further research.

Each topic has its own development time X  X ome topics develop slowly, while others may generate considerable discus-line, it cannot be an important topic. 4. The research experiment
This section describes the experimental design, execution, data collection, and the development of the emerging topic for predicting worthy topics, and outlines the value of this investigation. 4.1. Introduction
To verify the accuracy and effectiveness of the proposed indices for recognizing and predicting new trends, this study uses data on journal and conference papers listed in the ACM Digital Library and IEEE Computer Society databases. Table 4-1 shows the four descriptors of correlations between conference and journal papers.
 Some leading correlation categories between the conference papers and journal papers: Conference papers lead conference papers which we call C ? C.
 Conference papers lead journal papers which we call C ? J.
 Journal papers lead conference papers which we call J ? C.
 Journal papers lead journal papers which we call J ? J.

What researchers most care about is that the lead time and the leading trend position can be firmly established. The lack with C ? C is that the leading trend position can be firmly established based on the conference paper property. With J ? C verified by journal papers. Conference papers are the leading indicator.

This study focuses on identifying seed trends for a particular domain of study by exploring the relationship between con-ference papers and journal papers. A conference paper appears to mark the beginning of a research process. Therefore, we believe that conference papers represent trends. This study focuses specifically on data mining and information retrieval.
Computer science includes many sub-domains. Specific sub-domains need to be selected to define the perimeter of this re-sion. These two sub-domains can be described with ten keywords.

The ACM Digital Library and IEEE Computer Society are adopted as databases for conference papers. These are two re-nowned academic communities within the domain of information systems and computer science, and hold extensive collec-are the four databases for journal papers. The two extra databases are included to complement the ACM Digital Library and IEEE Computer Society X  X  sparse journal collections, and to generalize the research findings.
 than three times. The data are presented in matrix form, with columns representing features and rows representing papers. conference papers and journal papers can be obtained using years as a unit of measurement.

Similarities in the topics of conference papers in sequential years are identified. The research findings strongly support the assumption that 87.23% of the data nodes in 1990 X 2007 demonstrate that the topic for one year influences topics in fu-pers. Furthermore, massive amounts of data can be efficiently processed automatically by computing the similarities between conference papers and journal papers, pinpointing the keywords and topics that would most often appear in future journals ( Tu &amp; Seng, 2009 ). 4.2. Experimental design
To verify the accuracy and effectiveness of this method, an experiment is designed to utilize the proposed indices. The experimental results obtained in this study are compared with those obtained in previous work from which one can deter-mine whether the results are consistent. 4.2.1. Choosing the field and data resources Before determining whether a topic is important we first choose the data field and database, in this case the ACM Digital
Library. The ACM is the largest and oldest academic community in the field of education and computer science. It has had a platform for exchanging information, innovation and discoveries since 1947. ACM members belong to the information sys-tems and computer science community, and include professors, professionals, and students in industry, academia and public services in over 100 countries.

The range of the data is defined by using this method to browse journals and transactions not included in the magazine tational Biology and Bioinformatics (TCBB) and IEEE/ACM Transactions on Networking (TON) are not published by the IEEE, and the range of discussion is far exceeded the conferences held by the ACM. Conference data published by the ACM in 2007 are used. In total, the ACM held 137 conferences. Some conference papers in the database are not formal papers but rather are student papers, short papers, poster papers, keynote speeches, tutorials, and demo abstracts. These papers are not in-cluded in this study because they do not present new issues. 4.2.2. Selection of the descriptors
We use the following four descriptors referring to paper content: 3. Keywords : keywords have the highest density in knowledge, but cannot describe a new trend. Authors must identify 4. Full Text: The full text includes every concept the researcher uses concerning the subject, yet individual words embody Authors use keywords to characterize their papers. Consequently, when a term is a keyword, it becomes a backward term.
Although the full text contains the most information, it is a low knowledge-density descriptor. Many words and terms can be used to represent a research topic. Hence, typical information retrieval techniques without human judgment tend to extract journal and conference papers containing a term. The terms extracted from titles and abstracts in 2007 are used for compar-this study finds that just because there are more words in the abstract, the information embedded therein is more complete uses the abstract as the study descriptor. And, Stop-words means the words which are needed but not important meaning in a sentence such as  X  X  X he X  X ,  X  X  X  X  X ,  X  X  X n X  X ,  X  X  X s X  X  ... and so on. 4.2.3. Investigating extracted topics than frequently used words. Instead of a single word, a composite word or abbreviation is used as the candidate research topic. Although this approach will overlook topics represented by a single word such as ontology, a single word topic must be identified by a person. Candidate research topics comprised of composite words or abbreviations possess better proper-ties than single word topics which require human judgment. Conferences and journals have their own candidate research topics. To determine which one is a leading trend, we examine the intersection of candidate research topics between con-ferences and journals. This intersection represents the research topics in this study.

We assume that a hot or important topic can be found in 2007. When a topic is hot or important, discussion will increase regardless of when the topic was introduced. The year 2008 was not chosen because it had not yet ended when this study was carried out meaning that collections for conferences and journals would not be complete. For each journal and confer-ence, we assume that the research position is equal without considering priority and importance. Furthermore, the database only records the volume of papers, not the frequency that the terms occur in the document. Thus, regardless of how many topic. The approach mentioned above is used to identify research topics, which are then input into the ACM search engine as Table 3-1 .

After determining the volume of published papers in each year (see Table 3-1 ), Algorithm 3 X 1 is applied to determine which year is the C F , and Formulas (3 X 1) and (3 X 2) are applied to compute the CNI
NI table, which is formatted the same as Table 3-2 . Algorithm 3 X 2 and Formulas (3 X 3) and (3 X 4) are used to compute CPVI CNI and CPVI. Formula (3 X 5) is then used to compute the VDP for conferences and journals.

The emerging topic detection index helps in detecting the DP of a research topic in the YDP. We continue by using the YDP for conferences and journals to develop am emerging topic detection table for detecting whether a topic warrants further research. Each research topic that has a PDY exceeding 3 years is used to compute the VDP; the median of VDPs for the same its DP must be between the first and second year. After the third year, the VDP and DP will vary and NI different blocks. The emerging topic detection table uses the median VDP for each year. However, if a topic only develops for 3 years, then the VDP for the fourth year and later will not use the value of the research topic. 4.3. Experimental results
This study examined 35 journal issues and 137 conferences, altogether 689 journal papers and 5154 conference papers word terms are deleted and composite words and abbreviations retained as candidate research topics. The number of can-didate research topics from conferences is 1791 and that from journals is 311. There are 89 topics in the intersection set, ier to discover new topics in conference papers and there is still more divergence than journals.

The study suggests that some journals may concentrate on well defined topics while conferences in the same year may the volume of journals per year is less.
 cannot be viewed as an important and valuable research topic.

Using the CDP produced by CNI and CPVI , and the JDP produced by JNI and JPVI , we obtain the YCDP, which is the year of represents which type of curve generates the DP first. The YCDP and YJDP can be the determining point for which type of papers comprise the leading tread. Generally, we assume that the first paper published at a conference or in a journal will have the first DP. However, this is not exactly correct if we refer to the NI and PVI in the research. sider when determining the lead position. When the NI and PVI are also considered the outcome changes. In total, 87.64% of
This investigation confirms that researchers can discover new trends for research topics from conference papers. The re-search findings strongly support the hypothesis. 85.42% of the data nodes collected from 1990 to 2007 show that topics in conference papers influenced the topic of journal papers in the same year and for the following two years. In other words, researchers can mine new issues from conference papers.

Results from this study and previous studies can be used to validate the leading topic relationship. Here we investigate 89 research topics, while previous work focused on similarities over 3 years from 1991 X 2007. Although the data units are dif-the effectiveness of this method and indicates that the indices are useful and accurate. 4.4. How to use the emerging topic detection table to predict whether a topic warrants further research
The CDP generated from the CNI and CPVI and the JDP from the JNI and JPVI are used to generate the VCDP from CDP and the VDP for each year for years 3 X 5. The 3-year VDP focuses on the first, second and third year, and ignores data for the fourth and fifth years. The 4-year VDP is then calculated and year 5 data is ignored. This process continues until the full line for the 89 research topics.

Each topic has its own start and emerging time. Consequently, the median VDP can be used to generate the baseline for a research topic in each year. If an unknown topic exists then one cannot determine whether it has high worthiness for con-higher than the baseline, then that topic is worthless. Based on a topic X  X  development, one can determine whether the topic is valuable.

Take Virtual Environments (VEs) as an example. The VDP for each year is compared to the baseline ( Table 4-3 ). The emerging topic detection table is used to determine whether VEs should be investigated further. The JVDP in the third year that in the table (0.271), indicating that the topic of VEs in conferences in the eighth year is mature. 5. Validating the accuracy and effectiveness of the emerging topic detection indices
In this section, we describe an experiment using this research model to validate the proposed indices. We survey previ-ously published related works to find information about topics which have already been validated using other methods. We also survey some experts on the topic selected to validate the indices. The validation procedure for author impact power is illustrated in Fig. 5-1 .
 5.1. Comparing the experimental results with previous work
In order to validate the accuracy and effectiveness of the emerging topic detection indices, we look for related work where emerging topics have also been detected but within a different research time range and field. The most similar work that we found is that of Jo et al. (2007) in SIGKDD (ACM SIGKDD Conference on Knowledge Discovery and Data Mining). Their ap-than a random selection of documents. They used the Citeseer data which contains 716,771 papers, with 1740,326 citations.
This amounts to 2.43 citations per paper. For each paper, we use the combined title and abstract for documentation. The number of bigrams in the corpus after pruning out the low-frequency bigrams and 35 stop words is 631,839. The majority of papers are from the years 1994 to 2004.

Besides the research approach, the database and the time range of the dataset are different from those used this study, but emerging time of each topic. Their work contains both conference papers and journal papers. In order to map their work we selected topics which they claimed to have emerged from their study. These topics are image retrieval, sensor network, semantic web, support vector. The indices are then applied to find out the potential developed year and the published vol-ume in each year for these topics in the ACM digital library. The NI and PVI of each topic proposed by their work are com-puted afterwards. A comparison of the results is discussed below. 5.1.1. Sensor networks
The topic sensor network is one of the most common emergent topics in their work. The emerging time falls in the year 2004. Fig. 5-2 shows the topic evolution of sensor networks over time. The original published conference and journal vol-umes are shown in Figs. 5-3 and 5-4 , respectively. The year of the conference detection point is 2004. This is the same as in Jo et al. (2007) where the year of journal detection point is 2006. The results are shown in Fig. 5-5 . 5.1.2. Semantic web
The topic of  X  X  X emantic web X  X , which emerged in the year 2004, is another common emergent topic that was discussed in their work. Fig. 5-6 shows the evolution of the topic semantic web over time. The original published volume of conferences and journal are shown in Figs. 5-7 and 5-8 , respectively. The year for the conference detection point is 2004 which is the same as in Jo et al. (2007) and the year for the journal detection point is 2007. The results are shown in Fig. 5-9 . 5.1.3. Support vector
The topic  X  X  X upport vector X  X  is another topic that emerged in the year 2004. However, they claimed that the topic support sensor network and semantic web. Fig. 5-10 shows the evolution of the topic of support vector over time. In this current in 2004, are detected correctly using the emerging topic detection indices. 5.2. Comparing the experimental results with the expert survey results
Besides comparing the experimental results with those obtained from previous works as noted in the literature review, we also survey five experts who have investigated the topic of data mining. We ask them to give opinions, including yes, no professors, one associate professor and two full professors, three from the department of Management of Information Sys-tems and two from Computer Science and Engineering. E1 means Expert 1, and Grade represents the votes which a topic receives. The expert survey results for 3 topics also validate these indices as shown in Table 5-1 .

We give each topic a grade when one of the experts considers it to really be an emerging topic during the given period of not get more support because some of the experts were not sure whether support vector referred to the support vector ma-chine or not. This is a limitation because of the meaning of the term. We only can extract terms from previous work and can not exactly make sure of their meanings. 6. Applications and Implications
The NI helps researchers to exam research topics from the view point of novelty and aging theory. The novelty and aging concepts should be considered while we discuss the emerging topic detection not only the hot topic detection. Emergency implies new and urgent.

The PVI differs from past simple frequency lines such as in the work of Jo et al. (2007) which only can tell how much the falling curve.

The combination of the NI and PVI can draw the detection point and the VDP since the DP means the NI and PVI are both at the highest value. The DP possessing the characteristics of being both novel and hot matches the expectation of emerging topics. The most important finding is the development of a method and indices which helps researchers to construct their own field topic detection tables and examine new topics in their own field.

The database used in this study includes various journals and conferences related to computer science from the ACM database of publications of journals and transactions, and conference proceedings. There were 689 journal papers and 5154 conference papers published in 2007. Conferences account for 1791 research topics, and journals for 311 topics. The intersection is 89 research topics. From the research topics intersection ratio, the ratio of conferences is almost 5% and the journal ratio is nearly 29%. Thus, there is more convergence in the topics discussed in journals and more divergent in conferences.

We demonstrate the development of emerging topic detection indices. The YCDP and YJDP can determine the lead rela-quently, we suggest that the first DP is a leading position. The YDP can help to determine which type of paper is in the lead position. This study also proves that the first publication time is not the critical factor when determining the YDP. ment of journals. We use different research methods and different databases than in previous works which only focus on the tiveness of the proposed indices.

This study uses the NI and PVI to develop the emerging topic detection indices. The concepts of terms, topics, and can-didate research topics are used to investigate topics, and we also discuss the CNI and CPVI for conferences and the JNI and when the topic emerges. The YCDP and YJDP can be used to determine which type of papers stand in the leading position.
The VDP can be used to determine whether to investigate a topic further. Based on the NI and PVI, one can show that when ciently high for further research.

Finally, the emerging topic detection indexes detect the DP and obtain the YDP and VDP. By comparing conferences and basis of the detection table.

Even when the published volume is low, the PVI will be high since it compares to itself the total number that can decide rants further investigation. Consequently, when one does not know whether a topic is important or worthy, one can compute tion table, it has never garnered popular attention; thus, the topic is worthless.

The method presented in this study can also be applied in bibliometrics and patent analysis as in previously related works on tech mining. The method can be used by business analysts, inventors and governmental agencies and so on. For example, prediction by the financial analyst, to know which area of the market is over hot and where more investment is possible.
Organizations and governments can use the indices to determine and realize novelty and the number of the inbound com-petitors in their enterprise. Governments also can use the indices to observe the development of social phenomenon such as economics and to make sure that they balance supply and demand in marketplace. 7. Concluding remarks
This study addresses the inadequacy of topic detection and tracking to develop a set of novel indices for emerging topic detection. The novelty concept is used in combination with aging theory to develop the novelty index (NI). The published volume index (PVI) is an improvement over traditional frequency methods to reflect the growth of a discussion topic. The DP and YDP help determine the relationship between conference topics and journal topics and how long they lead ahead. The VDP is created to construct the detection table to determine whether a topic warrants further research. The NI and PVI can be applied to other fields to determine new trends, for example, the news or stock price predictions.
The indices also have some limitations based on the units of the data sets which we can collect. For example, the dates of research papers are based on the year instead of months, and the DPs at year 2022.1 and year 2002.9 will be the same given these indices.

Future work will extend the NI and PVI with more diversified experiments. The set of novelty indices can be improved using other areas of training and testing models. A more complicated detection table can be generated. References
