 Recently, the problem of Named Entity Recognition in Query (NERQ) is attracting increasingly attention in the field of information retrieval. However, the lack of context information in short queries makes some cla ssical named entity recognition (NER) algorithms fail. In this paper, we propose to utilize the search session information before a query as its context to address this limitation. We propose to improve two classical NER solutions by utilizing the search session context, which are known as Conditional Random Field (CRF) based solution and Topic Model based solution respectively. In both approaches, the relationship between current focu sed query and previous queries in the same session are used to extract novel context aware features. Experimental results on real user search session data show that the NERQ algorithms using search session context performs significantly better th an the algorithms using only information of the short queries. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval  X  search process Algorithms, Experimentation Search Session, Named Entity Recognition, CRF, Topic Model Nowadays, the Named Entity Recognition problem in Query (NERQ) has attracted increasingly attention from information retrieval community since it can be used to fix a number of failure cases in the relevance based sear ch engines. Figure 1 gives an example of failure case in a commonly used commercial search engine. If we can identify  X  Eagle Vision  X  as a named entity in query, this irrelevant result will not be returned to end users with high rank. To our best knowledge, there are only a few previous studies that have tried to recognize named entities in queries. As topic model to identify named entities in queries and they showed that around 70% of the real search queries contain named entities. However, since the queries are alwa ys very short (i.e., 2-3 words on average) and many of them do not satisfy the natural language grammar [3], both the classical Named Entity Recognition (NER) In the CRF [4] based method, tw o new types of search session features are used by the classifier. Following are the details of the new features:  X  Class feature: using every element of  X   X  X  X  X  X  X  in Definition-1 as  X  Overlap feature: using every element of  X   X  X  X  X  X  X  X  X  X  in In the Topic Model based me thod, a single-named-entity query  X  is represented as triples  X  X , X , X  X  , where  X  denotes named entity,  X  denotes the context of  X  in  X  , and  X  denotes the class of  X  [3]. In our experiment, for simp licity, only one query before the current focused query is considered . In online prediction, we try to segment both the current focused query and the previous query in all possible ways together, and the triples with the highest  X   X  X  X  X  X  X  X  X  X  X  X  value are output results for NERQ.  X  where Pr  X  X  X  X   X   X , X , X   X  and Pr  X  X  X   X   X , X , X   X  are the joint probabilities with respect to previous query and current query in the same search session.  X   X  X  X  X  X  X  represents the class distribution similarity between the two sequential queri es, which is defined as :  X   X  X  X  X  X  X  X  X  X  represents the effectiveness of the overlap feature, which is defined as: word X  X  index in the current focused query, and  X   X  is defined in experiment we define  X  as P X   X  X  X  X   X  X , X , X  X  X  In the experiments of this wo rk, we only use the car model domain queries for de monstration. We have two sets of experiments by CRF and topic m odel respectively to compare the NERQ results with and without context information in search sessions. In the experiment of using CRF model for NERQ, we start with a small car name dictionary whic h contains 1,663 standard car names to build a dataset for evaluation. Using the car name dictionary, we firstly scan one month X  X  click-through log data of a commercial web search engine. If a query which contains car names in the car name dictionary is found by exact match, then all the queries in the same search session are added to our dataset with the query order in session unch anged. In this experiment, we defined 5 named entity (NE) tags, namely 0 (Not entity), 1 (Single word entity), 2 (Beginning of the entity), 3 (Middle of the entity), 4 (Ending of the entity). We have asked 10 human labelers to manually label car domain named entities in queries of our corresponding search sessions are used as training set and 1000 queries in remaining search sessions are used as testing set. In this 
