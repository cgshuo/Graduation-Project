 Social network analysis has attracted increasing attention in recent years. In many social networks, besides friendship links amongst users, the phenomenon of users associating themselves with groups or communities is common. Thus, two networks exist simultaneously: the friendship network among users, and the affiliation network between users and groups. In this paper, we tackle the affiliation recommen-dation problem, where the task is to predict or suggest new affiliations between users and communities, given the current state of the friendship and affiliation networks. More gener-ally, affiliations need not be community affiliations -they can be a user X  X  taste, so affiliation recommendation algorithms have applications beyond community recommendation. In this paper, we show that information from the friendship network can indeed be fruitfully exploited in making affili-ation recommendations. Using a simple way of combining these networks, we suggest two models of user-community affinity for the purpose of making affiliation recommenda-tions: one based on graph proximity, and another using la-tent factors to model users and communities. We explore the two classes of affiliation recommendation algorithms sug-gested by these models. We evaluate these algorithms on two real world networks -Orkut and Youtube. In doing so, we motivate and propose a way of evaluating recommenders, by measuring how good the top 50 recommendations are for the average user, and demonstrate the importance of choosing the right evaluation strategy. The algorithms suggested by the graph proximity model turn out to be the most effective and efficient. This use of link prediction techniques for the purpose of affiliation recommendation is, to our knowledge, novel.
 H.2.8 [ Database applications -Data mining ] Algorithms, Experimentation
There has been an explosion in the number of online social networks and their active members. This wealth of informa-tion in the social networks has driven prolific work on the analysis of the networks, understanding the processes that explain the evolution of the networks, modeling the spread of behavior through the networks, predicting their future state and so on.

Users of a social network tend to affiliate with commu-nities. In some social networks, the groups are identified more by the preferences of the members of the social net-work than by direct declaration: e.g. the genre of movies that a set of customers tend to patronize more often in Net-flix. Online social networks like Facebook, Orkut and Live Journal are more interesting examples because the affiliation networks here are explicitly established by the members of the network. Thus, two networks exist simultaneously: the friendship network among users, and the affiliation network between users and groups.
 works[1], and co-evolution of social and affiliation networks[13] have been recently studied. One of the interesting challenges in social network analysis is the affiliation recommendation problem, where the task is to recommend communities to users. The fact that the social and affiliation networks  X  X o-evolve X  suggests that a better solution to the affiliation rec-ommendation problem can be obtained if the friendship net-work is considered along with the affiliation network. This problem setting has applications beyond community recom-mendation. Affiliations, for example, can be interpreted in general as a user X  X  taste for an item. Neither is it limited to social networks. For example, in biology, the friendship network can correspond to a network among genes, whereas the affiliation network can correspond to a network between genes and traits/ diseases, and the affiliation recommenda-tion problem can be viewed as one of identifying genes af-fecting the expression of a disease.
 play between users and communities in both the networks simultaneously. An ideal unifying model would not only explain the current state of the networks, but also help in predicting future relationships among the nodes. Using a simple way of combining these networks, we suggest and ex-plore two ways of modeling the networks for the purpose of making affiliation recommendations. The graph proximity model is based on estimating the affinity between a user and a community by considering their proximity as nodes in a combined graph, while the latent factors model is based on the proposition that community affiliations arise from inter-actions of user and group factors . Each of these network models suggests affiliation recommendation algorithms. We evaluate these algorithms on social networks from Orkut consisting of 9,123 users and 75,546 communities, and Youtube consisting of 16,575 users and 21,326 communi-ties. We propose a way of evaluating affiliation recommenda-tions, by measuring how good the top 50 recommendations per user are, and demonstrate the importance of designing the right evaluation strategy. Of the algorithms proposed, those suggested by the graph proximity model turn out to be the most effective and efficient. This use of link predic-tion techniques for the purpose of affiliation recommenda-tion is, to our knowledge, novel. We show that information in the friendship network can be used effectively for affilia-tion recommendation. We also observe that the benefit we derive from the social network in affiliation recommendation is strongly contingent on how the problem is modeled and what algorithms are used.
 nization of the paper. In Section 2, we consider a network formed by merging the friendship and affiliation networks and introduce two models of the behaviour of nodes in this network: the graph proximity model, and the latent factors model, and explore recommendation algorithms that arise from these models. In Section 3, we consider how the pro-posed models and algorithms relate to prior work. Then, in Section 4, we describe our chosen evaluation strategy, and using experiments on real world networks, we evaluate the effectiveness of various algorithms in affiliation recommenda-tion in practical scenarios. Finally, in Section 5, we conclude with a summary of our findings, and a discussion of future lines of research in this direction.
In this section, we first establish the notation used, and then pose the affiliation recommendation problem as a rank-ing problem. Then we describe a natural way of combining the friendship and affiliation networks into a single graph. In the subsections that follow, we describe affiliation recom-mendation approaches based on the graph proximity model and those based on the latent factors model.
 Notation. We use N u to denote the total number of users in the affiliation network and N g to denote the total number of communities in the affiliation network. A  X  R N u  X  N g de-notes the user  X  group adjacency matrix of affiliation net-matrix of friendship network S . Other notation will be in-troduced as needed.
 iations to a given user. This problem can be posed as a problem of ranking various affiliations in the order of the user X  X  interest in joining them. The methods we describe here to solve this problem rely on assigning scores to vari-ous affiliations in order to rank them. The task of an affil-iation recommendation algorithm can be viewed as one of generating an N u  X  N g score matrix.
Consider the adjacency matrices A and S . For now, we assume S to be symmetric (or equivalently S to be undi-rected), although a non-symmetric extension to our model can be easily obtained. Clearly, S corresponds to an undi-rected graph among users and undirected bipartite graph between users and groups. De-spite the heterogeneity of the two types of X  X inks X , it is rather natural to consider a graph C between all the users and groups, with the combined adjacency matrix where the heterogeneity of two types of links is reduced to a single parameter  X   X  0, that controls the ratio of the weight of friendship to the weight of group membership. Clearly when  X  = 0, the user-user friendship ceases to play a role in this joint graph, and it simply degenerates to the bipartite affiliation graph.

As in the case of prediction with a single graph, the pre-diction on C can be carried out from the following two per-spectives: We will elaborate on the two perspectives in the following two subsections.
As described earlier, the affiliation network can be mod-elled by a graph. The graph proximity model assumes that the probability of there arising a link between two nodes in a graph is based on an estimated proximity between the two nodes. The proximity of two vertices can be calculated as the weighted sum of the number of paths connecting the two with varying lengths. This is the underlying mechanism of many link prediction models in the context of social network analysis. Consider the widely-used Katz measure[8] on the friendship network S . The proximity is given by where the weights of paths decay exponentially with the length.
 A simple extension of Katz to the bipartite graph A is
Katz ( A ;  X  ) = (  X  AA T +  X  2 ( AA T ) 2 +  X  3 ( AA T ) where in the co-occurrence matrix AA T , two users i and j are considered connected if i and j belong to at least one same group, i.e. ( AA T ) ij &gt; 0. In this case, we consider the paths of the following types The intuition in considering AA T A is if user i shares some community with user j , it is likely that i will join some other community j belongs to. The higher order terms can be interpreted in a similar way.

Consider the following Katz-measure proximity matrix on the combined graph C The user-community block of the above matrix is simply katz ( C ;  X  ) 12 =  X  A +  X  2  X  SA +  X  3 (  X  2 S 2 A + AA Clearly (2) generalizes the normal Katz on the bipartite graph A by also considering some paths like and katz ( C ;  X  ) 12 can then be used as the score matrix.
Since the computation of the Katz matrices as described above is expensive, we consider a truncated Katz matrix, For computing the Katz matrices for the graphs described by A or C , a conservative estimate of the computational cost is O ( N u  X  nnz ), where nnz is the number of non-zeros in ( AA T ) k .
We now describe the latent factors model, consider the op-timization problem it tries to solve, and examine some of its properties. In this model, the zeros in the adjacency matrix of the affiliation network, A may be viewed as being unob-served entries with a huge prior belief in favor of them being actually zero. Every user i and community j are assumed to have a low dimensional representations u i , g j . The affinity of a user i to a community j is assumed to correspond to u g j . In other words, users and communities with a high inner product are assumed to be connected to each other; that is to say: In matrix form, we express this as R d, rank( G )  X  d, d  X  N u , N g .

To get factors which account for both the observed entries in A as well as the interactions in S we consider the following generalized combined network, where D is the derived similarity between groups which is not observed. Note that C = C  X  (  X , 0). Also, we approxi-mate C  X  as an interaction of user and group factors of the individual graphs. i.e.
 The same set of user factors drive both the friendship and affiliation network creations. We therefore want to find the user factors U and the group factors G such that the recon-struction error on the observed entries in C  X  , is minimized.
 Role of  X  . Intuitively, in equation (4),  X  controls the con-tribution of S in deciding the user factors. The larger the  X  , the learned factor model describes the friendship network S better, and correspondingly the affiliation network is de-scribed less well.
 ties D in the combined matrix C  X  can be approximated using proximity between communities in the graph corresponding to C  X  . It follows that a potential choice is D = A T A , which is simply the number of users which any two communities share. One may also consider weighing the contribution of D with  X  , which is the weight factor learnt for S . We will see later that the experiments suggest that the choice of D is not very important, and that the information from D , when derived from A, is redundant.
The analytical solution to the minimizing { U , G } of the objective function in (4) is given by the SVD of C  X  . Specif-ically, where SVD( C  X  , d ) denotes the rank-d singular value decom-position of matrix C  X  , i.e, C  X   X  U X G T , where  X  is the d  X  d matrix of singular values, U is the matrix of d leading left singular vectors, and G is the matrix of d leading right sin-gular vectors. We can interpret the low rank approximation U X G T as the score matrix.
Increasing attention to recommendation systems in gen-eral can be attributed primarily to commercial enterprises like Netflix and Amazon, where making good recommenda-tions for the customers is important for business. A huge body of literature studies the problem of group recommen-dation, where the problem is to recommend items or prod-ucts to a group of users in a friendship network. Affiliation recommendation for users of a friendship network, however, is relatively new and less studied.
We now examine the relationship of the latent factors model proposed in this paper to a variety of other mod-els proposed recently. Bader and Chew[2], in the context of information retrieval, tackle the problem of applying LSA to multi-lingual corpora. In such corpora, one has access to term-similarity information along with term-document matrices corresponding to various languages. In order to derive low dimensional term and document factors which account for information from both these sources, they form a joint matrix similar to our combined adjacency matrix C and compute its SVD. However, unlike this work, [2] does not deal with the item recommendation problem, and it does not view this joint matrix as arising out of a pair of networks.
We will now consider two other joint matrix factorization models: One class of models uses a probabilistic collabo-rative filtering to approach the problem, whereas another tackles the problem of combining information from multiple sources from the perspective of joint matrix factorization.
Collaborative filtering is a natural way to approach the affiliation recommendation problem. Typically collaborative filtering is applied to user-item preference problems. This is based on the simple idea that users with similar tastes behave similarly.

This approach has recently been applied to the affiliation recommendation problem by Chen et al[4]. The authors examined the use of Latent Dirichlet Allocation (LDA) in affiliation recommendation. The LDA approach does not use information from the friendship network among users. So, here we briefly examine the relationship between the latent factors model we propose and this LDA based approach, while ignoring the friendship network aspects of our model.
Consider the objective (4) we are trying to minimize. In the proposed model, if we ignore the constraint that the user factors U do not result in too large a deviation from S , we are essentially trying to find a low rank approximation to A in terms of the Frobenius norm. The solution which minimizes that objective is given by the SVD of A . This is the Latent Semantic Analysis approach (LSA), which has long been exploited for similar problems in the area of in-formation retrieval. pLSA, or probabilistic LSA [6], instead proposes a statistical model for the process generating A and then learns the model parameters which are most likely to have generated the observations in A . These parameters can then be used in finding a low rank approximation to A , in terms of the KL divergence. It can thus be viewed as the probabilistic version of LSA. LDA, where Dirichlet priors are added to pLSA X  X  generative model, can be viewed as the Bayesian version of pLSA. Thus, the LDA based approach to the affiliation recommendation problem may be viewed as trying to find a low rank approximation to A , albeit from a probabilistic, Bayesian perspective, while ignoring informa-tion from S .

Combinatorial collaborative filtering[5] is another work in the same vein. Unlike the LDA based approach, how-ever, the probabilistic model of user-community relation-ships used in this work utilizes information not only from A , but also from text descriptions of various communities. Next, we examine a couple of closely related matrix factor-ization models.
Tang et al have proposed Linked Matrix Factorization (LMF) [12] as a way of combining information from mul-tiple graphs on the same set of entities, in order to make more accurate inferences. However, they tackle a different problem, namely, clustering. The link between their network model and ours is established by the objective functions that we optimize. The LMF model tries to simultaneously find a low rank approximation for the adjacency matrix of each network, using matrix factorization. Each such matrix fac-torization has a source-specific factor matrix,  X  ( m ) , and a factor matrix, P , that is shared by all the sources. The ob-jective function of LMF is effectively to minimize the quan-tity,
Comparing this to (4), we see that U , which represents the user factors, is shared by the two sources of information, i.e., A and S . However, an important distinction is that we have two graphs which share only one set of entities in common, whereas in LMF, each source of information is a network on exactly the same set of users.

Singh and Gordon have proposed a model for relational learning called Collective Matrix Factorization[11]. They suggest a generalized framework for inferring relations, given a set of entities and observed relations among them. This model factors multiple source matrices simultaneously, and uses common factors for approximation whenever the same entity participates in multiple relations. It allows different loss functions for each matrix approximation, and combines the information from multiple relations using weights which reflect the relative importance for each relation. This essen-tially generalizes the idea of Linked Matrix Factorization. The Latent Factors Model proposed in this paper uses the parameter  X  to determine the contribution of the friendship network S in generating the user factors.

The above mentioned papers use optimization techniques based on the alternating least squares approach, we use SVD which efficiently solves the optimization problem posed by the latent factors model.
Researchers have studied the effects of friendship ties on affiliations in other contexts, like the growth and evolution of social networks[1], and spread of influence through a so-cial network[7, 3]. They tend to model the dependence of a user joining a group on the number of friends the user al-ready has in the group. Zheleva et al[13] proposed a unified model for the generation of social and affiliation networks, and observed that the social network is one of the factors that influences the evolution of affiliation network. Our idea that friendship network combined with the affiliation network can be exploited in making affiliation recommenda-tions is inspired by this line of research.
We first introduce the datasets on which we conduct our experiments, and describe the experiment setup. We then describe our methodology for comparing the performance of various algorithms at the affiliation recommendation task. Finally, we discuss the results of experiments which apply the algorithms based on both the graph proximity model and the latent factors model in performing affiliation rec-ommendation. We use two popular online social networks Orkut and Youtube , both operated by Google, for our experiments. The users of both the social networks explicitly identify them-selves as belonging to some communities or groups . Thus, for each of the networks we have adjacency matrix A that identifies the memberships of the users in the groups and adjacency matrix S that identifies friendships among users. For our experiments, we used data gathered by Mislove et al [9]. We compare the predictive ability of the algorithms using sub-networks extracted from these large networks 1 . The statistics for these networks are presented in Table 1. Feature Orkut Youtube N u 9123 16575 N g 75546 21326 Average number of groups per user 55.8 10.5 Minimum number of groups per user 4 4 Mode of number of groups per user 6 4 Average number of users per group 6.7 8.1 Mode of number of users per group 2 1 Minimum number of users per group 1 1 Average number of friends per user 46 11.7 Mode of number of friends per user 2 1 Table 1: Details about the datasets used in experi-ments.
For every user u , let E u = { ( u, v ) | A u,v = 1 } denote the affiliations of u , as observed in a given affiliation network A . Invariably in all the experiments, we set aside a subset of these affiliations E ( t ) u  X  E u as test data (we use | E 30% | E u | ). The remaining affiliations E ( tr ) u = E u used as training data for the recommendation algorithms.
All of our recommendation algorithms require  X  X earning X  parameters for some model of the affiliation process, and hence for the purposes of learning the parameters, we use a set of validation edges E ( v ) u  X  E ( tr ) u (we use | E 30% | E ( tr ) u | ). During the validation process, we compare different model parameters based on the number of cor-rect edges among 25 N u recommendations 2 made using the model.
We now describe our methodology for evaluating the per-formance of an affiliation recommendation algorithm. We first introduce notions of interest, such as precision, sensitiv-ity, specificity, ROC and AUC. We then describe the way in which we evaluate the performance of a recommendation al-gorithm based on its top 50 recommendations to the average user. We then demonstrate the importance of choosing the right evaluation method for the community recommendation task by showing that using a different, but less appropriate, evaluation strategy yields different results.

Three commonly used measures of quality of solutions in information retrieval and classification tasks are Precision , Recall or Sensitivity and Specificity . Precision measures the exactness or fidelity of the prediction while Sensitivity mea-sures the completeness of the prediction. Suppose that the
We extracted a small connected component from the large network for the propose of experimentation.
This is chosen because, in Section 4.2.1, we argue that a predictive model should be judged based on the quality of its top few recommendations. recommendation algorithm makes n recommendations to a user. Then, Precision is defined as the ratio of the number of correctly identified positives (true positives) to n , and Sen-sitivity is the ratio of the number of correctly identified pos-on the other hand, measures the ability of the recommender to exclude uninteresting affiliations from the recommenda-tions it makes. It is defined as the fraction of such  X  X eg-ative affiliations X  correctly excluded from the recommenda-tion. All three of these performance measures range from 0 to 1.

Often, one is interested in evaluating the performance of a recommendation algorithm not for a single value of the number of recommendations n , but for the entire range of n . For a given recommendation algorithm and a user, sen-sitivity is a non-decreasing function of n , while specificity is a monotonically non-increasing function of n . The relation-ship between the increase in sensitivity, as n increases, with the decrease in specificity is of interest in comparing the quality of recommendations. For a good recommendation, as n increases, sensitivity increases without a big drop in specificity. The Reciever Operating Characteristics (ROC) curve, which is a plot of sensitivity vs (1 -specificity) for all values of n , is a common way of comparing the perfor-mance of classification algorithms over the entire range of n (or equivalently cutoff scores). Area under the ROC curve, or AUC, is then used as a way to compare different clas-sification algorithms: the greater the AUC, the better the algorithm X  X  sensitivity vs 1-specificity tradeoff.
Consider a social network website, like Orkut or Face-book; or a vendor like Netflix which sells movies. They would be interested in making, let us say, five pages of rec-ommendations to their users, but not much more than that: certainly not a hundred. Also, irrespective of whether a user participates in five communities or seventy, the social net-working website would probably want to make roughly the same number of recommendations per user. So, we choose to evaluate the recommendation algorithms we propose based on their top 50 recommendations. We do this by examining a slice of the ROC curve formed by measuring the sensitiv-ity and specificity the recommendation algorithm achieves for an average user at regular intervals between n = 1 and n = 50. To do this, for a given n , we compute the sensitivity and specificity for every user in the network, and take the mean of these values to be the average sensitivity and aver-age specificity. We then plot the average sensitivity vs 1 -average specificity curve, as in Figure 2. Note that compar-isons made using this method are statistically robust, as the sensitivities and specificities of recommendation algorithms are averaged over, for example, 9500 users in Orkut and 16000 users in Youtube.

Let k ( n u ) be the number of X  X ood recommendations X  X ade by a recommendation algorithm for a user u , when it makes n u recommendations to that user. Then, the above  X  X er experiments, we will use  X  u : n u = 50.
 Contrast this with finding the X  X lobal X  X ensitivity k  X  ( n ) where k  X  ( n ) denotes the number of  X  X ood recommendations X  made by a given recommendation algorithm while making n predictions in total. For a fixed n , this  X  X lobal X  sensi-tivity is proportional to precision, and is a commonly used measure of performance of link prediction algorithms in the context of social network analysis. Note that, in this case, while n = P u n u , there is no guarantee that, for two given users u and v , n u = n v ; indeed the recommendation al-gorithm, when asked to make n recommendations, may not make any recommendations at all for some users. Therefore, this measure of goodness of a recommendation algorithm is not equivalent to the  X  X er user X  sensitivity described earlier.
Also, judging identical algorithms on identical datasets, using this alternate evaluation method can yield very differ-ent rankings of recommendation algorithms, as illustrated by comparing Figure 1 with Figure 2. Hence, the choice of an appropriate method for evaluating affiliation recommen-dations is an important one. Figure 1: Comparison of recommendation algo-rithms using X  X lobal sensitivity X  X ields results differ-ent from Figure 2 while making P u E u recommen-dations in total (See Section 4.2.1).
In this section, we report and analyse the performance of the various recommendation algorithms, based on the graph proximity model and latent factors model discussed in Sec-tion 2. We compare the performance of the graph proximity based methods with latent factors based methods based on the average sensitivity and average specificity metrics intro-Figure 2: Comparison of recommendation algo-rithms based on graph proximity and latent factors models, as described in Section 4.2.1. The leading slice of the ROC curve is shown. The graph proxim-ity based predictors consistently outperform latent factors based predictors in the two datasets. See Section 4.3 for discussion. duced earlier, for a given number of recommendations in the range [5,50] (in steps of 5).

The results are reported in Figure 2. Consider the per-formance of the recommendation algorithms on the Orkut dataset in Figure 2 (a). SVD( A ) gives the lowest perfor-mance of all the methods. SVD( C ) performs better than SVD( A ), which is expected given that it uses information from the friendship network S in addition to the information from affiliation network A . For the average user, the graph proximity model based methods significantly outperform la-tent factors based methods as observed from the figure. In particular, we see that tKatz( C ) performs much better than tKatz( A ), which in turn outperforms latent factor based methods. We see that the information in the friendship net-work indeed proves highly beneficial to making affiliation recommendations and graph proximity based methods ex-ploit this information the most.

Another interesting comparison of latent factor methods based on the choice of D in constructing the combined net-Figure 3: Comparison of latent factors based al-gorithms for various choices of D, for the Orkut dataset. See Section 4.3 for discussion. work C  X  given in (3), is presented in Figure 3. We observe that the choice of D does not appear to make any signifi-cant difference in the performance of the recommendation algorithm. In the plot, D 2 denotes using A T A for D in C  X  while D 3 denotes using  X  A T A , where  X  is also the weight associated with S in the combined graph. Though, in case of the Orkut dataset, we see that SVD( C  X  , D ) performs slightly better than SVD( C ), the choice of D 6 = 0 does not affect the performance. In case of Youtube (plots not shown), our ex-periments indicate that D is not useful at all. The potential choices for D do not perform any better than D = 0. The summary of performances of the algorithms on the Youtube dataset is shown in Figure 2 (b). We observe that the case for Youtube is similar to that of Orkut, in that graph proximity based algorithms significantly outperform latent factors based algorithms. In particular, tKatz( C ) is highly successful compared to the other methods.

The best parameters learnt by the various algorithms are presented in Table 2. Note that the best parameter  X  = 10  X  12 implies that the calculated tKatz measure was effec-tively using the common neighbors method. In other words, users and communities connected by path lengths 5 or more are not useful in making affiliation recommendations.
SVD( C  X  (  X  A T A )) d = 60 ,  X  = 0 . 6 d = 70 ,  X  = 1 Table 2: Best parameters learned by the recommen-dation algorithms using validation.

We see that the recommendation algorithms perform con-sistently across the two datasets, and the evaluations are robust as the specificities and sensitivities are averaged over 9000 users in Orkut and 16000 users in Youtube.
In this paper, we have tackled the affiliation recommen-dation problem, where the task is to recommend new affilia-tions to a given user, given the current state of the friendship and affiliation networks. We show that information from the friendship network can indeed be fruitfully exploited in making affiliation recommendations. This auxiliary source of information was hitherto not used in making community recommendations.

Using a simple way of combining these networks, we sug-gested two ways of modeling the networks for the purpose of making affiliation recommendations (Section 2). The first of these approached the problem from the graph proxim-ity viewpoint, whereas the second modelled the interactions of users and groups in the two networks using latent fac-tors derived from optimizing towards a joint matrix factor-ization objective. We studied the algorithms suggested by these models on real world networks (Section 4). We moti-vated and proposed a way of evaluating recommenders, by measuring how good the top 50 recommendations are, and demonstrated the importance of choosing the right evalua-tion strategy. Algorithms suggested by the graph proximity model turn out to be the most effective, based on experi-ments on large real world data-sets. These results show that the application of techniques from social network link predic-tion in affiliation and item recommendation is a promising one.
There is the intriguing possibility of using an affiliation network for link prediction in the friendship network. Dis-covering techniques and models which do this effectively seems to be a challenging research avenue. Our early ex-periments at doing this indicate that this is a much harder problem. The reasons for this are not yet clear, and this question seems fertile for further exploration.

Within the ambit of the affiliation recommendation prob-lem itself, one may research the ways of fruitfully using even more sources of information. For example, Chen et al[5] use information from textual description of communi-ties along with the affiliation network to make affiliation recommendations. It might be useful to consider the so-cial network together with this auxiliary information. Also, predictors based on latent factors model and the graph prox-imity model may be suited for different types of users, and creating a meta-predictor which combines predictions from both classes of predictors is another attractive research di-rection. Scalability is a challenge in using predictors based on the graph proximity models on massive datasets -both in terms of memory and in terms of computational cost[10], and developing efficient predictors based on the graph prox-imity model will be part of future work.
We thank Prateek Jain and Berkant Savas for helpful dis-cussions. We also thank Alan Mislove [9] for providing ac-cess to Orkut and Youtube datasets. Zhengdong Lu is sup-ported by an ICES postdoctoral fellowship at UT Austin. This research was supported by NSF grants CCF-0916309 and IIS-0713142. [1] Lars Backstrom, Dan Huttenlocher, Jon Kleinberg, [2] Brett W. Bader and Peter A. Chew. Enhancing [3] Wei Chen, Yajun Wang, and Siyu Yang. Efficient [4] Wen-Yen Chen, Jon-Chyuan Chu, Junyi Luan, [5] Wen-Yen Chen, Dong Zhang, and Edward Y. Chang. [6] Thomas Hofmann. Probabilistic latent semantic [7] David Kempe, Jon Kleinberg, and  X  Eva Tardos. [8] David Liben-Nowell and Jon Kleinberg. The link [9] Alan Mislove, Massimiliano Marcon, Krishna P. [10] B. Savas and I. S. Dhillon. Fast and accurate low rank [11] Ajit P. Singh and Geoffrey J. Gordon. Relational [12] Wei Tang, Zhengdong Lu, and Inderjit S. Dhillon. [13] Elena Zheleva, Hossam Sharara, and Lise Getoor.
