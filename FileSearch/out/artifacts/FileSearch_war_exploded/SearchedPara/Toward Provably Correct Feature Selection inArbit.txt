 The problem of feature selection has a long history due to its significance in a wide range of im-portant problems, from early ones like pattern recognition to recent ones such as text categoriza-tion, gene expression analysis and others. In such domains, using all available features may be prohibitively expensive, unnecessarily wasteful, and may lead to poor generalization performance, the domain for use in subsequent application of machine lear ning algorithms has become a standard preprocessing step. A typical task of these algorithms is learning a classifier : Given a number of ing the domain and the quantities that interact with the target q uantity.
 Many algorithms have been proposed for feature selection. U nfortunately, little attention has been ones that contain a (near) parity function [1], which contai n interactions that only appear when the values of multiple features are considered together. There is therefore an acute need for algorithms In this paper we present two such algorithms, an exact and a mo re practical randomized approximate one. We use the observation (first made in Koller and Sahami [2 ]) that an optimal solution to the problem is a Markov boundary, defined to be a minimal set of fea tures that make the probability the Markov boundary of a target variable in arbitrary domain s. We first introduce a theorem that tion of the ideal boundary that are provably correct under a minimal set of assumptions, including a set of axioms that hold for any probability distribution.
 Section 3. We subsequently introduce an important theorem a nd the aforementioned parameterized family of algorithms in Sections 4 and 5 respectively, inclu ding a practical anytime version. We evaluate these algorithms in Section 6 and conclude in Secti on 7. Numerous algorithms have been proposed for feature selecti on. At the highest level algorithms can be classified as filter , wrapper , or embedded methods. Filter methods work without consulting the it to evaluate each of a sequence of feature subsets, and sele cting the subset that results in mini-decision tree learners.
 Early work was motivated by the problem of pattern recogniti on which inherently contains a large number of features (pixels, regions, signal responses at mu ltiple frequencies etc.). Narendra and Fukunaga [3] first cast feature selection as a problem of maxi mization of an objective function over the set of features to use, and proposed a number of search app roaches including forward selec-tion and backward elimination . Later work by machine learning researchers includes the FO CUS algorithm of Almuallim and Dietterich [4], which is a filter m ethod for deterministic, noise-free domains. The RELIEF algorithm [5] instead uses a randomized selection of data points to update a weight assigned to each feature, selecting the features who se weight exceeds a given threshold. A large number of additional algorithms have appeared in the l iterature, too many to list here X  X ood surveys are included in Dash and Liu [6]; Guyon and Elisseeff [1]; Liu and Motoda [7]. An impor-a number of important papers such as Blum and Langley [8]; Koh avi and John [9]. The argument that the problem of feature selection can be cast as the probl em of Markov blanket discovery was first made convincingly in Koller and Sahami [2], who also pre sented an algorithm for learning an approximate Markov blanket using mutual information. Othe r algorithms include the GS algorithm [10], originally developed for learning of the structure of a Bayesian network of a domain, and ex-tensions to it [11] including the recent MMMB algorithm [12] . Meinshausen and B  X  uhlmann [13] recently proposed an optimal theoretical solution to the pr oblem of learning the neighborhood of a Markov network when the distribution of the domain can be as sumed to be a multidimensional Gaussian i.e., linear relations among features with Gaussi an noise. This assumption implies that the Composition axiom holds in the domain (see Pearl [14] for a definition of Composition); the difference with our work is that we address here the problem i n general domains where it may not necessarily hold. In this section we present notation, fundamental definition s and axioms that will be subsequently used in the rest of the paper. We use the term  X  X eature X  and  X  X a riable X  interchangeably, and de-denote the set of all variables/features in the domain (the  X  universe X ) by U . All algorithms pre-sented are independence-based , learning the Markov boundary of a given target variable usi ng the truth value of a number of conditional independence stateme nts. The use of conditional indepen-conditional independence with some of its predictor variab les (conditional on the subset selected at any given moment). A benefit of using conditional independen ce is that, while classification error estimates depend on the classifier family used, conditional independence does not. In addition, al-domains, as long as a reliable estimate of probabilistic ind ependence is available. that the variables in set X are (jointly) conditionally independent from those in set Y given the values of the variables in set Z ; ( X 6 X  X  X  Y | Z ) denotes their conditional dependence. We assume the existence of a probabilistic independence query oracle that is available to answer any query of the form ( X , Y | Z ) , corresponding to the question  X  X s the set of variables in X independent of the variables in Y given the value of the variables in Z ? X  (This is similar to the approach of learning from statistical queries of Kearns and Vazirani [1 5].) In practice however, such an oracle of all of its members, the set of remaining variables in the do main, taken together as a single set-Definition 1. A set of variables S  X  X  is called a Markov blanket of variable X if and only if ( X  X  X  X U X  S  X  X  X }| S ) .
 Intuitively, a Markov blanket S of X captures all the information in the remaining domain variab les U X  S  X  X  X } that can affect the probability distribution of X , making their value redundant as far as
X is concerned (given S ). The blanket therefore captures the essence of the feature selection problem for target variable X : By completely  X  X hielding X  X , a Markov blanket precludes the exis-tence of any possible information about X that can come from variables not in the blanket, making it an ideal solution to the feature selection problem. A mini mal Markov blanket is called a Markov boundary.
 Definition 2. A set of variables S  X  X  X  X  X } is called a Markov boundary of variable X if it is a minimal Markov blanket of X i.e., none of its proper subsets is a Markov blanket.
 Pearl [14] proved that that the axioms of Symmetry, Decompos ition, Weak Union, and Intersection are sufficient to guarantee a unique Markov boundary. These a re shown below together with the axiom of Contraction. The Symmetry, Decomposition, Contraction and Weak Union ax ioms are very general: they are has a non-zero probability of occurring. According to Definition 2, a Markov boundary is a minimal Mark ov blanket. We first introduce a theorem that provides an alternative, equivalent definitio n of the concept of Markov boundary that we will relax later in the paper to produce a more general boun dary definition.
 Theorem 1 ( Markov Boundary Theorem ) . Assuming that the Decomposition and Contraction axioms hold, S  X  X  X  X  X } is a Markov boundary of variable X  X  X  if and only if A detailed proof cannot be included here due to space constra ints but a proof sketch appears in U X  X  X } into two parts: (a) set P 1 that contains all subsets of U X  S , and (b) set P 2 containing the remaining subsets. All sets in P conditionally dependent with X .
 of Markov blanket and its minimality i.e., the equation Algorithm 1 The abstract GS ( m ) ( X ) algorithm. Returns an m -Markov boundary of X . or, equivalently, (  X  T  X  X  X  S  X  X  X } , ( X  X  X  X  T | S )) (as T and S are disjoint) corresponds to the definition of Markov blanket, as it includes T = U X  S  X  X  X } . In the opposite direction, the contrapositive form is This corresponds to the concept of minimality of the Markov b oundary: It states that all sets that contain a part of S cannot be independent of X given the remainder of S . Informally, this is because if there existed some set T that contained a non-empty subset T  X  of S such that ( X  X  X  X  T | S  X  T ) , then one would be able to shrink S by T  X  (by the property of Contraction) and therefore S would not be minimal (more details in Appendix A). Theorem 1 defines conditions that precisely characterize a M arkov boundary and thus can be thought of as an alternative definition of a boundary. By relaxing the se conditions we can produce a more general definition. In particular, an m -Markov boundary is defined as follows.
 Definition 3. A set of variables S  X  X  X  X  X } of a domain U is called an m -Markov boundary of variable X  X  X  if and only if We call the parameter m of an m -Markov boundary the Markov boundary margin . Intuitively, an m -boundary S guarantees that (a) all subsets of its complement (excludin g X ) of size m or smaller are independent of X given S , and (b) all sets T of size m or smaller that are not subsets of its complement are dependent of X given the part of S that is not contained in T . This definition is a special case of the properties of a boundary stated in Theore m 1, with each set T mentioned in the theorem now restricted to having size m or smaller. For m = n  X  1 , where n = |U| , the condition | T | X  m is always satisfied and can be omitted; in this case the definit ion of an ( n  X  1) -Markov boundary results in exactly Eq. (2) of Theorem 1.
 an m -boundary of a target variable X . GS ( m ) operates in two phases, a growing and a shrinking phase (hence the acronym). During the growing phase it exami nes sets of variables of size up to m , where m is a user-specified parameter. During the shrinking phase, single variables are examined for conditional independence and possible removal from S (examining sets in the shrinking phase is not necessary for provably correct operation X  X ee Appendix B). T he orders of examination of the sets for possible addition and deletion from the candidate bound ary are left intentionally unspecified in Algorithm 1 X  X ne can therefore view it as an abstract represen tative of a family of algorithms, with each member specifying one such ordering. All members of thi s family are m -correct, as the proof of correctness does not depend on the ordering. In practice n umerous choices for the ordering exist; one possibility is to examine the sets in the growing phase in order of increasing set size and, for each such size, in order of decreasing conditional mutual in formation I ( X, Y , S ) between X and Y members of the Markov boundary. We used this implementation in all our experiments, presented later in Section 6.
 completeness: For m = n  X  1 = |U| X  1 , the algorithm returns a Markov boundary in unrestricted Algorithm 2 The RGS ( m,k ) ( X ) algorithm, a randomized anytime version of the GS ( m ) algorithm, utilizing k random subsets for the growing phase. parity function is m + 1 or less i.e., if k  X  m + 1 (parity functions are corner cases in the space Eqs. (1) only i.e., Intersection is not needed, and thus it is widely applicable (to any domain). A Practical Randomized Anytime Version therefore also we here provide a more practical randomized v ersion called RGS ( m,k ) (Randomized given a large enough k . Many possibilities for the method of random selection of th e subsets exist; in our experiments we select a subset Y = { Y to between X and Y may be limited and/or the limit unknown beforehand: it is eas y to show that the growing phase of for the shrinking phase to be executed (which conducts a numb er of tests linear in n and is thus fast), extraneous variables will be removed and a minimal bl anket (boundary) approximation will be returned. These features make it an anytime algorithm, which is a more appropriate choice for situations where critical events may occur that require the interruption of computation, e.g., during the planning phase of a robot, which may be interrupted at any time due to an urgent external event that requires a decision to be made based on the present state  X  X  feature values. 4 variables ( X and various degrees of noise. The remaining independent var iables ( X Figure 2: Left: F noise. Middle: Probabilistic isolation performance comparison between GS (3) and RELIEVED on real-world and benchmark data sets. Right: Same for GS (3) and RGS (3 , 1000) . tractors X  and had randomly assigned probabilities i.e., th e correct boundary of X number of distractors and because each X of
B 1  X  X  X i } (they only become dependent when including all of them in the conditioning set). To measure an algorithm X  X  feature selection performance, a c-curacy (fraction of variables correctly included or exclud ed) is inappropriate as the accuracy of trivial algorithms such as returning the empty set will tend to 1 as n increases. Preci-sion and recall are therefore more appropriate, with precis ion defined as the fraction of features returned that are in the co r-rect boundary (3 features for X of the features present in the correct boundary that are re-turned by the algorithm. A convenient and frequently used measure that combines precision and recall is the F sure, defined as the harmonic mean of precision and recall [18]. In Fig. 1 (top) we report 95% confidence intervals for the F subsets), using 20 data sets containing 10 to 100 variables, with the target variable X with 10% probability. As can be seen, the RGS ( m,k ) and with respect to F respect to execution time however RGS ( m,k ) exhibits much greater scalability (Fig. 1 bottom, log scale); for example , it executes in about 10 seconds on average in domains contain-average for this domain size.
 ables. As it has been reported [9] that RELIEF can exhibit lar ge variance due to randomization that is necessary only for very large data sets, we instead used a d eterministic variant called RELIEVED [9], whose behavior corresponds to RELIEF at the limit of infi nite execution time. We calculated the F with noise probability ranging from 0 (no noise) to 0.4. We us ed domains containing 50 variables, as formance of GS ( m ) and RGS ( m,k ) for m equal to 1 and 3, k = 1000 and RELIEVED for thresholds  X  = 0 . 01 and 0.03 for various amounts of noise on the target variable. Again, each experiment was repeated 20 times to generate 95% confidence intervals. We ca n observe that even though m = 1 (equivalent to the GS algorithm) performs poorly, increasi ng the margin m makes it more likely to recover the correct Markov boundary, and GS (3) ( m = 3 ) recovers the exact blanket even with few (1,000) data points. RELIEVED does comparably to GS (3) for little noise and for a large threshold, threshold for RELIEVED X  X etter performing  X  at low noise can become worse in noisy environ-ments; in particular, small  X  tend to include irrelevant variables while large  X  tend to miss actual members.
 the UCI Machine Learning repository. As the true Markov boun dary for these is impossible to know, we used as performance measure a measure of probabilistic isolation by the Markov boundary re-turned of subsets outside the boundary. For each domain vari able X , we measured the independence of subsets Y of size 1, 2 and 3 given the blanket S of X returned by GS (3) and RELIEVED for  X  = 0 . 03 (as this value seemed to do better in the previous set of exper iments), as measured by the average p-value of the  X  2 test between X and Y given S (with p-values of 0 and 1 indicating ideal dependence and independence, respectively). Due to t he large number of subsets outside the boundary when the boundary is small, we limited the estimati on of isolation performance to 2,000 (right plot). To obtain a statistically significant compari son, we used the non-parametric Wilcoxon other, while both outperformed RELIEVED at the 99.99% signi ficance level (  X  &lt; 10  X  7 ). distribution) domains that may contain complex interactio ns that only appear when the values of multiple features are considered together. We introduced t wo algorithms: an exact, provably cor-rect one as well a more practical randomized anytime version , and evaluated them on on artificial, benchmark and real-world data, demonstrating that they per form well, even in the presence of noise. We also introduced the Markov Boundary Theorem that precise ly characterizes the properties of a boundary, and used it to prove m -correctness of the exact family of algorithms presented. W e made minimal assumptions that consist of only a general set of axi oms that hold for every probability distribution, giving our algorithms universal applicabil ity.
 Proof sketch. ( =  X  direction) We need to prove that if S is a Markov boundary of X then (a) for every set T  X  X  X  S  X  X  X } , ( X  X  X  X  T | S  X  T ) , and (b) for every set T  X  6 X  X  X  S that does not Decomposition theorem. Case (b) can be proven by contradict ion: Assuming the independence of T pendence property of a Markov boundary, i.e., that ( X  X  X  X U X  ( S  X  T  X  contradicts the assumption that S is a boundary (and thus minimal). (  X  = direction) We need to prove that if Eq. (2) holds, then S is a minimal Markov blanket. The proof that S is a blanket is immediate. We can prove minimality by contrad iction: Assume S = S S which is a contradiction.
 Let the value of the set S at the end of the growing phase be S phase S Observation 1. For every Y  X  X  X  S Observation 2. For every Y  X  S Lemma 2. Consider variables Y Contraction holds, if ( X  X  X  X  Y Proof. By induction on Y down to S  X  X  Y desired relation ( X  X  X  X  Y | S  X  Y ) . the shrinking phase are actually jointly independent of X , given the final set S { Y 1 , Y 2 , . . . , Y t } i.e., S Corollary 3. Assuming that the Contraction axiom holds, ( X  X  X  X  S T  X  X  X  S G  X  X  X } such that ( X  X  X  X  T | S G ) , Furthermore S Proof. From Corollary 3, ( X  X  X  X  S S ( X  X  X  X  T  X  S  X  | S S ) .
 To prove minimality, let us assume that S by contradiction: Assume that there exists a set S  X   X  S W = S S  X  S  X  6 =  X  . Note that W and S  X  are disjoint. We have that However, at the end of the shrinking phase, all variables Y in S have been evaluated for independence and found dependent (O bservation 2). Thus, since W 6 =  X  , there exists at least one Y such that ( X 6 X  X  X  Y | S Theorem 5. Assuming that the Contraction, Decomposition, and Weak Uni on axioms hold, Algo-rithm 1 is m -correct with respect to X .
 Proof. We use the Markov Boundary Theorem. We first prove that or, equivalently,  X  T  X  X  X  S Since U X  S kinds of sets of size m or less to consider: (i) all sets T  X  S and (iii) all sets (if any) T = T  X   X  T  X  X  , T  X   X  T  X  X  =  X  , that have a non-empty part T  X   X  S non-empty part T  X  X   X  X  X  S To complete the proof we need to prove that Let T = T variable Y  X  S Weak Union, we get ( X 6 X  X  X { Y } X  ( T From (the contrapositive of) Decomposition we get ( X 6 X  X  X  T S disjoint. [2] Daphne Koller and Mehran Sahami. Toward optimal feature selection. In Proceedings of the [3] P. M. Narendra and K. Fukunaga. A branch and bound algorit hm for feature subset selection. [4] H. Almuallim and T. G. Dietterich. Learning with many irr elevant features. In Proceedings of [5] K. Kira and L. A. Rendell. The feature selection problem: Traditional methods and a new [7] Huan Liu and Hiroshi Motoda, editors. Feature Extraction, Construction and Selection: A [8] Avrim Blum and Pat Langley. Selection of relevant featur es and examples in machine learning. [9] R. Kohavi and G. H. John. Wrappers for feature subset selec tion. Artificial Intelligence , 97 [10] Dimitris Margaritis and Sebastian Thrun. Bayesian net work induction via local neighborhoods. [12] I. Tsamardinos, C. Aliferis, and A. Statnikov. Time and sample efficient discovery of Markov [13] N. Meinshausen and P. B  X  uhlmann. High-dimensional graphs and variable selection w ith the [14] Judea Pearl. Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference . [15] Michael Kearns and Umesh V. Vazirani. An Introduction to Computational Learning Theory . [16] A. Agresti. Categorical Data Analysis . John Wiley and Sons, 1990. [18] C. J. van Rijsbergen. Information Retrieval . Butterworth-Heinemann, London, 1979.
