 1. Introduction
Wireless sensor networks (WSNs) are currently emerging as one of the most disruptive technologies enabling and supporting next generation ubiquitous and pervasive computing scenarios ( Sohraby et al., 2007 ). WSNs are capable of supporting a broad array of high-impact applications in several domains such as disaster/crime prevention, military, environment, logistics, health care, and building/home automation. WSNs applied to the human body are usually called Wireless Body Sensor Networks (WBSNs) ( Yang, 2006 ). WBSNs are conveying notable attention as their real-world applications aim at improving the quality of life of human beings by enabling continuous, real-time and non-invasive medical assistance at low cost. Health-care applications in which WBSNs could be greatly useful include early detection or prevention of diseases, elderly assistance at home, e-fitness, rehabilitation after surgeries, motion and gestures detection, cognitive and emotional recognition, medical assistance in disaster events, etc. are complex tasks. This is mainly due to the challenge of imple-menting signal processing intensi ve algorithms for data interpreta-tion on wireless nodes that are very resource constrained and have to meet hard requirements in terms of wearability and battery duration as well as computational and storage resources. This is challenging because WBSN applications usually require high sensor data sampling rates which affects real-time data processing and transmission capabilities since computational power and available bandwidth of the WBSN infrastructu re are generally scarce. Indeed, efficient implementation of WBSN applications requires appropriate allocation of the limited resources on the nodes in terms of energy, memory and processing. This is especially critical in signal proces-sing systems, which usually have large amounts of data to process and transmit. Current embedded ope rating systems do not address such high level and complex requirements as they mainly focus on hardware abstraction, power man agement, routing, security and synchronization algorithms, and sometimes on general-purpose data structures, dynamic memory management, and multi-tasking.
To deal with the aforementioned issues, several software frameworks have been developed such as CodeBlue ( Malan et al., 2004 ), Titan ( Lombriser et al., 2009 ), and SPINE ( Fortino et al., 2009 ). They aim at decreasing development time and improving interoperability among signal processing intensive applications based on WBSNs. In particular, they basically rely on a star-based network architecture, which is organized into a coordinator node and a set of sensor nodes. Moreover, they are developed in TinyOS at the sensor node side and in Java at the coordinator node side.
However, apart from the adoption of effective frameworks, we believe that the exploitation of the agent-oriented programming paradigm to develop WBSN applications could provide more effectiveness as demonstrated by the application of agent tech-nology in several key application domains ( Luck et al., 2004 ).
In this paper, we therefore propose an agent-oriented approach to develop WBSN applications based on the MAPS (Mobile Agent
Platform for Sun SPOTs) framework ( Aiello et al., 2008 , 2011 )that enables agent-oriented programming by offering powerful abstrac-tions allowing rapid prototyping of WSN applications on the Sun
SPOT sensor platform. The proposed approach is exemplified through the design, implementation and evaluation of an agent-based real-time human activity monitoring system. In particular, the system architecture is a typical star-based WBSN composed of a coordinator node and two sensor nodes which are located on the waist and thigh of the monitored assisted living, respectively. The coordinator relies on a Jade (2011) -based enhancement of the SPINE coordinator ( Fortino et al., 2009 ; Signal Processing In-node
Environment, 2011 ) and allows configuring the sensing process, receiving sensed data features, and recognizing pre-defined human activities through a KNN (K-nearest neighbor) classifier. Each sensor node executes a MAPS-based agent that performs sensing of the 3-axial accelerometer sensor, computation of significant features on the acquired data, features aggregation and transmis-sion to the coordinator. Finally, the experimentation phase of the developed prototype allows evaluating the obtainable monitoring performances and activity recognition accuracy.

The main research contribution of this paper is twofold. On one hand, it proposes the design, implementation and evaluation of a novel agent-oriented system based on WBSNs for real-time monitoring of human activities by means of MAPS atop the Sun
SPOT sensor platform. On the other hand, it provides an analysis of the effectiveness and efficiency of the application of agent frameworks, namely MAPS and AFME the only two frameworks available for Sun SPOTs so far, within the WBSN application domain; such analysis is carried out also with respect to the
SPINE framework ( Bellifemine et al., 2011 ), an open-source domain-specific framework for WBSN applications. Obtained results show that MAPS can be more effective (from the program-ming point of view) and efficient (from the system perspective) than AFME and SPINE in developing WBSN applications.

The rest of this paper is organized as follows. Section 2 first discusses related work for the development of WBSN applications, ranging from monolithic applications to domain-specific frame-works, and then introduces a reference architecture for WBSN applications from network and functional perspectives. In Section 3 the available agent platforms for WSNs (Agilla, ActorNet and
AFME) are described and compared with MAPS. Section 4 describes the architecture and programming model of MAPS that is used to design and implement an agent-oriented signal processing in-node environment for real-time human activity monitoring that is presented in Section 5 along with the analysis of programming effectiveness and system performances of MAPS, AFME and SPINE. Finally conclusions are drawn and on-going research discussed. 2. WBSN application development
Programming WBSN applications is a complex task mainly due to the hard resource constraints of wearable devices and to the lack of proper and easy to use software abstractions. In this section we overview the available approaches for the develop-ment of applications based on WBSNs and describe a reference architecture for WBSNs that enables rapid prototyping of efficient signal processing in-node applications. 2.1. Programming frameworks
Most of previous research on WBSN applications has focused on proof-of-concept applications with the aim of demonstrating the feasibility of new context-aware algorithms and techniques, e.g. for the recognition of physical activity through accelerometer sensors or prompt detection of hearth diseases ( Najafi et al., 2003 ; Bao and Intille, 2004 ; Yang, 2006 ). Moreover such research has considered issues related to power consumption and radio channel usage but has scarcely taken into account code reusability and modularity. One of the most relevant attempts to define a general platform able to support various WBSN applications is CodeBlue ( Malan et al., 2004 ). CodeBlue is a framework based on TinyOS (2011) and specifically designed for integrating wireless medical sensor nodes and other devices that could be involved in a disaster response scenario. CodeBlue allows such devices to discover each other, report events, and establish communications. It relies on a publish/ subscribe-based data routing framework in which sensors publish relevant data to a specific channel and end-user devices subscribe to channels of interest. CodeBlue provides end-user devices with a query interface to retrieve data from previously discovered sensor nodes. While it is possible to select sensor types or physical node identifiers as data sources, configure the data rate and define in-node threshold-based filters to avoid unnecessary data to be transmitted, more sophisticated in-node processing of the sensor data is not supported. A different approach is proposed by Titan ( Lombriser et al., 2009 ), which is also implemented in TinyOS. Titan is a middleware for distributed signal processing in WSNs that supports implementation and execution of context recognition algorithms in dynamic WSN environments. Titan represents data processing by a data flow from sensors to recognition results. The data is processed by tasks which implement elementary computa-tions. Tasks and their data flow interconnections define a task network, which runs on the sensor network as a whole. Tasks are mapped onto each sensor node according to the sensors and the processing resources it provides. Titan dynamically reprograms the WSN to exchange context recognition algorithms and handle defective nodes, variations in available processing power, or broken communication links. The architecture of Titan is composed of several software components, which enhance modularity. Although CodeBlue and Titan raise the programming abstraction level by offering general-purpose platforms and middlewares for effectively developing signal processing applications in WBSNs, they are sometimes too general for providing efficient solutions in specific application domains. Thus, domain-specific frameworks ( Bao and Intille, 2004 ; Bellifemine et al., 2011 )havebeenproposed which are positioned in the middle between application-specific code and middleware approaches. They specifically address and standardize the core challenges of WSN design within a particular application domain. While providing high efficiency, such frameworks allow for a more effective development of customized applications with little or no additional hardware configuration and with the provision of high-level programming abstractions tailored for the reference application domain. A notable example of such approach is represented by the SPINE framework ( Fortino et al., 2009 ; Bellifemine et al., 2011 ; Signal Processing In-node Environment, 2011 ). SPINE provides libraries of protocols, utilities and processing functions, and a lightweight Java API that can be used by local and remote applications to manage the sensor nodes or submit service requests. By providing these abstractions and libraries, which are common to most signal processing algorithms used in WBSNs for sensor data analysis and classification, SPINE also provides flexibility in the allocation of tasks among the WBSN nodes and allows the exploitation of implementation tradeoffs. Currently SPINE is implemented for several sensor platforms based on TinyOS (2011) and Z-stack (2011) by using the programming paradigms offered by such platforms (event and component-based programming in TinyOS and C programming in Z-Stack) and is being effectively applied to the development of applications in the health care domain ( Iyengar et al., 2008 ). In this paper we propose an agent-oriented approach which borrows the basic features characterizing the domain specific framework approach, particularly SPINE, with the aim of providing more programming effectiveness as demonstrated by the application of agent technology in several key application domains ( Luck et al., 2004 ). 2.2. A reference system for in-node signal processing
The network architecture of the reference WBSN system for signal processing, which is derived from the SPINE system ( Fortino et al., 2009 ; Signal Processing In-node Environment, 2011 ; Bellifemine et al., 2011 ), is organized into multiple sensor nodes and one coordinator node (see Fig. 1 ). The coordinator manages the network, collects, stores and analyzes the data received from the sensor nodes, and also can act as a gateway to connect the WBSN with wide area networks (e.g. Internet) for remote data access. Sensor nodes measure local physical para-meters and send raw or pre-processed data to the coordinator. In this system, sensor nodes only communicate with the coordinator according to the star network topology, which is the most used topology in WBSN ( Yang, 2006 ). However, the system could be easily extended to support also direct and multi-hop communica-tions among sensor nodes. In the reference architecture a sensor node is associated with a single coordinator; a possible extension is to allow sensor nodes to be associated and communicate with multiple coordinators. A scenario where such architecture could be used is when a human wearing sensor nodes moves across locations; in this case such sensors should connect to a different coordinator at each different location. The software architecture of the system consists of two main components, implemented, respectively, on the coordinator (e.g. a PC or a PDA/smartphone) and on the WBSN sensor nodes. Fig. 2 shows a schema of the architecture from a functional point of view.
 placed between user applications and the hardware and software host platform is made available. User applications manage the
WBSN through a system API. The top level of the software architecture at the coordinator side allows registered applications to be notified of the following events generated by the WBSN: discovery of new nodes, sensor data communication, node alarms, and system messages such as low battery warnings. Commands issued by the user application and network-generated events are both coded in lower-level messages and decoded in higher-level information by the Host Communication Manager according to a specific over-the-air protocol. This component handles packets generation and retrieval and is interfaced with specific software components of the host platform to access the physical radio module for transmitting/receiving packets to/from the WBSN. At the sensor node side, the software framework provides abstrac-tions of hardware resources such as sensors and the radio, a default set of ready-to-use common signal processing functions and, most importantly, a flexible and modular architecture to be customized and extended to support new physical platforms and sensors and introduce new signal processing services. In particu-lar, the Node Communication Manager acts as the counterpart of the Host Communication Manager. The Sensor Controller man-ages and abstracts the sensors on the node platform, providing a standard interface to the diverse sensor drivers. It is responsible of sampling the sensors and storing the sensed data in properly defined Buffers. The Node Manager is the central component, responsible for interpreting the remote requests and dispatching them to the proper components. Finally, the Processing Manager consists of a dispatcher for the actual processing services and a standard interface for user-defined services integration. 3. Agent-based platforms for wireless sensor networks provide an API for developing agent-based applications, and an agent server able to execute agents by providing them with basic services such as communication, migration and node resource access. Although many APs exist for conventional distributed systems ( Luck et al., 2004 ), developing flexible and efficient APs for WSNs is a challenging and very complex task due to the currently available resource-constrained sensor nodes and related operating systems ( Vinyals et al., 2011 ). Very few APs for WSNs have been to date proposed and actually implemented. In the following, we first introduce Agilla and ActorNet, the most significant available research prototypes based on TinyOS, and then describe in more details Agent Factory Micro Edition (AFME), which runs on Java Sun SPOTs, as AFME is the only available Java-based agent platform related to MAPS. Finally we provide a 3.1. TinyOS-based agent platforms
Agilla ( Fok et al., 2005 ) is an agent-based middleware devel-oped on TinyOS ( Gay et al., 2003 ) and supporting multiple agents on each node. As shown by its software architecture (see Fig. 3 ),
Agilla provides two fundamental resources on each node: a tuple-space and a neighbors list. The tuplespace represents a shared memory space where structured data (tuples) can be stored and retrieved, allowing agents to exchange information in a temporally decoupled way. A tuplespace can be also accessed remotely. The neighbors list contains the address of all one-hop-distant nodes, needed when an agent has to migrate. Agents can migrate carrying their code and state, but do not carry their tuples that are locally stored on a tuplespace. Packets used for communication between nodes (e.g. for agent migration/cloning, remote tuples accessing) are very small to minimize message losses, whereas retransmission techniques are also adopted. Although Agilla is developed for
TinyOS platforms, agents are not programmed through nesC but a proprietary ISA (Instruction Set Architecture) was specifically defined for their programming.

ActorNet ( Kwon et al., 2006 ) is an agent-based platform specifically designed for TinyOS/Mica2 sensor nodes. To overcome the difficulties in allowing code migration and interoperability due to the strict coupling between applications and sensor node architectures, ActorNet exposes services like virtual memory, context switching, and multi-tasking. Thanks to these features, it effectively supports agents programming by providing a uni-form computing environment for all agents, regardless of hard-ware or operating system differences. The ActorNet architecture is depicted in Fig. 4 . The ActorNet language used for high-level agent programming, has syntax and semantics similar to those of Scheme ( Kent Dybvig, 1987 ) with proper instruction extension. 3.2. Agent Factory Micro Edition
AFME ( Muldoon et al., 2006 , 2008 ; Agent Factory, 2011 )isan open-source, lightweight, and J2ME Mobile Information Device Profile (MIDP) compliant agent platform based upon the Agent Factory Framework (2011) and intended for wireless pervasive systems. Thus, AFME has not been specifically designed for sensor networks but, thanks to a recent support of J2ME onto the Sun SPOT sensor platform, it can be adopted for developing agent-based WSN applications. AFME is based on the Believe-Desire-Intention (BDI) paradigm ( Rao and Georgeff, 1995 ), in which agents follow a sense-deliberate-act cycle. To facilitate the crea-tion of BDI agents the framework supports a number of system components that developers have to extend when building their applications: perceptors, actuators, modules, and services. Per-ceptors and actuators enable agents to sense and act upon their environment respectively. Modules represent a shared informa-tion space between actuators and perceptors of the same agent, and are used, for example, when a perceptor may perceive the resultant effect of an actuator affecting the state of an object instance internal to the agent. Services are shared information space between agents used for agent data exchange. The agents are periodically executed using a scheduler, and four functions are performed when an agent is executed. First, the perceptors are fired and their sensing operations generate beliefs, which are added to the agent X  X  belief set. A belief is a symbolic representa-tion of information related to the agent X  X  state or to the environ-ment. Second, the agent X  X  desires are identified using resolution-based reasoning, a goal-based querying mechanism commonly employed within Prolog interpreters. Third, the agent X  X  commit-ments (a subset of desires) are identified using a knapsack procedure. Fourth, depending on the nature of the commitments adopted, various actuators are fired. In AFME, agents are defined through a mixed declarative/imperative programming model. The declarative Agent Factory Agent Programming Language (AFAPL), based on a logical formalism of belief and commitment, is used to encode an agent X  X  behavior by specifying rules defining the conditions under which commitments are adopted. The impera-tive Java code is instead used to encode perceptors and actuators. A declarative rule is expressed through the following form: b 1, b 2, bn 4 doX ; where b 1 , b 2 , ... , bn represent beliefs, whereas doX is an action. The rule is evaluated during the agent execution, and if all the specified beliefs are currently included into the agent X  X  belief set, the imperative code enclosed into the actuator associated to the symbolic string doX is executed.

The AFME platform architecture is shown in Fig. 5 . It comprises a scheduler, a group of agents, and several platform services needed for supporting agent communication and migration.
To improve reuse and modularity within AFME, actuators, perceptors, and services are prevented from containing direct object references to each other. Actuators and perceptors devel-oped for interacting with a platform service in one application can be used, without any changes to their imperative code, to interact with a different service in a different application. In the other way round, the implementation of platform services can be completely modified without having to modify actuators and perceptors. Additionally, the same platform service may be used within two different applications to interact with a different set of actuators and perceptors. So, all system components of the AFME platform are interchangeable because they interact without directly refer-encing one another. 3.3. A comparison
In Table 1 , a comparison among the aforementioned agent platforms with respect to seven characteristics (migration, multi-tasking, communication model, programming language, agent model, intentional agents, sensor platforms) is reported. Agent migration and multitasking, which allows for the execution of multiple agents on the same node, is supported by all the systems. The agent communication model of Agilla is centered on local tuple space where agent can asynchronously insert tuples and take tuples left by other agents. Conversely the communica-tion model of the other systems is based on (unicast and broad-cast) message passing. The programming language and model is different among the systems. Agilla is based on a proprietary low-level language composed of an assembler-like instruction set which makes programming of complex agents very difficult. ActorNet is based on a functional Scheme-like language whereas MAPS and AFME on the Java language. Indeed, MAPS uses a finite state machine model to define agent behaviour whereas AFME employs a more complex BDI-like model based on the AFAPL language. Intentional agents are therefore only offered by AFME. Agilla and ActorNet run on motes; in particular Agilla on Mica2, MicaZ, and TelosB, whereas ActorNet currently only on Mica2. On the contrary, MAPS and AFME are based on Sun SPOTs.

All the four compared systems are effective solutions for agent-oriented programming of WSNs even though they are based on (very) different programming abstractions and archi-tectures. However, being MAPS and AFME specifically conceived for Sun SPOT sensor technology, which is more capable than the sensor mote technology on which Agilla and ActorNet are based (see the last row of Table 1), they are less limited in terms of resources so more capable agents can be defined. Moreover, as MAPS offers FSM-based agents, such programming paradigm is very appealing for programmers and designers of embedded systems who usually exploit programming tools based on FSMs or their derivatives. 4. MAPS: a Java-based agent platform for sun spots networks based on Sun SPOT technology ( Aiello et al., 2008 , 2011 ; Mobile agent, 2011 ) which enables agent-oriented programming of
WSN applications. MAPS has been appositely defined for resource-constrained sensor nodes accordin g to the following requirements: ture and the agent programming model. 4.1. System architecture following basic components: parts: an object formalizing the agent behavior based on a multi-plane state machine (see Section 4.2) embedded into an archi-tectural component directly connected to the MAEE (see below).
The mobile agent execution engine (MAEE) supports the execu-tion of agents by means of an event-based scheduler enabling lightweight concurrency. It handles each event emitted by or to be delivered at an MA through decoupling event queues.
The MAEE interacts with the other core components (see below) to fulfill service requests issued by MAs.

The mobile agent migration manager (MAMM) supports the migration of agents from one sensor node to another. In particular, the MAMM is based on the feature of Isolate (de)hi-bernation provided by the Sun SPOT (2011) environment and is thereforeabletostopandhibernateanMA,serializeitintoabyte array and transmit it to the targe t sensor node. On the migration target sensor node, the MAMM can receive a message containing a serialized MA, deserialize, dehibernate and resume it. The agent serialization format includes data and execution state whereas the code should already reside at the destination node (this is a current limitation of the Sun SPOTs which do not support dynamic class loading and code migration).

The mobile agent communication channel (MACC) enables inter-agent communication based on asynchronous messages supported by the Radiogram protocol. Messages can be unicast or broadcast.

The mobile agent naming (MAN) provides agent naming based on proxies to support the MAMM and MACC components in their operations. The MAN also manages the (dynamic) list of the neighbor sensor nodes which is updated through a bea-coning mechanism based on broadcast messages.

The timer manager (TM) provides the timer service which allows for the management of timers to be used for timing MA operations.

The resource manager (RM) provides access to the resources of the Sun SPOT node: sensors (3-axial accelerometer, tempera-ture, light), switches, leads, battery, and flash memory.
Indeed, the core components for agent migration and resource access can be plugged and unplugged to allow for optimization of computing and memory resources according to specific applica-tions needs. As an example, when agent mobility is not a require-ment of the application, the MAMM component can be unplugged so saving memory space in central memory and on the flash.
To allow for different application needs and resource require-ments, three different versions of the MAEE are available (see
Fig. 7 ) which support three different implementations of the agent architectural component. In particular, such component can be: (a) a single-threaded Isolate according to the Java Sun SPOT libraries, (b) a Java thread, or (c) a Java object. Such three solutions can be used according to specific application contexts. The first solution is the only one supporting mobility as agent migration is only supported in terms of Isolate migration. The second and third solutions are exploited when migration is not necessary and more execution efficiency is required. In particular, in the first solution, agents are connected to the MAEE through a mediator component called inter-isolate server which introduces internal communication overhead as agents are in their own Isolate; in the second and third solutions, agents are in the same isolate of the MAEE so communication between agents and MAEE is based on direct object references. The last solution is the most lightweight in terms of memory requirements as an agent is only formed by a non-thread-based composite object. 4.2. Agent programming model The main programming abstractions of MAPS are Agents and Events (see Fig. 8 ).

Agents are active entities, uniquely identified by an identifier, whose behavior is modeled as a multi-plane state machine (MPSM) ( B  X  ol  X  oni and Marinescu, 2000 ). The MPSM consists of a set of planes, global variables and global functions. Each plane may represent the behavior of the MA in a specific role so also enabling role-based programming. In particular a plane is com-posed of local variables, local functions, and an Event-Condition-Action (ECA) ruled automaton that represents the dynamic behavior of the MA in that plane. The automaton is composed of states and mutually exclusive transitions among states. Transi-tions are labeled by ECA rules: E [ C ]/ A , where E is the event name, [ C ] is a boolean expression based on the global and local variables, and A is the atomic action. A transition t is triggered if t originates from the current state (i.e. the state in which the ECA automaton is), the event with the event name E occurs and [ C ] holds. If the transition fires, A is executed and the state transition finally takes place. In particular, the atomic action can contain global/local variable and functions to carry out computation, and, particularly, the core primitives (see Fig. 9 ) to request specific services. As agents interact through events, the delivery of an event at agents is asynchronous and carried out by the event dispatcher (a component of the MAEE, see Fig. 7 ) which inserts the event in the agent queue. Once the ECA automaton is idle (i.e. the handling of the last delivered event is completed), a new event is fetched out from the queue and handled by one or more planes. It is worth noting that the MPSM-based agent behavior program-ming allows exploiting the benefits deriving from three main paradigms for WSN programming ( Yoneki and Bacon, 2005 ): event-driven programming, state-based programming and mobile agent-based programming.
 components and agents. In particular, Agents emit Events through the primitives reported in Fig. 9 for requesting the following services: (i) message transmission through the send primitive; (ii) agent creation, cloning and migration through the primitives the setTimer and resetTimer primitives; (iv) sensor resource handling through the primitives sense for sensing, actuate for led manipulation, flash for load/save data from/to the flash memory, input for reading switches. Emitted events are handled by the associated components which, after handling them, reply with Events that drive the agent behavior. Agents can also emit internal Events to proactively drive their behaviors; this is the basic mechanism to program goal-directed behaviors of event-driven agents as described in Fortino et al. (2010) . 5. An agent-based real-time system for monitoring human activity
In this section we present an agent-oriented signal processing in-node environment specialized for real-time human activity monitoring based on WBSNs. In particular, it is able to recognize postures (e.g. lying down, sitting and standing still) and move-ments (e.g. walking) of assisted livings. The system is designed and implemented with MAPS at the sensor node side and through
Java and JADE at the coordinator side. In Sections 5.1 and 5.2, system design, implementation and evaluation are detailed. Moreover, as the sensor-side system is also implemented with AFME and SPINE, a performance comparison between the MAPS-,
AFME-, and SPINE-based versions is described. Finally, in Section 5.3, a discussion of the programming effectiveness of MAPS for the development of WBSN applications is provided. 5.1. Design and implementation
The architecture of the system, shown in Fig. 10 , is organized into a coordinator and two sensor nodes according to the reference WBSN system described in Section 2.2.

The coordinator side (see Fig. 10 ) is based on a JADE agent that incorporates two modules of the Java-based SPINE coordinator ( Fortino et al., 2009 ), developed in the context of the SPINE project ( Signal Processing In-node Environment, 2011 ), which are the SPINE Manager and the SPINE Listener. In particular, the SPINE Manager is used by end-user applications (e.g. real-time activity monitoring application) for sending commands to the sensor nodes. Moreover, the SPINE Manager is responsible of capturing low-level messages and events sent from the nodes through the SPINE Listener, which integrates several sensor plat-form-specific SPINE communication modules (e.g. TinyOS, Z-Stack, etc), to notify registered applications with higher-level events and message content. A SPINE communication module is composed of a send/receive interface and some components that implement such interface according to the specific sensor plat-form and that formalize the high-level SPINE messages in sensor platform-specific messages. In this work, the SPINE Listener has been enhanced with a new MAPS/Sun SPOT communication module to configure and communicate with MAPS-based sensor nodes. Such module translates high-level SPINE messages for-matted according to the SPINE OTA (Over-The-Air) protocol ( Signal Processing In-node Environment, 2011 ) into lower-level MAPS/Sun SPOT messages through its transmitter component and vice versa through its receiver component. The JADE agent coordinator also integrates an application-specific logic for the synchronization of the two sensors (see below and Section 5.2). The SPINE-based real-time activity monitoring application was thus completely reused as well as the SPINE Manager, only the SPINE Listener was modified to account for such enhancement. The sensor node side (see Fig. 10 ) is based on two Java Sun SPOTs sensors respectively positioned on the waist and the thigh of the monitored person. In particular, MAPS is resident on the sensor nodes and supports the execution of the WaistSensorAgent and the ThighSensorAgent. Moreover, as the mobility feature of agents is not needed and in order to have higher execution performances, the thread-based version of the MAEE (see Section 4.1) is used. WaistSensorAgent and the ThighSensorAgent have the following similar step-wise cyclic behavior: 1. Sensing the 3-axial accelerometer sensor according to a given sampling time ( ST ). 2. Computation of specific features on the acquired raw data according to the window ( W ) and shift ( S ) parameters. In particular, W is the sample size on which features are com-puted whereas S is the percentage of sliding on W (usually S is set to 50%). 3. Features aggregation and transmission to the coordinator. 4. Goto 1.

The agents differ in the specific computed features even though the W and S parameters are equally set. In particular, while the WaistSensorAgent computes the mean values for the accelerometer data sensed on the XYZ axes, the min and max values for data sensed on the X axis, the ThighSensorAgent calculates the min value for data sensed on the X axis.
The interaction diagram depicted in Fig. 11 shows the inter-action among the three agents constituting the real-time system: CoordinatorAgent, WaistSensorAgent and ThighSensorAgent. In particular, the CoordinatorAgent first sends one AGN_START event for each sensor agent to configure them with the sensing parameters ( W , S and ST ); then, it broadcasts the START event to start the sensing activity of the sensor agents. Sensor agents sends the DATA event to the CoordinatorAgent as soon as features are computed. If the CoordinatorAgent detects that the agents are not synchronized anymore, it sends the RESYNCH event to resynchronize them.

The behavior of the WaistSensorAgent is specified through 1-plane reported in Fig. 12 (the behavior of the ThighSensorAgent has the same structure but the computed features are different as driven by the occurrence of the AGN_START event, the sensing plane goes into the WAIT4SENSING state. The MSG.START event allows starting the sensing process by the execution of action A1, which in particular performs the following steps: 1. sensing parameters ( W , S , ST ), data acquisition buffers for XYZ channels of the accelerometer sensor (windowX, windowY, windowZ), and data buffers for feature calculation (window-
FE4X, windowFE4Y, windowFE4Z) are initialized (see initSen-singParamsAndBuffers function); 2. the timer is set for timing the data acquisition according to the
ST parameter (see timerSetForSensing function and in particular the highly precise Sun SPOT timer is used); 3. a data acquisition is requested by submitting the ACC_CUR-
RENT_ALL_AXES event through the sense primitive (see doSen-sing function).
 Once the data sample is acquired, the ACC_CURRENT_AL-L_AXES event is sent back with the acquired data and the action A2 is executed; in particular: 1. the buffers are circularly filled with the proper values (see bufferFilling function); 2. the sampleCounter is incremented and the nextSampleIndex is incremented module W for the next data acquisition; 3. if S samples have been acquired, features are to be calculated, thus sampleCounter is reset, samples in the buffers are copied into the buffers for computing features, calculation of the features is carried out through the meanMaxMin function, and the aggregated results are sent to the base station by means of the MSG_TO_BASESTATION event appropriately constructed; 4. the timer is reset; 5. data acquisition is finally requested.
 In the ACC_SENSED&amp;FEAT_COMPUTED state the MSG.RE-SYNCH might be received for resynchronization purposes (see Section 5.2); it brings the sensing plane into the WAIT4SENSING state. The MSG.RESTART brings the sensing plane back into the
ACC_SENSED&amp;FEAT_COMPUTED state for (reconfiguring and) con-tinuing the sensing process. The MSG.STOP eventually terminates the sensing process.
 5.2. System analysis
The analysis of the developed prototype involves the following two aspects (which are respectively detailed in the next two subsections):
The performance evaluation of the timing granularity degree of the sensing activity at the sensor node and the synchroniza-tion degree or skew of the activities of the two sensor agents.
The recognition accuracy which shows how well the human postures/movements are recognized by the system. 5.2.1. Performance evaluation
Two important issues to deal with are the timing of the sensing process in terms of admissible sampling rate and the synchronization between the operations of the two agents which is to be maintained within a maximum skew for not affecting the real-time monitoring. If such skew is overtaken, the two agents are to be re-synchronized. Indeed such two aspects are strictly correlated. In particular, as the sensor agents compute a different number of features, when the sampling rate is high, the agent computing more features (i.e. the WaistSensorAgent) takes more time to complete its operations for each S sample acquisition than the ThighSensorAgent. Re-synchronization is driven by the syn-chronization logic included in the developed MAPS/Sun SPOT comm module, which sends a resynchronization message (see the
MSG.RESYNCH event in Fig. 12 ) as soon as it detects that the synchronization skew is greater than a given threshold. Detection is based on the skew time between the receptions of two messages sent by the agents that contain features referring to the same interval of S sample acquisition: if skew 4  X  P n then synchronize, where P is a percentage, S  X  0.5 W, and ST is the sampling time. Thus, the evaluation aimed at analyzing the synchronization of the sensor agents and their monitoring con-tinuity. The defined measurements are:
The Packet Pair Average Time (PPAT), which is the average reception time between two consecutive pairs of synchronized packets (same logical timestamp, see timestamp variable in Fig. 12 ) containing the computed features (see the MSG_TO_-
BASESTATION event in Fig. 12 ) sent by the sensor agents. PPAT should be ideally equals to ST n S , i.e. the packet pair arrives each monitoring period and so there is no de-synchronization in the average.

The Synchronization Packet Percentage (SPP), which is the percentage of resynchronization packets (see RESYNCH event in Fig. 12 ), which are sent by the coordinator for re-synchro-nizing the sensor agents, calculated with respect to the total number of received feature packets. SPP should be as much as possible close to 0, i.e. a few or no resynchronizations are carried out and so the monitoring can be continuous as a resynch operation usually takes 600 ms.

In particular, the experiments were carried out by fixing ST (ms)  X  [25, 50, 100], W (samples)  X  [100, 80, 40, 20, 10], and P (%)  X  [5, 10, 25]. Each experiment took 15 min and 50 tests per experiment were carried out. The obtained values were averaged over the 50 tests performed (also the standard deviation is reported). The values of ST and W were chosen to evaluate the system under different operating conditions: from high ( ST  X  25 ms, W  X  10, S  X  50 % 4 response time  X  125 ms) to slow ( ST  X  100 ms, W  X  100, S  X  50 % 4 response time  X  5 s) system response times. The system response time can directly affect th e accuracy of the human activity recognition (see Section 5.5.2) as higher is the frequency of refreshing the human activity status, quicker is the capability of the system to capture human activity changes. Moreover the variation range of P % accommodates for small to medium skews.

Fig. 13 shows the obtained results for P  X  25and5%byvarying ST and W in the ranges defined above. As can be noticed, the system cannot support an ST  X  25 ms because PPAT is always greater than the ideal value and SPP is too high. This leads to a non continuous monitoring due to very frequent resynchronizations  X  SPP Z ST  X  50 ms can be supported for P  X  25% and W Z 40 as SPP is maximum 8% so slightly impacting the monitoring continuity. The best results are obtained with ST  X  100 ms, P  X  25% and W guarantee monitoring continuity due to an SPP 0 % and regularity as experimented PPAT ideal PPAT for W Z 20. If P  X  5% and W  X  [10, 20] or P  X  25% and W  X  10, an ST  X  100msisnotagood value either because an out-of-limits skew frequently occurs.
It is worth noting that even though a lower ST would allow a more frequent monitoring, the considered human activities can be well captured by an ST  X  100 ms and W  X  20 (which implies a response time  X  1 s) as demonstrated by the experimental results obtained from the carried-out real-time human activity monitor-ing (see Section 5.2.2).

To compare the efficiency of MAPS, AFME and SPINE, the node-side implementation of the system was also carried out with AFME whereas the implementation with SPINE was already documented in Bellifemine et al. (2011) . The experiments were carried out by fixing ST (ms)  X  [25, 50, 100], W (samples)  X  [40, 20], and P (%)  X  [5, 25]. Each experiment took 15 min and 50 tests per experiment were carried out. Figs. 14 and 15 show the obtained results, which are the average values of the 50 tests (also the standard deviation is reported). As can be noticed, all the systems cannot support an ST  X  25 ms because PPAT is always greater than the ideal value and SPP is too high. This leads to a non continuous monitoring due to the very frequent resynchronization (SPP Z 20 for W  X  20 and S  X  10). The best results are obtained with ST  X  100 ms, P  X  25% and W  X  20; they guarantee monitoring continuity due to an SPP 0 % and regularity as experimented PPAT ideal PPAT for W  X  20. If W  X  20 and P  X  5%, ST  X  100 ms is not a good value either because an out-of-limits skew frequently occurs. Although the AFME implementation performs better than the MAPS implemen-tation, the AFME implementation collapses in the case W  X  20, S  X  10 and P  X  5%. SPINE performs better for the parameters ST  X  100, W  X  40, and P  X  25% whereas it has lower performance in the other cases. On the basis of the obtained results we can state that MAPS on Sun SPOT shows comparable performances with SPINE on TelosB sensors, which is a domain-specific framework for WBSNs, so confirming its suitability for supporting efficient WBSN applications. In addition in Table 2 a comparison among the sensor-node-side applications based on MAPS, AFME and SPINE with respect to RAM usage and code dimension out of the available memory resources is reported. Both MAPS and AFME requires more memory than SPINE; however, the Sun SPOTs are wireless sensors more capable than the TelosB Sky-motes so the percentages of used memory by MAPS and AFME are much less than SPINE. It is finally worth noting that MAPS performs slightly better than AFME. 5.2.2. Recognition accuracy
The activity monitoring system i ntegrates a classifier based on the K-Nearest Neighbor algorithm ( Cover and Hart, 1967 )thatis capable of recognizing postu res and movements defined in a training phase. The classifier was setup through a training phase and tested considering the following parameter setting: ST  X  100 ms, W  X  20 ( S  X  10), P  X  25%. Accordingly, the features (Min, Max and Mean) are computed on 20 sampled data every new 10 samples acquired by the sensors. The training phase used a KNN-based classifier parameterized with K  X  1 and the Manhattan distance which performs quite well as classes (lying down, sitting, standing still and walking) are rather separate and scarcely affected by noise. The test phase is carried out by considering the pre-defined sequence of postures/movements represented by the state machine reported in Fig. 16 . Accordingly, the obtained classification accuracy results are reported in Fig. 17 . As can be noted after a transitory period of 5 s from one state to another, all the postures/movements are recognized with an accuracy of 100%. The state transitions more difficult to recognize are STA -SIT, WLK -STA, and SIT -whereas the transition STA -WLK is recognized as soon as it occurs. The obtained results are good and encouraging if compared with other works in the literature which use more than two sensors on the human body to recognize activities ( Maurer et al., 2006 ). 5.3. On the programming effectiveness of MAPS enough efficiency to support the requirements of real-time recognition of human activities, in this section, we discuss the programming effectiveness of the agent-oriented approach based on MAPS for the development of WBSN applications according to the experience gained in the development of the presented agent-based system and of a wide range of SPINE-based WBSN applications ( Gravina et al., 2010 ). Programming effectiveness refers to two main aspects: (i) suitable programming abstrac-tions for an effective modeling and prototyping of the system behavior (notably including resource constrained operations) and (ii) usability of such abstractions to create new applications.
Such two aspects should be carefully considered in the specific application domains in which MAPS is currently applied such as real-time human monitoring systems based on WBSNs. MAPS provides agent-oriented programming abstractions which are suitable to model not only WBSN systems but also general-purpose WSN systems in terms of multi-agent systems: (i) FSM-based behavior that can model both reactive and proactive agents; (ii) event-driven interface that allows for an easy access to the agent system and the sensor-node resources; and (iii) message-based interaction that enables direct and broadcast communications among agents. The development of the activity monitoring system in AFME also provided useful insights for the comparison of the programming effectiveness between MAPS and AFME. As described in Section 3, the programming abstractions of AFME to specify the agent behavior, which is based on a BDI-like model, are very different from those of MAPS, even though the interaction among AFME agents is also based on messages. In Figs. 18 and 19 , the MAPS-based architecture and the AFME-based architecture of the sensor agents of the activity monitoring system are respectively reported. The AFME-based architecture is more complex than the MAPS-based architecture. In particular, in the former, according to the AFME model, specific components for Perceptors, Actuators, SharedDataModules and TERImplication formulas are to be defined; conversely, in the latter according to the MAPS architecture only the FSM plane is to be programmed. modeled should not have a dynamic goal-oriented behavior which usually necessitates a complex architecture more suitable to capture complex requirements, the MAPS approach is more effective as the programming of the agent architecture is more rapid and straightforward. Indeed, it is worth pointing out that the programming of complex proactive agents in wireless sensor nodes is a very difficult task due to the limited computational resources of such nodes. In fact, AFME was originally conceived for PDAs/smartphones that are devices much more resource-capable than wireless sensor nodes. In the context of WBSN applications which specifically requires intensive in-node signal processing, sensor-side computing components are more reactive than proactive. Moreover, as already stated in Section 3.3, the
FSM model is one of the most used programming model in embedded computing so making MAPS appealing for program-mers in the embedded computing research and development area. Finally, as the proposed activity monitoring system was also completely developed with SPINE and, previously, without SPINE by means of the nesC programming language ( Gay et al., 2003 ), some insights deriving from the exploitation of different programming approaches (two agent-oriented approaches based on MAPS and AFME, a WBSN domain-specific approach based on SPINE and a lower-level programming approach based on nesC) for WBSN application development are discussed in the following. The effectiveness of the agent-oriented approach is evident if compared with the nesC approach as it provides higher-level programming methods to abstract away specific low-level opera-tions, such as sensor driver access and low-level radio protocols, and ease the modeling of cooperative behavior through agent interactions. Finally, as SPINE is a WBSN domain-specific frame-work, it provides programming abstractions specific to the devel-opment of WBSN applications so being even more effective that MAPS and AFME in defining operations such as buffered sampling processes and data feature extractions. However, proactive beha-viors and peer-to-peer sensor node interactions are not provided by SPINE whereas both MAPS and AFME agents support them in a straightforward way. 6. Conclusions
Programming WBSN applications is a complex task which requires suitable programming paradigms and frameworks cop-ing with the WBSN specific characteristics. Several kinds of frameworks and approaches have been to date proposed. Among them, domain specific frameworks have the potential to provide both rapid development of WBSN applications and also good performances. In this paper we have proposed an agent-oriented approach, which relies on the basic features characterizing the domain specific frameworks and on the agent-oriented MAPS framework, aiming to offer more programming effectiveness while providing the required efficiency. In fact, MAPS has been purposely defined for resource-constrained environments and is based on (i) lightweight agents so avoiding conventional heavy-weight agent architectures and (ii) run-time architecture formed of components efficiently handling the low-level sensor node functions and providing higher-level services to agents. In parti-cular, by using MAPS, a WBSN application can be structured as a set of agents distributed on sensor nodes supported by a compo-nent-based agent execution engine which provides basic services such as message transmission, agent creation, timer handling, easy access to the sensor node resources, and agent migration (if needed). The development and testing of a full-fledged real-time human activity monitoring system based on wireless body sensor networks has been described. It is emblematic of the effectiveness and suitability of MAPS to deal with the program-ming of WBSN applications. The carried out performance evalua-tion of the developed prototype shows fine synchronization of the sensor nodes, continuous real-time monitoring, and good recog-nition accuracy, once parameters are carefully set. However, the MAPS-based development of new applications having stringent requirements (sensing rate, computing speed, message transmis-sion latency) must be carefully analyzed case by case as WSNs are application-specific systems.

Finally, the comparison of MAPS with the AFME framework based on Sun SPOTs and the WBSN-specific framework SPINE based on TinyOS in the development of the monitoring system, has produced important considerations about the provided system efficiency and programming effectiveness. From the system per-formance perspective, MAPS shows performances similar to those obtainable with AFME and SPINE that are suitable for fulfilling the real-time requirements of the monitoring system. From the pro-gramming effectiveness perspective, MAPS is more effective than AFME for WBSN applications as it is based on an FSM-based agent model that is more suitable than the AFME agent model for the development of lightweight WBSN-based components that are mostly reactive components. Moreover, with respect to SPINE, MAPS (and also AFME) is able to support peer-to-peer interactions among WBSN sensor nodes and proactive components.

On-going research efforts are devoted to: (i) porting MAPS onto the Sentilla JCreate pervasive computers which are compli-ant to J2ME CLDC 1.1 but based on TelosB-like sensors that are less powerful than Sun SPOTs; in particular, the on-going porting has arisen the need to define a TinyMAPS, a compressed version of MAPS, to drastically reduce the memory footprint; (ii) developing a full-fledged agent-based version of SPINE (named ASpine) through MAPS and the JADE framework to enable agent-oriented development of pervasive applications for assisted livings (such as emergency medical care) based on heterogeneous computing platforms: PC/workstations (JADE), PDA/smartphones (JADE Leap), and sensor nodes (MAPS); and (iii) defining an agent-oriented methodology for heterogeneous W(B)SN applications which uses MAPS as main target agent platform for wireless sensors and JADE for sensor coordinators.
 Acknowledgments Authors wish to thank Roberta Giannantonio, Marco Sgroi and Antonio Guerrieri for their precious contributions in terms of ideas and discussions, and Alessio Carbone for his on-going implementation efforts on ASpine. This work has been partially supported by CONET, the Cooperating Objects Network of Excel-lence, funded by the European Commission under FP7 with Contract number FP7-2007-2-224053.
 References
