 Duke University, Durham, NC 27519, USA There are two basic approaches for analysis of data from two or more tasks, single-task learning (STL) and multi-task learning (MTL). Whereas STL solves each task in isolation, with possible relations between the tasks ignored, MTL solves the tasks jointly, exploiting between-task relations to reduce the hypothesis space and improve generalization (Baxter, 2000). The ad-vantage of MTL is known to be manifested when the tasks are truly related and the task relations are ap-propriately employed. For supervised learning, in par-ticular, MTL can achieve the same level of general-ization performance as STL, and yet uses significantly fewer labeled examples per task (Baxter, 2000). The reduced sample complexity in each task is achieved by transferring labeling information from related tasks. While the MTL literature has primarily assumed that the tasks have the same input and output domains and differ only in data distributions (Baxter, 2000; Bakker Borbely, 2008), a number of recent publications are beginning to break the limit of this assumption, in an attempt of extending MTL to a wider range of appli-cations (He &amp; Rick, 2011; Maayan &amp; Mannor, 2011; Kulis et al., 2011; Wang &amp; Mahadevan, 2011). In these recent publications, different tasks are per-mitted to have different feature spaces. In particu-lar, (He &amp; Rick, 2011) simultaneously performs multi-view learning in each task and multi-task learning in shared views, assuming each task has its own features but may also share features with other tasks. The method in (Maayan &amp; Mannor, 2011) allows tasks to have different feature representations, learning rota-tions between the feature representations by matching the tasks X  empirical means and covariance matrices. The work in (Kulis et al., 2011) considers a source task and a target task, assumed to have different fea-ture dimensions, and learns a nonlinear transformation between the source feature domain and the target fea-ture domain using kernel techniques. Finally, (Wang &amp; Mahadevan, 2011) employs a manifold alignment tech-nique to map each task X  X  input domain to a common latent space, with the task-specific maps achieving the goal of simultaneously clustering examples with the same label, separating examples with different labels, and preserving the topology of each task X  X  manifold. In this paper, we address the problem of multi-task learning across heterogenous domains, assuming that each task is a binary classification with a task-specific feature representation. The approach we take differs from (Maayan &amp; Mannor, 2011; Kulis et al., 2011; Wang &amp; Mahadevan, 2011) in several important as-pects. First, while these previous methods all learn domain transforms and classification in two separate steps, we integrate the two steps by learning domain transforms and classification jointly. Secondly, the do-main transforms in our approach are represented by sparse matrices, with the sparsity enforced by a Lapla-cian prior on the transform matrices (corresponding to an ` 1 penalty to the log-likelihood). By contrast, all previous methods do not impose sparsity on domain transforms. The third difference is that the overall model in our approach consists of a factor model for the observed features, which can be used to synthe-size new data unseen during training. Finally, our approach is semi-supervised, using labeled as well as unlabeled examples to jointly find the domain trans-forms and the classification. By contrast, the meth-ods in (Maayan &amp; Mannor, 2011; Kulis et al., 2011) are supervised, and the method in (Wang &amp; Mahade-van, 2011) is semi-supervised in learning domain trans-forms, but supervised in learning classification. While full supervision can be challenged by the scarcity of labeled examples (typically assumed in MTL), semi-supervision is doubly beneficial to a joint learning ap-proach, in which unlabeled examples help to perform classification, while labeled examples help to find the domain transforms.
 The proposed approach is based on a sparse hierar-chical Bayesian model, referred to as the latent probit model (LPM), which jointly represents the sparse do-main transforms and a common sparse probit classi-fier (Albert &amp; Chib, 1993) in the latent feature space, with the sparsity imposed by a hierarchical Lapla-cian prior (Figueiredo, 2003). We employ expectation-maximization (EM) to find the maximum a posterior (MAP) solution to the domain transforms and probit parameters.
 The sparsity of domain transforms in LPM plays a pivotal role in defining the between-task relations. Roughly speaking, a greater sparsity in domain trans-forms indicates closer relations between the tasks. In other words, sparser domain transforms imply that dif-ferent tasks look more similar to each other in the la-tent feature space, and thus greater performance gain may be achieved by sharing information among the tasks. We give a quantitative analysis of the perfor-mance gain by providing an upper bound to the es-timation error of the probit classifier, which is shared among the tasks in the latent space. The bound has an analytic functional dependence on the sparsity level of domain transforms, showing that sparsity contributes directly to the error reduction. In addition, the bound also reveals the error X  X  dependency on the number of tasks, the number of labeled examples in each task, and the latent dimensionality. The latent probit model (LPM) is a generative prob-abilistic model for M  X  2 partially labeled sets of feature vectors (data points), assuming each dataset has a different feature representation. The LPM has a hierarchical Bayesian structure, as graphically shown in Figure 1, and is parameterized by {  X ,  X  ,  X  ,b, w } and { F m , d m } M m =1 . The parameters w specify the pro-bit classifier shared by the tasks in the latent feature space, and F m specifies the domain transform for the m -th dataset up to a translation (which is specified by d m ). The parameters w and { F m } M m =1 are given hierarchical Laplacian priors (Figueiredo, 2003) to en-courage sparsity, with the priors specified by hyper-parameters {  X , X  } . The other hollow circles in Figure 1 denote latent variables, which include {  X  , u , s ,z } . The generative process in the LPM is described below, with N (  X  ,  X  ) denoting a normal distribution with mean  X  and covariance matrix  X  .
 Given hyper-parameters {  X , X  } , the sparse parameters w and { F m } M m =1 are generated as follows. 1. Draw w = [ w j ] F 0  X  1 , the sparse parameters of the 2. For m = 1 , 2 ,  X  X  X  ,M , draw the sparse domain Given parameters {  X ,  X  ,  X  ,b, w } X  X  F m , d m } M m =1 , the data sets are generated as follows.

For i = 1 , 2 ,  X  X  X  ,N m and m = 1 , 2 ,  X  X  X  ,M , Note that the latent normal distribution in (1) can be extended to a mixtures of normal distributions to account for more complicated data manifolds.
 With { F m } M m =1 drawn from sparse prior distributions, most entries of these matrices will be zero; by (2) this implies that only a few latent features are responsi-ble for generating the observed features. Since this is true for any m , the chance for different datasets to use the same features to generate their observed features is large. However, latent features are identi-cally distributed; thus the shared latent features must have the same statistics across the tasks. Therefore, the datasets (sets of features vectors) generated by the LPM model are encouraged to be closely related. While the sparsity of { F m } M m =1 reflects the relatedness between the sets of features vectors, the sparsity of w encourages the classification to be dependent on a few latent features. This is important, because even when the observed features differ among tasks to entail less sparse { F m } M m =1 , the tasks may still be able to share information for classification through appropriately se-lected latent features. The goal of our analysis is to quantify the notion that sparse domain transforms encourage the tasks to be related, and that better generalization can be achieved by sharing information among related tasks to learn the common classifier. The analysis is based on an upper bound for the estimation error of w , with the bound represented in terms of the number of nonzero elements of the true { F m } M m =1 .
 Since we are analyzing the general information-sharing mechanism in the LPM, we expect the results to be insensitive to the choice of estimation method. We therefore employ a simple two-step approach to estimate w . The estimation is based on training data generated by the true LPM parameterized by tions b = 0,  X  = I ,  X  = 0 , and d m = 0  X  m , where 0 is a vector of zeros of appropriate dimensions. Note we have used a superscript  X  to emphasize w  X  is the vector of unknown parameters to be estimated.
 Let { X m } M m =1 , with X m = [ x m 1 , x m 2 ,  X  X  X  , x M sets of feature vectors, each corresponding to a task. By the generative process of the LPM, where { mij } are i.i.d. drawn from a zero-mean normal distribution with variance  X  , and the entries of S m are i.i.d. from the standard normal distribution. Given X m , the maximum-likelihood solutions to { S m } are given by which form a global data matrix by pooling data across the tasks, where n t = P M m =1 L m is the total number of training examples across all M tasks.
 To simplify the analysis, we assume access to the latent responses of w  X  to  X  , i.e, where z = [ z 1 ,  X  X  X  , z M ] T with z m = [ z m 1 ,  X  X  X  ,z and the entries in e are assumed i.i.d. from the stan-dard normal distribution. These assumptions may be avoided at the price of complicating the bound, which is not pursued here. The estimate of w  X  is given by We derive an upper bound to k similar arguments as in (Bickel et al., 2009; Lounici et al., 2009) and making use of a key result in (Byrne, 2009) on extreme singular values of Hermitian matri-ces. Our main results are stated in Theorem 1, the proof of which is in the Appendix.
 Theorem 1. Let w  X  have nonzero and zero elements indexed respectively by J and J c . Denote s = | J | as the cardinality of J . Let  X  = in (7), and c 0 be the minimum nonnegative number such that k  X  J c k 1  X  c 0 k  X  J k 1 . Let  X  j be the transpose of the j -th row of  X  and  X   X  = max j k  X  j k 2 . For any F 0  X  2 and a  X  P e = 1  X  F where f m, : ,j denotes the j -th column of F m and k f k denotes the number of nonzero elements in vector f . The bound in (8) establishes the functional depen-dency of k istic parameters of the LPM. Foremost, the term k f m, : ,j k 0 measures the number of nonzero elements in the j -th column of F m . A sparse F m has small k f m, : ,j k 0 for its columns, which decreases the term ror reduction. Second, s is the number of nonzero el-ements in w ; a sparse w has a small s , which makes the error small.
 Third, recall that n t = P M m =1 L m , where M is the number of tasks, and L m is the number of training samples in the m -th task. The n t in the denominator of (8) plays the role of normalization with respect to the training examples across all tasks, leaving the n t in the numerator to influence the error: large n t dicates small error. Note that some tasks may have few examples while other have abundant ones; as long as they add up to a large n t , similar error reduction will be achieved. Lastly, F 0 is the dimensionality of la-tent features shared across the tasks. The error bound decreases as F 0 becomes smaller. We seek a MAP estimate of the parameters  X  = {  X  ,  X  ,b, w } X  X  F m , d m } M m =1 . Taking into account all data (labeled and unlabeled) and the sparse priors, and integrating out the latent variables {  X  , u , s ,z } , one obtains the logarithmic posterior probability of  X , + + + P j ln R p ( w j | u j ) p ( u j |  X  ) du j labeled and unlabeled feature vectors in the m -th data set, i.e., L m  X  X  m = { 1 , 2 ,  X  X  X  ,N m } .
 We employ an expectation-maximization (EM) algo-rithm to maximize ` ( X ), with {  X ,F 0 } and hyper-parameters {  X , X  } treated as input parameters to the algorithm, determined separately by cross-validation when necessary. The EM algorithm consists of an iteration of E-step and M-step. In the E-step, one computes the conditional moments of latent variables { z mi , s mi ,  X  , u } given the data and the most recent parameters  X . In the M-step, one calculates the up-dated model parameters b  X  using the latent variables X  moments obtained in E-step. The complete EM al-gorithm is given in Algorithm 1, with major update equations summarized below. The algorithm requires O ( F 0 P M m =1 D m ( F m + F 2 0 )) scalar products per itera-tion.
 Update of Latent Features X  Distribution 1  X 
R  X   X   X  mi = 1 + w T Q m w ,  X 
Q Update of Domain Transforms b b f Algorithm 1 The EM algorithm for learning the LPM
Initialize  X . repeat until ` ( X ) Converges for k = 1 , 2 ,  X  X  X  ,F 0 and m = 1 , 2 ,  X  X  X  ,M , where  X  =  X   X  Update of Probit Classifier b w = G (  X  I + G X  1 G )  X  1 G b b = where  X  =
G = diag( p | w 1 | , p | w 2 | ,  X  X  X  , p | w F 0 | ) . 5.1. Cancer Diagnosis We first consider the two Wisconsin breast cancer datasets (original and diagnostic) from the UCI ma-chine learning repository 2 . The objective of both tasks is to identify benign or malignant cells. The feature dimensionality is 9 for the original data and 30 for the diagnostic data. We set F 0 to the smallest dimen-sionality among the tasks to favor error reduction (as suggested by (8)), and  X  = 10  X  3 to enlarge the role of domain transforms in connecting the tasks, with the regularization parameters (  X , X  ) determined via cross-validation (the robustness to these parameters is shown below). We perform both multitask learn-ing and transfer learning experiments, and compare the LPM to STL and the methods in (Wang &amp; Ma-hadevan, 2011) (abbreviated as HDAMA), (Maayan &amp; Mannor, 2011), and (Kulis et al., 2011), with all com-peting methods using standard probit classifiers. The method in (Maayan &amp; Mannor, 2011) cannot perform MTL and is excluded in the comparisons on MTL. The performance is measured in terms of the area un-der ROC curve (AUC), as a function of the number of labeled examples per task in the MTL case, or the number of labeled examples in the target task in the transfer learning case. The results are averaged over 50 independent runs, each constituting an independent split of the data into training sets and test sets. Figure 2(a) shows that, for MTL, the LPM performs comparably as or slightly better than HDAMA and both outperform the other methods, especially when labeled data are scarce. In transfer learning, all data in the source domain are labeled, and we have only a few labeled data in the target domain. We transfer all the labeled data from the source domain to the target domain. Figure 2(b-c) show that the performance of the LPM is slightly better than HDAMA, probably due to the fact that the amount of data (labeled and unlabeled) is balanced between the two tasks.
 The regularization parameters  X  and  X  control the sparsity of domain transforms and the classifier, re-spectively. Table 1 summarizes the performance of the LPM relative to STL, under a wide range of settings for these parameters. The importance of sparsity is in-dicated by the diminishing performance improvements as the regularization parameters approach zero. Over a wide range in the middle, the LPM maintains stable performance improvements over STL, indicating the learning is robust to the settings of regularization pa-rameters. The table also shows that the sparsity of domain transforms plays a more prominent role in in-fluencing the performance than the classifier itself, sig-naling that the benefit of sharing information among the tasks can outweigh the benefit of feature selection. 5.2. Mine Detection The land-mine detection problem (Xue et al., 2007) is based on airborne synthetic-aperture radar (SAR) data and the underwater mine detection problem (Liu et al., 2009) is based on synthetic-aperture sonar (SAS) data 3 . Here we solve these two problems together, us-ing the proposed cross-domain multitask learning ap-proach. The feature dimensionality of land-mine data is 9 and that of underwater mine data is 13, and the labels do not have the same exact meaning for the two problem domains. There are a total of 19 land-mine tasks and 8 underwater mine tasks. The number of data points in the underwater mine tasks ranges from 756 to 3562, which is much larger than that for the land-mine tasks (ranging from 445 to 454). This prob-lem can be viewed as a multitask learning across het-erogeneous input and output domains (although the labels have known correspondence). We consider 9 land-mine tasks and all 8 underwater tasks, pairing them up to form 9  X  8 = 72 MTL problems. The re-sults are reported as an average over the 72 problems, with the setting of F 0 and regularization parameters based on the same rule as in Section 5.1.
 The performance comparisons for multi-task learning are shown in Figure 3(a) in terms of average AUC. Each curve results from an average of 100 independent runs of independently splitting the data into training and test sets and 9  X  8 combinations of underwater tasks versus land-mine tasks. In the transfer learning case, 50 labeled samples together with all other un-labeled samples are transferred to the target domain. The performance on the target task is shown in Fig-ure 3(b-c). It is seen that the LPM outperforms all other methods by significantly large margins, in both multi-task learning and transfer learning from land-mine data to underwater mine data. The competi-tion on transfer learning from underwater mine data to land-mine data is more intense, but the LPM still gives the best overall outperformance.
 While the amount of examples is balanced between the two Wisconsin tasks, it is highly unbalanced between the land-mine tasks and the underwater mine tasks (as detailed above). The results indicate that the LPM is more robust to this unbalance than the other methods. We have proposed the LPM model for cross-domain multi-task learning, assuming heterogenous feature representations across the tasks. The benefit of MTL in the LPM is based on the tasks X  relatedness in the la-tent feature space, which is characterized by the sparse domain transforms. By promoting sparseness of do-main transforms and the common classifiers, informa-tion sharing is encouraged to the advantage of improv-ing performance in each individual task. The impor-tance of sparsity is demonstrated by both theoretical analysis and experimental results.
 The research reported here has been supported by the ONR ATL program.
 Proof of Theorem 1
