 We propose a novel latent factor model to accurately predict re-sponse for large scale dyadic data in the presence of features. Our approach is based on a model that predicts response as a multiplica-tive function of row and column latent factors that are estimated through separate regressions on known row and column features. In fact, our model provides a single unified framework to address both cold and warm start scenarios that are commonplace in practi-cal applications like recommender systems, online advertising, web search, etc. We provide scalable and accurate model fitting meth-ods based on Iterated Conditional Mode and Monte Carlo EM al-gorithms. We show our model induces a stochastic process on the dyadic space with kernel (covariance) given by a polynomial func-tion of features. Methods that generalize our procedure to estimate factors in an online fashion for dynamic applications are also con-sidered. Our method is illustrated on benchmark datasets and a novel content recommendation application that arises in the con-text of Yahoo! Front Page. We report significant improvements over several commonly used methods on all datasets.
 H.1.1 [ Information Systems ]: Models and Principles; G.3 [ Mathematics of Computing ]: Probability and Statistics Algorithms, Theory, Experimentation Sparse, Interaction, Predictive, Latent Factor, Recommender Sys-tems, Dyadic Data, Metadata
Estimating interactions for massive but highly incomplete dyadic data is an important task in several applications such as recom-mender systems, web advertising, social networks, etc. Typically, the training data is collected for some fixed time period, and con-sists of a response variable y ij available for a small fraction of dyads or cells ( i, j ) (pairs of elements from two different sets re-ferred to as rows and columns) along with features attached to rows, columns and cells. The goal is to predict the response value for a new cell ( i, j ) new at some time in the future, row i and/or column j corresponding to ( i, j ) new may not necessarily have occurred during the training period. For instance, in a movie recommender system, rows and columns correspond to users and movies respec-tively and the response y ij may denote the explicit rating provided by user i to movie j . Row features w i may include age, gender, geo-location of the user; column features z j may include genre, title words, release date of the movie. One may also have cell spe-cific features x ij like: Is the user X  X  favorite actor playing a lead role in the movie ? The accuracy with which one could predict the rating a user i would provide to movie j at some future time point is an important component that affects the quality of the recom-mender system. Another example is online advertising where rows and columns correspond to queries and ads respectively, the goal is to predict the probability of a click on an ad for a given query. The success of several other applications that include e-commerce, web search, social networks also depend on similar estimation prob-lems. For ease of exposition, we shall refer to rows and columns as users and items respectively.

Accurate estimation of interactions for large, incomplete and dy-namic dyadic data entails several challenges. Lack of data (data sparseness) is a key issue; observations are available only for a small fraction of possible dyads. In fact, the distribution of avail-able observations is highly non-random; a small fraction of users (items) typically account for a large fraction of data while the re-maining are sparsely distributed among others. Moreover, the sys-tem is not static and often prediction is required for dyads that in-volve new users and/or items over time (also commonly referred to as the cold-start problem). In several applications, both users and items are associated with a set of informative features. For ex-ample, users may supply demographic information like age, gen-der, occupation at the time of registration, and we can infer the geo-location of a user through his/her IP address. When items are movies, we may know their genres, release dates, cast, etc. For news items, we can extract features from the article content. One approach is to build a predictive model that is entirely based on user and item features, such a method does not suffer from the cold-start problem. However, it treats old users (items) similarly as new users (items) and does not utilize past interaction data to estimate user/item centric models; it also fails to capture correlations that are often present in residuals associated with the same user/item. In fact, models that ignore features and are only based on users X  past interaction with items have been shown to predict well for old users and items. This is evident in the plethora of methods that have been proposed in the context of the movie recommender systems. Although effective for warm-start, they fail to address the cold-start problem. Methods that simultaneously incorporate past interaction data and features for accurate prediction and smoothly handle both cold-start and warm-start scenarios are attractive.

We propose a regression-based latent factor model ( RLFM ) that a) improves prediction for old user-item dyads by simultaneously incorporating features and past interactions and b) provides predic-tions for new dyads through features. In addition, we also provide a strategy for online estimation of latent factors. We discuss and illustrate our method on a new recommender system problem that arises in the context of Yahoo! Front Page where dyads are dynamic in nature, methods that work only for old dyads are ineffective [2] here. We also illustrate our method on movie recommender ap-plication and show that simultaneously incorporating features and past interactions through our RLFM significantly improves predic-tion accuracy for both old and new users. Since the Netflix data does not provide user features, we illustrate our methods on Movie Lens and Each Movie datasets.

The key idea of RLFM is to associate latent factors (or profiles) u and v j to user i and item j where u i and v j are r -dimensional la-tent factors. We shall refer to r as the number of latent dimensions. Interaction is captured through a multiplicative function u is similar in spirit to SVD for complete matrices; the incomplete-ness, imbalance and noise in data makes it a significantly harder problem. In particular, it is important to regularize the latent fac-tors to avoid over-fitting and achieve the best bias-variance trade-off. Several authors [24, 8, 1, 22] have recently studied the prob-lem, especially in the context of the Netflix competition where it is referred to as matrix factorization . The regularization is mostly based on a zero-mean Gaussian prior on the factors, we refer to this method as ZeroMean . Our method also assumes a Gaussian prior but replaces the zero mean with a feature-based regression; thus, it simultaneously regularizes both user and item factors through known features. We show that such a prior poses challenging issues for scalable computation and has other theoretical implications. In particular, it addresses both cold and warm-start problems seam-lessly through a single model. It also induces marginal correlations among response values that share a common user or item. Corre-lation provides extra information for response at a dyad ( i, j ) and improves predictive performance. Thus, if two movies are corre-lated, knowing the rating of user i on the first one in the past helps us accurately predict his/her rating on the other one. In fact, we show that our model is a stochastic process (similar to a Gaussian process) on the dyadic space with non-zero covariance only among responses with either a common user or item. While Gaussian pro-cesses are known to provide accurate predictive models in several contexts [21], the main computational bottleneck is the cubic com-putation associated with a dense correlation matrix. In our case, we exploit the special structure of the covariance process and reduce the computational complexity to  X  X ssentially X  linear in the number of data points, users and items.

Our RLFM method works by anchoring user/item profiles around a global feature-based one whereby user/item-specific profiles are then constructed by estimating deviations from the global ones in a smooth fashion; the amount of deviation depends on sample size and correlations among observations. In particular, users/items with sparse data are deemed more unreliable to deviate and  X  X hrunk X  aggresively to the global one. Thus, users/items start out with pro-files based on their known features that gets refined smoothly with the availability of more data. This ability to move from coarse to fine resolutions in a smooth fashion after accounting for differ-ing sample sizes, correlation and heterogeneity are key aspects that provides for an accurate, scalable and general predictive method (a) RLFM for heavy users Figure 1: Comparing latent factors estimated through RLFM , ZeroMean and FeatureOnly . Each point ( x, y ) in a plot reports the estimated values, x and y , of the first latent factor of a user using the two methods indicated in the plot. For light users, ZeroMean collapse to zero, RLFM on the other hand collpases to FeatureOnly . through RLFM for large scale dyadic data. To provide more intu-ition, Figure 1 shows the relationship among user latent factors es-timated separately for a sample of heavy and light users on the Ya-hoo! Front Page using RLFM , ZeroMean and FeatureOnly . Here, ZeroMean is a model that uses latent factors regularized through zero mean priors(matrix factorization), FeatureOnly is based on fea-tures alone while RLFM uses latent factors regularized through re-gression based priors. For light users, ZeroMean  X  X hrinks X  the pro-files close to zero and leads to biased estimates. RLFM on the other hand recognizes the data sparseness and falls back on the FeatureOnly profiles. For heavy users, ZeroMean is aggressive and tends to overfit the data. RLFM on the other hand anchors itself around FeatureOnly profiles and deviates from it in a smooth way that leads to better regularization.

Our contributions are as follows. We propose a novel class of latent factor models called RLFM that incorporates both known user/item features and past interaction data into a single model for predicting dyadic response in a generalized linear model (GLM) framework. Our method provides a single unified framework to handle both cold and warm start scenarios in a smooth way. We prove theoretical equivalence to a stochastic process model with polynomial kernel on a dyadic space. We provide a scalable, ac-curate and robust model fitting procedure through a Monte Carlo EM algorithm with complexity linear in number of observed dyads, users and items. We also provide a procedure to generalize our method to dynamic settings through an online updating procedure for the factors. Our methods are illustrated on benchmark datasets and on a new recommender system application that arises in the context of displaying the best stories to users visiting the Yahoo! Front Page. Our method significantly outperforms several existing and commonly used methods on all datasets we considered.
Our regression-based latent factor model ( RLFM ) and the model fitting problems are mathematically defined in Table 1. RLFM is a two-stage hierarchcial latent factor model, fitting algorithms find the maximum likelihood estimate of the model parameters and pos-terior distribution of factors for a given training dataset. In this sec-tion, we describe the model and state some of its properties. In sec-tion 3, we describe scalable model-fitting algorithms implemented through Monte Carlo EM (MCEM) and Iterated Conditional Mode (ICM) algorithms. We begin with notations and preliminaries fol-lowed by a detailed description of RLFM for Gaussian response. For binary response, we fit a logistic regression through a varia-tional approximation as discussed in Section 3.2. In Section 4, we describe a method to smooth latent factors over time.
For ease of exposition, we describe our model by considering the problem of predicting user ratings on items. Let index i run through users, and index j run through items. Dyad ( i, j ) has an associated rating (rating given by user i to item j ). We note that in another application, i may represent a web page, j may repre-sent an ad, and dyadic response may represent the click-through rate. For the sake of discussion, we shall refer to rows, columns and dyads are as users , items and ratings respectively. Let M be the number of users, N be the number of items and K be the num-ber of ratings. The notations { o i } , { o j } and { o ij of o  X  X  over all users, items and ratings respectively, where o is a placeholder. The notation [ a | b ] denotes the conditional probabil-ity distribution of random variable a given b , and [ b ] denotes the marginal distribution of b . Let N (  X ,  X  2 ) and MVN (  X ,  X ) denote the single-variate and multi-variate normal distributions with mean  X  (vector for multi-variate) and variance  X  2 and  X  respectively. Next, we introduce notations for observed and latent data.
Observed Data : We observe ratings (the response), user fea-tures, item features and features specific to ratings. Let w z j denote feature vectors for user i and item j ; y ij and x denote the response and feature vector associated with dyad ( i, j ) . When convenient, we use X ij = ( x ij , w i , z j ) to denote known feature values associated with dyad ( i, j ) . Our method learns the relationship between y ij and X ij from observed data to predict un-observed y new ij for a dyad ( i, j ) new with features X
Latent Data : To model [ { y ij }|{ X ij } ] , we augment observed user and item features with unobserved latent factors attached to each user and item. Our approach connects the response and ob-served features indirectly through the factors that are predicted at a finer user/item resolution through a feature-based regression model. The estimated factors are in turn used to predict the response (see graphical model in Figure 2 and equations in Table 1 for more details). Specifically, we attach a latent  X  X rofile X  (  X  user i and a latent  X  X rofile X  (  X  j , v r  X  1 j ) to item j . Now, we have ( r + 1)( M + N ) latent factors that need to be estimated from the data. When convenient, we use  X  ij = (  X  i , u i ,  X  note all latent factors associated with dyad ( i, j ) . Drawing analogy to state-space models, latent factors can also be interpreted as un-known states and our model specifies how states and observations ( { y ij } ) are generated. Note that we use latent factor, profile and state interchangeably in this paper.

Hierarchical Modeling Approach : We now describe our two-stage hierarchical modeling approach. The first stage of our model
First stage: y ij  X  N ( m ij ,  X  2 ) , or (Gaussian)
Second stage:  X  i = g 0 0 w i +  X   X  i ,  X   X  i  X  N (0 , a  X  sponse when both observed features and latent factors are known. The second-stage specifies a generative model for the latent pro-files, i.e., [ {  X  ij }|{ X ij } ,  X  2 ] . Here,  X  = ( X  1 rameters that are required to specify the appropriate distributions and are estimated from data in practice. In particular, the parame-ter  X  2 are called hyperparameters . The two-stages specify the joint distribution of [ { y ij } , {  X  ij }|{ X ij } ,  X ] , which is equal to The joint distribution in Equation 1 is obtained by stitching together distributions in the two stages. Marginalizing (integrating out) over {  X  ij } provides the desired distribution [ { y ij }|{ X ij } ,  X ] for pre-diction. We note that marginalization involves computing a high dimensional integral that is generally not available in closed form. This is the main computational challenge that arises when working with such hierarchical models.
The fist stage model specifies how observations { y ij } are gener-ated given the latent factors. We assume conditional independence of response which is mathematically expressed as This intuitively means when latent user/item profiles are known without error, the response arising through user-item interaction for dyads are independent of each other. In general, latent profiles are estimated with error and averaging over the uncertainty induce de-Figure 2: Graphical representation of RLFM . Variance com-ponents (  X  2 , a  X  , a  X  , A u , A v ) are omitted for succinctness. pendencies in dyadic response as we shall see later. The first stage model is also referred to as observation equation.

We specify [ y ij | X ij ,  X  ij ,  X  1 ] in a generalized linear model (GLM) framework , linear, logistic and Poisson regression are special cases (see [18, 4] for more details). Letting m ij = E [ y ij |  X  sume l ( m ij ) is given by Equation (1) in Table 1, where l is some transformation of the mean whose range is the real line. In this paper, the illustrative datasets are analyzed using the linear and lo-gistic regression models in the first stage; we provide computation details for both but note that extension to other members of the GLM family is standard. For ease of exposition, we develop the theory for Gaussian response (linear regression) where several for-mulae are available in closed form.
Our second stage model specifies [ {  X  ij }|{ X ij } ,  X  2 shall refer to as the state equation. For many applications, K &lt;&lt; MN ; in fact, the imbalance in our data is such that K  X  ( M + N ) . Moreover, there is heterogeneity in the number of observations as-sociated with users/items  X  a small fraction of users/items account for a large fraction. The total number of parameters in the first stage observation model is s + M + N + r ( M + N ) = s +( r +1)( M + N ) . Clearly, the number of parameters is large and maximum likelihood estimates (MLE) of model parameters overfit even for reasonably small values of r . Hence, it is imperative to put constraints on the latent factors through the state equation to avoid over-fitting. In fact, the state equation determines the quality and predictive per-formance of the model to a large extent. In this paper, we propose a novel state equation that assumes latent factors {  X  ij } are functions of observed features { X ij } . Specifically, we assume conditional independence among latent factors where  X  2 = ( g 0 , a  X  , G, A u , d 0 , a  X  , D, A v ) . The component la-tent factor distributions are given by Equation (2) in Table 1. We note that it is also possible to use non-linear functions G ( w ) , D ( z ) , g ( w ) , d 0 ( z ) , we assumed linearity to ensure scalability. To com-plete model specification, we note that it is possible to further reg-ularize regression coefficients by using any off-the-shelf procedure like ridge regression, LASSO. We use a t-prior on the coefficients recently introduced by [13] which performs automatic variable se-lection by setting the coefficients of non-informative features to be close to zero.
After fitting the model using observations { y old ij } and { X we obtain an estimate of the parameters  X   X  . Then, given the fea-tures X new ij for a new dyad we would ideally predict the response y ij by its posterior predictive mean E [ y new ij |{ y old after marginalizing over [  X  ij |{ y old ij } , { X old ij putationally expensive at runtime. For the sake of efficiency, we simply use point estimates that are commonly used in practice and does not necessarily lead to loss in prediction accuracy [27]. That is, we predict y new ij by where  X   X  = E [  X  |{ y old ij } , { X old ij } ,  X   X ] for  X  =  X  Note that these posterior means are also the output from the fitting procedure. For new users and items, the posterior means are just prior means predicted purely by features; e.g.,  X   X  i =  X  g old users and items, the posterior means provide the  X  X ight X  balance between features and past activity through our model.
We show some popular classes of warm-start and cold-start mod-els arise as special cases of RLFM , providing further insights on how it provides a unified framework to deal with both scenarios in a smooth way. In fact, assuming g 0 = d 0 = G = D = 0 , one obtains the probabilistic matrix factorization model, which we call ZeroMean , [23, 24, 22] that has successfully modeled explicit movie ratings data. Next, we point out the relation between em RLFM and a pure feature-based model for a Gaussian response variable. A pure feature-based model is given as where h is an unknown function and the  X   X  X  are zero mean white noise random variables. One natural choice with categorical pre-dictors is a linear h , i.e., The unknown matrix of coefficients B capture interactions among users and items, estimating B may however be challenging for large values of p and/or q . In general, one takes recourse to some form of penalization on the entries of B (e.g. L 0 , L 1 or L ties). Another attractive approach that is often used is a low rank approximation of B = G 0 D that reduce the number of parameters from pq to r ( p + q ) . Plugging Equation (2) into Equation (1) in Table 1 for the Gaussian case, we get Hence, the pure feature based model is obtained as a special case of RLFM by assuming a zero variance for random effects, i.e.,  X   X  ij in Equation 4. We shall refer to this as FeatureOnly . The ad-ditional randomness in RLFM introduced through a two-stage pro-cess induce dependencies in response values sharing the same user or item and improves predictive performance.
Regularizing latent factors through regression has important con-sequences when modeling sparse dyadic data. For users/items with little data, we obtain reliable factor estimates by using the regres-sion estimates as a fallback . In fact, the model provides a unified framework to deal with both cold and warm start situations; we predict factors for new users/items through a feature-based regres-sion but converge to a user/item level profile that may deviate sub-stantially from the global regression for heavy hitters . Moreover, the regression on factors indirectly induce marginal dependencies among response variables as we discuss next.

Marginal dependencies: After adjusting for the effect of fea-tures, the residuals associated with the same user/item are expected to be correlated due to unmeasured latent effects; exploiting these correlations can significantly improve performance. For instance, if two items are correlated (people who bought A also bought B), it helps predict user X  X  response on B given his past response to A. Our RLFM captures item-item and user-user similarity through a quadratic form in the features and improves prediction. In partic-ular, pairwise correlation between user (item) ratings are constant across users (items) and depend on the item (user) features. The marginal moments can be computed in closed form for the Gaus-sian distribution and are given below.
 The expression shows our model defines a stochastic process on the dyadic space with polynomial kernels specifying pairwise correla-tions between user and item ratings. In particular, from standard stochastic process theory, the predicted value at a dyad ( i, j ) given by where P is the precision matrix of { y old ij } and Also note that  X  new ij is non-zero only for entries in the training data across the i th row and j th column. Thus, RLFM predicts at a dyad by adding an adjustment to the linear feature-based predictor; the adjustment is a weighted average of row and column residuals with weights depending on the induced correlations based on features. Hence, if item j is correlated with other items and/or user i has correlations with others, the stochastic process will exploit them to provide an additional adjustment term that will improve perfor-mance. In practice, it is computationally infeasible to work directly with the stochastic process defined through Equation 5, our model fitting strategy that works by augmenting observed data through la-tent factors is one way to scale computations. In fact, the stochastic process defined through Equations (5) and (6) shows the role played by regression parameters in inducing correlations among observa-tions. It also provides the invariant parameters that matter in predic-tion, namely, G 0 D , A u A v , G 0 A v G and D 0 A u D . While working directly with the latent factor model (instead of the marginalized one), this invariance is manifested in the non-estimability of u v individually; only the product u 0 i v j can be uniquely identifiable from the data. One can also interpret the regression coefficient ma-trices G and D as providing a rectangular kernel approximation for the dyadic stochastic process.
In this section, we provide details of our scalable model fitting al-gorithm for the Gaussian model. We begin with a brief description of existing methods to fit ZeroMean followed by a detailed descrip-tion of the Monte Carlo EM (MCEM) algorithm to fit RLFM ; we also briefly discuss an alternative method, the Iterated Conditional Mode (ICM) algorithm. We then describe a variational approxima-tion for the Logistic model.

Prior fitting methods : Several methods to fit ZeroMean have been reported in the literature, these include alternate least squares [8], Iterated Conditional Mode through gradient ascent [24] and Gibbs Sampling [23]. The difficulty in fitting ZeroMean arises from the fact that the posterior distribution of latent factors { u { v j } is multi-modal; predictive accuracy depends on how rapidly an algorithm converges to a reasonable mode in the posterior space. The additional complexity of estimating regression parameters in RLFM makes model fitting more challenging.

Our model fitting approach : We adopt an EM approach [11] and consider several variations. In particular, we experimented with three methods, alternate least squares (ALS), ICM and MCEM (based on Gibbs sampling), on several datasets (real and simulated) and found MCEM to be the best, both in terms of predictive accu-racy and resistance to overfitting with increasing number of latent dimensions r . The latter is an important property since it is com-putationally expensive to determine the appropriate value of r in practice. We found that ICM tends to overfit when r is large, and ALS performs poorly compared to MCEM and ICM.
We first describe the MCEM algorithm, then the ICM algorithm and a brief comparison between the two. Our goal is to find  X  that maximizes the marginal log-likelihood of observed response [ { y ij }|{ X ij } ,  X ] ; marginalization is performed with respect to la-tent variables {  X  ij } = ( {  X  i } , {  X  j } , { u i } , { v distribution is hard to be maximized directly since the hyperparam-eters appear in the inverse and determinant of a large K  X  K co-variance matrix. Thus, we work with the complete data likelihood of [ { y ij } , {  X  ij }|{ X ij } ,  X ] .
 EM Algorithm: Starting from some initial estimate  X  init , the EM algorithm maximizes the marginal log-likelihood by iterating through expectation (E) and maximization (M) steps until the so-lution converges. Each sweep of the E and M steps is guaranteed not to reduce the marginal log-likelihood. Let  X  curr be the current estimate of  X  in the iterative process. In the E-step, we compute the expected log-likelihood of complete data with respect to the conditional distribution of [ {  X  ij }|{ y ij } ,  X  curr ] . In the M-step, we maximize the expected log-likelihood (from E-step) with respect to  X  and obtain a new estimate. To ensure convergence, it is suffi-cient to use any hill climbing method in the M-step that provides a new improved value of  X  ; such variants are called generalized EM (GEM) [19].

Monte Carlo E-step: The E-step in our model cannot be com-puted in closed form due to the multiplicative terms u 0 i first-stage model, this makes [ {  X  ij }|{ y ij } , { X standard distribution. However, it is easy to draw Monte Carlo sam-ples through Gibbs sampling from [ {  X  ij }|{ y ij } , { X the full-conditionals of are all Gaussian with means ane variances given in Table 2, where Rest denotes other variables. In fact, user (item) popularity  X  parameters are all conditionally independent, and the same holds plementation of each Gibbs iteration through parallelization across users followed by parallelization across items in drawing samples from conditional Gaussian distribution. Hence, we replace the E-step by a Monte Carlo E-step, providing an MCEM algorithm ([9] and references therein). The details of the Gibbs sampling are given in Algorithm 1. For ease of exposition, we use  X  k to denote any one of  X  i ,  X  j , u i and v j , where k represents either user i or item j . We note that replacing the precise E-step with a Monte Carlo average no longer guarantees an increase in the marginal likelihood at each step. If the Monte Carlo sampling error associated with  X  estimate of  X   X  new that is obtained from true E-step) is large rela-tive to ||  X  curr  X   X   X  new || , Monte Carlo E-step is wasteful since it is swamped by the Monte Carlo error. There are no rigorous solu-tion to this problem in the literature (especially when samples are dependent) except for some practical guidelines [9]. For instance, it is better to use fewer Monte Carlo simulations during early iter-ations. We performed extensive experiments with various schemes and found 30 EM iterations with 5 samples for the first 5 iterations, 20 for next 5 and 100 each for last 20 provides good performance in our applications.
 Algorithm 1 Monte-Carlo EM (MCEM) Algorithm Input: { y ij } , { X ij } and initial estimates of {  X  ij Output:  X   X  that maximizes Pr[ { y ij }|{ X ij } ,  X ] . 1: for t = 1 , ..., T do 2: E-step: Draw L samples of {  X  ij }|{ y ij } ,  X  curr using Gibbs 3: for ` = 1 , ..., L do 4: for each  X  k  X  X   X  i } X  X   X  j } X  X  u i } X  X  v j } do 5: Update  X  k drawn from N ( E [  X  k | Rest ] , Var [  X  k 6: end for 7: end for 8: Let  X   X  k and Var  X  (  X  k ) denote the empirical mean and vari-9: M-step: Find  X  that maximizes 10: for each of the five regression problems (see footnotes) do 11: Let (  X  k ,  X , f k , a ) denote the regression problem, where 12: Update  X  by regressing response  X   X  k using feature f 13: Let RSS and n be the residual sum of squares and the 14: Update a by ( RSS + 15: end for 16: end for M-step : In the M-step, we want to find  X  that maximizes E log[ { y ij }{  X  ij }|{ X ij } ,  X ] , where the expectation is taking over {  X  ij }|{ y ij } ,  X  curr . The major computation in the M-step involves regressing estimated averages {  X   X  k } from Monte-Carlo samples in E-step against features to get updated values of  X  . Here, one can use any off-the-shelf regression technique; we used a linear regres-sion with t -priors on the coefficient vectors that was recently pro-posed by [13] as mentioned in Section 2. In fact, the rationale behind adopting an EM instead of a fully Bayesian approach was to easily utilize a large number of effective methods that exist for conducting accurate and scalable linear regression. The details of M-step is given in Algorithm 1.
 Scalability: The MCEM is scalable and easily parallelizable. Let T denote the number of EM iterations and L denote the av-erage number of Gibbs samples we draw per iteration. Drawing each sample goes though all the data points 4 times (we have K observations). Thus, the total time complexity of all the E-steps is O ( KLT ) . In all of our experiments, LT in the order of a few thousands gives good result. Also note when drawing a sample users (items) are conditionally independent and draws could be made independently. For instance, the popularity parameters for users given other profiles are independent and can be sampled si-multaneously across users. This can speed up each Gibbs iteration by straightforward parallelization. Each M-step mainly consists of solving five standard linear regression problems. Any scalable lin-ear regression software can be used to achieve efficiency.
ICM Algorithm: ICM replaces the Gibbs sampling in the E-step by finding {  X  ij } that maximizes Pr[ {  X  ij }|{ y ij } , { X As noted in [24], this ignores uncertainty in the posterior of {  X  and is inferior to Gibbs sampling. It can be easily seen that to max-imize Pr [ {  X  ij }|{ y ij } , { X ij } ,  X  curr ] is to minimize the negative complete data log-likelihood  X  (as defined in Table 2) with respect to {  X  ij } . We implemented the ICM algorithm using the conjugate gradient (CG) descent method with gradients given in Table 2. A popular alternative is the gradient descent method; we found CG to be better and more automatic since gradient descent requires care-ful tweaking of learning rate parameter for each new application.
Comparison between MCEM and ICM In our experiments, we found that MCEM is better than ICM. The following table shows an example for MovieLens data (with 1M total ratings) where we fit our RLFM using both algorithms. The first half (based on time) of data is used for training and the root mean square errors of both methods on the test data (last half) are reported in the table. MCEM performs better since the Gibbs sampler explore the multi-modal posterior more efficiently than ICM. Also note that as the latent di-mension r increases, ICM starts to overfit, while MCEM is more resistant to over-fitting. Similar results were observed on other sim-ulated datasets.

We generalize our model to perform logistic regression through a variational approximation as discussed in [26]. The approxima-tion involves creating a new Gaussian response variable T variance  X  2 ij after each EM iteration. This is given by where  X  ij is the log-odds at the current estimated value of latent factors {  X  ij } .
It is common to have new items and/or users appear over time in applications. Moreover, systems are often dynamic and require temporal adaptation of parameters. One can adapt latent factors to such changes by giving more weight to recent data through an online learning process. We describe our batched online learning scheme below.

Assume the hyperparameters  X  have been estimated through large amount of training data; i.e., we assume  X  is fixed and only up-date the latent factors {  X  ij } . We also assume data is updated in a batched fashion. In general, updating model parameters for each observation is expensive; batched updates every few hours (or ev-ery few observations) are more reasonable.

At the end of our training phase, we run the Gibbs sampler for large number of iterations ( 200  X  500 ) and estimate the posterior mean and covariance of the latent factor each user and item. For each batch of observations received online, the current posterior becomes the prior and combined with the data likelihood provides the new updated posterior. However, computing the posterior accu-rately requires both mean and variance estimates; the latter requires a large number of Gibbs samples, making the method slow in online settings. We perform an approximation that only computes the pos-terior mode (ICM or small number of Gibbs sample) and combines with previous factors through an exponentially-weighted moving average (EWMA) to obtain the updated factors. The EWMA en-sures a stable estimate of the factors over time. In fact, we provide different EWMA weights to new and old user/items; old elements evolve much slower than the new ones in our model. After careful tweaking, we found EWMA weights of . 5 an . 99 on new and old elements performed well in our applicatons. For movie datasets, we updated batches of size 10K, for Yahoo! Frontpage we update a batch of 1K at a time. We denote this method by Dyn-RLFM .
We illustrate our methods on benchmark datasets (MovieLens and EachMovie) and on a novel recommender system that arises in the context of Yahoo! Front Page. We did not consider Netflix data since it does not provide user features; hence it is not a good example to illustrate our method. In fact, improving performance on Netflix is not the focus of this paper; our goal is to present a new methodology that provides effective predictions for large scale in-complete dyadic data by smoothly merging both cold-start (through features) and warm-start (through past interactions) situations into a single unified modeling framework. For movie datasets, we use RMSE (root mean square error) as the performance metric, this is popular in the movie recommendation domain. Note that even a 0.01 improvement in RMSE is significant (the top 40 competitors of the Netflix Prize have RMSE differences within 0.015). For Ya-hoo! data, we use ROC curves.

Methods: We evaluate our RLFM by comparing it with the fol-lowing methods: ZeroMean and FeatureOnly (described in Section 2.5) that are special cases of our model; MostPopular is a baseline method that recommends the most popular items in the training set to users in the test set; FilterBot [20] is a hybrid method designed to handle cold-start collaborative filtering. We used 13 bots (based on global popularity, movie genre and the popularity in each of the 11 user groups defined based on age and gender) coupled with an item-based algorithm [15]. Several other collaborative filtering al-gorithms (including pure item-item similarity, user-user similarity, regression-based) were also tried. Since FilterBot was uniformly better among these, we only report results for it.

MovieLens data : We conducted experiments on two MovieLens datasets: MovieLens-100K, which consists of 100 K ratings with 943 users and 1,682 movies, and MovieLens-1M, which consists of 1 M ratings with 6,040 users and 3,706 movies (although the readme file mentions 3,900 movies). User features used include age, gender, zipcode (we used the first digit only), occupation; item features include movie genre. MovieLens-100K comes with 5 pre-specified training-testing splits for 5-fold cross validation. We report the RMSEs of RLFM , ZeroMean and FeatureOnly on this dataset with r = 5 . We note that for this data, there are no new users and items in the test set; the gain obtained through RLFM relative to ZeroMean is entirely due to better regularization achieved through feature-based prior (see Figure 1 for an example). However, testing methods based on random splits may end up using the future to predict the past . This does not correspond to the real world scenario where the goal is to predict ratings for dyads that occur in the future. A more realistic training/test splitting should be based on time. Surprisingly, we did not find prior work in the movie recommendation literature that performs evaluation using a strict time-based split. For MovieLens-1M, we report results on more realistic time-based splits. We set aside the last 25% of ratings as the test data and train each model on three training sets, which consist of the first 30%, 60% and 75% of the ratings, respectively. The test-set RMSEs are reported in Table 3.

First, we see that the pure feature based model FeatureOnly has poor performance (although it is better than a constant model, hence features are weakly predictive), in fact the item popularity model is significantly better than FeatureOnly . The ZeroMean model out-performs all the existing collaborative filtering methods we experi-mented with. Our RLFM based on factors regularized through fea-tures and item popularity significantly outperforms all other static methods. A large fraction of dyads in the test set (almost 56 per-cent) involve new users (most of the items are old). By adaptively estimating factors for new users starting out from a feature based prior through our dynamic RLFM , we obtain significant boost in predictive accuracy over the static RLFM model.
 EachMovie data: The EachMovie dataset is similar to Movie-Lens but is far more noisy (RMSE for constant model is close to best models) with a large fraction of users missing one of more features. It contains 2,811,983 ratings with 72,916 users and 1,628 movies. We cleaned up this dataset by only including 2,559,107  X  X eal X  ratings (those with weights equal to 1) and then linearly scaled the ratings so that the ratings are from 0 to 5. We created training/test splits in the same way as the MovieLens case. The test-set RMSEs are reported in Table 3. Results are qualitatively similar to that of Movie-lens. The RLFM provides the best offline trained model, dynamic version of RLFM significantly outperforms all other methods.

Yahoo! Front Page (Y!FP) data: Our main motivating appli-cation is the Today Module on Yahoo! Front Page[3]. This module consists of four tabs (Featured, Entertainment, Sports and Video) and recommends four stories in the Featured tab for each user visit. Our goal is to develop algorithms that maximize the number of clicks by recommending  X  X asteful X  stories to each user. Stories in our application have short lifetimes (usually less than one day) and, for reasons of scalability, models can only be re-trained periodi-cally in an offline fashion. Hence, when a model trained offline is deployed, almost all stories (and large fraction of users) are new. Classical collaborative filtering algorithms that assume stories have some user ratings in the training set does not apply in this scenario. Models that can use both features and users X  past ratings are attrac-tive. We also note that we only have a few live items in the system at any given time, hence online updates of latent item factors is an attractive method to obtain good performance. A dataset, which we call Y!FP, was created to evaluate performance of our recom-mendation algorithms. This dataset consists of 1,909,525  X  X inary
Figure 3: ROC curves of different methods on Y!FP data ratings X  (clicks or views without any subsequent click) given by 30,635 frequent Yahoo! users (each has at least 30 ratings in 5 months) to 4,316 stories. User features include age, gender, geo-location and browsing behavior that are inferred based on a user X  X  network wide activity (search, ad-clicks, page views, subscriptions, etc.) on the Yahoo! portal. In fact, a user is assigned an intensity score in a few thousand content categories based on his/her activity pattern in the recent past; we reduced these to a few hundred fea-tures by conducting a principal components analysis on the training data. Item features consists of hand-labelled categories that are as-signed to a story by editors.

Results on Y!FP : Every model is significantly better than a model which predicts constant score for all examples (ROC curve for this model is a straight line). We note that almost all items that occur in the test set are new in this application. Hence for ZeroMean , the item factors (  X  j , v j ) are zero; the only contribution is from user popularity term  X  i . Thus, prediction based on user X  X  click propen-sity alone performs better than a pure feature-based model. The static RLFM model which exploits granular user profiles along with item features significantly outperforms the ZeroMean indicating pres-ence of strong user-item interactions in the data. As for other datasets, the dynamic version of RLFM that estimates item pro-files (  X  j , v j ) of new items in an online fashion is the most granular model and has the best performance.

Discussion of Experimental Results : In previous research on recommender systems, past interaction data has been found to be more predictive. We observed similar results in our experiments. Models purely based on features are inferior to those based on user-item specific statistics. That said, the features are predictive and when combined together with past interaction data through our model provides significant improvement in accuracy. Online updat-ing of factors is also important since most applications in practice are dynamic in nature. We believe future work in this area should evaluate algorithms using a time-based split to get a realistic esti-mate of an algorithm X  X  performance. Commonly used evaluation methods that do not use time-based split at best only provide per-formance indicators for persistent user-item dyads. Our RLFM is related to research in the following areas.

Latent Factor Models : Latent factor models for dyadic data have been studied extensively in the literature, a proper review of this field is not possible here. The factors could be discrete [16, 7, 4] or continuous [22, 17], our work falls in the latter category. In fact, we are related to SVD stype matrix factorization methods that have been been successfully applied to movie recommendation data (especially in the context of the Netflix competition, see [24, 23, 8, 1] for illustrations). However, none of these methods model fac-tors as function of features to address cold-start, nor do they model temporal variation in the factors. In fact, providing a principled modeling framework through hierarchical models that adds more flexibility to the factorization methods is the main contribution of our work.

Hierarchical Random Effects Model : Our method is related to the well studied area of hierarchical random effects models [12] in statistics. Such models provide a flexible framework to model complex processes, handle data sparseness, data imbalance and in-corporate excess heterogeneity. However, parameter identifiability and computational scalability present formidable challenges requir-ing novel research for different applications. The work that is most closely related to ours in this area are hierarchical Bayesian models that are used in marketing for studying consumer preferences for products[5]. These models assume latent user factors are modeled through regression as we do for u i  X  X  but there are no item factors in the model; instead, the interaction is captured u 0 i z the fixed feature vector for item j . A similar model was studied recently in [28] for recommender systems; however, their method is limited and did not consider features to model u i .

Collaborative Filtering : Models to address both cold-start and warm-start have been studied in collaborative filtering. Several hybrid methods that combine content and collaborative filtering techniques have been proposed. In [6], the authors X  present the first hybrid recommender system that computes user similarities based on content-based profiles. In [10], collaborative filtering and content-based filtering are combined linearly with weights adjusted based on absolute errors of the models. [14], [20] used filterbots to improve cold-start recommendations. A filterbot is an automated agent that rates items algorithmically, these are treated as additional users in a collaborative filtering system. [25] extends aspect model to combine item content and user ratings under a single probabilis-tic framework. Again, none of these simultaneously incorporate user features, item features, diverse response types, data imbalance, excess heterogeneity into a single modeling framework as RLFM .
We showed latent factor models with regression priors provide a flexible class of models for prediction with large scale dyadic data and significantly outperform existing state-of-the-art methods. In general, pure feature based models are weakly predictive but when combined with user-item centric models, they perform significantly better. Incorporating temporal variation substantially improves per-formance. Simulation based fitting algorithms like MCMC ex-plore the posterior space more efficiently and provide better per-formance. We are currently investigating sequential Monte Carlo techniques to perform efficient posterior computations in an online fashion. Our code will be submitted as R software package after completing our employer X  X  code releasing process. [1] KDD cup and workshop. 2007. [2] D. Agarwal, B.-C. Chen, and P. Elango. Spatio-temporal [3] D. Agarwal and B.-C. Chen, et al. Online models for content [4] D. Agarwal and S. Merugu. Predictive discrete latent factor [5] G. Allenby, P. Rossi, and R. McCulloch. Hierarchical bayes [6] M. Balabanovic and Y. Shoham. Fab: content-based, [7] A. Banerjee and I. Dhillon, et al. A generalized maximum [8] R. Bell, Y. Koren, and C. Volinsky. Modeling relationships at [9] J. Booth and J. Hobert. Maximizing generalized linear mixed [10] M. Claypool and A. Gokhale, et al. Combining [11] A. P. Dempster, N. M. Laird, and D. B. Rubin. Maximum [12] A. Gelman and J. Hill. Data Analysis using Regression and [13] A. Gelman and A. Jakulin, et al. A weakly informative [14] N. Good and J. B. Schafer, et al. Combining collaborative [15] J. L. Herlocker and J. A. Konstan, et al. An algorithmic [16] T. Hofmann. Probabilistic latent semantic indexing. In [17] D. L. Lee and S. Seung. Algorithms for non-negative matrix [18] P. McCullagh and J. A. Nelder. Generalized Linear Models . [19] R. Neal and G. Hinton. A view of the EM algorithm that [20] S.-T. Park and D. Pennock, et al. Na X ve filterbots for robust [21] C. Rasmussen and C. Williams. Gaussian Processes for [22] J. Rennie and N. Srebro. Fast maximum margin matrix [23] R. Salakhutdinov and A. Mnih. Bayesian probabilistic matrix [24] R. Salakhutdinov and A. Mnih. Probabilistic matrix [25] A. I. Schein and R. Popescul, et al. Methods and metrics for [26] A. I. Schein, L. K. Saul, and L. H. Ungar. A generalized [27] R. Smith. Bayesian and Frequentist Approaches to [28] Y. Zhang and J. Koren. Efficient bayesian hierarchical user
