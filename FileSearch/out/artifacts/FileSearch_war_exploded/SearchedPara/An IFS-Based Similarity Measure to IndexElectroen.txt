 An electroencephalogram ( EEG) captures the brain X  X  electric activity through several electrodes placed on the scalp 1 . The result is a multidimensional time series 2 . An EEG signal can be classified into several types of cerebral waves char-acterised by their frequencies, amplitudes, morphology, stability, topography and reactivity. The interpretation of the seq uence of cerebral waves, their localisa-tion and context of occurrence (eg ey es closed EEG or sleep EEG) leads to a diagnosis. The complexity of the sequen ces of cerebral waves, the non-specificity of EEG recordings (for example, with out any context being given, the EEG recording of a chewing artifact can be mi staken as that of a seizure (see figure 1)) and the amount of data generated make the interpretation process a difficult, time-consuming and error-prone one. Consequently, the interpretation process is being automated, in part at least, through several methods mostly consisting in extracting features from EEGs and applying classification algorithms to the sets of extracted features to discriminate bet ween two different patient states (usu-ally the  X  X ormal X  state and a pathological state). For example, empirical mode decomposition and Fourier-Bessel expansion are used in [13] to discriminate be-tween ictal EEGs (i.e EEGs of an epileptic seizure) and seizure-free EEGs. The interpretation methods are usually tested on different datasets. To make them comparable, a benchmark database of EEGs is required. Such a database has to designed so as to be able to handle queries in natural language such as the following sample queries: 1. find EEGs of non-convulsive status epilepticus 2. find EEGs showing rhythms associated with consumption of benzodiazepines Obtaining a simple answer to this set of queries would require the EEG dataset to be heavily and precisely annotated and tagged. But what if the annotations are scarce or not available? Furthermore, the whole process of annotating and tagging each and every sequence of the EEG dataset is time-consuming and error-prone. This means that feature extraction techniques are necessary to solve all of these queries since they can help define a set of clinical features representative of a particular pathology (query 1) or detect particular sets of patterns and process the EEG based on them (query 2). EEG r ecordings correspond to very diverse conditions ( eg.  X  X ormal X  state, seizure ep isodes, Alzheimer disease). Therefore, a generic method to index EEGs without having to deal with disease-specific features is required 3 . Generic methods to index time series often rely on the def-inition of a similarity measure. Some of the similarity measures proposed include a function interpolation step, be it piecewis e linear interpolation or interpolation with AR (as in [8] to distinguish between normal EEGs and EEGs originating from the injured brain undergoing transient global ischemia) or ARIMA models, that can followed by a feature extraction step (eg. computation of LPC cep-stral coefficients from the ARIMA model of the time series as in [9]). However, ARIMA/AR methods assume that the EEG signal is stationary, which is not a valid assumption. In fact, EEG signals can only be considered as stationary during short intervals, especially intervals of normal background activity, but the stationarity assumption does not hold during episodes of physical or men-tal activity, such as changes in alertness and wakefulness, during eye blinking and during transitions between various ictal states. Therefore, EEG signals are quasi-stationary. In view of that, we propose a similarity measure based on IFS interpolation to index EEGs in this paper, as fractal interpolation does not as-sume stationarity of the data and can adequately model complex structures. Moreover, using fractal interpolation makes computing features such as the frac-tal dimension simple (see theorem 21 for the link between fractal interpolation parameters and fractal dimension) and the fractal dimension of EEGs is known to be a relevant marker for some pathologies such as dementia (see [7]). 2.1 Fractal Interpolation Fractal dimension. Any given time series can be viewed as the observed data generated by an unknown manifold or attractor. One important property of this attractor is its fractal dimension. The fractal dimension of an attractor counts the effective number of degrees of freedom in the dynamical system and therefore quantifies its complexity. It can also be seen as the statistical quantity that gives an indication of how completely a fractal object appears to fill space, as one zooms down to finer and finer scales. Another dimension, called the topological dimension or Lebesgue Covering dimen sion, is also defined for any object and a fortiori for the attractor. A space has Lebesgue Covering dimension n if for every open cover 4 of that space, there is an open cover that refines it such that the refinement 5 has order at most n + 1. For example, the topological dimension of the Euclidean space R n is n . The attractor of a time series can be fractal (ie its fractal dimension is higher than its topological dimension) and is then called a strange attractor. The fractal dimension is generally a non-integer or fractional number. Typically, for a time series, the fractal dimension is comprised between 1 and 2 since the (topological) dimension of a plane is 2 and that of a line is 1. The fractal dimension has been used to:  X  uncover patterns in datasets and cluster data ([10,2,15])  X  analyse medical time series ([14,6]) such as EEGs ([1,7])  X  determine the number of features to be se lected from a datas et for a similarity Iterated function systems. We denote as K a compact metric space for which a distance function d is defined and as C ( K ) the space of continuous functions on K . We define over K a finite collection of mappings W = w i i  X  [1 ,n ] and their associated probabilities pi i  X  [1 ,n ] such that We also define an operator T on C ( K )as( Tf )( x )= n i =1 p i ( f  X  w i )( x ). If T maps C ( K ) into itself, then the pair ( w i ,pi ) is called an iterated function system on ( K ,d ). The condition on T is satisfied for any set of probabilities p i if the transformations w i are contracting, in other words, if, for any i ,thereexistsa  X  hyperbolic in this case.
 Principle of fractal interpolation. If we define a set of points ( x i ,F i )  X  R 2 : sponding to this set of points is a continuous function f :[ x 0 ,x n ]  X  R such that f ( x i )= F i for i  X  [0 ,n ]. In fractal interpolation, the interpolation function is often constructed with n affine maps of the form: where d i is constrained to satisfy:  X  1  X  d i  X  1. Furthermore, we have the following constraints: After determining the contraction parameter d i , we can estimate the four re-maining parameters (namely a i , c i , e i , f i ): d i can be determined using the geome trical approach given in [11]. Let t be a consecutive interpolation points so tha t the map parameter s desired are those defined for w p . We also define  X  as the maximum height of the entire function measured from the line connecting the end-points ( x 0 ,y 0 )and( x n ,y n )and  X  as the maximum height of the curve measured from the line connecting ( x p ,y p ) and ( x q ,y q ).  X  and  X  is positive (respectively negative) if the maximum value is reached above the line (respectively bel ow the line). The co ntraction factor d p is then defined as  X   X  . This procedure is also valid when the contraction factor is computed for an interval instead of for the whole function. The end-points are then taken as being the end-points of the interval. For more details on fractal interpolation, see [3,11].
 Estimation of the fractal dimension from a fractal interpolation. The theorem that links the fractal interpolation function and its fractal dimension is given in [3].The theorem is as follows: a set of points and R 2 ; w i ,i =1 , 2 , .., n an IFS associated with the set of points where: f i are defined as in section 2.1 (in equations 1,2,3 and 4) for i =1 , 2 , ..., n . We denote G the attractor of the IFS such that G is the graph of a fractal interpolation function associated with the set of points.

If n i =1 | d i | &gt; 1 and the interpolation points do not lie on a straight line, then the fractal dimension of G is the unique real solution D of i =1 | d i | a D  X  1 i =1 . 2.2 K-Medoid Clustering An m  X  m symmetric similarity matrix S can be associated to the EEGs to be indexed (with m being the number of EEGs to index): Given the computed similarity matrix S (defined by equation 5), we can use the k -medoids algorithm to cluster the EEGs. This algorithm requires the number of clusters k to be known. We describe our choice of the number of clusters below, in section 2.3. The k -medoids algorithm is similar to k -means and can be applied through the use of the EM algorithm. k random elements are, initially, chosen as representatives of the k clusters. At each iteration, a representative element of a cluster is replaced by a rando mly chosen nonrepresentative element of the cluster if the selected criterion ( e.g. mean-squared error) is improved by this choice. The data points are then rea ssigned to their closest cluster, given the new cluster representative elements. The iterations are stopped when no reassignments is possible. We use the PyCluster function kmedoids described in [5] to make our k -medoids clustering. 2.3 Choice of Number of Clusters The number of clusters in the dataset is estimated based on the similarity matrix obtained following the steps in section 3 and using the method described in [4]. The method described in [4] takes the s imilarity matrix and outputs a vector called envelope intensity associated to the similarity matrix. The number of distinct regions in the plot of the envelope intensity versus the index gives an estimation of the number of clusters. For details on how the envelope intensity vector is computed, see [4]. 3.1 Fractal Interpolation Step We interpolate each channel of each EEG (except the annotations channel) us-ing piecewise fractal interpolation. Fo r this purpose, we split each EEG channel into windows and then estimate the IFS for each window. The previous descrip-tion implies that a few parameters, namely the window size and therefore the embedding dimension, have to be determ ined before estimating the piecewise fractal interpolation function for each channel. The embedding dimension is de-termined thanks to Takens X  theorem which states that, for the attractor of a time series to be reconstructed correctly (i.e the same information content is found in the state (latent) and observation spaces), the embedding dimension denoted m satisfies : m&gt; 2 D +1 where D is the dimension of the attractor, in other words its fractal dimension. Since the fractal dimension of a time series is between 1 and 2, we can get a satisfactory embedding dimension as long as m&gt; 2  X  2 + 1 i.e m&gt; 5. We therefore choose an embedding dimension equal to 6. And we choose the lag  X  between different elements of the delay vector to be equal to the average duration of an EEG data record i.e 1s. Therefore, we split our EEGs in (non-overlapping) windows of 6 seconds. A standard 20-minutes EEG (which therefore contains about 1200 data records of 1 second) would then be split in about 200 windows of 6 seconds. Each window is subdivided into intervals of one second each and the end-points of these intervals are taken as interpolation points. This means there are 7 interpolation points per interval: the starting point p 0 of the window, the point one second away from p 0 ,the point two seconds from p 0 , the point three seconds away from p 0 ,thepointfour seconds away from p 0 , the point five seconds away from p 0 and the last point of the window. The algorithm 6 to compute the fractal interpolation function per windowisasfollows: 1. Choose, as an initial point, the starting point of the interval considered (the 2. Choose, as the end point of the interval considered, the next interpolation 3. Compute the contraction factor d for the interval considered. 4. If | d | &gt; 1goto2,otherwisegoto5. 5. Form the map w i associated with the interval considered. In other words, 6. Go to 2 until the end of the window is reached. 7. Store the interpolation points and contraction factor which yield the min-8. Repeat steps from 1 to 8 for each window of the EEG channel. 9. Apply steps 1 to 9 to all EEG channels. 3.2 Fractal Dimensions Estimation After this fractal interpolation step, each window of each signal is represented by 5 parameters instead of by signal frequency.window duration points. The dimension of the analysed time series is th erefore reduced in this step. For a stan-dard 20-minutes EEG containing 23 signals of frequency 250 Hz, this amounts to representing each signal with 1000 values instead 50000 and the whole EEG with 23000 values instead of 1150000, thus to reducing the number of signal values by almost 98%. This dimension reduction may be exploited in future work to compress EGGs and store compressed rep resentations of EEGs in the database instead of raw EEGs as the whole EEGs can be reconstructed from their fractal interpolations. Further work needs to be done on the compression of EEG data using fractal interpolation and the loss of information that may result from this compression. Then, for each EEG channel and for each window, we compute the fractal dimension thanks to theorem 21. The equation of theorem 21 is solved heuristically for each 6-second interval of each EEG signal using a bisection al-gorithm. As we know that the fractal dimension for a time series is between 1 and 2, we search a root of the equation of theorem 21 in the interval [1,2] and split the search interval by half at each iteration until the value of the root is approached by an -margin ( 7 being the admissible error on the desired root). Therefore, for each EEG channel, we have the same number of computed frac-tal dimensions as the number of windows. This feature extraction extraction step (fractal dimension computations) further reduces the dimensionality of the analysed time series. In fact, the number of values representing the time series is divided by 5 in this step. This leads to representing a standard 20-minute EEG containing 23 signals of frequency 250 Hz by 4600 values instead of the initial 1150000 points. 3.3 Similarity Matrix Computation We only compare EEGs that have at lea st a subset of identical channels (i.e having the same labels). When two EEGs don X  X  have any channels (except the annotations channel) in common, the similarity measure between them is set to 1 (as the farther (resp. closer) the dist ance between two EEGs, the higher (resp. lower) and the closer to 1 (resp. closer to 0) the similarity measure). If, for the two EEGs compared, the matching pairs of feature vectors (i.e vectors made of the fractal dimensions computed for each signal) do not have the same dimension then the vector of highest dimension is approximated by a histogram and the M most frequent values according to the histogram ( M being the dimension of the shortest vector) are taken as representatives of that vector and the distance between the two feature vectors is approx imated by the distance between the shortest feature vector and the vector formed with the M most frequent values of the longest vector. The similarity measure between two EEGs is given by: where N is the number of EEG channels, d ( ch EEG 1 i ,ch EEG 2 i ) the distance be-tween the fractal dimensions extracted from channels with the same label in the two EEGs compared and d min and d max respectively the minimum and maxi-mum distances between two EEGs in the analysed set. We choose as metrics ( d ) the Euclidean distance and the normalized mutual information. We interpolate (with fractal interpola tion, as described in section 3) 476 EEGs 8 whose durations range from 1 minute 50 seconds to 5 hours 21 minutes and whose sizes are between 1133KB and 138 MB. All signals in all these files have a frequency of 250Hz. Of the files used, 260 have a duration between 15 and 30 minutes (54.6%)-which is the most frequent duration range for EEGs-, 40 files (8.4%) a duration below 15 minutes and 176 files (37%) a duration higher than 30 minutes. Moreover, 386 files contain 23 signals (81.1 %), 63 20 signals (13.2 %), 13 19 signals (2.7 %), 7 25 signals (1.5 %), 3 28 signals (0.6 %), 1 12 signals (0.2 %), 2 13 signals (0.4 %) and 1 2 signals (0.2 %). The experiments were run on an openSuSe 10.3(x86-64) (kernel version 2.6.22.5-31) server (RAM 32GB, diagnosis conclusion is either unknown or known to be abnormal without any further details are not considered in the distance computation and clustering steps described in section 3. This mea ns that the distance computation and clustering steps are performed on a subset of 328 files of the original 476 files. The similarity matrice obtained is a 328  X  328 matrix . The files contained in the subset chosen for clustering can be separated in 4 classes: normal EEG (195 files i.e 59.5%), EEG of epilepsy(64 files i.e 19.5%), EEG of encephalopathy(31 files i.e 9.5%) and EEG of brain damage (vascular damage, infarct, or ischemia)(34 files i.e 10.4%). Figure 2 shows the plot of the envelope intensity versus the index for the euclidean-distance-based similarity measure and the plot of the envelope intensity versus the index for the mutual-information-based similarity measure. The plot for the Euclidean-distance based similarity matrix exhibits 2 distinct regions whereas the plot for the mutual-information based similarity matrix exhibits 4 distinct regions. We the refore cluster the data first in 2 different clusters using the Euclidean-based simila rity matrix and then in 4 clusters using the mutual-information based matrix. As we can see, the mutual information-based measure yields the correct number of clusters while the Euclidean distance-based similarity measure isn X  X  spread enough to yield the correct number of clusters. We compare the performance of the IFS-based similarity measure with an autoregressive (AR)-based similarity measure inspired from [9]:  X  An AR model is fitted to each of the signals of each of the EEG files consid- X  The LPC cepstrum coefficients are computed based on the AR model fitted  X  The Euclidean distance, as well as the mutual information between the com-Finally, we use the similarity matrices to cluster the EEGs (see Section 3.3). Figure 3 illustrates the relation between the duration of the EEG and the time it takes to interpolate EEGs. It shows that the increase of the fractal interpolation time with respect to the interpolated EEG X  X  duration is less than linear.
In comparison, AR modelling execution times increase almost linearly with the EEG duration. Therefore, fractal int erpolation is a scalable method and is more scalable than AR modelling. In particular, the execution times for files of durations between 15 and 30 minutes are between 8.8 seconds and 131.7 seconds, that is execution times between 6.8 to 204.5 times lower than the duration of the original EEGs. Furthermore, the method doesn X  X  impose any condition on the signals to be compared as it handles the cases where EEGs to be compared have no or limited common channels and have signals of different lengths. More-over, fractal interpolation doesn X  X  require model selection as AR modelling does, which considerably speeds up EEG interpolation. Moreover, with our dataset, the computation of the Euclidean dista nce between the cepstrum coefficients calculated based on the EEGs AR m odels leads to a matrix of NaN 9 :theAR modelling method is therefore less stable than the fractal interpolation-based method. Table 1 summarises the clustering results for all similarity matrices. The low sensitivity obtained for the abnormal EEGs (epilepsy,encephalopathy,brain damage) can be be explained through the following reasons:  X  most of the misclassified abnormal EEGs are EEGs representing mild forms  X  most of the misclassified abnormal EEGs (in particular for epilepsy and brain In this paper, we considered the problem of defining a similarity measure for EEGs that would be generic enough to cluster EEGs without having to build an exponential number of disease-specific classifiers. We use fractal interpolation followed by fractal dimension computation to define a similarity measure. Not only does the fractal interpolation provide a very compact representation of EEGs (which may be used later on to compr ess EEGs) but it also yields execution times that grow less than linearly with the EEG duration and is therefore a highly scalable method. It is a method that can compare EEGs of different lengths containing at least a common subset of channels. It also overcomes several of the shortcomings of an AR modelling-based measure as it doesn X  X  require model selection and is more stable and scalable than AR modelling-based measures. Furthermore, the mutual-information based measure is more sensitive to the correct number of clusters than the Euc lidean distance-based one. In future work, we will explore other entropy-base d measures. It was also shown that the shortcomings of the similarity measure when it comes to clustering abnormal EEGs can be overcome through pre-proce ssing the EEGs before interpolation to remove artifacts, tuning the weight parameters in the measure to account for small localised abnormalities and incorporating qualitative metadata knowledge to the measure. All those solutions constitute future work.
