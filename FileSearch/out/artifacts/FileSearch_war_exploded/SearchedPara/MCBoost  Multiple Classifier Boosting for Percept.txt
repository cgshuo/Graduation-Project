 discriminate the positive class from the negative class by H( x ) = vector,  X  are dependent on image clusters, requiring a concurrent clu stering of images and features. See Figure 1 for an example where subsets of face images are po se-wise obtained with associated The proposed method (Section 3) has potential for wide-appl ications in perceptual data exploration. It generally solves a new co -clustering problem of a data set (e.g. a set of face images) and a feature s et (e.g. simple visual features) in a way to maximise discrimination of the data set from another data set (e.g. a set of random images). T he method is also useful for object detection tasks. Boosting a classifier with simple features [3] is a state-of-the-art in object det ection tasks. It delivers high accuracy and is very time-efficient. Conven tionally, multiple boosting classifiers are separately learnt for mul tiple cate-gories and/or multiple views of object images [6]. It is, how ever, tedious to manually label category/pose for a large data set and, im-portantly, it is not clear to define object categories and sco pes of each pose. Would there be a better partitioning for learning mult iple boost-a set of weak-learners.
 and present our solution in Section 3. Experiments and concl usions are drawn in Section 4 and Section 5 respectively. ously clusters rows and columns of a co-occurrence table by e .g. maximising mutual information that we consider.
 phasises local experts and is suitable when input data can be naturally divided into homogeneous are limited for delivering a meaningful part-based represe ntation of images. classification problems but cannot solve XOR problems where only half the data can be correctly fiers, are required to conquer each half of data by a set of weak -learners. optimise image clusters and boosting classifiers simultane ously. of weak-learners as where  X  classifiers, we formulate Noisy-OR as where P learning.
 The sample weights are initialised by random partitioning o f positive samples, i.e. w and w w ki = 1 /K at t -th round of boosting, to maximise where h greatly reduced. The risk is defined as where N B class and the same class of x i (See Figure 3). The weak-learner weights  X  found to maximise J(H +  X  function J = log weight of k -th classifier over i -th sample is updated by See Figure 4 for the pseudocode of the proposed method. 3.1 Data clustering We propose a new data clustering method which assigns a posit ive sample x i to a classifier (or cluster) that has the highest P probability of k -th classifier P by the k -th classifier at next rounds (i.e. high P their expertise through the rounds of boosting. This can be i nterpreted as data partitioning. 3.2 Examples by weak-learners (step 5).
 desirably exhibits quicker convergence when a better initi alisation is given. 3.3 Discussion on mixture of experts and future work Anyboost framework. The sample probability in MoE is where Q the function Q fier is given as w and the update of Q does not use all experts.
 Useful future studies on the MCBoost method include develop ment of a method to automatically find right clusters, they exhibit convergence by decreasing the weak-learner weights. We performed experiments using a set of INRIA pedestrian dat a [10] and PIE face data [9]. The class in training and 589 pedestrian and 9030 random images i n testing. The pedestrian images show wide-variations in background, human pose and shapes, clothes and illuminations (Figure 6). 24 exploited.
 MCBoost learning was performed with the initial weights tha t were obtained by the k-means clus-20 within 50 boosting rounds.
 clusters seem to capture unique characteristics of the face images.
 We have also evaluated the proposed method in terms of classi fication accuracy. Figure 7 shows false-negative and false-positive curves of MCBoost metho d and AdaBoost method [7]. We set all number of classifiers K , MCBoost significantly outperformed AdaBoost method by find ing optimal with manual pose labels (bottom right).
 In the AdaBoost method, increasing number of clusters deteriorated the accuracy for the pedestrian data, whereas it increased the per-formance for the face data. This may be explained by the number of meaningful data clusters. We observed in Figure 6 that there are only three heterogenous pedestrian clusters while there are more than nine face clusters. In general, a smaller number of positive samples in each classifier (i.e. a larger K ) causes per-formance degradation, if it is not counteracted improve the accuracy for both data sets).
 number of 172,277 image patches to classify. Our method ran i n 3.6 seconds by non-optimised Matlab codes in a 3GHz CPU PC. We have introduced a discriminative co-clustering problem of images and visual features and have clustering method and pose-labels.
 on MCBoost method have also been discussed in Section 3.3. Le arning with a more exhaustive training set would improve the performance of the method in o bject detection tasks. Acknowledgements comments and suggestions. They include Z. Ghahramani, B. St enger, T. Woodley, O. Arandjelovic, Sussex College of the University of Cambridge.

