 We present a novel passage -based approach to re-ranking documents in an initially retrieved list so as to improve pre-cision at top ranks. While most work on passage-based doc-ument retrieval ranks a document based on the query sim-ilarity of its constituent passages, our approach leverages information about the centrality of the document passages with respect to the initial document list. Passage centrality is induced over a bipartite document-passage graph, wherein edge weights represent document-passage similarities. Em-pirical evaluation shows that our approach yields effective re-ranking performance. Furthermore, the performance is superior to that of previously proposed passage-based doc-ument ranking methods.
 Categories and Subject Descriptors: H.3.3 [Informa-tion Search and Retrieval]: Retrieval Models General Terms: Algorithms, Experimentation Keywords: passage-based document retrieval, passage lan-guage models, centrality, passage-document graphs
To improve precision at the top ranks of results returned in response to a query, resea rchers suggested to automat-ically re-rank the documents in an initially retrieved list [11, 7, 2, 4, 5]. Information induced from inter-document similarities is often used in these approaches. Specifically, document centrality , as measured by textual similarity to (many) other (central) documents in the initial list (or their clusters), was effectively utilized for re-ranking [4, 5].
An issue not accounted for in the re-ranking approaches just mentioned is that long and/or heterogeneous relevant documents may contain very few parts ( passages )thatper-tain to the query. Indeed, methods for ranking all docu-ments in a corpus, which utilize passage-query similarity information, were designed to address this issue [9, 1, 6].
We propose a novel approach to the re-ranking task that leverages insights from the two lines of work just described. We (re-)rank the documents in the initial list by utiliz-ing information about their constituent passages X  centrality with respect to the document list. Passage centrality is de-fined (using graph-based methods) in terms of similarity to (central) documents in the list  X  analogously to a cluster-We use the TREC corpora from Figure 1 for evaluation. The data is tokenized and Porter-stemmed using the Lemur toolkit (www.lemurproject.org), which is also used for lan-guage model induction. Topics X  titles are used for queries.
The list upon which re-ranking is performed, D init ,isset to the 50 documents in the corpus that are assigned the highest initial ranking score sim ( q, d ). (For the purpose of estimating sim ( q, d ), the document language model smooth-ing parameter,  X  , is set here and after to a value optimizing map@1000, as in some previous work on re-ranking [4, 5].) P G ( D init ) is the set of half overlapping window passages [1, 6] (of 150 terms) of the documents in D init .

For reference comparisons to our centrality-based meth-ods, we use DocBase  X  the initial ranking from which D init is derived, and two commonly used passage-based doc-ument ranking approaches [9, 1, 6]: PsgBase ,whichscores d scores d  X  X  init by  X  sim ( q, d )+(1  X   X  )max g i  X  d sim ( q, g i );  X  is a free interpolation para meter. (Note that PsgBase is a specific instance of InterPsgDoc with  X  =0.) We also explore a variant of Equation 1, denoted MultPsg-Doc , which uses passage-query similarity information in-stead of passage-centrality information for scoring d  X  X  init : sim ( q, d )max g
We use precision at the top 5 and 10 documents (p@5, p@10) and the mean reciprocal rank of the first relevant document (MRR) to evaluate the effectiveness of the re-ranking methods in improving precision at top ranks. The free parameters of the re-ranking methods are set to values optimizing p@5:  X  , the graph  X  X ut-degree X , is chosen from { 9 , 19 ,..., 99 } ,and  X  (in the InterPsgDoc algorithm) is se-lected from { 0 , 0 . 1 ,..., 1 } ;  X  is set to 2000 [12]. Statistically significant performance differences are determined using the Wilcoxon two-tailed test at a confidence level of 95%.
We can see in Figure 1 that our passage-centrality-based methods are effective in re-ranking the initial list. (Com-pare the performance of influx and authority with that of DocBase  X  the initial document ranking.) Furthermore, our centrality-based methods are superior in most relevant comparisons (corpus  X  evaluation measure) to the refer-ence comparisons that utilize passage-query similarity infor-mation (PsgBase, InterPsgDoc and MultPsgDoc); in many cases the performance differences are also statistically sig-nificant. In comparing the centrality-induction approaches (influx and authority), we see that none dominates the other; the performance differences between the two are not statis-tically significant.
