 Hamid Farvaresh, Mohammad Mehdi Sepehri n 1. Introduction
Telecommunication businesses are producing and storing a huge amount of data all over the world. These data are very interesting for data mining applications. The main feature of these great databases is their extraordinary size. More than 300 million records per day, for example, are stored in AT&amp;T solely for long-distance calls ( Cortes and Pregibon, 2001 ). Although these companies own a great source of information, only few of them are aware of the hidden knowledge of these databases. Thus, they do not use it frequently in their decision making processes.
A challenge that not only telecommunication companies but also other service institutions such as banks, water and energy suppliers, and credit companies confront is customers X  fraud detection. Fraud in telecom services causes a substantial loss of annual revenue for many telecommunication companies through-out the world ( Paredes, 2005; Xing and Girolami, 2007 ). There are different types of fraud in the telecommunication business ( Shawe-Taylor et al., 1999 ). Shawe-Taylor et al. (2000) present six different fraud types: subscription fraud, the manipulation of
Private Branch Exchange (PBX) facilities or dial through fraud, free phone fraud, premium rate service fraud, handset theft, and roaming fraud.

A common type of fraud is subscription fraud ( Estevez et al., 2006 ). Many companies offer lower tariffs for residential subscribers than for commercial ones. So customers may ask for residential subscription, but use it for commercial purposes. In wireline telephone service, identifying the subscription fraudu-lent customers is possible by checking the installation and usage place. However, identifying all fraudulent customers through checking all residential customers in companies like Telecommu-nication Company of Tehran (TCI), which has millions of residential customers, needs a lot of money and time. Therefore, reducing the number of customers to be checked is very demanding. This study intends to propose a method to detect different patterns of residential and commercial subscribers X  behaviors based on their call detail recording (CDR) and bills X  data in order to differentiate residential subscription, which have a behavior similar to fraudulent customers. We have tried to recognize the true subscription type with the highest accuracy.
Detecting subscription fraud can prevent a great part of telecommunication income loss.
 reviews the previous literature on the techniques for customers X  fraud detection. The proposed method is then described in
Section 3. In Section 4, a real dataset provided by Telecommuni-cation Company of Iran (hereinafter called TCI), is applied as a case study to demonstrate the effectiveness of the proposed method. Finally, concluding remarks are offered in Section 5. 2. Literature review companies to extract an accurate profile for each subscriber based on his/her CDR patterns. Subscribers X  profiles not only are useful for detecting abnormal behaviors but also mainly used for marketing purposes and customer relationship management (CRM) ( Sohn and Kim, 2008 ). These profiles are based on either
CDR (e.g., number of calls, call duration, call type) or subscriber demographic properties (e.g., age, gender, region) or both.
Generally speaking, customer fraud detection techniques divide customers into two groups of normal and fraudulent customers.
Many researchers studied customer fraud detection in telecom-munication companies using data mining techniques ( Barson et al., 1996; Fawcett and Provost, 1997; Shawe-Taylor et al., 1999 ). Detecting insolvent customers ( Ezawa, 1996; Daskalaki et al., 2003 ), detecting subscription fraud ( Cahill et al., 2002;
Cortes et al., 2003; Estevez et al., 2006 ), and detecting fax lines from telephone lines ( Kaplan et al., 1999 ) are some examples of recent studies.
 profile. Fraud detection in telecommunication business is mostly done for mobile services ( Buschkes et al., 1998; Gosset and
Hyland, 1999; Burge and Shawe-Taylor, 2001 ). Methods like rule mining ( Fawcett and Provost, 1997; Adomavicious and Tuzhilin, 1999 ), clustering ( Oh and Lee, 2003 ), Bayesian network ( Buschkes et al., 1998 ), neural network ( Manikopoulos and Papavassilliou, 2002; Daskalaki et al., 2003 ), latent Dirichlet allocation ( Xing and
Girolami, 2007 ), and decision tree ( Daskalaki et al., 2003 ) are some examples in this context. A comprehensive survey of data mining techniques applied to various fraud detection problems was presented in Phua et al. (2005) .
 classification problem that may be solved by various data mining techniques. These techniques vary in terms of statistical techni-ques (e.g., regression family techniques), artificial intelligence techniques (e.g., decision trees, neural networks), dimension reduction method (e.g., PCA, MDS), number of features included in the model, as well as feature-selection method (e.g., theory versus stepwise selection). In any case, a classifier should classify each customer into one of the two classes of normal or fraudulent customers. However, the major challenges in detecting telecom-munication fraud are: (1) to deal with the high volume of call traffic in an efficient manner; (2) to be effective at identifying small percentage calls which are fraudulent; and (3) to be done at a reasonably low cost ( Kou et al., 2004; Xing and Girolami, 2007 ). techniques is presented. It should be noted that due to space limitation technical and mathematical details of the methods are not presented here, and interested readers are referred to appropriate references. 2.1. Discriminant analysis (DA) and logistic regression (LR) with artificial intelligence and machine learning have been widely used to make classifiers ( Desai et al., 1996; Thomas, 2000; West, 2000 ). Linear discriminant analysis (LDA) is the oldest and most common statistical tool in handling classification problems ( Lee et al., 1999 ) that has been employed in fraud detection and credit scoring ( Desai et al., 1996; Daskalaki et al., 2003; Lee et al., 2006 ).
Reichert et al. (1983) mentioned two disadvantages for LDA: assuming (1) multivariate normality of metric independent variables and (2) homogeneous covariance matrix between categorical dependent variable (classes). However, since the independent variables are a mixture of categorical and continuous variables, the multivariate normality assumption will not hold. LR is another statistical method which is used in credit scoring models ( Laitinen and Laitinen, 2000; Westgaard and van der Wijst, 2001 ). The advantage of LR in comparison with LDA is that
LR does not make any assumption about the distribution of the independent variables. Furthermore, the result of classification is not in the YES/NO format, but is an estimated probability of each observation belonging to a given class, and is easy to interpret ( Timm, 2002 ). LR, however, has also some restricting assumptions which may not be always true. Homogeneous variance matrix between classes is an example in this regard ( McCulloch and
Searle, 2001 ). The interested reader is referred to several relevant references ( Sharma, 1996; Timm, 2002; Izenman, 2008 ). 2.2. Neural networks (NN)
Recently, NN has been widely used due to its ability for modeling complex and non-linear models, and also not having any strict limitations and rigorous assumption for the type of input data ( Stern, 1996; Anderson and Rosenfeld, 1998 ). As a negative aspect, on the other hand, one can mention long learning time, overfitting error, and black box characteristics of NN ( Bishop, 1995; Hippert et al., 2005 ). NN has also been used for telecommunication and bank customers X  credit scoring problem ( West, 2000; Lee et al., 2002; Mahlhotra and Malhotra, 2003;
Hsieh, 2005 ). For a comprehensive account of neural networks refer to ( Bishop, 1995 ). 2.3. Decision tree (DT)
C4.5 decision tree learning is one of the most widely used and practical methods for inductive inference. It is a method for classification that is robust to noisy data and capable of learning disjunctive expressions. Decision tree learning is a method for approximating discrete-valued functions, in which the learned function is represented by a decision tree. Learned trees can also be represented as sets of if X  X hen rules to improve human readability. Among rule based methods, DT models including
CART, ID3, and C4.5 have been used for customer classification, fraud detection, and customers X  credit scoring problems more than other methods ( Rosset et al., 1999; Shao et al., 2002;
Daskalaki et al., 2003; Lee et al., 2006 ). ID3 has been less used because of its categorical property. C4.5 has been recently introduced as a successful tool for customer classification due to its ability to handle continuous variables ( Wei and Chiu, 2002; Daskalaki et al., 2003; Hung et al., 2006; Chung and Suh, 2009 ).
An advantage of DT is that it does not have any limitations about data type, and, moreover, it represents the results in an under-standable format ( Ong et al., 2005 ). Nevertheless, DT and other rule based methods do not guarantee to cover the whole variable space. So it is possible to have a new instance which cannot be classified by any of the available rules. For more on decision tree (C4.5) see Quinlan (1993) .
 2.4. Support vector machines (SVM)
Much more recently, support vectors machines (SVM) have shown excellent generalization performance in a wide range of classification problems ( Coussement and Poel, 2008 ). In binary classification problems, SVM tries to find a linear optimal hyper-plane so that the margin of separation between positive and negative cases is maximized. This is done by solving a quadratic optimization problem in which only support vectors, i.e., the data points closest to the optimal hyper-plane, play a critical role. However, in practice, the data are not often linearly separable. In order to enhance the feasibility of the linear separation, the input space is transformed via a non-linear mapping into a higher dimensional feature space by using a kernel function ( Steinwart and Christmann, 2008 ). Coussement and Poel (2008) used SVM to predict churn subscription-services applications. Their results show that SVM has a good generalization performance when applied to noisy marketing data. They investigated the impor-tance of parameter setting on the performance of SVM in comparison with LR and random forests. Chen et al. (2006) employed SVM and NN to detect frauds in credit cards. Their results show the effectiveness of both methods. They also showed that when the data records are small, SVM can offer a better performance than NN does. Kim et al. (2003) proposed SVM ensembles with either bagging or boosting with aggregation methods for telecommunications subscription fraud. More details on SVM can be found in Steinwart and Christmann (2008) . 2.5. Semi-supervised learning
Telecommunication Company managers are often sure that commercial subscriptions are used for commercial purposes, but they cannot certainly say that residential subscriptions are only used for non-business purposes. Therefore, only one class of customers, the commercial ones, has been labeled accurately. Such classification problems, that there is no certainty about all instances labels, are called semi-supervised learning problems. Semi-supervised learning methods are criticized for making strong model assumptions ( Chapelle et al., 2006 ).

Kim et al. (2003) developed a five-step algorithm to detect fraud in datasets, which include labeled and unlabeled instances in a semi-supervised manner. First, a set of rules is randomly generated using algorithm Apriori , and the diversity of rules is increased by a calendar schema; secondly, rules are applied on the known legitimate transaction database, and any rule which matches this data will be discarded; thirdly, remaining rules are used to monitor the actual system, and again any rule detecting no anomalies will be discarded; fourth, rules detecting anomalies are replicated by adding tiny random mutations; and fifth, successful rules will be retained.

So far, there have been lots of comparisons among algorithms in order to find the most appropriate classification algorithm in the literature. Caruana and Niculescu-Mizil (2006) presented an extensive empirical comparison among ten supervised methods including: neural nets, decision trees, SVM, logistic regression, na X   X ve bayes, memory-based learning, random forests, bagged trees, boosted trees, and boosted sumps. They used a variety of performance criteria to evaluate the learning and generalization capabilities of the mentioned methods. Their results show a relative superiority of some methods in terms of some criteria. According to Wolpert X  X  studies and  X  X  X o-free-Lunch X  X  theorem ( Wolpert and Macready, 1997 ), we came to the conclusion that there is no perfect algorithm or technique for classification problems. Problem context, the way models parameters are adjusted, and presumptions about model input data are basic criteria that cause an algorithm to perform better in a case than it does in the others. Therefore, it is rational to employ various methods and select the most appropriate ones. 3. Research methodology
As it was mentioned previously, our problem is a classification problem. Thus, we propose an applicable framework for sub-scription fraud detection in telecommunication business based on CDR and bills data.

Our proposed process has three phases ( Fig. 1 ). The first phase is preprocessing which includes data preparation, cleaning, transformation, and dimension reduction. After that, both supervised and unsupervised learning methods are applied. In the unsupervised learning phase, preprocessed data is clustered with a hybrid clustering algorithm, and outliers are removed. It is expected that some clues from clustering towards subscription fraud detection will be identified. Therefore, findings of the unsupervised learning will be used as inputs to the supervised learning. Specifically, we add three new features to the dataset based on the clustering results. The third phase is supervised learning in which classifiers will classify the resulted data obtained from the previous phases into commercial or residential classes. We examine many potential classifiers to achieve the most appropriate models. In the following section each part will be discussed in detail. 3.1. Data preprocessing phase
Much of the raw data contained in databases are unprepro-cessed, incomplete, and noisy. The databases may contain features that are obsolete or redundant, missing values, outliers, and data in a form not suitable for data mining models. Therefore, data should be preprocessed in order to help improve the quality of the data and mining results, and improve the efficiency and ease of the mining process with respect to time, cost, and quality.
Data preprocessing consists of (1) data cleaning, a method for fixing missing values, outliers, and possible inconsistent data; (2) data integration, the union of (possibly heterogeneous) data coming from different sources into a unique data store; and (3) data dimensionality reduction, the process of reducing the number of features under consideration ( Cios et al., 2007 ).
High dimensionality might increase learning time, reduce generality in learning, and put the model at risk of overfitting. Telecommunication datasets have a large number of features.
There are a variety of benefits to dimensionality reduction. The key benefits are ( Tan et al., 2006 ): (a) most data mining algorithms work better if dimensionality  X  the number of attributes in the data  X  is lower. This is partly because dimensionality reduction can eliminate irrelevant features and reduce noise, and partly because of the curse of dimensionality. (b) Reduction of dimensionality can lead to a more under-standable model because the model may involve fewer attributes. (c) The time and memory required by the data mining algorithm is reduced with a reduction in dimensionality.

Principal components analysis (PCA) is a linear algebra technique that finds new features (PCs) that (1) are linear combinations of the original features, (2) are orthogonal to each other, and (3) capture the maximum amount of variation in data ( Johnson and Wichern, 2002 ). The justifications for using PCA as a dimension reduction technique in the present paper include the followings: (1) PCA has been successfully employed in similar cases as well as in customer classification models ( Hilas and
Mastorocostas, 2008; Sohn and Kim, 2008 ), (2) the main objective of this study is to create an accurate classifier for detecting subscription fraud, and (3) we do not want to assign label or interpret new features. 3.2. Unsupervised learning phase cluster is rather far from other clusters, or has very specific characters, or is an outlier cluster, it will be discarded in this phase because it may decrease the accuracy of the classifier ( Han and Kamber, 2006 ).
 clusters ( Han et al., 2002 ). However, choosing an initial point and the number of clusters are the main challenges of K-means algorithm which highly affect the performance of the algorithm. In the previous studies, hierarchical algorithms, and especially Ward algorithm, were used to overcome this challenge ( Punj and
Steward, 1983 ). Kuo et al. (2002) claimed that if K-means parameters (initial points and number of clusters) are adjusted properly, then clustering results are much better than those of other algorithms. Hsieh (2005) preferred self-organizing maps (SOM) to hierarchical algorithms for determining cluster centers and number of clusters. Kiang et al. (2006, 2007) reviewed the pros and cons of SOM and K-means in the literature. They claimed that these two algorithms can compensate each others X  weak-nesses and improve their strengths. So we use SOM in this study for determining initial centers and the number of clusters. We also practically show the advantages of using these two algorithms together.

As shown in Fig. 1 , SOM will use preprocessed data to produce primal clusters. After determining the number of clusters and the centers of initial clusters, K-means will produce final clusters from primal ones. Since SOM map is rather large with a great number of neurons, it is not easy to determine the number of clusters precisely. So some rational scenarios based on SOM results should be defined. Such scenarios should be evaluated by cluster validity indices like Dunne ( Dunn, 1976; Pal and Biswas, 1997; Garcia and Gonza  X  lez, 2004 ) and Davies X  X ouldin ( Davies and Bouldin, 1979; Garcia and Gonza  X  lez, 2004 ) indices. These indices validate compact clusters which are distinctly separated.
When Davies X  X ouldin index is minimized, and Dunne index is maximized, we have the best possible clusters. It should be noted that the data which are used in this phase have no commercial/ residential class label.

The main objective of this phase is to remove outliers and introduce new features in order to keep clusters properties for the classification phase. Since three new features are defined in order to keep the learning obtained from the clustering results, we call this method memorized clustering. The assumption is that telecommunication data can reflect the different patterns of behavior of residential and commercial subscribers. Since cluster-ing is done by unlabeled data, we expect that the results reveal inherent patterns in the data. If there is any inherent distinct pattern among subscribers, then most of the customers who belong to the same cluster have some similarities, and particularly have similar type of subscription. However, this is not a 100% accurate rule. Using new features prevents the obtained learning from the unsupervised learning phase to be neglected. The new features are cluster membership (clus-no) as a categorical type feature, distance from cluster center (dist_clus_cent), and distance from center of the whole data (dist_cent) as continuous features. In some clusters, commercial subscriber class is at majority while in some other clusters the residential cluster holds the majority. Clus_no represents some sort of similarity for members of a specific cluster while it shows dissimilarity for members of two different clusters. Dist_clust_cent represents intra-cluster simi-larity, i.e., the relative position of records in its related cluster. Dist_cent shows inter-cluster similarities and differences, i.e., the relationship between records from different clusters. This means that records from the same clusters are more similar to each other, and have the greatest difference from other clusters members. 3.3. Supervised learning phase and performance evaluation
To increase model accuracy to distinguish a different sub-scription behavioral pattern, we use supervised learning algo-rithm with a predefined commercial/residential label for a sample of subscribers. There are many studies that recommend single classifiers like NN, DT, SVM, and other learning methods ( Daskalaki et al., 2003; Hung et al., 2006; Coussement and Poel, 2008; Hilas and Mastorocostas, 2008 ). There are also some good empirical evaluations that strongly support ensemble methods ( Kim et al., 2003; Caruana and Niculescu-Mizil, 2006 ).
The basic idea of constructing ensembles is to train multiple classifiers from the original data and then aggregate their learning when classifying unknown examples. The ensemble of classifiers can be constructed in many ways: (1) by manipulating the training set (e.g., bagging and boosting), (2) by manipulating the input features (e.g., random forests), (3) by manipulating the class labels (e.g., error-correcting output coding), (4) by employing a meta-level learning on output of multiple base classifiers (stacking), and (5) by voting among classifiers (majority and consensus voting). Researchers have noted that much of the power of ensemble methods comes from the diversity among base classifiers, which reduces the variance of ensemble models ( Bauer and Kohavi, 1999; Kim, 2009 ). More specifically, an ensemble model generalizes well by combining base classifiers that make errors on different parts of feature subspaces. The effectiveness of bagging and boosting can be explained based on the bias-variance decomposition of classification error ( Bauer and Kohavi, 1999 ).

Two of the most popular ensemble algorithms are bagging ( Breiman, 1996 ) and boosting ( Freund and Schapire, 1996 ). There are two major differences between bagging and boosting. Firstly, boosting changes adaptively the distribution of the training set based on the performance of previously created classifiers while bagging changes the distribution of the training set stochastically. Secondly, boosting uses a function of the performance of classifiers as a weight for voting, while bagging uses equal weight voting. Boosting algorithms are considered stronger than bagging on noise-free data; however, bagging is much more robust than boosting in noisy settings ( Kotsianti and Pintelas, 2004 ). Inter-ested readers are referred to Tan et al. (2006) and Hastie et al. (2009) for more detail.

We tried to examine both single and ensemble classifiers. At the first step, three most recommended methods including NN,
DT, and SVM are trained individually. Their performances are evaluated and compared by statistical tests. The best trained individual classifiers are preserved for contributing on stacking and voting ensembles. At the second step, constructing ensembles using NN, DT, and SVM will be accomplished. Bagging and boosting ensembles using DT and NN as base classifiers are created. A stacking ensemble (meta-learner) is also created based on the best gained DT, NN, and SVM classifiers. Additionally, the output of each individual classifier is used to build voting ensembles by employing both majority and consensus voting strategies. The performance of all ensembles is evaluated based on various metrics and compared by statistical tests.
For evaluating the performance of classifiers, it is essential to use an estimation method with low bias and variance. Kohavi (1995) performed an extensive empirical study to compare the performance metrics obtained using different estimation methods such as random sub-sampling, bootstrapping, and k-fold cross-validation. His results suggest that the best estimation method is based on the 10-fold stratified cross-validation. Furthermore, the different performance metrics measure different tradeoffs in the predictions made by a classifier, and it is possible for learning methods to perform well on one metric, but be suboptimal on other metrics. Caruana and Niculescu-Mizil (2006) divided performance metrics into three groups: threshold metrics, ordering/rank metrics, and probability metrics. We choose metrics from threshold and ordering groups, namely accuracy,
F -score and lift as threshold metrics, and area under the ROC curve (AUC) as an ordering metric. The third group is more appropriate for prediction problems rather than classification ones. Recall and precision are two widely used metrics employed in applications where successful detection of one of the classes is considered more significant than detection of the other classes.
Precision and recall can be summarized into another metric known as the F -score. AUC does not depend on a threshold, and is, therefore, a better overall evaluation metric compared to accuracy. Lift is very much related to accuracy, but has the advantage of being well used in marketing practice ( Burez and Poel, 2009 ). Interested readers are referred to Caruana and
Niculescu-Mizil (2004) and Tan et al. (2006) for a more detailed description of the performance metrics. 4. Case study: Tehran telecommunication subscribers
In this section we run our methodology and examine potential algorithms with real data from TCI in Tehran. TCI in Tehran had approximately 6,500,000 wireline telephone subscribers by the end of 2009. TCI provided us a sample of 25,000 subscribers who are randomly selected from different zones of the city. The dataset includes data from 8 two-month periods. The whole data set covers the following information: Customer attributes, e.g. name, family name, age, gender; call detail records, e.g. the detail of all calls that each customer had made during that period; financial information of the bill, e.g. cost, customer X  X  debt, due date, date of payment. 4.1. Data preprocessing
After gathering and integrating data in a single table, records containing missing values were deleted. New features (see
Appendix A) were defined based on CDR and bill X  X  data. Features were calculated based on customer behavior in the form of periodical mean, moving average, and other statistical measures.
Some of these features include short distance calls, long distance calls, mobile calls, and international calls. It should be noted that one of these 56 features for each record was its class label which was a binary code. Due to class imbalance problem and high dimensionality, data reduction should be done in two ways. The first one is reducing the number of records that is called instant selection. The second one is reducing the number of features by means of PCA and selecting the best new explanatory features (PC X  X ).
 reduced to 16,855 records including 9846 commercial and 7009 non-commercial subscribers. As it was mentioned before, in our case commercial subscriptions were used for commercial pur-poses; but, we were not sure whether all residential subscriptions were only used for homes or not. TCI was requested to provide the true label for a set of records among 7009 non-commercial subscribers whose actual labels were residential. TCI labeled, given its time and personnel limitations, 1084 subscribers (out of 7009 non-commercial subscribers) as residential subscribers.
They also found that 31 residential subscribers used their line for commercial purposes. Since the true label is obtained by checking the installation place, it is very costly to provide an adequate set of true labeled fraudulent cases. Due to the scarcity of fraudulent cases, it is neither possible to buildup accurate models based on the fraudulent and non-fraudulent cases (common approach) nor to use this small number of fraudulent cases in model training along with true labeled commercial and residential subscriptions. Therefore, as stated before, we train our models based on true labeled commercial/residential cases to find residential customers with behaviors like commercial ones. Now, there is a dataset comprised of 3252 true labeled records. that belong to commercial/residential classes. Because the class distribution is skewed toward commercial class, this, however, would imperil the resulting learning effectiveness and might result in a biased classifier that simply classifies all records as having the majority class as the training dataset ( Weiss, 2004 ).
Sampling is the most used method for handling the class imbalance problem ( Weiss, 2004 ). The main idea of sampling is to modify the distribution of instances so that the rare class is well represented in the training set. Some of the available techniques for sampling include under-sampling (discard major-ity-class cases), over-sampling (duplicate minority-class cases), and a combination of both approaches in order to achieve the desired class ratio in training dataset. These sampling methods do, however, have several drawbacks ( Weiss, 2004 ). Burez and Poel (2009) investigations show that under-sampling can lead to improved prediction accuracy, especially when classifiers are evaluated with the area under ROC curve.
 population is skewed toward commercial class, (b) balancing classes with a 1:1 ratio may lead to a high false commercial rate classifier which classifies non-fraudulent customers as fraudulent, and (c) in over-sampling no new information is added to sample, balancing the classes with a 1:1 ratio is not done (conservatory) and classes X  distribution in learning dataset adjusted with a 1:2 ratio in favor of the commercial class. To sum up, we prepared a dataset comprised of 3252 records which included 1084 and 2168 customers in residential and commercial classes, respectively. Each record of customers had 56 features (see Appendix A). records showed a high correlation among features. P -value of
Bartlett test was less than 0.001. Hence, the features correlation matrix was non-identity ( Timm, 2002 ). Furthermore, the KMO index was 0.917 for our case. This also showed high correlation among features. This evidence allowed us to use PCA as a dimension reduction technique. We used PCA to produce independent new features. PCA reduced input features from 55 to 24 features against losing about %11.14 of variances. At the end of this phase, a training dataset comprised of 3252 records with 25 features (24+1) was prepared. The last feature was the class label. 4.2. Unsupervised learning We set topologic properties of SOM based on ( Garcia and
Gonza  X  lez, 2004 ) results. A network of 280 neurons in the form of a 14 20 rectangle was designed. We compared three clustering scenarios with each other: SOM, K-means, and a hybrid of SOM and K-means. Then we calculated Davies-Bouldin (hereafter called DB index) and Dunne indices for each of the scenarios to evaluate the quality of clustering. Table 1 shows the results of
SOM, K-means, and hybrid of SOM and K-means in separate columns. DB and Dunne indices show that the hybrid of SOM and
K-means has the best clustering results. Fig. 2 visualizes all cases and an approximate boundary of resulted clustering from SOM and K-means hybrid using the first and second principal components.

The clustering results demonstrate that commercial and residential subscribers were not completely separated into different clusters. In the best clustering model selected according to DB and Dunne indices (hybrid of SOM and K-means), the ratio of commercial to residential was maximum in the first cluster and minimum in the second one. Therefore, cluster number 1 mostly reflected the behavior of commercial customers while cluster number 2 represented residential ones to a large extent.
Commercial population in cluster number 3 is higher than those of the residential ones. But cluster number 4 and 5 are completely different from the other clusters. Since the ratio of commercial to residential is close to the value of this ratio in original dataset, these clusters are considered inconsistent clusters and we cannot, therefore, label them. Further investiga-tion is needed to be carried out on these customers in order to provide an accurate profile for them. Cluster number 6 had 98 records where 69 records are commercial and 29 records are residential. According to Fig. 2 and also computed Euclidian distance between the centers of the clusters, the special point about cluster number 6 is that records of cluster 6 are located far away from the rest of the data and do not appear to fit the pattern of the other data values. We concluded that this is an outlier cluster. It should be noted that outlier cluster has a different meaning from single outlier. More specifically, an outlier cluster may contain records which may seem unusual with respect to other clusters X  records but not with respect to records in its local neighborhood. It should also be noted that records of cluster 6 are different from gross errors which include human or mechanical errors. We removed most of the outliers and gross errors in the preparation phase. Since an outlier cluster can create tremendous distortion in the classifiers, removing the records of this cluster from our sample data could improve classification results. It will be experimentally investigated in next section. Since cluster 6 deviates from the pattern(s) suggested by the majority of the data, we recommend that these records be excluded from data set.
However, if one is interested in classifying these cases into residential/commercial classes, it is better to do more investiga-tions and build separate classifiers to specifically learn outlier cluster X  X  patterns. Indeed, in this case clustering is used to detect very special clusters.

Because PCA is heavily influenced when there are outliers in the data ( Izenman, 2008 ), we recalculate principal components after removing outliers and update the dataset. As a result, PCA reduced input features from 55 to 24 features against losing only 8.23% of variances which shows approximately 3% improvement in the total explained variance at the same dimensions. 4.3. Supervised learning
After clustering, as it was mentioned previously, we added 3 new features based on the clustering results to our dataset. Hence, 3154 records with 28 (24+1+3) features will be classified by single and ensemble classifiers. We also compare the classification results of using the dataset with three new features with those obtained from the dataset without these three new features. As mentioned before, in this study, a 10-fold stratified cross-validation is employed as the evaluating method. In a stratified cross-validation, folds are stratified so that they contain approximately the same proportions of classes as the original dataset. We stratify folds based on clustering results. In fact, instead of stratifying folds based on classes solely, stratification is done based on class distribution in clusters. More clearly, in each fold a proportionate number of cases of commercial and residential subscribers will be presented from 5 clusters. 4.3.1. Parameter setting
It was tried to explore the space of parameters of learning algorithms as thoroughly as is computationally possible. The parameter setting used for DT, NN, and SVM and ensembles are summarized as follows:
DT : Previous research has shown that pruning can make a substantial difference in algorithm performance ( Quinlan, 1993 ). The C4.5 algorithm is implemented with and without pruning option. Therefore, when DT is trained, pruning using a confidence level of 0.10 will be used. Both pruned and unpruned DT for bagging and boosting ensembles will also be tested.

NN : In order to find the appropriate NN architecture and its learning algorithms and parameters, we tried to use a systematic search. Three NN types including linear, multi layer perceptron (MLP) (3-layers MLP and 4-layers MLP), and radial basis function (RBF) were considered. To find the proper number of neurons on each hidden layer, 2 X 28 neurons for MLP and 1 X 10 neurons for
RBF were tested. Furthermore, the learning rate from 0.01 to 0.15 with step 0.01 and the momentum from 0.15 to 0.4 with step 0.05 were tested. NN training was accomplished in two phases. In the first phase NN was trained by back-propagation, and in the second phase it was trained by conjugate gradient descent or Levenberg X 
Marquardt algorithms. Totally, over 3000 different alternative networks were tested to find the best network architecture and parameters.

SVM : The two important steps in the implementation of SVM include scaling and kernel selection. In the current study, the values of all features are linearly scaled to the range [1,+1] to prevent domination of features with high numeric value range over those with low numeric value range. The linear, polynomial degree 2, radial with width {0.001, 0.005, 0.01, 0.5, 1, 2} kernel functions is tested. We also change the regularization parameter by factors of ten from 10 5 to 10 2 with each kernel.
Bagging : The number of base classifiers in bagging affects the prediction performance. Therefore, three different ensemble sizes 25, 50, and 100 are considered. Bagging and boosting are strongly recommended for non-parametric classifiers such as DT and ANN ( Kim, 2009 ). This is mainly because these classifiers tend to have a bigger component of model variance and, hence, can significantly benefit from ensembles. Since SVM is a relatively stable classifier, it is not used in bagging and boosting ensembles. Previous studies do not recommend SVM ensembles due to lower or only marginally better performance than its single classifier at extra computational costs ( Kim, 2009 ).

Boosting : Adaboost.M1 strategy is used. Furthermore, ensem-bles of at most 100 classifiers are constructed. Despite this fact, if the Adaboost.M1 algorithm terminated early due to having weighted error greater than 0.5 or unweighted error equal to zero, then a smaller ensemble is necessarily used.

Stacked generalization : Na X   X ve Bayes (NB) and multi-response linear regression algorithm (MLR) ( Ting and Witten, 1999 ) are tested as meta-learners. We also test two situations for the inputs of meta-learner algorithm, specifically the binary class label and the posterior probabilities obtained from DT, NN, and SVM.
Using the probabilities has the advantage of capturing not only the predictions of the base-level classifiers (DT, NN, and SVM), but also their certainty. Since the SVM is not designed to predict probabilities, Platt X  X  method ( Platt, 1999 ) is used to transform the predictions to posterior probabilities by passing them through a sigmoid.

Voting : In contrast to stacking, no learning takes place at the meta-level when combining classifiers by a voting scheme. Two kinds of voting are employed: (a) consensus voting and (b) majority voting. In consensus voting, the ensemble only classifies a record as commercial class if all the three individual classifiers identify it as commercial customer, whereas in majority voting the ensemble classifies records based on the major class resulted from the three individual classifiers. Consensus voting is a more conservative approach than the widely used majority voting is. 4.3.2. Classification with/without using clustering features without using the three constructed features based on clustering results. We estimate 95% confidence intervals for true accuracy of each single classifier using approximated normal test ( Tan et al., 2006 ). Table 2 shows the performance of single classifiers in both conditions. Results are presented in terms of confusion matrix, overall accuracy, F -score, lift, AUC and 95% confidence intervals for accuracy. Since the performance of C4.5 with pruning was better than that of C4.5 without pruning in all experiments, only the result of C4.5 with pruning is reported. The best NN network architecture for this study was a 4-layer feed-forward network which had 27, 20, 20, and 1 neurons in each layer, respectively, with resilient back-propagation algorithm as a training algorithm.
NN with resilient back propagation dramatically converges sooner than other algorithms. These results were also confirmed by
Riedmiller (1997) .As Table 2 shows, SVM has the best performance across all metrics except for F -score. DT is the second best model in terms of all metrics. NN in both conditions has inferior performance relative to DT and SVM according to all metrics. The highest value for metrics is printed in bold, and the lowest value for metrics is italicised in Table 2 . In summary, DT,
NN, and SVM, as single classifiers are able to correctly classify 88.1%, 84.9%, and 88.2% of customers, respectively. The values of the lift metric show that DT, NN, and SVM classify records 2.430, 2.249, and 2.432 times, respectively, better than a random classifier (e.g. classifying by tossing up a coin). The narrow estimated 95% confidence intervals show a good stability of all classifiers. It may be due to good parameter setting and tuning. detect fraudulent customers, the results recommend using SVM which has 88.2% overall classification accuracy, 9.67% false rate in commercial customer and 16.11% false rate in residential customers classification. It means that if the SVM classifier used for the subscription fraud use, the model labels 16.11% of residential customers as commercial customers unfairly. This is not so favorable in the customer relationship management context since no customer wants to be unfairly classified as fraudulent. In contrast, although classifying 9.67% of commercial customers as residential could damage the company incomes, it does not contradict having a respectful relation with customers.
To investigate the negative effects of the outlier cluster 6 on classifiers performance, we trained and evaluated DT, NN, and
SVM with dataset which includes records of cluster 6. The overall accuracy of DT, NN, and SVM reduced to 85.57%, 81.04%, and 85.32%, respectively. This result confirms that despite of its small number of records, the outlier cluster 6 make a tremendous distortion in all classifiers. Indeed cluster 6 deviates from the pattern(s) suggested by the majority of the data and using them in training process leads to biased classifiers. 4.3.3. Comparing the performance of models with and without using clustering features Our goal is to test whether the observed difference between
DT, NN, and SVM with and without using features constructed based on clustering results is statistically significant. Therefore, the performance of each model in these two cases is statistically compared pair-wisely. To do that, confidence intervals for true difference of model performance in two cases on a 0.05 level of significance are estimated using paired t -test. Indeed, we provide 95% confidence intervals for the observed difference between the accuracy of each single classifier in two conditions. If confidence intervals do not include zero, then the test concludes that there is a significant difference in performance between two conditions in which algorithms is trained. The 95% confidence intervals are (0.0016, 0.0339), ( 0.0019, 0.0336), and (0.0031, 0.0356) for DT, NN, and SVM, respectively. Since the corresponding intervals of
DT and SVM do not cover zero, it means that adding constructed features based on clustering results significantly improves the accuracy of DT and SVM. Accordingly, at the 0.05 level of significance no significant difference between NN accuracy with and without the mentioned features is seen.

Besides overall accuracy, adding 3 new features based on clustering results improved all other metrics of DT and SVM. The
F -score, lift, and AUC of DT increased from 0.803, 2.334, and 0.859 to 0.826, 2.430, and 0.885, respectively. These measures for SVM increased from 0.799, 2.339, and 0.877 to 0.826, 2.432, and 0.893, respectively. Although adding 3 new features do not improve the overall accuracy of NN, but it was very interesting to see that while the number of features increased, NN X  X  convergence time reduced. On average, NN converges in 112 s and 295 epochs, while with new features NN converges in 103 s and 255 epochs. This calculation was done by a 2.0 GHz Core 2 Duo CPU with 2 GB of RAM. 4.3.4. Classification with ensembles
Our experimental results show that all stacking, bagging, and boosting ensemble models have a superior performance (mea-sured by various metrics) than their corresponding single classifiers; however, the degree of improvement was dependent on the type of classifiers. Furthermore, ensemble models were more robust than single classifiers by reducing the variance of the single classifier. These characteristics of ensembles are very desirable for business managers. However, ensembles require more computing resources and are less scalable. Another weak-ness of ensemble models is they are not easy to interpret. Due to tree structure and if X  X hen rules, for example, DTs have been well adopted for many business applications. Conversely, outputs of DT ensembles are not easy to understand because there are multiple sets of rules coming from each base tree learners.
We report the results of classifiers with the best performance in terms of the four mentioned evaluation metrics for each ensemble type. Table 3 presents the performance of ensemble models. Boosted trees model has the best performance in terms of all metrics. Bagged trees model is the second best model in terms of accuracy, F -score, and AUC metrics followed by stacked generalization, boosted NN, bagged NN, majority voting, and consensus voting. There is a significant variability across the ensembles over lift metric which is not in accordance with other metrics. After boosted trees, majority voting has the highest value of lift; bagged trees, stacked generalization, boosted NN, bagged NN, and consensus voting are ranked next. The highest value for metrics is printed in bold, and the lowest value for metrics is underlined in Table 3 .

Like single classifier results, a trade-off between false com-mercial and false residential rates across ensemble models is observable. In fact, models (like majority and consensus voting) that do not benefit from learning at the meta-level have this trade-off in the worst possible form. Majority voting has the lowest residential false rate and consensus voting have the lowest commercial false rates. In contrast, majority voting has the highest commercial false rate and consensus voting has the highest residential false rates. Despite high residential false rate which damages company income in the current problem, consensus voting may be a good choice for conservative managers who value their relation with customers and focus on customer retention.

Boosted trees model scores the best performance on the sum of commercial and residential false rates. Boosted trees model reduces commercial and residential false rates simultaneously.
According to Table 3 boosted trees model as the best trained model is able to correctly classify 93.0% of all customers. The values of the lift metric show this model classify records 2.637 times better than a random classifier. The false rate of commercial and residential classification for boosted trees model is 8.63% and 6.15%, respectively. The superiority of boosted trees over other single and ensemble classifiers suggests that this model is better suited to these particular problems. Bagged trees, stacked generalization, boosted and bagged NN also reduce both com-mercial and residential false rates concurrently. Our experiments show no significant improvement between bagging ensembles size 25 and 50, and 100 classifiers. Therefore, we report the bagged trees and NN of size 25. In stacked generalization, MLR using the probabilities as inputs shows superior performance compared to NB in both situations. Thus what is reported in
Table 3 as stacked generalization shows the result of MLR. 4.3.5. Pair-wise comparison of classifiers
We performed statistical tests to compare all pairs of single and ensemble models. To do that, we applied a 10-fold cross-validated t -test to construct 95% confidence intervals for the difference in the error rates of the algorithms. If this confidence interval does not include zero, then the test concludes that there is a significant difference in performance between the algorithms. Table 4 summarizes the results of these confidence intervals.
Interval in cell ( i , j )of Table 4 shows 95% confidence interval for observed difference between the performances of model in row i and model in column j . Hence, interval in cell ( i , j ) with negative lower and upper bound values indicates that model in row i has a better observed performance than model in column j . It is obvious that intervals in cell ( i , j ) with positive lower and upper values reflects the better performance of model in column j . Confidence intervals which cover zero indicate that there is no significant difference between model in row i and column j . As the row of corresponding to boosted trees shows, this model performance is significantly higher than other single and ensemble models.
According to the estimated confidence intervals, a significant difference between bagged trees and all other classifiers except from boosted trees is observed. It is also interesting that bagged
NN model has no statistical superiority in terms of accuracy metrics compared to single DT and SVM. Other comparisons can be traced in Table 4 . 4.4. Examination of the effectiveness of dimension reduction and clustering steps
The aim of the study was to present the most precise model of fraudulence detection, and this could be achieved, unfortunately, at the cost of loosing simplicity. In certain applications, the efficiency of algorithm learning and inference, namely, its time and space complexity is very important. It should be noted that in the current problem once the model is trained  X  regardless of which one of the proposed classifiers is employed  X  it does not store the training dataset but only the structure and parameters of the methods; this implies that space complexity is low. Further-more, in the current problem and similar applications, opposed to real-time applications, enough time to inference (classifying residential subscribers) is available. Hence, the proposed model is applicable to telecommunication companies as well as other non-real time applications.

However, we tempted to investigate, while qualifying the job, if the proposed process could be simplified. We are to compare the proposed process against its three simplified versions in terms of the prediction performance. Simplified versions are: (a) the proposed process without dimension reduction by PCA, (b) the proposed process without clustering, and (c) the proposed process without dimension reduction by PCA and clustering. The third version was presented in Daskalaki et al. (2003) and employed to detect solvent fraud in telecommunication companies. To this end, we evaluate the performance of three single classifiers in each version and compare it with the proposed process. Since the train and test data are not the same, z -statistic ( Tan et al., 2006 )is used instead of paired t -statistic to test the hypothesis of equal error rate of classifiers (or zero value for true error difference) between the classifiers of simplified versions and proposed process. We also estimate a 95% confidence intervals using z -statistic for the true difference in the error rates of the classifiers and compute p -value as a measure of evidence against the null hypothesis. Table 5 summarizes the results of removing PCA and clustering steps of the proposed process in order to achieve a simpler process with a lower computational cost, yet qualifying the job. In each simplified version, the accuracy of three single classifiers, a 95% confidence interval for true difference of error rate between classifier in the simplified version and proposed process, and p -value in separate rows are presented. In the last row of Table 5 , the reference value of comparisons, which is the accuracy of DT, NN, and SVM in our proposed process, is shown.
As Table 5 shows, the accuracy of DT and NN significantly decrease by excluding PCA from the proposed process ( p -value o 0.001), while the accuracy of SVM is not affected even in significant level 0.05. In other words, there is no difference between the accuracy of SVM with or without using PCA as a dimensional reduction technique at significant levels smaller than 0.064. On the other hand, the accuracy of all algorithms decrease significantly ( p -value o 0.001) when the clustering step is removed from the proposed process. SVM is more affected than DT and NN are. The substantial reduction of the classifiers X  accuracy can be attributed to outlier cases in the form of outlier cluster and also to three useful constructed features. As the last comparison, the accuracy of the simplest version which is the proposed process without PCA and clustering steps, is significantly ( p -value o 10 5 ) much smaller than the proposed process. To sum up, we conclude that dimension reduction by PCA along with clustering play an important role in the proposed process performance.

As mentioned before, there are 31 fraudulent cases in the original dataset. As also stated before, due to the rarity these cases were not used in model training. Finally, we passed these cases to trained models as a separate test dataset. All the trained models classified these cases as commercial subscription without error. This indicates that the models learned the commercial/residential customers X  behaviors correctly and hence the model can be employed to detect suspected fraudulent cases in practice. 5. Conclusion
In this study we made use of data mining tools to solve one of the challenging problems in business. Therefore, a framework for detecting fraudulent telecommunication subscribers was pro-posed which covers different techniques and algorithms for data cleaning, dimension reduction, clustering, and customers X  classi-fication. We introduced a hybrid approach consisting of pre-processing, clustering, and classification phases; appropriate tools were employed commensurate to each phase. In the data preparation phase, in addition to using the common tasks like data cleaning and transformation, PCA was used as a dimension reduction technique. In the second phase we used SOM and K-means subsequently to improve clustering results. Two popular indices i.e., Dunne and DB indices were employed to evaluate the clustering results. DT, NN, and SVM as single classifiers and bagged trees, bagged NN, boosted trees, boosted NN, stacking generalization, majority and consensus voting as ensembles were examined. The parameter space of models explored by a systematic procedure and models calibrated appropriately.
TCI subscribers X  data were used as our case study to evaluate the proposed methodology. The performance of all single and ensemble classifiers is evaluated based on various metrics including accuracy, F -score, lift, and AUC. In addition, many comparisons were done by estimating appropriate confidence intervals. The results showed that SVM among single classifiers and boosted trees among all classifiers has the best performance in terms of various metrics. Narrow estimated 95% confidence intervals showed that single and ensemble classifiers have low variances.

We introduced 3 new features based on the clustering results in order to keep the learning obtained from the clustering results, and memorize it for the classification phase. This is a new idea in this context that needs more investigation. However, the effec-tiveness of the new features was investigated experimentally which showed that adding new constructed features can improve the performance of DT and SVM significantly. We also tried to test simplified versions of proposed process by removing dimension reduction by PCA and clustering steps. The results provided evidence for the effectiveness of PCA and clustering steps.
The type of subscription fraud investigated in this study occurred in a relatively long time usage period. In fact, there is no difference between a commercial and a residential call per se. the fraud is the result of using a residential subscription for commercial purposes for a period of time. The presented models need the historic data of subscribers to classify them in commercial or residential class. Therefore, the proposed method has some limitations and tradeoffs. The main hurdle is data limitation. That is, the model could not be used to classify new customers without enough historic data. Regarding the other applications, the model cannot be used for real-time purposes due to computational aspects, although in our case this did not pose itself as a problem. In subscription fraud enough time to inference is available. Hence, the proposed model is applicable to tele-communication companies; it can also be used for other non-real time applications. Since the proposed method finally provide a list of residential subscriptions, which are suspected to be used for commercial purposes, yet the company needs to investigate more certify that a fraud has occurred. Therefore, though the model is able to drastically reduce the efforts to detect subscription frauds, it does not eliminate the need for a final company checking. This is because we cannot accuse subscribers of fraudulent behavior solely based on the outputs of the model.

The research findings showed that the proposed process had a high performance, and the resulting outcomes were significant both theoretically and practically. In other words, a great amount of TCI X  X  income, as well as that of other telecommunication companies, which is lost due to customers X  subscription fraud, can be prevented via the proposed process.

As the last remark, while data mining techniques help businesses address more questions than ever before, this capability may add to the risk of invading customer privacy.
Although in this research subscribers X  personal information was given to researchers anonymously, it should be mentioned that in data mining projects customer privacy rights are some-times disregarded. As an important point, customer privacy should be taken into account in next implementation or similar projects.
 Acknowledgements
We appreciate Telecommunication Company of Iran for providing us with the required data, and for its partial financial support. We would also like to thank F. Behzadpour and R.B. Kazemzadeh for their constructive comments.
 Appendix A List of features are given in Table A1 .
 References
