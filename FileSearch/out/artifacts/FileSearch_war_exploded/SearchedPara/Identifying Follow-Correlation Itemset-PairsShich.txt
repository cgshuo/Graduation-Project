 will likely occur when A occurs. This is a classical association rule. In real world applications, such as bioinformatics and medical research, there are many follow correlations between itemsets A and B : B likely occurs n times after A occurred m times, wrote to &lt;A B &gt;. We refer to this follow-correlation as P3.1 itemset-pairs because &lt;A 3 , B 1 &gt; like that in Example 2 should be uninterested in association analysis. This paper designs an efficient algorithm for identifying P3.1 itemset-pairs in sequential data. We experimentally evaluate our approach, and demonstrate that the propos ed approach is efficient and promising. The goal of mining association rules is to capture and model the useful associated correlations within data. By the definition in [1], an association rule is an implication of the form A  X  B, where A and B are frequent itemsets in a transaction database. In practical applications, the rule A  X  B can be used to predict that  X  X f A occurs in a transaction, then B will likely also occur in the same tran saction X , and we can apply this association rule to predict the behavior that the presence of A implies the pr esence of B in marketing. Such applications are expected to increase product sales and provide more convenience for supermarket customers. Therefore, mining association rules in databases has been an active research topic in data mining and rooted in market basket analysis [1, 2, 10].
While association rule mining techniques have advanced to a mature stage, in many real world applications there exists another type of interesting pattern between objects (or itemset) that is different from the association rules. It has the form of  X  X temset B likely occurs n times after itemset A occurred m times X . We refer to this type of follow correlation between two itemsets as the Follow-Correlation Itemset-Pairs (denoted as P3.1 Itemset-Pairs or FCIP , which will be defined in detail in section 2) and use the form of an ordered pair to represent the P3.1 pattern, namely &lt;A B &gt;, where A is the Condition itemset and B is the Action itemset of the pattern; m and n represent the occurring times of the antecedent and consequent respectively. This paper proposes this new kind of interesting patterns and aims to develop techniques for mining them.

From the previous work of researchers, the association rule mining tends to find out those patterns, whose elements appear simulta neously in a transaction. Different from association rule mining, the discovery of the P3.1 pattern is the identification of those interesting patterns, whose elements do not appear simultaneously. Instead, the elements occur in an asynchronous way.

Our P3.1 patterns are also different from the sequential patterns, which were first brought up by [3]. The difference is that the traditional sequential patterns do not consider the quantities of items bought in a transaction, which may lead to the loss of important interesting information. 
A P3.1 pattern  X  A m , B n  X  can be used to predict that  X  X f A has occurred m times, then B will likely occur n times in the following transactions X . Like association rules, we can also utilize this P3.1 pattern to predict customer behavior in marketing as well as many other domains. 
We now illustrate some kinds of P3.1 patterns using several examples below. Example 1. Consider a given database D with randomly appended transactio ns. Let A and B be two items in D. After deleting other items and those transactions that do not contain item A or B, assume we have the following data Where  X 1 X  indicates that item A occurs in a transaction and  X 0 X  indicates that item A does not occur in a transaction. 
Using the support-confidence framework, we can see that the support count of AB is 2, which is very low, and itemset AB may be not interesting. However, the above data has shown an interesting follow-correlation: B occurs 1 time after A occurred 1 time and, in last two transactions B occurs 1 time when A occurred 1 time. Using our method (will be built in this paper), we can identify an interesting follow-correlation: itemset-pairs  X  A 1 , B 1  X  with frequency of 10. Example 2. Consider the same database D in Example 1. Assume we have the following data, Using support-confidence framework, we can obtain the association rule A  X  B with confidence 0.333. It should be not of interest. However, the above data has also shown another interesting follow-correlation: B occurs 1 time after A occurred 3 times. Using our method (will be built in this paper), we can discover an interesting follow-correlation: itemset-pairs  X  A 3 , B with frequency of 6. We can identify the same follow-correlation from, for example, the following data Certainly, the association rule A  X  B with support 1 is not of interest according to the support-confidence framework. 
Also, we can identify an interesting follow-correlation: itemset-pairs  X  A 4 , B 2  X  with frequency 4 from the following data 
Generally, we can obtain a common form for follow-correlation itemset-pairs. We name this new kind of itemset-pairs as P3.1 pattern. A P3.1 pattern is Condition itemset that occurs at first, and A is the Action itemset that occurs successively; m and n denote the occurring times of the itemsets C and A in the database respectively. As described in example 2, the itemset-pairs  X  A 3 , B 1  X  should be pruned away in the association rule mining settings. But from another point of view, it is an interesting P3.1 pattern that will be useful in real world application. 
The P3.1 patterns are common and useful in many domains. Below are two examples of the P3.1 patterns. Example 3. In a daily stock exchange database, assume there are three attr ibutes: the stock name, the percentage change of its value in terms of its previous day X  X  value, and the date. From this database, it is possible to discover patterns related to stock value increases and decreases. Inst ead of real percentage values, we use some notations, such as D (representing more than 10% of the daily value Decrease), I (representing more than 20% of the daily value Increase) and O (Other kinds of changes). We then use these notations to transform the original data of stock exchange database into a new form of data. Consider the transformed sequence  X  X DIIIODDDIIIIODDD X  for stock A and  X  X ODDOIDODODDODODD X  for stock B. Suppose we only care about the increase of the stocks, if there is an incr ease in the sequence, set the value in the corresponding position to 1, otherwise, set to 0. So, 10000100000000000. We can find an interesting phenomenon that after the real percentage value of stock B increased one time, stock A will increase four times (we omit those zero valu es that appear in the same position of stock A and B, after deletion, the sequences of A and B are 111101111 and 100010000 respectively). This observation can be utilized to predict the trend of stock A based on the trend of stock B. On the contrary, we can also infer the trend of stock B based on the analysis of A X  X  sequences. Example 4. Suppose a patient is infected with a kind of disease (denoted as A), he is taking medicine B for treatment. And each column in the table below denotes a period of treatment. In the 2 nd and 3 rd columns, he will receive as many as 5 tim es treatments, because the density of virus in his body is very high at first. While in the next two period of treatments, he is recovering, so he needs fewer and fewer treatments. Generally, he needs 4 or 5 treatments during the whole period. From the above examples, we can see that the Follow-Correlation Itemset-Pairs ( P3.1 pattern or FCIP ) are interesting and widely hidden in many real world applications, which can reveal the underlying relationships between objects that occur one after another. We will give a formal definition of the P3.1 pattern in the next section, and propose an algorithm for efficiently mining these interesting patterns from sequential dataset. 
Some studies, such as cyclic association rules [4], serial and parallel episodes [9], segment-wise periodic patterns [6], and cyclically repeated patterns [7,8] are different from classical associ ation rules. These studies have extended the association rule to a general form or a sequential form, which can well model the underlying sequential relationship between objects. Some research efforts [4] a ssume that the transactional data to be analyzed is time-stamped and that time intervals are specified by th e user to divide the data into disjoint segments, then to discover such regularities in the behavior of association rules over time. The work of [6], wh ich can mine the segment-wise or point-wise periodicity in time-related data sets, differs from the cyclic associ ation rules which aims at finding full-cycle periodicity for all the segments in the selected sequences of the da ta. Both cyclic association rules and segment-wise periodic patterns are based on the work of mining sequential patterns [3]. The work of [9] discovers frequent episodes in sequences of events, such as the serial episode and parallel episode. Our proposed P3.1 patterns are similar to the above patterns, but also different significantly from them. One can distinguish the diffe rences from the definition of the p3.1 pattern. The rest of this paper is organized as follows. In Section 2, a formal definition of the P3.1 pattern is presented; and in Section 3 we describe an algorithm for mining P3.1 patterns; experimental study is given in Section 4; finally we conclude this paper and present our future work in Section 5. We first use a market basket database as an example to introduce the concept of the follow-correlation itemset-pairs ( P3.1 pattern or FCIP ), and then give a formal description of this concept. Example 5 . Given a customer transactional database of a supermarket, see Figure 1, which contains 9 transactions. Each transaction consists of different number of items, representing the corresponding commodities purchased simultaneously by a customer. 
The left table of Figure 1 is the original transactional database, while the right one is a transformed database of the left table. We use 0 and 1 to indicate an item does or doesn X  X  occur in a transaction. From the transformed database, we can find some interesting patterns. For instance, item c is likely to appear two or more times after item d has occurred two times. We use ordered pairs &lt; d 2 , c 3 &gt; and &lt; d 2 , c 2 follow-correlation. As mentioned in Section 1, we refer this kind of pattern to the Follow-Correlation Itemset-Pairs ( P3.1 pattern, or FCIP ). Note that for the fourth times of the occurring of item d , the item c is also occurring at the same time (in transaction 7) and continues its appearance to tr ansaction 8. This kind of Correlation Itemset-Pairs ( SFCIP ), while for the pattern, say &lt; d 2 , c 3 &gt;, we call it the Lag Follow-Correlation Itemset-Pairs ( LFCIP ). As for items d and f , they both do not occur in transaction 3,4,5 and 9, so we omit these non-occurring sequences, and the resulting sequence of item d is  X 11110 X , the sequence of f is  X 01101 X . Finally, we can get the FCIP patterns from the sequences of the two items as &lt; d 1 , f f transactions only for ease of finding the FCIP patterns. From figure 1, we also find that for items d, e and c , c &gt;. This kind of P3.1 pattern contains more than one items in its Condition itemset. For ease of discussion, in this paper we consider the situation that there is only one item in the Action itemset of a P3.1 pattern. Some other Itemset-pairs are listed here, &lt; f 1 , a 1 &lt; g 3 , b 1 &gt;, &lt; b 1 , g 3 &gt;, &lt; b 1 , g 2 &gt;, &lt; b association rules mining algorithms cannot capture this kind of patterns. For one thing, the P3.1 pattern usually has relatively low support count under the traditional association rules mining framework. Take the items c and d for example, the support for itemset cd is only 1/9= 0.11, which is fairly low and is likely to be pruned away while generating interesting patterns. For the other thing, the traditional association rules mining framework tries to discover underlying correlations between items that within a same transaction, which can X  X  be used to mine out those follow-correlations between items that do not appear within the same transaction. While using our proposed algorithm, one can efficien tly grasp such kind of interesting follow-correlation patterns, providing the decision maker with more useful information. 
Our proposed patterns are different from the sequential patterns, which were first brought up by [3]. The difference is that the sequential patterns do not take the quantities of items with a pattern into account, which may lead to the loss of important interesting patterns such as our proposed P3.1 patterns. This difference is crucial for distinguishing the P3.1 patterns from the sequential patterns. Definition 1. Item occurring sequence Given a database D with size of T transactions, the occurring sequence of an item I in D is denoted as S I I representing that item I occurs or doesn X  X  occur in transaction t respectively. And I t is in front of I the sequence for all t =1, 2, ... , T -1. An appearance sequence , 1 I S , of an item I is a subsequence of S I , in which item I is appearing consecutively, that is, 1 ,..., Imn SII =&lt; &gt; , where I t = m,...,n, and 1 mnT  X  X  X  X  . The length of 1 I
Len S n m = X  + . Similarly, the non-appearance sequence of item I is defined as 0 ,..., where I t = 0, t = m, ... ,n, and 1 mnT  X  X  X  X  . The length of 0 I S is 0 () 1 I Len S n m = X  + . Thus, the occurring sequence of item I in a database is decomposed into the appearance sequences and non-appearance sequences that are interleaved by each other. The traditional transaction database D is transformed into a set of the item occurring sequences in order to facilitate the finding of the Follow-Correlation Itemset-Pairs , which will be discussed in Section 3. Definition 2. Follow-Correl ation Itemset-Pairs (or P3.1 pattern, FCIP ) A Follow-Correlation Itemset-Pairs is an ordered pair &lt; C , A &gt;, where C and A , representing the Condition and the Action itemset respectively, are both appearance sequences , that is,  X  X  X  ; and The pair &lt; C , A &gt; is called the Lag Follow-Correlation Itemset-Pairs ( LFCIP ), if 1 kn =+ ; and is called the Strong Follow-Correlation Itemset-Pairs ( SFCIP ), if = . We will use the term  X  P3.1  X  and  X  FCIP  X  interchangeable throughout this paper. The Condition itemset C and Action itemset A of a P3.1 pattern may contains one or more items, but currently we only consider the situation that the Action itemset A only contains one item in this paper for ease of discussion. 
For instance, for sequences C = X 111011101110 X , D =  X 000100010001 X  and E= X 001100110011 X , we can get LFCIP &lt;C 3 , D 1 &gt; and SFCIP &lt;C 3 , E 2 pattern can be obtained, that is &lt;{ D, E } 1 , C above sequences of items. Note that, for sequence A= X 101010101010 X  and sequence B =  X 010101010101 X , Both &lt;A 1 , B 1 &gt; and &lt;B different FCIPs because Fellow-Correlation Itemset-Pairs is an order pair, FCIP &lt;A 1 , B 1 &gt; is LFCIP and its frequency is 6 and FCIP &lt;B 1 , A 1 &gt; is also a LFCIP pattern, but its frequency is 5. 
Without loss of generality, we use the general form of the FCIP , which is &lt; C L1 , A L2 &gt;, where L 1 the lengths of the Condition and the Action itemset appearance sequences re spectively, that is, A FCIP p  X  = &lt; C  X  , A  X  &gt;, where '' '' ' ,...,
A AA =&lt; &gt; , is a subpair of FCIP p= &lt; C , A &gt;, called a ( j 1 , j 2 ) -subpair of p if 1 (') ' '1 jLenC nm Definition 3. (T he frequency of a P3.1 pattern) The frequency of a P3.1 pattern p= &lt; C L1 , A occurring times of p in a database D . 
We can get the frequency of a pattern p by scanning the whole database and count how many times that p occurs. The users can take advantage of those P3.1 patterns that have higher frequency counts, because frequently occurred P3.1 patterns may be more useful in decision-making. Definition 4. Longest P3.1 pattern Given two appearance sequences of item C = ,..., mn CC &lt;&gt; , and mklT &lt; X  X  X  and 1 kn  X + , the longest FCIP pattern of these two appear ance sequences is a pair 
There are some interes ting properties of the P3.1 pattern, which can be utilized to facilitate the mining process. We present some of them as follows. Property 1. If a P3.1 (or FCIP ) pattern p has a frequency of s , then each of its subpairs has a frequency, say s  X  , which is at least equal to or larger than the frequency of p. That is, ' SS  X  . 
This property is similar to that of frequent itemsets called anti-monotone in association rules mining framework. Different from the association rules mining process [1], we find out the longest P3.1 (or FCIP ) pattern p at each time without counting all its subpairs. After checking the whole database, we output p to the user and all its subpairs as well. This can substantially reduce the search space. 
The number of longest P3.1 patterns of the appearance sequences of tw o items is equal to the number of transactions that these two items both occur simultaneously. So we can get the second property for P3.1 pattern below. Property 2. The frequency of a strong follow-correlation itemset-pairs ( SFCIP ) p= &lt; C 1 , A 1 items, C and A , are approximately equal to the support count of the itemset CA in a database D . This can be proven from the previous definitions of SFCIP . Because the support count, say f , of an itemset CA in database is the total number of transactions that contain the itemset, while for a SFCIP pattern p= &lt; C A &gt; with frequency s , itemsets C and A may appear simultaneously in about s transactions approximately. That is, we have f  X  s . For example, for item occurring sequences A= X  1011010011  X  , B= X  0110110010  X  , and C= X  1110101011  X  , we can get some SFCIP patterns as, &lt; A 1 , B 1 &gt; with frequency 3, &lt; A 1 , C 1 &gt; with frequency 4, perspective of traditional association rules mining framework, we know that the support counts for itemsets AB, AC, and ABC are 3, 4, and 2 respectively. 
From property 2, we can have a deep understanding of the relationship between the association rules mining framework and our proposed patterns, that is, the association rules try to find out those items that occur together in each trans action, which can be called synchronized occurring ; while in our model we want to search the items that app ear one after another, which can be called asynchronous occurring . Given a database D , our goal is to find out those P3.1 patterns, whose frequencies are larger than or equal to user defined minimal support count (currently, we only address the mining problem of P3.1 patterns with a single item in the Action itemset). The task of mining such patterns is different from traditional association rules mining in that the association rules mining algorithm is to generate candidate itemsets and then check them against the database; while our algorithm need not generate candidate P3.1 patterns. Instead, it searches the se quences of two items from end to end, counting each longest P3.1 patterns that it encountered. After the counting process, all the frequency of FCIP s and its subpairs are output to the user. The mining algorithm for FCIP will be discussed in Section 3. Our algorithm for mining FCIP patterns from databases consists of two steps, the first step is to sequentialize the data, which converts the transactional forms of items into sequences; the second step is to search the sequences in order to find out the longest FCIP patterns. The algorithm is presented in Figure 4. Sequentialize Phase : In this first step, we read in the data and build a list for each item, which stores the appearance and the non-appearance sequences of the item. In practice, the databases are usually very large, which will hinder the construction of the sequences of items. We devise a technique called Lazy Counting , in order to save storage space and quicken the process of sequentialization for items. The main idea of Lazy Counting is that we needn X  X  count the information about an item when it does not occur in a transaction. This technique takes effect with the help of a tail pointer that points to the last node of the item occurring list, and a pointer that indicates the current number of transaction that is under processing. We adopt the same database in Example 1 to illustrate the sequentialize algorithm and the Lazy Counting technique. 
In Figure 2, a list table is maintained, in which the  X  name  X ,  X  tail  X  and  X  child  X  denote the name of item, the pointer that points to the tail node of the list and the consecutive child list respectively. The  X  X ail X  pointer is used for quickening the access of the list, because each time we need to add a new node to the end of the list. The fields  X  X  X , X  X  X  and  X  X   X  denote the Start position, End position and the successive Pointer to next node respectively. We use CurrTrans to denote current number of transaction that is being processed.

The  X  X  X  and  X  X  X  record the start number and the end number of transactions between which the item appears continuously. For instance, item a occurs from  X  X  X  fields are set to 3 and 5 respectively. For example, if current transaction contains item a , we then access the last node of item a  X  X  list and see whether the value of field  X  X  X  equals to CurrTrans -1. If yes, we then set the field  X  X  X  to E=E+1; othe rwise, we can infer that since last occurring of item a , there are CurrTrans-E-1 transactions in total that do not contain item a . So we have to generate a new node and link it to the last node of item a  X  X  list, setting the new node with filed  X  X  X  and  X  X  X  both to CurrTrans . Finally we modify the pointer tail of a to point to the new node. If current transaction does not contain item a , we need not to access a  X  X  list leaving the field of  X  X  X  unchanged. When we access the first node of item a  X  X  list, for example, we find that a  X  X  field  X  X  X  is 3, as a consequence, we can infer that from 1 st transaction to 2 nd transaction item a does not occur. Above discussion is the main idea of the Lazy Counting technique. For each item, we do not need to count the information of its  X 0 X  sequence (does not appear in transactions), instead, only the information of its  X 1 X  sequence (appear in transactions) will be recorded. We call this strategy the Lazy Counting , which is lazy for treating the  X 0 X  sequences. When all the transactions are processed, the list table is presented in Figure 3. Because of the principle of Lazy Counting , after processing all the transactions, we get the final list table of items in Figure 3. The last appearances of items b and g are both in the 8 th transaction, while the total transactions of database D is 9, so we can infer that items b and g do not occur in the remained transactions. After the sequentialize process, all the items of database D are transformed into a long sequence, which consists of consecutive appearance sequences. These appearance sequences can be expressed by mutually disjoint intervals, which are important for the next step of finding the longest FCIP patterns. 
S equentializeItemsWithLaz y Counting ( ) 1. Initialize the item list for database D 2. While EOF ( D )=false do 3. read in a trans action, count each item in the 4. Enddo
FindingFCIPpatterns ( ) 1. C =  X  ; 2. While not_finish_processing_the_list_table do 3. for each two items, process the appearance 4. Enddo 5. Count all the subpairs of longest FCIP in C
Figure 2. Illustration of sequentialize process Finding FCIP Patterns Phase : After constructing the list table for all items, we then search the sequences of each two items in order to find out the FCIP patterns. The search process is re latively straightforward, because we have got all the appearance sequences of each item, the next thing we should do is to compare the endpoints and the overlapping region of these mutually disjoint intervals for two sequences and count up all the longest FCIP patterns. Based on Property 1 in Section 2, the subpairs of the FCIP patterns are also counted up, and finally, the results are presented to the user. In this section, we present a pruning strategy in order to reduce the huge search sp ace for item pairs in order to discover P3.1 patterns. This strategy is based on mutual information (MI). The proposed algorithm aims to find out the P3.1 patterns between the Condition and Action itemsets sequences in database, which can lead to combination explosion. For example, if there are 1000 distinct items in a database D , then the algorithm needs to check as many as 1000*(1000-1)=999000 sequence pairs of items, resulting in a great in efficiency in performance. This problem will be getting worse when D contains many items. Actually, we need not to check all these item pairs. For instance, item A may have relations with item C , while item B may have weak or none relations with item C . Therefore, we only need to search the sequences of items A and C , and needn X  X  to check the sequences of items B and C . 
In order to measure the relationship between items, we employ the mutual information (MI) to evaluate the relations between items instead of the chi-squared test [5]. If two items are independent, then the MI between them is zero. If the two items are strongly dependent, as for the case if one is a f unction of the other, then the MI between them is large. In other words, the value of MI between two items indicates the strength between these two items. We adopt the MI because it can measure the general (non-linear) dependence while a correlation function measures linear dependence. In most cases in real world application, we usually don X  X  know the exact relationship between items, so adopting MI is an appropriate choose. We give an example for illustrating the computation of MI between two items. For example, we want to compute the MI between item a and b in Figure 1. We first generate the contingency table for a and b , which is presented in Table 1. The MI between items a and b is calculated as: where ij P , . j P and . i P are corresponding values from Table 1. The MI between items a and b is 0.0488 based on the above equation. For the case of multi-items in Condition itemset, we simply transfer the Condition itemset into a new item, and then compute the MI by using the new item. For example, there are sequences for three items, A=  X 1011010011 X , B=  X 0110110010 X , and C=  X 1110101011 X . We transfer itemset AB to a new item A X  with occurring sequence  X 0010010010 X , that is, we set the sequence to  X 1 X  if items A and B are both occur in a same transac tion. Otherwise, set the sequence to  X 0 X . Then, we compute the MI between items A X  and C . If the MI value is gr eater than the user specified threshold, that means we can mine the P3.1 pattern &lt;{ A, B } L1 , C L2 &gt; in the database. 
After the MI for all item pairs are computed, we sort the MI values and only process the top K percentage of largest MI values of item pairs in database, where the parameter K is given by the user. This can diminish the search space substantially. 
Generally, the number of P3.1 that contained in a database is usually very large and is beyond the user X  X  ability to process. Even we adopt some pruning strategies, such as the one described in section 3.2, there are still large amount of P3.1 patterns derived from database. As mention in section 2, a P3.1 pattern frequency, or support count, of the ordered items pair &lt; C m , A n &gt;. We can use a support count threshold given by the user, in order to throw away the P3.1 patterns whose frequencies ar e below the threshold and output those interesting P3.1 patterns whose frequencies are equal to or larger than the specified threshold. Table 1. The contin g enc y table for item a , b
Another commonly used technique is the Top-k method. We can output the top k percentage patterns from all the generated P3.1 patterns, which are sorted in descent order according to their frequencies. Here frequency than that of pattern q , then we can say that pattern p is more interesting than q . We have conducted extensive experiments in order to evaluate the performance of our proposed algorithm for finding P3.1 patterns in databases. The dataset in this paper is generated as the same in [2], and we use the same notations to describe the features of dataset, i.e., we use T to denote the average length of each transaction, I the average length of patterns and D the number of transactions in dataset. In this section, we will report our experimental results of mining P3.1 patterns from several aspects, i.e., the number of P3.1 patterns generated, the execution time and the relationship between frequent itemsets obtained by using the association rules mining algorithm, under various settings of dataset. Because the number of different length of P3.1 patterns is very huge, i.e., there are many combinations of m and n. Due to the paper size restriction, we only report the experimental results of two kinds of P3.1 patterns, &lt;C 1 , A 1 &gt; and &lt;C A &gt;. Throughout this section, we use  X  X attern 1 X  and  X  X attern 2 X  to denote the above P3.1 pattern &lt;C and &lt;C 3 , A 1 &gt; respectively. The experiments have been conducted on a PC with P4 2.1GHz CPU and 256M main memory, the operating system is WINDOWS XP. 
The P3.1 patterns describe the interesting follow correlations between items in databases. Generally, the items are hundreds or thousands as large in super-market databases; while in biological databases, the number of items (commonly called attributes) is simply too huge to be handled. So we aim to evaluate our algorithm for finding P3.1 patterns from databases that contains different number of items in this subsection. We adopt two kinds of databases with different size, T10I4D10K and T10I4D100K , each of which is generated with 50, 100, 200, 500 and 1000 items respectively. Then we use our algorithm to extract two kinds of P3.1 patterns, &lt;C 1 , A 1 &gt; and &lt;C above various databases. The K is set to 50%, i.e., we only output the top 1/2 of the total generated P3.1 patterns, which are sorted by their frequencies. The mining results are presented in Figures 5 and 6. 
From above figures, we can see that the execution time increases approximately linearly when the number of distinct items increases. While in Figure 6, the number of generated P3.1 patterns increases greatly when the number of items is large. But clearly, the increase of the number of short P3.1 patterns (&lt;C, A&gt; in Figure 6) is much faster than the long P3.1 patterns (&lt;C 3 , A 1 &gt; in Figure 6) do. 
In this subsection, we use databases with different size to test our algorithm, which contain 10000, 20000, 50000, 100000 and 250000 transactions respectively. All of these databases have a fixed number of 400 distinct items, and the average length of transactions is set to 10. The results are listed in Figures 7 and 8. In Figures 7 and 8, we can see a same trend as in Figures 5 and 6. Our algorithm for finding P3.1 patterns can well scale up to large datasets, which is promising in real world applications. 
Generally, the number of items in database is very large, resulting in huge combinations of item pairs that need to be checked for P3.1 patterns. In order to reduce the search spaces, we adopt the pruning strategy in section 3.2. We give the mining results by using the MI based pruning strategy along with the Top-k method. The settings of database are as follows. The number of different items is 1000, the average length of transaction is 10 and the total number of transactions is 100000. The execution time and number of generated P3.1 patterns are presented in Figures 9 and 10 under different K. 
From Figure 10, the number of P3.1 patterns will shrink significantly if one can select an appropriate K value. Another factor that affects the mining process of the P3.1 patterns is the average length of transactions in databases. For this reas on, we generated several databases with different average length of transactions, i.e., T4, T6, T10, T15 and T20 . We fix the number of distinct items to 400, and the total number of transactions to 100000. The experimental results of our algorithm under above settings are presented in Figures 11 and 12. We have presented a model for identifying a new type of pattern called Follow-Correlation Itemset-Pairs ( P3.1 , or FCIP ) in sequential data. A P3.1 pattern is a pair of two items, in which the condition item likely occurs m times followed by the action item that likely appears n times in sequential data. The model consists of defining the P3.1 patterns, and finding those patterns from sequences of items. Our P3.1 pattern differs from the frequent itemsets of traditional association rules mining, and also differs from the sequential patterns and cyclic patterns. In many real world applications, we can find that P3.1 is very useful in modeling the underlying relationship between objects, which is usually less considered by the existing models for finding association rules, sequential patterns and cyclic pattern etc. We have developed an algorithm for mining the P3.1 patterns from sequential data. Extensive experiments have been conducted under various settings and the results show that our algorithm is efficient in finding the P3.1 patterns. 
In our future work, we will extend the P3.1 pattern, in which the Action itemset of a P3.1 pattern is a collection of items instead of single item at present. 
Figure 12. The number of P3.1 patterns under different average length of transactions different average length of Transactions
