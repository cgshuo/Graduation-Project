 Synchronous context-free grammars (SCFG) are be-hind most syntax-based machine translation mod-els. Efficient machine translation decoding with an SCFG requires converting the grammar into a bina-rized form, either explicitly, as in synchronous bina-rization (Zhang et al., 2006), where virtual nontermi-nals are generated for binarization, or implicitly, as in Earley parsing (Earley, 1970), where dotted items are used.

Given a source-side binarized SCFG with termi-nal set T and nonterminal set N , the time complex-ity of decoding a sentence of length n with a m -gram language model is (Venugopal et al., 2007): where K is the maximum number of right-hand-side nonterminals. SCFG binarization serves two impor-tant goals:  X  Parsing complexity for unbinarized SCFG  X  In machine translation, integrating language
In this paper, we examine a CYK-like syn-chronous binarization algorithm that integrates a novel criterion in a unified semiring parsing frame-work. The criterion we present has explicit consider-ation of source-side terminals. In general, terminals in a rule have a lower probability of being matched given a sentence, and therefore have the effect of  X  X nchoring X  a rule and limiting its possible applica-tion points. Hopkins and Langmead (2010) formal-ized this concept as the scope of a rule. A rule of scope of k can be parsed in O ( n k ) . The scope of a rule can be calculated by counting the number of ad-jacent nonterminal pairs and boundary nonterminals. For example, has scope two. Building on the concept of scope, we define a cost function that estimates the expected number of hyperedges to be built when a particular binarization tree is applied to unseen data. This ef-fectively puts hard-to-match derivations at the bot-tom of the binarization tree, which enables the de-coder to decide early on whether an unbinarized rule can be built or not.

We also investigate a better way to handle target-side terminals during binarization. In theory, differ-ent strategies should produce equivalent translation results. However, because decoding always involves pruning, we show that different strategies do have a significant effect in translation quality.

Other works investigating alternative binarization methods mostly focus on the effect of nonterminal sharing. Xiao et al. (2009) also proposed a CYK-like algorithm for synchronous binarization. Appar-ently the lack of virtual nonterminal sharing in their decoder caused heavy competition between virtual nonterminals, and they created a cost function to  X  X iversify X  binarization trees, which is equivalent to minimizing nonterminal sharing.

DeNero et al. (2009b) used a greedy method to maximize virtual nonterminal sharing on the source side during the -LM parsing phase. They show that effective source-side binarization can improve the ef-ficiency of parsing SCFG. However, their method works only on the source side, and synchronous bina-rization is put off to the +LM decoding phase (DeN-ero et al., 2009a).

Although these ideas all lead to faster decoding and reduced search errors, there can be conflicts in the constraints each of them has on the form of rules and accommodating all of them can be a challenge. In this paper, we present a cubic time algorithm to find the best binarization tree, given the conflicting constraints. An SCFG rule is synchronously binarizable if when simultaneously binarizing source and target sides, virtual nonterminals created by binarizations always have contiguous spans on both sides (Huang, 2007). Algorithm 1 The CYK binarization algorithm.
 Even with the synchronous binarization constraint, many possible binarizations exist. Analysis of our Chinese-English parallel corpus has shown that the majority of synchronously binarizable rules with ar-ity smaller than 4 are monotonic , i.e., the target-side nonterminal permutation is either strictly increasing or decreasing (See Figure 1). For monotonic rules, any source-side binarization is also a permissible synchronous binarization.

The binarization problem can be formulated as a semiring parsing (Goodman, 1999) problem. We define a cost function that considers different bina-rization criteria. A CYK-like algorithm can be used to find the best binarization tree according to the cost function. Consider an SCFG rule X  X  h  X ,  X  i , where  X  and  X  stand for the source side and the tar-get side. Let B (  X  ) be the set of all possible bina-rization trees for  X  . With the cost function c defined over hyperedges in a binarization tree t , the optimal binarization tree  X  t is where c ( h ) is the cost of a hyperedge h in t .
The optimization problem can be solved by Al-gorithm 1. h i, k, j i denotes a hyperedge h that con-nects the spans ( i, k ) and ( k, j ) to the span ( i, j ) c can recover the optimal source-side binarization tree by augmenting the algorithm with back pointers. Binarized rules are generated by iterating over the nodes in the optimal binarization tree, while attach-ing unaligned target-side terminals. At each tree node, we generate a virtual nonterminal symbol by concatenating the source span it dominates.

We define the cost function c ( h ) to be a tuple of component cost functions: c ( h ) = ( c 1 ( h ) , c 2 ( h ) , ... ) pared, the components are compared piecewise, i.e. If the (min , +) operators on each component cost satisfy the semiring properties, the cost tuple is also a semiring. Next, we describe our cost functions and how we handle target-side terminals. 2.1 Synchronous Binarization as a Cost We use a binary cost b to indicate whether a binariza-tion tree is a permissible synchronous binarization. Given a hyperedge h i, k, j i , we say k is a permissible split of the span ( i, j ) if and only if the spans ( i, k ) and ( k, j ) are both synchronously binarizable and the span ( i, j ) covers a consecutive sequence of non-terminals on the target side. A span is synchronously binarizable if and only if the span is of length one, or a permissible split of the span exists. The cost b is defined as: b ( h i, k, j i ) = Under this configuration, the semiring operators (min , +) defined for the cost b are (  X  ,  X  ) . Using b as the first cost function in the cost function tuple guar-antees that we will find a tree that is a synchronously binarized if one exists. 2.2 Early Source-Side Terminal Matching When a rule is being applied while parsing a sen-tence, terminals in the rule have less chance of be-ing matched. We can exploit this fact by taking ter-minals into account during binarization and placing terminals lower in the binarization tree. Consider the following SCFG rule: The synchronous binarization algorithm of Zhang et most binarizable points on the source side: The source side of the first binarized rule  X  [] NN, propose a JJ NN  X  contains a very frequent non-terminal sequence  X  JJ NN  X . If one were to parse with the binarized rule, and if the virtual nontermi-nal [] following the binarization tree in order to determine whether the original rule would be matched. Further-more, having two consecutive nonterminals adds to complexity since the parser needs to test each split point.

The following binarization is equally valid but in-tegrates terminals early:
Here, the first binarized rule  X  [] pose a JJ  X  anchors on a terminal and enables earlier pruning of the original rule.

We formulate this intuition by asking the ques-tion: given a source-side string  X  , what binarization tree, on average, builds the smallest number of hy-peredges when the rule is applied? This is realized by defining a cost function e which estimates the probability of a hyperedge h i, k, j i being built. We use a simple model: assume each terminal or non-terminal in  X  is matched independently with a fixed probability, then a hyperedge h i, k, j i is derived if and only if all symbols in the source span ( i, j ) are matched. The cost e is thus defined as 2 For terminals, p (  X  the source side of the training corpus. For nontermi-nals, we simply assume p (  X 
With the hyperedge cost e , the cost of a binariza-tion tree t is P hyperedges to be built when a particular binarization for the cost e are the usual (min , +) operators on real numbers. 2.3 Maximizing Nonterminal Sharing During binarization, newly created virtual nontermi-nals are named according to the symbols (terminals and nonterminals) that they generate. For example, a new virtual nonterminal covering two nonterminals NP and VP is named NP+VP. To achieve maximum virtual nonterminal sharing, we also define a cost function n to count the number new nonterminals generated by a binarization tree. We keep track of all the nonterminals that have been generated when binarizing a rule set. When the i  X  X h rule is being binarized, a nonterminal is considered new if it is previously unseen in binarizing rules 1 to i  X  1 . This greedy approach is similar to that of DeNero et al. (2009b). The cost function is thus defined as: n ( h i, k, j i ) =
The semiring operators for this cost are also (min , +) on real numbers. 2.4 Late Target-Side Terminal Attachment Once the optimal source-side binarization tree is found, we have a good deal of freedom to attach target-side terminals to adjacent nonterminals, as long as the bracketing of nonterminals is not vio-lated. The following example is taken from Zhang et al. (2006): With the source-side binarization fixed, we can pro-duce distinct binarized rules by choosing different ways of attaching target-side terminals:
The first binarization is generated by attaching the target-side terminals as low as possible in a post-order traversal of the binarization tree. The conven-tional wisdom is that early consideration of target-side terminals promotes early language model score integration (Huang et al., 2009). The second bina-rization, on the contrary, attaches the target-side ter-minals as high as possible in the binarization tree. We argue that this late target-side terminal attach-ment is in fact better for two reasons.

First, as in the example above, compare the fol-lowing two rules resulting from early attachment of target terminals and late attachment of target termi-nals: The former has a much smaller chance of sharing the same target side with other binarized rules be-cause on the target side, many nonterminals will be attached without any lexical evidence. We are more likely to have a smaller set of rules with the latter binarization.

Second, with the presence of pruning, dynamic programming states that are generated by rules with many target-side terminals are disadvantaged when competing with others in the same bin because of the language model score. As a result, these would be discarded earlier, even if the original unbinarized rule has a high probability. Consequently, we lose the benefit of using larger rules, which have more contextual information. We show in our experiment that late target side terminal attachment significantly outperforms early target side terminal attachment.
Although the problem can be alleviated by pre-computing a language model score for the original unbinarized rule and applying the heuristic to its bi-narized rules, this still grants no benefit over late ter-minal attachment. We show in our experiment that late target-side terminal attachment significantly out-performs early target side terminal attachment. 3.1 Setup We test our binarization algorithm on an Chinese-English translation task. We extract a GHKM gram-mar (Galley et al., 2004) from a parallel corpus with the parsed English side with some modification so as not to extract unary rules (Chung et al., 2011). The corpus consists of 250K sentence pairs, which is 6.3M words on the English side. A 392-sentence test set was to evaluate different binarizations.
Decoding is performed by a general CYK SCFG decoder developed in-house and a trigram language model is used. The decoder runs the CYK algorithm with cube-pruning (Chiang, 2007). In all our exper-iments, we discard unbinarizable rules, which have been shown by Zhang et al. (2006) to have no signif-icant effect on translation accuracy. 3.2 Results We first discuss effects of maximizing nonterminal sharing. Having nonterminal sharing maximization as a part of the cost function for binarization did yield slightly smaller grammars. However, we could not discern any noticeable difference or trend in terms of BLEU score, decoding speed, or model score when comparing translation results that used grammars that employed nonterminal sharing max-imization and ones that did not. In the rest of this section, all the results we discuss use nonterminal sharing maximization as a part of the cost function.
We then compare the effects of early target-side terminal attachment and late attachment. Figure 2 shows model scores of each decoder run with vary-ing bin sizes, and Figure 3 shows BLEU scores for corresponding runs of the experiments. (b,n)-early is conventional synchronous binarization with early target-side terminal attachment and nontermi-nal sharing maximization, (b,n)-late is the same set-ting with late target-side terminal attachment. The tuples represent cost functions that are discussed in Section 2. The figures clearly show that late attach-ment of target-side terminals is better. Although Figure 3 does not show perfect correlation with Fig-ure 2, it exhibits the same trend. The same goes for (b,e,n)-early and (b,e,n)-late.

Finally, we examine the effect of including the source-side terminal-aware cost function, denoted  X  X  X  in our cost tuples. Comparing (b,e,n)-late with (b,n)-late, we see that terminal-aware binarization gives better model scores and BLEU scores. The trend is the same when one compares (b,e,n)-early and (b,n)-early. We examined binarizing synchronous context-free grammars within a semiring parsing framework. We proposed binarization methods that explicitly take terminals into consideration. We have found that al-though binarized rules are already scope 3, we can still do better by putting infrequent derivations as low as possible in a binarization tree to promote early pruning. We have also found that attaching target side terminals as late as possible promotes smarter pruning of rules thereby improving model score and translation quality at decoding time. Im-provements we discuss in this paper result in better search, and hence better translation.
 Acknowledgments We thank Hao Zhang for use-ful discussions and the anonymous reviewers for their helpful comments. This work was supported by NSF grants IIS-0546554 and IIS-0910611.
