 Twitter is one of the biggest platforms where massive instant mes-sages (i.e. tweets) are published every day. Users tend to express their real feelings freely in Twitter, which makes it an ideal source for capturing the opinions towards various interesting topics, such as brands, products or celebrities, etc. Naturally, people may an-ticipate an approach to receiving the common sentiment tendency towards these topics directly rather than through reading the huge amount of tweets about them. On the other side, Hashtags, starting with a symbol  X # X  ahead of keywords or phrases, are widely used in tweets as coarse-grained topics. In this paper, instead of pre-senting the sentiment polarity of each tweet relevant to the topic, we focus our study on hashtag-level sentiment classification. This task aims to automatically generate the overall sentiment polarity for a given hashtag in a certain time period, which markedly differs from the conventional sentence-level and document-level sentiment analysis. Our investigation illustrates that three types of informa-tion is useful to address the task, including (1) sentiment polarity of tweets containing the hashtag; (2) hashtags co-occurrence relation-ship and (3) the literal meaning of hashtags. Consequently, in order to incorporate the first two types of information into a classification framework where hashtags can be classified collectively, we pro-pose a novel graph model and investigate three approximate collec-tive classification algorithms for inference. Going one step further, we show that the performance can be remarkably improved using an enhanced boosting classificatio n setting in which we employ the literal meaning of hashtags as semi-supervised information. Ex-perimental results on a real-life data set consisting of 29,195 tweets and 2,181 hashtags show the effectiveness of the proposed model and algorithms.
 I.2.7 [ ARTIFICIAL INTELLIGENCE ]: Natural Language Pro-cessing X  Text analysis  X  This work has been done when the author was visiting Microsoft Research Asia.
 Algorithms, Experimentation Sentiment Analysis, Hashtag, Twitter, Graph-based Classification
Twitter 1 is popular for its massive spreading of instant messages (i.e. tweets) and the nature of freedom. Bursts of world news, en-tertainment gossips about celebrities, and discussions over the re-cently released products are all collected in Twitter vividly. Beyond merely displaying news and reports, the Twitter itself is also a large platform where different opinions are presented and exchanged. No matter where people come from, what religious belief they hold, rich or poor, civilized or uneducated , they comment, discuss, com-pliment, argue and complain over topics they are interested in, shar-ing their own feelings freely. It has been well recognized that these user-generated content with rich sentiment information should be utilized for many applications such as search engines and other in-formation systems.

While tweet level sentiment analysis results indeed provide very useful information, the overall or general sentiment tendency to-wards topics are more appealing in some scenarios. For example, people are curious about how others feel about Apple X  X  new prod-uct  X  X Phone4 X  and it will offer great convenience for them if major opinions are collected from massive tweets. Fans of Lady Gaga are fascinated about what is going on with their superstar and the reaction from other people. Wh ile reading news about political elections, it is expected to get an overview about the support and opposition for presidential candidates in Twitter at the same time. In all these scenarios, a comprehensive sentiment tendency analysis towards the topic during a time period is in need. In this paper, to address this demand, we utilize the unique characteristic of hashtag in Twitter.

In twitter, hashtags are a community-driven convention for adding additional context and metadata to tweets. They are created or-ganically by Twitter users as a way to categorize messages and to highlight topics, which is done by simply prefixing a word or a phrase with a hash symbol, such as  X #hashtag X . The extensive use of hashtags makes Twitter more expressive and welcomed by people. We measured on a datas et with around 0. 6 million ran-domly selected tweets and found that around 14.6% of them have at least one hashtags in each. When only considering the subjective http://twitter.com/ tweets (tweets with positive/negative sentiment expressions), this number increases to 27.5%. The statistics shows a great potential for sentiment analysis with hashtags in Twitter. Another aspect of analysis illustrates the close conn ection among the topic, sentiment and hashtags in Twitter. To be precise, hashtags can be catego-rized into three types. Most hashtags ( topic hashtags ) serve as user-annotated coarse topics, like in tweet  X  yesterday I watched ur movie again, and this time I cried. love u so much! #Justin_Bieber  X . In other cases, hashtags ( sentiment hashtags ) could be an easy way to highlight the sentiment information. This category of hashtags are composed of sentiment words only, such as  X #love X ,  X #sucks X , etc. Besides, the third kind of hashtags ( sentiment-topic hashtags) are those in which the topical word and the sentiment words appear together without separating blanks. For example,  X #iloveobama X  (I love Obama) directly expresses positive opinion towards Presi-dent Obama. Hence, hashtags falling in this category are even more informative since they explicitly indicate the sentiment target and its expression at the same time. Based on these observations, we believe the hashtag-level sentiment analysis will bring about much understanding about topics in Twitter.

One intuitive idea about the hashtag-level sentiment classifica-tion is to aggregate the sentiment polarity with the classification results for each corresponding tweet containing the hashtag. How-ever, this straightforward method does not perform well in our ex-periments. One major reason contributing to the poor performance is that even for the state-of-the-art sentiment classification algo-rithm, the accuracy for tweet-level sentiment classification is usu-ally not as high as expected, making the hashtag-level classification task even more challenging and intractable. We do not focus on the tweet-level sentiment analysis. Instead, we aim to seek other char-acteristics of hashtags to produce robust and reliable hashtag-level sentiment classification results. Specifically, besides the tweet-level sentiment analysis results, we have identified other two types of in-formation which is powerful for determining the sentiment polar-ity of hashtags. First, the co-occurrence relationship among hash-tags is important. In our Twitter dataset, we observe that for any two co-occurring hashtags, the probability to share the same sen-timent polarity is over 0.8055. However, when they are randomly chosen, the value drops to 0.5324. This comparison implies the possibility to employ this pair-wise information to boost the classi-fication performance. Second, th e hashtag literal meaning is an-other useful feature. For the sentiment hashtags (e.g.  X #love X ,  X #sucks X ), we find they often appear together with topic hashtags (e.g.  X #iPad X ,  X #Obama X ) to form tweets, conveying the sentiment tendency towards the topics clearly; For the sentiment-topic hash-tags like  X #iloveobama X , they are sufficiently self-explainable to indicate the sentiment polarity and the targets explicitly. Accord-ingly, we are motivated to incorporate the co-occurrence relationsip and the literal information of hashtags into the classification frame-work, leading us to the the hashtag graph model as presented in this paper.

Particularly, we propose a novel graph model, which incorpo-rates the co-occurrence information of hashtags, to tackle the prob-lem and adopted three popular inference algorithms for the graph-based classification (Loopy belief propagation (LBP) [18], Relax-ation labeling (RL) [19] and Iterative classification algorithms (ICA) [15]). Furthermore, we utilized the literal meaning of hashtags as semi-supervision information in our enhanced boosting setting. We compare the results with the SVM-voting baseline, which employs a two-stage support vector machine (SVM) [4, 2] to generate the tweets X  sentiment polarity probability distribution and then votes for hashtag classification. Experiment results on a real-life tweet corpus demonstrates the effectiveness of the proposed model and algorithms.

Paper Organization The rest of this paper is organized as fol-lows. We present our graph model and three classification algo-rithms in section 3 after a brief review of the related work in Sec-tion 2. Then, we present the experiments in Section 4 and conclude the paper in Section 5 with some future work.
The task of sentiment analysis (SA), a.k.a. opinion mining, has been a hot topic in the research community for years. Previous research on sentiment analysis [8, 30] mainly focuses on product or movie reviews, which are experimentally convenient and easy for evaluation. For other document types including webpages and news, efforts are also made to explore the same task [28]. While the bulk of such work has focused on the document level, some others [27, 23, 22] address the sentiment analysis in the phrase and sen-tence level which regards sentences (phrases) as classification sam-ples. The objective of above works is to obtain the sentiment polar-ity for given text (snippets, sentences, or documents). As compared to this thoroughly studied problem, the sentiment analysis for top-ics is rarely investigated. Though some work attempt to incorporate the sentiment factor into topic models like probabilistic latent se-mantic indexing (PLSI) or latent Dirichlet allocation (LDA) to give the description about opinion generation [12, 10], it is still hard to reach an agreement for the defin itions about topics and how to ex-plain the meaning of sentiment classification (positive/negative) for them. The problem lies in that the definition for topic/entity sen-timent polarity using only one-bit representation (positive or neg-ative) is not well-posed. In our work, we try to avoid this critical question but instead aim to provide a sentiment-based snapshot for topics in one period through analyzing corresponding tweets and investigating other features. This task is more clarified and clearer because the opinion tendency for a given topic in a certain time in-terval is usually associated with some burst events and hence the sentiment classification for topics makes sense.

In terms of methodology, natural language processing techniques and machine learning approaches are two major popular methods for sentiment analysis. Many research followed the natural lan-guage processing way to tackle the problem. Nasukawa and Yi [14] proposed an approach to identify the semantic relationship between the target and expression with a syntactic parser and sentiment lex-icon. In addition, Ding and Liu [7] used linguistic rules to detect the sentiment orientations in product reviews. Although rule-based methods for identifying the sentiment polarity and targets are ef-fective, the major drawbacks are that it cannot be extended with-out expert knowledge and the coverage of rules is not satisfactory. While on the other hand, Pang et al. [17] investigated three ma-chine learning methods to produce automated classifiers to gener-ate the class labels for movie reviews. They tested on Na X ve Bayes, Maximum Entropy and Support Vector Machine, and evaluated the contribution of different features including unigrams, bigrams, ad-jectives and POS-tags. Their experimental results found that the SVM classifier with unigram presence features outperformed other competitors. In [16], they tried to separate the subjective portions from the objective ones through finding minimum cuts in graphs to achieve better sentiment analysis performance. Generally, the machine learning based approaches usually have higher recall than rule-based methods because of th e strong generalization ability of classifiers. However, the performance of classifiers is extremely sensitive to the quality of training data [13, 3, 29], making the text-level sentiment analysis using machine learning techniques rather unreliable. As a result, in this paper, we not only leverage the sen-timent classification for each tweet but also incorporate the link in-formation among hashtags and the literal meaning of them to solve the hashtag sentiment classification problem, which is expected to be more robust and reliable.

Recently, the opinion mining research has begun to pay more and more attention to social networks such as Twitter because they give rise to the massive user-generated publishing activities. In Twitter, a huge amount of tweets contain sentiment information. Barbosa and Feng [2] first investigat a two-stage SVM (subjectivity and po-larity) classifier which seems to be more robust regarding biased and noisy data. In this paper, we adopt this two-stage classifica-tion framework to build our tweet-level classifier. In Twitter, some unique characteristics can also be utilized for sentiment classifica-tion. Davidov et al. [5] employ hashtags and smileys as sentiment labels for classification to allow diverse sentiment types for short texts. In their another paper [6], they analyze the use of  X #sarcasm X  hashtags and addressed the problem of sarcastic tweets recognition. Jiang et al. [9] propose to take the target of sentiment into consid-eration in Twitter sentiment analysis, where the hashtags were also utilized as unigram f eatures. Although the hashtag has become a key feature in many micro-blog services, to our best knowledge, our paper is the first to address the task of hashtag-level sentiment classification.
We start this section with a formal definition for the task of hashtag-level sentiment classification 2 . Given a set of hashtags H = { h 1 ,h 2 ,...,h m } where each hashtag h i is associated with a set of tweets T i = {  X  i 1 , X  i 2 ,..., X  in } , we aim to collectively infer the sentiment polarities, y = { y 1 ,y 2 ,...,y m } { pos, neg } 3 ,for H . Weassumethehashtagsin H are with senti-ments. The reason lies in that we are particularly interested in the hot hashtags (i.e. topics) which are usually accompanied with sen-timent since people tend to express rich sentiment information in their tweets towards these hot topics. The hashtag-level sentiment classification inherently bases upon the tweet-level sentiment anal-ysis results. Let C T be a tweet-level classifier where each tweet  X  can be assigned with positive or negative probability Pr pos Pr neg (  X  ) , ensuring that Pr pos (  X  )+Pr neg (  X  )=1 to form a binary probability distribution. Here, neu tral tweets are ignored since they are not useful for the polarity prediction of hashtags. We develop C
T using the state-of-the-art sentiment analysis method, which is presented in details in Section. 4.2.

We can obviously induce the sentiment polarity y i for the hash-tag h i through aggregating the results from C T by a simple voting strategy. This approach, as stated in Section. 4.3, takes the clas-sification for each hashtag independently. As seen in our experi-ments, the result is not promising. We have shown that hashtags co-occurring in tweets have much higher probability to share the same sentiment polarity than that if they are randomly selected. This observation clearly motivates us to conduct the hashtag-level sentiment classification collectively, which has been proven to be effective in link-based text classification [24, 20]. In the rest of this section, we will first introduce the hashtag graph model and then present the classification framework and the approximate al-gorithms for inference.
For the sake of simplicity, we restrict our scenario within the con-text of Twitter, although applying this framework to other micro-blogs where hashtags also exist is straightforward.
Hereafter, we use pos and neg to represent positive and negative label, respectively. We define a hashtag graph HG = {H , E} , in which the edge set E consists of links between hashtags and each edge e ij represents an undirected link between hashtags h i and h j , which co-occur in at least one tweet. Figure. 1 illustrates an example of the hashtag graph, in which hashtags are linked if and only if they co-occur at least once in tweets. Here we take the hastag  X #obama X  as an exam-ple. The surrounding hashtags are generally of three categories: (1) topics which is closely connected to Obama (e.g.  X #president X  and  X #healthcare X , etc.); (2) sentiment hashtags which expresses sub-jective opinions towards Obama, like  X #ideal X ,  X #leader X  and (3) sentiment-topic hashtags which indicate the target and the senti-ment polarity simultaneously, such as  X #iloveobama X . From this figure, as we can see, the neighbor hashtags more or less lend some sentiment tendency to  X #obama X . Consequently, It would be unwise if we independently determine the sentiment polarity of each hashtag. Our graph model is aimed at incorporating the co-occurrence relationship and deciding sentiment polarity collec-tively.

Given the hashtag graph, our ultimate goal is to assign each hash-tag h i with a proper sentiment label y i  X  X  pos, neg } .Wemake the Markov assumption that the determination of sentiment polar-ity y i can only be influenced by either the content of correspond-ing tweets  X   X  X  i or sentiment assignments of neighbor hashtag h j s.t. ( h i ,h j )  X  X  , which results in our HG a pairwise Markov Network [21]. This leads us to the following factorized distribution: where the first and second sums correspond to the potential func-tions of a tweet-based factor and a hashtag-hashtag factor. Z is the regularization factor. The potential function of tweet-based factor can be directly obtained through calculation of the polarity proba-bility for each corre sponding tweet; while the h ashtag-hashtag fac-tor potential function should incorporate the link information to allow the neighbor hashtags to influence the classification result. The potential functions will be explained together with the infer-ence algorithms in the subsequent section. Given this formula, our objective is to maximize the following function with appropriate sentiment labels:
As for solving the assignment inference problem given the graph model, many efforts are made and some good inference algorithms are proposed as well. In [11], a structured logistic regression based algorithm is investigated as inference method in a link-based text classification framework. Angelova and Weikum [1] combine Re-laxation Labeling [19] inference algorithm and Na X ve Bayes to form a context-aware approach for hyperlinked text classification. In this paper, we investigate LBP, RL and ICA as inference approaches to solve the hashtag-level sentiment classification problem.
With graph HG containing cycles and no apparent structure, it becomes infeasible to apply exact inference to the optimization function (Equation. 2). Instead, we present three approximate col-lective classification algorithms (ACCAs): Loopy Belief Propaga-tion (LBP), Relaxation Labeling (RL) and Iterative Classification Algorithm (ICA) to infer the probable sentiment assignment to each hashtag.
As an iterative algorithm, LBP tries to classify each node in a graph through belief message passing. It is originally proposed to work for tree-like networks as a Bayes likelihood-ration updating rule [18]. Although not guaranteed to converge to a fixed point after any number of iterations, LBP shows surprisingly good per-formance in practice, as discovered by [25]. In fact, the propagation process tries to reach the stationary points of the Bethe approxima-tion free energy for a factor graph [26].

We define the potential functions as follows: where I y j = y k is the identity function with value 1 when y and 0 otherwise. #( h j ,h k ) denotes the number of co-occurrence for hashtag h j and h k and #( h j ) is the number of occurrence that h j appears in tweets. Through this setting, the co-occurrence re-lationship and the label information of the hashtags are taken into account in the hashtag-hashtag factor potential function.
To obtain the result, we compute in an iterative fashion. The Al-gorithm. 1 is described in pseudo code. In the algorithm,  X  is a pro-visional computed normalized factor which keeps that m i  X  m  X  j ( neg )=1 . The sum of polarity pr obability of correspond-ing tweets was used as tweet-based factor potential function. The tweet-level classifier is used as a weak classifier to generate the ini-tial classification probability for hashtags. Propagation procedure can be viewed as a boosting process which relabels the hashtags after iteration terminates. During the loops, the positive (or neg-ative) messages conveyed from hashtag h i to h j , as denoted by m  X  j ( pos ) (or m i  X  j ( neg ) ), are continuously updated until con-vergence is reached, as shown in the innermost loop of the iterative procedure. These converged message values are then used to com-pute the final class labels at last.
 Algorithm 1: Loopy Belief Propagation Input : Hashtag Graph HG
Output : Sentiment label for each hashtag h begin
Relaxation Labeling is an alternative inference algorithm for graph-based classification models. Rosenfeld et al. [19] first investigate the RL algorithm in the vision community. Later, it was applied as a general rational classification algorithm. In [1], the algorithm was adopted for text categoriza tion. Unlike LBP, which explicitly defines the potential functions for tweet-based factor and hashtag-hashtag factor, RL assumes that d i,j denotes the  X  X mprotance X  of node j to its neighbor i and r ( y i ,y j ) to be the  X  X ompatibility X  be-tween labels y i and y j , and hence updates t he polarity probability of hashtags accordingly at each iteration.

Here, we use b i ( y i ) to denote the possibility that hashtag h beled with assignment y i . To measure the compatibility of two sen-timent labels, we compute the correlation of any two label (positive or negative) types, as suggested in the nonlinear probabilistic case by [19]. To be precise, at the initialization stage of the algorithm, we aggregate the averaged pol arity probability of corresponding tweets as the sentiment probability distribution for hashtags, and then assign the label with the max probability to hashtags. Then, the marginal probability of a label and joint probability of any two labels ( pos -pos , neg -neg and pos -neg ) can be directly estimated from the assignments. The correlation function is defined as:
Naturally, it is expected that the hashtags that are more likely to co-occur in tweets to have more mutual influence. We hereby have:
The procedure is presented in Algorithm. 2
In [15], the iterative classification algorithm is presented to ex-plore the relational data. Algorithm. 3 begins by classifying each hashtag using its tweet-based factor potential function. Each itera-tion recomputes the hashtag X  X  polarity distribution conditioned on Algorithm 2: Relaxation Labeling Input : Hashtag Graph HG
Output : Sentiment label for each hashtag h begin the current neighborhood polarity probabilitie s. At the end of each iteration, it relabels the top-k confident hashtags, where k is a value linearly increasing with the number of iterations. And the last iter-ation will update polarity assignments for all hashtags.

In our experiment, we have: p i ( y i | HG , y )  X  exp We describe the algorithm below in Algorithm. 3 Algorithm 3: Iterative Classification Algorithm Input : Hashtag Graph HG
Output : Sentiment label for each hashtag h begin
The three approaches mentioned above use the sentiment labels of corresponding tweets obtained from the tweet-level classifier to initialize the sentiment polarity distribution for every hashtag. Through taking the co-occurrence relationship among hashtags into consideration, the graph-based model, however, boosts the classifi-cation result.

Based on previous observations, the sentiment hashtag and sentiment-topic hashtags can indicate the opinion tendency from its literal in-formation. Examples like  X #iloveobama X ,  X #sucks X ,  X #awesome X ,  X #horrible X , are all self-explainable to infer the sentiment informa-tion merely from the hashtag itself explicitly. An interesting obser-vation is that these two kinds of hashtags are usually accompanied with topical hashtags. One simple example tweet is:  X  Restoring my #Ipod yet again. #Apple software is such crap that I have to do this routinely. #Apple, fix your software for #Ipod. It #sucks!  X . The topical hashtags  X #Apple X ,  X #Ipod X  show up together with hash-tag  X #sucks X . This pattern strongly conveys negative opinion from  X #sucks X  to  X #Apple X  and  X #Ipod X .

We expect to further enhance the classification algorithms through introducing a semi-supervised adaptive iteration manner which also take advantage of the literal meaning of hashtags. In our work, we first construct a strong sentiment lexicon, specified with labels { pos, neg } . We assume that hashtags containing these words have the same polarity as the sentiment lexicon. In the three graph-based algorithms, provided the semi-supervision information, we do not use the tweet-level classifier to initialize its sentiment distribution of these self-explainable hashtags. Instead, we fix their sentiment polarity probability from the beginning. In other words, these label-fixed hashtags are not involved in polarity distribution updating, but only offer sentiment influence to others. Experimental results show that this semi-supervised manner of enhanced boosting classifica-tion significantly improves the performance.

Because the enhanced boosting se ttings for three inference al-gorithms are similar, due to the page length constraint, we only present the major difference of the boosted LBP algorithm as com-pared with the original version.

For hashtag set  X  H X  X  , each hashtag h i in  X  H contains strong sentiment lexicon which is sufficient to indicate the sentiment po-larity y  X  h i . Unlike the original initialization stage, for h
Thus the formulas ensure the sentiment assignment for hashtags in  X  H to be the same as its contained sentiment words. The main difference with the unboost version lies in the iteration procedure, we show the different part in Algorithm. 4: Algorithm 4: Enhanced Boosting Loopy Belief Propagation Input : Hashtag Graph HG
Output : Sentiment label for each hashtag h begin  X  X  X  Figure 2: An example of the enhanced boosting classification setting in which strong sentiment hashtags only provide polar-ity influence to neighbors. Hashtags in red are positive label-fixed nodes and green are negative.

To illustrate this better, we present an example in Figure. 2, where the hashtag  X #ipad X  has several strong sentiment neighbors such as  X #love X  and  X #isuck X . In our enhanced boosting setting, these colored neighbors will not get involved in dynamic updating them-selves but only send polarity influence to surrounding neighbors. The propagation from  X #ipad X  to these colored neighbors will be neglected and blocked.
The evaluation of the hashtag-level sentiment classification is challenging because it is difficult to collect the  X  X olden standard X  data set. Although human annotation is possible, we maintain that the workload is rather demanding for large scale evaluation data. What makes it more unreliable is that the satisfactory inter-annotator agreement cannot be achieved, with two contributing factors being that hashtags are often used in tweets with different sentiments, and the sentiment polarity of tweets cannot always be determined with confidence. Instead, in our experiments, to evaluate the per-formance of the hashtag sentiment classification and to collect the training data for enhanced boosting classification, we use a self-annotation manner to label the dataset.

The data collection process is described as follows. We first ran a coarse-grained selection to find hashtags that we are interested in. We picked 10 topics including  X  X bama X ,  X  X ush X ,  X  X ady Gaga X ,  X  X ustin Bieber X ,  X  X slam X ,  X  X akers X ,  X  X outube X ,  X  X Pad X ,  X  X ndroid X  and  X  X icrosoft X . Then we searched from the tweets pool for hash-tags containing the topic words as our seeds. This seed set was hence expanded into our hashtag set H by retrieving all hashtags that has co-occurred with at least one of the seed hashtags. Finally, for the selected hashtags in H , we labeled hashtags containing sen-timent words 4 with appropriate sentiment polarity labels ( pos , neg ). This subset of H , denoted by  X  H , is used as our label-fixed set for enhanced boosting classification and test set for evaluation to mea-sure the accuracy, precision, recall and F1 metrics. In addition, we
In our experiments, we selected 50 strong positive and 50 strong negative words as our sentiment lexicon conduct a case study to illustrate so me interesting results in Sec-tion. 4.6.

In our experiments, our tweets pool has about 0.6 m illion tweets which were collected in one week period from Twitter. After the seeds selection and data enrichment process, we obtain H consist-ing of 2,181 hashtags which occur in 29,195 tweets. The size of edge set E is 27,430. Selecting hashtags containing strong senti-ment words results in a subset  X  H containing 947 examples, which has 595 positive samples and 352 negative samples. The remaining hashtags in H do not have a automatic annotated groundtruth, but the classification of them can be evaluated through the case study. This dataset is used for measuring the performance of hashtag sen-timent classification algorithms. For enhanced boosting classifica-tion approaches, this dataset will be spilled into the training set and test set to evaluate the classification result with cross validation.
In this paper, we build the hashtag-level sentiment classification on top of the tweet-level sentiment analysis results. Basically, we adopted the state-of-the-art tweet-level sentiment classification ap-proach [2], which uses a two-stage SVM classifier to determine the sentiment polarity of a tweet. The first (i.e. subjectivity) classi-fier determines whether a tweet is neutral or subjective while the second one (i.e. polarity classifier) assigns a subjective tweet with positive or negative polarity. The SVM light package 5 is used in our experiments. The two SVM classifiers take the same features as input, which are divided into two categories: subjectivity(1) 83.13% 59.45% 36.59% 45.27% We use the subjectivity classifier to filter out the neutral tweets. The output of the polarity classifier for a subjective tweet is a real value score s which is positive when predicting the tweet t as pos-itive and negative when predicting as negative. Since we need to convert this value into the polarity probability, we use an empirical threshold  X  =2 and the following formula is adopted, which is similar to the manner introduced in [16] : http://svmlight.joachims.org/ http://www.wjh.harvard.edu/ inquirer/ SVM-voting 55.96 64.03 68.23 66.06 39.61 35.22 37.29
We manually annotated around 15,000 tweets which are ran-domly selected from the 0.6 million tweets. The tweets are labeled with positive, negative or neutral. Table. 1 shows results of the two-stage SVM tweet-level classifier with 5-fold cross validation. For the two binary classifiers, i.e. subjectivity SVM and polarity SVM, we report the accuracy, precision, recall and F1 values for subjective and positive classes respectively. We also give the over-all accuracy for the tweet-level sentiment classifier.

It should be noted that while the accuracy gives an overall eval-uation of the classification performance, the precision, recall and F1 values are equally important. These metrics reveal much more information about the classification property, especially when the data is imbalanced. In real-life tweets data, the subjective class is only a minority part: merely 23.8% tweets are subjective in our 15,000 tweets dataset. It is worthy observing that the subjectiv-ity classifier, though have a high accuracy (83.13%), shows ex-tremely low precision (59.45%) and recall (36.59%) for the sub-jective class, which points out the low ability for discriminating subjective tweets. However, the error analysis and the improving for the tweet-level sentiment classifier is out of the scope of this paper.
Intuitively, we can aggregate the hashtag-level sentiment polarity from the results of the tweets containing the hashtag through sim-ple voting methods. We build the SVM-voting baseline approach on the tweet-level classifier. To estimate the positive/negative prob-ability for one hashtag, we use the average polarity distribution of tweets containing hashtag h :
The results of the SVM-Voting method is presented in Table. 2, which is not promising. The reason lies in that the tweet-level sen-timent analysis results are not reliable. We maintain that the low discriminating ability for subjective class is the major cause of this low accuracy (55.96%). This observation motivates us to exploit other available information for this task, as detailed in Section 4.4.
We compare the three approximate collective classification algo-rithms with the SVM-voting baseline in this section. The aim is to examine the effectiveness of employing the hashtag co-occurrence information and enhanced boosting techniques in the context of hashtag-level sentiment classification.
 Table. 2 shows the comparison results. The iteration number for ICA is set to M =10 in our experiments. As shown, linked-based algorithms (i.e. LBP, RL and ICA) achieve encouraging results compared to the baseline approach, which clearly demonstrates the effectiveness of the hashtag co-occurrence information in the proposed graph-based model for hashtag-level sentiment classifi-cation. The improvement mainly comes from the identifying of negative class, the F1 score of which has a remarkable increase from 37.29% to 54.50% (for LBP). Since the number of negative hashtags (352 out of 947) is much less than that of the positive ones, this benefit from link-based algorithms is not very significant. An-other major reason for this result, as we found in the experiments, is that the hashtag Graph HG suffers the problem of sparseness. The graph density D 7 is as low as 0.011, which indicates HG is very sparse. Therefore, many hashtags receive little sentiment propaga-tion from their few neighbors and the final classification result is biased by the SVM-voting outcome.

We further add the enhanced boosting versions of the graph-based algorithms into our performance comparison. In this boost-ing setting, we run each experiment with 10-fold cross validation, separating the hashtags containing strong sentiment words samples) into a training set and a test set (the proportion of the training set to  X  H is 0.9). The polarity distribution of the labeled set is fixed during iterations. These label-fixed hashtags only play the role of sentiment propagation. Their impact to neighbors is strengthened and results in a notable performance gain, which can be shown from the comparison. In Table. 2, we observe that the most significant improvement is from the boosting loopy belief propagation, with the high classification accuracy up to 77.72%. The other two boosting ACCAs also increase the performance con-siderably, as compared with the corresponding un-boosting ver-sions. As for the precision of positive (up to 98.33%) and negative class (up to 63.02%), significant progress is also witnessed. Taking these factors into consideration, we conclude that the literal infor-mation of hashtags and the semi-supervised boosting classification approaches are able to greatly enhance the discriminating ability for hashtag-level sentiment classification.
In our enhanced boosting setting, we utilized the literal meaning of hashtags as semi-supervision information. Specifically, we sep-arate the hashtag set  X  H into a label-fixed training set and an test set for performance evaluation. The training set provides sentiment influence to other hashtags in iterations but blocks the propagation back from them. We vary the size of label-fixed set used in each algorithm by randomly selecting a certain number of labeled hash-tags. The size of training set is measured by the proportion to the
To measure the density of a graph, we use the metric  X  X raph Den-all strong sentiment hashtags  X  H (947 hashtags). The remaining hashtags in
Hashtag SVM HG Neighbors offering Example tweets correct impacts #gaga pos neg #hate, #gay Say I worship #Gaga... Ok... does that mean I am #gay? total labeled 947 hashtags  X  H . Meanwhile, we should keep it in mind that there are altogether 2181 hashtags in HG , the remaining of which are not included in the performance test for calculation of precision, recall, F1 and accuracy metrics, but will be used for case study in the following section.

Figure. 3 presents the values of macro F1 and accuracy against varying amount of label-fixed hashtags. The reported values are calculated with 10-fold cross validation. It reflects a strong consis-tence of the changing tendency for the two metrics. We observe that when little labeled data is provided (0.1 to 0.4), the performance for the three algorithms is stable. The values for macro F1 and accuracy has a notable increase when more labeled hashtags are added, strongly indicating that increasing the amount of training set will effectively improve the overall performance for our graph models. Besides, we can see the performance for ICA and LBP are very close with each other. While on the other hand, we argue that the performance of RL is below the other two algorithms all along. This is because that the correlation between two labels is calculated with the initial probability distribution and will not be updated afterwards in RL.
We investigate the result of hashtag-level sentiment classifica-tion by looking at some specific examples. We list some interesting hashtags that can be classified correctly only by our proposed graph model in Table. 3. Since we do not intend to highlight the perfor-mance of any specific ACCA, we present the result obtained from LBP only. We list the hashtags together with their neighbors that offer impacts to change their polarity assignments into correct la-bels 8 and corresponding tweets.

In this list, topic hashtags like  X #obama X  were classified as nega-tive by SVM-voting at first. This is not true since through our anal-ysis, we found that  X #iloveobama X ,  X #change X , and  X #ideal X , and other positive hashtags are often show up together with  X #obama X , and these neighbor hashtags are created by users to highlight their sentiment tendency towards  X #obama X , as shown in the following tweets in Table. 3. The collective classification for hashtags can be extremely effective especially when the tweets are not straightfor-ward enough for sentiment classification with the two-stage SVM. The example tweets for  X #ipad X :  X  X ames for Cats on #iPad #jaja #ILoveIPad http://youtu.be/vaif2uq_0Vc X , fails to be predicted cor-rectly with the tweet-level classifier since it cannot capture the pos-itive sentiment from  X #ILoveApple X  at all. Another tweet talking about Lady Gaga  X  X ay I worship #Gaga... Ok... does that mean I am #gay? X  implicitly conveys the negative sentiment which is far too difficult for the tweet-level sentiment classification.
There are three reasons for the low performance of the SVM-voting baseline: (1) Tweets are short and it is hard to infer the sentiment polarity only with the unigram and sentiment lexicon features; (2) tweets contain links directing (or redirecting, such as  X  X ttp://bit.ly/eZJDoJ X ) to videos or news that reflect the author X  X  underlying sentiment towards the topics cannot be analyzed suc-cessfully. (3) Tweets contain both positive and negative sentiment expression towards topics, like  X  iTunes is good software but it fails as usually as you use :) #fail #itunes #apple  X . These factors make the tweet-level classifier and our baseline rather sensitive to noisy
After reprocessing, hashtags are case-insensitive. data, leading to an poor hashtag-level sentiment analysis perfor-mance.

Incorporating the neighbor hashtag sentiment information gives us a chance to relabel hashtag polarity collectively. This method improves the performance since it tolerates the error introduced by the tweet-level classification and allow the mutual sentiment influ-ence among hashtags.
In this paper, we investigate a novel task, i.e. sentiment classifi-cation of hashtags in Twitter. We believe this is important for senti-ment analysis of topics since hashtags can be approximately viewed as user-annotated topics. We develop the baseline approach on sen-timent analysis results of the tweets containing the hashtag through simple voting strategy. The performance of this intuitive approach is not encouraging as we expected. In order to improve the hashtag-level sentiment classification, we propose a graph model to boost the results from the voting baseline, which effectively incorporates the tweets sentiment information and hashtags co-occurrence rela-tionship. The preliminary results demonstrate that our graph model is able to give competitive performance as compared with the base-line. Going one step further, by extracting the literal sentiment hint from hashtags, we construct the enhanced boosting hashtag classi-fication framework, in which self-explainable hashstags are label-fixed and not updated for polarity, but only offering sentiment in-fluence to neighbor hashtags. Experiment results show significant improvements are achieved in this boosting settings.

There exists some possible extensions to our work. It would be interesting if we can produce a short summary for hashtags based on the sentiment classification. For example, for a new product it is expected to present a list of related features together with typ-ical sentiment expressions, beyond the one-bit snapshot (positive or negative). In addition, we envision to employ the classification of hashtags to enhance the tweet-level sentiment categorization in return.
This study is partially supported by the HGJ Grant (No. 2011ZX 01042-001-001) as well as The Specialized Research Fund for the Doctoral Program of Higher Education of China under Grant (" FSSP" Grant No.20100001110203). [1] R. Angelova and G. Weikum. Graph-based text [2] L. Barbosa and J. Feng. Robust sentiment detection on [3] D. Blaheta. Handling noisy training and testing data. In [4] C. Cortes and V. Vapnik. Support-vector networks. Machine [5] D. Davidov, O. Tsur, and A. Rappoport. Enhanced sentiment [6] D. Davidov, O. Tsur, and A. Rappoport. Semi-supervised [7] X. Ding and B. Liu. The utility of linguistic rules in opinion [8] M. Hu and B. Liu. Mining and summarizing customer [9] L. Jiang, M. Yu, M. Zhou, X. Liu, and T. Zhao.
 [10] C. Lin and Y. He. Joint sentiment/topic model for sentiment [11] Q. Lu and L. Getoor. Link-based classification. In Machine [12] Q. Mei, X. Ling, M. Wondra, H. Su, and C. Zhai. Topic [13] P. Melville, N . Shah, L. Mihalkova, and R. Mooney. [14] T. Nasukawa and J. Yi. Sentiment analysis: capturing [15] J. Neville and D. Jensen. Iterative classification in relational [16] B. Pang and L. Lee. A sentimental education: Sentiment [17] B. Pang, L. Lee, and S. Vaithyanathan. Thumbs up? [18] J. Pearl. Reverend bayes on inference engines: A distributed [19] A. Rosenfeld, R. A. Hummel, and S. W. Zucker. Scene [20] P. Sen and L. Getoor. Link-based classification. In Technical [21] B. Taskar, P. Abbeel, and D. Koller. Discriminative [22] T. Wilson, J. Wiebe, and P. Hoffmann. Recognizing [23] T. Wilson, J. Wiebe, and P. Hoffmann. Recognizing [24] Y. Yang, S. Slattery, and R. Ghani. A study of approaches to [25] J. S. Yedidia, W. T. Freeman, and Y. Weiss. Generalized [26] J. S. Yedidia, W. T. Freeman, and Y. Weiss. Constructing [27] H. Yu and V. Hatzivassiloglou. Towards answering opinion [28] W. Zhang, C. Yu, and W. Meng. Opinion retrieval from [29] X. Zhu, X. Wu, and Y. Yang. Effective classification of noisy [30] L. Zhuang, F. Jing, and X. Y. Zhu. Movie review mining and
