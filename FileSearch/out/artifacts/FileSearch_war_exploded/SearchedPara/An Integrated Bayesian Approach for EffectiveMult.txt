 Truth-finding is the fundamental technique for corroborat-ing reports from multiple sources in both data integration and collective intelligent applications. Traditional truth-finding methods assume a single true value for each data item and therefore cannot deal will multiple true values (i.e., the multi-truth-finding problem). So far, the existing approaches handle the multi-truth-finding problem in the same way as the single-truth-finding problems. Unfortu-nately, the multi-truth-finding problem has its unique fea-tures, such as the involvement of sets of values in claims, different implications of inter-value mutual exclusion, and larger source profiles. Considering these features could pro-vide new opportunities for obtaining more accurate truth-finding results. Based on this insight, we propose an inte-grated Bayesian approach to the multi-truth-finding prob-lem, by taking these features into account. To improve the truth-finding efficiency, we reformulate the multi-truth-finding problem model based on the mappings between sources and (sets of) values. New mutual exclusive relations are de-fined to reflect the possible co-existence of multiple true val-ues. A finer-grained copy detection method is also proposed to deal with sources with large profiles. The experimental results on three real-world datasets show the effectiveness of our approach.
 H.2.8 [ Information Systems ]: Database Management X  Data Mining ; I.2.m [ Computing Methodologies ]: Artifi-cial Intelligence X  Miscellaneous Models; Algorithms; Experimentation; Measurement Truth discovery; multi-truth-finding features; Bayesian model; data source dependence
Integrating data from multiple sources has been increas-ingly becoming a commonplace in both Web and the emerg-ing Internet of Things (IoT) applications to support collec-tive intelligence and collaborative decision making [4]. Un-fortunately, it is not unusual that the information about a single item comes from different sources, which might be noisy, out-of-date, or even erroneous. It is therefore of paramount importance to resolve such conflicts among the data and to find out which piece of information is more reli-able [15]. For example, in a recent controversy on Obama X  X  birthplace 1 , some people rumored Kenya, while others in-sisted on Hawaii. Clearly, such conflicts can be extremely disturbing and misleading to the users who want to find the specific facts on something or somebody they concern [12]. Solutions to this challenge are generally recognized as truth-finders . Different from methods that seek non-factual truth (e.g., aggregating users X  rating on a product, or analyzing people X  X  opinions on a recent event), truth-finders aim at dis-covering the factual truth, such as the birthplace of Obama and the capital city of the United States.

While the single-truth-finding problem (STF) X  X hich aims at finding the single true value for an item X  X as been widely studied, a more general case, where multiple true values (or multi-truth) might exist for a single item, is rarely ex-plored [24]. In fact, multi-truth scenarios commonly exist in our real lives. For example, a book is usually authored by several people; a conference may have several deadlines; and the presidents of the United States involve a long list of names. We recognize the discovery of multiple true values (for either one or multiple data items) as the multi-truth-finding problem (MTF), of which STF can be treated as a special case. We identify the main challenges on solving MTF as follows: http://beforeitsnews.com/obama-birthplace-controversy/
In this paper, we propose an integrated Bayesian approach to address the above challenges. In a nutshell, we make the following main contributions:
The rest of the paper is structured as follows. Section 2 reviews the related work. Section 3 reformulates the multi-truth-finding problem. Section 4 presents the details of our solution, including the integrated Bayesian model and the
Dependent sources are those sources that rely on other sources to provide data, e.g., copiers or aggregators. related algorithms. Section 5 reports our experimental re-sults. Finally, Section 6 provides some concluding remarks.
Over the last few years, truth finding has become an active research area [21, 3, 5, 24, 9, 11]. Early truth-finding meth-ods either take the mean or median (for numerical data) or employ the majority voting (for categorical data) to predict the truth. These methods treat every source equally and ne-glect their quality differences [1]. Recent approaches differ-entiate sources by giving more credit to trustworthy sources and propose solutions for the quality estimation of data sources. TruthFinder [21] alternately computes two mea-sures, the confidence of fact (here, facts refer to values) and the trustworthiness of source , from each other through an iterative procedure. Pasternack et al. [16] propose Average-Log , Investment and PooledInvestment to avoid overestimat-ing the trustworthiness of those sources that make more claims. Galland et al. [5] propose Cosine and 2-Estimates to incorporate the mutual exclusion between categorical values. In [5], the authors refine the 2-Estimates algorithm by in-troducing a new measure, hardness of fact ,toestimatehow hard in obtaining each fact. Truth-finding has also been modeled as optimization problems. The Conflict Resolution on Heterogeneous Data (CRH) framework recently proposed by Li et al. [11] models truth-finding as the problem of min-imizing the weighted deviation of multi-source inputs from the estimated truth. Yin and Tan [22] employ a different optimization model and propose a semi-supervised solution.
Most above approaches have the disadvantage that a sin-gle evaluation result (e.g., the confidence of fact of a value) alone cannot indicate whether the value is true, which is also the reason that we have to adapt some of the exist-ing methods in Section 5.2 for MTF. For better interpre-tation of evaluation results, Bayesian analysis [3] is intro-duced as a principled approach to the truth-finding problem, which yields explicit probabilistic estimations. Most current Bayesian-based approaches assume a prior distribution of la-tent variables, such as a uniform distribution over a single type of values (e.g., false values) [3] or distributions of all latent variables [7, 23, 24, 9]. Many of them develop proba-bilistic graphical models for handling categorical values [24], numerical values [23], ordinal values [9] and knowledge base triples [7]. Waguih et al. [20] summarize and experimentally evaluate these truth-finding methods.

Despite these efforts, most existing studies focus on single-truth-finding, yet little attention has been paid to the more general multi-truth-finding problem (MTF). The only work that we are aware of dealing with MTF is the Latent Truth Model (LTM) proposed in [24]. Based on a probabilistic graphical model, LTM makes strong assumptions on the prior distributions of latent variables, rendering the modeled problem intractable and inhibitive to incorporating various considerations. Distinguishing from previous approaches, our approach features an integrated Bayesian model based on a reformulated MTF model. Besides considering the unique features of MTF, our work also differs from the LTM approach [24] in two aspects: i) no assumption on prior dis-tribution of latent variables and ii) new measures for bet-ter data source quality estimation. Both the reformulation model and no requirement of prior distribution of latent vari-ables help reduce the computational load, which has been validated in our experimental studies (see Section 5).
In general, a multi-truth-finding problem (MTF) involves four basic inputs: i) data items , the true values of which are to be discovered, e.g., the author-names of a book, ii) sources , which provide values on data items, e.g., a website that publishes the information on books and authors, iii) values , e.g., the author-names published by a website, and iv) mappings among the above elements, e.g., which websites publish which author X  X  which books.

For each data item, MTF aims at identifying an opti-mal subset of values from the multi-source inputs to ap-proximate the truth. Multi-truth-finding differs from single-truth-finding in that each source may claim multiple values X  instead of a single value X  X n a single item, and multiple true values may hold on a single item.

Suppose m sources, S = { s 1 ,s 2 ,...,s m } ,providevalues on n items, O = { o 1 , o 2 , ... , o n } . Wedenoteby S i that provide values on item o i , O ( s i ) the items on which a source s i provides values, and V ij the values provided by source s i on item o j . To describe the mappings between sources and values, we further denote by S i ( v ) the data sources that provide a specific value v on item o i ,and V the values provided by a specific source s on item o i .
MTF is inherently difficult and prohibitive to be solved directly. Given a set of possible true values V , any element of the power set of V , instead of any single value of V in STF, could be the actual truth in MTF. Intuitively, MTF can be first transformed into its single-truth counterparts to be solvable by the existing approaches. However, a direct transformation could excessively expand the problem scale and the unique features of MTF may not be preserved. To address these problems, we propose to reformulate the MTF model by grouping sources and values based on their mapping relationships over all data items. For ease of illus-tration, we depict the source-value mappings under different models of MTF with respect to a single data item in Fig-ure 1. Each subfigure shows a bipartite graph/hypergraph that maps sources (or sets of sources) and values (or sets of values) via edges. The three models are as the following:
Under the single-mapping model (Figure 1b), edges be-tween sources and sets of values can be simply replaced with the edges between sources and individual values (e.g., the three edges between data source s 2 and values v 3 , v 4 , v Interestingly, the single-truth-finding problem (STF), which is a many-to-one mapping between sources and values on a Figure 1: An example illustrating four sources claiming six potential true values under different models of the multi-truth-finding problem. single item, immediately transforms to the single-mapping model when multiple items are concerned. This explains why the single-mapping model can be directly solved by ex-isting single-truth-finding methods.

Though viable, transforming an MTF directly to the single-mapping model tends to result in an exploded problem scale, represented by a multiplied number of nodes in the result-ing graph. This could in turn complicate the computation load of the truth-finding methods. As an example, the three nodes in the right side of Figure 1a X  X hich are actually three overlapping sets of values X  X re decomposed into six nodes in Figure 1b. To reduce the resulting problem scale, instead of decomposing each set into single values, we group the sources (resp., values) that share the same mapping schema in Figure 1b. Each source-group represents the maximum number of sources that claim the same set of values. Simi-larly, each value-group represents the maximum number of values that are claimed by the same set of sources. As an example, sources s 3 and s 4 in Figure 1c claim the same set of values { v 4 ,v 5 ,v 6 } ,so s 3 and s 4 are grouped together as a source-group g 3 . While v 6 is solely claimed by s 3 and s and v 2 are claimed by s 1 ,so, v 1 and v 2 are grouped together as a value group c 1 ,and v 6 alone as a group c 4 .Wecan see that after the grouping, the node size is reduced from 10 (4:6) in Figure 1b to 7 (3:4) in Figure 1c.

We introduce new concepts of source-group and value-group to define our reformulated problem model. In par-ticular, we denote by G the set of source-groups, C the set of value-groups, G n the source-groups that claim values on item o , O ( g k ) the items on which a source group g k claims val-ues, and C kn the value-groups claimed by the source-group g k on item o n . To describe the mapping, we further denote by G n ( c ) the source-groups that claim a specific value-group c on item o n ,and C n ( g ) the value-groups claimed by a spe-cific source-group g on item o n .

Different from value-groups, each source-group represents the joint strength of all the member sources. To represent this joint strength, we add weights to the edges associated with source-groups in Figure 1c. Given a data item o n , we define the weight on the edge between source-group g and an associated value-group c as  X  ( g,c )= | g | ,where c C ( g ), | g | is the number of sources contained in g .Forthe example in Figure 1c, both the edges associated with g 3 should be weighted by 2 because g 3 contains two sources. All the other edges are weighted by 1 because they each contains only one source. After the weighting, each source-group and each value-group will be considered as a single node in the subsequent truth-finding process.
In this section, we introduce the details of our approach, including the methods on grouping sources and values, the integrated Bayesian framework and the corresponding algo-rithms. The main notations used in this paper are summa-rized in Table 1.
Grouping methods aim at reducing the scale of the truth discovery problems. To this end, we expect each group to be as large as possible, to maximally reduce the computation load. Meanwhile, we expect the elements in each group to be as similar as possible, so as to keep the computation simple.
In our approach, we group sources directly based on the multi-mapping model for all data items, which is similar to Figure 1a, but involves multiple data items. We first map all distinct values to a Hash table, and then calculate the sum of hash values regarding each source. If two sums turn out equal, the corresponding sources are further compared with respective to their claimed values. In this way, we grad-ually assemble similar sources until all sources associated with the same set of values are grouped together. In case the hash values are non-additive, we designate a unique sequence over all the different values, and group those sources that map to the same subsequences. Values are grouped with re-spect to each data item in three steps based on the resulting source-groups. First, we transform the multi-mapping into the single-mapping model, and then transform the source-value mapping in the single-mapping model into the map-ping between source-groups and values. Finally, the values are grouped in the similar way as we group sources. The time complexity of th e grouping methods is O ( |S||V| ).
The Bayesian model estimates the a posteriori veracity of values (i.e., latent variables) based on sources X  trustworthi-ness (i.e., model parameters) and sources X  reports on poten-tial true values (i.e., observations) by Eq.(1). The sources X  trustworthiness can in turn be assessed by the estimated veracity.

Both the apriori veracity and sources X  trustworthiness are manually defined, and the conditional probabilities are calculated by:
In our approach, we extend the basic Bayesian model by incorporating the following considerations:
In addition, since combining positive and negative per-spectives can help better distinguish between sources with truth-sensitive and fault-sensitive behavioral features, we use positive precision (  X  pp ) X  X recision on true samples, and negative precision (  X  np ) X  X recision on false samples, to re-place  X  in Eq.(2). We define the above two measures based on the veracity score (  X  ( c )) of value-groups as follows:
We compute veracity score as the truth probability of value-groups using the extended Bayesian model. We find the degree of claim naturally resides over quality measures as powers in the Bayesian model and should not be normalized X  the Bayesian model calculates the joint effect of sources by multiplying their respective effects, and the multiplication turns into a power function when all sources have equal ef-fect. Indeed, the Bayesian model requires modeling all fac-tors as powers because simple multipliers will be eliminated during calculation. Therefore, we model above parameters as powers over the quality measures in our model. Here, we simply take the product of the different scores to represent their joint effect, but leave more sophisticated combinations of the scores to our future work. For simplicity, we synthe-size the parameters into four factors:
Given a value-group c , we define the likelihood of X under different assumptions on the truthfulness 3 of c :
The source-groups that support or oppose the same asser-tions should have the following relations:
By substituting Eq.(5) into Eq.(1) and adopting Eq.(6), we have: P ( a ( c ) |X )= 1
Since most truth-finding methods tend to favor sources with large profiles, incorporating the mutual exclusive re-lation can significantly neutralize this effect and therefore improve truth discovery accuracy on categorical data. An example of mutual exclusion is that, by claiming Washing-ton, D.C. as the capital city of the United States, a source
Truthfulness could be either true or false. implicates that all other cities are not. Similarly, we can define mutual exclusion between sets of values for MTF. However, traditional truth-finding methods assume that a source always supports or opposes an assertion by its full credit. In fact, in MTF, a claimed value does not strictly re-ject the unclaimed values because each source could provide only partial true values. We use the confidence score ,  X  ( g,c ), to quantify the strength that a source-group supports or op-poses an assertion. Similar to the Kappa coefficient [6], the idea is to exclude the effect of random guess in determining the strength. More specifically, given a set of value-groups if a source-group g claims a subset C ( g )  X  X  ,the confidence score of g on each value-group c is calculated as:
Based on above definition, by claiming certain value-groups, a source-group supports each claimed value-group and op-poses each unclaimed value-group at the same time with the confidence score s defined by Eq.(8a) and Eq.(8b), respec-tively. All the confidence score s regarding the same source-group sum up to 1, where each score  X  ( g,c )  X  (0 , 1].
Generally, the confidence score has the following interest-ing properties:
As an example, suppose a source-group claims a subset { v the corresponding scores as { +1 ,  X  1 , +1 ,  X  1 ,  X  1 } trast, our method would produce { +2 5 ,  X  1 15 , +2 5 ,  X  1
In both results, the positive (resp., negative) sign repre-sents the source-group supports (resp., opposes) the asser-tion that the corresponding value is true. particular, the values 2 5 is calculated as 1 2  X  (1  X  1 5 (8a) and 1 15 is calculated as 1 3  X  1 5 by using Eq. (8b). Compare to the results of the traditional method, our results reflect a differentiation towards source-groups X  confidence on the claimed and unclaimed value-groups, i.e., 2 5 for the claimed and 1 15 for the unclaimed value-groups, instead of 1 for both types of value-groups. This is important because disclaim-ing a value is no longer equivalent to disclaiming the value in the MTF X  X  context. Besides, our results implicitly reflect a differentiation towards source-groups of different behav-ioral features. Following the above example, if a source-group claims another subset { v 1 ,v 3 ,v 4 ,v 5 } ,whichiscloser to the full set, our method would redeem the source-group as being more audacious than being cautious and therefore lower the confidence on the claimed value-groups (meanwhile increase the confidence on the unclaimed value-groups), as manifested by the new results { +1 5 ,  X  1 5 , +1 5 , +1 5
Although copying relation has been actively studied re-cently [3, 14, 19], existing copy detection techniques only calculate a global score for each source [13]. Thus, they can hardly be applied to cases with partial dependence and/or high-order dependence. Especially according to the long tail characteristics [10], a source may have an extremely large profile (e.g., the store A1Books , which is a source in the book-author dataset, published nearly 700 book records on www.abebooks.com ). Under such condition, a global score cannot manifest the characteristics of all different parts of the source X  X  data. In contrast, a finer-grained copy detection technique will produce better predictions.

Based on this insight, we introduce a new copy detection method to calculate the independence score for each (source-group, value-group) pair. Given such a pair ( g,c ), we first calculate a score, I ( s, c ), for each (source, value-group) pair ( s, c ), where s  X  g , and then aggregate the above scores to derive to independence score for ( g,c )asfollows: where I ( g,c ) is the independence score of source-group g on value-group c .
Copying only happens between sources that provide the same value-group. Based on this observation, we propose to calculate I ( s, c ) by examining the independence prob-ability of s on every other sources that provide the same value-group c .Given X  c , the observation that two sources provide the same value-group c ,wedenoteby  X  (resp.,  X  ) the independence (resp., copying) relation between sources on c ,and  X  the former copies c from the latter. Note that, we omit parameterizing the above notations by c (except  X  ) for ease of description. For two arbitrary sources s and s ( s = s i ), we have: Given a value-group c , and any source that claims c , s  X  S ( c ), we define the independence score of s on c as the prob-ability that s never copies c from other sources:
We assume equal probability of the two directions of copy-ing, i.e.,
By incorporating Eq.(10) and Eq.(12), we reform Eq.(11) into:
To calculate the probability of independence between two sources, we first define the likelihood of  X  c under different assumptions on source dependence and the truthfulness of c :  X   X   X 
Here,  X  =1 - X  np ( s )and  X  =1 - X  pp ( s ). For any assumption d  X  X  s 1  X  s 2 ,s 1  X  s 2 } , we develop Bayesian formulas to cal-culate the corresponding probability, where a  X  X  a ( c ) ,  X  a ( c )
In our approach, we distinguish between two types of copiers, namely blind copiers and smart copiers . The blind copiers assume independence between the veracity of values and sources X  probability of copying, i.e., P ( d | a )= P can thereby rewrite Eq.(15) to:
Since blind copiers have no bias on copying true/false val-ues, we define a single copying probability  X  for all sources and on all value-groups: By substituting Eq.(14) and Eq.(17) into Eq.(16), we get: where P sum denotes the sum term in the numerator of Eq.(16): P sum = P ( a ( c ))(  X  pp ( s 1 )  X  pp ( s 2 )+(1  X   X  np ( s
Without prior knowledge, we can initialize veracity as:
On the other hand, the smart copiers have some  X  X mart-ness X  that they are more likely to copy true value-groups than false value-groups. We define different conditional prob-abilities for the two cases to reflect the  X  X martness X : It can be inferred from the above equations that:
P ( s 1  X  s 2 | a ( c )) = 1  X  2  X  t , P ( s 1  X  s 2 |  X  a ( c )) = 1
For copiers to be X  X mart X , the probability of a source copy-ing a true value-group should be larger than the probability of copying a false value-group, i.e.,  X  t &gt; X  f . By substituting Eq.(14)(20)(21) into Eq.(15), we get: where P over denotes the numerator in Eq.(15):
P over =(1  X  2  X  t ) P ( a ( c ))
Because it is critical for smart copiers to acquire some prior knowledge in order to be  X  X mart X , we update the prior probability with the latest estimation of veracity scores after each cycle of the iteration:
This ensures that the smart copiers X  perception on values X  veracity keeps evolving with the truth-finding process.
Various algorithms, such as the iteration algorithm [21, 3, 5, 17] and the Expectation Maximization (EM) algo-rithm [23, 2], can be applied to solve our model. Both algorithms belong to the category of coordinate ascent al-gorithms , which differ in the methods used for estimating the quality of data sources. In particular, the former defines linear or nonlinear functions to calculate sources X  quality, while the latter infers sources X  quality by maximizing the (lower bound of the logarithmic) likelihood of observations over all source-claimed values.
 Here we present an iteration algorithm for our integrated Bayesian model, but omit the description of the EM algo-rithm, which is only slightly different from [18], due to the limited space. For the ease of illustration, we use a single notation to represent the copying probabilities of the two Algorithm 1: Iterative Multi-Truth-Finding types of copiers:
The detailed procedure is described in Algorithm 1. In the initialization phase (Lines 1-7), the copying probabilities are defined apriori (Line 1). Sources X  quality and values X  ve-racity are initialized with default values (Lines 2-5). The algorithm then computes the degree of claim and confidence score for each pair of source-group and value-group (Lines 6-7). Both parameters and the copying probabilities remain unchanged until the algorithm terminates. For each cycle of the iteration (Line 8-16), the algorithm calculates the ve-racity scores (Lines 9-13) and sources X  quality (Lines 14-15) in turn. For each data item, the veracity scores are calcu-lated in two steps: i) calculates the synthesized factors (as defined by Eq.(4)) and independence score for each pair of source-group and value-group (Lines 10-12) and ii) updates the veracity scores for each value-group (Line 13). The iter-ation terminates when the algorithm converges (i.e., the al-gorithm X  X  judgment on the truthfulness of all values remains unchanged for certain consecutive cycles) (Line 16). Loga-rithms are used in calculating the multiplication of small decimals to ensure accuracy.
In this section, we report our experimental studies on the comparison of our approach with the state-of-the-art algo-rithms and the impact on the performance of our approach of different key aspects in the Bayesian model.
We used three real-world datasets in our experiments. The book-author dataset [21] contains 33,971 book-author records crawled from www.abebooks.com . The records of the web-site are contributed by numerous book stores (i.e., sources), where each record represents a book store X  X  claim on the au-thor(s) of a book. We removed the invalid and duplicated records. To make the problem more challenging, we also ex-cluded the records with only minor conflicts (i.e., the records related to those books on which less than two distinct lists Table 2: Evaluation of the major sources in the movie-director dataset.
 of author-names are provided). Finally, we obtained 12,623 distinctive claims describing 649 sources (i.e., websites) that provide author-names on 664 books. On average, each book has 3.2 authors. The ground truth provided for the original dataset is used as gold standard.

The parent-children dataset [16] contains 11,099,730 records about people X  X  birth and death dates, the names of their parents/children and spouses, edited by different users (i.e., sources) on Wikipedia. We particularly extracted the records on the parent-children relations from this dataset. After eliminating the duplicates, we finally obtained 55,259 users claiming children for 2,579 persons. In the resulting dataset, each person has on average 2.45 children. We used the latest editing records as the ground truth.

We prepared the third dataset, the movie-director dataset , by crawling 33,194 records from 16 movie websites. We re-moved redundant records and finally obtained 6,402 movies, each on average having 1.2 directors. We sampled 200 movies and extracted their director information from citwf.com as the ground truth. Table 2 shows the top ten websites that provide the most records, with their quality values obtained by one of our methods MBM (see Section 5.2 for details). It should be noted that most datasets used in previous works for categorical truth discovery [12, 20] are not suitable for our multi-truth-finding problem. The three real datasets used in our work are comparable to those datasets in size.
We compared our approach with the following methods, which were modified, if necessary, to incorporate mutual ex-clusion.
It should be noted that we excluded the comparison with several methods that are inapplicable to the multi-truth-finding problem. For example, the algorithms in [3] can-not be applied to our problem because they all assume the number of false values as a prior knowledge. The approach in [16] requires normalizing the veracity of values, which is infeasible for the multi-truth-finding problem. Finally, the methods in [23, 11] focus on handling heterogeneous data, while our approach is proposed specially for categorical data.
To ensure fair comparisons, we first ran a series of experi-ments to decide the optimal parameter settings for the base-line methods. Since the parameter tuning for our methods are relatively more complicated, we simply used a generic parameter settings for all datasets, i.e., the copying proba-bilities of blind copiers  X  =0.8 and for smart copiers,  X  and  X  f =0.7. The initial source quality values do not usually affect the experimental results as long as they are not un-reasonably large or small (as indicated in our experiments in Section 5.3.2), so we just initialized them as  X  pp ( g )=0.8 and  X  np ( g )=0.7.

To evaluate our approach under different implementations, we derived three variants of our approach:
We implemented all algorithms using Java SDK 7, and conducted experiments on a 64-bit Windows 7 PC with an octa-core 3.4GHz CPU and 8GB RAM.
Table 3 shows the performance of different algorithms on the three datasets in terms of precision , recall ,and computa-tion time . The computation time of our algorithms includes the time spent for both problem reformulation and Bayesian truth discovery. However, the results show the time spent on reformulation is minor when compared to that of main truth discovery process. Our three algorithms consistently achieved the best precision and recall among all the com-pared methods, except the majority voting which always achieved the best precision (in those cases, our algorithms still yielded the second best results). All the algorithms achieved lower precision on the book-author dataset due to the elimination of the records with minor conflicts.
We only used blind copiers for the comparison because smart copiers tend to produce similar results. They will be specially compared via experiments in Section 5.3.2.
The majority voting achieved comparatively low recall (nearly always the lowest) on all datasets. This is because most sources tend to provide only a minor proportion of the entire truth. So when tuning the sources X  trustworthiness as the prior parameters, only the precision of the method is op-timized. Despite the low recall, the majority voting achieved nearly perfect precision X  X xcept on the book-author dataset where the approach is inapplicable. This may imply that the majority voting method is better used for generating the ground truth for semi-supervised truth-finding approaches, rather than for solving MTF, unless more comprehensive quality measures are considered in evaluating the sources.
Besides the majority voting, both LTM and 2-Estimates showed higher precision than the other baselines. All base-lines except TruthFinder considered the mutual exclusive re-lation. However, these methods achieved lower recall when compared to TruthFinder or our methods. They identified only a small proportion of true values. This may be due to their neglect of the possibility of random guess in consid-ering sources X  claims X  X s opposed to the definition of mu-tual exclusive relation in our approach. This should explain why our methods achieve better recall than those methods. It should be noted that TruthFinder achieved better recall yet generally lower precision than the other baselines, which may attribute to its overestimation of veracity scores.
As for the efficiency, our MBM and all the baselines X  except LTM X  X ad comparable computation time on the three datasets. LTM and MBM-C always demanded the longest computation time. While the efficiency of LTM depends on the problem scale, MBM-C is more sensitive to data-sets. Specially, MBM-C achieved significantly better effi-ciency than LTM on the parent-children dataset, because of the many source-groups and value-groups in this dataset. Overall, our three methods showed no significant difference in their truth-finding quality. However, MBM-C exhibited less stable performance, depending on the underlying de-pendence among sources in the datasets. MBM-EM always ranked in the middle of the three in term of efficiency.
We also studied the impact of different aspects to our methods and report the findings in this section.
 Grouping of sources/values . We exploited our methods to discover various source-groups and value-groups in the three datasets. Table 4 shows examples of three source-groups found in the book-author dataset. In the first example, six sources claim the same two authors for a book. In the third example, two sources claim the same author for each of the ten books. By grouping the sources , the num-ber of sources in the three examples was reduced from 10 Figure 2: Performance comparison of the proposed algorithms between using and not using the group-ing methods. The algorithms marked by asterisk are those without using the grouping methods. to 3. After the grouping, the total number of sources (or joint sources) in the book-author dataset is reduced from 4,264 to 3,874. We found the author-book dataset contained more source-groups, while the movie-director dataset con-tains more value-groups. The parent-children dataset con-tains large numbers of both types of groups. A comparison of the three algorithms between using and not using the grouping methods (Figure 2) demonstrates the effectiveness of the grouping methods.
 Mutual exclusion. In our datasets, each item has on average 1 to 4 different values, so the confidence scores stay in the range of (0 . 08 , 0 . 75) (calculated by Eq.(8a) and Eq.(8b)). To examine the effect of our defined confidence scores, we imple-mented our methods based on the traditional definition and our new definition of mutual exclusive relation, respectively, and compared the results. Figure 3a shows the comparison on the movie-director dataset, which demonstrates that our definition almost always brings better precision and recall. The results on the other two datasets are similar. Table 4: An example of three source-groups in the book-author dataset.
 Blind and smart copiers . We investigated the effect of in-corporating copy detection by comparing MBM and MBM-C in the experiments. The results showed improved precision and recall of our approach by incorporating copy detection methods. We further studied the performance of our meth-Figure 3: (a) Performance comparison of the pro-posed algorithms between using the traditional def-inition and using our definition of mutual exclusion on the movie-direct dataset: the algorithms marked by asterisk are those adopting the traditional defi-nition. (b) Performance comparison of MBM-C be-tween using the blind copiers and using the smart copiers. Both blind copiers and smart copiers were configured with their optimal parameter settings and ran a fixed number of iterations, i.e., 10, re-gardless if they converge. Figure 4: (a) Performance of MBM-C under varying copying probability of blind copiers, i.e.,  X  .(b)Per-formance of MBM-C under varying copying proba-bilities of smart copiers, i.e.,  X  t and  X  f . ods using blind copiers and smart copiers, respectively. We observed that using smart copiers led to slightly slower con-vergence but better results on the movie-director dataset (Figure 3b). As the copying probability grew, we observed an increase in both precision and recall of the methods using blind copiers on the movie-director dataset, until the prob-ability became close to 0.8 (Figure 4a). Smart copiers also showed similar features (Figure 4b) on the movie-director dataset (Figure 4b). It is worth noting that, recall had some robustness on  X  f . At certain points, increasing  X  f could even yield a higher recall . The impact of initial parameters were similar for the other datasets.
 Comprehensive source quality . We varied the initial values of source quality measures for our methods and observed similar results on all three datasets. This indicates that our approach is insensitive to the initial assumptions of source quality (as long as the initial values are not infeasible large or small, such as equal to one, or close to zero). Compared to the traditional measures, our source quality measures in-curred similar computation time but higher recall on larger datasets (e.g., the parent-children dataset and the movie-director dataset), while the advantages on smaller datasets (e.g., the book-author dataset) was not obvious.
In this section, we briefly review the important concepts incorporated in our approach via the hardness of fact to better understand the experimental results. The hardness of fact was first proposed in [5] to quantify the difficulty in determining the truthfulness of a value. It is used by pay-ing the most trust on the sources that claim a more difficult value (which has a higher hardness of fact ). We find that both the smart copiers and our mutual exclusion definition can be interpreted or inferred from the concept of hardness of fact in evaluating the sources. In particular, a smart copier prefers copying the values with higher veracity. Those values are usually claimed by more sources. In defining a higher probability of copying, the smart copier actually dampens the effect of those sources which jointly claim values with many other sources. This is exactly the effect of considering the hardness of fact in the truth-finding process. As for our proposed mutual exclusion definition, a claimed value would receive a higher confidence score if given a larger number of distinct values on a specific item. This can also be inter-preted from the hardness of fact . Since it is more difficult to identify a true value from a larger set of different values, once a value is identified as true, the value should be more trusted based on the philosophy of the hardness of fact .
In this paper, we address the problem of discovering multi-ple true values from the multi-source data, which has rarely been studied in the previous works. We propose an inte-grated Bayesian approach, which comprehensively incorpo-rates novel methods on three key aspects that character-ize the multi-truth-finding problem (MTF), namely source-value mapping, mutual exclusive relation, and source de-pendency, to better solve the problem. In particular, we leverage the unique mapping features of MTF to reformu-late the problem model in order to reduce the problem scale. We develop a new definition of mutual exclusion to reflect the inter-value implication under the MTF X  X  context and a finer-grained copy detection method to cope with sources with large profiles. Experimental studies on three real-world datasets demonstrate the effectiveness of our approach. Our future work will focus on investigating more comprehensive ways for solving the MTF, e.g., by identifying and integrat-ing more aspects to enhance the Bayesian model. [1] J. Bleiholder and F. Naumann. Conflict handling [2] A. P. Dempster, N. M. Laird, and D. B. Rubin. [3] X. L. Dong, L. Berti-Equille, and D. Srivastava. [4] X. L. Dong and D. Srivastava. Big data integration. In [5] A. Galland, S. Abiteboul, A. Marian, and P. Senellart. [6] K. L. Gwet. Handbook of inter-rater reliability: The [7] G.Kasneci,J.V.Gael,D.Stern,andT.Graepel.
 [8] J. M. Kleinberg. Authoritative sources in a [9] B. Lakshminarayanan and Y. W. Teh. Inferring [10] Q. Li, Y. Li, J. Gao, L. Su, B. Zhao, M. Demirbas, [11] Q. Li, Y. Li, J. Gao, B. Zhao, W. Fan, and J. Han. [12] X. Li, X. L. Dong, K. Lyons, W. Meng, and [13] X. Li, X. L. Dong, K. B. Lyons, W. Meng, and [14] X.Liu,X.L.Dong,B.C.Ooi,andD.Srivastava.
 [15] A. Pal, V. Rastogi, A. Machanavajjhala, and [16] J. Pasternack and D. Roth. Knowing what to believe [17] J. Pasternack and D. Roth. Making better informed [18] J. Pasternack and D. Roth. Latent credibility analysis. [19] R. Pochampally, A. D. Sarma, X. L. Dong, A. Meliou, [20] D. A. Waguih and L. Berti-Equille. Truth discovery [21] X. Yin, J. Han, and P. S. Yu. Truth discovery with [22] X. Yin and W. Tan. Semi-supervised truth discovery. [23] B. Zhao and J. Han. A probabilistic model for [24] B. Zhao, B. I. Rubinstein, J. Gemmell, and J. Han. A
