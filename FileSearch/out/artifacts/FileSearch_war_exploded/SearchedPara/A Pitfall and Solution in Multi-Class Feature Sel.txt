 Hewlett-Packard Labs, 1501 Page M ill Road, Palo Alto, CA 94304 USA A customer support division of Hewlett-Packard approached our data-mining department in HP Labs with an apparently straightforward text classification task: sorting millions of technical support documents into topic categories. In the process of developing a machine learning solution, we found that well-established feature selection methods failed to perform tolerably. Our in-depth study of the problem revealed that there is a remarkably pervasive pitfall in most multi-class feature scoring methods, such as Information Gain, Mutual Information and Chi-Squared. It arises in situations where one or a few  X  X asy X  classes have many strongly predictive features, and other  X  X ifficult X  classes have only weakly predictive features. All feature selection methods that evaluate features independently will be consistently drawn to the many strong pred ictors of the easy classes, and will be distracted from selecting features to help discriminate the difficult classes. In the extreme, a tremendous surplus of excellent predictive features for one class can effectively hide all useful features for discerning other classes. This is not far fetched: for example, consider classifyin g email into folders, where one particular folder represents a very dissimilar class, e.g. German or spam.  X  X  X  X  X  Appearing in Proceedings of the 21 st International Conference on Machine Learning , Banff, Canada, 2004. Copyright 2004 by Hewlett-Packard. We encountered this problem X  X hich we call the  X  X iren pitfall X  X  X n the technical support classification task, and we speculate that it may be more common in practical industrial tasks than in the typically homogeneous benchmark datasets often studied in the research literature. Nonetheless, this study shows the issue is pervasive even in homogeneous tasks.
 In Section 2 we analyze and illustrate the pitfall for an example dataset. Rather than exhibit it for our industrial task X  X hich may leave the read er unconvinced as to how frequently the pitfall may occur in practice X  X e demonstrate that it occurs even with a well balanced, homogeneous task : a dataset of research paper abstracts in 36 categories representing different fields of computer science with exactly 50 cases for each class. Given this understanding, we then present in Section 3 a family of feature selection algorithms, motivated by round-robin allocation. They avoid the risks of completely independent feature evaluation, and at the same time avoid compute-intensive wrapper methods. In Section 4 we evaluate the performance improvement on a set of 19 multi-class text classification tasks. We summarize and suggest future work in Section 5. The balance of the introduction further defines the scope of this work, and contrasts with related work. 1.1 Scope and Related Work The scope of this paper impl icates all feature scoring methods that evaluate features independently. This excludes wrapper methods, which apply general search mechanisms, such as sequen tial forward selection or genetic search, with repeated calls to the induction algorithm subroutine to evaluate various subsets of features (Hall &amp; Holmes, 2003; Kohavi &amp; John, 1997). Wrapper methods effectiv ely consider the joint distribution of features X  X o the extent that the underlying induction algorithm can. However, they involve great computational cost and are inappropriate for high dimensional tasks. In text classification, the number of potential word features commonly exceeds the number of training examples by more than an order of magnitude, not to m ention t he ex plosi ve num ber of pot ential wor d phrase feat ures (M ladeni c &amp; Gro belnik, 1 998). I n cont rast , feat ure-sc ori ng m etho ds, suc h as In form ation Gain, run m uch faster be cause they eva luate features independ ently with ou t consid ering feat ure interactions and withou t ind uction . There has be en a num ber of feat ure sel ect ion st udies applied to binary (two -class) classification tasks (e.g. Fo rm an, 20 03 ; Gu yon , West on , Barnh ill &amp; Vapn ik, 2002 ; Mladeni c &amp; Gr obelnik, 1999). Thi s pa per , howe ver , foc uses on mu lti-cla ss or 1-o f-M task s: ch oosin g on e of M nom inal classes, where M&gt; 2. App licatio ns includ e filing documents in fo lders, or routing und irected cu sto mer email to th e mo st ap propriate d epartm ent. Som e feat ure s elect ion st udi es have been perform ed i n the fram ewor k of topic id entifica tio n or N-o f-M tasks (e.g. Yang &amp; Ped ersen , 19 97) . This f ormulatio n co mprises a set of M indepen dent bi nary cl assi ficat ion t asks. T he solution to such prob lem s is to prov ide each of th e M binary classifiers with its o wn optimized feature selection. In so me situ ati ons, howev er, it may b e necessary du e to system const raints to sel ect one set of feat ures t o be use d by all b inary cl assifiers; in th is case, t his paper ap plies. Feature sc oring m ethods conside r each feature inde pen dently, exam ining t he co unt s in the co ntinge ncy table across cl asses. Mainstre am sco ring meth od s in clud e Inform ation G ain (I G), M utual Inf orm ation, Chi-S qua red (CHI ), a nd variations on Term Freque ncy x In verse Doc ument Fre que ncy (M ladenic et al ., 1 999). Ya ng a nd Ped ersen (1997 ) performed a co ntrolled stud y in th e tex t classi ficat ion dom ain and f ound C HI a nd IG t o be t op per formers. What is c ommon to all of these feature -scori ng m ethods i s that they concl ude b y ranki ng the feat ure s by their i ndepe ndently det erm ined sc ore s, a nd then select the top scoring fea tures. The level of difficul ty of text classi ficat ion tasks nat ural ly varies. As th e nu mber of distinct classes increase s, s o set neede d. In any m ulti-cl ass text classification task, inevitab ly so me classes will b e m ore difficu lt th an others to classify, that is, they receive s ubsta ntially lower precision and/ or recall for t hat category compared with the o thers. Reason s for th is may b e: (1) very few po sitiv e train ing exa mples for th e class, (2) lack of go od predictive feat ures for that clas s. In th e form er c ase, th ere is litt le o ptio n bu t to ob tain m ore training cases for t hat class. As a sm all cons olation, classes that account for onl y a s mall fraction of the prob ability d istrib ution can lik ewise have only a sm all effect on ove rall accuracy (or micro-ave raged F-m easure ). Howe ver, just because a clas s has a sm all r eprese ntation in th e train ing set d oes no t mean th at in deployment th e precision/recal l for t hat class will not be i mportant. For exam ple, in a movie recommender syste m, although one may have onl y seen and ranke d a fe w ex cel lent movi es and m any m ediocre o nes, the p reci sion for t he m inori ty class is m ost im portant. Ou r hypo thesi s is th at in ca se (2 ) above, w here it is ha rd to get go od predictive fea tures fo r some cla ss(es ), existin g fea ture sco ring mechan isms w ill fo cus o n the fea tures tha t are us eful pre dictors f or other, easi er cl asses, a nd w ill igno re th e d ifficu lt cla sses X  X h e  X  X iren pitfall.  X  Th is is exactly th e wro ng thing to do  X  X  ifficu lt classes n eed, if anyth ing , mo re attention a nd feat ures selected for t hem , so t hat they ca n be better clas sified. 2.1 Empirical De mons trat ion of the Siren Pitfall We fu rth er h ypo thesize tha t th is p itfa ll o ccu rs p erva sively, even in w ell-bal ance d  X  X ese arch quality X  t ext cla ssifica tio n pro blems. We demonstrate th is b y a d etailed analysis on a balanced text classification task. As a running exam ple, we take t he task of classifying rese arc h pape r ab stract s i nto va rious fi elds o f com put er sci ence. Fo r th e dataset, we ex tracted a set of abstracts and their associated cl assifications within t he Cora t opic categorization that was once m ade available by Whi zban g.com . We sel ect ed from their many topi cs 36 classes, eve nly di stribut ed am ong 6 br oad t opi c areas, i n order t hat the task shou ld b e relativ ely u niform in difficulty (f or com pari son, a n inhomogene ous task m ight have included a fe w cl asses fr om a bra nch of biology ). To c ontrol for problem (1) ab ove , we popula ted each class with exactly 50 traini ng case s. The m any classes m ake for a lo w m ajority -gu essi ng accur acy, so pe rformance above 1/36=2.8% accuracy is attributab le to use ful features, not chance . (T he features a re Boolean, i ndi cat ing whether a specific word appea rs in th e doc um ent, whe re a word consists of consec utive alph anum eric characters, force d lowercase, with no stemmin g and no stopw ord list. We include al l w ords e xcept ver y co mmon wo rds a ppea ring in &gt;25% of t he doc um ent s, and ra re w ords occu rring in fewe r tha n three d ocum ents.) Ev en in a task with fairly h omogeneou s and un ifo rm-sized classes, t here is si gni fican t v ariatio n in th e d ifficu lty of the ind ividual classes. To illu strate th is, we m easu red the precisi on, recall, and F-m easure for e ach individual class. (Precision P = tru e positiv es / al l g uessed po sitiv es. Recall R = tru e positiv es / all p ositiv es in ground tru th. F-measure is their harm onic av era ge = 2 P R/(P+R). ) We use d a state-of-the-a rt classi fier: a multi-class one -vs-all Support Vect or Mac hine (SVM, linea r kernel, C=1) (W itten &amp; Fran k, 2 000 ). We selected the top 500 features via IG (a fter determining 500 is sufficient for accepta ble per formance; see Fi gure 4) . W e used 4-fold st rat ified measurem ents due t o ra ndom ized splits. For each fold, t he feature selector must be re-run from scratch so that no inform atio n leak s fro m th e test set. plot shows the precision (be nt end), recall (straight end) and F -measure (ro und m arker ). The classes are sorted by their F-m easure. Sca nni ng t he whiske rs, we see that s ome classes have a wi de di scr epancy bet ween t heir p reci sion and recall. The ove rall macro-ave rage F-measure is 50%, indicated by the round marker on the y-axi s. Thi s is eq uival ent to the micro-a verage d F-m easure , beca use the class distribution i s uni form . M icro -ave raged F -measure i s a per -document m easure, s o it is heavi ly influence d by larger classes, while m acr o-ave rage d F-measure gives equal weight to each clas s rega rdless of size. Si nce sm aller classes tend to be harder t o classify and there tend to be m ore of t hem than large r classe s, the m acro-Ca veats : Looking at the al location of feat ures i n this way does lend insig ht, bu t th is evidence is no t co mpletely consistent. For e xam ple, class 15 s hows a lack of pre dictive fea tures, yet achieves a nearl y median F-measure. M eas uri ng IG local ly is onl y a heuristic poi nting towa rds t he be st features for each class, a nd m ay not be the op timal metric to u se; reso lving that q uestion is out side o ur s cope here , b ut see Form an (20 03). A ny  X  X m perfectio ns X  in th e scori ng m etric slig htly scram ble bot h t he o rder in which feat ures are selected globally, and the local ranking of the fe ature dots in each colum n. Finally, features are not inde pend ent, and th eir v alue to the classifier depends on wha t othe r feat ure s are i ncluded. avera ged F-m easure is often said to em phasize th e s maller classes, while micro-ave raged F-m easure e mphasizes the larg e classes. Research literatu re th at stud ies on ly th e micro-ave rage, therefore, m ight m ore easily overlook th is pitfall. We see the re is wide variation i n the F-measure s across the classes. In partic ular , notice the classes HW-High Perf ormance and HW-Distribut ed ha ve t he wo rst sco res. Since we ha ve cont rolled f or u neven cl ass di stribution (case 1) , by ou r hypo thesis, w e expect that the available feature s for predicting these diffic ult classe s are wea k and excluded i n fe ature selection. That is, the y are weake r than the feat ures available for othe r classes, and the feature sc oring mechanism is dra wn m yopi cal ly to those stro nge r featu res. 2.2 The Si ren Pi tfall is Persi stent X  X  on -Soluti ons Inst ead o f m easuri ng t he gl obal IG, t he  X  obvious  X  sol ution to th is prob lem is to m easu re th e IG score fo r each class agai nst the ot hers as we ha ve d one , and then t ake t he maxim um sc ore ac hieve d by each fe ature for a ny indi vidual cl ass, a. k.a. M ax.IG or M ax.Chi (Ya ng et al ., 1997 ). Th e ho rizo ntal lin e in Fi gure 2 rep resen ts the part icular threshol d t o rea p the t op 100 fea tures sel ect ed by th is pro posal. Th is wou ld certain ly do a b etter job of distributing t he sel ect ed feat ures am ong m ore cl asses, b ut note, ho wev er, th at it still su ffers fro m th e v ery problem we are t rying t o solve. Obse rve that diffic ult classes, suc h as 1, 2, 3 and 5 ha ve no feat ures rat ed ab ove t his threshol d, so they would still not receive any allocation. To veri fy this, Fi gure 2 shows a plot of the IG sc ores of the top pre dictive feat ures for eac h class i ndepe ndently. The scores for each class are plotted in se parate colum ns, sorte d left-to -right just as in F igure 1. T he hi ghe r the d ot, more useful the feature is t o that class. Eac h col umn has all th e featu res, th oug h in differen t po sition s (so me o ut of view below the x-ax is). Notice in general th at th e m ore difficu lt classes to ward the left ten d to have fewer goo d pre dictive features . In selecting features for th e b aselin e in Fig ure 1, we computed IG on th e g lobal multi-class task , as typ ically practiced in the literatu re. To in dicate th e g lobal selectio n order , we em bol den points in Fi gure 2 that re prese nt top feat ure s sel ect ed by the global feat ure sc ori ng; a gl obal ly selected feature will e mbolde n one dot in each col umn. We use diffe rent marker i cons t o label fea tures t hat are include d i n the t op 25, t op 5 0, an d t op 7 5 gl obally selected features; features th at were not selected withi n that num ber are re prese nted by sm all dots. This give s a view i nto how the global feature s election mechanism is allocating feat ures am ong the classes, a nd whic h locally inde pende nce of feat ures for a moment, the more features selected hi ghe r up i n eac h c olum n, the m ore easily that class sh oul d be t o di scriminat e by t he i nduct ion alg orith m. A co lumn with no ne of its b est features selected, e.g. c olum ns 3 and 7, m ay th en be m ore d ifficu lt to classify. For this rea son, we truncate t he gra ph bel ow at 0 .01, so ou r focus is on ly on predictive features. Moreove r, as a Geda nken e xpe riment, sho uld there be a class with man y very stron gly predictive features, it wo uld se rve as a l ight ning r od eve n fo r this  X  X ax X  vari ant of feature sco ring, co mpletel y sh ield ing th e o ther classes from any allocation of fe atures. For s uch a dataset , ran dom feat ure sel ect ion m ay prove s upe rior. A ny rando m flu ctuatio ns or  X  X mp erfectio ns X  i n th e scoring metric wo uld h elp it o verco me su ch a situ atio n. Th is suggests t hat a random ele ment in feature selection m ay prove bene ficial. Furt herm ore, this probl em persists for an y other f eatur e sel ect ion m etric and other a ggre gation f unctions, s uch as the mode, m ean, clipped mean, or any general affine trans formation.
 So me h ave criticized th e p olicy o f selectin g a fix ed num ber of fe atures fo r induct ion, and have instead prop osed th e selectio n m ethod adju st th e nu mber o f feat ure s chose n based on their di stribut ion in the t raining dat a. F or e xam ple, R enni e (2001), am ong others, propose using a sign ifican ce thresh old on th e resu lt o f a statistical test. For s uch methods , o ne doe s n ot know a pri ori how man y featu res will b e selected fo r a new d ataset, bu t for a given dat aset , t he si gnificance t hresh old pa ram eter effectively s kim s features off the t op just as ot her sc ori ng mechani sms, yi elding no protect ion from the si ren pi tfall. Ob serv e th at th ere is wid e variab ility b etween th e classes in bot h t he number of  X  X est  X  features, a nd the m axim um or ave rage scores of t hose feat ure s. No ne of t he best feat ure s f or col umn 7 ha ve bee n sel ected gl obally. Co lumns 2 and 5 show no do ts at all X  X heir best features fall b elow th e x -axis thresho ld ch osen for th is grap h. These two classes also ha ve som e of the lowest F-measures. Fi nally, obse rve t hat the top 75 feat ure s do not appea r to be  X  fairly X  di stributed acros s the classes. This lends e vidence to our hy pot hesi s t hat the global feat ure allo catio n do es no t p ay adeq uate atten tio n to difficu lt classes. Although w e have dem onst rated t he pi tfall he re onl y for Inform atio n Gain on a sing le tex t task , we hav e cond ucted sim ilar experi ments y ielding si milar obs ervat ions with other feat ure s elect ion m etrics (i ncl uding CHI, M ax.I G, wei ghted M ax.IG, a nd hy pot hesi s t esting) an d wi th anot her t ext dataset (fbi s of Han &amp; Ka rypis, 20 00). W e om it their anal yses for brevit y. Th e first p arameter R, in its most g eneral fo rm , is a dynam ic sched uling policy am ong t he cl ass es. We prese nt here two of the sim pler p olicies we stud ied : 1 Ro und -R obin : Th is sim ple p olicy tak es the b est feature suggeste d from each class in t urn. Rand-Robin : Th is rando mized sch edu ler, motiv ated by the ob ser vation o n ra ndom ization ab ove, s elect s t he next class ra ndom ly with proba bilit ies according to the class distribu tio n. If th e im portan ce of the class es is une qual and known (e .g. cl assi ficat ion c osts, or more po pul ar categories), t his inform ation coul d be used to skew t he selectio n prob ability distrib ution. Desid erata fo r any so lution to th e siren pitfal l in clu de: 1. The prese nce of o ne or a fe w classes havi ng many The sec ond pa ram eter M i s any feat ure-ranki ng m ethod for two-class tasks. T his c ould involve a fe ature scoring metric, such as In form ati on Gai n or C hi-Sq uare d, but more g enerally, it n eed only retu rn a t otal ord er of feature s for each class. Absolu te scores for the feature s are not compared against one anot her, so different ranking algorithms might be use d for di ffere nt cl asses (su pposing there were pri or knowledge that particula r classes woul d bene fit from cert ain k nown m ethods , or we as a machi ne learn ing disci plin e ev entually learn in wh ich situ atio ns to apply v ariou s featu re scorin g m etrics). No te th at the feature ranking algorithm onl y need deal with a myopic two-class task , an d so th is op ens u p th e po ssib ility ev en on m ulti-class task s to use meth od s th at can on ly h and le binary tasks, such as O dds R atio (M laden ic et al ., 199 9) and B i-Norm al Sepa rat ion (Form an, 2 003). Not e al so that the su b-tasks may be com put ed i nde pendent ly and are amenable to parallelizatio n. Th e resu lts o f the ran king are use d in order , so onl ine or any tim e al gori thm s may be employed in addition to trad itio nal b atch algo rith ms. Fin ally, sin ce th e rank ing is d epend ent on ly on th e class and the dat aset, it m ay be p re-c omput ed an d re-used, unlik e al gorithm s th at resa mp le o r perm ute th e d ataset and re peatedly call th e r anking algor ith m. 2. Whi le the di scussi on above cent ered on a t ext task 3. It wo uld be d esirabl e i f the sol ution we re tuna ble 4. Likewi se, i t wo uld be use ful if the sol ution were 5. It sh ould be reaso nabl y qui ck t o com put e for l arge 3.1 SpreadF x[R, M] Feature Se lection F amily The ba sic ker nel of t he sol ution a ppl ies r ound-robin t urn taking to let each class propose features. T o ge neralize a bit, we fi rst pro pose an abstr act family of feature selection alg orith ms th at is p aram eterized acro ss two general dimensi ons. Any fam ily of al gorithms rai ses m ore que stions a bout w hat its op timal param eteri zat ions m ay be. N onet heless, t hey can be use ful for di ssect ing a problem at a n abstract level and considering options . Later we perform an e mpirical evaluation of the idea for three instan tiatio ns. We b egin by presen ting th e fam ily of alg orith ms: We begin by illu strating th e im provement th at Sp readFx[ Roun d-Rob in, IG ] m akes o ver trad ition al IG for th e 36-class Co ra dataset presen ted earli er. As b efore, we p erfo rm ed a 4 -fo ld cro ss-v alid ation on th e d ataset, using m ulti-cla ss SVM and selectin g th e top 500 feat ures. The ar rows in Fi gure 3 s how the gain i n F-m easure for each class . We see dramatic im prove ment for m ost classes, es peci ally at the left, and a slight dec rease for som e of the easy classes on th e righ t X  X  trad eoff we expect. In order to obtain a sin gle perfo rmance statistic fo r th e entire dataset, we m acro-a vera ge the se indivi dual F-measures. (Thi s is equal to the micro-a vera ge F-m easure  X  X  X  X   X  in this cas e because t he class di stribu tion is un ifo rm.) In this expe rim ent, we achie ved an overall F-m easure of 61.2%, u p 22% from the previ ous basel ine of 50% fo r trad itio nal IG. (W e rep eated th is ex perimen t for Na X v e Bayes and sa w a si milar im provem ent of 12% o veral l.) 4.1 Impro veme nt over all 19 Datase ts Next we prese nt an eval uatio n over a large classification benc hm ark t o test the merit of S prea dFx appl ied t o the widel y pract iced IG an d C HI m ethods . C ertainly as we increase t he num ber of fe atur es to a ve ry large num ber, any featu re selectio n alg orith m will b egin to prov ide many predictive feat ures fo r all c lasse s. So th e p rim ary hypo thesis to test is wh eth er th e b enefit o f Sp read Fx is bene ficial at smaller num ber s of selected features. T hat said , we wo uld also lik e to see a g ain fo r larg er nu mbers of features selected. SpreadFx[ R oun d -Ro bin, IG ] Fo r th e indu ctio n algo rith m, we ch ose the multi-class Support Vector Mac hine (SVM), as it is consi dere d among th e b est in class for t ext classificatio n, an d qu ite popu lar (e.g. Yang &amp; Liu , 1999 ; Jo ach im s, 1 998 ). We initially ex pected th at it wo uld be difficult to improve SVM resu lts. To sh ow th at th e resu lts are no t p articu lar to SVM , we al so dem onst rate sim ilar im prove ment for t he traditional Na X  ve Bayes clas sifier, which is m ore hi ghly sen sitiv e to featu re selection . We per formed o ur eval uat ions on the C ora dat aset , plus 18 other t ext dat aset s p rovided by Han and Kary pis (2000). Refe r to Table 1. The classifica tion tasks a re dra wn fr om standa rd benc hm arks such as R euters, OH SUM ED, and TR EC , a mong ot hers. The dat aset s ran ge from M=6 t o 36 cl asses, 2,000 t o 31,000 binary featu res, and h ave un even class distribu tio ns with a med ian of 1 positiv e to 17 negativ e trai ning ex am ples (and a vera ge 1:31). No clas s is du plicat ed i n diffe rent datasets. For a d etailed ex positio n of th e datasets, p lease refer to th eir pap er or else Form an (2 003 ). We will g ladly make the feature vectors a vailable on request . For eac h dataset and feat ure selection schem e, we per form 4-f old cros s-val idation runs , o btaining t he m acro-avera ged F-m easure ac ros s all the classes o f th e d ataset. We the n a verage t hese results across five random stratified cro ss-v alid ation sp lits for each of th e 19 datasets. (The results for accuracy and even m icro-averag e F-m easu re are qualitativ ely si milar to wh at follows and are o mitted fo r brev ity.) Figure 4 pres ents the resu lts fo r S VM (left) an d the trad itio nal Na X v e Bayes classi fier (righ t). Each gr aph shows resu lts for th e po pu lar multi-class IG m etric, as wel l as t he M ax.IG vari ant an d S prea dFx var iant s fo r bot h of the sc hedul ing algorithms di scuss ed. First, o bserv e th at trad ition al IG an d Max. IG p erform ed worse t han either Sprea dFx variant ov er mo st of th e range for bot h clas sifiers. As w e expect, t he greatest gai n appea rs at sm aller num bers of features s elected, with Ro und -Robin pr ov iding th e best im prov em ent. In cont rast , R and-Robi n at 20 feat ures i s eq uival ent in per formance t o pl ain I G. T he best pe rformance o ver both graph s is ob tain ed by SVM using Rand -Rob in with 500 -1000 feat ures , whereas Ro und-Robi n d ecl ines he re. Ob serv e th at SVM with 1 00 feature s selected via Sp readFx[ Roun d-Rob in, IG ] has better perform ance than IG  X  X  best pe rform ance wi th an o rder of m agni tude m ore feature s, and is better t han using all the features, i ndicate d by the l abel ed horizontal line. T hat IG has difficulty achi eving this level of pe rformance may l end t o the popular m yth that su pport vector m achi nes do not bene fit from feature se lection. Clearl y Na X ve Bayes is much m ore sen sitiv e t o featu re selectio n, and Roun d-Rob in lead s to a great perform ance im provement. To dem onstrat e that the sire n effect is not peculiar to IG, we also prese nt the res ults for CH I an d i ts variants i n Figure 5 likewise. The Round-R obi n variant agai n dom inates i n protect ing ei ther classifier from the siren effect . Rand-Robi n pr oved weaker paired with CHI. Fo r all m ulti-class featu re selectio n m ethods th at p erfo rm inde pen dent feat ure-sco ring we have e xpos ed a pitfall whe reby they get distracted from sel ect ing usef ul feat ures pre dictive features for easie r classes. We dem onstrate d this in detail on a dataset th at h as been carefu lly con struct ed t o have a u niform cl ass di stribut ion an d roughly uniform topical cont ent in each class. Text classification tasks in real-world settings are rarely this regular, e.g. classifying email into folders, and would be even more likely to exhibit this siren pitfall. We then discussed a parameterized family of algorithms to distribute the allocation of features among the classes, presenting two scheduling policies that are simple to implement. In evaluation on a substantial benchmark, we found consistent improvements for multi-class SVM and Na X ve Bayes over basic IG or CHI, especially at smaller numbers of features selected. We note that SVM using features selected by SpreadFx[ Rand-Robin, CHI ] performed better with 500-1000 features than any other method, including using all the available features. The proposed family of feature allocation policies attempts to be  X  X air X  in distributing attention to all classes, optionally according to their class distribution or other estimated cost weighting. We note that there is no guarantee that such a policy will work better. For example, suppose there were a large important class for which no features are predictive X  X  policy that focuses features on this large difficu lt class may ultimately suffer overall. It could be that allocating that budget of features to other classes would lead to a much greater overall improvement in classification. There are certainly few guarantees in this business. The best we can hope for is that typical text classification tasks rarely exhibit such pathological behavior, and so there may be some feature selection methods that are significantly better and more robust on typical text classification tasks encountered in practice. Potential future work includes verifying the benefit for other promising classification models, other benchmarks including non-text and cost-sensitive scenarios, other scheduling policies, and other base feature selection metrics, such as weighted Bi-Normal Separation (Forman 2003), which can otherwise be applied only to two-class tasks. Finally, although we d eclared at the outset that wrapper methods are outside the scope of this paper, note that advances in fast scoring methods, such as proposed here, should be welcome to research in wrapper methods for use as potential heuristics to guide their search more efficiently. We gratefully acknowledge th e WEKA machine learning project for their open-source software (Witten &amp; Frank, 2000), Han and Karypis (2000) for their prepared datasets, and Tom Fawcett for the Cora dataset. We acknowledge the INRIA Info rmatics and Distribution Laboratory for cycles on the ID/HP i-cluster. Thanks also to the reviewers who made this a better paper. Forman, G. (2003). An Extensive Empirical Study of Feature Selection Metrics for Text Classification. Journal of Machine Learning Research , 3 , 1289-1305. Guyon, I., Weston, J., Barnhill, S., &amp; Vapnik V. (2002). Gene Selection for Cancer Classification using Support Vector Machines. Machine Learning, 46, 389-422. Hall, M., &amp; Holmes, G. (2003). Benchmarking Attribute Selection Techniques for Discrete Class Data Mining. 
IEEE Transactions on Knowledge and Data engineering , 15, 1437-1447. Han, E.H.S., &amp; Karypis, G. (2000). Centroid-Based Document Classification: Analysis &amp; Experimental 
Results. 4 th Conference on Principles of Data Mining and Knowledge Discovery (pp. 424-431). Joachims, T. (1998). Text Categorization with Support Vector Machines: Learni ng with Many Relevant Features. 10th European Conference on Machine Learning (pp. 137-142). Kohavi, R., &amp; John, G. H. (1997). Wrappers for Feature Subset Selection . Artificial Intelligence, 97, 273-324. Mladenic, D., &amp; Grobelnik, M. (1999). Feature Selection for Unbalanced Class Distribution and Na X ve Bayes. 16th International Conference on Machine Learning (pp. 258-267). Mladenic, D., &amp; Grobelnik, M. (1998). Word sequences as features in text learning. 17th Electrotechnical and Computer Science Conference . Rennie, J. (2001). Improving multi-class text classification with naive Bayes. Master's thesis, Massachusetts Institute of Technology (ch. 5). Witten, I. H., &amp; Frank, E. (2000). Data mining: Practical machine learning tools with java implementations. San Francisco: Morgan Kaufmann. Yang, Y., &amp; Liu, X. (1999). A Re-examination of Text Categorization Methods. ACM SIGIR Conference on 
Research and Development in Information Retrieval (pp. 42-49). Yang, Y., &amp; Pedersen, J.O. (1997). A Comparative Study on Feature Selection in Text Categorization. 14th 
International Conferen ce on Machine Learning (pp. 
