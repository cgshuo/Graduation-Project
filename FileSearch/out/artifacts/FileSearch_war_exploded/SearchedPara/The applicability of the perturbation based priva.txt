 1. Introduction
Privacy preserving data mining has been studied extensively during the past several years. Several tech-niques ranging from perturbation to secure multi-party computation have been explored. In this paper, we focus primarily on the perturbation techniques. These techniques are usually used in scenarios where individ-uals can perturb their private data with some known random noise and report the perturbed data to the data miner. Since the distribution of the added noise is known, the data miner could reconstruct the original dis-tribution using different statistical methods and mine the reconstructed data.
When we examine the details of the perturbation techniques, introducing noise and reconstructing the original distribution emerge as the two most important phases (see [1 X 3] ). During the noise addition phase, random noise from a known distribution (e.g. Gaussian Noise with mean 0, variance r vacy sensitive data. Currently, all of the existing noise addition methods add the same amount of noise for example, according to an Internet user survey reported in [4] ,  X  X  X t seems unlikely that a one-size-fits-all approach to online privacy is likely to succeed X  X . To address this issue, we suggest a new noise addition technique that allows each individual to choose his/her own privacy level according to their privacy choices. Our experimental results indicate that our noise addition approach can support various types of users with varying privacy needs without significant degradation in the quality of the data mining results.

In this paper, we also address the applicability of reconstruction techniques in the real world. Our exper-imental results indicate that the reconstruction techniques may not work well when applied to many real-world data sets. This implies that using the reconstruction methods, such as the one proposed in [1] , may not give good data mining results in practice. Instead, for some data mining techniques such as the Naive
Bayes classification, we suggest to skip the reconstruction phase and build data mining models from the per-turbed data directly. We show the effectiveness of our proposed approach on different real-world data sets. 1.1. Our contributions
Our main contributions in this paper are as follows:  X  We present a novel two-phase perturbation method for numerical data that enables individually adaptable privacy protection.  X  We carry out an extensive study of the perturbation methods on different data mining tasks using both syn-thetic and real-world data sets, and show that in many cases skipping the reconstruction phase can give better data mining results. 1.2. Organization of the paper
The paper is organized as follows: In Section 2 , we discuss the related work. Section 3 introduces a privacy metric used to measure privacy loss in our experiments. Section 4 describes our two-phase perturbation model and shows the reconstruction results of our model. Section 4.2 describes how the model described in Section 4 imental results that are conducted by using various data mining techniques on both synthetic and real-world the future work. 2. Related work
Previous work in privacy preserving data mining is based on two approaches. In the first one, the aim is to preserve customer privacy by perturbing the data values [1] . The main premise of this approach is that the perturbed data does not reveal private information, and thus is X  X  X afe X  X  to use for data mining. The key result is that the distorted data together with the information on the distribution of the random data used to distort the data can be used to generate an approximation to the original data distribution without revealing the original data values. Later, refinements of this approach tightened the bounds on what pri-vate information is disclosed, by showing that the ability to reconstruct the distribution can be used to tighten estimates of the original values based on the distorted data [2] . Since then many good approaches have been proposed [3,5,6] . To the best of our knowledge, the existing perturbation based approaches apply random noise to the data sets without considering different privacy requirements of the different users.
Also one interesting reconstruction approach is proposed by Kargupta et al. in [3] . By using random matrix properties, Kargupta et al. [3] successfully separate the data from the random noise and subse-quently reconstructs a good approximation to original data. Recently Huang et al. [6] analyzed the con-ditions under which the privacy of the underlying data used in perturbation method could be violated.
Their results indicate that when the correlations between the data items are high, the original result can be constructed more easily. Some other researchers have proposed different noise addition techniques to protect the private data [7 X 9] .In [9] , authors have proposed a random rotation based perturbation approach, in [7] the authors used multiplicative random projection matrices, and in [8] the authors inves-tigated the distance preserving data perturbation technique from attackers X  point of view. Only few of these works have explored the applicability of the perturbation based approaches on variety of real-world data sets.

The perturbation approach has been also applied to Boolean association rules [10,11] . Again, the idea here all these cases the attributes have to be enumerable  X  X 0 X  X  or  X  X 1 X  X  values.

The other approach uses cryptographic tools to build data mining models. For example, in [14] , the goal is approach treats privacy preserving data mining as a special case of secure multi-party computation and not only aims for preserving individual privacy but also tries to preserve leakage of any information other than the final result. Unfortunately, in this approach, the communication and computation cost grow significantly as the number of parties increases. 3. Privacy metrics
In [2] , authors have proposed a privacy measure based on differential entropy. In this section we briefly review the related concepts that are used in this paper.

The differential entropy h ( A ) of a random variable A is defined as follows: Based on this observation, in [2] , they proposed to measure the privacy inherent in the random variable A as P ( A )=2 h ( A ) . We choose this privacy measure to quantify privacy in our experiments.
For example, using the above definition, a random variable U distributed uniformly between 0 and a has uniformly in an interval of length 1 . Furthermore if f B
For example, a random variable uniformly distributed over [0,1] has half as much privacy as a random var-iable uniformly distributed over [0,2]. In [2] authors have also defined conditional privacy and information loss. For more details, please refer to [2] . 4. Individually adaptable two-phase perturbation model
The perturbation method is based on introducing noise without significantly changing the distribution of extent to which we perturb the original data can dramatically affect the data mining results and subsequently turbation is not trivial. For example, consider the following common noise addition technique, first proposed in [1] .
 identically distributed ( iid ) random variables, each has the same distribution as the random variable X .  X  Let y 1 ; y 2 ; ... ; y n be the random values used to distort the original data, y identically distributed ( iid ) random variables, each has the same distribution as the random variable Y . Either uniform or gaussian distribution with the following properties is used to generate random variable
Y : estimate probability distribution F 0 X (of original data).

We can see that the noise addition procedure described above is only one step; that is, we add the noise to model the one-phase perturbation model.
In this paper we propose a two-phase perturbation model. In this new model, we first divide the domain of the W into predetermined intervals. After generating the w  X  l ; l k  X  1  X  which w i falls. Instead of using w i during the reconstruction phase, we use a w
W have similar cumulative distribution functions for small intervals, consider the relationship between the c . d . f of W and W 0 shown in Figs. 1 and 2 . In these figures, W intervals are used to create the W 0 data set; similarly W using 20 intervals. We can see that when the interval number is increasing, the c . d . f of W the c . d . f of W . In practice, we set the number of intervals such that c . d . f of W
Fig. 3 shows the processes of both one-phase and two-phase perturbation models. Below, we show that the phase perturbation model. 4.1. Original distribution reconstruction for two-phase perturbation model
As we mentioned above, the second important step of the perturbation based approaches is to reconstruct reconstructing the original data distribution are very important in learning useful models.
To show that our two-phase noise addition approach described in this section could be used in practice, we run experiments using the pioneering Bayesian inference base reconstruction method proposed by Agrawal et al. [1] . (Please see the Appendix for more details.)
For accurate comparison, we use the same experimental set up that is also used in [1] . Let X be the original [0,1]. Let Y be the noise distribution where we use the following parameter values:  X  Gaussian distribution: We use a normal distribution with mean l = 0 and standard deviation std = 0.25.
We keep the original data set and the first step perturbed data set W . We create the data W (1) We divide [ 0.5,1.5] (the domain of W ) into 40 intervals. (2) Given the each perturbed data point w i , we sample uniformly from the corresponding interval where
The experimental results shown in Fig. 4 indicate that Agrawal et al. X  X  Bayesian inference based reconstruc-does not significantly change the underlying cumulative distribution of the W . Therefore the Bayesian infer-ence based reconstruction approach could still achieve good reconstruction results, as shown in Fig. 4 . For more experimental results, please refer to our earlier work [19] . 4.2. Individually adaptable perturbation model using two-phase perturbation
Our two-phase perturbation model described in Section 4 could be easily modified to incorporate different w user who is more cautious could use the interval  X  l k 1 ; l
Using this fact, we can describe individually adaptable perturbation method as follows: (1) The system first adds a random noise Y  X  X  y 1 ; y 2 ; ... ; y (2) User i chooses his/her privacy level among various privacy levels shown in Fig. 5 . (3) Based on the user X  X  privacy level choice, the system applies an interval length  X  l (4) w 0 i value is sent to the data miner.

The relationship between different privacy preference and perturbation level is shown in Fig. 5 . Each pri-different individuals will enable the individual adaptability.

Once the data miner receives the w 0 i values, Bayesian based reconstruction approach described in Section 4 the given data will look more like a random sample. If the length of the chosen interval is small w from is small, cumulative distribution function F W and F tomers can choose different interval lengths to modify their privacy levels. This privacy level could be mea-sured using the metrics described in Section 3 . To test the effectiveness of our individually adaptable perturbation method, we have conducted extensive experiments as described in Section 6 . 5. Data mining experiment results
Although, we wish to protect individual privacy by carrying out privacy preserving data mining, our ulti-ginal data set, we do not want the perturbation technique to have any significant effect on the data mining results. To test the effect of privacy preserving data mining on accuracy, we build decision trees and naive Bayes classifiers on both synthetic and real-world data sets.

Before, we discuss the results, we give an overview of the data sets used in our experiments. 5.1. Overview of the data sets
For comparison purposes, we used the synthetic data which was used by Agrawal et al. in [1] . The data set Appendix for completeness.

We have chosen three real-world data sets for our experiments from University of California, Irvine, machine learning database repository, 1 We briefly summarize the properties of these data sets below.  X  Income data
The data set was extracted from the census database 1994, and it is used to predict whether the income attributes, six are continuous attributes and eight are nominal attributes. We only use the six continuous attributes in our experiments. We used 32,561 instances for training and 16,281 for testing purposes.  X  Haberman survival data  X  Liver data 5.2. Reconstruction of the original distribution
As described above, in each data set there are more than one attribute, and for training data, each instance completeness.  X  Global  X  ByClass  X  Local
In [1] , the authors mentioned that the global method does not give good results, and local method X  X  com-putation cost is high due to repeated the reconstruction process. For these reasons, we choose to use ByClass method as a reasonable compromise between efficiency and accuracy to reconstruct the original distribution. 5.3. Data mining experimental results on synthetic data
For the synthetic data experiments, we have generated 100,000 records, and randomly choose 66,000 of those records are used for training, and 34,000 of those records are used for testing purposes. We used
WEKA [20] data mining software to run decision tree and Naive Bayes classifiers on our reconstructed data, and reported the experiment results on the test data. We have compared the performance of these two classifiers on various scenarios with the results reported in [1] . In our experiments, we assumed that there are four different user types with different privacy requirements. Table 2 shows the four different cases with different percentage of people with different attitudes towards privacy. Compared to the normal people, cautious people may want to preserve more privacy. So when we are sampling the perturbed data, we use a smaller interval length for normal people; and we use twice the interval length for cautious peo-ple; and so on. Based on the four different groups, we generate four different data sets, named case 1 to case 4, and with different percentages are assigned to different categories. Since different attributes have different lengths in our data set, we set the intervals for each type by calculating domain-size divided by the number of intervals. For example, in case 4, 100K perturbed record data set is created as follows: we sample 70K perturbed data records using 200 intervals, then we sample 20K records using 100 intervals, and then we sample 5K records using 50 intervals, the last 5K records are sampled using 25 intervals.

We apply the privacy metrics described in Section 3 to four different cases. We used the mutual information most privacy loss, case 2 has less, and so on, then case 4 has the least privacy loss.
Although it looks like that the privacy enhancement between case 1 and case 4 shown in Table 2 is small, the main difference occurs due to increased privacy provided for paranoid, cautious and extra cautious user types. As it can be seen from Table 2 , both case 1 and case 4 have almost 70% normal users.
Fig. 6 shows our data mining results. First of all, our results indicate that the differences between the outcomes of our two-phase perturbation model compared to those from one-phase perturbation model are not significant. Among these five functions we tested, function 2 and 3 are not easy to learn. (Please see Naive Bayes classifiers.
 5.4. Experimental results for real-world data
We use the three real-world data sets, Income, Liver and Haberman, which we have described in the previous the predication accuracy significantly. For Liver and Haberman data sets, we randomly choose 2/3 of the
The interesting experimental results are shown in Table 3 . The first column is the data mining accuracy obtained from original data set. We use this column as the base line. The second column is the data mining accuracy obtained from perturbed data sets. We can see that accuracy is lower for the perturbed data, except turbed test data.
 In the first test, all the results have higher accuracy than the ones obtained from the original data sets.
In the second and third tests, two data sets get very low data mining accuracies. Only the Haberman data set achieves an accuracy similar to what we obtain from the perturbed data. This result raises the follow-ing question: Is the reconstruction method applicable for all the real-world data sets? Please note that for reconstruction, the instances of the reconstructed data set are similar to the original data set due to the fact that every attribute is independently and uniformly distributed. This is not realistic in many situations.

In this paper, we have conducted experiments on three real-world data sets. These data sets may have their limitations, but still our experimental results indicate that perturbation methods do not work well when the hard reconstruction problem as an intermediate step. Although, at this point we can not simply say that the reconstruction method is not applicable for real-world data sets. Clearly, caution needs to be exercised before applying reconstruction phase in practice. 6. Applicability of reconstruction method in PPDM for real-world data
As shown in the previous section, reconstruction phase of the perturbation based privacy preserving data mining may not be applied in some cases. The question is what can we do if the reconstruction phase fails for the data set we are interested in (e.g. Income data and Liver data in our case)?
Our solution is rather simple. We suggest a direct approach for such hard reconstruction cases. Our mation for solving some problem, try to solve the problem directly and never solve a more general problem as cient for solving a more general intermediate problem. X  X  the perturbed data. By learning data mining models from perturbed data directly, we intend to solve the ori-ginal problem (e.g. building data mining models) without trying to solve a hard intermediate problem (e.g. reconstruction of the original data distribution). Below, we show that this is not only feasible but it may be preferable in the case of learning Naive Bayes Classifiers from perturbed data directly.
Also Agrawal et al. [1] observed the phenomenon that mining directly from the perturbed data sets can obtain fair data mining results for synthetic data sets. Compared to their work, we have performed extensive experiments using different data mining techniques on several different real-world data sets. We believe that our results provide more evidence to support this phenomenon. 6.1. Naive Bayes classifier construction over perturbed data
We do not need to reconstruct the original data distribution to build a Naive Bayes classifier from the per-turbed data. Instead, we can directly use the Naive Bayes algorithm on the perturbed data. Before showing why such a direct approach is feasible, we give an overview of the Naive Bayes classifier construction, then we explain why the Naive Bayes algorithm can be applied directly on the perturbed data.
Using the Bayesian approach, the Naive Bayes classifier labels a new instance by assigning the most prob-simplify the estimation of the required probabilities. Using the above assumptions, Naive Bayes classifier selects the most likely classification C nb as [23] where X  X  X 1 ; X 2 ; ... ; X n denote the set of attributes, C  X  C labels, and C nb denote the class label output by the Naive Bayes classifier.

Clearly, we need to calculate the probabilities P ( X i = x j C practice, for numeric attributes, P ( X i = x j C j ) is estimated by using Gaussian distribution N  X  l required parameters, l ij = E ( X i j c j ) and r 2 ij  X  Var  X  X
In our case, we need to estimate l ij and r 2 ij for each attribute X perturbed numeric data to construct a Naive Bayes classifier. In the perturbed data case, instead of the original attribute value X i , we only see the W i = X the t th training data instance with class label C j . In addition, we assume that there are n instances with class label C j .
 variance r 2 R . Using the above facts, we can show that the expected value of w
Since the sample variance S 2  X  1
As a result, as long as we do not change the class labels, we can directly construct Naive Bayes classifier from the perturbed data. Even more, since the parameter estimations done by using the perturbed data and the original data have the same expected values, we should be able to get similar classification accuracy reconstruction, we may get a better accuracy.

The test results reported in Table 3 verifies the above intuition. The reported results using the Naive Bayes accuracy when we mine the Naive Bayes model directly from the perturbed data.
 6.2. Directly apply data mining technique to perturbed data sets
From the above analysis of Naive Bayes classifier, we can see that when we only introduce white noise, directly applying data mining techniques to perturbed data is an effective and efficient approach.
Of course our analysis are only valid for Naive Bayes classification. Unfortunately, it is not trivial to extend such analytical analysis for more complex data mining models. Instead, to investigate the effect of directly mining perturbed data in general, we have performed experiments using different data mining techniques. 6.2.1. Experimental results of data mining accuracy vs data set size
We used three different classifiers (e.g. decision tree C4.5, Naive Bayes (NB) and neural network, mul-tilayer perceptron (MLP) learning) on different size perturbed data sets randomly selected from Income data. In these experiments, we use Gaussian noise with signal to noise ration set to 1.0. In our experiments, we used different size, (e.g. 1k,3k, ... ,11k), of perturbed data as training data set, and then test the model accuracy either on original data set or perturbed data set. The experimental results have been reported in Table 4 . The data mining accuracy fall in the rage from 76.22 to 79.76, compared with the data mining accuracy obtained from original 3k data set, which are 83.29 for tree C4.5, 79.66 for
Naive Bayes, and 83.43 for neural network. Especially for Naive Bayes classifier, the accuracy difference is less than 1%. This confirms our analysis in the previous section. Also it is interesting to see that for income data set, number of instances bigger than 1K did not have any significant effect in terms of accuracy. 6.2.2. Experimental results of data mining accuracy vs. SNR values
As we mentioned before, SNR denotes to signal to noise ratio. This is an important feature when we use on original data is low. This definitely effects the data mining accuracy when mining is done using the per-sifiers as the SNR value decreases, the data mining accuracy decreases as well. 6.2.3. Experimental results of data mining accuracy vs. different real-world data sets
The results reported in Tables 5 and 6 indicate that directly mining perturbed data for the cases where reconstruction phase do not work is a viable alternative even for some other data mining tasks. 6.2.4. Individually adaptable perturbation model on perturbed data sets
We also applied our two-phase individually adaptable perturbation model on these three real-world data types (shown in Section 5.3 ). We applied different data mining techniques on these four different cases and compared to the results obtained using one-phase perturbation model. The data mining result accuracy has shown in Tables 7 X 9 . We can see that our two-phase adaptable model enables users to have more privacy choices without reducing the data mining accuracy. 7. Conclusions and future work
Due to the varying privacy needs of different individuals, the one-size-fits-all approach is not realistic in many privacy preserving data mining tasks. In order to address this problem, we have proposed a new per-turbation method for privacy preserving data mining that can provide individually adaptable privacy protec-tion. Our method enables users to choose different privacy levels without significant data mining performance degradation.

In order to confirm the effectiveness of our method, we have carried out extensive experiments under dif-ferent data mining scenarios. Our results indicate that if only a small number of people choose to have high levels of privacy (i.e., more perturbation), we can still find useful data mining results.
Similar to the previous work in this area, our method does not address the multiple attribute case. The obvious solution of adding independent random noise to each attribute may not offer good privacy protection for high dimensional data, since outliers can be easily detected. Although existing methods could be used by adding a random noise using a multivariate distribution, construction process could require large amounts of data. As part of our future work, we plan to investigate a different approach. Instead of trying to come up with a noise addition method that can be used for general data mining tasks, we plan to develop a noise addition method specific to different data mining techniques.

Reconstruction is a very important step for the perturbation based PPDM approaches. We have found that when applied to real-world data sets reconstruction could be a problem. To address this problem, we proposed
PPDM methods which skip this reconstruction step and compute the data mining results directly. We prove the viability of directly constructing data mining models on real-world data sets. In the future, we plan to investigate different data mining methods in this direction.
 Appendix A. Agrawal et al. X  X  algorithm  X  Bayes estimation based approach
In Agrawal et al. X  X  work [1] , the Bayes theorem based algorithm is described as follow: Given the noisy data probability distribution F Y , and the random values of perturbed data ( x original data set can be estimated as below: Algorithm 1. Agrawal and Srikant Bayes theorem reconstruction algorithm
Running the algorithm on a large data set, and set the stop criterion to a small number, e.g. 0.25%, the algorithm would calculate an estimated density function that is very close to the real density function. Appendix B. Signal to Noise Ratio
Signal to noise ratio (SNR) is a very important index in the noise addition techniques. When using Gauss-[3] . SNR is the term to quantify the relative amount of noise added to actual data.
 Appendix C. Data mining functions used for synthetic data
There are five functions used as data mining classification functions in mining synthetic data. These func-tions are well described in the work [1] , shown in Table C.1 .

References
