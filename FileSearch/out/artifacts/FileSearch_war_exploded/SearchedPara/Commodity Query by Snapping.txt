 Commodity information such as prices and public reviews is always the concern of consumers. Helping them conveniently acquire these information as an instant reference is often of practical significance for their purchase activities. Nowa-days, Web 2.0, linked data clouds, and the pervasiveness of smart hand held devices have created opportunities for this demand, i.e., users could just snap a photo of any commodity that is of interest at anytime and anywhere, and retrieve the relevant information via their Internet-linked mobile devices. Nonetheless, compared with the traditional keyword-based information retrieval, extracting the hidden information re-lated to the commodities in photos is a much more com-plicated and challenging task, involving techniques such as pattern recognition, knowledge base construction, semantic comprehension, and statistic deduction. In this paper, we propose a framework to address this issue by leveraging on various techniques, and evaluate the effectiveness and effi-ciency of this framework with experiments on a prototype. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval Information retrieval; commodity; snapping
Query by keywords is one of the most important and prevalent mechanisms for information retrieval. Nonethe-less, this mechanism is still far from perfect or convenient sometimes. Take the following scenario as an example. When users stumble across a X  X ew X  X roduct in a supermarket, they usually would like to refer to others X  reviews and comments on the product, or to know whether there is a lower price or any better alternatives. With the traditional information re-trieval procedure, users have to visually extract and organize the keywords to describe the product by themselves, and in-put these keywords on their Internet-linked mobile devices, followed by checking each search result if it contains review information as expected. Such a process is not so easy since the choosing of keywords affects the search results. Instead, it would be more efficient and effective for users to snap a photo of the product, and let the system automatically gen-erate the keywords as inputs to an existing search engine. The idea of query by snapping is not new. It was introduced in 2006 when camera became a part of a mobile phone.
In recent years, several APPs and APIs running on mobile devices have been developed for query by snapping, such as barcode scanners, image matching-based solutions [5], and Google Goggles which combines image matching and OCR. Nevertheless, these approaches still have a few minor flaws in effectiveness or convenience when they are used to query commodities. For example, (1) it is not convenient for a user to take and turn a commodity to scan its barcode when the commodity is not at hand or the user is in a hurry; (2) commodities sharing similar appearances, such as se-ries products, significantly affect the image matching results; and (3) the results of image matching and OCR are directly returned by Google Goggles without a further analysis to determine the exact names of the objective commodities.
In this paper, we focus on a simple yet effective mecha-nism for commodity query by snapping. It enables users to retrieve relevant and useful product information, such as the exact name, brand information, recommended retail price, reviews, and similar alternatives, by just snapping a photo of a commodity and submitting it to our system. We pro-pose a framework which addresses the following three issues: (1) first, extracting the information printed on the surface of an objective commodity; (2) second, deducing the brand in-formation which will help users locate the commodity more accurately; and (3) third, generating the final keywords that exactly describe the commodity for the retrieval of the re-lated product information from the Internet.
The framework contains two parts, i.e., (1) the off-line part in which a knowledge base is constructed based on m product names N j ( j = 1 , . . . , m ) crawled from e-commerce web sites, such as Amazon and eBay; and (2) the on-line part consisting of three phases, i.e., keyword extraction, brand deduction, and information retrieval.

In the off-line knowledge base, the product names are split into a set W of standard word items w i  X  W , i = 1 , . . . , n , and the three matrices below are constructed by statistics, namely (1) the word symbiosis matrix S w here the value of each element S ik ( i, k  X  { 1 , . . . , n } ) denotes the co-occurrence probability Pr( w k | w i ) that word w k appears in the product names containing word w i ; (2) the product-word matrix P of which each element P ji ( j  X  { 1 , . . . , m } , i  X  { 1 , . . . , n } ) represents the occurrence times of word w in product name N j ; and (3) the brand-product matrix B indicates whether or not the commodity with product name N j belongs to the t th brand with 1 for yes and 0 for no.
Using the knowledge base, the on-line part carries out a query by snapping through the following three phases.  X  Keyword Extraction . On a commodity, there are usually both useful information (e.g., product name, brand) and trivial information (e.g., net weight, user guide). Thus this phase aims to extract the informative keywords that describe the commodity in the specified photo appropriately.  X  Brand Deduction . To retrieve the product information of a correct commodity for users, it is important to iden-tify the commodity accurately. Although the extracted key-words may express the most important information of the commodity, sometimes they are not clear enough to find out the exact commodity, especially when there is no brand information contained in the keywords. For example, key-words  X  X acial X ,  X  X oam X , and  X  X ucumber X  have delivered the main information for a commodity named dove facial foam of cucumber scent though, they are still ambiguous for the tivated by this, we deduce the brand of the commodity to complement extracted keywords for the sake of clarity. In-stead of using existing techniques such as image matching-based Logo recognition [1], we infer the brand information based on the extracted keywords, the product-word matrix P and the brand-product matrix B , avoiding the extensive cost of building a large-scale brand Logo database.  X  Information Retrieval . In a traditional information ac-quisition mechanism, users provide an exact description of a commodity as the query keywords to obtain a better search results. In our framework, this query keywords can be gen-erated automatically using extracted keywords and the de-duced brand with the help of Google. With our query key-words which exactly describe an objective commodity, the desired commodity information can be accurately retrieved from the e-commerce and product-review websites.
There is plenteous information on a commodity X  X  package, such as the product name, brand, producer, net weight, and so on. Hence, it plays a key role in the commodity identifica-tion to extract the most useful keywords from the package. To this end, we introduce a three-step approach, i.e., (1) running OCR on the photo of a commodity to obtain what are printed on its package, (2) standardizing the OCR re-sults to a subset of the standard word items, and (3) filtering the standardized word items to remove the noise words that are not regular collocations of the other words.
To utilize the existing information of a commodity in a specified photo for the subsequent steps, first of all, we have  X  X acial foam cucumber X  and  X  X ove facial foam cucumber X . to recognize the characters printed on its package. Thanks to the advanced OCR techniques (e.g., Tesseract-OCR), the character recognition can handle characters from multiple languages and with poly-fonts. Nonetheless, due to the var-ious design styles of product package, such as flourish letters, and different inter-word and inter-character spaces, OCR is often unable to recognize every word on the commodity ac-curately. Partial OCR results are useless string fragments corresponding to errors in the recognition. To address this problem, we employ the set W of standard word items to emend the OCR results, and filter out the useless standard-ized word items based on the word symbiosis matrix S .
For each string fragment s in OCR results, we map it to a standard word item w i  X  W ( i  X  { 1 , . . . , n } ) with the maximal similarity to s . Here, the similarity is defined as
Similarity ( s, w i ) = 1  X  Ed ( s, w i where Ed ( s, w i ) is the edit distance (a.k.a. Levenshtein dis-tance, which is commonly used to evaluate the similarity be-tween strings [3]) between s and w i , Length ( s ) &amp; Length ( w are the string lengths of s and w i respectively. As Ed ( s, w 0 , max { Length ( s ) , Length ( w i ) } , Similarity ( s, w
Since a few string fragments are meaningless symbols (e.g.,  X ? X ,  X  ||  X ,  X  X  X ) corresponding to errors and noises in OCR, we make use of the following heuristic, i.e., for each string fragment s , if Similarity ( s, w i ) is less than a threshold T ( T s = 0 . 5 in this paper) for any w i , then the current s is discarded without mapping it to any standard word item.
Although standardization cleans up OCR results, it may occasionally bring with several word items that are not printed on the commodity. For example, the word  X  X en X  may be transformed from a meaningless string fragment  X  X en X . In order to improve the accuracy of the commodity identifica-tion, these unexpected word items should be removed.
Inspired by collaborative filtering [4] which predicts the interests of a user by collecting preferences from many users, we predict the unexpected word items according to the co-occurrence probability of each two standard word items, i.e., the elements of the word symbiosis matrix S . The detailed steps for the filtering process are as follows.

Step 1. If  X  w k , S ik = 0, then filter out this standardized word item w i .
 Step 2. For each remaining w i with max k S ik &lt; 1, if where I (  X  ) is the indicator function, and T p a threshold ( T 0 . 2 in this paper), then filter out this w i .

By filtering out the unexpected words, we can obtain a set of word items with much more cohesiveness in colloca-tion. These filtered word items are returned as the extracted keywords for the objective commodity.
Product brand is important for commodity identification due to its uniqueness. However, sometimes there is no brand information in the extracted keywords, especially in the cases that the commodity brands are images or in art fonts that a re very difficult to be recognized by OCR. Instead of us-ing Logo recognition, we deduce a product brand with the extracted keywords, avoiding to hassle with constructing a large-scale Logo database.

In fact, even if extracted keywords may not contain prod-uct brands explicitly, their collocations can also imply brand information. For example, keywords  X  X ro-x X  and  X  X rofes-sional X  imply that the commodity is very likely one of the pro-x series products of Olay. Thus, we can deduce the prod-uct brand by two steps, i.e., (1) finding out the most relevant commodities of the extracted keywords, and (2) checking which brand owns these relevant commodities.
In our knowledge base, there are n standard word items w i ( i = 1 , . . . , n ) extracted from the product names N ( j = 1 , . . . , m ) of m commodities. For each w i , the product-word matrix P has recorded its occurrence times P ji in each product name N j . Let Y i be the occurrence times of w i the extracted keywords, we can evaluate each commodity X  X  relevance  X  j ( j  X  { 1 , . . . , m } ) to the extracted keywords by solving the following minimization problem. where  X  = {  X  1 , . . . ,  X  m } .

The reasons behind are as follows. To minimize the squares bias between Y i ( i = 1 , . . . , n ) and P m j =1  X  j P (1) if P ji is close to Y i &gt; 0, i.e., word w i appears in both the extracted keywords and the j th commodity X  X  name with about the same occurrence times, then the j th commodity should have a higher relevance  X  j to the extracted keywords; (2) otherwise,  X  j will be close to zero since the extracted keywords include only a few standard word items such that most of Y i are equal to 0. Therefore, by solving the mini-mization problem with ridge regression [2], the relevance  X  between the extracted keywords and the commodities in the knowledge base will be revealed.
As the brand-product matrix B has recorded the affilia-tion between brands and commodities, we can combine it with the relevance  X  to deduce the brand of the commodity in the photo. Let  X  t ( t  X  { 1 , . . . , b } ) be the probability of that the t th brand is the true one, then the probability of each brand can be estimated as
By summing up the relevance between the extracted key-words and the relevant commodities belonging to the t th brand, each probability  X  t denotes the relevance between the commodity in the photo and the t th brand. The brand with the maximal probability is returned as the target one.
Based on the extracted keywords and the deduced brand, we generate the final keywords that describe the objective commodity much more exactly with the help of Google. The generation can be performed as follows.
 Figure 1: Example of the generated final keywords
S tep 1. Combine the brand with the extracted keywords as the search terms k = { k 1 , . . . , k p } , where k i the i th word in the search terms, and input them to Google.
Step 2. Extract a set t = { t 1 , . . . , t q } of the titles of the top search results listed on the first search result page, in which t j (1 6 j 6 q ) represents the j th title. Step 3. Rank each title t j according to its consistency C ( t j ) with the search terms k , where C ( t j ) denotes the total number of matched word items and approximately matched collocations in t j and k , and can be calculated as
C ( t j ) = X p
Step 4. Select the title with the maximal consistency with the search terms k as the final keywords.

Fig. 1 illustrates an example of the final keywords gen-erated by our framework for a commodity photo, together with the search results of these final keywords on Google, where the first one corresponds to the correct commodity.
By using the generated final keywords as the query terms, we can retrieve the related product information, such as rec-ommended retail price, reviews, and alternatives, from the e-commerce and product-review web sites.
We have implemented a prototype with Java for the pro-posed framework. With the prototype, we verify the effec-tiveness and efficiency of our framework from the two aspects below, i.e., (1) the performance study in terms of accuracy of commodity identification, and (2) the efficiency study in terms of runtime, after we present the experimental setup.
The prototype focuses on query personal care commodi-ties by snapping. It constructs a knowledge base with 830 standard word items, which are extracted from the prod-uct names of 600 personal care commodities crawled from Amazon.com. All these products come from 201 brands.
We adopt 100 photos of personal care commodities as the testing set. These photos differ from sizes, image-capturing conditions, illuminations, pros and cons of the commodities, etc. Furthermore, for the sake of fairness, about half of the testing commodities are outside the knowledge base.
The prototype runs on a laptop PC (2GB RAM, Intel Core 2 Due CPU 1.80GHz) under a 54.0Mbps wireless network.
We study the accuracy performance of our prototype in terms of (1) the accuracy of commodity identification (name accuracy for short), and (2) the brand accuracy. We also report the performance of Google Goggles, which is based T s &amp; T p . (c) Runtime on each tested photo. (d) Runtime distribution on both OCR and image matching, just for a reference. The detailed performance metrics are as follows.  X  Our prototype. (1) For the name accuracy, the first search result on Google using the generated final keywords should correspond to the true commodity; and (2) for the brand accuracy, the brand information within the final key-words should be unique and exactly the true brand.  X  Google Goggles. (1) The metric for its name accuracy is relaxed to either the first search result on Google using the OCR results as the search terms or the returned similar im-age corresponding to the true commodity; and (2) its brand accuracy can be checked by its Logo recognition result.
The accuracy study consists of two parts, i.e., (1) the effect of the size of knowledge base, in which we randomly select m ( m = 100 , 200 , . . . , 600) product names from the original 600 product names to construct knowlege base with different sizes, and record the accuracy performance of the prototype. Without loss of generality, we report its average performance of 20 times of run for each m ; and (2) the effect of the two parameters in our framework, i.e., the thresholds T s (see Section 3.2) and T p (see Section 3.3).

Fig. 2(a) illustrates the accuracy performance of the pro-totype using knowledge bases with various sizes, from which we can observe that the name and brand accuracy increase with the growth of the size of knowledge base. The rea-sons behind are as follows. (1) With fewer product names in the knowledge base, the number of the standard word items is smaller, increasing the risk that the OCR results cannot be mapped to the correct standard word items, and thus affecting the performance of the subsequent processes. (2) Contrarily, if there are abundant standard word items collected from many real product names, these word items can cover most words, even those in a  X  X ew X  product name not included in the knowledge base, which better reflects the word collocations in reality, leading to more reasonable extracted keywords and deduced brand.

Fig. 2(b) depicts the accuracy performance of the proto-type using different thresholds T s and T p , from which we can observe that the name and brand accuracy vary slightly with the change of these two parameters. In other words, the prototype is relatively robust to the parameters.
In this experiment, we investigate the efficiency perfor-mance of our prototype in terms of runtime by illustrat-ing the runtime for processing each photo in the testing set, and the runtime distribution in Figs. 2(c) and 2(d), respectively. Furthermore, since each runtime consists of three parts, namely (1) the time for OCR; (2) the compu-tation time for the standardization and filtering processes, the brand deduction, and the computation of local matching degree during the product information acquisition via web, and (3) the time consumed on Internet communication, the OCR, computation, and communication times and their dis-tribution are also depicted in the figures respectively.
We can observe that (1) the average runtime of the pro-totype is about 4.5 seconds, comparable to approximately 5 seconds required by Google Goggles running on the same wireless network; and (2) the computation and communi-cation times change slightly in each execution, resulting in that the runtime mostly depends on the time for OCR.
In this paper, we have proposed a simple yet effective framework for commodity query by snapping, which enables users to obtain relevant commodity information via their smart mobile devices by just taking a snapshot of an ob-jective commodity and submitting it to our system. Ex-periments on a prototype have verified the effectiveness and efficiency of the proposed framework.
This work was partly supported by the National Key Tech-nologies R&amp;D Program (Grant No.: 20128AH94F01), NSFC 61003049, the Fundamental Research Funds for the Central Universities (Grant No.: 2012QNA5018, 2013QNA5020), and the Key Project of ZJU Excellent Young Teacher Fund. [1] J. Chen, L. Wang, and D. Chen. Logo Recognition: [2] T. Hastie, R. Tibshirani, and J. Friedman. The [3] Y. Li and B. Liu. A normalized levenshtein distance [4] B. Sarwar, G. Karypis, J. Konstan, and J. Reidl. [5] S.S. Tsai, D. Chen, V. Chandrasekhar, G. Takacs, N.M.
