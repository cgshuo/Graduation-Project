 Performance monitor software for data centers typically gen-erates a great number of alert sequences. These alert se-quences indicate abnormal network events. Given a set of observed alert sequences, it is important to identify the most critical alerts that are potentially the causes of others. While the need for mining critical alerts over large scale alert se-quences is evident, most alert analysis techniques stop at modeling and mining the causal relations among the alerts. This paper studies the critical alert mining problem: Given a set of alert sequences, we aim to find a set of k crit-ical alerts such that the number of alerts potentially trig-gered by them is maximized. We show that the problem is intractable; therefore, we resort to approximation and heuristic algorithms. First, we develop an approximation algorithm that obtains a near-optimal alert set in quadratic time, and propose pruning techniques to improve its runtime performance. Moreover, we show a faster approximation ex-ists, when the alerts follow certain causal structure. Second, we propose two fast heuristic algorithms based on tree sam-pling techniques. On real-life data, these algorithms identify a critical alert from up to 270 , 000 mined causal relations in 5 seconds; meanwhile, they preserve more than 80% of so-lution quality, and are up to 5 , 000 times faster than their approximation counterparts.
System monitoring and analysis in data centers and cyber security applications produces alert sequences to capture ab-normal events. For example, performance metrics are posed on hosts in data centers to measure the system activities, and capture alerts such as high CPU usage, memory over-flow, or service errors. Understanding the causal and de-pendency relations among these alerts is critical for data center management [12, 25], cyber security [17], and device network diagnosis [23], among others.

While there exist a variety of approaches for modeling and deriving causal relations [3, 31, 32], another important step is to efficiently suggest critical alerts from a huge amount of observed alerts. Intuitively, these critical alerts indicate the  X  X oot causes X  that account for the observed alerts, such that if fixed, we may expect a great reduction of other alerts without blindly addressing them one by one. We consider several real-life applications below.
 Data centers . System monitoring and analysis providers seek efficient and reliable techniques to understand a large number of system performance alerts in data centers. Ac-cording to LogicMonitor 1 , a SaaS network monitor company, a data center of 122 servers generates more than 20 , 000 alerts per day. While it is daunting for domain experts to manually check these alerts one by one, it is desirable to au-tomatically suggest a small set of alerts that are potentially causes for a large amount of alerts, for further verification. These critical alerts also help in determining key control points for data center infrastructures [25].
 Intrusion detection [2, 16]. State-of-the-art intrusion de-tection systems produce large numbers of alerts from cyber network sensors, over tens of thousands of security metrics, e.g., Host scan or TCP hijacking [2]. As suggested in [16], it is observed that a few critical alerts generally account for over 90% of the alerts that an intrusion detection system triggers. By handling only a small number of critical alerts, a huge amount of effort and resource can be reduced. On the other hand, critical alerts can reduce the number of  X  X alse alerts X  and improve alarm quality [2].
 Network performance diagnosis [23]. Large-scale IP networks ( e.g., North America IPTV network) contain mil-lions of devices, which generate a great number of perfor-mance alarms from customer call records and provider logs. Scalable mining of critical alerts for a given set of symptom events benefits fast network diagnosis [23].

These highlight the need for efficient algorithms to mine critical alerts, given the sheer size of observed ones. In this work, we investigate efficient critical alert mining techniques. We focus on a general framework with desirable performance guarantees on alert quality and scalability. (1) We formulate the critical alert mining problem: Given a set of alerts and a number k , it aims to find a set of k critical alerts, such that the number of alerts that are poten-tially caused by them is maximized. We introduce a generic framework for mining critical alerts. In this framework, we learn and maintain an alert graph , a graph representation h ttp://www.logicmonitor.com/ of causal relations among alerts. Upon users X  requests, top c ritical alerts are mined from alert graphs. (2) We show that the critical alert mining problem is np -complete. Nonetheless, we provide an algorithm with ap-proximation ratio 1  X  1 e , in time O ( k | V || E | ), where | V | and | E | are the number of alerts and the number of their causal relations, respectively. To further improve the efficiency of the algorithm, we propose a bound and pruning algorithm that effectively reduces the size of alerts to be verified as critical ones. In addition, we identify a special case: when alert graphs are trees, it is in O ( k | V | ) time to find k critical alerts, with the same approximation ratio. (3) The quadratic time approximation may still be expensive for large alert graphs. We further propose two fast heuristics for large-scale critical alert mining. These algorithms induce trees that preserve the most probable causal relations from large alert graphs, and estimate top critical alerts and their impact by only accessing the trees. The first one induces a single tree, while the second algorithm balances alert quality and mining efficiency with multiple sampled trees. (4) We experimentally verify our critical alert mining frame-work. Over real-life data center datasets, our algorithms ef-fectively identify critical alerts that trigger a large number of other alerts, as verified by domain experts. We found that our approximation algorithms mine a top critical alert from up to 270 , 000 causal relations (one day X  X  alert sequences) in 5 seconds. On the other hand, while our heuristics preserve more than 80% of solution quality, they are up to 5 , 000 times faster than their approximation counterparts. The heuristics also scale well over large synthetic alert graphs, with up to in total 1 million alerts and 10 million relations.
In contrast to conventional causality modeling and min-ing, our algorithms leverage effecitive pruning and sampling methods for fast critical alert mining. In addition, we do not assume the luxury of accessing rich semantics from the alerts that helps in improving mining efficiency, although our methods immediately benefit from the semantics in spe-cific applications [16, 23, 25], as well as domain experts. Taken together with domain knowledge and causality min-ing tools, these algorithms are one step towards large-scale critical alert analysis for data centers, intrusion detection systems, and network diagnosis systems.
We start with the notions of alert sequences and alert graphs. Then we introduce the critical alert mining problem. Performance metrics . A performance metric measures an aspect of system performance. For data centers, com-mon types of performance metrics include CPU and mem-ory usage for virtual machines, error rate of disk writes for a service, or communication time between two hosts. The same type of metrics over different hosts, virtual machines, or services are considered as distinct performance metrics.
In practice, system service providers e.g., LogicMonitor may cope with 2 million metrics from a data center with 5 , 000 hosts. These metrics could correlate with and cause each other due to functional or resource dependencies. Alert and alert sequences . For a set of performance metrics P , alerts are determined by aggregating the metric values of interest. For example, in data centers, an alert is raised when the value of a performance metric ( e.g., CPU usage) goes beyond a pre-defined threshold ( e.g., &gt; 75%). In this work, we define an alert as a triple u = ( p u , t where p u  X  P is a performance metric u corresponds to, t denotes the timestamp when the alert u happened, and w u is the weight of u , representing the benefit if u is fixed.
We use a sequence of alerts to characterize abnormal events for a specific performance metric. Indeed, in prac-tice the performance metrics are typically periodically mon-itored to capture the abnormal events as alerts. We denote as ~s p an alert series (an ordered sequence of alerts following their timestamps), for a specific performance metric p  X  P . Each entry of ~s p is either 0 (normal) or 1 (alert).
To characterize causal relations between two alerts, we next introduce a notion of dependency rule . We also in-troduce alert graph as an intuitive graph representation for multiple dependency rules.
 Dependency rule . Let p and q be two distinct perfor-mance metrics. A dependency rule p l pq  X  X  X  X  q denotes an alert issued on q at some time t is caused by an alert issued on p at t  X   X  [ t  X  l pq , t  X  1], where l pq is a lag from p to q ( e.g., 5 minutes). Note that we do not specify the time t , as a dependency rule describes a statistical rule for all the ob-served alerts. Intuitively, a dependency rule indicates that alerts on q occurs if and only if alerts on p occurs as the cause of the alerts on q ; that is, the alerts on p will trigger the alerts on q . If certain trouble shooting action is taken to fix p , q is addressed accordingly [2, 23].

Dependency rules can be automatically learned from alert series [3, 31]. They can also be suggested by experts and ex-isting knowledge bases [10]. To smoothen the noise or error brought by rule generation process, we associate an uncer-tainty to each dependency rule. In particular, we denote the uncertainty by Pr( p l pq  X  X  X  X  q ), which is the probability that the corresponding dependency rule holds.
 Alert graph . An alert graph over a set of alerts V is a directed acyclic graph G = ( V, E, f e ):
We shall use the following notations. Abusing the notions from tree topology, we say u (resp. v ) is a parent (resp. child) of v (resp. u ) if ( u, v )  X  E , and the edge ( u, v ) is an incoming edge of v . The topological order r of an alert u in G is defined as follows. (a) r ( u ) = 0 if u has no parent, and (b) r ( u ) = 1 + max r ( v ), for all its parents v .
Following the convention of causal relation and cascading models [29], we assume that an alert is caused by a single alert issued earlier, if any. Intuitively, a path from an alert u to another alert v in the alert graph indicates a potential  X  X ausal chain X  from u to v , indicated by e.g., the actual dependencies among the vulnerabilities of the servers [5]. C ritical alerts . We next introduce a metric to characterize critical alerts, in terms of how many alerts are potentially caused by them via a cascading effect (and hence are ad-dressed if the critical ones are fixed). Given G = ( V, E, f a set of fixed alerts S  X  V , and an alert u  X  V , we use a notion of alert-fixed probability P f to characterize the prob-ability that u is fixed if S is fixed. More specifically,
Based on the alert-fixed probability, we next define a set function, denoted as Gain , to characterize critical alerts. Given an alert graph G = ( V, E, f e ) and S  X  V , the gain of S is a set function
As remarked earlier, here w u refers to the weight of u , i.e., the benfit if u is fixed. Intuitively, Gain ( S ) computes the total expected benefits induced via fixing a set of alerts S and subsequently addressing the alerts caused by S . The larger Gain ( S ) is, the more  X  X ritical X  S is.
 We next introduce the critical alert mining problem.
Definition 1. Given an alert graph G and an integer k , the critical alert mining problem (referred to as CAM ) is to find a set of k critical alerts S  X  V such that Gain ( S ) is maximized.

Finding the best set of k alerts which maximize the gain is desirable albeit intractable.

Theorem 1. For a given alert graph G and an integer k , the problem CAM is NP-complete.

Proof. We prove the NP-completeness of the decision version of CAM as follows. (1) CAM is in NP. Indeed, given an alert graph G = ( V, E ) and a set of vertices S  X  V , one can evaluate Gain by computing P f ( S, v ) of each alert v in polynomial time. (2) To show that CAM is NP-hard, we construct a reduction from the maximum coverage problem, which is known to be np -hard [35]. An instance of a max-imum coverage problem consists of a set of sets S and an integer k . It selects at most k of these sets such that the number of elements that are covered is no less than a bound B . A maximum coverage instance can be constructed as a bipartite alert graph, with each  X  X pside X  node as a set in S , each  X  X ownside X  node a distinct element in these sets, and there is an edge from upside node to downside node if the corresponding element is in the set denoted by the upside node. In addition, the weights on edges are uniformly 1. Given the bound B , one may verify that there is a solution for the maximum converage problem if and only if there is a set S of k critical alerts with Gain ( S )  X  B . Therefore, CAM is at least as hard as maximum coverage problem, and is NP-hard. Hence, CAM is np -complete.
I n this section, we present a framework for critical alert mining. It consists of three components as illustrated in Figure 1: (1) offline dependency rule mining; (2) online alert graph maintenance; and (3) on-demand critical alert mining. Offline dependency rule mining . Given a set of ob-served alert sequences, the system mines the alerts of inter-est and their causal relations offline, and represent them as a set of dependency rules. As there are a variety of methods to model a causal relation, in this work we adopt Granger causality [3, 31], which can naturally be represented by de-pendency rules. An alert sequence X is said to Granger-cause another sequence Y if it can be shown, via certain statistic tests on lagged values of X and Y , that the values of X provide statistically significant information to predicate the future values of Y . More specifically, (1) We collect alert sequences for all performance metrics of interest as training data, following two criteria as follows: (a) the alerts in training data should be the latest ones such that the latest dependency patterns among performance metrics can be captured; and (b) the alert information should be rich enough such that learned dependency rules would be more robust. In our work, we treat the latest one week alert data as the training data. (2) We apply existing Granger causality analysis tools [31] to mine the dependency rules, and apply conditional prob-abilities to estimate the uncertainty of the rules [20].
The learned dependency rules are stored in knowledge bases to support online alert graph maintenance. More-over, existing knowledge bases such as event causality sce-narios [10], or vulnerabilities exploitation among cyber as-sets [5] can also be  X  X lugged X  into our critical causal mining framework. The dependency rules are then shipped to the next stage in the system to maintain alert graphs. Online alert graph maintenance . Using dependency rules, our system constructs and maintains an alert graph G online from a range of newly issued alerts. Upon an alert u from performance metric q is detected at time t , it first marks u a s a new alert in G . It then checks (1) if there exists dependency rules in the form of p l pq  X  X  X  X  q , and (2) whether there are alerts detected on performance metric p during the time period [ t  X  l pq , t ). If there exists such an alert v on p , an directed edge from v to u is inserted, and the rule uncertainty Pr( p l pq  X  X  X  X  q ) is associated to the edge ( v, u ). Following the above steps, it maintains G online for newly detected alerts.
 On-demand critical alert mining . The major task (and the focus of this work) in the pipeline is to identify k critical alerts from alert graphs. In practice, a user may specify a time window of interest, which induces an alert graph from the maintained alert graph. It contains all the alerts de-tected during the time window. However, the induced alert graphs can still be huge.

In this paper, we propose three algorithms to address the scalability issue: (1) a quadratic time approximation with performance guarantees on the quality of critical alerts, (2) a linear time approximation, which guarantees the alert qual-ity for tree-structured alert graphs; and (3) sampling-based heuristics which can be tuned to balance the alert quality and response time. The critical alerts are then returned to users for further analysis and verification.
Theorem 1 tells us that it is unlikely to find a polynomial time algorithm to find the best k alerts with the maximum gain. All is not lost: we can find polynomial time algorithms that approximately identify the most critical alerts. The main result in this section is as follows.

Theorem 2. Given an alert graph G = ( V, E, f e ) and an integer k , (1) there exists an algorithm in O ( k | V || E | ) time with approximation ratio 1  X  1 e , where e is the base of nat-ural logarithm, and (2) there exists a 1  X  1 e a pproximation algorithm in O ( k | V | ) time, when G is a tree. Here e refers to Euler X  X  number (approximately 2.71828). Denote the optimal k alerts as S  X  , we present an effi-cient algorithm to identify k alerts S where Gain ( S )  X  (1  X  1 e ) G ain ( S  X  ), in quadratic time.
 We start with a greedy algorithm, denoted as Naive . Naive greedy algorithm . Given an alert graph G = ( V, E, f e ) and an integer k , Naive finds k critical alerts in k iterations as follows. (1) It initializes a set S 0 to store the selected alerts. (2) At the i th iteration, Naive checks each alert in V , and greedily picks the alert s i that maximizes the incremental gain Gain ( S i  X  1  X  { s i } ), where S i  X  1 set of critical alerts found at iteration i  X  1. (3) It repeats the above step until k alerts are identified.

One may verify that Naive is a 1  X  1 e a pproximation algo-rithm. To see this, observe that the set function Gain (  X  ) is a monotonically submodular function . A function f ( S ) over a set S is called submodular if for any subset S 1  X  S 2  X  S and x  X  S \ S 2 , f ( S 1  X  { x } ) -f ( S 1 )  X  f ( S 2  X  { x } ) -f ( S known that for maximizing a submodular function, a greedy strategy achieves 1  X  1 e a pproximation ratio [27]. Hence it suffices to show that the function Gain is a monotonically submodular function. Indeed, (1) one may verify that Gain is monotonic: for any S 1  X  S 2  X  V , Gain ( S 1 )  X  Gain ( S (2) the diminishing return of Gain can be shown by mathe-matical reduction. We provide the detailed proof in [1].
For complexity, Naive requires k iterations, and in each it-eration, it scans all the vertices u and computes P f ( S which takes in total O ( k | V || E | ) time.

Naive provides a polynomial time algorithm to approxi-mate CAM within 1  X  1 e . Nevertheless, the scalability issue of Naive makes it difficult to use in practice for large alert graphs. For instance, when an alert graph of around 20 K vertices and 200 K edges, Naive mines 6 critical alerts in more than 800 seconds. We next present a faster approx-imation algorithm with the same approximation ratio. By using pruning and verification, the algorithm is 30 times faster than Naive , as verified in our experimental study.
To select a most promising alert at each iteration, Naive evaluates the incremental gain for each alert in V \ S , and then selects the one of the highest incremental gain, which runs in O ( | V || E | ) time. Instead of blindly processing every alert, we may efficiently filter X  X npromising X  X lerts, and then evaluate the exact gain for the remaining vertices. In partic-ular, at each iteration i , for two alerts v  X  and v  X  V \ S we compute upper bounds U  X  v , U v and lower bounds L  X  v v is already not a critical alert, all the alerts v with L  X  can be safely skipped without losing the alert quality.
We next derive an upper and lower bound for Gain (  X  ), and present algorithms to compute them efficiently. Instead of visiting each alert and causal relation in G , these algorithms compute the bounds by visiting only local information of each alert in G . This enables a fast estimation of Gain (  X  ).
We introduce a notion of sum gain (denoted as SGain ) to characterize the upper bound for Gain (  X  ). Given an alert graph G = ( V, E, f e ), an alert v  X  V , and a set of se-lected critical alerts S  X  V , an upper bound is computed as SGain ( S  X  { v } ) = P u  X  V w u  X   X  P f ( S  X  { v } , u ), where
The sum gain SGain (as illustrated in Fig. 2) is an upper bound for Gain (  X  ). Better still, it can be efficiently computed.
Proposition 1. Given an alert graph G = ( V, E, f e ) , a set of critical alert S  X  V , and an alert u  X  V \ S , (1) Gain ( S  X  { u } )  X  SGain ( S  X  { u } ) ; and (2) SGain can be com-puted for all alerts in V in O ( | E | ) time.

We first prove Proposition 1 (1). We remark that SGain is built upon the following generalization of Bernoulli X  X  in-equality [24]. Given x i  X  1, we have
We next conduct a mathematical induction over the topo-logical order (Section 2) of the alerts in G as follows.
Figure 2: Algorithm B nP : Upper and lower bound Therefore, for any u  X  V , P f ( S, u )  X   X  P f ( S, u ). By defini-tion, Gain ( S  X  X  u } )  X  SGain ( S  X  X  u } ). Hence, SGain is indeed an upper bound for Gain (  X  ).
 Upper bound computation . As a constructive proof for Proposition 1 (2), we present a procedure (denoted as computeUpperBound ) for SGain to compute the upper bounds for all vertices in O ( | E | ) time.

The algorithm (not shown) follows a  X  X ottom up X  compu-tation, starting from the alerts with the highest topological order in G . (1) It first computes the topological order for all the alerts in G . (2) Starting from the alert with the highest topological order, it computes SGain for each alert u  X  V \ S as follows: (a) SGain ( S  X  { u } ) = SGain ( S  X  { u } ) + w (b) for each u  X   X  N i ( u ), it updates SGain ( S  X  { u  X  step (2) until all the alerts are processed.

It takes O ( | E | ) time for computeUpperBound to obtain the topological order by depth-first search in step (1). Each edge in G is visited exactly once in step (2) and (3). Therefore, the algorithm runs in O ( | E | ) time.

The above analysis completes the proof of Proposition 1.
To compute the lower bound of Gain (  X  ), we introduce a notion local gain (denoted as LGain ). Given an alert graph G = ( V, E ), an alert v  X  V , a set of selected alerts S  X  V , and an integer h , LGain of S  X  { v } is defined as follows. where h is a tunable integer, and V h v  X  V is a set of ver-tices that can be reached from v in no more than h hops. Intuitively, LGain estimates a lower bound of Gain ( S ) with the impact of an alert to its local  X  X earby X  alerts in G (as illustrated in Fig.2). One may verify the following.
Proposition 2. Given G = ( V, E ) , S  X  V , for any alert u  X  V \ S , (1) Gain ( S  X  { v } )  X  LGain ( S  X  { v } ) , and (2) LGain can be computed in O ( P v  X  V | E h v | ) time, where E h the set of incoming edges in G of the alerts in V h v . We present a procedure computeLowerBound to compute LGain . For each alert v  X  V \ S ( e.g., u 3 in Fig 2), the algo-rithm visits the alerts in V h v and their incoming edges ( e.g., ( u 3 , u 3 )) once, and computes LGain following the definition, in O ( P v  X  V | E h v | ) time.
Based on the upper and lower bounds, we propose an ap-proximation, denoted as BnP . BnP enables faster critical alert mining while achieving the approximation ratio 1  X  1 T he algorithm follows Naive  X  X  greedy strategy: given an in-teger k , it conducts k iterations of search, each determines a top critical alert. The difference is that in each iteration, it invokes a procedure Prune to identify a set C of candidate alerts for consideration.

The procedure Prune (as illustrated in Fig. 3) invokes computeUpperBounds and computeLowerBounds to dynam-ically update the lower and upper bounds for each alert by accessing their local information (lines 1-2), and filters the alerts that are not critical: 1. it scans the lower bounds LGain of each alert, and find 2. it scans the upper bounds SGain of each alert, and Correctness and Complexity . The algorithm BnP achieves approximation ratio 1  X  1 e , as it follows the same greedy strategy as Naive . Note that the pruning procedure Prune does not affect the approximation ratio.

For complexity, let C m be the maximum set of candidate sets in all the iterations after pruning. For the alerts in C it takes BnP O ( | C m || E | ) time to find a best alert. The total time for pruning is O ( k ( P u  X  V | E h u | + | E | )). Hence, it takes BnP in total O ( k ( P u  X  V | E h u | + | C m || E | )) time. Moreover, u | is typically small, and is tunable by varying h , as in-dicated by Proposition 2. For example, when h = 1, LGain can be computed in O ( d m | E | ) for all the alerts, where d the largest in-degree in G . As h gets larger, the computa-tion complexity gets higher, leading to tighter lower bound LGain . In our experimental study, by setting h = 3, 95% of the alerts are pruned, which makes BnP 30 times faster than Naive without losing alert quality.
 Mining Alert Trees . When G is a directed tree, the algo-rithm BnP identifies k critical alerts in O ( k | V | ) as follows. (1) Starting from the alerts u  X  V o f the highest topological order, it computes Gain ( u ) = Gain ( u ) + w u , and makes an update by Gain ( u  X  ) = Gain ( u  X  )+ f e ( u  X  , u ) Gain ( u ), if u parent of u . (2) It repeats (1) on the alerts following the de-creasing topological order, until all the alerts are processed. One iteration over (1) and (2) identifies a critical alert. (3) BnP repeats (1) and (2) to find k critical alerts.
Following the correctness analysis, BnP preserves the ap-proximation ratio 1  X  1 e o ver trees. Moreover, each edge in G is visited once in a single iteration. Hence, it takes O ( k | V | ) time of BnP over G as trees. Theorem 2 (2) hence follows.
Algorithm BnP needs to process all the candidates and their causal relations, which may not be efficient for a large amount of alert sequences. In extreme cases where few alerts are pruned, BnP degrades to its naive greedy counterpart.
As indicated by Theorem 2(2), fast approximation exists for alert graphs as trees. Following this intuition, we may make large alert graphs  X  X mall X , by sparsifying them into directed trees, which  X  X reserve X  most of alert dependency information in an alert graph. This enables both fast algo-rithms and low quality loss.
We start by introducing a heuristic algorithm ST . The basic idea is to induce a maximum directed tree (forest) T from a given alert graph G , such that for any set of alerts S in G , Gain ( S ) in T is  X  X lose X  as much as possible to Gain ( S ) in G , and a fast approximation can be performed over T without much quality loss.
 Maximum directed tree . Given an alert graph G = ( V, E, f e ), a maximum directed tree of G is a spanning tree T = ( V, E  X  ), where E  X   X  E , such that (1) for any u  X  V , u has at most one incoming edge, and (2) P h u,v i X  E  X  f e is maximized. Intuitively, T depicts a  X  X keleton X  of an alert graph G , where causal relations always follow the most likely dependency rules.
 Algorithm ST . Given an alert graph G = ( V, E, f e ), the single-tree approximation ST mines k critical alerts as fol-lows. (1) ST first finds the maximum directed tree T . To construct T , an algorithm simply selects, for each alert u in G , the incoming edge ( u  X  , u ) with the maximum f e among all its incoming edges. (2) ST searches the k critical alerts following the algorithm BnP over T .
 One may verify that it is in O ( | E | ) time to construct T . From Theorem 2(2), it is in O ( k | V | ) time to find k critical alerts in T (as either a tree or a forest). Hence, the algo-rithm ST takes in total O ( | E | + k | V | ) time. Note that the induced T can be a set of disjoint trees, where the above complexity still holds.
Single-tree approximation provides fast mining method for large scale alerts. On the other hand, using induced trees to approximate causal structures may lead to biased results. For example, more dependency information could be lost for alerts with more incoming edges. To rectify this, we propose a heuristic, denoted as MTS , based on multi-tree sampling. Algorithm MTS . The algorithm MTS is as illustrated in Fig. 4. Given an alert graph G = ( V, E, f e ), integer k and a sample number N , MTS starts by initializing a set S 0 as  X  , the alert-fixed probability for each node as 0 (line 1), and identify the topological orders of the alerts in G .
Algorithm MTS then finds a set S critical alerts in k itera-tions as follows. Denote the selected critical set at iteration i  X  1 as S i  X  1 . At each iteration i , (1) MTS updates the alert-fixed probability P ( i  X  1) f ( S i  X  1 , u ) for each alert u  X  V in G , fixing S i  X  1 as the critical alerts (lines 3-4). (2) It then invokes procedure sampleTree to sample N trees from G (lines 6-7), according to the updated alert-fixed probabil-ity in (1). (3) For each alert u , MTS computes the weighted sum of u  X  X  descendants D ( u, l ) in each sampled tree T and takes the average D ( u, l ) over all sampled tress as an estimation of Gain ( S i  X  1  X  X  u } ) (lines 8-9). It selects the alert u that introduces the maximum improvement, and update S i  X  1 as S i by adding u (lines 10-11), which is used to update P (  X  ) in G in the next iteration.
 Procedure sampleTree . Given an alert graph G and an integer N , the procedure sampleTree (line 7) samples N trees (forest) from G at iteration i . More specifically, it generates a single tree (or forest) T i,l as follows. (1) It first samples a set of alerts V i,l as the nodes for tree T following Bernoulli distributions. For each alert u  X  V and the updated P ( i  X  1) f ( u ), MTS selects u with probability 1  X  P ( i  X  1) f ( u ), and inserts it to V i,l . (2) MTS then samples an edge for each alert u  X  V i,l . It randomly orders u  X  X  parents. Starting from the first parent, u tries to build an edge ( u to its parent with probability f e ( u  X  , u ), where u  X  all the parents of u , until an edge is selected (and attached to u ), or all the parents are visited. (3) MTS repeats (2) until all the alerts u  X  V i,l are visited.

It takes in total O ( k  X  N | E | ) time for MTS to find k critical alerts. (a) MTS takes in total O ( k | E | ) time to update P G ; (b) the total sampling time is in O ( k  X  N | E | ); and (c) it takes in total O ( k  X  N | V | ) time to select the critical alerts.
In contrast to its single-tree counterpart, MTS leverages sampling to reduce the bias: alerts with more parents and larger probability are more likely to have a parent in a sam-pled tree. In addition, it synthesizes the gain estimation from multiple trees, such that the noise from a single tree is smoothed. Indeed, we found that using only 300 samples, MTS finds top 6 critical alerts with Gain (  X  ) 90% as good as Naive , and is 80 times faster. It reduces 10% more loss on Gain (  X  ) compared with ST (see Section 6).
W e applied both real-life and synthetic data to evaluate our algorithms. We first provide a case study (Section 6.2). Using real-life data, we next investigate (1) the efficiency and effectiveness of our algorithms (Section 6.3), (2) the impact of the number of explored hops to the performance of BnP (Section 6.4), and (3) how the number of samples affects MTS (Section 6.5). In addition, we evaluate the scalability of our algorithms, over large synthetic data (Section 6.6). Real-life data . We use real-life data center performance data (referred to as LM ), from LogicMonitor, an SaaS net-work monitoring company. The data spans 53 days from Nov. 23, 2013 to Jan. 14, 2014. It contains the sequences for 50,772 performance metrics from 9,956 services residing in 122 servers. Each metric is reported every 2 minutes. The alerts are identified by specified rules provided by Log-icMonitor, where we assign a weight 1 . 0 to all the metrics. Dependency rules and alert graphs . Dependency rules were mined from data collected in 7 consecutive days, and are used to construct alert graphs using the data from the following days. We used the tool developed by [31] to mine the Granger causality among performance metrics as depen-dency rules (with the p-value set to be 0.01 [31]). We then applied conditional probability to estimate the uncertainty of the rules [20]. From the dataset LM , we mined 46 sets of dependency rules, where each set contains on average 2 , 082 rules. Each set of rules were mined in less than 60 minutes.
By applying the sets of dependency rules on the alert de-tected in the next single day, we obtained 46 alert graphs, following the online alert graph construction (Section 3). The number of alerts (resp. edges) ranges from 20 , 248 to 25 , 057 (resp. 162 , 000 to 270 , 370) for a single graph. Synthetic alert graphs . For scalability tests over large alert graphs, we applied the graph model proposed in [18] to generate large synthetic alert graphs (referred to as SYN ). In particular, the node degree and edge weights follow the empirical distributions [34] learned from alert graphs over the real-life data LM . We ranged the number of alerts from 100K to 1M, and the average degree of SYN graphs is 9. Evaluation . To measure the quality of the critical alerts identified by an algorithm A , we investigate a metric loss ratio of A defined as where S Naive (resp. S A ) is the set of critical vertices returned by the algorithm Naive (resp. algorithm A ). As Naive guar-antees the alert quality within a bound, loss ratio suggests how X  X lose X  X he quality of the alerts from heuristic algorithms and the optimal ones is. The less, the better.
 Implementation . In addition to the proposed algorithms BnP , ST , and MTS , we implemented the following base-line algorithms: (1) Naive , the greedy algorithms without pruning strategy; (2) BnP UB , a simplified version of BnP , which only uses upper bound to filter unpromising alerts: it skips those alerts with upper bound smaller than an alert with computed Gain (  X  ) in each iteration (Section 4). (3) MaxDeg , a simple strategy that returns the top k alerts with the largest weighted sum of outgoing edges.

All the algorithms were implemented in C++, and all ex-periments were executed on a machine powered by an In-tel Core i7-2620M 2.7GHz CPU and 8GB of RAM, using Ubuntu 12.10 with GCC 4.7.2. Each experiment was run 10 times, and their average results are presented.
Using real-world data LM , our algorithms suggest reason-able critical alerts that are indeed the source of a range of large amount of alerts, as verified by the domain experts from LogicMonitor. We illustrate three  X  X ausality patterns X  induced by top two critical alerts and their descendants fol-lowing the weighted dependency rules in Fig. 5. (1) Our algorithms suggest that StorageUsed , a critical alert that in-dicates insufficient memory, leads to poor performance of Web servers (Apache), which typically triggers delayed Ping round-trip time (Ping-avgrtt) from other servers. In another set of hosts, it leads to insufficient shared memory over a range of servers, which typically triggers slower Shared Data Access write time (SDA writetime) on their own. (2) A sec-ond critical alert DiskReadLatency suggests I/O bottleneck for a range of abnormal status of database applications. The disk access speed alert often triggers the unsolved back up requests from another server, which leads to poor perfor-mance of CPU and database servers, and further affects a range of database related requests from more outside servers. These causal patterns are consistent with the workflow of data centers at LogicMonitor.
 Our algorithms do not assume prior domain knowledge. On the other hand, external knowledge and rules enable our algorithms to further improve the quality of the criti-cal alerts and causal patterns.
We first investigate the efficiency and effectiveness of the proposed algorithms, using alert graphs from LM . In the following tests, we fixed the number of explored hops in BnP as 3, and the number of sampled trees in MTS as 300. As illustrated in Figure 6(a), the proposed algorithms BnP , MTS , and ST consistently outperform the baseline al-gorithms Naive and BnP UB in efficiency, while varying k , the number of required critical alerts. They introduce differ-ent levels of efficiency improvement. Compared with Naive and BnP UB , BnP is 30 times and 17 times faster, respec-tively, without quality loss on solutions. With some quality loss, ST is 5000 times and 3000 times faster than Naive and BnP UB , respectively, and MTS results in 80 times and 50 times speedup. In addition, all the algorithms take more time when k varies from 1 to 6, as expected.

Figure 6(b) shows the loss ratio of ST and MTS , where k varies from 1 to 6. Compared with MaxDeg , MTS and ST
F igure 6: Mining performance on LM alert graphs obtain significant improvement on loss ratio. As k increases, the loss ratio of MaxDeg is consistently more than 0 . 4; mean-while, the loss ratio of MTS and ST is around 0 . 1 and 0 . 2, respectively. Compared with MTS , ST receives higher effi-ciency at the cost of solution quality loss. When the number of required critical alerts varies from 1 to 6, MTS and ST share the same trend: the loss ratio decreases. Compared with BnP that returns critical alerts without quality loss, ST and MTS are 180 and 3 times faster, respectively, at the cost of small quality loss.

In all cases, we observe that the total Gain (  X  ) increases with larger k with diminish return (not shown). This is consistent with its submodularity.
In this set of experiments, we focus on the impact of the number of hops h (for lower bound computation) to the performance of BnP . We fixed k as 1. Besides running time, we investigate the pruning ratio of BnP , defined as | V | X  X  C | w here | V | is the total alert number in an alert graph G , and | C | is the average size of the candidate set C (Section 4) after pruning, for all the k iterations.

Figure 7(a) and Figure 7(b) illustrate how the computa-tion time of different components in BnP varies, and how the pruning ratio varies, respectively, while the number of explored hops h varies from 1 to 5. The result tells us the fol-lowing. (1) When h increases from 1 to 3, the response time of BnP drops. Indeed, as observed from Figure 7(b), the efficiency improvement comes from the increasing number of pruned alerts. With more alerts pruned, the amount of time taken on Gain evaluation, which is the dominating cost, drops accordingly. (2) When the number of hops increases from 3 to 5, the response time of BnP increases. As the num-ber of hops grows from 3 to 5, we can see that the pruning ratio of BnP marginally is improved from Figure 7(b); how-ever, the amount of computation time for lower bound in F igure 7: BnP performance on LM alert graphs BnP dramatically increases, which becomes the dominating computation cost. According to our result, when the num-ber of explored hops is set to be 3, BnP achieves the best performance on LM alert graphs.

In addition, as shown in Figure 7(b), BnP consistently outperforms BnP UB in terms of pruning ratio, since the upper and lower bounds in BnP introduce more powerful pruning to reduce unnecessary computation.
In this set of experiments, we demonstrate how the num-ber of sampled trees affect the performance of MTS .
Figure 8(a) tells us the following. (1) While the number of required critical alerts is fixed, the response time of MTS is proportional to the number of sampled trees (varies from 5 to 500). (2) When the number of samples is fixed, the response time of MTS grows linear to the number of required critical alerts. In all cases, MTS takes no more than 15 seconds.
Figure 8(b) illustrates how the number of sampled trees influences the effectiveness of MTS . When the number of sampled trees increases, the loss ratio of MTS decreases, while the reduction of loss ratio diminishes. As the number of sampled trees changes from 5 to 100, the loss ratio of MTS is significantly improved; meanwhile, as the number of sampled trees changes from 100 to 500, the loss ratio is marginally improved. In addition, fixing the number of sampled trees, when the number of required critical alerts is increased, the loss ratio of all MTS variants decreases.
On SYN alert graphs, we fixed the number of required critical alerts to be 3, and evaluate the scalability of BnP , MTS , ST , Naive , and BnP UB . Note that the number of hops explored in BnP is fixed to be 3, and the number of sampled trees in MTS is fixed to be 300.
Figure 8: MTS performance on LM alert graphs
Figure 9 reports the scalability results. When the number of alerts in SYN graphs increases from 100K to 1000K, the response time of MTS and ST linearly grows. In particular, when a SYN graph has 1M alerts and more than 90M edges, MTS and ST return 3 critical alerts in 4 minutes and 13 seconds, respectively. On the other hand, Naive , BnP UB , and BnP cannot finish the computation in an hour, even for alert graphs with 100 K alerts (hence are not shown). Indeed, the efficiency of BnP relies on the amount of alerts it can prune. In the worst case, it works as slow as Naive . In contrast, MTS and ST are much less sensitive to the growth of graph size, and are more promising for large alert graphs.
We found the following. (1) With pruning strategy, BnP outperforms baseline algorithms in terms of efficiency up to 30 times, without loss of solution quality. (2) While MTS is up to 80 times faster than baseline algorithms, the resulting loss ratio is around 0 . 1. (3) ST is up to 5000 times faster than baseline algorithms, with loss ratio around 0 . 2. Causality models and analysis . Causal relations among time series data have been modeled with Granger causal-ity [33], lagged correlation [23], Bayesian networks [29, 26], among others. Granger causality measures a cause in terms of whether it passes Granger Test, i.e., whether it helps in predicating the future events, beyond what can be predicted by using only the historical events. Lagged correlation char-acterizes causal relations with the correlation between two time series shifted in time relative to one another. Causal Bayesian networks interprets causal relations with graphical models, in which the predecessors of a node are interpreted as directly causing the variable associated with that node.
A variety of causality mining techniques have been stud-ied [3, 31, 32], varied with causality models. Silverstein et al. [32] proposed algorithms to mine causal relations in large databases by estimating the conditional probability of rules of interest. For Granger causality, Arnold et al. [3] applied Lasso Granger method to find a set of events that are con-ditionally dependent with regression, without exhaustively performing pairwise Granger Test. A toolbox for detecting Granger causality is developed [31]. These methods stop at identifying causal relations. Our work, on the contrary, effi-ciently identifies the most critical alerts rather than suggest-ing all possible causal relationships. On the other hand, effi-cient causality mining techniques, as well as existing knowl-edge bases on event causality scenarios [10] serve as prepro-cessing in our critical causal mining framework.
 Root cause analysis . We are aware of a range of domain-specific studies that aims to find the  X  X oot causes X . Given a set of observed symptom events, the problem is to identify the set of root causes that can best explain the symptom. In intrusion detection, Julisch [16] leveraged alert cluster-ing techniques to indicate root causes for system alarms. A hierarchical clustering process is iteratively performed over groups of similar alarms, until the top causes are identified. In network performance diagnosis, Mahimkar et al. [23] pro-posed methods to identify potential root causes as the events that have statistically significant (lagged) correlations with a set of known symptom events. In contrast, we propose a general computational framework for efficient root cause analysis over large-scale alert sequences in networks. While we do not have the luxury to assume the access of rich domain-specific semantics that benefit event filtering, any such knowledge serves as preprocessing to reduce the input size of our problem.
 Influence maximization . Node influence evaluation aims to select a group of nodes with maximized influence, under various information diffusion models, such as independent cascade model [21], linear threshold model [19], competing model [4, 15], continuous-time model [11, 30], and credit distribution model [13]. The problem is, however, highly intractable (#P-hard). Sampling methods such as Monte Carlo simulations are usually applied to estimate node in-fluence. Nonetheless, these approaches typically take mas-sive amount of computation time and are hard to scale over large graphs [22]. To improve the scalability, various prun-ing algorithms have been proposed to reduce the number of Monte Carlo simulations [9, 11, 14, 36], and heuristic algo-rithms have been studied to estimate node influence [6, 7, 8, 28]. In contrast to these works, we identify efficient algo-rithms for critical alert mining, with desirable performanc e guarantees on alert quality and efficiency. Striking a balance between mining quality and efficiency, these algorithms sug-gest scalable mining for large scale alert analysis.
We have studied the critical alert mining problem. De-spite its intractability, we developed approximation algo-rithms with quality guarantees, as well as fast heuristics that preserve at least 80% of solution quality, and perform up to 5 , 000 times faster than their approximation counterparts.
This work is a first step towards large-scale critical alerts mining. We are conducting experiments over various large real-life datasets and causality models. One topic is to ex-tend our techniques for distributed network monitoring sys-tems and data centers. Another topic is to dynamically maintain the alert graphs and mined critical alerts. In ad-dition, to further improve the alert quality, one wants to combine the mining framework with external semantics and knowledge bases, and to automatically interpret the critical alerts for various application domains.
 We thank Dr. Douglas Kelly at Army Research Lab for valuable comments. This research was sponsored in part by the Army Research Laboratory under cooperative agree-ments W911NF-09-2-0053, NSF IIS-0954125, and NSF IIS-1219254. The views and conclusions contained herein are those of the authors and should not be interpreted as rep-resenting the official policies, either expressed or implied, of the Army Research Laboratory or the U.S. Government. The U.S. Government is authorized to reproduce and dis-tribute reprints for Government purposes notwithstanding any copyright notice herein.
