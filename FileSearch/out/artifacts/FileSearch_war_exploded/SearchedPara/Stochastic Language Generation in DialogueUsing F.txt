 University of Cambridge University of Cambridge
Most previous work on trainable language genera tion has focused on two paradigms: (a) using a generation decisions of an existing generator. Both approaches rely on the existence of a hand-the language generation task as a search for the most likely sequence of semantic concepts and realization phrases, according to Factored Language Models (FLMs). As domain utterances are to produce the data necessary to represent human linguistic variation for nontrivial domains. collecting data from a large sample of untrained annotators using crowdsourcing X  X ather than a few domain experts X  X y relying on a coarse meaning representation. A second contribution of this article is to use crowdsourced data to sh ow how dialogue naturalness can be improved driven methods for generating paraphrases in dialogue are presented: (a) by sampling from the n-best list of realizations produced by B AGEL  X  X  FLM reranker; and (b) by learning a structured perceptron predicting whether candidate realizations are valid paraphrases. We train B a set of 1,956 utterances produced by 137 annotators, which covers 10 types of dialogue acts and 128 semantic concepts in a tourist informati on system for Cambridge. An automated eval-uation shows that B AGEL outperforms utterance class LM baselines on this domain. A human evaluation of 600 resynthesized dialogue extracts shows that B terances comparable to a handcrafted baseline, whereas the perceptron classifier performs worse.
Interestingly, human judges find the system sampling from the n-best list to be more natural than a system always returning the first-best utterance. The judges are also more willing to interact with the n-best system in the future. These results suggest that capturing the large variation found in human language using data-driven methods is beneficial for dialogue interaction. 1. Introduction
The field of natural language generation (NLG) was one of the last areas of compu-tational linguistics to embrace statistical methods, perhaps because of the difficulty of collecting semantically annotated corpora . Over the past decade, statistical NLG has followed two lines of research. The first , pioneered by Lan gkilde and Kn ight (1998), didate outputs of a handcrafted generator. Their HAL language model trained on news articles. HAL OGEN is thus domain-independent, and it was successfully ported to a specific dialogue system domain (Chambers and Allen 2004). However, its performance depends largely on the granularity of the underlying meaning representation, whic h typically includes syntactic and lexical information. A major issue with data-driven NLG systems is that collecting fine-grained semantic an-notations requires a large amount of time and expertise. For most domains, handcrafting templates remains a more cost-effective solution.
 chical syntactic language models (Bangalore and Rambow 2000), discriminative models trained to replicate user ratings of utterance quality (Walker, Rambow, and Rogati 2002), or language models trained on speaker-spe cific corpora to model linguistic alignment (Isard, Brockmann, and Oberlander 2006). However, a major drawback of the utterance-level overgenerate and rank approach is its inherent computational cost. In contrast, this article proposes a method in which loc al overgeneration can be made tractable through beam pruning.
 decision level by training models that find th e set of generation parameters maximizing an objective function, for example, producing a target linguistic style (Paiva and Evans 2005; Mairesse and Walker 2008), generating the most likely context-free derivations given a corpus (Belz 2008), or maximizing the expected reward using reinforcement learning (Rieser and Lemon 2010). Although such methods do not suffer from the com-putational cost of an overgeneration phase, they still require a handcrafted generator to define the generation decision space within which statistics can be used to find an optimal solution. Recently, research has therefore focused on reducing the amount of handcrafting required by learning to infer generation rules from data (see Section 2). ances aligned with coarse-grained semantic concepts. B AGEL utterances within a large dialogue system domain while minimizing the overall de-velopment effort. Because repetitions are common in human X  X omputer interactions X  especially when facing misunderstandings X  a secondary objective of this article is to improve dialogue naturalne ss by learning to generate paraphrases from data. Although domain experts can be used to annotate data, domain utterances are not readily avail-able for most NLG tasks, hence a creative process is required for generating these utterances as well as matching semantics. The difficulty of this process is increased for systems aiming at producing a large amount of linguistic variation, because it requires enumerating a large set of paraphrases for each domain input. This article is based on the assumption that learning to produce paraphrases can be facilitated by collect-ing data from a large sample of annotators. However, this requires that the meaning representation should (a) be simple enough to be understood by untrained annotators, and (b) provide useful generalization propert ies for generating unseen inputs. Section 3 describes B AGEL  X  X  meaning representation, which sat isfies both requirements. Section 4 then details how our meaning representation is mapped to a phrase sequence, using 764 cascaded Factored Language Models with back-off smoothing. Section 5 presents two methods for using B AGEL  X  X  probabilistic output for paraphrase generation in dialogue. information domain were collected using cro wdsourcing. Section 7 then evaluates the trained models in a dialogue setting, by showing that (a) B to a handcrafted rule-based generator; and (b) human judges prefer systems sampling from the n -best output over systems always select ing the top ranked utterance. Finally,
Section 8 discusses the implication o f these results as well as future work. 2. Related Work
Although statistics have been widely used to tune NLG systems, most previous work on trainable NLG has relied on a pre-existing handcrafted generator (Langkilde and Knight 1998; Walker, Rambow, and Rogati 2002). Only recently has research started to develop
NLG models trained from scratch, without any handcrafting beyond the definition of the semantic annotations.
 phases: (a) sentence planning and (b) surface realization. The sentence planning phase maps input semantic symbols to an intermediary tree-like or template structure repre-senting the utterance; then the surface reali zation phase converts it into the final text. As developing a sentence planner capable of over generation typically requires a substantial amount of handcrafting (Walker, Rambow, and Rogati 2002; Stent, Prasad, and Walker 2004), Stent and Molina (2009) have proposed a method that learns sentence plan-ning rules from a corpus of utterances labele d with Rhetorical Structure Theory (RST) discourse relations (Mann and Thompson 1988). Although additional handcrafting is needed to map the sentence plan to a valid syntactic form by aggregating the syntactic structures of the relations arguments, we believe RST offers a promising framework for improving the expressiveness of statistical generators. Section 8 discusses how B expressiveness could be improved by including RST relations.
 order to remove the need for a handcrafted overgeneration phase (Oh and Rudnicky 2002; Ratnaparkhi 2002). Oh and Rudnicky X  X  (O&amp;R) approach trains a set of word-based n -gram LMs on human X  X uman dialogues, one for each utterance class in their corpus. An utterance class corresponds to the intent and zero or more slots in the input dialogue act. At generation time, the corresponding LM is used for overgenerating a set of candidate utterances, from which the final utterance is selected based on a set of reranking rules. Ratnaparkhi addresses som e limitations of the overgeneration phase by comparing systems casting the NLG task as (a) a search over a word sequence based on an n -gram probabilistic model, and (b) as a search over syntactic dependency trees based on models predicting words given its syntactic parent and sibling nodes (Ratnaparkhi 2002). O&amp;R X  X  method represents the first line of research on NLG that limits the amount of handcrafting to a small set of post-processing rules in order to facilitate the development of a dialogue system X  X  NLG component. Section 7.1 there-fore compares B AGEL  X  X  performance with O&amp;R X  X  utterance class LM approach, and discusses differences between the two techniques.
 and machine translation. The W ASP  X  1 generator combines a language model with an inverted synchronous context-free grammar parsing model, effectively casting the generation task as a translation problem f rom a meaning representation to natural language (Wong and Mooney 2007). W ASP  X  1 relies on G IZA derivations of the meaning representation (Och and Ney 2003). Although early exper-iments showed that G IZA ++ did not perform well on our data X  X ossibly because of the coarse granularity of our semantic representation X  X uture work should evaluate the generalization performance of synchronous c ontext-free grammars in a dialogue system domain. Lu, Ng, and Lee (2009) show that Tree Conditional Random Fields (CRFs) outperform W ASP  X  1 and their own inverted semantic parser, based on automated evaluation metrics, although their system remains to be evaluated by human judges (Lu, Ng, and Lee 2009). Similarly to the perceptron reranking approach presented here,
Tree CRFs learn a log linear model, estimatin g the conditional probability of semantic tree/phrase alignments given an input seman tic tree. Although this line of research is promising, the two data sets evaluated X  X  EO Q UERY and R number of utterances that only differ by the proper name used. For example, 17 out of the 880 instances of the G EO Q UERY data set match the template what is the capital of $STATE . Such instances are therefore likely to occur simultaneously in the training and test partitions. In contrast, in our evaluation such templates are mapped to the same meaning representation, and we enforce the condition that the generated meaning representation was not seen during training.
 tion task is cast as a sequence of generation d ecisions selecting either: (a) a database minimum , maximum ); and (c) a template realizing those fields (e.g., with a low around $MINIMUM ). They train a set of log-linear models predicting individual generation decisions given the previous ones, using domain-independent features capturing the lexical context as well as content selecti on. The templates are extracted from data aligned with the input records using expect ation maximization. This approach offers the benefit of allowing predictions to be made given generation decisions that are arbitrarily far in the past. However, long-range feature dependencies make a Viterbi search intractable, hence the authors use a greedy search, which produces state-of-the-art results on the R OBOCUP data set and two weather domains. More recently,
Kondadadi, Howald, and Schilder (2013) also decouple the NLG task as a template extraction and ranking problem, and show that an SVM reranker can produce outputs comparable to human-authored texts for weather reports and short biographies. training a forest of PCFGs expressing the relation between records, fields, and words. A Viterbi search is used to find the optimal derivations at generation time; however, the
PCFG weights are rescored using an averaged structured perceptron using both content selection and lexical features. The authors show that their approach outperforms Angeli,
Liang, &amp; Klein X  X  (2010) method on the air transport query domain (ATIS data set). This article evaluates the same averaged structured perceptron algorithm within the B framework (see Sections 5.2 and 7.2).

The surface realization task is an attractive research topic as it is not tied to a specific application domain. Factored language models have been used for surface realization within the OpenCCG framework (White, Rajkumar, and Martin 2007; Espinosa, White, and Mehay 2008). More generally, chart generators for different grammatical formalisms have been trained from syntactic treebanks (Nakanishi, Miyao, &amp; Tsujii 2005; Cahill and 766 van Genabith 2006; White, Rajkumar, and Martin 2007), as well as from semantically annotated treebanks (Varges and Mellish 2001). Because manual syntactic annotation is costly and syntactic parsers do not necessar ily perform well at labeling spoken language utterances, the present work focuses on the generation of surface forms directly from semantic concepts. Future work should inves tigate whether explicit syntactic modeling improves performance (e.g., by conditionin g the realization FLMs on part-of-speech information).
 mated tutoring dialogues (Pon-Barry et al. 2006), and suggested that users prefer di-alogue systems in which repetitions are signaled (e.g., as I said before ), even though that preference was not significant (Foster and White 2005). However, we do not know of any research applying statistical paraphrasing techniques to dialogue. Most research on paraphrasing has focused on unsupervised techniques for extracting paraphrases from a corpus of written text. Proposed techniques learn to identify phrase templates, which tend to have the same arguments in a monolingual corpus (Lin and Pantel 2001), or to detect variations between translations of the same text (Barzilay and McKeown 2001;
Bannard and Callison-Burch 2005). Although t hese methods could be used to enrich an existing generator, they do not model semantics; hence they cannot be applied directly to NLG. Statistical reranking models have been used for over a decade for language generation (Langkilde and Knight 1998); how ever, we do not know of any evaluation of their paraphrasing power. Whereas linguistic variation is typically ignored in NLG systems, a recent line of research has started investigating how to control a generator to convey a specific style X  X or example, to ge nerate language with a target linguistic genre (Paiva and Evans 2005), to convey a specific personality trait (Mairesse and Walker 2008, 2011), or to align with their conversational partner (Isard, Brockmann, and
Oberlander 2006). These system s use statistics for controlling the style of their output; however, they require an existing handcrafted generator, and they were not evaluated within a dialogue context. We believe that the techniques presented here can also be used for stylistic control by including stylistic elements in our stack-based semantic representation; however, we leave this to future work.
 optimizing NLG and speech synthesis can improve human perceptions of voice quality.
This was achieved by finding the candidate p araphrase yielding the lowest speech unit concatenation cost using weighted finite st ate transducers (Bulyko and Ostendorf 2002) or by using a discriminative reranker trained to predict human judgments of synthesis quality (Nakatsu and White 2006). Similarly, Stone et al. (2004) propose a method using dynamic programming for simultaneou sly optimizing NLG, speech synthesis, and gesture in animated characters. Although all three approaches learn the paraphrase selection step from data, they rely on handcrafted NLG for producing candidates.
Hence future work should investigate whether voice quality could also be improved by composing the n -best paraphrases generated by B AGEL with a prosodic reranker. 3. Phrase-Based Generation from Semantic Stacks B
AGEL uses a stack-based semantic representation to constrain the sequence of semantic concepts to be searched. This representation can be seen as a linearized semantic tree similar to the one previously used for natural language understanding in the Hidden
Vector State model (He and Young 2005). A stack representation provides useful gen-eralization properties, and it allows for effi cient sequential decoding using dynamic programming. In the context of dialogue systems, Figures 1 and 2 illustrate how the concepts (represented as boxes) and aligned with a phrase sequence, resulting in one stack/phrase pair per time frame. The root concept of the semantic tree (i.e., the bottom concept in each stack) expresses the overall communicative goal of the utterance and is referred to as a dialogue act type . For example, the inform indicates that the utterance provides information about an entity matching the user  X  X  constraints; the dialogue act type informall in Figure 2 indicates that all the entities matching some of the user  X  X  constraints also satisfy other constraints. In contrast, the reject dialogue act type indicates that the system cannot find an entity matching the specified constraints. See Table 4 in Section 6 for more example dialogue act types.
Non-root semantic concepts include attribut es of that entity under consideration (e.g., name , food ,and area at frame 1, 3, and 9 in Figure 1), values for those attributes (e.g., respectively, name ( Jinling ), food ( Chinese ), and well as special symbols for logical quantifiers (e.g., all 768 specifying that an attribute is irrelevant ( dontcare ). Punctuation symbols are modeled using the semantic concept punct , as in frame 7 in Figure 1.
 collection of mandatory semantic stacks S m derived from the input dialogue act. Manda-tory stacks are represented in bold in Figure 1, such as frame 9. While mandatory stacks must all be conveyed in the output realization, does not contain the optional filler stacks S i that can refer to (a) general attributes of the object under discussion (e.g., inform ( area ) in frame 8); (b) concepts that are not in the input at all, which are associated with the singleton stack to a dialogue act type such as  X  X s a X  in Figure 1, or clause aggregation operations such as  X  X nd X  ); or (c) punctuation symbols (e.g., inform ( punct quirements of an information presentation dialogue system; that is, a dialogue manager typically returns a tree-like structure of coars e-grained semantic concepts describing (a) the overall dialogue act type, (b) the constrai nts over entities stored in a domain-specific database, as well as (c) logical modifiers expressing relations between sets of domain entities, depending on the dialogue act type. A major advantage of our formalism com-pared with more fine-grained formalisms (e.g., lambda calculus) is that it can be easily understood by human annotators. We believe that this is a crucial point for collecting the range of utterances required for learning to generate natural paraphrases in large domains (see Section 6). Furthermore, Section 8 discusses how its expressiveness could be extended by including additi onal discourse structures.
 rather than external linguistic knowledge about what constitutes a unit of meaning; namely, contiguous words belonging to t he same semantic stack are modeled as an atomic observation unit or phrase . 2 In contrast with word-level language models, a major advantage of phrase-based generation models is that they can model long-range dependencies and domain-specific idiomatic phrases with fewer parameters. 4. FLM-Based Statistical NLG
In order to find the optimal stack and realization phrase sequences given an input dialogue act, we cast the generation task as a search over Factored Language Models (FLMs), which were introduced by Bilmes and Kirchhoff (2003). FLMs extend tradi-tional language models by allowing predicted variables to be conditioned on differ-ent utterance contexts, depe nding on whether they were sufficiently observed in the training data. This approach is equivalent to a dynamic Bayesian network in which the probability of child nodes are estimate d by interpolating over different parent nodes. Dynamic Bayesian networks have been used successfully for speech recognition, natural language understanding, dialogue management, and text-to-speech synthesis (Rabiner 1989; Tokuda et al. 2000; He and Young 2005; Lef` evre 2006; Thomson and
Young 2010). Such models provide a principled framework for predicting elements in a large structured space, such as required for non-trivial NLG tasks. Additionally, their probabilistic nature makes them suitable for modeling linguistic variation X  X hat is, there can be multiple valid paraphrases for a given input. 4.1 NLG as a Viterbi-Search Pipeline B
AGEL models the generation task as finding the most likely sequence of realization phrases R  X  = ( r 1 ... r L ) given an input dialogue act. Each dialogue act is represented as a set of mandatory semantic stacks S m (unordered), with | S derive the optimal sequence of semantic stacks S  X  that will appear in the utterance given S m , that is, by inserting filler stacks if needed and by performing content ordering. Let us define the set of mandatory stack orderings as Order ( stacks can be inserted between two consecutive mandatory stacks, as long as all their concepts are included in either the previous or following mandatory stack, and as long as each stack transition leads to a different stack (see example in figures 1 and 2). For each mandatory stack sequence S m in Order ( S m ), let us define the set of all possible stack sequences matching the filler insertion constraints as Fill ( S semantic stack sequences. Dur ing the generation process, the realization probability can be computed by marginalizing over all possibl e semantic stack sequences satisfying the dialogue act constraints:
Inference over such a model would require the decoding algorithm to consider all possible underlying stack sequences togethe r with all possible realizations, which is intractable for non-trivial domains. Because a key requirement of this work was to develop data-driven techniques that can be used to generate utterances in real-time ,the generation task is approximated by splitting it into three sequential decoding steps, illustrated in Figure 3: 1. The ordering of mandatory stacks S m is predicted independently from the 770 2. The resulting n -best mandatory stack sequences S  X  m are used to constrain 3. The resulting n -best full stack sequences S  X  are used to condition the
Each decoding step can be computed using dynamic programming; however, the de-coding efficiency depends highly on the locality of context features. In the basic decoder, we factorize our models by conditioning the realization phrase at time t on the previous phrase r t  X  1 , and the previous, current, and following semantic stacks. The semantic stack s t at time t is assumed to depend only on the previous two stacks: achieved by keeping track of the mandatory stacks that were visited in the current sequence and pruning any sequence that has not included all mandatory input stacks on reaching the final frame. Because the number of filler stacks is not known at decoding time, the network is unrolled for a fixed number of frames T defining the maximum number of phrases that can be generated (e.g., T = 50). The end of the stack sequence is then determined by a special end symbol, which can only be emitted within the T frames once all mandatory stacks have been visited. The probability of the resulting utterance is thus computed over all frames up to the end the length L of S  X  and R  X  . Whereas the decoding constraints enforce that L search for S  X  requires comparing sequences of different lengths. A consequence is that shorter sequences containing only mandat ory stacks are likely to be favored. Future work should investigate length normalizat ion strategies, but we find that the learned transition probabilities are skewed enough to favor stack sequences that include filler stacks.
 to find the optimal sequence of output sym bols (mandatory semantic stacks, filler stacks, and realization phrases) given the input (unordered mandatory stacks, ordered mandatory stacks, and the full stack sequenc e, respectively). Our initial generator thus tational complexity, the number of stack sequences Order ( the first decoding step increases exponentially with the number of input mandatory stacks. However, the proposed three-stage architecture allows for tractable decoding by (a) pruning low probability paths during each Viterbi search, and (b) pruning low probability sequences from the output n -best list of each component. 4.2 Generalization to Unseen Contexts
FLMs allow predicted symbols to be conditioned on any contextual feature. Further-more, if a feature was not observed d uring training time, the FLM can back off to more general features according to a predefined bac k-off strategy. This section shows how the generation process can be made more robust to unseen dialogue acts by factoring the semantic stack and realization phrase variables. 4.2.1 Partial Stack Modeling. A robust language generator should be able to infer that some stack sequences are more likely than others even if they were only par-tially observed during training, based on co -occurrences on individual stack concepts.
For example, such a generator should learn that likely to follow inform ( pricerange ( cheap )) based on the observation of ( pricerange ( cheap )) followed by inform ( type ( hotel ( restaurant )) has not been seen during training, it will be assigned a low prob-ability regardless of its context. This can be alleviated by factorizing the stack variable into underspecified stack configu rations X  X hat is, model the probability of observing a stack s t as the probability of observing the tail of the stack l as the head of the stack h t given its tail. In other words, the probability of a stack occurrence given the previous stack is factorized as P ( s
P ( l | s followed by inform ( type ( restaurant )) will be high even if was not observed, as long as inform ( pricerange ( cheap )) is frequently followed by the tail symbol inform ( type ( SOMETHING )) in the training data.
 sity issue, it limits its impact to a single factor. In the example above, ( type ( restaurant )) has not been seen during training; hence there is no data to estimate 772 the probability that the head symbol restaurant governs inform the second factor. A solution is to back off to the probability of in a more general context (e.g., ignoring the underlying stack concepts). The back-off back-off variables is shown in the right column of Table 1.
 ordering, but it can also be used to assign non-zero probabilities to realization phrases observed in unseen semantic contexts by backing off to the head and the tail of the ization back-off graph in Figure 4(b). The neighboring semantic stacks s are first replaced by their stack tails l t  X  1 and l t + three resulting contexts were observed during training, the current semantic stack s variables the farthest away are dropped in the following back-off steps. In extreme cases, the realization probability i s approximated by the unigram count P ( r
This mechanism provides B AGEL with the ability to generalize lexical realizations across contexts. For example, if reject ( area ( centre )) was never observed at training time,
P ( r
P ( r in the centre of town if the phrase centre of town was associated with the concept in a different context, such as inform ( area ( centre )). 4.2.2 Partial Phrase Modeling. The robustness of FLM-based generation models can also be improved by allowing the realization model to back off to partial phrase contexts .For example, even if the phrase sequence located in the and centre of town has not been seen during training, it would be desirable for it to have a higher probability than located in followed by centre of town , which misses a determiner. This can be achieved by backing off to the last words of the preceding phrase (e.g., in the or the ), which are more likely to precede centre of town in the data. Hence FLMs can learn to predict function words without allocating them an explicit time fram e during decoding. In our experiments, we sequentially back off to the last two words and the last word of the preceding phrase. B
AGEL  X  X  decoding models, and Table 1 shows an instantiation of the back-off variables for an example utterance. The predictions of FLMs can be improved by smoothing their probability estimate over different co ntexts by interpolating between different back-off probability distributions (Bilmes and Kirchhoff 2003). In o ur experiments, the conditional probability distributions of the three models in Figure 3 are smoothed using Witten X  X ell interpolated back-off smoothing, according to the back-off graphs in
Figure 4. Generally, variables that are the farthest away in time are dropped first, and partial stack variables are dropped last, as they are observed the most. As the optimal back-off strategy can vary depending on the c ontext, the realization model implements parallel back-off strategies (see steps 2, 4, and 5 in Figure 4(b)) X  X hat is, multiple back-off paths are explored at run-time, and the probability of each back-off node is computed as the maximum probability of all outgoing paths. 4.2.3 High Cardinality Concept Abstraction. Although we should expect a trainable gener-ator to learn multiple lexical realizations fo r a given semantic concept, learning lexical realizations for high-cardinality database entries (e.g., proper names) would increase the number of model parameters prohibitivel y. We thus divide pre-terminal concepts in the semantic stacks into two types: (a) enumerable attributes whose values are associated with distinct semantic stacks in our model (e.g., inform ( non-enumerable attributes whose values are replaced by a generic symbol before training in both the utterance and the semantic stack (e.g., values are then replaced in the surface realization by the corresponding value in the input specification. A consequence is that our model can only learn synonymous lexical realizations for enumerable attributes. 4.3 Scaling to Large Domains Using Large-Context Reranking FLMs A major inconvenience of the proposed approach is that the performance of the three
Viterbi decoding steps is highly dependen t on the size of the context of the predicted variable. For example, a trigram phrase model with a vocabulary of size V requires 774 searching over V symbols times V 2 paths leading to that symbol at every time step.
Generating utterances for real-time intera ction in a realistic domain typically limits context features to a single neighboring time frame (i.e., bigram) for both the semantic stack and realization models, which results in poor modeling accuracy. In order to model longer contexts while maintaining a cceptable decoding performance, we use a cascaded reranking approach in which the n -best output of each Viterbi search is reranked by an FLM. The complexity of the reranking steps grows linearly with n and does not depend on V ; hence its impact on performance is minimal compared with the decoding steps. Figure 5 illustrates the resulting pipeline of FLM models.
 for our reranking models, as they offer a rich context while maintaining acceptable real-time performance. The semantic reranking models are dependent on three preceding time frames, and the realization reranking model is dependent on the two previous and two following phrases. Reranking back-off strategies can be more complex than the strategies used during search, as they are only called over a small number of candidate sequences. For example, the realization r eranking strategy in Figure 6(b) makes use of parallel back-off to learn patterns such as serves X food or is an X restaurant .Thiscan be achieved by allowing the probability of a phrase to depend on the phrase at time t  X  2 rather than on the preceding phrase (se e right branch in Figure 6(b)). Hence if the pattern exists in the training data, p ( r t | l t  X  1 , r during reranking, for example, giving a large probability of r and l t  X  1 = inform(food(SOMETHING)) . 5. Stochastic Paraphrase Generation
Because a dialogue act can typically be conveyed in a large number of ways, it seems natural to model the NLG task as a one-to-many mapping. However, previous work on statistical NLG has typically focused on evaluating the top ranked utterance, without evaluating whether the generator can produce paraphrases matching a reference para-phrase set (Langkilde-Geary 2002; Reiter and Belz 2009). Although single-output NLG is acceptable for one-off text generation , NLG systems used within long-term human X  computer interaction are likely to benefit from modeling the paraphrasal variation found in human language (e.g., by reducing the repetitiveness of dialogue system utterances or by improving the chances o f successful dialogue clarifications). machine learning problem. One advantage of casting the NLG task as search over search for valid paraphrases. See Table 2 for examples of B tourist information domain. This section proposes two methods using those outputs to generate paraphrases that can be used interchangeably in dialogue. 5.1 n -best Selection Beam for Paraphrasing We first propose taking a sample from the top of the n -best list produced by B realization reranking FLM shown in Table 2. However, to avoid sampling from the long tail of low-probability utterances, we only c onsider utterances whose probability lies within a selection beam relative to the probability first-best utterance p the utterances generated with a probability above are kept. The top utterances are typically gr ammatical and natural; however, determin-ing a cut-off threshold that captures some of the linguistic variation found in the data without introducing disfluencies is a nontrivial problem. Because many system acts are associated with multiple reference paraphrases in our data, the BLEU score (Papineni et al. 2002) can be used to tune the threshold value. BLEU is a corpus-level metric that is typically used to evaluate a test corpus against a set of reference paraphrases. In order to evaluate the worth of the predicted set of utterances, each utterance within the selection beam is considered as part of the test corpus, thus favoring models generating multiple utterances matching any of the reference paraphrases rather than a single utterance.
Figure 7(a) shows the BLEU score of paraphrase sets generated using different n -best selection beams, averaged over a 10-fold cro ss-validation over 1,646 distinct dialogue 776 act and paraphrase set pairs collected thro ugh crowdsourcing. The data collection process is detailed in Section 6. It is important to note that none of the dialogue acts used for testing were seen at training time. The BLEU score was computed by treating all predicted paraphrases as a whole document. We find that including the top 6% of the n -best list produces a higher BLEU score than using the first-best utterance only (BLEU = .39 vs .37). As a high level of overlap with a ref erence utterance does necessarily result in grammatical or natural outputs, Figure 7(b) also looks at the precision and recall of the generated paraphrase set given the reference set (i.e., only considering exact utterance matches). Although exact matches are rare on unseen inputs, we find that the optimal
F-measure is obtained when considering the top 8% of the probability mass of the n -best list, which corresponds to an aver age of 2.1 paraphrases, according to Fig-ure 8. Both evaluation metrics suggest that ge nerating paraphrases improves linguistic variation without affecting grammaticality, hence potentially improving naturalness in dialogue. Unless stated otherwise, we use a selection beam of 8% in our experiments. outputs. We find that some errors arise from the separation between the semantic stack decoding step and the realization step, together with an excess of smoothing. For example, X is a Y food in the city centre in the first section of Table 2 was associated with a non-zero probability because the phrase sequence X serves Y food occurs frequently in the data, hence allowing the stack inform ( food ( Y )) to be followed by rather than inform ( type ( restaurant )). At the realization stage, the is a realization phrase is associated with a high probability, given an inform rant name and a sentence start symbol, while the phrase food following is a Y is allowed because the unseen context gets dropped by the back-off strategy. Similarly, the example unfortunately, there are no, there are no university departments near X in the last section of
Table 2 is associated with a non-zero probability because the semantic stack decoding step predicted multiple reject stacks followed by a punctuation mark because the non-adjacent stack context was smoothed away, leading to phrase repetitions at the realization stage. Although these type of erro rs are typical of sequential models trained on a limited amount of data, they tend to be associated with a lower probability than the top hypotheses, and additional data would m ake such errors less likely by allowing for 778 larger contextual dependencies to be mode led without back off. However, FLMs will always associate a small probability to a large range of utterances; hence there is a need for selecting paraphrases based on a selection beam or statistical classification methods. 5.2 Structured Perceptrons for Paraphrase Classification
FLMs can be trained easily by estimating cond itional probabilities from feature counts over a corpus, and they offer efficient decoding techniques for real-time generation.
However, FLMs do not scale well to large featu re sets (i.e., contexts), as each additional feature increases the amount of data requi red to accurately estimate the FLM X  X  con-ditional probability distribution. Backing o ff as described in Section 4.2 alleviates this issue, although finding the optimal back-off strategy is nontrivial even for small feature sets (e.g., 10 features). Furthermore, FLMs are trained to maximize the likelihood of the training data; hence utterances contai ning frequent phrases are more likely to be generated than utterances containing infrequent phrases, even if the latter is part of the training set. Whereas in the previous section, a selection beam was optimized for selecting paraphrases, it is learned once and for all regardless of the input. This section therefore investigates whether performanc e can be improved through discriminative training, by rescoring the list of candidate semantic stack and realization sequences produced by the FLMs based on binary classification models predicting whether each candidate sequence is a valid paraphrase. W e propose a training method inspired by
Collins X  work on discriminative reranking for part-of-speech tagging and syntactic parsing, which uses the structured perceptron on-line algorithm to learn to rerank the output of a generatively trained mode l (Collins 2002a, 2002b; Collins and Roark 2004).
The structured perceptron algorithm learn s a linear discriminant function of the fea-stack and realization phrase sequences, respe ctively) by iteratively updating its feature weights  X  each time it wrongly predicts a training example. Each update makes the weight vector closer to the features of the t raining example, and further away from the incorrect prediction. A crucial point is tha teachpredictionrequiresfindingtheoutput z that maximizes the discriminant function given the input x .AsaViterbisearchisnot tractable because of the large context dependencies of the features, we limit our search to sequences in the n -best list GEN ( x ) produced by the short context FLMs. tion (Collins 2002a; Collins and Roark 2004), the result ing scores cannot be used directly to select multiple valid paraphrases among th e candidates. Rather than learning a cut-off threshold as done in Section 5.1, we cast the perceptron reranking step as a binary classification task, by updating the perce ptron X  X  weight vector accordingly each time (a) a reference realization is classified negatively and (b) a non-reference realization in
GEN ( x ) is classified positively. The main difference with Collins X  reranking model is that the zero of the discriminant function is trained to act as a classification threshold.
At generation time, the learned model classifies each candidate realization of GEN ( x ) to determine whether it should be included in the paraphrase set from which the final utterance can be selected. It is important to no te that this approach iterates over training pairs generated from the same input dialogue act. A consequence is that the data is no longer independently and identically dist ributed, thus potentially increasing the generalization error of the models.
 in Table 3, which learns a set of feature vec tors and their corresponding weights. To facilitate understanding, Table 3 also presents the simplified algorithm in the case of a
Input: T training iterations, n training examples associating each input x output set Y i (i.e., semantic stack or realization sequences). GEN ( x n -best output sequences for input x i based on a Viterbi search using the corre-sponding FLM, in which n depends on a pruning beam and a maximum value.

 X  ( x i , y ) is a sparse feature vector of dimensionality d representing the number of occurrences of specific combinations of realization phrases and/or semantic stacks in ( x i , y ), with an entry for each instantiation in the training data of each node of the backoff graph of the large context FLM in Figure 6.

Output: a collection V of feature vectors in R d and their respective weights
R | . Using a linear kernel, the algorithm i s simplified as the weighted feature vectors can be represented as a single weight vector w = |
Linear kernel algorithm: w = 0 For t = 1 ... T , i = 1 ... n For z in GEN ( x i )  X  Y i If w .  X  ( x i , z )  X  0then w  X  w  X   X  ( x i , z ) // incorrect positive prediction For y in Y i If w .  X  ( x i , y ) &lt; 0then w  X  w + X  ( x i , y ) // incorrect negative prediction
Kernelized algorithm with kernel function K : R d  X  R d  X  R
V = [ 0]  X  = [0] For t = 1 ... T , i = 1 ... n For z in GEN ( x i )  X  Y i
If | V | j = 1  X  j K (  X  ( x i , z ), V j )  X  0 then // incorrect positive prediction For y in Y i
If | V | j = 1  X  j K (  X  ( x i , y ), V j ) &lt; 0 then // incorrect negative prediction linear kernel, in which the weighted feature vectors are collapsed into a single weight vector. In our experiments, we use a polynomial kernel of degree 3. The feature vectors represent the number of occurrences of specific combinations of realization phrases and/or semantic stacks in the input and output sequences, with an entry for each instantiation in the training data of each node of the back-off graph of the large context
FLM in Figure 6. For example, the back-off node r t | l t derive a feature characterizing the number of occurrences of the phrase has followed by the stack tail inform ( food ( SOMETHING )) followed by the phrase food . 780 using the averaged weight vector over all updates was shown to generalize better to un-seen examples (Collin s 2002a). Collins h as shown that structured perceptrons can out-perform boosting and SVM-based models, with a training complexity growing linearly with the training set size (as opposed to a cubi c complexity for large-margin classifiers). reranking the output of each FLM decoding model. All perceptron models are trained simultaneously by iteratively generatin g each training example, and updating each reranking model if its first-best sequence differs from the reference sequence. This the candidate n -best list is reranked twice: (a) before updating the perceptron X  X  weight vector in order to find whether the current best hypothesis matches the reference, and (b) after updating the weight vector to maximize the accuracy of the input to subsequent models in the pipeline. 6. Corpus Collection Our target domain is a large-scale spoken tourist information system for Cambridge.
Table 4 illustrates the 10 types of dialogue acts that are produced by the dialogue manager. Because each dialogue act type exhi bits different stack ordering patterns, they require distinct semantic stack predicti on models. Some of the communicative goals include logical operators, such as global negations and logical quantifiers (e.g., rows 2, 4, and 5 in Table 4), each of which require a specific dialogue act type. Figures 10 illustrate the ontology of our domain, which results in 128 distinct semantic stack con-cepts (e.g., characterizing whether a venue is a bar, museum, cinema, but also whether it is cheap, near another venue, whether it has Internet, parking space, or whether it allows children). Because our approach targets dialogue applications, B representation is defined by the domain ontology itself; hence the semantic concepts typically correspond to constraints used to narrow down the user goal. In information presentation systems, such concepts are typically associated with database attributes of the entities of interest. In our framework, t he ontology is shared between the dialogue manager, the language understanding component, and the NLG component. Our ontology was thus refined over a long peri od of time prior to this work. The manual effort required for defining an ontology for a new domain is highly dependent on the domain granularity. While automatically deriving ontologies for complex domains remains an unsolved problem, in recent work an ontology for a bus transportation dialogue system was handcrafted in a matter of days (Thomson et al. 2010).
 ager, the NLG component is expected to handle any combination of dialogue act type and semantic concept arguments. The main advantage of data-driven methods over handcrafted methods is their potential for scaling to such large domains by shifting the bulk of the development effort from man ual tuning to data collection. However, a major issue is that such methods typically require semantically annotated data, which is costly to collect. Furthermore, domain data is rarely available; hence a creative process is required for generating a wide range of domain utterances. This article is based on the assumption that learning to produce paraphrases can be facilitated by collecting data 782 from a large sample of annotators. However, this requires that the meaning represen-tation should be simple enough to be understood by untrained annotators. This section describes how we make use of B AGEL  X  X  coarse-grained semantics to collect data from a large sample of untrained annotators, using Amazon X  X  Mechanical Turk.
 stand the meaning of the semantics to be conveyed. Annotators were first asked to provide an utterance matching an abstract description of the dialogue act, regardless of the order in which the constraints are presented (e.g., Offer the venue Taj Mahal and
The order of the constraints in the descrip tion was randomized to reduce the effect of priming. The annotators were then asked to align the attributes (e.g., Indicate the approximated by the set of system dialogue acts produced during 250,000 simulated dialogues between our statistical dialogue manager (Young et al. 2010) and an agenda-based user simulator (Schatzmann et al. 2007). In order to build the training set, we started with a set of utterances collected for a small subset of our domain (Mairesse et al. 2010). We then ordered the dialogue acts based on their frequency of occurrence in the simulated dialogues. In order to ensure that each semantic stack defined by the domain ontology occurs at least once in our data, w e expanded our training set by iteratively adding the most frequent unseen act which contains an unseen mandatory semantic stack. The resulting data set consists of 1,646 unique dialogue acts after replacing non-enumerable values by a generic symbol. Eac h dialogue act contains an average of 3.27 784 mandatory semantic stacks. We generally co llected one utterance per act, although two paraphrases per act were collected during ou r initial experiment. The resulting data set contains a total of 1,956 aligned utterances produced by 137 native speakers of English.
After manually checking and normalizing the data set, 4 the layered annotations were automatically mapped to phrase-level seman tic stacks by splitting the utterance into phrases at annotation boundaries. Each anno tated utterance is then converted into a sequence of symbols such as in Table 1, which are used to estimate the conditional probability distributions defined in figures 4 and 6. The resulting vocabulary consists of 864 distinct semantic stacks and 1,180 distinct realization phrases, with an average of 7.35 phrase/stack pairs per utterance. 7. Evaluation
This section evaluates B AGEL in the tourist information domain, using an automated metric as well as human judgments of resynthe sized dialogues. Our objective is not only to evaluate the naturalness of the generated utterances for different training methods, but also to assess whether the linguistic variation found in B the naturalness of the overall dialogue interaction. 7.1 Comparison with Utterance Class Language Models
As Oh and Rudnicky X  X  LM-based approach is the first statistical NLG method that requires almost no handcrafting (Oh and Rudnicky 2002), we first compare their method to B AGEL in our domain and discuss the differences between both approaches. 7.1.1 Utterance Class LM Baseline. Oh and Rudnicky X  X  (O&amp;R) approach trains a set of word-based n -gram language models (LMs) after replacing slot values by placeholder variables. In order to bias the LMs towards specific intents, the LMs are trained on sub-sets of the data referred to as utterance classes . An utterance class is the set of utterances inform(near(X)) would be a valid utterance class, characterizing all the utterances with the inform dialogue act type and at least one near slot. Given large domains, eval-uating all possible utterance class partitions of the data is not tractable: In their experi-ments in the air travel domain, O&amp;R limit their utterance classes to at most one slot. In order to identify how to partition our data, we investigate a number of utterance classes: (a) using dialogue act types only; and (b) including one or more slots. Because deciding what slot to include is a nontrivial problem, we include slots based on their frequency of occurrence in the utterance class. The utterance class near(X)) for instance indicates that eattype(restaurant) also generate other slots besides those belonging to the class, the main difference being that those other slots act as run-time constr aints in the overgeneration phase, whereas utterance class slots constrain the model X  X  training data.
 overgenerate a set of candidate utterances in a depth-first fashion by sampling from the
LM distribution, one word after the other. Because B AGEL end symbol, we extend O&amp;R X  X  model with an end symbol determining when to end the utterance. In addition to random sampling, we also implemented a deterministic ver-sion of the algorithm that generates all words that followed the utterance context in the training data, as long as they do not violate input constraints (i.e., generate unspecified slots). Decoding was halted if the utterance generated more than 20 words. Although it was not needed on our data set, it is important to note that such a greedy search is likely to require beam pruning on larger data sets. We find that the deterministic version both improves performance and makes it more comparable with B algorithm. Additionally, in order to investigate the effect of the granularity of emission symbols on performance, we also train a phrase-based version of the baseline in which the LMs are trained to predict symbols repr esenting contiguous words either within implementation of the rescoring rules used in O&amp;R, which rescore the utterance based on whether: 1. The utterance is too short or too lo ng. The probability of the generated 2. The utterance contains repetitions of any of the slots. 3. The utterance contains slots for which there is no valid value in the input. 4. The utterance lacks any of the required slots.

The last three rules result in a multiplicative weight of 10 only be chosen if no other candidates satisfy the slot constraints. The system returns the most highly scored utterance over 10,000 iter ations for the sampling baseline (vs. 50 in
O&amp;R X  X  experiments). Additionally, our implementation of O&amp;R X  X  method keeps track of visited slots during generation, hence pr uning paths that generate a slot placeholder which is not part of the input, or generate a slot more times than specified in the input. partitioning the 1,646 distinct dialogue acts for which we collected one or more utter-ances. None of the test dialogue acts are pres ent in the training folds. Results report the
BLEU scores averaged over the 10 test folds. 7.1.2 Results. A first result shown in Table 5 is that O&amp;R X  X  original sampling approach does not perform as well as the determinist ic algorithm, while being more computa-tionally expensive. A paired t-test over the 10 cross-validation folds reveals that the dif-ference is significant for all configurations (p &lt; 0 . size used is much larger than in O&amp;R X  X  experiment, suggesting that sampling does not scale well to larger domains. The rest of this section refers to the deterministic approach. .10. We believe this is due to the lack of semant ic labels besides slot values, which causes phrases to be very long and unlikely to occur both in the training and test folds. The rest of this section therefore refers to O&amp;R X  X  word-based approach.
 of the utterance class. The trigram model performs best without including any slot in the utterance class, with a mean BLEU score of .28. In contrast, B shows that this score is significantly higher (two-tailed, p 786 the only one producing an output utterance for almost all unseen inputs in the test folds (99% for bigram LMs, 93% for trigram). Figure 12 illustrates results for additional slot combinations, showing that adding more slots consistently decreases performance.
Figure 13 shows that this performance decrease can also be observed when using sampling.
 performance significantly with a BLEU score of .06 with a bigram model and .02 formance decreases further with larger n -gram sizes. This decrease is likely to be due to the fragmentation of the training data illustrated in Figure 14, as sparser probability counts make the generation process less like ly to find a path satisfying the global slot constraints. For instance, adding the most frequent slot in the training data as part of using a bigram model. Although removing the d ecoding constraints is not tractable, we can estimate the performance of O&amp;R X  X  method given unlimited computing power by only evaluating it on the subset of the data for which the constraints are not violated X  that is, on the test data which does produce an output utterance. In this case the best
O&amp;R baseline yields a score of .32 on successf ul predictions (69% of the data) using the 5-gram model with no slots, whereas the same model yields a score of .20 when taking all test utterances into account.
 learns a model more likely to produce the most frequent patterns in the utterance class, making it difficult to model specific slot combinations correctly. An utterance class including many slots can model those slots more accurately; however, it can only be trained on the fraction of the data matching that class, creating data sparsity issues. decreases for contexts larger than trigr ams. For example, Figure 12 shows that the
BLEU score decreases significantly from .28 for trigrams to .24 and .20 for 4-grams and 788 decrease in performance is likely to be due to overfitting. Larger n -grams are less fertile because they result in fewer non-zero transitions from a given context; hence they are less likely to produce an utterance satisfying t he slot constraints. This particular issue could be alleviated by investigating different smoothing strategies.
 able, we did not evaluate O&amp;R X  X  approach using human judges. It is important to note that a human evaluation would be desirable to strengthen our findings. Additionally, future work should evaluate whether the difference in performance holds for larger data sets. 7.1.3 Discussion. Like B AGEL , O&amp;R X  X  method uses a search over a sequential probabilistic model of a phrase given its context. However, a major difference with our approach is that semantic concepts are only explicitly modeled through slot placeholders and the utterance class partition before training, namely, determining what slots the words should be conditioned on, if any. Including all slots as part of the utterance class would highly fragment the data, whereas using only the dialogue act type is likely to reduce the model X  X  capability of producing slot-specific phrasings. As shown in our experiments, the choice of what slots to include in the utterance class has a large impact on the quality of the output utterances. B AGEL mitigates this by not conditioning the generated words on a global utterance class value, but by conditioning the individual words on elements of a generated sequence of semantic symbols. Given that the number of semantic concepts is lower than the vocabulary size, usi ng an explicit semantic representation can reduce the number of parameters to estimat e during training compared with systems relying on various word contexts. In some cas es, however, the previous words provide additional useful information (e.g., for lo cal agreement); hence there is value in taking both the semantic and word context into account whenever needed. Factored language models provide a way for the learner to choose what context to rely on.
 tics implies that each lexical item realizing an input slot value has to be specified in the input. This is a valid approach for domains in which slot values are limited to numerical values or proper nouns, but not for domains in which semantic concepts need to be realized differently, depending on the context and the dialogue act type. For example, compare how B AGEL realizes the area semantic concept in the query Whereabouts were
Requiring each slot value to be realized using the same lexical item regardless of the context is likely to be impossible for large domains, especially with multiple dialogue act types. This limitation could be alleviated by including the n slots for which we want to control the lexical realization as part of the utterance class. However, this is not tractable as it would require fragmenting the data further to produce all 2 combinations as distinct utterance classes. Sharing data across utterance classes or using hierarchical class-based language models could mitigate this issue, but this is beyond the scope of this article.
 utterance class-based LM methods on our data using automated evaluation metrics.
We n o w e v a l u a t e B AGEL using human judgments. 7.2 Human Evaluation from Text Samples
Although automated metrics provide useful information for tuning model param-eters, they only correlate moderately with human naturalness ratings (Papineni et al. 2002). We therefore evaluate the methods presented in the previous sections through a subjective rating experiment, using Am azon X  X  Mechanical Turk services. For each dialogue act in our unseen test set, we generate a set of paraphrases with each of the following system configurations: (a ) using large context reranking FLMs ( FLM ); (b) using perceptron reranking ( perceptron ); and (c) using the output of the decoding models directly ( no reranking ). In order to validate the paraphrasing FLM threshold analysis presented in Section 5.1, we evalua te utterances generated within a selection beam of 8% and 15% relative to the probability of the top hypothesis (FLM
FLM 15 ), as well as a system returning the top hypothesis only (FLM figuration, we either train all decoding and reranking models on distinct data sets dialogue act types ( global ). Although a global realization model can potentially gen-eralize across dialogue act types (e.g., not requiring each top semantic concept to be seen with each act type during training), p erformance is likely to be affected by the resulting increase in vocabulary size and the reduction in consistency between training examples.
 with a polynomial kernel of degree 3 as it pe rformed best in preliminary experiments on a subset of our training data. We evaluate all the paraphrases classified as positive by the model for a given input act. Our experiment compares two variants of the perceptron model: (a) using the weights of the last perceptron update ( Last ); and (b) taking the average of each weight update w eighted by the number of instances for which the weight vector was left unchanged during training ( Avg ). In order to account 790 for differences in computational resources needed by each system, we set the pruning thresholds such that each paraphrase set is generated within 0.5 seconds on a Pentium 4.2 GHz. For each input dialogue act, a maximum of 100 realizations were reranked in our experiments. These were derived from up to five semantic stack sequences, each generating up to 20 realization phrase sequences.
 combined and presented in random order, for four dialogue acts at a time. Participants were told that each utterance was meant to have the same meaning, and they were asked to evaluate their naturalness on a 5-point Likert scale, as illustrated in Figure 15. Naturalness is defined as whether the utterance could have been produced by a human.
Each utterance is taken from the test folds of the cross-validation experiment presented in Section 5.1 X  X hat is, the models are trained on up to 90% of the data and the training set does not contain any of the generated dialogue acts. 7.2.1 Results. Table 6 presents the average natura lness rating for each configuration ( Nat ). A Wilcoxon rank sum test shows that all systems outperform the FLM system returning the top hypothesis of the search models, with no reranking (p two-tailed). 5 We find that the best performance is obtained using the FLM reranking models, with an average naturalness of 3.83 when only considering the top hypothesis (FLM 0 ), compared with 3.16 without any reranking ( base ). Whereas the automated eval-uation in Section 5.1 predicted an optimal selection beam of 8%, we find that the average naturalness decreases to 3.78 when taking t he average over all paraphrases within that beam; however, the decrease in naturalness is not significant over 1,097 samples (p = 0 . 33). Because these results do not take the coverage of the generated paraphrase set into account, such a nonsignificant decrease in naturalness is encouraging, as it suggests that the naturalness of the paraphrases produced are close to the first-best. Using a larger selection beam of 15% increases cov erage further but produces a significantly lower naturalness than both the FLM 0 and FLM 8 systems (p respectively). While we expected that shar ing realization models across dialogue act types would help generalize, overall we fi nd that using one realization model per dialogue act type does not perform significantly worse than global realization models (FLM 15 global), although the former greatly red uces the number of model parameters. the no reranking baseline (p &lt; 0 . 0001). We find that using the averaged weight vector produces a smaller set of paraphrases that are perceived as more natural (p confirming the improvement previously obs erved for the part-of-speech tagging task (Collins 2002a). However, res ults show that both the FLM perform the perceptron-based systems (p &lt; 0 . 01 and p
FLM 8 system produces slightly more paraphrases. We find that the averaged perceptron reranking model produces utterances that are comparable to an FLM selection beam of 15%; although for the same level of naturalness, the thresholded FLM produces 2.03 utterances on average, as opposed to 1.46 for the perceptron.
 selection beam offers the best trade-off between utterance naturalness and paraphrasal variation. 7.3 Human Evaluation from Dialogue Extracts
Although a text-based evaluation gives a g ood insight into the level of naturalness of a generated paraphrase set, it does not evaluate whether differences in naturalness can be perceived in a spoken dialogue context, nor does it evaluate the effect of the linguistic variation resulting from the use of multiple paraphrases within a dialogue. generators can produce language perceived as natural in a dialogue context; (b) vary-ing the paraphrases used throughout the dialogue improves the system X  X  naturalness; and (c) this increase in naturalness makes the user more willing to interact with the system.
 comparing dialogue extracts in which the s ystem utterances have been regenerated and resynthesized. The original dialogues were c ollected over the phone during a task-based evaluation of the Hidden Information State dialogue manager (Young et al. 2010) on the
CamInfo domain, using a handcrafted rule-based language generator. Each utterance is 792 synthesized using an HMM-based text-to-speech engine trained on the AWB voice of the ARCTIC data set using the HTS toolkit (Tok uda et al. 2000).
 (a) the FLM reranking method with n -best outputs sampled from an 8% selection beam ( FLM n-best ); (b) the averaged kernelized perceptron reranking method with uniform sampling over positive predictions ( Perceptron ); and (c) the single output of the hand-crafted rule-based generator ( Handcrafted ). The handcrafted generator is an extension of the SPaRKy sentence planner (Stent, Prasad, and Walker 2004), which associates each dialogue act with a content plan tree combining syntactic templates with rhetorical structure relations. The syntactic templates are aggregated two-by-two in a bottom X  X p fashion by trying different clause-combining operations (e.g., by in serting a conjunction, merging identical subjects, or associating e ach template with distinct sentences). The aggregated syntactic tree is then converted into a flat string using the RealPro surface realizer (Lavoie and Rambow 1997). The handcrafted generator has been tuned over several months to produce natural utterances for all possible input acts; we therefore treat it as a gold standard in our evaluation.
 system that always selects the top realization at each turn ( FLM first-best ). In order to maximize the effect of generated linguistic variation, we do not sample paraphrases that were already chosen during the previous dialogue turns, unless there are no re-maining paraphrases for that dialogue act. A total of 255 dialogues were regenerated for each system. In order to facilitate the liste ner  X  X  task while maintaining some aspect of the dialogue context, the dialogues were split into chunks consisting of the two consecutive system turns, concatenated with the corresponding prerecorded user turn.
In order to make the dialogue extracts more intelligible, regenerated system turns are concatenated with the user turns with no speech overlap.
 out of all the regenerated dialogues. The rat ers are presented with four pairs of dialogue extracts at a time, which only differ by their system prompts. For each dialogue pair, they are asked to listen to both sound clips and evaluate (a) which system is the most natural ( naturalness score), and (b) which system they would rather interact with ( user preference score), as illustrated in Figure 16. Participants were native speakers of English recruited through Amazon Mechanical Turk, and geographically restricted to the USA. Although the British TTS voice used might aff ect overall perceptions of naturalness of
U.S. judges, it should not introduce any bias within the system comparison as the same voice was used for each system. Each dialogue extract was rated by a single participant, and each participant could rate between 4 and 100 dialogue extract pairs. As a result, between 55 and 64 participants took part in the evaluation of each system pair. 7.3.1 Results. Table 7 summarizes the results of the preference tests. The naturalness and user preference scores represent the percentage of times the judges selected a given system over the other. A binomial test suggests that the judges did not prefer the handcrafted gold over the FLM reranker with n -best outputs, as no significance was reached over 600 comparisons (p &lt; 0 . 05). However, the judges preferred the hand-crafted generator over the perceptron reranker, possibly because it was also perceived as significantly more natural (p &lt; 0 . 05). No significance was found when comparing the
FLM reranker with the perceptron reranker, a lthough most judges preferred the former, hence confirming results from the text-based evaluation. Finally, the FLM reranker with n -best outputs was perceived as significantly more natural than the same system with first-best output only (p &lt; 0 . 001). Furthermore, results confirm that the judges would generation approach has a higher risk of selecting ungrammatical outputs compared with the first-best approach. However, our re sults show that despite that risk, judges prefer the n -best system, which suggests that data-driven paraphrase generation is beneficial in dialogue.
 compared with standard lab-based evaluation, mostly due to the possibility of uncoop-erative evaluators. However, the randomization of the order of the evaluated utterances ensures that such noise does not bias the results towards one system. It is therefore likely that a more controlled evaluation would have revealed even more significant results. 8. Discussion and Conclusion
This article presents and evaluates B AGEL , a statistical language generator that can be trained entirely from data, with no handcrafting required beyond the semantic anno-tation. All the required subtasks (i.e., conte nt ordering, aggregation, lexical selection, and realization) are performed implicitly through a search over Factored Language
Models. We propose a stack-based semantic representation at the phrase level, which is expressive enough to generate natural utterances from unseen inputs, yet simple enough for data to be collected from a large set of untrained annotators with minimal manual correction and normalization. Results show that this approach outperforms utterance class LM methods on our data.
 we limit the context-size of the decoding FLMs and rerank their n -bestoutputusing large-context reranking models. We investigate two types of reranking models, namely, (a) generatively trained FLM rerankers and (b) discriminatively trained structured per-ceptron models. The perceptron learns a discriminant function weighting local feature counts over the full utterance. By kernelizing t he perceptron algorithm, the discriminant function is implicitly made dependent on a larger set of feature combinations (e.g., a polynomial kernel contains the products of each FLM context feature). Although our 794 results show that the perceptron reranking step is a viable alternative, we find that the large context FLM generalizes better on uns een data. This could be a consequence of the fact that some of the training examples of our algorithm are generated from the same input, and non-independently distributed data is likely to affect generalization error.
A possible solution to this issue is to only allow a single weight update per input by moving the weight vector closer to the features of the lowest ranked reference para-phrase, and away from the highest ranked non-reference utterance. However, selecting the final paraphrase set would require a cut-off threshold that would need to be learned separately. Future work should also invest igate the use of the large margin criterion instead of the perceptron criterion, whic h is more costly to compute but less likely to overfit; and it can minimize arbitrary loss functions (Tsochantaridis et al. 2004). Finally, the decoding models could also be learned dis criminatively, for example, by learning to predict phrase sequences using maximum entropy Markov models or conditional random fields.
 against exact repetitions (i.e., verbatim repet itions are prohibited unless all paraphrases have been generated). Our n -best system does not model the case in which verbatim repetitions could be used as an emphasis device. This could be addressed by adding a semantic element specifying that a specific phrase should be repeated for emphasis purposes. Because the n -best system did not implement that functionality, we believe that the preference for the n -best system could be increased when modeling exact repetitions. Apart from the case of emphasis, we believe that paraphrasing is generally more natural in dialogue contexts. Although this claim is difficult to evaluate, Torrance,
Lee, and Olson (1992) have shown that children under 6 fail to distinguish between verbatim repetitions and paraphrases (i.e., before they learn to read). This result sug-gests that there might not be any additional cognitive load from using paraphrases in dialogue.
 us to use crowdsourcing to collect semantic ally annotated utterances from untrained annotators. A first implication is that such methods could dramatically reduce devel-opment time of NLG systems, while improv ing scalability to large domains. Future work should therefore evaluate whether the same performance can be achieved in other task-oriented domains. Furthermore, although this work treats the training set as fixed, recent work has shown that active learning can further improve the efficiency of the data collection process (Mairesse et al. 2010).
 by the attributes of the entity of interest in our domain X  X s expressive enough for a large range of information presentation systems. Although it is not as expressive as first-order logic, B AGEL implements the all , none ,and only quantifiers by treating the limitation is that currently B AGEL can only present entities satisfying the same set of constraints within a dialogue act, for example, X and Y are French restaurants near King X  X 
College . Future work should focus on extending o ur semantic representation to include contrastive or justificative statements by allo wing the presentation of entity-dependent attributes; for example, X is near King X  X  College however Y is close to the train station or Yo u might be interested in X because it is cheap and near the VUE cinema . Previous work in NLG has represented such statements using discourse relations from Mann and Thompson X  X  Rhetorical Structure Theory (1988) as part of the sentence planning process (Walker, Rambow, and Rogati 2002; Stent, Prasad, and Walker 2004; Stent and Molina 2009).
Hence B AGEL  X  X  expressiveness could be improved by including discourse relations as part of the semantic tree and corresponding stack sequence. For example, Charlie Chan including a CONTRAST discourse relation to produce the tree in Figure 17. As this would require increasing the stack depth, experim ents with new back-off strategies are likely to be required to confirm that B AGEL can generalize to support such discourse relations. Although adopting a formalism such as RST would increase B for annotating training utterances, thus potentially making it more difficult to rely on crowdsourcing for collecting training examp les. There is thus a trade-off between the complexity of the semantic annotation and the amount of annotated data that can be realistically collected. While we believe the g ranularity of our semantic scheme offers a good balance for dialogue system applicat ions, more research is needed to establish whether more fine-grained semantics can yie ld a sufficient amount of data in arbitrary domains.
 annotators. The B AGEL framework requires the onto logy to be designed such that for the system X  X  natural language understanding component. Annotation errors can typically be smoothed out by the statistical model; however, systematic errors due to ambiguities in the annotation schema can affect system performance. A consequence is that the annotation schema might require mu ltiple iterations, based on the observed performance. We believe that most misunderstandings can be resolved by renaming semantic concepts, or by presenting e xample utterances to the annotators.
 us with a varied set of training paraphrases. Even without explicitly collecting multiple utterances for a single dialogue act, identica l semantic concepts are typically associated with different realization phrases across dialogue acts. We believe that statistical NLG methods have the potential to learn to reproduce that variability at no extra cost. A further contribution of this article is ther efore to present and evaluate two methods for learning to generate paraphrases in dialogue: (a) by thresholding the n -best output of FLM reranking models and (b) by using a perceptron reranker to learn a decision boundary between negative and positive u tterances in the training set. Whereas NLG components are typically evaluated from text outputs only, we evaluate both 796 paraphrase generation meth ods within the context of dialogue system interaction.
A first result is that human judges do not perceive the resynthesized outputs as significantly less natural than the outputs of a highly tuned handcrafted gold standard.
This result confirms that B AGEL can successfully learn to generate utterances over a large, real-world domain. Furthermore, we find that a system varying its output by sampling from a thresholded n -best list is perceived more favorably than a system always returning the first-best utterance. These results need to be confirmed by a task-based dialogue system evaluation; but they s uggest that users prefer systems producing varied linguistic outputs, which is cont rary to the intuition that users are more comfortable with machines conversing in a pr edictable, repetitive, machine-like way. Acknowledgments References 798
