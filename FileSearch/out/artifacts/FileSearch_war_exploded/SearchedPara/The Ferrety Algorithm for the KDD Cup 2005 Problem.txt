 be considered as such a problem. Usually, document cat-egorization requires supervised learning methods, however, in the case of KDD Cup 2005 there are some major differ-ences compared to the well-known document categorization problems that exclude the simply use of an off-the-shelf text categorizer: 1. The documents are very short (up to five words for 2. The corpus is very noisy (more than 30% of the cor-3. The number of sample queries (only 111 pieces) is two As a consequence, the set of sample queries can only be used for evaluation, hence no training corpus was given. Nev-ertheless, we argue for the strong necessity of supervised learning because Therefore, here we propose a new technique (named Ferrety algorithm) to overcome these problems, which consists of the following steps (see also Figure 1): 1. Find source: Determine the proper semantics for query 2. Stem queries: Preprocess all queries by performing 3. Query the Web: Exploiting the connections between Moreover, L&amp;Z have a very clear and useful description on each category that determines the proper semantics for the given category. We created our basic dictionary and ontol-ogy based on this phenomenon. Since we strongly believed that the KDD Cup 2005 prob-lem required a supervised learning method, we acquired our training data as follows. First, we stemmed all queries of the KDD Cup 2005 corpus by Porter stemmer. Then we posted the stemmed queries to Internet search engines for relevant answers. In general, we prefer to use a special set of clue words to find the most relevant taxonomy in order to get a corpus with a reasonable quality. Obviously, in the case of KDD Cup 2005, the corpus itself was the most adequate one to find the necessary taxonomy.
 L&amp;Z results have two main parts: local categories to which the query may belong (if any) and relevant contexts of the words contained in the query. Each category has a semantic description that describes the content of the category with a few words. We looked at the semantic description of local categories and we saved their default path from the root. As a result, we obtained semantic descriptions (real definitions) to all L&amp;Z-relevant categories and a default hierarchy of categories. From now on, we call this corpus Basic Corpus ( BC ), and its categories BC -categories. The taxonomy building procedure was designed to deter-mine the maximum relevant set of words which may corre-spond to a given query category. It assumes that the query category name most accurately describes the information belonging to that particular query category. If the name is the most proper description, then all synonyms are also sup-posed to be valid terms to that category. That is why our procedure extends query category names by their WordNet synonyms. We call this step a semantic closure. Let stand for this initial set of partitions where w i (0) denotes the semantic closure of the i th query category.
 We applied W (0) to find relevant BC -categories, i.e. we searched BC -categories with semantic description containing the given set of words. Let C 0 i  X  X C be the subset of the Basic Corpus determined by w i (0). The Ferrety Algorithm calculates the well-known tf-idf measure (see e.g. [2]) for the words of the descriptions in C 0 i , which have frequency greater then  X  in at least one C 0 i , and occur no more than in  X  C 0 i . Let A 0 denote the set of words that holds this property. Then we can apply the recursive formula: w i ( n + 1) = w i ( n )  X  X  a | a  X  A n  X  X  n i } ( n = 0 , 1 ,... ) (1) We also use this step for the higher level categories, e.g. Com-puters, Living, Entertainment, etc. For this level, we cre-ate the union of sub-levels, and apply the above mentioned procedure. This step is important, because the limitation in idf factor might eliminate words that determine e.g. the valid top level context of Computers. Later on, if a query is determined to be in Computers, however, none of its sub-levels proved to be appropriate, then it will be categorized as  X  X ther X  (here: Computer/Other).
 most relevant ones. There are numerous parameters of both training and categorization to control the depth and the width of the searching path of the categorization. For more details see the references. Because the queries themselves contains very few words we found that the feature set (size of dictionary) might not be large and descriptive enough to determine the correct cate-gories for unknown queries, therefore, we supplemented the training set and created 4 different alternatives for train-ing. When explaining training sets, we refer the Reader to Subsection 3.2 for notations of L&amp;Z result pages. The first 3 alternatives assign training data to L&amp;Z cate-gories by means of asking the search engines with stemmed queries. The training data is the query itself or its aug-mented version as described below. The training data is assigned to such L&amp;Z categories that occurs at least once among the local categories on the ISE X  X  result page. The link between L&amp;Z and query categories is established by the taxonomy mapping described in Section 3.3. The last alter-native of training set assigns training data L&amp;Z categories directly, that is without using query information.
Q Query : This is the simplest case, the training data is WQ Weighted Query : Same as the previous, but the
T Text : The text of the stemmed queries is augmented
C Category info : Short semantic description of L&amp;Z One of the most crucial parts of the training is the deter-mination of the feature set. One has to find the optimal balance between discarding rare terms and keeping discrim-inative ones in the dictionary. In HITEC we have two sim-ple parameters to control the dictionary size ( |D| ): a lower limit for the minimal occurrence ( d 1 ) of a term in the entire (training) corpus, and a maximum allowed value ( d 2 ) for the overall distribution of a term over the corpus. These para-meters are related to the TFIDF frequency scheme: d 1 and There are two important parameters to control the size of the result set of a categorization. By max-variance ( v max ) one can specify the minimal deviation (ratio) of a node to be considered for further search w.r.t. the maximal confi-dence value at a given hierarchy level. Setting this value low (around 0.5), one can have many firing categories at each level of the taxonomy. By threshold (  X  ), one can set the minimal confidence value of a node. Setting this value low (0 . 05  X  0 . 15) results in better recall values and more re-sult categories. With the help of these two parameters, we were able to make a trade-off between recall and precision. For the current task, our goal was to obtain large result set for the categorization, therefore we set v max = 0 . 5 and  X  = 0 . 1.
 HITEC provides possibility to use different training corpora for dictionary creation and for training. We exploited this feature and in most run disregarded the Q training set, be-cause the using of Q at training decreased the quality of categorization. This fact can be explained by arguing that the query text are two short for effective categorization. On the other hand, Q is useful at dictionary creation since it could raise the importance of certain occurring terms in the entire Q+T+C training corpus.
 The learning capability of some settings X  X .e. how HITEC could learn the training data X  X s indicated in Table 2. Fig-ure 4 shows the effect of learning during iterations in terms of HITEC X  X  inner quality measure. The efficiency measures shown in the table is obtained by testing the algorithm on indicated training sets (see also Section 3.4.1 ). We evaluated various feature selection and training settings by means of the 111 sample queries (see also Figure 5). result with d 1 = 2,  X  = 0 . 1 and v max = 0 . 5. Unfortunately, R1 run finished after the submission deadline, so we used the result of R2 run for submission. The submitted results were aggregated from two sources: 1. for the queries in the training set (cca. 400k queries) we 2. for those queries that did not produce useable results 3. There were about 80k queries X  X ost probably mainly The above sets were selected based on validation performed on 111 sample queries and on the consideration that HITEC X  X  would rather increase than decrease the categorization error on training set.
 Because of the lack of time, we had no chance to do fine tuning on HITEC X  X  setting. Hence, our approach achieved 0.340883 and 0.34009 precision and F 1 -measure in the evalu-ation, resp, as determined by the organizers. We reckon that it could be raised at least a few percent if more time would have left for tuning, and could submit the HITEC results on R1 run. In the near future, we will investigate the effect of HITEC X  X  setting on query categorization results, and the robustness of Ferrety algorithm. In this paper we presented an algorithm to solve the KDD Cup 2005 problem. The taxonomy building procedure ap-plies interesting ideas (set of clue words, modified tf-idf cal-culation) to determine the proper category of very short de-scription. We combined a web search based categorizer and a taxonomy mapper for limited training sets. The taxonomy mapper that we developed for this particular competition can be applied for general use in connecting taxonomies. We feel that our approach were very successful considering that (i) we participated first time at the competition (ii) started the problem from scratch (apart from HITEC), and (iii) our team had the fewest members among the winning teams. Our thanks to KDD Cup 2005 organizers, Ying Li (Mi-crosoft) and Zijian Zheng (Amazon) for the interesting and successful competition. We would also like to thank Gy  X orgy Bir  X o (Textminer Ltd., Budapest) for the use of HITEC auto-categorizer software. Domonkos Tikk was supported by the J  X anos Bolyai Research Scholarship of the Hungarian Acad-emy of Science. [1] HITEC categorizer online. http://categorizer.tmit. [2] G. Salton and M. J. McGill. An Introduction to Modern at Budapest University of Technology and Economics (BUTE). His research interests include (deductive and relational) data-bases, logic, knowledge representation, natural language pro-cessing, and human computer interaction. He is expected to get his Ph.D. degree early next year.
 Domonkos Tikk is a Senior Researcher at DTMI, BUTE. He has received his Ph.D. in 2000 from the same institution in fuzzy systems. His research covers text mining, natural language processing (NLP), internet search engines, pattern recognition, fuzzy systems and soft computing techniques. Recently he is focusing on hierarchical text classification and NLP related problems. He is acted as the major coach of this KDD Cup team.
 Zolt  X an B  X ans  X aghi is a graduate student at BUTE. His field of interest includes text mining, natural language processing and programming.

