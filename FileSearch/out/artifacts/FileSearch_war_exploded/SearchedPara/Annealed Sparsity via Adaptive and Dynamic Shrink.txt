 Sparse learning has received tremendous amount of inter-est in high-dimensional data analysis due to its model in-terpretability and the low-computational cost. Among the various techniques, adaptive ` 1 -regularization is an effec-tive framework to improve the convergence behaviour of the LASSO, by using varying strength of regularization across different features. In the meantime, the adaptive structure makes it very powerful in modelling grouped sparsity pat-terns as well, being particularly useful in high-dimensional multi-task problems. However, choosing an appropriate, global regularization weight is still an open problem. In this paper, inspired by the annealing technique in mate-rial science, we propose to achieve  X  X nnealed sparsity X  by designing a dynamic shrinking scheme that simultaneously optimizes the regularization weights and model coefficients in sparse (multi-task) learning. The dynamic structures of our algorithm are twofold. Feature-wise ( X  X patially X ), the regularization weights are updated interactively with model coefficients, allowing us to improve the global regularization structure. Iteration-wise ( X  X emporally X ), such interaction is coupled with gradually boosted ` 1 -regularization by adjust-ing an equality norm-constraint, achieving an  X  X nnealing X  effect to further improve model selection. This renders inter-esting shrinking behaviour in the whole solution path. Our method competes favorably with state-of-the-art methods in sparse (multi-task) learning. We also apply it in expression quantitative trait loci analysis (eQTL), which gives useful biological insights in human cancer (melanoma) study. Sparse regression, adaptive LASSO, multi-task LASSO, reg-ularization path, sparse multi-task learning With the rapid development of data acquisition technolo-gies in various science and engineering domains such as imag-ing, physics, biology, and computer networks, we are having access to digital data of unprecedented amount and quality. In this modern paradigm, a significant challenge for data discovery is the huge number of features in representing ob-jects. For example, a high-resolution image is composed of millions of pixels; the micro-array data in human genomic s-tudy typically includes tens of thousands of gene expressions; in movie recommendation systems the number of movies can be tens of millions. How to identify truly relevant features in the huge feature pools for accurate learning and prediction has become one of the key challenges in data mining.
Sparse regression has recently emerged as a powerful tool for high-dimensional data analysis, especially in removing irrelevant variables and identifying a parsimonious subset of covariates for predicting the target [29, 38, 39]. Given a response vector y = [ y 1 ,y 2 ,...,y n ] &gt; and predictors X  X  R n  X  D , where without loss of generality the data is centered, sparse regression and in particular the LASSO solves the following regularized linear regression problem: where  X   X  R D  X  1 is the regression coefficient vector. The ` norm |  X  | 1 is used to enforce the sparsity of solution, mak-ing the model easy to interpret. In the meantime, recent advances in solving the non-smooth, convex LASSO prob-lem has made it computationally extremely efficient [14, 12]. Therefore the LASSO and related methods have been ap-plied with great success in a number of domains including bioinformatics [17, 24, 35, 36], imaging and computer vision [33, 21, 9], and signal processing [5, 6].

It is shown that LASSO can perform automatic variable selection because the ` 1 -penalty is singular at the origin [11]. It was also shown that variable selection with the LASSO is consistent only under certain conditions [22, 37]. Namely, there are scenarios in which the LASSO selection is not con-sistent. To fix this problem, [38] proposes to use adaptive weights to regularize the model coefficients along different features, as where  X  w  X  R D  X  1 is the regularization weight, and |  X  w  X  | P i  X  w i |  X  i | , namely each dimension of  X  is penalized different-ly instead of sharing a single regularization parameter  X  as in LASSO (1). The regularization weights  X  w can be chosen as  X  w = |  X  ols |  X   X  , where  X  ols is the ordinal least-square solution, and  X  is a positive number. Such choice renders the oracle property of the adaptive LASSO estimator in simultaneous variable selection and prediction.

Besides improving the asymptotic behaviour of sparse mod-el estimation, the adaptive LASSO can also be quite useful in imposing structured sparsity patterns, in particular in high-dimensional multi-task learning by sharing the same adap-tive weight across different tasks. Therefore it has gained a lot of research interest from various domains [10, 17, 19]. However, choosing an optimal regularization weight vector  X  w (2) can be much more challenging than selecting a single regularization parameter  X  (1). The former has a signifi-cantly larger search space, and is the key to the superior performance of adaptive LASSO.

In this paper, we propose a novel approach to simultane-ously compute the model coefficients and adaptive regular-ization weights in ` 1 -regularized regression, in comparison to most existing methods that address them separately. The basic idea is to adopt an alternating optimization frame-work to establish the closed-form relations between model coefficients and regularization weights (under an equality norm-constraint of the latter). By doing this, the two set-s of parameters can then be optimized iteratively, until an equilibrium state is obtained upon convergence.

The interactive updating scheme can acquire greater flex-ibility in tuning the sparse model. In the meantime, to fur-ther improve its convergence and reduce the sensitivity on initial conditions, we borrow the idea from material science and propose an  X  X nnealed X  shrinking procedure. Specifical-ly, throughout the interactive updates between model coef-ficients and regularization weights, we gradually strengthen the global magnitude of ` 1 -penalization by adjusting the e-quality norm-constraint on the regularization weight vector. Then, by starting from a dense solution, the system will go through a series of micro-stages that continuously sparsify and ameliorate itself. In this  X  X nnealing X  process, features are like particles: in the  X  X igh-temperature X  beginning, all features have the freedom to compete with each other and position themselves in the model; however, when the sys-tem gradually cools down, fewer and fewer features could preserve their energy; finally, only those features that sur-vive the dynamic competing process will be selected.
We find that such a dynamic shrinking scheme leads to an interesting mechanism of feature selection and compe-tition, which favors the choice of truly relevant features. Through extensive experiments, we compare our approach with a number of state-of-the-art techniques in sparse learn-ing, and obtain promising results. The contribution of the paper is summarized as follows: 1. We introduce the concept of  X  X nnealing X  in sparse learn-2. We extend our approach to solve high-dimensional multi-3. We apply our approach in eQTL, which successfully The rest of the paper is structured as follows. Section 2 dis-cusses the proposed method. Section 3 extends it to multi-task learning scenario. Section 4 describes related methods. Empirical results are presented in Section 5, and the last section concludes the paper.
Consider the following linear regression problem with the design matrix X  X  R n  X  D , where n is the sample size and D is the dimensionality, and the target response vector y  X  R n  X  1 We use an adaptive weight vector w = [ w 1 , w 2 , ...,w D regularize over different covariates, as Here,  X   X  R D  X  1 is the model, w  X  R D  X  1 is the regulariza-tion weight vector, and | w  X   X   X  | = P D d =1 w  X   X  d  X |  X  parameters will be optimized in our learning procedures.
The equality norm-constraint P d w d =  X  is quite useful in controlling the global strength of regularization (in an aver-age sense). To see this, note that the regularization imposed on the d th feature is w  X   X  d (3) . Therefore, if  X  is positive: then the larger the  X  , the smaller the average strength of the ` 1 -penalty; on the other hand, if  X  is negative: then the larger the  X  , the larger the average strength of ` 1 -penalty. Later we shall see that, it is exactly because of this equality norm-constraint (4) that we acquire the flexibility of  X  X n-nealing X  the whole system to improve the state of solution. The power parameter  X  can be chosen either as a positive or negative real number, in comparison to the power parameter that can only be positive in the adaptive LASSO [39].
We first consider  X  as a pre-defined constant. Then the problem (1) can be solved by alternating optimization. Name-ly we first fix w and solve  X  , and then fix  X  and solve w , and keep iterating until convergence. Here we use  X  d to denote the d th entry of  X  .
 Fix w and solve  X  . Then this becomes an adaptive LASSO problem, which can be computationally converted to a standard LAS-SO problem [38].

Fix  X  and solve w . This then become the following constrained optimization problem Problem (6) has a closed form solution, The derivations are in the appendix.

Choice of the  X  Parameter . Based on equation (7), we can examine the relation between the actual regularization imposed in (3), w  X   X  , and the (absolute) value of the model coefficient,  X  d (4). We discuss the following scenarios: 1.  X  &gt; 0: if  X  d is larger (compared with  X  d 0 ,d 0 6 = d ), then 2.  X  &lt;  X  1: if  X  d is larger (compared with  X  d 0 ,d 3.  X  1 &lt;  X  &lt; 0: if  X  d is larger (compared with  X  d As can be seen, in case  X  &gt; 0 or  X  &lt;  X  1, the regularization term w  X   X  d and the model coefficient  X  d are inversely related to each other: larger  X  d will lead to smaller regularization coefficient w  X   X  d , and vice versa. In practice, we update w and  X  d iteratively. As a result, important features in the current iteration will tend to be penalized less in the next iteration; on the contrary, less important features will be confronted with strong penalty in future iterations. The system reaches a stationary point upon convergence.
In case  X  1 &lt;  X  &lt; 0, however, w  X   X  d and  X  d will be favorably associated with each other. In other words, relevant features in the current step will be strongly penalized in the next iteration. This obviously leads to unstable iterations and therefore we will exclude it from our parameter choice.
In the adaptive LASSO [38], the regularization weight is also inversely related to some pre-computed model co-efficient. The difference of our method is that, first, our weights are carefully tuned based on previous model coef-ficients through norm-regularization (7); second, we keep alternating instead of using a single update; third, as will be discussed, we have the freedom of annealing the strength of global regularization via the equality norm-constraint (4).
The interactive updates between models and the adaptive weights mimic a self adapting process that is expected to drive the whole system to a desired state. However, this optimization problem is non-convex, therefore in case of bad initialization, the iterations might quickly get stuck into a local optimum. In this case, dimensions with large model coefficients will keep being dominant and and dimensions with small coefficients may never have a chance to regain their magnitudes.

In order to prevent pre-mature convergence, we propose a multi-stage shrinking procedure. The basic idea is to in-troduce strong perturbations in the beginning, such that all features have the chance to be selected and compete with each other. Then we gradually  X  X ool down X  the system by using stronger and stronger ` 1 -penalties. Namely fewer and fewer features can survive in the progressive shrinking. By doing this, the system will go a series of self-adjusting micro-stages sequentially before reaching the final solution.
Suppose we initialize w with | w | =  X   X  ,  X  = 0. Then we interactively update  X  (5) and w (6) under this equality norm constraint until convergence. When this stage ends, we will start next stage of iterations with an updated norm constraint | w | =  X   X  ,  X  = 1, which imposes a stronger ` penalty. Then we iterate between  X  and w until the second stage ends. By repeating this, we keep strengthening the global ` 1 -norm regularization stage by stage, achieving an  X  X nnealing X  effect. Here each stage is indexed by  X  and is composed of iterations under | w | =  X   X  .

Depending on the choice of  X  , in order to guarantee that the global regularization strength w  X   X  will gradually in-crease, we need different strategies in tuning the  X  param-eter. (1)  X  &gt; 0:  X  will start from a large value (corre-sponding to a weak regularization) and gradually decrease; (2)  X  &lt;  X  1:  X  will start from a small value and gradually increase throughout the iterations.
In material science, annealing is a powerful heat treatment technique [31] to improve physical and chemical properties of a metal. It heats the metal to a high temperature, which gives the energy for its atoms to break the bond and dif-fuse actively within crystal lattices; a suitable temperature is then maintained and gradually cooled down, allowing the material to progress towards equilibrium state. Annealing can reduce the Gibbs-Free-Energy of the metal.

The dynamic shrinking method in Algorithm 1 very much resembles (and is indeed inspired by) an annealing process. The strength of the ` 1 -regularization can be deemed as con-trolling the temperature of the system: in the beginning stages when regularization is weak, all features have the freedom to compete and position themselves in the model, meaning that the solution is dense and the system has a high energy. When the regularization gradually enhances, the system begins to cool down, model coefficients start shrink-ing progressively, and the system energy decreases as well. The norm-constraint | w | =  X  can be deemed exactly as the as controlling the  X  X emperature X  of the system: a larger  X  imposes a weak regularization, meaning high temperature and energy status; a smaller  X  , on the contrary, enforces low temperature and energy status.

The initial temperature of annealing should be higher than metal recrystallization temperature. Similarly, we also start from a high temperature, i.e., a weak regularization such that initial model parameters are dense. This allows differ-ent features to fully compete with each other; if the solution is already sparse in the beginning, the iterations will quickly get trapped into a poor local optima. In our context, the densest initial solution is the ordinary least-square solution, namely a sparse regression with vanishing ` 1 -penalties.
It is worthwhile to point out the difference between our method and simulated annealing [15]. Simulated annealing is a probabilistic searching technique that can be applied to any pre-defined objective function to find its global optimum [25]; in comparison, we target on more effective sparse re-gression and feature selection by reformulating the adaptive LASSO with a progressive, multi-stage shrinking mechanis-m, thus bearing an analogy to the  X  X nnealing X  process.
Suppose we have a number of k tasks, each task is com-posed of the design matrix X k  X  R n k  X  D and target y k R k  X  1 ; we use shared adaptive weight w = [ w to regularize over all the K tasks, as Algorithm 1: Adaptive LASSO + dynamic shrinking
Input : multi-task data Z = { X k , y k } K k =1 ; initial norm
Output : solution path for all the k tasks begin 2 while model is unempty do 3 t = 0; 4 while Convergence do 7 t = t + 1; 10  X  =  X  + 1 Here,  X  k  X  R D  X  1 is the model coefficients for the k th task for k = 1 , 2 ,...,K , and B = [  X  1 ,  X  2 , ..., X  k ]. Through similar derivations, we have the following procedures.

Fix w and solve  X  k  X  X  . Then this becomes K indepen-dent adaptive LASSO problems, for k = 1 , 2 ,...,K which can be easily converted to a standard LASSO.

Fix  X  k  X  X  and solve w . This then becomes the following constrained optimization problem Problem (11) has a closed form solution,
As can be seen, the proposed method can conveniently handle multi-task learning scenarios, thanks to the flexibility of using an adaptive regularization weight. In the following we introduce two routines to simplify our presentation of the algorithm. Using these notations, we summarize the algorithm in Algorithm 1, which is applicable to both single and mul-tiple tasks. Here the upper index  X  denotes outer iterations, where each iteration  X  corresponds to a stage with distinct value of  X  ; the lower index t indexes the inner iterations in-side each stage. The  X  is a shrinking factor that is smaller than 1 when  X  &gt; 0, and a growing factor that is larger than 1 when  X  &lt;  X  1. The iteration will keep going until all fea-tures are removed from the model. Then a cross-validation can be used to select the best model along the solution path.
In case of classification tasks with high-dimensional fea-tures, one can consider the sparse logistic regression [27], min  X  P n i =1 ln 1 + exp[  X   X  &gt; x i  X  y i ] + | w  X  | efit from our dynamic shrinking approach as well. Similar-ly, the iterative procedures will decompose into two sub-problems: when fixing w , it becomes a standard logistic re-gression with adaptive ` 1 -regression; and when fixing  X  , the problem is identical to (6) and can be solved accordingly.
In [4], an interesting, re-weighted LASSO algorithm was proposed to improve the sparsity of LASSO. After solving a standard LASSO at time t (starting from t = 0), it will compute a set of adaptive regularization weights w ( t +1) the ` 1 regularization. Here is a small number to ensure that a zero component in  X  does not strictly prohibit a nonzero estimate at the next step. As can be seen, the algorith-m repeatedly performs the adaptive LASSO by using the absolute value of the inverse of previous model coefficients as the regularization weights for the next iteration. Such iterations may easily get trapped in local optimal solution due to the sensitivity of the convergence on initial values. In comparison, our approach avoids pre-mature convergence by continuously adjusting the global regularization strength.
In case there exists grouping structures among input vari-ables, the LASSO algorithm has been extended to recover such grouping. For example, the elastic net algorithm pe-nalizes both the ` 1 and ` 2 norm of the model [39], which encourages a grouping effect such that strongly correlated predictors tend to be in or out of the model together. When the groupings of the inputs are available as prior knowledge, the group LASSO [34] penalizes the ` 2 -norm of each group as a unit for variable selection, using the following optimiza-tion framework, Here, the predictors are assumed to have l groups with group size p l ; X l represents predictors of the l th group, with corre-sponding coefficient  X  l . The group LASSO achieves sparse feature selection at the group level: depending on  X  , an en-tire group of predictors is either selected simultaneously in the model, or will be removed together.
Multi-task learning has drawn considerable interest in da-ta mining [2, 3]. It assumes that different tasks share some common structures, and enforcing the task relatedness can help improve the learning performance. We focus on sparse multi-task learning [16, 23, 34, 17], namely joint feature se-lection in multiple tasks needs to be performed.

The ` 1 /` 2 penalty of group lasso has been used to recover inputs that are jointly relevant to all of the outputs, or tasks, by applying the ` 2 -norm to outputs instead of groups of in-puts.For example, [23] proposed to penalize the sum of the ` -norms of the blocks of coefficients associated with each feature across tasks, which is called mixed-norm or ` regularization. One appealing property is that it encour-ages multiple predictors from different tasks to share similar parameter sparsity patterns. Let B = [  X  1 ,  X  2 , ..., X  define B i  X  R 1  X  K as the i th row in the model coefficient matrix B . Then the objective function of the ` 1 /` q regular-ization is as follows: Here k B k ` When q = 2, we have a block ` 1 /` 2 norm, which is identi-cal to the group LASSO [34]. Other choices have also been studied such as ` 1 /`  X  [30]. The mixed-norm regulariza-tion encourages simultaneous feature selection across tasks. Namely, a given feature is either selected as relevant for all the tasks X  output simultaneously, or is excluded all-together for all the tasks. Such regularization is very effective if the underlying task relation satisfies such assumption. However it can be too restrictive in some other applications.
In [17], an adaptive multi-task LASSO framework was proposed which combines adaptive regularization with the mixed-norm regularization, as min Here L is the loss function; the second term is an adaptive LASSO that imposes ` 1 -norm penalty with strength  X  1  X   X  |  X  | 1 from all tasks; the third term is a mixed-norm regular-ization together with an adaptive weights, which imposes the penalty  X  2  X   X  j k  X  j k 2 ; the last term is a normalization factor on the conditional probability p (  X  |  X , X  ). The whole frame-work has an elegant Bayesian interpretation. It achieves sparsity both across tasks and within each task. However, the regularization weights are assumed to be spanned by features from extra domains with prior knowledge, which might not be available in general multi-task learning; on the other hand, it separates the learning of the model and the regularization profile.
The dynamic shrinking process of the proposed algorith-m is illustrated in Figure 1, where the strength of the ` regularization gradually increases, leading to a solution path. Due to the interplay between adaptive weights w and mod-els coefficients B , the whole solution path of B is connected: each solution B is affected by its predecessor. This means, the effect of system evolution is inherited from one stage  X  to the next stage  X  + 1, or from one iteration t to the nex-t iteration t + 1 inside a single stage. In other words, the solutions have to be obtained in a sequential manner. For the standard LASSO, in comparison, the solution path can actually be obtained by training a number of independent LASSO X  X  with different  X   X  X .

Note that the solution path of LASSO can also be ob-tained in a sequential manner by using the least angle re-gression [8], which fully exploits the piecewise linear struc-tures of the solutions. However, an important difference is that, our approach will re-define the LASSO regression in each iteration. To see this, note that any adaptive LASSO problem min k X  X   X  y k 2 2 + | w  X  | 1 can be converted to a LASSO min k XW  X  1  X   X  y k 2 2 + |  X  | 1 where  X  = w  X  and W = diag ( w ). In our approach, since the regularization weight vector w keeps updating, therefore each iteration is equivalent to a LASSO problem with continuously rectified data XW  X  1 , making it different from traditional solution path. It will be a very interesting topic to explore the solu-tion path structures of our dynamic shrinking approach, so as to make it more computationally efficient.
In this section, we perform extensive experiments to ex-amine the performance of our approach, in both simulation data sets and real-world bioinformatics application.
Altogether, we implement and compare the following al-gorithms: 1. Standard LASSO algorithm [29]: We use the LARS 2. Adaptive LASSO [38]: We use inverse of ridge regres-3. Adaptive LASSO-II [13]: We use inverse of the marginal 4. Multi-task LASSO [23]: We choose different values of 5. Re-weighted LASSO [4]: We choose different values of 6. Our approach: We simply choose  X  = 1, an initial
We use the following measurements to evaluate the per-formance of different methods: 1. Specificity (SPC) versus true-positive-rate (TPR) (SPC 2. Cross-validated mean-squared-error (CV-MSE): we re-3. Cross-validated F-score (CV-Fscore): we comput the
We use the SLEP sparse learning package [18] to imple-ment our approach. All codes are written in Matlab and run on a cluster server with 2.2  X  2.8 GHz CPU. the global strength of ` 1 -regularization grows stronger.
First we use single task sparse regression problem to test the performance of different methods. Following the details in [4], we simulate the data set of n = 100 samples with dimensionality D = 256, and the design matrix is an n-by-d i.i.d. Gaussian entries. Among the 256 features, only p = 20 are relevant features with randomly chosen non-zero  X  en-tries from a zero-mean unit-variance Gaussian distribution. We then use the linear relation y i = x i  X  + N (0 , X  2 ) to gen-erate the response y .

Results are shown in Figure 2, where each algorithm is marked by their indexes specified in Section 5.1. In this data set, multi-task LASSO (method (4)) is identical to s-tandard LASSO (method (1)) and therefore is removed. As can be seen, our approach is superior in terms of picking out relevant covariates throughout the whole solution path, demonstrating the effectiveness of annealed sparsity in im-proving the sparse model selection. In the meantime, the cross-validated mean-squared-error and F-score of our ap-proach are also the best among competing methods.
In this experiment we simulate data with K = 5 tasks, each task has n = 40 samples with dimension D = 100. For each task design matrix is an i.i.d Gaussian distribution, and we assume the linear relation y k i = x k i  X  k + N (0 , X  the relevant features, the corresponding entries in  X  k  X  X  are randomly chosen from the distribution 3 + N (0 , 1). Here we generate two types of multi-task data. 1. Multitask-I: strict group-wise sparsity. We choose p = 2. Multitask-II: mixed sparsity patterns. We then intro-
We report the results in Figure 3 and Figure 4. We can observe that our approach has the best performance in terms of both feature selection (F-score) and regression (predict-ing error), on both types of multi-task data sets. The adap-tive LASSO-II [13] using the inverse of the marginal regres-sion coefficients as adaptive weights seems to perform better than the adaptive LASSO using ordinary-least-squares co-efficients. The LASSO considers each task separately and can be less accurate. Another observation is that, in case of mixed sparsity patterns, all algorithms perform worse than in the case of strict group-wise sparsity, in particularly judged by feature selection accuracy (F-score). Neverthe-less, our approach still performs the best among competing methods.

We also experiment with different noise levels to test the noise tolerance shown in Figure 5. As can be observed, our approach is competitive under different noise levels.
In this section, we study properties of the proposed method from different perspectives.
First, to have a direct picture on the shrinking behaviour of our method, we plot the solution path of our approach in Figure 6. Here we use the multi-task simulation data with group wise sparsity under the highest noise level (  X  = 3). To prevent visual cluttering, we only plot the solution path for one task, and we only demonstrate 10 of the 20 relevant features and all the rest 80 irrelevant features.

We have several interesting observations. First, note that when the regularization is relatively weak, the solution paths are all smooth; when the regularization becomes stronger, solution paths begin to show clear stage-wise behaviour: the coefficient value is relatively stable within each stage, but may change significantly across stages (due to the change of  X  ), indicating that the system state goes through significant changes. Second, the solution path is quite non-monotonic. With the growing strength of regularization ( 1  X  ), we can ob-serve that the model coefficients first expand and then grad-ually shrink. This is in sharp contrast to the solution path of the LASSO, whose solution path almost monotonically shrinks with growing regularization.

The non-monotonic shrinking can be quite beneficial in practice. Note that in the beginning stage, both relevant and irrelevant features have large model coefficients, mean-ing that they are difficult to differentiate. When the regu-larization grows stronger, interestingly, we can see that most relevant features begin to expand, while most irrelevant fea-tures begin to shrink. This becomes particularly obvious around 1  X   X  10  X  4 . 5 , where the majority of irrelevant fea-tures suddenly shrink to zero, while relevant features have a jump increase in their coefficients. This is quite beneficial in practical feature selection problems.

Competing mechanism of annealing . In the begin-ning, under weak global ` 1 -penalty, model coefficients are dense, indicating that the  X  X nergy X  of the system is distribut-Figure 6: Solution path for dynamic shrinking. Thick colored lines represent relevant features, and dashed lines for irrelevant features. Vertical line in the middle marks change of display scales (for visual clarity). Regularization increases from left to right. ed somewhat uniformly among competing features. As the regularization grows, the system begins cooling toward a lower-energy state; in the meantime, energy distribution be-comes more concentrated. That is, competitive features (in terms of better prediction in the least-square) will attrac-t more energy from irrelevant features, making the latter shrink. This is why we observe significant growth of some feature magnitude even though the global sparsity enhances. Such energy re-allocation through annealing solves the fea-ture selection problem in an effective manner.
In this section, we study how the performance of our ap-proach is affected by the following two parameters: the  X  that controls the initial  X  X emperature X  of the system; the shrinking factor  X  that controls the  X  X ooling rate X  of the sys-tem. The performance is measured by the F-score using the multitask-I data set with  X  = 1. (a) Initial temperature (  X  0 ) (b) Shrinking factor (  X  ) Figure 7: Performance of our method versus differ-ent parameters.

First, we examine the performance w.r.t.  X  0 chosen from some grid points { 10 10 , 10 9 ,..., 10  X  3 } . As can be seen from Figure 7(a), in a wide range of high initial temperatures, the performance of our approach is quite satisfactory; when the initial temperature is below a certain value, the performance quickly drops. This coincides with our expectation, since a low initial temperature fails to start the whole system with sufficient energy and as a result the iterations could quickly stop at a local optima. In practice, we simply choose  X  0 a large value such as 1 e 8.

In Figure 7(b), we examine the performance of our ap-proach w.r.t. the shrinking factor. As can be observed, more aggressive shrinking scheme (  X   X  0) makes the performance worse; in comparison, milder shrinking scheme (  X   X  1) al-lows the system to evolve slowly such that the  X  X nnealing X  is sufficient, but it is computationally more expensive. In between efficiency and the quality of annealing.
In this section, our task of expression quantitative trait loci (eQTL) is to identify genes whose DNA copy (DNA copy-number data as input ) are associated with the mR-NA expression level of six P53 target genes (normalized ex-pression data as response ). Note that P53 is a well-known tumor suppressor gene. The data set is obtained from Can-cer Cell Line Encyclopedia (CCLE) project 1 , with DNA copy-number of 23316 genes across 1011 samples. The six target genes include CDKN1A, PMAIP1, BBC3, MSH2, PML and PRKAA2 , which are of particular relevance to melanoma as suggested by biological experts [32]. The regulatory genes identified through our regression analysis will then help un-derstand the whole P53 regulation mechanism for cancer, and in particular melanoma.

In the application, we treat the eQTL of six P53 tar-get genes as six tasks, since we believe that the regulating processes on all these melanoma-related genes should share some underlying mechanism. We have used the 5-fold cross-validated error to select the best model. Table 1 reports the 5-fold CV-MSE for all competing methods, from which we can see that our method achieves the lowest fitting error. This fully illustrates the superior performance of the pro-posed dynamic shrinking scheme in high-dimensional, real-world multi-task learning problems.

We further explore whether the selected genes by our method makes biological sense, by following the common practice of gene set enrichment analysis (GSEA) [28]. Specif-ically, we rank the selected genes in each task based on the regression coefficients and feed the ranking to GSEA2-2.2.2 software. We consider the canonical pathways/gene sets pro-vided by the Molecular Signatures Database 2 . For each task, GSEA returns a number of significant pathways/gene-sets under false discovery rate (FDR) 5%, and we pick one ex-ample pathway to illustrate in Figure 8. Here, the pathway name is marked on top of each figure; the red bar denotes the ranking of the  X  -coefficient for each task, and the black lines mark the genes belonging to selected pathway. Our approach identifies more than 100 significant pathways for each task, which is much larger than other methods.
These significant pathways based on our computed gene ranking are very relevant to cancers and/or melanoma, as discussed below: this ranking, via gene enrichment analysis on the CCLE data. Adaptive LASSO-II 1.3701 Re-weighted LASSO 1.5507 The above results show that our approach not only predicts target gene expressions more accurately, but also identifies biologically meaningful molecular predictors.
In this paper, we propose a dynamic shrinking framework to compute adaptive regularization in sparse (multi-task) re-gression. Our key contribution is to introduce the concept of annealing in sparse model estimation and feature selec-tion, through an iterative, self-adapting and self-competing mechanism. Empirically, the annealing process can improve the accuracy of models in particular in multi-task problem-s. In the future, we will study how to explore underlying structures of the dynamic solution path to make it computa-tionally more efficient; we also want to incorporate explicit, task-level constraints to make the learned model coefficients more useful for subsequent learning tasks. Finally, we are trying to build a more rigorous, mathematical connection between our approach and annealing so as to fully charac-terize the behaviour of system evolutions.
 To derive (7), we use the Lagrangian of (6). We first drop the non-negativity constraint. Then the Lagrangian can be written as By setting  X  X   X  X  Plugging the above relation in the constraint P d w d =  X  , then we have so we have Plugging the above equation in (14), we finally have Since  X  d = P k |  X  d k | X  0, and  X   X  0, the solution will satisfy the non-negative constraints automatically. This completes the proof of solution (13).

