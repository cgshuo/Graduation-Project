 In natural language understanding research with data-dri ven techniques, data labeling is an essential but time-consuming and costly process. To alle vi-ate this effort, various semi-supervised learning al-gorithms such as self-training (Yaro wsk y, 1995), co-training (Blum and Mitchell, 1998; Goldman and Zhou, 2000), transducti ve SVM (Joachims, 1999) and man y others have been proposed and success-fully applied under dif ferent assumptions and set-tings. The y all aim to impro ve classication accu-rac y by exploiting more readily available unlabeled data as well as labeled examples. Ho we ver, these iterati ve training methods have shortcomings when trained on data with imbalanced class distrib utions. One reason is that most classiers underlying these methods assume a balanced training set, and thus when one of the classes has a much lar ger number of examples than the other classes, the trained classier will be biased toward the majority class. The imbal-ance will propagate through subsequent iterations, resulting in a more skewed data set upon which a further biased classier will be trained. To exploit unlabeled data in learning an inherently skewed data distrib ution, we introduce a semi-supervised classi-cation method using contrast classiers, rst pro-posed by Peng et al. (Peng et al., 2003). It approx-imates the posterior class probability given an ob-serv ation using class-specic contrast classiers that implicitly model the dif ference between the distrib-ution of labeled data for that class and the unlabeled data.

In this paper , we will explore the applicabil-ity of contrast classiers to the problem of semi-supervised learning for identifying agreements and disagreements in multi-party con versational speech. These labels represent a simple type of  X speech act X  that can be important for understanding the interac-tion between speak ers, or for automatically summa-rizing or bro wsing the contents of a meeting. This problem was pre viously studied (Hillard et al., 2003; Galle y et al., 2004), using a subset of ICSI meet-ing recording corpus (Janin et al., 2003). In semi-supervised learning, there is a challenge due to an imbalanced class distrib ution: over 60% of the data are associated with the def ault class and only 5% are with disagreements. The contrast classier approach was developed by Peng et al and successfully applied to the problem of identifying protein disorder in a protein struc-ture database (outlier detection) and to nding arti-cles about them (single-class detection) (Peng et al., 2003). A contrast classier discriminates between the labeled and unlabeled data, and can be used to approximate the posterior class probability of a given data instance as follo ws. Taking a Bayesian approach, a contrast classier for the j -th class is dened as: where h class j in the labeled data, g ( x ) is the distrib ution of unlabeled data, and r of unlabeled data compared to the labeled data for class j . This discriminates the class j in the la-beled data from the unlabeled data. Here, we con-strain r class distrib ution skew, as described belo w. Re writ-ing equation 1, h cc j ( x ) Then, the posterior probability of an input x for class j , p ( j | x ) , can be approximated as: where q be approximated by the fraction of instances in the class j among the labeled data. By substituting eq. 2 into eq. 3, we obtain: Notice that we do not have to explicitly estimate g ( x ) . Eq. 4 can be used to construct the MAP clas-sier: To approximate the class-specic contrast classier , cc j ( x ) probability , such as a neural net, logistic regression, or an SVM with outputs calibrated to produce a rea-sonable probability .

Typically a lot more unlabeled data are avail-able than labeled data, which causes class imbalance when training a contrast classier . In a supervised setting, a resampling technique is often used to re-duce the effect of imbalanced data. Here, we use a committee of classiers, each of which is trained on a balanced training set sampled from each class. To compute the nal output of the classier , we imple-mented four dif ferent strate gies.  X  For each class, average the outputs of the con- X  Average only the outputs of contrast classiers  X  Use a meta classier whose inputs are the out- X  Classify an input as the majority class only
Another benet of the contrast classier approach is that it is less affected by imbalanced data. When training the contrast classier for each class, it uses the instances in only one class in the labeled data, and implicitly models the data distrib ution within that class independently of other classes. That is, given a data instance, the distrib ution within a class, h ( x ) , determines the output of the contrast classi-er for the class (eq. 1), which in turn determines the posterior probability (eq. 4). Thus it will not be as highly biased toward the majority class as a clas-sier trained with a collection of data from imbal-anced classes. Our experimental results presented in the next section conrm this benet. We conducted experiments to answer the follo wing questions. First, is the contrast classier approach applicable to language processing problems, which often involv e lar ge amounts of unlabeled data? Sec-ond, does it outperform other semi-supervised learn-ing methods on a skewed data set? 3.1 Featur es and data sets The data set used consists of seven transcripts out of 75 meeting transcripts included in the ICSI meet-ing corpus (Janin et al., 2003). For the study , 7 meetings were segmented into spurts, dened as a chunk of speech of a speak er containing no longer than 0.5 second pause. The rst 450 spurts in each of four meetings were hand-labeled as either posi-tive (agreement, 9%), negative (disagreement, 6%), bac kchannel (23%) or other (62%).

To approximate cc Machine (SVM) that outputs the probability of the positi ve class given an instance (Lin et al., 2003). We use only word-based features similar to those used in (Hillard et al., 2003), which include the num-ber of words in a spurt, the number of keyw ords associated with the positive and negative classes, and classication based on keyw ords. We also ob-tain word and class-based bigram language models for each class from the training data, and compute such language model features as the perple xity of a spurt, probability of the spurt, and the probability of the rst two words in a spurt, using each language model. We also include the most lik ely class by the language models as features. 3.2 Results First, we performed the same experiment as in (Hillard et al., 2003) and (Galle y et al., 2004), using the contrast classier (CC) method . Among the four meetings, the data from one meeting was set aside for testing. Table 1 compares the 3-class accurac y of the contrast classier with pre vious results, mer g-ing positive and bac kchannel class together into one class as in the other work. When only lexical fea-tures are used (the rst three entries), the SVM-based contrast classier using meta-classiers gives the best performance, outperforming the decision tree in (Hillard et al., 2003) and the maximum en-Table 1: Comparison of 3-w ay classication accu-rac y on lexical (le x) vs. expanded (exp) features sets.
 Table 2: Comparison of the classication perfor -mance Method 3-w ay A/D A/D unsupervised 79 8 83 cc 81.4 4 82.4 cc-threshold 76.7 6 85.2 cc-meta 86.7 5 81.3 cc-meta-thres 87.1 5 82.4 trop y model in (Galle y et al., 2004). It also outper -formed the SVM trained using the labeled data only . The contrast classier is also competiti ve with the best case result in (Galle y et al., 2004) (last entry), which adds speak er change, segment duration, and adjacenc y pair sequence dependenc y features using a dynamic Bayesian netw ork.

In table 2, we report the performance of the four classication strate gies described in section 2. For comparison, we include a result from Hillard, ob-tained by training a decision tree on the labels pro-duced by their unsupervised clustering technique. Meta classiers usually obtained higher accurac y, but averaging often achie ved higher reco very of agreement/disagreement (A/D) spurts. The use of thresholds increases A/D reco very , with a decrease in accurac y. We obtained the best accurac y using both meta classiers and thresholds together here, but we more often obtained higher accurac y using meta classiers only .
 Ne xt, we performed experiments on the entire ICSI meeting data. Only 1,318 spurts were labeled, and 62,944 spurts were unlabeled. Again, one of the labeled meeting transcripts was set aside as a test set. We compared the SVM trained only on labeled data Table 3: Classication performance, training on the entire ICSI data set. F is dened as 2 pr macro precision and r is the macro recall.
 with three semi-supervised methods: self-training, co-training, and the contrast classier with a meta-classier . The self-training iterati vely trained an SVM with additional data labeled with condence by the pre viously trained SVM. For the co-training, each of an SVM and a multilayer backpropagation netw ork was trained on the labeled data and the un-labeled data classied with high condence (99%) by one classier were used as labeled data for fur -ther training the other classier . We used two dif fer -ent classiers, instead of two independent vie w of the input features as in (Goldman and Zhou, 2000). Table 3 sho ws that the SVM obtained high accu-rac y, but the F measure and the recall of the smallest class, negative , is quite low. The bias toward the ma-jority class propagates through each iteration in self-training, so that only 5% of the negative tok ens were detected after 30 iterations. We observ ed the same pattern in co-training; its accurac y peak ed after two iterations (85.1%) and then performance degraded drastically (68% after ve iterations) due in part to an increase in mislabeled data in the training set (as pre viously observ ed in (Pierce and Cardie, 2001)) and in part because the data skew is not controlled for . The contrast classier performs better than the others in both F measure and negative class recall, retaining reasonably good accurac y. In summary , our experiments on agree-ment/disagreement detection sho w that semi-supervised learning using contrast classiers is an effecti ve method for taking adv antage of a lar ge unlabeled data set for a problem with imbalanced classes. The contrast classier approach outper -forms co-training and self-training in detecting the infrequent classes. We also obtain good per -formance relati ve to other methods using simple lexical features and performance comparable to the best result reported.

The experiments here kept the feature set x ed, but results of (Galle y et al., 2004) suggest that further gains can be achie ved by augmenting the feature set. In addition, it is important to assess the impact of semi-supervised training with recog-nizer output, where gains from using unlabeled data may be greater than with reference transcripts as in (Hillard et al., 2003).

