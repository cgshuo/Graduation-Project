 In this paper, we study the problem of effective keyword search over XML documents. We begin by introducing the notion of Valuable Lowest Common Ancestor (VLCA) to ac-curately and effectively answer keyword queries over XML documents. We then propose the concept of Compact VLCA (CVLCA) and compute the meaningful compact connected trees rooted as CVLCAs as the answers of keyword queries. To efficiently compute CVLCAs, we devise an effective op-timization strategy for speeding up the computation, and exploit the key properties of CVLCA in the design of the stack-based algorithm for answering keyword queries. We have conducted an extensive experimental study and the ex-perimental results show that our proposed approach achieves both high efficiency and effectiveness when compared with existing proposals.
 H.2 [ Database Management ]; H.3.3 [ Information Search and Retrieval ]: Algorithms Information Retrieval;Keyword Search; LCA; VLCA; CVLCA
Keyword search is a proven and widely accepted mech-anism for querying in document systems and World Wide Web. The database research community has recently recog-nized the benefits of keyword search and has been introduc-ing keyword search capability into relational databases[4, 6, 11, 12, 16, 18, 22, 25, 27, 28], XML databases[9, 10, 13, 17, 19, 21, 23, 26, 31] and graphs [15, 20].
 Traditional query processing approaches on relational and XML databases are constrained by the query constructs im-Copyright 2007 ACM 978-1-59593-803-9/07/0011 ... $ 5.00. posed by the language such as SQL and XQuery. Firstly, the query language themselves are hard to comprehend for non-database users. For example, the XQuery is fairly compli-cated to grasp. Secondly, these query languages require the queries to be posed against the underlying, som etimes com-plex, database schemas. These traditional querying meth-ods are powerful but unfriendly for day-to-day users. Key-word search is proposed as an alternative means of query-ing the database, which is simple and yet familiar to most internet users as it only requires the input of some key-words. Although keyword search has been proven to be effective for text documents (e.g. HTML documents), the problem of keyword search on the structured data (e.g. re-lational databases) and the semi-structured data (e.g. XML databases) is not straightforward nor well studied.
Keyword search in text documents take the documents that are more relevant with the input keywords as the an-swers, while that on relational databases will take the cor-relative records of database that contain all the keywords as the answers. However, it still remains an open prob-lem that, for XML database, what should be the answer for keyword search? The notion of Lowest Common Ances-tor (LCA) has been introduced to answer keyword queries on XML databases [13]. More recently, XRank, Meaningful LCA (MLCA), Smallest LCA (SLCA), Grouped Distance Minimum Connecting Tree (GDMCT) and XSeek have been proposed to improve the efficiency and effectiveness of key-word search against LCA in [13, 21, 31, 17, 23], respectively.
However, existing proposals on keyword search over XML databases suffer from two problems: meaningfulness and completeness of answers, and the scope of the search. First, the existing approaches, such as SLCA and XRank, return some irrelevant results or false positives as answers and may also miss some results from answers (We will give an ex-ample to describe the details in Section 2). The false pos-itive problem renders the results less meaningful while the false negative problem causes the incompleteness of answers. Second, the answer of keyword search should not be limited to just the LCAs of the keywords, and taking only LCAs as the answer of keyword search is inaccurate. Although the subtrees proposed in existing methods [17, 23], which are composed of LCAs and their relevant keywords, may be more meaningful as the answer of keyword search on XML databases, these subtrees are not compact and meaningful enough to answer keyword search and cannot accurately re-flect the essence of keyword queries.

In addition, XML documents involve fairly complicated structures, therefore it is fairly difficult to find the meaning-ful desired data, which still preserves the structure relation-ship and also conforms to the documents, for users through limited input keywords. Existing studies mainly focus on efficiency of keyword search on XML databases and usually leads to low effectiveness, and accordingly, how to discover the structure clue from the input keywords so as to improve the effectiveness is urgent to investigate. We emphasize the effectiveness of keyword search on XML databases in this paper, which is at least as important as efficiency.
To achieve our goal, we first introduce the notion of el-ementary type and propose Valuable LCA (VLCA) to ef-fectively and accurately answer keyword queries, which not only improves the accuracy of LCAs by eliminating redun-dant LCAs that should not contribute to the answer, but also retrieves the false negatives filtered out wrongly by SLCA. We then introduce a novel concept, called compact VLCA (CVLCA), and take compact connected trees as an-swers of keyword queries. Finally, we propose an effective optimization strategy for computing the CVLCAs and de-vise an efficient stack-based algorithm as a total solution. To the best of our knowledge, this is the first paper that improves the effectiveness of keyword search over XML doc-uments in considering XML schemas. To summarize, we make the following contributions:
The remainder of this paper is organized as follows. We discuss the background and our motivation in Section 2. Section 3 introduces the notion of VLCA. In Section 4, a brute-force algorithm to compute VLCAs is proposed. We introduce an optimization strategy for computing CVLCAs and design an effective stack-based algorithm in Section 5. Extensive experimental evaluations are provided in Section 6. Finally we conclude the paper in Section 7.
In this section, we review existing related proposals about keyword search, and discuss their weaknesses.
We begin first by introducing the XML data model and some notations. An XML document can be modeled as a rooted, ordered, and labeled tree. Nodes in this rooted treecorrespondtoelementsintheXMLdocument. For any node v ,  X  ( v ) denotes the label/tag of v , u  X  v ( u v )de-notes that node u is an ancestor (descendant) of node v , while u v denotes that u  X  v or u = v . u&lt;v ( u&gt;v ) denotes that u precedes (follows) v in the XML document, that is, u is before (after) v in document order, but not an ancestor (descendant) of v . For example, in Figure 1(a), paper (5) author (7), paper (12) conf (2), chair (19) &lt; name (21), and author (26) &gt; year (22).
 Given a keyword query K = { k 1 , k 2 ,  X  X  X  , k m } and an input XML document D ,weuse I i to denote the keyword list of k , i.e., the list of nodes which directly contain k i ,andwe call each node in I i the content node w.r.t. k i . I i can be retrieved by using the well-known inverted indices.
The first area of research related to our work is the com-putation of the LCA of two or more nodes, which has been studied in [14, 29]. As an extension of LCA, XRank, MLCA, SLCA, GDMCT and XSeek have recently been proposed to answer keyword queries over XML documents respectively in [13], [21], [31], [17] and [23]. We begin by formally intro-ducing the concept of Lowest Common Ancestor (LCA).
Definition 2.1. (LCA) Given m nodes n 1 , n 2 ,  X  X  X  , n m is cal led LCA of these m nodes, iff,  X  1  X  i  X  m, v is an ances-tor of node n i ,and  X  u , v  X  u , u is also an ancestor of each n , denoted as v =LCA ( n 1 , n 2 ,  X  X  X  , n m ) .

Definition 2.2. ( LCASet ) Given a query K = { k 1 ,  X  X  X  , k and an XML document D .ThesetofLCAsof K on D is, LCASet =LCA ( I 1 , I 2 ,  X  X  X  , I m ) = { v | v =LCA ( v v  X  X  i (1  X  i  X  m ) } .
 The basic idea of LCA is that, given a keyword query K = { k 1 , k 2 ,  X  X  X  , k m } and for 1  X  i  X  m ,node n i is a content node w.r.t. k i ,if v =LCA( n 1 , n 2 ,  X  X  X  , n m ), then v contains all the input keywords and should be an answer of K .For example, a user wants to search for the paper with the ti-tle containing  X  X R X  and one author being  X  X ohn X  in the XML document in Figure 1(a), and he/she can input query {  X  X R X , X  X ohn X  } .Node paper (15) is a LCA of the two in-put keywords, and it should be an answer  X  of this keyword query.

However, there is a problem of LCA. For example, con-sider another keyword query {  X  X R X , X  X om X  } , the nodes, conf (2), paper (12) and paper (15), circled by the rectangle in Fig-ure 1(a), are the LCAs (especially, conf (2) is the LCA of title (13) and author (17), which directly contain  X  X R X  and  X  X om X  respectively). However, it is easy to figure out that conf (2) should not be an answer of this keyword query, as title (13) and author (17) do not belong to the same paper. On the contrary, paper (12) and paper (15) should be the two results.
 To address the false positive problem of LCA, Meaningful LCA (MLCA)[21], Smallest LCA (SLCA) [31] and XRank [13] have been proposed. There is a difference between MLCA and other methods. MLCA assumes that the users have some knowledge of XML structures and incorporates a new function mlcas to compute all the MLCAs into XQuery, and it is not a pure keyword search method. XSeek [23] stud-ies the problem of how to infer the return clause for keyword search, however XSeek is orthogonal to our method as we mainly study the meaningfulness and completeness of key-word search in this paper. XRank and SLCA are much related to our work, we here only briefly introduce SLCA, which is defined as follows.

Definition 2.3. ( SLCASet ) Given a keyword query K = { k k ,  X  X  X  , k m } and an XML document D , the set of SLCAs of K on D is, SLCASet =SLCA( I 1 , I 2 ,  X  X  X  , I m )= { v | v  X   X  X  X  , I m ), and  X  u , v  X  u , u  X  LCA( I 1 , I 2 ,  X  X  X  ,
The basic idea behind SLCA is that, if node v contains all the input keywords, its ancestors will be less meaningful than v . Hence, SLCA introduces the concept of the small-est tree, which is a tree that contains all the keywords but contains no subtrees which also contain all the keywords. For example, although conf (2)  X  LCASet of query {  X  X R X ,  X  X om X  } on the XML document in Figure 1(a), it is not in SLCASet ,as paper (15)  X  LCASet and conf (2)  X  paper (15). Hence, SLCASet = { paper (12), paper (15) } of this keyword query.
However, there are still two problems, false positive (i.e., taking some irrelevant nodes as answers) and false negative (i.e., missing some correct resu lts from answers), of SLCA. For example, in Figure 1(b), consider query {  X  X ML X , X  X ob X  issued on the XML document, paper (12) should be an an-swer, while, paper (5), which also contains the two keywords, should be another answer. However, paper (5) is an ancestor of paper (12) ( paper (5)  X  paper (12)), therefore paper (5) will not be a valid SLCA according to Definition 2.3. Hence, paper (5) will not be in SLCASet and will be absent from the final answers of SLCA. Therefore, SLCA causes a seri-ous problem, false negative. For another example, suppose a keyword query, {  X  X ML X ,  X  X ohn X  } is issued on the XML document in Figure 1(c), conf (2) and paper (23), the nodes enclosed by rectangles, are both their SLCAs. It is easy to figure out that conf (2) should not be the answer of this key-word query, because title (6) and author (18) do not belong to the same paper. Therefore, SLCA causes another prob-lem, false positive. We mainly address these two problems in this paper as accurate answers to keyword queries are vital to the meaningfulness of keyword search.
DISCOVER [18], BANKS [6] and DBXplorer [4] are sys-tems built on top of relational databases. DISCOVER and DBXplorer output trees of tuples connected through primary-foreign key relationships that contain all the keywords of the query, while BANKS identifies connected trees in a labeled graph by using an approximation to the Steiner tree prob-lem, which is an NP-hard problem. Liu et al [22] proposed a novel ranking strategy to solve the effectiveness problem for relational database, which employs phrase-based and concept-based models to improve search effectiveness. Luo et al [25] presented a more effective ranking method on re-lational databases by adopting the concept of virtual docu-ment. More recently, Sayyadian et al [28] introduced schema mapping into keyword search and proposed a method to an-swer keyword search across heterogenous databases. Ding et al [11] employed dynamical programming to improve the ef-ficiency of identifying the Steiner trees, while Guo et al [12] proposed data topology search to retrieve meaningful struc-tures from much richer structural data  X  biological databases. [20] and [15] studied the problem of keyword search over graphs by employing the techniques of bidirectional expan-sion and graph partition respectively.

XRank [13] and XSEarch [10] are systems facilitating key-word search for XML databases, which return subtrees as answers for the keyword queries. However, XRank does not return connected trees to explain how the keywords are con-nected to each other. Furthermore, only the most specific result is output. They also present a ranking method which, given a tree T containing all the keywords, assigns a score to T using an adaptation of PageRank for XML databases. Their ranking techniques are orthogonal to the retrieval and, hence, can easily be incorporated in other works. XSEarch focuses on the semantics and the ranking of the results and, during execution, it uses an all-pairs interconnection index to check the connectivity between the nodes, which are very inefficient for large XML documents. Hristidis et al [17] proposed GDMCT, which generated the grouped subtrees to answer keyword queries.
In this section, we introduce the notion of Valuable Low-est Common Ancestor (VLCA), and illustrate how to em-ploy this semantics in effectively answering keyword queries. Moreover, we propose a novel numbering scheme of Mean-ingful Dewey Code (MDC) to accelerate computing VLCAs.
The problem of SLCA is that, it will take SLCA of content nodes w.r.t. given keywords, even if certain content nodes may be irrelevant between each other, as answers, and this will violate the constraint of the DTD (or schema) w.r.t. an XML document and lead to some errors. For example, in Figure 2(c), although conf (2) is SLCA (LCA) of title (6) and author (18), conf (2) should not be an answer of the keyword (a) An XML document (b) DTD of (a) Figure 2: An example XML document and its DTD query {  X  X ML X ,  X  X ohn X  } , because they are descendants of different papers . Based on above observations, we propose the concept of Valuable LCA (VLCA) to address this prob-lem and we begin by introducing two notions as follows.
Definition 3.4. (Elementary Type) An Elementary Type of a node in an XML document is its label/tag in the DTD (or schema).

Definition 3.5. (Homogenous/Heterogenous) Given two nodes u , v ,and w =LCA( u , v ). uSet and vSet are two sets of nodes in the paths of w  X  u and w  X  v respectively. Let wSet = uSet  X  vSet . u and v are heterogenous (denoted as u  X  v ), iff,  X  u  X  wSet , v  X  wSet , u and v are of the same elementary type, i.e.,  X  ( u ) =  X  ( v ) ,except u and v maybe having the same elementary type. On the contrary, u and v are homogenous (denoted as u  X  v ), iff, there are no two nodes of the same elementary type, except u and v .
Example 3.1. Nodes paper (5) and paper (15) in Figure 1( c ) are of the same elementary type as they have the same label. LCA of title (6) and author (18) is conf (2). As paper (5) and paper (15) are in the paths, conf (2)  X  title and conf (2)  X  author (18) respectively, so title (6)  X  author On the contrary, author (17)  X  author (18), because there are no other two nodes in { paper (15), author (17), author (18) with the same elementary type, except themselves.
Based on the concept of homogenous/heterogenous, we introduce a novel semantics, Valuable LCA, to answer key-word search.

Definition 3.6. (Valuable LCA) Given m nodes n 1 , n 2 ,  X  X  X  n m , v =LCA( n 1 , n 2 ,  X  X  X  , n m ). VLCA( n 1 , n 2 ,  X  X  X  these m nodes are homogenous, that is,  X  1  X  i&lt;j  X  m, n
Definition 3.7. ( VLCASet ) Given query K = { k 1 , k 2 , and an input XML document D .ThesetofVLCAsw.r.t. K and D ,is, VLCASet =VLCA( I 1 ,  X  X  X  , I m )= { v | v =VLCA( v ), v  X  X  i } .

LCASet is the set of the nodes, which contain all of the input keywords. SLCASet is a subset of LCASet , which elim-inates the LCAs that have LCA descendants. VLCASet can avoid the false positives and false negatives introduced by SLCA, and is a more accurate subset of LCASet to answer keyword queries. To describe how each result matches a key-word query, we introduce a meaningful concept as defined in Definition 3.8. Each result is represented as a connected subtree, which is rooted at a VLCA and contains the corre-sponding content nodes so that each result is self-explained and can explain how it matches the keyword query. Definition 3.8. (Answer of keyword search) Given a query K = { k 1 , k 2 ,  X  X  X  , k m } and an XML document D . K ( D  X  ( v 2 ): c 2 ,  X  X  X  ,  X  ( v m ): c m ) | X  v i  X  X  i , r =VLCA( v where c i denotes the text content that v i contains. } .
Existing proposals on keyword search usually focus on ef-fectively computing LCASet or SLCASet , which cannot de-scribe how each result matches a keyword query. In con-trast, the tuple ( r ;  X  ( v 1 ): c 1 ,  X  ( v 2 ): c 2 ,  X  X  X  method, not only preserves the structure information ( r and v ), but also reflects the user desired data ( c i ). However, to compute VLCAs, we need to determine whether two nodes are homogeneous, which is cost-efficient through navigat-ing the XML document, while the all-pairs interconnection index proposed in [10] is very expensive for large XML doc-uments. Therefore, Meaningful Dewey Code (MDC) is in-troduced to address this issue in next sections.
To effectively compute VLCAs, we introduce a novel num-bering scheme, MDC, which is inspired from Dewey code in [24], [30]. Generally, there is a corresponding DTD (or schema) associated with an XML document, which describes the document type definition. A DTD is typically much smaller than its corresponding XML document, therefore it is easier to be manipulated. Even if there does not exist a DTD, we can extract one from the XML document. For example, in Figure 2, ( a )isanXMLdocumentand( b )is the DTD extracted from this XML document.

Given an XML document, we number/encode its nodes based on the corresponding DTD. Let parent ( n )denote the parent of n and presib ( n ) denote the preceding sibling (neighboring) of n . Suppose the MDC of the root is and C denotes the MDC of node n , we can encode each node from the root to the leaf as follows: for any node n ,itsMDCis its parent X  X  MDC, C parent ( n ) , concatenated with an assigned and ordered number O n , i.e., C n = C parent ( n )  X O n . Without of the children of parent ( n )inDTDand  X  ( n )isthe k -th label, we can compute O n and C n through Equations (3-1) and (3-2) respectively. It is obvious that O n % m = k ,that is, the siblings with the same label will get the same re-mainder when divided by the total number of distinct labels among their siblings. More importantly, MDC captures the following properties: i) Node a is an ancestor of node d ,iff, C a is a prefix of ii) Node a follows (or precedes) node b iff C a is greater (or iii) Given the MDC of a node, we can deduce its ancestors X 
Lemma 3.1. Given two nodes, u and v , w =LCA( u , v ), iff, C w =LCP( C u , C v ), where LCP( C u , C v ) denotes the longest common prefix of C u and C v .

Lemma 3.2. Given m nodes, v 1 ,  X  X  X  , v m , w =LCA( v 1 , v  X  X  X  , v m ), iff, C w =LCP( C v 1 , C v 2 ,  X  X  X  , C v m ), where LCP( C v m ) denotes the longest common prefix of C v 1 , C v 2 , i )and ii ) are obvious according to the encoding strategy. Based on them, we introduce Lemma 3.1 and Lemma 3.2 to compute the LCA of two or more nodes. iii )isthekey property of MDC different from the general Dewey code. Given the MDC of node n , we demonstrate how to infer the labels of the ancestors of n as follows. Since MDC of the root is always , we deduce the labels iteratively form the root, and here we only introduce how to infer the label of a given node according to its MDC and its parent X  X  la-bel. Consider the MDC of node n is C parent ( n )  X O n ,andits parent X  X  label,  X  ( parent ( n )), has been obtained through it-eration. Suppose the distinct labels of parent ( n ) X  X  children are, orderly, l 0 , l 1 ,..., l m  X  1 ,whichcanbegottenfromthecor-responding DTD. We can compute the order of  X  ( n )among these labels, i.e., O n % m , and accordingly get its label, i.e., l n % m . Hence, given the MDC of a node, we can deduce the labels of its ancestors from the root to itself iteratively.
When checking whether two nodes u , v are homogenous or not, we first compute their LCA, w , based on Lemma 3.1, and then deduce the labels of nodes on w  X  u and w  X  based on the property iii ) of MDC, finally check whether there are two distinct nodes with the same elementary type in the two paths. Moreover, we introduce an optimization technique to check whether two nodes are homogenous or not as stated in Lemma 3.3.

Lemma 3.3. Given two nodes u , v , w =LCA( u , v ), uSet , vSet are two sets of the nodes in the paths of w  X  u and w respectively. Let wSet = uSet  X  vSet , lSet = {  X  ( u ) u and v are heterogenous, iff, | wSet | -|{  X  ( u ) } X  X   X  ( v ) while u and v are homogenous, iff, | wSet | -|{  X  ( u ) } X  X  | lSet | .

Lemma 3.4. Given m nodes v 1 , v 2 ,  X  X  X  , v m , w =LCA( v v ), vSet i is the set of nodes in the path w  X  v i .Let wSet =1 vSet i , lSet = {  X  ( u ) | u  X  wSet } .The m nodes are het-erogenous, iff, | wSet | -( m -| X  m i =1 {  X  ( v i ) }| m nodes are homogenous iff | wSet | -( m -| X  m i =1 {  X  ( v
We can adopt Lemma 3.3 to check whether two nodes are homogenous or not. Consider d is the depth of an XML document, the complexities of computing uSet and vSet are both O( d ), while the complexity of computing wSet through merging them is also O( d ). To compute lSet we need to eliminate the duplicates and the complexity is O( d log( d )). To sum up, the complexity of checking whether two nodes are homogenous or not is O( d log( d )) as formal-ized in Lemma 3.3. Consider checking whether m nodes are homogenous, we need to check whether any two nodes among them are homogenous. As there are m 2 combina-tions, the complexity is O( m 2 d log( d ))=O( m 2 d log( d )). We can reduce it to O( md log( md )) as formalized in Lemma 3.4, where the complexities of computing vSet i , wSet and lSet are O( d ), O( m log( m ) d )andO( md log( md )) respectively. To further illustrate how to com pute VLCAs, we give a running example as shown in Example 3.2.

Example 3.2. Consider the XML document in Figure 2 ( a ) and its DTD in Figure 2 ( b ) .MDCof conf , i.e., the first child of the root node( bib ), is 0 according to Equation (3-2). Node conf (0) has four child labels, name,year,paper,chair thus m =4. As name is the first child of conf (0), so O name according to Equation (3-1) and C name =0.0. As year is the second child label of conf (0) and O name % m = 0 &lt;k (1) , so O hence C paper 2 =0.6. Accordingly, we can encode the nodes in the document as illustrated in Figure 2(a).
 Given an MDC, 0.6.1, its ancestors X  MDCs are , 0 , 0 . 6 . importantly, we can deduce the labels of 0 . 6 . 1  X  X  ancestors based on the DTD. Since the root is bib ,thelabelof 0 . 6 . 1  X  X  ancestor at level 0 is bib (the level of the root is 0). bib has only one child label, i.e., conf , in the DTD, and as the assigned and ordered number of 0 . 6 . 1  X  X  ancestor at level 1 (
O 1 )is0,and O 1 % 1 =0, so the ancestor of 0 . 6 . 1 at level 1 is conf .Node conf (0) has four ( m =4) distinct child la-bels, orderly name,year,paper,chair according to the DTD. As the assigned and ordered number of 0 . 6 . 1  X  X  ancestor at level 2 ( O 2 )is6,and O 2 % m =6%4=2, so the ancestor of 0 . 6 . 1 at level 2 is paper . In the same way, as paper three distinct child labels, orderly title,author,bib ,and O % m = 1 %3= 1 , so the label (at level 3) of 0 . 6 . 1 is Therefore, the labels of 0 . 6 . 1  X  X  ancestors form the root to itself, are bib,conf,paper,author .

When checking whether u (0.2.0) and v (0.6.4) are homo-geneous or not, we first compute their LCA, w ( C w = 0) ,and then deduce the labels of the nodes on the paths w  X  u and w  X  v , which are conf,paper,title and conf,paper,author respectively. Accordingly we can get wSet , { conf (0), paper title (0.2.0), paper (0.6), author (0.6.4) } . lSet = { conf,paper, author,title } .As | wSet | =5, | lSet | =4, |{  X  ( u ) } X  X  u and v are heterogenous based on Lemma 3.3. This section presents a brute-force algorithm to compute VLCAs and the answers of keyword queries. Constructing the inverted index for the keywords in the XML document is proved to be an efficient way [31]. In our approach, we also employ the inverted index. Accordingly, given a key-tent node list, I i w.r.t. k i , through our inverted index, and then enumerate all the combinations of the nodes in each I , i.e., ( v 1 , v 2 ,  X  X  X  , v m ), and subsequently compute VLCA of the nodes in each combination according to Lemma 3.4. Fi-in Definition 3.8.

We devise the brute-force algorithm as shown in Figure 3. It first retrieves the inverted list I i for each keyword k (line 3), then for each combination of nodes in I i (line 4), if the nodes in the current combination are heterogenous, this combination will not constitute an answer and will be skipped (line 5), otherwise it will be an answer and added Algorithm 1 : Brute-force Algorithm to the result set (lines 8-9). To further understand the al-gorithm, we walk through the algorithm with a running ex-ample as described in Example 3.3.

Example 3.3. Consider keyword query {  X  X ML X ,  X  X ohn X  X  } on the XML document in Figure 2 (a). We first retrieve the inverted lists, i.e., I XML = { 0.2.0;1.2.0 } , I John 1.2.1 } . For combinations, (0.2.0;0.6.4), (0.2.0;1.2.1), (1.2.0; 0.6.4) are not results of this keyword search because the two nodes in these tuples are heterogenous. Only node 1.2 is a VLCA of the combination (1.2.0;1.2.1), and the three nodes will constitute the answer of this keyword query. We analyze the complexity of the brute-force algorithm. There are m i =1 ( |I i | ) combinations for the content nodes, where |I i | is the number of content nodes w.r.t. k i .For each combination, ( v 1 , v 2 ,  X  X  X  , v m ), we need to compute their LCA and check whether these m nodes are homogenous or not, and the complexity of the former is O( md ) according to Lemma 3.2, while that of the latter is mdlog ( md ) according to Lemma 3.4. To sum up, the complexity of our algorithm is O( mdlog ( md ) m i =1 ( |I i | )). Since m and d are small integers, mdlog ( md ) is dominated by m i =1 ( |I i | ). When there are many content nodes w.r.t. the input keywords, the brute-force algorithm is inefficient, and we will introduce a more efficient stack-based algorithm to address this issue in Sec-tion 5.
As above observation, if there are a large number of con-tent nodes associated with the input keywords, the brute-force algorithm based on exhaustive enumeration is ineffi-cient. To improve the search efficiency, in this section, we propose a stack-based algorithm VLCAStack to address this issue in this section. VLCAStack is inspired from the stack-based family of algorithms for structure join and twig join [5, 7, 8], however, our method is orthogonal to them in that they have to deal with the complicated structure relation-ships (ancestor-descendant or parent-child relationships). In addition, our method is different from the existing studies on keyword search algorithms, such as MLCA [21], SLCA [31], GDMCT [17] and XRank [13]. The difference is that, SLCA and XRank employ the general Dewey code and will involve false negatives and false positives as discussed in Sec-tion 2, MLCA requires some knowledge of XML structures and incorporates keyword search into XQuery, and GDMCT groups the candidate nodes to compute LCAs and ranks them through the distances of the connected trees rooted at their LCAs. MLCA and GDMCT employ the region-based code, and we will experimentally demonstrate that they are not so efficient as our algorithm based on MDC.

To speed up computing VLCAs, we introduce the notions of Compact LCA and Compact VLCA (CVLCA). CVLCA is more compact than VLCA, and the connected subtree rooted at CVLCA, called compact connected subtree, is more compact and meaningful to answer keyword queries. Definition 5.9. (Compact LCA and Compact VLCA) Given m nodes, v 1  X  X  1 , v 2  X  X  2 ,  X  X  X  , v m  X  X  m , w =LCA( v v ). w is called to dominate v i ,if w LCA( v 1 , v 2 ,  X  X  X  v w is a Compact LCA w.r.t. these m nodes, if w dominates each v i . w is a Compact VLCA (CVLCA), if w is a compact LCA and also a VLCA.
 Definition 5.10. (Compact Answer of keyword search) Given a keyword query K = { k 1 , k 2 ,  X  X  X  , k m } and an input  X  ( v 2 ): c 2 ,  X  X  X  ,  X  ( v m ): c m ) | r is the CVLCA of v where c i denotes all the text content that v i contains.
Definition 5.9 presents a more compact and accurate con-cept to answer keyword queries, and Definition 5.10 demon-strates that the compact answer composed of compact con-nected trees should be more meaningful to answer keyword queries, where each compact connected tree describes how each result matches the keyword query. The idea behind the compact connected tree is, since node v is in a compact connected tree, it will not be in another looser one, which contain some other irrelevant nodes. Furthermore, CVLCA is different from and more meaningful than SLCA. For ex-ample, consider the keyword query {  X  X ML X ,  X  X ob X  } on the XML document in Figure 1(b), paper (5) and paper (12) are both CVLCAs as paper (5) dominates title (6) and author (7) while paper (12) dominates title (13) and author (14); but pa-per (5) does not dominate title (6) and author (14). Moreover, only compact nodes (e.g., title (13) and author (14)) share a CVLCA while the loose ones (e.g., title (6) and author (14)) cannot. However, paper (5) is not a valid SLCA since it has a descendant paper (12) which is also a LCA of this keyword query, and paper (5) will be absent from the answer of SLCA. Therefore, SLCA causes the false negative problem as they wrongly discard LCAs which have LCA descendants, and CVLCA can avoid this problem.

More importantly, CVLCA has a key property that we can efficiently compute CVLCAs through only one scan of the input content nodes. Observed from Definition 5.9, when detecting that all the current elements in each input list are larger than the current LCA, we can assure that those ele-ments in each input list and the elements before the current LCA (i.e., the elements that have been popped out from input lists) will not constitute a compact connected tree together, and Lemma 5.5 guarantees the correctness. Sub-sequently, we introduce an effective optimization technique for computing CVLCAs, and inspired from this optimiza-tion, we devise a novel stack-based algorithm, VLCAStack . Algorithm 2 : VLCAStack Algorithm
Lemma 5.5. Given m nodes, v 1  X  X  1 , v 2  X  X  2 ,  X  X  X  , v m w =LCA( v 1 , v 2 ,  X  X  X  v m ).  X  v i  X  X  i , v i &lt;w or v not exist w , which dominates both v i and v j ( j = i ).
Optimization Technique: Let r =LCA ( v 1 , v 2 ,  X  X  X  , v m  X  d , d r , d will not share a common Compact LCA with any node n , C n &gt; C r . Hence, when detecting a compact LCA, r , we can discard the descendants of r as they will not con-stitute other compact LCAs.

Based on the above optimization technique, we can devise an effective stack-based algorithm. Stack-based algorithms require that the input elements I i are sorted in order by their MDCs. In VLCAStack , MDCs of each inverted list are sorted in ascending order. Different from traditional stack-based algorithms, besides maintaining a stack S i for each input list I i , VLCAStack still maintains another stack to preserve the current LCA, denoted as S VLCA . In addition, each node in
S VLCA is associated with some pointers to preserve the nodes that it contains in each current stack S i . If the node in S
VLCA contains all of the input keywords and is a VLCA, this node and the associated nodes with its pointers that contain input keywords will constitute a compact connected tree.

The basic idea of our algorithm is to merge the nodes in each I i into compact connected trees rooted at their com-pact LCAs, and conceptually validate whether each com-pact LCA is a CVLCA. More importantly, all the nodes in each I i will be scanned and pushed into its corresponding stack S i and S VLCA at most once. In addition, once a node popped out from a stack, it will not contribute any answer in future. Accordingly, we demonstrate how to devise our algorithm based on the optimization technique.

Now, we introduce how to effectively identify all the com-pact connected tress through once scan of each I i . While I is not empty or S VLCA is not empty, we select the node with minimal MDC among the first nodes of each current I . Without loss of generality, we assume the minimal node Figure 5: A running example of VLCAStack algo-rithm for the keyword query {  X  X ML X , X  X ohn X  } on the XML document in Figure 2(a). is n min and from I min .Wepop n min from I min and push it into S min .Ifnode vlca , the top element in S VLCA ,isan ancestor of n min , we push n min into S VLCA with a pointer to
S min .top(); otherwise, for each element vlca in S VLCA , which is not an ancestor of n min ,if vlca contains all the key-words, it will be a compact LCA, and the nodes associated with its pointers and itself will constitute a compact con-nected tree. Subsequently, we need to check whether this compact LCA is a CVLCA. More importantly, if vlca is not an ancestor of n min , n min &gt; vlca must hold, hence and the nodes associated with its pointers can be popped out from corresponding stacks according to Lemma 5.5 and the proposed optimization technique; on the contrary, vlca does not contain all the input keywords and will be popped out from S VLCA , since its ancestor also contains the nodes associated with its pointers and may constitute a compact connected tree in future, and thus all the pointers associated with it will be transformed to its direct ancestor (i.e., the ele-ment directly below it in S VLCA ). We repeat these steps un-til both each I i and S VLCA are empty, and Lemma 5.5 and the proposed optimization technique guarantee the correct-ness. Accordingly, we can devise our algorithm, VLCAStack asshowninFigure4.

VLCAStack first retrieves the input lists of the keywords (line 3), and then gets the node n min , which has minimal MDC among the first nodes of each I i (lines 5-6). n min will be popped out from I min and pushed into its corresponding stack S min (lines 7-8). While the top element of S VLCA vlca , is not an ancestor of n min , VLCAStack pops vlca from S VLCA (line 10). If vlca contains all the keywords and is a CVLCA, this vlca with the nodes associated with is pointers must constitute a compact connected tree and be added into the result set, KwRst (line 13), then VLCAStack pops them from corresponding stacks (line 14); otherwise, transforms the pointers of vlca to its ancestor, i.e., the current top node of S VLCA (line 16). Finally, VLCAStack pushes n min withitspointersinto S VLCA (lines 17-18).

To further digest the algorithm for readers, we walk through our algorithm with a running example as shown in Example 5.4 and Figure 5.

Example 5.4. Consider the keyword query {  X  X ML X , X  X ohn X  } on the XML document in Figure 2(a). VLCAStack first re-trieves the input keyword lists, I XML = { 0.2.0;1.2.0 } , 1.2.1 } through the inverted index, and then computes the VLCAs and generates the compact connected trees rooted at these VLCAs as follows. In the first step, as S VLCA is empty and n min = 0 . 2 . 0 , whose MDC is minimal among the first nodes of each I i ,wepushitinto S VLCA with a pointer to the top element of S XML (Figure 5(b)). In step 2, as n min is 0.6.4 and the top element of S VLCA , vlca =0.2.0, is not an ancestor of 0.6.4, so VLCAStack pops vlca from S VLCA and transforms its pointer to its ancestor node 0.2. In the same way, VLCAStack pops 0.2 and transforms the pointer of 0.2 to its ancestor 0, and then pushes node 0.6.4 with its pointer into S VLCA (Figure 5(c)). In step 3, as n is 1.2.0 and vlca =0.6.4 is not an ancestor of 1.2.0, so we pop 0.6.4, 0.6 from S VLCA and transform their pointers to their ancestors. As node conf (0)containsallthekeywords (node 0.2.0 and node 0.6.4 are both associated with its point-ers, i.e., they are descendants of conf (0)), we check whether conf (0) is a VLCA, and then pop it form S VLCA and so do the two nodes, 0.2.0 and 0.6.4 from S XML and S John respec-tively (Figure 5(d)). Since node conf (0) is not a VLCA as discussed in Example 3.2, it will not be added into the re-sult and skipped. In addition, VLCAStack pushes node 1.2.0 with its pointer into S VLCA (Figure 5(e)). Accordingly, we can proceed to walk through the algorithm as shown in Fig-ure 5. Finally, we get the answer of the keyword query, { ( paper (1.2); title :XML(1.2.0), author :John(1.2.1)) } . We analyze the complexity of VLCAStack . According to Lemma 5.5, there are at most |I minSize | compact LCAs, where I minSize is the input list that has minimal size among each I i . However, the number of the compacted connected trees may be larger than |I minSize | ,and VLCAStack will iden-tify all the compact connected trees as the answers. There-fore, VLCAStack needs to scan each I i once and for each ele-ment, v i in I i , pops the nodes which is not its ancestor from S
VLCA and pushes v i into S VLCA , and then for each com-pact connected tree which contains all the input keywords, checks whether the root of this tree is a VLCA according to Lemma 3.4. The complexity of the former is O( d m i =1 |I while that of the latter is O( mdlog ( md ) | CCTrees | ), where m isthenumberofkeywordsinvolvedinakeywordquery, d is the depth of the XML document and | CCTrees | is the number of compact connected trees. Thus, the total com-plexity of VLCAStack is O( d m i =1 |I i | + mdlog ( md )* |
CCTrees | is usually proportional to |I minSize | ,andismuch less than m i =1 |I i | . Therefore, this further demonstrates that VLCAStack outperforms our brute-force algorithm based on exhaustive enumeration.
We have designed and performed a comprehensive set of experiments to evaluate the performance of our proposed algorithms. We used both real and synthetic datasets. The synthetic dataset was generated using the XMark bench-mark [3] with a factor of 1.0 and the raw file was about 115MB. We also used the real dataset DBLP [1] and SIG-MOD Record, TreeBank datasets from Washington XML Data Repository [2] to explore the performance of our algo-rithms. The sizes of DBLP, SI GMOD Record and TreeBank were respectively about 350MB, 500KB and 82MB.

The experiments were conducted on an Intel(R) Pentium(R) 2.4GHz computer with 512M B of RAM running Windows XP Professional. The algorithms were implemented in Java and the parsing of the XML files was performed using the Figure 6: Evaluation of Elapsed Time on SIGMOD-Record Figure 7: Evaluation of Elapsed Time on DBLP SAX API of the Xerces Java Parser. We compared our ap-proach with the state-of-art proposals, XSEarch [10], SLCA [31]  X  , and GDMCT [17].

We employed four metrics, elapsed time, precision, re-call and F -measure to evaluate the efficiency and effective-ness of these algorithms. To compute precision and recall, we manually reformulated the keyword queries into schema-aware XQuery queries according to the schemas of datasets and took the results of these corresponding transformed queries as a baseline, and then computed precision and recall of given queries according to the baseline as follows. Given a keyword query K and its corresponding transformed XQuery X , the accurate result set of K , i.e., the result of X ,isde-noted as AR , and the approximate result set, i.e., the result of a specified algorithm on K , is denoted as PR . Accordingly, we can defined the precision and recall of this algorithm as follows. Precision of the specified algorithm is the ratio be-tween | AR  X  PR | and | PR | , while Recall is the ration between | AR  X  PR | and | AR | .For F -measure , F = 2  X  X  X  X  P + R and R are F -measure , precision and recall of the specified algorithm respectively.

To better understand the performance of our algorithms for various keyword queries with different selectivities, we performed our experiments using various sets of keywords with different frequencies, namely, low, medium and high, respectively corresponding to keywords with frequency be-tween 1-50, 51-500, and above 500.
We evaluated the efficiency of VLCAStack , our brute-force algorithm, XSEarch, SLCA and GDMCT on SIGMOD Record, DBLP, XMark and TreeBank datasets respectively in this section, and compared their elapsed time on various queries.
For each dataset, we selected fifteen keyword queries. Each one of the first five queries has at least one keyword with low frequency, each of the medium five queries has no key-words with low frequency and has at least one keyword with medium frequency, and for the last five queries, all the key-words of each query have high frequencies. In addition, ev-ery keyword query contains 2-6 keywords, for example, in Figure 6, Q S l 2 (3) means that Q S l 2 is a selected query on SIGMOD Record dataset, which contains 3 keywords and has at least one keyword with low frequency. Figure 6, 7, 8 and 9 describe the experiment results on SIGMOD Record, DBLP and XMark and TreeBank datasets respectively.
Figure 8: Evaluation of Elapsed Time on XMark Figure 9: Evaluation of Elapsed Time on TreeBank
Besides inverted indices associated with keywords, XSEarch still has to maintain an all-pairs interconnection index, which is very expensive to compute whatever online or offline. The brute-force algorithm is also inefficient when some input key-words have high frequencies in that it has to exhaustively enumerate all the combinations of content nodes in each I Therefore, VLCAStack outperforms XSEarch and the brute-force algorithm. Especially, on Q S h 5 , VLCAStack costs less than 200ms, while the brute-force algorithm costs 700ms and XSEarch costs more than 800ms as shown in Figure 6. While, on Q X h 5 , the speedup  X  of VLCAStack over the brute-force algorithm and XSEarch are 8 and 12 respectively as illustrated in Figure 8.

VLCAStack is also superior to GDMCT, and the reason is that, GDMCT employs the region-based code, which is not as efficient as MDC to compute LCAs of various nodes. Es-pecially, on Q D m 4 , VLCAStack only costs 50ms, while GDMCT costs 80ms as shown in Figure 7. In addition, we can see SLCA is more efficient than the other ones when a keyword has a low frequency, e.g., Q S l 5 (6), Q S l 2 (3) and Q However when the frequencies of all keywords have no dis-tinct differences, VLCAStack is as good as SLCA and even better than it. For example, on Q S h 3 (4), Q D l 5 (6) and Q the speedup of VLCAStack against SLCAs are about 1.2, 1.4 and 1.5 respectively. Furthermore, SLCA is efficient in that it only retrieves SLCASet instead of the compact connected tree as our method, so that it leads to low effectiveness when compared with other methods, which will be further dis-cussed in Section 6.2.
This section evaluates the effectiveness of those algorithms basedonthreegoodmetricsborrowedfromIRliterature, precision, recall and F -measure , and reports the experimen-tal result. We selected six keyword queries for each dataset and performed the five algorithms on them, and computed precision, recall and F -measure of the five algorithms on the selected keyword queries.

SLCA will cause false positive and false negative prob-lems, while XSEarch, GDMCT and the brute-force algo-rithm will cause the false positive problem as discussed in above sections. VLCAStack achieves higher precision than the other approaches, and the brute-force algorithm has the same precision as XSEarch, which in turn outperforms GDMCT and SLCA. In addition, VLCAStack is as good as the brute-force algorithm, XSEarch, and GDMCT in terms of completeness, and they achieve higher recall than SLCA, as SLCA will miss results from the answer in the case that their descendants are also LCAs. The experimental results are illustrated in Figure 10, Table 2 and Table 1.
Precision. We can see, in Figure 10, VLCAStack out-performs the other three algorithms in term of precision (we omit the brute-force algorithm since it has the same precision as XSEarch) on whatever datasets. More impor-tantly, the precision of VLCAStack is nearly 90% on all the selected datasets, and thus it works well in practice. Al-though XSEarch also achieves high precision, it is inefficient since it is very expensive to compute an all-pairs intercon-nection index. For example, on Q T 5 (the keyword query with 5 keywords on TreeBank), the precision of VLCAStack nearly reaches 90%, while those of XSEarch, GDMCT and SLCA are only 73%, 70% and 68% respectively as shown in Figure 10. This comparison further reflects the effectiveness of our method. In addition, VLCAStack returns compact connected trees as answers, which are more compact and meaningful than the answers of SLCA, GDMCT and XSEarch.

Recall. Based on the discussion in above sections, VLCAStack XSEarch, GDMCT and the brute-force algorithm should achieve higher recall than SLCA as only SLCA causes the false negative problem. However, there is no difference be-tween the former four algorithms, hence we here mainly com-pare VLCAStack with SLCA as shown in Table 2. Since only if there are some nested labels/tags in the XML documents, SLCA involves false negatives, thus we compared them on TreeBank and our synthetic dataset generated according to the DTD in Figure 2(b) using IBM XML Generator. We can see VLCAStack achieves higher recall on all the keyword queries, and is superior to SLCA about 20 percent. This comparison reflects that our method outperforms SLCA sig-nificantly.
F -measure . To further compare those algorithms, we employed another good metric F -measure . We selected six queries for each dataset and compared the average of their F -measure .Wecansee VLCAStack beats the other algo-rithms and achieves the best F -measure asshowninTable 1. For example, on TreeBank, F -measure of VLCAStack reaches 90.1%, while those of the other ones are less than 70%, and especially that of SLCA is only 62.1%.

In summary, in terms of efficiency, VLCAStack is always better than GDMCT, which in turn is superior to the brute-force algorithm and XSEarch on whatever datasets and key-word queries. When the input keywords have no distinct frequencies, VLCAStack is as good as SLCA and even better than SLCA. On the other hand, VLCAStack outperforms the brute-force algorithm and XSEarch, which in turn are better than GDMCT and SLCA in terms of effectiveness. Hence, VLCAStack achieves both higher efficiency and effectiveness when compared with other methods.
In this paper, we have investigated the problem of key-word search over XML documents, with the aim of identi-fying the most meaningful content elements that contain all the input keywords, along with a compact connected tree to describe how each result matches a given keyword query.
To obtain more meaningful results of keyword queries, we propose the notions of Valuable LCA and Compact VLCA to accurately and efficiently answer XML keyword queries. Based on the two concepts, we propose the compact con-nected trees rooted CVLCAs as the answers of keyword queries. Moreover, we present an optimization technique for accelerating the computation of CVLCAs and devise an efficient stack-based algorithm to identify the meaningful compact connected trees.

We have implemented our method and the extensive ex-periment results showed that our method achieved high effi-ciency and effectiveness on bot h synthetic and real datasets. This work is partly supported by the National Natural Sci-ence Foundati on of China under Grant No . 60573094, the National High Technology Development 863 Program of China under Grant No . 2007AA01Z152, the National Grand Fun-damental Research 973 Program of China under Grant No. 2006CB303103, Basic Research Fo undati on of Tsinghua Na-tional Laboratory for Information Science and Technology (TNList), and Tsinghua Basic Research Foundation under Grant No. JCqn2005022.
