 1. Introduction In the Web environment, where collections tend to be enormous, it is so important to have robust queries. in poor recalling power. Moreover, they tend to be too broad to retrieve relevant documents of a specific topic, thus lacking precision. In 2003, Chau, Fang, and Liu Sheng (2005) used the Utah state government website ( http://www.utah.gov/ ), and captured about 2 million queries, over a period of 168 days. In their results, the obtained mean and median of the number of terms in a query are 2.25 and 2, respectively. Spink, Wolfram,
Jansen, and Saracevic (2001) have obtained the same median of 2 after analyzing a log of 1,025,910 user que-ries submitted during a portion of a single day, on the  X  X  X xcite X  X  search engine. The study showed also that among the 32% of the users who modified their queries, about 29.3% of them added one more term, and 15.5% shortened them by one term. Spink et al. (2001) have concluded that Web users tend to go more often from broad to narrow query formulations, via word addition for more precision.
Instead of the expansion mentioned above, we will introduce an automated process for expanding search queries. The automated process is more efficient since it improves both recall and precision.

In Section 2 of this article we will survey the query expansion issue. The QE problems and some suggested solutions from the literature are discussed in Section 3 . In Section 4 , we describe our new technique of query expansion which is driven by semantic similarity of involved words. In Sections 5 and 6 , we thoroughly eval-uate the performance of our system using the TREC-10 data set and discuss the results. Our conclusion and future work are depicted in Section 7 . 2. Literature review
One of the most important issues, and still an open ended question, in the Information Retrieval (IR) field is the search for the appropriate wording of a query, for effective information retrieval. Previous work was done to explore methodologies that can enhance the accuracy and the performance of retrieval systems ( Cro-nen-Townsend, Zhou, &amp; Croft, 2004; Efthimiadis, 1996 ). QE is among the proposed solutions. The overall performance of the QE research is significant in the IR process. Obtained results showed that the approach enhances the precision of IR systems ( Imai, Nigel, &amp; Jun X  X chi, 1999 ).
 The QE mechanism might be applied via one of the following strategies: manual, interactive, or automatic.
For the manual procedure, a user modifies the query by adding or removing words, selectively. QE via the interactive approach, known as  X  X  X elevance feedback X  X , involves user selected relevant documents to expand the query. The automated query expansion does not involve the user. Upon query submission, few among the top retrieved documents are assumed relevant and therefore used to formulate the new query (pseudo-feed-back). Harman (1992) gives a detailed account of relevance feedback and other query reformulation tech-niques. Additional work in QE can be found in the literature ( Efthimiadis, 1996; Harman, 1992; Mitra, Singhal, &amp; Buckley, 1998; Qiu &amp; Frei, 1996; Xu &amp; Croft, 1996 ).

The application of relevance feedback for query expansion has been experimented within different retrieval systems. The effectiveness of relevance feedback has been demonstrated to improve the recall and the preci-back utilizes only the user selected relevant documents from the retrieved list, in response to initial query.
Such selected documents will be used to re-weight, expand, and re-formulate a new searching query. Even though the user has the ability to choose the most relevant documents, such relevancy has to exist, in the first place. Lack of documents relevancy would result in less efficient manual expansion. There are many research efforts contributing to the design and improvement of the QE process. Hybrid and automatic approaches for expanding queries are among the current experimental efforts in the IR field. Kekalainen and Jarvelin (1998) evaluated experiments to analyze expansion versus non-expansion performance using a thesaurus. They con-cluded, in general, that the best performance was obtained using the largest expansion, utilizing all semantic relationships in the thesaurus. Failing cases might be due to either the thesaurus did not provide accurate relations, or that the query was very precise. Grefenstette (1992) designed a system to draw the syntactic rela-tionship between words. The assumption is that the words that appear in the same context share the same trait. 3. Corpus for query expansion
The main concern about utilizing QE in IR systems is that the expansion is not always beneficial. The expansion might degrade the performance of some individual queries ( Cronen-Townsend et al., 2004 ). A lower performance might be due to  X  X  X uery Drift X  X , when the new query has little re-semblance to the original ( Mitra et al., 1998; Stenmark, 2005 ). Consequently, there will be a subject shift in the retrieved documents. Hence, adding more words does not always improve the performance.

Additional QE concerns might be due to the utilized thesaurus, involving its compilation, maintenance, and updating. Hence, it is important to select the appropriate thesaurus for the QE process.

Alternative solutions were suggested using  X  X  X inguistic corpus X  X , to overcome the above concerns. A linguis-tic corpus has a large collection of unified, well structured, and balanced texts, usually annotated as well. The coverage of the corpus can be verified, e.g. the amount and the content variety of texts. Recently, it is much easier to compile corpora over the Internet. Processing this huge amount of data can be fully automated.
Successful experiments on building corpora from online data have been acknowledged in ( Abdelali, Cowie, &amp; Soliman, 2005; Goweder &amp; De Roeck, 2001 ). Projects at Linguistic Data Consortium (LDC) and The Euro-pean Language Resources Association (ELRA) have significantly contributed to the availability of such resources. The sentences within a corpus define the relations between their words, e.g. re-occurrences of some words in several sentences will reflect a stronger relation between these words. Among the advantages of using corpora over thesaurus is defining more accurate relations between words. Hence, we would have a better con-trol over the QE. Moreover, the corpora require lesser time and efforts.

The sense that a word takes in one context is defined by its neighboring words. Therefore the statistical information that can be gathered from a corpus will define the senses that a word takes at each occurrence.
Using Latent Semantic Analysis (LSA) ( Landauer, Foltz, &amp; Laham, 1998 ), each meaning of a word or a sen-tence is modeled as a vector in the semantic space, where the meaning of a sentence is the sum of its words X  vectors. Although this process neglects the sentence syntax, LSA has proven to be a powerful and useful tool. Consider the following examples ( Kintsch &amp; Bowles, 2002 ): The stock market collapsed.
 The bridge collapsed.

The meaning of the word  X  X  collapsed  X  X  depends on its immediate context. In LSA, the vector rep-resenting a predicate combined with the neighboring words X  vectors would reflect the actual sense of such predicate. In context-sensitive interpretation from the meaning of the same word in the second sentence.

If two constructs (words or sentences) have an angle h between their representing sense vectors, then their semantic similarity measure is a function of cos h . Constructs with matching semantic ( h = 0) have a cos h near 1; whereas constructs with orthogonal senses ( h = 90) have cos h near 0.

Stenmark (2005) utilized the LSA but on word-by-word semantic vectors matching between words from the query and the corpus. He did not achieve the expected enhancement of applying his QE approach. 4. System design and description
We implemented a novel QE approach that utilizes the LSA mechanism for more efficient and reliable QE process. In our approach, we construct a total sense vector that represents the en-tire query semantics. Then, instead of basing the QE on matching semantics  X  X  X ord-by-word X  X  between query words and words from the corpus, we use the new total query vector to find the closest matching set of words/documents X  vectors in the corpus. Selectively, we expand the query utilizing the obtained set of words. Our approach is motivated by the intuition that searching the corpus with the total query semantic vector would obtain more precise and supportive words/documents to enrich the initial query. As we expected, experimental results of our new system supported our hypothesis.

We used two different settings to experiment with our approach: 1. Expanding using words. 2. Expanding using documents.

In both approaches, we used LSA to compute the corresponding sense vector for every query, after removing the  X  X  X top-list X  X  words. Such list contains the most frequent words in the corpus. Stop words are considered irrelevant for searching purposes because they occur very frequently in the language and they tend to slow down the search without improving the results. The stop-list will be also ignored in the process of indexing the documents (see Section 5.2 ). Using the refined query, we build its corresponding sense vector that is used to obtain, from the corpus, a list of the top n closest words X  or documents X  vectors to the query in hand. The obtained list will be used to expand the query.
 5. System evaluation 5.1. Data
For the purpose of evaluating our new system, we used the LDC Arabic Newswire, a corpus composed of articles from the Agence France Presse (AFP) Arabic Newswire. The LDC corpus size is 869 megabytes which is divided over 383,872 documents. The corpus includes articles from 13 May 1994 to 20 December 2000 with approximately 76 million tokens and 666,094 unique words. In order to facilitate the manipulation of Arabic text, we transliterate the cp-1256 (Arabic Windows) encoded text to Roman codes (Romanization). Due to memory limitation, we could not use the entire corpus to build the se-mantic space;, instead we randomly used only half of it, which accounts for about 37 million words and around 341,000 unique terms. In order to val-idate the obtained results for the random selection, we executed several runs to check the variations of the results. 5.2. The retrieval process
As part of the evaluation of our new QE technique, a Unicode Retrieval System Architecture (URSA)
AFP corpus. A total of 25 Queries from TREC-10 topics is involved to evaluate the system, comparing the results with those of a  X  X  X aseline-system X  X  with no query expansion. Relevant documents are retrieved for newly regenerated queries (i.e., expanded) via the obtained top n closest words or documents to the original query, from the corpus. TRECEVAL software, by TREC, is deployed to evaluate the precision and recall of the retrieval process, as part of assessing the performance of our system. 5.3. Experimental results
In order to assure efficient and precise retrieval process of our QE approach, we define a notion of accept-able threshold (lower limit) of similarity between the query and corpus vectors. Such threshold is imposed on the selection of the aforementioned top n words/documents to be used in the QE process.

Throughout the expansion process, we choose different values for n , e.g., n = 2,5,10,15,20,30, and 50. For every value of n , we expand the query using only those words or documents that possess cos h P 0.5 (i.e., h 6 45), where h is the angle between each of their LSA sense vectors and the original query sense vector.
The new re-formulated query is run against the indexed corpus; and the retrieved documents is compared to those obtained from baseline system, without any query expansion. 5.3.1. Experimenting with word expansion
Using the threshold cosine similarity measurement, with the total query vector, words are sorted and the top n used in the expansion. Table 1 shows that the results of expanding queries using words have retrieved more relevant documents, specifically, we have achieved a 5% increase in number of relevant documents retrieved over the baseline system. Yet, for higher values of n (e.g., 30, 50), the number of relevant documents declined.

Tables 2 and 3 provide an overview of the similarities of words to the topics, while the words in Table 2 show weak relation to the topic 19 in Fig. 1 . Moreover, topic 20 got a significant boost with the additional words that are much more related. The words highlighted in bold in Table 4 carry more semantic relation to the topic 20. 5.3.2. Experimenting with document expansion
When the expansion uses documents, the new reformulated query is too long to be handled by the retrieval system. Therefore, the expanded query is divided into smaller sub-queries, to be submitted separately. As expected, there will be a huge number of retrieved documents for the generated sub-queries. Hence, we deploy either local or global pruning techniques to trim the obtained set of documents. In the global pruning, we sort all the documents retrieved by the sub-queries, according to their relevancy to the query and get the reasonable number (say D ) of top ranked documents. Localized pruning selects the top D / m documents from each of the m sub-queries retrieved documents. For the best optimal pruning process, we are exploring solutions from the  X  X  X ata fusion X  X  research field ( Vogt, 2000 ).

Compared to word expansion, Table 4 shows better results of document expansion. Specifically, we obtained an additional 60% in-crease in the number of relevant documents. Tables 5 and 6 provides an over-view of the similarities of documents to the topics 19 and 20 respectively.

For example in Table 7 , at a Recall point of 0.7, document expansion approach achieved an additional 98.91% (0.0909 versus 0.0457 of the baseline system) higher precision when compared to 4.60% (similarly 0.0478 versus 0.0457) precision by word expansion.

Also, as shown in Table 7 , the precision at higher number are better than the baseline system. Moreover, we obtained good results with respect to relevant documents. Yet, we are still concerned about the lack of better precision at lower recall points. A possible explanation might be due to the aforementioned pruning strategies we used. 5.3.3. Re-visiting word expansion
The results of using document expansion, especially in recalled documents ( Table 6 ), seem very encourag-ing. Hence, motivated by the document expansion results, we deployed the same approach of using the query division mechanism in word expansion. The major drawback of the sub-queries approach is the extra time (overhead) of manufacturing and processing m sub-queries for every original query. The new approach has been evaluated using the same sets of data and topics. The results showed significant increase (between 45% top 110%) in the number of relevant retrieved document; with the obtained precision between 5% and 10% (see Table 8 ). 6. Discussion
Fig. 2 histograms display the achievements of the extended queries comparing to the baseline system, an average of an additional 50 relevant documents has been retrieved.

Among the 25 queries used for the evaluation, four queries were not improved  X  two among them got worse achieved with other queries.

From the obtained results, the failure of the two queries might be related to their length, since the length fairly correlates negatively with the performance of the expansion (see Table 8 ). Short queries tend to perform better than the long ones. Long queries are hard to expand because the length reflects the semantic richness of the query, hence adding more words would slightly increase the query sense Table 9 .

The analysis of our results indicates consistent improvement of the word expansion precision, compared to the baseline system. Moreover, our strategy of controlled query expansion, using the expansion threshold, promises a much better IR performance than existing LSA based competitive techniques.

In summary, our technique shows a significant increase in recall and precision due to the use of small, but semantically related numbers of words/documents in the expansion process. The uncontrolled (not well thought out) addition of words to the query might hurt the retrieval process, and the expansion will not be beneficial.

All the results of the above experiments were statistically significant using Student X  X  t -test at a p -value of &lt;0.05.
 7. Conclusion and future work This paper demonstrates that the QE process can play a significant role in the performance enhancement of IR systems. The most critical factor in the process is the selection of words/documents to expand the query.
The wrong choice of expansion constructs might harm the retrieval process by drifting it away from the opti-mal correct answers.

In order to avoid the harmful expansion, expanding words/documents might be selected under the guidance of information inferred from corpora. We designed a mechanism that can automatically select corpus words that are semantically related to the query, in the expansion process. The major advantage of our approach is its well thought out mathematical approach in selecting the query expanding words/documents from the cor-pus. Only corpus words with the largest sense vector similarity (within some  X  X  X osine X  X  threshold) to the sense vector of the  X  X  X ntire X  X  initial query will be selected for the expansion process. Such algorithmic approach will guarantee the usefulness of the expansion, rather than inefficient traditional blind QE. Moreover, it assures the topic consistency and helps in a stable QE process that would not result in topic shift or query drift.
The obtained results of our newly automated expansion are very promising. On the other hand, we noticed that some of words added to the query were not frequent in the collection; hence their effect on the retrieval scores is not significant.

In our future work we will investigate a possible solution to the above problem. We might try the inclusion of the frequency of occurrences factor of words/documents in the corpus, as additional criteria, in the QE selection process. We will also experiment with boosting the recall via expanding the query using only more frequent words. The question that we will explore is  X  X  X ould the use of this category of scarce words lead to the discovery of otherwise unseen documents? X  X  The answer to the above question might be particularly impor-tant if there are very few relevant documents in the collection.
 References
