 Reading is a complex cognitive process, errors in which may assume diverse forms. In this study, introducing a novel ap-proach, we use two families of probabilistic graphical mod-els to analyze patterns of reading errors made by dyslexic people: an LDA-based model and two Na  X   X ve Bayes models which differ by their assumptions about the generation pro-cess of reading errors. The models are trained on a large corpus of reading errors. Results show that a Na  X   X ve Bayes model achieves highest accuracy compared to labels given by clinicians ( AUC = 0 . 801  X  0 . 05), thus providing the first automated and objective diagnosis tool for dyslexia which is solely based on reading errors data. Results also show that the LDA-based model best captures patterns of reading er-rors and could therefore contribute to the understanding of dyslexia and to future improvement of the diagnostic pro-cedure. Finally, we draw on our results to shed light on a theoretical debate about the definition and heterogeneity of dyslexia. Our results support a model assuming multiple dyslexia subtypes, that of a heterogeneous view of dyslexia. J.4 [ Computer Applications ]: Social and behavioral sci-ences Psychology Probabilistic Graphical Models; Dyslexia; Diagnosis; Latent Dirichlet Allocation; Na  X   X ve Bayes c  X 
Reading is an intricate task involving multiple processes located in different areas in the brain [25]. Errors in read-ing can result from dyslexia, a disorder involving a vari-ety of such errors. Dyslexia is a highly common disorder with estimates of prevalence ranging from 5% to 17.5% [34], pointing to the need for accurate and accessible diagnosis. However, current diagnostic procedures require experts, and are mostly lengthy and expensive. In this study, we aim to provide an accessible, reliable and cheap diagnosis tool for dyslexia. We do this by showing that rich probabilistic graphical models can diagnose dyslexia closely to how ex-perts do, rendering them accurate, reliable and automated tool for diagnosis. Moreover, by providing probability dis-tributions of errors given target words in screening tests, models can be used for future improvement of the diagno-sis procedure and understanding of dyslexia. Finally, our results provide a novel and quantitative perspective on an ongoing debate regarding the nature of dyslexia (e.g., [9]).
A dyslexic person may read the word three as there , as tree or as four . Despite this heterogeneity, many studies in the field of reading disorders focus on measures of speed and accuracy to characterize dyslexia, thus possibly ignoring the rich structure of types of reading errors. These studies often assume a common phonological [26], [28], [36], [37] or sen-sorimotor [37] cause to all types of reading errors. However, an alternative approach views dyslexia as an umbrella term for various deficiencies, or dyslexia subtypes, each character-ized by specific error types (e.g., [6], [11], [20]). According to this approach, each of the errors above could result from a different subtype of dyslexia. This approach suggests that fundamental aspects of reading disorders lay in the complex structure of reading errors.

We explore the structure of reading errors and the hetero-geneity of dyslexia using probabilistic tools. Probabilistic graphical models have several advantages as a framework for modelling reading errors. Probabilistic models allow ex-plicitly capturing a dependency structure among variables in the problem, making learning more efficient. Probabilistic graphical models provide both diagnoses and explicit error distributions per each type of dyslexia and target word, as learned from the corpus data, and can naturally follow an error-generation process.

We use two families of graphical models. First, we con-struct Na  X   X ve Bayes models which are well-known for hav-ing a good performance as classifiers with relatively low model complexity (see, e.g., [18]). These models are thus suitable for the classification of reading errors. Next, we construct a Latent Dirichlet Allocation based (LDA-based) model, which has been proven to well capture generation processes in the context of writing and text [1], [31]. In such a model, the generation of reading errors made by a dyslexic person is a more complex process than that in a Na  X   X ve Bayes model, as it assumes that errors are generated according to a mixture of subtypes of dyslexia. An LDA model is therefore a natural candidate for dyslexia analysis.

We compare the models on two different tasks. First, we identify the probabilistic model that best performs on the task of diagnosing dyslexia. We achieve this by comparing the diagnoses of the models to those of experts. Secondly, we explore which model best captures the complex structure of the patterns of reading errors. We achieve this by comparing the models on the task of predicting unseen errors. Finally, the performance of the models is used to explore the question of whether reading errors do result from different subtypes of dyslexia, or rather from one general malfunction.
The rest of the paper is organized as follows: section 2 de-scribes the related literature of probabilistic graphical mod-els and of dyslexia. It also provides a summary of the major views of dyslexia in the current literature of reading disor-ders. Section 3 describes the structure and size of the data that was used in this study. Section 4 provides a detailed de-scription of the probabilistic graphical models. Finally, sec-tion 5 describes the results of this study: the performance of the models on the task of diagnosing dyslexia (section 5.1), and the performance of the models in predicting reading er-rors (section 5.2).
The LDA model was introduced a decade ago to dis-cover topics in documents, and has been most influential since. Three main algorithms for approximate inference in the model were proposed: Variational Expectation-Maximiz-ation [1], the Expectation-Propagation [21], and Collapsed Gibbs Sampling [15]. In this paper we use the latter method. The generative process described by the LDA model com-mences in Dirichlet priors which are often chosen to be uni-form. However, following the demonstration of the impor-tance of using non-uniform priors for this model [39], we use these and not uniform priors in this study.
Literature on reading disorders presents various accounts of the causes of developmental dyslexia. One central ap-proach describes developmental dyslexia as a disorder that can be reduced into a single cause, and will be referred to hereby as the single-type approach. The most influential ex-ample of this approach is the phonological deficit hypothesis . According to this theory, developmental dyslexia originates from a deficit affecting either the representations and pro-cessing of speech sounds [34], [35], [36], or as other authors have argued, from the access to these representations [27]. This hypothesis had influence on much research in neuro-science and brain imaging studies, e.g., [2], [8], [10], [14], [26], [28].
 Figure 1: The dual-route model (see, e.g., [11]).

Another central approach describes dyslexia as a hetero-geneous disorder, having several different causes, and will be referred to hereby as the subtypes approach. The most influ-ential example of this approach derives from the Dual-Route Reading Model [5], [6], [20], describing the process of reading by several processing stages and routes (figure 1). Accord-ing to this approach, there are subtypes of dyslexia, each resulting from a deficit or malfunction in a different stage in the process of reading. For example, reading signs as sings may result from a specific malfunction in letter position pro-cessing during the early visual-orthographic stage, and is in this case ascribed to Letter Position Dyslexia [12]. However, reading signs while pronouncing the  X  X  X , may be caused by Surface Dyslexia, characterized by reading irregular words according to the regular grapheme-to-phoneme conversion rules [7]. The deficit leading to Surface Dyslexia occurs in one of two long-term memory lexicons, the orthographic or phonological lexicon, or in the information processing be-tween them. Brain imaging studies following this approach aim to identify the neural correlates of different subtypes of dyslexia, e.g., [16], [19].

The single-type approach and the subtypes approach use different procedures to diagnose dyslexia. The diagnostic procedure based on the single-type approach mainly uses phonological tasks, for example, asking the subject to swap between the first phonemes in the two words fresh bread (ex-pecting to get bresh fread ). When otherwise using reading tasks, the degree of dyslexia is assessed by measuring accu-racy and speed in such tasks, while disregarding the types of errors which were made. However, the diagnostic procedure based on the subtypes approach mainly uses reading tasks, asking the subject to read aloud a list of words which are prone to erroneous reading. These tests assess the subtype of dyslexia by counting the errors made of each type.
Another group of studies aim to characterize dyslexia sub-types (e.g., [23]), however the diagnostic procedure in these studies is not based on data of error types in reading tests, but on measures of speed and accuracy in various tasks. Several such studies have proposed probabilistic models to analyze the data (e.g., [24]). See also [30] for analysis of reading aloud data, however in contrast to our study, they were not concerned with error types in reading tests but focused on reading of nonwords by normal subjects. We test our models on reading tests collected from 313 Hebrew-speaking individuals with developmental dyslexia, aged 7 to 62 years, all diagnosed in the Language and Brain laboratory in Tel-Aviv University. Out of the 313 subjects, 97 were diagnosed with an Attention Deficit Disorder (ADD) in addition to dyslexia. This is, to our knowledge, the largest reading-errors corpus used so far (see [22], [29]). The bat-tery of tests has two parts: (1) screening-tests: reading tests given for initial assessment of dyslexia (TILTAN battery, [13]), and (2) varying post-tests which are determined ac-cording to the results of the screening-tests. These are used to further specify the diagnosis. Since different subjects take different post-tests, only the corpus of the screening tests was used in this study.

The screening test is composed of 196 target words in He-brew, which are prone to erroneous readings. The audio responses of subjects are recorded, and then encoded before used in the model. Responses were encoded by experts in dyslexia diagnosis and research, into one of 19 different er-ror types (appendix B, table 2). Each of the 313 subjects therefore read 196 words in the screening-test, resulting in a corpus consisting of a total of 61,348 pairs of target-word and response.

Based on the screening tests and on additional post-tests, had these been conducted, each subject is diagnosed by an expert by marking the subtypes of dyslexia that he or she has. We represent each diagnosis as a multi-label binary vector of length 7, corresponding to seven dyslexia subtypes:  X  X etter position dyslexia X ,  X  X ttentional dyslexia X ,  X  X eglexia X ,  X  X urface dyslexia X ,  X  X isual dyslexia X ,  X  X owel letter dyslexia X  and  X  X ormal state X .

The collected data corpus is in Hebrew, therefore it is im-portant to discuss the applicability of this work to other lan-guages, specifically English. The underspecification of vow-els in Hebrew makes the Hebrew orthography neighborhood denser than that of languages such as English. An example of this is that in Hebrew, letter transpositions inside a word are more likely to result in another existing word, than in English. This property makes some dyslexias more easily detectable in Hebrew than in English. However, once the relevant stimuli are selected for an English reading task, the same dyslexias with the same properties are detectable in both languages. And indeed, the dyslexias we describe have all been identified in English (For a comprehensive survey of this literature of dyslexia types in English, see for ex-ample [6]; for the specific dyslexias that we describe here see Letter position dyslexia: [6]; Attentional dyslexia: [32], [33]; Neglexia: [38]; vowel dyslexia: [17]; Surface dyslexia: [3], [4], [5], [7]). This work can therefore be expanded to English and other languages.
Bayesian models are expressive statistical models. Typi-cally, these are used for mathematically modeling assump-tions regarding the manner in which data (in this case, read-ing errors), is generated. We construct three different proba-bilistic graphical models for this purpose: a Latent Dirichlet Allocation (LDA) model, and two Na  X   X ve Bayes models.
We begin to explore the generation process of reading er-rors with the class of Na  X   X ve Bayes models. Na  X   X ve Bayes models have shown much success in classification tasks, and could therefore fit the task of classifying reading error into dyslexia subtypes.

The types of the errors made by the subjects are denoted in the models by e i ( i = 1 ,...,N ). This variable takes one of E possible values e i  X  1 ,...,E , where E stands for the num-ber of possible error-types including a correct response. An-other observed variable of the model represents the target-words. We denote it by w i ( i = 1 ,...,N ), where N repre-sents the number of target-words in the screening-test. This variable can have one of W possible values w i  X  1 ,...,W . Since in our case each target-word is present only once in the screening-test, we have W = N .

In all three models, a dyslexia state defines a hidden vari-able that stands for a state associated with a specific sub-type of dyslexia, and is characterized by particular reading errors. For example, being in a state of low orthographic attention could be associated with Letter Position Dyslexia (LPD), typically leading to letter migration errors. We de-note a dyslexia state by d i , where d i can have one of D d  X  1 ,...,D dyslexia states. We have 7 such states as de-scribed above.

In all models, S stands for the total number of subjects, N stands for the number of target-words in the screening test, W is the size of the vocabulary of the target-words, and D stands for the total number of dyslexia states. e represents an error type, w a target-word and d a dyslexia state.
Typically, clinicians use the screening test to diagnose dyslexic subjects based on the total counts of different er-rors types they make. This approach disregards the specific target-words on which the errors were made, for instance, whether it is a word that many subjects misread, or specific subjects only. This diagnosis procedure can be modeled with a Na  X   X ve-Bayes model in which the probability of an error-type depends on the dyslexia subtype only. In what follows, we refer to this model as the Na  X   X ve Bayes 1 (NB1) model.
For test results of a single subject, the joint distribution of the NB1 model factorizes as: where the subscript i runs over all word-error pairs in the screening-test. Note that each error is independent of the specific target-word on which it was made. Figure 2a de-scribes the plate diagram of the model.
A more complex model is a Na  X   X ve Bayes model in which the probability of an error is dependent on the dyslexia sub-type and also on the target-word. We examine this model as well and will refer to it in what follows as the Na  X   X ve Bayes 2 (NB2) model.
In this model the response of the subject e i is dependent on the i th target-word w i and on the dyslexia state d i ilarly to the NB1 model, the joint distribution for the NB2 factorizes as: where the subscript i runs over all word-error pairs in the screening-test as before. Figure 2b describes the plate dia-gram of the model.
We continue our inquiry with a particular family of Bayesian models that has attracted much attention in the past decade, the Latent Dirichlet Allocation (LDA) Model [1]. The LDA model enables inferring unobserved variables given observed data, and has shown much success in capturing generative processes of text documents [1], [31].
The LDA model captures the more complex assumption that a person can suffer from a mixture of different dyslexia subtypes. According to this model, each person has a unique distribution over dyslexia subtypes. Additionally, each dys-lexia subtype has a unique distribution of expected errors for a given target-word. When a person is reading a target-word, a particular dyslexia subtype is directing the way by which the word is read. The response is then dependent on this dyslexia subtype and the target-word. We therefore de-fine two additional hidden variables. A diagnosis  X  s , which is a distribution over dyslexia states d i for a subject. This distribution is learned from the data. A word-error-dyslexia distribution  X  wed = p ( e i = e | w i = w,d i = d ) is a dis-tribution for all subjects in which, given a dyslexia state d and a target-word w , each error has a certain probability of occurring. For example, given an LPD state, and the target-word three , the erroneous response there would be of high probability, but tree would be of a lower one. Similarly, given a normal state, and the target-word three , all error re-sponses would have low probabilities except for the (correct) response three .

The input to the model is the word-error pairs of all sub-jects. The hidden variables discovered by the model are: (1) N dyslexia states for each subject; (2) the diagnosis of each subject - X  s , and (3) a single word-error-dyslexia distribution  X  wed for all subjects. Figure 2c describes the plate diagram of the dyslexia-state model.
The generative process we use to model reading errors uses two Dirichlet priors from which the two distributions  X  ,  X  wed are sampled. Dirichlet priors are often chosen to be uniform. However, adding priors that adequately describe the generative process could enhance model performance. As the subtype approach to dyslexia has developed ways to detect typical reading errors for each dyslexia subtype, this prior knowledge can be incorporated into the LDA model. We tested the model both with this prior knowledge coded into it and without it.

The expert knowledge is used for sampling the word-error-dyslexia distribution and we denote it by  X  wed . This knowl-edge tells us about the error expected for each target-word given a dyslexia state (figure 2c). For example, given an LPD dyslexia-state, the word three is more likely to be read as there than tree or four . We incorporate this into the model by assigning a higher prior value  X  high to the more probable responses of an LPD dyslexia-state, in this example there . We also assign a lower prior value  X  low to the less probable responses, in this case tree and four . This is repeated for all dyslexia-states, including the normal state.
Gibbs sampling is a form of a Markov Chain Monte Carlo (MCMC) method which is widely used for parameter esti-mation in topic models ([15], [31]). We use Gibbs sampling to construct a Markov chain between dyslexia-states, where the order of the Markov chain is based on the order of target-words in the reading-test. In each step, a dyslexia-state is sampled from its posterior distribution conditioned on all other variables in the model (see appendix A ): where, d i = d represents the assignment of the i th word-error pair to dyslexia-state d . w i = w represents the observation that the i th target-word is w , and e i = e represents the observation that the i th error type is e . d  X  i represents all dyslexia-state assignments excluding the current i th instant. w  X  i represents all target-words observations excluding the current i th instant. Similarly, e  X  i represents all target-words observations excluding the current i th instant. C wed,  X  i resents the number of times the word-error pair ( w,e ) was assigned to the dyslexia-state d , excluding the current in-stance. C ds,  X  i represents the number of times the dyslexia-state d was assigned to the dyslexic person s .  X  ds are the Dirichlet prior weights (see 4.1.2). At each step of the Markov chain, we update the diagnoses of the sub-jects {  X  s } S s =1 and the word-error-dyslexia distribution  X  according to the dyslexia-state assignments  X  d s . These are then used to assess the accuracy and predictive power of the model.
We conduct two experiments with the data. In the first, described in section 5.1, we compare three graphical models to find which model most accurately predicts dyslexia di-agnosis. In principle, this model can be used to automate dyslexia diagnosis. In the second experiment, described in section 5.2, we compare the quality by which these three graphical models predict specific reading errors. The best model to predict errors could contribute to the better char-acterization of dyslexia.

We use two different types of cross validation, first leaving out a set of subjects and then leaving out a set of word read-ings of the test subjects. Specifically, we randomly split the data into a training-set with 219 subjects (70%) and a test-set with 94 subjects (30%), controlled to have the same pro-portion of subjects which are also diagnosed with Attention Deficit Disorder. See illustration in figure 3. The test-set is further divided into two equal-sized sets: a diagnosis-set with 98 pairs of target-words and subject responses, used to infer the diagnosis of test subjects, and a prediction-set also with 98 word-response pairs, used for assessing the predictions of the models.
Automation of the diagnosis process could facilitate the accessibility of the process to many people and increase Figure 3: Data is partitioned into 3 sets. The dataset is first divided into a training-set which con-tains reading-tests of 70% of the subjects, and a test-set which contains the remaining 30% of the data. The test-set is further divided into two sub-sets, a diagnosis-set containing the first halves of the reading-tests, and a prediction-set containing the re-maining reading-tests of the test subjects. awareness to treatment of specific reading deficits. We com-pare the automatic diagnosis of the three models  X  NB1, NB2 and LDA  X  to those given by experts, to test if the au-tomated tool can indicate the diagnosed dyslexia type with high accordance to diagnoses given by experts. We evaluate the diagnosis quality as follows. The automatic diagnosis is based on the diagnosis-set. This set is used to infer the di-agnosis distribution  X  s for each subject. The accuracy of the models is then assessed using the diagnoses given by experts. The prediction-set together with the diagnosis distribution  X  are later used for the evaluation of the predictive power of the models. The prediction-set is therefore not used in the diagnosis process. Diagnosis quality of the two Na  X   X ve Bayes models, is estimated by computing where the dyslexia prior p ( d ), the probability of error given a dyslexia subtype p ( e i | d ), and the probability of an error given a dyslexia-type and a target-word p ( e i | d,w are evaluated from the training group.

For the LDA model, we train the model on the training-set together with the diagnosis-set. The model is initialized with random dyslexia state assignments {  X  d s } P s =1 which are then iteratively sampled according to the sampling rule in (1). At each step of this process, we update the dyslexia distribution per each subject  X  s and the word-error-dyslexia distribution  X  wed according to the new sampled dyslexia-state.

The reason we train the model on the training-set and the diagnosis-set together is to avoid a discrepancy between the hidden dyslexia-states of the word-error-dyslexia distri-bution  X  wed , learned from the training-set, and those of the dyslexia distributions {  X  s } s  X  test  X  set , learned from the diag-nosis set. If the model is trained on the sets separately, the hidden states of these distributions might differ by a permu-tation relation. All results below are averages over 5 splits of subjects to train-and test-sets (allocations of subjects), and also over 10 different random initializations of the dyslexia state assignments (a total of 50 runs). 500 iterations were found to suffice for convergence (figure 5A).

We compare the diagnoses given by the three models to those given by experts. The Na  X   X ve-Bayes models are known to be strong classifiers and were designed by similar assump-tions and guidelines to the ones held by diagnosticians, and therefore their diagnoses are expected to strongly correlate with those given by experts. The LDA model is designed to capture the generative process of the patterns of reading errors, (see section 5.2) but may therefore be a worse pre-dictor of dyslexia subtypes. Note also that the diagnoses of the clinicians are given according to the results of the entire screening-tests and the post-tests results, whereas the diag-noses of the models are based on only halves of the screening-tests. This is expected to lower the maximum accuracy for all models.
 Figure 4: Accuracy results for the three graphical models  X  LDA, NB1 and NB2, with (dark bars) and without (light bars) typical errors priors to NB2 and LDA.

Figure 4 shows the comparison between the accuracy of the models, table 1 summarizes the resulting AUC values. The highest accuracy is achieved with the NB2 model when it is provided with typical-errors priors  X  wed . Next are the LDA when it is provided with typical-errors priors and the NB1 Models. Results reflect that the NB2 model is best at replicating diagnoses of experts, and therefore can be used as an automated data-driven tool for dyslexia diagnosis.
As expected, the LDA model reasonably correlates with expert diagnosis. Yet, it predicts the same diagnosis as ex-perts in fewer cases than NB2. In the following section we examine whether this is ought to the LDA model being an inaccurate model of dyslexia, or rather the opposite -it may contribute to expert knowledge in capturing dyslexic phe-nomena.
Which model of the proposed models (NB1, NB2, LDA) best captures the hidden error patterns in the data, thereby best characterizing dyslexic errors? We answer this by com-paring the predictive power of the three models. We evaluate the predictive power of the models using the prediction-set (figure 3). The perplexity score is commonly used in as-sessing the predictive power of a language model (e.g., [1]). Here, it reflects the degree of  X  X urprise X  of the models to the errors made by the dyslexic person. Formally it is: and it is evaluated on the prediction-set, where  X  w the observed target-words and  X  e s are the error types in the prediction-set of person p. |  X  w s | represents the number of words in the prediction-set ( |  X  w s | = 98), and N total number of test subjects ( N test = 219).

We also compare the predictive power of NB2 to LDA when provided with priors about the typical errors for each dyslexia subtype. Figure 5 shows that the perplexity of these models is lower when provided with priors (figure 5: dark curve in panel A and dark bars in panel B). Incorporating expert knowledge into the model therefore increases its pre-dictive power.

The prior value of the diagnosis distribution was set to be uniform with arbitrary value  X  dp = 0 . 05. The lower prior for the word-error-dyslexia distribution was set to  X  0 . 05, whereas for the higher prior  X  high , different values were explored.  X  high is then chosen to be the value that achieves lowest perplexity  X  high = 0 . 7 (figure 5). The perplexity values for all three models are summarized in figure 5b.
These results show that the best prediction of reading errors is achieved by the LDA model when it is provided with typical-errors priors (figure 5B). This result is consis-tent for different typical-error priors when compared to the NB2 model (figure 6). These results indicate that the LDA model best captures the hidden structure of reading errors, among all three models.
In addition to dyslexia, other factors may contribute to reading errors. For instance, people make reading mistakes due to momentarily lowered attention, which may be caused by an attention deficit or simply because they become tired as the diagnostic procedure progresses. These causes may in-teract with dyslexia. We hypothesized that we could  X  X lean out X  incorrect assignments of reading errors to dyslexia, rath-er than to an unattended state, by disentangling errors caus-ed by dyslexia from errors caused by low attention. We fur-ther hypothesized that by disentangling the two, we could classify between participants which are diagnosed with at-tention deficit disorder in addition to dyslexia. We there-fore designed a model that takes into account the two pos-sible causes of reading errors, specific dyslexia types and a generic low attention state, incorporating the manner in which these change during the diagnostic procedure. Specif-ically, we added to the LDA-based graphical model a binary random hidden variable marking the attentional state of the subject, attended or unattended, while reading each word. We set these attentional states as a hidden Markov chain, incorporating the dynamics of reading errors in time. We trained the model in a similar way to the LDA-based model, but this time also inferring the hidden attention states and learning the transition probabilities between these states.
When evaluating this model, as in the above experiments, we did not find the Dyslexia-Attention model to improve over the dyslexia-state LDA model. We hypothesize that two reasons may explain the lack of improvement. First, adding the attention hidden variables requires a significantly larger number of parameters, which might be hard to well optimize with the current dataset. It is possible that train-ing the model with an even larger corpus of data would im-prove the predictions. A second possible reason is that the attentional processes follow a different time scale than the one captured by the current experiments. The time spent in a state in an hidden Markov model follows an exponen-tial distribution, and this may not be an adequate model for switching between attention states. We encourage and intend to further examine this line of research with more accumulating data.
This study is a first demonstration of using probabilistic graphical models as a method for analyzing reading errors made by dyslexic people. The work has two main novel contributions: (a) it provides an automatic diagnosis tool of dyslexia, based on data of types of reading errors; (b) it provides probabilistic tools which enable exploring dyslexic phenomena based on reading errors data. By using these tools, the hidden structure of reading errors data, such as the probability of an error-type given a dyslexia and a target-word, may be extracted.

We tested three graphical models, a Latent Dirichlet Al-location (LDA) model and two Na  X   X ve-Bayes models, all dif-fering by their complexity. The models were trained on a uniquely large data set of reading tests taken by dyslexic people.

Two experiments were conducted with the data to deter-mine: (a) which model best captures the fine structure of the patterns of reading errors, and (b) which model best agrees with expert diagnoses. Figure 6: Perplexity values calculated for the NB2 and LDA models for varying size of typical-error prior value  X  high .

To answer the above questions, multiple models where trained on a large corpus including 313 subjects and 196 tar-get words in each test. Note that the majority of responses on the reading tests are correct responses of the subject, therefore most of the information about the structure of the errors resides in a small proportion of the data ( &lt; 20%). We expect accuracy of algorithms to improve as more data is accumulated.

The results show that the LDA model achieves best per-formance in terms of predicting reading errors, and it is therefore best in capturing the fine structure of the data. This result has both theoretical and practical implications. It may contribute to the understanding of dyslexic phenom-ena, and it may be used to improve designs of screening tests.

Another result of this study may serve as an application for diagnosis of dyslexia. NB2 was best in replicating di-agnoses of experts ( AUC = 0 . 801). This is yet another demonstration of Na  X   X ve-Bayes models being efficient classi-fiers. Note that in this study all models were trained on the screening-tests only, whereas diagnoses of clinicians are usually based on the results of the post-tests as well. The data-driven models, and particularly NB2, performed well in detecting the dyslexia subtype without leveraging the post-test information and thus are very effective.

Finally, the predictive power of the Na  X   X ve-Bayes and LDA models is improved when the models are provided with pri-ors which are set according to knowledge of experts from the subtype approach. If the subtype approach were wrong, adding these priors would damage the predictive power of the model rather than improving it. The accuracy of these models is also improved when providing the models with such priors. Our work therefore provides support to the subtype approach to dyslexia, and exemplifies the ability of probabilistic graphical models to shed light on theoretical is-sues from different research fields, such as reading disorders in the case here.

Our vision is to deploy the algorithm of the NB2 model as a mobile application, providing an accessible, cheap and fast screening test, which allows people to obtain initial screen-ing results, helping them decide whether further diagnosis is needed. This can be achieved by a mobile application which presents a series of words, asks the user to read them aloud, recognizes the spoken words, and uses the diagno-sis algorithms described here to provide an initial diagnosis. The main challenge in achieving this is having the speech recognition component recognize utterances that are non-words. Responses of dyslexic people may differ from exist-ing words, whereas automatic speech recognizers (ASRs) are often trained to provide the most likely word elicited. For example, a subject may read an existing word such as cloud , as another existing word could , but also as a nonword such as clud . This kind of distinction is crucial for the diagnosis. This challenge can be addressed by training and assessing ASR tools on data sets of labeled nonwords.

To conclude, this study is a demonstration of the use of probabilistic graphical models as a method of analyzing reading errors data. The progress presented in this paper can also be deployed as a novel, efficient diagnostic tool for dyslexia, based on reading errors only. The Naive-Bayes model tested in this research was compared to labels given by experts in diagnosis of dyslexia, and was found to be an accurate and reliable candidate for an automated tool for initial screening of dyslexia, by its subtypes.

In this section, we expand on the derivation of the update rule of the Gibbs sampler (section 4.2). The derivation we use follows similar lines as the ones described in [15], with the modification required for our dyslexia-model (figure 2C):
The joint distribution of the model is given by: p (  X  e,  X  w,  X  d,  X  ,  X ;  X , X  ) = p ( X  |  X  ) p (  X  ) p ( X  s |  X  s ) p (  X  s ) = p ( X  |  X  ) p (  X  ) p ( w i,s ) p (  X  s ) Given that p ( X  s |  X  s ) and p ( X  |  X  ) are Dirichlet priors, and that p ( w i,s ) are constant, rewriting the expression for the joint distribution, we get: Table 2: List of error types and possible responsible dyslexia types. NS -Normal State; LPD -Letter Po-sition Dyslexia; VD -Visual Dyslexia; VLD -Vowel Letter Dyslexia; AD -Attentional Dyslexia; ND -Neglect Dyslexia; Other -Other types of dyslexia, such as phonological output buffer dyslexia or deep dyslexia, which are diagnosed based on additional post-tests.
 1 Correct response NS 2 Consonant migration LPD, VD 3 Consonant omission VD 4 Consonant addition VD 5 Consonant substitution VD 6 Vowel migration VLD, LPD, VD 7 Vowel omission VLD, VD 8 Vowel addition VLD, VD 9 Vowel substitution VLD, VD 10 Semantic error Other 11 Morphological error Other 12 Surface error SD 13 Visual error (left side) ND, VD 14 Function word error Other 15 Letter doubling, or double omission LPD, VD 16 Attentional omission AD 17 Attentional vowel letter error AD, VLD 18 Attentional migration between words AD 19 Migration of end letters VD Integrating out  X  and  X  , we get: p (  X  e,  X  w,  X  d ;  X , X  )  X 
ZZ S Y
Z Y The posterior distribution for the i th dyslexic state can now be expressed using the expression for the joint distribution: The numerator and denominator of the above fraction, dif-fer only by the counts having the i th pair of word-error in them, whereas all other terms cancel out. The posterior dis-tribution thus results in the following update rule (section 4.2.3):
The list of all error-types used to encode the data is shown in table 2. Possible dyslexia-types which may be responsible for each error are listed in the second column.
 [1] D. M. Blei, A. Y. Ng, and M. I. Jordan.  X  X atent dirich-[2] B. Boets et al.  X  X ntact but less accessible phonetic [3] Y. M. Broom and Doctor A. E.  X  X evelopmental phono-[4] A. Castles, T. Bates, and M. Coltheart.  X  X ohn Mar-[5] A. Castles and M. Coltheart.  X  X arieties of developmen-[6] M. Coltheart and S. Kohnen.  X  X cquired and devel-[7] M. Coltheart et al.  X  X urface dyslexia X . In: Quarterly [8] S. Dehaene. Reading in the brain: The new science of [9] J. G. Elliott and E. L. Grigorenko. The dyslexia debate . [10] M. van Ermingen-Marbach et al.  X  X istinct neural sig-[11] N. Friedmann and M. Coltheart.  X  X ypes of develop-[12] N. Friedmann and A. Gvion.  X  X etter position dyslexia X . [13] N. Friedmann and A. Gvion. TILTAN: Battery for the [14] P. Georgiewa et al.  X  X honological processing in dyslexic [15] T. L. Griffiths and M. Steyvers.  X  X inding scientific top-[16] G. Jobard, F. Crivello, and N. Tzourio-Mazoyer.  X  X val-[17] L. Khentov-Kraus and N. Friedmann.  X  X yslexia in vowel [18] P. Langley, W. Iba, and K. Thompson.  X  X n analysis of [19] J. Levy et al.  X  X esting for the dual-route cascade read-[20] J. C. Marshall and F. Newcombe.  X  X atterns of par-[21] T. Minka and J. Lafferty.  X  X xpectation-propagation [22] J. Pedler.  X  X omputer correction of real-word spelling [23] B. F. Pennington.  X  X rom single to multiple deficit mod-[24] B. F. Pennington et al.  X  X ndividual prediction of dyslexia [25] C. J. Price.  X  X  review and synthesis of the first 20years [26] F. Ramus.  X  X euroimaging sheds new light on the phono-[27] F. Ramus and G. Szenkovits.  X  X hat phonological deficit? X  [28] F. Ramus et al.  X  X heories of developmental dyslexia: [29] L. Rello, R. Baeza-Yates, and J. Llisterri DysList.  X  X n [30] S. Robidoux and S. Pritchard.  X  X ierarchical Clustering [31] M. Rosen-Zvi et al.  X  X he author-topic model for au-[32] E. M. Saffran and H. B. Coslett.  X  X mplicit vs. letter-[33] T. Shallice and E. K. Warrington.  X  X he possible role [34] S. E. Shaywitz and B. A. Shaywitz.  X  X yslexia (specific [35] M. J. Snowling. Dyslexia . Blackwell Publishing, 2000. [36] M. J. Snowling.  X  X yslexia as a Phonological Deficit: [37] J. Stein.  X  X he magnocellular theory of developmental [38] G. Vallar, C. Burani, and L. S. Arduino.  X  X eglect dyslexia: [39] H. M. Wallach, D. Minmo, and A. McCallum.  X  X e-
