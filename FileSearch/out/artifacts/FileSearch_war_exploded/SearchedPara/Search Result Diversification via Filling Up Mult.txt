 Result diversification is a topic of great value for enhancing user experience in many fields, such as web search and recommender systems. Many existing methods generate a diversified result in a sequential manner, but they work well only if the preceding choices are optimal or close to the optimal solution. Moreover, a manually tuned parameter (say,  X  ) is often required to trade off relevance and diversity . This makes it difficult to know whether the failures are caused by the optimization criterion or the setting of  X  . In context of web search, we formulate the result diversification task as a 0-1 multiple subtopic knapsack problem (MSKP), where a subset of documents are optimally chosen like filling up multiple subtopic knapsacks. This formulation yields no trade-off parameters to be specified beforehand. Solving the 0-1 MSKP is NP-hard, we treat the optimization of 0-1 MSKP using a graphical model over latent binary variables as a maximum posterior inference problem, and tackle it with the max-sum belief propagation algorithm. To val-idate the effectiveness and efficiency of the proposed 0-1 MSKP model, we conduct a series of experiments on two TREC diver-sity collections. The experimental results show that the proposed model outperforms several state-of-the-art methods significantly, not only in terms of standard diversity metrics (  X  -nDCG, nERR-IA and subtopic recall), but also in terms of efficiency. H.3.3 [ Information Search and Retrieval ] Diversification; Knapsack problem; Message passing
Recent studies show that billions of daily searches are made by web users. Instead of formulating natural language queries, the vast majority of users are submitting short queries with little or no con-text, which are often ambiguous and/or underspecified [32]. Con-sider the well-worn query Harry Potter for example, it could refer to a book or a movie . For the movie , a user may be interested in the main character or reviews . In view of the above-mentioned facts, the technique of result diversification (e.g., [1, 23, 13, 6, 14, 20]) has been proposed to tackle queries with unclear information needs, which has attracted significant attention in fields of web search and recommender systems. In this paper, we focus on the field of web search, and the concept of subtopic is used to refer to a possible information need or an intent underlying a query (sometimes they are used interchangeably). Among the literatures of various result diversification approaches, the most commonly mentioned notions are relevance , novelty and diversity . Relevance denotes how well a document meets a subtopic or a set of subtopics underlying a query. Novelty denotes how different the information provided by a doc-ument is with respect to the documents seen in the past. Clarke et al. [9] made a distinction between novelty and diversity as that: novelty is considered as a feature to avoid redundancy and diversity is considered as a feature to resolve ambiguity. Novelty is closely related to diversity in the sense that documents which are diverse from those at earlier ranks provide novel information. Moreover, the promotion of novelty and diversity is inherently linked to a query itself. A system that enhances diversity tends to generate a result with novel information. Relevance, diversity and/or novelty are combined in various ways by different diversification models, which feature a trade-off between relevance (ranking more relevant documents in higher positions) and diversity (assigning documents for each possible subtopic). By providing a diversified result list, these models increase the likelihood that users find documents rel-evant to their specific intents, and thus enhance user experience.
The task of generating a diversified result, with respect to the subtopics of a given query, has been investigated mainly from the perspective of balancing relevance and diversity. In other words, most prior approaches first provide various definitions of diversity based on content (or similarity), novelty or semantic coverage , and then select the k documents with the highest score according to some heuristic criteria [12]. Most of the time, a manually tuned parameter  X  is required to balance relevance and diversity. In this paper, we formulate the task of result diversification as filling up multiple subtopic knapsacks. The 0-1 Multiple Knapsack Problem (MKP) [22] is a problem of assigning m items, each having a profit and a weight , to n knapsacks in such a way that the total weight in each knapsack does not exceed its capacity limit and the total profit in the knapsacks is maximized. Analogous to the 0-1 MKP, we view each subtopic as a knapsack, the number of documents that can be assigned to a subtopic as its capacity, the weight of a document as a unit 1, the relevance score between a document and a subtopic as the document X  X  profit when assigning documents to a specific subtopic knapsack. For a given query q , let D be a set of documents, S be the desired subset of D for forming the ranked list (commonly, | S |  X  | D | ), the problem of result diversification can be regarded as assigning | D | documents to | T | subtopic knap-sacks ( T refers to the subtopic set of q ), whilst respecting the total capacity limit | S | . Within the context of web search, some mean-ingful constraints are further incorporated. For example, instead of hard-capacitated knapsack packing like the typical 0-1 MKP, it will be penalized if the number of documents in a subtopic knap-sack exceeds its capacity limit, whilst respecting the total capacity limit | S | . We call the resulting model as a 0-1 multiple subtopic knapsack problem (MSKP), which can be regarded as a variant of the traditional 0-1 MKP. Take the query Harry Potter again as an example, suppose there are merely two subtopics (say, book and movie ), the corresponding popularity are 0 . 6 and 0 . 4, and the target is to generate a ranked list of | S | = 10. Under the 0-1 MSKP model, we assume that the capacity of each subtopic knapsack is propor-tional to the subtopic X  X  popularity. Thus the capacity of the two subtopic knapsacks  X  X ook X  and  X  X ovie X  will be 6 and 4 respec-tively, the objective is to optimally select 10 documents to fill up the two subtopic knapsacks. Since a subtopic knapsack essentially is a subtopic, sometimes they are used interchangeably.
Based on the above analogy, we further propose a graphical model for solving the 0-1 multiple subtopic knapsack problem. It is an adaptation of the max-sum belief propagation algorithm, a stan-dard algorithm for finding the maximum joint likelihood of a set of latent variables. We compare the effectiveness and efficiency of the proposed 0-1 MSKP model to other diversification methods based on two TREC diversity collections. The experimental results show that the proposed approach outperforms the baseline meth-ods, not only in terms of several standard diversity metrics, such as  X  -nDCG, nERR-IA and subtopic recall that many models have been designed to optimize, but also in terms of efficiency.
In the next section, we briefly survey the typical models for re-sult diversification. In section 3, the 0-1 multiple subtopic knap-sack problem for result diversification is formalized in context of web search. Relying on the max-sum belief propagation algorithm, we further describe in detail a graphical model for solving the 0-1 multiple subtopic knapsack problem. A series of experiments are conducted and discussed in section 4. We conclude our work in section 5.
In this section, we give a brief survey of the typical approaches for result diversification. For detailed review, please refer to the work [12, 28]. To generate a subset of documents that are both relevant and diverse simultaneously, the most intuitive way is the greedy best first strategy . At the beginning, this strategy initial-izes S with the most relevant document d  X  1 , and then selects the subsequent documents one by one according to a specific heuristic criterion, e.g., where d  X  j represents the document selected at j -th round, S { d 1 ,..., d and a document, W ( d j , S j  X  1 ) measures how far d j disperses with respect to S j  X  1 . At each round, it involves examining each docu-ment that has not been selected, computing a gain using the above heuristic criterion, and selecting the one with a maximum gain.
A typical instance is the well-known Maximal Marginal Rel-evance (MMR) model [4]. In MMR, W ( d j , S j  X  1 ) is defined as -max ilarity among two documents. As studied by Zuccon et al. [35], the diversity models of Modern Portfolio Theory (MPT) [29] and Quantum Probability Ranking Principle (QPRP) [34] can also be rewritten as different variants of the greedy best first strategy. The xQuAD framework [25] took into account the possible subtopics to promote diversity. For each selected document, xQuAD down-weights each of the subtopics based on the degree of its relevance to the already selected documents, thus the subtopics with less rel-evant documents will have a higher priority in the next round. Sim-ilarly, Dang and Croft [11] studied result diversification by consid-ering the notion of proportionality, they argued that the number of documents assigned to a specific subtopic should be proportional to this subtopic X  X  popularity. At each step, the document that best maintains the overall proportionality is selected, and then the so-called quotient of the corresponding subtopic will be updated.
Under the greedy best first strategy, the previously selected doc-uments would no longer be the ones that maximize the gain value in later rounds. A natural extension is the greedy best k strategy . It initializes S with an arbitrary solution (e.g., the k most relevant documents or random k documents), and then iteratively refines S by swapping a document in S with another one in D \ S . At each round, interchanges are made only when the current solution can be improved. The process may be terminated until it converges or after a fixed number of iterations. Take the Desirable Facility Placement (DFP) model [35] as an example, the objective function to be minimized is written as: where this time W ( d i , d j ) defines the distance between documents. The second part of  X  d diversity, which resembles the famous k-medoids clustering prob-lem [18]. Due to the complexness of the second part, this strategy often runs with a high computational cost, which is shown in sec-tion 4.5.

A common place between greedy best first strategy and greedy best k strategy is the manually tuned parameter  X  , which trades off relevance and diversity. As shown in section 4.3, both of the two strategies suffer from the fact that the  X  achieving the best per-formance differs from query to query. In view of this, Sanner et al. [24] proposed to perform the greedy optimization of Exp -1-call @ k w.r.t. a latent subtopic model, the selecting criteria is given as: where at each step, d  X  j is selected so as to maximize a similar-ity function while minimizing a diversity penalty that increases as S  X  j  X  1  X  X  coverage of query-relevant subtopics in document d creases.

There are also many supervised methods for result diversifica-tion, such as [2, 30, 3]. In this paper, we do not investigate the methods of this kind and put more efforts on the inherently unsuper-vised ones. Different from the existing work, we formulate search result diversification as a 0-1 multiple subtopic knapsack problem. On one hand, it yields no manually tuned parameter to trade off relevance and diversity. On the other hand, we solve the derived 0-1 multiple subtopic knapsack problem using a graphical model, which allows us to simultaneously consider all the documents and gradually identify the optimal subset.
For a query q , let T = { t 1 ,..., t n } be the corresponding subtopic set, the popularity of each subtopic be p 1 ,..., p n , D = { d be the top-m documents of an initial retrieval run. We formulate the task of result diversification, i.e., selecting the optimal subset S from document set D that are both diverse and relevant w.r.t. subtopic set T , as a 0-1 multiple subtopic knapsack problem (MSKP). Without loss of generality, it is formalized as the following integer linear program: where y j indicates whether document d j is selected, x ij whether document d j is assigned to the subtopic knapsack t notes the relevance score between subtopic t i and document d denotes the similarity between the k -th subtopic and i -th subtopic ( s uments assigned to subtopic knapsack t i , and c i denotes the capac-ity of subtopic knapsack t i . For convenience, x : j = { x | S | =  X  i c i , i.e., the total weight in the subtopic knapsacks is ex-actly the size of S . In order to achieve the optimal diversification result, Equation 8, Equation 9 and Equation 10 are ad-hoc restric-tions. Specifically, (1) Instead of hard-capacitated knapsack packing like the typi-cal 0-1 MKP, Equation 9 means that: a subtopic knapsack will be penalized by function f when the number of assigned documents exceeds its capacity. Combined with Equation 8, they enforce the constraint that the total number of packed documents must be equal to the size of S . (2) Equation 10 means that: we prefer the assignment that pack-ing a document into a more relevant subtopic knapsack with a higher popularity. Specifically, under Equation 5 and Equation 6, a docu-ment can only be packed into one subtopic knapsack if it is selected. In Equation 10, for a specific document d j , the product of p represents the relative  X  X rofit X  if it is assigned to the i -th subtopic knapsack. Once a document d j is selected (i.e., y j = 1), we have x host knapsack is the k -th subtopic knapsack. If the  X  X rofit X  p is not the maximum one in the set of { p 1 r 1 j ,..., p n be negative values (e.g., p k r k j  X  p t r t j , where p decrease the objective (Equation 4). As s ki represents the similar-ity between two subtopics, 1  X  s ki indicates the divergence between two subtopics. By multiplying 1  X  s ki , packing a document into a similar subtopic knapsack is a better choice if not the most prof-itable one.

Finally, the objective (Equation 4) is to maximize the sum of all relevance scores between the selected documents and their host subtopic knapsacks plus the penalties for knapsacks of which the capacity limit are exceeded, whilst respecting several ad-hoc re-strictions.
Since the proposed 0-1 multiple subtopic knapsack model is a variant of the typical 0-1 MKP that is in general NP-hard, exactly searching for an optimal configuration of matrix x = [ x ij vector y = [ y j ] 1  X  m that maximizes the objective (Equation 4) is also NP-hard. Here we follow a number of recent works [15, 21], in which the message passing algorithm is used to find the optimal in-teger linear program solution. We formulate the optimization of 0-1 MSKP using a graphical model over the binary random variables x and y as a maximum posterior (MAP) inference problem, i.e, searching a setting of x and y that achieves the largest joint likeli-hood. This can be tackled through a closely related algorithm called max-sum inference (log-domain max-product) [19, 10]. Fig.1 illus-trates the factor graph corresponding to the 0-1 MSKP.
R
R R
Corresponding to the factor graph in Fig.1, the factor potentials are given as follows: the optimization objective.  X  C i ( x i : , u i ) ,  X  F j are constraint factors. In particular, (1)  X  C i ( x i : , u i ) enforces the constraint expressed by Equation 7. Namely, the packed documents in a subtopic knapsack are the same as the documents being selected. (2)  X  F j ( x : j , y j ) enforces the constraint expressed by Equation 5, and reflects the optimization objective (Equation 10) at the same time. Namely, if a document is selected, it only can be packed into one subtopic knapsack. By function w j ( x : j , y j section 3, we prefer the assignment of packing a document into a more relevant subtopic knapsack with a higher popularity. In implementation, function w j ( x : j , y j ) needs to be calculated only when y j = 1, with which we get x k j  X  x ij = 1. Thus the part of  X  can be computed ahead of time, so as to avoid repeated computa-tion during message passing. (3) To accomplish the constraint of Equation 8, i.e., the total number of packed documents is exactly the same as the size of S , we incorporate a Hidden Markov Model (HMM) using the strat-egy proposed by Lazic [21]. Under this hidden markov model, z as noisy observations. By setting z 0 = 0 and enforcing the con-z =  X  m k = 1 y k corresponds to the total number of packed documents w.r.t. the total subtopic knapsacks. Moreover, an arbitrary potential (i.e., the size of S ) on z m is incorporated via the factor G
To solve the 0-1 multiple subtopic knapsack problem, now we have turned to search the optimal setting that maximizes the fol-lowing max-sum objective: In general, most of the belief propagation algorithms proceed by iteratively passing vector-valued messages between variable nodes and factor nodes in a factor graph. In our case, scalar messages are utilized following the works [15, 16], i.e., only propagating the difference between the message values. As shown in Fig.2, there are 14 types of messages propagated along each edge in the factor graph.

The message update equations for the factor graph in Fig.1 are summarized as follows (the detailed derivation can be found in the appendix): Figure 2: The messages propagated between variable nodes and factor nodes.  X  j = max where x  X  ij represents x : j \ x ij in Equation 17.

Algorithm 1 details the max-sum algorithm for tackling the 0-1 multiple subtopic knapsack problem.

The notations in bold  X  ,  X  , v ,  X  , h , a and b are used to represent matrices [  X  ] n  X  m , [  X  ] n  X  m , [ v ] 1  X  m , [  X  ] 1  X  m [ b ] ( m + 1 )  X  ( m + 1 ) respectively. Function eval () computes the result according to the input equation. Function convergence () is used to check whether the algorithm has converged or the local decisions stay constant. When updating the messages, it is important to take into account the message oscillations that arise in some circum-stances. In particular, each message is set to  X  times its value from the previous iteration plus 1  X   X  times its prescribed updated value, where  X   X  [ 0 , 1 ) . The updating procedure may be terminated after a fixed number of iterations (e.g., the threshold in Algorithm 1), or after the local decisions stay constant for some number of iter-ations. In our experiments, we set  X  = 0 . 5 and threshold = 5000. Finally, we sum together all incoming messages for variables y , the computed belief is denoted as b y . Intuitively, the magnitude of y belief is interpreted as an accumulated appropriate evidence that document d j should be selected. The selection vector y  X  to 1 or 0 using the Iverson notation ( [ true ] = 1 and [ false ] = 0), where y  X  j = 1 indicates that document d j is selected. Meanwhile, Algorithm 1 Max-sum algorithm for 0-1 MSKP 1: Initialize  X   X  0,  X   X  0, v  X  0,  X   X  0, h  X  0, a  X  0, 2: while !convergence() and count  X  threshold do 3:  X   X   X  X  +( 1  X   X  ) eval ( Equation -17 ) ; 4:  X   X   X  X  +( 1  X   X  ) eval ( Equation -18 ) ; 5: v  X   X  v +( 1  X   X  ) eval ( Equation -19 ) ; 6: h  X   X  h +( 1  X   X  ) eval ( Equation -21 ) ; 7: update( a , b ); 8:  X   X   X  X  +( 1  X   X  ) eval ( Equation -20 ) ; 9: count ++; 10: end while 11: b y =  X  + v 12: y  X  = I [ b y  X  0 ] 13: 14: Function update( a , b ) 15: Initialize z 0 = 0, b m ( z m ) = G m + 1 ( z m ) ; 16: for j = 1: m do 17: a j ( z j ) = max { a j  X  1 ( z j ) , a j  X  1 ( z j  X  1 )+ v 18: end for 19: for j = m :1 do 20: b j  X  1 ( z j  X  1 ) = max { b j ( z j  X  1 ) , b j ( z 21: end for 22: the selected documents are sorted by their belief values in descend-ing order. The standard test collections released in the diversity tasks of TREC 2009 Web Track (WT-2009) [7] and TREC 2010 Web Track (WT-2010) [8] are adopted (50 queries each). Our query set con-sists of 50 queries from WT-2009 and 48 queries from WT-2010 (queries numbered 95 and 100 are discarded due to no judgment data).

The evaluation metrics used in the diversity tasks of WT-2010 are adopted, i.e., novelty-biased discounted cumulative Gain (  X  -nDCG) [9], normalized intent-aware expected reciprocal (nERR-IA) [5] and subtopic recall (strec) [33]. For  X  -nDCG, the gain of a document will be discounted based on how much novel infor-mation it provides. The parameter  X  is used to determine the bal-ance between rewarding relevance and intent coverage. nERR-IA is obtained by averaging the value of ERR [5] w.r.t each subtopic, weighted by the subtopic popularity. Subtopic recall explicitly mea-sures diversity in terms of subtopic coverage in a document rank-ing. In particular, all of these measures are computed using the top 20 documents of each model. The script ndeval10 1 of WT-2010 is used following the default settings.
Across this study, the OKAPI BM25 model ( k 1 =1 . 2, k 3 b =0 . 5 using the kernel technique by Xu et al. [31]) is used to com-pute the relevance score between a query (a subtopic string as well) and a document, the similarity score between two subtopics. The standard TFIDF model is used to compute the similarity score be-tween two documents. The parameter settings of each model are summarized as follows: http://trec.nist.gov/data/web10.html 1. BM25 Baseline (BM25). Following the same retrieval setup [24, 17], the OKAPI BM25 model is used to perform the initial re-trieval run. In our experiments, the  X  X uery X  field of the test topic is used as the initial query. On one hand, this run is used as a naive baseline without diversification, on the other hand, the top-100 documents are further used for other diversity models to per-form re-ranking. 2. Maximal Marginal Relevance (MMR). The widely mentioned MMR method by Carbonell and Goldstein [4] is compared. For the tuning parameter  X  , instead of an arbitrary value 0 . 5, it is ob-tained by averaging the optimal  X  of each query. In particular, the  X  derived from WT-2009 is used for WT-2010, and vice versa. The derivation is detailed in section 4.3. 3. Desirable Facility Placement (DFP). The desirable facility placement model proposed by Zuccon et al. [35] is compared. For the tuning parameter  X  , it is obtained in the same way as the  X  of MMR (section 4.3). The iteration threshold is 10000. It should be noted that the results of DFP should be taken as indicative only, because our initial run is different from the original paper. 4. Expected 1  X  call @ k (1-call@k). By combining diversity via a latent subtopic model of binary relevance, the Expected 1  X  call @ k model [24] removes the need of a tuning parameter  X  . We follow the same setting as suggested by Sanner et al. [24], Specif-ically, a Latent Dirichlet Allocation (LDA) topic model (  X  =2 . 0,  X  =0 . 5, topic number is 15) is trained on the top-100 OKAPI BM25 results for each query and the obtained subtopic distributions are used for the similarity and diversity kernels. 5. 0-1 Multiple Subtopic Knapsack Problem (MSKP). For the proposed 0-1 MSKP model, the official subtopics annotated by the TREC assessors are directly used. This enables us to investigate the effectiveness of this model without the possible impact of subtopic identification. However, the subtopic popularity is not available. Similar to the existing works [26, 27, 11], we assume uniform pop-ularity for all subtopics, and the capacity of each subtopic knapsack the fact that sometimes | S | is not divisible by | T | . Thus, it sets a larger capacity limit for each subtopic knapsack if needed, which ensures a uniform popularity, finally the top-| S | ranked documents of the list generated by the 0-1 MSKP model are used.
As for result diversification, many approaches require the tuning parameter  X  so as to make a balance between relevance and diver-sity. However, the effect of  X  has not yet been thoroughly explored. Many existing approaches treat a query set as a whole when tun-ing  X  for improvements. To investigate the impact of  X  on models of this kind (e.g., MMR and DFP), we tune  X  for each query by varying  X  in the range [ 0 , 1 ] with a step of 0.1. Then we compute the distribution of queries with respect to the optimal  X  , with which the model achieves the best performance in terms of  X  -nDCG@20 (other diversity metrics would lead to a consistent result). For mod-els of MMR and DFP, Fig.3 illustrates the query distribution w.r.t. the optimal  X  on WT-2009 and WT-2010 respectively.

As can be observed from Fig.3(a) and Fig.3(b), the queries are skewly distributed for both MMR and DFP. In other words, many queries achieve the best performance in terms of  X  -NDCG@20 with different  X  s, especially with  X  = 0 and  X  = 1. This is probably because the inherent relevance and diversity among documents are not simply combined in a  X  way as expected. At the same time, this observation indicates that the performance will be discounted if we set the same  X  for a whole query set. In our later experimental comparisons w.r.t MMR and DFP, the average value of all optimal  X  s of queries in a set is used. Specifically, the averaged  X  derived from WT-2009 is used for WT-2010, and vice versa. Under the MMR model, the averaged  X  s of WT-2009 and WT-2010 are 0 . 272 and 0 . 1813 respectively. Under the DFP model, the averaged  X  s of WT-2009 and WT-2010 are 0 . 43 and 0 . 55 respectively.
Table 1 shows the results obtained for BM25, MMR, DFP, 1-call@k and 0-1 MSKP in terms of  X  -nDCG, nERR-IA and subtopic recall (strec). As the first page of a search engine X  X  result generally has 10 slots, we use strec@10 to measure the subtopic coverage.
An overview of the results in Table 1 is that: all models except 1-call@k perform worse in position-sensitive metrics of  X  -nDCG and nERR-IA on WT-2010 than they do on WT-2009. The reason is that all the diversification models rely on the initial retrieval run BM25, which performs better on WT-2009 than that on WT-2010. As a non-position based metric, subtopic recall does not account for ranking a relevant document at position r  X  1 or r  X  2. Thus the results of diversification models are not consistent with BM25 in terms of subtopic recall. Furthermore, though MMR, DFP and 1-call@k take into account the diversity feature, these models do not consistently outperform the BM25 baseline. On WT-2009, MMR and DFP outperforms BM25 in terms of nERR-IA with different cutoff values, whereas in terms of  X  -nDCG, only with a cutoff of 5. On WT-2010, DFP performs worse than it does on WT-2009, and shows a worse result than BM25. On the contrary, 1-call@k performs better on WT-2010, and shows a better result than BM25. For the reason why DFP and 1-call@k do not achieve substantial improvements over BM25, the probable explanations are: (1) To derive novelty and diversity, DFP selects k best representative docu-ments from the initial run in a way of k-medoids clustering. If most documents in the initial run are non-relevant ones, these noisy doc-uments will discount the obtained diversity. (2) 1-call@k makes use of the documents in the initial run to train a latent subtopic model, then it is further used to quantify the similarity between the input query and a document, as well as the dispersion between two documents. If most documents in the initial run are non-relevant ones, the effectiveness of the obtained subtopic model will be dis-counted again. To examine how many noisy documents we have in the initial run, Table 2 shows the averaged ratio of documents that provide useful information being relevant to at least one subtopic. For example, among the top-100 documents in WT-2009, the doc-uments that provide useful information merely account for an aver-aged ratio of 0.1532.

Table 2 indicates that noisy information will be mixed if we use all the documents in the initial run for training a particular model or computing diversity. This also explains the low performance of DFP and 1-call@k to some extent.

As expected the proposed 0-1 MSKP outperforms the other meth-ods considerably across all the metrics on both WT-2009 and WT-2010. The effectiveness of the 0-1 MSKP model depends on the following factors: (1) It performs result diversification using ex-plicit subtopics. Compared with DFP and 1-call@k, the 0-1 MSKP model reduces the risk of mixing noisy documents that are not rel-evant to the subtopics of an input query. (2) As discussed in sec-tion 4.3, the optimal  X  differs from query to query. Different from MMR and DFP, the 0-1 MSKP model requires no parameters to be specified beforehand for balancing relevance and diversity. (3) For the methods (e.g., MMR and 1-call@k) that generate a diver-sified list sequentially, a drawback is that after the addition of a document, previously selected documents would no longer be the ones that maximize the overall objective of the entire ranked list. The problem arises when the preceding documents are not optimal, which may provide some misleading information. By simultane-ously considering all the documents and gradually identifying the optimal subset, the 0-1 MSKP model is able to get rid of noisy documents.
 Despite the above advantages, there are also some failure cases. Table 3 shows the queries for which the 0-1 MSKP model failed to select the predefined number of documents. For example, for queries numbered 23 (from WT-2009) and 83 (from WT-2010), only 17 and 14 documents were selected respectively. For queries numbered 91,92,93,94,96,97,98 and 99, no documents were se-lected. This is probably because our derived max-sum algorithm failed to converge to the optimal solution. For these queries, we took a shortcut for generating the final ranked list. Specifically, we straightforwardly rank the entries in y (section 3.1) by their belief values in decreasing order, then the corresponding documents of differences to BM25, MMR, DFP and 1-call@k respectively. D 0 . 2378
B , M 0 . 0662 B 0 . 0802 B 0 . 0979 B , M 0.2184
D 0 . 1544 D 0 . 1715 D 0 . 1839 D 0 . 3688 the top-| S | entries of y are used to for the ranked list. For finding a reasonable solution for these failure queries, we leave it as a future work.

Different from the ad-hoc retrieval tasks, each topic of the di-versity track is structured as a representative set of subtopics. The topic query is further categorized as either  X  X aceted X  or  X  X mbigu-ous X . We now investigate the effectiveness of the different mod-els on faceted queries and ambiguous queries separately. Table 4 shows the results obtained for MMR, DFP, 1-call@k and 0-1 MSKP in terms of  X  -nDCG, nERR-IA and subtopic recall (strec) on faceted and ambiguous queries respectively.

In WT-2009, there are 38 faceted queries and 12 ambiguous queries. In WT-2010, they are 22 and 26. From Table 4, the first observation is that all models perform worse in all metrics on ambiguous queries than they do on faceted queries, except a spe-cial case for 1-call@k in terms of  X  -nDCG@5. As for the differ-ences between faceted queries and ambiguous queries, the TREC assumption 2 goes like this: For an ambiguous query that has di-verse interpretations, the users are assumed to be interested in only one of these interpretations. For a faceted query that reflects an underspecified subtopic of interest, the users are assumed to inter-ested in one subtopic, but may still be interested in others as well. As a position-insensitive metric, the lower strec for all models on ambiguous queries than that on faceted queries indicates that it is relatively harder to select diverse documents to guarantee a high subtopic coverage.

Moreover, the proposed 0-1 MSKP model outperforms the other methods in all metrics on both faceted queries and ambiguous queries, except the case for MMR in terms of strec. The 0-1 MSKP model gets a lower subtopic recall than MMR on ambiguous queries. The explanation for MMR that achieves a better strec but lower results in other metrics is that: Keeping in mind that strec does not account for ranking a relevant document at position r  X  1 or r  X  2, this re-sult indicates that MMR failed to rank the high-quality documents in higher positions. On the contrary, the 0-1 MSKP model performs http://plg.uwaterloo.ca/ trecweb/2010.html a more reasonable ranking for documents providing relevant infor-mation to different subtopics, thus gets a higher value in terms of other metrics.
We also evaluated the overhead of each diversification model by the average runtime per query for generating the result. All the experiments are conducted using Eclipse (Release 4.3.2) on a desktop computer (Windows 64 bit, Intel Core2 Quad CPU Q9400 2.66GHz, 12 GB of RAM). Table 5 illustrates the runtime per query in msec.

As can be observed from Table 5, DFP is the most computa-tionally expensive. The probable explanation is that: the objective function of DFP includes a part of NP-hard k-medoids clustering (Equation 2, and it is optimized using a greedy local search al-gorithm, e.g., hill climbing). 1  X  call @ k requires more time than MMR, because a topic model needs to be trained based on the top-100 BM25 results for each query for computing topic distributions. Though our 0-1 MSKP method is also a NP-hard model, the time required for it is the same order of magnitude w.r.t the intuitive greedy best first model (MMR), which is relatively fast. Because the proposed approach for tackling 0-1 MSKP is essentially an ap-plication of the inference algorithm max-sum, which commonly requires less computational cost than many other greedy search al-gorithms [15]. Moreover, the results should be taken as indicative only, because particular efforts can be put in optimizing the codes of each method, which is beyond the scope of this paper.
In this paper, we studied the task of search result diversification for faceted queries and ambiguous queries, which receives increas-ing attention as many users commonly submit queries of this kind. Analogous to the typical 0-1 multiple knapsack problem, we pre-sented a novel model for search result diversification: 0-1 multiple subtopic knapsack problem (MSKP). Under 0-1 MSKP, the repre-sentative subtopics of a query are viewed as different knapsacks, the task of selecting an optimal subset of documents that are both in bold.
  X  -nDCG nERR-IA strec relevant and diverse is formulated as assigning documents to mul-tiple subtopic knapsacks. Within the context of web search, the ob-jective is to maximize the sum of all relevance scores between the selected documents and their corresponding linked subtopics plus the penalties for subtopic knapsacks of which the capacity limit are exceeded, whilst respecting several ad-hoc restrictions. To solve this NP-hard optimization, the max-sum belief propagation algo-rithm is utilized to search a configuration that achieves the maxi-mum joint likelihood. The experimental results have demonstrated that the proposed model is statistically significantly better than sev-eral state-of-the-art methods not only in terms of standard diversity metrics (  X  -nDCG, nERR-IA and subtopic recall), but also in terms of efficiency. By the way, the problems analogous to the 0-1 mul-tiple subtopic knapsack problem arise in a variety of applications, e.g., recommender systems. We believe that our approach provides a new perspective for addressing problems of this kind.
A limitation of our current work is that: as stated in section 4.4, our approach failed to generate the desired results for 10 queries. We took a shortcut and still used the belief values to generate results for these queries. In our future work, we will study the convergence property of 0-1 MSKP model so as to obtain a more robust ap-proach. Compared to the utilization of official subtopics annotated by the TREC assessors, it is worthwhile to investigate how subtopic identification affects the retrieval performance. For generating the ranked list, we straightforwardly sorted the selected documents by their belief values in decreasing order. It would be an interesting work to explore other methods for merging the selected documents of each subtopic knapsack.
We sincerely thank Dr. Scott P. Sanner for sharing the data and code. Great thanks to the reviewers for helping us improve this study. This research has been partially supported by the Ministry of Education, Science, Sports and Culture of Japan under Grant-in-Aid for Scientific Research (A) No. 22240021. [1] R. Agrawal, S. Gollapudi, A. Halverson, and S. Ieong. [2] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, [3] Z. Cao, T. Qin, T. Liu, M. Tsai, and H. Li. Learning to rank: [4] J. Carbonell and J. Goldstein. The use of mmr, [5] O. Chapelle, D. Metlzer, Y. Zhang, and P. Grinspan. [6] X. Cheng, P. Du, J. Guo, X. Zhu, and Y. Chen. Ranking on [7] C. L. Clarke, N. Craswell, and I. Soboroff. Overview of the [8] C. L. Clarke, N. Craswell, I. Soboroff, and G. V. Cormack. [9] C. L. Clarke, M. Kolla, G. V. Cormack, O. Vechtomova, [10] T. H. Cormen, C. E. Leiserson, R. L. Rivest, and C. Stein. [11] V. Dang and W. B. Croft. Diversity by proportionality: an [12] M. Drosou and E. Pitoura. Search result diversification. [13] M. Drosou and E. Pitoura. Disc diversity: result [14] P. Fraternali, D. Martinenghi, and M. Tagliasacchi. Top-k [15] B. J. Frey and D. Dueck. Clustering by passing messages [16] I. E. Givoni and B. J. Frey. A binary variable model for [17] S. Guo and S. Sanner. Probabilistic latent maximal marginal [18] J. Han, M. Kamber, and J. Pei. Data Mining: Concepts and [19] F. R. Kschischang, B. J. Frey, and H. A. Loeliger. Factor [20] O. K X  X  X ktun X , E. Saule, K. Kaya, and U. V.  X ataly X rek. [21] N. Lazic. Message Passing Algorithms for Facility Location [22] S. Martello and P. Toth. Knapsack Problems: Algorithms and [23] F. Radlinski and S. Dumais. Improving personalized web [24] S. Sanner, S. Guo, T. Graepel, S. Kharazmi, and S. Karimi. [25] R. L. Santos, C. Macdonald, and I. Ounis. Exploiting query [26] R. L. Santos, C. Macdonald, and I. Ounis. Selectively [27] R. L. Santos, C. Macdonald, and I. Ounis. Intent-aware [28] M. R. Vieira, H. L. Razente, M. C. N. Barioni, [29] J. Wang and J. Zhu. Portfolio theory of information retrieval. [30] J. Xu and H. Li. Adarank: a boosting algorithm for [31] J. Xu, H. Li, and C. Zhong. Relevance ranking using kernels. [32] H. Yu and F. Ren. Role-explicit query identification and [33] C. X. Zhai, W. W. Cohen, and J. Lafferty. Beyond [34] G. Zuccon and L. Azzopardi. Using the quantum probability [35] G. Zuccon, L. Azzopardi, D. Zhang, and J. Wang. Top-k
A message is viewed as the sum of constant and variable compo-nents. In what follows, when a variable is binary, the message is de-rived by taking the difference between its values corresponding to each setting of the binary variable. When a variable is non-binary, only the variable component is used.

Let  X  j denote the scalar message difference  X  j ( 1 )  X   X  same applies to  X  ,  X  , v ,  X  , etc. The message propagations corre-sponding to Fig.2 are derived as follows: r ( 1  X  s k i )( p k r k j  X  p i r ij )+ p k r k j } (26) r )+ p i r ij As for  X  ij ( 0 ) , it is derived w.r.t. the cases of y j ,..., x nj )+  X  )( p r  X  p r k j )+ p i r ij } , Before deriving the messages a j ( z j ) and b j  X  1 ( z j  X  1 ) for an example, { a 0 ( z 0 )+ d 1 ( y 1 ) } = by treating d 1 ( 0 ) as the constant component, we can get ( z ) } = max { a 0 ( z 1  X  1 )+ v 1 + l 1 , a 0 ( z 1 ) } (31) Analogously, we can get a j ( z j ) = max { a j  X  1 ( z j { b j ( z )+ a j  X  1 ( z  X  1 ) } X  max  X  } x  X  ik }} // w.r.t. the cases of u i = 0 and u i 6 = 0 } X  max =  X  k x ik {  X  k x ik  X  ik } , by keeping only the variable component, we can get x i k  X  ik } (36) 3.1.
