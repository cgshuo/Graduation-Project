 Jeffrey Chan  X  James Bailey  X  Christopher Leckie Abstract Graphs provide powerful abstractions of relational data, and are widely used in fields such as network management, web page analysis and sociology. While many graph representations of data describe dynamic and time evolving relationships, most graph min-ing work treats graphs as static entities. Our focus in this paper is to discover regions of a graph that are evolving in a similar manner. To discover regions of correlated spatio-temporal change in graphs, we propose an algorithm called cSTAG. Whereas most clustering tech-niques are designed to find clusters that optimise a single distance measure, cSTAG addresses the problem of finding clusters that optimise both temporal and spatial distance measures simultaneously. We show the effectiveness of cSTAG using a quantitative analysis of accu-racy on synthetic data sets, as well as demonstrating its utility on two large, real-life data sets, where one is the routing topology of the Internet, and the other is the dynamic graph of files accessed together on the 1998 World Cup official website.
 Keywords Data mining  X  Evolving graphs  X  Dynamic graph analysis  X  Spatio-temporal analysis  X  Correlated spatio-temporal changes  X  Clustering  X  Event discovery 1 Introduction Graphs are powerful abstractions of relational data, hence their popularity in many fields, including network management, sociology [ 10 ], webpage linkage analysis [ 38 ] and bioin-formatics [ 34 ]. Previous work has concentrated on discovering patterns within and among a set of static graphs X  X raphs that are not considered to change with time. Examples include finding frequent subgraphs among a set of static graphs [ 13 , 57 ], discovering communities in social and information networks [ 27 , 37 ], and using degree distributions, diameter and connectivity measures to characterise a computer science literature citation graph [ 4 ].
In contrast to the focus of this prior work, many of the relationships modelled by graphs evolve with time. The additional temporal dimension introduced by these evolving, dynamic graphs permits many new types of analyses. These include analysing how global properties of graphs, like their diameter, change with time [ 43 ], mining dynamic frequent subgraphs [ 8 ], dynamically analysing links using a form of incremental pagerank algorithm [ 19 ], and detecting anomalous changes in an evolving graph [ 49 ].

A novel but unconsidered problem in this context is how to group changes in a dy-namic graph that are topologically and temporally related. In particular, how to group similar sequences of changes that occur over the same period of time (temporally correlated), as well as the same region of the graph (spatially correlated). We refer to subgraphs that are tempo-rally and spatially correlated over a period of time as regions of correlated spatio-temporal change .

Changes to graphs can be structural, e.g., the appearance or disappearance of an edge between two snapshots of an evolving graph, changes to the weights of edges and vertices, or even changes to designated subgraphs. Although we focus on structural changes in this paper, the techniques we present to find these spatially and temporally correlated subgraphs are general, and can easily be adapted to analyse changes in other graph properties.
The problem of finding regions of correlated spatio-temporal change arises in a variety of contexts, such as:  X  Fault diagnosis: When a fault occurs in a communications network, it can induce changes  X  Mining of spatio-temporal co-occurring items: In this context [ 9 ], the aim is to find items  X  Event detection: For example, discovering external events based on an analysis of the
In this paper, we focus on the applications of fault diagnosis and event discovery in multi-layered computer networks. However, we stress that any application with data that has some relation defined over a set of entities, and exhibits correlated change behaviour, can make use of regions of correlated spatio-temporal change.

To illustrate what is a region of correlated spatio-temporal change, consider an example of five sequential snapshots of an evolving graph, shown in Fig. 1 . For example, this evolving graph could represent the routing topology of an IP network. Consider the set of edges in region A. Notice that for each of the five snapshots, the edges are either all present, or all absent. This is an example of correlated temporal behaviour. In addition, consider the shortest path distance between the edge pairs in region A X  X ll the distances are very small. This is an example of spatial correlation. Hence, the edges in region A form a region of correlated spatio-temporal change. The same type of analysis can be performed for the other regions. Note that computing the shortest path distance and requiring all edges in a region to have small temporal and spatial distances is only one method to group the changes to edges. In Sect. 3 , we shall highlight several other techniques. We use this example throughout the rest of the paper to illustrate our approach.

To discover the regions of correlated spatio-temporal change from evolving graphs, we have developed a framework named cSTAG (clustering for Spatio-Temporal Analysis of Graphs). The framework takes as input a sequence of snapshots of a dynamic graph, and outputs the discovered regions of correlated spatio-temporal change. It represents (struc-tural) changes to the graph as binary waveforms. Temporal correlation can then be measured using the distance between the associated binary waveforms. Similarly, topological distance measures are used to compute the spatial correlation, e.g., shortest path distance [ 45 ]. In addition, we introduce various clustering solutions that simultaneously incorporate temporal and spatial distance information to find regions of correlated spatio-temporal change. Finally, a region association method is presented to find regions with long-term correlation.
To demonstate the utility of spatio-temporal correlation analysis on evolving graphs, we applied cSTAG to the discovery of events in two applications. One of these applications was the discovery of the root causes of routing changes in the Border Gateway Protocol (BGP) [ 28 ] connectivity graph of the Internet during a known external event X  X he landfall of Hurricane Katrina [ 16 ]. The BGP connectivity graph models the top-level routing topology of the Internet. In this application, cSTAG was able to discriminate regions that were spa-tially or temporally close, but corresponded to different events. The other application was detecting flash crowd events at the official 1998 World Cup website. Each flash crowd event corresponded to a particular match being played.

In addition, we have evaluated cSTAG on a number of synthetic datasets, in order to quan-tify the effectiveness of different clustering methods in our framework and the effect of the parameter settings on the accuracy and timing.

In summary, the main contributions of this work are as follows: 1. We propose a new pattern to mine from evolving graphs, namely, regions of correlated 2. We provide a comprehensive evaluation of the accuracy and efficiency of cSTAG using
The rest of the paper is organised as follows. In Sect. 2 , the problem of discovering regions of correlated spatio-temporal change is formally presented. Section 3 describes the cSTAG algorithm in more detail. Accuracy and timing evaluation using synthetic datasets, and an analysis of the patterns mined from two real application domains, are presented in Sect. 4 . In Sect. 5 , related work is surveyed. Finally, Sect. 6 presents future work and concludes the paper. 2 Problem statement In this section, we formally define the problem of discovering regions of correlated spatio-temporal change. First, we introduce the notation we use. For ease of reference, Table 2 provides a description of the main symbols used in the paper.
 Agraph G ( V G , E G ) consists of a set of vertices V G , and a set of (unweighted) edges E
G , E G : V G  X  V G , representing the pairwise relationships over V G . Where there is no ambiguity, we shall use G to denote G ( V G , E G ) .A dynamic graph is represented as a sequence of consecutive snapshots G 1 , G 2 ,..., G S of the graph, 1  X  t  X  S . We denote the subsequence of snapshots (or window) &lt; G ts ,..., G te &gt; by W ts , te ,1  X  ts  X  te  X  S . W 1 , 5 from Fig. 1 . E G t + 1 ) or disappearance ( e  X  E G t , e /  X  E G t + 1 )of e between any two consecutive snapshots G , G t + 1 ,1  X  t  X  S  X  1. Then the set of all edges that have experienced at least one structural
Next, we define our notation for the change waveforms , which represent the temporal change behaviour of edges over a particular subsequence of snapshots.
 Definition 1 For structural changes to edge e i , over the subsequence W ts , te , we can represent [ te  X  ts + 1 ] ,where As an example, the change waveforms for each changed edge in Fig. 1 are shown in Table 1 . This representation of temporal behaviour can easily be extended to continuous entities, like real-valued edge weights. Where there is no ambiguity, we will use the notion q ( e i ) for q
Finally, we present the notation used to describe the temporal and spatial distance mea-sures between changed edges. We then give the formal definition of a region of correlated spatio-temporal change, and summarise the problem of discovering such regions of correlated spatio-temporal change.
 The pairwise temporal distance between a pair of edges is defined as d tem ( e i , e j , W between the two waveform representations. The temporal distance measures the difference in temporal change behaviour of the edges e i and e j over the subsequence W ts , te .Weshall elaborate on the measures we used to compute the distance in Sect. 3 . We similarly define a is based on the topological properties of the dynamic graph. As the topological properties and hence the spatial distance may change with time, spatial distance is also defined over a subsequence.
 Definition 2 A region of correlated spatio-temporal change R ts , te r is defined as a subset quence W ts , te . The set of changed waveforms associated with the changed edges in R ts , te r is denoted by R ts , te r . Q , the set of (change waveform, frequency) pairs.
 R r . Q summarises the temporal behaviour of the edges in R change waveforms for a region as the collection of the change waveforms of its member edges. Then we define the (relative) frequency of each unique change waveform in the col-lection of waveforms as the (relative) number of times it occurs. The frequency ranges from 0 (exclusive) to 1 (inclusive).

The lifetime of a region of correlated spatio-temporal change R ts , te r is defined as the period of time the edges in the region are correlated. The correlation span is required to be continuous, i.e., there are no gaps in it. The lifetime is defined by the start time ts and end time te .

For example, Table 1 shows the regions of correlated spatio-temporal change from the dynamic graph in Fig. 1 . Of particular interest are regions 5, and 5a and 5b. Region 5 has a lifetime of 1 to 4, because its three edges 12  X  13, 13  X  14 and 15  X  16 are only temporally cor-related over the subsequence &lt; G 1  X  G 4 &gt; . However, if correlation is sought over the whole sequence, then edges 12  X  13 and 13  X  14 form a region (region 5a), and edge 15  X  16 forms another (region 5b), due to the difference in their change waveforms (i.e., their temporal behaviour).

Where there is no ambiguity, we shall use Q r . q a and Q r . freq a to denote a waveform-change waveforms of a region, and freq a denotes the relative frequency of waveform q a in the region. In addition, if it is clear from the context, we use R r instead of R ts , te r .
With all the definitions in place, we can now define the set of regions of correlated spatio-temporal change and the problem of discovering these regions.
 Definition 3 The set of regions of correlated spatio-temporal change R is a hard partition h , 1  X  g , h  X  L ,and L is the number of regions.
 Definition 4 The problem of discovering regions of correlated spatio-temporal change involves finding a set of regions of correlated spatio-temporal change that maximise the following intra-region criteria simultaneously and across all regions: 1. max R R 2. max R R compactness of the edges in R r , based on the distance measures d tem and d spa respectively. Given that there are two criteria to be optimised simultaneously, the exact interpretation of maximisation in this context can be approached in several different ways. We propose several specific approaches to this problem in Sect. 3.5.1 .

To summarise, the problem of discovering regions of correlated spatio-temporal change can be summarised as follows: Input: Process: Output: 3cSTAG In this section, we first outline the challenges in solving the problem of discovering regions of correlated spatio-temporal change. We then provide an overview of cSTAG, our solution to this problem, which discovers regions of correlated spatio-temporal change. It consists of a number of components, which we will describe in the following subsections. 3.1 Challenges and overview There are a number of challenges that need to be addressed by any solution to this problem:  X  The number of regions of correlated spatio-temporal change is unknown a priori.  X  The length of correlation, or lifetime, of each region is unknown a priori.  X  The exact start time of each region is unknown a priori.

A quick sketch of a naive method to find the set of regions R demonstrates the difficulty of the problem. A naive method would partition the sequence into a number of overlapping windows, of lengths 2 to S . Then for each window, it would enumerate all regions of corre-lated spatio-temporal change that exhibit temporal correlation over the window. From the set of all such regions, we find a subset, across all window lengths, that satisfies the constraints outlined in the problem statement and which maximises the temporal and spatial criteria. This step may require further splitting and merging of regions. The naive method would be complete, but intractable X  X his naive approach is similar to finding an optimal job/timeta-ble schedule from a set of known jobs of different lengths and costs, which is known to be NP-Hard.

Hence, we have developed an approximate solution to the problem of discovering regions of correlated spatio-temporal change. As an illustration of the approach, consider an example from Fig. 1 . Consider the case where region 6 has been split into two regions, 6a and 6b, where region 6a is defined over the snapshots G 1 to G 4 , and region 6b over snapshots G 2 and G 5 . Refer to Table 3 for details about regions 6, 6a and 6b, and Fig. 2 for the alignment of the change waveforms of region 6.

There are several important points to note:  X  Both regions 6a and 6b have the same set of edges as region 6, since if the edges 8 X 9,  X  Forthesnapshotscommontoboth W 1 , 4 and W 2 , 5 ,whichwedenote W common ( W common =  X  Even though regions 1a (1b) have the same change waveforms over W common to regions
This means that we can first find regions of correlated change over shorter correlation periods, then merge those that have high overlap in their set of edges and high similarity in their change waveforms (over the common subsequence of snapshots) to form regions with longer correlation periods. This can be repeated, until the region with the maximal correlation period is found.

From this illustrative example, it can be seen that we can find the regions of correlated change by first dividing the sequence of snapshots into a set of overlapping, subsequences of snapshots. Then for each subsequence, we find the set of regions of correlated change for each subsequence, using a clustering approach. This is analogous to finding R 1 a for subsequence 1, then R 1 b for subsequence 2. Up to this point, we can find regions with correlation up to the length of each subsequence. To find regions with correlation greater than the length of a subsequence, we merge regions discovered in adjacent windows, using the criterion that two regions should be merged across subsequences if both their sets of edges and their change waveform, over the common subsequence of snapshots, are highly overlapping and similar.
The general process is illustrated in Fig. 3 , and in more detail in Algorithm 1 .Notethat there are some terms and ideas in Algorithm 1 that are not introduced until later in this section. Nevertheless, the general direction of the algorithm can still be appreciated without understanding all the terms in detail.
The overall process of cSTAG can be broken down to the following steps. First, in the windowing step, the input sequence is split into a number of subsequences using a sliding window process. The set of changed edges E ts , te C , for subsequence W ts , te , is then extracted by the function extract () (line 15). This can be easily done by examining if an edge appears or disappears between two snapshots in the subsequence. Then the temporal and spatial dis-tances are computed in lines 19 and 21, respectively. Next, we discover the set of regions whose correlation length is the same as the length of the sliding window. We call this step the discovery of regions of correlated spatio-temporal change , represented by the regDis-covery () function (line 23). The final step, region association , merges regions discovered in the individual windows to find regions of correlated spatio-temporal change, whose lifetime is greater than the sliding window length (line 32).

In comparison with the naive method, cSTAG has the advantage that it enumerates only the regions of correlated spatio-temporal change for one given subsequence/window length. Although it is an approximate solution, we show in the evaluation section that it can achieve up to 100% accuracy in detecting a variety of regions of correlated spatio-temporal change. In the coming sections, we describe each component in detail. We also discuss the temporal ( d tem ) and spatial ( d spa ) distance measures that we have applied to this problem. Algorithm 1 Overview of the cSTAG Algorithm. 3.2 Windowing Sliding windows have been extensively studied and applied in the literature. Consequently, we provide only a brief description of the sliding window procedure. The sliding window procedure involves moving a window across a sequence, generating a number of overlapping windows.

More formally, let the length of the sliding window be denoted by  X  , and the increment by which the sliding window is moved each time be denoted by inc , 1  X  inc  X   X   X  1. Then for sequence &lt; G 1 ,..., G S &gt; , a sliding window process of window length  X  and increment inc will generate a set of S  X   X  + 1 inc subsequences { W 1 , X  , W 1 + inc , X  + inc ,..., W
The window length  X  represents the minimum length of temporal correlation that a region of correlated spatio-temporal change must possess to be considered a region. A short win-dow length tends to produce few regions of many edges, but most of the discovered regions are uninteresting and the changes are more likely to be grouped together by coincidence. A longer window length will avoid these problems, but tends to produce many regions of small size, which again may be of limited use. We shall empirically investigate the effect of window length in the evaluation section (Sect. 4.1.3 ). 3.3 Temporal distance measures ( computeTem ) The choice of what is the  X  X est X  temporal distance measure is dependent on the application context. For example, in the case of applications such as network fault diagnosis, where we wish to group routing changes induced by the same root cause, changes effected by the same root cause might exhibit delays as changes cascade through the network. In this context, two waveforms should only be considered similar if they have the same shape, and the timing of the changes roughly coincides.

In this section, we shall outline several temporal distance measures that are potentially relevant in this context and discuss their advantages and disadvantages. We then describe the actual distance measure we have developed for use in network fault diagnosis. Note that in general, cSTAG can accept any temporal distance measure, as long as it is symmetric and produces a distance relation on the set of changed edges.

Two candidate distance measures that take waveform shape similarity into consideration are Dynamic Time Warping (DTW) [ 15 ] and Longest Common SubSequence (LCSS) [ 55 ]. They can handle translations between the compared waveforms, and in the case of LCSS, are robust to noise. However, the main drawback of these measures is that they are computation-ally expensive for comparing simple binary waveforms. In particular, if q ( 1 ) and q ( 2 ) are the compared waveforms, where l 1 =| q ( 1 ) | and l 2 =| q ( 2 ) | ,and  X  is a threshold specifying the maximum waveform stretching allowed, then an implementation of DTW that computes
An alternative approach that addresses these complexity costs is the popular Euclidean distance measure ( d euc ), which is simple and efficient to calculate ( O ( W ) where W =| q | ). Definition 5 For two binary sequences q ( e i ) and q ( e j ) of length  X  , the (normalised) Euclid-ean distance can be defined as where  X  represents exclusive OR (0  X  0 = 1  X  1 = 0, 0  X  1 = 1  X  0 = 1).

However, two of the known weaknesses of the Euclidean distance measure are that it is not robust to any delays or difference in scale between two compared waveforms, even if the two waveforms have the same shape. Since we are using binary valued waveforms, there are no scaling problems. To overcome the translation weakness, we additionally consider the shapes when comparing the (binary) waveforms. The approach we take is similar to DTW, particu-larly the Derivative DTW (DDTW) [ 35 ], but we do not need to use the relatively expensive dynamic programming technique to stretch or compress the time axis of the waveforms.
Before we present our modified Euclidean distance measure, we first introduce the concept of a transition sequence . In a transition sequence, we represent the changes in a binary wave-form as a sequence of transitions. Let a 1  X  0 transition in a change waveform be denoted as  X  ,anda0  X  1 transition as + . We then define a sequence of transitions trans ( e i ) for waveform q ( e i ) as a sequence of alternating  X  / + transitions. Using this definition, two wave-forms with the same shape will have transition sequences of the same length and each of the  X  / + transitions in the sequences will match. For example, consider Table 4 ,whichshows the change waveforms and transition sequences for edges e 1  X  6 , e 1  X  3 ,and e 2  X  4 from Fig. 1 . The transition sequences of e 1  X  6 , e 1  X  3 are different, corresponding to the difference in the shape of their change waveform. However, the transition sequences of e 1  X  3 and e 2  X  4 are the same, despite q ( e 2  X  4 ) being a delayed version of q ( e 1  X  3 ) .
 So, our modified distance measure is then defined as: Definition 6 ThemodifiedEuclideandistancebetweenwaveforms q ( e i ) and q ( e j ) oflengths  X  can be defined as where 0  X  d m _ euc ( q ( e i ), q ( e j ))  X  1.
 Intuitively, this version of the Euclidean distance measure determines the number of snap-shots in which two edges are either both present or both absent, while taking into consider-ation the shape of the waveforms. Two waveforms are similar if they have the same general shape (in terms of their transition sequences) and their unmodified edit distance is low (i.e., d m _ euc () is close to 0). For example, reconsider the waveforms in Table 4 . The modified distance between q ( e 1  X  3 ) and q ( e 2  X  4 ) is 0.2, as they have the same transition sequence sequences are different.

The complexity of computing the modified Euclidean distance is O ( | q | ) , which is the same or lower than the other alternatives. We further reduce the complexity of computing the modified Euclidean distance by implementing an incremental version of d euc and trans .
We can incrementally compute the Euclidean distance d euc ( e i , e j , W ts +  X , te +  X  ) for win-dow W ts +  X , te +  X  from the computed Euclidean distance for the previous window W ts , te by the following relation: The correctness of Eq. ( 2 ) can be shown by writing both the left-and right-hand sides of the equality in their summation form.
Similarly, trans ( e i , W ts , te ) can be computed from trans ( e j , W ts  X  inc , te  X  inc ) by: or transitions associated with the snapshots ts  X  inc to ts  X  1, inclusive, from the transition W from snapshot te  X  inc + 1to te , to the transition sub-sequence trans ( e i , W ts , te  X  inc ) ,to form the the transition sequence for snapshots ts to te , trans ( e i , W ts , te ) .
Using these Eqs. ( 2 )and( 3 ), d euc can be incrementally computed by keeping the sub-sequence distances calculated in the previous window, D ts , te  X  inc euc , and just computing the sition sequences, we introduce time markers to record the time the change occurred. This enables the truncation to be computed in constant time. Hence for transition sequences, we
In the remainder of the paper, in order to simplify the description of our algorithms, we describe cSTAG in terms of using a non-incremental temporal distance implementation. However, it is a straightforward matter to use the described incremental distance implemen-tation. 3.4 Spatial distance measures ( computeSpa ) Given that we are mining patterns in graphs, the spatial distance measures that we use are topology based. There are many topology based measures, but the most intuitive one for fault diagnosis is the shortest path distance. Two changing vertices that have low shortest path distance, and hence are spatially similar, are more likely influenced by the same change event, e.g., consider the router example from the introduction. In general, changes (to edges) caused by the same change event will have edges that possess small shortest path distances between them. Again, the exact definition of closeness depends on the specific application.
For example, in prior work [ 10 ], two changed edges were considered to be close if there exists a path between the two edges that only consists of edges from the set of changed edges, i.e., among the changed edges, the sets of changed edges that form connected components are considered close to each other. Although this enabled very fast computation of spatial prox-imity and is generally well suited for network fault detection, it can be inaccurate in certain cases. For example, there can be two different faults occurring at the same time and inducing the same routing changes. The two affected sets of edges are also topologically connected by a single edge (i.e., a bridge). Then using the previous connected component method, the two sets of edges will be incorrectly identified as one spatially close region. However, if we use the shortest path distance and use a clique definition (i.e., a set of edges that are consid-ered spatially close should all have low shortest path distances between them), then we can correctly separate the edges into two separate regions, based on their spatial differences. In general, using shortest path distance can allow many definitions of spatial proximity, hence can increase the range of applications for which finding regions of correlated change can be useful.
Before we introduce how we compute the shortest path distance between two edges in a snapshot graph, we shall consider how to compute shortest path distances on a dynamic graph. As the underlying graph is dynamic, the shortest path distances themselves are dynamic, too. A naive method would be to compute the shortest path distances for each snapshot, and then take the average across all the snapshots. However, this approach is expensive. Hence, a popular, alternative approach is to maintain the shortest path trees between vertices (or edges changes need to be updated, and queries can be answered in constant time. However, due to the storage and maintenance of the shortest paths, this causes a substantial increase in mem-ory usage. For example, an implementation of several well-known dynamic shortest path algorithms [ 18 ] required over 1.5GB of memory when tested on scale-free graphs with a few thousand vertices and edges. Hence, we do not consider dynamic shortest path algorithms to be a viable option for use in cSTAG.

The alternative method we used was to compute the shortest path distances over a sub-sequence of snapshots. Basically, we compute the union graph over the subsequence and compute the shortest path distances on these. This reduces the time cost of computing the distances for each snapshot, while avoiding the high memory cost of maintaining shortest paths. Computing the distances over a union graph is accurate if the shortest path distances themselves do not undergo significant change. This will occur when there are few changes. Even when there are many changes, if there exist many alternative shortest paths between any pair of edges (e.g., in a dense graph), most of the shortest path distances themselves do not vary much. We will observe this phenomenon in the evaluation of the synthetic datasets in Sect. 4.1 .

We compute the shortest path distances for a subsequence of consecutive snapshots of length  X  spd ,1  X   X  spd  X  S . The sequence of snapshots is segmented into a number of disjoint subsequences, all of length  X  spd . The last window can be less than  X  spd . For each subsequence, we compute the union graph of the snapshots (performed by the function com-puteUnion ) in Algorithm 1 , then compute the shortest path distances on this union graph. For example, if the subsequence of snapshots is &lt; G 1 , G 2 ,..., G 5 &gt; and  X  spd = 2, then there and U 5 , 5 3 = G 5 . If we want to compute the shortest path distance for snapshot G 1 ,thenwe then we compute the distance over U 1 , 2 1 and U 3 , 4 2 , then take an average. In the evaluation, we have evaluated the effect of varying the union window size  X  spd on the running time and accuracy of cSTAG.

Algorithm 2 provides an outline of our approach to estimating the shortest path distances using a sequence of union graphs. Next, we describe the techniques we have used to speed up the shortest path distance calculations for a single graph snapshot. 3.4.1 Computing the shortest path distance for a single graph For a pair of changed edges, the shortest path distance is defined as the smallest number of vertices needed to traverse from one edge to the other. Hence, with a slight, and simple modification, we can use existing algorithms for computing shortest path distances between vertices for the distance between edges.

A fast and popular algorithm for finding the exact shortest path distance is Dijkstra X  X  algorithm [ 2 ], which is the equivalent to breadth-first search in unweighted graphs. This has Algorithm 2 Spatial distance computation -function computeSpa() . a worst case complexity of O ( | E | ) [ 14 ]. We have improved upon breadth-first search by using the following two techniques.
 Bi-directional search We can improve this search by using a bi-directional search, starting at both the source and target edges. This is known [ 32 ] to decrease the average number of ver-tices (edges) visited for each distance computation, compared with a unidirectional search. From empirical testing on synthetic and scale free graphs, this produces a speed improvement of up to 70%.
 Limiting search depth Let d limit represent the maximum depth to which the shortest path distance search expands. For bi-directional, it is the total depth of both searches, i.e., the sum of the depths from each search. Another speed up technique is to limit the depth to which the search expands to d limit . When the depth limit is reached, the two edges in question are considered far apart and given a maximum distance of 1. Obviously, when the distance of two edges is actually more than d limit , then this will incorrectly identify them as being far apart, i.e., it will overestimate the actual distance. However, our experiments have shown that setting a small d limit does not have a large effect on accuracy. This is particularly true when the regions themselves do not have a diameter greater than d limit . 3.5 Discovering regions of correlated spatio-temporal change for each subsequence The aim of this component of cSTAG is to discover the set of regions of correlated spatio-temporal change for each subsequence of graphs. Recall that we seek sets of edges that have high temporal and spatial similarity, measured by the set of pairwise temporal and spatial distances computed earlier. To find these regions, we use clustering techniques to group the edges based on their temporal and spatial distances. Each cluster of changed edges rep-resents a region of correlated spatio-temporal change with lifetime [ ts , te ] . The clustering respectively. The clustering methods used also determine the shape that the edges in a region of correlated spatio-temporal change will form. For example, single linkage [ 23 ] generally produces elongated clusters, hence the regions produced using single linkage clustering will tend to be elongated as well.

However, many existing clustering methods [ 23 , 31 ] cannot be directly used to find the regions of correlated spatio-temporal change in a subsequence. The reason is that these exist-ing methods are designed to find clusters that satisfy some optimality measure on one distance measure. However, the problem of finding regions of correlated change involves clustering
This problem has similarities to the co-clustering (also known as bi-clustering) problem [ 12 , 22 ]. In co-clustering, two sets of objects have one distance relation defined over them X  e.g., document-term frequency analysis in information retrieval [ 22 ] X  X nd the aim is to find co-clusters (subsets of both object sets) that minimise or maximise some objective measure. However, the problem of finding regions of correlated spatio-temporal change is not exactly the same. There is only one object set (edge X  X dge), but two distance relations (spatial and temporal). Therefore, co-clustering cannot be used.

Hence, we propose a variety of clustering methods to solve this clustering problem. Each of these methods implement the regDiscovery () function from Algorithm 1 differently. These include (1) combining the two distance measures into a single one, and (2) clustering using one set of relations, then further refining the obtained clusters using the other set of rela-tions (possibly using a different clustering method). In the rest of the section, we detail each of these multi-relation clustering methods. In addition, we describe a well-known single-relation clustering method that we have used. 3.5.1 Combining distance measures One method to solve the multi-relation clustering problem is to combine the two distance measures into one, then use an existing single-relation clustering method to find the regions. We outline two proposals, one based on constrained clustering, the other combining the two distances using a weighted linear sum. After combining the two distance measures into one, the changed edges are clustered using the combined distances. The process for both proposals is the same, apart from the way the distance measures are combined. Algorithm 3 outlines the overall process.
 Algorithm 3 Outline of regDiscovery () function for Hard and Soft Modification Methods. Hard modification The hard modification multi-relation clustering method is similar in principle to constrained clustering [ 54 , 56 ]. One of the relations is chosen as the main rela-tional space (optimised space), while the other (constraint space) is used to constrain and modify the optimised distance relation.
 Then the constrained optimised distance d comb ( e i , e j ) for edges e i , e j is defined as:
The advantage of this approach is that it is extremely simple to implement and com-paratively efficient X  X t can be partially precomputed during the distance calculation step. 1 However, the disadvantages of this approach are that T con needs to be tuned, and all object pairs with d con ( e i , e j )  X  T con are set to the same, maximum distance. This ignores the original distances, which may decrease the accuracy of the clustering X  X f two objects are close in the optimisation space, but their distance in the constraint space is just above the threshold, then this is regarded as being just as dissimilar as two objects that are far in both spaces. This motivates the next technique, which does not use hard cutoffs.
 Soft modification The second distance modification approach combines the two distances using a weighted linear sum.
 Definition 8 Let  X , 0  X   X   X  1 be a user defined parameter to determine the relative weight of d con and d opt in the combined distance measure. Then the combined distance is defined by Again, the advantage of this method is that it is simple and relatively efficient to compute. However, there is a parameter  X  to tune again, and there is an implicit assumption that the relationship between the two distance relations is linear, which might not necessarily be the case. 3.5.2 Sequential clustering A disadvantage of the previous schemes was that one (modified) distance measure and one clustering method was used to cluster objects in two different spaces. Depending on the mea-sures and the true distribution, clustering separately might produce more accurate results. Hence, another relatively simple approach is to cluster in one space first, then further partition each discovered cluster using the other distance relation. The resulting sub-clusters are the final clusters. Again, any clustering method can be used for clustering in both steps. The disadvantage of this is the sensitivity of the choice of which distance relation to use first. Such order dependence is less than in the distance modification approaches, but it is still important, as the initial clustering in the first domain constrains which sub-clusters can be found in the second clustering. Algorithm 4 outlines the sequential clustering process. In our cSTAG implementation, we cluster using the temporal distances first, then the spatial ones. We found that by using the temporal distances first, we obtained better accuracy. This is Algorithm 4 Outline of regDiscovery () function for Sequential Method. because in general, the temporal distances between two regions are more likely to be larger than the spatial distances. Hence, separating by temporal distance first enables the algorithm to make fewer mistakes in the first clustering step. 3.5.3 Single relation clustering To group the changed edges into clusters using a single distance relation, we require a single-relation clustering method. The number of clusters is not known a priori, hence we require a clustering method that does not require knowing the number of clusters beforehand. There-fore, we chose a partitional method, leader X  X ollower , which we describe below. For compar-ison, we also tested two hierarchical methods X  X ingle and average linkage clustering. From our experiments, we have found that these hierarchical methods are, at best, slightly more accurate than using the leader-follower method. However, they run much slower, particularly for larger graphs. Since the results of hierarchical clustering do not show any significant difference from the results of using the leader-follower algorithm, we do not present them in this paper.
 Leader X  X ollower Leader X  X ollowerclusteringdescribesagenericclusteringapproach,where a threshold is used to decide whether each point should be included in an existing cluster, or a new cluster should be created to incorporate the point. In Duda et al. [ 23 ], a basic leader X  follower clustering algorithm is described. This algorithm assumes that a cluster centre can be computed and updated. However, the  X  X oints X  we are dealing with are edges, and all the distances defined over them are relational, hence there is no concept of a cluster centre. Therefore, we modified the basic leader X  X ollower algorithm described by Duda et al. This modified version is outlined in Algorithm 5 .

The algorithm considers each edge and compares the average distance with existing clus-threshold ( regWidth ). If an edge cannot be incorporated into any of the existing clusters, a new singleton cluster, with the edge as its member, is created. 3.6 Region association ( regAssoc ) The final step in the cSTAG algorithm is region association. Recall that the aim of the region association step is to discover regions whose correlation is longer than the sliding window Algorithm 5 Modified Leader-Follower Algorithm. length  X  . This is achieved by associating and merging similar regions that have been discov-ered in consecutive windows.

As described in the introduction to cSTAG in Sect. 3.1 , the criteria for merging two regions are: 1. Both regions share a significant number of edges (we do not require strict set equality, 2. The subsequences extracted from both regions for the common snapshot subsequence
More formally, we can express these criteria as two inter-region distance functions, d S and d Q , and two user specified thresholds,  X  merge (spatial) and  X  merge (temporal). d S mea-sures the amount of overlap between the edges in the two regions, while d Q measures the total weighted distance between the waveform sets of the two regions. Hence, given two quence W ts + 1 , te + 1 ), we merge these two regions if and 0
Recall that R r . Q denotes the set of change waveforms of region R r . Equation 5 compares W common . The distance between the two waveforms is weighted by the relative frequency of each waveform in their respective Q sets.
 atedbyaslidingwindowprocesswithincrement inc = 1,tomerging R ts , te g and R ts + inc , te + inc h where inc &gt; 1.

Algorithm 6 provides an overview of the region association procedure. Basically, an evo-lution graph is constructed from the set of regions discovered for each window. The vertices of the evolution graph are the regions discovered, and there exists an edge between two vertices if their corresponding regions are discovered in adjacent windows and their spatial and temporal inter-region distances are below the respective thresholds. Then each con-nected component in the constructed evolution graph will represent discovered regions that are similar across windows. Hence, the final step in the region association step is to find the connected components of the evolution graph, and merge these regions. Merging two regions involves unioning the edges of the regions, and concatenating the waveforms. Concatenating the waveforms is non-trivial, as each region can consist of a set of waveforms. However, we can use the same rationale as used in computing d Q , i.e., if two waveforms have a high relative frequency in their respective merged regions, then we should assign a high frequency to the resulting concatenated waveform, as the parent waveforms were frequent in their respective regions. Therefore the concatenated waveform should also be frequent in the merged region. If the two regions to be merged are R g and R h , then the merged region R gh has edge set R  X  R h , and its set of (waveform, frequency) pairs R gh . Q is {( concat ( q a [ 1 ,  X  1 , X  ] ) , freq a  X  freq b ) | ( q a , freq a )  X  R g . Q , ( q b , freq b )  X  R h . Q }.
At the end of the region association step, we have a set of merged regions, representing the regions of correlated spatio-temporal change of different correlation lengths. 4 Evaluation In this section, we evaluate the performance of cSTAG using two types of datasets. First, we use synthetic datasets to test the accuracy of cSTAG. In addition, we demonstrate the practical benefits of using regions of correlated spatio-temporal change to detect local routing events in the BGP connectivity graph from the Internet, and also flash crowd events at the 1998 World Cup website. In each of the evaluations, we first describe the dataset and then present the results. 4.1 Synthetic dataset evaluation 4.1.1 Accuracy evaluation measure We require a quantitative measure to evaluate the sensitivity and accuracy of cSTAG to its parameter settings. We have used a measure from cluster validation [ 29 ]. Cluster validation involves comparing two sets of clusters X  X he reference clustering, and the actual clustering obtained from the evaluated clustering method. Although there are many proposed measures, we present results using only the Jaccard coefficient [ 29 ]. We have considered other measures such as the Rand index [ 29 ]and Minkowski measure [ 29 ], but found that they yielded the same results as the Jaccard coefficient .

Let C ={ C 1 ,..., C u } be the actual clustering results, and P ={ P 1 ,..., P v } be the reference clustering. If both clusterings partition a dataset X , then for each pair of objects, Algorithm 6 Procedure for region association step -function regAssoc (). ( x , x j ), x i = x j , x i , x j  X  X , it is possible to classify them as follows [ 29 ]: SS , if both objects belong to the same cluster in both clusterings; SD , if the objects belong in the same cluster for clustering C , but different clusters for clustering P ; DS , if the objects belong to different clusters for clustering C , but in the same cluster for clustering P ; DD , if the objects belong in different clusters for clustering C and P .Let n SS , n SD , n DS and n DD denote the number of SS , SD , DS and DD pairs respectively. Then the Jaccard coefficient is defined as [ 29 ]:
The Jaccard Coefficient ranges from 0 to 1. It measures the similarity between the clus-terings. A score of 1 indicates a perfect match between the actual and reference clusterings, while a score of 0 indicates a complete mismatch.

To evaluate cSTAG using cluster validation, we simulated several datasets and manually introduced changes, so that we know the correct reference regions of change. We then applied the Jaccard Coefficient to measure the accuracy of cSTAG, using the discovered regions as the actual clustering to be evaluated, and the introduced regions as the reference clustering. 4.1.2 Dataset description
To create the reference clusters, we first constructed several synthetic graphs and manually introduced changes into them. The results are the set of four synthetic datasets in Table 5 (we shall call these the manual synthetic datasets ). 2 The aim of the closeDiff datasets is to test the accuracy with respect to temporal similarity. The first dataset, different (Fig. 4 ), tests different sequences of changes, each with their own unique transition sequences. The second dataset, combo (Fig. 5 ), tests multiple regions that have the same sequence of transitions, but where the timing of the actual changes are different.

The farSameCloseDiff dataset (Fig. 6 ) has several regions that have different types of change, but in close topological proximity. There are also pairs of regions that are far apart, but have the same type of change. This tests any potential tradeoffs between the spatial and temporal similarities.

There is the more challenging dataset cross (Fig 7 ). The cross dataset consists of a region resembling a cross, with four other regions separated by the cross region. The four regions have the same type of change. The cross dataset tests how well the algorithm detects non-spherical regions.

In addition, we generated a set of scale-free graphs, based on the Barabasi model [ 7 ], and randomly introduced regions of change into them. Each region generally forms a connected component, though this is not guaranteed. We generated scale-free graphs to test the effect of  X  spd , the union window size, and d limit , the maximum depth limit used when calculating the shortest path distance, on the running time and accuracy. We found that  X  spd had little effect on the accuracy for the four other synthetic datasets. We also tried generating graphs where we randomly generated regions, then added paths between them X  X gain  X  spd did not affect the accuracy. In addition, we needed larger graphs to test the effect of d limit and the scalability of cSTAG, which the Barabasi model allows us to easily do. Hence, we used scale-free graphs, which have been found to accurately model many real life graphs. 4.1.3 Manually constructed synthetic datasets
To evaluate the accuracy of our approach, we applied cSTAG to the first four datasets in Table 5 , i.e., different , combo , farSameCloseDiff and cross . In each case, we tested the three different clustering techniques that we proposed in Sects. 3.5.1 and 3.5.2 for combining temporal and spatial distance measures, i.e., hard modification, soft modification and sequen-tial clustering, combined with the leaderFollower algorithm. For each clustering method, we measured how the accuracy of the results varied as we changed the parameter settings in each algorithm. Note that in the hard and soft modification clustering techniques, temporal distance is used as the optimised criterion d opt ,and spatial distance is used as the constraint criterion d con . Similarly, in sequential clustering, we first cluster using temporal distance, and then further partition each cluster based on spatial distance.

We do not report the timing results for these four datasets because their running time was in the tens of milli-seconds, which is too small to make any meaningful comparisons. We examine the effect of the significant parameters ( d limit and  X  spd ) on the timing in the next subsection, using the scale-free graphs.

The accuracy results for each manual synthetic dataset are shown in Figs. 8 , 9 , 10 .For the hard modification method (Fig. 8 a X  X ), the results of varying T con and regWidth on the accuracy are shown. For the soft modification method (Fig. 9 a X  X ), the results of varying  X  and regWidth on the accuracy are shown. For the sequential method (Fig. 10 a X  X ), we show the results of varying the sliding window size  X  and regWidth on the accuracy. Varying the window size  X  tests the accuracy of the merging portion of cSTAG. Note that we have also evaluated the effect of varying  X  on the other two clustering methods, but obtained similar trends as the results for sequential clustering, hence we do not present those results. In addi-tion, we found that varying  X  merge and  X  merge from 0.05 to 0.50 did not affect the accuracy over all window sizes  X  and all combining methods. Hence, to avoid over reporting, we do not present the accuracy graphs when varying the two merging thresholds.

In each figure, we show the clustering accuracy for each clustering technique based on the Jaccard measure. Let us first consider each set of results in detail.
 Hard modification When hard modification is used, if the threshold on distance in the con-straint space is zero ( T con = 0), then spatial distance is not considered by the clustering algorithm, and the results only depend on the temporal similarity of the change waveforms. Otherwise, the clustering results are highly sensitive to the choice of T con . As shown in Fig. 8 a X  X , if T con is too low, then the spatial distance is too tightly constrained, and the true regions are fragmented into smaller regions. Conversely, if T con is too high, then the discovered regions can contain excessive variation in spatial distance, and distant regions with the same temporal change are incorrectly merged.
 Soft modification When soft modification is used, the accuracy of the discovered regions is highly sensitive to the choice of values for the cluster width parameter regWidth in the Leader Follower clustering algorithm, as well as the choice of value for  X  , which determines the relative importance of the constraint distance, i.e., spatial distance. When  X  = 0forthe different and combo datasets (see Fig. 9 a,b), 100% accuracy can be achieved, since only temporal distances are considered. Otherwise, in all datasets, the maximum accuracy that can be achieved depends on how the settings of  X  and regWidth are fine-tuned. If regWidth is too small, then regions become fragmented. However, if regWidth is too large then distant regions can be erroneously merged together.
 Sequential clustering In comparison to hard and soft modification, sequential clustering is able achieve high accuracy, with little sensitivity to the choice of parameters. In sequen-tial clustering, edges are first grouped based on their temporal similarity. Thus, dissimilar changes are kept separate, e.g., in the combo dataset (see Fig. 10 b). Each temporally coher-ent region is then further partitioned based on spatial distance. Thus, distant regions with similar change waveforms are separated, e.g., in the farSameCloseDiff and cross datasets (see Fig. 10 c,d). Note that some errors can occur if the sliding window size is too small, e.g., when w inSize = 6forthe farSameCloseDiff dataset (see Fig. 10 c). In this case, there are time windows when the change waveforms appear similar, and hence regions can be erroneously merged. However, in most cases high accuracy can be achieved.

In summary, of the three clustering methods, sequential clustering generally provides the most accurate and robust results across all our synthetic datasets. While hard and soft mod-ification can achieve good results, they are much more sensitive to the choice of parameter settings. 4.1.4 Scale-free graphs
We have found the shortest path distance calculations dominate the running time as the graphs increase in size. As the union window size  X  spd and the depth limit d limit are the main factors that determine the running time of the shortest path distances, our aim is to test the specific effects of these parameters. In this section, we test the effect of  X  spd and d limit on accuracy and running time using scale-free graphs.

We varied the size of the scale-free graphs from 1,000 to 16,000 edges, generating three different graphs for each size. We then introduced a different set of changes to each graph, and averaged the accuracy and timing results. The total percentage of edges in each graph that experienced change was 30%. We also tried varying 10 X 60% of the edges in each graph, but the results exhibited the same trends as the 30% case, hence they are not presented. Figure 11 shows the effect of varying  X  spd and d limit on accuracy and timing for the scale-free graphs of 1,000 edges.

From Fig. 11 , we can make the following observations: 1. As the union window size (  X  spd ) approaches the length of the whole sequence of snap-2. A small depth limit ( d limit ) results in a slightly increased running time. This is because
In order to measure the scalability of cSTAG in terms of running time on large networks, we varied 20% of the edges on each of the generated scale-free graphs and measured the time required for cSTAG to find the regions therein. We tested the leader-follower algorithm with hard modification, soft modification and sequential methods, and found they required similar running times. Hence, we only present the timing results for hard modification with leader-follower clustering as shown in Fig. 12 .InFig. 12 we separate the total running time into three components: (1) the time required to compute the temporal and shortest path dis-tances ( distance ), (2) the time required for clustering ( clustering ), and (3) the time required for region association ( association ).

Figure 12 shows that the distance calculations, particularly the shortest path distance calculations, dominate the running time. The clustering and association steps constitute an insignificant portion of the running time. In future work, we plan to try and decrease the time taken for shortest path distance calculations by coarsening the graph into a smaller, approx-imate version [ 58 ], and using zones to measure the shortest path distances in the coarsened graph [ 47 ]. 4.2 BGP dataset evaluation In this section, we demonstrate the effectiveness of cSTAG on a practical problem by anal-ysing the effect of the 2005 Hurricane Katrina on the US portion of the Border Gateway Protocol (BGP) connectivity graph. This analysis has partly been presented in [ 11 ]. The BGP connectivity graph represents the top-level routing topology of the Internet. In this analysis, we compare the output of cSTAG on the BGP graph with known events of affected locations [ 16 ]. We also highlight the difficulty in identifying meaningful regions if cSTAG is restricted to using only spatial distances alone or temporal distances alone. 4.2.1 BGP data source BGP is a routing protocol used to establish the forwarding tables between the routers of organisations, known as Autonomous Systems (ASs), on the Internet. The vertices in the BGP connectivity graph represent the ASs, and the edges represent the existence of a routing path between the ASs. An important challenge in managing the Internet is how to detect problems in the BGP routing topology and diagnose the event that caused each problem [ 24 ].
In order to understand how the BGP graphs were built from routing tables, we briefly introduce how paths are stored in the tables. Each BGP routing table entry can be summa-rised as a network prefix and its AS PATH attribute. AS PATH lists the path of ASs that was used by the original announcement in reaching the current router and its AS. For example, AS1-AS2-AS3 means the prefix originated from AS3, and the announcement propagated from AS3 to AS2 to AS1, before reaching the current AS.

The RouteViews project 3 at the University of Oregan collects BGP routing information by passively peering with a number of distributed ASs. From each table obtained from Route-Views, we built a snapshot of the BGP connectivity graph using the AS PATH path entries. By using multiple path entries it is possible to construct an approximation of the true BGP connectivity graph. 4.2.2 Hurricane Katrina We examine the Katrina event because it has been reported that its effect on the Internet was mostly localised around Louisiana and several other southern states. We concentrate on the ability of cSTAG to clearly show significant activity in the ASs around that region. We also compare the results found using an analysis reported in [ 16 ], which is based solely on an analysis of global statistics of the network as a whole.

We concentrate on the US portion of the BGP graph, as this was large enough to hide very localised events, like the Hurricane Katrina event. In August 2005, the US BGP graph consisted of around 9,000 X 10,000 vertices and 45,000 edges. We analysed three and half days of snapshots, from 29 August, 13:19 to 31 August, 22:32. This period included the landfall of Hurricane Katrina (around 29 August, 10:00). This corresponds to the period between snapshots 11 and 12. As the synthetic dataset evaluation showed, sequential clustering was most stable and accurate, hence we use it for our BGP analysis. In addition, we found a regWidth of 0.25, window size  X  of 10, window increment inc of 1, and  X  merge and  X  merge of 0.2 produced the clearest results. In fact, window sizes from 6 to 10 produced very similar results, again highlighting the accuracy of the merging part of cSTAG.
 Event Separation To demonstrate the difficulty of analysing the changes using only global statistics of the graph as a whole, we first consider how the total number of individual changes for each window fluctuated during the landfall of Katrina. We then compare and demonstrate the ability of cSTAG to separate specific events among this global set of changes.
Consider Fig. 13 , which shows the number of edges and vertices that have experienced a change in each window. It shows there is a significant number of changing edges and vertices that need to be analysed, even before the landfall of Katrina. This is partly due to general background changes, and Katrina X  X  earlier effects on the Florida part of the network. So even before major events like the landfall of Katrina, there are 50 X 100 individual edge changes that need to be examined by users. During the window immediately after the landfall of Katrina, the number of changed edges rises to nearly 300. Given that the only knowledge available for each individual changed edge is whether it appeared or disappeared between adjacent snapshots, it is difficult to determine any pattern from the individual changes.
Contrast this with the regions of correlated spatio-temporal change discovered by cSTAG, displayed in Table 6 . As the results demonstrate, the discovered regions correspond either to different events, or different local subgraphs affected by the same cause. For example, the merged region labelled A represents a large failure region. It has been reported [ 16 ] that a sig-nificant percentage of the Louisiana (and Mississippi) network was knocked out by Katrina. To check if region A corresponds to this failure event, we obtained the registered, geographic states of each AS that are connected to the edges of region A, via the whois service of the American Registry for Internet Numbers. 4 We found that of the 41 unique changed edges that are in region A, 32 of them are connected to an AS registered in Louisiana or Mississippi and seven to the ISPs Sprint and MCI, which experienced some connectivity problems due to Katrina. Therefore it is likely that region A corresponds to this reported disruption.
Region B is a recovery region. All the edges are centred around AS 701 (MCI), and this region appears to represent a recovery from failure problems that occurred before the start of our analysis X  X ence we only see the appearance of the edges. An important point to note is that the edges in region B are adjacent to region A (via AS 701) but are not incorrectly merged with them, due to the difference in temporal behaviour. This demonstrates the benefit of considering the temporal dimension as well as the spatial dimension, and highlights the ability of cSTAG to discriminate different events that are spatially close. In addition, only five of the edges are in reported connectivity blackout areas (Florida and Texas).
Region C is another failure region, with the time of failure transition also centred around snapshot 12. However, it is identified as a separate region from region A because the majority of the ASs in this region are associated with the Department of Defense and the military, and are spatially separate from each other. The cause of these failures could be due to Katrina, and hence could be merged with region A. However, we argue that it is more useful and interesting to separate the failure of the military network from the civilian organisations represented in region A, as they represent generally different types of organisations and networks. Again we highlight the point that without considering the spatial dimension, regions A and C would have been merged together.

The changed edges in Region D, representing a failure followed by a recovery, are cen-tred around AS 3356, another major ISP (Level 3). This is clearly a separate event from the other three, and again demonstrates the effectiveness of cSTAG at discriminating multiple simultaneous events.

To further illustrate why we use both temporal and spatial distances for region discovery, we also evaluated two naive strategies that used either temporal distances only ( tem-only )or spatial distances only ( spa-only ).
Consider the tem-only strategy first. We applied this strategy using the same parameters as cSTAG (except that there are no spatial distance considerations). A significant region discovered by the tem-only strategy is highlighted in Table 7 .AsTable 7 shows, we have region TA, which has the same change waveform as the regions A and C discovered by cSTAG (Table 6 ). Therefore, due to its lack of spatial knowledge, the tem-only strategy has incorrectly grouped the edges of regions A and C as region TA.

Now consider the spa-only scheme. The results of analysing the Katrina data are shown in Table 8 . As the table shows, region SA consists of many edges and a large number of different change waveforms. It has incorrectly grouped most of the changed edges together, including all the regions of Table 6 . Hence, this mega-region SA is not very interesting or useful. Therefore, as these two naive schemes show, both temporal and spatial distances must be considered when trying to obtain interesting and meaningful results.

In summary, this analysis demonstrates cSTAG is able to separate events and their impact on the dynamic graph, even if the events, represented by regions, are either topologically adjacent or temporally similar to each other. In comparison to the high level temporal anal-ysis of changes in Fig. 13 , cSTAG provides much greater insight into the underlying events that have caused the changes. 4.3 1998 World Cup Web Site evaluation In 1998, the 16th FIFA World Cup was held in France. To study the workload characteristics of the official web site, www.france98.com, 5 access logs 6 of the web site was analysed by Arlitt and Jin [ 5 ].

It was reported by Arlitt and Jin that the website experienced flash crowds X  X udden, large increases in the number of unique, legitimate clients accessing the website. This coincided with the time of weekday matches. Arlitt and Jin suggested that during weekdays most people are at work or school and cannot watch the matches on television. The 1998 World Cup was the first world cup where live scores were available online. Therefore, a significant num-ber of fans, who cannot watch the matches on television, monitored the live scores via the website during the matches, producing the flash crowds. Figure 14 , which shows the number of requests per hour over the period from June 7 to June 13, illustrates the aforementioned flash crowd effect coinciding with the times of the matches.

We wish to construct a dynamic graph of the website accesses and find regions of corre-lated change that correspond to the flash crowd events. By studying the change waveforms of the regions, we can corroborate which regions are most likely to be associated with each of the flash crowd events, and determine the set of affected web pages. This demonstrates another application where regions of correlated change can be used to infer underlying events. 4.3.1 Dataset The access logs consist of a list of website accesses. Each access has a timestamp, client ID (corresponding to the IP address of computer accessing the website), object ID (where an object is any individual file requested by the clients, such as HTML, image, java files for example), and various other (irrelevant) information.

Each flash crowd should to have a set of objects that are uniquely associated with the flash crowd, i.e., objects associated with the team that was playing at the time of the flash crowd. This set of objects should have a sudden, large number of unique clients accessing them over the period of the associated matches, and after the match, this set of objects are no longer frequently accessed at the same time. For example, if Paraguay was playing, then we expect objects relating to Paraguay to be accessed by a large number of the same clients during that period.

Therefore, to infer the flash crowds/matches from the web logs, we construct snapshots of the object X  X bject graph and find regions in the snapshot sequence. Each vertex in the object X  object graph represents an object, and a (weighted) edge exists between a pair of objects if one or more clients accessed both objects during the period over which the snapshot is defined. The weights count the number of unique clients accessing the two incident objects. The regions of correlated change discovered over the snapshots represent groups of objects that have been accessed by the same set of clients. These clients should be predominately the fans of the teams playing, hence each flash crowd/match should produce a unique region.
To build the snapshots, we divide the list of accesses into a sequence of two hour snap-shots, which roughly correspond to the length of a match, including half-time and regular extra-time. From each two hour bin, we build the object-object snapshots. We then convert the weighted snapshots to unweighted snapshots by setting a filter threshold X  X dges with weights less than the filter threshold are deleted, and all remaining edges are turned into unweighted edges. As Fig. 14 shows, there is a high level of background activity and traffic which is not of interest. We plotted the number of edges with weight x verses the weight x , and found that the distribution was heavy tailed. The objects involved in the flash crowds predominately have large edge weights between them. This suggests that there are many irrelevant edges with small weights that can be considered as noise and therefore should be filtered out. We set the threshold for filtering irrelevant edges to 500. 4.3.2 Findings on the 1998 World Cup dataset In this section, we present and discuss some of the regions of correlated change discovered by cSTAG, over the two day period from 0000 Friday, June 12th to 2,359 Saturday, June 13th. This period included several matches/flash crowd events.

We shall discuss five of the discovered regions X  X hree correspond to each of the matches on Friday, one corresponds to one of the matches on Saturday, and finally one corresponds to fans that are interested in multiple matches on Friday. The characteristics of the regions are presented in Table 9 .

To obtain a better understanding of what the regions represent, we extracted the list of incident objects in each region and obtained the actual files to which these objects correspond. As there are several hundred unique objects in total, we truncated the list of objects in each to the most interesting ones. These lists are presented in Tables 10 , 11 , 12 , 13 , 14 .
As the website is no longer available, we do not know the content of the actual webpages or objects, but we can still distinguish the different regions and identify some interesting features of those regions. For example, we can infer that the files matchprogXXXX .htm refer to the webpages that display the live scores of match XXXX, and matchstatXXXX .htm refer to the webpages that display the statistics of the match. In addition, files of the form team-bioYYY .htm probably refers to the biography of team YYY, and groupstandings163_77.htm refers to the group standings of group 164_77.

The four regions labelled Fri-1, Fri-2, Fri-3 and Sat-1 (Tables 10 , 11 , 12 , 13 , 14 )are regions that we hypothesise refer to a unique match/flash crowd. Each of these regions have a unique matchprog88XX.htm object. In addition, most of them also have a unique match-stat88XX.htm object. Furthermore, the timing of the changes for all four regions does not coincide. For example, Fri-1, which appears in snapshot 7, is different from region Fri-2 (snapshot 9) and Fri-3 (snapshot 10). This coincides with the timing of each of the three matches on Friday. The fact that the numbering of the team biographies (and group stand-ings) generally do not overlap between regions strengthens this hypothesis. There are some cases where the matchstat objects of other matches are in a region, but these are limited, and are likely to be fans checking the results of earlier matches in the day.

The region Fri-C (Table 13 ) is interesting. It is defined over the same period as regions Fri-1 and Fri-2 and consists of objects that belong to at least one of the regions. This region most likely represents fans that are interested in both the matches. This suggests that hierarchical relationships may exist between the regions.

In summary, we have used the synthetic datasets to show that cSTAG can accurately find regions of correlated spatio-temporal change. In addition, we have shown how the parameters settings in cSTAG affect accuracy and running time. Furthermore, we have analysed two real datasets. We found that the discovered regions for the BGP routing graph correlates with reported routing events during the landfall period of Hurricane Katrina. Finally, we have managed to find different user access patterns to the 1998 World Cup website based on the group of files that were accessed frequently together over time. 5 Related work The problem of analysing evolving graphs has been studied from a range of different per-spectives. Desikan et al. [ 21 ] have proposed a framework to classify different approaches to this problem, in terms of whether we are analysing properties of (1) the whole graph, (2) specific subgraphs or (3) individual nodes. Whole graph analysis examines changes to global properties, like the diameter of the graph. Subgraph analysis investigates graph dynamics at the resolution of subgraphs. Single-node analysis involves analysing the changes in node information. We consider our work to be in the subgraph analysis category. Although Desikan et al. have not proposed any algorithm to perform subgraph analysis, recently they have used evolving graphs as a model in computing an incremental page rank algorithm and in spam email detection [ 19 , 20 ]. In this section, we outline related work, using the framework of Desikan et al. as a guide. We also summarise spatio-temporal approaches to clustering and pattern mining, and contrast work in data stream clustering with our own.

In terms of whole graph analysis, Leskovec et al. [ 43 ] recently investigated how global properties of graphs, like node degree and the diameter of a graph, evolve with time. Using four large, real dynamic graphs, they found the average out-degree and number of edges to follow a power law distribution, as well as the diameter of graphs decreasing with time. Based on these observations, they proposed two probabilistic graph models to explain and generate the observed distributions. Using Desikan X  X  framework, this can be regarded as global analysis, thus having a different focus to our work.

Similar to our work, Gaetler and Patrignani [ 26 ] focused on summarising the temporal evolution of the BGP connectivity graph. They used spectral graph clustering to reduce the size of the BGP graph they analysed. However, they did not make simultaneous use of the topological and temporal information of the evolving BGP graph.

In terms of subgraph analysis, Kraetzl et al. [ 49 ] surveyed various techniques to detect abnormal changes, including two techniques for identifying the regions of greatest change between two snapshots. One technique was to construct and permute a change matrix. The other technique was to construct k-neighbourhoods for each vertex, and compare the neigh-bourhood graphs using a graph distance measure.
Recently, Borgwardt et al. [ 8 ] defined the novel problem of finding frequent subgraphs in dynamic graphs. In addition to the traditional definition of being topologically frequent, these subgraphs must also exhibit similar temporal evolution synchronously (over the same period of time), and asynchronously (can be over different periods of time). Although similar to our work, the frequent subgraphs sought by Borgwardt do not have any topological/spatial constraints, whilst in our work, we require changed edges to be topologically close.
Related to finding dynamic frequent subgraphs is mining minimal contrast subgraphs [ 53 ]. Minimal contrast subgraphs are subgraphs that appear in one class of graphs, but not in another set, and are minimal, i.e., there are no proper subgraphs that are also contrast sub-graphs. It can be applied to mining dynamic graphs if we consider a snapshot as one class, and the next snapshot as the other class. When applied in this context, the discovered set of minimal contrast subgraphs are the smallest subgraphs that explain the changes between the snapshots. In contrast to regions of correlated change, the edges and vertices in a minimal contrast subgraph do not have to be temporally correlated, or even topologically near each other, hence mining contrast subgraphs cannot be used as a solution to our problem.
In [ 39 ], Kumar et al. explored the evolution of community structure and behaviour in several collections of weblogs. They introduced the notion of a time graph to model the evolution of a collection of weblogs and the links between them. Edges in the time graph are labelled with their creation time. Using these time graphs, they extracted the weblog communities and analysed the degree distribution, evolution of node distributions in com-munities, and burstiness of communities. In [ 40 ], they performed a similar analysis on the structure and evolution of two online social networks, namely Flickr and Yahoo! 360. Similar to Leskovec et al. [ 43 ], their focus is on how local structures evolve with time, rather than finding correlation in changes.

In [ 3 ], Ali et al. introduced the idea of phenomena detection and tracking (PDT) in sensor networks. PDT involves detecting sensors that are geographically near to each other and have similar readings over a certain time period. The motivating example was to track oil spills from a sensor network deployed at sea. Although similar in aim to our work, the PDT algorithm involves optimising SQL queries in sensor network databases, and only uses single linkage to define a spatially close neighbourhood.

Lauw et al. [ 41 ] used spatio-temporal co-occurring patterns to construct affiliation net-works. The idea is that people or entities who are co-located frequently are mostly likely to be affiliated to each other. In an affiliation network, an affiliation is represented as an edge between two vertices (representing people or entities). Like spatio-temporal mining, which we survey next, our work uses graphical data, as opposed to time-stamped locations of different entities. In addition, our work seeks temporal correlation over longer periods than Lauw et al.

In spatio-temporal clustering and pattern mining, the main objective is to find objects or incidents that are in close spatial (usually geographical) proximity, and either occur at the same time (clustering), or occur frequently together (pattern mining). An example of spatio-temporal pattern mining is given in [ 9 ], where Celik et al. define the problem of mining mixed-drove spatio-temporal co-occurrence patterns. These patterns are objects in spatio-temporal databases that are spatially near each other for many time instances. In spatio-tem-poral clustering [ 30 , 44 ], clusters of disease, crime and other incidents of interest are grouped according to their geographical proximity and their temporal occurrence. Although both types of spatio-temporal mining are similar to our work, we are concerned with spatial distances that are based on topological distance in graphs, while in spatio-temporal mining, the spatial distance is geographically based. Furthermore, in spatio-temporal clustering, the focus is to seek dense groups of points, whereas density is not defined in relational data (i.e., graphs) -the closest definitions of density are vertex degree, and the number of triangles among triplets of vertices. Finally, spatio-temporal mining is concerned with clusters of incidents or objects that co-occur or are more frequent than normal, while our work is concerned with groups of entities that report strong temporal correlation over a window of time.

In the related area of data stream clustering [ 1 , 60 ], the aim is to cluster objects/points that arrive continuously. The emphasis of data stream clustering is to perform the clustering online, while keeping memory consumption within reasonable limits. Aggregate statistics of the objects are updated online, and clusters can be produced anytime from these aggre-gates. This is different from the region discovery problem, as there is no identifying how any particular object evolve with time, nor tracking of how the relationships between individual objects change with time. Hence, current stream clustering algorithms [ 1 , 60 ] cannot be used to solve the region discovery problem. 6Conclusion In this paper, we have defined a novel problem in data mining, namely, how to find regions of correlated spatio-temporal change in evolving graphs. The problem of finding correlated regions of change arises in a variety of contexts, such as fault diagnosis and event discovery in computer networks. To address this problem, we have developed an algorithm called cSTAG, which can find clusters that simultaneously maximise both the temporal and spatial similarity of the regions of change. Using a quantitative analysis on a simulated dataset, we showed that cSTAG can accurately characterise a variety of different patterns of spatio-temporal change in networks. Furthermore, we have applied cSTAG to finding patterns in the Internet connectivity graph from the Border Gateway Protocol, and shown that it was able to identify reported failures and simultaneous events during the 2005 Hurricane Katrina disaster in an accurate and scalable manner. In addition, we have grouped different sets of accesses to the 1998 World Cup website based on the groups of files requested frequently together, and we were also able to corroborate the discovered regions with known flash crowd events.
Our research has stimulated a number of promising directions for future research. So far, we have used an incremental approach to merge regions of change from different time win-dows. A future challenge is to develop a more global approach to simultaneously combine related regions from consecutive time windows. In addition, one of the important post-pro-cessing steps in clustering is to use a measure to rank the obtained clusters. We currently use the size of regions as an indication of their interest to users, but there are other potential mea-sures that could be extended and modified upon. For example, Bar-yossef et al. [ 6 ] recently proposed a cohesion based measure that ranks how good partitions of a graph are. Finally, there are many other types of application domains where cSTAG can be applied. We are currently investigating how cSTAG can be used to detect spatio-temporal regions of corre-lated activity in Magnetic Resonance Imaging snapshots of brain activity during different types of cognitive activity.
 References Author Biographies
