 Tue Herlau tuhe@dtu.dk Morten M X rup mmor@dtu.dk Mikkel N. Schmidt mnsc@dtu.dk Proof Recall the following claims regarding regard-ing the THRM c1 invariance under relabeling of vertices c2 invariance under temporal translation of all coor-c3 marginal consistency when integrating a single c4 correlation of the hierarchies at epochs t and s de-c5 marginally distributed as the HRM at each epoch. where marginal consistency indicate the condition The proof of these claims mainly relate to the prop-erties of the prior, The first two claims follow easily in that the generative procedure makes no specific reference to vertex labeling and only depend on the ordering of temporal states, and the last claim fol-low from the change-point prior being less correlated across longer time spans. The fifth claim follows easily from the fourth by projecting out all temporal obser-vations not at the given epoch one at a time.
 To show C4, consider two models m , m + 1 defined on temporal states S m , S m +1 . By assumption, the two models agree on all parameters aside those relating There are three cases for how the new temporal state 1. Before showing the marginalization condition we list the following properties relating to the HRM and Gibbs fragmentation trees is not changed, but if F it = 1 a new vertex is inserted in the giant tree. In either case the epoch t will contain an extra vertex-observation. We first compute X (1  X   X  ) p (  X  \ t | T m ) X  X  X By argument similar to before p (  X  \ t | T m +1 ) = p (  X  \ t | T m ). In the first case the tree proj C obtained from T m by the addition of one vertex. In the second case the tree proj C from T C t by the addition of one extra vertex; thus in both cases the condition (P2) is fulfilled giving from which the result follows by (P1). The final case 3, past expansion follows by an argument similar to
 Tue Herlau tuhe@dtu.dk Morten M X rup mmor@dtu.dk Mikkel N. Schmidt mnsc@dtu.dk Complex networks play a central role in the study of many complex systems. Most networks in practically all fields of research are dynamic. In biology tempo-ral organizations arise in protein networks by mech-anisms as diverse as their evolutionary history and cell cycle dynamics (Pastor-Satorras et al., 2003), and the functional connectivity of the brain changes dur-ing maturation and fluctuate spontaneously in awake rest (Dosenbach et al., 2010; Fox &amp; Raichle, 2007). In social networks ties between individuals play dif-ferent roles over the course of time: People move, change workplace as well as interests and these changes in turn affect how we interact with each other (Dor-eian, 1997), and global trends affect the fabric of so-ciety at the macro-scale. While networks tradition-ally have been modelled as static aggregated graphs, their temporal evolution carries important informa-tion about the structure of the system that is missed when considering only the time-aggregated network of interactions (Holme &amp; Saram  X aki, 2012; Perra et al., 2012). Figure 1 illustrate some of the temporal effects presently considered.
 In this work we explore two modelling assumptions: Networks are organized at multiple scales Studies in network science suggest networks often ex-hibit multi-scale organization (represented as hierar-chies over vertices), in which vertices are divided into groups which are further divided into subgroups. It has been shown that multiscale organization of net-works account well for various network statistics such as scale-invariance, short paths lengths and a high degree of clustering (Clauset et al., 2008; Fortunato, 2010; Ravasz &amp; Barab  X asi, 2003), and by modeling net-works in terms of hierarchies it is possible to account for the structures emerging at different scales (Her-lau et al., 2012; Meunier et al., 2010; Ravasz et al., 2002; Roy &amp; Teh, 2009; Roy et al., 2007; Sales-Pardo et al., 2007; Simon, 1962). Furthermore, cognitive sci-ence has long suggested that semantic knowledge is hierarchically organized, making it an attractive rep-resentation from an unsupervised learning perspec-tive (Collins &amp; Quillian, 1969) Networks are temporally organized The study of dynamic networks has been at the forefront of sta-tistical mechanics for more than a decade, focusing on network models which can take network growth into account. Common growth models have focussed on popularity (Barab  X asi, 1999) or on how node similar-ity (McPherson et al., 2001; Watts et al., 2002) can explain the emergence of particular scaling properties ubiquitous in real networks (Dorogovtsev et al., 2000; Redner, 1998). Recent research has pointed out tem-poral evolution at two levels: The connectivity-level at which vertices enter or leave the system (i.e. cap-turing network growth), and at the interaction-level capturing processes whose timing and duration takes place at a shorter scale, typically reflecting interaction between the units forming the network (Albert et al., 1999; Holme &amp; Saram  X aki, 2012; Perra et al., 2012). These effects can often be motivated on purely physi-cal grounds (networks between physical entities do not form spontaneously), and compiling network datasets often involve the explicit removal of temporal infor-mation by edge aggregation or windowing (Holme &amp; Saram  X aki, 2012).
 Motivated by these two properties we propose the tem-poral hierarchical relational model (THRM) which de-scribe the data by a temporally evolving multifurcat-ing hiearchy. The THRM model assumes the temporal network data are organized in epochs indexed by t such that each epoch corresponds to the network observed at that time point.
 At each epoch the multiscale relational structure is modelled using a hierarchical latent structure, and as a prior over hierarchies the Gibbs fragmentation tree (GFT) (McCullagh et al., 2008; Schmidt et al., 2012) is used.
 Changes at the connectivity-level such as birth and death of vertices is accounted for by allowing vertices to be present or not at different epochs, while at the interaction-level nodes can change role and function in the multiscale organization to capture temporal ef-fects at a shorter timing. To accomplish this each ver-tex has a change-point model that governs when ver-tices changes their placement in the hierarchical struc-ture, see figure 1 for examples of inferred change-point structures. The model supports two limits: If no ver-tices have change-points the model reduces to a single, shared hierarchy for all vertices, and if all vertices have change-points at each epoch there is no temporal or-dering in the hierarchical structure of each network. In between these two extremes the model captures temporally evolving hierarchical network structures, sharing statistical strength between time epochs such that the closer two time instances are the more cor-related their hierarchical structure will be. Inference in the model is performed using a distributed Gibbs sampler. 1.1. Related work Time-evolving relational data has previously been con-sidered with a variety of methods including multi-way models (Peng &amp; Li, 2010), information-theoretic approaches (Rosvall &amp; Bergstrom, 2010), block-type models (Ishiguro et al., 2010) and change-point pro-cesses for edges (Vu et al., 2011). There is a grow-ing literature on creating nonparametric priors for temporally evolving cluster structures using for in-stance connections between Dirichlet and Gamma pro-cesses (Lin et al., 2010) or fragmentation-coagulation processes (Teh et al., 2011). However, none of these works consider hierarchies as the organizational prin-ciple.
 Our model most closely relate to existing Bayesian ap-proaches to the modeling of hierarchical structure in networks, however these past models have not consid-ered temporal evolution. In (Clauset et al., 2008) a network model with uniform prior over binary trees is proposed where the probability of generating an edge between two nodes is specified by a parameter at the level of their nearest common ancestor. In (Roy et al., 2007) each edge in the binary tree includes a weight defining the extend to which the network complies with the split, and in (Roy &amp; Teh, 2009) the Mondrian pro-cess is proposed which for bipartite networks randomly bisects the nodes of the two modes until a stopping criterion is met, and parameters are then assigned to model the probability of links between each of the resulting pairs defined by the bisections. In (Herlau et al., 2012) a uniform prior over multifurcating trees is proposed where the leafs of the tree terminate at clusters generated from a Chinese Restaurant Process (CRP). In (Schmidt et al., 2012) the Gibbs fragmenta-tion tree process is used as prior over trees when mod-eling relational data (in the following denoted HRM). The THRM currently proposed can be considered an extension of this framework to the modeling of time-evolving networks. Before introducing our proposed model, we briefly re-view the infinite relational model (IRM). We then in-troduce relevant results for Gibbs fragmentation trees (GFT) and show how they can model networks in the hierarchical relational model (HRM). Using properties of Gibbs fragmentation trees we introduce temporal correlation to the HRM, leading to the proposed Tem-poral Hierarchical Relational Model (THRM). 2.1. Network models As the simplest case, consider a simple graph of n ver-tices represented by the binary adjacency matrix A such that A ij = 1 iff. there is an edge between vertex i and j . In the stochastic blockmodel (Holland et al., 1983) it is assumed that each vertex is assigned to one of k labelled communities, and the probability of an edge between vertex in community  X  and community  X  is given by the number  X   X  X  . In a non-parametric Bayesian formulation (the IRM (Kemp et al., 2006)) the number of clusters is a priori unbounded and in-ferred from data.
 Letting z i =  X   X  X  1 ,...,k } indicate the assignment to clusters, the IRM become where CRP(  X  ) is the Chinese Restaurant Pro-cess (Kemp et al., 2006) with parameter  X  and Beta is the beta distribution. Intuitively the infinite relational model divides the adjacency matrix A into blocks (see figure 2 top,left ), and each block is assigned a number  X   X  X  that determines the probability of forming edges on that region of the adjacency matrix (see figure 2). By conjugacy the  X  -parameters may be integrated out with A ij replaced by (1  X  A ij )) are called the pseudo counts , indicating the number of links (or nonlinks) in each block. B ( x,y ) =  X ( x ) X ( y ) /  X ( x + y ) is the beta function. 2.2. Multiscale Network Modelling Multiscale network structure is naturally modelled us-ing hierarchies over vertices: The root of the hierarchy corresponds to the coarsest resolution level indicating the large-scale structure, and moving further down the hierarchy corresponds to finer-scale structure between the fewer vertices partaking in the sub-hierarchies An intuitive view of this process is illustrated in figure 2, where the construction corresponds to modelling the entire network (at the top-level) by an IRM model, and then introducing new IRM models on the clusters along the diagonal in a recursive fashion. The con-struction is easiest formalized using notation from the GFT prior (McCullagh et al., 2008) reviewed below. Gibbs Fragmentation Tree Prior Consider a rooted multifurcating tree T B with leaf-set B . The leafs will later corresponds to vertices in the net-work so we write n = | B | . Each vertex b  X  T B can be identified with the set of leafs off the subtree rooted at b , T b , so without loss of generality we write T B = { leafs T b | b  X  T B } . Notice the collection contains B (corresponding to the root) and | B | singleton sets corresponding to the leafs and is also called a frag-mentation (McCullagh et al., 2008) of B , see figure 2 (top,right) for an illustration of a fragmentation of the set { A,B 1 ,B 2 ,C 1 ,C 2 ,D,E } .
 For any subset A of B , consider the new tree T A ob-tained by removing all leafs not in A , and then remov-ing all vertices of degree 1. We call this operation the projection onto A written proj A T B . In set notation it is given as T B 7 X  T A = { b  X  A | b  X  T B ,b  X  A 6 =  X  X  . In figure 2 (bottom,right) is seen two projections onto the sets A,B 1 ,C 1 ,D,E and A,B 2 ,C 2 ,D,E . Also, for a vertex b  X  T B such that | b |  X  2, let b 1 ,b 2 ,...,b b  X  X  k children in T B and n i = | b i | their size. Defining the partition  X  b = { b 1 ,...,b k } , we say T B fragments b into  X  b .
 A random fragmentation model is a family of distribu-tions over GFTs defined for all finite B  X  N having the following properties: exchangeable , meaning the distri-bution of T B is invariant to labelling of B , Markovian , meaning for all partitions B = B 1  X  B 2  X   X  X  X   X  B k , the k tree { proj B as T 1 ,...,T k , and finally consistent , meaning for all A  X  B , proj A T B is distributed as T A .
 McCullagh et al. (McCullagh et al., 2008) show all random fragmentation models have a representation as p ( T B ) = Q b  X  T normalization is not given in the reference, for all but a few degenerate cases q takes the form q ( n 1 ,n 2 ,...,n k ) = for prior parameters 0  X   X  &lt; 0 , X  &lt;  X  2  X  (multifurcat-ing trees with arbitrary block number) or  X  &lt; 1 , X  =  X  2  X  (binary trees). We have introduced the notation g k, X  (  X  ) = Q q (1) = 1. The two-parameter fragmentation process given by eq. (2) is denoted by GFP(  X , X  ).
 The Hierarchical Relational Model Returning to relational modelling, we can formalize the construc-tion as follows. Consider again a network A and as-sume the n vertices B = [ n ] are arranged in a GFT T At the root, T B fragments B into a partition  X  B = { B 1 ,B 2 ,  X  X  X  ,B k } . Defining z by z i =  X  iff. i  X  B induces a block-structure on A . Since each of the sets B  X  corresponding to diagonal elements in the block-structure (communities) these are further fragmented by T B each of these blocks creating a recursive refinement of the block-structure of A . The construction continues over all vertices of T B , see figure 2 (bottom,left) . Under this model the likelihood becomes Assume T B fragments b into  X  b = { b 1 ,...,b k } and let  X , X  denote indices of each fragment. Using the Bernoulli likelihood we obtain the following form, f b ( A ,  X  b , X  b ) = 2.3. Temporal Hierarchical Relational Model Returning to temporal modelling, assume we are given a set of coordinates ( i,t ) ( vertex observations ) indicat-ing vertex i was participating in the network at epoch t . All vertex observations are collected in a binary lat-tice S , ie. if S it = 1 vertex i was present at epoch t and otherwise S it = 0. S it is assumed to be known. Next we encode if vertices between epochs t and t + 1 may change their hierarchical organization. This is done using the binary change-point matrix J it ( jumps ), defined for vertex observations ( it ) where S it = 1, with the interpretation that if J it = 0 ver-tex i do not change hierarchical organization between time t and t + 1. In this case we say vertex i do not change temporal state , and if J it = 1 vertex i is said to change temporal state. It is assumed different vertices are always in different temporal states and an exited temporal state cannot be reentered. We use the con-vention J it = 1 if vertex i is not present at t  X  1. The collection of all temporal states is denoted by C . See figure 2 for illustration of J and C for a sys-tem of 5 vertices A,B,C,D,E , where vertex B and C change temporal states between epoch 1 and 2 giv-ing the unique temporal states A = 1 ,B 1 = 2 ,B 2 = 3 ,C 1 = 4 ,C 2 = 5 ,D = 6 and E = 7.
 To model the correlated hierarchical organization, all unique temporal states of the vertices according to their change-points are organized in a single hierar-chy, the giant tree , denoted by T GT (see figure 2 (top,right) ). By projecting this tree to the set of tem-poral states at each epoch, we arrive at the hierarchi-cal organization for each observed network which can be modelled by an ordinary HRM. In figure 2 (bot-tom,right) we illustrate projections onto epoch t = 1 (states A,B 1 ,C 1 ,D,E ) and t = 2 ( A,B 2 ,C 2 ,D,E ) corresponding to vertices B and C changing hierarchi-cal organization.
 For simplicity we consider simple life spans where each vertex has a single birth and death.
 To formalize the construction, again let n denote the total number of vertices and T the total number of epochs. The network at epoch t is indicated by A t (forming a simple graph) and all T networks simply by A . Notice it is possible that no single vertex is present at all epochs, and that all networks contain less than n vertices.
 Define J it for vertex observations ( it ) st. S it = 1 as where  X  is a parameter affecting the rate of change. The change-point deterministically give rise to the unique temporal states of all vertices: Different ver-tices i 6 = j are always in different temporal states: c and only if J ij = 1, and finally once a state is ex-ited it can never be reentered later (if c it t &lt; t &lt; t 2 then c it Let C =  X  it { c it } be the set of unique temporal states. Notice | C | = | J | . We let the elements in C form the leafs of a hierarchy T GT C (i.e., the giant tree ) distributed as a GFT(  X , X  ). It is this hierar-chy that induces the hierarchies used for each epoch simply by projecting the giant tree onto the tempo-ral observations at that epoch. Formally, defining C t = { c it | i st. S it = 1 } , the hierarchy at time epoch t is found as proj C these hierarchies we simply model each network ac-cording to a HRM. Generatively the model becomes
J it |S  X  According to eq. (4) change points, C  X  GFT(  X , X  ) giant tree, A t | T t  X  According to eq.(3) edges. (5) To put the model in words, we first generate the change points independently, thus determining when vertices may change roles in the network. Next all unique tem-poral states are arranged in a giant Gibbs fragmenta-tion tree, and by projecting this tree onto each epoch the networks at each epoch is conditionally indepen-dently generated using the HRM.
 The hyperparameters were selected as  X  + 0 =  X   X  0 =  X  0 =  X  uniform beta distributions. Preliminary experiments suggest the results are robust to these choices. Properties of the model Consider a family of models p n of n parameters x 1 ,...,x n . Such a family is simply exchangeable if it is invariant under relabelling and marginally consistent if and a family of models having these properties is said to be completely exchangeable (McCullagh et al., 2008).
 Qualitatively, marginal consistency means inference is not affected by knowing there exists additional data which is unobserved. This is particulary important for temporal models, since the number of observed ver-tices at each epoch may be very different, and we do not wish this fact alone to drive the marginal distri-butions. While there may be other ways to correlate hierarchical structure, we take marginal consistency to be a primary goal of a temporal hierarchical models in general and the primary justification for our choice of prior.
 With respect to full exchangeability, one should not hope the model to be fully invariant under relabelling, since that would imply no causal structure across time. With these comments in mind we summarize the prop-erties of our model in the following claims: c1 invariance under relabeling of vertices. c2 invariance under temporal translation of all vertex c3 marginal consistency when integrating over a single c4 correlation of induced hierarchies at epochs t and c5 marginally distributed as the HRM at each epoch. The last property implies if there are several epochs in a model, but we only observe one, it is distributed as a single HRM. Proofs of the claims can be found in the supplementary material. 2.4. Evaluation method A principal quantitative way of evaluating network models is by link prediction (Clauset et al., 2008; Miller et al., 2009; M X rup &amp; Schmidt, 2012). Con-sider a triplet ( i,j,t ) indicating a potential edge ob-servation between vertex i and j at time t . Let probabilities are combined to form the set of transi-tion probabilities relevant for operations on the giant tree.
 When combining the transition probability in the giant tree (requiring computation of the likelihood, eq. (2)) and when computing the contributions to the likeli-hood at each subtree (eq. (3)), the changes to the like-lihood can be reused according to the tree-structure: If b is an ancestor of b 2 and b 2 is an ancestor of b 3 , per-forming a change (for instance insertion of subtree) at b requires changes at the level of b 1 , but these changes can be reused when computing changes to the tree at level b 3 . In our implementation the parallel compu-tations at the level of epochs were performed using distributed computing resources.
 Previous work in HRMs (Schmidt et al., 2012) only considered Metropolis-Hastings pruning and regraft-ing. To compare to the THRM, consider the total number of (new) states considered by the Gibbs sam-pler in one sweep. If there are n = 200 vertices observed over T = 30 time-steps and a change rate  X  = 1 Including internal vertices this give  X  3000 vertices in total and considering only Gibbs sampling of leafs (3000 + 1000)2000 = 8  X  10 6 regrafting steps at each sweep due to the 2 types of regraft moves (not con-sidering regrafting of subtrees and changes in J ). 100 sweeps is then  X  10 9 regrafting operations, compared to about  X  10 6 subtree regrafting operations consid-ered by Schmidt et.al.(Schmidt et al., 2012). Despite these efforts, neither the IRM or THRM mix well on the larger datasets. The synthetic datasets shown in figure 1 were created by planting each of the four cluster structures using a simple model with within-cluster edge density 0.9 and between-cluster edge density 0.1. All networks had n = 42 and T = 8. The sampler was evalu-ated for 80 iterations (random initialization, half of which were discarded as burn-in. Shown are the true cluster-membership matrices and inferred J -matrices averaged over 10 networks. For upheaval and flip-flop the average can be expected to be less clear due to different sets of vertices participating for different net-works, but as can be seen the sampler correctly in-fers the timing and allows identification of the type of change.
 In addition, we also analyzed three larger datasets. Enron email network: The Enron email net-work(Cohen, 2009) consists of the email communica-tion of 184 Enron executives. The email communica-tion was binned into months giving 44 epochs corre-sponding to 1st November, 1998 to 1st July, 2002. For each epoch directed edges was added between execu-tive i and j if i send j an email in that month. The re-sulting network was directed and all simulations were performed using directed versions of the models, ie. both using the upper and lower parts of the  X  -matrix as individually defined entries. The edge-density was 2 . 3%.
 US Senate voting records: The US senate vot-ing records dataset (Lewis et al., 2010) covers voting records for 235 senators in the 101st congress (1989-1991, first two years of the presidency of G.W. Bush), to the 111th congress (2009-2011,first 2 years of the B.H. Obama presidency). Senators were included from their first registered votes to their last, and at each epoch the network was constructed by computing the Jaccard index between each senators binary yes/no voting record in the particular senate seating and in-cluding the top 20% values as edges.
 NIPS author collaboration: The NIPS dataset (Roweis, 2002) covers co-authorship of the 1-12th NIPS conference. Edges indicate co-authorship and authors were included who participated in at least 3 conferences giving 360 authors. The edge-density was 0 . 9%.
 As comparison we considered two ways for applying the IRM and HRM to temporal data. One was sim-ply modelling each time epoch independently (Sliced), and the other was fixing cluster-assignments/hierarchy in the IRM/HRM across all epochs (Joint), forcing all temporal epochs to share structure while  X  t is epoch specific. In the later case we treated all edges inci-dent to vertices not present at the given epoch as un-observed to avoid bias. Finally as a base reference we considered a naive model (Past) which predicted edges based on them being present in the previous time In table 1 is shown results of all three scores for the three considered datasets. For each entry the appro-priate sampler was evaluated for 2000 Gibbs sweeps in case of the IRM and 100 sweeps for the hierarchical-based models. Half the samples were discarded as burn-in and 10 equidistant samples was used. Shown is the mean and standard deviation of the mean for four simulation, and for the naive model the standard deviation of the mean was computed based on splitting the (balanced) set of edges/non-edges into four. Focusing on AUC, for Enron and NIPS all methods perform well, joint IRM perhaps slightly underper-forming. The NIPS network shows more variation, with hierarchical methods outperforming IRM meth-ods and THRM scoring higher than sliced HRM, pos-sibly also better than joint HRM. Model-wise, the hi-erarchical models seem to perform more consistently than the IRM. The NIPS network is very sparse, and results are indicative that hierarchical methods are better suited for this type of data. This is of par-ticular interest from the perspective of temporal net-work modelling, since in the very sparse limit shared information across epochs can be expected to have the largest effect. All models (except IRM on NIPS) out-perform the naive link prediction method, indicating methods based on inferring structure carry good ex-planatory power.
 In figure 3 is shown the temporal hierarchy for the MAP sample of the US Senate dataset. The giant tree is first laid out and then projected onto each epoch while keeping the leaf-locations fixed. Gray lines indi-cate movement across epochs and vertices are colored according to party. Republicans and democrats are consistently split, showing a strong tendency to vote similarly along these two factions.
 To better illustrate the multi-scaled structure of voting patterns, for each epoch the set of democrats and re-publicans was fragmented according to the tree struc-ture into sets of size less than 30. We used the set of senators mean location on the inserted color-bar to color-code their home states. The results indi-cate some consistency, for the projection of repub-licans notice California, Arizona and Utah Arkansas and Alabama seem to form a consistent pattern across all epochs contrasted to a faction consisting of Texas along with several central states. For democrats the CA,AZ,UT,AL,AB pattern seem to be present during the first three epochs and then become less consistent during the B. Clinton presidency.
 To illustrate the possibility for the model to explain faction changes, we extracted the senators present dur-ing at least 8 epochs and plotted the fraction of times they change position in the tree as well as standard deviations. Care need to be taken for this result due to the multiple-comparison problem, but notice the high value for J. Lieberman (D) who became an inde-pendent democrat during the 111th senate. Mind this is not indicating lower or higher degree of similarity of voting pattern, but that the voting pattern is not stable. We have proposed the temporal hierarchical relational model which incorporates two important aspects of complex networks: Temporal evolution and multiscale structure. The model is thereby able to express a num-ber of important dynamic network effects such as the emergence of new factions or vertices changing from one faction to another at multiple scales. The model is invariant under relabeling of vertices, invariant un-der temporal translation of all coordinates, marginal consistent, and marginally distributed as the HRM at each epoch.
 We further described how inference in the model can make use of distributed Gibbs sampling where compu-tations are reused by exploiting computational aspects of the inferred hierarchical structure during inference. Experiments on real datasets demonstrate that hierar-chical models perform on par or better than the IRM model, while the proposed THRM provides a novel dynamic description of the data.

