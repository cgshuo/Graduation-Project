 Procedures for collective inference make simultaneous statis-tical judgments about the same variables for a set of related data instances. For example, collective inference could be used to simultaneously classify a set of hyperlinked documents or infer the legitimacy of a set of related financial transactions. Several recent studies indicate that collective inference can significantly reduce classification error when compared with traditional inference techniques. We investigate the underly-ing mechanisms for this error reduction by reviewing past work on collective inference and characterizing different types of statistical models used for making inference in relational data. We show important differences among these models, and we characterize the necessary and sufficient conditions for reduced classification error based on experiments with real and simulated data.
 I.2.6 [ Artificial Intelligence ]: Learning; I.5.1 [ Pattern Recog-nition ]: Models.
 Algorithms, Performance, Design, Theory.
 Relational learning, probabilistic relational models, collective inference. Recent research in relational learning has produced several novel types of statistical models. These models estimate con-ditional and joint probability distributions for graph-structured data [1,4,12,15]. Researchers have evaluated their performance on several domains, including classifying web pages [1,15], tracking communicable diseases [6], and identi-fying topics in scientific literature [12].
 Some of this work focuses on collective inference  X  proce-dures that make simultaneous statistical judgments about the same variables for a set of related data instances. Collective inference can exploit relational autocorrelation, a widely ob-served characteristic of relational data in which the value of a variable for one instance is highly correlated with the value of the same variable on another instance [7]. Several studies [1,10,16] have shown that, by making inferences about multi-ple data instances simultaneously, collective inference can significantly reduce classification error.
 In this paper, we show that the reduced error attributed to col-lective inference results from a clever factoring of the space of possible statistical dependencies in relational data. This fac-toring produces relational models with a parameter space only incrementally larger that of their non-relational counterparts, and thus the variance component of their error is roughly equivalent. When relational information is not informative, the bias component of their error is identical to those of non-relational models, but when relational information is informa-tive, bias is vastly reduced. Thus, the increased algorithmic complexity of collective inference purchases a large increase in representational power at minimum cost. Relational models that do not exploit collective inference generally have much larger parameter spaces and require much larger data samples to learn relational models reliably. Traditional graphical models such as Bayesian networks and dependency networks assume that data consist of independent and identically distributed (i.i.d.) instances, and inference procedures for these models instantiate a separate network for each data instance. No dependencies run between the networks, because of the assumption that data instances are independent. Algorithms for constructing probabilistic relational models (PRMs) [4,12,15] remove the independence assumption, and instantiate a single network that represents dependencies both within and between the data instances in a given test set. This procedure  X  often called rollout  X  is common to graphical models that assume some form of instance dependence, includ-ing PRMs, HMMs, and others. Examples of PRMs include relational Bayesian networks (RBNs) [4], relational Markov networks (RMNs) [15], relational dependency networks (RDNs) [12], and Bayesian logic programs (BLPs) [8]. The process of rollout is sufficiently general that it can be applied to a wide variety of graphical models for relational data. Each type of model imposes different constraints on the possible dependencies in the network. Only some of these types make collective inference possible.
 For example, consider a data graph with a regular structure of n objects arranged in an n  X  n lattice. Each object in the lattice links to each of its immediate neighbors. With the exception of objects along the outer boundary, each object links to four others positioned above, below, left, and right. All links are undirected. Each object is characterized by a set of variables that includes a single probabilistic variable C (a class label) and several other variables A i (one or more attributes) whose values are known with certainty. The task is to construct a joint model of the probability distribution over all the values of the class labels.
 Given this task, multiple models could be used to infer the values of C . We will focus on five such models in our experi-ments: Intrinsic  X  For a given object, the Intrinsic model estimates the joint distribution of the class label and attributes on that object. It assumes that objects are i.i.d., and thus corresponds to traditional models used in many knowledge discovery ap-plications. The model is depicted graphically in figure 1a us-ing the plate notation common in the graphical modeling community. The inner box, along with the edge connecting A and C , indicates that m different versions of node A (corre-sponding to m attributes A i ) each depend on C . The outer box indicates that the model creates N different versions of the network, each containing a single node C . For example, this model would indicate that the words on a web page (the attrib-utes A i ) depend only on the topic of that page ( C ) and are inde-pendent of the topic and words on any other page.
 Relational 1 (R1)  X  The model R1 is a simple relational model indicating that the attributes of an object depend on the class label of that object as well as the class labels of objects one link away. Figure 1b shows this model using a modified plate notation in which the integer within the diamond-shaped an-notation ( X 1 X ) indicates the graph distance of neighboring objects and the multiplier on the edge ( X 4x X ) indicates the number of such neighboring objects. The path of the annotated edge outside the outer box emphasizes the dependence on the class labels of adjoining objects. Here, the value of each A depends on five different parents C , four of which are from neighboring objects. For example, this model would indicate that the words on a web page depend on the topic of that page and the topics of four adjoining pages.
 Relational 2 (R2)  X  A somewhat more complex relational model R2 indicates that the attributes of an object depend on the class label of that object and the class labels of objects up to two links away (Figure 1c).
 None of these three models allows interdependence among class labels, which is a prerequisite for collective inference. We examine two additional models that do allow for such depend-ence: Collective Inference (CI)  X  The model CI , shown in figure 2a, provides the same type of dependence as Intrinsic , but adds dependence between the class label of an object and the class label of adjoining objects. This is equivalent to specifying that the topics of web pages depend on those of adjoining pages (and also determine the words on the page).
 Relational Collective Inference (RCI)  X  The model RCI , shown in figure 2b, extends the R1 model by adding dependence among class labels of neighboring objects one link away. These models are relatively simple because the example data are highly regular and contain only a single object and link type. More heterogeneous data might require models with longer and more complex paths among objects. For example, paths connecting autocorrelated objects might pass through one or more intervening objects of specified types. However, the simplicity of this example allows us to focus on the criti-cal aspects of learning and inference in relational data. Collective inference has been a small but active area of re-search in relational learning for at least six years, since the publication of Chakrabarti, Dom, and Indyk's detailed study of hypertext categorization strategies [1]. Several more recent studies of collective inference have extended and broadened this work [9,12,14,15,17]. Finally, some work has extended the basic paradigm of collective inference to incorporate selecting among a range of possible actions. For example, Domingos and Richardson's work on mining the network value of cus-tomers incorporates collective inference into a larger approach to "viral marketing" [3]. Table 1 summarizes the types of mod-els evaluated in seven key papers.
 Many studies of collective inference have reported large reduc-tions in error when the method is applied. For example, Chak-rabarti et al [1] report large reductions in classification error, including one drop in error of over 70% (from 68% to 21%). In previous work, two of the authors reported significant accu-racy gains from a relatively simple technique for collective inference [10]. Macskassy and Provost show how models that consider only autocorrelation in class labels (equivalent to CI without attributes) can perform very well when only a small fraction of the class labels are known [9].
 Several studies have also pointed out that collective inference of various types can also reduce accuracy. For example, Chak-rabarti et al. [1] discuss an experiment where including rela-tional information about web pages actually reduces accuracy. They hypothesize that the additional features meant that the learning and inference scheme was "overwhelmed by the signal to noise ratio".
 Based on these results, it appears clear that collective inference is capable of significantly improving probabilistic inferences in relational data. Important questions remain, however: why and under what circumstances does collective inference im-prove the accuracy of relational models? One reasonable explanation is that the power of collective inference lies merely in the larger feature-space provided by models such as CI . These models consider features that their less expressive cousins (e.g., R1 ) do not. In experiments below, we will show that this explanation is inadequate to explain the power of collective inference.
 Instead, we show that methods for collective inference benefit from a clever factoring of the space of dependencies . The models CI and RCI have substantially smaller parameter spaces than the model R2 , yet they can benefit from information propagated from outside of their local neighborhood. Predic-tions about the class label C on other objects essentially  X  X undle information X  about the graph beyond the immediate neighborhood. In addition, collective models can make use of known class labels (e.g., known topics of web pages) to im-prove inferences about unknown labels. This provides a new, and often highly reliable, additional feature for learning and inference.
 This increased representational power is purchased with only an incremental increase in the parameter space. In this way, CI and RCI emulate other robust techniques such as simple Baye-sian classifiers and linear regression models. Even when their assumptions are violated, CI and RCI often perform well. To evaluate different models and inference methods, we con-ducted experiments with both real and synthetic data. Our empirical experiments considered relational data about the yeast genome, containing information about 1,243 genes and 1,734 interactions among their associated proteins (http://www.cs.wisc.edu/~dpage/kddcup2001/). Both gene location and function are autocorrelated in this dataset [11] so we expect it to be a good testbed for investigating the relative performance of the various relational models.
 The learning task was to predict gene localization in the cell. There are 15 locations ranging from mitochondria to plasma membrane, with a default error rate of 0.57. In addition to gene location, each gene has 13 boolean attributes indicating gene function. Each gene may have as many as six functions. For non-collective models, we used relational Bayesian classi-fiers (RBCs) [13] to predict gene location given the function attributes. The Intrinsic model considered the 13 function attributes on the genes themselves. The R1 model added an-other 13 function attributes for genes one link away (through interactions) for a total of 26 attributes. The R2 model then added another 13 attributes for genes two links away, for a total of 39 attributes. For collective models, we used relational dependency networks (RDNs) [12] with RBCs to represent the component conditional probability distributions. The CI model considered the location attribute of genes one link away, in addition to the 13 function attributes of the genes in isolation. The RCI model added in the 13 function attributes for genes one link away for a total of 27 attributes. The RDNs used 250 Gibbs iterations and all models used Laplace correc-tion for zero-values.
 To compare the five approaches, we evaluated zero-one loss over ten-fold cross validation trials. We report average error over the ten folds and use two-tailed, paired t-tests to assess the significance of the results. To generate synthetic data, we extended the example presented in section 2.1. We generated data with a regular two-dimensional lattice structure. The first and last two rows and columns make up the  X  X rame X  of the lattice. Objects in the frame are not used to train models, and objects in the frame are not used for loss estimates, although inference is performed over all objects in the lattice, including the frame. Thus, train-ing or test sets of size S 2 correspond to a lattice of ( S +4) ( S +4) objects, and models are trained or evaluated on the S objects in the core of the lattice.
 Each object in a given dataset contains the same set of attrib-utes. In every dataset, objects contain a class label C and a single attribute A 1 , that is correlated with C . Depending on dataset generation parameters, objects may also contain up to 14 additional attributes, none of which are correlated with C . We generated the values of attributes and class labels in two ways, which we label  X  X elational X  and  X  X ollective X . Both use parameters given in Table 2. For collective data generation , we begin by assigning each object in the lattice an initial class label with P(C=1) = 0.5 . We then perform Gibbs sampling over the entire lattice. The class labels assigned to each object after 200 iterations are used as the final labels. To assign class la-bels during Gibbs sampling, we use a manually specified model that assigns class labels to each object based on the class values of neighboring objects one link away. The pa-rameters of this model are varied to produce different levels of autocorrelation among neighboring class labels. Once class labels are assigned, a value for the A 1 attribute is randomly drawn from a distribution conditioned on the class label of the object  X  derived from the P(C|A 1 ) and P(A 1 ) data generation parameters. Finally, random values are assigned to all other attributes with P(A i ) = 0.5 . Once a dataset is generated, we measure the proportion of objects with positive class labels, and any dataset with a value outside the range [0.4, 0.6] is dis-carded and replaced with a new dataset. This ensures consis-tency in P(C) across datasets and reduces variance in estimated model performance. Bold numbers in the value column indicate default values. For relational data generation , we begin by training the pa-rameters of an R2 model on a large dataset consisting of 100 lattices of 1000 objects each. The attributes and class labels on the objects of each lattice are determined by the collective data generation method described above. We also train a univariate model of P(A i ) for each attribute A i . We create a lattice of ob-jects in the usual way, assign attribute values randomly to each object based on the learned model of P(A i ) , and assign class labels to each object based on the attribute values of itself and all neighboring objects up to two links away using the learned R2 model.
 We measured bias and variance for each model using the de-composition defined for squared-loss by Domingos [2]. Loss is decomposed into three factors: bias, variance and noise. Although calculation of variance is straightforward for rela-tional data, calculation of bias is not. Fortunately for the syn-thetic data experiments, we know the probabilities from the generative model and can use these as the optimal predictions. Bias and variance estimates are calculated for each test exam-ple using 10 different training sets and averaged over the en-tire test set. This was repeated for 20 test sets to calculate aver-age test set bias and variance. Figure 3a shows squared loss as a function of training set size for all models. Data for figure 3a were produced using the col-lective generator, so it is not unexpected that CI rapidly con-verges to a relatively low loss. R2 continues to reduce its loss as TrainSize increases. At TrainSize=5000 , none of the mod-els achieve minimum error, corresponding to the CI model provided with perfect class information, but R2 continues to reduce loss at a steady rate. For all points with TrainSize &gt; 100 , the 95% confidence intervals are less than 0.004 Figure 3b shows the same type of results for the relational data generator. Even though they do not match the data generator, CI and RCI outperform other models when TrainSize is small. R2 continues to have corresponding high loss, though it will eventually drop below CI and RCI as it declines to the optimal value of loss at high TrainSize . R1 performs similarly, drop-ping below CI at around TrainSize =3000. For TrainSize &gt; 100 , the 95% confidence intervals are less than 0.004. We obtained similar results with experiments on the yeast protein data, shown in Table 3. CI resulted in the lowest zero-one loss and its loss was significantly different than the zero-one loss of all other models.
 What is responsible for the low error of CI models? We meas-ured bias and variance for the probability estimates of each model to compare their decomposed loss as a function of TrainSize . Figures 4a and b show the results for the relational generator. For the collective generator, the variance results were qualitatively similar and the bias varied only slightly across the range of TrainSize .
 For all models except R2 , bias quickly becomes nearly level. The bias of R2 continues to decline as data slowly accumulate in joint distributions and overcome the prior (an initial Laplace correction to prevent zero probabilities). Variance is level for Intrinsic and CI , but continues to decline for R2 , and less so for R1 and RCI , between TrainSize values of 1000 and 5000. For all points with TrainSize &gt; 100 , the 95% confidence intervals are less than 0.002.
 Thus, the large initial gap in loss between CI and R2 appears directly attributable to the size of R2  X  X  parameter space, and the difficulty of making good estimates with sparse data. This difference between CI and R2 is pronounced even though ob-jects in the data contain only three attributes. If the number of attributes on each object is increased, as shown in figure 5, the loss of R2 soars compared to other models, including CI , whose loss remains nearly constant. Even R1 and RCI show marked increases in loss, though to a much smaller extent than R2 . The results for data produced by collective generation are qualitatively similar.
 This growth in the number of attributes is modest compared to some of the most common applications of relational learning algorithms, such as classifying web pages, in which objects have hundreds or thousands of attributes (e.g., words on a web page). For these applications, the ability of CI to provide a built-in factoring of the feature space may be almost essential.
Figure 3: Squared loss for (a) collective data generation, The negative effect of large parameter spaces on R2 and RCI is a plausible explanation for the results of our experiments with the yeast protein data. Both R2 and RCI perform worse than CI . Our data generation procedures use two parameters P(A P(C|A 1 ) to determine the strength of probabilistic dependence between the attribute A 1 and the class label C . The relative per-formance of models differs based on the strength of this de-pendence. Figure 6 depicts how the quantity loss(R2)  X  loss(CI) varies as a function of P(A 1 ) and P(C|A The largest difference between the two models occurs when P(A 1 ) is uniformly distributed and the dependence of A and C is weakest. That is, CI performs best, in relative terms, when few correlations exist other than autocorrelation of class la-bels. The relative advantage of CI disappears as more informa-tion is available to R2 . However, if no attributes are useful then only CI would be able to attain non-random performance. Relational autocorrelation refers to the correlation among the values of the same variable on several related objects. The widespread occurrence of autocorrelation is one of the strong-est motivations for relational inference of any kind. Its effects have been noted and explored by several researchers in collec-tive inference, including Macskassy &amp; Provost [9], Taskar et al. [15], and Yang et al. [17].
 Figure 7 shows the effect of increasing levels of autocorrela-tion on the relative performance of different models. All mod-els we consider, except Intrinsic , are greatly aided by autocor-relation, though their relative ordering changes slightly. R1 is aided least by autocorrelation while R2 is aided most. These results reveal another advantage of CI . Even when auto-correlation is entirely absent, CI  X  X  performance is equal to that of Intrinsic . CI can exploit autocorrelation when present, but is not significantly impaired by its absence. The core of collective inference is that inferences about one object can inform inferences about another. This capability is particularly useful when some values are known with certainty. For example, predictions about the topic of a previously un-visited webpage may be aided by considering the known top-ics of previously visited pages.
 Figure 8 shows how varying the proportion of labeled data affects CI and RCI , and how their performance compares to an alternative inference scheme for these models (labeled de-fault ). Rather than conducting full collective inference, de-fault models terminate inference after the first round of Gibbs sampling. These results indicate the advantage of collective inference over non-collective, holding all other factors con-stant. As shown in figure 8, the relative advantage of collective inference is reduced as more of the data are labeled. That is, collective inference procedures become less and less necessary as the percentage of true labels increases.
 While only a few studies [1,9,16] have actively varied the per-centage of known labels, the results above closely parallel those of Macskassy and Provost [9], who show that the relative advantage of an iterative inference procedure over a non-iterative procedure reduces as the percentage of labeled data increases. They show that, in general, their collective inference procedure performs better when class skew is present or when few labels are known with certainty.
 We also evaluated this effect using the yeast protein data, ob-taining the results shown in table 4. For each of the ten-fold cross-validation partitions, we learned a CI model on the 90% training partition and applied the model to the entire dataset. During collective inference, we varied the proportion of the data that was labeled X  X he test partition was always unlabeled but the training partition was labeled at the following levels {1.0,0.55,0.11} to produce overall levels of {0.9,0.5,0.1}. Ac-curacy was measured on the unlabeled instances and averaged over the ten folds. Loss increases significantly when only 10% of the data are labeled, but there is no significant difference in performance between 50% and 90% labeled.

Figure 4: Loss decomposition into (a) bias, and (b) vari-Table 4: Yeast protein data results with partial labeling. Our experiments with real and synthetic data indicate that the reduced error attributed to collective inference results primar-ily from a clever factoring of the space of statistical dependen-cies in relational data. Models that represent this factoring, when combined with algorithms for collective inference, can greatly reduce bias in data with strong autocorrelation with the minimum possible increase in variance. When autocorrelation is absent, the models have practically equivalent error to their non-relational counterparts. Amy McGovern and Agustin Schapira provided technical as-sistance with experiments. This effort is supported under a AT&amp;T Labs Graduate Research Fellowship and by AFRL under contract number F30602-01-2-0566. The U.S. Government is authorized to reproduce and distribute reprints for governmen-tal purposes notwithstanding any copyright notation hereon. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily represent-ing the official policies or endorsements either expressed or implied, of AFRL or the U.S. Government. [1] Chakrabarti, S., B. Dom &amp; P. Indyk. Enhanced Hypertext [2] Domingos, P. A Unified Bias-Variance Decomposition for [3] Domingos, P. &amp; M. Richardson. Mining the Network [4] Getoor, L., N. Friedman, D. Koller, &amp; A. Pfeffer. Learning [5] Getoor, L., E. Segal, B. Taskar, &amp; D. Koller. Probabilistic [6] Getoor, L., J. Rhee, D. Koller, &amp; P. Small. Understanding [7] Jensen, D. &amp; J. Neville. Linkage and Autocorrelation [8] Kersting, K. &amp; L. De Raedt. Basic principles of learning [9] Macskassy, S. &amp; F. Provost. A Simple Relational Classi-[10] Neville, J. &amp; D. Jensen. Iterative Classification in Rela-[11] Neville, J. &amp; D. Jensen. Supporting Relational Knowledge [12] Neville, J., &amp; Jensen, D. Collective Classification with [13] Neville, J., D. Jensen &amp; B. Gallagher. Simple Estimators [14] Slattery, S., &amp; T. Mitchell. Discovering Test Set Regulari-[15] Taskar, B., P. Abbeel &amp; D. Koller. Discriminative Probabil-[16] Taskar, B., E. Segal &amp; D. Koller. Probabilistic Classifica-[17] Yang, Y, S. Slattery &amp; R. Ghani. A Study of Approaches to
