 One fundamental issue of learning to rank is the choice of loss function to be optimized. Although the evaluation mea-sures used in Information Retrieval (IR) are ideal ones, in many cases they can X  X  be used directly because they do not satisfy the smooth property needed in conventional machine learning algorithms. In this paper a new method named RankCSA is proposed, which tries to use IR evaluation mea-sure directly. It employs the clonal selection algorithm to learn an effective ranking function by combining various ev-idences in IR. Experimental results on the LETOR bench-mark datasets demonstrate that RankCSA outperforms the baseline methods in terms of P@n, MAP and NDCG@n. Categories and Subject Descriptors: H.3.3 [Informa-tion Storage and Retrieval]: Retrieval models General Terms: Algorithms, Experimentation, Theory. Keywords: Clonal Selection Algorithm, Information Re-trieval, Machine Learning, Learning to Rank, Ranking func-tion
In recent years, learning to rank is becoming more widely used for the ranking problem of IR. It has been devoted to automatically learning a ranking function from a set of training data with relevancy labels. One fundamental is-sue of learning to rank is the choice of loss function to be optimized. Since in IR, ranking results are generally evalu-ated using IR evaluation measures, therefore they are ideal loss functions for optimizing. In this way, high accuracy in training promises high performance in evaluation. However, this is usually difficult due to the requirements of loss func-tions in conventional machine learning techniques, i.e., most optimization algorithms need smooth, or even convex loss functions while IR measures are rank-dependent, and thus non-continuous and non-differentiable [8].
 Many proposed learning to rank algorithms transform the ranking problem into binary classification on pairs constructed between documents [3, 4]. These methods typically mini-mize a loss function loosely related to IR evaluation mea-sures. Recently, several methods have managed to directly optimize the performance in terms of IR measures [9]. Mostly, these methods address the non-smooth optimization by sur-rogate loss functions, which bound or approximate IR mea-sures. The effectiveness of the direct optimization methods have been verified empirically and theoretically [7, 9]. But in many cases the relationships between the surrogate func-tions and the IR measures are not clear [7].

In this paper, we aim to develop a general learning ap-proach that can directly optimize the performance measures used in IR innately. To address this challenge, a learning to rank method called RankCSA is proposed, which employs the clonal selection algorithm to learn an efficient ranking function by combining various evidences in IR.

The main contributions of this work are as follows. First, this paper employs the clonal selection algorithm for learn-ing ranking functions. We define the representations of anti-gen and antibody together with a shape-space model for the ranking problem of IR. The second contribution is the direct use of IR measure, Mean Average Precision, as the affinity function in the evolution process. Using IR measure but not a surrogate function helps RankCSA outperform other methods. Finally, the effectiveness of the proposed method is verified on the LETOR collections in comparison with the state-of-the-art methods. The results show that RankCSA achieves consistent improvements over the compared rank-ing algorithms in most cases.
In training, a query set Q = { q 1 ,q 2 ,...,q | Q | } and a docu-ment set D = { d 1 ,d 2 ,...,d | D | } are given. Each query q associated with a list of documents d i = { d i 1 ,d i 2 ,...,d and a list of labels y i =( y i 1 ,y i 2 ,...,y i | d i | denotes the j th document in the list and y ij is a relevance judgment indicating the relative similarity of d ij to q i
Each query-document pair ( q i ,d ij ) can be expressed as  X  ( q i ,d ij ), where  X  : Q  X  D  X  N is a feature mapping function from a query-document to a feature vector, a point in N dimensional space.

In the learning to rank task for IR, an antigen derived from the biological immune systems can denoted as a 3-tuple.
Itcanbeseenthateachantigeniscomposedofaquery,a list of related documents and the corresponding list of labels. In this way, our method enjoys the advantages of the listwise approach. The training set is created as a set of antigens. An antibody Ab represents a potential ranking function. It is defined as a functional expression using three compo-nents: S f , S c , S op . S f is a set of symbols, referring to features in the feature vector  X  ( q,d ). S c is a set of real numbers, ranging from 0.0 to 10. S op is a set of arithmetic operators. Thus an antibody can be denoted as Equation 3 shows.
 where S f , S c and S op are given by Equation 4.
In this paper, we choose the tree-based framework as our computing architecture for antibodies. Specifically, Ab is represented as a complete binary tree structure. The inter-nal node is an arithmetic operator and the leaf node is either a feature or a constant. The maximum number of available nodes of an antibody is determined by the depth of the tree, which is a parameter of the learning method.

A repertoire is a set of antibodies, wherein each mem-ber represents a candidate solution, and can be denoted as Equation 5 shows.

For each document d ij in Ag i , Ab can output a score ac-cording to  X  ( q i ,d ij ). A ranking  X  i =(  X  ( d i 1 ) , X  ( d is produced by sorting the scores, where  X  ( d ij )istheposi-tion that d ij appears at in  X  i .Thatis,  X  i is the predicted ranking of the documents with respect to q i given by the antibody Ab .
Mathematically, the generalized shape of a molecule, ei-ther an antibody or an antigen, can be represented as a L dimensional attribute string m . The attribute string con-tains values of the individual coordinates of the shape in the shape-space S, i.e. m = &lt;m 1 ,m 2 ,...,m L &gt;  X  S L . In this paper, a shape-space model for rank problem of IR is defined to characterize of the antigens and antibodies, and quantitatively describe their interactions. For the given antigen and antibody, let m Ag i = y i , m Ab =  X  i and L = respectively.

The Ag-Ab representation determines the affinity mea-sure. Based on the definitions above, the affinity function can be defined as follows.
 where E is an evaluation measure in IR.

The objective of learning is formalized as selection of a best antibody which can maximize the mean affinity with respect to all antigens in the training data.

The proposed learning method, RankCSA, can be de-scribed in Algorithm 1.
 Algorithm 1 RankCSA Input: training set T , validation set V and parameter N (The fixed antibody repertoire size), n (The number of anti-bodies to select for cloning), Gen (Stop condition), d (The number of antibodies to select for replacing) Output: the best antibody Ab best Learning Procedure: (1) Randomly initialize N antibodies as the initial reper-toire, R . (2) Present the training set T to each of the N antibodies in R and determine their affinities by Equation 7. (3) Select n high affinity antibodies from R composing a new set R n of high affinity antibodies. (4) The n selected antibodies in R n will be cloned (repro-duced), generating a repertoire R C of clones. (5) All antibodies in R C are submitted to an affinity mat-uration process inversely proportional to their antigenic affinities, generating a population R C  X  of matured clones: the higher the affinity, the smaller the mutation rate. (6) Determine the affinitie s of the matured clones. (7) From this set of mature clones, re-select the N  X  n high affinity antibodies that are not in R n . These antibodies and R n generate a repertoire R E of elites. (8) Replace the d lowest affinity antibodies from R E by new randomly generated individuals to re-compose the antibody repertoire, R . (9) Repeat Step (2)-(8) until the number of iterations reaches Gen . (10) Select the best antibody Ab best in R .

Following are the explanations for Algorithm 1.
In Step (3) and (7), antibodies are not selected in a se-quential manner, because it is opposite to the principles of immune system. Instead, we introduce the conception  X  X eme X  into our approach, which originates from an impor-tant technology of GP. Select an antibody Ab r randomly, then itself together with its | Deme | X  1 neighbors comprise a Deme as follows, The antibody with the highest affinity in the deme will be selected.
In addition to selection, the iterative process in RankCSA involves three other operations: cloning, hyper-mutation andreplacement. InStep(4),thenumberoftheclones generated for each of the n antibodies is given by round (  X  n  X  MAF ( Ab, T )), where  X  is a multiplying factor and the round (  X  ) function rounds a number to the nearest integer. So that the total amount of clones, namely the population of R C , can be denoted as Equation 9 shows.

The hyper-mutation provides the algorithm with the abil-ity to introduce new material into the repertoire and ex-pands the solution space searched. The inverse proportion-ality of hyper-mutation ensures that high-affinity antibodies are disturbed only slightly while low-affinity ones are mod-ified to a high extent [6]. There are two kinds of opera-tions used in hyper-mutation to diversify the clones: single-mutation and multi-mutation . Single-mutation only makes some changes on a single node of the antibody. For multi-mutation , a mutant is created by randomly choosing an in-ternal node then replacing its whole sub-tree with a ran-domly generated tree. The choice of which operation takes place depends on a dynamic parameter P m :Ifallthean-tibodies in the repertoire have similar affinities, RankCSA will emphasize multi-mutation by increasing its probability of occurrence. Otherwise the rate is set unchanged as the initial one.

It is important to remark that antibody with higher affin-ity must somehow be preserved as high quality candidate so-lutions, and shall only be replaced by improved candidates, based on statistical evidences. In order to maintain the best antibodies for each clone during evolution, in Step (7), we keep one original antibody for each clone un-mutated during the maturation phase. A duplicate antibody is not allowed.
Another basic mechanism to diversify the repertoire of an-tibodies is replacement. In Step (8), newcomers are added to the repertoire and low-affinity antibodies are eliminated to stop further alteration. It also offers the ability to es-cape from local optima on an affinity landscape and yield a broader search for the global optimum of ranking functions. In the last step of the algorithm, we use a validation set V to help choosing the best antibody from R that is not over-specialized for antigens in the training set. To assure antibody X  X  generalization ability, we consider the average performance of an antibody in both the training and val-idation sets minus the standard deviation value, which is called AV G  X  method in [2]. Formally, for all the antibodies Ab in R , the best one is selected by Equation 10. AV G  X  :argmax
LETOR [5] is a package of benchmark datasets for re-search on learning to rank released by Microsoft Research Asia, which contains standard features, relevance judgments, data partitioning, evaluation tools, and several baselines. We conducted experiments to test the performance of RankCSA using two benchmark datasets: OHSUMED and MQ2007.
For each benchmark dataset, 5-fold cross validation strat-egy is adopted. We use four learning methods, Ranking SVM [4], ListNet [1], AdaRank [9] and RankBoost [3] as baselines and evaluation measures P@1-10, MAP and NDCG@1-10 are conducted to compare with the proposed RankCSA method.

For RankCSA, most parameters are set empirically in the experiments. The type of the ranking function that RankCSA targets at is assumed non linear. We set Gen = 200, N = 500, n = 50, | Deme | =9, d = 100 (corresponding to a rate of 20% newcomers) and  X  = 10. P m is initialized as 0.5 and will be increased in step of 0.05 if necessary. The most widely-used IR measure, MAP is utilized as the affinity function. The tree depth is set to be 8 in order to at least cover the case that leaf nodes contain all features and the same number of constants.

Same with [10], we perform RankCSA 10 times to reduce the effect of the random process. Results shown in the next section are the average over 10 runs.
Table 1 gives the evaluation result of MAP on the both datasets. It shows that RankCSA beats all the baseline methods in all cases. However, there is no significant differ-ence among these methods in terms of the MAP measure. This is because MAP emphasizes the overall ranking perfor-mance, i.e., it gives consideration to the ranking precision at all positions.

Figure 1 shows the results on OHSUMED. From Fig-ure 1(a), we observe that all methods perform similarly after n = 6. But if we focus on the P@1-5, RankCSA outperforms all baseline methods evidently. Especially for P@1, RankCSA achieves more than 11% relative improve-ment over RankSVM. Similar result is also observed in Fig-ure 1(b). NGCD@1 is improved by 14.6% and 4% over RankSVM and the second best method, ListNet respec-tively. However, RankCSA is beaten by AdaRank-NDCG in terms of NDCG@5 and NDCG@6 by a nose.

We also conducted experiments to observe the learning curve of RankCSA. We recorded the average affinity of the best antibody in the repertoire every 10 generations in 10 runs. Figure 1(c) demonstrates the average affinity variation curve. We observe that the affinity changes sharply before 100 generations and will converge after that. Furthermore, the observation implies RankCSA still has a potential after 200 generations. This issue will be discussed in Section 3.3. Figure 2 shows the results on MQ2007. We can see that RankCSA outperforms all baseline methods in terms of all measures. In Figure 2(a), RankCSA has a clear advan-tage over the four baselines with respect to P@1-6. Al-though RankCSA is competitive with RankBoost in terms of P@n value after n = 7, it performs much better than the three other methods. Figure 2(b) shows that RankCSA achieves significant improvements. In particular, NDCG@1 and NDCG@2 are improved by 11.6% and 10.8% over AdaRank-MAP respectively.
Based on the comparison and analysis on the both datasets, we can draw a conclusion that the proposed RankCSA is good at ranking relevant documents at the very top posi-tions, e.g., it shows distinct advantage in terms of P@1 and NDCG@1.

The experiment results demonstrate that RankCSA can always improve upon the pairwise methods of Ranking SVM and RankBoost. In addition, AdaRank optimizes an expo-nential loss function based on MAP while RankCSA uses MAP as the affinity function without any relaxation or ap-proximation. The experiment results indicate that the pro-posed RankCSA is more effective than AdaRank.

Through the experiments, we conjecture that the results of RankCSA might be improved if more generations and larger populations are given. However, the computational cost of RankCSA is much huge. There is a trade-off between performance and time complexity.
We have proposed a learning method called RankCSA for learning to rank for IR. RankCSA employs the clonal se-lection algorithm to learn an effective ranking function by combining various evidences in IR. Our method avoids op-timizing surrogate loss functions of IR measures. Instead, it directly optimizes IR measures themselves. We conducted experiments on LETOR benchmark datasets. Four state-of-the-art learning methods of RankSVM, ListNet, AdaRank and RankBoost were compared with RankCSA. The results show that RankCSA yields consistent improvements over baseline methods in most cases.
This work is supported by the Natural Science Founda-tion of China (60970047) , the Natural Science Foundation of Shandong Province (Y2008G19) and the Key Science-Technology Project of Shandong Province (2007GG10001002, 2008GG10001026).
