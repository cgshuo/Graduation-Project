 Yakub Sebastian 1( Literature-based discovery (LBD) is one of the grand challenges in data mining [ 1 ]. Its goal is to discover interesting, novel connections between previously dis-connected research areas [ 2 , 3 ]. Associations between literatures often take the form of co-citation links between them [ 4 ]. Figure 1 shows the evolution of paper clusters 1 before and after the publication of Swanson X  X  seminal hypothesis on previously unknown relationships between dietary fish oil and Raynaud X  X  syn-drome [ 5 ]. It can be observed that new co-citation links emerged between fish oil (FO) and Raynaud X  X  syndrome (RS) papers following the announcement of Swanson X  X  discovery in 1986. Consequently, the LBD problem can be formulated as predicting future co-citation links between papers from previously discon-nected literature clusters, and the challenge for data mining is to find which features can be used to reliably predict the future formation of these links. ciations between disjoint literatures based on the number of co-occurring terms between them [ 6 , 7 ]. Unfortunately, a major limitation of these methods is that merely relying on lexical analysis tends to produce high recall but low precision results [ 8 ]. Many false associations were generated because term co-occurrence can only send a weak signal about meaningful associations between different papers [ 3 ]. The more sophisticated LBD methods incorporate knowledge-based resources LBD accuracy. For example, Hristovski et al. [ 11 ] extracted logical assertions from text as subject-predicate-object triplets and assembled them to make inferences about hidden relationships between papers. Unfortunately, it has been argued that most logical associations in text may not exist in such a simple linguistic template [ 2 ], and such approaches are likely to suffer from low recall.
 citation links between papers in disconnected research areas by exploiting latent, semi-structured data found in heterogeneous bibliographic information network (HBIN) [ 13 ]. We first constructed a HBIN network from which we built a number of meta path features. We evaluated the performance of these meta path features using five machine learning algorithms for predicting three types of co-citation reproducing Swanson X  X  classic dietary fish oil and Raynaud X  X  syndrome (DFO-RS) hypothesis [ 5 ]. We found that meta path features outperformed several well-known document similarity features.
 method combines lexical and citation information. HBIN meta paths allow lexical associations (e.g. common terms between papers) to propagate through the cita-tion structures between papers (e.g. via common authors or shared references). We argue that this approach has increased both the precision and recall of our LBD method. Results show that we could accurately predict future co-citation links between fish oil and Raynaud X  X  syndrome papers with 0.851 F-Measure. More importantly, the performance of our method is achieved without relying on knowledge-based resources nor sophisticated NLP techniques. To the best of our knowledge, this is the first work that uses HBIN to solve LBD problems. This paper is organized as follows. Section 2 highlights some related work followed by detailed descriptions of HBIN in Section 3 . Section 4 explains how we learned meta path features from an HBIN network to predict future co-citation links. Section 5 presents our experimental results and Section 6 presents some discussions. We conclude the paper in Section 7 . A few authors have used HBIN to enhance the accuracy of citation recommenda-features to predict direct citation link between papers in DBLP and PubMed datasets. Given a query paper, they learned the probabilities that candidate papers will be cited by the query paper based on the similarity of their meta paths. These methods first reduce their search space by grouping candidate papers into  X  X uckets X  of papers that belong to similar research areas or interests. This grouping allows these algorithms to focus their search on candidate papers that have similar research areas to the query paper. Liu et al. [ 15 ] combined meta path features with additional features that capture citation count and citation topic motivations in order to predict direct citation links between papers. These features, however, require that the abstracts or full-text of papers be available. Our method does not assume that full-text papers are available and only requires basic bibliographic meta data, e.g. title, author, publisher, and citations. Although related, current citation recommendation systems such as the above are fundamentally different from the LBD work presented in this paper. These algorithms assume that a paper will only cite papers from the same or closely related research areas [ 14 ]. In contrast, LBD is concerned with finding hidden relationships between papers from seemingly unrelated research areas. In this respect, our LBD problem is harder than than citation recommendation problem. Another important difference is that the existing works [ 14  X  16 ] aim at predicting direct citation links, whereas our work aims at predicting co-citation links. In addition, we also study more types of meta path features (in total 87 distinct features in more detail in Section 4 . A heterogeneous information network is a directed graph posed of multiple-typed entities and links [ 13 ]. HBIN is a type of heterogeneous information network that allows one to model rich interactions between var-ious types of bibliographic entities. As shown in Figure 2 , HBIN consists of four types of bibliographic entities A with many possible connections among them: paper ( P ), author ( AU ), venue (journal or conference) ( (
T ), A = { P,AU,V,T } . Unlike previous work [ 14  X  16 ], we further categorize the entity type P into core paper ( P core ), citing paper ( P (
P ref ) sub-types, P = { P core ,P cite ,P ref } . Core papers are papers that belong to either one of the disconnected literatures being studied. For example, in the case of Swanson X  X  DFO-RS hypothesis, papers that belong to either the fish oil or Raynaud X  X  syndrome literature are considered as core papers. Citing papers are papers that cite core papers while reference papers are papers cited by core papers. Each core paper is associated with zero or more citing papers and ref-erence papers. Using these entity sub-types, we hope to capture more specific relational semantics between instances of entity P .
 ties in HBIN, R = { P  X  AU, P  X  X  X  P, P  X  V, P  X  T } . We will describe these edge types in sections that follow. A meta path MP MP = A to model latent, semi-structured relationships among bibliographic entities in HBIN which could signal previously unknown connections between core papers that have never physically cited each other or have never been co-cited before (isolated). For example, the red meta path  X (3) X  and green meta path  X (4) X  in Figure 2 suggest some connections between core papers p Likewise p FO ( B ) is written by the same author of a paper that cites (path  X (3) X ). Both papers also cite papers published in a similar venue (path  X (4) X ), also signaling their potential associations. Given a pair of disconnected core papers p i and p j , we define 16 different types of n -degree meta-paths between the core papers, where n is the number of edges separating p i from p j . These sixteen meta paths consist of 4 paths, 6 three -degree meta paths, and 6 four -degree meta paths. Refer again to Figure 2 , meta path  X (2) X  is a two-degree meta path connecting p )and p RS ( B ) (i.e. p j ) via a common term T . The same meta path type can be established via AU , V ,or P ref . Meta path  X (3) X  is a three-degree meta path where p FO ( B ) shares a common author AU with paper that cites Likewise the same meta path can be established through the sharing of via P cite and P ref . Finally, path  X (4) X  is a four-degree meta path through which p
B ) and p RS ( A ) are connected by their cited references which are published at the same venue V . The same path may exist via P cite that share We measure the association strength of a meta path using a meta path score. This score is determined by the weights of a path X  X  component edges. We propose five edge weighting schemes which measures the local importance and the global importance of a meta path edge. For example, the local importance of edge P  X 
AU is the importance of author AU with respect to paper P important to P if he or she is the sole author of P than if he or she is just one of many authors of P . The global importance of AU is its importance with respect to the research areas being studied. It is measured by the frequency of his or her co-authorships with other authors in those research areas. If the author has a high number of co-authorships in a particular research area, we assume he or she is an important contributor to that area.
 We compute the weight of an edge between paper p i and author where count ( p i ,AU p i ) is the total authors in paper total non-unique co-authorship pairs between author a j and other authors in cluster k ,and freq ( AU P k ) is the total non-unique co-authorship pairs of all authors in cluster k . This weighting score measures the importance of association with respect to paper p i (local importance) as well as author global importance in N number of disconnected research areas being studied. Next, we compute the weight of edge P  X  X  X  P as follows: where and the total papers that cite p i , respectively. The less references in more important p j is to p i . This is because, given limited opportunities to cite references in their papers, most authors would only include important references. The count ( P k ,p j )and and the total papers in cluster k cited by p j , respectively, whereas count ( the total number of papers in cluster k . The more frequently k or the more frequently p j cites papers in the cluster k , the more important it is to the cluster. Next, the weight of edge P  X  T is: papers of cluster k divided by the total all terms in the cluster. The more fre-quently term t j appears in a paper or a cluster, the more important the term is. Lastly, we define the weight of edge P  X  V as: where count ( P k ,v j ) is the total papers in cluster k 4.1 Constructing HBIN Matrices Having defined the edge weighting schemes above, we constructed HBIN network using a set of matrices in a manner similar to Ren et al. [ 16 ]. Given papers in P , P = { P core ,P cite ,P ref } , we first built adjacency matrix that stores citation relationships between instances of P cites p j ,and M ij = 0 if no citation exists between them. Based on subsequently built two weighted adjacency matrices: We also built bi-adjacency matrices that represent the relationships between instances of P and instances of AU , V ,and T . Bi-adjacency matrix R n  X | AU | represents bi-partite relationships between instances of where B ( AU ) ij =1if p i is written by a j ,and B ( AU ) B AU ) , we built a weighted bi-adjacency matrix: Next, we built bi-adjacency matrix B ( V )  X  R n  X | V | , where published in venue v j ,and B ( V ) ij = 0 if not. Based on bi-adjacency matrix: Finally, given a set of unique terms T = { t 1 ,...,t | T | bi-adjacency matrix B ( T )  X  R n  X | T | where the value of term t j appearing in the title and abstract of paper p i . We removed English stop-words 2 and applied Porter Stemmer 3 to discard morphological and inflexional endings from English terms. From B ( T ) we built the following matrix: 4.2 Meta Path Features We used 16 adjacency matrices MTM ( mp )  X  MP mm to store all meta paths between m core papers, where MTM ( mp ) ij is a set of zero or more meta path instances between core papers p i and p j . Given a set of all meta paths between p and p j , we compute five different meta path scores: (1) Path count , a simple count of meta paths; (2) Sum of weights , the sum of edge weights of all meta paths; (3) Average of weights , the average edge weights of all meta paths; (4) Minimum weight , the smallest edge weight of all meta paths; and (5) Maximum weight , the largest edge weight of all meta paths.
 From these 16 types of meta path and 5 types of meta path scores, we derived 80 distinct meta path features. We also added 7 meta path features consist-ing of 3 features based on the total count of n -degree meta paths, 3 features based on total count of meta paths according to their meta data type, and 1 feature which is the total count of all meta paths between presents a compacted list of all meta path features we used. For example, fea-ture 7 is read as 2 term sum , which is the sum of all edge weights of all two-degree meta path instances of type P  X  T  X  P between p i and read as 3 term ref count which is the number of distinct three-degree meta path instances of type P  X  T  X  P ref  X  X  X  P . Feature 74 is read as 4 term cite min , which is the minimum weight of all edges of all four-degree meta path instances of type P  X  X  X  P cite  X  T  X  P cite  X  X  X  P .
 5.1 Benchmark We formulated LBD as a multi-class classification problem and evaluated the performance of HBIN meta path features in predicting co-citation links between disconnected research areas. Our goal is to replicate Swanson X  X  DFO-RS hypoth-esis [ 5 ]. We emphasize that many previous LBD methods have used this hypoth-is a vector of features and a class label. There are three classes: inter-cluster co-citation link (+1), within-cluster co-citation link (-1), and no link (0). The performance of our model was evaluated in two ways. First, we evaluated the ability of HBIN meta path features to accurately classify instances of all three classes. Secondly, and more importantly, we evaluated their ability to predict future inter-cluster co-citation links between FO and RS papers (i.e. class +1). The actual co-citation links formed between FO and RS papers following Swan-son X  X  discovery was used as the evaluation ground truth.
 existing document similarity measures: LDA topic model [ 18 ], term frequency-inverse document frequency (TF-IDF) [ 19 ]and bibliographic coupling (BC) [ 20 ]. Similarity algorithms underpinned many existing LBD methods [ 2 ] because it is commonly assumed that highly similar documents or terms tend to form associ-ations. We used Mallet X  X  implementation of LDA 4 to discover topics in title and abstract text of core papers (10, 30, 50, and 100 topics) and computed the cosine similarity between their topic probability distribution to give us 8 LDA-based features. We also computed the cosine similarity between TF-IDF vectors of terms in core papers X  titles and abstracts, obtaining 2 TF-IDF features. Finally, using Sci 2 To ol 5 , we calculated the bibliographic coupling strength between core papers through simple coupling count and cosine similarity, giving us 2 features. 5.2 Experimental Setup First, we retrieved bibliographic records of fish oil and Raynaud X  X  syndrome papers from Thomson Reuter X  X  Web of Science (WoS) 6 . Each record includes a paper X  X  title, author(s), publication venue, cited references, and citing articles. To be consistent with [ 5 ], we used the same search keywords originally used by Swanson and restricted the query results to year 1900 to 1985 prior to his discovery (Figure 1 ). We filtered the query results to obtain only records that had abstracts. We obtained 485 records (352 FO and 133 RS core papers). instances in our learning set. Using HBIN matrices constructed in Section 4.1 ,we indexed all distinct meta paths between all unique core paper pairs. To assign a class label to each instance, we retrieved another set of FO and RS records from WoS but this time included papers published in 1986 after Swanson X  X  discovery. We labeled an instance as class +1 if it consists of a pair of FO paper and RS papers that had no co-citation link before 1986 but which became co-cited in 1986. An instance is labeled as -1 if it consists of two papers in the same cluster that were obtained 210 instances of +1, 677 instances of -1, and 116,483 instances of 0. To obtain a balanced learning set, we randomly selected 210 instances from class -1, 210 instances from class 0, and kept all +1 instances. In total we had 630 instances and 99 features as the final learning set.
 We evaluated the performance of our model in predicting instances of the three classes using five classifiers implemented in Weka [ 17 ] (default parame-ter settings): the SMO-variant of Support Vector Machine (SVM), Neural Net-works (NN), Nave Bayes (NB), Bayesian Network (BN), and C4.5 Decision Tree (C4.5). We applied a 10-time repeated holdout validation at 70:30, 60:40, and 50:50 percent split as follows: 1. Randomize 630 instances in our learning set and select the first 70% of instances as the training set and the remaining 30% as the test set. Repeat this step ten times. 2. Repeat Step 1 for 60:40 and 50:50 split to obtain 30 training-test sets. 3. Apply each classifier on each training-test set and measure their performance in terms of Accuracy % and Weighted Average F-Measure (  X  4. Calculate each classifier X  X  average performance in all 30 training-test sets. In the following phase of our experiment, we also evaluated the performance of meta path features against LDA, TF-IDF and BC features using the three best performing classifiers previously learned. In particular, we analyzed their performance in predicting future co-citation links (+1) between FO and RS papers, which is the main goal of literature-based discovery. 5.3 Results Using InfoGain feature selection, we removed 5 meta path features that had zero contribution to the classification performance, leaving us with 94 features. BN , NN ,and SVM emerged as top performers. Due to page limitation, in this paper we only present results based on these three classifiers. Using 94 features, BN performed the best with the average accuracy ranging between 86.27% and 87.14% in classifying instances of the three classes at 70:30, 60:40, and 50:50 ten-time repeated holdout settings. It also achieved the highest mean weighted average F-Measure (in the range of 0.863 and 0.872).
 Subsequently we found that using HBIN meta path features alone could achieve up to 86.67% accuracy and 0.87 weighted average F-Measure in classi-fying instances of the three classes, outperforming LDA, TF-IDF, and Biblio-graphic Coupling (Table 2 ). We also analyzed the performance contributions of different meta path feature categories. The table also shows that 4-degree meta path features outperformed other lower degree meta path features in terms of Accuracy % and F-Measure for predicting instances of all classes. The results also show that, regardless of the number of path degrees, meta paths formed by the term-sharing between papers performed better than other types of meta paths. Table 3 shows that among all types of 4-degree meta path features, meta paths via term-sharing ( 4 term ref max and 4 term cite max ) led to the highest F-Measure (0.704). Similarly, in terms of accuracy, even though the 4-degree author-sharing features achieved the highest accuracy (71.40%), these were followed closely by the same term-sharing features (70.64% ). very well in predicting future inter-cluster co-citation links (+1) with 0.851 F-Measure ( precision : 0.845, recal l : 0.857). This performance is much better than BC (0.612 F-Measure), LDA (0.608 F-Measure), and TF-IDF (0.457 F-Measure). Figure 3 shows that HBIN meta path features gained the largest area under curve (AUC) compared to its competing algorithms. Lastly, consistent with our findings earlier, 4-degree meta path features and term-sharing meta path features also performed the best (F-Measure 0.798 and 0.812, respectively) in predicting instances of class +1 compared to other meta paths (last column of Table 2 ). Our results suggest that the rich relational features of HBIN meta paths could be used to discover latent connections between papers in disconnected research literatures better than the existing document similarity measures that rely only on homogeneous information (LDA, TF-IDF, BC). The higher performance of our 4-degree meta path features indicates that many hidden connections between core papers run through their  X  peripheral  X  papers, i.e.
 that it is useful for future LBD methods to incorporate citation information into their models. In addition, the high precision and recall achieved by HBIN meta path features also suggest that our method can mitigate the performance trade-off normally suffered by the exclusive use of lexical and citation analysis in LBD. Lexical analysis is known to suffer from low precision-high recal l , whereas ment may attributable to the combinations of lexical and citation information in HBIN meta path features. For example, the best performing meta path features in predicting class +1, 4 term ref max and 4 term cite max , are the mea-sures of lexical similarity (i.e. term-sharing) between core papers that propagate through the papers X  citation structures ( P ref and P cite conducted to verify this intuition. citation link prediction problem. Unlike the previous LBD methods, our method exploited the rich, semi-structured information in heterogeneous bibliographic information network. The performance of our HBIN meta path features was com-pared to well-established document similarity algorithms. Experimental results showed that meta path features outperformed the competing algorithms in pre-dicting future co-citation links between papers from fish oil and Raynaud X  X  syn-drome literature. Future work includes extending our method to other LBD cases, e.g. the discovery of novel alternatives to water purification [ 3 ].
