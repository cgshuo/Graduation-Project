 The last few years have seen significant interest in  X  X eep X  learning algorithms that learn layered, hierarchical representations of high-dimensional data. [1, 2, 3, 4]. Much of this work appears to have been motivated by the hierarchical organization of the cortex, and indeed authors frequently compare their algorithms X  output to the oriented simple cell receptive fields found in visual area V1. (E.g., [5, 6, 2]) Indeed, some of these models are often viewed as first attempts to elucidate what learning algorithm (if any) the cortex may be using to model natural image statistics. However, to our knowledge no serious attempt has been made to directly relate, such as through quantitative comparisons, the computations of these deep learning algorithms to areas deeper in the cortical hierarchy, such as to visual areas V2, V4, etc. In this paper, we develop a sparse variant of Hinton X  X  deep belief network algorithm, and measure the degree to which it faithfully mimics biological measurements of V2. Specifically, we take Ito &amp; Komatsu [7] X  X  characterization of V2 in terms of its responses to a large class of angled bar stimuli, and quantitatively measure the degree to which the deep belief network algorithm generates similar responses.
 Deep architectures attempt to learn hierarchical structure, and hold the promise of being able to first learn simple concepts, and then successfully build up more complex concepts by composing together the simpler ones. For example, Hinton et al. [1] proposed an algorithm based on learning individual layers of a hierarchical probabilistic graphical model from the bottom up. Bengio et al. [3] proposed a similarly greedy algorithm, one based on autoencoders. Ranzato et al. [2] developed an energy-based hierarchical algorithm, based on a sequence of sparsified autoencoders/decoders. In related work, several studies have compared models such as these, as well as non-hierarchical/non-deep learning algorithms, to the response properties of neurons in area V1. A study by van Hateren and van der Schaaf [8] showed that the filters learned by independent components analysis (ICA) [9] on natural image data match very well with the classical receptive fields of V1 simple cells. (Filters learned by sparse coding [10, 11] also similarly give responses similar to V1 simple cells.) Our work takes inspiration from the work of van Hateren and van der Schaaf, and represents a study that is done in a similar spirit, only extending the comparisons to a deeper area in the cortical hierarchy, namely visual area V2. 2.1 Features in early visual cortex: area V1 The selectivity of neurons for oriented bar stimuli in cortical area V1 has been well documented [12, 13]. The receptive field of simple cells in V1 are localized, oriented, bandpass filters that resemble gabor filters. Several authors have proposed models that have been either formally or informally shown to replicate the gabor-like properties of V1 simple cells. Many of these algorithms, such as [10, 9, 8, 6], compute a (approximately or exactly) sparse representation of the natural stimuli data. These results are consistent with the  X  X fficient coding hypothesis X  which posits that the goal of early visual processing is to encode visual information as efficiently as possible [14]. Some hierarchical extensions of these models [15, 6, 16] are able to learn features that are more complex than simple oriented bars. For example, hierarchical sparse models of natural images have accounted for complex cell receptive fields [17], topography [18, 6], colinearity and contour coding [19]. Other models, such as [20], have also been shown to give V1 complex cell-like properties. 2.2 Features in visual cortex area V2 It remains unknown to what extent the previously described algorithms can learn higher order fea-tures that are known to be encoded further down the ventral visual pathway. In addition, the response properties of neurons in cortical areas receiving projections from area V1 (e.g., area V2) are not nearly as well documented. It is uncertain what type of stimuli cause V2 neurons to respond opti-mally [21]. One V2 study by [22] reported that the receptive fields in this area were similar to those in the neighboring areas V1 and V4. The authors interpreted their findings as suggestive that area V2 may serve as a place where different channels of visual information are integrated. However, quantitative accounts of responses in area V2 are few in number. In the literature, we identified two sets of quantitative data that give us a good starting point for making measurements to determine whether our algorithms may be computing similar functions as area V2.
 In one of these studies, Ito and Komatsu [7] investigated how V2 neurons responded to angular stim-uli. They summarized each neuron X  X  response with a two-dimensional visualization of the stimuli set called an angle profile. By making several axial measurements within the profile, the authors were able to compute various statistics about each neuron X  X  selectivity for angle width, angle ori-entation, and for each separate line component of the angle (see Figure 1). Approximately 80% of the neurons responded to specific angle stimuli. They found neurons that were selective for only one line component of its peak angle as well as neurons selective for both line components. These neurons yielded angle profiles resembling those of Cell 2 and Cell 5 in Figure 1, respectively. In addition, several neurons exhibited a high amount of selectivity for its peak angle producing angle profiles like that of Cell 1 in Figure 1. No neurons were found that had more elongation in a di-agonal axis than in the horizontal or vertical axes, indicating that neurons in V2 were not selective for angle width or orientation. Therefore, an important conclusion made from [7] was that a V2 neuron X  X  response to an angle stimulus is highly dependent on its responses to each individual line component of the angle. While the dependence was often observed to be simply additive, as was the case with neurons yielding profiles like those of Cells 1 and 2 in Figure 1(right), this was not always the case. 29 neurons had very small peak response areas and yielded profiles like that of Cell 1 in Figure 1(right), thus indicating a highly specific tuning to an angle stimulus. While the former responses suggest a simple linear computation of V1 neural responses, the latter responses suggest a nonlinear computation [21]. The analysis methods adopted in [7] are very useful in characterizing the response properties, and we use these methods to evaluate our own model.
 Another study by Hegde and Van Essen [23] studied the responses of a population of V2 neurons to complex contour and grating stimuli. They found several V2 neurons responding maximally for angles, and the distribution of peak angles for these neurons is consistent with that found by [7]. In addition, several V2 neurons responded maximally for shapes such as intersections, tri-stars, five-point stars, circles, and arcs of varying length. Hinton et al. [1] proposed an algorithm for learning deep belief networks, by treating each layer as a restricted Boltzmann machine (RBM) and greedily training the network one layer at a time from the bottom up [24, 1]. In general, however, RBMs tend to learn distributed, non-sparse representations. Based on results from other methods (e.g., sparse coding [10, 11], ICA [9], heavy-tailed models [6], and energy based models [2]), sparseness seems to play a key role in learning gabor-like filters. Therefore, we modify Hinton et al. X  X  learning algorithm to enable deep belief nets to learn sparse representations. 3.1 Sparse restricted Boltzmann machines We begin by describing the restricted Boltzmann machine (RBM), and present a modified version of it. An RBM has a set of hidden units h , a set of visible units v , and symmetric connections weights between these two layers represented by a weight matrix W . Suppose that we want to model k dimensional real-valued data using an undirected graphical model with n binary hidden units. The negative log probability of any state in the RBM is given by the following energy function: 1 Here,  X  is a parameter, h j are hidden unit variables, v i are visible unit variables. Informally, the maximum likelihood parameter estimation problem corresponds to learning w ij , c i and b j so as to minimize the energy of states drawn from the data distribution, and raise the energy of states that are improbable given the data.
 Under this model, we can easily compute the conditional probability distributions. Holding either h or v fixed, we can sample from the other as follows: Here, N (  X  ) is the gaussian density, and logistic (  X  ) is the logistic function. For training the parameters of the model, the objective is to maximize the log-likelihood of the data. We also want hidden unit activations to be sparse; thus, we add a regularization term that penalizes a deviation of the expected activation of the hidden units from a (low) fixed level p . 2 Thus, given a minimize { w where E [  X  ] is the conditional expectation given the data,  X  is a regularization constant, and p is a constant controlling the sparseness of the hidden units h j . Thus, our objective is the sum of a log-likelihood term and a regularization term. In principle, we can apply gradient descent to this problem; however, computing the gradient of the log-likelihood term is expensive. Fortunately, the contrastive divergence learning algorithm gives an efficient approximation to the gradient of the log-likelihood [25]. Building upon this, on each iteration we can apply the contrastive divergence update rule, followed by one step of gradient descent using the gradient of the regularization term. 3 The details of our procedure are summarized in Algorithm 1.
 Algorithm 1 Sparse RBM learning algorithm 1. Update the parameters using contrastive divergence learning rule. More specifically, where  X  is a learning rate, and  X  X  X  recon is an expectation over the reconstruction data, estimated using one iteration of Gibbs sampling (as in Equations 2,3). 2. Update the parameters using the gradient of the regularization term. 3. Repeat Steps 1 and 2 until convergence. 3.2 Learning deep networks using sparse RBM values given the data are inferred. These inferred values serve as the  X  X ata X  used to train the next higher layer in the network. Hinton et al. [1] showed that by repeatedly applying such a procedure, one can learn a multilayered deep belief network. In some cases, this iterative  X  X reedy X  algorithm can further be shown to be optimizing a variational bound on the data likelihood, if each layer has at least as many units as the layer below (although in practice this is not necessary to arrive at a desirable solution; see [1] for a detailed discussion). In our experiments using natural images, we learn a network with two hidden layers, with each layer learned using the sparse RBM algorithm described in Section 3.1. 4.1 Learning  X  X trokes X  from handwritten digits We applied the sparse RBM algorithm to the MNIST handwritten digit dataset. 4 We learned a sparse RBM with 69 visible units and 200 hidden units. The learned bases are shown in Figure 2. (Each basis corresponds to one column of the weight matrix W left-multiplied by the unwhitening matrix.) Many bases found by the al-gorithm roughly represent different  X  X trokes X  of which handwritten digits are comprised. This is consistent Figure 3: 400 first layer bases learned from the van Hateren natural image dataset, using our algorithm. with results obtained by applying different algorithms to learn sparse representations of this data set (e.g., [2, 5]). 4.2 Learning from natural images We also applied the algorithm to a training set a set of 14-by-14 natural image patches, taken from a dataset compiled by van Hateren. 5 We learned a sparse RBM model with 196 visible units and 400 hidden units. The learned bases are shown in Figure 3; they are oriented, gabor-like bases and resemble the receptive fields of V1 simple cells. 6 4.3 Learning a two-layer model of natural images using sparse RBMs We further learned a two-layer network by stacking one sparse RBM on top of another (see Sec-tion 3.2 for details.) 7 After learning, the second layer weights were quite sparse X  X ost of the weights were very small, and only a few were either highly positive or highly negative. Positive weights represent excitatory connections between model V1 and model V2 units, whereas negative elements represent inhibitory connections. By visualizing the second layer bases as shown in Fig-ure 4, we observed bases that encoded co-linear first layer bases as well as edge junctions. This shows that by extending the sparse RBM to two layers and using greedy learning, the model is able to learn bases that encode contours, angles, and junctions of edges. We now more quantitatively compare the algorithm X  X  learned responses to biological measure-ments. 8 5.1 Method: Ito-Komatsu paper protocol We now describe the procedure we used to compare our model with the experimental data in [7]. We generated a stimulus set consisting of the same set of angles (pairs of edges) as [7]. To identify the  X  X enter X  of each model neuron X  X  receptive field, we translate all stimuli densely over the 14x14 input image patch, and identify the position at which the maximum response is elicited. All measures are then taken with all angle stimuli centered at this position. 9 Using these stimuli, we compute the hidden unit probabilities from our model V1 and V2 neurons. In other words, for each stimulus we compute the first hidden layer activation probabilities, then feed this probability as data to the second hidden layer and compute the activation probabilities again in the same manner. Following a protocol similar to [7], we also eliminate from consideration the model neurons that do not respond strongly to corners and edges. 10 Some representative results are shown in Figure 5. (The four angle profiles shown are fairly typical of those obtained in our experiments.) We see that all the V2 bases in Figure 5 have maximal response when its strongest V1-basis components are aligned with the stimulus. Thus, some of these bases do indeed seem to encode edge junctions or crossings.
 We also compute similar summary statistics as [7] (described in Figure 1(C,D,E)), that more quanti-tatively measure the distribution of V2 or model V2 responses to the different angle stimuli. Figure 6 plots the responses of our model, together with V2 data taken from [7]. Along many dimensions, the results from our model match that from the Macaque V2 fairly well. 5.2 Complex shaped model V2 neurons Our second experiment represents a comparison to a subset of the results described in Hegde and van Essen [23]. We generated a stimulus set comprising some [23] X  X  complex shaped stimuli: angles, single bars, tri-stars (three line segments that meet at a point), and arcs/circles, and measured the response of the second layer of our sparse RBM model to these stimuli. 11 We observe that many V2 bases are activated mainly by one of these different stimulus classes. For example, some model V2 neurons activate maximally to single bars; some maximally activate to (acute or obtuse) angles; and others to tri-stars (see Figure 7). Further, the number of V2 bases that are maximally activated by acute angles is significantly larger than the number of obtuse angles, and the number of V2 bases that respond maximally to the tri-stars was much smaller than both preceding cases. This is also consistent with the results described in [23]. We presented a sparse variant of the deep belief network model. When trained on natural images, this model learns local, oriented, edge filters in the first layer. More interestingly, the second layer captures a variety of both colinear ( X  X ontour X ) features as well as corners and junctions, that in a quantitative comparison to measurements of V2 taken by Ito &amp; Komatsu, appeared to give responses that were similar along several dimensions. This by no means indicates that the cortex is a sparse RBM, but perhaps is more suggestive of contours, corners and junctions being fundamental to the statistics of natural images. 12 Nonetheless, we believe that these results also suggest that sparse deep learning algorithms, such as our sparse variant of deep belief nets, hold promise for modeling higher-order features such as might be computed in the ventral visual pathway in the cortex. Acknowledgments We give warm thanks to Minami Ito, Geoffrey Hinton, Chris Williams, Rajat Raina, Narut Sereewat-tanawoot, and Austin Shoemaker for helpful discussions. Support from the Office of Naval Research under MURI N000140710747 is gratefully acknowledged.

