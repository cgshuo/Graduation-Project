 getting worse along with the increase of users.. could judge what users like and what they don X  X  like. 
Inspired by this opinion, we assume that in recommendation system, it is necessary passive feedbacks. experimental results in Section 5 and finally conclude the paper in Section 6. ers-based[7] and item-based[8] algorithms are common memory-based methods. Dif-of each user is dependent on the feature vector of his direct neighbors. model by distinguishing the positive feedbacks and passive feedbacks. 3.1 Session Definition exceed this threshold, they should be seem to be in two different sessions. comment, we assume these microblogs can provide passive feedbacks which are use-ful to indicate what users don X  X  like. what users have read during each session. This method is shown in figure 1: 
Through the above method, we identify what users could receive during each ses-contents they received during each session. 3.2 Feature-Based Matrix Factorization Matrix Factorization models have been popular in recommendation, Chen[3] propose a linear regression term: be described as follow: over fitting. 3.3 Inner Session Features make effort s on this problem, we choose some useful features as follows: 3.4 Session Contextual Features Leibler (KL) divergence. 
In this paper, we choose 4 time range to examine the topic similarity:  X  describe some momentary interests of users.  X  identify users X  new focusing interest.  X  without too much old data.  X  all: describe users X  all interests. sessions, each feature has a weight value expressed by their topic KL divergences. 4.1 Experimental Setting experimental subjects, the filter criteria are shown in Table 2: posts of them as the total experimental dataset. keep sessions which have at least one retweet activity. dataset. MAP, NDCG@n and MRR to evaluate our approach. We also perform a significance test using Wilconxon signed rank test (p&lt;0.05). 4.2 Methods Comparison Comparison among Overall Da ta and Restricted Data FSVD) to make comparison. results directly on these data. For FSVD, we choose 50 as the latent factor dimensionality. provements on FSVD (p &lt; 0.05 using Wilconxon test). tent factors. However, rFSVD can significantly outperform ItemCF and FSVD in all metrics, such as being up to 1.59 times on MAP and 2.56 times on MRR over FSVD. recommendation. Comparison among Different Methods and choose positions at 5, 10, 20, 50. 
Table 4 shows the exact l nificant improvements on provements on rRankSVM .
 From Figure 2 and Ta b RankSVM in all P@n an d good results on global ma y forms better than rRankS V factors in rFSVD model. 
In addition, when rRan k passive feedbacks and sam e set, which means its trainin g by contrast, rRankSVM is the results shown in Tabl e RankSVM, which make 33 The main reason for this e passive feedbacks which c o microblogs of the global p a read them to make a choice , In this paper, we propose using users X  passive feedb a predict users X  preference and improve recommendation performance, and ing methods to train our model, including list-wise methods. 
