 fangfei562@126.com ,geshili@gdufs.edu.cn,songrou@126.com The past 60 years has witnessed great progr ess in machine translation. Nowadays, language texts, which has become the necessary function of word processing systems and information retrieval systems. However, as for t he need of intensive reading, there still exist many problems in automatic machine translation, especially in the translation of long sentences.

In the field of machine translation, there are two widely -used evaluation methods: manual evaluation and object ive evaluation (also known as automatic evaluation). According to Koehn [1] , the former is a method that evaluates outputs of machine translation systems by subjective judgments; the latter evaluates MT output s automat-ically according to a certain mathemat ical model. Nei ther of them can show the source of MT errors, not to mention the improve ment of long sentence translation .
According to Zhao et al [2] , translation errors can be divided into 7 types: 1) incor-rect words , 2) missing content words , 3) wrong w ord order , 4) translation with mean-ing contrary to the original , 5) errors of named entity , 6) errors of numerals and quan-tifiers/temporal words and 7) other errors. That paper comes to the conclusion that the first 3 types, especially incorrect words and wrong word order, account s for the larg-est proportion. This analysis is correct, but it d oes not explain the objective phenome-non that MT has a poorer performance in long -sentence translation than in short -provid es no direct benefit for the quality improvement of long sentence machine translation.

The paper explores the results of English -Chinese machine translation, categorizing and component omissions. Examples are employed to illustrate the significant influ-sentences on the performanc e of machine translation and to suggest the possibility expected to offer some inspirations for breaking through the bottleneck of automatic long sentence translation. As for the categories in machine translation errors, our ideas are as follows:
The aim of translation is to keep the semantic consistency between the source text correctness o f forms of semantic structures, including errors like additions, omissions, mistaken usages, wrong types of semantic structures and wrong word choices in leaf nodes of semantic structures. Giving that additions rarely occur, we can categorize translation e rrors into 3 types: omissions of semantic structures (component omis-word choice (incorrect lexical choices). 
The semantic structure mentioned in this paper is in view of a higher and more ab-stract level, which includes the referential component plus its statement (subject -certain structure are transposed, it will be classified into err ors of structural type, nam-also other errors. For example, some construction should be translated into attribute -head construction but the MT output is a structure of adverbial -head, or there is con-fusion of logical arguments on whether they are the referential or the statement on the two sides of coordinate conjunctions, etc. In this paper, c omponent omissions are lexical choices are mostly incorrect words proposed by Zhao et al [2] . Yet, if preposi-tions, conjunctions, or any verbs are omitted or mistranslated, causing structural er-rors, they are classified into errors of structural types. As for the rest 4 types proposed by Zhao et al [2] , they can also be classified into the 3 types mentioned above .
To illustrate semantic structure more clearly, we offer the f ollowing example of semantic structure in the form of a semantic tree. Original English text : (It) announced new advertising rates for 1990 and said The MT output :  X  X  X  X  X  X  X  X  X  X  X  X  1990  X  The revised translation :  X  X  X  1990  X  X  X  X  X  X  X  X  X  X  X  X  X  The comparison of semantic structur es:
In F ig. 1, the last line is Chinese MT output; the line above it is the manually re-vised translation based on the MT output. From F ig. 1, we can see that  X 1990 X  should be translated into  X 1990  X   X . So , it is an incorrect lexical choice which is annotated by underlined words. Besides,  X 1990  X   X  is the modifier of  X   X  X  X  X  X  X  X  X  X   X , but  X 1990 X  is placed after  X   X  X  X  X  X  X  X  X  X   X  in the MT output , unable to show its modifier -object tree.  X  X nd X , here showing the coordination of two predicate components, should be translated into  X   X   X , not  X   X   X  whic h shows the coordination of referential compo-marked with an underline and an ellipse respectively.  X  X aid X  should be translated into  X   X   X , which does not occur in the MT output. This kind of error , i.e., component omission, is marked with dots. Song and Ge [3] define an NT clause as the structure consisting of a naming and a modification component of the naming. In English language there are 8 specific rela-tionship s between a naming and its telling: subject and predicate, the referential com-phrases, present participial phrase, infinitive phrase, adjective phrases, declarative prepositional phrases and the explanatory noun phrases. 
Example 1: Documents filed with the Securities and Exchange Commission on the pending sp inoff disclosed that Cray Research Inc. will withdraw the almost $ 100 million in financing it is providing the new firm if Mr. Cray leaves or if the product -design project he heads is scrapped.

For the sake of visual cognition, we represent the relation b etween naming and tell-ing in an English sentence with specific method called newline -indented schema by telling part in a new line and indent it after its naming part.

In Fig. 2 , the first line and the eighth line except the conjunction  X  X r X  and  X  if  X  are referential component s , i.e. naming, annotated with NNM; the fifth and seventh lines but lacking the object, so typed PRD -;  X  X ocuments X  in the first line acts as the nam-ing of these three tellings, so they are indented to its right end in the new lines. The sixth line is a relative clause, and its antecedent is  X  X he almost $100 million in financ-ing X  in the fifth line and is the direct object of the relative clause, which is suggested by the WO1 in the sixth line. The sixth line is indented to the right end of its anteced-ent and a vertical bar is used to mark the left end of the antecedent, signaling the be-from the above explanation. A pair of black square brackets is employed to mark the object clause ranging from the fifth line to the tenth line, which belongs to the fourth line. 
In Fig. 2 , each naming is placed on the upper -left side of its telling, thus sequences These NT clauses are numbered according to the line number of their tellings. 2. Documents+filed with the Securities and Exchange Commission //ED 3. Documents+on the pending spinoff //PP 4. Documents+disclosed that //PRD -5. Cray Research Inc. will withdraw the almost $ 100 million in financing //SV 6. the almost $ 100 million in financing +it is providing the new firm //WO1 7. if Mr. Cray leaves //SV 9. the product -design project+ he heads //WO 10. or if the p roduct -design project+ is scrapped.//PRD NT clauses can be used for the basic structure of categorizing translation errors. called SV clause s , while the other one is non -adjacent subject -predicate structures or we distinguish these two types is the different difficulty level s they occur in machine of clauses and the subject and predicate are adjacent, which can be handled effective-ly by either rule method or s tatistical method; however, the latter does not accord with the syntax of normal English clauses, and non -adjacent subject -predicate structures or be confronted with great difficulty. 
By using the newline -indented schema, we have annotated NT -clause structure for several thousands of English sentences from the Wall Street Journal in Penn Treebank and have a more detailed test on 253 English sentences among them. Two ways ar e adopted for machine translation in the paper. One is that w e input these whole English sentences into Baidu Translate , a popular machine translation engine in China, and amend the MT output s manually . Then, through comparing the MT output s with the manua lly amended texts , we classify and tag the errors in MT output s. The other way are then t ranslated separately. The errors are tagged according to three types we men-rors and non -SV -structure errors. E xamples will be given in section 3 to illustrate the specific procedure of these two ways. In section 4, we categorize and compare errors occurring in MT output s which are obtained through these two different ways. Section 5 will list conclusions drawn fro m the comparison . Example 2: Newsweek, trying to keep pace with rival Time magazine, announced new advertising rates for 1990 and said it will introduce a new incentive plan for advertis-ers.

The ali gnment of the translated Chinese word sequences and the original English text are as follows: MT output and revised translation are as follows: choices are still underlined under the words; component omissions are marked with dots on corresponding MT output texts. 
There are errors in 3 phrases of the MT output : (1)  X 1900 X  should be translated into  X 1990  X  (year) X . Numerals can be functioned as dates or years in English without any addition, but in Chinese, these characters  X   X  (date),  X  (month) and  X  (year) X  should be added after the numerals. So it belong s to incorrect lexical choices . Besides,  X 1990  X  (for 1990) X  is the modifier of  X   X  X  X  X  X  X   X  X  X  (new advertising rates) X , but  X 1990 X  is placed after  X   X  X  X  X  X  X  X  X  X   X  in the MT output , which is ungrammatical Chinese structure. (2)  X  X nd said X  should be translated into  X   X  X   X , b ut the machine translates it into  X   X  (and) X . Even though  X  X nd X  has two corresponding meanings of  X   X   X  and  X   X   X  in Chinese,  X   X   X  is used for the coordination of the referential components while  X   X   X  signifies for the coordination of statements. Here the context contains two statements, thus  X  X nd X  should be translated into  X   X   X . This point belongs to incorrect lexical choices . Besides, it also belongs to errors of structural type. Furthermore, the meaning of  X  X aid X  is omitted in the Chinese text, so this belongs t o component omission. (3)  X  X or advertisers X  should be translated into  X   X  X  X  X  X  X   X , but the machine trans-lates it into  X   X  X  X   X , which signals the omission of beneficiary argument  X   X  (for) X .  X   X  X  X  X  (advertisers) X  is translated into  X   X  X  X  (advertisement) X , which belongs to incorrect lexical choices . Besides  X   X  X  X  X  X  X  (for advertiser) X  is an adverbial and should be placed before its modified predicate  X   X  X  X  X  X  X  X  X  X  X  X  (announced a new incentive plan) X . The post -position of the adverbial  X   X  X  X   X  makes the translated text hard to understand. So this also belongs to structural errors.

To sum up, we can make a calculation that there are 3 structural errors, 3 incorrect lexical choices and 2 component omissions. In order to analyze the causes for these errors, we parse the original sentence into NT clauses by showing with a newline -indented schema as follows, and original words of errors in the MT output are underlined , where the different line types will be explained soon :
In Fig. 5 , the third line and the fourth line where errors occur are both predicates of the first line. These two lines are also tellings of the first line. The difficulty of trans-lation increases because of the two pairs of subjects and predicates being non -adjacent. Besides, the conjunction  X  X nd X  before the predicate of the fourth line also increase the difficulty of machine translation. The fifth line is a NT clause of subject -predicate type and is not long, but is placed at the end of the whole sentence without Therefore, there is no surprise that err ors occur in this simple clause. 
The above analysis of reasons for translation errors enlightens us to think that if we parse long English sentences into NT -clause sequences, errors in machine translation into 4 NT clauses and make simple mechanical changes to let every NT clauses be grammatically correct clauses with a subject -predicate structure. Then we input these NT clauses into machine translation system, and the resu lts are as follows: (1)
The NT clauses:  X  Newsweek  X  (trying|tries) to  X  keep pace  X  with  X  rival  X  Time magazine
Note:  X (trying|tries) X  means shifting the present participle trying into finite verb tries .
 The MT output :  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  ...  X  X  X  X  X  X  X  T he revised translation :  X  X  X  X  X  X  X   X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X 
Analysis of errors:  X   X  X  X  X  X  X  X   X  is omitted in the sentence. (2) The N T clauses:  X  Newsweek  X  announced  X  new  X  advertising rates  X  for 1990 The MT output :  X  X  X  X  X  X  X   X  X  X  X   X  X  X  X   X  X  X  X  X  X  X   X  X  X  1990 The revised translatio n :  X  X  X  X  X  X  X   X  X  X  X   X  1990  X  X  X  X  X  X   X  X  X  X  X  X  X 
Analysis of errors: there still occurs an incorrect lexical choice and a structural er-ror  X  X or 1990 X . (3) The NT clauses:  X  Newsweek (and)  X  12 said
Note: (and) means temporarily deleting the conjunction and between the naming and the telling before translation.
 The MT output :  X  X  X  X  X  X  X   X  12  X 
No error. (4) tisers No error.

Total errors: 1 structural error, 1 incorrect lexical choice and 1 component omis-sions.
 Compared with errors in the MT output of the original whole sentence, the errors in MT output of NT clauses are with 2 structural errors , 2 incorrect lexical choices and 1 component omission less.

In order to show the comparison between the two results, in the above newline -indented schema, namely, in Fig. 4, we underline words and phrases where errors occur in MT output of the original whole sentence with bold underlines while wave lines are used to mark words and phrases where errors occur in MT output of NT clauses, and bold wave lines to mark words and phrases where errors occur in MT output s of both ways. 
Example 3: About 160 wor kers at a factory that made paper for the Kent filters were exposed to asbestos in the 1950s .

The alignment of the translated Chinese word sequences and the original English text as follows : MT output and revised translation are as follows: Errors in MT output are as follows :
All errors occur in the relative clause  X  X hat made paper for t he Kent filter X . The verb -object structure  X  X ade paper X  is translated into a modifier -head structure  X   X  X   X  X  X  X  X  X  X   X  in Chinese. So the above error belongs to structural errors .  X  X or the Kent filter X  is translated into  X   X  X  X  X  X   X   X . First of all, the preposition  X  X or X  is omitted; then, the prepositional phrase  X   X  X  X  X  X  X  X   X  (for the Kent filter) X  functioning as adverbial should be placed before the verb phrase  X   X  X  X  (made paper) X . This error belongs to structural errors.
 To sum up, there are 2 structural errors and 1 compon ent omission in MT output. The newline -indented schema of example 3 are as follows: because th e relative clause of  X  X  factory X  is inserted into the middle of the subject and chine t ranslation. We parse the whole sentence into 2 NT clauses, make simple me-chanical changes that make them into normal subject -predicate clause and input them into the machine translation system separately . Results are as follows: (1) 
The NT clause: 1950s
The MT output:  X  14  X   X  15 20  X  X  X  50  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  160  X  X  X  X  X  X   X  12  X  X  X  X   X  13  X  X  X  X  (2) The NT clause:  X  the  X  factory (that)  X  made paper  X  for  X  the Kent  X  11 filters
Note: ( that ) means temporally deleting the relative pronoun that between the naming and the telling.
 The MT output :  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X   X  11  X  X  X  X  X  X  X  X  X  X  X  Both of these two clauses have no error s .

Compared with the MT output of the original sentence, according to Fig. 7, we can see there is a reduction of 2 structural errors and 1 component omission.

Example 4: The survival of spinoff Cray Computer Corp. as a fledgling in th e su-percomputer business appears to depend heavily on the creativity  X  and longevity  X  of its chairman and chief designer.

The alignment of the translated Chinese word sequences and the original English text is as follows: MT output and rev ised translation are as follows:
Errors in MT output are as follows: (1)  X  X pinoff Cray Computer Corp. X  should be translated into a modifier -head struc-ture  X   X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X   X  in Chinese, but here it is translated into a verb -object structure  X   X  X  X  X  X  X  X  X  X  X  X  X  X   X , which belongs to structural errors. (2) it is correct to translate  X  the survival X  into  X   X  X  X   X , but as the head noun, in Chinese it should be placed after its attribute  X   X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X   X . It is placed before its attribute in the MT output, so it is a structural error. (3)  X  X s a fledgling in the supercomputer business X  is the post -modifier of  X  X pino ff Cray Computer Corp. X . It is acceptable to translate  X  X s a fledgling in the supercom-puter business X  into an adverbial -verb structure  X   X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X   X  as a statement of  X  X pinoff Cray Computer Corp. X , but in MT output, the addition of  X   X   X  in Chinese makes t he adverbial -verb structure shift into a modifier -head structure. It is a structural error. (4)  X  X f its chairman and chief designer X  is the attribute of the head noun  X  X he crea-tivity --and longevity  X   X , so when translated into Chinese, it should be placed before its head noun. It is a structural error. (5)  X  X ppear X  has two meanings:  X   X  X  X   X  and  X   X  X  X   X  in C hinese, but according to the context, it should be translated into  X   X  X  X   X , while  X   X  X  X   X  in MT output, so it is an incorrect lexical choice.

From the above analysis, there are 4 structural errors and 1 incorrect lexical choice in the MT output.
 The newline -inde nted schema of example 4 are as follows :
In Fig. 11, errors occur in the naming of the first line and the telling of the second clauses and inputted into machine translation system. (1)
The NT clause:  X  spinoff  X  Cray Compu ter Corp. [ is ]  X  as  X  a  X  fledgling  X  in  X  the supercomputer business Note: [ is ] is added to make the sentence accord with grammatical rules.

The MT output:  X  X  X  X   X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X   X  X  X  X  X  X  X 
The revised translation:  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X   X  X  X  X  X  X  X  X 
Analy sis of errors: there is still 1 structural error. (2)
The NT clause:  X  The survival  X  of  X  spinoff  X  Cray Computer Corp  X  appears to  X  11 depend  X  12 heav-designer
The MT output:  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X   X  12  X  X  X  X  X  X  X   X  11  X  X  X   X  13  X   X  14  X  X   X   X 
The revised translation  X   X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X   X  12  X  X  X  X  X  X  X   X  11  X  X  X   X  13  X  Analysis of errors: there is still 1 structural error and component omission .
Compared with the original result of MT out put, there is a reduction of 2 structural errors and 1 incorrect lexical choice . The compared results show that making the sub-ject and the predicate adjacent can strengthen the bondage of their meanings, thus the parsing of NT clauses also can help elimina te incorrect lexical choices . 4.1 Analysis of Error Types We use the method described above to carry on manual evaluation in English -Chinese machine translation. So far, 243 English sentences have been manually evaluated, including 6232 English word tokens in 68 2 NT clauses. Total amount of errors in MT output s is 606 in whole sentence translation . According to our categorization, the proportion of error types in MT output among the 243 English sentences is presented in the pie chart below .
 type. The structural error accounts for 4 7 %, in which the proportions of SV -structure choices take up 37%, and component omissions 16%. Then we ca n see that structural errors nearly takes up about a half of all errors, in which non -SV -structure errors are more than SV -structure errors obviously.
 structure errors among SV clauses and non -SV clauses. According to data in table 1, non -SV -structure errors are 1.39 times as many as SV -structure errors. The causes for very large number; secondly, a more important cause is that structural errors in each non -SV clause are greatly more than those in each SV clause, with the ratio of 1.33: 1. Therefore, we can co nclude that non -SV clauses are main source of errors. T ype of clause N umber of clauses N umber of struc-tural errors Non -SV c lause 345 166 0.48
N on -SV/SV 1.02 1.39 1.33 4.2 Comparison between Whole Sentence Translation and NT Clause When parsing the English sentences which have errors in the MT output of whole sentence translation, into NT clauses and then inputting them into Baidu Translate, we obtain the result of MT output of these NT clauses and the distribution of errors. The tab le 2 is a comparative result of errors before and after parsing. 
According to the data in table 2 , structural errors and component omission decline by about one half, and incorrect lexical choices decline by 10%. The total reduction is mai ntain that there are two causes for the reduction. Firstly, when English sentences together, which can strengthen syntactic and semantic constraint, thus largely elimi-nat ing ambiguity of phrases; secondly, that sentences are shortened after parsing also helps reduce incorrect lexical choices and omissions. 4.3 Correlation between the NT Clause Number in a Sentence and the Error Based on preliminary observation of machine translated results, we predict that ma-chine translation has a better performance in short sentences than in long sentences. In order to verify this predication, we analyze data of the number of NT clauses in Eng-line chart shows the relationship between these two variables.

In Fig. 13, the horizontal axis represents the number s of NT clauses in sentences and numbers in brackets represent the total amount of sentences which contain each number of errors. So the line in the figure represents the co rrelation between the num-positive correlation between these two variables when the number of NT clauses ranges from 1 to 5 in sentences, which is consistent with our predicat ion. with our previous predication. As to causes for this phenomena, we think that com-pare d with sentences containing 1 -5 NT clauses, the number of sentences with 6 -7 NT need further studies . Chinese machine translation, and conclusions are made as follows.

Firstly, the majority of errors in machine translation is structural errors. These structural errors mainly exist in non -SV clauses including non -adjacent subject -pre dicate structures and adjacent or non -adjacent non -subject -predicate structures.
Secondly, as non -SV structures exist largely in long English sentences, so the above conclusion reveals the cause for the bottleneck of English long -sentence trans-lation. Furthermore, the conclusion above suggest s that English long sentences should be parsed into NT clauses before being translated. The suggested model has been paper support t he suggestion. Definitely parsing long sentences of English will bring also bring loss. These losses are not discussed in the paper. However, firstly parsing and assembling are tasks made in monolingual category, so their difficulties are ap-parently lower than tasks made in bilingual category; secondly, as NT clauses are generally simple and short and if units in training corpus are all NT clauses, the quali-worthy of further exploration. 
Thirdly, the relationship between naming and telling, based on cognitive structures, is common to human language. All languages may be parsed into sequence s of NT adopted in this paper is language -independent. However, naming and telling are rep-ships have been summarized in this paper, which are based on features of English syntax. Therefore, this classification is language -dependent. The author s will give detailed discussion of this point in the future. 
Lastly, translation of NT clauses are generally (not absolutely) independent of each other , because NT clauses are complete cognitive structures with self -sufficient mean-i ng. Natural language is context dependent . For present computer processing power, it is difficult to analyze and translate long English sentences correctly in one shot. Long sentences can usually be parsed into several segments and the parsing method based on structures of NT clauses advocated in this paper is appropriate. Detailed infor-mation can be found in Song &amp; Ge [3] .
 Ac knowledgements. This research is supported by the 2016 Key Project of t he Na-tional Languages Committee ( ZDI135 -30 ) , Innovative School Project in Higher Edu-cation of Guangdong, China (GWTP -LH -2015 -10) , the Science and Technology Pro-ject of Guangdong Province, China ( 2016A040403113 ), National Natural Science Foundation of China (61171129) and the fund of Center for Translation Studies, Guangdong University of Foreign Studies (CTS2014 -13) .

