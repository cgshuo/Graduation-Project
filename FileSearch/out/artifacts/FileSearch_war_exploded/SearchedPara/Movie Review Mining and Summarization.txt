 With the flourish of the Web, online review is becoming a more and more useful and important information resource for people. As a result, automatic review mining and sum-marization has become a hot research topic recently. Differ-ent from traditional text summa rization, review mining and summarization aims at extracting the features on which the reviewers express their opinions and determining whether the opinions are positive or negative. In this paper, we fo-cus on a specific domain  X  movie review. A multi-knowledge based approach is proposed, which integrates WordNet, sta-tistical analysis and movie knowledge. The experimental results show the effectiveness of the proposed approach in movie review mining and summarization.
 I.2.7 [ Artificial Intelligence ]: Natural Language Process-ing X  text analysis ; H.2.8 [ Database Management ]: Database Application X  data mining Algorithms, Experimentation review mining, summarization
With the emerging and developing of Web2.0 that em-phasizes the participation of users, more and more Websites, such as Amazon (http://www.amazon.com) and IMDB (http:  X 
This work was done while the first author was visiting Mi-crosoft Research Asia. Li Zhuang and Xiao-Yan Zhu are also with State Key Laboratory of Intelligent Technology and Systems.
 Copyright 2006 ACM 1-59593-433-2/06/0011 ... $ 5.00. //www.imdb.com), encourage people post reviews for the information they are interested in. These reviews are useful for both information promulgators and readers. For exam-ple, from the online reviews of political news or announce-ments, the government can perceive the influence of recent policies or events on common people, and take proper and timely actions based on the information. Through product reviews, on the one hand, manufacturers can gather feed-backs from their customers to further improve their prod-ucts. On the other hand, people could objectively evaluate a product by viewing other people X  X  opinions, which will possi-bly influence their decisions on whether to buy the product. However, many reviews are lengthy with only few sentences expressing the author X  X  opinions. Therefore, it is hard for people to find or collect useful information they want. More-over, for each information unit to be reviewed, such as a product, there may be many reviews. If only few reviews are read, the opinion will be biased. As a result, automatic review mining and summarization has become a hot research topic recently.

Most of the existing work on review mining and summa-rization is focused on product reviews. In this paper, we will focus on another domain  X  movie review. Different from product reviews, movie reviews have the following unique characteristic. When a person writes a movie review, he probably comments not only movie elements (e.g. screen-play, vision effects, music), but also movie-related people (e.g. director, screenwriter, actor). While in product re-views, few people will care the issues like who has designed or manufactured a product. Therefore, the commented fea-tures in movie review are much richer than those in product review. As a result, movie review mining is more challenging than product review mining.

In this paper, we decompose the problem of review mining and summarization into the following subtasks: 1) identify-ing feature words and opinion words in a sentence; 2) deter-mining the class of feature word and the polarity of opin-ion word; 3) for each feature word, fist identifying the rele-vant opinion word(s), and then obtaining some valid feature-opinion pairs; 4) producing a summary using the discov-ered information. We propose a multi-knowledge based ap-proach to perform these tasks. First, WordNet, movie casts and labeled training data were used to generate a keyword list for finding features and opinions. Then grammatical rules between feature words and opinion words were applied to identify the valid feature-opinion pairs. Finally, we re-organized the sentences according to the extracted feature-opinion pairs to generate the summary. Experimental re-sults on the IMDB data set show the superiority of the pro-posed method over a well-known review mining algorithm [6].

The remainder of this paper is organized as follows. Sec-tion 2 describes some related work. Section 3 states the problem. Section 4 introduces the proposed approach. In Section 5, experimental results are provided and some typ-ical errors are analysis. Finally, the conclusion and future work are presented in Section 6.
Since review mining is a sub-topic of text sentiment anal-ysis, it is related with work of subjective classification and sentiment classification. In the following of this section, we will first introduce existing work on review mining and sum-marization. Then, we will present work on subjective clas-sification and sentiment classification and discuss their rela-tionship with review mining.
Different from traditional text summarization, review sum-marization aims at producin g a sentiment summary, which consists of sentences from a document that capture the au-thor X  X  opinion. The summary may be either a single para-graph as in [1] or a structured sentence list as in [6]. The former is produced by selecting some sentences or a whole paragraph in which the author expresses his or her opin-ion(s). The latter is generated by the auto-mined features that the author comments on. Our work is more relevant to the latter method.

Existing works on review mining and summarization mainly focused on product reviews. As the pioneer work, Hu and Liu proposed a method that uses word attributes, including occurrence frequency, part-of-speech and synset in WordNet [6]. First, the product feature s were extracted. Then, the features were combined with their nearest opinion words, which are from a generated and semantic orientation labeled list containing only adjectives. Finally, a summary was pro-duced by selecting and re-organizing the sentences accord-ing to the extracted features. To deal with the reviews in a special format, Liu et al expanded the opinion word list by adding some nouns [8]. Popescu and Etzioni proposed the OPINE system, which uses relaxation labeling for finding the semantic orientation of words [14]. In the Pulse system introduced by Gamon et al [4], a bootstrapping process was used to train a sentiment classifier. The features were ex-tracted by labeling sentence clusters according to their key terms.
The task of subjective classification is to distinguish sen-tences, paragraphs or documents that present opinions and evaluations from sentences that objectively present factual information. The earliest work was reported in [20], in which the author focused on finding high quality adjective features, using a method of word clustering. In 2003, Riloff et al in-vestigated subjective nouns learned from un-annotated data using bootstrapping process [15], and they used the same approach to learn patterns for subjective expressions [16]. Yu and Hatzivassiloglou presented several unsupervised sta-tistical techniques for detecting opinions at the sentence level, and then used the results with a Bayesian classifier to determine whether a document is subjective or not [22]. In 2005, Wiebe and Riloff developed an extraction pattern learner and a probabilistic subjectivity classifier using only un-annotated texts for training [21]. The performance of their approach rivaled that of previous supervised learning approaches.

The difference between subjective classification and re-view mining is two-folds. On the one hand, subjective clas-sification does not need to determine the semantic orien-tations of those subjective sentences. On the other hand, subjective classification does not need to find features on which opinions have been expressed. While review mining need not only find features, but also determine the semantic orientations of opinions.
The task of sentiment classification is to determine the se-mantic orientations of words, sentences or documents. Most of the early work on this topic used words as the process-ing unit. In 1997, Hatzivassiloglou and McKeown investi-gated the semantic orientations of adjectives [5] by utiliz-ing the linguistic constraints on the semantic orientations of adjectives in conjunctions. In 2002, Kamps and Marx proposed a WordNet (http://wordnet.princeton.edu) based approach [7], using semantic distance from a word to  X  X ood X  and  X  X ad X  in WordNet as the classification criterion. Tur-ney used pointwise mutual information (PMI) as the seman-tic distance between two words [18] so that the sentiment strength of a word can be measured easily. In [19], Turney et al further introduced the cosine distance in latent semantic analysis (LSA) space as the distance measure, which leads to better accuracy.

The earliest work of automatic sentiment classification at document level is [11]. The authors used several machine learning approaches with common text features to classify movie reviews from IMDB. In 2003, Dave et al designed a classifier based on information retrieval techniques for fea-ture extraction and scoring [3]. In 2004, Mullen and Collier integrated PMI values, Osgood semantic factors [10] and some syntactic relations into the features of SVM [9]. Pang and Lee proposed another machine learning method based on subjectivity detection and minimum-cut in graph [12]. In 2005, Pang and Lee further developed their work to deter-mine a reviewer X  X  evaluation with respect to a multi-point scale [13]. In [2], the authors compared two kinds of ap-proaches based on machine learning and semantic orienta-tion systematically.

Sentiment classification is not involved in finding concrete features that are commented on yet. Therefore, its granu-larity of analysis is different to that of review mining and summarization.
Let R = r 1 ,r 2 , ..., r n be a set of reviews of a movie. Each review r i consists of a set of sentences &lt;s i 1 ,s i 2 The following describes some related definitions.
Definition (movie feature) : A movie feature is a movie element (e.g. screenplay, music) or a movie-related people (e.g. director, actor) that has been commented on.
Since reviewers may use different words or phrases to de-scribe the same movie feature, we manually define some classes for features. The feature classes are pre-defined ac-cording to the movie casts of IMDB. The classes are di-vided into two groups: ELEMENT and PEOPLE. The EL-EMENT classes include OA (overall), ST (screenplay), CH (character design), VP (vision effects), MS (music and sound effects) and SE (special effects). The PEOPLE classes in-clude PPR (producer), PDR (director), PSC (screenwriter), PAC (actor and actress), PMS (people in charge of music and sounds, including composer, singer, sound effects maker etc.) and PTC (people in charge of techniques of movie-making, including cameraman, editor, set designer, special effects maker etc.). Each class contains words and phrases that describe similar movie elements or people in charge of similar kinds of work. For example,  X  X tory X ,  X  X cript X  and  X  X creenplay X  belong to ST class;  X  X ctor X ,  X  X ctress X  and  X  X upporting cast X  belong to PAC class.

Definition (relevant opinion of a feature) :Therel-evant opinion of a feature is a set of words or phrases that expresses a positive (PRO) or negative (CON) opinion on the feature.

The polarity of a same opinion word may vary in different domain. For example, in product reviews,  X  X redictable X  is a word with neutral semantic orientation. While in movie reviews,  X  X redictable X  plot sounds negative to moviegoers.
Definition (feature-opinion pair) : A feature-opinion pair consists of a feature and a relevant opinion. If both the feature and the opinion appear in sentence s, the pair is called an explicit feature-opinion pair in s. If the feature or the opinion does not appear in s, the pair is called an implicit feature-opinion pair in s.

For example, in sentence  X  X he movie is excellent X , the feature word is  X  X ovie X  and the opinion word is  X  X xcellent X . Therefore, the sentence contains an explicit feature-opinion pair  X  X ovie-excellent X . While in sentence  X  X hen I watched this film, I hoped it ended as soon as possible X , the reviewer means the film is very boring. However, no opinion word like  X  X oring X  appears in the sentence. We consider this sentence contains an implicit feature-opinion pair  X  X ilm-boring X .
The task of movie review mining and summarization is to find the feature-opinion pairs in each sentence first, and then identify the polarity (positive or negative) of the opin-ions, finally produce a structured sentence list according to the feature-opinion pairs as the summary, of which feature classes are used as the sub-headlines. In the next section, we will introduce our approach to perform the task.
In this paper, we propose a multi-knowledge based movie review mining approach. The overview of the framework is shown in Figure 1. A keyword list is used to record in-formation of features and opinions in movie review domain. Feature-opinion pairs are mined via some grammatical rules and the keyword list. More details of the proposed approach will be introduced in the following.
Considering that feature/opinion words vary obviously with different domains, it is necessary to build a keyword list to capture main feature/opinion words in movie reviews. We divide the keywords into two classes: features and opin-ions. The feature/opinion phrases with high frequency, such as  X  X pecial effects X ,  X  X ell acted X  etc., are also deemed as keywords.
 Figure 1: Architectural overview of our multi-knowledge based approach
In the following, we used statistical results on 1,100 man-ually labeled reviews to illustrate the characteristics of fea-ture words and opinion words. In fact, keyword list gener-ated from the training data was utilized in final experiments. Data we used will be introduced in Section 5.
In [6], the authors indicated that when customers com-ment on product features, the words they use converge. Same conclusion could be drawn for movie reviews accord-ing to the statistical results on labeled data. For each fea-ture class, if we remove the f eature words with frequency lower than 1% of the total frequency of all feature words, the remaining words can still cover more than 90% feature occurrences. In addition, for most feature classes, the num-ber of remaining words is less than 20. Table 1 shows the feature words of movie elements. The results indicate that we can use a few words to capture most features. There-fore, we save these remaining words as the main part of our feature word list. Because the feature words don X  X  usually change, we don X  X  add their synonymic words to expand the keyword list as for opinion words, which will be introduced in the next sub-section.

In movie reviews, some proper nouns, including movie names and people names, can also be features. Moreover, a name may be expressed in different forms, such as first name only, last name only, full name or abbreviation. To make name recognition easier, a cast library is built as a special part of the feature word list by downloading and saving full cast of each movie first and removing people names that are not mentioned in training data. By removing the re-dundant names, the size of the cast library can be reduced significantly. In addition, because movie fans are usually interested in a few important movie-related people (e.g. di-rector, leading actor/actress, and a few famous composers or cameramen), the strategy will not lose the information of people who are often commented on, but preserve it well.
When mining a new review of a known movie, a few regu-lar expressions are used to check the word sequences begin-ning with a capital letter. Table 2 shows the regular expres-sions for people name checking. If a sequence is matched by a regular expression, the cast library will give a person name list according to the same regular expression, so that the matched sequence has same format with each name in the list. If the sequence can be found in the given list, the corresponding name will be the recognition result.
The characteristic of opinion words is different to that of feature words. From the statistical results on labeled data, we can find 1093 words expressing positive opinion and 780 words expressing negative opinion. Among these words, only 553 (401) words for positive (negative) are labeled P (N) in GI lexicon [17], which describes semantic orientation of words in general cases. The number of opinion words indi-cates that people tend to use different words to express their opinions. The comparison with GI lexicon shows that movie review is domain specific. Therefore, for better generaliza-tion ability, instead of using all opinion words from statisti-cal results of training data directly, the following steps were performed to generate the final opinion word list.
Firstly, from the opinion words coming from statistical re-sults on training data, the first 100 positive/negative words with highest frequency are selected as seed words and put to the final opinion keyword list. Then, for each substan-tive in WordNet, we search it in WordNet for the synsets of its first two meanings. If one of the seed words is in the synsets, the substantive is added to the opinion word list, so that the list can deal with some unobserved words in train-ing data. Finally, the opinion words with high frequency in training data but not in the generated list are added as domain specific words.
A sentence may contain more than one feature words and opinion words. Therefore, after finding a feature word and an opinion word in a sentence, we need to know whether they compose a valid feature-opinion pair or not. To solve this problem, we use dependency grammar graph to mine some relations between feature words and the corresponding opinion words in training data. The mined relations are then used to identify valid feature-opinion pairs in test data.
Figure 2 shows an example of dependency grammar graph, which is generated by Stanford Parser (http://www-nlp. stanford.edu/software/lex-parser.shtml), without distinguish-ing governing words and depending words. In training pro-cess, first a shortest path from the feature word to the opin-ion word is detected. Then the part-of-speech (of stemmed word) and relation sequence of the path is recorded. For example, in the sentence  X  X his movie is a masterpiece X , where  X  X ovie X  and  X  X asterpiece X  have been labeled as fea-ture and opinion respectively, the path  X  movie (NN) -nsubj -is (VBZ) -dobj -masterpiece (NN)  X  could be found and recorded as the sequence  X  NN-nsubj-VB-dobj-NN  X . If there is a negation word, such as  X  X ot X , the shortest path from the negation word to a word in the feature-opinion path is recorded as the negation sequence, which is showed as the red dashed line in Figure 2. Finally, after removing the low frequency sequences, the remained ones are used as the templates of dependency relation between features and opinions. Table 3 shows four dependency relation templates with highest frequency.

We use the keyword list and dependency relation tem-plates together to mine explicit feature-opinion pairs. First, in a sentence, the keyword list is used to find all feature/opinion words, which are tagged with all of its possible class la-bels. Then, the dependency relation templates are used to detect the path between each feature word and each opin-ion word. For the feature-opinion pair that is matched by a grammatical template, whether there is a negation rela-tion or not is checked. If there is a negation relation, the opinion class is transferred according to the simple rules: not P RO  X  CON , not CON  X  PRO .
Mining implicit feature-opinion pairs is a difficult prob-lem. For example, from the sentence  X  X hen I watched this film, I hoped it ended as soon as possible X , it is hard to mine the implicit opinion word  X  X oring X  automatically. In this paper, we only deal with two simple cases with opinion words appearing.

One case is for very short sentences (sentence length is not more than three) that appear at the beginning or ending of a review and contain obvious opinion words, e.g.  X  X reat! X ,  X  X  masterpiece. X  This kind of sentences usually expresses a sum-up opinion for the movie. Therefore, it is proper to Figure 3: Some opinion words frequently used for only feature class OA or movie-related people give an implicit feature word  X  X ilm X  or  X  X ovie X  with the fea-ture class  X  X A X . The other case is for a specific mapping from opinion word to feature word. For example,  X  X ust-see X  is always used to describe a movie;  X  X ell-acted X  is always used to describe an actor or actress. In order to deal with this case, we record the information of feature-opinion pairs where the opinion word is always used for one movie element or for movie-related people. Therefore, when detecting such an opinion word, the corresponding feature class can be de-cided, even without a feature word in the sentence. Figure 3 shows some opinion words frequently used for only feature class OA or movie-related people as examples.
After identifying all valid feature-opinion pairs, we gen-erate the final summary according to the following steps. First, all the sentences that express opinions on a feature class are collected. Then, the semantic orientation of the relevant opinion in each sentence is identified. Finally, the organized sentence list is shown as the summary. The fol-lowing is an example of the feature class OA.
 Feature class: OA PRO: 70 Sentence 1: The movie is excellent.
 Sentence 2: This is the best film I have ever seen.  X  X  X  CON: 10 Sentence 1: I think the film is very boring.
 Sentence 2: There is nothing good with the movie.  X  X  X 
In fact, if movie-related people names are used as the sub-headlines, the summary could be generated easily with the same steps. The following is such an example. For movie fans, this kind of summary probably interests them more. Actress: Vivien Leigh PRO: 18 Sentence 1: Vivien Leigh is the great lead.
 Sentence 2: Vivien X  X  performance is very good.  X  X  X  CON: 1 Sentence 1: Vivien Leigh is not perfect as many people con-sidered.
As aforementioned in Section 2, Popescu X  X  method out-performs Hu and Liu X  X  method. However, Popescu X  X  system OPINE is not easily available, which brings difficulty with adapting Popescu X  X  method. Therefore, we adapted Hu and Liu X  X  approach [6] and use it as the baseline. More specifi-cally, on the one hand, the proposed keyword list was used to detect opinion words and determine their polarities. On the other hand, the proposed implicit feature-opinion min-ing strategy was utilized. Precision, recall and F-score are used as the performance measures and defined as precision = N ( correctly mined feature recall = N ( correctly mined feature where N (  X  ) denotes the number of  X  .
We used the customer reviews of a few movies from IMDB as the data set. In order to avoid bias, the movies are se-lected according to two criteria. Firstly, the selected movies can cover as many different genres as possible. Secondly, the selected movies should be familiar to most movie fans. Ac-cording to the above criterions, we selected 11 movies from the top 250 list of IMDB. The selected movies are Gone with the Wind , The Wizard of OZ , Casablanca , The Godfather , The Shawshank Redemption , The Matrix , The Two Towers (The Lord of the Rings II) , American Beauty , Gladiator , Wo hu cang long ,and Spirited Away . For each movie, the first 100 reviews are downloaded. Since the reviews are sorted by the number of people who think them helpful, the top reviews are more informative. There are totally more than 16,000 sentences and more than 260,000 words in all the selected reviews.

Four movie fans were asked to label feature-opinion pairs, and give the classes of feature word and opinion word re-spectively. If a feature-opinion pair is given the same class label by at least three people, it is saved as the ground-truth result. The statistical results show that the consistency of at least three people is achieved in more than 80% sentences.
We randomly divided the data set into five equal-sized folds. Each fold contains 20 reviews of each movie. We used four folds (totally 880 reviews) as the training data and one fold as the test data, and performed five-fold cross-validation. Table 4 shows the average five-fold cross-validation results on the data.

From Table 4, three conclusions could be drawn. First, the precision of our approach is much higher than that of Hu and Liu X  X  approach. One main reason is that, in Hu and Liu X  X  approach, for each feature word, its nearest opinion word is used to construct the feature-opinion pair, which produces many invalid pairs due to the complexity of sentences in movie reviews. While our approach uses dependency rela-tions to check the validity of a feature-opinion pair, which effectively improves the precision. Second, the average recall of our approach is lower than that of Hu and Liu X  X  approach, which is due to two reasons: 1) Hu and Liu X  X  approach iden-tifies infrequent features, while our approach only depends on the keyword list that does not contain infrequent fea-tures; 2) Feature-opinion pairs with infrequent dependency relations cannot be detected by our approach because the infrequent relations are removed, while Hu and Liu X  X  ap-proach is not restricted by grammatical relations. The Last conclusion is that the average F-score of 11 movies of our approach is higher than that of Hu and Liu X  X  approach by relative 8.40%.

Table 5 shows the average results of 11 movies for two feature classes -OA and PAC, as an example for detailed results. From it, same conclusions about precision and recall could be drawn.

Comparing with the product review mining results re-ported in [6] and [14], it can be found that both precision and recall of movie review mining are much lower than those of product review mining. This is not surprising, since movie reviews are known to be more difficult with sentiment min-ing. Movie reviews often contain many sentences with ob-jective information about the plot, characters, directors or actors of the movie. Although these sentences are not used to express the author X  X  opinions, they may contain many positive and negative terms. Therefore, there may be many confusing feature-opinion pairs in these sentences, which re-sult in the low precision. In addition, movie reviews con-tain more literary descriptions than product reviews, which brings more implicit comments and results in the low recall.
For further improvement, we checked the mining results manually and carefully. In the following, we will show a few examples to analyze some typical errors. For clarity, Italic and underline are used to denote feature word and opinion word, respectively.
 Example 1: Sentence: This is a good picture .
 Error result: Feature class: VP Right result: Feature class: OA In most cases,  X  X icture X  means visual representation or im-age painted, drawn or photographed, which belongs to the feature class  X  X P X  in our keyword list. However, in this sentence, it means movie.
 Example 2: Sentence: The story is simple .
 Error result: Opinion class: PRO Right result: Opinion class: CON ple X , which has different semantic orientations in different cases. Sometimes, it means the object is easy to understand, where the semantic orientation is PRO. While sometimes it means the object is too naive, where the semantic orienta-tion should be CON. In our approach, we just looked up the keyword list, and took the first found item as the re-sult, which resulted in the e rror. However, from only one sentence, it is very difficult to identify the semantic orienta-tion of words such as  X  X imple X ,  X  X omplex X  etc. To solve the problem, context information should be used.
 Example 3: Sentence: Is it a good movie ? Error result: Feature-Opinion pair: movie-good Right result: NULL we cannot decide the polarity of the opinion about the fea-ture  X  X ovie X  from only this s entence. However, the pro-posed algorithm cannot deal with it correctly, because the possible feature-opinion pair  X  X ovie-good X  can be matched by the most frequently used dependency relation template  X  JJ -amod -NN  X , and  X  X ovie/good X  is an obvious fea-ture/opinion keyword. Same as example 2, context infor-mation should be used to solve the problem.
 Example 4: Sentence: This is a fantasic movie .
 Error result: NULL Right result: Opinion word: fantastic tastic X . In fact, there are many spelling errors in online movie reviews. In the test set, there exist errors such as  X  X ttative X ,  X  X avelous X  and so on. It is easy for the human labelers to recognize and label these words. However, most of these unusual words will not be added to the keyword list. Therefore, this kind of errors will be almost unavoid-able unless spelling correction is performed.
In this paper, a multi-knowledge based approach is pro-posed for movie review mining and summarization. The objective is to automatically generate a feature class-based summary for arbitra ry online movie reviews. Experimen-tal results show the effectiveness of the proposed approach. In addition, with the proposed approach, it is easy to gen-erate a summary with movie-related people names as the sub-headlines, which probably interests many movie fans.
In the future work, we will further improve and refine our approach from two aspects as the analysis of errors indi-cated. Firstly, a spelling correction component will be added in the pre-processing of the rev iews. Secondly, more context information will be considered to perform word sense disam-biguation of feature word and opinion word. Furthermore, we will consider adding neutral semantic orientation to mine reviews more accurately.
The authors wish to express sincere gratitude to the anony-mous referees and Dr. Hang Li for their constructive com-ments and helpful suggestions. They are also very thankful to Qiang Fu, Hao Hu, Cheng Lv, Qi-Wei Zhuo and Chang-Hu Wang for their efforts on data preparation. The first au-thor and the third author are grateful to the financial sup-port by the Natural Science Foundation of China (Grants No. 60572084 and 60321002).
Additional authors: Lei Zhang (Microsoft Research Asia, email: leizhang@microsoft.com ). [1] Philip Beineke, Trevor Hastie, Christopher Manning [2] Pimwadee Chaovalit and Lina Zhou. Movie review [3] Kushal Dave, Steve Lawrence and David M. Pennock. [4] Michael Gamon, Anthony Aue, Simon Corston-Oliver [5] Vasileios Hatzivassiloglou and Kathleen R. McKeown. [6] Minqing Hu and Bing Liu. Mining and summarizing [7] J. Kamps and M. Marx. 2002. Words with attitude .In [8] Bing Liu, Minqing Hu and Junsheng Cheng. Opinion [9] Tony Mullen and Nigel Collier. Sentiment analysis [10] Charles E. Osgood, George J. Succi and Percy [11] Bo Pang, Lillian Lee and Shivakumar Vaithyanathan. [12] Bo Pang and Lillian Lee. A sentimental education: [13] Bo Pang and Lillian Lee. Seeing stars: Exploiting class [14] Ana-Maria Popescu and Oren Etzioni. Extracting [15] Ellen Riloff, Janyce Webie and Theresa Wilson. [16] Ellen Riloff and Janyce Wiebe. Learning extraction [17] Philip J. Stone, Dexter C. Dunphy, Marshall S. Smith [18] Peter D. Turney. Thumbs up or thumbs down: [19] Peter D. Turney and Michael L. Littman. Measuring [20] Janyce Wiebe. Learning subjective adjectives from [21] Janyce Wiebe and Ellen Riloff. Creating subjective and [22] Hong Yu and Vasileios Hatzivassiloglou. Towards
