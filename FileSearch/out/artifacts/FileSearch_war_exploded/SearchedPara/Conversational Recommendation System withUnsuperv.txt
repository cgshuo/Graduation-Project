 We will demonstrate a conversational products recommen-dation agent. This system shows how we combine research in personalized recommendation systems with research in di-alogue systems to build a virtual sales agent. Based on new deep learning technologies we developed, the virtual agent is capable of learning how to interact with users, how to an-swer user questions, what is the next question to ask, and what to recommend when chatting with a human user.

Normally a descent conversational agent for a particular domain requires tens of thousands of hand labeled conver-sational data or hand written rules. This is a major barrier when launching a conversation agent for a new domain. We will explore and demonstrate the effectiveness of the learning solution even when there is no hand written rules or hand labeled training data.
  X  Information systems  X  Recommender systems; Dialogue systems, recommendation systems, personal assis-tant, chat bot
Recommendation systems have achieved much commer-cial success and are becoming increasingly popular in a wide variety of online stores. Current recommendation systems provided ranked lists or images of items for a given user. Virtual sales agent with the capabilities of personalized rec-ommendation have been imagined for years. With the ever increasing popularity of smart phones, mobile devices and virtual reality systems, this becomes a very important prob-lem that could be a huge impact in the near future.
Research in recommendation systems field has enjoyed wide success, largely because the techniques are not restricted
The goal of a conversational recommendation agent is to finalize a purchasing order for the user at the end of the con-versation. In order to achieve this goal, the users need to provide values for meta data needed for the agent to place the order. These information are also known as slot-value pairs [1]. For example, a pair [ type = latte ] denotes the type of coffee ordered by user is  X  X atte X . After each user utterance, the user intention prediction and state tracking component needs to predict the current user X  X  intention pre-cisely and to update which state she/he is at. The state includes all slot-value pairs the agent has from the user so far, such as [ f ood = Japanese, location = 95070]. Without requiring hand labeled data for each user utterance, we de-veloped a new unsupervised learning method to train models used by this component. Our approach is to train a deep learning model [2] that learns from delayed rewards, which are the orders at the end of each conversation. These de-layed rewards are collected by e-commercial companies in their normal business.
Recommendation in conversation is an open area for re-search. Besides user transaction history and user demo-graphic information that are normally used in traditional recommendation engines, our engine also has a rich set of additional information about the user needs, such as possi-ble user initial request (i.e. a user query) or supplemental information collected while talking with the user. To bet-ter serve users in our system, we have a recommendation system that X  X  capable of using those information to rank products, generate recommendations, get user feedback to update memory and actively solicit additional user feedback.
We will demonstrate two machine utterance generation mechanisms inside our system. One is a template based model with a statistical learning method to select a tem-plate and automatically fill the missing components in the selected template for each machine utterance generation re-quest. The second solution is based on a deep learning model (i.e. a sequence to sequence language generation model).
