 As mobile devices equipped with localization function become increasingly popular among people, the age of Mobile Big Data has come. The mass data has the potential of enabling the design of mobile intelligent applications, such as mobile advertisement, location-based social network and Life-log applications [1]. Thus, providing an efficient strategy to manage and mining such mass spatial-temporal trajectory data is becoming a challenging and promising task.

In this paper, we mainly focus on the trajectory segmentation problem: dividing a long and continues trajectory sequence int o shorter and topically coherent segments. Each trajectory segment represents the user X  X  regular mobility in a certain region and a certain time interval with particular spatial-temporal topic distribution reflecting high-level semantics of human mobile behavior. The motivation of trajectory segmentation is that it is a fundamental requirement to model the structure of human mobile be-havior, especially in trajectory indexing, user similarity measure and routine mining. For instance, the management of massive human mobile behavior data requires divid-ing long trajectory into shorter segments to support effective and efficient trajectory indexing [16]. As for mining users X  long-term activity routines from human mobile sequences, the trajectory segment can help better understanding human mobile behav-ior [3].

In traditional research the trajectory sequence is segmented on the basis of fixed time window or spatiotemporal criteria. Katayoun Farrahi [5] proposed a distant n-gram topic model (DNTM) to model trajectory sequence over pre-defined fixed time window for routines. As human routines have mu ltiple timescales, the existing methods may destroy the structure of human mobile behavior. Buchin [17] addressed the problem of segmenting human GPS trajectory based on spatial-temporal criteria while ignoring the human mobile regularity. Another most similar series of work are topic segmentation model [9], which can divide the text into topically coherent segments with different topic distribution. But they only focused on lexical cohesion using bag of words with-out considering the spatial property and Markov property of human mobile behavior. Thus, we are confronted with following difficulties in human trajectory topic modeling compared with topic segmentation of other domains: the human mobility is affected by spatial distance and it has an obvious temporal Markov property beyond bag of words at the same time.

In this paper, we propose a probabilistic topi c model considering the spatial property and the Markov property of human mobility to address the problem of topic segmenta-tion in human mobile behavior. As in our model trajectory segment boundary is associ-ated with significant change in the spatial-temporal topic distribution, our method could model the temporal persistence of human mobility. We assume that each word transition is attached with a particular topic shift tendency which is related to the spatial factor as supervising information according to Tobler X  X  First Law of Geography [12]. As for the temporal Markov property of human mobility, bigram model [8] is jointly incorpo-rated beyond bag of words. We derive the inference process using Markov Chain Monte Carlo (MCMC) sampling [11]. A comparative experimental analysis is performed com-pared with traditional method, providing better segmentation performance on a syn-thetic dataset. Lastly, we apply our model to a real-life dataset successfully finding typical long duration routines while previous methods failed.

This paper is organized as follows. The next section discusses related work. Problem definition is proposed in Section 3. We then discuss methodology in Section 4. We present and discuss the experimental results in Section 5. Section 6 draws the paper to conclusion. Most related works can be summarized as trajectory segmentation and topic segmenta-tion model described as follows.
 Trajectory Segmentation: Some researchers address the problem of trajectory seg-mentation based on spatiotemporal criteri a. Buchin [17] requires that each segment is homogeneous in the sense that a set of spatiotemporal criteria are fulfilled. They de-fine different such criteria, including loca tion, heading, speed, velocity and so on. Re-searchers [15] propose a new partition-and-gr oup framework for clustering trajectories of moving objects, which partitions a trajectory into a set of line segments, and then, groups similar line segments together into a cluster to discover common sub-trajectories from a trajectory database. For the first phase, they present a formal trajectory partition-ing algorithm using the minimum description length (MDL) principle. This kind of research ignores the human mobile regularity focusing on the spatiotemporal criteria.
Trajectory segmentation has been used in ex tracting routines (e.g., work, home, en-tertainment). In these research trajector y sequence is segmented on the basis of fixed time window. Eagle and Pentland [2] use Principal Component Analysis (PCA) to iden-tify the main components structuring daily human behavior by daily segmentation. PCA captures features over the entire day, whereas the method using topic models has the ad-vantage of capturing characteristic trends occurring over part of the day. The state-of-the-art method is proposed by Katayoun Farrahi [5,6]. It proposes a distant n-gram topic model (DNTM) for location routines by modeling trajectory sequence over pre-defined fixed time interval of several hours. As human routines have multip le timescales, this kind of research may destroy the structure of human mobile behavior.
 Topic Segmentation Model: Actually, topic segmentation has first been researched in natural language processing well and many models have been proposed. It is used to produce information which can be used to summarize, browse or retrieve informa-tion contained in text. And the recent models characterise the lexical cohesion using topic models. Lexical cohesion in this line of research is modeled by a probabilistic generative process. PLDA is presented by Purver et al [9]. PLDA is an unsupervised topic modeling approach for segmentation. It chains a set of LDAs [7] by assuming a Markov structure on topic distributions. A bi nary topic shift variable is attached to each text passage (i.e., an utterance in [9]. It is sampled to indicate whether the j th text pas-sage shares the topic distribution with the ( j  X  1) th passage. Using a similar Markov structure, SITS [10] chains a set of HDP-LDAs. Unlike PLDA, SITS assumes each text passage is associated with a speaker identity that is attached to the topic shift variable as supervising information.

In summary, traditional trajectory segmentation methods mostly focus on spatiotem-poral criteria or fixed time window. While existing topic segmentation models only focus on lexical cohesion using bag of words ignoring the spatial property and Markov property of human mobility behavior. Our work can be viewed as the combination of two tasks together: segmenting trajectory sequence and then assigning topic distribution to trajectory segments. We use the GPS trajectory data collecti ons throughout the paper, r eferring to entities such as  X  X patial-temporal word X  and  X  X rajectory segment X . This is useful in that it helps to guide intuition, particularly when we introduce latent variables which aim to capture abstract notions such as  X  X patial-temporal topics X .
 Definition 1 (GPS trajectory). A GPS point is a pair p =( lng,lat ) , representing the longitude and latitude of the location. A GPS trajectory is a sequence of pairs Traj = ( p 0 ,t 0 ) , ..., ( p n ,t n ) ,inwhich p k is a GPS point and t k ( k =0 ...n ) is a timestamp (  X  0  X  k&lt;n,t k &lt;t k +1 ) .
 Definition 2 (Visit point). A visit point is a triple VP =( p, t in ,t out ) ,where p is a GPS point, t in and t out are timestamps, and the visit point stands for a location p which the user stays for longer than a time threshold (i.e. t out  X  t in &gt; X  time ). A reference place is a collection of visit points P = { VP 1 , ..., V P n } ,inwhichthey are close to each other. Reference places can be viewed as the significant places (e.g. home, work, etc.) where the user frequently visits. Because people X  X  daily routes can be characterized by a significant probability to return to a few highly frequented loca-tions, reference places can better model the structure of user mobility than raw GPS trajectories. Reference places are detected by [14] from all the visit points and indexed according to their frequency of occurrence.
 Definition 3 (Spatial-temporal word). A spatial-temporal word w =( l,t ) is com-posed of a location l  X  L where the user stopped over a time threshold and a time span of the day t  X  T . L = { 1 , 2 , ..., M } ,where M is the number of reference places and l is the index. T = { 1 , 2 , ..., D } ,where D is is the number of discrete time spans of the day.
 For better data representation we transform raw GPS trajectory to a structured sequence of spatial-temporal words similar to a corpus.
 Definition 4 (Spatial-temporal topic). Each spatial-temporal word has a correspond-ing latent variable spatial-temporal topic. It can be modeled as a multinomial distri-bution over spatial-temporal words. A spatial-temporal topic can be interpreted as a human mobility interest considering spatial property and Markov property.
 A trajectory segment is a sequence of N words denoted by Seg = { w 1 , ..., w N } . It represents the user X  X  regular mobility behavior in a certain region and a certain time interval with particular spatial-temporal topic distribution. The durations of trajectory segments are long and time varying because of characteristics of human mobility. Tra-jectory topic segmentation can be cast as an unsupervised machine learning problem: placing topic boundaries in unannotated trajectory sequence. The basic idea behind seg-mentation is that human trajectory sequence is made up of a set of continues segments. We associate a binary switching variable w ith each spatial-temporal word, indicating whether the topic distribution of mobility trajectory has changed. If it is true, a new segment starts from here. The variable is sampled by our spatial-temporal topic seg-mentation model. In this section, we describe our method to tackle the problem. We first introduce our spatial-temporal topic segmentation model in Section 4.1. Like many existing topic models, our model also introduces new latent variables into the graphical structure. In Section 4.2, in order to derive the latent var iables that best explain observed data, we use Gibbs sampling, a widely used Markov chain Monte Carlo inference technique. 4.1 Spatial-temporal Topic Segmentation Model Modeling Topic Boundary: We endow each spatial-temporal word w i with a binary switching latent variable c i , called the topic shift indicator. The topic shift indicator shows whether the topic of the word with will change the spatial-temporal topic distri-bution of its predecessor segment. As a result the c i indicates the probability that a new segment should start at i . As a result our method could model the temporal persistence of trajectory avoiding too frequent changes.

In fact, not every spatial-temporal word in the sequence could be the trajectory seg-ment boundary. The basic principle is that there must be user X  X  movement from one lo-cation to another between trajectory segments. So if the location of the spatial-temporal word is different from its predecessor, the word may be qualified to be the boundary. We call the two consecutive words a transition t m  X  X rom word w i  X  1 to word w i  X . Not every two adjacent spatial-temporal words c orrespond to a transition and the transitions are recurring.

Topic models typically do not model the spatial-temporal dynamics of human tra-jectory. Instead, we assume each transition is attached with a particular topic shift ten-dency. Tobler X  X  First Law of Geography [12] shows that everything is related to ev-erything else, but near things are more related than distant things. We make use of the spatial factor as supervising information in our model that the distance between two adjacent spatial-temporal words smaller, the smaller the shift tendency  X  m of the m th transition will be. And the frequency of the transition means a lot, too. The more fre-quent the transition is sampled as boundary, t he probability of topic shift is bigger. In general, this variable  X  m is intended to capture the propensity of a transition to affect a topic shift. It represents the probability that the transition t m will change the topic distribution of a trajectory segment.

We assume the topic shift probability  X  m of the word w i ( m is the index of the transi-tion), a Beta distributed random variable, i.e.,  X  m  X  Beta (  X  1 , X  2 ) . Then, the boundary indicator variable c i is sampled from c i  X  Bernoulli(  X  m )  X   X  ( dis m ) . dis m is the dis-tance of the m th transition of t m .
We h av e
In Equation 1, max and min are the maximum and minimum distance of the transi-tions.  X  0 ( dis m ) is a decreasing function and  X  1 ( dis m ) is a increasing function. The two functions imply the importance of the distance of the transition to topic shift.  X  is a pa-rameter describing the width of each trajectory segment activity area. As  X  is decreased, the width increases. Probability P ( c i |  X  m ,dis m ) can be writen as Equation 2. In Equation 2,  X  m =  X  m  X   X  0 ( dis m )+  X  m  X   X  1 ( dis m ) is the normalization constant.
To sample topic shift indicator c i , we use a point-wise sampling algorithm. Conse-quently, a sequence of topic shift indicators defines a set of segments. For example, let and { 6, 7, 8 } .
 Modeling Topic Structure: Since the segment boundary should be the associated with significant change in the topic distribution, we sample a new distribution over topics for the next segment if the c i is sampled as 1.

From the research [4], people X  X  mobile behavior is a kind of Markov structure which is beyond bag of words. What the user will do next is influenced by his current state(spatial and temporal). Here we introduce the bigram model [8] for modeling spatial-temporal words in the trajectory sequence. A spatial-temporal word in trajec-tory sequence is assumed to be also conditi onally dependent on the previous word.
The model parameters are defined in Table 1.The graphical model for our model is illustrate in Figure 1. We use a probabilistic approach where observations are repre-sented by random variables, highlighted in gray. The latent variable z corresponds to a spatial-temporal topic. The latent variable c corresponds to a topic shift. The generative process is defined as follows: 1. For each transition t m in the sequence, draw corresponding topic shift tendency 2. For each spatial-temporal word w i : 4.2 Inference To find the latent variables that best explain observed data, we use Gibbs sampling, a widely used Markov chain Monte Carlo inference technique [11]. The state space is latent variables for topic indices assigned to all tokens z and topic shifts assigned to c . We margin over all other latent variables.
 Sample Topic: The conditional probability of z i indicates the probability that w i should be assigned to a particular topic, given other assignments, the current segmenta-tion, and the words in the segment.
 Use the Bayesian rule, we can get the conditional distribution for z i is shown in Equation 3.

We u s e n seg j to denote the number of tokens in current segment seg assigned topic j ; n seg  X  denotes the number of tokens in segment seg . n j w of times the topic j is assigned to the spatial-temporal word w i given the previous word w i  X  1 in the vocabulary because of the sequence property. Marginal counts are
In Equation 3, the first factor is proportional to the likelihood of observing word w i given the sampled topic and the previous word; the second factor is proportional to the probability of observing topic j given the sampled segment. Since an uninformed prior is used, when a new topic is sampled, all tokens are equivalent.
 Sample Topic Shift: The probability of topic shift tendency smaller, the spatial-temporal word is more likely in the same segment with its predecessor word.

The topic shift indicator variable c i with corresponding transition t m is sampled from Bernoulli distributed with parameter  X  m and the distance dis m of the transition, c distance of the transition to topic shift.

Sampling the topic shift variable c i requires us to consider merging or splitting seg-ments. The conditional probability of c i indicates the probability that a new segment should start at w i . It means merging the two adjacent segments when c i = 0; it means splitting the current segment into two when c i =1.Weuse n seg j to denote the number of tokens in segment seg assigned topic j ; n seg  X  denotes the number of tokens in segment seg . Again, the subscript C  X  i is used to denote exclusion of c i in the corresponding counts. n x m denotes the number of times that topic shift value of x is assigned to the m th transition. n this distribution, we have Equation 4.

As for c i = 0 in Equation 4, the first factor is proportional to the joint probability of all topics in segment seg and the second factor is pr oportional to the probability of assigning a topic shift of value 0 to transition m influenced the distance when c i =0.
As for c i = 1 Equation 4, the first factor is proportional to the joint distribution of the topics in two adjacent segments seg  X  1 and seg . The second factor is proportional to the probability of assigning a topic shift of value 1 to transition m. 5.1 Data and Preprocessing To inference the model, we sample the latent variables for many iterations, taking sam-ples and then average the sampled c i variables to derive an estimate for the posterior probability of a segmentation boundary at each transition. This probability is thresh-olded to derive a final segmentation which is compared to the manual annotations. Varying this threshold allows us to segment the trajectory in a more or less finer grained way.

We consider two different datasets for expe riments. The representations for each are detailed below.
 Synthetic Dataset. To solve the problem lacking of ground truth of human mobile be-havior, we constructed a synthetic dataset: a sequence of spatial-temporal words chosen from a vocabulary of 50. It is constructed according a typical user who has a regu-lar weekly repeating mobility pattern. The trajectory sequence is 300 days long and contains 14400 words. Each trajectory segment has a constant topic distribution over spatial-temporal words. The user has a constant trajectory segment in Monday, a one day long pattern in Tuesday and Wednesday, and two two-day long patterns in the next four days in every week.
 Nokia Dataset. We use real-life data collected by the Nokia N95 smart-phone from 2009.10.01 to 2010.09.01 corresponding to a 11 month period of the Lausanne Data Collection Campaign [13]. We selected 10 from 110 volunteers. The phone has an ap-plication that collects location data on a quasi-continuous basis using a combination of GPS and WiFi sensing, along with a method to reduce battery consumption. For data representation, the day is divided into 48 discrete time spans with 30 minutes as an interval. There are 105 reference p laces in total after place extraction. 5.2 Experiments in the Synthetic Dataset To analyze the properties of our algorithm we first applied it to a synthetic dataset. We compare our method with the most widely used and stable topic segmentation method PLDA [9]. For the sampling, 10 randomly initialized Gibbs chains were used. Each chain ran for 10,000 iterations with 5,000 for burn-in, with samples collected after every 200 iterations to minimize autocorrelation. Then 250 samples were drawn for 10 Gibbs chains. The discount parameter  X  =0.5,and  X  1 =  X  2 =0.1,  X  = 0.1, the other on word distributions  X  = 0.01.

We take one week long sequence segmentation results as an example. PLDA and our algorithm were trained with 30 topics. Figure 2 shows an example of how the inferred segment boundary proba bilities at transitions compare with the gold-standard bound-aries on the synthetic dataset. The gold-standard segmentation is { 23, 71, 119, 232, 359, 407, 455, 568, 695, 743, 791, 904 } , PLDA and our model infer { 23, 69, 102, 230, 359, 435, 548, 701, 796,900 } and { 22, 72, 119, 226, 350, 412, 454, 572, 700, 741, 795, 908 } respectively. PLDA miss the boundary after the 407 th and 743 th word. The two transitions both have a quite long distance which in our method would be set the segmentation boundary. Note the boundaries placed by our model are always within 20 words with respect to the gold standard. Thus, considering the properties of transi-tions and spatial property of human mobility might further improve the segmentation performance. 5.3 Experiments with Nokia Dataset To test the practical property of our algorithm we applied it with the Nokia smartphone data. The results shown here are for the discount parameter  X  =0.5,and  X  0 =  X  1 =0.1,  X  = 0.1, the other parameter on word distributions  X  = 0.01. We first train the model with the user X  X  trajectory to get the topic segme ntation. Then we use k-means to cluster the segments by spatial-temporal topic distribution with Euclidean distance into meaningful categories to find the user X  X  typical routines and pattern. We will compare our results with DNTM [6].

We take one user as an example. The Figure 3 indicates his mobile history of 11 months in Lausanne, Switzerland,. And the point in the map is larger and redder, the place he visited more frequently.

After clustering, some group of trajectory segments indicate the user X  X  typical rou-tines shown in Figure 4. In Figure 4(a), it shows a kind of routine around working areas that the user usually works in the morning, eats in the midday and then goes back to work until late in the afternoon. The routine mainly occurs in the weekdays. It occurs in the same day. In Figure 4(b), it shows a kind of routine around home areas that the user stays at home for a long time from the night of the first day to the noon of the third day. This routine occurs across three days, usu ally in weekends because the users usually goes to home at Friday night and stays until Sunday noon.

Though only selected results are presented for the discussion here, our method is generally effective for all the regular users. The results show that our model outperforms DNTM [6] in finding long time duration routines. They modeling trajectory sequence over pre-defined fixed several hour time intervals. While our topic segmentation model could model the temporal persistence of trajectory to get long routines with multiple timescales as Figure 4(a) and Figure 4(b) s how. As we can see from Figure 3 that the working area and the home area is far from each other. Our segmentation model can clearly segment the trajectory according the spatial factor of human mobility. In this paper, we propose a probabilistic t opic model to address t he problem of topic segmentation in human mobile behavior. Our model takes the spatial property and the Markov property of human mobility into consideration to better model the structure of trajectory sequence. The trajectory segments here are meaningful and build a foundation for more intelligent applications. We performed a comparative experimental analysis with traditional method on a synthetic dataset with better segmentation performance. We also apply our model to a real-life dataset proving that through our model typical long duration routines can be successfully mined out while previous methods failed. As a result, our model performs well both in theory and practice.

There are several directions in the next. Firstly, we can make a comparison with the unsupervised generative model Hidden Mar kov Model in topic segmentation and long duration routine mining. Secondly, we can make use of the typical routines to measure user similarity among the people to group similar users together.
 Acknowledgments. This work was supported by the National High Technology Re-search and Development Program of China ( X 863 X  X rogram) (No. 2014AA015103).

