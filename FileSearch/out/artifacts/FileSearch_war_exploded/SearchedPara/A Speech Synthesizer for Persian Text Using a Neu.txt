 AND The development and applica tion of text to speech-synthes is technology for various languages are growing rapidly [Ainsworth 1973; Bagshaw 1998; Sproat et al. 1998; Wu et al. 1997]. Designing a synthesizer for a language is largely dependant on the structure regions. Designing a synthesizer requires significant investigation into the language speech synthesizer for the most common Persian dialect. The English language has some advantag es over Persian that make the synthesizer design much easier. For example, English vowels always appear in written words, even distinguishing the long vowels is not an easy task. Thus the first and most important step in designing a Persian synthesizer is to determine the phonetic spelling of each word ________________________________________________________________________ there is a general correspondence between standard phonetic spelling and diacritic orthography. There is no major differen ce between extracting the vowels and the phonetic spelling of a word, and both need the same processing.
 There are several ways in which Persian wo rds can be translated into phonetic spelling. word and store these assignments in a lexicon. With this technique, a database is searched to find the phonetic spelling corresponding to each word. This is known as the dictionary method [Lee et al.1993]. Several commercial methods for text-to-phoneme conversion dictionaries, and therefore the phonetic spelling performance is compromised. A common approach to mitigate this problem is to search the database for the best match. approach uses a neural network to obtain the Persian phonetic spelling structure. For this purpose, training data should be gathered that is representative of the language. Using a neural network for extracting phonetic spe lling in text-to-speech conversion creates a database. The dictionary method has the adva ntage of being accurate, but it needs a huge database that consumes significant resources; and access time for such a database can be considerable. In the second and third methods some errors can be expected, but the access time is considerably lower (suitable for real -time applications), and the resources needed are negligible in comparison with the dictionary method. Since there is a lack of accurate probabilistic information about the Persian language, the probabilistic method cannot be used independently of other procedures to model the language. Due to the complexity of the process for extracting phonetic spelling in Persian, using a neural network to extract all of the required structures results in poor accuracy. So a combina tion of the second and third methods, in addition to utilizing some Persian language rules, is a reasonable approach for implementation. In this article we present a composite method with the following stages: word processing, sentence processing; and speech generation. 2. WORD PROCESSING The first step in designing a Persian synthesizer is to determine the phonetic spelling of multiperceptron neural network (MLP), as shown in Figure 1. This is based on the pioneering work of Sejnowski and Rosenberg [1987], i.e., NetTalk. NetTalk uses a single neural network to deal with all phoneme cases. The number of nodes in the input, hidden, and output layers is 54, 300, and 3, respectively. The activation function that is used for creating nonlinearity is sigmoid. (Note that Persian is written and read from right to left.) There are many learning algorithms for trai ning a neural network. One of the most common algorithms, back propagation (BP), is employed here. The learning rule in the BP algorithm was chosen to be a 3-valued function with respect to the error at the output nodes. After the neural network is trained, it may produce errors in the phonetic spelling extraction of an unknown word. Some of these errors have a very negative impact on the Markov model (SEHMM), which will be described later in the article. Before the words enter the neural network, some preprocessing is useful. Due to the complexity of the process for extracting phonetic spelling, applying some Persian language rules can greatly increase the accuracy of the extraction. For example, if certain rules that should be learned by the neural network. Thus, using these preprocessing rules were determined by the authors.) language in which the phonetic spelling extraction process obeys known rules [El-Imam stored in the database. There are some exceptions to the Persia n rules, which means th ere are words for which stored in a dictionary separated from the original word before the word enters the neural network. These suffixes and prefixes result in many different words. Thus by learning just a main word, preprocessing. The word is now ready to enter the MLP. A file containing the most common Persian words, along with their phonetic spelling, is used to train the neural network. Before the neural network begins to process the words, each letter is mapped into a 6-bit string (There are 32 letters in the Persian alphabet plus mapping is given in Table I. representations of the 4 adjacent right and 4 adjacent left letters. For letters located near neural network only operates on isolated words. We consider a sliding window, similar to NetTalk, with the letter to be vowelized placed in the middle of the window, i.e., central window positioning [Sejnowski and Rosenberg 1987]. In the alignment presented in Embrechts and Arciniegas [2000], the window-positioning structure is second position asymmetric windowing (SPAW), with an unequal number of places before and after the letter under consideration. This structure is called  X  X econd position X  because this letter is in the second position from the center of the wi ndow. This structure is described in detail in Sejnowski and Rosenberg [1987]. The neural network inputs for learning a typical word are shown in Figure 2. The number of adjacent letters is 8, which in Persian is the minimum number of adjacent letters necessary to determine the vowel of a letter without ambiguity. Signs are also used in Persian (e.g.,  X  tashdid  X  (gemination), and  X  tanween  X ). One of tashdid is placed on the second letter. When this sign is encountered, the omitted letter is restored and the tashdid sign eliminated. In this case the first letter does not have a vowel, and so doesn X  X  need to be processed by the neural network, since the output is the vowel of the letter. neural network output should also help to determine any exceptions (these will be discussed later). The following procedure is used by the neural network to identify long long vowel. This is determined by whether these three letters appear as consonants or not. When these letters appear as consonants, they do not indicate a long vowel for the presence of a long vowel. In these cases the neural network doesn X  X  process the letters  X  ,  X  or  X  . some letters (in a special order) in Persian with an orthography that does not correspond to their phonetic stru cture, for example,  X  X  X  , but only in certain special words. Otherwise these letters are pronounced normally. Wh en the neural network encounters these exceptions, it alerts the system which then labels these exceptions so they can be pronounced correctly. For exampl e, consider the two words  X   X  X  X  X  X   X  (/ xa:h X r /) and  X  treated properly. The complete list of neural network outputs is shown in Table II. 3. PHONETIC SPELLING EXTRACTION USING A NEURAL NETWORK word, and then the neural network processes each word, letter by lette r. While the neural network moves from one letter to another, th e Persian rules (mentioned in Section 2) are letters. These rules decrease the amount of processing done by the neural network in both the training and testing stages. They also increase the accuracy of synthesizing unknown words (those that the network has not been trained for). on the training data), may be an unpronounceable word. The system should have a mechanism to address these situations in order to produce a meaningful phonetic spelling. In this article, a 33-state smooth ergodic HMM (SEHMM) is employed to handle these cases. process in which the underlying process is not directly observable [Rabiner 1989]. In the SEHMM model, the observation probabilities of the SEHMM are conditioned on the current state of the SEHMM, as well as the precedi ng and following states. Knowing these three states, the probability distributi on of the observations can be determined. the Persian alphabet is 32 (blank is a separate state). Define Q as the set of states that are involved in specifying the observation probability function of the SEHMM at time i . The other parameter is the number of distinct observation symbols ( v ), which is 6 in our the observation vect or for the HMM is or a fully connected SHMM (smooth HMM). In a SEHMM, every state of the model can be reached (in a single step) from every other state, as shown in Figure 4. This model is practical for any language, since it assumes th at every letter is reachable from every other one. This assumption is very close to reality and enables the model to adapt itself to any new words that are ad ded to the language. ation about the vowel of the letter conditioned on the preceding and future letters. in a dictionary, considering only the first letter of each word. observation. This probability is employed in counting the occurrences used in calculating the probabilities according to where w is a word with state sequence Q and w P is the probability of w occurring. Any of the estimation algorithms discussed previously can be used with the standard ML parameters  X  , yielding operation of the neural network. vowel), it cannot be pronounced. To handle these situations, the SEHMM generates a vowel of the letter can be determined without ambiguity. This statistical information (which was gathered from a much larger database than used for training the neural network) can be used to choose the most probable vowel for the beginning letter. have no assigned vowels at the neural network output. In this case, the SEHMM generates a vowel for the middle consonants. 4. SENTENCE PROCESSING The pronunciation of a word in English doesn X  X  vary according to the sentence it appears in. However, in Persian the pronunciation of a word may differ slightly depending on the sentence due to the vowel of the last letter in each word. The vowel of the last letter in a noun can have the vowel /e/ or  X  Sokoon  X . The vowel of the last letter in other words (e.g., verbs, prepositions, conjunctions) is always  X  Sokoon  X . Nouns that govern the genitive case the relation between words and their function in a sentence is considered. 5. SPEECH GENERATION transcription systems have been developed for many languages. Since the use of stored speech as words or phrases is impractical (due to the huge number of words and phrases), many applications that can profit from such systems, such as elect ronic mail readers and talking computers. The three approaches, ar ticulatory synthesis, formant synthesis and concatenative synthesis, have a long histor y. The simplest appro ach is concatenative synthesis, since it takes segments of record ed speech and concatenates these segments during synthesis. Some systems use record ed speech coded by linear predictive coding (LPC). Other systems perform synthesis directly in the time domain (e.g., PSOLA) by storing and concatenatin g waveform segments. In general, the speech quality of systems that use time-domain techniques is higher than that of LPC-based systems. This section considers the design of a text-to-speech system that accepts phonetic spelling as an input and generates speech as an output. As mentioned above, in terms of complexity and the quality of the synthesized speech, used for a large vocabulary, since an impractically large amount of memory would be required. In contrast, using phonemes and allophones for synthesis produces low-quality speech. In addition, the design of such a system is very complex, but the resources required are negligible in comparison to the first method. The procedure developed in this article uses a moderately-sized inventory of subphonetic segments of short duration. These segments comprise the required steady -state sounds and the transitions between Figure 6 shows the complete text -to-speech conversion process. 5.1 Synthesis Units and Phonemes vowels cannot be the first letter, but can occur between two consonants or at the end of a word. The 32 Persian consonants can occur anywhere in a word; there are vowel-consonant and consonant-vowel transitions in Persian. Any of the 32 consonants can consonants depicted in Table III. 5.2 Converting Text to Its Equivalent Phonetic Spelling The text-to-phonetic spelling conversion consists of two stages. The first converts exceptional words and abbreviations to phonemes via the pronunciation dictionary. The strings of numbers must also be converted to words. The second stage is the extraction of phonetic spelling for all the remaining words. The exception lexicon contains the spelling and equivalent phonetic spelling for Persian nouns whose pronunciation does not follow the regular rules (as mentioned previously, Persian rules are used to improve the performance of the system). These rules and the phonetic extraction rules have some exceptions that must be stored in a database. Words with a fixed pronunciation, abbreviations, and some frequently occurring words are added to the database to speed-simple table structure. String s that are matches in the lexi con are converted and passed on to the speech-generation part of the system. Persian phonetic spelling extraction is not as complex as for English, and there is a corr espondence between standa rd phonetic spelling and diacritic orthography. However, in Persia n there are diacritical symbols that are used to represent morphophonemic proces ses of the language, for example  X  tanween  X  and  X  tashdid , X  X s explained previously. Y N N sounds /a/, /u/, and /i/, respectively. The diacritical symbols of the three different types of  X  tanween , X   X   X   X  ,  X   X  ,  X  and  X   X   X  are pronounced as the phoneme sequences /an:/, /un:/, and /in:/, respectively. The Persian long vowels (/a:/, /u:/, and /i:/) ar e not represented in the orthography by diacritical symbols. Instead, they have to be inferred from the written context of the letters for  X  alef , X   X  waw , X  and  X  ye  X . The long vowel generation rules are as follows. The long vowel /a: / is produced when the letter symbol for  X  alef  X  is preceded by preceded by a consonant, which should not have a diacritical symbol. The long vowel /i: / is produced when the letter symbol for  X  ye  X  is preceded by a consonant, which should not have a diacritical symbol. short vowels requires the introduction of morphologic and syntactic levels, which is done The final step is to concatenate the synthesis units into wave files. allophone [z:] /z/  X  [b:] /b/  X  [t:] /t/  X  [p:] /p/  X  [z:] /z/  X  [t:] /t/  X  [q:] /q/  X  [j:] /j/  X  [f:] /f/  X  [  X  :] /  X  /  X  [q:] /q/  X  [h:] /h/  X  [k:] /k/  X  [x:] /x/  X  [g:] /g/  X  [d:] /d/  X  [l:] /l/  X  [z:] /z/  X  [m:] /m/  X  [r:] /r /  X  [n:] /n/  X  [z:] /z/  X  [w:] /w/  X  [ X :] / X /  X  [h:] /h/  X  [s:] /s/  X  [y:] /y/  X  [ X :] / X /  X  6. TD-PSOLA The speech synthesis module uses the time domain pitch synchronous overlap add (TD-PSOLA) method [Moulines and Charpentier 1990] to synthesize the synthesis units, based on a waveform dictionary. Finally, the TTS system concatenates the synthetic waveforms and then delivers the result to the playback device. Before synthesis, however, the phonemes must have their duration and pitch modified in order to fulfill the prosodic constraints of the new words containing these phonemes. This processing is necessary to avoid the production of monoto nous-sounding synthesized speech. To allow these modifications in the recorded subun its, many concatenation-based TTS systems employ the TD-PSOLA method, where the speech signal is first processed by a pitch-marking algorithm. This algorithm assigns mark s at the peaks of the signal in the voiced segments. The synthesis is made by a superposition of Hanning windowed segments centered at the pitch marks and extending from one pitch mark to the next. Duration modifications are provided by deleting or replicating some of the windowed segments. between windowed segments. These modifications are illustrated in Figure 7. 6.1 Pitch Marking One of the most popular techniques for detecting pitch is to use autocorrelation analysis on speech that has been appropriately preproce ssed [Rabiner et al. 1976]. Autocorrelation methods have met with good success, for se veral reasons: Autocorrelation is applied directly to the waveform and is computationally straightforward. This method is amenable to digital hardware implementation, generally requiring only a single multiplier and an accumulator as computational elem ents. The autocorrelation method is largely phase distortion via transmission.
 problem of choosing an appropriate analysis frame size. The ideal analysis frame should pitched speakers to 50ms for low-pitched speaker s. In this article, the pitch period of the synthesis units was estimated, and found to provide acceptable performance (so this problem is not an issue here). function, most methods use a low-pass filter w ith cut-off frequency around 900Hz. This will, in general, preserve a sufficient nu mber of pitch harmonics for accurate pitch detection, but will eliminate the second and higher formants. 7. SYSTEM IMPLEMENTATION To demonstrate the quality and stability of the Persian synthesis, the text-to-speech conversion system was implemented on a pe rsonal computer (P C). The system was programmed to do the text-to-speech and phoneme-to-speech modules. A total of 322 synthesis units was extracted beforehand and stored on the PC. The concatenation of the synthesis units was carried out in a speech buffer. 7.1. System Performance To evaluate system performance, a test text containing 800 words was employed. Processing this test text using the system without postprocessing resulted in 146 vowelization errors among the 2100 tested letters. By utilizing postprocessing, the number of errors was decreased to 84. To demonstrate the understandability of the synthesized speech, a closed ev aluation test was conducted in which users had access to the original text. In addition, an open evaluation test was done to evaluate the perceptual language is Persian, but who had no previous experience with synthesized Persian speech. An audiotape of stimulus words was prepared that contained the synthesized words. The test text was played only once, and the listeners were not allowed to review the tape. Subjects were tested individually and informed that they would hear the synthesized text. In the closed evaluation test , subjects were told to score the text words they heard. Table IV. Results of the Closed Evaluation Test for the System Without Postprocessing . Table V. Results of the Closed Evaluation Test for the System with Postprocessing. addition to the understandability percentage for each listener. It is clear that not handling unpronounceable words results in poor performance, as intelligibility is well below 90%. among the listeners. Another closed evaluation test was performed with the complete schedule and expensive to conduct. Note that the people who evaluated the system were test material was chosen from several different texts. text was given to the listener. The evaluation results show that the listeners wrote 89% of the words correctly. Repeating the test for people who were previously exposed to synthesized speech resulted in better performance. 8. CONCLUSIONS In this article, we presented a system designed to extract Persian phonetic spelling using a neural network. When unknown words are encountered, the neural network may cause postprocessing is done using a SEHMM . We showed that the SEHMM improves system performance by 10-15%. A synthesizer was designed to test the phonetic spelling extraction process. The synthesizer accepts an input diacritical text (vowelized text) and produces output speech by concat enating speech synthesis units. substitute for dictionary-based phonetic spelling extraction systems. This system can easily be applied to Arabic (which is very similar to Persian). However, the system parameters (e.g., SEHMM observation functions, neural network weights, and extracted rules) are language-dependent, and should be determined separately for each language. REFERENCES 
