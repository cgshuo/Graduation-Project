 In this pap er, we extend the tradition asso ciation rule prob-lem by allowing a weight to b e asso ciated with each item in a transaction, to re ect interest/intensity of the item within the transaction. This provides us in turn with an opp or-tunity to asso ciate a weight parameter with each item in the resulting asso ciation rule. W e call it weighted asso ci-ation rule (W AR). W AR not only improves the con dence of the rules, but also provides a mechanism to do more ef-fective target marketing by identifying or segmenting cus-tomers based on their p otential degree of loyalt yorv olume of purchases. Our approach mines W ARs by rst ignoring the weight and nding the frequent itemsets (via a tradi-tional frequent itemset discovery algorithm), and is followed b yin tro ducing the weight during the rule generation. It is shown by exp erimental results that our approach not only results in shorter average execution times, but also pro duces higher quality results than the generalization of previous known metho ds on quantitative asso ciation rules.
 H.2.8 [ Information Systems ]: Database Managemen t| database applications W eighted asso ciation rules, Ordered shrinkage Asso ciation rule discovery has b een an active research topic during recen ty ears. However, the traditional asso ciation rules fo cus on binary attribute. This mo del only considers whether an item is present in a transaction, but do es not tak ein to account the weight/intensity of an item within a transaction. For example, a customer may purchase 10 b ot-tles of so da and 5 bags of snacks and another may purchase 4 b ottles of so da and 1 bag of snacks at a time. These two transactions will b e treated the same in the conventional as-so ciation rule approach. This could lead to the loss of some vital information. Assume, for example, that if a customer buys more than 7 b ottles of so da, he is likely to purchase 3 or more bags of snacks. Otherwise, the purchase tendency of so da is not strong. The traditional asso ciation rule can-not express this typ e of relationship. With this kno wledge, the sup ermarket manager may set a promotion such as \if a customer buys 8 b ottles of so da, he can get two free bags of snacks." In this pap er, we rst extend the traditional asso ciation rule problem by allowing a weight to b e asso ciated with each item in a transaction, to re ect interest/intensity of each item within the transaction. In turn, this provides us with an opp ortunity to asso ciate a weight parameter with each item in a resulting asso ciation rule. W e call them weighted asso-ciation rules (W AR). For example, soda [4 ; 6] ! snack [3 is a weighted asso ciation rule indicating that if a customer purchases so da in the quantit ybet ween 4 and 6 b ottles, he is likely to purchase 3 to 5 bags of snacks. Thus W AR can not only improve the con dence in the rules, but also pro-vide a mechanism to do more e ective target marketing by identifying or segmenting customers based on their p otential degree of loyalt yorv olume of purchases.
 Previous work dealing with numerical attributes includes the quantitative asso ciation rule approach and optimized asso-ciation rule approach. These approaches are not designed for weighted asso ciation rules [4]. In the problem we study in this pap er, there can b e a very large numb er of items and every item has a numerical attribute, although only a small fraction of items are present in a transaction. Thus, in our approach, the frequent itemsets are rst discovered (without considering weights), and then the weighted asso ci-ation rules for each frequent itemset are generated. Our goal is to segment the weight domain of each item in the item-set so that rules with higher con dence can b e discovered. Moreo ver, the sp eci ed weigh tin terval of each attribute in a weighted asso ciation rule should also coincide with the nat-ural distribution of the data and human intuition. In most case, only the weigh tin terval combinations that represen ta signi can tn umb er of transactions are interesting. Our goal can b e transformed into nding highly p opulated regions. Thus, we use another metric density for such purp ose. As a result, the weight domain space of each frequent itemset is partitioned into ne grids. A density threshold is used to separate the transaction concentrating regions from the rest. W ARs can b e identi ed based on these \dense" regions. The contributions of this pap er are summarized as follows.
Permission to make digital or hard copies of part or all of this work or permission and/or a fee.

KDD 2000, Boston, MA USA  X  ACM 2000 1 -58113 -233 -6/00/0 8 ...$5.00 The remainder of this pap er is organized as follo ws. The problem is form ulated in Section 2, while Section 3 out-lines the general approac h. Sections 4 and 5 presen t the space partition and W AR generation, resp ectiv ely . Section 6 sho ws the exp erimen tal results. A conclusion is dra wn in Section 7. Let = = f i 1 ;i 2 ;:::;i M g b e a set of items and } b e the set of non-negativ ein tegers. A pair h x; w i is called a w eigh ted item , where x 2= is an item and w 2 } is the w eigh t asso ciated with x . A transaction is a set of w eigh ted items. F or example, T 1 = fh f ashion; 15 i ; h spor ts; 10 ig and T fh f ashion; 20 i ; h book ; 5 ig are t w o transactions. An in terv al w eigh ted item is a triple h x; l ; u i . This denotes the fact that the w eigh t asso ciated with the item x is within the range [ l; u ] where l and u are non-negativ ein tegers and l u . Note that w e can alw a ys view a w eigh ted item h x; w i as a sp ecial case of the in terv al w eigh ted item h x; l ; u w = l = u . Therefore, w e will use the term weighte d item if no am biguit y will o ccur. Giv en t w ow eigh ted items I h x 1 ;l 1 ;u 1 i and I 2 = h x 2 ;l 2 ;u 2 i ,w e call I 1 a generalization of I 2 (and I 2 is a sp ecialization of I 1 )i x 1 = x 2 1 l 2 u 2 u 1 . F or example, h f ashion; 10 ; 20 i is a sp ecializati on of h f ashion; 10 ; 25 i . Note that an yw eigh ted item h x; l ; u i can b e view as a sp ecializatio n of the item x . W e use the term w eigh ted itemset to represen t a set of w eigh ted items. Let item ( X ) denote the set of items that are in v olv ed in a w eigh ted itemset X , i.e., item ( X )= f x j x 2= ; h x; l ; u i2 X g . Giv en t w ow eigh ted itemsets X , X 1 is a sp e cializatio n of X 2 (or X 2 is a gener alizat ion of X 1 )i item ( X 1 )= item ( X 2 ) and eac hw eigh ted item in X 1 is a sp ecializati on of a w eigh ted item in X 2 . F or instance, fh f ashion; 10 ; 20 i ; h book ; 5 ; 7 ig is a sp ecializati on of fh f ashion; 10 ; 20 i ; h book ; 5 ; 10 ig . Giv en a transaction T and a w eigh ted item h x; l ; u i ,w esa y that T supp orts this w eigh ted item i there exists a w eigh ted item h x; w i2 T suc h that h x; w i is a sp ecializati on of h x; l ; u i . Similarl y , w esa y that a transaction T supp orts aw eigh ted itemset X i T supp orts eac h individ ual w eigh ted item in X .F or instance, if X = fh f ashion; 10 ; 20 i ; h book ; 5 ; 10 ig , then T supp orts X while T 1 do es not. Giv en a w eigh ted itemset X and a set of transactions, referred to as &lt; ,w esa y X has supp ort s in &lt; i s % of transactions in &lt; supp ort X . Note that the supp ort of a w eigh ted itemset is alw a ys less than or equal to the supp ort of an y of its generalization . A w eigh ted asso ciation rule (W AR) is an implication X ! Y where X and Y are t w ow eigh ted itemsets and item ( X ) \ item ( Y )= ; . A transaction is said to supp ort aW AR X ! Y i this transaction supp orts the w eigh ted itemset X [ Y . In turn, w e de ne the supp ort of the W AR as the supp ort of X [ Y . In addition, w esa y that the W AR X ! Y holds in the transaction set &lt; with c on denc e c i c % of the transactions in &lt; that supp ort X also supp ort Y . In other w ords, the con dence of the W AR is the ratio of the supp ort of X [ Y o v er the supp ort of X . The density of a W AR is de ned as the ratio of the actual supp ort of the W AR and the \exp ected" supp ort of the W AR. W e will elab orate on the densit y de nition in Section 5. In this pap er, w e assume that Y only con tains one w eigh ted item for the sak e of simplicit y .
 Giv en a transaction set &lt; , our ob jectiv e is to nd a set of W eigh ted Asso ciation Rules (W AR) whic hha v e sup-p ort, con dence, and densit y greater than or equal to some user-sp eci ed minim um supp ort (referred to as minsup ), min-im um con dence (referred to as minc onf ), and minim um densit y (referred to as d ). Since there could b e a h uge n um b er of quali ed W ARs, in this pap er, w e aim at mining maxim um W AR . A quali ed W AR X ! Y is a maxi-m um W AR if for an y generalizati on X 0 of X and Y 0 of Y where X 0 6 = X and Y 0 6 = Y , neither of X 0 ! Y , X ! Y nor X 0 ! Y 0 is a quali ed W AR. Clearly , there can b e a h uge n um b er of p oten tial W ARs, due to the n umerical nature of the w eigh t. Ecien t pruning of suc hah uge searc h space b ecomes a crucial task in the min-ing pro cess. Unlik e [3], w e design a t w ofold approac h based on an observ ation w e made in Section 2: the supp ort of a weighte d itemset is always less than or e qual to the supp ort of any of its gener alizat ion s . This indicates that, for an y w eigh ted itemset I , its supp ort is alw a ys less than or equal to the supp ort of item ( I ). This suggests that w e can rst cal-culate frequen t itemsets (without considering the w eigh ts) and then examine the w eigh t factor for eac h frequen t itemset to generate the W ARs. A frequen t(w eigh ted) itemset is a (w eigh ted) itemset whose supp ort is larger than or equal to the threshold minsup .Th us, w e emplo yat w ofold approac h. (1) Generate frequen t itemsets. In this step, w e ignore the w eigh t asso ciated with eac h item in the transaction set. (2) F or eac h frequen t itemset, nd the W AR(s) that meets the supp ort, con dence, and densit y thresholds.
 Since the rst phase is mainly the frequen t itemset coun ting (as in the traditional asso ciation rule mining), w e will not elab orate it in this pap er. After obtaining the set of frequen t itemsets, referred to as F ,w e examine them to generate the w eigh ted asso ciation rules. Giv en an itemset I of cardinalit y n , the domain of the w eigh ts of all items forms an n dimen-sional space where eac h dimension corresp onds to the w eigh t of one item. (F or simplicit y ,w e assume that the w eigh t range on eac h dimension to b e the same.) Eac h sp ecializatio n of I corresp onds to an n -dimensional (rectangular) b o x within this space. Our ob jectiv e is to nd the maxim um b o x(es) so that supp ort, con dence, and density are satis ed. T o facilitate this pro cess, w e discretize the space in to a set of grids and divide the second phase further. 1. Space partition and coun ter generation: The goal is 2. W ARs generation: The goal is to generate the maxi-The densit y concept is in tro duced to dev elop e ectiv e prun-ing tec hniques for iden tifying candidate b o xes for W AR min-ing. W ew an ttok eep the additional parameters that need to b e sp eci ed b y the users to a minim um. The in ten tis toin-tro duce one densit y threshold that is applicabl e to all grids, regardless of the n um b er of dimensions. A straigh tforw ard partitioning metho d is to divide eac h dimension in to a xed n um b er of partitions. Ho w ev er, under this approac h, as the n um b er of dimension increases, the n um b er of grids gro ws exp onen tiall y , while the a v erage densit y of eac h grid drops rapidly . This implies that di eren t densit y thresholds w ould b e needed for grids of di eren t dimensional i ties . W e hence use an alternativ e approac h that k eeps the n um b er of grids N xed regardless of the n um b er of dimensions. Another adv an tage of this partitionin g metho d is that w e can easily con trol the n um b er of coun ters b yv arying the v alue of N . This pro vides us with the capabilit y to tak e full adv an tage of the a v ailable storage space dynamically .
 The grid is tak en as the gran ularit y of our W AR mining pro cess. An y n -dimensional b ox within this space, whic his the union of a set of adjacen t grids and is rectangular in shap e, uniquely corresp onds to a sp ecializati on of I .Th us, in the remainder of this pap er, w e will use the term \b o x" and \w eigh ted itemset" in terc hangeably if no am biguit y will o ccur. Let b e the a v erage n um b er of transactions that supp ort a grid. W eha v e = j&lt;j is de ned as the ratio of the supp ort of this grid and . In tuitiv ely , densit y can b e view ed as an indication of the relativ e concen tration of transactions within the space. A grid is dense i its densit yisabo v e a threshold d , where d&gt; 1 is a small real n um b er. In order to limit the searc h space, w e only in v estigate dense grids and the region formed b y them. Unlik eabo x, a region do es not ha v e to b e of rect-angular shap e. The motiv ation b ehind this is that w e only w an t to rep ort W ARs whic h represen t signi can t patterns in the data. Therefore, a range will not b e included in a W AR if there is not enough evidence (densit y) to supp ort it. A dense r e gion is the union of a set of adjacen t dense grids. Eac hbo x within a dense region, referred to as dense b ox ,is a candidate of frequen tw eigh ted itemset. The volume of a bo x is de ned as the n um b er of distinct grids it con tains. Although this approac h needs one densit y threshold for prun-ing, it do es create additional complexities on the pruning algorithms, as the pro jection of an n -dimensional grid on to an ( n 1)-dimensional subspace do es not align on the grid b oundaries of the ( n 1)-dimensional subspace. In fact, suc h pro jection is alw a ys of a lo oser gran ularit y than the grid in the ( n 1)-dimensional space. This can b e easily ob-serv ed in Figure 1. The pro jection of a grid in Figure 1(1) o v erlaps with 9 grids in Figure 1(2).The lev elwise pruning in [2] can still b e adopted with one mo di cation: giv en an n -dimensional grid g , if the supp ort of the union of the ( dimensional grids that can co v er the pro jection of g is b elo w d , than g cannot b e a dense grid. F or example, if the supp ort of the shaded area in Figure 1(2) is b elo w d , then the grid in Figure 1(1) cannot b e dense. After nding all dense grids, dense regions, whic h serv e as the basis for W AR generation, can b e easily iden ti ed b y a depth-rst tra v ersal through neigh b orin g dense grids similar to [2]. Giv en an n -itemset I = f i 1 ;i 2 ;::: ;i n g , there are p oten-tially n di eren tW AR formats b ecause eac h item migh t serv e as the righ t hand side. In order to searc h for the range asso ciated with eac h item, w e examine eac h dense re-gion sequen tially . Giv en a dense region, if its supp ort is b elo w the required minsup threshold, w e simply discard it, since no quali ed W AR can b e generated from this dense region. Otherwise, w e start from the minim um b ounding bo x of the dense region. The minim um b ounding b o xisthe bo x with smallest v olume whic h con tains the dense region. In general, suc habo x itself ma y not satisfy the con dence requiremen t, but ma y con tain dense b o x(es) corresp onding to quali ed W AR(s). Th us, w ec ho ose to shrink the mini-m um b ounding b o xto w ards the maxim um W ARs. An al-ternativ e algorithm is to pic k a grid and gro wto w ards the maxim um W ARs. Since the maxim um W ARs usually ha v e large v olumes, shrinking to w ards a maxim um W AR is gen-erally more ecien t than gro wing to w ards it. T o the b est of our kno wledge, this is the rst algorithm to use shrinking instead of gro wing in mining asso ciation rules or cluster-ing. A shrinkage is de ned as the action that reduces the span of a b o xo v er one dimension b y exactly one base in-terv al. A t eac h step, a candidate b o xisc hosen to p erform a shrink age to generate a new dense b o x that ma y serv e as a candidate for further shrink age at a later step. The pro cess ends when the newly generated dense b o x meets the con dence requiremen t or all remaining candidate b o xes fall to meet the supp ort requiremen t. Without loss of general-it y ,w e assume that there is only one dense region. Fig-ure 2(a) is a dense region whose minim um b ounding b o x is sho wn in Figure 2(b), where the dark shaded grids and ligh t shaded grids are dense grids and non-dense grids, re-sp ectiv ely .F or eac h item, the range of its w eigh t can b e shrunk en to w ards t w o directions: increasing the lo w erb ound or decreasing the upp erb ound. Th us, there are 2 n di eren t shrink ages applicabl e to a w eigh ted n -itemset. As a result, 2 n new w eigh ted n -itemsets can b e generated. Since these new w eigh ted item sets are pro duced b y one shrink age from the original w eigh ted itemset, w e call them the imme diate sp e cializatio ns of the original w eigh ted itemset. The original w eigh ted itemset is an imme diate gener alizatio n of these new w eigh ted itemsets. Figure 2(c) sho ws the six di eren t direc-tions to shrink a w eigh ted 3-itemset and their corresp onding outcomes. Clearly , eac h dense b o x can b e reac hed b y a set of shrink-ages from the minim um b ounding b o x of the dense region. Assuming that w e can only p erform one shrink age on one candidate b o x at a time, the en tire pro cess can b e view ed as a sequence of op erations ( B j ;H j )( j =1 ; 2 ;::: ) where B a candidate b o x and H j is a shrink age along some direction. Let j b e the set that includes the minim um b ounding b o x of the dense region B 1 and all b o xes generated via op era-tions ( B 1 ;H 1 ) ;:::; ( B j 1 ;H j 1 ). j th us represen ts the set of candidate b o xes (for further shrinking) a v ailable b efore the j th op eration. Clearly ,w eha v e B j 2 j at eac h step. The sequence stops when all W ARs are generated. F or the bo x B j visited at the j th step, there exists a subsequence 1 is the minim um b ounding b o x of the dense region and 1 ;H j 2 ;:::;H j r is a shrinkage p ath to B j from the mini-m um b ounding b o x of the dense region. Note that, at eac h step, there are m ultiple candidate b o xes in j and di eren t shrinking directions to c ho ose from. As a result, di eren t algorithms for pic king candidate b o x and shrinking direc-tion can pro duce di eren t sequences of op erations and hence could require di eren tn um b er of op erations b efore all nec-essary W ARs are generated. Therefore, the eciency of an algorithm dep ends on the amoun t of time consumed at eac h op eration and the n um b er of op erations needed. One p ossible approac h is the brute force algorithm. Let be j excluding those b o xes whic h satisfy either of the fol-lo wing conditions: (1) all of its immediate sp ecializati ons are in j , or (2) it is a maxim um W AR. A t eac h step, the brute force algorithm randomly pic ksabo x from 0 j . The algorithm terminates when 0 j = ; . The computational complexit y of the brute force algorithm is O (2 n ) n n Therefore, this approac h is indeed inecien t. In tuitiv ely , this ineciency is caused b y the fact that a b o xma ybe visited m ultiple times via di eren t shrink age paths. This w ould lengthen the op eration sequence and th us cause the ineciency .F or example, there are t w o paths to reac h the bo x in Figure 2(d)(2) from the b o x in Figure 2(d)(1). One is \reducing the upp er b ound of dimension 2" follo w ed b y \reducing the upp er b ound of dimension 1", while the other is \reducing the upp er b ound of dimension 1" follo w ed b y \reducing the upp er b ound of dimension 2". The set of shrink ages of the t w o paths is the same. The only di erence is that di eren t paths adopt a di eren t p erm utation of these shrink ages. In general, if it tak es b shrink ages to reac h from bo x B 0 from B (where B 0 is enclosed within B ), then there exist b ! di eren t shrink age paths. In order to eliminate the redundancy of w eigh ted itemset generation, w ein tro duce an ordered shrink age tec hnique. This guaran tees that eac h w eigh ted itemset is generated exactly once.
 W e rst c ho ose a p erm utation, referred to as , of 2 n dif-feren t shrinking directions and retain this order during the en tire pro cess. F or example, the six shrinking directions in Figure 2(c) can b e ordered as incr e asing lowerb ound of di-mension 1, de cr e asing upp erb ound of dimension 1, incr e as-ing lowerb ound of dimension 2, de cr e asing upp erb ound of dimension 2, incr e asing lowerb ound of dimension 3, de cr e as-ing upp erb ound of dimension 3 . Then, during the shrinking pro cess, a shrink age of the k th direction in can b e p er-formed on a b o x B only if no shrink age of direction after the k th one in has b een p erformed to generate B .W e call suc h shrink age a valid shrink age. F or instance, if w e tak e the b o x in Figure 2(c)(4) as the candidate to gener-ate new w eigh ted itemsets, according to the order w e pic k, three shrinking directions can b e applied: de cr e asing upp er-b ound of dimension 2, incr e asing lowerb ound of dimension 3 , and de cr e asing upp erb ound of dimension 3 . As a result, the only v alid shrink age path from Figure 2(d)(1) to Fig-ure 2(d)(2) is \reducing the upp er b ound of dimension 1" follo w ed b y \reducing the upp er b ound of dimension 2". It is ob vious that this ordered shrink age approac h completely eliminates the redundancy of b o x generation in the previous brute force approac h, b y pro viding eac h p ossible w eigh ted itemset a unique shrink age path from the ro ot. The compu-tational complexit y of the ordered shrink age for one itemset is O ( N 2 ). The detailed algorithm is sho wn in [4]. W e implemen ted our algorithm in C and executed it on an IBM AIX RS6000 mac hine with a 333 MHz CPU. The data w as placed on a disk with appro ximate 8 MB/s throughput. T o analyze the p erformance of our prop osed approac hes, w e generate the input data in a similar manner as in [1]. The data set con tains 1 million transactions with 10000 di eren t items. The n um b er of items in a transaction is clustered around a mean 15 and a few transactions ha v e man y items. The v olume of frequen tw eigh ted itemsets are also clustered around a mean 500. Refer to [4] for further information on data generation and additional exp erimen ts.
 The quan titativ e asso ciation rule (QAR) has b een prop osed for the general n umerical attribute v alues that are asso ci-ated with ev ery database record. Ev en though w e are in-v estigating a di eren t scenario, QAR is the only other ap-proac h whic hw e kno w that ma y b e generalized to mine W ARs. Therefore, w e compare our approac h with the QAR approac h. In essence, the quan titativ e asso ciation rule ap-proac h [3] rst quan tizes the domain of ev ery item, and map it in to a binary v alue. Since at the b eginning it is unkno wn that whic h items will app ear in an itemset, all attribute do-mains ha v e to b e partitioned. Ifan umerical attribute is partitioned in to in terv als, then these in terv als are mapp ed in to 2 + 2 items b ecause eac h of the original in terv als and the com bined in terv als is treated as a di eren t item. F or the syn thetic dataset generated ab o v e, if the w eigh t domain of eac hw eigh ted item is partitioned in to 20 in terv als, then there are o v er 2 million binary items for the QAR approac h. The QAR approac h utilizes a parameter maxsup to reduce the resulting set of rules. It is clear that maxsup can im-pro v e the p erformance, but could p oten tially degrade the qualit y of the results signi can tly .T o analyze the p erfor-mance and qualit y of these t w o approac hes, w e set =20 and maxsup = minsup +0 : 2 for QAR. F or the W AR ap-proac h, the densit y d and the total n um b er of grids ( N ) for eac h itemset are set to 1.5 and 1 million, resp ectiv ely . The qualit y of the resulting rules is analyzed via t w o mea-suremen ts: recall and accuracy . Since the datasets are gen-erated arti cially ,w e kno w the set R of all existing rules. First, w e compute the v olume of eac h rule r 2 R , denoted r acy )of R 0 with resp ect to R is computed as follo ws. F or eac h r 2 R ( r 0 2 R 0 ), nd the rule r 0 2 R 0 ( r 2 R ) suc h that the o v erlap of r and r 0 is the largest, i.e., V ( r \ r is the largest. Next, the individ ual recall (accuracy) of r The o v erall recall (accuracy) of R 0 with resp ect to R a v erage of the individ ual recalls (accuracies) for eac h r 2 R . Figure 3(a) sho ws the a v erage execution time of the t w o ap-proac hes with resp ect to minsup .W AR on a v erage is a cou-ple order of magnitude faster than QAR, ev en though the execution time of b oth approac hes increases exp onen tiall y with decrease of minsup b ecause the complexit y is appro x-imately linear to the n um b er of coun ters, whic h usually in-creases exp onen tially with smaller minsup . (Note that the Y-axis is in log-scale.) Figure 3(b) sho ws the recall ratio of the t w o algorithms with resp ect to the minim um sup-p ort threshold. W AR has a signi can t higher recall v alue than QAR b ecause a signi can t amoun t of imp ortan t rules are pruned b y the maxsup threshold in QAR. Finally ,w e examine the accuracy of the t w o approac hes. The w eigh t domain of eac h item in W AR is partitioned in to m uc h ner grids than that in QAR for 2, 3, and 4-itemsets for whic h most rules exist. As a result, with the ner partition, the W AR approac h pro duces m uc h more accurate rules than the QAR approac h as sho wn in Figure 3(c). In this pap er, w eha v ein v estigated a new class of in terest-ing problem: w eigh ted asso ciation rules, whic hha v e wide implication s. W e prop osed a t w o-fold approac h, where the frequen t itemsets are rst generated (without considering w eigh t) and then the maxim um W ARs are deriv ed using an \ordered" shrink age approac h. Exp erimen tal results sho w that our prop osed approac h not only outp erforms direct gen-eralization of previous w ork b y an order of magnitude, but also pro duces b etter qualit y results. [1] R. Agra w al and R. Srik an t. F ast algorithms for mining asso ciation rules. Pr o c. 20th VLDB , 1994. [2] R. Agra w al, J. Gehrk e, D. Gunopulos, and P .
Ragha v an. Automatic subspace clustering of high dimensional data for data mining application . Pr o c.
A CM SIGMOD , 1998. [3] R. Srik an t and R. Agra w al. Mining quan titativ e asso ciation rules in large relational tables. Pr o c. A CM
SIGMOD , 1996. [4] W. W ang, J. Y ang, and P .Y u. Ecien t mining of w eigh ted asso ciation rules (W AR). IBM R ese ar ch R ep ort
R C 21692(9773 4) , Marc h, 2000.
