 When using simple dictionary translations without addressing the problem of translation ambiguity, the effectiveness of cross-language information retrieval (CLIR) can be 60% lower than that of monolingual retrieval [1]. Translation ambiguity stems from the fact that many words do not have a unique trans-lation, and sometimes the alternate translations have very different meanings. This problem is particularly severe in view of the observed tendency of web users to enter short queries; it is difficult for even a human to reliably determine the intended meaning from the available context. The dictionary-based translation approaches are prone to error due to the likelihood of selecting the wrong transla-tion of a query term among alternatives provided by the dictionary. Techniques, that use statistics obtained from training corpora have been proposed to reduce the ambiguity and errors introduced during query translation. However, use of different data sets and language pairs has meant that it has not been possible to draw clear conclusions about the relative merits of the different disambiguation techniques. By using the same data sets, we aim to compare and understand the merits of the different disambiguation techniques. Amongst the various approaches to CLIR, translation of the query language to that of the document language has been most commonly used, and researchers have applied dictionary-based translation methods with success. Web queries are generally short, and thus sophisticated natural language processing techniques can flounder due to lack of context. However, any dictionary-based technique must address the fact that many words have multiple translations. This dis-ambiguation phase is crucial to the transl ation result. Interestingly, researchers have used different disambiguation techniques utilizing statistics obtained from the test collection, all seemingly with good results. These have included us-ing term similarity [2], co-occurrence statistics in the target document collec-tion [1,3,4,5,6], and probabilistic methods based on a language model [7,8].
As these previous experiments were generally carried out on different test collections, it is unclear whether any particular approach is superior. The goal of this work is to compare the effectiveness of these techniques on the same data sets. We first review the different approaches that have been used. 2.1 Term Similarity Adriani [2] proposed a disambiguation technique based on the concept of sta-tistical term similarity. A term-similarity matrix was built using the statistical term-distribution parameters obtained from the corpus terms. The term similar-ity is obtained using the Dice similarity coefficient (DSC)  X  a term association measure commonly used in clustering. The term similarity value between term x and y ,SIM( x, y ), is calculated as follows: where The term weight w xi of term x in document i is computed using the stan-dard tf.idf weighting formula. This algorithm computes the sum of maximum similarity values between each candidate translation of a term and the trans-lations of all other terms in the query. They used one document as the win-dow of co-occurrence. For each query term, the translation with the highest sum is selected as its translation. The results of their Indonesian X  X nglish and English X  X ndonesian CLIR experiments demonstrated the effectiveness of this dis-ambiguation technique. Gao at al. [3] employed a similar approximate algorithm for choosing optimal translations in English X  X hinese CLIR. 2.2 Term Co-occurrence Ballesteros and Croft [1] used co-occurrence statistics obtained from the target corpus for translation disambiguation. Their hypothesis is that the correct trans-lations of query terms should co-occur in target language documents and incorrect translations should tend not to co-occur. Other studies including [4,5,6] also used similar approaches to select the best translation(s). Building on the work [1,4,6], Gao et al. [3] observed that the correla tion between two terms is stronger when the distance between them is shorter. They extended the previous co-occurrence model by incorporating a distance factor D ( x, y )= e  X   X  (Dis( x,y )  X  1) .Themutual information (MI) between term x and y ,MI( x, y ), is calculated as follows: where f w ( x, y ) is the frequency with which x and y co-occur within a window size of w in the collection; f x is the collection frequency of x ;and f y is the collection frequency of y . D ( x, y ) decreases exponentially when the distance between two terms x and y increases, where  X  is the decay rate, which is empirically set as 0 . 8;andDis( x, y ) is the average distance between x and y in the collection. They experimented on the TREC-9 Chinese collection and showed that the addition of the distance factor leads to substantial improvements over the basic co-occurrence model. 2.3 Language Modelling Given a query s 1 ,s 2 ,s 3 ..., s n , each translation candidate set T is a sequence of words t 1 ,t 2 ,t 3 ..., t n . In previous work [8], we used a probability model P ( T )= P ( t 1 ,t 2 ,t 3 ..., t n ) to estimate the maximum likelihood of each sequence of possible translations and selected the translation set T with the highest prob-ability value P ( T ) among all possible translation sets. Our disambiguation tech-nique is based on a bigram hidden Markov model (HMM), such models have been used widely for probabilistic modelling of sequence data: To compute the probability of a sequence of words, we need to calculate the quantities P ( t ), the probability of word t ,and P ( t | t ), the probability of t in the context of t , as follows: where f ( t ) is the collection frequency of term t , N is the number of terms in the document collection, and P w ( t, t ) is the probability of term t occurring after term t within a window of size w . The zero-frequency problem arises in the context of probabilistic language models, when the model encounters an event in a context in which it has not been seen before. Smoothing provides a way to estimate and assign the probability to that unseen event. We use the following absolute discounting and interpolation formula, which applies the smoothing method proposed by [7]. In this method, where f w ( t, t ) is the frequency of term t occurring after term t within a window size w . [7] successfully used this formula to compute the frequency of term t and t within a text window of fixed size through an order-free bigram language model in Italian X  X nglish CLIR. The absolute discounting term  X  is equal to the estimate proposed by [9]: where n k is the number of terms with collection frequency k . To test the effectiveness of Chinese X  X nglish CLIR using the different techniques described in Section 2, we conducted a set of experiments using the data sets of NTCIR 4 and 5. A Chinese topic contains four parts: title , description , narrative , and key words relevant to the whole topic. We chose to use the titles of the Chinese topics only as queries for two reasons: first, ambiguity problem is often resolved implicitly when queries are long enough (the additional words provide sufficient context to resolve confusion) but is still a critical problem when queries are short [10]; second, web queries are often short, and the average length of the titles approximates the web queries.

Our experiments consist of four runs: a mono-lingual reference in RUN mono , the term similarity technique in RUN ts , the term co-occurrence technique in RUN tc , and our technique based on a HMM in RUN lm .Ourexperimentsused the Lemur IR system 1 developed by the Computer Science Department at the University of Massachusetts and the School of Computer Science at Carnegie Mellon University.

The relevance judgements provided by NTCIR are at two levels  X  strictly relevant documents known as rigid relevance , and documents that are likely to be relevant, known as relaxed relevance . In this paper, we used the rigid relevance judgements provide by NTCIR to report our results. A comparison of the characteristics of several translation disambiguation tech-niques is tabulated in Table 1. The term similarity technique uses both tf and idf , and selects the best translation of each query term from multiple candi-dates by comparing their statistical associations with the candidate translations of all other query terms within each document. The term co-occurrence technique makes use of tf and of the frequency of terms co-occurring within a window size of w in the collection. In addition, a distance factor is incorporated to discrimi-nate strong and weak term correlation. Our language modelling technique uses tf and the frequency of terms co-occurring within a window size of w together with an absolute discounting model for smoothing. When using a bigram HMM language model, only the co-occurrences of the candidate translations of adjacent query terms are considered. Interestingly the language modelling disambiguation technique increases in complexity in accordance with the product of the number of possible translations for each query term, and thus becomes impractical for longer queries. Each of the techniques uses different models, formulae and para-meters; nonetheless each achieved compar able results across multiple data sets, asshowninTable2.

We used a t-test to analyze the statistical significance of our results. These re-sults suggest that there is no significant difference in the overall effectiveness on the data sets tested. However, analysis of the individual queries reveals a differ-ent story. Of the 93 NTCIR 4 and 5 queries with ambiguity (at least one query term has multiple translations), the three different disambiguation techniques produced the same translation in only 19% of the queries (10 out 50 NTCIR-4 queries and 8 out of 43 NTCIR-5 queries), and manual inspection showed that these were indeed correct translations. In the other 81% of queries with differing translations, there was often significant difference in the average precision results for each of the approaches. An indicative sample of the differing results for the 50 NTCIR-4 ambiguous queries is shown in Figure 1. In some cases there were only minor differences in average precision. For example, in query 40, the Chinese term in appr o pr i ate tra n s l at ion. Fo re x amp l e ,in quer y30 X   X  X  X  X  X  X  X   X , the term This research has shown that, superficially, all these translation disambigua-tion methods are comparable (no significant difference) when averaged across a query set. However, at the individual query level, each of the techniques fre-quently produce differing results. This means that it may be possible to develop a new approach that combines the best elements of these current methods. At the very least, it should be possible to use a  X  X ombination of evidence X  ap-proach [11] to improve the overall translation quality. Further, when all meth-ods produce the same translation, we can have a higher degree of confidence in the correctness, and differing translations could act as a trigger for further analysis.
