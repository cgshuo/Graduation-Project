 In recent years, community structure has attracted increasing atten-tion in social network analysis. However, performances of multifar-ious approaches to community detection are seldom evaluated in a suite of systematic measurements. Furthermore, we can hardly find works which reveal diverse features based on the detected commu-nity structure. In this paper, we build a tool called CoDEM to make both quality evaluations of community detection and an in-depth mining for pivotal nodes inside communities. This tool integrates several effective approaches to community detection, establishes an overall evaluation system and gets the multi-dimensional rank-ing for the local importance of nodes. Moreover, the tool is built with a friendly user interface.
 H.3.3 [ Information Search and Retrieval ]: Clustering; D.2.8 [ Software Engineering ]: Metrics X  complexity measures, performance mea-sures Community Detection, Evaluation, CoDEM
Social networks usually possess inherent communities where mem-bers cluster together to form closely connected groups. Revealing latent community structure is a crucial problem in social network analysis. It also leads to advances in various social network ser-vices and applications. Considering the diversity of datasets and various perspectives to address this issue, it is a puzzle to choose a best-performed approach from the abundant candidates. Although a comparative study [8] has been proposed recently, up to now, we do not have a suite of systematic evaluation metrics to make a com-prehensive comparison based on the quality of the community as-signment. Moreover, to explore the formation and evolution of the  X  Corresponding author: Chaokun Wang.

The major functions of our CoDEM have been implemented in standard C++; the data-driven technique D3 3 is adopted for the vi-sualization. According to the system function and workflow, Co-DEM consists of four basic modules: Displayer, Processor, Evalu-ator and Graph Storage (as shown in Fig. 1) . They can be mapped to different system layers, and we will introduce them in further detail below.

User Access Layer . The included Configurator covers selections and requisite parameters of algorithms as well as the customized evaluation metrics. The overall setup will be sent out for both de-tection and evaluation. Displayer itself also accepts and presents the produced results from the evaluation layer in various views, such as table, diagram and multiple graph displays.

Core Processing Layer . The Core Detector is mainly respon-sible for the implementation of community detection approaches. Apart from that, the detector is extendible and any other method can be implemented in it easily. The Inner Miner aims at finding the pivotal nodes inside a community by a series of node centrali-ties ( degree , betweenness , closeness and PageRank ). Considering the customized centralities, the ranking of nodes inside the com-munity can be obtained by the Fagin algorithm as an example.
Core Evaluation Layer . With insight into community detection, the Evaluator covers both effectiveness and accuracy. In CoDEM, comparisons are made in this layer based on the customized met-rics which are reasonable, recognized and comprehensive enough. Then, evaluation results upon different metrics of all approaches are integrated and ultimately organized from multiple views.
Data Storage Layer . Any network in a certain format can be im-ported from the browser; the same as the ground truth file if we have one. Datasets here consist of two parts. First, we use the well-known datasets which have the corresponding ground truth, such as Karate-Club, Strike and Football-NCAA. Moreover, we also use large-scale networks in the Stanford Large Network Dataset Col-lection 4 . The established graph model records attributes of nodes and edges in the whole detection and evaluation process.
CoDEM consists of two prime processes: 1) evaluating the de-tected communities; 2) mining the keynodes inside them.
Many approaches are proposed along with the performance test by the only criterion. In addition, many former evaluations have overfull dependence on the ground truth. Actually, we have con-fronted two problems in this field: 1) In practice, we can hardly know what the exact community assignment is in the real world; 2) The single criterion cannot represent the performance of an ap-proach objectively. Therefore, in CoDEM, metrics from multiple aspects are employed to make the evaluation of community detec-tion.

Modularity [2] is the most widespread quality function for com-munity detection. Essentially, modularity compares the result with a randomized one to indicate how reasonable the nodes are assigned http://d3js.org/ http://snap.stanford.edu/data/
In this section, an example is given to demonstrate how CoDEM works.

Setup . First, on the setup page, we can upload a network file, e.g. Strike, as well as the available ground truth. Then the basic information will be shown in the right information bar. We can find that the network has 24 nodes and 76 relationships and it is an undirected network with weight=1 on each relationships. Then, we can make a personalized setup since approaches in the category lists, requisite parameters and evaluation metrics are all customiz-able for users. Note that some approaches assign each node to a certain community. However, in social network theory, the entire network always consists of grouped members and independent out-liers. Therefore, based on the results by algorithms, we can set the global filter to 2 to eliminate tiny groups, making the evaluation more fair and reasonable.

Display for Evaluation . After clicking the button  X  X ompare X , the integrated evaluation results can be shown in the  X  X able X  view (Fig. 3). We can get the overall results and find which approach stands out clearly w.r.t. the current dataset. Results, including mod-ularity, strength (percentages of strong and weak communities), maximal clustering coefficient, purity and time cost, of different ap-proaches from various perspectives are shown together. Therefore, we can make full use of the information to analyze the differences among various kinds of approaches. We can find that label propa-gation algorithms perform better on this dataset. Furthermore, his-tograms in the  X  X hart X  view can intuitively rank the approaches according to a specific metric so that the variances in the aspect can be shown clearly.

Entries for Details . If we want to find some more details about the results, we can utilize the entries for details. In Fig. 3, if we click the first yellow button  X  X how Graph X , the detected communi-ties in both the  X  X ommunity X  view (Fig. 4(b)) and the  X  X elation X  view (Fig. 4(a)) will be shown. The former clearly presents the community structure and the latter shows the assignment in the re-lational graph by different colors. In Fig. 4, we can find that the result of the original label propagation algorithm is nearly consis-tent with the ground truth. If we click the next button  X  X etail Ta-ble X , details about each community, including the size, members, strength (labeled as  X  X trong X ,  X  X eak X  or  X  X either X ) and the cluster-ing coefficient will be shown. Combined with the above results, we can make a comparison of these approaches intuitively. Sup-pose that an approach performs terribly in modularity, we may find that the color distribution is scattered in the relation view. If an approach reacts badly in most cases, we may think that it does not perform well enough.

Keynode Mining . The right-most button  X  X how KeyNodes X  links to the other page to mine keynodes inside each community. After
