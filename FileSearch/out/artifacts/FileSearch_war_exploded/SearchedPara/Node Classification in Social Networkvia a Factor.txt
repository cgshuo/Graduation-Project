 With the success of many large-scale online social networks these years, such as Facebook, Tweeter, Weibo, social network has become a bridge between the virtual web world and our daily life. Weibo, one of the largest and most influ-ential social networks in China, has more than 300 million active users in 2012. Consequently, Network ideas have been a pplied successfully in many areas such as Internet (pages) [3][8], coauthors[19], mobiles and mails[5]. Considerable re-search has been conducted on social network analysis, such as social influence analysis[6][18], community structure learning[18][1][14], and of course node clas-sification in social network[4][15][7][10].

As is usual in machine learning, we first have to identify some features of nodes that can be used to guide the classification. The obvious features are properties of the node itself. For online social network like Weibo, information that may be known for all (or most) nodes, such as age, location, and some other profile information is usually considered first. For coauthor network, people may take authors profile, publish year as features. More than that, some latent features such as topic model become more and more popular in network analysis, these latent features reflect user character quite well. But in a network structure, the presence of an explicit link structure makes the node classification problem dif-ferent from traditional machine learning classification tasks, where objects being classified are considered independent. In contrast to the traditional classification, we should first think about the network topology, the neighbors label information may be very important and decisive. The social sciences identify two important phenomena that can apply in social networks:  X  homophily , when a link between individuals (such as friendship or other  X  co-citation , regularity is a related concept, which holds when similar indi-Macskassy and Provost used a simpler cl assification method based on taking a weighted average of the class probabilities in the neighborhood (wvRN)[11]. This classifier is based on a direct application of homophily and uses the immediate neighborhood of a node for classification. Another classifier, which is similar with wvRN, is called the Class-Distribution Relational Neighbor (CDRN)[12], it also considered on the distribution of the neighbors only. There were many works about using random walk on node classification, but most of them concerned about the labels of neighbors. Pennacchiotti and Popescu[15] used a machine learning algorithm with hundreds of features in twitter data, but they simply take network topology as some features in a traditional classifier.
In this work we address the task of node classification in social networks, our main contributions are the following:  X  We employ a factor graph model to classify nodes in networks, using topic  X  We conduct experiments on two data sets (DBLP coauthor and Weibo) and  X  We provide an in-depth analysis of experiments on the partially-labeled data The rest of this paper is organized as follows. Section 2 formally formulates the problem. Section 3 explains the factor graph model we used. And then in section 4 we discuss the experiments and evaluation. Finally, in Section 5 we draw final conclusions and outline future work. In this section, we first give several necessary definitions and then present the problem formulation.
 Definition 1. Social network: A social network can be represented as G = ( V,E ) ,where V is a set of | V | = N users. E  X  V  X  V is a set of | E | = M relationships between N users.
 As we know, Social relationships might be directed in some networks (e.g., A follow B in Weibo) or undirected in others (A and B are coauthors in DBLP). In this work, we make the relationship as factor and ignore whether it is directed or undirected, the number of relationship types is what we only concern about. In some situations, the network can be defined in more than one way, such as in DBLP coauthor network: take each author as a node, coauthor may be a relationship; we can also take each paper as a node, two papers have common author may be a relationship. Which one should we choose is depend on the specific task, in this work, we choose the latter.

In real networks, it is difficult to cost much time and energy to label every node, the labeled data is always less than expected, so naturally, we define the input of our problem, a partially labeled network.
 Definition 2. Partially labeled network: A partially labeled network is an aug-mented social network represented as G =( V L ,V U ,E,Y L ,W ) ,where V L is a set of labeled nodes while V U is a set of unlabeled nodes with V L V U = V ; Y L is a set of labels corresponding to the node classes in V L ; W is an weight matrix associated with users in V where each row corresponds to a user, each column an attribute, and an element w ij denotes the value of the j th attribute of user v i . In our work, we choose a topic model called PLSA (Probabilistic Latent Semantic Analysis)[9] to analysis the text about each node as attribute. The PLSA model assumes that there are k topics in the corpora, where k is a fixed parameter, and every document in the corpora corresponds to one distribution of topics. This is a hierarchical model. We can desc ribe its generative process as:  X  Select a document d with probability P ( d ) ;  X  Pick a latent topic z with probability P ( z | d ) ;  X  Generate a word w with probability P ( w | z ) .
 For example, we use PLSA to analysis the microblogs of every user in Weibo, and w ij represents the probability of user v i belongs to j th topic.
Based on the above concepts, we can now define the problem of node classifi-cation in social network. Given a partially labeled network, the goal is to detect the classes (labels) of all unknown nodes in the network. Formally, Target 1. Node classification in social network: Given a partially labeled network G =( V L ,V U ,E,Y L ,W ) , the objective is to learn a predictive function The above formulation make our work very different from existing work on node classification. Macskassy, C. Perlich and Desrosiers[4][11][12] had done some con-structive work about relational learning algorithm, but they only concern about the relationships in network. Pennacchiotti[15] tried many features about each node, even treated relationship as some features, but he ignored the network topology. Actually in social network analysis, there are some works about utilizing graph model.Forexample,Tang[17]usedafactorgraphmodeltoinfersocialties;Yang[18] proposed a factor graph model too, their worksfocused on representative-userfind-ing and community-structure discovery.In this section, we explain the factor graph model we use to classify nodes in social network. 3.1 Basic Domain Criterions For inferring label of nodes in social network, we have three basic criterions from our specified domain knowledge.

First, users from different classes may have different topics while in same class may have similar topics. For example, if two users come from the same company, they may have similar microblogs in Weibo which talk about their works or about their company. Second, the relationships may have a correlation in classification. For example, in DBLP network, if two papers have at least one common author, they probably belong to th e same research are a (e.g., artificial intelligence, database and so on).
 And last, different relationship types may lead to different kinds of effects. For example in Weibo, user A follows user B but B doesnt follow A back, this is a relationship type; user A follows user C and user B also follows C, this is another relationship type between A and B, obviously, these two relationship types are quite different, and of course it will influence the classification model. 3.2 A Factor Graph Model with Partially-Labeled Data Based on the above observations, we then describe the proposed factor graph model in details.

As we can see in figure 1, it is a small network with 4 nodes v 1 ,v 2 ,v 3 ,v 4 and some relationships between these nodes. Corresponding to the factor graph model, we have 4 hidden vectors y 1 ,y 2 ,y 3 ,y 4 and the nodes attribute factor. To deal with multiple relationship types, we should have multiple relation factors. Actually, we use at most 2 relation factors in our experiments, but in theory, we can use as many relation factors as possible. The definitions of the factors are as follows:  X  Attribute factor: f ( y i ,w i ) represents the posterior probability of the rela- X  Relation factor 1: g ( y i ,y j ) denotes a relationship of node y i and y j ;  X  Relation factor 2: h ( y i ,y j ) denotes another relationship of node y i and Given a partially-labeled network G =( V L ,V U ,E,Y L ,W ), based on the defini-tion of factor graph model, we can have the joint distribution over Y as where N 1 ( y i )and N 2 ( y i ) are sets of neighbors of y i . The three factors can be instantiated in different ways. In this work, we use exponential-linear functions. Particularly, we define the attribute factor as where  X  is a weighting vector that will be learned in the model and  X  is a vector of feature functions. Similarly, we denote the relation factor as where  X  and  X  is similar with  X  , g and h can be defined as a vector of indicator functions. 3.3 Model Learning and Parameter Inference Learning this model is to estimate a series of parameters  X  =(  X , X , X  )andmax-imize the log-likelihood of observation information (labeled nodes). For simple presentation, we concatenate all factor functions for y i as The joint probability can be written simply as where Z = Z  X  Z  X  Z  X  is a normalization factor, and S is the combination of factor functions of all nodes.

Since the input data of this model is partially-labeled, to calculate the nor-malization factor Z , we need to sum up the likelihood of possible states for all labeled and unlabeled nodes. Naturally, we think of using the labeled data to infer the label of unknown nodes. Then, we have the objective function as Where Y | Y L denotes inferring label of Y from Y L . To solve this problem, we use a gradient decent method to cal culate the partial derivative of  X  Since the social network can be arbitrary graphical structure, our factor graph model may have many circles, so it is intractable to calculate the expectation in a directed and exact way. To alleviate t he cost of computation, some kinds of approximate algorithms have been proposed such as LBP (Loopy Belief Propa-gation)[13] and MCMC (Markov Chain Monte Carlo)[16]. In this work, we utilize LBP to calculate the marginal probabilities.

LBP is simply to apply the sum-product algorithm even though there is no guarantee that it will yield good results[2]. It is possible because the message passing rules for the sum-product algorithm are purely local. However, because the graph now has cycles, information can flow many times around the graph. For some models, the algorithm will converge, whereas for others it will not.
After completing the calculation of the marginal probabilities, the gradient can be obtained by summing over all nodes, and then we update each parameter withalearningrate  X  and the gradient.
 3.4 Infer Unknown-Label Nodes and Classify Finally, we can infer the category of unknown-label node. Based on the learned parameters  X  , we can predict the label of each node by finding a label configu-ration which maximizes the joint probability as In the same way, we use LBP to calculate the marginal probability of each node p ( y i | Y L ,G ), then we can put one node into the class which has the maximum marginal probability. In other words, the marginal probability is taken as the prediction confidence. The model we use to classify nodes is general and can be used in many different situations. In this section, we present our experiment results on two different data sets with multiple tasks to evaluate the effectiveness of our model. 4.1 Data Sets DBLP Coauthor Network. This benchmark data set contains more than 50000 papers published at 22 computer sc ience conferences from 2008 to 2010. These conferences can be mainly divided into five research areas:  X  AI: artificial intelligence, including IJCAI, AAAI, ICML, UAI and NIPS;  X  DB: database, including EDBT, ICDT, ICDE, PODS, SIGMOD and VLDB;  X  DP: distributed and parallel computing, including ICCP, IPDPS and PACT;  X  GV: graphics, vision and HCI, including ICCV, CVPR and SIGGRAPH;  X  NC: networks, communications and performance, including MOBICOM, IN-In this data set, the objective is to classify papers into the correct research area. We extract some subsets randomly for three tasks:  X  6000 papers with 3000 papers published in GV (positive set) and 3000 in  X  6000 papers with 3000 papers published in NC (positive set) and 3000 in  X  10000 papers with 5000 papers published in AI (positive set) and 5000 in Weibo Network. As our previous introduction, Weibo is a very large online social network with 300 million users. We extract some small experiment data from Weibo by crawler. In Weibo data, we have two binary classification tasks as:  X  Company Affiliation: 600 users with 305 belong to a specific company  X  Domain Affiliation: 3231 users with 1580 positive users whose study do-4.2 Experiment Description and Evaluation In the DBLP data set, we make each paper as a node, if two papers have at least one common author, we treat this relationship as an edge. In DBLP data, we simply use one relationship type. In Weibo data set, we treat each user as a node, if a user follows another user, we put an edge between them. More in Weibo data, we consider about the relationship of following common users (e.g. two users follow at least 5 common users) and make it as another edge factor.
In both two data sets, we use PLSA to get the topic model of each node as the node features. Actually, we set the number of topics as 20.

To compare our approach with the traditional methods, we carried out the representative algorithms such as wvRN, CDRN, LibSVM on the same data sets:  X  wvRN: a simply neighbor-voted classifier, consider about the relationship  X  CDRN: similar with wvRN, it uses the probability distribution of neighbors  X  libSVM: a traditional classification algorithm, using node features to clas-To quantitatively evaluate the model we use, we consider three aspects:  X  Results Analysis (Basic Experiment): we try to prove the effectiveness  X  The Influence of Labeled Data Size: since our method is semi- X  Discussion on Multiple Relationship Types Setting: we consider For the classification performance, we ev aluate the approaches in terms of accu-racy, precision, recall, and F1-score.
 4.3 Accuracy Performance Basic Experiment. Table 2 lists the accuracy performance of classifying nodes in DBLP data with three tasks by the different methods. All these three tasks, the labeled data is 10% of each subset.

As we can see from the results, our method consistently outperforms other comparative methods on all the three tasks in DBLP data. In terms of F1-score, our model is 5%  X  12% better than libSVM, 30%  X  40% better than wvRN andCDRN.WenoticethatwvRNandCDRN,whicharefocusonthelabelsof neighbors, get very high precision scores, even better than our model, but their recall scores are really poor, and their F1-score are much worse than libSVM and our model, so wvRN and CDRN dont classify the nodes well. Actually, these two methods classify most of the nodes into negative set.
 Different Size of Labeled Data. We have known that in DBLP data, our model perform much better than other s and either wvRN or CDRN has a poor result. One of the reasons maybe the labeled data is only 10%. Based on the above assumption, we have some experiments on company affiliation using Weibo data, the classification objective is estimate w hether a user is from a specific company or not. We test the size of labeled data from 10% to 90%, and the results are shown in figure 2.

From the results shown in figure 2, we can find some interesting points. When labeled data are 10%, our model is 11 . 9% better than libSVM, about 30% better than wvRN and CDRN in F1-score; on accuracy score, our model is also 10% better than others. When labeled data are 50%, on F1-score, our model is still 11 . 8% better than libSVM, and about 35% better than wvRN and CDRN; on accuracy score, our model is more than 20% than others. When labeled data are 90%, our model is 11 . 7% better than libSVM and more than 25% better than wvRN and CDRN on F1-score; on accuracy score, our model is more than 15% better than others. More notably, ei ther F1 or accuracy, the score of our method increases smoothly and almost monotonously when the size of labeled data increases, while other methods shak e obviously. It denotes that our model is much stronger and more effective no matter how many data are labeled. Multiple Relationship Types. We now evaluate the performance of multiple relationship types. Table 3 shows the result of our experiment on both company affiliation and domain affiliation in Weibo data, where our model(S) denotes using just single relationship type, Our model(M) denotes using multiple rela-tionship types, the size of labeled data is set 10%.

As we can see, our method is much better than other methods, although in domain affiliation, libSVM has 1% better than our model in terms of accuracy score, the F1-score of our model is much higher than others (at least 10%). Considering the multiple relation types, the accuracy scores are improved by 0 . 1% and 1 . 4% in two tasks while the F1-scores are improved by 1% and 0 . 7%. It suggests that multiple edge features do add value to our classification model. In this paper, we study the problem of node classification in social network, which is an interesting but challenging research domain. We use a factor graph model with semi-supervised learning to infer the category of unlabeled data. In our model, each node in social network is modeled as variable node and various relationships are modeled as factor nodes. In this way, this model can take the advantages of both node features and graph information. Experiments on the different data sets validate the effectiveness of the model we use. It outperforms both model of pure node features (libSVM) and model of pure relationships (wvRN, CDRN).

Node classification in social network is a potential research direction in social network analysis. As future work, since many networks have multiple categories, extending our method to multi-class classification will be quite useful. Consider-ing it is intractable to simply modify the objective function, we should use some indirect approach such as one-against-one to solve the multi-class classification, for example, if there are k categories, we need k ( k +1) / 2 classifiers and vote for each unlabeled node. In addition, the online social network becomes larger and larger, it is interesting to study some fast but effective method for huge networks.
 Acknowledgment. The work was Supported by the Upgrading Plan Project of Shenzhen Key Laboratory (No. CXB201005250038A) and The Shenzhen Key Technology R&amp;D Program (No. ZD201010210080A, No.JCYJ20120619153002947). In addition, we thank the anonymous reviewers for their very valuable comments and suggestions.

