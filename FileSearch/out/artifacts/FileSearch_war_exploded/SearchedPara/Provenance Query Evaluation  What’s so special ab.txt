 While provenance has been extensively studied in the literature, the efficient evaluation of provenance queries remains an open prob-lem . Traditional query optimization techniques, like the use of general-purpose indexes, or the materialization of provenance data, fail on different fronts to address the problem. Therefore, the need to develop provenance-aware access methods becomes apparent.
This paper starts by identifying some key requirements that are to a large extent specific to provenance queries and are necessary for their efficient evaluation. The first such property, called dual-ity , requires that a single access method is used to evaluate both backward provenance queries (which input items of some analysis generate an output item) and forward provenance queries (which outputs of some analysis does an input item generate). The second property, called locality , guarantees that provenance query evalu-ation times should depend mainly on the size of the provenance query results and should be largely independent of the total size of provenance data. Motivated by the above, we identify proper data structures with the aforementioned properties, we implement them, and through a detailed set of experiments, we illustrate their effectiveness on the evaluation of provenance queries.
 H.2.4 [ Database Management ]: Systems X  Query Processing Algorithms, Performance
In a number of domains, like healthcare and finance, an abun-dance of data threaten to overwhelm users. In healthcare, patient monitoring sensors (e.g., blood-pressure, electrocardiogram) pro-duce several kilobytes of physiological readings per second, while typical rates of stock market ticks in finance approach 5,000 ticks/sec. The domain users (e.g., clinicians, brokers) do not have the physi-cal capacity to (post-)process such volumes of raw data. Therefore, special-purpose analytics are commonly used to filter the raw data (either in real-time or offline) and only expose to the users certain significant events. Examples of such events include medical patient alerts, in healthcare, or stock buy/sell recommendations in finance.
To decide the merit of an event and how to act upon it, users must know its provenance [5] ( a.k.a. lineage [8], or pedigree ). This in-cludes both the analytics workflow graph that resulted the event (a.k.a. workflow provenance [10]), and the raw and intermediate analysis data used by these analytics (a.k.a. data provenance [19]). So, a clinician receiving an Angina Pectoris alert (by the medi-cal analytics graph of Figure 1(a)) must retrieve through a work-flow provenance query the subset of the graph that contributed to its generation (this is the graph of Figure 1(a) minus the WB and PH nodes). For a Prehypertension alert, the clinician must retrieve through a data provenance query all the blood-pressure readings contributing to the alert. Prehypertension alerts are generated by the PH node in Figure 1(a), using the following procedure: with 4 readings in every 3-hour epoch (readings and alerts in Figures 1(b) and (c) that are in the same epoch are colored alike), the PH node generates an alert at the end of an epoch when any of the readings in the middle of an epoch (the 2 nd or 3 rd reading) has a systolic pressure larger than 135mmHg. Intuitively, assuming medication is administered to a patient at the beginning of each 3-hour epoch, the above checks whether the medication affects a patient X  X  blood pressure (where medication effects are assumed to be more visi-ble in the middle of each epoch, when medication is more active ). Given the above, a data provenance query for the alert with id 202 should return the reading with id 110, while for the alert with id 203 it should return the readings with id s 114 and 115. These are exam-ples of a backward data provenance query where given the output (e.g., medical alert) of some analysis, the query retrieves all the inputs (and intermediate results) contributing to its generation. Of equal importance, a forward data provenance query considers the input of an analysis (e.g., a blood-pressure reading) and retrieves the alerts (if any) generated in part due to this input. For example, for the reading with id 105 no alert is retrieved by such a query since this being the first reading in an epoch, it generates no alert, while for the reading with id 102 the alert with id 201 is retrieved.
All these (workflow/data/forward/backward) provenance queries must access the persistent raw data (e.g., blood-pressure readings, alerts) and possibly auxiliary provenance data [2, 11, 18]. Although we already made a point about the size of these raw data, auxiliary provenance data should not be overlooked since their size can be orders of magnitude larger than the raw data [6]. Yet, data size is only one of the factors that influence the efficiency of provenance queries, currently an open problem [9] in the provenance litera-ture. In what follows, we investigate other factors that affect prove-nance query performance, and we show (a) what makes provenance queries special (compared to normal queries); and (b) why tradi-tional optimizations techniques are inadequate in this context.
Hereafter, we focus on (forward/backward) data provenance queries which are characterized as fine-grained [19], when compared to workflow provenance queries, since the data required/accessed while answering the former queries are expected to be orders of magni-tude more than those for the latter. Therefore, efficiency is more imperative for the data provenance queries. Yet, our work is appli-cable to workflow provenance queries as well (see Section 7). Provenance encoding queries: One alternative to evaluate prove-nance queries is to use the SQL language to encode the provenance relationship between raw data. For example, queries Q 1 and Q in Figure 2(a) encode the provenance relationship between blood-pressure readings and Prehypertension alerts from Figures 1(b) and (c). In more detail, query Q 1 is a backward provenance which given the timestamp of an alert the query (a) identifies the blood pres-sure readings in the corresponding epoch (in the nested sub-query resulting relation T 1 ); (b) isolates the 2 nd and 3 rd epoch (in the nested subqueries producing T 2 and T 3 ); and (c) re-turns those readings with a systolic pressure larger than 135mmHg. Query Q 2 is a forward provenance query and is indeed more com-plex than query Q 1 . Given a reading, query Q 2 initially retrieves any alert that results in at the end of the epoch the reading belongs to (in T 1 ). This alert is not necessarily caused by the input reading since it might not have a systolic pressure larger than 135mmHg. Even if this check succeeds, the query still needs to check whether this is the 2 nd or 3 rd reading in the epoch (this check requires es-sentially evaluating query Q 1 as a nested query of Q 2 ). If either of these two checks fails, query Q 1 returns the empty result.
A common trend in the SQL encoding of provenance queries is that the resulting queries are complex, often with several nested sub-queries [11, 18]. Therefore, they are expensive to evaluate and hard to optimize, even by sophisticated optimizers. Coupled with large data sets, such queries suffer from poor performance. Customized indexes, like the ones in MMS [18] or later in Mon-drian [15], improve efficiency. However, not being generic, these indexes are only applicable to the specific provenance models. Materialized provenance queries: Often, it is impossible to en-code provenance relationships in SQL . Full fledged programs in C or Java are commonly used as the logic of an analytics node. The complexity of such programs cannot always be captured accurately by SQL . In such situations, a common alternative is to materialize the provenance relationships between the data. For example, rela-tion BP2Alert in Figure 1(d) explicitly lists the readings with their resulted alerts. Given this relation, evaluation of backward/forward provenance queries essentially amounts to evaluating simple SQL queries like Q 3 and Q 4 (shown in Figure 2(b)).
 Obviously, this approach requires (a) to persist a relation like BP2Alert , and (b) to create/maintain a separate index for each of the attribute columns (e.g., B+-trees, hash indexes), to efficiently eval-uate queries Q 3 and Q 4 . In the literature, models for data prove-nance like DBNotes [2] and the initial version of Mondrian [11] employ this alternative and rely essentially on materialization and general-purpose indexes to answer provenance queries. An ob-vious shortcoming of materialization is that it requires additional space. Furthermore, we must maintain (at least) two separate in-dexes to support both forward and backward provenance queries, since generic indexes are inherently directional : Given an alert, a generic index retrieves all the blood pressure readings in BP2Alert that are associated with the alert. However, starting from a reading we cannot use the same index to retrieve its generated alerts. Only an index structure that exhibits a bi-directional ( duality ) property can support both types of queries at the same time.

To address the shortcomings of these alternatives, we identify existing data structures whose properties make them suitable for provenance query evaluation. Our contributions are: 1. To our knowledge, this is the first work identifying the unique characteristics and common requirements of provenance queries across a wide spectrum of provenance models. It is this set of re-quirements (e.g., duality, locality) that provides the foundation and drives any technical development in building a framework to sup-port efficient provenance query evaluation. 2. In Section 2, we make the connection between the require-ments of provenance queries and the properties of an index struc-ture originally developed for efficient text indexing [12, 1]. Then, we adapt the index for provenance query evaluation (in Section 3). Unlike generic indexes (like B+-trees or hash indexes), we show that this structure has several desirable provenance-related prop-erties (e.g., duality ). To our knowledge, no index in the existing literature exhibits these properties. 3. We present extensions of the original structure not considered in the text indexing setting. Specifically, we show how to incremen-tally maintain the index (in Section 4) and we propose (in Section 5) two orthogonal optimizations, namely, (a) a provenance-aware in-dex decomposition into sub-indexes that reduces both memory con-sumption and cpu utilization; and (b) a compression technique to reduce the index memory footprint. 4. Our final contribution (in Section 6) is the first implementation and deployment of the theoretical constructs in [12, 1], that also includes the customizations and extensions presented here.
The next two sections present key concepts from [12, 1] and show how these are used in the evaluation of provenance queries. Objects and Labels: We use the abstract concepts of objects and labels to denote the two data sets having a provenance relationship (e.g., blood-pressure readings and Prehypertension alerts). Rank and Select: Consider a symbol s in an alphabet S and a vec-tor V of symbols from S . For a position i of V , rank ( s, i ) returns the number of occurrences of s before position i . For a number j , select ( s , j ) returns the position of the j th occurrence of s in V . X-fast trie: Let N be a set of indexed values. An X-fast trie [21] is a binary trie where indexed values appear as leaves. For a non-leaf node d at height h of the trie, all descendant leaves of d , denoted as Desc ( d ), have values between i  X  2 h and ( i  X  2 h )  X  1 , for some integer i , called the identifier of d . Figure 3 shows the X-fast trie for N = { 0 , 1 , 3 , 7 , 9 , 13 } . Assume that we want to check whether value v is in the trie. In a typical trie, starting from node d at height h , we check the h th bit of v and if this is 0, we follow the left child of d , else we follow the right child. We iterate in this fash-ion until either we reach the leaf holding v , or we cannot proceed, which implies that v is not in the trie. Clearly, this process requires O (log | N | ) time. Unlike typical tries, in X-fast tries searches are faster and only take O (log log | N | ) time. Two characteristic of the X-fast trie result in this improvement. First, a (different) hash function is used at each height of the trie to index the nodes at that height. Second, while searching for a value v in the X-fast trie, instead of going down the trie one level at a time, we perform a bi-nary search over the height of the trie. In more detail, starting from a node d at height h , we jump to height h/ 2 and call hash func-tion Hash ( h/ 2) with input v/ 2 ( h/ 2) (the identifier of the ancestor of v at height h/ 2 ). If no ancestor of v exists at height h/ 2 , then the search iterates by looking for ancestors between heights h and h/ 2 . If an ancestor is found, again the search iterates by looking for ancestors between heights h/ 2 and 1 . At the end of the binary search, we are either at the ancestor of v at level 1 (and we can check in O (1) for the existence of v ), or we have found the lowest ancestor of v in the trie (although v itself is not in the trie).
The index construction algorithm is quite elaborate. Therefore, we present its main points through a running example and use the algorithm pseudo-code (in Figure 4) to facilitate the presentation. The algorithm input is a (provenance) binary relation R between a set of objects O and a set of labels L . The algorithm has four steps. Step 1: We create a binary matrix M , with rows representing la-bels, columns representing objects, and entry M [ i, j ] is 1, if the label of row i is associated with the object of column j in R (lines 1  X  3 in Procedure main ). Figure 5(a) shows the matrix M gen-erated from the inputs L = { 1 , 2 , 3 } , O = { 1 , 2 , 3 , 4 , 5 } and R = { (1 , 1) , (1 , 2) , (1 , 3) , (2 , 3) , (2 , 4) , (3 , 2) , (3 , 5) } . Step 2: Procedure CompCOLROW (line 4 in Procedure main ) com-putes two new vectors, namely, vectors V C and V R , in the following manner. Vector V C contains as many entries as the number of 1 X  X  in M (which is equal to |R| ), while vector V R contains |R| + |L| entries. In our example, the former vector has 7 entries, while the latter has 10. To populate the vectors, we traverse matrix M in row-major order. If the j th column in the i th row has value 1, then (a) we add j to V C ; and (b) we add a 0 to V R . Furthermore, at the end of each row of M , we add a 1 to V R . Figure 5(b) shows the two vectors for our running example. Since vector V R stores only 1 X  X  and 0 X  X , it can be stored efficiently using |R| + |L| bits. Step 3: Procedure EncodeCOLUMNS (line 5 in Procedure main ) uses vector V C to generate three new constructs. The first construct is another binary matrix T of size O ( |R|  X  |O| ) with as many columns as the size of vector V C (i.e., |R| ), and as many rows as the number of distinct values in V C (i.e., |O| ). In our example, T is a 5  X  7 matrix (Figure 5(c)). Entry T [ i, j ] is 1 if the j V
C has the value corresponding to the i th row. Matrix T is used to construct two additional vectors, namely V A and V B . The former vector results in by a row-major traversal of matrix T , and is not shown due to space constraints. The latter vector is generated by a two-step procedure in which (a) we split V A in blocks of size equal to the number of rows of T ; and (b) for each block, we write its car-dinality of 1 X  X  in unary and we add a 0 after that. Figure 5(c) shows the resulting vector. Since only vector V B is used in the remaining computation, V A is discarded. Vector V B is of size O ( |R| ) and therefore it can be stored efficiently using O ( |R| ) bits. Step 4: Procedure EncodeROWS (line 6 in Procedure main ) uses vector V R to generate four constructs. Specifically, for a parameter K , we split V R in blocks of size K . Then, L R 0 [ i ] ( L number of 0 X  X  (resp. 1 X  X ) up to the i th block. Furthermore, L ( L 1 [ j ] ) stores the index of the position in V R of the ( K  X  j ) (resp. 1). Figure 5(d) shows these constructs for K = 2 .
We conclude the index construction by noting that matrices M and T are actually not maintained as part of the index since they are very expensive due to their large size. Still, for illustration pur-poses, we present the matrices alongside the other constructs. The computed vectors V C , V R , V B and L R/S 0 / 1 , which in a sense con-tain the compressed information found in the matrices, are the only constructs used during query evaluation.
As in the previous section, we use a running example to illustrate the main ideas. The algorithms here are also based on the ones outlined in [12, 1] and their pseudo-code is shown in Figure 6.
A forward provenance query accepts as input an object o and re-turns the set of labels associated with it. The forward provenance evaluation algorithm has two steps. First, the algorithm uses Pro-cedure object_nb to retrieve from the index the number of labels associated with the input object. Second, a simple loop calls Pro-cedure object_select to retrieve the i th label, in each iteration.
Intuitively, for an object o corresponding to the j th column in matrix M , a label l is in the answer of a forward provenance query for o , if M [ i, j ] = 1 , where i is the row corresponding to label l . Figure 7 shows the relevant column (and labels) for o = 2 . We use the rank and select primitives over the constructs of the previous section to locate all these labels efficiently (note that matrices M and T are not maintained, due to their large size, but only shown here for illustration purposes). Specifically, Procedure object_nb (Figure 6) uses the rank primitives defined over the V C and V tors to compute the number of labels associated to the input object o . Notice that this is equal to the number of 1 X  X  in the highlighted row of matrix T , and can be computed without accessing T . To do this, rank computes the number of 1 X  X  that one would find in the first two rows of T (line 3 in object_nb ) and from that number sub-tracts the number of 1 X  X  found in the first row (line 5 in object_nb ). X-fast tries are used here (and elsewhere) since they are at the core of the implementation of rank bk function.

In terms of Procedure object_select (in Figure 6), assume that we want to retrieve the second label associated with object o = 2 , i.e., label l = 3 . The procedure first determines (in lines 3  X  5 ) the index Idx of the entry in V C that contains the second occurrence of value o = 2 . In our example, Idx = 6 . If we could traverse M in row-major order, the 6 th 1 is located in M [3 , 2] , which is indeed shows that the second label for object o = 2 is label l = 3 . Since matrix M is not available, to identify the second label we find the position of the Idx th 0 in V R (lines 6  X  7 ). In our case, this is position 8 of V R . Then, by counting the number of 1 X  X  in V (line 8), which correspond to the number of rows in M before that position, we determine that position 8 is in the third row of M and, therefore, label l = 3 is our answer.
 Analysis: The cost of both Procedure object_nb and Procedure object_select is O (log log |O| ) . Therefore, the overall cost of Pro-cedure ForwardProv is O ( |A|  X  (log log |O| )) , where A is the num-ber returned by Procedure object_nb , i.e., the number of labels as-sociated with the input object. This number is essentially the size of the answer set of the forward provenance query.
A backward provenance query accepts as input a label l and re-turns the set of objects associated with it. Similar to forward prove-nance, backward provenance evaluation involves two steps. In the first step, Procedure label_nb retrieves the number of objects asso-ciated the l . In the second step, a loop calls Procedure label_select , retrieving the i th object in the corresponding iteration.
Procedure label_nb relies solely on V R to compute the number of objects of label l . Since label l corresponds to the l the number of objects associated with l is equal to the number of 1 X  X  in this row. For our example in Figure 8, for l = 3 this is equal to 2. In turn, this number is equal to the number of 0 X  X  between the ( l  X  1) th and l th 1 in vector V R . Two calls of select the positions of the ( l  X  1) th and l th 1 in V R , while two calls in rank V R count the number of 0 X  X  up to those positions. Procedure label_nb then returns the difference between the latter numbers.
Assume that we are interested on retrieving the second object associated with l = 3 . Procedure label_select also relies on V To retrieve the i th object associated with l , we use select 2) to find the position in V R after which all the 0 X  X  for the line corresponding to l are stored. In our example, this is position 7. A call in rank V R (line 3) returns the number tmp1 of 0 X  X  before that position, five in our example. Then, a second call to select returns the position of the ( tmp 1+ i ) th zero, i.e., position 9. Given this position, we can now go to V C and determine that entry (9 -( l -1) = 7) of V C holds the identifier of the second object, here o = 5 . Analysis: Unlike the case of forward provenance queries, the cost of procedures label_nb and label_select is O (1) . This is mainly due to the fact that both procedures rely on operations that do efficient lookups over the V R and V B vectors. Therefore, the cost of Pro-cedure BackwardProv is O ( |A| ) , where A here corresponds to the number of objects returned by Procedure label_nb that are associ-ated with the input label. Note again that this number is essentially the size of the answer set of the backward provenance query.
Clearly, the index has the duality property since it can be used for the evaluation of both forward and backward provenance queries. Furthermore, it can support an index-only evaluation of the queries without requiring any materialization of provenance data since all the provenance data are encoded inside the index itself. Finally, we note that unlike previous indexes that are tied to particular prove-nance models [11, 15, 18], this index is provenance model-independent .
The cost analysis for the forward and backward provenance queries clearly illustrates another desirable property of the index, namely, locality . Specifically, the analysis shows that the cost of prove-nance queries is largely independent of the sizes of the indexed data (in this case, the sets L , O , and R ) and mainly depends on the size of the answer sets . This is obvious for backward provenance queries and the situation is practically similar for forward prove-nance queries which only depend on log log |O| . The importance of this property becomes apparent if one compares the performance of the index with that of current generic indexes. The introduction mentions that existing approaches often employ B+-indexes to in-dex provenance data. Such approaches not only require the main-tenance of separate indexes for forward and backward queries (due to the non-duality of the B+-tree index), but also have performance issues since they require time O (log |L| ) and O (log |O| ) , respec-tively, to access the index in order to answer these queries.
While our index is inspired by techniques on text indexing [12, 1], an assumption there is that the set of objects O , labels L , and the (provenance) relation R between them are known a priori , before the index is built. Although this assumption might be reasonable in text indexing, here we must be able to maintain an index incre-mentally , as new labels/objects/(provenance) relationships become available. In what follows, we address this issue. We consider three update types, namely, inserting a new label l , a new object o , and a new (provenance) relationship ( l, o ) between a label and object. Then, we study the effects of these updates in the existing index structure and we show how to incrementally maintain it.
 Label insertion: Intuitively, inserting a label l to the index amounts to adding a new row to matrix M (see Figure 9(a) where a row is in-serted in the example of Figure 5). Since the inserted row contains only 0 X  X , vector V C is unaffected and therefore so is matrix T and vector V B . However, the addition of the new row requires adding an extra 1 at the end of vector V C . Then, Procedure EncodeROWS must also update the last entries in vectors L R 1 and L S operations, and thus label insertion, can be done in O (1) time. Object insertion: Inserting an object o amounts to adding a col-umn to matrix M (see Figure 9(b)), which neither affects V V
R (or any other construct for that matter). Therefore, inserting an object can also be done in O (1) . Since during the insertion of both labels or objects the index is largely unaffected, inserting large volumes of base data has minimal impact on our index, when these data do not have provenance relationships .
 Relationship insertion: Figure 9(c) shows the results of inserting a new relationship ( l, o ) = (1 , 4) to the example of Figure 5. Notice that all the index constructs are affected. However, the effects of the insertion are more localized for vectors V C and V R . In more detail, Procedure UpdateCOLROW (Figure 10) locates in O (1) time the part of V C corresponding to the row of label l (lines 1  X  4 ). Then, it uses an X-fast trie to locate in O (log log |O| ) time the entry pos that object o must be inserted (line 5). Finally, both vectors V and V R are shifted to make space for the new entry. Value o is inserted in V C , while a 0 is inserted in V R (Figure 9(c)). The cost of shifting the V C and V R vectors is O ( |R| ) and O ( |R| + |L| ) , respectively. However, by making the vectors less space efficient, we can amortize the cost of inserting a value in the middle of the vectors and make insertions in O (1) . Therefore, the overall cost of Procedure UpdateCOLROW is O (log log |O| ) .

The situation is more complicated for vector V B since, as the figure shows, vector V new B after the insertion is radically differ-ent from vector V old B before it. Therefore, one might be tempted to use Procedure EncodeCOLUMNS to re-compute the vector from scratch , which would require O ( |R| X |O| ) time. However, an in-cremental approach is possible. Indeed, Procedure UpdateVectorB (Figure 10) not only updates incrementally the existing vector and converts it into the new one, but also requires only O ( |R| ) time, i.e., a single pass over the underlying bit vector and its accompany-ing structures. The procedure processes vector V B one block b at time, where a block is a series of 1 X  X  followed by a 0. Each block b essentially counts the number of 1 X  X  in an area of matrix T , when it is traversed in row-major order. In our example, each block b counts the number of 1 X  X  every five entries of T in row-major or-der. Inserting a relationship ( l, o ) results in the (virtual) insertion of a new column NC in T which, in turn, affects this counting since it affects the grouping of entries in sets of five. In our example, there is a single 1 in the first five entries of T before the insertion, and two 1 X  X  after the insertion. Procedure UpdateVectorB considers each block b in turn, and determines what are the effects of (virtu-ally) adding column NC in matrix T . The possible effects of such an insertion are: (a) some of the 1 X  X  from block b 0 that is before block b in V B are carried over to b (line 3); (b) the position of 1 X  X  within a block is shifted (lines 5  X  8 ) and possibly some 1 X  X  need to by carried over to the next block b 00 of b (line 11); (c) a new 1, that belongs to the inserted column, is added to b . By considering these cases, and with a single pass of the blocks in V old B , Procedure Up-dateVectorB determines the contents of the blocks of V new
We present two orthogonal optimizations, starting with one to compress the X-fast trie to reduce its memory consumption without affecting its performance. Then, to address the issue of the index growing beyond physical memory bounds, we propose a provenance-aware decomposition of the index into a number of smaller coop-erating sub-indexes that exploits the latest hardware trends.
In an X-fast trie, a path from the root to some indexed value v often contains internal nodes that are used solely for indexing v (for each such node d , Desc ( d ) = { v } ). For example, in the trie of Figure 3, two internal nodes are used solely to connect the trie root with the leaf holding value 13. Similarly, two nodes are used solely to connect node 0 at level 3 with the leaf holding value 7. Here, we propose a compression of tries that removes all such nodes for which | Desc ( d ) | = 1 . For example, by compressing the trie of Figure 3, we get the trie to the left of Figure 11. Similar trie com-pression techniques have also being proposed in the past (e.g., PA-TRICIA tries [17]). However, to the best of our knowledge, none of these compressed trie structures supports binary searches over the height of the trie, and therefore the compression techniques there do not affect or interact with external structures that are tied to the trie, as is the case with the hash indexes associated with the X-fast tries. As a result, the compression of X-fast tries is more involved.
To support the compression, the logic of Procedure FindValue (which searches for an indexed value in the trie) must be updated to account for the fact that indexed values can now appear in all levels of the trie (not just on level 0). The updated Procedure FindValue (Figure 12) relies, in turn, on the updated logic of Procedure Fin-dAncestor . The latter procedure performs a binary search over the height of the trie, looking for the ancestor anc of v at the lowest height h . Given node anc , Procedure FindValue checks whether v is indeed a child of anc . For example, consider searching for value v = 3 in the trie to the left of Figure 11. Procedure FindAnces-tor returns as anc node 0 at level 2, and FindValue returns 1, since indeed the node holding value 3 is a child of anc . From the de-scription in Section 2, there is a notable difference between the way the original FindValue is described there and the version presented here. In more detail, the original FindValue would always fail to find value v = 3 in the compressed trie since in that FindValue if FindAncestor returns a node that is not in level 1, then FindValue assumes that value v is not in the trie. Another difference between the procedures in the original and compressed X-fast trie is that in the original X-fast trie, a hash function Hash h at height h would index all the nodes in that height. However, in the compressed trie, non-leaf and leaf nodes are intermixed at any height of the trie but only the non-leaf nodes should be considered for hashing.
Procedure InsertIndexValue (which inserts new values into the trie) must also be updated to reflect the new compressed trie struc-ture. The procedure starts by calling FindAncestor to determine the node anc where a value v is to be inserted. In the simplest case, v is to be inserted as a left (right) child of anc , and anc has no left (resp. right) child. Then v is inserted as that child of anc . How-ever, if anc already has a child in that position, then the tree needs to be expanded. The new Procedure CreatePath creates as many internal nodes in the trie as the number of common bits between v and the child of anc , starting from the ( h anc  X  1) th bit. Each new internal node is also inserted into the hash index at the correspond-ing height. The loop terminates when it finds a bit in which the left (right) child of anc differs from v . Then, the child of anc and v become children of the internal node that was created last. To illustrate, consider the trie to the left of Figure 11 while to the right of the figure we show the trie after the insertion of value v = 11 . Here, FindAncestor returns as anc node 1 at level 3. Value v = 11 is to be inserted to the left of anc but the node storing value v is stored there. Therefore, CreatePath creates a new internal node 2 at level 2, since both v and v 0 agree up to their second most signif-icant bit. Values v and v 0 then become children of this new node.
There are two main advantages in decomposing a single index structure into multiple sub-indexes: Improved memory utilization: A single index used throughout the system lifetime quickly becomes too big to fit into physical memory. This affects the performance since secondary storage is accessed during query evaluation. Therefore, there are obvious ad-vantages into splitting the index into sub-indexes that fit in memory. Improved CPU utilization: Even commodity desktops have multi-core CPUs. Multi-cores can be used to parallelize the processing of sub-indexes during query evaluation.

With this in mind, we propose a decomposition in which our sin-gle index I is replaced by a set of C sub-indexes I 1 , I with C being a parameter of our approach. For each label l (object o ), let A l represent the set of objects (resp. A o the set of labels) re-turned by Procedure BackwardProv (resp. Procedure ForwardProv ). While constructing the sub-indexes, we divide set A l in C subsets , A 2 , . . . , A C , each with cardinality | A l | /C . The assignment of objects in A l (labels in A o ) to a subset A i can be dependent on the provenance relationship between the objects and labels, or it can use a simple round-robin assignment. Then, each subset A i to construct index I i . In what follows, we show that our decompo-sition strategy is guided by the locality property of our index. In-tuitively, a naive index decomposition would create one sub-index for each subset of relation R . To illustrate, in the left of Figure 13 we show a relation R with 16 ( l, o ) pairs, associating 4 labels with 16 objects. To the right of the figure, we show various index strate-gies for R , where objects are depicted as white rectangles, labels as gray rectangles, and each label is depicted after the set of objects it is associated with in R . At the top of the figure, we assume that a single index I is built for all the ( l, o ) pairs in R , while in the mid-dle of the figure we use the naive decomposition where this single index is split into two sub-indexes, with I 1 indexing the first half of the relation (which includes the pairs ( l, o ) for labels l = 1 and l = 2 ), and I 2 indexing the second half of the relation (with pairs for the remaining two labels). We argue that the naive decomposi-tion does improve memory utilization ( I 1 and I 2 are smaller than I ), but it does not improve CPU utilization. To see this, remember that the evaluation time of a backward provenance query for a label l (similarly, for forward queries and an object o ) largely depends on the number of objects (resp. labels) that are retrieved from the index for label l (resp. object), that is, it depends on the cardinality of A l (resp. A o ). Therefore, for a label like l = 2 , the evaluation time of a backward provenance query using index I depends on the 4 objects returned by the index. Using the naive decomposition of Figure 13, the same query is expected to have a similar running time, in spite of the fact that indexes I 1 and I 2 might be accessed in parallel by different processors. This is because 4 objects still need to be retrieved from index I 1 (and no objects from index I due to the locality, is similar to retrieving 4 objects from index I .
Our proposed decomposition (shown at the bottom of Figure 13) addresses the shortcomings of the naive decomposition by paral-lelizing the access within sets A l (resp. A o ), i.e., the access of ob-jects (labels) associated with the same label (resp. object). There-fore, the decomposition improves both the memory and the CPU utilization. Now, a query for label l = 2 retrieves only two ob-jects from index I 1 and two from index I 2 which, if the indexes are accessed in parallel, almost halves the query evaluation time.
For this study, we borrow a simple provenance model that can represent provenance associations in a wide spectrum of real-life applications [16]. We briefly review the model and note that our results are not model-specific and any model could have been used.
Analytics, like the ones in our introduction, process data from a set S and produce a new set of data T . Although the nature of such analytics is often domain dependent, the provenance relationship between inputs and outputs can often be described in terms of some domain-independent primitives. Examples of such primitives are: Time: A data item from T can be associated with items from S that are bounded by a time window. Partly, this is the provenance rela-tionship between Prehypertension alerts and blood-pressure read-ings. The primitive format is T ( t ) :-S  X  (( t  X  t b , t  X  t where t specifies the timestamp of the data item of T , ( t  X  t ( t  X  t e ) the time window enclosing the items from S , sf the shift of the time window between consecutive items in T , and or the prim-itive order (more on the order later). To illustrate, rule Alert ( t ) :-BP  X  (( t, t  X  180 , 180) , 1)  X  indicates that an alert at time t is asso-ciated with all the blood pressure readings in a 3-hour epoch, with consecutive epochs having no overlap in time.
 Sequence: The primitive expresses dependencies in terms of a data item in T and sequences of data items in S . Its format is T ( t ) :-quence numbers of data items in S , sf the shift of the sequence win-dow, and or the primitive order. For example, rule AV GBP ( t ) :-BP  X  ((1 , 10 , 5) , 1)  X  indicates that an average blood-pressure read-ing at time t is calculated by the last 10 actual blood-pressure read-ings (irrespectively of their timestamps). The sequence window is shifted by 5 readings, hence the same reading in S contributes to the generation of two different averages in T .
 Value: The primitive expresses dependencies in terms of a data item in T and a set of items in S whose attribute attr has a value in a predefined range. The format is T ( t ) :-S  X  ( attr, ( v where v b and v e specify the value range the attribute attr must satisfy, sf the shift of the value window, and or the primitive order. For example, rule Alert ( t ) :-BP  X  ( systolic, (135 , 140 , 10) , 1)  X  indicates that an alert at time t depends on all the blood-pressure readings between 135 and 140. Between consecutive alerts the ten oldest readings are dropped from consideration.

For enhanced expressiveness, primitives can be combined using the  X  X rder X  field, with the output of a lower order primitive acting as the input for a higher order primitive. For example, the rule: says that a Prehypertension alert is generated from 4 readings in every 3-hour epoch, if the 2 nd or 3 rd reading in the epoch have a systolic pressure larger than 135mmHg. Generic setup: The provenance index implementation is around 6K lines of C code. For our experiments we used a dual-processor Intel Xeon 2.4GHz with 2GB of memory, running Linux.
 Provenance Data Generation Module ( PDGM ): We created a provenance data generator whose input is a four-tuple  X  U, L, G, E  X  , consisting of (a) the specification of a provenance rule U ; (b) an input loss rate L (c) an output data generation rate G ; and (d) an end time E . The generator simulates an analytics provenance-enabled system where (a) the analytics logic abides to the rule U ; (b) the input data set has L % of missing items (to simulate irreg-ularly sampled input in time); (c) the output data set is populated with a rate dictated by G ; and (d) the lifetime of the system is de-termined by E . For example, given the four-tuple  X  ( Alert ( t ) :-ECG  X  (( t, t  X  180 , 180) , 1)  X  ), 5, 10, 43200  X  , the PDGM simulates a health-care analytics system that generates an alert based on ECG readings from the last 180 seconds (with 1 reading/second), where 5% of the input readings are missing (due, say, to sensor errors). In a real-life, it is unlikely that every epoch of 180 ECG readings pro-duces an alert. Therefore, only 10% of the epochs produce an alert during the system lifetime, which is 43200 seconds (12 hours). The simulator output is a trace of the system execution. We use the term trace signature , to refer to the four-tuple used to generate a trace. Figure 14 shows some of the signatures used in our experiments. Provenance Query Generation Module ( PQGM ): To measure the performance of both forward and backward provenance queries in any setting, we distinguish between queries with empty and non-empty provenance results. Therefore, four query classes are iden-tified. Class-1 are backward provenance queries that, given a data item in T , they return a non-empty set of associated data items in S . empty answer set. Class-3 and Class-4 include forward provenance queries with non-empty and empty answer sets, respectively.
Given a trace generated by the PDGM , the PQGM must guarantee that it will generate appropriate queries for each of the four classes. To do this, the PQGM consults the trace itself and its signature, i.e., the provenance rule, the retention and generation rates and the lifetime of the trace. The number of queries generated for each class depends on a user-provided input. For any given trace, and for each of the classes, in our experiments we generate 10000 queries. Experiment 1: The objective of this experiment is to validate our cost analysis (Section 2) of the backward and forward provenance query performance. Based on this analysis, the evaluation time is O ( |A| ) for the former , and O ( |A|  X  (log log |O| )) for latter queries. In the experiment, we keep constant the size |A| of the query answer sets across different experimental runs. At the same time, we increase the size of the input |O| , output |L| and prove-nance relation |R| sets, across runs. Our objective is to illustrate the locality property, that is, the evaluation time of the former queries will remain almost constant across runs, while for the latter queries the evaluation time will be influences by the log log |O| .
To this end, we generated 24 traces using the PDGM module. As input to the module, we used the trace signature 0 (Figure 14) where variable E in the signature ranged between 1800 and 43200 , in 1800 increments. Intuitively, each outputted trace simulates an an-alytics node which generates every second an output data item for each pair of input items during the last two seconds. Approximately 10% of the input is lost due to failures and, similarly, only 90% of the expected outputs is generated. The system lifetime ranges from 30 minute to 12 hours, in 30 minute increments between consecu-tive traces. The main difference between the 24 traces is the size of the input |O| , output |L| and provenance relation |R| sets, which all linearly increase from one trace to the next. Yet, irrespectively of the trace, each generated output only depends on the same num-ber of inputs, namely, two, and each input only generates one out-put. Therefore, the size |A| of the answer set for both forward and backward provenance queries remains constant across traces.
For each of the 24 traces, the PQGM produced 10000 queries (for each query class) whose average evaluation times (in microsec-onds) are shown in Figure 15. The figure verifies the locality prop-erty of our index. Specifically, for backward provenance ( Class-1 ) queries, Figure 15(a) shows that running time is almost constant, while Figure 15(b) shows that forward provenance ( Class-3 ) queries are only slightly influenced by the increasing size of |O| . Figure 15(c) shows that for queries returning empty results there is little difference in running times. These results not only verify index locality and its effect on query performance but also highlight the difference between this index and generic indexes, like B+-trees. Unlike this index, for B+-trees the evaluation time for backward (forward) provenance query is O (log |O| + |A| ) ( O (log |L| + |A| ) ). Clearly, for both queries this index is more efficient.
 Experiment 2: In Experiment 1, we kept the answer set size |A| constant across runs. In this and the next experiment, we study the effects of the answer set size on the evaluation times. In this exper-iment, we used the PDGM module with three different arguments, namely, trace signatures 2 , 3 and 4 (Figure 14), where T ranged between 3600 and 43200 , in 3600 increments. In this manner, 36 traces were generated (three sets of 12). For the same value of E , the difference between the three traces (one per signature) is that in the trace of signature 2 an output results in from the last 60 in-puts, in the trace of 3 from 120 inputs, and in that of trace 4 from 180 inputs. Clearly, this affects the cardinality of answers for back-ward provenance queries. Figure 16(a) shows the average evalua-tion time (in microseconds) of 10000 Class-1 queries, for each of the 36 traces. Notice that as the cardinality of answers increases linearly (from 60 to 120 to 180), this is also the case for the corre-sponding evaluation times. Indeed, this is also evident by the next two figures. Consider Figure 16(b), generated by the 12 traces of signature 5 . The traces simulate analytics where each output, say an alert, (generated with a 5% frequency) depends on all the inputs that have a value above 135. The PDGM guarantees that inputs that satisfy this constrain are regularly produced and therefore, as time passes, output items depend on a linearly increasing number of in-puts, spread throughout the input data set. These input items are the answer set of Class-1 queries and the figure indeed shows that as their cardinality increases linearly, so are the query evaluation times. One might wonder whether this increase is affected by the inputs being widely spread through the input data set (not adjacent in time). Our next figure shows that adjacency is not an influential factor here. We consider a different setting here where ten different traces are used, using signature 6 ( I ranges between 1 and 10). All traces consider a system with a lifetime of 43200 seconds, and the difference between the traces is that an increasing number of adja-cent inputs is used to produce an output (ranging from 60 to 600 inputs). Notice that the picture in Figure 16(c) is consistent with that of the previous figure, and therefore distribution of items in the input set does not affect evaluation times.
 Experiment 3: We used the same setup here as in Experiment 2, and produced 36 traces using the trace signatures 2 , 3 and 4 . How-(forward provenance) queries. As expected, by comparing query evaluation times over the three signatures for each date point (at 3600 , 7200 , etc.) in Figure 17(a), we see that the evaluation times of Class-3 queries are almost unaffected by having an increasing number of input items contributing to a single output item. This is because for all these queries, the size |A| of the answer set of Class-3 queries is still 1 . Across the different data points, any ob-served increase in evaluation times is only due to the increase in the size |O| of indexed inputs (actually, the increase is analogous to the log log |O| and consistent with our analysis).

A natural question is how Class-3 queries are affected by hav-ing a single input contributing to multiple output items, i.e., how increasing |A| for Class-3 queries affects their evaluation time. Fig-ure 17(b) considers 12 traces generated by signature 5 (Figure 14). Here, a single input at time t with value above 135 contributes to every output after time t . Similar to the corresponding setting for early with respect to the cardinality of the answer set.

Finally, as in Figure 16(c), Figure 17(c) shows that the distribu-tion of items in the input set does not affect the evaluation times of 6 (Figure 14), the |A| of Class-( 3) queries is constant in all traces (only the number of inputs associated to a single output item dif-fers between traces), and evaluation times are only influenced by the log log |O| of the input set O .
 Discussion: The previous experiments illustrate an interesting trade-off between backward and forward provenance queries. Remember the two basic notions of labels and objects from our index construc-tion. In our encoding, we used labels to encode output items and objects to encode inputs. This resulted in a structure where back-ward provenance queries can be evaluated in time independent to the size of the input/output data sets but linear to the size of the answer set, and forward provenance queries that can be evaluated in time that increases slightly with the size of the input set, and is linear to the size of the answer set. Clearly, the performance for both types of queries is very satisfactory. Yet, nothing forbids us to reverse this encoding and use labels to encode inputs and objects to encode output items. Then, the performance of backward and for-ward queries is also reversed . Depending on the application, the importance of backward vs. forward queries, the characteristics of the input/output sets, and the properties of the provenance rule, it might be desirable to use one encoding versus the other. The above is a clear indication of not only the effectiveness of our index struc-ture in terms of performance but also of its flexibility and ability to be customized to the specific application needs.
 Experiment 4: In this experiment, we illustrate the benefits for some of our proposed optimizations. Figure 18(a) compares the number of nodes of the basic and optimized X-fast trie structure, required to index the same set of randomly generated values. The cardinality of the indexed value set ranges between 3600 and 43200 values, in 3600 increments. Notice that the compressed X-fast trie structure consistently requires almost an order of magnitude less nodes (and memory) than the basic structure. Even in less favorable scenarios, where the indexed values are not randomly generated (and therefore the index is dense), the optimized X-fast trie requires approximately 17% less nodes than the basic structure (figure not shown due to space constraints). Figure 18(b) shows that these savings do not come at a cost in terms of index access time. Indeed, the average access times of the two indexes are almost identical.
Up to this point, our experiments do not use index decomposi-tion (and thus run on a single CPU). Figure 18(c) shows the effect of index decomposition in the evaluation time of Class-1 queries. Specifically, we used signature 5 to generate 12 traces, where E again ranged between 3600 and 43200 , in 3600 increments. We decomposed our index into two sub-indexes, each running on a dif-ferent CPU of our dual-processor machine. In the figure, for each trace size we show both the single index (single-CPU) evaluation times and the decomposed index (multi-CPU) parallel evaluation times. The benefits of index decomposition are clear. By decom-posing the index, the evaluation times are almost halved. Similar benefit are observed in the case of forward provenance queries, but due to space constraints the graphs are not shown here. Data provenance has recently received considerable attention [5]. The survey in [19] identifies two types of provenance, namely, workflow provenance [10]) and data provenance , and it focuses on studying works belonging to the latter type of provenance. It classifies these works into two categories, the annotation (e.g., [11, 18]) and the non-annotation (e.g., [7]) approaches. Distinguishing characteristic of the works in the two categories is that the former use meta-data to represent data provenance while the latter do not. These works address provenance query performance either by us-ing customized indexes (e.g., [15, 18]) or standard built-in database indexes (e.g., [11]). Customized indexes are specific to the associ-ated provenance models and cannot be used across models and, like standard indexes, are not expressive enough to support both backward and forward provenance queries. For a performance per-spective, the index presented here has a clear advantage over these indexes since its locality property guarantees that the index perfor-mance is largely independent of the size of the indexed data.
The index can be used for an index-only evaluation of lineage [8] or why-provenance [4] queries, by maintaining the association of an output tuple t of a query Q with the input tuples of Q that are witnesses of t . It can also be used to support the evaluation of how-provenance [13] queries, although an index-only evalua-tion is not possible here since complementary information for the provenance semirings must be maintained. Finally, with minor ex-tensions, the index can be used to evaluate where-provenance [4] queries by maintaining the association of a value v of an output tuple t with the input tuple values of Q that result in value v in t .
The index is directly applicable and can be used as is in provenance-enabled systems like Trio [20], GridDB [14] and Zoom [3]. In these systems, provenance queries are essentially recursive SQL queries over edge tables [9]. The provenance index nicely fits these set-tings since (due to its duality) it can be used to index and query the edges (tuples) in these tables along both of their directions. Clearly, the above illustrate the ability to use the index for the evaluation of workflow provenance queries, since edge tables are one possible representation for workflow analytics graphs.
We have addressed the open problem [9] of efficiently evaluating provenance queries by proposing an index structure that is inspired from recent techniques in text indexing [12, 1]. The index has a duality property, i.e., it supports the evaluation of both forward and backward provenance queries. The locality property ensures that evaluation times are largely independent from the (often over-whelming) size of provenance data, and only depend on the size of the query results. Starting from the basic index, we showed how to incrementally maintain it, and we proposed two orthogonal op-timizations, namely, (a) a provenance-aware index decomposition into sub-indexes to reduce both memory consumption and cpu uti-lization; and (b) a compression technique for the X-fast trie struc-ture [21] used internally by the index. Using the index implemen-tation, we have presented a detailed set of experiments to illustrate its efficiency in a number of real-life settings.

As is evident from the previous section, due to its generality and efficiency, the index can support the evaluation of diverse types of provenance queries. Yet, the previous section also illustrates an important avenue for future work, namely, the development of a complementary index to support the efficient indexing and eval-uation of queries on provenance-semirings ( how-provenance [13] queries). The development of such a complementary index, along with the development of a methodology to have it be used alongside the index presented here, would provide the first complete solution in the space of efficient provenance query evaluation.
