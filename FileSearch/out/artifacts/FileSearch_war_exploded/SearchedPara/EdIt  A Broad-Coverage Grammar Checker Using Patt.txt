 Recently, an increasing number of research has targeted language learners  X  need in editorial assis -tance including detecting and correcting grammar and usage errors in texts written in a second lan -guage . For example, Microsoft Research has de -veloped the ESL Assistant, which provides such a service to ESL and EFL learners .

Much of the research in this area depends on hand-crafted rules and focuses on certain error types . Very little research provides a general framework for detecting and correcting all types of errors . However, in the sentences of ESL writing , there may be more than one errors and one error may affect the performance of handling other er -rors. Erroneous sentences could be more efficiently identified and corrected if a grammar checker han -dles all errors at once, using a set of pattern rules that reflect the predominant usage of the English language.

Consider the sentences,  X  He play an important roles to close this deals.  X  and  X  He looks forward to hear you.  X  The first sentence contains inaccurate word forms (i.e., play , roles , and deals ) , and rare usage (i.e.,  X  role to close  X  ), while the second sen -tence use the incorrect verb form of  X  hear  X . Good responses to these writing errors might be (a) Use  X  played  X  instead of  X  X lay. X  (b) Use  X  role  X  instead of  X  roles  X , (c) Use  X  in closing  X  instead of  X  to close  X  (d) Use  X  to hearing  X  instead of  X  to hear  X , and (e) insert  X  from  X  between  X  hear  X  and  X  you . X  Th ese suggestions can be offered by learning the patterns rules related to  X  play ~ role  X  and  X  look forward  X  based on analysis of ngrams and collo -cations in a very large-scale reference corpus. With corpus statistics, we could learn the needed phra -seological tendency in the form of pattern rules such as  X  play ~ role in V-ing ) and  X  look forward to V-ing . X  The use of such pattern rules is in line with the recent theory of Pattern Grammar put forward by Hunston and Francis (2000).

We present a system, EdIt, that automatically learns to provide suggestions for rare/wrong usage s in non-native writing. Example EdIt responses to a text are shown in Figure 1. EdIt has retrieved the related pattern grammar of some ngram and collo -cation sequences given the input (e.g.,  X  play ~ role in V-ing 1  X , and  X  look forward to V-ing X ). EdIt learns these patterns during pattern extraction process by syntactically analyzing a collection of well-formed, published texts.

At run-time, EdIt first processes the input pas -sages in the article (e.g.,  X  He play an important roles to close  X ) submitted by the L2 learner . And EdIt tag the passage with part of speech informa -tion, and compares the tagged sentence against the pattern rules anchored at certain collocations (e.g.,  X  play ~ role  X  and  X  look forward  X ). Finally, EdIt finds the minimum-edit-cost patterns matching the passages using an extended Levenshtein X  X  algo -rithm (Levenshtein, 19 6 6). The system then high -lights the edits and displays the pattern rules as suggestions for correction. In our prototype, EdIt returns the preferred word form and preposition usages to the user directly (see Figure 1); alterna -tively, the actual surface words (e.g.,  X  X losing X  and  X  X eal X ) could be provided.
 Grammar checking has been an area of active re -search. M any methods , rule-oriented or data-driven, have been proposed to tackle the problem of detecting and correcting incorrect grammatical and usage errors in learner texts. It is at times no easy to distinguish these errors. But Fraser and Hodson (1978) shows the distinction between these two kinds of errors .

For some specific error types (e.g., article and preposition error ) , a number of interesting rule-based systems ha ve been proposed. For example, Uria et al. (2009) and Lee et al. (2009) leverage heuristic rules for detecting Basque determiner and Korean particle errors , respectively. Gamon et al. (2009) base s some of the modules in ESL Assistant on rules derived from manually inspecting learner data. O ur pattern rules , however, are automatically derived from readily available well-formed data, but nevertheless very helpful for correcting errors in non-native writing.

More recently, statistical approaches to develop -ing grammar checkers have prevailed. Among un -supervised checkers , Chodorow and Leacock (2000) exploit s negative evidence from edited tex -tual corpora achieving high precision but low re -call , while Tsao and Wible (2009) use s general corpus only. Additionally, Hermet et al. (2008) and Gamon and Leacock (2010) both use Web as a corpus to detect errors in non-native writing. On the other hand, s upervised models, typically treat -ing error detection / correction as a classification problem , may train on well-formed texts as in the methods by De Felice and Pulman (2008) and Te -treault et al. (2010), or with additional learner text s as in the method proposed by Brockett et al. (2006). Sun et al. (2007) describe s a method for constructing a supervised detection system trained on raw well-formed and learner texts without error annotation. 
Recent work has been done on incorporating word class information into grammar checkers. For example, Chodorow and Leacock (2000) exploit bigrams and trigrams of function words and part-of-speech ( PoS ) tags, while Sun et al. (2007) use labeled sequential patterns of function, time ex -pression, and part-of-speech tags. In an approach similar to our work , Tsao and Wible (2009) use a combined ngrams of words forms, lemmas, and part-of-speech tags for research into constructional phenomena . The main differences are that we an -chored each pattern rule in lexical collocation so as to avoid deriving rules that is may have two consecutive part-of-speech tags (e.g,  X  V Pron$ socks off X  ). The pattern rules we have derived are more specific and can be effectively used in detect -ing and correcting errors.

In contrast to the previous research, we intro -duce a broad-coverage grammar checker that ac -commodates edits such as substitution, insertion and deletion, as well as replacing word forms or prepositions using pattern rules automatically de -rived from very large-scale corpora of well-formed texts. Using supervised training on a learner corpus is not very feasible due to the limited availability of large-scale annotated non-native writing. Existing systems trained on learner data tend to offer high precision but low recall. Broad coverage grammar checkers may be developed using readily available large-scale corpora. To detect and correct errors in non-native writing, a promising approach is to automatically extract lexico-syntactical pattern rules that are expected to distinguish correct and in correct sentences. 3.1 Problem Statement We focus on correct ing grammatical and usage errors by exploiting pattern rules of specific collo -cation (elastic or rigid such as  X  play ~ rule  X  or  X  look forward  X ) . For simplification, we assume that there is no spelling errors. EdIt provides sug -gestions to common writing errors 2 of the follow -The system is designed to find pattern rules related to the errors and return suggestionst. We now for -mally state the problem that we are addressing.
Problem Statement: We are given a reference corpus C and a non-native passage T . Our goal is to detect grammatical and usage errors in T and provide suggestions for correction . For this, we extract a set of pattern rules , u 1 ,..., u m from C such that the rules reflect the predominant usage and are likely to distinguish most errors in non-native writing. 
In the rest of this section, we describe our solu -tion to this problem. First, we define a strategy for identifying predominant phraseology of frequent ngram s and collocation s in Section 3.2. Afer that, we show how EdIt proposes grammar correc -tions edits to non-native writing at run-time in Sec -tion 3.3 . 3.2 Deriving Pattern Rules We attempt to derive pattern s (e.g.,  X  play ~ role in V-ing  X  ) from C expected to represent the immedi -ate context of collocations ( e.g.,  X  play ~ role  X  or  X  look forward  X  ). Our derivation process consists of the following four-stage: Stage 1. Lemmatizing, POS Tagging and Phrase chunking. In the first stage, we lemmatize and tag sentences in C . L emmatization and POS tagging both help to produce more general pattern rules from ngram s or collocation s . The based phrases are used to extract collocations.
 Stage 2. Ngrams and Collocations. In the second stage of the training process , we calculate ngrams and collocations in C , and pass the frequent ngrams and collocations to S tage 4 .

We employ a number of steps to acquire statisti -cally significant collocations--determining the pair of head words in adjacent base phrases, calculating the ir pair-wise mutual information values, and fil -tering out candidates with low MI values.
 Stage 3. onstructing Inverted Files. In the third stage in the training procedure , we build up in -verted files for the lemmas in C for quick access in S tage 4 . For each word lemma we store surface word s , POS tags, pointers to sentences with base phrases marked. Stage 4. Deriving pattern rules. In the fourth and final stage, we use the method described in a pre -vious work (Chen et al., 2011) and use the inverted files to find all sentences containing a give word and collocation. Words surrounding a collocation are identified and generalized based on their corre -sponding POS tags. These sentences are then trans -formed into a set of n-gram of words and POS tags, which are subsequently counted and ranked to produce pattern rules with high frequencies. 3.3 Run-Time Error Correction Once the patterns rules are derived from a corpus of well-formed texts , EdIt utilizes them to check grammaticality and provide suggestions for a given text via the procedure in Figure 2 .
 In Step (1) of the procedure , we initiate a set Suggestions to collect grammar suggestions to the user text T according to the bank of pattern gram -mar PatternGrammarBank . Since EdIt system fo -cuses on grammar checking at sentence level , T is heuristically split (Step (2)).

For each sentence , we extract ngram and POS tag sequences userU s age in T . For the example of  X  X e play an important roles. He looks forword to hear you X , we extract ngram such as he V DET, play an JJ NNS, play ~ roles to V, this NNS, look forward to VB, and hear Pron. 
For each userU s age , we first access the pattern rules related to the word and collocation within (e.g., play-role patterns for  X  play ~ role to close  X ) Step (4). And then we compare userU s age against these rules (from Step (5) to (7)). W e use the ex -tended Levenshtein  X  X  algorithm shown in Figure 3 to compare userU s age and pattern rules.

If only partial matches are found for userU s age , that could mean we have found a potential errors. We use minEditedCost and minEditedSug to con -train the patterns rules found for error suggestions (Step (5)). In the following, we describe how to find minimal-distance edits.

In Step (1) of the algorithm in Figure 3 we allo -cate and initialize costArray to gather the dynamic programming based cost to transform userUsage into a specific contextual rule pattern . Afterwards, the algorithm defines the cost of performing substi -tution (Step (2)), deletion (Step (3)) and insertion (Step (4)) at i-indexed userUsage and j-indexed pattern . If the entries userUsage [ i ] and pattern [ j ] are equal literally (e.g.,  X  X B X  and  X  X B X ) or gram -matically (e.g.,  X  X T X  and  X  X ron$ X ), no edit is needed, hence, no cost (Step (2a)). On the other hand, since learners tend to select wrong word form and preposition, we set a lower cost for sub -stitution among different word forms of the same lemma or lemmas with the same POS tag (e.g., replacing V with V-ing or replacing to with in  X  . In addition to the conventional deletion and insertion (Step (3b) and (4b) respectively), we look ahead to the elements userUsage [ i +1] and pattern [ j +1] con -sidering the fact that  X  with or without preposition X  and  X  X ransitive or intransitive verb X  often puzzles EFL learners (Step (3a) and (4a)). Only a small edit cost is counted if the next elements in use -rUsage and Pattern are  X  X qual X . In Step (6) the extended Levenshtein  X  X  algorithm returns the minimum edit cost of revising userUsage using p attern .

Once we obtain the costs to transform the use -rUsage into a similar, frequent pattern rules, we propose the minimum-cost rules as suggestions for correction (e.g.,  X  play ~ role in V-ing  X  for revising  X  play ~ role to V  X ) (Step (8) in Figure 2 ) , if its minimum edit cost is greater than zero . Otherwise, the usage is considered valid. Finally, the Sugges -tions accumulated for T are returned to users (Step (9)). Example input and edit orial suggestions re -turned to the user are shown in Figure 1. Note that pattern rules involved flexible collocations are de -signed to take care of long distance dependencies that might be always possible to cover with limited ngram (for n less than 6). In addition, the long pat -ter rules can be useful even when it is not clear whether there is an error when looking at a very narrow context. For example,  X  X ear X  can be either be transitive or intransitive depending on context. I n the context of  X  X ook forward to X  and person noun object , it is should be intransitive and require the preposition  X  X rom X  as suggested in the results provided by EdIt (see Figure 1).

In existing grammar checkers, there are typically many modules examining different types of errors and different module may have different priority and conflict with one another. Let us note that this general framework for error detection and correc -tion is an original contribution of our work . In ad -dition, we incorporate probabilities conditioned on word positions in order to weigh edit costs . For example, the conditional probability of V to imme -diately follow  X  X ook forward to X  is virtually 0, while the probability of V-ing to do so is approxi -mates 0.3. Those probabilistic values are used to weigh different edits. In this section, w e first present the experimental setting in EdIt (Section 4.1). Since our goal is to provide to learners a means to efficient broad-coverage grammar checking, EdIt is web-based and the acquisition of the pattern grammar in use is offline. Then, we illustrate three common types of errors, scores correlated, EdIt 4 capable of handling . 4.1 Experimental Setting We used British National Corpus (BNC) as our underlying general corpus C . It is a 100 million British English word collection from a wide range of sources. We exploited GENIA tagger to obtain the lemmas, PoS tags and shallow parsing results of C  X  X  sentences , which were all used in construct -ing inverted files and used as examples for GRASP to infer lexical ized pattern grammar.

Inspired by (Chen et al., 2011) indicating EFL learners tend to choose incorrect prepositions and following word forms following a VN collocation, and (Gamon and Leacock, 2010) showing fixed-length and fixed-window lexical items are the best evidence for correction , we equipped EdIt with pattern grammar rules consisting of fixed-length (from one-to five-gram) lexical sequences or VN collocations and their fixed-window usages (e.g.,  X  IN( in ) VBG X  after  X  X lay ~ role X , for window 2). 4.2 Results We examined three types of errors and the mixture of them for our correction system (see Table 1). In this table, results of ESL Assistant are shown for comparison, and grammatical suggestions are un -derscored. As suggested, lexical and PoS informa -tion in learner text s is useful for a grammar checker, pattern grammar EdIt uses is easily acces -sible and effective in both grammaticality and us -age check, and a weighted extension to Leven -shtein X  X  algorithm in EdIt accommodates substitu -tion, deletion and insertion edits to learners X  fre -quent mistakes in writing. Many avenues exist for future research and im -provement. For example, w e could augment pat -tern grammar with lexemes X  PoS information in that the contexts of a word of different PoS tags vary. Take discuss f or instance . The present tense verb discuss is often followed by determiners and nouns while the passive is by the preposition in as in  X  ... is discussed in Chapter one . X  Additionally, an interesting direction to explore is enriching pat -tern grammar with semantic role labels (Chen et al., 2011) for simple semantic check.

In summary, we have introduced a method for correcting errors in learner text based on its lexical and PoS evidence. We have implemented the method and shown that the pattern grammar and extended Levenshtein algorithm in this method are promising in grammar checking. Concerning EdIt X  X  broad coverage over different error types, simplic -ity in design, and short response time , we plan to evaluate it more fully: with or witho u t conditional probability using majority voting or not.
