 In social recommendation system s, users often publicly rate objects such as photos, news articles or consumer products. When they appear in aggregate, these ratings carry social signals such as the direction and strength of the raters X  average opinion about the product. Using a controlled expe riment we manipulated two central social signals  X  the directi on and strength of social ratings of five popular consumer products  X  and examined their interacting effects on users X  ratings. The results show an asymmetric user behavior, where th e direction of perceived social rating has a negative effect on user s X  ratings if the direction of perceived social rating is negative, but no effect if the direction is positive. The strength of perceived social ratings did not have a significant effect on users X  ra tings. The findings highlight the potential for cascading adverse effects of small number of negative user ratings on subs equent users X  opinions. H.1.2 [Models and Principles]: User/machine systems  X  X uman Factors; H.5 Information interfaces and presentation Anchoring; recommender systems; so cial influence; social signals; theory-driven design. Extant research ihas demonstr ated that people X  X  expressed opinions online can be influenced by what they perceive to be the behavior or opinions of others [11, 17]. In social recommender systems, where users can expre ss opinions about objects they come across (e.g., photos, news ar ticles, consumer products), the basic social information provided to users about others X  opinions, is the number of others as well as their  X  X verage X  rating. Examples include information about up/down or like/dislike votes made by others. These basic elements of in formation  X  or social signals  X  often influence the signals X  viewers, who in turn often express their own opinions by rating, voting, or liking. Presented together, these social signals can be thought of as representing the direction of the social rating (i.e. whether, on average, others have positive or negative opinion about the object), and the social rating strength (i.e. how many personal ratings the average social rating is based on). Our objective in this study was to identify and quantify the interacting effects of social rati ngs X  direction and strength on user behavior. We addressed the follow ing research question: can we describe the mechanisms by which social influence shapes users X  ratings of objects online? And mo re specifically, what are the interacting roles of the social influence X  X  direction and its strength? Using a web-based randomized controlled experiment, we sought to identify social influence patterns that are consistent across objects and user opinions. Social influence its underlying mechanisms have been studied extensively in a variety of online se ttings [4, 7]. For example, [18], [16] and [14] showed that experi mental manipulations arbitrarily signaling the seeming prior  X  X ucce ss X  of products on Kickstarter, downloadable songs, and articles on a social news aggregation website, respectively, led users to favorable online behavior toward these perceived  X  X uccesses X . Furthermore, higher ratings on Yelp were found to lead to in creased restaurants X  sales [3]. Social influence is often explained by a conformity effect, whereby people form or change their judgment when presented with a consensus, even when such consensus contradicts their own perception or opinion [19]. Therefore, good understanding of the mechanisms that determine social influence online is important for effective design and manageme nt of social recommendation systems. By design, social recommender systems often give way to anchoring  X  users X  bias towards information that is available to them [13]. In numerous studies, anchoring was shown to influence people X  X  behavior. For example, exposure to high and low prices can influence the prices consumers would be willing to pay for products in related and unrelated cat egories [1]. Similarly, studies in law have found that among judge s, anchors influence judicial decisions [9]. Similar findings were reported in other areas such as finance [12] and visual perception [10]. Researchers have largely focused on either the direction of the social signals  X  for example, whether the social ratings anchor users to a certain value or direction (e.g. positive vs. negative)  X  or alternatively, on the strength of these social signals, such as how strong the social consensus is, or how many others downloaded the song. For example, [7] found that when users of a movie recommender system were asked to re-rate movies while (experimentally manipul ated)  X  X redicted X  rating were presented to them, they tended to change their rating toward the  X  X rediction X  anchor. More recently, [2] showed that users X  ratings are often influenced by a recommender system X  X  (experimentally manipulated) anchors, and that th e effects of anchoring can be separated from the effects of the system X  X  perceived reliability. However, social recommender systems often present simultaneously to users both the dire ction of the social signal (i.e. the average opinion of others, represented by their average ratings), and its strength (i.e. th e number of others on which the average rating is based). Therefore, to examine the interacting effects of the social signals X  direction and strength on users X  ratings, we used a randomized experiment in which we manipulated the social ratings X  direction and strength attributed to a number of popular consumer products the experiment participants were exposed to, and compared the product ratings provided by these participants. Our hypothesis, based on the prior research reviewed above, was that both the strength and the direction of the social signals will affect users X  opinions. In particular, our hypothesis was that the interaction between strength and direction will work such that the signals X  strength will moderate the effect of their direction. In other words, a strong positive social signal about an object will lead user to express, on average, a more positive opinion about the same object than when a weak positive signal is associated with it. Similarly, a strong negative social signal would have a more negative effect than a weak negative signal. Using a between-subjects experime ntal design (see Table 1), we explored behavior patterns that are consistent across different objects and different social rating levels. Table 1. Experimental conditions: social signals X  direction and 
Social signal strength Weak Strong Participants in the experiment were recruited from Amazon Mechanical Turk (MTurk) and asked about their opinions on a number of popular consumer produc ts. Participants were paid $1.00 for their taking part in the stud y. All participants had at least 100 prior HITs of which at least 99% were approved, and were all from the US, based on the MTurk filter. Participants were presented with images and names of five online and offline consumer products, one at a time and in a random order. The products included Ch eerios, Gmail, Starbucks coffee, Twitter, and WhatsApp, selected for their popularity. Once they were presented with the products X  names and images, participants were asked to rate their familiarity with the product on a 1-10 scale, using a slider ranging between  X  X ot at all familiar with it. X  and  X  X xtremely familiar with it. X  The default value of the familiarity question was set at 5 and users could move the slider to the right (more familiar), to the left (less familiar), or leave it unchanged. The users then needed to click the Submit button to move to the next screen in whic h they rated products (see Figure 1). The familiarly question served two purposes: first, as an honesty check to screen out partic ipants who might quickly click through the task without attempting to answer honestly. To screen out such data, in the analysis of each product we moved all product ratings from users who indi cated a familiarity rating of 5 for the analyzed product. This way, we ensured that users had to make a deliberate choice. Second, the familiarity question helped us make sure that the products presented to users were across a wide range of familiarity levels. Familiarity in itself was not part of our hypotheses, since causal relationship between familiarity and opinion are difficult to disentangle: it X  X  unclear if, for example, positive opinion leads to greater familiarity (I have a good opinion so I use it more) or if familiarity leads to positive opinion (by using it more I get used to it and develop a positive opinion on it). Participants could only take part in the experiment once, and were asked to rate each product in a separate product page, using a 1-5 star ratings (see Figure 2). In each product page, the participants were assigned to one of five experimental conditions: four were manipulated social signals, assigned randomly, in which information about the average rating of the product was presented next to the product image, togeth er the number of ratings received by previous viewers (along the lines of UI design that are common to popular recommender systems such as Amazon or Netflix). A fifth experimental treatment served as a control condition, in which no social rating was pres ented to users. The ratings provided by users in the control condition served as a baseline against which to compare the effects of the social signaling experimental interventions. Social anchoring was used to represent to users the direction of the social ratings. To achieve this, we presented to the users consumer products next to their experiment ally manipulated average ratings made by  X  X ther X  participants in the study. These perceived ratings of  X  X thers X  signaled the directi on of social ratings, and were anchored in two opposing directions: a negative signal was represented by values ranging between randomly assigned 0.5-1 star (out of five possible), and a positive signal represented by values ranging between 4.5-5 st ars randomly assigned for each product (see Figure 2). The strength of the social rating s was manipulated by varying the number of  X  X thers X  who seemi ngly rated the product (see Figure 2): the number of others was set at either a single-digit number of other raters, ranging between 3-7, representing a weak social signal, or a random high numbe r (ranging between 3,000-7,000), representing a strong social signal. The difference in the strength of these chosen social signals values was shown in prior research to be perceived by users as re presenting significantly different numbers of raters [15]. We wanted all participants to interpret the social signals in a similar way. Therefore, the text  X  X verall rating (based on N previous viewers) X  was placed a bove the social rating (see Figure 2). The value of N presented to users changed between products and users, based on the expe rimental condition assigned. In order to increase the perceived authenticity of the social rating the users viewed, we increased the variety of social opinions users we exposed to throughout their expe riment interaction: we added two popular products (Colgate toothpaste and Diet Coke) for which all values of the social si gnals X  direction and strength were different from the values assigned to the products included in the experiment. The social signal di rection of these dummy products was set at 1, 2, 3 or 4 stars, and the signal X  X  strength at around 50 and 500 prior raters (non-rounded numbers were used). This addition ensured that under any experimental condition combination, no user will see the same social signals for all products. In summary, for each product they rated, users were exposed to one of five experimental conditions -four interventions combining signal direction and strength (see Table 1), and a control condition. Overall, 1040 people took part in this study. Their age ranged between 18 and 79, with the average at 34.7 (stdev = 11.7). 54.1% of the participants were women. Since ratings in which the users chose the default level of 5 as th eir familiarity level were removed from the statistical analysis, di fferent products were analyzed using different sample sizes. To explore the simultaneous effect s of the direction and strength of social ratings, Analysis of Variance (ANOVA) was performed followed by Bonferroni corrections, to compare user ratings across the five experimental conditions for each product (see Figure 3). Specifically, we compared users X  rating in the four intervention conditions with the control conditions. The following product-specific differences in user rating were found: for Starbucks coffee, we found a significant effect of Direction-Strength on user ratings (F (4, 962) = 4.24, p &lt; 0.01). User ratings in the Weak-Negati ve condition were significantly lower than user ratings in the control condition (p&lt;0.05). For Gmail, we also found a significant effect of Direction-Strength on user ratings (F (4, 880) = 6.81, p &lt; 0.001). User rating in the Strong-Negative condition were signifi cantly lower than ratings in the control condition (p&lt;0.01). For Whatsapp, we found a significant effect of Direction-St rength on user ratings (F (4, 816) = 19.27, p &lt; 0.001). Here, user ratings in both the Strong-Negative and Weak-Negative conditions were significantly different lower than ratings in the control conditi on (p&lt;0.01 in both comparisons). Similarly, for Cheerios, we found a significant effect of Direction-Strength on user ratings (F (4, 1000) = 5.25, p &lt; 0.001). User rating in the Weak-Negative were significantly lower than the ratings in the control conditions (p&lt;0.05). Finally, for Twitter we found a significant effect of Direction-Strength on user ratings (F (4, 874) = 7.03, p &lt; 0.001). The Strong-Negative condition was significantly different from the control condition with the average ratings in it lower than ratings in the control condition (p&lt;0.01). To ensure that the effects observe d were not a result of different levels of familiarity with the products, we examined the interactions between familiarity and signal direction, and found no significant effect on users X  ratings. In summary, in all five products negative social signals led to significantly lower user ratings, whereas positive signals did not have any significant effect on user ratings. The size of the social signal was not found to effect user ratings. By comparing users X  rating in the experimental conditions, we examined the simultaneous effect s of perceived social ratings X  direction and strength on users X  ratings (Figure 3). The findings point to two aspects of the rela tionship between direction and strength and their influence. First, there is an asymmetry between the effects of the positive and negative direction signal: a negative signal influences users X  expressed opinions in the expected direction (downward), but a positive signal did not lead to a similar effect in the opposite direction. This asymmetry was consistent across different products and varying leve ls of average product ratings. Second, the social signals X  strength did not have an effect on users X  ratings: none of the ten Strong -Weak positive and Strong-Weak negative pairs (i.e. two per product) exhibited significant differences between the weak and strong signals. A possible interpretation of the asymmetry found between the effects of positive and negative social signals is that negative signals may be more persuasive than positive signal s. Such a finding is consistent with prior research, and extends the research about the effectiveness of framing (i.e. the presentation of the positive or negative consequences of adhering to message reco mmendations), which found negative frames to be more persuasive than positive ones in the contexts of health behavior communication [6] a nd political campaigns [8]. It is also consistent with research showing that negative framing of messages can be more effective than positive one when the level of elaboration is low [5], as it is in many product rating settings. The mixed findings of the effects of social signals X  strength may reflect the weight people attribute to the social signals X  strength. While somewhat surprising, it may be that users pay little attention to the number of others (as oppose to these others X  opinions). Additional research is therefore required in order to explore this possible explanation further, but more data supporting it may demonstrate that a small number of responders or commenters can relatively easily sway the expressed opinions of other users who view their responses. Some suppor ting evidence in this direction has been provided in prior research [14]. A limitation of this study stems from its experimental design: by exploring only two values for each of the strength and direction treatments, the scope of the findings is limited. Future work may address this limitation by examining a larger number of interventions, and in particular, a dditional combinations of signal direction-strength levels. This study nonetheless demonstrates the importance of considering both of these factors, simultaneously, in the design and management of soci al computing systems. Another direction for future work involves additional settings in which to explore direction-strength effects. The findings presented here will be more generalizable if similar patterns are to be found in settings such as news article comments, photos, and other settings where both social signals are presented to users. Our findings have implications fo r designing and managing social computing systems. The asymmetric effects of social ratings X  direction call for a careful use of so cial signaling, especially when such signaling is at the early stages of an object X  X  presence online. Initial negative social signaling may create a cascade of increasingly negative opinions. With respect to presenting social signals X  presenting to users the number of prior raters. 
In this work we examined the simultaneous effects social ratings X  direction and strength. We showed that the direction signal is influential, but only when negative, and that social ratings X  strength does not affect users X  behavior. The findings highlight the potential effects negative social signals carry, and stress the need for designers of social computing systems to consider the risk of cascading negative input which may be self-reinforcing. 
This work was partially s upported by NSF Award IIS 1149745. [1] Adaval, R. and Wyer R. , "Conscious and Nonconscious 
Comparisons with Price Anchors," Journal of Mark eting Research, 48, 355-365, 2011. [2] Adomavicius, G., Bockstedt, J., Curley, S., and Zhang, J., "Recommender systems, consumer preferences, and anchoring effects," in Proc. Decisions @ RecSys 2011 . [3] Anderson, M. and Magruder, J., "Learning from the crowd: 
Regression discontinuity estimates of the effects of an online review database*," The Economic Journal, 122, 957-989, 2012. [4] Arazy, O., Nov, O., and Kuma r, N., "Personalityzation: UI Personalization, Theoretical Grounding in HCI and Design Research," 
AIS Transactions on Human-Computer Interaction 7, 43-69 2015. [5] Baba , S, Britton, J., and Payne, J. "Does Elaboration Increase or Decrease the Effectiveness of Negatively versus Positively Framed 
Messages?," J. of Consumer Research, 31, 199-208, 2004. [6] Block, L. and Keller, P., "Whe n to accentuate the negative," J. of 
Marketing Research, 192-203, 1995. [7] Cosley, D., Lam, S. K., Albert, I., Konstan, J. A., and Riedl, J., "Is seeing believing?: how recommender system interfaces affect users' opinions," Proc. CHI 2003 . [8] Enikolopov, R., Petrova, M., an d Zhuravskaya, E., "Media and political persuasion: Evidence from Russia," The American Economic 
Review, 101, 3253-3285, 2011. [9] Guthrie, C., Rachlinski, J., and Wistrich, A., "Blinking on the bench," Cornell Law Review, 93, p. 1, 2007. [10] Hullman, J., Adar, E., and Shah, P., "The impact of social information on visual judgments," Proc. CHI 2011. [11] Hysenbelli, D., Rubaltelli, E., and Rumiati, R., "Others X  opinions count, but not all of them," Judgment and Decision Making, 8, 678-690, 2013. [12] Johnson, J., Schnytzer, A., and Liu, S., "To what extent do investors in a financial market anchor their judgments excessively?," 
J. Behavioral Dec. Making, 22, 410-434, 2009. [13] McElroy, T. and Dowd, K., "S usceptibility to anchoring effects," 
Judgment and Decision Making, 2, 48-53, 2007. [14] Muchnik, L., Aral, S., and Tayl or, S. J., "Social influence bias: A randomized experiment," Science, 341, 647-651, 2013. [15] Nov, O. and Arazy, O., "Per sonality-Targeted Design: Theory, 
Experimental Procedure, and Preliminary Results," in Proc. CSCW, 2013. [16] Salganik, M., Dodds, P., and Watts, D., "Experime ntal study of inequality and unpredictability in an artificial cultural market," 
S cience, 311, 854-856, 2006. [17] Sun, M., "How Does the Va riance of Product Ratings Matter?," 
Management Science, 58, 696-707, 2012. [18] van de Rijt, A., Kang, S. M., Restivo, M., and Patil, A., "Field experiments of success-br eeds-success dynamics," PNAS, 111, 6934-6939, 2014. [19] Zhu, H., Huberman, B., and Luon, Y., "To switch or not to switch," Proc. CHI 2012. 
