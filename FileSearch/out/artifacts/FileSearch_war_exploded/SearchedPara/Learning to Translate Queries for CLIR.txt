 The statistical machine translation (SMT) component of cross-lingual information retrieval (CLIR) systems is often regarded as black box that is optimized for translation qual-ity independent from the retrieval task. In recent work [10], SMT has been tuned for retrieval by training a reranker on k -best translations ordered according to their retrieval per-formance. In this paper we propose a decomposable proxy for retrieval quality that obviates the need for costly inter-mediate retrieval. Furthermore, we explore the full search space of the SMT decoder by directly optimizing decoder parameters under a retrieval-based objective. Experimen-tal results for patent retrieval show our approach to be a promising alternative to the standard pipeline approach. H.3.3 [ Information Storage and Retrieval ]: Informa-tion Search and Retrieval; I.2.7 [ Artificial Intelligence ]: Natural Language Processing Algorithms, Experimentation Machine translation, cross-lingual retrieval, patent search
Cross-Lingual Information Retrieval (CLIR) addresses the problem of ranking documents whose language differs from the query language. One of the simplest yet well perform-ing approaches to CLIR is based on query translation using an existing Statistical Machine Translation (SMT) system which is treated as a black box. Thus, a monolingual re-trieval engine does not need to be altered after translating queries into the target language. This approach is justified First two authors contributed equally to the work.
 in the absence of cross-lingual relevance annotations, but in the presence of large parallel text corpora for SMT training
In this work we argue that one should not only  X  X ook in-side X  the black box of the SMT system [16], but directly opti-mize SMT for the CLIR task at hand. We address this prob-lem by discriminative training techniques which are widely used in the SMT community, and use automatically con-structed relevance judgments from linked data. We show that a decomposable proxy for retrieval quality in training alleviates the problem of a costly intermediate retrieval step in reranking frameworks [10], and allows us to make use of the full, and lexically more diverse, decoder search space to optimize query translations for the CLIR task.

Our approach combines information specific to translation and to retrieval in one model targeted to CLIR: Basic trans-lation units (phrases [7] or hierarchical phrase rules [1]) are estimated on parallel training data, while parameter opti-mization for lexicalized features that can boost or demote word/phrase translations is done on relevance judgments of existing queries. We present experiments in the domain of patent prior-art search where parallel training data for ma-chine translation and relevance judgments for retrieval are available in large amounts. The results from our experi-mental evaluation shows our approach to be a promising alternative to the standard pipeline approach.
Common techniques for modulating query expansion with lexical variations use either comparable corpus statistics [14] or the k -best lists of an SMT system [16]. Experimental results show the latter approach to be superior to state-of-the-art approaches based on direct translation. In [9], consistent preprocessing of MT and IR training data yielded some improvements for retrieval and translation speed. [10] is the work closest to our approach. They present an approach to learn a reranking model on k -best translations that are ordered according to retrieval performance. The approach requires expensive retrieval for each derivation in the k -best list. They show improvements over a regular SMT baseline on a small set of parallel queries. However, besides the need for costly retrieval in training, the features of the reranking mode cannot be integrated into an SMT decoder, thus limiting the usefulness of their approach.

A tighter integration with a decoder requires the target quality to be decomposable over transductions of its search space. Such approximations were proposed and evaluated
For example, see Google X  X  CLIR approach [3]. in [13], however, only for translation-specific measures. Sim-ilar to this work, we design a decomposable approximation for CLIR measures (MAP, NDCG) and present a learning algorithm for tuning SMT towards retrieval quality.
In this paper, we will use the following notational con-ventions: For a translation q of a foreign query f , a (mono-lingual) real-valued scoring function S ir ( q,d ) assigns a re-trieval score to each document d in a collection C . Relevance judgments for C are expressed by a function rel ( f,d )  X  0 that assigns to each query f and document d a relevance level (which is zero for irrelevant documents, and increasing values indicate higher relevance). The ranking induced by S ir ( q,d ) can be evaluated using common rank-based met-rics, such as Mean Average Precision (MAP) or Normalized Discounted Cumulative Gain (NDCG). For a term-based scoring function S ir ( q,d ), queries and documents are repre-sented as bag-of-word vectors, and S ir ( q,d ) is decomposable over query terms t in q . In this work we use Okapi BM25 S ir ( q,d )  X  bm 25( q,d ) = P t  X  q bm 25( t,d ).
State-of-the-art SMT systems compute the target-language query q of a foreign query f by recombining, through con-catenation and reordering, small bilingual translation units called phrases (contiguous substrings in phrase-based SMT) or synchronous grammar rules (in hierarchical phrase-based SMT). These units are the result of a complex process that starts with word-to-word alignments and culminates with assigning various numerical confidence scores ( feature func-tions or models ) to the extracted units [7].

The union of complete hypotheses over the large number of possible input sentence splits, applicable translation op-tions, and reordering possibilities, is called the search space , and is commonly structured as directed acyclic graphs ( lat-tices ) or hypergraphs . Inference ( decoding ) in SMT relies on maximizing the hypothesis score over the search space, i.e., maximizing the likeliness of obtaining a word alignment a of the target q given source f . This is usually parameterized as a linear model, S smt ( q,a,f ) = w  X  h q,a,f , where h a numerical vector of features and w is a parameter vector: E f is the set of reachable translations/alignments that the SMT system can produce for the input f . For notational convenience we will omit dependence of the max operator and features h on a .

An important computational property of the quantity un-der arg max is that its components can be decomposed (through summation) over the scores of the individual units that are used in the alignment of q and f . This property is required to obtain a compact representation of the decoder search space, which can then be explored efficiently with dynamic programming (e.g., quantities like (1) are computed on lat-tices using shortest path algorithms). The optimal value for w is found in a tuning process that tries to replicate human reference translations by maximizing n -gram-based
BM25 parameters were set to k 1 = 1 . 2, b = 0 . 75. precision measures such as BLEU [11] on a development set consisting of pairs of source and target sentences.
We use the structured SVM margin-rescaling framework [15] to learn a new w adapted to the CLIR task. The framework assumes a unit-decomposable penalty  X ( q,q 0 )  X  0, defined on structured outputs (translations), suffered for producing q instead of q 0 ; it is zero if q = q 0 and gracefully increases as q deviates more and more from q 0 . When optimizing for translation quality, the following loss function is minimized: where q  X  f is either a desired reference translation r f reachable substitute q  X  f = max q (  X   X ( q,r f )) with  X  approx-imating an inverted SMT quality measure.
 In CLIR, a single desired output does not exist, but a set C f of relevant documents for each foreign query f . Therefore we define a new function  X ( q, C + f ) = max q S rel ( q, C S rel ( q, C + f ), that is the difference in best achievable approxi-mate retrieval quality and retrieval quality for translation q . We will define S rel ( q, C + f ) in section 3.3. Let us define fear , hope and oracle derivations [2, 5] for a foreign query f : and the corresponding feature vectors, h fear q  X  h q fear The oracle derivation is the best derivation possible, i.e. with the smallest penalty in E f . The fear is the deriva-tion maximizing the model score minus a confidence margin equal to the penalty (remember that  X  = 0 if q = q hope ). As the static oracle derivation can be too idiosyncratic for the linear model to produce, the hope includes the model score to find a reasonable compromise. Additionally, a hope de-pending on the (changing) model score increases exploration of the search space during training.
 With the new penalty we consider two losses to minimize: For a learning rate  X  , the respective (sub)gradient descent updates are: The update (4) for the standard structured loss (2) [15] in-creases weights of the features present in the oracle deriva-tion and decreases for the ones in the fear. The ramp loss objective in equation (3) [5] boosts weights of features found in the current hope derivation. Table 1: Oracle performance on the small training set for phrase-based (Moses) and hierarchical phrase-based (cdec) SMT decoders.
In this work, we are interested in tuning an SMT system for retrieval performance. Even though some correlation between BLEU scores and MAP has been shown [4], we note that an n -gram based precision metric like BLEU focuses strongly on the problem of reordering translation units to accommodate for higher n -gram matches and is thus not a suitable optimization metric for retrieval models, that do not take word order into account. A suitable optimization metric should either directly optimize the rank of relevant documents ( learning-to-rank ), or, more related to the task of translation, optimize lexical choices in the translation to improve term matching and adjust weights for reordering and language models correspondingly.

Directly optimizing rank-based metrics is problematic be-cause a full retrieval for each derivation generated by the SMT system is required. This usually restricts the search space for oracle translations to the k -best list of deriva-tions [10]. To alleviate this problem, we abstract away from the ranking problem and approximate retrieval quality of a translation q with its relevance score S rel ( q, C + f ) to the set of relevant documents C + f = { d  X  C| rel ( f,d ) &gt; 0 } . Let C f,k = { d  X  C| rel ( f,d ) = k } be the set of relevant docu-ments in the k -th relevance level. Since BM25 is decompos-able over query terms, we directly assign partial relevance scores to terms t in the translated query q : S wh ere the  X  k are relevance weights adjusting the importance of each relevance level k in C . To ensure good quality of the oracle translations, we found optimal values for  X  k by grid search with a step size 0 . 1 and a constraint P k |  X  k | = 1. So far we only reward terms that appear in C + f . While the SMT system thrives to generate relevant terms it produces them in phrases, together with connecting words as dictated by the translation model. If such  X  X y-product X  terms appear sufficiently often in irrelevant documents, this can inadver-tently boost their ranks. To counterbalance this effect we experimented with two penalties, with weight  X  0  X  0: (1) a junk-word penalty that fires on insertion of irrelevant terms, or (2) a word penalty that acts on each word in the deriva-tion. A comparison of oracle configurations in terms of the maximal performance (over the tested range of  X  k and  X  0 found on the training set is given in Table 1. For training we used oracles found with junk penalty for Moses, and with word penalty for cdec.
We conducted experiments on the BoostCLIR 3 dataset, www.cl.uni-heidelberg.de/statnlpgroup/boostclir a corpus of Japanese (JP) &amp; English (EN) patent abstracts [12], using two open-source MT decoders, phrase-based Moses and hierarchical SCFG decoder cdec 5 .

We took NTCIR-7 data (1.8M parallel sentences) from the years 1993-2000 for SMT training and the NTCIR-8 test collection (2k sentences) for parameter tuning. Additionally to a dozen of vanilla dense SMT features, both decoders in-cluded lexicalized sparse features based on word alignments, indicating source word deletions, target word insertions, and word-to-word mappings. Both baseline systems were tuned with their respective MIRA [2] implementations. On held-out parallel test data, Moses and cdec achieved 0.2640 and 0.2829 BLEU, respectively.

For the ranking data, EN patents are regarded as relevant to the query JP patent, if they are cited by either the ap-plicant or the patent examiner [6]. We assigned relevance level (2) for examiner citations, level (1) for applicants X  own citations, and level (0) otherwise. A patent abstract con-tains about 5 sentences on average. Before running mono-lingual BM25-based retrieval, sentence-split query transla-tions were concatenated back into a single query. The data was split into two training subsets of 200 and 1,000 queries (resp., ' 1k and ' 5k sentences) and dev/test subsets (of 400 queries each), all sampled without replacement. Oracle tuning and the training to determine the best learning con-figuration (see below) were done on the smaller training set and evaluated on the development set. We ran our train-ing for 20k iterations starting from the MIRA weights found during the SMT tuning step of respective decoders, with the learning rate  X  = 0 . 001.

Figure 1 shows experimental MAP 6 retrieval results for our approach evaluated for phrase-based (Moses) and hier-archical phrase-based (cdec) translation models. Small but stable improvements are gained only for the phrase-based system. 7 We show results for both updates (4) and (5). We see that ramp loss updates generally perform better than SVM updates for Moses. This is due to the ability to trade off the capabilities of the model against the best possible approximate performance on the retrieval task in the ramp loss setting. The SVM update is forced to perform  X  X old up-dates X  towards the oracle which can result in updates that overfit to particular oracles [8]. Furthermore, we find it to be beneficial to constrain updates by freezing the dense features after MIRA training on parallel data, and tune only parame-ters of sparse lexicalized features that promote or demote the insertion, deletion, and translation of particular words. Ad-ditionally, we test two decoding evaluation setups of search space rescoring and redecoding . The former reuses hyper-graphs/lattices produced with the MIRA-tuned weights and applies new weights to find an alternative, CLIR-optimized, derivation. The latter runs the decoder directly with the new weights. Both constraints (freezing and rescoring) show that the farther the setup strays away from the original MIRA model, the more difficult becomes generalization to unseen data. This suggests that it is crucial to find the optimal com-bination of translation-and retrieval-specific information for both inference and learning. www.statmt.org/moses www.cdec-decoder.org
Evaluating with NDCG results in the same optimal config-urations for both decoders.
An implementation of the reranking approach [10] with our set of features scored about ' 0 . 002 MAP above baseline.  X  X edecode, svm X  curve is below the visible part of the plot. T able 2: Test performance of the chosen learning con-figurations for Moses (rescore: ramp/frz@9k, redecode: svm/frz@8k) and cdec (svm/frz: rescore@2k, redecode@6k). Superscripts denote p -values obtained by a paired random-ization test with respect to the baseline.

Table 2 shows test results for models trained on the bigger training set using the best settings found on the develop-ment set (see caption). For the hierarchical system improv-ing over the significantly (at level p = 0 . 01) stronger baseline proves to be difficult. One reason could be a relatively harsh pruning strategy in cdec, governed by the language model, which produces lexically less diverse search spaces. This is supported by much worse oracles (Table 1) and fewer ac-tive sparse features in the learned models when compared to Moses (17k vs. 23k on the small training set).
We presented an approach for tuning an SMT system for cross-lingual retrieval. Our approach is efficient since it uses a decomposable proxy for retrieval quality that can be com-puted directly on the translation hypergraph or lattice in training. It is effective since optimal weights of retrieval-governing sparse features are accessible to the decoder, which combines this information with translation-specific dense fea-tures for optimal query translation in a cross-lingual re-trieval setup.

Acknowledgments. This research was supported in part by DFG grant RI-2221/1-1  X  X ross-language Learning-to-Rank for Patent Retrieval X . [1] D. Chiang. Hierarchical phrase-based translation. [2] D. Chiang, Y. Marton, and P. Resnik. Online [3] J. Chin, M. Heymans, A. Kojoukhov, J. Lin, and [4] A. Fujii, M. Utiyama, M. Yamamoto, and T. Utsuro. [5] K. Gimpel and N. Smith. Structured ramp loss mini-[6] E. Graf and L. Azzopardi. A methodology for building [7] P. Koehn. Statistical Machine Translation . Cambridge [8] P. Liang, A. Bouchard-C X ot  X e, D. Klein, and B. Taskar. [9] W. Magdy and G. J. Jones. Studying machine [10] V. Nikoulina, B. Kovachev, N. Lagos, and C. Monz. [11] K. Papineni, S. Roukos, T. Ward, and W. Zhu. BLEU: [12] A. Sokolov, L. Jehl, F. Hieber, and S. Riezler. [13] A. Sokolov, G. Wisniewski, and F. Yvon. Lattice [14] T. Talvensaari, J. Laurikkala, K. J  X  arvelin, M. Juhola, [15] I. Tsochantaridis, T. Joachims, T. Hofmann, and [16] F. Ture, J. Lin, and D. W. Oard. Looking inside the
