 Peter Haider haider@cs.uni-potsdam.de Tobias Scheffer scheffer@cs.uni-potsdam.de We address the problem of identifying botnets that are capable of exploiting the internet in a coordinated, dis-tributed, and harmful manner. Botnets consist of com-puters that have been infected with a software virus which allows them to be controlled remotely by a bot-net operator. Botnets are used primarily to dissemi-nate email spam, to stage distributed denial-of-service (DDoS) attacks, and to harvest personal information from the users of infected computers (Stern, 2008). Providers of computing, storage, and communication services on the internet, law enforcement and prose-cution are interested in identifying and tracking these threats. An accurate model of the set of IP addresses over which each existing botnet extends would make it possible to protect services against distributed denial-of-service attacks by selectively denying service re-quests from the nodes of the offending botnet. Evaluating botnet models is difficult, because the ground truth about the sets of IP addresses that con-stitute each botnet at any given time is entirely un-available (Dittrich &amp; Dietrich, 2008). Many studies on botnet identification conclude with an enumeration of the conjectured number and size of botnets (Zhuang et al., 2008). Reliable estimates of the current size of one particular botnet require an in-depth analysis of the communication protocol used by the network. For instance, the size of the Storm botnet has been assessed by issuing commands that require all active nodes to respond (Holz et al., 2008). However, once the communication protocol of a botnet is understood, the botnet is usually taken down by law enforcement, and one is again ignorant of the remaining botnets. We develop an evaluation protocol that is guided by the basic scientific principle that a model has to be able to predict future observable events. We focus on email spam campaigns which can easily be observed by monitoring the stream of messages that reach an email service provider. Our evaluation metric quantifies the model X  X  ability to predict which email spam campaign a given IP address is going to participate in. Previous studies have employed clustering heuristics to aggregate IP addresses that participated in joint campaigns into conjectured botnets (Xie et al., 2008; Zhuang et al., 2008). Because an IP address can be a part of multiple botnets during an observation inter-val, this approach is intrinsicaly inaccurate. The prob-lem is furthermore complicated as it is possible that a botnet processes multiple campaigns simultaneously, and multiple botnets may be employed for large cam-paigns. We possess very little background knowledge about whether multiple networks, each of which has been observed to act in a coordinated way, really form one bigger, joint network. Also, distributional assump-tions about the generation of the observable events are very hard to motivate. We address this lack of prior knowledge by directly modeling the conditional distri-bution of clusterings given the observable data, and by searching for minimal clusterings that refrain from merging networks as long as empirical evidence does not render joint membership in a botnet likely. Other studies have leveraged different types of data in order to identify botnets. For example Mori et al. (2010); DiBenedetto et al. (2010) record and cluster fingerprints of the spam-sending hosts X  TCP behavior, exploiting that most bot types use their own protocol stacks with unique characteristics. Yu et al. (2010) identify bot-generated search traffic from query and click logs of a search engine by detecting shifts in the query and click distributions compared to a back-ground model. Another angle to detect bots is to mon-itor traffic from a set of potentially infected hosts and find clusters in their outgoing and incoming packets (Gu et al., 2008; John et al., 2009); for example, DNS requests of bots used to connect to control servers (Choi et al., 2009) or IRC channel activity (Goebel &amp; Holz, 2007). The major difference here is that ac-cess to all the traffic of the hosts is required, and thus these methods only work for finding infected hosts in a network under one X  X  control.
 The rest of this paper is organized as follows. In Sec-tion 2, we discuss our approach to evaluating botnet models by predicting participation in spamming cam-paigns. In Section 3, we establish the problem of min-imal graph clustering, devise a probabilistic model of the conditional distribution of clusterings given the input graph, and derive a Gibbs sampler. Section 4 presents a case study that we carried out with an email service provider. Section 5 concludes. The ground truth about the sets of IP addresses that constitute each botnet is unavailable. Instead, we fo-cus on the botnet model X  X  ability to predict observable events. We consider email spam campaigns which are one of the main activities that botnets are designed for, and which we can easily observe by monitoring the stream of emails that reach an email service provider. Most spam emails are based on a campaign template which is instantiated at random by the nodes of a bot-net. Clustering tools can identify sets of messages that are based on the same campaign template with a low rate of errors (Haider &amp; Scheffer, 2009). A single cam-paign can be disseminated from the nodes of a single botnet, but it is also possible that a botnet processes multiple campaigns simultaneously, and multiple bot-nets may be employed for large campaigns.
 We formalize this setting as follows. Over a fixed pe-riod of time, n messages are observed. An adjacency matrix X of the graph of messages reflects evidence that pairs of messages originate from the same bot-net. An edge between nodes i and j  X  X epresented by an entry of X ij = 1 X  X s present if messages i and j have been sent from the same IP address within the fixed time slice, or if a campaign detection tool has assigned the messages to the same campaign cluster. Both types of evidence are uncertain, because IP ad-dresses may have been reassigned within the time slice and the campaign detection tool may incur errors. The absence of an edge is only very weak and unreliable ev-idence against joint botnet membership, because the chance of not observing a link between nodes that are really part of the same botnet is strongly dependent on the observation process.
 The main part of this paper will address the problem of inferring a reflexive, symmetric edge selector matrix Y in which entries of Y ij = 1 indicate that the messages represented by nodes i and j originate from the same botnet. The transitive closure Y + of matrix Y defines a clustering C Y of the nodes. The clustering places each set of nodes that are connected to one another by the transitive closure Y + in one cluster; the clustering is the union of clusters: Because Y + is reflexive, symmetric and transitive, it partitions all nodes into disjoint clusters; that is, c  X  c 0 =  X  for all c,c 0  X  C Y , and S c  X  C An unknown process generates future messages which are characterized by two observable and one latent variable. Let the multinomial random variables s indi-cate the campaign cluster of a newly received message, a indicate the IP address, and let latent variable c indi-cate the originating cluster, associated with a botnet. We quantify the ability of a model C Y to predict the observable variable s of a message given a in terms of the likelihood Equation 2 assumes that the distribution over cam-paigns is conditionally independent of the IP address given the botnet; that is, botnet membership alone determines the distribution over campaigns.
 Multinomial distribution P ( s | c,C Y ) quantifies the likelihood of campaign s within the botnet c . It can be estimated easily on training data because model C Y fixes the botnet membership of each message. Multi-nomial distribution P ( c | a,C Y ) quantifies the probabil-ity that IP address a is part of botnet c given model C
Y . Model C Y assigns each node X  X hat is, message X  to a botnet. However, an address can be observed multiple times within the fixed time slice, and the bot-net membership can change withing the time interval. Hence, a multinomial distribution P ( c | a,C Y ) has to be estimated for each address a on the training data, based on the model C Y . Note that at application time, P ( c | a,C Y ) and hence the right hand side of Equation 2 can only be determined for addresses a that occur in the training data on which C Y has been inferred. Let X be the adjacency matrix of the input graph with n nodes. Entries of X ij = 1 indicate an edge between nodes i and j which constitutes uncertain evidence for joint membership of these nodes in a botnet. The in-put matrix is assumed to be reflexive ( X ii = 1 for all i ), and symmetric ( X ij = X ji ).
 The outcome of the clustering process is represented by a reflexive, symmetric edge selector matrix Y in which entries of Y ij = 1 indicate that nodes i and j are as-signed to the same cluster, which indicates that the messages originate from the same botnet. The tran-sitive closure Y + of matrix Y defines a clustering C Y of the nodes according to Equation 1. Intuitively, the input matrix X can be thought of as data, whereas output matrix Y should be thought of as the model that encodes a clustering of the nodes. A trivial base-line would be to use X itself as edge selector matrix Y . In our application, this would typically lead to all messages being grouped in one single cluster.
 No prior knowledge is available on associations be-tween botnets in the absence of empirical evidence. If the adjacency matrix X does not contain evidence that links nodes i and j , there is no justification for grouping them into the same cluster. This is reflected in the concept of a minimal edge selector matrix . Definition 1. A selector matrix Y and, equivalently, the corresponding graph clustering C Y , is minimal with respect to adjacency matrix X if it satisfies where ( Y +  X  X ) ij = Y + ij X ij is the Hadamard product that gives the intersection of the edges of Y + and X . Intuitively, for every pair of nodes that are connected by the adjacency matrix, selector matrix Y decides whether they are assigned into the same cluster. Nodes that are not connected by the adjacency matrix X must not be linked by Y , but can still end up in the same cluster if they are connected by the transitive closure Y + . Equation 3 also ensures that the transi-tive closure Y + does not differ from Y for any pair of nodes i,j that are connected by the adjacency matrix. This enforces that no two different minimal selector matrices have the same transitive closures and there-fore induce identical clusterings, which would inflate the search space. 3.1. Probabilistic Model This section derives a probabilistic model for the min-imal graph clustering problem. Its most salient prop-erty is that it is not based on a generative model of the graph, but instead directly models the conditional probability of the clustering given the adjacency ma-trix X . This circumnavigates systematic errors caused by inaccurate distributional assumptions for the gen-eration of the adjacency matrix X .
 We define the posterior distribution over all reflexive and symmetric matrices Y that are minimal with re-spect to X .
 Definition 2. Let X  X  { 0 , 1 } n  X  n be a reflexive and symmetric adjacency matrix. Then, Y X  X  { 0 , 1 } n  X  n is the set of matrices that are reflexive, symmetric, and minimal with respect to X .
 In our application, each node is an element of at most two cliques because each message is connected to all other messages that have been sent from the same IP address, and to all other messages that match the same campaign template. If a template or an address has been observed only once, either of these cliques may resolve to just the node itself. Let Q X denote the set of cliques in X , and let C q Y be the projection of clustering C Y to the elements of q  X  Q X . Within each clique q  X  Q X , any clustering C q Y is minimal with respect to X because X ij = 1 for all i,j  X  q , and therefore any reflexive, symmetric, and transitive clustering of q is possible. We model the probability distribution over clusterings of each clique q  X  Q X as a Chinese Restaurant process (Pitman &amp; Picard, 2006) with concentration parameter  X  q &gt; 0: Equation 5 now defines the distribution over all par-tition matrices Y  X  Y X as a product over all cliques in Q X , where the clique specific concentration param-eters are collected into  X  = {  X  q : q  X  Q X } .
P ( C Y | X,  X  )  X  Equation 5 can be seen in analogy to the factoriza-tion of the posterior over cliques in conditional ran-dom fields. However, because the minimality property has non-local effects on the possible values that edges can assume, this factorization is not equivalent to the assumption of the Markov property on which the fac-torization theorem for random fields is based (Ham-mersley &amp; Clifford, 1971).
 Normalization of Equation 5 is computationally in-tractable because it requires the enumeration of the elements of Y X . However, the Gibbs sampler that we will derive in the following only has to normalize over all values of the random variables that are reassigned in each step of the sampling process. 3.2. Inference Computing the posterior distribution P ( C Y | X,  X  ) is a generalization of the inference problem for conven-tional Chinese Restaurant process models. When all entries of X are one, the graph has only one clique and the special case of a Chinese Restaurant process is ob-tained. In this case, depending on the concentration parameter, the outcome may be one single cluster of all nodes. Maximization of the posterior as well as full Bayesian inference are intractable even for this special case because of the non-convexity of the posterior and the exponential number of possible clusterings. Hence, in this section we describe a Gibbs sampler that gen-erates unbiased samples from the posterior.
 Algorithm 1 Assignment space Y Y i for Gibbs sampler Input: Current partitioning matrix Y 1: let q 1 ,...,q k be the cliques with element i 2: let Y i =  X  3: for all combinations c 1  X  C q 1 Y  X  {{ i }} , . . . , 5: let Y 0 il = Y 0 li = 1 if and only if l  X  c j for any j 7: add Y 0 to Y Y i 8: else 9: discard Y 0 10: end if 11: end for Return: Y Y i , all reflexive, symmetric, minimal parti-Gibbs samplers divide the set of random variables into smaller subsets and iteratively draw new values for one subset given the values of the remaining variables. For the observations to form an unbiased sample, the ran-dom variables have to be partitioned such that the sequence of assignments formes an ergodic Markov chain; that is, each state has to be reachable from each other state. In our case, perhaps the most obvious-seeming approach would be to factor the posterior over individual edges. However, since many matrices Y vi-olate the minimality condition, the chain of alterations of single matrix entries would not in general be ergodic. Therefore, we devise a sampling algorithm that jointly samples the i -th row and column (the i -th row and column are identical because Y is symmetric). Let Y 0 i refer to the i -th row and column of the new matrix Y , and let Y 0  X  i = Y  X  i refer to the remaining matrix entries, such that Y 0 = Y 0 i  X  Y 0  X  i . Equation 6 expands the definition of the conditional probability; Equation 7 factorizes over the cliques, according to Equation 5. Equation 8 omits all terms that are constant in Y the denominator, and all cliques in which node i does not occur. Normalization of the right hand side of Equation 8 is now over all values for Y 0 i that render Y reflexive, symmetric, and minimal with respect to X . The main computational challenge here is to determine the set Y Y i of reflexive, symmetric, minimal matrices that can be derived from Y by changing row and col-umn i . Since Equation 8 has to be normalized, all of its elements have to be enumerated. An obvious but inefficient strategy would be to enumerate all up to 2 n assignments of Y i and test the resulting matrix for reflexivity, symmetry, and minimality.
 However, most values of Y 0 i violate minimality and need not be enumerated. Algorithm 1 constructs the set Y Y i in O ( n k ), where k is the maximal number of cliques that each node is a member of. In our applica-tion, each node is an element of up to two cliques X  X he set of messages with a shared IP address, and the set of messages that follow the same campaign template. Hence, in our case, the algorithm has a worst-case ex-ecution time of O ( n 2 ). In most cases, the number of clusters in each of the two cliques is much lower than n , and thus much fewer than n 2 cases are considered. Theorem 1. Given an adjacency matrix X and an edge selector matrix Y, Algorithm 1 constructs a set i that contains all Y ive, symmetric, and minimal with respect to X . The execution time of Algorithm 1 is in O ( n k ) when each node is a member of at most k cliques in X .
 Proof. Let node i be an element of cliques q 1 ,...,q k . On these cliques, the current partitioning matrix Y in-duces clusterings C q 1 Y ,...,C q k Y with at most n clusters each. When Y 0 i links node i to more than one cluster from any C q l Y , then by the definition of a clustering in Equation 1 these clusters are merged in C Y 0 . However, when Y 0 i links node i to two clusters with at least one other element in q l each, say j and l with Y jl = 0, the transitive closure Y 0 + has to add at least an edge to Y 0  X  i that links j and l . Since j and l are in clique q , they have to be connected by the adjacency ma-trix, X jl = 1. But Y 0 jl = 0, Y 0 + jl = 1 and X jl violates the minimality condition defined in Equation 3. Therefore, Y 0 must only merge clusters that have elements in different cliques, and so at most n k com-binations of clusters can lead to minimal matrices Y 0 when merged. Reflexivity and symmetry of Y 0 follow from reflexivity and symmetry of X . The execution time is dominated by the enumeration of all n k many combinations of clusters in Line 3.
 The Gibbs sampler iteratively samples Y t +1 according to P ( Y 0 i is created from the predecessor by cycling over the rows that are resampled X  X hat is, i t = t mod n . The conditional is defined over the set Y Y t i argue that a sequence of matrices created by the Gibbs sampler is an ergodic Markov chain.
 Theorem 2. For  X  q &gt; 0 , the sequence Y 0 ,...,Y T godic Markov chain.
 Proof. The sequence is a Markov chain because each element is sampled from a distribution that is param-eterized only with the preceding matrix and the row that is to be resampled. For it to be ergodic we have to prove that from any state Y, every other state Y 0 can be reached. With the  X  q &gt; 0, Equation 5 is posi-tive for all states in Y X that are reflexive, symmetric, and minimal with respect to X . In each step the sam-pler can only change row and column i . Hence, any because by Theorem 1, all elements of Y Y t ( t mod n ) are reflexive, symmetric, minimal with respect to X and differ from Y t only in row and column i .
 To begin with, we argue that from any state Y the identity matrix I can be reached which connects each node only to itself. To prove this, it suffices to show that for any i and any Y , a state I Y,i with I Y,i ii = 1 for all i , I Y,i ij = 0 for all j 6 = i , and I Y,i jk = Y all j,k 6 = i can be reached directly from state Y by sampling row and column Y i . By the definition of Y Y i the Gibbs sampler can directly reach state I Y,i from Y if I Y,i is symmetric, reflexive, minimal with respect to X , and differs from Y only in the i -th row and column. By its definition, it is clear that I Y,i differs from Y only in the i -th column and row, and that it is reflexive. Since Y is symmetric and the i -th row and column of I
Y,i are identical, I Y,i has to be symmetric as well. It remains to be shown that I Y,i = I Y,i +  X  X . We split the proof of this claim into two parts. First, we show that the i -th row and column of I Y,i are equal to the i -th row and column of I Y,i +  X  X . Intuitively, because I
Y,i connects node i only to itself, the transitive closure adds nothing, and the Hadamard product has no effect because X is reflexive. Formally, this can be shown via an inductive proof along the following construction of the transitive closure of I Y,i . Let R 0 = I Y,i . For all R ik = 1 and R R l  X  1 contains an open triangle of edges R l  X  1 R kj = 1, then R 1. Then the limit lim l  X  X  X  R l is the transitive closure ( I
Y,i ) + . Now inductively, if for all j : R l  X  1 for all j : R l ij = 0, and from I Y,i i = 0 it follows that I Secondly, we show that all elements in I Y,i + except the i -th row and column remain unchanged from Y + : From the monotonicity of the transitive closure op-erator and I Y,i  X  Y it follows that ( I Y,i +  X  X )  X  i ( Y +  X  X )  X  i . Furthermore, since the transitive closure operator only adds positive edges, ( I Y,i +  X  X )  X  i ( I
Y,i  X  X )  X  i = ( Y  X  X )  X  i , which is in turn equal to ( Y +  X  X )  X  i because Y itself is minimal with respect to X . Both inequalities together give us ( I Y,i +  X  X )  X  i ( Y +  X  X )  X  i , and because I Y,i  X  i = Y  X  i we have that I
Y,i  X  i = ( I Y,i +  X  X )  X  i . Together with the first part finally I Y,i = I Y,i +  X  X .
 This establishes that I Y,i can be reached by the Gibbs sampler from any state Y for any i , and thus by repeat-edly using this state transition for all i , I is reachable. The reachability relation is symmetric because Y t +1 is constructed from Y t by reassigning one column and row which can be reversed, and Y t is required to be in Y
X , and therefore can be reached from Y t +1 . Hence, from any state Y , every other state Y 0 can be reached via the state I , and ergodicity holds. 3.3. Prediction The Gibbs sampler creates a chain Y 0 ,...,Y T of ma-trices, governed by the posterior P ( Y | X,  X  ). In order to predict which campaign s a given IP address a will participate in, we can approximate the Bayesian infer-ence of c (Equation 9) using the chain (Equation 10). Equation 1 decomposes P ( s | a,C Y ) into two multi-nomial distributions that can be estimated from the available data. In this section, we conduct a case study on botnet de-tection. Since the gound truth about which botnets are currently active and which hosts they are com-posed of is not available, we evaluate the model in terms of its accuracy of predicting which spam cam-paign a given IP address will participate in.
 We record incoming spam emails over a period of 11 days in January 2012 at a large email service provider. We select only emails that have been blacklisted on the grounds of three content-based filtering techniques: The first is a set of manually maintained regular ex-pressions, each tailored to match against all spams of one particular campaign. The second is a list of semi-automatically generated, campaign-specific fea-ture sets (Haider &amp; Scheffer, 2009). A feature set con-sists of words and structure flags and is the intersection of all previously observed emails from the campaign. The third is a blacklist of URLs that spam emails link to. Thus, we have a reliable partitioning of all emails into spam campaigns.
 We exclude IP addresses of known legitimate forward-ing servers that relay inbound emails according to their users X  personal filtering policies. To this end, we track the IP address from the last hop in the transmission chain. If the address has a valid reverse DNS entry that matches a domain from a list of well-known email service providers, we omit the message.
 Equation 5 allows for individual values of the concen-tration parameters  X  q for each clique q in the email graph X . We use two distinct values: a value of  X  a for all cliques that share a joint IP address, and a value of  X  s for all cliques that match a joint campaign. Param-eters  X  a and  X  s are tuned to maximize the AUC metric on the data recorded on the first day. The data of the remaining ten days is then used for evaluation. Within each day, the Gibbs sampler infers a chain of cluster-ings on the data of the first 16 hours. The emails of the last 8 hours with a sender IP address that has pre-viously occurred are used as test data. Emails from IP addresses that have not been seen before are ex-cluded, since no informed decision can be made for them. The proportion of IP addresses that have not previously been observed depends on the proportion of the global email traffic that the server gets to observe. Also, we exclude emails from campaigns that appear less than 100 times. In total, this data collection pro-cedure results in 701,207 unique pairs of campaigns and IP addresses in the training sets and 71,528 in the test sets. Each test email serves as a positive example for its campaign and a negative example for all other campaigns. 4.1. Reference Methods We compare the Minimal Graph Clustering model to three baselines. The first, threshold-based baseline is an agglomerative clustering algorithm based on a threshold heuristic, adapted from Zhuang et al. (2008). It operates on the assumption that each campaign is sent by only one botnet. Initially, every campaign con-stitutes its own cluster. Clusters c and c 0 are greedily merged if their fraction of overlapping IP addresses exceeds a threshold. This fraction is defined as
P where I is the indicator function and s i the campaign of the i -th email. Given a clustering C of emails, multinomial distributions P ( s | c ) and P ( c | a,C ) have been estimated on the training data. The clustering threshold is tuned for performance on the first day. The second baseline is spectral clustering , where we tune the number of clusters and similarity values for emails with matching campaign or IP address. We use the implementation of Chen et al. (2011).
 The third baseline is a straightforward generative clus-tering model for email graphs with a Chinese Restau-rant process prior and a likelihood function that factor-izes over the edges of the email graph X , assuming in-dependence for the edges in X . The likelihood function has a set of four parameters  X  = {  X  in s , X  in s , X  out a that quantify the probability of the presence of a link when the nodes are and are not elements of a joint botnet. The likelihood for an edge that connects two emails from the same campaign is given as where C ( i ) denotes the cluster that clustering C as-signs email i to. The likelihood of an edge between two emails from the same IP address is defined analogously, using the paramters  X  out a and  X  out a . The joint probabil-ity of the email matrix and a clustering C is then given as P ( X,C |  X ,  X  ) = P CRP ( C |  X  ) Q i,j&lt;i P ( X ij The parameters are adjusted using gradient-ascent on the joint data likelihood. 4.2. Results We measure ROC curves; IP addresses for which the likelihood P ( s | a,X,  X  ) of the correct campaign ex-ceeds the threshold are counted as true positives, ad-dresses for which the likelihood of an incorrect cam-paign exceeds the threshold as false positives. Figure 4 shows ROC curves for the four methods under study. Minimal graph clustering attains the highest area un-der the ROC curve of 0.784, compared to 0.675 for threshold-based clustering, 0.671 for spectral cluster-ing, and 0.651 for the generative edge model baseline. The threshold-based method is marginally more accu-rate than the Minimal Graph Clustering model for low threshold values, and less accurate for all other thresh-old values. Threshold-based clustering infers P ( s | c ) and P ( c | a,C ) and consequently P ( s | a,C ) to be zero for many values of s and a . Therefore, a large interval of points on the ROC curve cannot be attained by any threshold value; this is indicated by a dashed line. Typically, the number of requests during a DDoS at-tack exceeds the capacity to serve requests by far. An unprotected system will serve only a small, random fraction of requests and will be unable to serve all oth-ers; this amounts to a false positive rate of close to one. In order to defend against such an attack, one has to select a small proportion of requests which can be served. Therefore, in defending against DDoS at-tacks, the right hand side of the ROC curve that allows high true positive rates is practically relevant. Figure 4 shows execution times for running all four methods until convergence depending on the number of examples. The Minimal Graph Clustering model is computationally more expensive than the baselines. For continuously maintaining a clustering that sub-sequently incorporates newly available messages, it is thus advisable to use the previous clustering as a start-ing point of the Gibbs sampler in order to reduce the number of necessary iterations until convergence. Figure 4 shows area under ROC curve depending on what fraction of the training sample is used. For test-ing, only emails with IP addresses that are present in the smallest subset are used. The plots indicate that having access to a larger sample of the overall email traffic could increase performance considerably. The identification of spam-disseminating botnets can be reduced to the problem of clustering the graph of email messages in which messages are linked if they originate from the same IP address or match the same campaign template. We devised a probabilistic model that directly describes the conditional probability of a clustering given the input graph without making dis-tributional assumptions about the generation of the observable data. We derived a Gibbs sampler; we showed that resampling rows and edges of the output matrix creates an ergodic Markov chain, and that each sampling step can be carried out in O ( n 2 ). We argue that botnet models can be evaluated in terms of their ability to predict which spam campaign a given IP ad-dress is going to participate in. From a case study carried out with an email service provider we conclude that the minimal graph clustering model outperforms a number of reference methods X  X pectral clustering, a generative model, and a threshold-based, agglomera-tive clustering model X  X n terms of its area under the ROC curve.
 The botnet model draws a picture of the current size and activity of botnets. From the IP addresses, the ge-ographical distribution of each botnet can be derived. The botnet model can be used to select particularly prolific botnets for in-depth analysis and possible le-gal action. Widespread botnet software is versatile and supports both, dissemination of email spam and the staging of network attacks (Stern, 2008). When both, a mailing campaign and a network attack are carried out by a single network within the typical IP-address reassignment interval of one day, then the botnet model which has been trained on email data can score HTTP requests by the likelihood that their sender IP address is part of an attacking botnet. This allows to prioritize requests and to maintain a service during an attack. Alternatively, the botnet model can be trained with HTTP requests instead of emails; the recipient domain of an HTTP request plays the role of the campaign template. Again, the botnet model allows to infer the likelihood that an individual sender IP address acts as part of an attacking botnet. Direct evaluation of the model X  X  ability to decide whether an IP request is part of a network attack would require evaluation data in the form of a col-lection of individual HTTP requests labeled with the botnet that has sent the request. While it is relatively easy to collect the entire stream of legitimate and at-tacking HTTP requests that reach a domain during an attack, there is no practical means of labeling indi-vidual requests. In general, HTTP requests contain no information that allows even a human expert to decide whether a request is part of an attack, let alone which botnet a request has really been sent from. This work was funded by a grant from STRATO AG.
