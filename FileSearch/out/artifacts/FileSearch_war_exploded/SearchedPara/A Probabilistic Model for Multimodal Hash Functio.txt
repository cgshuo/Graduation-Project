 In recent years, both hashing-based similarity search and multimodal similarity search have aroused much research interest in the data mining and other communities. While hashing-based similarity search seeks to address the scala-bility issue, multimodal similarity search deals with appli-cations in which data of multiple modalities are available. In this paper, our goal is to address both issues simultane-ously. We propose a probabilistic model, called multimodal latent binary embedding (MLBE), to learn hash functions from multimodal data automatically. MLBE regards the bi-nary latent factors as hash codes in a common Hamming space. Given data from multiple modalities, we devise an efficient algorithm for the learning of binary latent factors which corresponds to hash function learning. Experimental validation of MLBE has been conducted using both syn-thetic data and two realistic data sets. Experimental results show that MLBE compares favorably with two state-of-the-art models.
 H.3 [ Information Storage and Retrieval ]: Information Search and Retrieval; H.4 [ Information Systems Appli-cations ]: Miscellaneous; G.3 [ Mathematics of Comput-ing ]: Probability and Statistics X  Probabilistic algorithms Hash Function Learning, Binary Latent Factor Models, Multimodal Similarity Search, Metric Learning
Similarity search, a.k.a. nearest neighbor search, is a fun-damental problem in many data mining, database, and in-formation retrieval applications [1, 34]. Given a query doc-ument 1 , the similarity search problem can be regarded as
In this paper, we use the term  X  X ocument X  in a generic sense finding one or more nearest neighbors of the query from a database according to some similarity measure chosen.
There are two challenging issues to address in similarity search, namely, the scalability and task-specificity issues [1, 33]. The scalability issue addresses the challenge when the database searched is of very large scale, possibly contain-ing millions or even billions of documents. As for the task-specificity issue, the concern is that the similarity measure used should not be a generic one, but it should be specific to the application at hand to ensure that the nearest neighbors found are relevant.

Two major approaches have been proposed to address the scalability issue. One approach employs tree-based meth-ods to organize data using data structures based on trees [3, 11]. The other approach uses hashing-based methods to map documents into bins such that collisions in the hash table reflect nearest neighbor relationships [12, 10, 9]. Although tree-based methods work well on low-dimensional data, they can easily degenerate into brute-force search as the data dimensionality increases. This limitation makes tree-based methods unappealing for real applications in which high di-mensionality is commonly encountered. On the contrary, hashing-based methods can index data with compact binary codes and hence can perform very fast search without suf-fering from the curse of dimensionality.

The most well-known hashing-based methods belong to the locality-sensitive hashing (LSH) family [5, 17, 7, 2], in which hash functions are constructed (but not learned) based on random projections or permutations. Due to their simplicity and effectiveness, LSH algorithms have been suc-cessfully applied to many applications [19, 37, 42]. However, they often generate very long codes mainly due to their data independence nature. In other words, the hash functions are designed for some standard similarity measures which may not suit the application at hand. This is an example of the task-specificity issue in similarity search.

To address the two issues mentioned above, some research attempts in the past few years pursue a data-dependent ap-proach by applying machine learning techniques to learn the hash functions from data automatically. We refer to this new direction as hash function learning (HFL).

To the best of our knowledge, Shakhnarovich et al. [35] made the first attempt to learn hash functions using a well-known machine learning algorithm, namely, a boosting al-gorithm [32]. Later, a method called semantic hashing [31] was proposed based on stacked restricted Boltzmann ma-to refer to data from any modality, such as text, image, audio or even their combinations.
 chines (RBMs) [16]. Using a large image database consist-ing of millions of images [36], it has been demonstrated that these two methods are much more effective than LSH. In a subsequent method called spectral hashing [40], a met-ric learning approach is used and the hash codes are found by spectral decomposition. Although spectral hashing is faster and more effective than the previous two methods, it takes a restrictive and unrealistic assumption that the data are uniformly distributed in a hyper-rectangle. Several new methods have since been proposed to relax this restrictive assumption, such as self-taught hashing [44], binary recon-structive embeddings [18], distribution matching [22], and shift-invariant kernel hashing [29]. Compared to spectral hashing, they have shown superior performance. Some more recent HFL methods focus on hashing in several special and important settings, including kernelized hashing [26, 14, 27], semi-supervised hashing [38, 39, 23], composite hashing [43], and active hashing [45].

Most existing HFL methods can only be applied to uni-modal data. However, for a growing number of applications, it is also common to conduct similarity search on multimodal data with data belonging to multiple modalities. For exam-ple, given an image about a historic event, one may want to find some text articles that describe the event in detail. As a result, developing multimodal HFL methods is a very worthwhile research direction to explore. Up to now, how-ever, only very few such attempts have been made [6, 20].
In this paper, we study hashing-based similarity search in the context of multimodal data. We propose a probabilistic latent factor model, called multimodal latent binary embed-ding (MLBE), to learn hash functions from multimodal data automatically. As a generative model, the hash codes are binary latent factors in a common Hamming space which determine the generation of both intra-modality and inter-modality similarities as observed either directly or indirectly. Given data from multiple modalities, we devise an efficient algorithm for learning the binary latent factors based on maximum a posteriori (MAP) estimation. Compared to its counterparts [6, 20], MLBE can: (a) be interpreted easily in a principled manner; (b) be extended easily; (c) avoid overfitting via parameter learning; (d) support efficient learning algorithms.

The remainder of this paper is organized as follows. Sec-tion 2 briefly introduces some recent related work. Section 3 presents our model and the learning algorithm. Experimen-tal validation of MLBE conducted using both synthetic data and two realistic data sets is presented in Section 4. Finally, Section 5 concludes the paper.
Our work bears some resemblance to metric learning which aims at learning similarity or distance measures from data [41]. Such data-dependent similarity measures are generally more effective than their data-independent counterparts. Although a lot of research has been conducted on metric learning, multimodal metric learning is still largely unexplored even though multimodal data are commonly found in many ap-plications. Some recent efforts have been made on non-hashing-based methods [21, 28]. Compared with hashing-based methods, these methods do not have the merits of low storage requirement and high search speed.

To the best of our knowledge, Bronstein et al. proposed the first hashing-based model, called cross-modal similar-ity sensitive hashing (CMSSH) thereafter, for multimodal similarity search [6]. Specifically, given a set of similar and dissimilar point pairs, CMSSH constructs two groups of lin-ear hash functions (for the bimodal case) such that, with high probability, the Hamming distance after mapping is small for similar points and large for dissimilar points. In their formulation, each hash function (for one bit) can be obtained by solving a singular value decomposition (SVD) problem and the hash functions are learned sequentially in a standard boosting manner. However, CMSSH ignores the intra-modality relational information which could be very useful [40].

Recently, Kumar et al. extended spectral hashing [40] to the multi-view case, leading to a method called cross-view hashing (CVH) [20]. The objective of CVH is to minimize the inter-view and intra-view Hamming distances for similar points and maximize those for dissimilar points. The opti-mization problem is relaxed to several generalized eigenvalue problems which can be solved by off-the-shelf methods.
Both CMSSH and CVH have archieved successes in sev-eral applications but they also have some apparent limita-tions. First, both models can only deal with vectorial data which may not be available in some applications. Besides, they both involve eigendecomposition operations which may be very costly especially when the data dimensionality is high. Furthermore, CMSSH has been developed for shape retrieval and medical image alignment applications and CVH for people search applications in the natural language pro-cessing area. These applications are very different from those studied in this paper.

Our work is also related to binary latent factor models [25, 15] but there exist some significant differences. First, the binary latent factors in MLBE are used as hash codes for multimodal similarity search, while the latent factors in [25, 15] are treated as cluster membership indicators which are used for clustering and link prediction applications. More-over, the model formulations are very different. In MLBE, the prior distributions on the binary latent factors are sim-ple Bernoulli distributions, but in [25, 15], the priors on the binary latent factors are Indian buffet processes [13]. Fur-thermore, from a matrix factorization point of view, MLBE simultaneously factorizes multiple matrices but the method in [25] factorizes only one matrix.
We present MLBE in detail in this section. We use bold-face uppercase and lowercase letters to denote matrices and vectors, respectively. For a matrix A , its ( i,j )th element is denoted by A ij .
For simplicity of our presentation, we focus exclusively on the bimodal case in this paper, but it is very easy to extend MLBE for more than two modalities. As a running example, we assume that the data come from two modalities X and Figure 1: Graphical model representation of MLBE Y corresponding to the image modality and text modality, respectively.

The observations in MLBE are intra-modality and inter-modality similarities. Specifically, there are two symmet-ric intra-modality similarity matrices S x  X  R I  X  I and S R
J  X  J , where I and J denote the number of data points in modality X and that in modality Y , respectively. In case the observed data are only available in the form of feature vectors, different ways can be used to convert them into similarity matrices. For the image data X , the similarities in S x could be computed from the corresponding Euclidean distances between feature vectors. For the text data Y , the similarities in S y could be the cosine similarities between bag-of-words representations.
 In addition, there is an inter-modality similarity matrix S xy  X  { 1 , 0 } I  X  J , where 1 and 0 denote similar and dissim-ilar relationships, respectively, between the corresponding entities. Note that it is common to specify cross-modal possible to specify real-valued cross-modal similarities ob-jectively. The binary similarity values in S xy can often be determined based on their semantics. Take multimedia re-trieval for example, if an image and a text article are both for the same historic event, their similarity will be set to 1. Otherwise, their similarity will be 0.

Our probabilistic generative model has latent variables represented by several matrices. First, there are two sets of binary latent factors, U  X  { +1 ,  X  1 } I  X  K for X and V  X  { +1 ,  X  1 } J  X  K for Y , where each row in U or V corresponds to one data point and can be interpreted as the hash code of that point. In addition, there are two intra-modality weight-ing matrices, W x  X  R K  X  K for X and W y  X  R K  X  K for Y , and an inter-modality weighting variable w &gt; 0. The basic assumption of MLBE is that the observed intra-modality and inter-modality similarities are generated from the bi-nary latent factors, intra-modality weighting matrices and inter-modality weighting variable. Note that the real-valued weighting matrices and weighting variable are needed for generating the similarities because the values in the latent factors U and V are discrete.

The graphical model representation of MLBE is depicted in Figure 1, in which shaded nodes are used for observed variables and empty ones for latent variables as well as pa-rameters which are also defined as random variables. The others are hyperparameters, which will be denoted collec-tively by  X  in the sequel for notational convenience. We first consider the likelihood functions of MLBE. Given U , V , W x , W y , X  x and  X  y , the conditional probability den-sity functions of the intra-modality similarity matrices S and S y are defined as where u i and u i 0 denote the i th and i 0 th rows of U , v v 0 denote the j th and j 0 th rows of V , and N ( x |  X , X  2 the probability density function of the univariate Gaussian distribution with mean  X  and variance  X  2 .

Given U , V and w , the conditional probability mass func-tion of the inter-modality similarity matrix S xy is given by p ( S xy | U , V ,w ) = where Bern( x |  X  ) is the probability mass function of the Bernoulli distribution with parameter  X  , O ij is an indicator erwise, and  X  ( x ) = 1 / (1 + exp(  X  x )) is the logistic sigmoid function to ensure that the parameter  X  of the Bernoulli distribution is in the range (0 , 1).

To complete the model formulation, we also need to define prior distributions on the latent variables and hyperprior dis-tributions on the parameters. For the matrix U , we impose a prior independently and identically on each element of U as follows: 2 where Beta(  X  | a,b ) is the probability density function of the beta distribution with hyperparameters a and b . This par-ticular choice is mainly due to the computational advantage of using conjugate distributions so that we can integrate out  X  ik , as a form of Bayesian averaging, to give the following prior distribution on U : Similarly, we define the prior distribution on V as:
For the weighting matrices W x and W y , we impose Gaus-sian prior distributions on them:
The weighting variable w has to be strictly positive to enforce a positive relationship between the inner product
Conventionally, the Bernoulli distribution is defined for dis-crete random variables which take the value 1 for success and 0 for failure. Here, the discrete random variables take values from { X  1 , +1 } instead assuming an implicit linear mapping from { 0 , 1 } . of two hash codes and the inter-modality similarity. So we impose the half-normal prior distribution on w :
Because the parameters  X  x , X  y , X  x , X  y and  X  are all random variables, we also impose hyperprior distributions on them. The gamma distribution is used for all these distributions: where Gam(  X  | a,b ) = 1  X ( a ) b a  X  a  X  1 e  X  b X  denotes the proba-bility density function of the gamma distribution with hy-perparameters a and b , and  X (  X  ) is the gamma function.
With the probabilistic graphical model formulated in the previous subsection, we can now devise an algorithm to learn the binary latent factors U and V which give the hash codes we need. A fully Bayesian approach would infer the poste-rior distributions of U and V , possibly using some sampling techniques. However, such methods are often computation-ally demanding. For computational efficiency, we devise an efficient alternating learning algorithm in this paper based on MAP estimation.

We first update U ik while fixing all other variables. To find the MAP estimate of U ik , we define a loss function with respect to U ik in Definition 3.1: Definition 3.1.
 L where u + i is the i th row of U with U ik = 1 , u  X  i row of U with U ik =  X  1 ,  X  + ij =  X  ( w v T j u + i ) , and  X   X  ( w v T j u  X  i ) .
 With L ik , we can state the following theorem: Theorem 3.1. The MAP solution of U ik is equal to 1 if L ik  X  0 and  X  1 otherwise.
 The proof of Theorem 3.1 can be found in Appendix A.1. Similarly, we have Definition 3.2 and Theorem 3.2 for the MAP estimation of V . The proof of Theorem 3.2 is similar and so it is omitted in the paper due to page limitations. Definition 3.2.
 Q where v + j is the j th row of V with V jk = 1 , v  X  j row of V with V jk =  X  1 ,  X  + ij =  X  ( w u T i v + j ) , and  X   X  ( w u T i v  X  i ) .
 Theorem 3.2. The MAP solution of V ik is equal to 1 if Q jl  X  0 and  X  1 otherwise.

With U , X  x and  X  x fixed, we can compute the MAP es-timate of W x using Theorem 3.3 below. The proof is in Appendix A.2.

Theorem 3.3. The MAP solution of W x is where w x is a K 2 -dimensional column vector taken in a columnwise manner from W x , s x is an I 2 -dimensional col-umn vector taken in a columnwise manner from S x , A = U  X  U , M 1 is a diagonal matrix with each diagonal entry equal to 1 if it is the linear index of the upper-right portion of W x and 0 otherwise, and M 2 is similarly defined but with a different size which is determined by S x .
 Similarly, we have Theorem 3.4 for W y .

Theorem 3.4. The MAP solution of W y is where w y , s y , B and  X  M 2 are also defined similarly.
To obtain the MAP estimate of w , we minimize the nega-tive log posterior p ( w | U , V , S xy , X  ), which is equivalent to the following objective function:
L where  X  ij =  X  w u T i v j .

Although the objective function is convex with respect to w , there is no closed-form solution. Nevertheless, due to its convexity, we can obtain the global minimum easily using a gradient descent algorithm. The gradient can be evaluated as follows:  X  w =  X   X  w (1) As for the parameters, closed-form solutions exist for their MAP estimates which are summarized in the following the-orem.
Theorem 3.5. The MAP estimates of  X  x , X  y , X  x , X  y and  X  are:
Theorem 3.5 can be proved easily. Briefly speaking, we first find the posterior distribution of each parameter and then compute the optimal value by setting its derivative to zero. Details of the proof are omitted here.

To summarize, the learning algorithm of MLBE is pre-sented in Algorithm 1.
 Algorithm 1 : Learning algorithm of MLBE Input : S x , S y , S xy  X  similarity matrices begin end
Algorithm 1 tells us how to learn the hash functions for the observed bimodal data based on their intra-modality and inter-modality similarities. However, the hash codes can only be computed this way for the training data. In many applications, after learning the hash functions, it is necessary to obtain the hash codes for out-of-sample data points as well. One naive approach would be to incorporate the out-of-sample points into the original training set and then learn the hash functions from scratch. However, this approach is computationally unappealing due to its high computational cost especially when the training set is large.

In this subsection, we propose a simple yet very effective method for finding the hash codes of out-of-sample points. The method is based on a simple and natural assumption that the latent variables and parameters for the training data can be fixed while computing the hash codes for the out-of-sample points.

Specifically, we first train the MLBE model using some training data selected from both modalities. 3 Using the latent variables and parameters learned from the training points, we can find the hash codes for the out-of-sample points by applying Theorem 3.1 or Theorem 3.2. For illus-tration, Algorithm 2 shows how to compute the hash code for an out-of-sample point x  X  from modality X using the latent variables and parameters learned from two training sets  X  X and  X  Y . It is worth noting that the hash code for each out-of-sample point can be computed independently. The implication is that the algorithm is highly paralleliz-able, making it potentially applicable to very large data sets. The same can also be done to out-of-sample points from the other modality with some straightforward modifications. Algorithm 2 : Algorithm for out-of-sample extension Input :  X  S x  X  intra-modality similarities for x  X  and  X  begin end
The computational cost of the learning algorithm is mainly spent on updating U , V , W x , W y and w .

The complexity of updating an entry U ik is O ( IK 2 + JK ), which grows linearly with the number of points in each modality. Updating W x requires inverting a K 2  X  K 2 ma-trix. Since K is usually very small, this step can be per-formed efficiently. The complexity of evaluating the gradi-ent  X  w is linear in the number of observations of the inter-modality similarities. We note that the complexity can be greatly reduced if the similarity matrices are sparse, which is often the case in real applications.
We first present an illustrative example on synthetic data in Section 4.1. It is then followed by experiments on two publicly available real-world data sets. Section 4.2 presents the experimental settings and then Sections 4.3 and 4.4 present the results. The code and data can be downloaded at http://www.cse.ust.hk/~dyyeung/code/mlbe/ .
There are four groups of data points with each group con-sisting of 50 points. We associate each group with one of four and [  X  1 , 1 ,  X  1 , 1], and use a 200  X  4 matrix H to denote the hash codes of all 200 points. We generate W x W y from N (  X  | 1 , 0 . 01) and N (  X  | 5 , 0 . 01), respectively.
We do not make any assumption on how the training data are selected. They may be selected randomly for simplicity or carefully based on how representative they are. Random selection is used in our experiments. Based on the latent representation, we generate the sim-ilarity matrices S x and S y using N ( S x il | h T i W x S ij = 1 if h i = h j and S all entries in S xy are observed, i.e., O ij = 1 ,  X  i,j .
Based on the similarities generated, we train MLBE to obtain the hash codes U and V . Because the bits of the hash codes are interchangeable, it is more appropriate to use inner products of the hash codes to illustrate the similarity structures, as shown in Figure 2. Note that the whiter the area is, the more similar the points involved are. Figure 2(a) depicts the ground-truth similarity structure, Figure 2(b) and 2(c) show the learned intra-modality similarity structure for each modality, and Figure 2(d) shows the learned inter-modality similarity structure. As we can see, the whiter areas in the last three subfigures are in the same locations as those in Figure 2(a). In other words, both the intra-modality and inter-modality similarity structures revealed by the learned hash codes are very close to the ground truth, showing the effectiveness of MLBE.
We have conducted several comparative experiments on two real-world data sets, which are, to the best of our knowl-edge, the largest publicly available multimodal data sets that are fully paired and labeled. Both data sets are bimodal with the image and text modalities but the feature repre-sentations are different. Each data set is partitioned into a database set and a separate query set.

We compare MLBE with CMSSH 4 and CVH 5 on two com-mon cross-modal retrieval tasks. Specifically, we use a text query to retrieve similar images from the image database and use an image query to retrieve similar texts from the text database. Since the data sets are fully labeled, mean-ing that each document (image or text) has one or more semantic labels, it is convenient to use these labels to decide the ground-truth neighbors.

We use mean Average Precision (mAP) as the perfor-mance measure. Given a query and a set of R retrieved
The implementation is kindly provided by the authors.
Because the code is not publicly available, we implemented the method ourselves. documents, the Average Precision (AP) is defined as where L is the number of true neighbors in the retrieved set, P ( r ) denotes the precision of the top r retrieved documents, and  X  ( r ) = 1 if the r th retrieved document is a true neighbor and  X  ( r ) = 0 otherwise. We then average the AP values over all the queries in the query set to obtain the mAP measure. The larger the mAP, the better the performance. In the experiments, we set R = 50.

We also report two types of performance curves, namely, precision-recall curve and recall curve. Given a query set and a database, both curves can be obtained by varying the Hamming radius of the retrieved points and evaluating the precision, recall and number of retrieved points accordingly.
For MLBE, the intra-modality similarity matrices are com-puted based on the feature vectors. We first compute the Euclidean distance d between two feature vectors and then transform it into a similarity measure s = e  X  d 2 / 2  X  2 the parameter  X  2 is fixed to 1 for both data sets. The inter-modality similarity matrices are simply determined by the class labels. Since MLBE is not sensitive to the hyperparam-eters, we simply set all of them to 1. Besides, we initialize U and V using the results of CVH, set the initial values of  X  , X  y , X  x , X  y to 0 . 01, and use a fixed learning rate 10 updating w .

In all the experiments, the size of the training set, which is randomly selected from the database set for each modality, is set to 300 and only 0.1% of the randomly selected entries of S xy are observed. 6 To be fair, all three models are trained on the same training set. The Wiki data set is generated from a group of 2 , 866 Wikipedia documents provided by [30]. Each document is an image-text pair and is labeled with exactly one of 10 seman-tic classes. The images are represented by 128-dimensional SIFT [24] feature vectors. The text articles are represented by the probability distributions over 10 topics, which are de-rived from a latent Dirichlet allocation (LDA) model [4]. We use 80% of the data as the database set and the remaining 20% to form the query set.

The mAP values for MLBE and the two baselines are re-ported in Table 1. The precision-recall curves and recall curves for the three methods are plotted in Figure 3.
Image Query Text Database Image Database
We can see that MLBE significantly outperforms CVH and CMSSH when the code length is small. As the code
We have tried larger training sets, e.g., of sizes 500 and 1 , 000, in our experiments but there is no significant perfor-mance improvement. So we omit the results due to space limitations. (c) K = 8 (g) K = 16 (k) K = 24 length increases, the performance gap gets smaller. We con-jecture that MLBE may get trapped in local minima during the learning process when the code length is too large.
Besides, we observe that as the code length increases, the performance of all three methods degrades. We note that this phenomenon has also been observed in [38, 23]. A pos-sible reason is that the learned models will be farther from the optimal solutions when the code length gets larger.
The Flickr data set consists of 186 , 577 image-tag pairs, which are pruned from the NUS dataset [8] by keeping the pairs that belong to one of the 10 largest classes. Each pair is annotated by at least one of 10 labels. The image features are 500-dimensional SIFT features and the text features are 1000-dimensional vectors obtained by performing PCA on the original tag occurrence features. We use 99% of the data as the database set and the remaining 1% to form the query set.

Image Query Text Database Image Database
The mAP results are reported in Table 2. Similar to the results on Wiki, we observe that MLBE outperforms its counterparts by a large margin when the code length is small.

The corresponding precision-recall curves and recall curves are plotted in Figure 4. We note that MLBE has the best overall performance.
In this paper, we have presented a novel probabilistic model for multimodal hash function learning. As a latent factor model, the model regards the binary latent factors as hash codes and hence maps data points from multiple modal-ities to a common Hamming space in a principled manner. Although finding exact posterior distributions of the latent factors is intractable, we have devised an efficient alternating learning algorithm based on MAP estimation. Experimen-tal results show that MLBE compares favorably with two state-of-the-art models.

For our future research, we will go beyond the point esti-mation approach presented in this paper to explore a more Bayesian treatment based on variational inference for en-hanced robustness. We would also like to extend MLBE to determine the code length K automatically from data. This is an important yet largely unaddressed issue in exist-ing methods. Besides, we also plan to apply MLBE to other tasks such as multimodal medical image registration. This research has been supported by General Research Fund 621310 from the Research Grants Council of Hong Kong. (c) K = 8 (g) K = 16 (k) K = 24 [1] A. Andoni. Nearest Neighbor Search: the Old, the [2] A. Andoni and P. Indyk. Near-optimal hashing [3] S. Arya, D. M. Mount, N. S. Netanyahu, [4] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent [5] A. Z. Broder, M. Charikar, A. M. Frieze, and [6] M. M. Bronstein, A. M. Bronstein, F. Michel, and [7] M. Charikar. Similarity estimation techniques from [8] T.-S. Chua, J. Tang, R. Hong, H. Li, Z. Luo, and Y.-T. [9] A. Dasgupta, R. Kumar, and T. Sarlos. Fast [10] K. Eshghi and S. Rajaram. Locality sensitive hash [11] J. H. Friedman, J. L. Bentley, and R. A. Finkel. An [12] A. Gionis, P. Indyk, and R. Motwani. Similarity search [13] T. L. Griffiths and Z. Ghahramani. Infinite latent [14] J. He, W. Liu, and S.-F. Chang. Scalable similarity [15] K. A. Heller and Z. Ghahramani. A nonparametric [16] G. E. Hinton and R. Salakhutdinov. Reducing the [17] P. Indyk and R. Motwani. Approximate nearest [18] B. Kulis and T. Darrell. Learning to hash with binary [19] B. Kulis and K. Grauman. Kernelized locality-sensitive [20] S. Kumar and R. Udupa. Learning hash functions for [21] D. Lee, M. Hofmann, F. Steinke, Y. Altun, N. D. [22] R.-S. Lin, D. A. Ross, and J. Yagnik. SPEC hashing: [23] W. Liu, J. Wang, S. Kumar, and S.-F. Chang.
 [24] D. G. Lowe. Distinctive image features from [25] E. Meeds, Z. Ghahramani, R. Neal, and S. T. Roweis. [26] Y. Mu, J. Shen, and S. Yan. Weakly-supervised [27] M. Norouzi and D. J. Fleet. Minimal loss hashing for [28] N. Quadrianto and C. H. Lampert. Learning [29] M. Raginsky and S. Lazebnik. Locality-sensitive [30] N. Rasiwasia, J. Costa Pereira, E. Coviello, G. Doyle, [31] R. Salakhutdinov and G. E. Hinton. Semantic hashing. [32] R. E. Schapire. A brief introduction to Boosting. In [33] G. Shakhnarovich. Learning Task-Specific Similarity . [34] G. Shakhnarovich, T. Darrell, and P. Indyk, editors. [35] G. Shakhnarovich, P. Viola, and T. Darrell. Fast pose [36] A. Torralba, R. Fergus, and Y. Weiss. Small codes and [37] F. Ture, T. Elsayed, and J. Lin. No free lunch: Brute [38] J. Wang, S. Kumar, and S.-F. Chang. Semi-supervised [39] J. Wang, S. Kumar, and S.-F. Chang. Sequential [40] Y. Weiss, A. Torralba, and R. Fergus. Spectral [41] E. P. Xing, A. Y. Ng, M. I. Jordan, and S. Russell. [42] H. Xu, J. Wang, Z. Li, G. Zeng, S. Li, and N. Yu. [43] D. Zhang, F. Wang, and L. Si. Composite hashing [44] D. Zhang, J. Wang, D. Cai, and J. Lu. Self-taught [45] Y. Zhen and D.-Y. Yeung. Active hashing and its
To obtain the MAP solution of U ik , it suffices to compare the following two posterior probabilities: Specifically, we compute the log ratio of the two probabil-ities, which is larger than or equal to zero if p +  X  p  X  smaller than zero otherwise. The log ratio can be evaluated as follows: log Pr( U ik = 1 | U  X  ik , V , W = log Pr( S + log Pr( S + log Pr( U ik = 1 |  X  u , X  u ) =  X   X  x  X   X  x + where U  X  ik denotes all the elements in U except U ik . The log ratio thus computed gives exactly L ik . This completes the proof.

The negative log of the posterior distribution of W x can be written as: =  X  log P ( W x |  X  x )  X  log P ( S x | U , W x , X  x ) +  X  =  X  x =  X  x = 1 where  X  C is a constant term independent of W x .

Setting the derivative of Equation (7) to zero, we get This completes the proof.
