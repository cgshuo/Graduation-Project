 Given a set of N p moving objects in a two dimensional region of interest, at time { o , ( o x ,o y ) , ( o x ,o y ) } , where o id is the identifier of the object, ( o can be represented by ( q x ,q y ), and N q is the number of queries in this set. The problem we study in this work is to get the k nearest neighbours ( k -NNs) of each query in real-time. We adopt the snapshot semantics, i.e., the answer of q ( t )is only valid for the positions of the objects at time t  X   X t , where  X t is the latency due to query processing. Apparently, minimizing this latency  X t is critical in our problem and is the main objective of this work. To make our approach more general, we do not make any assumptions on the movement patterns of the objects, i.e., the objects can move without any predefined pattern. Such k -NN queries based applications in a wide array of location-based ser-vices (e.g., location-based advertising). There have already been many algo-rithms to process k -NN queries over moving objects. However, most of them are based on a centralized setting with a single server and is thus usually only suitable for applications with a limited data size. On the other hand, we are experiencing a rapid growth in the scale of spatio-temporal data due to the increasing prevalence of positioning devices, such as GPS trackers and smart phones. The abundance of such data and the increase in the workload in the location-based applications has rendered the centralized solutions inapplicable in many cases, and more scalable solutions are in order.
 k -NN queries. We first design a grid-based index called Block Grid Index (BGI), which can be constructed and maintained efficiently in a distributed setting. BGI is designed as a two-layer structure. The top layer is a grid structure, i.e. it partitions the region of interest into a grid of equal-sized cells without overlap. Each cell in the grid is in charge of indexing the moving objects within itself. The bottom layer is established based on the first layer and consists of a set of blocks, which also constitute a non-overlapping partitioning of the interest region. Each block of the bottom layer corresponds to one or more cells from the top layer and the number of objects within the block cannot be greater/less than the user-specified maximum/minimum thresholds. As objects move, the blocks can be split/merged when the number of objects in the blocks goes out the range we set. The proposed structure is particularly suitable for the distributed setting as it can achieve fast maintenance due to its simple structure.
 ing based on BGI, which guarantees returning the query results with only two iterations. Given a query q , DBGKNN can directly locate the blocks that are guaranteed to contain at least k neighbours of q based on BGI. Then the algo-rithm chooses a set of objects that are closest to q from candidate blocks and identifies the k -th nearest neighbour in these selected objects. Using this neigh-bour as a reference point, it can determine a search region and compute the final k -NNs by calculating the distances between q and the objects in this region. We implement BGI and DBGKNN in a master-worker mode, which can be easily deployed to distributed setting, such as Storm and S4. We conducted extensive experiments to evaluate the performance of our solutions.
 moving objects in a distributed setting. Guaranteeing to return the results with only two iterations, DBGKNN has a superior and more predictable performance than other grid-based approaches. related work. Section 3 introduces the BGI index structure. Section 4 presents the DBGKNN algorithm. Experimental results are presented in Section 5. Section 6 concludes this paper. As a fundamental operation, k -NN query processing has been intensively stud-ied in recent years. Early k -NN search algorithms are for the case where both the query point and the data points are static. [ 4 ] solves this problem using the R-tree associated depth-first traversal and branch-and-bound techniques. An incremental algorithm using traversed R-tree is developed in [ 2 ]. k -NN queries over moving objects have also been considered. The first algorithm for contin-uous nearest neighbour queries is proposed in [ 7 ]. It handles the case that only the query object is moving, while the data objects remain static. An improved algorithm was proposed by [ 8 ] which searches the R-tree only once to find the k nearest neighbours for all positions along a line segment.
 Existing k -NN search methods can also be classified based on the structure of the index used. Tree-based approaches and grid-based approaches are both widely used. Tree-based approaches mostly are variants of the R-tree. The first algorithm of k -NN was based on R-tree as aforementioned. TPR-tree is used to index moving objects and filter-and-refine algorithms are proposed to find the data and define a reference point in each partition, then index the distance of each object to the reference point to support k -NN queries.
 The grid index partitions the region of interest into equal sized cells, and indexes objects and/or queries (in the case of continuous query answering) in each cell respectively [ 6 , 10 , 11 ]. Most of these approaches are designed for the centralized setting, and cannot be directly deployed on a distributed cluster. Most existing grid-based algorithms of k -NN search follow the similar thought: (1)location the query object. (2)enlarge the search region iteratively to get the k objects near query object. (3)find the farthest object to query object in(2). (4)taking the distance between farthest object in (2) and the query object as the radius, the query object as the circle center, draw a circle. (5)get the k -NNs from the objects fall in the circle. In step(2), the number of iterations needed to get k objects is unknown. If we implement this kind of algorithm on a master-worker mode, let master node maintain the grid index, worker nodes store the data belongs to each grid cell. Then we will face the uncertain times communication between master and workers, which will lead to low performance. Aim to implement k -NN algorithm on distributed system, we design the BGI, a main-memory index structure to meet these requirements. 3.1 Structure of BGI Without loss of generality, we assume that all objects exist in the [0 , 1) square, through some mapping of the interest region. BGI is designed into a two-layers structure(See Fig.1). The top layer uses a grid structure, which partitions the unit square into a regular grid of cells of equal size  X  . Each cell is denote by ( i, j ), corresponding its row and column indices. Given a query q ( t ), we can directly know that it falls into the cell ( i, j ), if i  X  ( j + 1). In the top layer, each cell only contains the id of block which it belongs to. The bottom layer is a set of blocks, which consisting of data located in the corresponding cells. Objects stored in block are organized by cells X  X  boundary. Briefly, we take cell as the smallest unit to partition (without overlap) the region of interest, and objects are partitioned by cell size.
 is the number of blocks) and also can be represented by { b id is the unique identifier of b i ,and CL ( b id ) is a list of cells that b In the bottom layer, each cell is represented by { ( i, j ) ,OL ( i, j ) new element OL ( i, j ) to store the objects which fall into the cell. The blocks are non-overlapping and every object must fall into one cell of one block.  X   X  N b  X   X  for all block b i . N b is the number of objects in block. When objects are updated, blocks split or merged as needed to meet this condition. We call  X  and  X  the minimum and maximum threshold of a block respectively. Typically  X   X  . In the rare case where the total number of objects N minimum threshold requirement cannot be satisfied. This is handled as a special case in query processing. To simplify our discussion, we assume without loss of generality that at any time the total number of objects N 3.2 Insertion When an object comes, BGI gets the block id where the object located according cell ( i, j )has b i  X  X  id. The insertion is done by appending o When an object o is inserted into a block b i , b i will be split if the number of objects in it exceeds the maximum threshold. A split method split b two new ones that hold approximately the same number of objects adapt to the data distribution. In this method, we first find the left bottom cell which has the number of cells we select is more than N b / 2. These cells are moved to a new block. Once b i is split, some cells move to a new block, the information in grid index need to be update. As shown in Fig.2. 3.3 Deletion When an object disappears or moves out of a block, it has to be deleted from the block that currently holds it. To delete an object o , we need to determine which block currently holds it, which can be done directly using BGI. After deleting an object, if the block b i has less than  X  objects, it will be merged with an adjacent block. The block b i needs to send message to the top layer. Then top layer can choose which block that has the most common edges with b ,denoted by b j . Next, two blocks merge together and cells which fall into b with updating the corresponding information. In case, the number of objects in the resulting block exceeds the threshold  X  , triggering another split. However, since in general  X   X  , such situations rarely happen and their impact on the overall performance is minimal.
 3.4 Analysis of the BGI Structure Time Cost of Maintaining BGI.
 Theorem 1. Let N p , N b and N c be the number of objects, blocks and cells respectively, and assume that the objects are uniformly distributed. T T operations respectively, and a i ( i =1 ,  X  X  X  , 6) are constants.
 T Proof. For an insert operation, we need to locate which cell o falls in and appending it to the end of the cell X  X  object list. We have to spent some time on finding the right cell in a block to complete this operation. Therefore, T a log N b . To delete an object from a cell, we need to locate the cell and then remove the object from its object list. The costs of these two operations are T elete  X  a 1 log N c N cells have half of objects, which takes linear time with respect to the number of objects:  X  . For a merge operation, we need to verify the block to merger, which requires to traverse the old block, i.e, a 4  X  .
 Advantages of BGI. BGI has the following advantages. a distributed system. The blocks do not overlap, making it possible to perform query processing in parallel. that only needs to store the cells X  boundary and the block id the cell belongs to, the capacity of BGI is directly proportional to the number of servers, lending it well to large-scale data processing. directly determine the blocks that contain at least k neighbours of a given query, without invoking excessive iterations. 4.1 The DBGKNN Algorithm The distributed k -NN search algorithm (DBGKNN) we proposed based on BGI follows a filter-and-refine paradigm. Given a query q , (1)the algorithm identify the blocks which are guaranteed to contain at least k neighbours of q through the first layer grid index. (2)corresponding blocks return at least k objects near q . (3)compute the k -th nearest neighbour of query in return objects set. (4)taking the distance between this neighbour and query as the radius, q as center, draw a circle. (5)among objects fall in the circle, compute the k -NN of query object. The algorithm is presented in Algorithm 2. Now we present the details of the algorithm. Without loss of generality, we assume that N p number of objects.
 Calculating Candidate Blocks. For a given query q , DBGKNN can directly identify the set of blocks that are guaranteed to contain k neighbours of q , called the candidate blocks. First, get which cell the query q falls into. As we partition the region of interest using grid, it is easy to locate which cell contains q according to q s coordinates. We denote the cell as c q candidate blocks. We locate a rectangle R 0 centred at the cell c size such that R 0 encloses cells falling into at least  X  denote the number of candidate blocks and satisfy  X   X   X   X  guarantee that there are at least k neighbours in the candidate blocks. blocks, b 4 , b 6 , b 7 . Assume  X  =3 ,k =6,now  X  =3 , X   X  { b ,b The algorithm of determining the candidate blocks DCS is shown in Algo-rithm 1. This procedure describes the details of DCS and can be implemented on the master-workers setting as shown in fig.5. BGI is maintained in a distributed fashion by multiple workers, where each worker is responsible for a set of blocks. The master is the entry point for the queries. It maintains the top layer, which only record the block id of each cell. When the master receives a query q ,itcan immediately determine the candidate blocks by running DCS, and then send q to the workers that hold the candidate blocks.
 Determining the Final Search Region. After the candidate blocks are deter-mined, we send query q to the candidate blocks. Then every block return  X  objects which are closest to q . Then we can identify a supporting object o , which is the k -th closest to q in the return of candidate blocks. Let the distance between o and q be r q . The circle takes ( q x ,q y ) as the center and r radius is thus guaranteed to cover the k -NNs of q. Next, we identify the set of cells that intersect with this circle, and search k -NNs of q in these cells. Fig.4 shows an example, where the query q is a 3-NN query and let  X  = 1. We find the supporting object o 5 in its candidate blocks { b 1 ,b r which equals the distance between q and o 5 . The circle C contain the 3-NNs of q . After scanning all objects that are located within C we find that the 3-NNs are o 3 , o 4 and o 8 .
 Fig. 5 shows this step in the master-workers setting. Master sends q to workers who holds candidate blocks. Then these workers send objects near q to calcula-tion worker. Next, calculation worker send the circle C q the final set of cells C which intersected with C q . Then master sends C to the blocks holding cells in C . Finally, k nearest neighbours are chosen from each cell in C (or all the objects in the cell if it contains less than k objects) and sent to calculation worker, where the final k -NN of q are computed.
 4.2 Analysis of the DBGKNN Algorithm Time Cost of the DBGKNN Algorithm.
 Theorem 2. Let N p , N b and N c be the number of objects, blocks and grid cells respectively, and assume that the objects are uniformly distributed. For a given k -NN query q , the query processing time (without considering the communication cost) by DBGKNN is T q uery = T d + T c + T l ,where T d  X  k  X  log k , T l  X  a Proof. T d is the time of determining the candidate blocks, T obtaining the circle C q ,and T l be the time of searching k -NNs from the set of cells covered by C q . The time of finding the candidate blocks is a constant, for we can get the set of blocks directly through the grid index. Therefore, T To compute the circle C q , we need time a 2  X   X  N p N (to q ) from each candidate blocks. Obtaining the radius of the circle C takes time a 3  X  k  X  log k . Therefore, T c  X  a 2  X   X  N p we assume a uniform distribution of the data, the expected area of C Thus, the time of obtaining the k -NNs is T l  X  a 4  X  N c Effects of  X  and  X  . The minimum threshold  X  influences the frequency of the merge operation. We assume that the N p objects are uniformly distributed in a unit square for simplicity. When the number of objects in block is lower than  X  , the merge operation is running. Thus, when  X  increases, the probability of merge operations comes higher. However,  X  can not be too small. In the candidate blocks Algorithm 1. DCS Algorithm Algorithm 2. DBGKNN Algorithm notify stage, we need to meet the condition of  X   X   X   X  k ,if  X  is too small, then we need to enlarge the rectangle R 0 to get more candidate blocks. The maximum threshold  X  affects the splitting of blocks. when  X  decreases, more blocks need to split. Meanwhile, high  X  means every block has a high number of objects, which may influences the performance of circle computation.
 Advantages of DBGKNN. The most notable advantage of DBGKNN is that it minimize the probability that the master becomes a bottleneck, for the master only maintenance a grid structure to index objects and store the block id that the object belongs to. Given a query q , DBGKNN gets the k -NNs of q in two steps, first directly determining the candidate blocks using BGI, and then identifying the final set of cells to search by computing the circle C when the algorithm is running in a distributed system.
 Scalability of DBGKNN. DBGKNN is easily parallelizable and scales well with respect to the number of servers to handle increases in data volumes. These blocks in BGI in general reside on different servers, and the process of searching them for the k -NNs can take place simultaneously on individual servers. More processing power can be obtained by simply adding more servers to the cluster. We implement experiments to evaluate BGI and DBGKNN. We mainly test the performance of BGI by changing the parameters. For DBGKNN, we implement a distributed grid-based search algorithm according to [3]. We take this grid-based search algorithm as the baseline, and compare a lot between them. Every experiment is repeated ten times, and the average values are recorded as the final results. 5.1 Experimental Setup The experiments are conducted on a Dell R210 server, which has a 2.4GHz Intel processor and 8GB of RAM. We use the local mode to simmulate the master-worker mode. We simulate three different datasets for our experiments. The first dataset (UD) is consisting of the objects that follow a uniform distribution. In the second dataset (GD), 70% of the objects follow the Gaussian distribution, and the rest objects are uniformly distributed. In the third database, objects follow the Zipf distribution. All the objects are normalized to a unit square. 5.2 Experiment Performance We first test the time of building BGI with changing  X  , and the number of objects using different database. Fig. 6 shows the time of building BGI as we vary  X  . Fig.8 is the time of index construction with data in UD as we change the number of objects. In our study, the number of  X  is approximately reversely proportional to the account of spilt operation. The lower theta is, the higher split operations are, which means a longer build time.  X  cannot be overly large. In extreme cases, when  X  is too large, the total number of blocks may be 1, which means we will run the index like single server. A high  X  will also increase the time of query processing. The index build time increases almost linearly with the increasing number of objects. As objects changing, the more split and merge operations happen, leading the maintenance time increase. Data in Zipf and GD need more split and merge operations, so they take a higher cost of building index. Fig.7 shows the the query time of different database changing  X  . Data follow different distributions perform similarly and the query time of them all increase along with  X  getting higher. A higher  X  means that the average number of objects in one block is higher, which brings more time for calculation in one block. of objects. Baseline method build index very fast and the time it costs varies little when the number of objects changes. In fig.9, we show the query time between two algorithms. The query time of baseline method increases rapidly along with increasing objects number, comparing that our algorithm performs stable. When the number of objects becoming higher, the baseline method suffer from the communication cost of iterations. DBGKNN only need two iterations to get the result so that it is little unaffected by objects number. In the above experiments, we find that although DBGKNN takes time to build index, it performs better in query processing than the baseline method. The parameter  X  in DBGKNN matters the index build time and query processing time. A high  X  means more split operations, which leads to fast query processing time and high cost on index maintains. Therefore, we need to choose the optimal value of  X  according to the actual conditions. In summary, DBGKNN is more suitable for large volumes of objects in distributed system. The problem of processing k -NN queries over moving objects is fundamental in many applications. The large volume of data and heavy query workloads call for new scalable solutions. We propose a distributed grid index BGI and a dis-tributed k -NN search algorithm DBGKNN to address this challenge. Based on BGI, we present DBGKNN that can directly determine a region that is guaran-teed to contain the k -NNs for a given query with only two iterations. This has a clear cost benefit when compared with existing approaches, such as grid-based methods, which require an uncertain number of iterations. Extensive experiments confirm the superiority of the proposed method. For future work, we would like to explore how to evaluate continuous k -NN queries over moving objects. For a given k -NN query q , it is very possible that its result (a list of objects) remains relatively stable when objects move with reasonable velocities. Therefore, it is promising to investigate how the k -NN results can be incrementally updated as objects move.

