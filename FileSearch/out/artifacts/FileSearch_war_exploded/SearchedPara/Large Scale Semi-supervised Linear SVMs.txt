 Large scale learning is often realistic only in a semi-supervised setting where a small set of labeled exam-ples is available together with a large collection of unlabeled data. In many information retrieval and data mining ap-plications, linear classifiers are strongly preferred because of their ease of implementation, interpretability and em-pirical performance. In this work, we present a family of semi-supervised linear support vector classifiers that are de-signed to handle partially-labeled sparse datasets with pos-sibly very large number of examples and features. At their core, our algorithms employ recently developed modified fi-nite Newton techniques. Our contributions in this paper are as follows: (a) We provide an implementation of Trans-ductive SVM (TSVM) that is significantly more efficient and scalable than currently used dual techniques, for lin-ear classification problems involving large, sparse datasets. (b) We propose a variant of TSVM that involves multiple switching of labels. Experimental results show that this variant provides an order of magnitude further improve-ment in training efficiency. (c) We present a new algorithm for semi-supervised learning based on a Deterministic An-nealing (DA) approach. This algorithm alleviates the prob-lem of local minimum in the TSVM optimization procedure while also being computationally attractive. We conduct an empirical study on several document classification tasks which confirms the value of our methods in large scale semi-supervised settings.
 I.2.6 [ Artificial Intelligence ]: Learning; I.5.2 [ Pattern Recognition ]: Design Methodology X  Classifier design and evaluation Algorithms, Performance, Experimentation Copyright 2006 ACM 1-59593-369-7/06/0008 ... $ 5.00. Support Vector Machines, Unlabeled data, Global optimiza-tion, Text Categorization
Consider the following situation: In a single web-crawl, search engines like Yahoo! and Google index billions of doc-uments. Only a very small fraction of these documents can possibly be hand-labeled by human editorial teams and as-sembled into topic directories. In information retrieval rele-vance feedback, a user labels a small number of documents returned by an initial query as being relevant or not. The remaining documents form a massive collection of unlabeled data. Despite its natural and pervasive need, solutions to the problem of utilizing unlabeled data with labeled exam-ples have only recently emerged in machine learning litera-ture. Whereas the abundance of unlabeled data is frequently acknowledged as a motivation in most papers, the true po-tential of semi-supervised learning in large scale settings is yet to be systematically explored. This appears to be partly due to the lack of scalable tools to handle large volumes of data.
 In this paper, we propose extensions of linear Support Vector Machines (SVMs) for semi-supervised classification. Linear techniques are often the method of choice in many ap-plications due to their simplicity and interpretability. When data appears in a rich high-dimensional representation, lin-ear functions often provide a sufficiently complex hypothe-sis space for learning high-quality classifiers. This has been established, for example, for document classification with Linear SVMs in numerous studies.

Our methods are motivated by the intuition of margin maximization for semi-supervised SVMs [13, 5, 1, 6, 3, 4]. The key idea is to bias the classification hyperplane to pass through a low data density region keeping points in each data cluster on the same side of the hyperplane while re-specting labels. This algorithm uses an extended SVM ob-jective function with a non-convex loss term over the un-labeled examples to implement the cluster assumption in semi-supervised learning 1 . This idea is of historical impor-tance as one of the first concret e proposals for learning from unlabeled data; its popular implementation in [5] is consid-ered state-of-the-art in text categorization, even in the face of increasing recent competition.
The assumption that points in a cluster should have similar labels. The role of unlabeled data is to identify clusters and high density regions in the input space.
We highlight the main contributions of this paper. (1) We outline an implementation for a variant of Trans-ductive SVM [5] designed for linear semi-supervised classifi-cation on large, sparse datasets. As compared to currently used dual techniques (e.g in the SVM light implementation of TSVM), our method effectively exploits data sparsity and linearity of the problem to provide superior scalability. Ad-ditionally, we propose a multiple switching heuristic that further improves TSVM train ing by an order of magnitude. These speed enhancements turn TSVM into a feasible tool for large scale applications. (2) We propose a novel algorithm for semi-supervised SVMs inspired from Deterministic Annealing (DA) techniques. This approach generates a family of objective functions whose non-convexity is controlled by an annealing parameter. The global minimizer is parametrically tracked in this family. This approach alleviates the problem of local minima in the TSVM optimization procedure which results in better solutions on some problems. A computationally attractive training algorithm is presented that involves a se-quence of alternating convex optimizations. (3) We conduct an experimental study on many document classification tasks with several thousands of examples and features. This study clearly shows the utility of our tools for large scale problems.

The modified finite Newton algorithm (abbreviated l SVM-MFN) of Keerthi and Decoste [8] for fast training of linear SVMs is a key subroutine for our algorithms.
This paper is arranged as follows. In section 2 we describe the l 2 -SVM-MFN algorithm and present its semi-supervised extensions in section 3. Experimental results are reported in section 4. Section 5 contains some concluding comments. A more detailed version of this paper is available at [11]. The modified finite Newton l 2 -SVM method [8] (l 2 -SVM-MFN) is a recently developed training algorithm for Linear SVMs that is ideally suited to sparse datasets with large number of examples and possibly large number of features.
Given a binary classification problem with l labeled exam-ples { x i ,y i } l i =1 where the input patterns x i  X  R d ments) and the labels y i  X  X  +1 ,  X  1 } ,l 2 -SVM-MFN provides an efficient primal solution to the following SVM optimiza-tion problem: where l 2 is the l 2 -SVM loss given by l 2 ( z )=max(0 , 1 z ) 2 ,  X  is a real-valued regularization parameter and the final classifier is given by sign( w T x ).

This objective function differs from the standard SVM problem in some respects. First, instead of using the hinge loss as the data fitting term, the square of the hinge loss (or the so-called quadratic soft margin loss function) is used. This makes the objective function continuously differentiable, allowing easier applicability of gradient techniques. Sec-ondly, the bias term ( X  X  X ) is also regularized. In the problem formulation of Eqn. 1, it is implicitly assumed that an addi-tional component in the weight vector and a constant feature in the example vectors have been added to indirectly incor-porate the bias. This formulation combines the simplicity of a least squares aspect with algorithmic advantages asso-ciated with SVMs. We also note that all the discussion in this paper can be applied to other loss functions such as Hu-ber X  X  Loss and rounded Hinge loss using the modifications outlined in [8].

We consider a version of l 2 -SVM-MFN where a weighted quadratic soft margin loss function is used. Here we have rewritten Eqn. 1 in terms of the support vec-associated with the i th example has a cost c i . f ( w ) refers to the objective function being minimized, evaluated at a candidate solution w . Note that if the index set j ( w )were independent of w and ran over all data points, this would simply be the objective function for weighted linear regular-ized least squares (RLS).

Following [8], we observe that f is a strictly convex, piece-wise quadratic, continuously differentiable function having a unique minimizer. The gradient of f at w is given by: where X j ( w ) is a matrix whose rows are the feature vectors of training points corresponding to the index set j ( w ), Y is a column vector containing labels for these points, and C j ( w ) is a diagonal matrix that contains the costs c these points along its diagonal. l 2 -SVM-MFN is a primal algorithm that uses the New-ton X  X  Method for unconstrained minimization of a convex function. The classical Newton X  X  method is based on a sec-ond order approximation of the objective function, and in-volves updates of the following kind: where the step size  X  k  X  R , and the Newton direction n k  X  R d is given by: n k =  X  [  X  2 f ( w k )]  X  1  X  f ( w k ). Here, is the gradient vector and  X  2 f ( w k ) is the Hessian matrix of f at w k . However, the Hessian does not exist everywhere, since f is not twice differentiable at those weight vectors w where w T x i = y i for some index i . 2 Thus a generalized definition of the Hessian matrix is used. The modified fi-nite Newton procedure [8] proceeds as follows. The step  X  w k = w k + n k in the Newton direction can be seen to be given by solving the following linear system associated with a weighted linear regularized least squares problem over the data subset defined by the indices j ( w k ): h where I is the identity matrix. Once  X  w k is obtained, w is obtained from Eqn. 3 by setting w k +1 = w k +  X  k (  X  w after performing an exact line search for  X  k , i.e by exactly solving a one-dimensional minimization problem:
The modified finite Newton procedure has the property of finite convergence to the optimal solution. The key features
In the neighborhood of such a w , the index i leaves or enters j ( w ). However, at w , y i w T x i =1. So f is continuously differentiable inspite of these index jumps. that bring scalability and numerical robustness to l 2 -SVM-MFN are: (a) Solving the regularized least squares system of Eqn. 4 by a numerically well-behaved Conjugate Gradi-ent scheme referred to as CGLS, which is designed for large, sparse data matrices X . The benefit of the least squares aspect of the loss function comes in here to provide access to a powerful set of tools in numerical computation. (b) Due to the one-sided nature of margin loss functions, these systems are required to be solved over only restricted in-dex sets j ( w ) which can be much smaller than the whole dataset. This also allows additional heuristics to be devel-oped such as terminating CGLS early when working with a crude starting guess like 0, and allowing the following line search step to yield a point where the index set j ( w ) is small. Subsequent optimization steps then work on smaller subsets of the data Below, we briefly discuss the CGLS and Line search procedures. We refer the reader to [8] for full details.
CGLS is a special conjugate-gradient solver that is de-signed to solve, in a numerically robust way, large, sparse, weighted regularized least sq uares problems such as the one in Eqn. 4. Starting with a guess solution, several special-ized conjugate-gradient iterations are applied to get  X  w solves Eqn. 4. The major expense in each iteration con-sists of two operations of the form X j ( w k ) p and X T there are n 0 non-zero elements in the data matrix, these in-volve O ( n 0 ) cost. It is worth noting that, as a subroutine of l -SVM-MFN, CGLS is typically called on a small subset, X j ( w k ) of the full data set. To compute the exact solution of Eqn. 4, r iterations are needed, where r is the rank of X j ( w k ) . But, in practice, such an exact solution is unnec-essary. CGLS uses an effective stopping criterion for early termination. The total cost of CGLS is O ( t cgls n 0 )where t cgls is the number of iterations, which depends on the prac-tical rank of X j ( w k ) and is typically found to be very small relative to the dimensions of X j ( w k ) (number of examples and features). The memory requirements of CGLS are also minimal: only five vectors need to be maintained, including the outputs over the currently active set of data points.
Finally, an important feature of CGLS is worth empha-sizing. Suppose the solution w of a regularized least squares problem is available, i.e the linear system in Eqn. 4 has been solved using CGLS. If there is a need to solve a perturbed linear system, it is greatly advantageous in many settings to start the CG iterations for the new system with w as the initial guess. This is called seeding . If the starting residual issmall,CGLScanconvergemuchfasterthanwithaguess of 0 vector. The utility of this feature depends on the nature and degree of perturbation. In l 2 -SVM-MFN, the candidate solution w k obtained after line search in iteration k is seeded for the CGLS computation of  X  w k . Also, in tuning  X  over a range of values, it is valuable to seed the solution for a par-ticular  X  onto the next value. For the semi-supervised SVM implementations with l 2 -SVM-MFN, we will seed solutions across linear systems with slightly perturbed label vectors, data matrices and costs.
Given the vectors w k ,  X  w k in some iteration of l MFN, the line search step requires us to solve Eqn. 5. The one-dimensional function  X  (  X  ) is the restriction of the ob-jective function f on the ray from w k onto  X  w k . Hence, like f ,  X  (  X  ) is also a continuously differentiable, strictly convex, piecewise quadratic function with a unique minimizer.  X  is a continuous piecewise linear function whose root,  X  k ,can be easily found by sorting the break points where its slope changes and then performing a sequential search on that sorted list. The cost of this operation is negligible compared to the cost of the CGLS iterations. l 2 -SVM-MFN alternates between calls to CGLS and line searches. Its computational complexity is O ( t mf n  X  where t mf n is the number of outer iterations of CGLS calls and line search, and  X  t cgls is the average number of CGLS iterations. These depend on the data set and the toler-ance desired in the stopping criterion, but are typically very small. For example, on a text classification experiment in-volving 198788 examples and 252472 features, t mf n =11 and  X  t cgls = 102. Therefore, the complexity of l 2 -SVM-MFN is effectively linear in the number of entries in the data ma-trix.
We now assume we have l labeled examples { x i ,y i } l i =1 and u unlabeled examples { x j } u j =1 with x i ,x j  X  R d y  X  X  X  1 , +1 } . Our goal is to construct a linear classifier sign( w T x ) that utilizes unlabeled data, typically in situa-tions where l u . We present semi-supervised algorithms that provide l 2 -SVM-MFN the capability of dealing with unlabeled data. Transductive SVM appends an additional term in the SVM objective function whose role is to drive the classi-fication hyperplane towards low data density regions. Vari-ations of this idea have appeared in the literature [5, 1, 6]. Since [5] appears to be the most natural extension of stan-dard SVMs among these methods, and is popularly used in Text classification applications, we will focus on developing its large scale implementation.
 The following optimization problem is setup for standard TSVM 3 : min where the hinge loss function, l ( z )= l 1 ( z )= max (0 , 1 normally used. The labels on the unlabeled data, y 1 ...y are { +1 ,  X  1 } -valued variables in the optimization problem. In other words, TSVM seeks a hyperplane w and a labeling of the unlabeled examples, so that the SVM objective func-tion is minimized, subject to the constraint that a fraction r of the unlabeled data be classified positive. SVM margin maximization in the presence of unlabeled examples can be interpreted as an implementation of the cluster assumption. In the optimization problem above,  X  is a user-provided parameter that provides control over the influence of unla-beled data. For example, if the data has distinct clusters with a large margin, but the cluster assumption does not
The bias term is typically excluded from the regularizer, but this factor is not expected to make any significant dif-ference. hold, then  X  can be set to 0 and the standard SVM is re-trieved. If there is enough labeled data,  X ,  X  can be tuned by cross-validation. An initial estimate of r can be made from the fraction of labeled examples that belong to the positive class and subsequent fine tuning can be done based on validation performance.

This optimization is implemented in [5] by first using an inductive SVM to label the unlabeled data and then itera-tively switching labels and retraining SVMs to improve the objective function. The TSVM algorithm wraps around an SVM training procedure. The original (and widely popu-lar) implementation of TSVM uses the SVM light software. There, the training of SVMs in the inner loops of TSVM uses dual decomposition techniques. As shown by experi-ments in [8], in sparse, linear settings one can obtain signifi-cant speed improvements with l 2 -SVM-MFN over SVM light . Thus, by implementing TSVM with l 2 -SVM-MFN, we ex-pect similar improvements for semi-supervised learning on large, sparse datasets. Note that l 2 -SVM-MFN can also be used to speedup other TSVM formulations e.g [4] in such cases. The l 2 -SVM-MFN retraining steps in the inner loop of TSVM are typically executed extremely fast by using seed-ing techniques. Additionally, we also propose a version of TSVM where more than one pair of labels may be switched in each iteration. These speed -enhancement details are dis-cussed in the following subsections.
To develop the TSVM implementation with l 2 -SVM-MFN, we consider the TSVM objective function but with the L 2 -SVM loss function, l = l 2 .

Note that this objective function above can also be equiv-alently written in terms of the following loss over each un-labeled example x : Here, we pick the value of the label variable y that minimizes the loss on the unlabeled example x ,andrewriteinterms of the absolute value of the output of the classifier on x . This loss function is shown in Fig. 1. We note in passing that, l 1 and l 2 loss terms over unlabeled examples are very similar on the interval [  X  1 , +1]. The non-convexity of this loss function implies that the TSVM training procedure is susceptible to local optima issues. In the next subsection, we will outline a deterministic annealing procedure that can overcome this problem.

The TSVM algorithm with l 2 -SVM-MFN closely follows the presentation in [5]. A classifier is obtained by first run-ning l 2 -SVM-MFN on just the labeled examples. Temporary labels are assigned to the unlabeled data by thresholding the soft outputs of this classifier so that the fraction of the total number of unlabeled examples that are temporarily labeled positive equals the parameter r . Then starting from a small value of  X  , the unlabeled data is gradually brought in by increasing  X  by a certain factor in the outer loop. This grad-ual increase of the influence of the unlabeled data is a way to protect TSVM from being immediately trapped in a local minimum. An inner loop identifies pairs of unlabeled exam-ples with positive and negative temporary labels such that switching these labels would decrease the objective function. l -SVM-MFN is then retrained with the switched labels.
The TSVM algorithm presented in [5] involves switching a single pair of labels at a time. We propose a variant where upto S pairs are switched such that the objective function improves. Here, S is a user controlled parameter. Setting S = 1 recovers the original TSVM algorithm, whereas set-ting S = u/ 2 switches as many pairs as possible in the inner loop of TSVM. The implementation is conveniently done as follows: 1. Identify unlabeled examples with active indices and currently positive labels. Sort corresponding outputs in as-cending order. Let the sorted list be L + . 2. Identify unlabeled examples with active indices and currently negative labels. Sort corresponding outputs in de-scending order. Let the sorted list be L  X  . 3. Pick pairs of elements, one from each list, from the top of these lists until either a pair is found such that the output from L + is greater than the output from L  X  ,orif S pairs have been picked. 4. Switch the current labels of these pairs.

Using arguments similar to Theorem 2 in [5] we can show that Transductive l 2 -SVM-MFN with multiple-pair switch-ing converges in a finite number of steps.

We are unaware of any prior work that suggests and eval-uates this simple multiple-pair switching heuristic. Our ex-perimental results in section 4 establish that this heuristic is remarkably effective in speeding up TSVM training while maintaining generalization performance.
The effectiveness of l 2 -SVM-MFN on large sparse datasets combined with the efficiency gained from seeding w in the re-training steps (after switching labels or after increasing  X  ) make this algorithm quite attractive. The complexity of Transductive L 2 -TSVM-MFN is O ( n switches  X  t mf n where n switches is the number of label switches. Typically, n switches is expected to strongly depend on the data set and also on the number of labeled examples. Since it is difficult to apriori estimate the number of switches, this is an issue that is best understood from empirical observations.
The transductive SVM loss function over the unlabeled examples can be seen from Fig. 1 to be non-convex. This makes the TSVM optimization procedure susceptible to lo-cal minimum issues causing a loss in its performance in many situations, e.g as recorded in [3]. We now present a new algorithm based on deterministic annealing that can poten-tially overcome this problem while also being computation-ally very attractive for large scale applications. Determin-istic Annealing [2, 9] (DA) is an established tool for com-binatorial optimization that approaches the problem from information theoretic principles. The discrete variables in the optimization problem are relaxed to continuous proba-bility variables and a non-negative temperature parameter T is used to track the global optimum.

We begin by re-writing the TSVM objective function as follows: Here, we introduce binary valued variables  X  j =(1+ y j ) / 2. Let p j  X  [0 , 1] denote the belief probability that the unla-beled example x j belongs to the positive class. The Ising model 4 motivates the following objective function, where we relax the binary variables  X  j to probability variables p and include entropy terms for the distributions defined by p : Here, the  X  X emperature X  T parameterizes a family of ob-jective functions. The objective function for a fixed T is minimized under the following class balancing constraint: where r is the fraction of the number of unlabeled examples belonging to the positive class. As in TSVM, r is treated as a user-provided parameter. It may also be estimated from the labeled examples.

The solution to the optimization problem above is tracked as the temperature parameter T is lowered to 0. We monitor the value of the objective function in the optimization path and return the solution corresponding to the minimum value achieved.

To develop an intuition for the working on this method, we consider the loss term in the objective function associated with an unlabeled example as a function of the output of the classifier. Fig. 2 plots this loss term for various values of T . As the temperature is decreased, the loss function deforms from a squared-loss shape where a global optimum is easier to achieve, to the TSVM loss function in Fig. 1. At high temperatures a global optimum is easier to obtain. The minimizer is then slowly tracked as the temperature is lowered towards zero. A multiclass extension would use the Potts glass model. There, one would have to append the entropy of the distri-bution over multiple classes to a multi-class objective func-tion.

Figure 2: DA loss function parameterized by T.
The optimization is done in stages, starting with high val-ues of T and then gradually decreasing T towards 0. For each T , the problem in Eqns. 6,7 is optimized by alternat-ing the minimization over w and p =[ p 1 ...p u ] respectively. Fixing p , the optimization over w is done by l 2 -SVM-MFN with seeding. Fixing w , the optimization over p can also be done easily as described below. Both these problems involve convex optimization and can be done exactly and efficiently. We now provide some details. We describe the steps to efficiently implement the l 2 -SVM-MFN loop for optimizing w keeping p fixed. The call to l 2 SVM-MFN is made on the data  X  X = first l rows are formed by the labeled examples, and the next 2 u rows are formed by the unlabeled examples appearing as two repeated blocks. The associated label vector and cost matrix are given by C = diag
Even though each unlabeled data contributes two terms to the objective function, effectively only one term contributes to the complexity. This is because matrix-vector products, which form the dominant expense in l 2 -SVM-MFN, are per-formed only on unique rows of a matrix. The output may be duplicated for duplicate rows. Infact, we can re-write the CGLS calls in l 2 -SVM-MFN so that the unlabeled examples appear only once in the data matrix.
For the latter problem of optimizing p for a fixed w ,we construct the Lagrangian:
T 2 u Solving  X  L / X  X  j =0,weget: expression in the balance constraint in Eqn. 7, we get a one-dimensional non-linear equation in 2  X  : The root is computed by using a hybrid combination of Newton-Raphson iterations and the bisection method to-gether with a carefully set initial value.
For a fixed T , the alternate minimization of w and p pro-ceeds until some stopping criterion is satisfied. A natural criterion is the mean Kullback-Liebler divergence (relative entropy) KL ( p, q ) between current values of p i and the val-ues, say q i , at the end of last iteration. Thus the stopping criterion for fixed T is: A good value for is 10  X  6 . The temperature may be de-creased in the outer loop until the total entropy falls below a threshold, which we take to be =10  X  6 as above, i.e.,
H ( p )=  X 
The TSVM objective function,  X  2 is monitored as the optimization proceeds. The weight vec-tor corresponding to the minimum transductive cost in the optimization path is returned as the solution.
Semi-supervised learning experiments were conducted to test these algorithms on six text binary classification prob-lems. These are listed in Table 1.

The aut-avn and real-sim binary classification datasets come from a collection of UseNet articles 5 from four discus-sion groups, for simulated auto racing, simulated aviation, real autos, and real aviation. The ccat and gcat data sets pose the problem of separating corporate and government re-lated articles respectively; these are the top-level categories in the RCV1 training data set [7]. These data sets create an interesting situation where semi-supervised learning is required to learn different low de nsity separators respecting different classification tasks in the same input space. The 33-36 data set is a subset of a multiclass Yahoo shopping data set. Finally, the pcmac data set is a small subset of the 20-newsgroups data popularly used in semi-supervised learning literature (e.g in [3]). The results below are aver-aged over 10 random stratified splits of training (labeled and unlabeled) and test sets. The performance of SVM, DA and TSVM is studied as a function of the amount of labeled data in the training set. Since the two classes are fairly well rep-resented in these datasets, we report error rates, but expect
Available at: http://www.cs.umass.edu/  X  mccallum/data/ Table 1: Two-class datasets. d : data dimensionality,  X  n 0 : average sparsity, l + u : number of labeled and unlabeled examples, t : number of test examples, r : positive class ratio.
 our conclusions to also hold for other performance measures such as F-measure. We use a default value of  X  =1forall datasets except 6 for aut-avn and ccat where  X  = 10. The default value of  X  =0 . 001 was used for all datasets.
For datasets and software implementation, we point the reader to [12].
 We first examine the effectiveness of TSVM and DA in opti-mizing the TSVM objective function. In Table 2, we report the minimum value of the objective function achieved by TSVM and DA with respect to varying number of labels. As compared to TSVM, we see that DA performs significantly better optimization on aut-avn , ccat ,and pcmac datasets and slightly better optimization on the other datasets. Table 2: TSVM,DA: Minimum value of objective function achieved with respect to number of labels. Statistically significantly better minimizations are showninbold. In Table 3 we report error rates over unseen test examples for SVM (which only uses labeled examples), TSVM and DA with respect to varying amounts of labeled data. The following observations are made. (1) Comparing the performance of SVM against the semi-supervised algorithms, the benefit of unlabeled data for boost-
This produced better results for both TSVM and DA. A careful optimization of  X  was not attempted. Table 3: SVM, TSVM, DA: test error rate compari-son. TSVM (S=max) are results for multiple (max-imum possible) switching TSVM. Bold numbers in-dicate a significant performance difference between TSVM and DA. ing generalization performance is evident on all datasets. This is true even for moderate number of labels, though it is particularly striking towards the lower end. (2) On aut-avn and pcmac , DA outperforms TSVM sig-nificantly. On ccat , DA performs a much better optimization (Table 2) but this does not translate into major error rate improvements. DA and TSVM are very closely matched on gcat and 33-36 .On real-sim , TSVM and DA perform very similar optimization of the transduction objective function (Table 2), but appear to return very different solutions. The TSVM solution returns lower error rates as compared to DA on this dataset. (3) On all datasets we found that multiple switching (see rows corresponding to TSVM (S=max) in Table 3) returned nearly identical performance as single switching. Since it saves significant computation time, our study estab-lishes multiple switching as a valuable heuristic for training TSVM. (4) These observations are also true for in-sample trans-ductive performance. Both TSVM and DA are found to provide high quality extension to unseen test data. In Figure 3, we plot the average computation time for DA and TSVM with single and maximum switching. We make the following observations. The single switch TSVM is an order of magnitude slower than the maximum switching vari-ant. DA is significantly faster than single switch TSVM but slower than TSVM with maximum switching.
 Figure 3: Computation time with respect to num-ber of labels for DA and Transductive l 2 -SVM-MFN with single and multiple switches.
In Table 4, we compare our TSVM and DA implementa-tions with SVM light at its default optimization settings on the first split with fewest labeled examples. These compar-isons clearly demonstrate massive speedups with our meth-ods. Note that the results presented in this section were obtained with a MATLAB implementation. We expect sig-nificantly faster computation times with a C or a fortran implementation, especially with parallel computation of ma-trix vector products 7 .
 Table 4: Speed comparisons (in seconds) with SVM light . S=1 and S=max denotes our single and multiple maximum implementations.
 To confirm the necessity of an annealing component (track-ing the minimizer with respect to T ) in the optimization, we compare DA with the alternating w , p optimization pro-cedure where the temperature parameter is held fixed at T =0 . 1and T =0 . 001. In Figure 4 we plot the error rates achieved with and without annealing. We see that anneal-ing tends to provide higher quality solutions as compared to fixed temperature optimization.

It is important to note that the gradual increase of  X  to the user-set value in TSVM is also a mechanism to avoid preliminary experiments with a C++ implementation (to be made available at [12]) suggested about 5-fold further improvements in speed. local optima. The non-convex part of the TSVM objective function is gradually increased to a desired value. In this sense,  X  simultaneously plays the role of an annealing pa-rameter and also provides control over the strength of the cluster assumption. This dual role has the advantage that a suitable  X  can be chosen by monitoring performance on a validation set as the algorithm proceeds. In DA, however, we directly apply a framework for global optimization, and decouple annealing from the implementation of the cluster assumption. As our experiments show, this can lead to sig-nificantly better solutions on many problems.
In this paper we have proposed a family of primal SVM algorithms for large scale semi-supervised learning based on the finite Newton technique. Our methods significantly enhance the training speed of TSVM over existing meth-odssuchasSVM light and also include a new effective tech-nique based on deterministic annealing. The new TSVM method with multiple switching is the fastest of all the al-gorithms considered, and also returns good generalization performance. The DA method is relatively slower but often gives the best accuracy. These algorithms can be very valu-able in applied scenarios where sparse classification prob-lems arise frequently, labeled data is scarce and plenty of unlabeled data is easily available. Even in situations where a good number of labeled examples are available, utilizing unlabeled data to obtain a semi-supervised solution using these algorithms can be worthwhile. For one thing, the semi-supervised solutions never lag behind purely supervised so-lutions in terms of performance. The presence of a mix of labeled and unlabeled data can provide added benefits such as reducing performance variability and stabilizing the lin-ear classifier weights. Our algorithms can be extended to the non-linear setting [10], and may also be developed to handle clustering and one-class classification problems. These are subjects for future work. [1] K. Bennett and A. Demirez, Semi-Supervised Support [2] G. Bilbro, R. Mann, T.K. Miller, W.E. Snyder and [3] O. Chapelle and A. Zien, Semi-Supervised [4] R. Collobert, F. Sinz, J. Weston, and L. Bottou, Large [5] T. Joachims, Transductive Inference for Text [6] G. Fung and O. Mangasarian, Semi-Supervised Support [7] D. Lewis, Y. Yang, T. Rose and F. Li, RCV1: A New [8] S. S. Keerthi and D. DeCoste, A Modified Finite [9] C. Peterson and B. Soderberg, A new method for [10] V. Sindhwani, S. S. Keerthi, and O. Chapelle, [11] V. Sindhwani and S.S. Keerthi, Large Scale
