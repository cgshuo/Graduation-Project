 Trust plays a crucial role in helping users collect reliable in-formation in an online world, and has attracted more and more attention in research communities lately. As a con-ceptual counterpart of trust, distrust can be as important as trust. However, distrust is rarely studied in social me-dia because distrust information is usually unavailable. The value of distrust has been widely recognized in social sciences and recent work shows that distrust can benefit various on-line applications in social media. In this work, we investi-gate whether we can obtain distrust information via learn-ing when it is not directly available, and propose to study a novel problem -predicting distrust using pervasively avail-able interaction data in an online world. In particular, we analyze interaction data, provide a principled way to mathe-matically incorporate interaction data in a novel framework dTrust to predict distrust information. Experimental results using real-world data show that distrust information is pre-dictable with interaction data by the proposed framework dTrust. Further experiments are conducted to gain a deep understand on which factors contribute to the effectiveness of the proposed framework.
 H3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Information filtering Algorithms; Design; Experimentation Distrust in Social Media; Predictability of Distrust; Interac-tion Data; Balance Theory
Trust plays an important role in helping online user obtain reliable information and has attracted increasing attention in recent years [9, 36, 37]. The availability of trust informa-tion helps improve the performance of various applications in social media such as recommendation [9, 22], finding high-quality user generated content [21], and viral marketing [31]. However, as a conceptual counterpart of trust, distrust is rarely studied in the online world because distrust informa-tion is usually unavailable in the online world.

It is suggested in research [16, 11] that trust is a desired property while distrust is an unwanted one for an online so-cial community. Therefore, various online services such as Ciao 1 , eBay 2 and Epinions 3 implement trust mechanisms to help users to better use their services, but few of them al-low online users to specify distrust relations. As we learn from social sciences [26, 16], distrust can be as important as trust. Both trust and distrust can help a decision maker reduce the uncertainty and vulnerability associated with de-cision consequences [4], and sometimes distrust can play a critical role in consumer decisions [34, 26]. Many social sci-entists believe that distrust is not simply the negation of trust [18, 15]. This can be quickly verified using transitiv-ity 4 and balance theory [2, 12]. As we know, transitivity is an important property of trust, i.e., if u i trusts u j and u trusts u k , it is likely for u i to trust u k . If distrust was the negation of trust ( or distrust is equivalent to low trust) [33], according to transitivity, it would be true that if u i distrusts u j and u j distrusts u k , it is likely that u i distrusts u the transitivity of distrust would violate balance theory
The lack of distrust research could lead to a biased es-timate of the effect of trust, and distrust information has added value on trust [38]. The availability of distrust in-formation can benefit various applications in social media. For example, a small amount of distrust information can make remarkable improvement in trust prediction [38], and in e-commerce, users might or might not accept recommen-dations from their trusted users, but will certainly exclude recommendations from their distrusted users [26, 41]. Gen-uine distrust information tends to be more noticeable and credible, and weighed more than trust information of a simi-lar magnitude, therefore, distrust information can be critical in social media applications. Given the fact that distrust in-formation is usually unavailable but important, in this work, we investigate if distrust information can be obtained via learning from social media data. h ttp://www.ciao.co.uk/ http://www.ebay.com/ http://www.epinions.com/
A relation R is transitive if u i Ru j and u j Ru k , then u
If u i distrusts u j and u j distrusts u k , then u i trusts u Figure 1: An Illustration of Interaction Data in Pr oduct Review Sites.

In the physical world, people are likely to share trust with others while hide their distrust. However, we still can tell distrust by observing their interactions. With this intuition, interaction data in social media might be helpful to obtain distrust information when it is not directly available. Inter-action data is pervasively available in social media. Figure 1 illustrates interaction data available in product review sites like Epinions. Trust relations among users (e.g., { u 1  X  u are available. Users can give helpfulness ratings to reviews written by other users. For example, u 2 rates the helpful-ness of reviews r 1 and r 2 written by u 1 . Users can rate a review with various scores to indicate its helpfulness from  X  X ot helpful X  to  X  X ery helpful X . In this paper, we propose to turn the search of distrust information into a problem of predictability of distrust using interaction data. In essence, we investigate -(1) how to exploit interaction data? and (2) how to model interaction data mathematically to predict distrust relations? Our solutions to these two challenges re-sult in a novel framework dTrust for the distrust prediction problem. Our main contributions are summarized below,
The rest of paper is organized as follows. The studied problem is formally defined in Section 2. In Section 3, we describe the datasets and the importance of interactions in the predictability of distrust relations. In Section 4, we in-troduce the way to incorporate interaction data and the pro-posed framework dTrust to predict distrust relations with interaction data. Section 5 presents experimental results with discussions. Section 6 reviews related work. Finally, Section 7 concludes this study with future work.
In this paper, we study the problem in the context of prod-uct review sites, however, the proposed framework is general and can be applied to other sites implementing trust mech-anisms. Let U = { u 1 , u 2 , . . . , u n } and R = { r 1 be the sets of users and reviews respectively, where n is the number of users and m is the number of reviews. We use note user-user trust relations, user-user distrust relations, user-review authorship relations, and user-review helpful-ness ratings at time t , respectively. T ij = 1 (or D ij = 1) if u i trusts (or distrusts) u j , zero otherwise. P ij = 1 if u writes r j , zero otherwise. If u i rates the helpfulness of r R ij is the helpfulness rating score, and we use the symbol  X ? X  to denote R ij if u i does not rate r j .

The availability of trust information T encourages many trust-related applications, and trust prediction is one of the most important and popular applications. Assume that T t  X  R n  X  n denotes user-user trust relations established af-ter the time t , trust prediction aims to develop a predictor f to predict new relations T t using old relations T ,
When both distrust D and trust T information are avail-able, trust and distrust prediction problem is extensively studied to predict new trust and distrust relation as where D t  X  R n  X  n denotes user-user distrust relations es-tablished after the time t . Trust and distrust prediction problem is to develop a predictor f to predict new trust and distrust relations { T n , D n } using old trust and distrust relations { T , D } .

Given the unavailability and importance of distrust infor-mation, we ask whether distrust information can be learned from interaction data. We formally define it as: given user-user trust relations T , user-review authorship relations P and user-review helpfulness ratings R , we aim to develop a predictor f to predict distrust relations D with T , P and R ,
In this section, we first introduce the dataset we used for this study, and then provide our solution to the first chal-lenge -how to exploit interaction data.
Trust mechanisms are implemented by various online ser-vices; however, few of them allow uses to establish distrust relations. Although the product review site Epinions al-lows users to trust and distrust other users, distrust rela-tions are unavailable to the public. For the research pur-pose, a dataset with distrust relations was given by Epinions staff [24]. We preprocess the data by filtering users without any trust and distrust relations. This dataset includes trust and distrust relations, user-review authorship relations and user-review helpfulness ratings. Note that the availability of distrust relations in this dataset serves as the ground truth for only analysis and evaluation purpose, which are not used in the learning process of the proposed framework. The statistics of the dataset are shown in Table 1. F igure 2: The Distributions of Indegree and Outde-gree of Trust and Distrust Relations.

We compute the number of trust and distrust relations each user receives and creates, and these distributions are shown in Figure 2. The distributions for both trust and distrust suggest a power-law-like distribution that is typical in social networks. Users in Epinions can specify a score from 1 to 6 to indicate the helpfulness of a review from  X  X ot helpful X  to  X  X ery helpful X . We investigate the helpfulness rating distributions and find that more than 70% of users give a score 4 or 5 with an average score of 4 . 7129. In the following subsection, we investigate the correlation between interactions and distrust relations.
Users can participate in various online activities such as liking, commenting or rating, which produces rich interac-tion data in social media. Users can perform negative inter-actions to other users by disliking, giving negative comments or negative ratings on their generated content. In the con-text of product review sites, a user can rate reviews written by another user not helpful, which shows disagreement and antagonism toward the user. It is reasonable to surmise that negative interactions (e.g.,  X  X ot helpful X  ratings) might be correlated to their distrust relations. In this subsection, we study the correlations between negative interactions and distrust relations to seek a solution to the first challenge.
In Epinions, users can rate reviews with scores 1 to 6 to indicate their helpfulness. In this study, we consider scores less than 3 as not helpful ratings (or negative interactions). Ratio of Distrust Relations Figure 3: # Negative Interactions vs. Distrust Re-l ations.
 We calculate a matrix Q  X  R n  X  n from user-review author-ship relations P and user-review helpfulness ratings R where Q ij is the number of negative interactions from u i to u j
To study the correlation between negative interactions and distrust relations, we try to answer the question -are two users with negative interactions more likely to have a distrust relation than two randomly chosen users? . Let H = {h u i , u j i| Q ij &gt; 0 } be the set of pairs of users with nega-tive interactions. For each pair of users h u i , u j i , we use a and b r to indicate whether there exist distrust relations for h u i , u j i and h u i , u k i respectively, where u k is a randomly chosen user. If u i distrusts u j , a n = 1 and zero otherwise; while if u i distrusts u k , b r = 1 and zero otherwise. For all pairs in H , we obtain two vectors, a and b . a is the set of a n , while b is the set of b r . We conduct a two-sample t -test on a and b . The null hypothesis and the alternative hypothesis are defined as The null hypothesis is rejected at significance level  X  = 0 . 01 with p-value of 7.12e-147. Evidence from t-test suggests a positive answer to the question: there is a strong corre-lation between negative interactions and distrust relations, and users with negative interactions are likely to have dis-trust relations.

We define K as the set of unique non-zero numbers of negative interactions in Q as
To study the impact of the number of negative interactions on the correlation, we use S K to denote the set of pairs of users h u i , u j i where the number of negative interactions from u to u j is no less than K  X  X  , which is formally defined as
We further define that D K is the set of pairs with distrust relations in S K as Then we calculate p K a s the ratio of pairs with distrust relations D K in S K as
The distribution of ratios of distrust relations p K s with respect to K is shown in Figure 3. Note that the black solid line in the figure denotes the ratio of distrust relations r in the distrust network. For all K , p K s are much larger than r dis , which further suggests the correlation between negative interactions and distrust relations. With the increase of K , the ratios p K s tend to increase, which indicates that the more negative interactions two users have, the more likely a distrust relation exists between them.
In the last section, we find a strong correlation between negative interactions and distrust relations, and reveal the impact of the number of negative interactions on the correla-tion. In this section, we first introduce a way to model inter-action data by capturing the correlation, and then present the proposed framework dTrust with its optimization algo-rithm, which provides the solution to the second challenge.
To model interaction data, we try to capture the correla-tion with findings from the previous section. We first divide all n 2 pairs of users into three groups G = {G 1 , G 2 , G their definitions are stated as:
From above definitions, we can see that G 1 and G 2 corre-spond to the set of pairs of users with trust relations and neg-ative interactions, respectively. Based on these three groups, we introduce a matrix F  X  R n  X  n to represent user-user trust relations and pseudo distrust relations from interaction data, and the entities of F are defined as follows: The entities of F are formally defined as follows:
The values in the user-user trust and pseudo distrust ma-trix F may be not equally reliable. For example, F ij for h u i , u j i X  X  1 is very reliable since we observe trust relations, while values of pairs in G 2 with more negative interactions are more reliable based on our previous finding of the impact of the number of negative interactions on the correlations -the more negative interactions two users have, the more likely a distrust relation exists between them. Therefore, we define a weight matrix W  X  R n  X  n where W ij  X  [0 , 1] is a weight to indicate the reliability of F ij . Next we define the weight matrix as We empirically find the following definition of g ( x ) works well in this work: where g ( x ) is a non-decreasing function of x . In our problem, x is a positive integer therefore x + 1 can guarantee that The weight matrix W is formally defined as,
With the user-user trust and pseudo distrust relations F and its weight matrix W , our problem can boil down to a special trust and distrust prediction problem with trust and pseudo distrust relations. Therefore we can choose a representative trust and distrust prediction algorithm as our basic algorithm. In [35], a matrix factorization framework is proposed to predict trust relations based on T as where U  X  R n  X  d with d  X  n is the user preference matrix and T ij is modeled as the correlation between the prefer-ences of u i and u j by H as U i HU  X  j . The term  X  ( k U k k H k 2 F ) is added to avoid over-fitting. The framework can be directly extended for trust and distrust prediction by rep-resenting a distrust relation as -1 in T [13]. In this paper, we choose it as the basic algorithm. However, note that we could also choose other algorithms such as trust and distrust propagation [10] as the basic algorithm and we would like to leave this investigation for our future work. We may not directly apply Eq. (15) to our problem since the values in F may not be reliable. We modify Eq. (15) and the new formulation with the user-user trust and pseudo distrust re-lations F and its weight matrix W is to solve the following optimization problem, m in where the formation in Eq. (16) allows us to consider the reliability of values in F by W . The contribution of F ij the learning process is controlled by W ij . A large value of W ij , indicating the high reliability of F ij , will force U to tightly fit F ij while U i HU  X  j will loosely approximate F when W ij is small.

To model interaction data, we introduce the concept of pseudo distrust relations and the significance is three-fold. First, it provides a way to model interaction data. Second, it helps us boil down the studied problem into a special trust and distrust prediction problem. Finally it allows us to exploit some social theories for signed networks since the introduction of pseudo distrust relations converts the trust unsigned network into a signed trust and pseudo distrust network. In the following subsection, we will introduce how to model one of the most important and popular social the-ories for signed networks balance theory.
We use s ij to denote the sign of the relation between u i and u j where s ij = 1 (or s ij =  X  1) if we observe a trust re-lation (or a distrust relation) between u i and u j . With these notations, balance theory suggests that a triad h u i , u is balanced if
Note that balance theory is proposed for undirected net-works and following a common practice [17], we ignore the directions of relations, and only consider the signs of rela-tions (i.e., trust and distrust) when we apply balance theory to trust and pseudo distrust relations.

For a triad h u i , u j , u k i , there are four possible sign combi-nations (+,+,+) (+,+,-) (-,-,+) and (-,-,-), while only (+,+,+) and (-,-,+) are balanced. We examine all triads in the stud-ied dataset and find that more than 90% of them are bal-anced, which is consistent with observations in [17]. This result suggests that balance theory is a principle to under-stand the formation of trust and distrust relations. The introduction of pseudo distrust relations enables us to ex-ploit balance theory, while exploiting balance theory in turn may help us mitigate the effects of unreliability of pseudo distrust relations, and potentially improves the distrust pre-diction performance.

There are three common ways to exploit social theories in social media mining including feature engineering, con-straint generating, and objective defining [39]. In this work, we choose objective defining to model balance theory. For each user u i , we introduce a one-dimensional latent factor r and we further assume that the trust or distrust relation between u i and u j due to the effect of balance theory is modeled as [42], Next we will prove that Eq. (17) can capture balance theory with the following theorem:
Theorem 4.1. Eq. (17) can capture balance theory. That is to say, with Eq. (17), we can have
Proof. Let us first prove Case 1 . If sign ( F ij ) = 1 and sign ( F jk ) = 1, we have sign ( r i r j ) = 1 and sign ( r by multiplying sign ( r i r j ) and sign ( r j r k ), we have 1, i.e., sign ( F ik ) = 1.

We can use a similar process to prove Case 2 . If sign ( F  X  1 and sign ( F jk ) =  X  1, we have sign ( r i r j ) =  X  1 and sign ( r j r k ) =  X  1; by multiplying sign ( r i r j ) and sign ( r we have sign ( r i r j r j r k ) = 1. Since sign ( r 2 j sign ( r i r k ) = 1, i.e., sign ( F ik ) = 1, which completes the proof.

With the solutions to both challenges in the introduction s ection, next we will introduce the proposed framework with its optimization algorithm.
In Eq. (16), F ij is modeled as U i HU  X  j , and it is modeled as r i r j due to the effect of balance theory. When we consider both, F ij can be modeled by combining Eqs. (16) and (17) as where  X  is introduced to control the contribution from bal-ance theory. Then the proposed framework dTrust is to solve the following optimization problem, where r = [ r 1 , r 2 , . . . , r n ]  X  and the term  X  k r k to avoid over-fitting. Eq. (19) can be rewritten to its matrix form as where  X  is the Hadamard product where ( X  X  Y ) ij = X ij Y ij for any two matrices X and Y with the same size.
Set A = F  X   X  rr  X  and let L contain terms related to U and H in the objective function J of Eq. (20), which can be rewritten as, L = T r (  X  2( W  X  W  X  A ) UH  X  U  X  + ( W  X  W  X  UHU  X  ) the partial derivations of U a nd H with respective to J can be obtained from L are 1 2  X  J  X  U  X  ( W  X  W  X  A ) U H  X   X  ( W  X  W  X  A )  X  UH +  X  U + ( W  X  W  X  UHU  X  ) UH  X  + ( W  X  W  X  UHU  X  )  X  UH , 1 2  X  J  X  H  X  U  X  ( W  X  W  X  A ) U + U  X  ( W  X  W  X  U HU  X  ) U +  X  H
Set B = G  X  UHU  X  and let L r contain terms related to r in J , which can be rewritten as, then the partial derivation of r with respect to J is
With the partial derivations of U , H , and r , a optimal solution of the objective function in Eq. (20) can be obtained through a gradient decent optimization method as shown in Algorithm 1.
 Algorithm 1: T he Proposed Framework dTrust.

Input : U ser-user trust relations T , user-review authorship relations P , user-review helpfulness ratings R , { d,  X  } .

Output : A ranking list of pairs of users. 10: Set D = {h u i , u j i| sign (  X  F ij ) =  X  1 } 11: Ranking pairs of users in D (e.g., h u i , u j i ) according to
Next we briefly review Algorithm 1. In line 1, we con-s truct the trust and pseudo distrust relation matrix F and its weight matrix W from user-user trust relations T , user-review authorship relations P , and user-review helpfulness ratings R . From line 3 to line 8, we update U , H and r until convergence where  X  u ,  X  h and  X  r are learning steps, which are chosen to satisfy Goldstein Conditions [29]. Af-ter learning the user preference matrix U , H and r via Al-gorithm 1, the reconstructed trust and distrust matrix is  X  F = UHU  X  +  X  rr  X  . Finally we predict pairs h u i , u j sign (  X  F ij ) =  X  1 as a distrust relation with confidence |
In this section, we conduct experiments to evaluate the effectiveness of the proposed framework. In particular, we try to answer two questions via experiments -(1) can the proposed framework predict distrust information indirectly with interaction data? and (2) how do the components of dTrust affect its performance? We begin by introducing ex-perimental settings, then design experiments to seek answers for these questions and finally we do analysis on the impor-tant parameters of dTrust.
Before answering above two questions, we first introduce the experimental settings in this subsection. Let A be the set of pairs with trust relations in the dataset introduced in Section 3.1 and we sort A in a chronological order in terms of the time when pairs established trust relations. Assume that there are x % of pairs in A establishing trust relations until time t x . For each x , we collect trust relations, dis-trust relations, user-review authorship relations and user-review helpfulness ratings until time t x to form a evaluation dataset Epinionsx . In this paper, we vary x as { 50 , 70 , 100 } and correspondingly we construct three evaluation datasets from the dataset introduced in Section 3.1, i.e., Epinions50 , Epinions70 and Epinions100 . The purpose of varying the values of x is to investigate the performance of the proposed framework on Epinions datasets with different statistics.
For each dataset, we use T and O to denote sets of pairs of users with and without trust relations. D is the set of pairs with distrust relations, which is a subset of O . We follow the common metric for trust/distrust evaluation in [19, 35] to assess the prediction performance. In detail, each predictor ranks pairs in O in a descending order of confidence and we take the first |D| pairs as the set of predicted distrust relations, denoting P . Then the prediction quality is, where || denotes the size of a set. As noticed in [19], the PQ value is usually low and to more meaningfully represent predictor quality, a random predictor is usually used as a baseline method . Each experiment is repeated 10 times and we report the average performance.
To the best of our knowledge, we are the first to study the predictability of distrust in social media; hence, there are no existing baseline methods. However, to answer the first question, we still build the following baseline methods: Figure 4: Performance Comparison of Different Pre-d ictors. For baseline methods with parameters, we try various values of these parameters and report the best performance. For dTrust, we set  X  = 0 . 1, and empirically set { d = 250 ,  X  = 0 . 1 } . More details about parameter analysis for dTrust will be discussed later in this section. The comparison results are shown in Figure 4.

We make the following observations:
We perform t-test on all results and the t-test results in-dicate that all improvement is significant. In summary, per-formance comparison between the random predictor and the p roposed framework dTrust suggests that dTrust can accu-rately predict distrust relations by incorporating interaction data and modeling balance theory, which correspondingly answers the first question. dTrust has two important components -(1) incorporating interaction data by the user-user trust and pseudo distrust matrix F , and (2) modeling balance theory based on F . In this subsection, we investigate the effects of these compo-nents on the performance of dTrust to answer the second question. In detail, we systematically eliminate their effects from dTrust by defining its variants as follows,
The results are shown in Figures 5 and  X  X andom X  in the figure represents the performance of randomly guessing. The following can be observed: Table 2: Difference Definitions of g ( x ) f or W. Note that  X  X andom X  in the table denotes that we ran-domly assign values in [0 , 1] to the function.
 g ( x ) = 1  X  1 log ( x +1 ) 0.08737 0.15054 0.17391
In summary, the introduction of the trust and pseudo dis-trust matrix F to incorporate interaction data for dTrust enables not only distrust prediction but also modeling bal-ance theory mathematically, which can further improve the performance of dTrust.
There are two important parameters to control two major components of dTrust -(1) W controlling F to incorporate interaction data; and (2)  X  controlling the contribution from balance theory. In this section, we investigate the impact of each of these parameters on dTrust by fixing the other to see how the performance of dTrust varies.

W is defined based on the function g ( x ) to control the contribution from incorporating interaction data. We in-vestigate the impact of W on the proposed framework by choosing different types of g ( x ) for the following questions: We fix  X  = 0 . 1, the results of dTrust with different choices of g ( x ) are shown in Table 2. Note that  X  X andom X  in the table denotes that we randomly assign values in [0 , 1] to the function. We make the following observations Accuracy Figure 6: Impact of Balance Theory on dTrust.

A fter answering above two questions, we can conclude that (1) g ( x ) in W should not be random values; (2) defin-ing g ( x ) based on the number of negative interactions can significantly improve the performance of dTrust.

To investigate the parameter  X  , we set g ( x ) = 1  X  1 log ( x +1 ) mance variation with respect to  X  is depicted in Figure 6. In general, with the increase of  X  , the performance first in-creases, reaches its peak value and then decreases dramat-ically. This pattern may be useful for us to determine the optimal value of  X  in practice. In detail, when  X  increases from 0 to 10, we have the following observations
An appropriate incorporation of balance theory into dTrust based on the trust and pseudo distrust relation matrix F can greatly improve the performance of distrust prediction.
In this section, we first briefly review distrust in social sciences. As mentioned in the problem statement section, the studied problem is related to traditional trust predic-tion and prediction with both trust and distrust relations. Some work considers trust relations as positive relations and distrust relations as negative relations, and then trust and distrust prediction problem is converted into link prediction in signed networks [17, 42]. Therefore, we also briefly re-view related work from trust prediction, and link prediction in signed networks.
I n social sciences, the conceptual counterpart of trust, dis-trust, is considered as important and complex as trust [26, 16, 11, 6]. For example, [34, 4] claim that trust and distrust help a decision maker reduce uncertainty and vulnerability (i.e., risk) associated with decision consequences; and [6] in-dicates that only distrust can irrevocably exclude services from being selected at all. There is a basic problem about distrust -what is the relation between trust and distrust. Answering this question is significant. If trust and distrust are the same, lack of distrust research matters little; how-ever, if they are different, the lack of distrust research could be problematic because distrust may have unique impact. Some researchers believe distrust simply means a low level of trust, hence evidence of high trust was always regarded as being that of low distrust, and outcomes of high trust would be identical to those of low distrust [33, 1, 14]. Others be-lieve distrust is a concept entirely separate from trust [18, 15]. For example, in [18, 27], three reasons are proposed to prove that trust and distrust are separate:(1) they separate empirically; (2) they coexist; and (3) they have different antecedents and consequents.
Most existing trust prediction algorithms can be roughly categorized into two groups -supervised methods [20, 23] and unsupervised methods [10, 35]. There are usually two steps for supervised methods. First, they extract features from available sources to represent each pair of users and consider the existence of trust relations as labels. Second, they train a binary classifier based on the representation with extracted features and labels. For example, in [20], a taxonomy is developed to systematically organize an exten-sive set of features for predicting trust relations and the fea-tures include user and interaction factors. User factors con-tain rater-related, writer-related, or commenter-related; and Viet-An Nguyen et al. [28] proposes various trust prediction models based on a well-studied Trust Antecedent Frame-work used in management science, capturing the three fol-lowing factors: ability, benevolence and integrity. Unsuper-vised methods usually take advantage of some properties of trust to infer unknown trust relations. A trust propagation method is proposed in [10], which introduces four types of atomic propagations such as direct propagation, co-citation propagation, transpose propagation and trust coupling prop-agation. In [8], algorithms for inferring binary and continu-ous trust values from trust networks are proposed based on various properties of trust such as transitivity, composability and asymmetry. The user-user trust relation matrix should be low-rank and based on this property, a trust prediction algorithm is proposed based on low-rank matrix factoriza-tion in [35].
Link prediction in signed networks has attracted increas-ing attention in recent years. In [10], an algorithm based on trust and distrust propagation is proposed to predict trust and distrust relations. In [17], local-topology-based features based on balance theory are extracted to improve the per-formance of a logistic regression classifier in signed relation prediction. In [7], a trust and distrust prediction algorithm is proposed by combining an inference algorithm that relies on a probabilistic interpretation of trust based on random graphs with a modified spring-embedding algorithm. In [13], a low-rank matrix factorization approach with generalized loss functions is proposed to predict trust and distrust re-lations. Features derived from longer cycles in signed net-work can be used to improve link prediction performance [3]. There is also recent work to predict the signs of links. In [42], authors proposed a framework to predict the signs of a given network. Tang et al. proposed a framework to incorporate social theories into a machine learning model and infer the signs of social relations in a target network by borrowing knowledge from a different source network [40]. In [43], the authors use the transfer learning approach to leverage sign information from an existing and mature signed network to predict signs for a newly formed signed social network. The sign prediction problem is also very different from the stud-ied problem. The sign prediction problem predicts signs for existing relations; while our problem is to predict unknown distrust relations.
Distrust is considered as important as trust and the value of distrust is widely recognized by social sciences. However, distrust is rarely studied in the online world because distrust information in the online world is often unavailable to the public. In this paper, we investigate whether we can obtain distrust information indirectly by studying the problem of predictability of distrust from public interaction data. We first identify that there is a strong correlation between neg-ative interactions and distrust relations. The more negative interactions two users have, the more likely a distrust rela-tion between them exists. Then we model a trust and pseudo distrust relation matrix from interaction data with the cor-relation, which not only enables distrust prediction but also allows us to model balance theory. Finally we propose a novel framework dTrust for distrust prediction by incorpo-rating interaction data and modeling balance theory. Exper-imental results on real-world data show that the proposed framework dTrust can accurately predict distrust relations with interaction data. Further experiments are conducted to understand the importance of interaction data in predicting distrust relations.

There are several interesting directions needing further in-vestigation. First since negative interactions can be found in many social media websites which only provide positive links (such as friendships in Facebook), it would be very interesting to apply the proposed framework to predict neg-ative links with interaction data. Second, the current frame-work is an unsupervised method and chooses a matrix fac-torization method as the basic algorithm; we would like to investigate supervised methods and other basic algorithms for this problem. Finally, distrust relations inferred by the proposed framework may benefit various applications such as recommendation, and we plan to incorporate dTrust into these applications to improve performance.
 The work is, in part, supported by Army Research Office (#025071), The Office of Naval Research (N000141410095) and a research fund from Yahoo Faculty Research and En-gagement Program. [ 1] B. Barber. The logic and limits of trust . Rutgers [2] D. Cartwright and F. Harary. Structural balance: a [3] K.-Y. Chiang, N. Natarajan, A. Tewari, and I. S. [4] J. Cho. The mechanism of trust and distrust [5] J. Audun. Artificial reasoning with subjective logic. [6] P. Cofta. Distrust. In ICEC , 2006. [7] T. DuBois, J. Golbeck, and A. Srinivasan. Predicting [8] J. Golbeck. Generating predictive movie [9] J. Golbeck. Trust and nuanced profile similarity in [10] R. Guha, R. Kumar, P. Raghavan, and A. Tomkins. [11] R. Hardin. Distrust: Manifestations and management . [12] F. Heider. Attitudes and cognitive organization. The [13] C.-J. Hsieh, K.-Y. Chiang, and I. S. Dhillon. Low rank [14] A. Josang, E. Gray, and M. Kinateder. Analysing [15] R. M. Kramer. Trust and distrust in organizations: [16] D. W. Larson and R. Hardin. Distrust: Prudent, if not [17] J. Leskovec, D. Huttenlocher, and J. Kleinberg. [18] R. J. Lewicki, D. J. McAllister, and R. J. Bies. Trust [19] D. Liben-Nowell and J. Kleinberg. The link-prediction [20] H. Liu, E. Lim, H. Lauw, M. Le, A. Sun, J. Srivastava, [21] Y. Lu, P. Tsaparas, A. Ntoulas, and L. Polanyi. [22] H. Ma, D. Zhou, C. Liu, M. Lyu, and I. King.
 [23] N. Ma, E. Lim, V. Nguyen, A. Sun, and H. Liu. Trust [24] P. Massa and P. Avesani. Trust-aware bootstrapping [25] S. Chang, G. Qi, J. Tang, Q. Tian, Y. Rui and [26] D. H. McKnight and N. L. Chervany. Trust and [27] D. H. McKnight and V. Choudhury. Distrust and trust [28] V. Nguyen, E. Lim, J. Jiang, and A. Sun. To trust or [29] J. Nocedal and S. Wright. Numerical optimization . [30] Y. Qian and S. Adali. Extended structural balance [31] M. Richardson and P. Domingos. Mining [32] Z. Li, S. Chang, F. Liang, T. Huang, L. Cao and [33] J. B. Rotter. Interpersonal trust, trustworthiness, and [34] J. Singh and D. Sirdeshmukh. Agency and trust [35] J. Tang, H. Gao, X. Hu, and H. Liu. Exploiting [36] J. Tang, H. Gao, H. Liu, and A. Das Sarma. eTrust: [37] J. Tang and H. Liu. Trust in social computing. In [38] J. Tang, X. Hu, and H. Liu. Is distrust the negation of [39] J. Tang, Y. Chang, and H. Liu. Mining social media [40] J. Tang, T. Lou, and J. Kleinberg. Inferring social ties [41] P. Victor, N. Verbiest, C. Cornelis, and M. D. Cock. [42] S.-H. Yang, A. J. Smola, B. Long, H. Zha, and [43] J. Ye, H. Cheng, Z. Zhu, and M. Chen. Predicting
