 KDD Cup 2007 fo cuses on predicting asp ects of movie rat-ing b ehavior. We present our prediction metho d for Task 1 Who Rated What in 2006 where the goal is to predict which users rated which movies in 2006. We use the combi-nation of the following metho ds, listed in the order of their accuracy: By combining the predictions by linear regression we ob-tained a prediction with ro ot mean squared error 0.256. The rst runner up result was 0.263 while a pure all zero es pre-diction already gives 0.279, indicating the hardness of the task.
 J.4 [ Computer Applications ]: So cial and Behavioral Sci-ences; G.1.3 [ Mathematics of Computing ]: Numerical Analysis Numerical Linear Algebra data mining, recommender systems singular value decomp osition, item-item similarity, frequent sequence mining  X 
This work was supp orted by the eScience Regional Knowl-edge Centre, Hungary, a Yaho o Faculty Research Grant and by grant ASTOR NKFP 2/004/05 We present our rst place winner metho d for Task 1 Who Rated What in 2006. The task was to predict the probabil-ity that a user rated a movie in 2006 (with the actual date and rating b eing irrelevant) for a given list of 100,000 user movie pairs of the Netix Prize data set [2] . The users and movies are drawn from the Prize data set, i.e. the movies were released (or at least received ratings) b efore 2006 and the users also gave their rst rating b efore 2006. In addition, none of the pairs selected for the KDD Cup task were rated in the training set. We give a detailed description of the sampling metho d in Section 2.1 since it gives information that we use for the prediction.
 Our metho d is summarized as follows: 1. The combination of separate estimates for the num-2. The implementation of an SVD (Section 3.1) and an 3. Metho d fusion by using the machine learning to olkit We use the root mean squared error as the single evaluation measure, where w ij is a 01 ma-trix with value 1 if user i gave rating for movie j , and is the predicted value in the range of 0 to 1 given by the recommender system.
 The use of rmse implies that we actually predict the prob-ability of the existence of a rating: for a random variable that has value 1 with probability p and 0 otherwise, the rmse of the prediction of its value is minimized by p . If we correctly guess the numb er of ratings 7,804 in the 100,000 sample, then this metho d results in an rmse of 0.268 that would reach 5-6th place in the Cup, indicating the hard-ness of correctly predicting this value. Notice however that the rmse of 0.279 of the trivial all zero es prediction would also reach 10-13th place and remains not very far from the winner rmse.
 The exp eriments were carried out on a cluster of 64-bit 3GHz P-D pro cessors with 4GB RAM each and a multipro ces-sor 1.8GHz Opteron system with 20GB RAM. With certain variation dep ending on parameter settings, the running time range was 15 minutes for SVD, few hours for the item-item similarity based recommender, few days for frequent pat-terns and nally few minutes for linear regression. Mining frequent patters turned out most time consuming. The cur-rent version of the pap er contains a more thorough exp eri-mentation with frequent patters that we could not aord for the KDD Cup comp etition due to CPU time limitations. The rest of the pap er is organized as follows. In Section 2 we predict the marginals and use a naive usermovie inde-p endence assumption. Then in Section 3 we describ e our three data mining metho ds: the singular value decomp osi-tion, an item-item similarity based recommender and asso-ciation rule mining. The predictors are combined by linear regression; results are describ ed in Section 4. In this section we assume indep endence b etween the users and the movies for a Who Rated What prediction. Since we are lo oking for the probability of the existence of a rating, we start out with the marginal probabilities and use their pro duct. Notice that even the marginals form a highly non-trivial task that includes the How Many Ratings Task 2 of the KDD Cup as subproblem. We describ e our approaches separately for users and movies in the next two subsections. The prediction is given by the pro duct of the marginals scaled so that they sum up to R , the predicted total numb er of actual ratings for the Task 1 movies. Given a prediction N u for the numb er of ratings of user u and N m of movie m we use as the naive prediction for the usermovie pair u , m . Other than the values of N u and N m describ ed in the next two subsections, the prediction also dep ends on the choice of
R . We used an estimate of 10,000,000 that we obtained by generating a sample user-movie pairs by the exact same pro cedure of Task 1, except for using the marginals of the time range b etween Novemb er 2004 and Octob er 2005 and discarding pairs with rating b efore Octob er 2004. We ob-tained a sample of 100,000 user-movie pairs, out of which 6,800 was actually rated in the given one year time p erio d. By using the known marginals we observed R = 10 , 000 , 000 gave p um values that summed up to 6,800. For predicting the numb er of ratings of a given user we solely relied on the fact that the sample used for the Who Rated What task was taken prop ortional to the numb er of rat-ings of the user. We b egin with a detailed description of the sampling metho d. The 100,000 usermovie pairs were formed by drawing the movies from the 6822 movies selected for Task 1 and the users from the Prize data set, i.e. from those who gave their rst rating b efore 2006. Pairs that corresp onded to ratings in the existing Netix Prize dataset were discarded; we ignored this fact in our prediction. The key diculty in obtaining the user rating numb ers N u is the small probability of including a single user which im-plies a high probability of underestimating a single user. In particular we may assume that the actual rating numb er is non-zero for almost all users that do not app ear in the sample and hence an upward correction is necessary. We correct the numb er of times a user is included in the sam-ple by an estimated standard deviation in order to obtain as follows. The exp ected value of the numb er times the user u is included in the sample is equal to n u = 100 , 000  X  N Since N u /R is very small, its standard deviation is approx-imately p N u /R and hence the standard deviation of n u is p
N u /R  X  very large numb er of o ccurrences in the sample, all users o c-cur at most 20 times. We considered the most frequent user an outlier and based on the next maximum value 20 we as-sume the standard deviation to b e uniformly b elow 5. Hence we add 4 to the numb er of app earances in the sample for all users (including those who do not app ear at all) and obtain the estimate  X  N u by normalizing to sum up to the estimated total numb er of ratings R ; we use R = 10 , 000 , 000 . We give another justication of the choice for correcting the observed app earances in the sample upwards by 4. No-tice that since the probability of user u not b eing included in the sample is approximately exp(  X  100 , 000  X  N u /R ) probability is b elow 2% for a user with exp ected numb er of app earances at least 4. The task of predicting the numb er ratings by the users is the same as Task 2 How Many Ratings in 2006 of the KDD Cup 2007, but for a dierent set of movies. The task is to estimate the numb er of additional ratings for a given movie by users from the Netix Prize dataset. The set of movies that app eared (or at least received ratings) b efore 2006 were split randomly into two sets, one p er task, resulting in 6822 movies for Task 1 and 8863 for Task 2. Unlike the b est p erforming teams for Task 2 who used the Task 1 movies for training [9], here we did not use the fact that the Task 1 usermovie pairs were sampled prop ortional to the margins as describ ed in the previous section.
 We predict ratings for a given movie by analyzing the time series of its ratings as well as using IMDB movie release and videoeta.com DVD release dates for the movie and its likely series continuation releases. Movie titles across dier-ent databases as well as series titles were detected by com-puting the Damerau-Levenshtein distance [8] b etween the titles by giving more weight to the prex of the title and less weight for complete words that are missing. Stop word removal was also p erformed rst; an extended stop word list included phrases such as the b est of , the adventures of etc.
 Our prediction is the sum of a base estimated from previous ratings and additional ratings for predicted related release events. We observe an increase in the amount of ratings at and after the dates of related movie and DVD releases, hence if such an event is assumed to happ en, then the numb er of ratings will b e estimated higher accordingly. The increase in this case will b e prop ortional to the baseline prediction. The baseline is the total numb er of ratings of the movie in the p erio d of Novemb er 2004 and Octob er 2005. This amount is multiplied by a decay factor, another factor for the DVD release event, and a third factor for series continuation release events for the movie. The factors are trained for year Figure 1: The distribution of the 10-dimensional approxi-mation of the usermovie matrix for pairs with, resp ectively without ratings. 2005 as the validation p erio d. Movies that app eared in the second half of 2005 were also corrected upwards. For training we use the full 01 matrix of all known ratings; the rank k approximation of the matrix yields our predic-tion. The Singular Value Decomp osition (SVD) of a rank  X  matrix W is given by W = U T  X  V with U an m  X   X  ,  X  a  X   X   X  and V an n  X   X  matrix such that U and V are or-thogonal. By the Eckart-Young theorem [4] the b est rank-approximation of W with resp ect to the Frob enius norm is where U k is an m  X  k and V k is an n  X  k matrix contain-ing the rst k columns of U and V and the diagonal  X  k containing rst k entries of  X  .
 While the Frob enius norm is simply the rmse of the pre-diction for the existence of the rating if the of usermovie pairs are selected uniform at random, this is not true for the sampling metho d used for pro ducing the Task 1 pairs as describ ed in detail in Section 2.1. If the probability that the pair formed by user i and movie j is selected in the sample is p ij , then we have to minimize which is minimized similarly by the SVD of  X  p ij  X  w ij , di-vided p ointwise by  X  p ij .
 In our implementation we used the Lanczos co de of svdpack [3] that turned out b oth fastest and most precise in our re-cent exp eriments [7; 6]. Since we observed overtting for larger numb er of dimensions [6] we used the 10-dimensional approximation of the scaled matrix as in equation (1) where the p ij values are those obtained by the metho d of Sec-tion 2. The dierence b etween the distribution of the pre-dicted value for the actual ratings, resp ectively no-ratings is seen in Fig. 1.
 Figure 2: The distribution of the item-item similarity based prediction for usermovie pairs with and without ratings for a similarity top list of size K = 5 . Our item-item based recommender computes the adjusted cosine similarity [10] based not just on the existence of the ratings w ij as in the rest of the pap er, but also its value in the range of 1. . . 5: where  X  r u is the average of the ratings of user u and summa-tions are for all users u who rated b oth j and j 0 . Since the numb er of such users n replaced the ab ove sim value by its lower 95% condence in-terval of the adjusted cosine similarity obtained by Fisher's r -to-z transform [5] using p n An unrated movie j is recommended to a given user i based on the weighted average of the nearest K movies j 0 to j rated by the user. Weights are dened by the lower condence interval of sim as ab ove. We chose a value of K = 5 by ob-serving the dierence of the prediction for usermovie pairs with and without ratings in Fig. 2. In this choice we have to keep in mind that larger values intro duce noise, however if we start out with R known ratings, we may only p ossibly give predictions for R  X  K user-movie pairs that remain very sparse within the rating matrix if K is small. We used asso ciation rules for Task 1 via frequent sequences within the sets of movies rated by a user ordered by the time of the rating. In order to compute the supp ort supp ( m 1 m s ) we had to imp ose very strong restriction due to CPU time constraints that left us with rules that matched only 20,000 of the 100,000 user-movie pairs. Given the supp ort of all frequent sequences, we computed all asso ciation rules that apply to one of the 6822 Task 1 movies. These asso ci-ation rules are of form where b oth frequencies supp ( m 1 , . . . , m s ) and supp m s , m ) are ab ove the minimum supp ort. The condence of this rule is Since only a small numb er of users are involved, we may simply match all asso ciation rules brute force to the Task 1 user-movie pairs; a trie-based approach can sp eed this up if larger scale evaluation is required. Finally we use the maximum of the condence of all rules that t the user movie pair as prediction.
 We describ e our original set of restrictions that we used within an APRIORI [1] implementation for frequent sequence mining. We discarded all movies that received more than 50,000 ratings and all users that gave more than 3,000 rat-ings in the Prize data set. We added the condition that in a frequent sequence the numb er movie ratings must not dier by more than a factor of 4; since this prop erty is mono-tonic, we could implement it as a lter in the two-element candidate generation step of the APRIORI algorithm. In addition we also imp osed this condition later, i.e. we only formed candidate ( m 1 , . . . , m s , m s +1 ) if We counted the frequency of sequences restricted to t in time windows of 30 days; we allowed all p ermutations of movies that received their ratings from the user on the same day. We set the minimum supp ort to 50. By manual inves-tigation we found that the most restrictive rule was the 30 day time window restriction that resulted in the low numb er of matches with the Task 1 pairs. We combined the four predictions of the naive indep endence, SVD, item-item correlation and asso ciation rule based ap-proaches by the linear regression metho d of the machine learning to olkit Weka [11]. We obtained the equation as the nal prediction that reaches rmse 0.256, gaining 0.007 over the rst runner up and 0.023 over a pure all zero es prediction.
 In a preliminary version we used an alternate, seemingly less sophisticated metho d to combine predictions that p erformed only marginally worse, still reaching rst place in the com-p etition and may b e of p ossible further use for combining predictions. Next we sketch this metho d. As seen in Figs. 1 and Fig. 2, for a given predicted value x we can count (in the training set of Year 2005 data) the fraction of actual ratings with the predicted value x . By using a binning of step 0.1 we made one prediction value for each range given by the ab ove fraction. For ranges where the data was sparse we used manual correction. Since the numb er of sparse bins (as well as all bins) is small and they eect a small num-b er of user-movie pairs, there is no need for a more rened metho d. The nal prediction for a user-movie pair arises as the maximum of all bin predictions that the pair b elongs to. The main lesson learned by solving this task is probably the fact that very dierent data mining techniques catch very similar patterns in the data that makes it increasingly dif-cult to improve prediction quality b eyond certain p oint. We stress here however that tuning asso ciation rule based prediction is a very time (and CPU) consuming task and our metho d is far from b eing the result of an exhaustive exp erimentation. We also demonstrated the hardness of the task by showing how well trivial estimates p erform, just marginally outp erformed by our result and b eating most of the contestant teams. Just as it is the case for Task 2 [9], the information leaked by the sampling metho d used to generate the test usermovie pairs could b e used. While without re-constructing marginals it would likely have b een imp ossible to come within rst three. [1] R. Agrawal and R. Srikant. Fast algorithms for mining [2] J. Bennett and S. Lanning. The netix prize. In KDD [3] M. W. Berry. SVDPACK: A Fortran-77 software library [4] G. H. Golub and C. F. V. Loan. Matrix Computations . [5] H. Hotelling. New light on the correlation co ecient [6] M. Kurucz, A. A. Bencz X r, and K. Csalog X ny. Metho ds [7] M. Kurucz, A. A. Bencz X r, K. Csalog X ny, and [8] G. Navarro. A guided tour to approximate string [9] S. Rosset, C. Perlich, and Y. Liu. Making the most of [10] B. Sarwar, G. Karypis, J. Konstan, and J. Reidl. [11] I. H. Witten and E. Frank. Data Mining: Practical Ma-
