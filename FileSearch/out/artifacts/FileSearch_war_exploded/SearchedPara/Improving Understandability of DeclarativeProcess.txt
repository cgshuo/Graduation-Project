 Declarative process models have been proposed to counter the flexibility lim-itations of procedural modeling languages. Instead of modeling predetermined paths of activities, declarative process models use constraints to express what can, cannot, and must happen. Every execution sequence that is not strictly for-bidden by the constraints can be enacted by the model. This makes declarative models much more flexible indeed, but also more difficult to comprehend. To put it simplistically, it is not possible to  X  X ind an execution path by following your finger along the arcs X . There are many possible outcomes due to the interaction of the constraints over the activities. In different works approaches to deal with the understandability problems of declarative models have been proposed. For instance in [ 1 ], the impact of hier-archy is investigated and in [ 2 ] the typical pitfalls of understanding declarative models are pointed out.
 This paper proposes an approach capable of improving the understandabil-ity of models expressed in Declare [ 3 ], one of the most widely used declara-tive process modeling language. The approach deals with hidden dependencies [ 2 , 4 , 5 ], one of the main reasons that make Declare models difficult to under-stand. Hidden dependencies pose a significant challenge for humans: it is not sufficient to rely on the information explicitly indicated by the constraints, but one has to carefully analyze all the defined constraints for understanding all the dependencies that are not explicitly visible (i.e., that are hidden). The con-tribution of this paper consists of a methodology to build so-called constraint dependency structures in order to reveal all hidden dependencies and make them explicit in a Declare model. Furthermore, this methodology is developed into the Declare Execution Environment 1 , a tool that supplements an existing Declare model with visual and textual annotations to clarify which behavior is allowed or disallowed by the model. In an experimental evaluation with 95 novice Declare modelers, we show that the methodology to make hidden dependencies explicit and visually annotating a Declare model with this information, has a significant positive impact on the understandability of Declare models.
 The structure of the paper is as follows. First, the concept of Declare con-straints is briefly summarized and relevant characteristics are explained. Next, Sect. 3 explains how to capture and formalize dependency structures, followed by Sect. 4 , which shows the implementation and tool. This tool is used for exper-imental validation in Sect. 5 . Finally, Sect. 6 summarizes the related work and Sect. 7 discusses future work and the conclusion. Declare models are constructed using a fixed set of constraints, which are sum-marized in Table A1 in [ 6 ]. They range from unary constraints, indicating the position and cardinality of an activity, to n -ary constraints, which capture typical sequential behavior such as precedence and succession relationships. A Declare model DM =( A,  X  ) can be represented as follows:  X  A is a set of activities from the alphabet  X  ,  X   X  is the set of Declare constraints defined over the activities.
 In this paper we assume n  X  2. A Declare graph can be represented as a directed graph DG =( A,  X  ). Hence the activities and constraints map one-to-one onto the graph in case of n = 2, given that unary constraints are considered as self-loops. We denote all incoming arcs of a  X  A as  X  a  X   X  and outgoing arcs as a  X  X  X 
 X  . The antecedent and consequent of  X   X   X  are denoted as  X  constraints X  automata to obtain the behavior that is allowed for by all of them. This conjunction actually abolishes the notion of the separate constraints and thus throws away the infor mation of how the separate constraints interact. One technique to mitigate this is to color the constraints [ 11 ] by keeping both the global and separate automata, but still the interactions remain untraceable. For unary constraints, Existence(A,n) and Absence(A,n) together form Exactly (A,n) . Binary constraints are divided in different classes, for which every class depends on the previous one: Unordered (Responded/co-existence) , Sim-ple ordered (Precedence (p), Response (r), Succession (s)) , Alternating ordered (Alternate p,r,s) ,and Chain Ordered (Chain p,r,s) . Next to these constraints, there exist negative versions for three of them (Not co-existence, Not succession, Not chain succession) . Finally, the Choice constraint exists, which is comparable with a branched unary constraint Existence( { A,B } ,n) .
 Chain) Precedence(A,B) form (Alternate/Chain) Succession . When a property is discussed for, e.g., Chain succession , this also includes (Chain/Alternate) prece-dence/response and vice versa.
 in [ 12 ]. Some constraints have an impact on the temporary violation aspect of the model (the constraint is not in an accepting state and requires an activity to resolve it, e.g. Response or Choice ), some constraints can disable activities for the remainder of the execution (such as Exactly and Not succession ), and some constraints can temporarily block all other activities ( Chain constraints). These different characteristics all impose certain dependencies among constraints that are not directly visible through a single constraint (arc). E.g., a model con-contains a hidden dependency between a and c . When c is fired once (and hence can only fire one time anymore), and a has fired without b firing already, c should not fire before b resolves the temporary violation of Response ( a, b ), since after firing c , c cannot resolve Response ( b, c ) anymore (as it can only fire two times) and b should not fire to avoid another temporary violation of Response ( b, c ). explicit. In the following section, it is explained how they relate to the activities in a declarative model. This section discusses how dependency structures retrieved from Declare models can be constructed (Sect. 3.1 ), how they can aid interpretation of the model and the way in which constraints interact (Sect. 3.3 ). Before constructing the structures, however, the unary constraints in the model need to be propagated to achieve the correct interpretation, as explained in Sect. 3.2 . 3.1 Construction A hidden dependency can be defined as an interaction between constraints and their activities that is not made explicit as such in the model itself. They are the outcome of conjoining the separate constraints to avoid permanent violation, as explained earlier. Hence, it is paramount to find the ways to avoid perma-nent violation to occur. There are three types of resolution strategies to resolve temporary violations: 1. An activity must still happen: after firing the antecedent in Responded existence , Co-Existence , (Alternate/Chain) Response , the consequent must fire afterwards. 2. An activity must still happen a certain amount of times: Existence , Exactly , Choice . 3. An activity must still happen at a fixed moment in time: Chain response .
 Note that combining different constraints could lead to coalesced resolution strategies: Chain response(a,b) coupled with Existence(a,2) requires firing b at least twice on certain fixed moments (directly after a ) as well.
 Now we construct the set of dependency structures DP for DM with DS = (  X   X   X 
DS the constraint triggering the structure,  X   X  dep the set of dependent constraints, and  X  DS dep the set of nested dependency structures dependent of  X  To fill  X  DS dep and DS DS dep , Algorithm 1 creates a dependency structure for every activity that is involved in at least one of the five constraints that can perma-nently disable it. Hence, a structure is created for a in Absence/Exactly(a,n) , a and b in Exclusive choice/Not co-existence(a,b) , and for b in Not succession(a,b) as can be seen on lines 7 X 25.
 First, all backward-propagating constraints are considered (  X  inferred from resolution strategy 1) and used for recursive search, as well as stored in  X  dep (Algorithm 2 , lines 1 X 22). During this procedure, all incoming Existence and Choice constraints (as in 2) are stored as well (Algorithm 2 , lines 16 X 18). They also need to be fulfilled, but do not propagate due to their unary nature. When Responded existence is encountered, a new dependency structure DL firing its consequent), it is satisfied indefinitely (unlike, e.g., Response which can become temporarily violated again) and its propagation is also abolished (Algorithm 2 , lines 6 X 10).
 For every activity that is encountered by the algorithm, a forward-dependency search is performed for all forward-propagating constraints  X   X  , which include all ( Alternate/Chain ) precedence constraints and Co-existence . These constraints need to be activated (the antecedent has to be fired, in the case of alternating variant possibly multiple times) to resolve dependencies Algorithm 1. Retrieving Dependency Structures from backward-propagating constraints. The constraints dependent of them are linked to them through a separate, nested dependency structure DL (Algorithm 2 , lines 22 X 36).
 Example. Consider the model in Fig. 1 a. Not succession(c,b) , meaning any occurrence of c cannot be followed eventually by b , causes the algorithm to construct a dependency structure for b . Backward-searching will reveal Response(a,b) and Exactly(a,1) as dependent constraints. c cannot fire before a has resolved Exactly(a,1) , which will render Response(a,b) temporarily violated and requires b to resolve it. Hence sequences such as  X  = e are not possible. In a forward search, Precedence(b,d) requires a new depen-dency structure, nested in DS Not succession ( C,B ) . Firing e requires d to resolve Response(e,d) . Hence, firing c before firing e would render e disabled, as b can never fire anymore due to Not succession(c,b) ,sothe Precedence(b,d) can never be activated. Firing b before c would resolve this, as d can then fire an unlimited amount of times. The full dependency structure present in the model is DS = {  X  = Not succession ( c, b ) , X  dep = { Response ( a, b ) ,Exactly ( a, 1) {  X  = P recedence ( b, d ) , X  dep = Response ( e, d ) ,  X  X } Algorithm 2. Search for Dependency Constraints 3.2 Unary Propagation The construction and use of dependency structures depends on the correct prop-agation of all unary relations inside of the model. E.g., consider the model in Fig. 1 b. Changing Precedence(b,d) and Response(e,d) to their alternating variant and adding Existence(e,2) would require d and hence b to fire at least twice as well. In general, unary constraints that are not present in the original model are added in the following fashion for a, b  X  A :  X  Responded existence(a,b) ,if a occurs at least or exactly n times, then b has to occur at least once.  X  Co-existence(a,b) ,if a or b occurs at least or exactly n times, then b respec-tively a has to occur at least once.  X  Response(a,b) ,if a occurs at least or exactly n times, then b has to occur at least once.  X  Precedence(a,b) ,if b occurs at least or exactly n times, then a has to occur at least once.
  X  Succession(a,b) ,if a or b occur at least or exactly n times, then the other  X  Alternate response(a,b) ,if b occurs at most or exactly n times, then a can  X  Alternate precedence(a,b) ,if b occurs at least or exactly n times, then a has  X  Alternate succession(a,b) , both a and b have to have the same unary restric- X  Chain response(a,b) ,if a occurs at least or exactly n times, then b has to  X  Chain precedence(a,b) ,if a occurs at most or exactly n times, then b can occur  X  Chain succession(a,b) , both a and b have to have the same unary restrictions. Absence(m) , and they are combined and replaced by an Exactly constraint when n = m  X  1. These rules are applied to the model until no unary constraint changes anymore. If there would be an activity for n&gt;m the model would end up in a permanently violated state.
 have consistent dependency structures. Next, the same procedure is repeated to calculate for each activity how many times it still has to execute in the following execution steps. This helps the dependency structures to recognize whether a certain nested structure can be cast off because it can fire a sufficient amount of times.
 Example. Returning to the example, Existence(e,2) is propagated to d , yielding an Existence(d,2) and next to b yielding Existence(b,2) . The minimum amount of occurrences is also calculated and updated throughout the execution per activity. This way, the dependency structures will incorporate the unary constraints into the model and indicate that c cannot fire before b has fired its appropriate amount of times to enable d and e to fire at least twice. Initially, b , d ,and e must execute a minimum of 2 times. b can be disabled after d and e have fired at least once, and b has fired at least two times (once before d fired and once after d fired to grant d another execution because of Alternate precedence(b,d) ), for example sequence  X  1 = b  X  e  X  d  X  b  X  c or  X  2 = e  X  After this execution, d cannot fire until e is fired because they can both fire only once anymore ( d because of Alternate precedence(b,d) and hence e through Alternate response(e,d) )and d has to be able to resolve Alternate response(e,d) , e.g.  X  3.3 Interpretation Constructing dependency structures can already give extra information by displaying them in a graph showing which constraints interact with the main descriptions to annotate the model in order to help understand why constraints are related and what combined impact they have.
 First of all, for Exclusive choice(a,b) and Not co-existence(a,b) , the structures reflect that whenever an activity from either structure is fired (either the one for a or b ), the activities in the other structure become disabled permanently. Indeed, firing any activity in the dependency structure of a or b requires them to fire, hence activating Exclusive choice or Not co-existence . If the structures of a and b share activities, this means the net is not deadlock-free. Secondly, for Not succession(a,b) , a becomes disabled whenever a constraint  X   X 
 X  DS dep is temporarily violated and needs b to resolve it. Also, dependent structures in d  X  DS DS dep cannot contain any violations in their  X  antecedent of the main constraint  X  d  X  DS d dep is activated and can execute a min-imum number of times required (as explained in Sect. 3.2 ). For unary constraints, Absence(A,n) and Exactly(A,n) , this applies as well, with the exception that a becomes disabled when a constraint relies upon it to become satisfied again. Finally, every execution of activities in Chain constraints should be checked for executions one step ahead. For each of them, it is calculated whether the consequent is available to fire for Chain response , or is the only one available for Not chain succession in order to avoid deadlock. The construction of the dependency structures has been implemented in a Declare execution environment, of which the implementation can be found by following the link in the introduction. The tool can read a Declare model saved from Declare Designer [ 13 ], which, during execution, is supported by descrip-tions for the hidden dependencies. A screenshot and an example can be found in Fig. 2 .
 as a directed graph as well. Finally, the trace created over the model by the user is displayed below the model, aiding the user in understanding the history of the current situation displayed over the model.
 sists of the conjunction of the separate Declare automata expressed in regular expressions, as can be found in [ 9 , 10 ]. Making hidden dependencies explicit by annotating Declare models can signifi-cantly improve their understandability. In this section, it is empirically demon-strated that novice process modelers are indeed better capable of understanding Declare models when they are provided with an environment that makes hidden dependencies explicit through text and figures. 5.1 Experimental Setup In the experiment, 95 students (see Table 2 ) enrolled in KU Leuven X  X  Business Analysis course, in which both procedural and declarative process modeling are taught, were asked to solve five questions for each of five different Declare models in a timespan of two hours. The students have the same modeling experience and background and can be considered novice business process modelers. The models, as represented in Table 1 , are of increasing complexity and are tailored towards assessing different kinds of dependencies:  X  Model 1: focuses on the impact of the Not co-existence constraint.  X  Model 2: focuses on the impact of unary constraint propagation.  X  Model 3: focuses on the impact of simple forward and backward dependen-cies induced by Exactly(c,2) .  X  Model 4: focuses on the impact of more advanced forward and backward dependencies induced by Not succession(b,e) .  X  Model 5: focuses on the same impact as models 3 and 4, with an added Choice constraint.
 At the start of the test, students were provided instructions making use of the example used in Sect. 2 , a model which was used as a foundation for models 3 X 5, but without the additional constraints and activities added. As such, the idea behind hidden dependencies was explained, as well as how to make use of the tool they were provided with.
 In order to measure the impact of handing natural language descriptions and the visualization of dependency graphs, the students were divided into three groups which received a different version of the Declare Execution Environment. Group A could only see the Declare model and the constraint descriptions, but no color annotation nor dependency structure visualizations. Group B received a tool in which the enabled activities were colored green, and tem-porarily violated constraints were colored red, in a fashion described in [ 11 ]and similar to Declare Designer [ 13 ]. Also, the constraint descriptions were given. Finally, group C was given an environment with the same functionality as group B, but with extra descriptions concerning hidden dependencies, as well as the possibility to open a dynamic visualization of the dependency structures. grasped the full impact of the blend of different constraints. They were asked to indicate which activities were enabled after firing a certain sequence, and why or how to reach a certain firing sequence. Since two out of three groups knew which ones were enabled, they could focus more on the second part of the question. An example question used for model 1 was  X  X fter firing d , which activities are still enabled? Explain X .
 because of overlooked hidden dependencies or incorrect use of constraints) were still awarded a score higher than 0. E.g., a student from group B who provides the correct set of enabled activities but fails to state that activity c in model 3 is not enabled because of hidden dependencies was still awarded 0.6. The explanation was taken into account so as to make a fair comparison with students in group A, who got no extra information, and therefore many times missed even these basic answers. Group C students that just copied extra descriptions provided by the tool also did no receive a grade of 1, as they did not prove to understand the model. 5.2 Results Quantitative Results. Given this setup, an experimental analysis can be con-ducted to investigate the impact of the environment students were given (i.e. group) on the score, where a higher score reflects a better level of understand-ing. Figure 3 shows boxplots of the average scores over 5 questions, per model and per group. From the figure, it can be seen that for each model, an increase is observed in terms of the score when students are provided with additional hidden dependency-based annotations. Note that the data is available on the tool X  X  web site.
 So as to evaluate the statistical significance of this pattern, a linear regression ( Score =  X   X  model +  X   X  group + ) was fitted on the data. From the results in Table 3 , it is clear that both the impact of the model as well as the group (and hence tool) is highly significant. Observe that the data was also fitted for a model with interaction between model and group and also for a model with gender and program included. These models did not raise the R-squared values much ( &lt; 0.18), hence hinting at little extra explanatory power. Running a Durbin-Watson-test also rejected the hypothesis for correlation among the residuals. Finally, it was tested whether the error terms were normally distributed, as can be seen in Fig. 4 a.
 Qualitative Results. Since the participants did not just give an answer in the form of  X  X  is now enabled X  but had to motivate their answers, some extra observations could be made concerning the results. Although it was the case that the two groups with the more elaborate tool were better capable of seeing which activities are enabled and which constraints are violated, they still seemed to ignore these annotations. Especially group B sometimes ignored the coloring of the model as they did not understand some implications of the constraints. Par-ticipants often also bended the descriptions of the Declare constraints towards their understanding, hence starting to discuss irrelevant parts of the model. For the third group, this behavior was still present, although to a much lesser extent. Group A participants often found the hidden dependencies in the easier exam-ples. Because they had no support they analyzed the models thoroughly, but failed to find any hidden relations in the elaborate examples.
 Remarks. As for all empirical studies, there are threats to validity that need to be addressed, the main ones in our case are:  X  Internal validity: Our experiment had the maturation threat because sub- X  Construct validity: Our experiment was threatened by the hypothesis  X  External validity: Our experiment might suffer from interaction of selection number of subjects is quite high and their profiles balanced, we can only generalize the results to students. The subjects might not be representative to generalize the results to professional modelers as well. It is, e.g., not possible to claim that the tool can help or improve Declare modeling efforts of more experienced users. Declare, introduced as DecSerFlow and ConDec in [ 15 , 16 ], has become one of the most widely-used declarative process languages in research. Some competing approaches exist such as DCR Graphs [ 17 ], which are comparable to a slimmed-down version of Declare for improving understandability and setup, and the more data-oriented language Guard-Stage-Milestone [ 18 ].
 Declare and its understandability has been researched for a test case-driven approach [ 4 ], the impact of hierarchies [ 1 ], and its common understandability challenges [ 2 ]. While these works clearly state the presence of hidden dependen-cies, with [ 2 ] explicitly mentioning this as a common pitfall for understandability, they have not provided a way to capture them. This work continues on the pre-liminary approach for retrieving hidden dependencies of [ 19 ].
 Many other works on Declare mining exist as well, which have led to a better understanding of the properties of the language. Most notably the hierarchy [ 9 ] and semantics [ 10 , 20 , 21 ] and the transitivity properties [ 22 ]havebrought clarification as to how constraints behave in a model. This paper shows how to retrieve and use dependency structures and unary propagation in Declare models to increase understandability. It offers a theoretic aspect in explaining how to construct and interpret the relations of constraints and their hidden dependencies in ways that have not been proposed yet, and was validated on novice users in an experiment. This showed that explaining and visualizing hidden dependencies and constraint structures rendered users significantly better capable of understanding the models.
 Future work includes analyzing the results further by using extra user sta-tistics such as average grades, as well as including new observations from expert users. Next, it is also straightforward to extend these findings to n -ary con-straints, which changes only the propagation and interpretation slightly. Fur-thermore, constructing the hidden dependencies has numerous other applica-tions. By understanding in which way constraints are related, it becomes easier to grasp the complexity of conjoining the separate Declare constraints X  automata and hence it is possible to score the impact of different constraints on, e.g., the performance of calculating the global automaton of the whole model. Further-more, these insights can be used to score a Declare model for simplicity., i.e., models which contain more hidden dependencies can be scored lower for this metric.

