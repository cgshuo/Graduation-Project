 Automated playlist generation is a special form of music rec-ommendation and a common feature of digital music play-ing applications. A particular challenge of the task is that the recommended items should not only match the gen-eral listener X  X  preference but should also be coherent with the most recently played tracks. In this work, we propose a novel algorithmic approach and optimization scheme to generate playlist continuations that address these require-ments. In our approach, we first use collections of shared music playlists, music metadata, and user preferences to select suitable tracks with high accuracy. Next, we ap-ply a generic re-ranking optimization scheme to generate playlist continuations that match the characteristics of the last played tracks. An empirical evaluation on three col-lections of shared playlists shows that the combination of different input signals helps to achieve high accuracy during track selection and that the re-ranking technique can both help to balance different quality optimization goals and to further increase accuracy.
 Music Recommendation; Quality Factors; Evaluation
The automated creation of music playlists  X  a special form of music recommendation  X  is a typical feature of mod-ern digital music playing applications, and playlist gener-ators are nowadays used both by online music platforms and by  X  X ffline X  music applications that, e.g., run on smart-phones. Over the last fifteen years, a variety of playlist generation approaches has been proposed in the literature [4, 12]. These next-track recommendation approaches differ from each other, e.g., with respect to the kinds of inputs they expect, which forms of additional data about the tracks they can process, or which quality criterion they seek to optimize.
A distinctive feature of music playlist generation is that the recommended items are immediately  X  X onsumed X , usu-c  X 
In this section, we present the details of our multi-faceted weighted scoring approach. The goal is to determine a rel-evance score for each possible next track given a playlist history h (sequence of tracks) using different input signals.
In [4], a number of playlisting algorithms based on pat-terns in publicly shared playlists were benchmarked. The results showed that a k-Nearest-Neighbor-based (kNN) ap-proach worked best in terms of accuracy across all datasets in particular for the shorter list lengths that are relevant in our context. As we are interested in high-quality next-track recommendations, we will use kNN as a baseline. Given a history h and a set N h of nearest neighbor playlists of h , we compute the kNN score of a target track t  X  with sim cosine ( h,n ) as the binary cosine similarity of track oc-currences in h and n . 1 n ( t  X  ) = 1 if n contains t  X  and 0 otherwise. kNN was also used as a baseline in [8]. Small hit rate increases were achieved at long list lengths by combining it with tag-based track information. The work also showed that the kNN method performs better than recent methods like BPR [17] for the given task. In [8] however, a very small value for k = 10 was used. Since our experiments show that larger values for k ( k = 300) lead to significantly higher hit rates and to the best results, we will not use the tag-enhanced method of [8] as a baseline.
Playlist creators can have certain  X  X hemes X , goals or qual-ity criteria in mind when they design a playlist. The idea of our faceted scoring method is to combine the kNN approach with additional suitability scores. If we, for example, detect that the homogeneity of the tempo of the tracks is most probably a guiding quality criterion, we should give an ex-tra relevance weight to tracks that are similar in tempo to those in the history; if we observe that several tracks in the history were annotated by users with certain tags, we should increase the relevance score of tracks with similar tags.
Generally, the combination of different scores shall serve two purposes: (1) increasing the hit rate as more relevant tracks receive a higher aggregated score and (2) making the playlist continuation more homogeneous, which is often a desirable goal in the Music Information Retrieval literature.
In our experiments, we tested the following scores as ex-amples to validate our approach. The selection was based on the availability of track metadata in public sources. 1
There are several ways of determining the similarity of music tracks, e.g., by modeling the distribution of track fea-tures [2]. In our work, we retrieved the social tags 2 that were assigned to tracks by users on Last.fm as they are
Depending on the available data, various combinations of scores of different types can be used. In our experiments, we tested different configurations using a weighted scoring scheme. Given a set of scoring functions S , the score is where w i is a configurable weight term for each score i  X  S .
The selection of the scores as well as their corresponding weights depend on the goals that should be achieved. In this work, we systematically tested different values for the weight of each score and selected the best ones (listed in Table 2) with respect to accuracy.
In particular on Last.fm, we can find playlists that contain tracks of only one single artist. If a history h has only one artist A , we apply an additional heuristic and compute a special artist score ( AS ) for tracks by A . In the experiments, we used a baseline AS value that is generally higher than the combined scores as computed in Equation 5. This ensures that the playlist continuation starts with the  X  X ight X  artist. The tracks of artist A are then sorted according to their popularity, and we use a position-based decay function that assigns a lower AS value to less popular tracks of the artist and apply a minimum popularity threshold. The tracks of the other artists receive the usual combined score (Eq. 5).
So far, we have designed a number of ways to score tracks with respect to a history of recent tracks. Given a specific dataset, our first goal is to find suitable weight factors and other parameters to optimize the prediction accuracy of the model, in our case in terms of the hit rate. Once this is done, our assumption is that the top-scoring tracks are generally well-suited for the given history.

The goal of the subsequent fine-tuning phase is to opti-mize the selection of the immediate next tracks. For that purpose, we will take a limited number of tracks from the top-scoring tracks and systematically re-rank them in order to better match one or more characteristics of the history. Since we limit the re-ranking to a smaller set at the top of the list, we (a) limit the computational complexity of the optimization process 4 and (b) can ensure that the potential accuracy losses are not too high.
Consider, as an example, that our optimization goal is to find a 10-track playlist continuation that maintains the tempo level of the recent history. In that situation, we pick, e.g., the top 30 tracks of the previously scored list and then systematically identify those 10 tracks among them which are most suitable in terms of the tempo. Note that the optimization goal here is not to find 10 tracks that all have the same tempo, but a set of tracks whose tempo distribution is as similar as possible to the current playlist. As another example, consider the diversity (of genres, artists, release years). Clearly, there is no global and context-independent optimum how diverse a playlist should be in general. In our approach, we therefore aim to find a set of tracks that mimics
Algorithm 1: Top-n optimization algorithm. All possi-ble swapping combinations between r n and x m are eval-uated. r i  X  j n denotes a swap of track i in r n with j . input : int maxSteps ; Array h , r n , x m output : The updated top-n list r n for 1 to maxSteps do return r n ; Method. Let n be the length of the list of next tracks to be optimized. As a starting point, we take the first n rec-ommendations of the list r produced by the faceted scoring method from Section 2 and determine the track list char-acteristics of the top-n list r n as F c ( r n ). We then create an  X  X xchange List X  x m consisting of the m elements which immediately follow after r n in r (e.g., tracks 11 to 30).
The optimization procedure shown in Algorithm 1 takes these lists  X  together with the history h  X  as an input and systematically exchanges elements from r n with elements from x m . In each iteration of the main loop, the best pos-sible swap is determined. This is the one that leads to the largest reduction of e 0 c . At the end, an exchange is only ap-plied if it leads to a reduction of the difference between the characteristics of the history h and the updated top-n list. The algorithm stops when either no (measurable) improve-ment can be observed, all possible swaps are explored, or a maximum number of exchange steps were applied. The exact procedure is given in Algorithm 1.
 Dealing with multiple goals. The general algorithm scheme can be used to optimize more than one goal at once, consid-ering, e.g., both the tempo and the loudness in parallel. In-stead of determining only one difference e c , we would deter-mine multiple difference values e c 1 ,...,e ck and only perform a swap when the aggregated difference, e.g., the sum over all differences e c 1 ,...,e ck (normalized to the same level), will be reduced. Weighted combinations of the individual error measures are possible as well.
In the first part of the section, we analyze the effects of our faceted scoring method in terms of (a) accuracy, (b) homogeneity of the resulting lists, and (c) measure if the scoring methods help to generate list continuations that are coherent with the playlist histories. In the second part, we report the results of the re-ranking optimization procedure presented in the previous section. We use a significance level of p = 0 . 05 for all statistical tests throughout the section. We used playlist collections from three different sources. One set of playlists was retrieved from Last.fm via their public API, one consists of playlists by music enthusiasts on Method. We use the following four-fold cross-validation setup to measure accuracy [3, 4, 8]: The available playlists are split into training and test sets. As usual, the algo-rithms learn their models on the training sets. From each playlist in the test set, we hide the last track (resulting in a history h ) and let the algorithms recommend playlist contin-uations, i.e., predict the hidden track. A  X  X it X  is registered whenever the generated top-n list contains the hidden ele-ment. Therefore, the hit rate is the fraction of playlists in the test set for which the hidden track was found. Beside the hit rate, we report the Mean Reciprocal Rank (MRR) measure, which takes the position of the hit into account 7 . Results. Table 3 shows hit rate and MRR at list length 100. Determining the accuracy for this list length gives us flexibility in setting the size of the Exchange Set later on. Note in addition that top-n lists of this and even much larger sizes are common in this domain [3, 4, 8]. The lowest and highest values are marked in light gray (lowest) and a bold font and a dark gray background (highest) respectively.
As expected, kNN300 has a competitive performance com-pared with the other baselines and recommending the most popular tracks to everyone can sometimes be a better strat-egy than using noisy tags alone (Content). The highest ac-curacy 8 across all three datasets can be achieved by com-bining kNN with the personalized content-based algorithm from Section 2.2.3 and the artist heuristic from Section 2.4 (kNN300CPA). The differences between the best perform-ing hybrid method and the kNN baseline method are statis-tically significant on both measures and all three datasets. The results therefore indicate that different signals (track usage patterns, social annotations and personal long-term preferences) in combination with specific heuristics should be used to obtain high accuracy. While kNN300CPA con-sistently works best in absolute numbers, the differences to the second-best method for individual datasets and mea-sures are not always significant.

Combining kNN with the numerical features from Section 2.2.2 (release year, tempo and loudness) can in some cases lead to modest accuracy improvements. On AotM, playlist creators seem to pay attention to aspects like a consistent loudness level in the playlists, which explains the improve-ment of kNN300LD over kNN300. For the other datasets and music features, no significant difference is observed when kNN300 is paired with a numerical feature.

The results so far show that combining different scores can help to increase the accuracy. In the next set of measure-ments, we assess if the combination of scores also impacts other possible quality factors like diversity and coherence of the playlist continuations, which are in the focus of the subsequent optimization process. Method. Our first method to assess the diversity and coher-ence is based on the artists and the social tags of the tracks. We use the inverse ILS to quantify the diversity level and est diversity. All kNN-based methods exhibit a tendency to place a mix of different artists in their lists 11 . The content-based method leads to varying results. Sometimes, the artist diversity is higher than kNN (Last.fm), sometimes it is equal or lower (AotM, 8tracks). This phenomenon depends on the absolute diversity level achieved by the kNN method, which is comparably low for Last.fm, where users often only in-clude popular tracks of a few artists in their playlists. The hybrid methods kNN300CP and kNN300CPA often lead to an even lower diversity than their components alone, which means that the individual components select tracks from an overlapping set of artists.
 Discussion. Due to its hybrid nature the highly-accurate kNN300CPA method creates more homogeneous playlists than the pure kNN method in terms of tags and artists. At the same time, the playlist continuations generated by kNN300CPA are often less coherent than when using kNN alone, except for the Last.fm dataset. One possible explana-tion can be that the social tags used for tracks in the AotM and 8tracks datasets are more often related to the genre or mood and not to the artists. The content-based component would then push tracks that have the same genre but not necessarily the same artists as the history. In addition, the fact that the social tags for all datasets were obtained via the Last.fm API leads to a more sparse data situation for the other datasets. Method. For numerical features like the tempo, we ana-lyze the effects of combining the kNN method with the re-spective scoring component, e.g., kNN300TMP. Specifically, we measure the difference between the mean value of the given feature in the history h and the generated playlist. To be successful, a method like kNN300TMP should result in smaller differences than when using kNN alone, i.e., the resulting playlist should match the tempo of the history bet-ter. Besides the mean value, we also report the change of the differences in the standard deviations to see if the dis-tribution of the feature matches the history.
 Results . Figures 1a to 1c show the results for the features tempo, loudness and release years. Across all dimensions and on all datasets, including a corresponding scoring com-ponent (significantly) helps to make the playlist continuation  X  in terms of mean  X  more coherent with the recent history than when using only the kNN scorer. At the same time, as shown in Table 3, adding the specific scoring method can furthermore often help to slightly increase the accuracy. tracks. We tested several individual and combined optimiza-tion goals and again applied four-fold cross-validation. Results (AotM). The detailed results obtained for a set of selected configurations for the AotM are shown in Table 6 In the first column, we list the evaluation goal(s), e.g., artist (ART) or tag (TAG) diversity, or popularity (POP). In the following seven columns, we report the relative im-provement of the deviation from the history with respect to the baseline method kNN300CPA. The value  X .27 X  in the upper-left corner therefore means that after optimization for artists, the resulting playlist was 27% closer to the history (i.e., a better continuation) in terms of artist diversity than the playlist generated by the baseline method kNN300CPA. The last four columns refer to the relative change in accu-racy and the absolute accuracy values after optimization. The value  X .28 X  in the first row means that optimization not only helped to better match the artist diversity, but also led to a 28% improvement in the hit rate (HR).

In the first seven lines of Table 6, we report the results of single-goal optimization for the AotM dataset. All indi-vidual optimizations were (significantly) effective, which can easily be seen as all values on the diagonal are positive. The improvements range from 17% (tag diversity) to 35% (track popularity). Regarding the accuracy results we can observe for all single-goal optimizations except the tempo that the optimization did not negatively impact accuracy. In con-trast, the optimization in fact led to relative improvements both in terms of the hit rate (between 3 and 28%) and the MRR (up to over 100%).

Optimizing for tempo in the playlist continuation is effec-tive to reduce the deviation by 31%, but led to a modest relative degradation of the hit rate and the MRR (6% and 1%). Some of the single-objective optimizations furthermore have some side-effects, for instance, they all have a positive effect on the popularity aspect. In addition, the genre, tag, and artist optimization goals seem to be partially correlated.
In the last row of Table 6, we report the results of a multi-objective optimization run. We can observe that the results were improved in all dimensions  X  although to a smaller extent than with single-objective optimization  X  and again even helped to improve the accuracy. Other multi-objective combinations are possible, but are sometimes affected by optimization trade-offs and a loss in accuracy.
 Observations -Other datasets. The results for the non-public 8tracks dataset are in line with AotM. All optimiza-tions were effective and the relative improvements are in nearly all dimensions even stronger than for AotM. The hit rate improvements, for example, ranged between 7.8% and 39% and no negative effects on accuracy were observed.
On the Last.fm dataset, again all single-goal optimizations were effective. With respect to accuracy the effects of op-timizing for one goal are in some but not all cases positive. In particular optimizing for the tempo and the loudness can lead to a degradation of the hit rate of up to 16%. The MRR value is also sometimes negatively affected. A trade-off be-tween the goals can be observed for multiple-goal optimiza-tions and therefore not all possible combinations lead to an increase in accuracy.

The conclusion that can be drawn from this phenomenon is that criteria other than tempo and loudness seem to be the driving factors for users of the Last.fm platform when they create their playlists. For the users of 8tracks, match-ing both quality factors seems important; for the AotM approach to re-rank the whole recommendation list by chang-ing relevance scores of a baseline algorithms. Like our next-track optimization, the baseline algorithm is exchangeable, it however requires the existence of scores which might not be available if the underlying technique optimizes a rank measure as in learning-to-rank approaches. Furthermore, the focus of [9] lies on promoting long tail recommendations and does not cover aggregate measures. Finally, our re-ranking technique can be configured to exchange elements greedily from a comparably small exchange set x m , thereby leading to a limited computational complexity.

In [21], music tracks are recommended by combining mul-tiple algorithms through rank interpolation. Similar to our faceted scoring method, their goal is to increase the rec-ommendation accuracy as well as other factors like novelty, diversity and serendipity. However, their main focus lies on creating more serendipitous recommendations and the tech-nique is not based on exchangeable baseline methods but implements the optimizations inside the algorithms. In ad-dition, their method aims to achieve globally defined quality levels whereas in our work we try to minimize the difference between the playlist history and the immediate next tracks.
Playlist generation is a special form of music recommen-dation which is particularly challenging as the recommended items are immediately  X  X onsumed X , sequentiality and homo-geneity aspects can be important, and the choice of a few wrong tracks within the sequence can easily be detrimental to the perceived service quality as a whole.

In our work, we have proposed a new multi-aspect scor-ing scheme which combines patterns in existing playlist with meta-data features and personal user preferences to achieve higher accuracy and, if desired, higher homogeneity than previous approaches. A post-processing procedure can fur-thermore help to match the characteristics of the playlist continuation with the most recent listening history. In our ongoing work we evaluate the application of these proce-dures to general recommendation settings, where, e.g., the most frequent user ratings are used as representatives for the recent user preferences to which the next item recom-mendations should be adapted. Conducting a user study to evaluate our approaches in terms of the perceived quality of the playlists and user satisfaction is part of our future work. [1] G. Adomavicius and Y. Kwon. Improving aggregate [2] W. Balkema and F. van der Heijden. Music Playlist [3] G. Bonnin and D. Jannach. Evaluating the Quality of [4] G. Bonnin and D. Jannach. Automated generation of [5] K. Bradley and B. Smyth. Improving
