 Clustering is the problem of partitioning a set of observations into clusters such that observations assigned in the same cluster are similar (or close) and the inter-cluster observations are dissimilar (or distant). The other objective of clus-tering is to quantify the data by replacing a group of observations (cluster) with one representative observation (or prototype). A data stream is a sequence of potentially infinite, non-stationary (i.e., the probability distribution of the unknown data generation process may change over time) data arriving contin-uously (which requires a single pass through the data) where random access to data is not feasible and storing all arriving data is impractical. The stream model is motivated by emerging applications involving massive data sets; for example, customer click streams, financial transactions, search queries, Twitter updates, telephone records, and observational science data are better modeled as data streams [ 9 ]. Mining data streams can be defined as the process of find-ing complex structures in large data. Clustering data streams requires a process capable of partitioning observations continuously with restrictions of memory and time. In the literature, many data stream algorithms have been adapted from clustering algorithms, e.g., the density-based method DBScan [ 7 , 10 ], the partitioning method k -means [ 1 ], or the message passing-based method AP [ 18 ]. In this paper, we propose G-Stream, a novel algorithm for discovering clusters of split. It uses another data structure for saving summary statistics, named  X  -bin histogram. StrAP [ 18 ], an extension of the Affinity Propagation algorithm for data streams, uses a reservoir for saving potential outliers. In SVStream [ 16 ], the data elements of a stream are mapped into a kernel space, and the sup-port vectors are used as the summary information of the historical elements to construct cluster boundaries of arbitrary shape. SVStream is based on support vector clustering (SVC) and support vector domain description (SVDD) [ 16 ]. AING [ 6 ], an incremental GNG that learns automatically the distance thresholds of nodes based on its neighbors and data points assigned to the node of inter-est. It merges nodes when their number reaches a given upper-bound . Table 1 summarizes the main features offered by each algorithm in terms of: the basic clustering algorithm, whether the algorithm identifies a topological structure or not, whether the links (if they exist) between clusters (nodes) are weighted, how many phases it adopts (online and offline), the types of operations for updat-ing clusters (remove, merge, and split cluster), and whether a fading function is used. In this section we introduce Growing Neural Gas over Data Stream (G-Stream) and highlight some of its novel features. G-Stream is based on Growing Neu-ral Gas (GNG), which is an incremental self-organizing approach that belongs to the family of topological maps such as Self-Organizing Maps (SOM) [ 11 ]or Neural Gas (NG) [ 13 ]. It is an unsupervised algorithm capable of representing a high dimensional input space in a low dimensional feature map. Typically, it is used for finding topological structures that closely reflect the structure of the input distribution. We assume that the data stream consists of a sequence DS = { x 1 , x 2 , ..., x n } of n (potentially infinite) elements of a data stream arriv-notations used in this paper are presented in Table 2 . At each time, G-Stream three window models commonly studied in data streams: landmark, sliding and damped. We consider, like many others, the damped window model, in which the weight of each data point decreases exponentially with time t via a fading over time, t denotes the current time and t 0 is the timestamp of the data point. The weight of a node is based on data points associated therewith: weight ( c )= current time t . If the weight of a node is less than a threshold value then this node is considered as outdated and then deleted (with its links).
 Edge management: The edge management procedure performs operations related to updating graph edges, as illustrated in steps 13 -16 of Algorithm 1 . The way to increase the age of edges is inspired by the fading function in the sense that the creation time of a link is taken into account. Contrary to the fading function, the age of the links will be strengthened by the exponential function 2 the current time and t 0 is the creation time of the edge. The next step is to add a new edge that connects the two closest nodes. The last step is to remove each link exceeding a maximum age, since these links are no longer useful because they were replaced by younger and shorter edges that were created during the graph refinement in steps 18 -22 .
 Reservoir management: The aim of using the reservoir is to hold, temporar-ily, the distant data points. As mentioned before, each node has a threshold distance. The first batch of data is assigned to nearest nodes without comparing distance thresholds. The distance threshold of each node is learned by taking the maximum distance of the node to the farthest point that it has been assigned. When the reservoir is full, its data is re-passed for learning. They are placed in the heap of the data stream, DS , to be dealt with first and the distance thresholds of nodes are updated accordingly.
 Computational complexity: It is obvious that the most consuming opera-tions, in Algorithm 1 , are steps 4 , 18 -22 , 23 ,and 24 with O ( k ) time complex-ity each, where k is the number of nodes in the graph. The node insertion phase (step 22 ) is repeated 3 .n  X  times. Seeking the nearest node (step 4 ), fad-ing function (step 22 ), and adjusting the error variable (step 24 ) phases are repeated whenever a new data point is available, i.e. n times. The other steps have a constant time complexity. Therefore, G-Stream has a complexity given by n. (3 .O ( k )) + 3 .n  X  .O ( k )= n. (3 + 3  X  ) .O ( k )= O ( nk ). In this section, we present an experimental evaluation of the G-Stream algorithm. We compared our algorithm with the GNG algorithm and several well-known and relevant data stream clustering algorithms, including StreamKM++, Den-Stream, and ClusTree. Our experiments were performed on MATLAB platform using real-world and synthetic data sets. All the experiments are conducted on a KDD-CUP X 99 Network Intrusion Detection stream data set (KddCup99) and the Forest CoverType data set (CoverType) respectively.
 (Purity), Normalized Mutual Information (NMI) and Rand index [ 14 ]. The value of each measure lies between 0 and 1. A higher value indicates better clustering results. The Accuracy (Purity) averages the fraction of items belonging to the majority class of in each cluster. Acc = number of clusters, N d i denotes the number of points with the dominant class label in cluster i ,and N i denotes the number of points in cluster i . Intuitively, the accuracy (purity) measures the purity of the clusters with respect to the true cluster (class) labels that are known for our data sets [ 7 ]. Normalized mutual information provides a measure that is independent of the number of clusters as compared to purity. It reaches its maximum value of 1 only when the two sets of labels have a perfect one-to-one correspondence [ 14 ]. The Rand index measures how accurately a clusterer can classify data elements by comparing cluster labels with the underlying class labels. Given N data points, there are a total of N 2 distinct pairs of data points which can be categorized into four categories: ( a ) pairs having the same cluster label and the same class label (their number denoted as N 11 ); ( b ) pairs having different cluster labels and different class labels (their number denoted as N 00 ); ( c ) pairs having the same cluster label but different class labels (their number denoted as N 10 ); ( d ) pairs having different cluster labels but the same class label (their number denoted as N 01 ). The Rand index is defined as: Rand =( N 11 + N 00 ) / N 2 . 4.2 Evaluation and Performance Comparison This section aims to evaluate the clustering quality of the G-Stream and compare it to well-known data stream clustering algorithms, as well as the GNG algo-rithm. As explained in section 3 , the GNG and G-Stream algorithms start with two nodes. We used an online version of GNG but without the parameters that we added expressly to show the interest and contribution of these parameters in G-Stream. Therefore, we carried out experiments by initializing two nodes randomly among the first 20 points and we repeated this 10 times. For com-parison purposes, we used DenStream [ 7 ] and ClusTree [ 12 ]fromthe stream R package [ 5 ]. Comparison is also performed with StreamKM++ [ 1 ] (this lat-ter algorithm was coded in the C language). StreamKM++ was evaluated by 4.3 Visual Validation Figure 3 shows the evolution of the node creation by applying G-Stream on the letter4 data set (green points represent data points of the data stream and blue points are nodes of the graph with edges in blue lines). It illustrates that G-Stream manages to recognize the structures of the data stream and can sep-arate these structures with the best visualization. Figure 4 compares G-Stream with GNG-online on 2-dimensional data sets (DS1 and letter4), in terms of visual results i.e., the final graph found by GNG-online/G-Stream for each data set. As illustrated on these figures, the G-Stream algorithm is superior to the GNG-online with respect to visual structures found.
 4.4 Evolving Data Streams In this subsection, we perform G-Stream on different data streams ordered by class labels to demonstrate its effectiveness in clustering evolving data streams (i.e., data points of the first class arrive in first, then the ones of the second, third, etc. class). In this case, old concepts (class labels) disappear due to the use of fading function. In the same time, new concepts (class labels) appear as time of G-Stream and SVStream grow as the size of the data stream grows, and G-Stream is more efficient than SVStream. In this paper, we have proposed G-Stream, an efficient method for topological clustering an evolving data stream in an online manner. In G-Stream, the nodes are weighted by a fading function and the edges by an exponential function. Starting with two nodes, G-Stream confronts the arriving data points to the cur-rent prototypes, storing the very distant ones in a reservoir, learns the threshold distances automatically, and many nodes are created in each iteration. Experi-mental evaluation over a number of real and synthetic data sets demonstrates the effectiveness and efficiency of G-Stream in discovering clusters of arbitrary shape. Our experiments show that G-Stream outperformed the GNG algorithm in terms of visual results and quantitative criteria such as accuracy, the Rand index and NMI. Its performance, in terms of clustering quality as compared to three relevant data stream algorithms are promising. We plan in the future to implement adaptive windows, make our algorithm as autonomous as possible and develop it in Spark Streaming.

