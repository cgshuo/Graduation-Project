 We present a new class of adaptive algorithms that use com-pressed bitmap indexes to speed up evaluation of the range join query in relational databases. We determine the best strategy to process a join query based on a fast sub-linear time computation of the join selectivity (the ratio of the number of tuples in the result to the total number of pos-sible tuples). In addition, we use compressed bitmaps to represent the join output compactly: the space requirement for storing the tuples representing the join of two relations is asymptotically bounded by  X  X  X  X  (  X , X   X   X   X  ), where  X  is the number of tuple pairs in the result relation,  X  is the number of tuples in the smaller of the two relations, and  X   X  is the cardinality of the larger column being joined. We present a theoretical analysis of our algorithms, as well as experimen-tal results on large-scale synthetic and real data sets. Our implementations are efficient, and consistently outperform well-known approaches for a range of join selectivity factors. For instance, our count-only algorithm is up to three orders of magnitude faster than the sort-merge approach, and our best bitmap index-based algorithm is 1 . 2  X   X 80  X  faster than the sort-merge algorithm, for various query instances. We achieve these speedups by exploiting several inherent per-formance advantages of compressed bitmap indexes for join processing: an implicit partitioning of the attributes, space-efficiency, and tolerance of high-cardinality relations. H.3.1 [ Information Storage and Retrieval ]: Content Analysis and Indexing X  Indexing methods ; H.2.4 [ Database Management ]: Systems X  Query processing Algorithms, Experimentation, Performance, Theory
The join is a fundamental and versatile relational database operation. Informally, it is used to combine tuples from two (or more) different relations (or tables) based on some com-mon information [11]. There are several different kinds of joins, and a vast collection of algorithmic strategies to solve them [11 , 13 ]. In general, the join is considered one of the most difficult relational operations to implement efficiently.
A join is performed on two input relations  X  and  X  , pro-ducing a result relation  X  . The join condition specifies the desired relationship to combine the tuples from  X  and  X  . We denote the join attributes (or join columns) in  X  by  X  (  X  ), and the attributes in  X  by  X  (  X  ). The join relation  X  join condition. Let  X  and  X  denote the number of tuples in  X  and  X  , respectively. The join selectivity factor is defined as the ratio of the number of tuples in the resulting join re-lation (  X  ) to the total number of possible tuple pairs due to the cross-product of the two tables (  X  X  X  ).

In this paper, we present new algorithms for a specific type of join called the band [5] or range join . For this join variant, the join condition is of the form  X  (  X  )  X   X  1  X   X  (  X  )  X   X  (  X  )  X   X  for some constants  X  1 and  X  2 . Note that if  X  1 and  X  2 zero, this reduces to the commonly-used equijoin .

There are several known approaches for optimizing band joins, and in general the join operation. If the number of join attributes is small and known before-hand, one could construct a join index , a special relation tailored for answer-ing these queries. Bitmap join indexes are a specialization of this data structure that use bitmaps (bit vectors), and are extensively studied [2 , 9, 12 , 14]. However, by definition, they are only useful in cases involving specific columns for which the index has been built for; i.e., joins on arbitrary columns cannot benefit from this specialized index. In ad-dition, join indexes can be significantly larger than regular bitmap indexes. For instance, in a recent study on a geo-graphical application, Siqueira et al. found that a specific join index for their data was 1000 times larger than a reg-ular bitmap index [17]. For these reasons, it is worthwhile to investigate the possibility of using regular bitmap indexes for computing band joins and other variants.

The other class of algorithms for evaluating joins are ro-bust and general-purpose, requiring no specialized data stru-ctures. The nested-loop , sort merge , hash join , and their variants are some well-known examples [11 ]. The sort-merge join, as its name suggests, sorts the join attributes to re-duce the number of tuple comparisons. It then merges the tuples according to the join condition, and if the join se-lectivity is low (  X  (  X  )), this approach is significantly faster than nested-loop, and is more efficient in I/O accesses. The execution is typically dominated by the sorting step, which is  X  (  X  log  X  ) using a generic comparison-based sorting algo-rithm. Hash-based algorithms have a linear time complexity, but are known to be difficult to solve non-equijoins (for in-stance, band joins). Partitioned band join algorithms [5] try to minimize the disk I/O time in materializing the join re-sult by partitioning the relations using a sampling strategy, and then computing band joins on the smaller partitions. This divide and conquer strategy outperforms the standard sort-merge in several instances, but still relies on a sort as an inner computational kernel. In comparison, our approaches operate entirely with bitmap indexes and avoid the sorting kernel.
We present a class of new algorithms for computing range joins using bitmaps indexes. We directly compute cross-products using bitmaps for answering a join query, whereas the bitmap join index can be thought of as precomputing such cross-products. Because we keep the involved bitmaps compressed during every step of the query evaluation pro-cess, the storage requirement is low. We additionally use compressed bitmaps to represent the results of joins, which keeps the output also compact.

Our motivating applications for this work arise from the domain of scientific data analysis with predominantly nu-merical data sets. Here, there is a need to perform multi-dimensional range join operations on arbitrary attributes of two or more relations. For instance, in astronomical data analysis, we have large catalogs on which queries such as cross matching [16 ], cone searches, and spatio-temporal matching [6 ] are posed, with range joins as one of the key underlying computational kernels. Our algorithms can use compressed bitmap indexes already built for range queries, and thus do not require additional storage or preprocessing. To demonstrate the applicability of our approaches to large-scale astronomy data sets, we present range join query per-formance results on the Sloan Digital Sky Survey Release-1 in this paper.

This paper is organized as follows. We introduce com-pressed bitmap indexing in Section 2, define the problem of computing the cross-product of two bit vectors, and describe a baseline approach to compute equijoins using compressed bitmap indexes. We then present the range join problem formulation in Section 3 and outline an algorithm based on cross products of bit vectors to solve this problem. In Section 3.2 , we specialize this approach and present an al-gorithm to compute the join selectivity factor quickly, by inspecting compressed bit vectors corresponding to the two attributes being joined. We then extend the ideas to multi-way range joins in Section 4, and also detail how these join queries can be answered in conjunction with the search ca-pability of compressed bitmap indexes. Finally, we present a detailed experimental study in Section 5 comparing our new approaches with the traditional sort-merge algorithm. With a combination of theoretical and empirical results, we clearly identify the cases when our approach would be faster than the sort-merge algorithm, and quantify the speedups achieved. We demonstrate that our best approach is 1.2  X   X  80  X  faster than the sort-merge implementation.
A bitmap index is an indexing scheme that stores data as bit sequences, and answers queries using bitwise logical operations. The bit sequences are referred to as bitmaps or bit vectors. Typically, a bitmap index is generated for one attribute of a relation/table, and is comprised of a bit vector for each distinct value of the attribute. The distinct values are referred to as the keys . Since the bitmap size will then grow linearly with the number of distinct values, which is also known as the attribute cardinality , it is efficient only for columns with low cardinalities. The same restriction also applies to the bitmap join index [12 , 14]. There are a num-ber of commercial implementations of bitmap indexes, and users are often cautioned to use them only on low cardinality columns.

WAH compression : There are however various approa-ches to extend the effectiveness of bitmap indexes to columns with higher cardinalities. The three common ones are bin-ning [8 ], encoding [ 3, 4, 14 ], and compression [1 , 7]. In this work, we use compressed bitmaps with a compression method called Word-Aligned Hybrid (WAH) [ 19 ] for range join evaluation. In prior research, Wu et al. demonstrated that WAH compression is extremely efficient for compressing bitmap indexes and optimal for range queries. Our new al-gorithms are implemented in a software system built for sci-entific data, where the majority of the records are read-only. In this software package FastBit 1 , all data tables are verti-cally partitioned to support efficient ad-hoc queries. In many applications that use FastBit, a compressed bitmap index is already built for each column that is queried. Thus, our join algorithms require no additional preprocessing for sup-porting ad-hoc join queries. Our new join algorithms exten-sively use logical operations on WAH compressed bitmaps, which are shown to be very efficient in FastBit implementa-tions [19 ].

WAH compression is based on the idea of run-length en-coding. Two types of words are used to store bits: literal words and fill words. The most significant bit of the word is used to distinguish between a literal and fill word. Let  X  denote the number of bits in a computer word. Then, the lower  X   X  1 bits of a literal word contain bit values, 0 X  X  and 1 X  X , in an uncompressed form. The fill word, on the other hand, is used to compactly store 0 X  X  and 1 X  X  that are multi-ples of  X   X  1 bits. The second most significant bit in a fill word indicates the type of fill, and the rest of the  X   X  2 bits are used for storing the length of the fill, or the number of integer multiples of  X   X  1. If the total number of bits is not a multiple of  X   X  1, then the last literal word created has just a few valid bits. This is referred to as an active word .
We assume that equality encoding is used for the bitmap index. Bitmaps constructed with range [ 3] and interval en-coding are not as compressible as equality-encoded bitmaps, and the index size may become prohibitive when doing arbi-trary range joins. Binary encoding [14 , 18] would be signif-icantly more expensive than equality encoding for narrow-range queries, which would be our typical query instances on scientific data sets.
We first present a baseline algorithm for an important sub-routine, a cross-product of two WAH-compressed bit vec-tors. We will discuss equijoin algorithms based on this cross-product subroutine (denoted as BCP , or Baseline Cross Product) in the following sections.
More information about FastBit can be found at http: //sdm.lbl.gov/fastbit .
Symbol(s) Description  X  ,  X  Relations/tables that are being joined.  X  (  X  ),  X  (  X  ) Join attributes/columns in  X  ,  X  respec- X  Number of tuples in  X  , and size of each  X  Number of tuples in  X  , and size of each  X  Number of tuples in the join result.  X   X  , X   X  Number of bit vectors in bitmap index  X   X  Bit vector corresponding to value  X  in  X   X  Bit matrix corresponding to cross prod- X   X  Number of bits set to 1 in bit vector  X  .  X   X  Number of bits set to 1 in the bit matrix.  X   X  X  X  X  Number of bit vector OR operations in  X   X  Number of unique  X  bit vectors touched  X   X  X  X  X  X  X  X  Number of non-empty columns in com- X  Number of bits in a computer word.  X   X  , X   X  Selection conditions on  X  ,  X  respec-
Consider a join condition that just operates on one join column per relation, i.e.,  X   X  (  X  )  X  =  X   X  (  X  )  X  = 1. Let  X  and  X  denote these attributes in  X  and  X  , respectively. Let  X   X  denote the attribute cardinalities of  X  and  X  respectively. See Table 1 for a listing of other symbols.

Let  X   X  and  X   X  denote bit vectors corresponding to the value  X  in attributes  X  and  X  respectively. The cross-product of these two bit vectors is defined as a bit matrix  X   X  AND operator (illustrated in Figure 1). Clearly, an uncom-pressed representation of the bit matrix would quickly be-come intractable to store on current workstations, due to the quadratic space complexity. The performance of any high-level routine that may operate on this cross-product will also be adversely affected, due to the large memory footprint of the result. However, if we store both  X   X  and  X   X  in a com-pressed manner, then computing the cross-product would still be feasible.

Algorithm 1 describes a simple approach to construct the cross-product. At a high level, the algorithm for computing the cross product is to simply append the bit vector  X  to the appropriate location in the result bit matrix. For internal representation of the result matrix, we linearize it in column-major ordering. This allows us to treat the bit matrix as a long bit vector and apply the WAH-compression technique. Analysis : Let  X   X  and  X   X  denote the number of bits that are set to 1 in each vector. Since Algorithm 1 simply replicates  X   X   X  times, we can easily show that the size of the WAH-compressed cross-product is  X  (  X   X   X   X  ). The running time of Algorithm 1 is dominated by step 5, which is executed  X  times. Thus we have the following theorem. theorem 1. The space and time requirements to compute Figure 1: A simple representation of the cross-product of two uncompressed bit vectors.

Algorithm 1 : BCP : A simple approach for computing the cross-product of two compressed bit vectors.
 Input : Two compressed bit vectors  X  and  X  .

Output : The cross-product of  X  and  X  , stored in  X  .  X   X   X  ; (initialize an empty compressed bit vector)  X  X  X   X   X  &amp; 0; (initialize a compressed bit vector representing  X  zero bits.) for  X  = 1 to  X  do a cross product  X  of two bit vectors  X  and  X  are both  X  (  X  where  X   X  is the number of bits that are 1.
We generate explicit cross-products of bit vectors as de-scribed in Algorithm 1, since they provide a simple interface to implement joins using compressed bit vectors. Consider the illustration in Figure 2. The set bits in the cross-product  X   X  of  X   X  and  X   X  correspond to tuples in the join result for which the values match. It is evident that the resulting rela-tion from an equijoin can be obtained by performing a series of logical operations of bit vectors corresponding to values that match in both the join attributes. Using compressed bit vectors to represent the cross-products helps us store the result in a space-efficient manner, and also lets us leverage previous work on efficient bitwise logical operations. Figure 2: Computing an equijoin through a series of logical OR operations on bit vector cross-products.
Thus, we are obtaining the result of a join operation by extracting a subset of the Cartesian product of the two join attributes  X  (  X  ) and  X  (  X  ). The output bit matrix gives the pairs of tuple identifiers from the two columns which satisfy the join condition. The resulting join table can then be materialized by accessing the data, which may reside in main memory or secondary storage. Algorithm 2 formally lays out this bit vector cross-product based approach.

Algorithm 2 : BCP-EqJoin : An equijoin algorithm using explicit cross-products of bit vectors.

Input : Bitmap indexes of join attributes  X  and  X  from
Output : Pairs of tuple identifiers from  X  and  X  that  X   X   X  ; (initialize an empty compressed bit vector for storing the join tuple pair identifiers)  X   X  1;  X   X  1; while (  X   X   X   X  ) &amp; (  X   X   X   X  ) do Analysis : We assume that all the distinct values in these columns (the index keys ) are stored in a sorted array and can be accessed in constant time. This information is typi-cally available to us as an auxiliary data structure from the bitmap index corresponding to the join attribute. We in-spect keys in both  X  and  X  by stepping though the arrays in sorted order (we assume Fetch Next Key in Algorithm 2 provides us with these values in constant time). In step 11, we perform a cross-product on bit vectors corresponding to the matches, followed by a logical OR of this matrix with a running copy of the result  X  . From Theorem 1, we know that the size and running time of each intermediate cross-product computation is bounded by  X  (  X   X  X  X  ), where  X   X  X  X  is the number of set bits in an intermediate result bit matrix. The logical OR operation can be efficiently computed on the com-pressed bit vectors in optimal  X  (  X   X  X  X  +  X   X  X  X  ) time [19 ], where  X   X  X  X  is the number of set bits in the running OR result. Let  X   X  X  X  X  denote the total number of OR operations that are per-formed. By definition, we know that  X   X   X  X  X  X   X  =1  X   X  X  X  =  X  . In the worst case,  X   X  X  X  X  = min(  X   X  , X   X  ). Also, note that the  X  grows during the execution of the algorithm. Since this cost is incurred in every OR computation, it would be wise to de-fer the evaluation of cross-products leading to a significant number of set bits to latter stages of the algorithm. This leads us to an upper bound on the execution time, as well as an optimal ordering for computing the cross-products. theorem 2. The execution time of BCP-EqJoin is given by  X  (  X   X  X  X  X   X   X  ) , where  X   X  X  X  X   X   X  X  X  X  (  X   X  , X   X  ) and  X  is the number of set bits in the result relation. The space requirements of the algorithm are  X  (  X  ) .

We assume a worst-case ordering of the OR X  X  to compute this bound. In practice, we can scan through the lists in Table 2: Possible compressed result words created from a bit-level combination of uncompressed  X  1 and  X  2 bit vectors when evaluating  X  1  X   X  1  X   X  2  X   X  2 .
Bit value in  X  1 Bit value in  X  2 Result word(s) 0 0 0-fill word, value  X   X  0 1  X  2 1 0  X  1 1 1  X  1  X   X  2  X  (  X   X  +  X   X  ) time to determine the number of matches and the intermediate result sizes. We could then order the OR computations according to the estimated result matrix sizes, starting with the smallest one first. Note that the average-case running time here is dependent on characteristics of the join attributes.
Algorithm 2 is useful as a baseline approach for compar-ison to the new join algorithms we present in this paper. From the worst case theoretical bounds, we expect this cross-product based algorithm to either outperform or be compet-itive with the traditional approaches such as sort-merge and hash-join in the following scenarios: The multiplicative factor of  X   X  X  X  X  , the number of OR opera-tions that have to be performed, is the primary performance concern for this equijoin approach. We now investigate tech-niques to speed up this equijoin algorithm by first exploring approaches to reduce the computational complexity.

Step 11 of Algorithm 2 involves a cross-product computa-tion followed by a logical OR operation on potentially large vectors. To answer most join queries, we need to perform bitwise ORs of several different bit matrices. Consider an OR operation  X  1  X   X  2 where  X  1 =  X  1  X   X  1 and  X  2 =  X  2 Table 2 lists all possible outcomes of the output based on a bitwise comparison of the uncompressed bits in  X  1 and  X  2
We see from the table that it is possible to compute the result of the OR operation by just comparing bits of the uncompressed  X  1 and  X  2 vectors. Further, the result of the OR operation need not be explicitly stored, as the output words are possibly one of the following four combinations: a 0-fill word,  X  1 ,  X  2 , or  X  1  X   X  2 . We can compute the join result size by just determining the number of  X  1 ,  X  2 , and  X  occurrences in the result, and the number of 1 X  X  in each of these vectors.

Operating on individual bits is expensive. Consider work-ing with WAH-compressed  X  1 and  X  2 vectors, and perform-ing the OR operation without expanding the cross-product. Table 3 lists all possible combinations of word-level OR op-erations, assuming WAH compression. To simplify the anal-ysis, we assume that there are no active words in the  X  or  X  bit vectors. The number of new words created in the result, and the composition of the result for each combination, is listed in the table. As noted earlier, any contiguous section Figure 3: A scheme to further compress the cross-product bit matrix. of compressed words in the result array can only be one of four different possibilities: a 0-fill word,  X  1 ,  X  2 , or  X  leads to a further optimization. As illustrated in Figure 3, if we just store the type of the pattern (one of these four possi-bilities) and a running sum of the position offset associated with its location, we can reconstruct the result array. Analysis : The implicit cross-product approach we describe above is a replacement to line 11 of the BCP-EqJoin algo-rithm. We first evaluate pairwise combinations of the  X   X  X  X  X  result vectors in this manner, and then perform OR opera-tions on the resulting compressed bit vectors. In terms of storage, we need  X  pointers to compressed bit vectors of  X  bits each. The  X  pointers require  X  (  X  ) words, and the size of each  X  -bit vector is proportional to the number of set bits in it.

The percentage of literal and fill words in each of the  X  vectors, and the actual mix of operations performed in Ta-ble 3, would give us a better estimate of the execution time. We can apply an OR ordering similar to the BCP-EqJoin algorithm, deferring expensive OR X  X  to latter stages of the algorithm. By working on compressed bit vectors instead of bitwise comparisons (i.e., operations in Table 3 instead of Table 2), we achieve a multiplicative factor execution time saving proportional to the word size. The worst case occurs when both the  X   X  vectors are composed of only literal words. Then we need to look at each bit to expand the result, and so the time for one cross-product would be  X  (  X  ).
The compact output representation sketched out in Fig-ure 3 leads to significant space savings. Consider a single cross-product OR computation. By not expanding the  X   X  X  explicitly, we can cut down on the result space requirements by a multiplicative factor of  X  (  X   X  ). We refer to this improved equijoin algorithm as CP-EqJoin .
The most general form of the range join takes an arbi-trary distance function and a threshold, and finds all pairs of tuples chosen from the input relations whose values are within the specified threshold. In this paper, we focus on a more restrictive form of the range join that can be specified as a set of pairwise joins. This is equivalent to decomposing the distance function into individual dimensions. We denote each pairwise join condition between attributes  X  (  X  ) and  X  (  X  ) as  X   X   X   X  , which indicates a result relation that has merged tuples with attributes  X  and  X  within  X  of each other. In SQL, the same join may be expressed as  X   X  between  X   X   X  and  X  +  X  . X  The equijoin discussed in the previous section is a special case. If the join involves more than two attributes, we call it a multiway range join. Our focus is on ad-hoc joins that will work on arbitrary pairs of columns.
In the equijoin examples, we did not explicitly specify the keys corresponding to the bit vectors in a bitmap. However, for range joins, we need to examine the values of keys to determine the bit vectors to use in the cross-product.
Algorithm 3 gives the pseudo-code for range join evalua-tion using cross-products of bit vectors. Depending on the size of the band (the value of  X  ), we may need to evalu-ate a series of cross-products with the same left-hand-side  X   X   X   X   X   X   X   X   X   X  +1  X  ... . Instead, performing the logical OR operations before the cross-products (as depicted on line 4 of the algorithm) is much more efficient.

Typically, there is an additional set of selection conditions on the relations  X  and  X  . We evaluate these conditions us-ing bitmap indexes and produce two bit vectors (denoted by  X   X  and  X   X  in the algorithm) to represent them. Note that these masks resemble the Positionally Encoded Record Filters (PERF) used in the PERF join algorithm [10]. How-ever, the two major differences in our approach are that these masks can be efficiently computed using logical oper-ations on bitmaps, and we can store these masks compactly with WAH compression. To reduce the cost of the cross-product function, we usually apply the masks before each invocation of the cross-product function.

Algorithm 3 : CP-RangeJoin : A generic two-way range join algorithm based on cross-products of bit vectors.
Input : Bitmap indexes of join attributes  X  and  X  from
Output : Relation Q corresponding to a range join on  X   X   X  ; (initialize an empty compressed bit vector for storing the join output) for  X  = 1 to  X   X  do Analysis : The algorithm iterates over each bit vector (key) of  X  and identifies the keys of  X  for which the join condi-tion is satisfied. Thus, the outer for loop executes  X   X  However, if there is a range condition on  X  , for instance  X   X   X   X   X  , then the number of keys inspected, and con-sequently the amount of work done in the cross-product, is reduced. Similarly, step 4 prunes some of the keys in  X  .
We assume that the result bit matrix is generated using the cross-product algorithms described in the previous sec-tion. In comparison to the equijoin algorithm, this approach performs more work in evaluating the range join condition in step 5. Having the key information of  X  readily available through the bitmap index is certainly advantageous. In the worst case, step 5 will have to sift through all the keys of  X  , leading to an asymptotic time complexity of  X  (  X   X   X   X   X   X  Clearly, the straight-forward approach of creating the cross-product matrix will only be useful for attributes of low car-dinalities.  X   X   X  1  X   X  2  X   X  2 .

Word type in  X  1 Word type in  X  2 Result words # of result words 0-fill, value  X  0-fill, value  X  0-fill, value  X  X  X  X  (  X , X  )  X   X  . 1 0-fill, value  X  literal word (LW) 0-fill words (value  X   X  ) and  X  2 replicates (equal to
LW 0-fill, value  X  0-fill words (value  X   X  ) and  X  1 replicates (equal to
LW LW 0-fill words,  X  1 ,  X  2 , and  X   X   X  2 replicates. runtime
For all the algorithms proposed so far, cross-product eval-uation becomes expensive for large (  X  &gt;&gt;  X  (  X  )) join selec-tivity factors. From Theorem 1, we have an estimate of the size of the join result. Further, if we assume equality encod-ing, then there is no overlap between the bit vectors. It leads us to a significant reduction in the complexity of range join evaluation. Note the following result for WAH-compressed data with equality encoding: lemma 1. Let  X  1 , X  2 ,..., X   X  denote the bit vectors corre-sponding to the bitmap index of an attribute  X  . Then,  X  is a null vector for all 1  X   X   X  =  X   X   X  .
 This result implies that the the number of set bits in any OR computation of two  X   X  or  X   X  bit vectors is the sum of the set bits in the individual vectors, as these vectors do not overlap in their uncompressed form. This lets us very efficiently compute the tuple count in the join result for a range join (see Algorithm 4).

Algorithm 4 : CP-JoinCount : A fast algorithm to deter-mine the join selectivity factor.

Input : Bitmap indexes of join attributes  X  and  X  from
Output : The number of tuples in the relation Q,  X  X  X  X  X  X  X   X  0; for  X  = 1 to  X   X  do  X  X  X  X   X   X  X  X  X  X  X  X 
The count algorithm requires inspection of the keys of  X  on every iteration of the outer loop to evaluate the join condition. However, we can assume that the set bit counts in the bit vectors of  X  are readily available. The inner loop computation is thus  X  (  X   X  ), leading to an overall asymptotic complexity of  X  (  X   X   X   X   X  ). Note that if we have additional masks to apply to the bit vectors, this nice relation will not hold. In that case, we need to explicitly compute the bit vector OR X  X . If we use WAH compression, we know that the cost of a bitwise logical operation is in the worst case a linear function of the total size (bytes or words) of the two input bit vectors. This leads us to an asymptotic time complexity of  X  (  X  ). The memory footprint of this algorithm is smaller than a full cross-product evaluation, as we only need to operate on a few bit vectors in every iteration. We assume that  X   X  and  X   X  are available in main memory, and the  X  bit vectors can be loaded as required.
We can design faster algorithms for the full evaluation of range join if we assume that we are given an equality-encoded compressed bitmap index for the join attributes. Algorithm 4 provides us with the exact join selectivity fac-tor and requires linear space to compute in most cases. If we know that the result count is significantly large (quadratic space requirements), we can try out alternate strategies for representing the cross-product output. The non-overlapping nature of the bit vectors again proves helpful. In Algorithm 1 (and Figure 2), we detail the approach of constructing a bit matrix cross-product. Observe that each column of the bit matrix in its uncompressed form is a result of an OR compu-tation on some bit vectors of  X  . Further, since the bit vectors are non-overlapping, we can defer the OR computations un-til the latter stages of the algorithm. Instead we use  X  per column to store the bit vector identifiers of attribute  X  that we need to perform OR operations on. Algorithm 5 details a two-phase algorithm for the range join that first estimates or exactly computes the count, and then performs a full range join evaluation with the OR computation. Analysis : The first phase of this range join algorithm com-putes the result tuple count. In addition, it is also helpful to maintain a list of the  X  bit vectors that would appear at least once in a column of the result matrix. Let us denote this count by  X   X  . In case of an equijoin, the number of cross-product OR X  X  we need to compute is given by  X  It is easy to see that for a range join,  X   X  , X   X  X  X  X   X 
We initialize a list of pointers to the column vectors in uncompressed form to store the different non-zero columns of the bit matrix.  X  X  X  X  X  X  X  is a bit vector in the algorithm that indicates whether a column is present in the result bit ma-trix. If it is present, then we require  X   X  bits per column to keep a track of the different  X  bit vectors that appear in this column. Note that this is a complete representation of the result which can be expanded into an uncompressed bit vec-tor or matrix if required. Deferring the OR computation lets
Algorithm 5 : CP-FastRangeJoin : A memory-efficient algorithm for computing the range join.

Input : Equality-encoded bitmap indexes of join
Output : The output relation Q, corresponding to a  X  X  X  X  X  X  X   X  0;  X  X  X   X   X  ; (a list of compressed column vectors)  X  X  X  X  X  X  X   X   X  ; (an uncompressed bit vector to keep a track of columns that are non-zero) for  X  = 1 to  X   X  do for each set bit  X  in  X  X  X  X  X  X  X  do us cut down the space requirement of the result from  X  (  X  ) (for a linearized, compressed bit vector representation of the bit matrix) to  X  (  X   X   X   X  ) (for this new two-dimensional data structure that is uncompressed in one dimension). Clearly, this representation is superior to the  X  (  X  )-space structure Thus, based on the value of this count, we can choose an appropriate compressed bit vector representation for the re-sult.

Let  X   X  X  X  X  X  X  X  denote the number of set bits in  X  X  X  X  X  X  X  . The to-tal number of possibilities of bit vector OR X  X  grows exponen-tially with  X   X  , precisely as 2  X   X   X  1 . Contingent on the size of the resulting columns, one possibility is to precompute all possible bit vector OR X  X  and step through  X  X  X  X  X  X  X  assigning the appropriate pointers. This approach is certainly feasible in the case of very small values of  X   X  ( &lt; 10), and advanta-geous when  X   X  X  X  X  X  X  X  =  X  (  X  ). The other extreme would be to compute bit vectors using OR X  X  as we go along identifying non-zero  X  X  X  X  X  X  X  values. We expand  X   X  X  X  X  X  X  X  columns in total, and the work done is proportional to the number of set bits, since the operation being performed is a compressed bit vec-tor OR. Thus, the total amount of work done is again  X  (  X  ) in this case. However, in comparison to the CP-RangeJoin algorithm, the memory footprint of the individual OR com-putations is significantly lower, as we defer all expansion to the end and we process one column at a time.

Finally, observe that we can possibly achieve a multiplica-tive speedup factor of  X  (  X   X  X  X  X  X  X  X  ) for the expansion (this case arises when the same bit vector OR pattern occurs in ev-ery column, and we just compute it once and reuse it for the remaining  X   X  X  X  X  X  X  X   X  1 cases). Intuitively, a range join would introduce bands of contiguous (in the key values)  X  vectors on which we need to perform OR operations on. Any greedy heuristic that tries to minimize the computa-tion must be cognizant of the fact that the total amount of work to be performed in the straight-forward approach is still  X  (  X  ). Depending on the relative values of  X   X  , and the total amount of main memory available on the computing system, we may possibly precompute and store a few recurring bit vector patterns. From the various counts, we can estimate the running time and memory overhead for any heuristic. One greedy approach we use that appears to work well in practice, is to order the OR X  X  by the size of the resulting vector, and store a selected number of the larger pairwise OR X  X  that are reused.
Filtering and Projections : Since most queries involv-ing joins also contain additional conditions on the partici-pating relations, an obvious way to take advantage of bitmap indexes is to use them to evaluate the range conditions. We will refer to the conditions on each relation participating in the joins as the selection conditions on the relation , or simply the selection conditions. The tuples satisfying the selection conditions are called the selected rows . After eval-uating these selection conditions, we can apply one of the above cross-product based join algorithms.

A second possible approach to evaluate range joins is to project out the selected tuples of the join attributes. For most modest size joins, these projections often can be stored in memory and we may subsequently apply a traditional in-memory join algorithm. Assuming we can compute the in-memory join on the projection efficiently, this approach should be efficient overall. We use the nested-loop and sort-merge join algorithms to evaluate range joins on the pro-jections. In both cases, if we only want to count the result tuple sizes, we do not need to access any identifiers of the selected rows. However, if we need the create a new rela-tion satisfying the join conditions, we will need to maintain two sets of row identifiers, one for relation  X  and the other for relation  X  . By definition, the projection from  X  has  X  tuples and the projection from  X  has  X   X  tuples. Thus, we expect the nested-loop join algorithm to take  X  (  X  time if we do not need to generate the output bit matrix  X  . Similarly, the sort-merge join algorithm on the projections would take  X  (  X   X  log(  X   X  ) +  X   X  log(  X   X  )) time.
Multiway Joins : In many range joins, the distance func-tions are defined on multiple attributes. For example, in a query on network traffic data, one might perform a join on three out of four octets of source and destination IP ad-dresses, such as,  X  X .sourceIP A  X  0 S.destinationIP A and R.sourceIP B  X  0 S.destinationIP B and R.sourceIP C  X  0 S.destinationIP C. X  While the join operator is still applied on two tables, multiple range join operators  X   X  are specified. A common strategy to process these queries is to evaluate one of the join operators using indexes and then scan the base data to resolve the remaining join conditions. We can use one of the cross-product based approaches to construct a compressed bit matrix of the result for one pairwise join. An alternative strategy is to process each join operator sepa-rately and then combine the results with an AND operation on the compressed bit vectors. In both cases, we can apply Algorithm 4 to estimate the counts for each pairwise join operation.
We implement the new join algorithms discussed in this paper as subroutines of the FastBit bitmap indexing pack-age. In this section, we provide a detailed performance anal-ysis of the bit vector cross-product computation and the various join algorithms on both synthetic and real data. Ta-ble 4 summarizes the asymptotic worst-case complexities of the new compressed bit vector based algorithms presented in this paper. In addition, we also have implementations of the sort-merge and nested loop algorithms for performing equijoins and range joins. We observe that the sort-merge algorithm outperforms nested loop algorithm variants for all the queries studied in this paper, and hence we compare our new join algorithm only with the in-memory sort-merge al-gorithm. In future work, we will compare our algorithms to specialized join algorithms (such as indexed nested-loop join [13 ] and radix cluster join) that are tuned to answer particular classes of join queries efficiently.

We will mostly focus on joins involving two attributes in this section. The following are the key data parameters that determine the performance of our approaches: a) the num-ber of tuples in the input relations,  X  and  X  ; b) The at-tribute cardinalities  X   X  and  X   X  ; c) The range threshold pa-rameter  X  ; d) The join selectivity factor and the size of the result relation.
We use three sets of test data for our timing measure-ments: a synthetic data set with random integer values, a data set from a network traffic monitoring application, and a data set from the Sloan Digital Sky Survey. The syn-thetic data has random integers following the Zipf distribu-tions. We experiment with several different table sizes and attribute cardinalities using three Zipf exponents (0, 1, 2). The network traffic data is collected using an intrusion de-tection system called BRO 2 [15]. The network data used here is a small fraction of the data logs collected at a mid-sized research organization. It contains IP address informa-tion, port numbers, and timestamp information. The sky observations data was obtained from the Sloan Digital Sky Survey Data Release-1 3 and corresponds to three columns roughly of size 50 million tuples each.

All the tests were conducted on an Intel Core2 quad-core workstation running at 2.4 GHz. This system has 8 GB main memory and 4 MB of L2 cache. We built our codes with the GNU C compiler (version 4.2.4) and aggressive optimization enabled. We report wall-clock running time computed to a six-digit accuracy. Note that we perform in-memory joins on
Information about BRO is also available at http:// bro-ids.org .
SDSS SkyServer: http://skyserver.sdss.org/dr1/en/ sdss/release/ .
 Figure 4: Performance of the join count algorithm for queries on both real and synthetic data, corre-lated with the number of bit vector OR operations. all the data sets, and do not time the I/O accesses for load-ing the bitmap indexes. The running time is dominated by in-memory computation for the problem instances we tested on. We compare our approaches with the compute-time for an in-memory sort-merge join algorithm, and in both cases, an identical procedure can be followed to materialize the fi-nal join table after the result tuple list is determined. Our compressed bitmap-based algorithms are a replacement to existing range join approaches such as the sort-merge algo-rithm, and can be combined with other techniques to alle-viate the I/O time of materializing the join table.
Since the running times of the algorithms are highly query-dependent, we first correlate them with run-time perfor-mance counts that accurately model the performance. Con-sider first the cost of evaluating just the join count using Algorithm 4. Figure 4 plots the execution time for various queries. On the X-axis, we indicate the expected number of bit vector OR operations that have to be performed to expand the entire join result. We observe that the running times are linear correlated with this count, and these results are consistent with the worst-case bounds given in Table 4.
Next, we study performance of the cross-product based al-gorithms for different types of join queries and input datasets. The queries on the real data sets are self-joins on different attributes. We observe that the two parameters introduced Figure 5: Performance of range join queries on syn-thetic Zipf data. The numbers above the bars in-dicate the speedup achieved by CP On-the-fly over Sort-merge , and the X-axis labels indicate values of  X   X  and  X   X  X  X  X  X  X  X  respectively. in Section 3.3 ,  X   X  X  X  X  X  X  X  and  X   X  , capture variations in running time very effectively. As indicated in Table 4, the asymp-totic upper bound is achieved when these two parameters reach their highest values.

In Figure 5, we plot the average execution time of four dif-ferent range queries on synthetic data sets of different sizes. The values of  X   X  X  X  X  X  X  X  and  X   X  for each query are indicated as the X-axis label tuple. We report performance of two variants of the CP-FastJoinCount algorithm: Defer OR and On-the-fly . CP On-the-fly implicitly evaluates cross-product OR X  X  as they occur, while CP Defer OR applies ordering strategies and heuristics to defer OR computation to latter stages of the algorithm. We observe that in all four cases, CP On-the-fly outperforms the basic sort-merge join imple-mentation. The speedup varies from 60  X  (in the case of the query with the least  X   X  X  X  X  X  X  X  value) to 1.23  X  , with the selectivity factor being the third parameter influencing the performance. Also note that we do not explicitly produce a new result tuple list as output in the sort-merge algorithm, whereas the cross-product based relations compactly store the result in a bit matrix. Even with this work imbalance, it is remarkable that the performance of the cross-product based approaches is significantly better. As expected, when there are fewer OR computations (lower  X   X  X  X  X  X  X  X  values), the speedup is higher. We also observe that the running time of the Defer OR variant gets comparable to On-the-fly for larger values of  X   X  X  X  X  X  X  X  and  X   X  . Lower values indicates that there is comparatively lesser room for reordering and precomput-ing heuristics. Finally, for both the implementations, as the product of  X   X  X  X  X  X  X  X  and  X   X  increases, the running time goes up as well.

Figure 6 considers problem instances that are three orders of magnitude larger. In this case, we observe that the CP Defer OR is consistently faster than CP On-the-fly , and the reordering strategies pay off. We also observe that Defer OR outperforms Sort-merge for all the queries, with the speedup ranging from 1 . 37  X  to 44 . 7  X  . The queries are ordered in the increasing order of the join selectivity factor, starting with one that is  X  (  X  ). As expected from the theoretical analysis, the bitmap index based approaches are faster than Figure 6: Performance of equijoin queries on a syn-thetic data set of 10 million tuples. The numbers above the bars indicate the speedup achieved by CP defer-OR over Sort-merge , and the queries on X-axis are ordered in increasing join selectivity values.
 Figure 7: Average performance of join queries on the network data set. The numbers above the bars indicate the speedup achieved by CP defer-OR over Sort-merge , and three different query categories are indicated on the X-axis.
 Sort-merge for high join-selectivity queries.

Since CP-JoinCount is a lower bound on the execution time, we indicate the ratio of these two running times in the performance charts. This number gives us an estimate of the potential speedup that we can achieve in processing this query.

We next evaluate join performance on the network data (Figure 7), where the attributes have nearly 30 million tu-ples and varying column cardinalities. We report the av-erage performance of ten different queries falling in three categories: low join selectivity values, high  X   X  , and high join selectivity values. We plot the average running time of CP Defer OR and Sort-merge for these three cases, and observe that Defer OR is faster than Sort-merge for high  X  (similar to the results observed in Figure 5 ) and high join selectivity values (in accordance with results in Figure 6 ). Figure 8: Average speedup (logarithmic scale) achieved by CP-JoinCount over Sort-merge for various query instances.
 However, for the case of low join selectivity factor (in addi-tion to  X   X  X  X  X  X  X  X  ), the sort-merge algorithm is expectedly faster than the Defer OR variant. The observed performance is consistent with our theoretical analysis of the bounds. Note that we have not given the performance of sub-optimal ap-proaches such as BCP-EqJoin and the nested loop algorithm. These approaches only get competitive with the CP Defer OR algorithm for cases where  X  =  X  (  X   X   X  ), and in these scenario we already demonstrate a significant speedup over the Sort-merge algorithm.

In Figure 8, we summarize the speedup achieved by our in-dex based counting strategy (algorithm CP-JoinCount ) over the sort-merge algorithm for the various query instances dis-cussed previously. If we just need to determine the count of a join result, our approach is extremely fast and can result in a speedup up to three orders of magnitude in practice (for queries with high join selectivity factors). These speedup figures are also an indicator of the heuristic optimizations of our cross-product based approaches over the Sort-merge al-gorithm. For instance, the query class of low join selectivity factors may benefit from further reordering or deferred OR computation, as we obtain a speedup of 9 . 6  X  for a count-only query.
We present a set of new algorithms in this paper that uti-lize bitmap indexes efficiently to evaluate range joins. Our approaches are faster in practice than well-known algorithms such as sort-merge based approaches. With a combination of theoretical and empirical results, we attempt to charac-terize the join query and algorithm space, and reduce the performance gap between simple counting and full join re-sult expansion.

In future work, we will conduct a deeper theoretical study and experiment with other heuristics for the deferred OR computation join algorithm. Several algorithms discussed in this paper are amenable to parallelization, and it would be interesting to see what the bottlenecks to performance would be on current parallel systems. We also wish to extend our current prototype implementations of join algorithms to process large-scale partitioned datasets and more diverse query workloads.
This work was supported by the Director, Office of Sci-ence, of the U.S. Department of Energy under Contract No. DE-AC02-05CH11231. [1] G. Antoshenkov. Byte-aligned bitmap compression. [2] P. Bizarro and H. Madeira. The Dimension-Join: A [3] C.-Y. Chan and Y.E. Ioannidis. Bitmap index design [4] C.-Y. Chan and Y.E. Ioannidis. An efficient bitmap [5] D.J. DeWitt, J.F. Naughton, and D.A. Schneider. An [6] J. Gray et al. There goes the neighborhood: [7] T. Johnson. Performance measurements of compressed [8] N. Koudas. Space efficient bitmap indexing. In Proc. [9] N. Koudas and K.C. Sevcik. Size separation spatial [10] Z. Li and K.A. Ross. PERF join: an alternative to [11] P. Mishra and M.H. Eich. Join processing in relational [12] P. O X  X eil and G. Graefe. Multi-table joins through [13] P. O X  X eil and E. O X  X eil. Database: principles, [14] P. O X  X eil and D. Quass. Improved query performance [15] V. Paxson. Bro: A system for detecting network [16] R. Power. Large catalogue query performance in [17] T. Siqueira, R. Ciferri, V. Times, and C. Ciferri. [18] H.K.T. Wong, H.-F. Liu, F. Olken, D. Rotem, and [19] K. Wu, E.J. Otoo, and A. Shoshani. On the
