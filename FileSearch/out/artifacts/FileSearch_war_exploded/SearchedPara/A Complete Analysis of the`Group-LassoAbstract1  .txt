 Julia E. Vogt julia.vogt@unibas.ch Volker Roth volker.roth@unibas.ch In 1996, (Tibshirani, 1996) introduced the Lasso, an ` -constrained method for sparse variable selection. This method was extended by (Yuan &amp; Lin, 2006) and by (Turlach et al., 2005) to the problem where explanatory factors are represented as groups of vari-ables, leading to solutions that are sparse on the group Group-Lasso have been proposed: one uses the ` norm and the other one the ` tion. Many algorithms for the ` presented, see for instance (Yuan &amp; Lin, 2006; Meier or (Bach, 2008). Algorithms for the ` the Group-Lasso were studied in (Turlach et al., 2005; Schmidt &amp; Murphy, 2008; Quattoni et al., 2009) and (Vogt &amp; Roth, 2010). The mixed-norm regulariza-tion was elaborated in (Liu &amp; Ye, 2010) and (Zhang et al., 2010). In (Liu &amp; Ye, 2010), an ` Euclidean projection is presented and the optimiza-tion problem is solved through an accelerated gradient method. However, for large-scale problems with thou-sands of groups, this method is not efficient. In this work we derive conditions for the complete-ness and uniqueness of all ` 1 ,p Group-Lasso estimates, where a solution is complete , if it includes all groups these conditions it can easily be tested if a solution is complete, and all other groups that may be included in alternative solutions with identical costs can be identi-fied. We show the efficiency of this active set algorithm and we prove convergence to the global optimizer. Our main technical contribution in this work is three-fold: i) We present a unified characterization of solu-tions for all ` an efficient nesting of a constrained optimization prob-lem and a Lagrangian optimization problem. During optimization, we use a projected gradient method that works with the Lagrangian form of an optimization problem. However, the active set algorithm needs the constrained form of the problem. The efficient com-bination of these two optimization problems is not trivial, as finding the Lagrangian parameter can be slow convergence of the algorithm. We show that we can combine these two methods efficiently by using an interval bisection for finding the Lagrangian param-theoretic and algorithmic developments allow us to conduct large-scale comparison experiments between various different ` cus on multi-task (or transfer ) learning problems, in which the individual tasks are coupled via the group-structure of the constraint term. The underlying as-sumption here is that multiple tasks share a common sparsity pattern. Large-scale experiments reveal clear and statistical significant differences in the prediction performance of the different ` analysis shows a direct relation between norms with high p -values and increasing coupling strength of the Group-Lasso constraint. We consider the following setting of a generalized lin-ear model (see (McCullagh &amp; Nelder, 1983) for more details): given an i.i.d. data sample { x x i  X  R d , arranged as rows of the data matrix X , and a corresponding vector of responses y = ( y we want to minimize the negative log-likelihood where the exponential-familiy distribution f is the ran-dom component of a generalized linear model (GLM), The GLM is completed by introducing a systematic component  X  = x T  X  and a strictly monotone differen-tiable (canonical) link function specifying the relation-ship between the random and systematic components:  X  (  X  ) =  X  , where  X  = E  X  [ y ] is related to the natural pa-rameter  X  of the distribution f by  X  = b 0 (  X  ) =  X   X  1 ( From a technical perspective, an important property cient statistics y/ X  is one-dimensional and, therefore, minimal , which implies that the log partition function b (  X  ) / X  is strictly convex, see (Brown, 1986). For the be seen as a function in either  X  or  X  :  X   X  l (  X  ) =  X  X T  X   X  l (  X  ) =  X  X T ( y  X   X   X  1 ( X T For the following analysis, we partition X ,  X  and h :=  X  l is a strictly convex function in  X  . For general ma-in  X  if X has full rank and d  X  n . Given X and y , the Group-Lasso minimizes the negative log-likelihood viewed as a function in  X  under a constraint on the sum of the ` Here g (  X  ) is implicitly a function of the fixed param-eter  X  . Considering the unconstrained problem, the solution is not unique if the dimensionality exceeds n : every  X   X  =  X  0 +  X  with  X  being an element of the null space N ( X ) is also a solution. By defining the unique value  X  quire that the constraint is active i.e.  X  &lt;  X  though it might be infeasible to ensure this activeness by computing  X  cal algorithms will not suffer from this problem: given a solution, we can always check if the constraint was active. If this was not the case, then the uniqueness the solutions are usually not sparse, because the fea-ture selection mechanism has been switched off. To produce a sparse solution, one can then try smaller  X  -values until the constraint is active. We will restrict ( f &lt; +  X  ), i.e. l &gt;  X  X  X  . Technically this means that we require that the domain of l is R d , which implies that Slater X  X  condition holds.
 Theorem 2.1 If  X  &lt;  X  0 and X has maximum rank, P the solution is unique.
 Proof: Under the assumption l &gt;  X  X  X  a minimum of the region of feasible vectors  X  is compact. Since we assume that the constraint is active, any solution will lie on the boundary of the constraint region. It is easily seen that P J which implies that g (  X  ) is concave. Thus, the region d  X  n , the objective function l will be strictly convex, which implies that the minimum is unique.
 The Lagrangian for problem (6) reads For a given  X  &gt; 0, L (  X  , X  ) is a convex function in  X  The vector null-vector 0  X 
L (  X  , X  ). The subdifferential is  X   X  L (  X  , X  ) =  X   X  l (  X  ) +  X  v = X &gt;  X   X  l (  X  ) + 3 An Efficient Active-Set Algorithm 3 with v = ( v q =  X  and vice versa. Thus,  X  iff 0 Let d vector  X  holds that  X   X  k X T  X  = max it holds that  X  = k X T With these derivations we obtain results analogous that an algorithm has found a solution the set of  X  X ctive X  groups A := { j : A = B = { j : k other solution with an active set A 0 with |A 0 | &gt; |A| Thus, A = B implies that the solution is complete. Otherwise, the additional elements in B which are not contained in A define all possible groups that poten-tially become active in alternative solutions. However, A might still contain redundant groups. There exists a simple test procedure for uniqueness under a further rank assumption of the data matrix X (Roth &amp; Fis-cher): If every n  X  n submatrix of X has full rank, A denotes the active set corresponding to some solution b  X  of (6) and X A denotes the n  X  s submatrix of X composed of all active groups. Then, if A is complete and if s  X  n , shows a graphical representation of different ` The characterization of the optimal solution presented in section 2 allows us to construct an active set algo-rithm to solve the constrained optimization problem (6) for all ` groups are selected or removed, depending on the vio-lation of the Lagrangian condition. The algorithm is a straightforward generalization of the subset algorithm for the standard Lasso problem presented in (Osborne et al., 2000). The main idea is to find a small set of active groups. The optimization in step B can be per-A : Set A = j B : Optimize over the current active set A .
 Define set A + = n j  X  X  :  X  Define  X  = max C : Lagrangianviolation :  X  j /  X  X  , check if k h  X  . If this is the case, we have found a global solution. Otherwise, include the group with the largest violation to A and go to B .
 D: Check for completeness and uniqueness. formed by the projected gradient method (Bertsekas, 1995). The main challenge typically is to compute ef-ficient projections onto the ` a hard to solve nonlinear optimization problem with nonlinear and even non-differentiable constraints. For the ` algorithm for the projection to the ` projection to the ` by the method introduced in (Quattoni et al., 2009). The ` jection to the ` ` the main idea in the projected gradient method is that one does not optimize problem (6) directly but solves a subproblem with quadratic cost instead. First, we take a step s  X  step size s and obtain the vector b =  X   X  s  X  then project b on the convex feasible region to obtain a feasible vector. Hence, the minimization problem we need to solve now reads with Lagrangian multiplier  X  . Algorithm 2 shows the projection for all ` Convergence of Interval Bisection. It remains to show that the interval bisection within Algorithm 2 converges. This is our main technical contribution in this work: the efficient combination of a constrained problem with the Lagrangian form of an optimization problem. The projection algorithm proposed in (Liu &amp; Ye, 2010) needs the Lagrangian representation of the problem while we work with the constrained form in the active set algorithm. The combination of these two 4 Multi-Task Applications 4 B1 : Gradient : At time t  X  1, set b =  X  t  X  1  X  s  X  where s is the step size parameter.
 Initialize Lagrangian multiplier  X  within the interval (0 B2 : Projection : For all j  X  X  + minimize (11): While Compute projection as in (Liu &amp; Ye, 2010), obtain optimal  X   X  Lagrangian multiplier  X  via interval bisection. B3 : New solution :  X  j  X  X  + , set  X  t j =  X   X  j optimization problems is not trivial, as finding the ap-propriate Lagrangian multiplier  X  could be arbitrarily sensitive to the step length s what leads to extremely slow convergence of the algorithm. Our contribution is to show that we can combine these two methods by using an interval bisection for finding the Lagrangian parameter  X  that is guaranteed to converge rapidly. Theorem 3.1 The interval bisection in Algorithm 2 is guaranteed to converge.
 To prove Theorem 3.1, we need the following Lemma: Lemma 3.2 For two Lagrangian functions with con-vex likelihood function f (  X  ) L (  X  , X  L (  X  , X  it holds that:  X  1 &lt;  X  2  X  X  X   X  2 &lt;  X  1 . The proof of Lemma 3.2 is done via perturbation and or (Bertsekas, 1995) for more details) and is presented in the supplementary material. Now we can prove The-orem 3.1: Proof: Let  X  g (  X  ) :=  X  (  X  ) := arg min grangian function L (  X  , X  ) as defined in Lemma 3.2. Then we get with Lemma 3.2 and because we know that the solution lies on the boundary of the feasible set for  X   X  g (  X  1 ) = tinuous function in the interval [0 , X   X  tails about  X  holds that  X  g (0) = P J we assume that the constraint is active) and  X  g ( Theorem 1). According to the Intermediate Value Theorem,  X  g (  X  ) has a unique root in (0 , X  the interval bisection converges.
 After each iteration of the bisection method, the bounds containing the root decrease by a factor of two. As the interval bisection is guaranteed to converge, we know that we will achieve a given tolerance in the so-lution in a logarithmic number of iterations (see e.g. (Press et al., 2007) for more details). The convergence of the active set algorithm follows immediately: if the solution is not optimal, the solution of the augmented system will be a descent direction for the augmented problem and also for the whole problem, as primal fea-sibility is maintained and the constraint qualifications are fulfilled. This implies that the algorithm as a whole must converge. With these theoretical results we are now able to efficiently combine the active set algorithm with the projection algorithm for all p -norms. By us-now look at the prediction performance of all p -norms for large scale experiments with thousands of features. large number of tasks. In transfer or multi-task learn-ing, we want to improve the generalization ability and the predictive power by solving many learning prob-amount of data that is jointly given by all tasks and hence yield better results than examining every task individually. The motivation for using the Group-vidual tasks via the group structure of the constraint term, based on the assumption that multiple tasks share a common sparsity pattern. Due to our efficient sets with thousands of features in reasonable time. Coupling strength of ` p norms. The coupling properties of the different p norms have a major influ-ence on the prediction performance of the Group-Lasso variants. The higher the value of p , the stronger the different tasks are coupled. For p = 1, the tasks within one group are barely coupled, as the ` only induces a global coupling over all tasks. For p = 2 there exists an intermediate coupling of tasks within a group and for p =  X  the coupling of the tasks is 4 Multi-Task Applications 5 very strong. This is due to the fact that the `  X  norm only penalizes the maximum absolute entry of a group, meaning we can increase all other parameters in this group to the maximum value without changing the constraint. Hence we can assign maximum weight to pling strength and value of p is illustrated in Figure 2 and Figure 3. Synthetic Experiments. The synthetic data for a classification problem was created in the following way: we consider a multi-task setting with m tasks and d features ( B = [  X  for the i -th task. Further, assume we have a data set D = ( z where Z is the set of tuples ( x where each x a label that specifies to which of the m tasks the exam-ple belongs to and y class label. First, we generated the parameter matrix B by sampling each entry from a normal distribution N (0 , 1). We selected 2% of the features to be the set V of relevant features and zeroed the other entries. We ran four rounds of experiments where we changed the shared sparsity pattern across the different tasks. In the first round all tasks have exactly the same spar-sity pattern, just the values of  X  ond experiment, the tasks share 75% of the sparsity pattern, in the third experiment 50% and in the last experiment only 30%. For the training set, we sam-pled n -times a d  X  m matrix, where each entry of the matrix was sampled from the normal distribution N (0 , 1). The corresponding labels y  X  R nm are com-puted by y k = 1 ,...,m . The test data was obtained by splitting the training data in three parts and keeping 1 / 3 as an  X  X ut-of-bag X  set. We fixed the number of tasks m to 50, the number of features d to 500 and the number of examples n per task to 200. We compared different approaches to solve the multi-task learning problem. One approach is to pool the data, i.e. combine all tasks to one  X  X ig X  task. Then we conducted single-task learning on every task sep-arately, and we compared different ` methods where we used the same active set algorithm, the only difference lying in the projection step. The statistical significance was tested with the Kruskal-Wallis rank-sum test for multiple testing correction and the Dunn post test with Bonferroni correction. 5 Efficiency of the Algorithm 6 Figure 4 shows the result for the data set with 100% shared sparsity pattern. One can see that the pooled data performs worst and that single-task learning per-forms almost exactly the same as the ` As the ` not surprising. We perceive that single-task learning is significantly worse than multi-task learning. Between all Group-Lasso methods there is no statistical signif-icant difference. As we have exactly the same sparsity pattern in every task, even the very strong coupling of the ` In Figure 5 the results for 75% shared sparsity pattern are plotted. As in the experiment with the same spar-sity pattern, pooling the data is worst and multi-task learning outperforms single-task learning. Here we can see that the strong coupling of the ` worse result than in the experiment before, because the sparsity pattern is not exactly the same across the different tasks anymore. There is no significant differ-ence between the ` further reducing the joint sparsity pattern we observe that the very tight coupling of the ` to even worse results than single-task learning and we see a statistical significant advantage of the weak cou-pling norms ` case the weak coupling norm ` vantage and the strong coupling norms ` are even worse than single-task learning. These results are demonstrated in Figure 7. In all experiments, there is not one single case where the strong coupling ` norm performs better than the weak coupling regular-izations. There exists a convincing explanation for the better performance of the weak coupling variants: the different tasks are connected with each other only over the constraint term. If the tasks do not share exactly the same sparsity pattern, i.e. if the model assump-tions are violated, this strong coupling is sensitive to model mismatches. The ` too strong. For all values of p with 1  X  p  X   X  , val-between no coupling and very strong coupling. We show the efficiency of our active set algorithm by comparing the run time of our method with the ` To our knowledge, this is the only existing method that can compute Group-Lasso solutions for all ` norms. We created synthetic data in the same way as explained in section 4 and compared the run time of our algorithm and the algorithm proposed by (Liu The code for ((Liu &amp; Ye, 2010)) X  X  method is publicly lines show the run time for our proposed active set al-gorithm. We plotted the run time for the ` ` can see that our active set method is by far faster if the data set contains many groups. The steep increase in tween 10000 and 20000 groups is due to numerical problems that arise in their optimizer by having more than 10000 groups. This comparison shows the huge advantage of using an active set method. If the solu-tion is sparse, not all groups are selected, but only the active ones, and the active set algorithm only has to optimize over the active set, but not over the set of all possible groups. The first real-world data set we looked at is a prostate tensity images from microarrays. The RMA normal-ization was used to produce gene expression values 7 Conclusion 7 from these images. The second data set from (Welsh et al., 2001) is already in the form of gene expression values. Although the collection techniques for both data sets were different, they share 12600 genes which are used as features in this experiment. We used the same experimental setup as in (Zhang et al., 2010), i.e. we used 70% of each task as training set. Simi-lar to the synthetic experiments we compared different approaches to solve the classification problem. The re-sults of 20 cross-validation splits are shown in Figure 9 where we compared the prediction performance of the pooled data set, the ` regularization and we compared all these multi-task learning methods with single-task learning ` ing the data yielded as bad results as in the synthetic experiments. As in the synthetic experiments, the ` ods perform significantly better than single-task learn-the Kruskal-Wallis rank-sum test and the Dunn post test with Bonferroni correction. Even with only two cantly worse than multi-task learning.
 MovieLens Data Set In a second real world exper-iment, we applied different Group-Lasso methods on ratings for 1682 movies from 943 users. The genre in-ratings of the users are in five-point scale (1, 2, 3, 4, 5). Every user defines a task, hence we have 943 tasks and 19 features, as we have the information about 19 movie genres. Similar as above, we compared dif-ferent approaches to solve the learning problem. We conducted single-task learning and looked at different ` icant advantage of multi-task learning over single-task learning. Among the Group-Lasso methods, the very strong coupling of the ` sult. Between ` significant advantages over all other methods. Figure 10 shows the results for the MovieLens data set, here we plotted single-task learning ` the ` learning is significantly worse than multi-task learning and that the weak-and intermediate-coupling norms outperform the strong coupling norms. We have presented a unified characterization and a highly efficient active set algorithm for all ` of the Group-Lasso. With these results, we were REFERENCES 8 able to compare Group-Lasso methods for different p -norms in large-scale experiments. To summarize, side, we characterized conditions for solutions for all ` gorithm that is applicable for all ` methods. The main theoretical contribution consists section used to combine a constrained optimization problem and the Lagrangian form of an optimization problem in the inner optimization loop what leads to a fast update scheme. (iii) On the experimental side we compared the prediction performance of different Group-Lasso variants and demonstrated the computa-tional efficiency of our method compared to an existing tasks are coupled via a Group-Lasso constraint, we examined the prediction performance of all ` ants. We compared the different methods on synthetic data as well as on two real-world data sets.
 The prediction performance of the different Group-Lasso methods depends both on the coupling strength of the corresponding ` differences between the tasks. Our experiments indi-p norms with p 2 and the too loose coupling of the low-p norms with p 2 significantly degrade the prediction performance. The weak-coupling norms for p  X  [1 . 5 , 2] seem to be the best compromise between coupling strength and robustness against systematic differences between the tasks.
 Argyriou, A., Evgeniou, T., and Pontil, M. Multi-task feature learning. In Advances in Neural Information Processing Systems 19 . MIT Press, 2007.
 Bach, F. Consistency of the group Lasso and multiple kernel learning. JMLR , 9:1179 X 1225, 2008.
 Bertsekas, D. P. Nonlinear programming . Athena Sci-entic, 1995.
 Brown, L. D. Fundamentals of statistical exponential families: with applications in statistical decision the-ory . Institute of Mathematical Statistics, Hayworth, CA, USA, 1986. ISBN 0-940-60010-2.
 Forst, W. and Hoffmann, D. Optimization -Theory and Practice . Springer, 2010.
 Kim, Y., Kim, J., and Kim, Y. Blockwise sparse re-gression. Statistica Sinica , 16:375 X 390, 2006. Liu, J. and Ye, J. Efficient ` Technical report, 2010.
 McCullagh, P. and Nelder, J.A. Generalized Linear Models . Chapman &amp; Hall, 1983.
 Group Lasso for Logistic Regression. J. Roy. Stat. Soc. B , 70(1):53 X 71, 2008.
 Osborne, M., Presnell, B., and Turlach, B. On the
LASSO and its dual. J. Comp. and Graphical Statis-tics , 9(2):319 X 337, 2000.
 Press, W. H., Teukolsky, S. A., Vetterling, W.T., and
Flannery, B.P. NUMERICAL RECIPES. The Art of Scientific Computing , volume third edition. Cam-bridge University Press, 2007.
 Quattoni, A., Carreras, X., Collins, M., and Darrell, T.
An efficient projection for l Intern. Conference on Machine Learning, 2009. Roth, Volker and Fischer, Bernd. The Group-Lasso for generalized linear models: uniqueness of solutions and efficient algorithms. In ICML  X 08 , pp. 848 X 855. Schmidt, M. and Murphy, K. Structure learning in random fields for heart motion abnormality detec-tion. In In CVPR , 2008.
 Singh, D., PG., Febbo, K., Ross, DG., Jackson, J., Manola, C., Ladd, P., Tamayo, AA., Renshaw, D X  X mico, JP, Richie, ES, Lander, M, Loda, and
Kantoff PW, Golub TR, Sellers WR. Gene expres-sion correlates of clinical prostate cancer behavior. Cancer Cell , 1(2):203 X 209, March 2002.
 Tibshirani, R. Regression shrinkage and selection via the Lasso. J. Roy. Stat. Soc. B , 58(1):267 X 288, 1996. Turlach, B. A., Venables, W. N., and Wright, S. J.
Simultaneous variable selection. Technometrics , 47 (349-363), 2005.
 Vogt, J. E. and Roth, V. The Group-Lasso: ` ularization versus ` 2010 , pp. 252 X 261. Springer, 2010.
 Welsh, J. B., Sapinoso, L. M., Su, A. I., Wang-Rodriguez, S. G. Kernand J., Moskaluk, C. A., Jr.,
H. F. Frierson, and Hampton, G. M. Analysis of gene expression identifies candidate markers and pharmacological targets in prostate cancer. Cancer Research , 61(16):5974 :5978, August 2001.
 Yuan, M. and Lin, Y. Model selection and estimation in regression with grouped variables. J. Roy. Stat. Soc. B , pp. 49 X 67, 2006.
 Zhang, Y., Yeung, D., and Xu, Q. Probabilistic multi-task feature selection. NIPS, 2010. c  X 
