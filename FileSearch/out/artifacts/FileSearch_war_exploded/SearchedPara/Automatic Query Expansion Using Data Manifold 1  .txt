 performance [1, 2, 4, 7] in information retrieval (IR). Many methods have been clustering, statistical factor analysis, and document re-ranking [3, 8, 9]. 
In this paper, we propose a method for automatic query expansion that combines document re-ranking (DR) with Rocchio X  X  classical formula. We first reorder the positions of top initially retrieved documents, and then use standard Rocchio X  X  relevance feedback to do query expansion. 
The document re-ranking method using the intrinsic manifold structure of data is derived from semi-supervised learning [10]. The ranking problem is viewed as a special case of semi-supervised learning, in which only positive documents (e.g., query itself) are available while negative documents (irrelevant documents) are missing. 
This algorithm first form a weighted network on data, and assign a positive ranking score to each relevant documents and zero to the remaining documents that are to be achieved, and all documents are ranked according to their final ranking scores. 
The rest of this paper is organized as the following. In Section 2, we describe the re-ranking algorithm and automatic query expansion method in detail. Section 3 will give out the experimental results. Finally we present the conclusion in Section 4. 2.1 Document Re-ranking Given a query q and M ranked retrieved documents acquired from the initial retrieval, since we do not know the exact relevant documents, we simply pick top R ones as the pseudo relevant documents (query q itself is always considered as one pseudo relevant document). As a result, document re-ranking can be achieved by ranking the M documents supervised algorithm as shown in Figure 1. 
Following are some notations for the document reranking algorithm: o q : the query o { r j } (1  X  j  X  R ): the R pseudo relevant documents o { m j } (1  X  j  X  M ): the initial M retrieved documents to be re-ranked { m j } (1  X  j  X  M ) to be re-ranked. documents, then we can assign different ranking scores to the relevant documents proportional to their respective confidences. document, and y i = 0 otherwise. 
In the document re-ranking algorithm, the manifold structure in X is represented as order, and then repeat connecting the two documents with an edge according the order until a connected graph is obtained. 
The ranking scores of any vertex in the graph are spread to nearby vertices through weighted edges until a global stable state is achieved. Here, each vertex corresponds to a document, and the edge between any two documents x i and x j is weighted by w ij D the i-th row of W . Input: q : query; M : the set/the number of retrieved documents to be re-ranked; R : the set/the number of pseudo relevant documents; Algorithm: DocumentReranking( q, M, R) BEGIN ranked first). END scores from neighbors and the initial ranking scores. 
This algorithm has been shown to converge to a closed form points directly if the data scale is not very large. 2.2 Automatic Query Expansion After document re-ranking, we use Rocchio X  X  retrieval feedback [5], as improved by documents retrieved and that the information about the non-relevant documents is absent, Rocchio X  X  formula adapted to the retrieval feedback setting becomes: and w t,k are the weights of term t in the unexpanded query and in the pseudo-relevant documents, respectively, according to a weighting scheme applied to the whole collection. We used the NTCIR-3 CLIR Chinese SLIR subcollection as test data and the 42 D-run query topics as queries. We used the closed form expression (2), where parameter  X  space model as retrieval model. 
We used the NTCIR X  X  relaxed relevance judgment and rigid relevance judgment to measure the precision of retrieved documents. Relaxed relevance judgments consider highly relevant, relevant, and partially relevant documents, while rigid relevance judgments only consider highly relevant and relevant documents. We used Mean Average Precision (MAP) to measure the overall retrieval performance. 
The first experiment tested the effectiveness of the ranking algorithm using only the query itself as pseudo relevant document ( R =1). Table 2 lists the MAP values for re-indicates the number of top documents to be re-ranked, INI refers to the initial retrieval MAP(relaxed)/MAP(rigid) represent MAP values on relaxed /rigid relevance measure. From Table 1, we can see that document re-ranking improves MAP(rigid) and MAP(relaxed) by 9.8%-16.1% and 10.4%-12.9% respectively. We also conducted the paired t-tests. Table 1 lists their significance marks for each re-ranking setting. In the following, * correspond to p-values less or equal 0.05, which means significant MAP(rigid) and MAP(relaxed). This implies that the re-ranking can improve the performance of top retrieved documents significantly. 
From the closed form expression (2), we can see that the re-ranking of the used for the new relevant document sets. In the experiment, we simply considered top 10 documents as pseudo relevant documents and used them for re-ranking. Table 2 the new pseudo relevant document set. 
From Table 2, we can see that incorporation of top 10 documents as pseudo relevant document. This implies that initial retrieval helps the pure manifold-based re-ranking. 
To see whether the MAP improvement against the original query q as pseudo see that the improvement against the original query as pseudo relevant document was significant in most cases, especially when more documents were used for re-ranking. 
Now that document re-ranking can improve the performance of initial search, it should help query expansion. To confirm it, we combined the re-ranking with documents, and then applied standard Rocchio X  X  relevance feedback on re-ranked top documents. In the experiment, we sel ected 200 bi-grams from the top N ( N =15, 20, 25 or 30) retrieved documents to do query expansion. 
Table 3 gives the MAP values for standard QE (Rocchio) and extended QE (re-ranking + Rocchio), where the first column indicate the number of the top documents used for query expansion. N=15 0.2196 +30.1% 0.2836 +29.1% 0.2491 +47.6%* 0.3118 +41.9%* N=20 0.2229 +32.0% 0.2853 +29.9% 0.2513 +48.9%* 0.3127 +43%* N=25 0.2216 +31.3% 0.2843 +29.4% 0.2520 +49.3%* 0.3166 +44.1%* N=30 0.2208 +30.8% 0.2839 +29.2% 0.2518 +49.2%* 0.3157 +43.7%* 
From Table 3, we can see that using Rocchio X  X  standard QE improved MAPs by 29.1%-32% against initial search, while using extended QE achieved better results with improvement by 41.9%-49.3%. This indicates that the re-ranking helps query expansion to improve the performance. 
To see whether the MAP difference between extended QE and standard QE is significant, Table 3 also lists the significance marks, which suggests that extended QE significantly outperforms standard QE. To further check the effectiveness of extended QE, we compare our method with Mitra X  X  query expansion [4], which uses Maximal Marginal Relevance module to expansion. Table 4 gives the MAP values for Mitra X  X  method and extended QE, where comparable results than Mitra X  X  method; when M is larger ( M &gt;=40), our method gets better results. M=30 0.2378 +40.8% 0.3011 +37.1% 0.2376 +40.7% ~ 0.3004 +36.8% ~ M=40 0.2341 +38.6% 0.2989 +36.0% 0.2479 +46.9%* 0.3098 +41.0%* 
M=50 0.2315 +37.1% 0.2937 +33.6% 0.2501 +48.2%* 0.3133 +42.6%* In this paper, we propose an automatic query expansion method that combines document re-ranking and standard Rocchio X  X  relevance feedback. The document re-ranking method is based on semi-supervised learning algorithm, which integrates top retrieved documents with the query in learning process by representing them as vertices in a weighted graph and iteratively propagating the ranking information from any vertex to nearby vertices until this process converges. 
Our analysis and experimental results demonstrates the potential of this manifold significant improvement over standard Rocchio X  X  relevance feedback, and the re-ranking method itself gets significant improvement against the initial retrieval. 
