 Our life and work are facilitated by the Web-based applications such as online stores and brokerage, human resource applications, and supply-chain management systems. The performance and availability of these Web-based systems play a very important role in the operation of an organization. However, the performance of a Web system depends heavily on appropriate configuration. Tuning a Web system means to find the correct parameter settings under the specified conditions. In general, there are dozens or even hundreds of tunable parameters in just one tier of a Web system. How to get the server's appropriate configuration is very difficult for a layman. With different hardware conditions and complex applications deployed, tuning can be the tough work even for the most experienced Web system administrators. For example, a BEA Weblogic server may have 30 tunable parameters, and in different hardware condi-tions, the response time bottleneck of the system may be caused by different bad tuned parameters. On the other hand, the application to be deployed may have dissimilar types, such as CPU-intensive or memory-intensive, which induce inequable parameter settings. 
Most recently, with the fast development of Web 2.0[12], the concept of "blogging and the wisdom of crowds" is well known by common people. Nowadays, "dynamic websites" (i.e., database-backed sites with dynamically generated content) replaced static Web pages, which produces more pr essure on Web system. Many personal homepages and small-middle scale web site s providing Web 2.0 services are emerg-ing. Most of them are deployed on open-source Web servers, such as Tomcat, JBoss, Apache and etc. There is a lack of detailed documentations and technical support staffs for open-source Web servers. Faced with dozens of tunable parameters, a con-fused Web master doesn't know how to get started. Therefore, how to efficiently get the appropriate configuration for the Web system parameters has become a major concern in the age of Web 2.0. 
There are many drawbacks in existing Web system tuning approaches. On one hand, a Web system may have a hundred parameters that can be modified. Previous approaches choose two or three important parameters for tuning [11, 14], but they do not tell how to find out these important parameters among the hundreds parameters. When the number of parameters is large, the tuning approaches become unfeasible. On the other hand, some of the previous approaches focus on only one type of Web system software such as Apache, and they are not the all-purpose ways for perform-ance tuning [15]. 
Our work focuses on how to find the most important parameters of a Web system, ture selection method based on Information Gain criterion to find the parameters that affect system performance dramatically. Comparing to previous approaches, we can get the following advantages: Firstly, we solve the tuning problem when the number of parameters is large. If the number of pa rameters is reduced to be acceptable, many mature approaches can be used for tuning. So, our method paves the way for the next tuning steps. Secondly, little domain knowledge is needed during the tuning, for the selection approach is based on sampling data and train set. Thirdly, our approach can quickly find the most important parameters without the limitation of the application deployed or running environment. Finally, the approach can be applied to all kinds of Web system, so it is an all-purpose tuning method. 
The rest of the paper is organized as follows. Section 2 introduces the related work on Web system performance tuning. Section 3 presents the feature selection based method for finding the most important parameters. Section 4 presents the tuning methodology based on feature selection. Section 5 provides experimental results on different application deployed and on different Web servers. Finally we present con-cluding remarks and future work in Section 6. There have has some previous work on the performance tuning of Web system. We can classify the existing approaches of parameter tuning for Web system into two categories: model-based approach and experiment-based approach. 2.1 Model-Based Approach In this approach, an analytical model is built to predict and validate the performance of a Web system. There are some sophisticated mathematics models for system analyzing such as queuing system and control theory. The queue model is a widely used concep-tual framework in which computing systems are viewed as networks of queues and servers. It has been proven quite effective at modeling the steady-state behavior of the best combination of configuration parameters. Bhuvan Urgaonkar et al. [13] ana-lyze the architecture and request processing method in multi-tier Internet services, and methodology is described to determine the optimal concurrency level of an application server. A simple benchmarking application is used to derive a queue model of the server, which is strictly related to the design pattern of the running application as well as the application server implementation. Besides, the control theory is also well stud-ied and applied to many server tuning approaches. In [1], [9] and [15], the Web system is treated as a black box, thus the complexity of tuning is reduced. Gandhi et al. [6] use feedback control theory to model the Apache server, and the experiments shows that the model is efficient within the appropriate workload regions. 
These model-based approaches give some good solutions to the tuning and predic-tion of server performance. However, these studies may simplify actual systems too much despite the fact that today X  X  Web systems are quite complex. Moreover, build-ing these models needs detailed knowledge of server X  X  internal structure. Some online the models do not include the part of server X  X  hardware and do not consider the type of the application deployed, which may make a great contribution to the overall per-formance of the system. 2.2 Experiment-Based Approach In this approach, the Web system tuning problem is viewed as mathematical optimiza-tion problem and some heuristic search techniques are used to discover proper set-tings of parameters. Chung et al. [3] adjust the tunable parameters based on the ob-served performance results to improve the overall system performance. In [14], a Smart Hill-Climbing algorithm is proposed using the ideas of importance sampling and Latin Hypercube Sampling. The algorithm is tested using an online brokerage application running in a WebSphere environment, and the result shows that the algo-rithm is superior to traditional heuristic methods. In [11], the Quick Optimization via Guessing algorithm is proposed, which quickly selects one of nearly best configura-tions with high probability. 
While the proposed experiment-based approaches do not need much knowledge about target parameters and internal server states, they have some limitations. Firstly, these approaches need many experiments to collect sample data, and cost quite a long time to find the optimal values. Secondly, most of these approaches focus on tuning one or two key parameters on a certain Web system. They do not explain why these two parameters are more important than others. Moreover, there may be dozens of tunable parameters in one server, and finding the influential parameters may be a domain knowledge concerned approach. 
In the next section, we propose a feature selection based method to find the most important parameters. Our method can be the pre-step of many mature experiment-based tuning approaches and solve the tuning problem when the number of parame-ters is large. 3.1 Key Parameters There may be dozens of parameters that can be modified in one Web system, but in a certain running environment, only some of these parameters significantly affect server performance. Here we give the brief description of the key parameters. 
Assuming that the server parameter set is P , and Web system performance is a most influential parameters of a Web system. When P is large, it is a time-consuming task to get the appropriate configuration of all tunable parameters in P . However, we To confirm the effectiveness of key parameters, we measured the performance of the Apache Web server using a Web benchmark (for experiment setting details, refer to Sect. 5). Figure 1 plots the server average response time for different Threads-PerChild and Timeout settings. 
We can see that ThreadsPerChild dramatically affects server performance. In Figure 1(a), when ThreadsPerChild is set to 300, with workload 300, the response time de-grade down to 16.3% compared to the value of ThreadsPerChild 100. With the work-compared to the value of ThreadsPerChild 100. However, Figure 1(b) shows that server performance does not change much according to Timeout settings. So, in this running environment, ThreadsPerChild is the key parameter. The system performance can be quickly improved by just tuning one parameter ThreadsPerChild . However, we can pick out ThreadsPerChild from others because it is a well-known influential parameter in performance tuning of Apache. In many other Web systems, the key pa-rameters may change according to the type of application deployed and hardware con-ditions. In next section, we proposed an all-purpose key parameters searching method based on feature selection. With little domain knowledge, the method can quickly find out which parameters are important under certain circumstances. 3.2 Searching Key Parameter Based on Feature Selection Feature selection reduces the data set size by removing irrelevant or redundant fea-resulting probability distribution of the data classes is as close as possible to the origi-F }, n denotes the size of the feature set. A feature subset can be depicted by a binary evaluation function for the feature set F , so the feature selection is to find the optimal value of the expression: max E ( S ). 
The performance of a Web server can be recognized as the function of tunable parameters, and different parameters have different weights to affect the system per-formance. By feature selection method, we can pick out the most important parame-ters from the others, therefore, the tuning approach can be simplified and the cost for finding the optimal parameter configuration can be reduced dramatically. 
Basically, feature selection methods fall into three categories [7]: filter, wrapper, embedded. Among these categories, filter is the most comprehensively-studied meth-ods, and it can be independent from learning. Therefore, we use filter feature selection algorithm for searching key parameters of the Web system. We define the parameters settings of the Web system as the feature set F ( F 1 , F , ..., F n ), and size of the set n denotes n tunable parameters, in which there are key parameters. The general approach for searching these key parameters is shown in Figure 2. In Figure 2, the function Gen( F ) gets the feature subset S according to gen-eration algorithm. The evaluation function Eva ( S , F ) checks the goodness of subset S , and returns  X  . There is a loop to find the best S until the stopping criterion is reached. 
The critical problems in this key parameters searching algorithm (KPSA) are dis-cussed as follows: Subset generation: The subset selection includes search direction and search strat-egy. For search direction, there are Fo rward Generation, Backward Generation and Random Generation [4]. Since there may be dozens of features (i.e. tunable parame-ters), forward direction is the appropriate way of generating subset. The procedure starts from an empty set. As the search starts, parameters are added one at a time. At each iteration, the best parameter among unselected ones is chosen based on the evaluation function. The subset grows until the stopping criterion is reached. For search strategy, a complete evaluation of the 2 N subsets is impractical. So, in our key parameters searching algorithm, we use a kind of depth-first search method guided by search space is only quadratic in terms of the number of parameters. Evaluation function: Feature selection can be seen as an optimization problem, and and which feature is redundant. We use information theory to evaluate the features. In portant parameter for performance tuning. The Information Gain [2] of the feature F in sample dataset D is defined as: The Info ( D ) is the entropy of the sample, which is defined as: where p i is the probability that an arbitrary tuple in D belongs to class C i and is esti-represents the total number of the sample. According to service-level agreement (SLA) or user defined response time and throughput criteria, the sample dataset D can be classified into two categories: acceptabl e and unacceptable. So in our algorithm, m equals 2. Assume that feature F has v distinct values, and in Formula (3), Info F ( D ) is defined as: feature F . Info ( D j ) can be defined as: where p ij denotes the probability that a tuple in j th partition belongs to class C i . With parameters.
 Stopping criterion: Without a suitable stopping criterion the feature selection proc-ess may run exhaustively or forever through the space of subsets. The more parame-ters the algorithm produces, the more complex the tuning task is. Therefore, we can search is stopped. Also, we can define the stopping criterion as a predefined number of features that are selected. 
According to what we have discussed above, we proposed the key parameters searching algorithm (KPSA). The KPSA is effective in acquiring the most important parameters. In the next section, we discussed how to tune a Web system using KPSA. The KPSA can efficiently reduce the Web system configuration space, and pave the way for the next tuning steps. We propose a general Web system tuning methodology, which includes the entire process of parameter configuration (see Fig.3). Fig.3. depicts several steps of tuning a Web system. 1) Collect the tunable parameter list of a Web system, and usually, this can be 2) For each configuration parameter, select a reasonable range. The range may 3) Use benchmarks to test the system performance and record the response time 4) Based on result dataset, use KPSA to find the key parameters. 5) KPSA reduces the parameter configuration space, and with key parameters, the 
Our methodology has some outstanding advantages. Firstly, if there are a lot of tunable parameters, the experiment based tuning is a time-consuming task. Using key parameters, the further tuning method can get the result with less test runs. Secondly, different from some parameter specified method, our methodology is not related to the design pattern of running application as well as the server implementation. Thirdly, our methodology uses little domain knowledge, and it is especially useful for some open source web systems with few tuning guidelines. In this section, we test our method on different Web systems. We will first use KPSA to find the key parameters on different kinds of Web servers and application servers. Then, we will compare the key parameters on one same server with different kinds of application deployed. Finally, we will present how KPSA can reduce the time cost of experiment-based Web system tuning approaches. 
Our test Web system consisted of a Web server, an application server, a database server and a workload generating server. Each node is equipped with two Pentium Xeon 2.8 GHz CPUs, 2 GB memory running on Windows 2000 SP4. All of these were interconnected by a single switch via a 1000 Base-T Ethernet. Oracle 9i (patch 9.2.0.6) is chosen for database server. 
We deploy an online transaction processing application on our test bed Web sys-tem, which uses different kinds of Web server and application server. The workload generating server uses JMeter to simulate 300 clients concurrent access. Firstly, fol-lowed our feature selection based tuning methodology, we list the tunable parameters. Then, we set the range from 50% to 300% of the parameter X  X  default value. Thirdly, we use the workload generating server to take the performance benchmark, and for one kind of server, the test runs 100 times. For each run, parameter configurations are generated by a random function within the range. In one result dataset, the tuple con-tains parameter values and response time. We classify the dataset into two categories according to whether the response time is acceptable. Finally, we employ the KPSA to find the key parameters, and the result is shown is Table 1. 
In the test bed, Apache works as the Web server, and Weblogic, Websphere, JBoss and Tomcat work as application server. The KPSA pick out two from eight and fif-teen with Apache and Weblogic respectively. With high workload, the OLTP Web system performance bottleneck is most likely to be caused by server X  X  receiving re-maximum number of clients connecting to the server at the same time. The KPSA picks out the ThreadsPerChild validates that our algorithm can effectively find the parameters which affect the system performance dramatically. 
With different type of applications deployed, the key parameters in one server may be different. The table 2 compares key parameters found by KPSA when different type of applications is deployed on Weblogic. 
We test an EJB-based application for online graphics processing on Weblogic. Ta-ble 2 shows that our algorithm can pick ou t key parameters when different applica-tions are deployed. 
The key parameters pave the way for the next step experiment-based Web system tuning. Three ways of further tuning are compared is Figure 4. The Y axis values denote the run times needed by a tuning experiment. Suppose there are N tunable parameters in one server, each parameter has three available values to be set. The ordinary tuning way needs 3 N test runs to complete the task. Quick Optimization via Guessing (QOG) can reduce the test time by guessing the system performance. How-ever, in [11] experiment, only four parameters are picked out for configuration, and it when there are five optional parameters to be tuned, KPSA produces as much run becomes unacceptable. QOG also re quires a lot of time to get the best configuration. However, KPSA can find the key parameters, so the test runs times can be reduced dramatically. During the experiment, the best response time of this three tuning meth-ods with different tunable parameters has been recorded. It shows that when we only use key parameters to tune the system, the response time is only average 8% slower than the QOG and ordinary method. Compare to the benefit of much less test runs, we think this 8% slower response time is acceptable. Therefore, we can conclude that KPSA can dramatically reduce the test runs for experiment-based tuning approaches and still get acceptable system performance. Although there may be dozens of tunable parameters in one Web system, in previous online application. In this paper, we propose a feature selection method based on In-formation Gain criterion to find the key parameters of a Web system. Based on KPSA, the tuning methodology for Web system is introduced. Experiments show that our algorithm can effectively find the parameters that affect system performance most. Using key parameters, we can dramatically reduce the test run times of an experiment-based tuning approach; meanwhile, the users can get acceptable response time. 
There are some latent relations between server parameters. Further research direc-tions include improving KPSA by considering the relations between parameters. We can also use latent relations to improve the existing experiment-based Web system tuning method. 
