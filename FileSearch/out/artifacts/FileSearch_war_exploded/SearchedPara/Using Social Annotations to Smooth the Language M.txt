 Language modeling approaches to Information Retrieval (In the rest of this paper we take  X  X raditional Language Model X  or the abbreviation  X  X LM X  to represent the original each document and then to rank documents by the likelihood of the query according to the estimated language model. One of the central problems of TLM is data sparseness. Many smoothing methods are studied trying to resolve this problem [2]. These classic smoothing methods are very efficient but one restriction: They all use only collection smoothing to compensate for data sparseness. 
With the boosting of web 2.0 technologies, more and more web resources are an-notated by the web users manually. Annotations are metadata of their owner webpage. With this extra data, is there some way to combine them into IR and improve IR effi-ciency? To answer this question, we first analyzed the characteristics of social anno-three manners: 1) the annotations are summaries of webpages in users X  perspective; 2) an annotation is somewhat a cluster of the webpages sharing it; 3) their combination. We call the three Forms of LAM Language Annotation Model with Annotation Smoothing (LAM-AS), Language Annotation Model with Cluster Smoothing (LAM-CS), Language Annotation Model with both Annotation and Cluster Smoothing (LAM-ACS) respectively. 
To evaluate our new models, we constructed a new test bed consisting of 1,736,268 web pages with 269,566 different tags from Del.icio.us 1 . 80 queries are collected and labeled by a group of CS students. The experimental results show that the three new models outperform both Vector Space Model (VSM) and TLM significantly. 
In the rest of the paper, we first survey related work in Section 2, and then present three forms of the LAM in Section 3, later give experimental results in Section 4, fi-nally make concluding remarks and give some future work in Section. 5. 2.1 Language Model recognition systems [4]. In 1998, Ponte and Croft [1] proposed a smoothed version of the document unigram language model. Since then, there emerged a great amount of research work related to language model. Most of them tried to solve the following two model the proper dependencies between the query terms [5, 6]. This paper mainly fo-cused on how to utilize annotation information to lighten the data sparseness problem and simply ignore the term dependency problem by assuming all terms were generated independently. In order to resolve the data sparseness problem, many smoothing methods were suggested to reevaluate the probabilities of generating the query terms that did not appear in the document. Song and Croft proposed the good-turing methods were proposed and achieved significant improvement [7, 8]. 2.2 Social Annotation Analysis During the recent several years, many websites have been constructed to provide social annotation services (or collaborative tagging, folksonomy, social bookmarking). 
Though much research work has been done on social annotation, little of them focus on integrating annotations to IR process. In [9], the authors give a very detail analysis among tags based on their co-occurrences with users or resources. However the above generative model to obtain the emergent semantics hidden behind the co-occurrences of web resources, tags and users and implements semantic search based on the emergent ronment and developed a method to improve search efficiency by utilizing annotations. Different from their work, this paper integrates annotations with TLM and proposes a new Language Annotation Model. The social annotations can benefit the smoothing of language model in two aspects: 1) the annotations themselves can serve as the summaries of the web pages given by the their combination, respectively. 
In the first method, we consider using the combination of all the tags associated to a web page as a summary of the web page. More specifically, we concatenate all the tags aspects at the same time. The three methods lead to three new language models: Lan-guage Annotation Model with Annotation Smoothing (LAM-AS), Language Annota-tion Model with Cluster Smoothing (LAM-CS) and Language Annotation Model with both Annotation and Cluster Smoothing (LAM-ACS) respectively. 3.1 Language Annotation Model with Annotation Smoothing (LAM-AS) In LAM-AS, we concatenate a web page X  X  all annotations to create a pseudo document. The web page and the pseudo document are two data sources of one document. i document and the whole pseudo document collection respectively. 3.2 Language Annotation Model with Cluster Smoothing (LAM-CS) In LAM-CS, we extend the idea of the cluster-based smoothing [7]. We consider two kinds of strategies in using social annotations for building clustering.  X  actually extra information other than the documents themselves. Since a document can potentially have unlimited amount of annotations, one document can be smoothed by a number of other documents linking to it via the tags.  X 
The social annotation tags can be semantically related since a single semantic sense can be articulated in different words by different users. Thus, one document can also be smoothed by the documents whose social annotation tags are semantically close to the tag of the document. the clusters containing the document. For the second strategy, we proposed to use  X  X ag tag b . Finally we get the cluster smoothing model: milarity from the j th tag to the i th query term. 3.3 Language Annotation Model with Both Annotation and Cluster Smoothing The LAM-ACS is the integrating of LAM-AS and LAM-CS. 4.1 Delicious Data For the experiment, we crawled webpages and social annotations from Del.icio.us. The dataset consists of 1,736,268 webpages with 269,566 different tags. We conducted two steps of preprocessing on the raw dataset as listed in the following. they are not designed for machine. For the limitation of the Del.icio.us service, a tag cannot have a space. Users may concatenate se veral words together to form a tag like  X  X avaprogramming X  or  X  X ava/programming X . We split/tokenize this kind of tags with the help of WordNet. In [9], social annotation tags are grouped into 7 categories. We found Category 4, 6 and 7 too user-specific (e.g. tobuy, toread, myprefer etc.). Tags falling into these categories are of little value for generic IR so we filter them out. Secondly, we define Del.icio.us tag similarity according to two intuitions: 1) the tag asymmetrical. For example, sim(Ubuntu,Linux) may be 0.6 while sim(Linux,Ubuntu) may be only 0.06. Because Linux is a superset of Ubuntu. Equation (4) illustrates the intuitions, gine-google: 0.0710; engine-game: 0.0569; google-engine: 0.1018; 4.2 Experiment Setup In order to evaluate the LAM X  X  performance, we asked for a group of CS students to drogen fuel cell, Beatles music. The queries contain 497 relevant documents in all. 
All the models are based on Lucene 2.0. We implemented BM25 [13] as the VSM baseline of our experiment: k1, k3 and b are set 1, 1 and 0.5 respectively (It X  X  Xapian X  X  default weighting scheme 2 ). In the following experiment, MAP and Recall are used to evaluate the retrieval performance. 4.3 Evaluation of Language Annotation Model In order to make the evaluation fair, in BM25 we merge each web page X  X  annotations into its content to keep the five models X  data source the same amount. The parameter  X  in Equation (1) and (3) is selected to roughly make the score following  X  and the score following (1- X  ) equal. 
As we can see from Table 2 and Fig 1, the three forms of LAM all outperform BM25 and TLM. To understand whether the improvement is significant, we also performed t-tests on MAP. The p-value between LAM-ACS and TLM is 0.032, indicating sig-nificant improvement. However, compare to TLM, the Recall of the three LAMs are much lower. We analyzed this phenomenon and find that the occurrence of a term in an annotation will bring more impact to the result P(q|d) score than that in the web page may be too great and even contribute more than the web page. annotations to lighten the data sparseness within language model for IR; 2) Propose a novel Language Annotation Model to utilize social annotations. Three forms of LAM results show that the LAM outperforms both the TLM and VSM significantly. 
It X  X  just a start to integrate social annotations into language model. In future, we will explore more sophisticated smoothing methods for language model and integrate social annotations into other retrieval models. The authors would like to thank the three anonymous reviewers for their elaborate and helpful comments. 
