 In this study, a novel multidimensional time series classifica-tion technique, namely support feature machine (SFM), is proposed. SFM is inspired by the optimization model of sup-port vector machine and the nearest neighbor rule to incor-porate both spatial and temporal of the multi-dimensional time series data. This paper also describes an application of SFM for detecting abnormal brain activity. Epilepsy is a case in point in this study. In epilepsy studies, electroen-cephalograms (EEGs), acquired in multidimensional time se-ries format, have been traditionally used as a gold-standard tool for capturing the electrical changes in the brain. From multi-dimensional EEG time series data, SFM was used to identify seizure pre-cursors and detect seizure susceptibil-ity (pre-seizure) periods. The empirical results showed that SFM achieved over 80% correct classification of per-seizure EEG on average in 10 patients using 5-fold cross validation. The proposed optimization model of SFM is very compact and scalable, and can be implemented as an online algo-rithm. The outcome of this study suggests that it is pos-sible to construct a computerized algorithm used to detect seizure pre-cursors and warn of impending seizures through EEG classification.
 I.5.4 [ Pattern Recognition ]: Applications X  signal process-ing, waveform analysis Algorithms, Design, Experimentation, Performance classification, time series, epilepsy, optimization
This material is based upon work supported by the Na-tional Science Foundation under Grant No. 0546574. electrodes).
Epilepsy can be broadly defined as recurring seizures  X  sudden, brief changes in the way the brain works [8]. The most disabling aspect of epilepsy is the uncertainty of re-current seizures, which can be characterized by a chronic medical condition produced by temporary changes in the electrical function of the brain. Although neurological sig-nals like EEGs offer good spatial and excellent temporal resolution to characterize rapidly changing electrical activ-ity of brain activation, neuroscientists understand very little about the dynamical transitions to neurological dysfunctions of seizures. The unpredictable occurrence of seizures has presented special difficulties regarding the ability to investi-gate the factors by which the initiation of seizures occurs in humans and how to prevent seizures from happening. If seizures could be anticipated, it would lead to the de-velopment of completely novel diagnostic and therapeutic advances in controlling epileptic seizures. Finding hidden patterns or relationships in EEG data may offer a possi-bility to better understand brain functions from a system perspective, which will generally be very useful in medical diagnosis. Thus, the necessary first step to advance research in seizure prediction is to develop novel techniques capable of recognizing and capturing epileptic activity in EEGs be-fore seizures occur. The discriminant ability to detect the seizure susceptibility period (seizure precursor) is logically a prerequisite of seizure prediction/warning development.
Classification has been used for a wide variety of tasks in data mining. There are a wide variety and technical sophis-tication of the classification techniques. For example, there is a rich body of work in both statistical modeling (e.g.,
This paper proposes a novel spatio-temporal classification technique to enhance the ability to classify MDTS data. The proposed technique can be used to discriminate pre-seizure EEG signals (seizure pre-cursor) from normal EEG signals. One of the most challenging aspects in this study is the fact that EEG data are massive with an average over 300,000 data points per 1-minute of all electrode recordings. We propose an EEG feature extraction technique based on the chaos theory to reduce the dimensionality of EEG data. Since MDTS data like EEGs have properties in space and time, good MDTS classification techniques should be able to incorporate both spatial and temporal characteristics. To the best of our knowledge, this study represents the first at-tempt to formulate an optimization model to capture spatio-temporal properties for MDTS classification. The proposed technique, SFM, can incorporate both spatial and temporal properties by employing statistical time series analysis and the nearest neighbor rule within the optimization model. The SFM optimization model is to select the dimensions (features) of the MDTS that will maximize the correct clas-sification subject to the nearest neighbor rule on inter-class and intra-class time series statistical distances. The optimal features that maximize the classification accuracy will be selected and used in the testing phase. The solution to an SFM problem is also easy for the end users (e.g., physicians) to interpret. For instance, in our case, the SFM solution is a group of electrodes that show the most discriminating power in normal and pre-seizure EEG classification.
The organization of the succeeding sections of this paper is as follows. In Section 2, the method used to extract features from EEG data, statistical measures in time series analysis, and optimization models for SFM are described. The EEG data description and experimental design are presented in Section 3. The classification results and the performance characteristics of the proposed technique are addressed in Section 4. The concluding remarks are given in Section 5.
The spatio-temporal classification framework developed in this study is comprised of 3 key steps. The first step is the feature extraction from multi-channel EEG data. In this study, we employ a quantitative measure of brain dynam-ics from EEG data. The measure of brain dynamics, based on the chaos theory, has been previously shown capable of contemplating dynamical mechanisms of the brain network from EEG signals [15]. After the brain dynamical measure for each EEG channel is calculated, the subsequent step is the selection of time series similarity measures. We herein employ 3 time series similarity measures to the analysis of brain dynamics in EEG time series. Those measures include Euclidean, T-Statistical , and Dynamic Time Warping dis-tances. The third step is the classification algorithm, which is based on optimization models used to classify unlabeled samples based on the nearest neighbor rule. Integration of the optimization models and the nearest neighbor rule results into a novel MDTS classification technique, called SFM, which is used to classify normal and pre-seizure EEGs in this study. Figure 2: Diagram illustrating an EEG epoch em-bedded in phase space for the quantification of brain dynamics: assume p = 4 . The fiducial trajectory, the first three local Lyapunov exponents ( L 1 , L 2 , L 3 ), is shown. space. Define  X X i,j (0) = X ( t i )  X  X ( t j ) as the displacement vector at t i , i.e., a perturbation of the fiducial orbit at t i , and  X X i,j ( X  t ) = X ( t i + X  t )  X  X ( t j + X  t ) as the evolution of this perturbation after time  X  t . Denote t i = t 0 +( i  X  1)  X   X  t and t j = t 0 + ( j  X  1)  X   X  t , where i  X  [1 , N a ] and j  X  [1 , N ] with j 6 = i . Let  X  t be the evolution time for  X X i,j , i.e., the time one allows  X X i,j to evolve in the phase space. t 0 is defined as the initial time point of the fiducial trajectory and coincides with the time point of the first data in the data segment of analysis. In the estimation of STL max , for a complete scan of the attractor, t 0 should move within [0 ,  X  t ]. Finally, STL max is defined as the average of local Lyapunov exponents in the state space and can be calculated by the following equation:
In this study, the choice of similarity measures is a very important step in achieving accurate classification results. To our knowledge, we are the first to develop a framework in-corporating statistical time series similarity measures for dif-ferentiating EEG signals from normal and pre-seizure states. We will also apply and compare the performance of those similarity measures, including Euclidean, T-Statistical (in-dex), and Dynamic Time Warping distances. Each of these measures can give us different aspects and insights about temporal and spatial characteristics of EEG signals.
Give two time series (or vector sequences) X and Y of equal length | X | = | Y | = n , DTW is a distance (similar-ity) measure used to compute the best alignment warp be-tween time series X and time series Y with the minimum distortion. DTW has been widely used in many contexts in-cluding data mining [18, 1], gesture recognition [12], speech processing [31], and medicine [3]. The DTW distance can be calculated by using a dynamic programming approach. First, construct an alignment of every data point in time se-ries X to match with every point in time series Y . The n  X  n
The t-test is commonly used to determine if two time se-ries differ from each other in a significant way under the as-sumptions that the paired differences are independent and identically normally distributed. Note that the t-test deals with the problems associated with inference based on small samples (epochs of time series), which implies that the cal-culated mean and standard deviation may deviate from the  X  X eal X  mean and standard deviation. The t-index is a simi-larity degree from the paired t-test for comparisons of means of paired-dependent observations. In this study, we use the t-index as a measure of statistical distance between two time series. Specifically, it is used to estimate the difference of the EEG signals from different brain states. The t-index, T xy , between the time series X = x 1 , . . . , x n and Y = y 1 , . . . , y n is then defined as T xy = ple standard deviation of the absolute difference between time series X and Y estimated over a window with the length n . Note that the t-index follows a t -distribution with n  X  1 degrees of freedom.
The Euclidean distance is the most commonly used sim-ilarity measure. It is easy to understand and bear certain success in many classification problems. It measures the de-gree of similarity in terms of intensity of the data. In short, the Euclidean distance tells us an average of the difference in intensity of two time series. The Euclidean distance, ED, between the time series X and Y of length n is defined as:
The idea of SFMs is motivated by the optimization model of SVMs to enable the model to incorporate spatial and tem-poral properties. SFM employs the nearest neighbor rule to incorporate the temporal properties (i.e., time series sta-tistical distance), and formulates an optimization model to select features that minimize the classification error or max-imize the classification accuracy. The nearest neighbor rule is a very intuitive method in which the classifier categorizes an unlabeled time series sample based on its statistical dis-tances between baseline references of normal and pre-seizure EEGs in the training data. More precisely, for a given un-labeled time series A , the nearest neighbor rule finds the labeled time series in the training data set and assign A to the class that appears to be closest to A . A statistical dis-tance measure is a measure of  X  X loseness X . In this study, we will employ the same time series statistical distance mea-sures mentioned in the previous section. An example of the nearest neighbor rule is shown in Figure 4, where an un-known EEG epoch is labeled as normal or pre-seizure based on the nearest neighbor rule.
The goal of SFM is to select a group of electrodes that maximizes the number of correctly classified samples based on the nearest neighbor rule. To formulate the SFM problem into a mathematical program, we define the following sets: i  X  I is a set of | I | = n training samples; j  X  J is a set of | J | = m electrodes. We then define the following decision SFM is given by: where a ij = 1 if the nearest neighbor rule correctly classi-fied sample i at electrode j , 0 otherwise, n is total number of training samples, m is total number of electrodes, M = m 2 , and  X  is a small number, 0 &lt;  X  &lt; 1 2 , used to break the tie in voting. In order to demonstrate that the voting SFM can improve the voting nearest neighbor rule, we use the du-ality theory to prove that the  X  X elected electrodes X  by SFM always improves the solution quality in terms of correct clas-sification from the standard nearest neighbor rule (using X  X ll electrodes X ).

Proposition 1. The classification results (the number of correctly classified samples) given by the voting SFM are al-ways better/higher than or equal to those given by the voting nearest neighbor rule using all electrodes.

Proof. The constraints in Eqs. (4)-(5) represent the vot-ing nearest neighbor rule when x j = 1  X  j . It is easy to see that the solution (all x j = 1 ) is a feasible solution to V-SFM. Therefore, the objective function given by the voting nearest neighbor is always less than or equal to the optimal solution to V-SFM. This completes the proof.
The objective function of averaging SFM in Eq. (8) is to maximize the total correct classification. There are two sets of constraints in Eqs. (9)-(10) used to ensure that the train-ing samples are classified based on the averaging distance nearest neighbor rule. There is a set of logical constraints in Eq. (11) used to ensure that at least one electrode must be used. The mixed-integer program for averaging SFM is given by: where d ij is the average statistical distance between the EEG sample i and all other EEG samples from the same state at electrode j ( intra-class distance ),  X  d ij is the average statisti-cal distance between the EEG sample i and all other EEG electrodes from every patient. After all seizures are pin-pointed by our expert/neurologist, we randomly and uni-formly sample the continuous EEG recordings in each pa-tient into 2 groups (normal and pre-seizure) of 5-min EEG epochs. Normal EEG samples are selected from EEG record-ings that is more than 8 hours apart from a seizure. Pre-seizure EEG epochs are selected from EEG recordings dur-ing the 30-minute interval before. The data sampling pro-cedure is illustrated in Figure 5. Per seizure, 6 EEG epochs were randomly and uniformly drawn from normal and pre-seizure states (3 from each state). For example, Patient 1 had 7 seizures; therefore, 42 EEG epochs (21 normal and 21 pre-seizure) will be sampled from Patient 1 X  X  data set. Figure 5: A EEG Data Timeline for Sampling Pro-cedure.
After 2 groups of EEG epochs are collected, we first cal-culate the measure of chaos ( STL max ) from EEG signals using the method described in the previous section. Per electrode, the STL max profile was calculated continuously for each non-overlapping 10.24-second segment of EEG data. After we calculate an STL max profile for each EEG channel, we then perform the data preprocessing to generate input data for SFM models. In the voting SFM case, the nearest neighbor classification is performed by categorizing training samples using the nearest neighbor rule based on the sta-tistical distance at each electrode. In the averaging SFM case, the intra-class and inter-class distances for each of the training samples at each electrode are calculated. There are two parameters in the SFM classification that need to be trained. The first parameter is the choice of time series sim-ilarity measures (statistical distances) discussed previously. We apply all 3 statistical distances to SFM classification. Note that although the Euclidian distance is commonly used in a standard nearest neighbor algorithm, it is very sensitive to the choice of the similarity measure used and EEG char-acteristics are much more complicated than the Euclidean distance can capture. We anticipate that more sophisticated similarity measure like T-index and DTW will outperform the standard Euclidean distance. Another parameter is the Sakoe-Chiba band parameter during the DTW distance cal-culation, which will be optimized empirically.
There are many alternatives of how to divide the EEG data into training (baseline) and test sets. In order to re-duce the bias of training and test data, we propose to employ n -fold cross validation technique to train the SFM for the best electrode selection. Cross validation technique is ex-tensively used as a method to estimate the generalization error based on  X  X esampling X . Generally with n -fold cross validation, EEGs data will be divided into n subsets of (ap-proximately) equal size. The proposed SFM will be trained and tested n times, in which one of the subsets from training is left out each time, and tested on the omitted subset [7, 6]. As mentioned in [23], the result from one n -fold cross valida-
Ave. 0.6822 0.7520 0.7010 0.6333 0.9017 0.8858 sification results showed that the sensitivity for pre-seizure classification ranged from 57.27% (Patient 4) to 98.70% (Pa-tient 1), and the specificity ranged from 66.12% (Patient 7) to 99.67% (Patient 6). The overall sensitivity and specificity were achieved at the rates of 90.17% and 88.58%, respec-tively. In contrast, the classification results by NN yielded an overall sensitivity at the rate of 70.10% and an overall specificity at the rate of 63.33%. The classification results by SVM yielded an overall sensitivity at the rate of 68.22% and an overall specificity at the rate of 75.20%. In addition, we also calculated the classification accuracy of pre-seizure samples, which can be viewed as the reliability of a classifier. The accuracies of SVM, NN, and SFM are 74.98%, 71.69%, and 90.49 %. We also observed that, in every case, SFM approach provided not only far better classification results than NN, but also more robust results in terms of the vari-ation of classification performances. The NN results varied drastically in both sensitivity and specificity across patients. There were cases in NN where sensitivity was really high and the specificity was very low, vice versa. We speculated that this phenomenon occurred due to the downfall of the NN ap-proach under scattered and clustered data. When the EEG data from either normal or pre-seizure periods were much more clustered than the other, the NN approach would also classify unknown samples to the class where the data are more clustered. In the case where the data were equally clustered (Patients 2, 3, and 10), the NN results were more balanced. This observation underlines the efficacy of SFM as in every patient the SFM approach yielded very balanced classification results.

Figure 6 shows the ROC plot of Patient 3. We observed that the SFM averaging scheme outperformed the SFM vot-ing scheme in every case. We speculated that this may be be-cause the averaging scheme can provide a more refined scale in the nearest neighbor step than the voting scheme. In ad-dition, we remarked that the SFM approach tended to favor the T-statistical distance over the DTW and Euclidean dis-tances in both voting and averaging schemes. On the other hand, the NN approach equally favored the T-statistical and DTW distances. Figure 7 illustrates the overall classification performances of the averaging schemes of NN and SFM ap-proaches across all 10 patients.

Table 3 summarizes the average number of electrodes and appearance probability of electrodes from each brain area selected by the SFM approach using 5-fold cross valida-tion over 10 replications. The average numbers of selected and LOF were never selected in Patient 10. This observa-tion may lead to a greater understanding of some unique, yet very specific, symptoms or characteristics of epileptogo-netic processes in individual patient. This may also be very helpful in drug study or electrical stimulation.
 Table 3: The average number of electrodes and the appearance probability of electrodes from each brain area selected by the SFM approach per patient. Patient Elecs LTD RTD LST RST LOF ROF
To better explain why the SFM approach performs very well, Figure 8 illustrates an example of STL max values from 6 EEG samples, 3 pre-seizure and 3 normal, derived from electrodes that were selected and not selected by SFM, on the left and on the right respectively. The electrodes, se-lected from the training phase, demonstrated a very high separation of pre-seizure and normal EEGs with respect to the values of STL max . This observation confirms that the nearest neighbor rule applied to the selected electrodes should be more likely to correctly classify pre-seizure and normal EEGs. One can conclude that the SFM approach selects the electrodes that will enhance the classification performance using the nearest neighbor rule. On the other hand, the electrodes that were not selected from the train-ing phase showed that pre-seizure and normal EEGs are clustered together with respect to the values of STL max . This exhibits the tendency for the nearest neighbor rule to make an inaccurate classification. Therefore, these observa-tions suggest that the SFM optimization models enhance the ability to correctly classify EEG samples using the nearest neighbor rule.
Real challenges in epilepsy treatment lie on the anticipa-tion of seizures and the uncertainty of when the next seizure will occur. In this study, we propose a novel MDTS clas-sification technique used to classify pre-seizure and normal EEGs. The empirical results are very promising as the pro-posed SFM classification technique achieved an average sen-sitivity and an average specificity over 80% in 10 patients. The outcome of this study suggests that it is possible to construct a computerized algorithm used to detect seizure pre-cursors and warn of impending seizures. This has shed some lights on seizure prediction research. Specifically, this research has potential to develop a system capable of rapidly recognizing and capturing epileptic activity in EEGs before a seizure occurs through an online classification/monitoring framework. This research may subsequently lead to clinical investigations of the effects of timely therapeutic interven-tions to control/abort seizure occurrences. This will subse-quently revolutionize the treatment of epilepsy and provide [15] L. Iasemidis. On the dynamics of the human brain in [16] L. Iasemidis. Epileptic seizure prediction and control. [17] L. Iasemidis, H. Zaveri, J. Sackellares, and [18] E. J. Keogh and M. J. Pazzani. Scaling up dynamic [19] K. Lehnertz and B. Litt. The first international [20] O. Mangasarian. Linear and nonlinear separation of [21] O. Mangasarian, W. Street, and W. Wolberg. Breast [22] D. F. McCaffrey, S. Ellner, A. R. Gallant, and D. W. [23] A. Molinaro, R. Simon, and R. Pfeiffer. Prediction [24] F. Mormann, T. Kreuz, C. Rieke, R. Andrzejak, [25] N. Packard, J. Crutchfield, and J. Farmer. Geometry [26] H. Potter. Anatomy of the brain, 2006. [27] T. M. Rath and R. Manmathan. Lower-bounding of
