 Applications that create and consume unstructured data hav e grown both in scale of storage requirements and complexity of sear ch primitives. We consider two such applications: exhaustive search and integration of structured and unstructured data. Curre nt block-based storage systems are either incapable or inefficient to address the challenges bought forth by the above applications. We pr opose a storage framework to efficiently store and search unstruct ured and structured data while controlling storage management cost s. Ex-perimental results based on our prototype show that the prop osed system can provide impressive performance and feature bene fits. Categories and Subject Descriptors: H.3.0 [Information Storage and Retrieval]: General General Terms: Algorithms, Design, Performance
Storage systems for scientific applications are becoming ex -tremely complex due to the scale and variety of data. For inst ance, experiments at Mayo clinic (Rochester, Minnesota) have an a ver-age storage requirement of 1TB per 9 days [8]. Applications t hat require complex search primitives on unstructured data are also becoming increasingly common. For instance, query-by-exa mple and data summarization applications exhaustively search t hrough all files because either the query model is fuzzy or indices ar e ex-tremely expensive to maintain for high dimensional data. Su pport-ing exhaustive search is not among the primary design criter ia of today X  X  filesystems and database systems. Therefore the pro blem of where and how to store unstructured data in order to search it efficiently, needs a fresh re-assessment. Furthermore, uns tructured data is often created, updated and queried in the context of s truc-tured data. Although, there is a lot of research in providing a unified access at the query level, there is still lack of research in p roviding a scalable storage platform for integrating structured and unstruc-tured data. In the presence of petabytes of data and Informat ion Lifecycle Management (ILM) regulations like HIPAA, contro lling storage management costs is extremely challenging. In this paper, we present one complete solution to tackle three highly inte rcon-nected sub-problems: efficiently storing and searching a wi de va-Copyright 2007 ACM 978-1-59593-803-9/07/0011 ... $ 5.00. riety of unstructured data, integrating unstructured and s tructured data, controlling storage management costs.

The block interface, widely prevelant among todays X  system s, does not allow for any form of communication between the appl i-cation and the underlying storage subsystem. With complex a ppli-cations operating on petabyte scale storage, this disconne ct leads to scalability problems, performance degradation and high cost of storage management. Object-based storage [4, 6] addresses all the drawbacks of block-based storage by revamping the narrow bl ock interface with an extensible and expressive object interfa ce. In object-based storage devices (OSD, for short), the storage man-agement component of the filesystem or the database is migrat ed to the storage device. Therefore, the tasks of managing free space and mapping object IDs to physical disk locations is delegat ed to the storage system. This division of labor enhances scalabi lity, en-ables communication through a richer interface and empower s the storage to perform smarter data-specific optimizations to i mprove application performance.

Custom storage systems have been researched in the past to ov er-come the limitations of block storage. The Google Filesyste m [2] uses an object-based storage system to provide high storage per-formance through parallel, direct access I/O paths. The Act ive Disk [5] project demonstrated that large scale data mining a nd mul-timedia applications benefit from embedding search functio nalities into the storage system.

Storage systems that integrate structured and unstructure d data can be broadly classified into three categories. (1) The Database-only approach: unstructured data is stored as binary large objects (BLOBs) within a database. (2) The database-plus-filesystem ap-proach: structured data is stored in a database, unstructured data is stored in a filesystem and path names are used to link the dat a together (3) Custom Architectures: The Google Bigtable [1] inte-grates structured data and text. It uses the google filesyste m be-neath to store and manage data. Native XML stores can also be used to integrate structured data and text.

Our solution tackles the three subproblems (namely: storin g and searching unstructured data, integration with structured data and controlling storage management costs)in two steps. First, we we propose an application-aware storage system called an Inte lligent Storage Node (ISN, in short) that can efficiently store and se arch unstructured data. The underlying principle behind the pro posed ISN is that when the storage system is aware of the applicatio n, it can map application access patterns to storage-device specific op-timizations to improve application performance. We demonstrate this principle through a storage embedded exhaustive searc h algo-rithm that performs upto six times better than conventional tech-niques.

Second, we use ISNs as a building block to build a system calle d Figure 1: Architecture of an Intelligent Storage Node: Shad ed boxes represent the new modules that an ISN adds to a tradi-tional OSD SQUAD that enables seamless and storage-centric integrati on of structured and unstructured data. SQUAD stores unstructur ed data on ISNs and structured data in a traditional database. An ent ity called Metadata Server abstracts the ISNs and the database t o pro-vide a unified, query-able view to the client. In this section, we present the concept of an Intelligent Storage Node and show that through application-awareness at the storage level, an ISN can improve the performance of exhaustive sear ch. An intelligent storage node is an object-based storage devi ce with storage-device-specific software to make exhaustive searc h effi-cient. An ISN could just be a rack server or a commodity PC that exposes a standardized object interface like OSD T-10 [6]. T he ISN supports a new command OSD QUERY in addition to the OSD T-10 standard command set to submit exhaustive search queri es to the storage device.

In the filesystem-based approach, exhaustive search is impl e-mented by recursively exploring the filesystem namespace. W ith filesystem aging and fragmentation, recursive exploration can end up being a random scan operation at the disk level leading to e x-tremely poor performance. This clearly shows that the lack o f com-munication between the filesystem and the storage system lea ds to poor performance. Another drawback with current systems is the lack of performance isolation. Exhaustive search, being a l ong-running, I/O intensive task, can increase the response time s of other concurrent filesystems applicatons. Todays X  block-based s torage systems cannot differentiate between requests from two hos t appli-cations to provide any form of performance isolation. We sho w that through application-awareness at the storage level, the IS N boosts performance and provides performance isolation. We discus s these two features of the ISN in the next two subsections: Search St rat-egy and Search Suspend-and-Resume.
The principle of our search approach is to exploit applicati on-awareness at the storage device to transform application re quests to an access pattern that is most efficient at the storage device . For the exhaustive search application, we read all the objects in th e ISN in a specific order that gives near-sequential performance.
 An ISN stores data objects as a set of non-contiguous fragmen ts. Each fragment is a contiguous run of logical blocks on disk th at are assigned to a particular object. In an exhaustive search ope ration, all object fragments on the ISN need to be examined. Therefor e the order in which they are retrieved is not important. We lev erage on this characteristic feature of the exhaustive search app lication to plan the search operation such that we visit the fragments in an or-der that minimizes random seeks. By minimizing random seeks , we get close to sequential performance. Another critical poin t to note here is that since we operate at the granularity of a fragment , the extent of fragmentation on the ISN does not affect the perfor mance of the exhaustive search significantly. On the other hand, fil esystem level exhaustive search will be severely affected by fragme ntation since it operates at the granularity of files or objects. Our a pproach assumes that the fragments of the objects can be visited in an y or-der. With large main memory available in modern storage devi ces, this assumption is valid for most unstructured data like tex t, video, images and audio. Also, since objects that do not satisfy the query are not returned back to host, interconnect bandwidth is not wasted.
Figure 1 gives the architecture of the proposed ISN with embe d-ded exhaustive search functionality. The shaded boxes repr esent the application-aware intelligence that we introduce to a regular object-based storage device. In the front-end, we have an OSD command interpreter which exposes a standard object interface [6]. The object filesystem performs disk-space management routines and maps a given object-ID to the fragments it occupies on the disk. The Fragment Indexer maintains the fragments in efficient visit or-der. The fragment indexer interacts with the object filesyst em to update the index whenever object fragments are created, upd ated or deleted. The Search Planner module is the heart of the exhaus-tive search system. Given the current position of the disk he ad, the search planner consults the fragment indexer to find the most effi-cient order to visit the fragments. The search planner opera tes at a higher granularity when compared to the scheduler that resi des on the disk firmware. Based on an estimate of the disk X  X  current h ead position, the planner selects the set of fragments closest t o head and queues requests to those fragments inside the disk firmware q ueue. The disk may re-order these requests to find the most efficient or-der to visit them. So the search planner works in concert with the native command queuing available at the disk to discover the best possible search plan.

The proposed exhaustive search technique shows how to effi-ciently search a large disk drive and not what to search. Therefore, any application that needs to read the entire filesystem fits o ur re-quirement for a search application. We assume that storage i s the bottleneck in the system and the application can process the data close to sequential disk bandwidth. Recent trends indicate that stor-age blades with extremely fast processors and large buffer m em-ory are becoming common. The reader is referred to the Diamon d project [3] for exhaustive search applications and a storag e-level programming model for such applications.
Upon receiving a real-time request, an ongoing exhaustive s earch process is suspended. It is resumed after servicing the real -time re-quest. When a suspended search operation is resumed, the sea rch resumes exactly from where it left off. For instance, assume the disk head is over fragment number f i and the next fragment in the search plan is f i +1 , when a real-time request for block the disk. The search planner first finishes retrieving fragme nt It then suspends the search and repositions the disk head at l ogical block b for servicing a real-time request. On resumption, the searc h proceeds from fragment f i +1 irrespective of the physical distance between f i +1 and b . Therefore, on every resume operation, the static plan mode may incur costly seek operation. However th e re-sume operation is very straightforward to implement and has very little state information to be maintained, namely, last fra gment vis-ited. Also the search plan is computed just once and it remain s static until the search is completed.
Structured and unstructured data have entirely different s torage access techniques. Structured data is best placed within th e slot-ted page structure of databases while filesystems have been p roven to handle unstructured data better [7]. This impedance mismatch forms the underlying challenge in integrating structured a nd un-structured data at the storage level.

To address the above challenge, we propose SQUAD: a uni-fied framework for storing and querying structured and unstr uc-tured data. In SQUAD, structured data is stored in a traditio nal database system and the unstructured data lives in the ISNs a s ob-jects. Relationships between structured and unstructured data are maintained through object identifiers. The Metadata Server (MDS) forms a wrapper around the database and the ISNs to expose a si n-gle, query-able integrated data store. The SQUAD client use s a set of APIs exposed by the Metadata Server to provide intuitive t ools for the user to seamlessly store and search mixed data. The cl ient also has an object filesystem that exposes a traditional hier archical namespace while internally using object devices to store th e data. In the rest of the section we explain how the simple SQUAD fram e-work provides integration at the storage and query dimensio ns. Integration at the Storage Level: The database uses object IDs to keep track of the unstructured data related to a particula r tuple. Since object identifiers are application, filesystem path an d location independent, integration is generic. Furthermore, the ext ra indirec-tion provided by object IDs enables loose coupling between t he database and the ISNs. Consequently, the database is reliev ed from handling filesystem artifacts (e.g., path names and access c ontrol lists) and the filesystem is relieved from handling database features (e.g., integrity constraint violation checks). All tasks t hat fall in the intersection of filesystem and databases are now delegat ed to the MDS. The MDS is responsible for ensuring that any changes in the filesystem X  X  state do not render the database inconsis tent and vice versa. For instance, the MDS commits a delete only when the operation does not violate any integrity constraints of tuples as-sociated with the object. However, read/write of objects fr om/to the ISNs happens without the intervention of the MDS. This cl ear separation of control and data paths provides high parallel access performance [2, 4, 6].
 Integration at the Query Level: In SQUAD, ISNs and the database form a distribution query execution framework. Th e database executes queries on structured data while the ISNs exe-cute exhaustive search queries on unstructured data. Exhau stive search is one example to show how application awareness at st or-age can be used to improve performance. Concepts like extend ed attributes and sessions in object-based storage systems ca n be used to provide differentiated service based on the type of data a nd ap-plication [4, 6]. In SQUAD, the client submits a mixed query t o the MDS. The MDS then decomposes the query into its structured an d unstructured components, dispatches sub-queries to the da tabase and ISNs respectively, stitches the results together and re lays it back to the client.
We have built a prototype SQUAD system with all the compo-nents shown in Figure 2. In the following subsections, we exp lain in detail, some critical implementation aspects of our prot otype. An ISN is an enhanced version of an object-based storage devi ce. We extended an open source implementation of an object targe t available from the DISC-OSD project [9]. The DISC-OSD targe t is a user-level program, that exposes the T10 object interfa ce over iSCSI transport. The DISC-OSD target internally stores obj ects as files on the Linux extended filesystem (ext3). We implemented two modules within the target to support exhaustive search : fragment indexer and search planner . The fragment indexer maintains effi-cient search order of object fragments as they are created, u pdated or deleted. We use a persistent B-Tree to maintain fragment i nfor-mation (namely, object ID and fragment number) in increasin g or-der of logical block addresses (LBA). The search planner consults the fragment index to construct a search plan that sweeps fro m start to the end of the disk.

To compare the performance of our approach versus a filesyste m level exhaustive search, we construct search plans for both cases. The filesystem search plan visits each object in the order as s een by a filesystem (e.g., alphabetic order). The search plan const ructed by our technique visits the objects at a fragment granularit y and in an order that is as close to sequential as possible. We have im ple-mented the Query Executor which reads the entire filesystem con-tents based on the two search plans. The Query Executor uses t he SCSI generic (sg) driver [10] to construct SCSI READ commands and queue them at the disk.

To observe the effect of fragmentation on the performance of our scheme, we implemented a synthetic aging tool that performs file create, delete and append operations. We use a generalized v ersion of storage age metric introduced in [7] to quantify the extent of fragmentation of a storage system. The storage age of a volum e is defined as the ratio between the number of bytes of modified dat a (written/deleted) and the number of bytes in use on the volum e. We first bulk load a filesystem with binary data to the required oc cu-pancy level of l % . Since the filesystem is new and unfragmented, the age is zero. Then, we start the aging tool and fragment the filesystem to the required age. We ensure that while aging, th e size of the filesystem is always ( l +
In this section, we evaluate the performance of the proposed ISN and the SQUAD framework using our prototype system.
 The ISN is set up on a Dell PowerEdge 2650 Server that has two Intel Xeon 2GHz processors, 2 GB RAM and three direct-attach ed Seagate Cheetah 15K rpm, 73G SCSI hard drives (ST 373454LC). The PostgreSQL database is set up on another Dell PowerEdge 2650 Server with the same hardware configuration as above. Th e
Figure 3: Speedup provided by an ISN for the exhaustive search operation compared to a filesystem-level search.
 MDS code is set up on a Dell Power Edge 2950 that has two, dual core Intel Xeon 3GHz processors, 2GB RAM and three Fujitsu 15K rpm, 73G direct-attached SAS hard drives (MAX3073RC). The client is set up on a commodity PC that has an Intel Pentium III, 1 Ghz processor, 512 MB RAM and a direct attached Seagate 30G SATA hard drive. All the above components are connected through a gigabit Ethernet network.
In the first set of experiments, we examine the performance of an ISN for exhaustive search queries and compare it with the t radi-tional filesystem approach. We set up an ext3 filesystem on a pa r-tition of size 63GB. We use the aging tool mentioned in Sectio n 4 to control the extent of storage fragmentation. We populate the filesystem with random binary objects with an average of 256K B.
In the first experiment, we vary both the age of the storage sys tem and filesystem occupancy and find the times taken to perform ex -haustive search using filesystem level search and ISN-based layout-aware search (see Figure 3). The vertical axis shows the sear ch speedup which is the ratio of Filesystem Search Time to ISN Se arch Time. We see that that when the filesystem is new (age = 0), both the filesystem level search and the ISN-based search have the same performance (i.e., speedup = 1). But as the filesystem ages, t he performance of the filesystem level exhaustive search degra des. ISN-based search however is able to maintain the performanc e by re-ordering search requests to obtain near-sequential per formance, consequently leading to upto six times speedup.

Figure 4 gives the time taken to perform exhaustive search on an ISN (filesystem size=20G, age=5) in the presence of real-t ime traffic. The real-time requests were READ operations on one sec-tor randomly chosen within the filesystem boundary. The hori zon-tal axis gives the inter-arrival time between two real-time requests. Therefore as we move to the right, the real-time requests are less frequent. The vertical axis gives the exhaustive search tim e. We see that when the real-time traffic is high, the performance o f the exhaustive search suffers. This can be attributed to the inc urred random seek operations.
We now evaluate the performance of the SQUAD framework for mixed queries. The mixed queries are of the form ( Q = Q s where Q s is a SQL query on structured data and Q u is an exhaus-tive search query. We use the following schema in our experim ents: Wiki(pageID, date, HTML, icon) . pageID is an indexed attribute and date is a non-indexed attribute. The icon field stores a pointer to data stored outside the database. Depending on the whether w e use the database-plus-filesystem (DB+FS) approach or SQUAD, this pointer is a filesystem path name or objectID. Exhaustive sea rch is used for queries on icon . pageID and date form the structured com-ponent of the database while HTML and icon constitute the unstruc-tured component. We populate the table with roughly half mil lion rows. We use the 5G wikipedia dump for the HTML attribute. We evaluate the performance of SQUAD for two mixed queries. The structured component Q s has two variations, Q 1 and where Q 1 = ( date &gt; 10 / 3 / 2000) and Q 2 = ( date &gt; 10 / 3 / 2000) AND ( objectID &gt; 4000) . Therefore we have two mixed queries that are represented as : Q icon 1 and Q icon
We compare the performance of SQUAD with the DB+FS ap-proach for the queries Q icon 1 and Q icon 2 (See Figure 5). In both approaches, the database first executes Q s . On the resulting set of objectIDs from Q s , Q u is executed on either the filesystem or the ISN. We observe that SQUAD performs better than the DB+FS ap-proach for both queries. The performance advantage is becau se of the layout-aware search available at the ISNs. However in th is case, the ISNs do not perform an exhaustive search but instead sear ch a subset as found by Q s . From the above experiments, we can con-clude that for mixed queries involving exhaustive search, S QUAD has significant better performance than the DB+FS approach. The performance advantage stems from the fact that the SQUAD des ign embeds search functionalities in components based on where they can be performed best. Specifically, executing Q s is embedded in the database and executing Q u is embedded in the ISN.
