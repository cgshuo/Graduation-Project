 With the proliferation of XML as a standard for data representation and data exchanging, efficient querying techniques of XML data becomes an important topic for the database community. Many studies have focused on the indexing of XML data import part in improving performance of XML query processing, especial for query results have been computed and cached. To cache useful queries, one of the most effective approaches is to discover frequent query patterns from the user queries, queries. Basically, the frequent query pattern mining problem is considered as finding modeled as trees. 
In this paper, we present an efficient algorithm called BUXMiner to discover frequent query patterns using a bottom-up enumerating method. We introduce a novel data structure called compressed global tree guide (CGTG) to accelerate candidate generation and infrequent tree pruning. We note that previous algorithms such as XQPMiner, XQPMinerTID and FastXMiner [3, 5] employ a rightmost branch expan-perform an efficient bottom-up candidate generation process. We remove all infrequent nodes from the global tree guide before candidate enumeration and generate candidates unnecessary candidates. Once more, previous methods have no guarantee on the number constructing of CGTG since the supports of query pattern trees can be computed through CGTG. Like mining algorithms XQPMiner, XQPMinerTID and FastXMiner, we do not consider XML queries that contain sibling repetitions either. Experiments results on public datasets show that our method outperforms the previous algorithms. Meanwhile, we will show that our approach has good scalability. 
The rest of the paper is organized as follows. In section 2 we discuss previous work related to query pattern mining approaches. In section 3, we describe some concepts used in our mining approach. We propose the bottom-up algorithm BUXMiner in section 4. Section 5 gives the results of our experiments and we make a conclusion in section 6. Many efficient tree mining approaches have been developed [6, 7, 8, 9, 10, 11] to find tree-like patterns. Basically, there are two main steps for generating frequent trees in a database. First of all, a systematic way should be conceived for generating non-redundant candidate trees. Secondly, an e fficient way is needed to compute the support of each candidate tree and determine whether a tree is frequent. Anyhow, they adopt a straight-forward generate-and-test strategy. Various algorithms have been unordered tree mining approach in [6] and [7] respectively. Zaki gives ordered and unordered embedded tree mining algorithms in [8, 9]. Chi et al. bring forward algorithms for mining rooted unordered an d free trees in [10, 11]. However, these mining approaches mainly treat with general trees. They don X  X  take schema information into account when dealing with special trees like XML query pattern trees. 
XQPMiner and XQPMinerTID presented in [5] are two approaches to frequent query pattern discovering exploiting schema information to guide the enumeration of candidates. Both of them employ rightmost branch expansion enumeration approach to generate candidates from top to down. XQPMinerTID outperforms XQPMiner due XQPMinerTID only scans dataset when expansion happens on the leaf node. Mining algorithm FastXMiner in [3] also generates candidate trees with the help of schema tree. The support of non-single branch tree can be computed based on its joined rooted subtrees. In this way, FastXMiner needs less dataset scans than algorithms XQPMiner and XQPMinerTID. Frequent query access patterns can be made use of for caching to accelerate retrieval of query results. Liang et al. in [3] employ FastXMiner to discover frequent XML query patterns and demonstrate how the frequent query patterns can be used to improve caching performance. Ling et al. in [4] They cluster XML queries according to their semantics first and then mine association rules between clusters for caching. 3.1 Query Pattern Tree Query Pattern Tree. A query pattern tree is a tree QPT = &lt;R, N, E&gt; where: y R is the root node. y E is the edge set. For each edge e = (n 1 , n 2 ), node n 1 is the parent of n 2 . Rooted Query Pattern Subtree. Given two query pattern trees T and S , we say that S V , such that satisfies the following conditions: y  X  preserves the root of trees, i.e., R ( S ) = R ( T ). y  X  preserves the labels, i.e., L ( v ) = L (  X  ( v )),  X  v  X  V S . y  X  preserves the parent relation, i.e., ( u , v )  X  E S iff (  X  ( u ),  X  ( v ))  X  E T . Frequent Rooted Query Pattern Tree. Let D denote all the query pattern trees of the frequent if its support is more than or equal to a user-specified minimum support . 3.2 Global Tree Guide We associate each QPT a unique ID, denoted as QPT.ID, which will be used for construction of global tree guide and mining process. Global Tree Guide. By merging all the query pattern tress, we construct a global tree guide (GTG), with each node recording ID list of query pattern trees. Each ID indicates that a query pattern tree with such ID contains the path from root to current node. In Figure 1 we show a GTG constructed using 10 query pattern trees. The QPT deal with special label like wildcard  X * X  and descendent path  X // X , we combine the special label and the following label to produce a new label. For example, a QPT order/items//Java in the GTG will be considered as a single path tree with nodes order, items and //_Java. 
We denote a subtree rooted at arbitrary n ode in the GTG as OT, a subtree rooted at the root node of the GTG as RT, and a single path staring at the root node as SRT. Frequent Node. The support of node in GTG is the number of QPTs that contain the QPTs. For example, the support of node Java is 6 / 10 = 0.6. A node in GTG is frequent if its support is no less than the minimum support. Lemma 1: The support of the node is no less than the support of its descendent node. Proof: A descendent node can be reached only through its ancestor in a QPT. If a contain the path from root to the ancestor node. Therefore, the support of ancestor is more than or equal to the descendent. frequent tree. Proof: Since the support of an RT will be no more than the support of a node in the RT, then an RT will be infrequent if an included node is not frequent. Lemma 3: If a node is frequent in the GTG, a SRT including it as the leaf node must be a frequent tree. Proof: As the support of a SRT equals to the support of the leaf node, a SRT will be frequent if the node is frequent. 
Assume the minimum support is 0.2. In Figure 1 the node Internet is infrequent, and an RT order/items/book/title/Internet is also an infrequent one. The node XML is a frequent node, and the SRT order/items/book/title/XML is also frequent. the less support of the descendent nodes. As a result, we can prune all the infrequent root level by level and prune infrequent nodes along with all its descendent nodes once we find an infrequent node. For example, in Figure 1 node Internet can be pruned since it is an infrequent node. 
Furthermore, to reduce memory space, we can compress the node and its child one child; 2) the parent node and the child node have the same ID list of QPTs. For node book/title. Compressed Global Tree Guide. Employing the infrequent nodes pruning scheme and nodes compressing scheme, we compress the GTG into a compressed global tree guide (CGTG). Figure 2 presents a CGTG transformed from GTG in Figure 1. BUXMiner performs a bottom-up process for generating frequent RTs in the CGTG. To generate frequent RTs rooted at node n in the CGTG, we will have to generate all frequent RTs rooted at all children of n firstly, and then merge discovered RTs rooted at child nodes. Figure 3 shows the high level structure of BUXMiner. We first scan all query pattern trees and construct a GTG. We then generate a CGTG by way of pruning and compressing nodes of GTG. We use the root node of the CGTG as an input to the recursive generating algorithm to obtain all frequent RTs. 4.1 Generating Freque nt Query Pattern Trees Query Pattern Tree Encoding. In stead of the standard data structure, such as the adjacency-matrix, the adjacency-list representation, we adopt a string encoding scheme to represent trees, which is first introduced by Luccio [12]. This encoding scheme is more space-efficient and is simpler to be manipulated [8]. To generate the Whenever a backtracking occurs from a child to its parent a distinguished label (-1 is example, the tree OT 1 in Figure 4 can be encoded as a string  X  X tems, book, title, Java, -1, XML, -1, -1, -1, CD, title, -1, -1, -1 X . Prefix Equivalence Class. We say that OTs in the CGTG are in the same prefix equivalence class, if and only if they share a maximal common prefix tree. Thus using previous tree encoding scheme any two members of an equivalence class has a same example, in Figure 4 trees OT 1 , OT 2 , OT 3 are in a same equivalence class since they share a common prefix tree CPT. In Figure 5 we show the algorithm for generating frequent rooted trees in the CGTG, which employs a bottom-up approach. Frequent trees rooted at a given node are generated using the following steps: Adding Root Node. Since we perform the searching process in a CGTG which has pruned all infrequent nodes, the tree with only root node is a frequent RT. We QPT from the root node (Lines 1-2). Obtaining Children FRTs. To obtain frequent rooted trees at a specified node, we strategy on the frequent trees rooted at child nodes. FRT is represented as a frequent rooted tree. We denote FRTS i as the set of frequent trees rooted at the ith child. Trees in FRTS i constitute an equivalence class since they have a common prefix tree which is the ith child node itself. 4.2 Merging Query Pattern Trees We show the tree merging process in Figure 6. We merge a prefix tree with all suffix trees from a set of equivalence classes. To avoid unnecessary computing, a pruning process is performed before support computing of candidate trees. We prune the new candidate k -size tree if it has infrequent ( k -1)-size rooted subtrees. We then compute ordered in an ascending order, the ID list of new tree can be computed quickly by way of merge join. If the new merged tree is a frequent one, we add it into both the FRTS set and the new equivalence class whose prefix tree is a combined tree of prefixTree and the common prefix tree of EQClassSet . The FRTS set contains all discovered frequent trees. And the CandSet contains all new generated equivalence classes which will be used in a next merging process. Tree Merging. Given a prefix tree T 1 , a suffix tree T 2 , and a common prefix tree CT of T 1 and T 2 , we merge the two trees T 1 and T 2 and produce a new tree with prefix T 1 . We denote the merging process as T = T 1  X  CT T 2 . The ID list of the created tree is the join result of two ID lists of the merged trees. Suppose the CT is represented as string  X  CT_Labels , -1 X . Then we can denote T 1 as  X  CT_Labels , T 1 _Follow_Labels , -1 X  and T2 as  X  CT_Labels , T 2 _Follow_Labels , -1 X . The constructed tree is represented as  X  CT_Labels , T 1 _Follow_Lables , T 2 _Follow_Labels , -1 X . In Figure 7 we shows a tree merging process, where the CT_Lables is the string  X  X rder, year, 2006, -1, -1 X , T _Follow_Labels is  X  X erson, Jane, -1, -1 X , and T 2 _Follow_Labels is  X  X tems, book, title, Java, -1, XML, -1, -1, -1, -1 X . Automatic Ordering. If trees in an equivalence class set EQ are ordered according to node order in CGTG, then trees in a new equivalence class set NEQ constructed by Because the tree merging process do not change the node label order, and only append result in an automatic ordering of the trees in each equivalence class. Once more, trees also generated after their rooted subtrees based on our candidate generating process.
 Candidate Pruning. Before computing the support of a k -size candidate tree, we carry out a pruning test to make sure that all its rooted subtrees are frequent. For the sake of saving time, we only check whether its ( k -1)-subtrees are frequent. According automatic ordering property of our candidate generating method, we can make sure all ( k -1)-subtrees have been enumerated. To efficiently perform the pruning step, during creation of frequent RTs, we add each frequent tree into a hash table. The key of each time to check for each rooted subtree. Space Reducing. The main consumption of space is the ID list of QPT for each frequent rooted tree. If a parent node has been computed, then all frequent trees rooted at the child nodes can be removed. In this way, the space consumption of our algorithm is the whole CGTG plus ID list for FRTs rooted at the current node and its children. In this section, we present experimental results of our BUXMiner algorithm compared to previous algorithms XQPMinerTID and FastXMiner. We implemented both our mining algorithm and previous algorithms in Java language and carried out all experiments on an Intel Xeon 2.8GHz computer with 3GB of RAM running operating system RedHat Linux 9.0. When performing experiments, all QPTs are loaded into memory. Thus there is no disk access when scanning datasets. 5.1 Workload We use the DBLP.DTD [13] and XMARK.DTD [14] as the schemas to generate QPTs. DTDs are converted into DTD trees by introducing some wildcard  X * X  and descendent path  X // X  to make the query pattern trees more complex. We add 5  X * X  and 5  X // X  into DBLP.DTD, and 6  X * X  and 6  X // X  into XMARK.DTD. Table 1 shows the characteristics of 100,000 query pattern trees generated using DBLP and XMARK respectively. 5.2 Performance Comparison We evaluate the performance of BUXMiner and compare it with XQPMinerTID and FastXMiner on both DBLP and XMARK with various dataset sizes and supports. Since we do not take semantic containment with wildcard and descendent path into considera-tion, we implement the Contains algorithm in XQPMinerTID and FastXMiner in a simple way, i.e., we just perform an ordinal subtree inclusion process. In Figure 8 we show the response time for three algorithms with varying number of QPTs from 50,000 to 250,000. The minimum support is 1% for each dataset. From figure we can see that BUXMiner outperform XQPMinerTID and FastXMiner by 20% ~ 40%. On the one hand, we prune infrequent nodes before candidate generation scans to compute supports of candidates. Although XQPMinerTID and FastXMiner particular situations like leaf node expansion. In despite of memory dataset scan in our experiments, it still spends much time. When the dataset is larger, the improvement is datasets, XQPMinerTID and FastXMiner show different performance. XQPMinerTID outperforms FastXMiner on the DBLP dataset. Nevertheless, FastXMiner performs more efficiently than XQPMinerTID on the XMARK dataset. In addition to its efficiency, BUXMiner scales linearly as the number of QPTs increases. 
In Figure 9, we show the performance of three algorithms with various supports from 0.1% to 1.5% on dataset with 100,000 QPTs. As previous results, BUXMiner still outperforms the other two algorithms on various supports. When the support is low, the improvement is more obvious. For a low support, more frequent rooted query patterns are discovered. Thus XQPMinerTID and FastXMiner will spend more time on scans of dataset. As the previous experiments, XQPMinerTID and FastXMiner present different performance on different datasets. 
We show the effect of pruning scheme for BUXMiner in Figure 10 and Figure 11. We adopt both the infrequent nodes pruning and ( k -1)-size pruning schemes when mining pruning schemes for No_Pruning experiments. In Figure 10 we show the effect of pruning scheme for various datasets from 50,000 to 250,000. Our pruning schemes improve the mining time about 10% ~30% with various size and supports. Figure 11 presents the effect of pruning scheme for various supports. Pruning scheme has greater impact on mining with higher supporpt. This is because we will prune more infrequent nodes in the CGTG with a higher support. Less nodes in the CGTG result in less enumeration of candidates. In this paper, we present an efficient algorithm called BUXMiner to discover frequent query patterns using a bottom-up enumerating method. We introduce a compressed global tree guide (CGTG) as a schema to accelerate candidate generation and infrequent tree pruning. We perform an efficient candidate generation using a bottom-up approach. We remove all infrequent nodes from the compressed global tree guide before candidate generation and generate candidates within each prefix equivalence class. Our approach no longer needs dataset scan since the supports of query pattern trees can be computed through CGTG. Experiments show that our proposed methods outperform the mining algorithm XQPMinerTID, FastXMiner. 
