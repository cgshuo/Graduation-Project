 The offering of anonymity in relational databases has at-tracted a great deal of attention in the database community during the last decade [4]. Among the different solution ap-proaches that have been proposed to tackle this problem, K  X  X nonymity has received increased attention and has been extensively studied in various forms. New forms of data that come into existence, like location data capturing user movement, pave the way for the offering of cutting edge ser-vices such as the prevailing Location Based Services (LBSs). Given that these services assume an in X  X epth knowledge of the mobile users X  whereabouts it is certain that the assumed knowledge may breach the privacy of the users. Thus, con-crete approaches are necessary to preserve the anonymity of the mobile users when requesting LBSs.
 In this work, we survey recent advancements for the of-fering of K  X  X nonymity in LBSs. Most of the approaches that have been proposed heavily depend on a trusted server component  X  that acts as an intermediate between the end user and the service provider  X  to preserve the anonymity of the former entity. Existing approaches are partitioned in three categories: (a) historical K  X  X nonymity, (b) loca-tion K  X  X nonymity, and (c) trajectory K  X  X nonymity. In each of these categories we present some of the most prevalent methodologies that have been proposed and highlight their operation. The enormous advances in positioning technologies like GPS, GSM, UMTS and RFID, along with the rapid developments in the wireless communications industry, have made possible the accurate tracking of user location at a low cost [3]. The increased tracking accuracy gave rise to a novel class of ap-plications which are based on user location, spanning from emergency response and  X  X earch &amp; rescue X  services (such as E X 911), to services that automate everyday tasks, such as online user navigation to avoid traffic jams and/or bad weather conditions, way X  X inding, store X  X inding and friend X  finding, as well as mobile commerce and surveying. All these services, including localized news and state X  X f X  X he X  art location X  X ased games that merge physical and virtual spaces, require an extensive use of location data and are collectively known as Location Based Services (LBSs). The benefit of LBSs both to the individual subscribers and to the community, as a whole, is undeniable. With respect to the public welfare, the collection of location data by a governmental or other public agency may enhance the pro-cess of decision making regarding tasks such as urban plan-ning, routing, wildlife rescuing and environmental pollution. As is evident, the new computing paradigm is changing the way people live and work. However, it also poses a series of challenges as it touches upon delicate privacy issues [1]. The offering of LBSs requires an in X  X epth knowledge of the subscribers X  whereabouts. Thus, with untrustworthy service providers the deployment of LBSs may breach the privacy of the mobile users. Consider, for example, a service request originating from the house of a user. The request contains sufficient information to identify the requester, even if it lacks of any other identification data (e.g., the user ID, the user name, etc.). This is true since the mapping of the exact coordinates that are part of the user request to a publicly available data source of geocoding information can reveal that the request originated from a house and thus increase the confidence of the service provider that the requester is a member of the household. Moreover, if a series of re-quests for LBSs are matched to the same individual then it is possible for the service provider to identify places that this user frequently visits, reveal his/her personal habits, polit-ical/religious affiliations or alternative lifestyles, as well as build a complete profile of the user based on the history of his/her movement in the system. Consequently, without the existence of strict safeguards, the deployment of LBSs and the sharing of location information may easily lead the way to an abuse scenario, similar to Orwell X  X  Big Brother society. To avoid this situation and adequately protect the privacy of the users when requesting LBSs, sophisticated algorithms have to be devised. The rest of this work is organized as follows. In Section 2 we present the centralized model for the offering of privacy in LBSs along with an example of its operation. Section 3 highlights the working assumptions that are used by most of the state X  X f X  X he X  X rt privacy preserving approaches in LBSs. Following that, in Section 4 we present a taxonomy of the existing centralized K  X  X nonymization approaches for the of-fering of privacy in LBSs. Finally, Section 5 concludes this work.
 Figure 1 presents a big picture of the centralized model for privacy in LBSs. In this model, we consider a population of users who are supported by some telecommunication infras-tructure, owned by a telecom operator. Every user in the system has a mobile device that periodically transmits a location update to some traffic monitoring system residing in a trusted server of the telecom operator. The commu-nicated location update contains the current location (and time) of the user and is stored by the trusted server. A set of LBSs are available to the subscribed users through service providers that collaborate with the telecom operator. We assume that these service providers are untrusted; if a user submits a request for an LBS directly to the service provider then his/her identity can be revealed and his/her privacy can be compromised. Motivated by this fact, the centralized pri-vacy model requires that every user request for an LBS has to be submitted to a trusted server of the telecom operator via a secure communication channel. The role of the trusted server (anonymizer) is to filter the incoming user requests and to produce anonymous counterparts that can be safely forwarded to the service providers in order to be serviced. To produce the anonymous counterpart to an original user re-quest, the trusted server has to incorporate algorithms that (a) remove any obvious identifiers that are part of the user request (e.g., ID, name) and (b) effectively transform the exact location of request into a spatiotemporal area (a.k.a. the area of anonymity ) that includes a sufficient number of nearby users registered to the system so as to prevent the attacker from locating the requester. These users formulate the anonymity set of the requester. The operation of the centralized privacy model is exempli-fied in Figure 2, where we assume a user Bob who asks for the nearest betting office B i to his current location. This is a typical nearest neighbor query that is commonly met in LBSs. Bob forwards his query (request) Q to the anonymizer. Then the anonymizer, who has knowledge of the current location of each user in the system, identifies 3 users who are near Bob and encloses all four users in a region R . Subsequently, instead of sending Bob X  X  location to the LBS provider, the anonymizer sends region R . When the LBS service provider receives R it computes all the betting offices that can be the nearest neighbor of any point in R . It is important to notice that although the service provider is certain that Bob is located within R , it has no means to identify the exact location of Bob in R . Using its database, the service provider generates a candidate set of answers (i.e. { B 1 , B 2 , B 3 , B 4 } ) and forwards it to the anonymizer. The anonymizer uses the actual location of Bob inside R to filter out all the false hits and forward the actual nearest neighbor
Figure 2: A use X  X ase scenario of the centralized model. (in this case B 1 ) to Bob. This step concludes the provision of the LBS in a privacy aware manner. The way that region R is formulated, as well as the privacy guarantees that are offered to the requester by the system, are based on the spe-cific privacy methodology that is employed by the trusted server. Several centralized K  X  X nonymity approaches have been pro-posed for the offering of privacy in LBSs. In what follows, we present the working assumptions about the capabilities of the attacker that are employed by most of these approaches. The knowledge of the assumptions is necessary to compare the different approaches in terms of privacy guarantees that they offer to the requesters of LBSs. Generally, the attacker is assumed to have the following capabilities: 1. The attacker can intercept the region where anonymity 2. The attacker has knowledge of the algorithms that are 3. The attacker can obtain the current location of all the 4. The attacker tries to breach the location privacy of the The main body of research for the offering of privacy in LBSs includes approaches that are based on the notion of K  X  X nonymity. K  X  X nonymity, originally proposed by Sama-rati and Sweeney [11, 12] in the context of relational data, requires that  X  X ach data release must be such that every combination of values of private data can be indistinctly matched to at least K individuals X . In this sense, K  X  X nonymity requires that every record in a released dataset is indistin-guishable from at least K  X 1 other records with respect to a certain set of identifying variables. In the context of LBSs, the identifying variable is the location of the individuals when requesting LBSs; releasing a request of an individual for an LBS to an untrusted third party should make certain that the actual location of request cannot be associated (at least with a high probability) with the identity of the re-quester. To satisfy K  X  X nonymity in LBSs, the most widely adopted anonymization strategy is cloaking . In cloaking, the actual location of request is transformed into a bounded area that is large enough to contain the requester along with (at least) K  X 1 other users. Cloaking ensures that the iden-tity of the requester cannot be disclosed with a probability that is significantly larger than 1 / K , among K  X 1 other users. Some of the most prevalent cloaking strategies that general-ize the actual locations of request to spatially bounded ar-eas, are presented in Figure 3. They can be partitioned into two groups: data X  X ependent cloaking and space X  X ependent cloaking methodologies. Data X  X ependent cloaking strategies formulate the region of anonymity based on the actual location of each user in the system and his/her distance from the location of request. Specifically, distance X  X ased cloaking algorithms (e.g., [1, 7, 15]) retrieve the K  X 1 nearest neighbors of the requester and generate a region that includes all the K users. In K  X  X ucket cloaking (e.g., [2, 9]) the users are arranged into groups of K and the anonymity region is computed as the Minimum Bounding Rectangle (MBR) that contains the K users in the group of the requester. Space X  X ependent cloaking strategies take into consideration the total area that is covered by the anonymizer to formulate the regions of anonymity. Specifically, grid X  X ased cloaking strategies (e.g., [6, 8, 10]) partition the area in a grid fashion and generate the region of anonymity by retrieving the users in each cell of the grid (starting from the cell of the requester and moving to neighboring cells) until at least K users are found. On the other hand, region X  X ased cloaking strategies, such as [5], use the spatial properties of the area to generate rectangles centered at the location of request and to utilize them for the offering of K  X  X nonymity.
 In what follows, we present the different research directions for the offering of K  X  X nonymity in LBSs. Alongside the pre-sented methodologies, we include some examples to demon-strate their operation. Location K  X  X nonymity approaches (e.g., [5, 8 X 10]) protect user privacy by utilizing the current location (instead of the history of collected locations) of each user in the system. They operate on LBSs that require a single location trans-mission from the requesting party in order to be successfully provided (e.g., store X  X inder, friend X  X inder, etc.), instead of the communication of multiple location updates. The dif-ferent cloaking strategies that have been proposed for the offering of location K  X  X nonymity are presented in Figure 3. In what follows, we detail over some of the most popular approaches in this category.
 Clique Cloak [5] is a graph X  X ased (region X  X ased) approach that mutually anonymizes multiple incoming requests for LBSs. For each query that is received for servicing, the al-gorithm generates a rectangle centered at the location of the requester, with its sides being parallel to the considered x and y X  X xis, respectively having  X  x and  X  y extents. The new query is then marked as a node in a graph for as long as it awaits for its anonymization. Two vertices (queries) in the graph are connected together if the corresponding users fall in the rectangles of each other. An edge of the graph demon-strates that the requester of each of the two queries can be included in the computed anonymity set of the other, and thus, a K  X  X lique of the graph shows that all the correspond-ing K requests can be anonymized together (thus offering K  X  X nonymity to all the K users that participate in the K  X  clique). Finally, tight to each request is a temporal interval  X  t that defines the maximum amount of time that this re-quest can be retained by the system for its anonymization. If a K  X  X lique cannot be found within  X  t then the request is dropped as unserviceable. Figure 4 demonstrates the opera-tion of Clique Cloak in the case scenario where three queries for LBSs (located at U 1 , U 2 and U 3 ) have been synchronously submitted to the trusted server. Assuming that K = 2, the generated rectangles for U 1 and U 2 fall in each other and thus they form a 2 X  X lique in the graph. As a result, the MBR enclosure of the respective rectangles (shown here in gray) represents the Anonymity Spatial Region (ASR) where 2 X  X nonymity is offered to these users. On the other hand, the request of U 3 has to wait in the system until a new query (formulating a 2 X  X lique with U 3 ) arrives. As one can observe, Clique Cloak may affect the quality of service that is offered to the users as the servicing of some queries may be substantially delayed, while other queries may be dropped as unserviceable. The approaches that follow do not suffer from these shortcomings.
 Center Cloak [9] is a distance X  X ased approach that provides a na  X  X ve solution to K  X  X nonymity in LBSs. In Center Cloak , the K  X 1 nearest neighbors of the requester are retrieved and the ASR is computed as the MBR enclosure of all the K users. By construction, Center Cloak suffers from what is known as the  X  X enter X  X f X  X SR X  attack; the identity of the requester can be accurately guessed with a probability that far exceeds 1 / K as he/she is expected to be close to the cen-ter of the ASR. The  X  X enter X  X f X  X SR X  attack is an instance of a more general problem that is worth mentioning. Since cloaking algorithms are expected to be publicly available (see assumption 2 of Section 3), attackers can easily exploit any implementation decisions with respect to the placement of the requester to the generated ASRs. As an effect, sev-eral of the currently available approaches suffer from similar kinds of attacks.
 A randomized variant of Center Cloak , which offers increased uncertainty regarding the location of the requester in the generated ASR, is Nearest Neighbor Cloak ( NN X  X loak ) [9]. In NN X  X loak the ASR is formulated as follows: Given a user query for an LBS, NN X  X loak first retrieves the K  X 1 near-est neighbors of the requester. Second, it randomly selects one among the K users and identifies his/her K  X 1 nearest neighbors. Finally, the K  X  X SR is constructed as the MBR enclosure of the second set of K users, augmented (if neces-sary) to include the requester. Figure 5 presents an example where 3 X  X nonymity is offered to user U 1 by using NN X  X loak . First, U 1 formulates set S 1 = { U 1 , U 2 , U 3 } with his/her two nearest neighbors. Second, NN X  X loak randomly selects U 3 from S 1 and computes his/her two nearest neighbors in the system. This leads to set S 2 = { U 3 , U 4 , U 5 } . Finally, the MBR of S 2 is augmented to include the requester U 1 , lead-ing to the 4 X  X SR for U 1 that is shown in Figure 5. Since the probability of selecting the requester from S 1 when formu-lating S 2 is at most 1 / K (due to random choice), NN X  X loak is not vulnerable to the  X  X enter X  X f X  X SR X  attack.
 Casper [10] is one of the most popular grid X  X ased approaches to location K  X  X nonymity. In Casper the entire area that is covered by the anonymizer is divided in a grid X  X ashion and organized in a pyramid data structure of layers that is simi-lar to a Quad X  X ree [13] (see the pyramid structure in Figure 3(b)). The top layer of the pyramid contains the entire area, whereas the lowest level of the pyramid collects the finest X  X rained granularity of the partitioning. Each cell in the lowest level of the pyramid has a minimum size that cor-responds to the anonymity resolution. When a new query for an LBS is received by the trusted server, Casper locates the lowest X  X evel cell in the pyramid that contains the requester and examines if this cell also contains K  X 1 other users. If the cell contains enough users then it becomes the K  X  X SR. Otherwise, Casper searches the horizontal and the vertical neighbors of this cell to identify if the number of users in each of these cells, when combined with the number of users in the cell of the requester, suffice for the provision of location K  X  anonymity. If this is true, then the corresponding union of cells becomes the K  X  X SR. Else, Casper moves one level up in the pyramid to retrieve the parent (cell) of the cell of request and repeats the same process until the K users that will for-mulate the ASR are found. Figure 6 provides an example of this cloaking operation. Assuming a request coming from cell  X  (0 , 2) , (1 , 3)  X  (where (0,2) are the lower X  X eft and (1,3) the upper X  X ight coordinates of the cell) with an anonymity requirement of K = 2, the returned ASR is the same cell. In the event that a query with the same anonymity require-ments is issued from cell  X  (1 , 2) , (2 , 3)  X  the returned ASR is the union of cells  X  (1 , 2) , (2 , 3)  X  X  X  X  (1 , 3) , (2 , 4)  X  . Interval Cloak [8] is very similar to Casper as it also par-titions the total area that is covered by the trusted server into equi X  X ized quadrants and organizes this information in a Quad X  X ree structure. However, Interval Cloak does not consider the neighboring cells at the same level when com-puting the ASR, but instead it directly ascends to the an-cestor level in the pyramid. As an example, in Figure 6, a request for an LBS that is issued by U 3 or U 4 will generate As is evident, Casper is more effective in producing com-pact ASRs when compared to Interval Cloak . However, as is proven in [9], both Interval Cloak and Casper are secure only for uniform data distributions.
 Hilbert Cloak [9] does not suffer from this shortcoming as it generates the same K  X  X SR, no matter who among the par-ticipants of the anonymity set requested the service. The proposed approach is based on K  X  X ucket cloaking; it dy-namically arranges the users into groups of K and computes the ASR as the MBR enclosure that contains the K users in the group of the requester. Hilbert Cloak creates an one X  dimensional mapping of the position of each user. In the proposed mapping, locations that are near each other in the two X  X imensional plane, are expected to also lie near each other to its one X  X imensional transformation. For each re-quest with an anonymity requirement of K , Hilbert Cloak partitions each K users in the system into a bucket accord-ing to their Hilbert values. Following that, Hilbert Cloak retrieves all the K  X 1 users that lie in the same bucket as the requester, and formulates the K  X  X SR as their MBR enclo-sure. An example of this operation is presented in Figure 7, where we consider 10 users whose IDs are sorted in ascend-ing order based on their Hilbert values. Given a query for an LBS from U 3 with an anonymity requirement of K = 3, Hilbert Cloak uses the rank of the user (here 3) to dynami-cally identify the bucket in which he/she is partitioned (here is the first bucket). Then, it retrieves all the users who are partitioned in the same bucket as the requester (i.e. U 1 and U 3 ) and returns their MBR as the computed ASR for this request (see the 3 X  X SR shaded region in Figure 7). No-tice that any query with an anonymity requirement of K = 3 originating from any of U 1 , U 2 , would generate the exact same 3 X  X SR as the one that is generated for U 3 . Further-more, it must be noted that Hilbert Cloak can generate the bucket that contains the requester on X  X he X  X ly based on the rank of each user in the system. Historical approaches to K  X  X nonymity (e.g., [1,14,15]), keep track of the movement history of each user in the system and utilize this information when building the anonymity regions for the user requests. Compared to other method-ologies for the offering of K  X  X nonymity in LBSs, in historical K  X  X nonymity approaches the participants of the anonymity set are selected based on their history of movement in the system, with the requirement that at some time in their history of movement these users were close to the point of request. Ref. [14] states this observation as  X  X sing users X  footprints instead of their current positions, for cloaking X . Refs. [1, 15] consider the area that is covered by the trusted server as a set of Places X  X f X  X nterest (POIs) defined for each user in the system. Each POI has a spatial extent and can be related to an unanchored temporal interval. It represents a place that is frequently visited by a user based on his/her history of movement in the system, as well as the approxi-mate time X  X f X  X ay (represented as a time interval) of these visits. A series of POIs (along with their corresponding time intervals) that are frequently visited in sequel by a user can be considered as hazardous with respect to the privacy of the user when requesting LBSs, as such requests can easily disclose his/her identity.
 The trusted server monitors the users to identify when they request LBSs from any of their POIs. When a user trans-mits a request for an LBS from one of his/her POIs, the trusted server computes an area along with a time interval that contains the requester, as well as K  X 1 other users who happened at sometime in the past to pass by the location of the request. The computed area is said to be (histori-cally) K  X  X nonymous as it protects the requester by guar-anteing that his/her location cannot be identified with a probability that is larger than 1/ K , among the other K  X 1 users. The whole anonymization process is guided by a set of spatial and temporal constraints; the spatial constraints require that the generated region of anonymity is within some reasonable spatial bounds so as to allow the provision of the requested LBS, while adequately hindering the actual location of request. On the other hand, the temporal con-straints impose a barrier on how back in time (starting from the point of request) should the history of movement of all the users in the system be searched, so as to retrieve the participants of the anonymity set. Following the computa-tion of the anonymity region, the trusted server forwards the request containing the cloaked user location to the service provider for servicing. When a subsequent request is re-ceived from the same user, the trusted server tries to match this request to the next POI in his/her sequence of POIs, and if the match is successful it recomputes the area along with the time interval that contains the requester, as well as his/her K  X 1 original neighbors.
 Ref. [14] uses the history of movement of all the users in the system to apply a recursive top X  X own partitioning of the area that is covered by the trusted server into equi X  X ize quadrants. Each cell of the partitioning is divided into quad-rants up to the point that it contains at most N users who have visited this cell sometime in their movement history. By using this structure alongside a hash table that records the user IDs and the trajectories for the users of each cell, the proposed approach requires that each user who wishes to request an LBS has to first communicate a base trajectory to the trusted server. A base trajectory T = { c 1 , c 2
Figure 8: K  X  X nonymity based on historical movement. defines the itinerary that the user will follow in the system, where each c i corresponds to a location update on the tra-jectory on which the user will move. In response, the trusted server computes a new trajectory T 0 = { C 1 , C 2 , . . . , C that provides K  X  X nonymity to the user when using the LBS throughout his/her declared itinerary. Each C i in T 0 corre-sponds to a region of (historical) K  X  X nonymity that contains the requester (base trajectory) along with K  X 1 users based on their historical trajectories in the system. Whenever the user arrives at c i he/she informs the trusted server who, in turn, uses the K  X  X nonymity region of C i to continue to pro-tect his/her privacy. Figure 8 demonstrates the operation of the algorithm for the offering of historical 3 X  X nonymity to a requester of an LBS based on his/her computed base trajectory. Trajectory K  X  X nonymity approaches (e.g., [2, 6, 7]) are ap-propriate for preserving the privacy of the users who request LBSs that cannot be offered in just a single communication of the user with the service provider. As an example, con-sider a car navigation service, in which the current position of the user has to be communicated to the service provider for as long as the user travels to his/her destination (so that he/she receives updated directions). The approaches of this category are responsible for protecting the whole trajectory of the requester from the time of request until the service provision. Such services are called continuous and the corre-sponding requests are termed as continuous queries . It is im-portant to mention that contrary to historical K  X  X nonymity approaches (such those of [1,14]), which can also protect the user trajectory by providing K  X  X nonymity to the requester of LBSs, trajectory K  X  X nonymity approaches generate the K  X  X SRs by utilizing the current instead of the historical movement of the users in the system to adequately cover up the trajectory of the requester. In what follows, (a) we mo-tivate the necessity for trajectory K  X  X nonymity methodolo-gies by discussing the limitations of location K  X  X nonymity approaches, and (b) we provide a partitioning of the trajec-tory K  X  X nonymity algorithms along two principal directions, as well as discuss some of the most prevalent approaches in each direction. Location K  X  X nonymity approaches suffer from correlation attacks which prevent them from protecting the requesters of continuous queries. As indicated in [2], the identity of the requester can be easily revealed based on the participants of his/her anonymity set. Figure 9 demonstrates how this is possible. Imagine a query submitted at time t i by user A for a continuous service. The applied location cloaking strategy (e.g., [8,10]) generates the 5 X  X SR shown in Figure 9(a) that includes the requester along with four of his/her neighbors: B, C, D and E . As the user moves, he/she needs to transmit a new location update to the service provider for the contin-uation of the service provision. Thus, at time t i +1 the user sends a new query to the trusted server containing his/her new location. However, the users in the neighborhood of the requester have also moved in the meanwhile and thus the new 5 X  X SR that is produced by the employed location K  X  X nonymity algorithm (i.e. { A, B, F, G, H } ) has only user B in common with the previously generated ASR. As a re-sult, if an attacker knows the two ASRs he/she can safely conclude that the requester is either A or B , which signifi-cantly reduces the actual degree of anonymity that is offered to A from 1 / 5 to 1 / 2. In the next location transmission, at t i +2 , the identity of the requester is revealed since no other participant in his/her current ASR was also part of all the previous ASRs.
 To alleviate from correlation attacks, existing approaches to trajectory K  X  X nonymity ensure that all the K participants of the first K  X  X SR will also participate in all the subsequently computed K  X  X SRs, as produced by the cloaking algorithm. This way of eliminating the query tracking attack is pre-sented in Figure 9(b). Generic approaches to trajectory K  X  X nonymity do not take into consideration any particular movement behavior of the requester of an LBS (as well as of the other users in the sys-tem), when providing him/her with trajectory K  X  X nonymity. Instead, all requests for LBSs are handled in exactly the same manner by the trusted server, no matter what the lo-cation of request is or the path that the user follows in the system during the LBS provision.
 Ref. [2] proposes the first algorithm for trajectory K  X  X nonymity in LBSs. The main idea is to require that a user belongs in a group of at least K  X 1 other users prior to sending a con-tinuous query for an LBS. The generated K  X  X SR in each location transmission of the user is computed as the MBR enclosure of all the users in the group of the requester, based on their location in the system. It is important to mention that while a request for an LBS is in progress, no grouped user that participated to the original anonymity set of the requester is allowed to leave the group, as this action would jeopardize the privacy of the requester. Personalized approaches to trajectory K  X  X nonymity utilize the history of movement of all the users in the system to cope with correlation attacks in continuous user queries. They differ from generic approaches to privacy in LBSs, primarily due to the following reasons: (a) they drop assumption 4 (Section 3) by consider attackers who have knowledge of the users X  movement behavior in the system and can use their knowledge of the frequent movement patterns of the users to breach user privacy, (b) they depict the movement of each user u in the system as a continuous function f ( u, x, y, t ), instead of a set of individual locations and times, (c) they automatically derive a set of frequent movement patterns per user based on his/her history of movement in the sys-tem, which are subsequently used to protect his/her privacy when requesting continuous LBSs, and (d) they can offer trajectory K  X  X nonymity to the requesters of LBSs by as-suming an underlying network topology of user movement, instead of a grid X  X ased, free X  X errain solution.
 Ref. [6] provides a trajectory K  X  X nonymity solution that uses the history of movement of the users in the system to derive a set of frequent mobility patterns per user. Each of these patterns corresponds to a route (instead of a se-quence of POIs and related time periods, as in [1]) that is frequently followed by the corresponding user in the system and is stored as an f ( x, y, t ) function, having both a spatial and a temporal extent. The proposed algorithm identifies those frequent routes of a user that are rarely followed by many other users in the system. These routes are termed as unsafe for this user, as they can disclose his/her iden-tity when requesting LBSs from within any of them. In [6] a grid X  X ased, free X  X errain solution is employed that utilizes the computed unsafe routes of the users, in order to provide them with K  X  X nonymity when requesting LBSs.
 In [7] a network X  X ased privacy model is proposed that con-siders an underlying network of user movement in order to derive the unsafe routes of the users and to offer trajectory K  X  X nonymity to the requesters of LBSs. With respect to the offering of K  X  X nonymity, the proposed approach considers two spatial cloaking strategies, depending on the location of the requester at the time of request, as well as his/her subse-quent locations until the provision of the service. In partic-ular, K  X  present (the so X  X alled weak) trajectory anonymity identifies K  X 1 users that are close to the requester at the time of request and thus could have issued the request for the LBS. On the other hand, K  X  frequent (strong) trajectory anonymity, collects the subjects who were near the requester at the time of request and for whom the currently traveled route of the requester is also frequent. In this paper, we presented a survey on the state X  X f X  X he X  art centralized K  X  X nonymity approaches for the offering of privacy in LBSs. The aim of the presented methodologies is to protect the location of the requesters of LBSs in both static and continuous queries. On the other hand, a new and very prominent body of research regards K  X  X nonymity methodologies that protect the content of the user query in addition to the location of the user. We believe that future work in this research direction will lead to more robust and thorough methodologies that better protect the privacy of the user when requesting LBSs. [1] C. Bettini, X. S. Wang, and S. Jajodia. Protecting pri-[2] C. Y. Chow and M. F. Mokbel. Enabling private con-[3] R. Clarke. Person location and person tracking  X  [4] J. Domingo-Ferrer, editor. Inference Control in Statis-[5] B. Gedik and L. Liu. Location privacy in mobile sys-[6] A. Gkoulalas-Divanis and V. S. Verykios. A free terrain [7] A. Gkoulalas-Divanis, V. S. Verykios, and M. F. Mok-[8] M. Gruteser and D. Grunwald. Anonymous usage of [9] P. Kalnis, G. Ghinita, K. Mouratidis, and D. Papadias. [10] M. F. Mokbel, C. Y. Chow, and W. G. Aref. The new [11] P. Samarati. Protecting respondents X  identities in mi-[12] P. Samarati and L. Sweeney. Protecting privacy when [13] H. Samet. The Design and Analysis of Spatial Data [14] T. Xu and Y. Cai. Exploring historical location data for [15] P. Zacharouli, A. Gkoulalas-Divanis, and V. S.
