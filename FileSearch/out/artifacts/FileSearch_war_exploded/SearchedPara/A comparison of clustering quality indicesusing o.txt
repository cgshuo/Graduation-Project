 Campus de Montegancedo, Madrid, Spain Departamento de Arquitectura y Tecnolog  X  ia de Sistemas Inform  X  aticos, Facultad de Inform  X  atica, Universidad Polit  X  ecnica de Madrid, Campus de Montegancedo, Madrid, Spain 1. Introduction
Exploratory problems are one of the big challenges of data mining and are often tackled using clustering techniques. This type of problems are usually much more dif fi cult to evaluate than supervised classi fi cation problems because ther e is no  X  X round truth X  . Because of this, t he quality of each output solution is closely related to the domain problem. In spite of this, there are lots of clustering quality indices (CQIs) that try to assess the quality of the solution. To do this, indices tend to rate compact and isolated clusters highly. This partition quality is often used as a stopping rule for fi nding the correct number of clusters for a data set. Following this guideline, Milligan and Cooper [16] ranked 30 CQIs on an extensive battery of data sets without impurities (clear cluster structures). However, these data sets had different con fi gurations where the number of variables and instance distribution density levels varied, that is, instances were not equally distributed in each hidden group. Hierarchical clustering was used as the approach for grouping the data. This comparison is still considered as one of the main references for clustering validation even though the work was developed 25 years ago. This is exempli fi ed by current works dealing with the same issue [19]. These authors used the same type of data sets as [16] but changed the evaluation approach by introducing another type of CQIs for validation. The problem is clear separation and cohesion of the clusters. This is an utopian scenario in real problems, since there are usually irrelevant or noisy features or even no cluster structure in the data set. Throughout this document we use Millig an and Cooper X  X  ranking as reference because of the great number of CQIs compared in that work, but there are some other references in literature that attempt to evaluate some CQIs using different clustering algorithms and kind of data, like in [22,23]. Another very recent paper comparing internal cluster validation indices is [6]. This paper attempts to obtain a standard methodology for evaluating some clustering indices using hierarchical clustering approach. They consider that it is necessary not
Regarding the CQIs and based on clustering validation literature, some authors [21] indicated that there are two groups of CQIs: internal and external. Meanwhile, other authors [7,10] discussed the existence of a third group, called relative indices. Internal validation does not require knowledge of the ground truth; the quality of a partition using internal CQIs is assessed by eva luating each indi vidual p artition based on distance or dissi milarity measures. The problem with this appro ach is how each partition is built, since the quality is probably measured with different criteria than were used to build the partition, which can lead to incorrect validations. On the other hand, external validation is more accurate but not realistic in clustering. In this case, the ground truth must be known and the evaluation is carried out based on this knowledge. Although there are many CQIs, some of them are equivalent [1]. The relative index concept varies depending on the above-mentioned authors. It is also interesting to note that, as indicated in [27], the CQIs suffer from biases not only with regard to the data (shape or number of clusters for instance), but also to the clustering algorithm used to obtain the partition. For this reason, and as we list in the following and detail in the next section, fi ve different CQIs are used and, moreover, different clustering algorithms are used to partition the different kind of data.
 The fi ve internal CQIs that have been introduced in the comparison are: Silhouette [18], Calinski [3], C-index [9], DaviesBouldin (DB) [4] and Gamma [2]. Silhouette was the only CQI not compared in [16], butitiswidelyusedindifferent fi elds, like genomics [13] or neuroscience [12] for example. The external CQI used is adjusted Rand index (ARI) [8]. This index is an improvement on the also very well-known Rand index [17].

This work focuses on using each CQI as a stopping rule for fi nding the real number of groups in clustering using close-to-real domains for the purpose of evaluating the proposed indices. Using the CQIs in this way is an important and common step in clustering. Thus, we compare here some of the most used CQIs in different scenarios to output some behaviour patterns that can help decision making on what index should be used depending on the problem at hand and how it is solved. The scenarios are created using different databases that aim to simulate real cases, having different percentages of outliers or noisy dimensions. Besides, data are partitioned using three different clustering approaches and one random algorithm to check if the behaviours of the indices differ in each case. Finally, and following [19], an external CQI is used as support for the validation.

The remainder of this paper is organised as follows. Section 2 presents the work method, the databases used and a brief explanation of each algorithm and index used. The experimental process is commented in Section 3. In Section 4, the experimental results are presented by the different criteria, whereas Section 5 explains the conclusions drawn from the results and some discussion.
 2. Material and methods
The above fi ve internal CQIs were compared using different data partitioning methods. Differences in data are related to impurities, such as noisy dimensions or outliers. All these details are presented in the following. 2.1. Databases used
The data sets were generated using the original cluster data generator software described in [15]. All data sets are detailed in the following, where they are divided into three groups. The fi rst group ( clear ) is composed of data sets with strong and distinct clusters. The second group ( out5 and out10 )hasdata sets generated with 5% and 10% outliers (instances that do not belong to any prede fi ned cluster) and the last group ( noi1 and noi2 ) has data sets with 1 or 2 added random noisy dimensions (variables that do not contribute to separating the clusters).

The number of data sets in each group depends on the number of dimensions, clusters and types of density used. Thus, there are 36 data sets in the fi rst group, resulting from combining 4 different number of clusters in the data (fro m 2 to 5 clusters), each w ith different dimensions (4, 6 or 8) and 3 different density levels designed to change the cluster sizes and the instance distributions. At the fi rst level of density each cluster has the same number of instances; at the second level one cluster always contains 10% of instances; and at the third level one cluster contains 60% of instances. The size of each data set in this fi rst group is 50. The second group is divided into data sets with 5% and 10% outliers. There are 48 data sets in each subgroup since a new dim ensionality (10 variables ) is added on top of all the combinations explained for the fi rst group. Besides, 105 and 110 instances are used in each data set, respectively. Finally, the last two data sets have 100 instances each, but one noisy dimension is added in noi1 and two noisy dimensions are added in noi2 , again outputting a total of 48 data sets. Therefore, 228 data sets are used in the comparison here. 2.2. Clustering algorithms
Three clustering algorithms us ed in different approaches were used to par tition each data set: K-means [14], hierarchical clustering [11] using Ward X  X  method [20] and model-based clustering using Gaussian mixtures and the expectation-maximization (EM) algorithm [5]. All three algorithms are the maximum exponents of different approaches and a re well-known in the clust ering literature. The fi rst two are hard clustering approaches (each instance belongs to only one cluster), whereas the model-based Apart from these, data were random ly partitioned as if it were another a lgorithm. For each data set, this random strategy was executed for 50000 iterations in an attempt to achieve statistical signi fi cance for each case. 2.3. Clustering quality indices
The study compares fi ve internal CQIs, using one external CQI to check if clustering algorithms are able to fi nd the correct cluster structure. All used indices were designed for being used with hard clustering algorithms, then the partitions built using model-based clustering were adapted for evaluation with the indices. There are many others CQIs that are not considered in this work, some examples are the Dunn index [24], Je(2)/Je(1) [26] or the Beale index [25]. 2.3.1. Internal indices 2.3.1.1. Silhouette
The Silhouette coef fi cient [18], s ( i ) , is calculated for each instance i as follows: where a ( i ) is the average dissimilarity between instance i and all other points in the cluster to which i belongs ( C for instance) and b ( i ) is the minimum average dissimilarity to the instances of each cluster and is in the [  X  1 , 1] range. A high value indicates good quality clusters. 2.3.1.2. Calinski
This index [3] consists of fi nding well isolated clusters and is based on two measures that evaluate separation, between-cluster sum of squares ( BSS ), and cohesion, within-cluster sum of squares ( WSS ): where K is the number of clusters and N is the total number of instances. The aim is to fi nd a value of K that maximizes the index. This indicates isolated and uni fi ed clusters. 2.3.1.3. C-index This index [9] is de fi ned as: where d w is the sum of distances over all pairs of instances from the same cluster. If p is the number of pairs of instances in the same cluster, max( d w ) and min( d w ) are the sum of the p largest and smallest distances, respectively, considering all the pairs of instances. Again, this index should be minimized and is con fi ned to the interval [0 , 1] . 2.3.1.4. Davies-bouldin This index [4] is calculated by averaging each pair of clusters as: value for the DB index is small since this corresponds to compact and well-separated clusters. 2.3.1.5. Gamma This measure is also known as Baker and Huberts index [2] and is de fi ned as: s (+) being the number of consistent comparisons and s (  X  ) the number of inconsistent comparisons. Comparisons are made between all clusters pairwise and all between-clusters pairwise dissimilarities. A comparison is consistent if a within cluster distance is less than a between-clusters distance, otherwise it is considered as inconsistent. The target value of this index is the maximum value and it is bounded by 1. 2.3.2. External index 2.3.2.1. Adjusted rand index
The ARI [8] was created as an improvement on the Rand index [17]. The context to de fi ne these indices is: given a set of N objects, suppose S and T are two different partitions to be compared (one partition can be assumed to be the result of clustering and the other one to be the real label and we unify the name of the classes in the known partition and the clusters in the clustering results as  X  X roups X ). Then, a is the number of pairs of objects that are located in the same group in S and in T , b is the number of pairs of objects in the same group in S but not in T , c is the number of pairs of objects in the same group in T but not in S ,and d is the number of pairs of objects in different groups in both partitions S and T . Then, the Rand index is de fi ned as
The problem of the Rand index is its value when t wo random partitions are com pared, since it does not take a zero (minimum) value. The ARI was proposed to overcome this limitation concerning the random partitions. The ARI, like the Rand index, lies between 0 and 1, the latter being the value output when two partitions are equal. The ARI is calculated as: 3. Experimental process
The methodology consisted of creating the partitions , using the three clustering algorithms (K-means, hierarchical and model-based clustering) and the random grouping algorithm for all the possible number of clusters (from 2 to 5) fo r each data set and using the CQIs to ev aluate each built partition. Thus, if 4 different algorithms and 4 cluster combinations are used for each data set, 228  X  4  X  4 = 3648 partitions are evaluated with 5 internal and 1 external CQIs. The external CQI, ARI, is used as external validation to assess the qua lity of each built pa rtition again st the real partition, whic h is known beforehand.
For each index evaluation, the best number of clusters for each index is the maximum or the minimum value depending on the CQI. This choice will be correct if the chosen number of clusters matches the real number of clusters known beforehand. Otherwise, the choice will be classed as wrong irrespective of the distance to the real number of clusters. Besides, evaluating the external CQI, it is possible to fi nd out if the clustering algorithms were able to fi nd the real clusters structure for each data set in spite of correct or incorrect choices by the internal CQIs of the number of clusters.

All these points are evaluated on the above-mentioned data types, outputting results for data with non-overlapping ( clear ) clusters. Data with outliers and data with noisy dimensions are then added to compare the behaviour of the CQIs with these data types. 4. Results
The fi rst results are presented in Table 2. Table 2 shows the number of correct decisions on the number of clusters output by each CQI and each clustering algorithm in all the databases used (228 data sets). Clearly, the number of correct decisions output by the ARI is very high. This means that the clustering algorithms were able to fi nd the correct cluster structure in many situations, especially when they had to fi nd 2 or 3 clusters. In the case of internal indices, Calinski achieved the best results with around 70% of correctly identi fi ed clusters. It was followed by, Silhouette, DB and Gamma, which all achieved very similar results. C-index was the clear loser in this fi rst comparison. It was interesting to note however that this index was at least as competitive as Silhouette, DB or Gamma at fi nding 5 clusters.
Regarding the clustering algorithms, K-means behaved better when used with Calinski and C-index, whereas hierarchical clustering outperformed the other algorithms when used with Silhouette, DB or Gamma. Interestingly, EM was the best algorithm only when used with ARI, which was the most precise index. 4.1. Index behaviour in data sets with outliers
The results using the 96 data sets with 5% and 10% of outliers are shown in Table 3. They were different from the general results shown in Table 2. In this case, the biggest differences depended on the clustering algorithm used. For example, there was a 20% difference in the number of correct decisions using K-means and hierarchical clustering in Silhouette. This also applies to C-index, where EM returned around 26% and K-means around 51% correct decisions. In any case, the internal CQI with the highest percentage of correct decisions was again Calinski, but, taking into account all three clustering algorithms, Gamma had a worse mean than C-index. This algorithm achieved a better result than before thanks mainly to the improvement in the K-means output.

The behaviour of clustering algorithms with each CQI was very similar to before, and there were no signi fi cant differences. A minor difference was that K-means used with C-index performed much better than the other clustering algorithms. Proportionately, the other differences among the three clustering algorithms were unchanged.

With the appearance of outliers, the results for t he internal CQIs were very poor. Again, ARI output high outcomes, which means that the clustering algorithms found the cluster structures. However, the internal CQIs were not able to fi nd the structures used as stopping rules to determine the number of clusters. 4.2. Index behaviour in data sets with noise
The results using the 96 data sets with 1 and 2 dimensions of noise are shown in Table 4. In general, the results of the internal CQIs improved in data sets with these characteristics compared with outliers. This applies for Silhouette, DB and Gamma. The difference in Calinski was more balanced, whereas C-index was the big loser in data sets with noise. The number of correct decisions on the number of clusters using C-index was very low, mainly when the number of clusters was not 5. Because of these results, C-index was the lowest ranked internal CQI in this comparison. On the other hand, Gamma, which was the index with the poorest results in data se ts with outliers, achieved the best results in data sets with noise.
Another interesting feature of these results was the improvement of EM, which outperformed K-means and hierarchical clustering when used with Silhouette or Calinski and was at least as competitive as the others when used with C-index or Gamma. 4.3. CQI evolution depending on the data sets
Another important aspect to be examined in this work is how each CQI evolves when data change from  X  X lean X  clusters to data with outliers or noisy dimensions. Thi s could lead to conclusions about how these new data characteristics affect the behaviour of a CQI and determine when it a particular combination of CQI and clustering algorithm is better.

The complete evolution is shown in Fig. 1. One of the most interesting fi ndings was that C-index performed worse with the clear data sets than with outliers. However, when Calinski was used to fi nd the correct number of clusters in data sets with 5% outliers, the outcomes were at least as competitive as in clear data sets. One important point for examinatio n here was how the introduction of more outliers or noisy dimensions affected the behaviour of each index. Silhouette performed worse in data sets with outliers than in data sets with noise, but the intr oduction of the second noisy dimension had a bigger effect than the switch 5% to 10% outliers. This situation was even more marked using Calinski, since the performance decreased substantially compared with the other data sets when the second noisy dimension was introduced. DB and Gamma behaved similarly: results for data sets with outliers were very poor, whereas values for one noisy dimension data sets were competitive compared with clear data sets. When the second noisy dimension was introduced, the performance decreased. The exception was the C-index discussed above. Performance with this index was generally very low, but the results with K-means and hierarchical clustering were better when outliers were introduced. This was exception among internal CQIs, but not compared with ARI, since the external CQI performed better in data sets with outliers than in data sets with noise.
 Regarding the algorithms, EM and hierarchical clustering achieved the best results compared with K-means for clear data sets. For data sets with outliers, hierarchical clustering achieved results that were at least as good as the other clustering algorithms with all the internal CQIs, except for C-index, where K-means was the winner. In data sets with noisy dimensions, there was not a very clear pattern of clustering algorithm behaviour. The top cluster algorithms changed depending on the CQI and whether there was 1 or 2 noisy dimensions.

Besides the number of correct decisions on the number of clusters in a data set, another factor for evaluation was how the value of each index changed depending on the characteristics of the data. The mean values of each CQI for each data situation are shown in Fig. 2. Remember that the aim of Silhouette, Calinski, Gamma and ARI is to maximize the value, whereas the lower the value of C-index and DB the better. In general, the addition of noisy dimensions affected the values of all the indices more, and performance was worse. C-index was again an exception, because the values for the clear data sets were worse than for data sets with outliers. Note a lso that, when outliers were introduced in C-index previously, this index returned a better percentage of correct decisions, here again, when index value is observed, the introduction of outliers improved t he behaviour of the C-index value. As regards how the introduction of more outliers or more noisy dimensions affected th e output values, the performance of Calinski and Gamma decreased considerably when the second noisy dimension was introduced. In general, the addition of 5% of outliers affected the performance of all indices except for C-index and ARI. 4.4. Random groups and clustering algorithms
After running the studies using different clustering algorithms to partition the data, a different approach was introduced. Data was randomly partitioned to com pare the behaviour of the CQIs with the returned values previously when cluste ring algorithms were us ed. There are 50000 ra ndom partiti ons for each data set, outputting t he same number of qua lity assessments fo r each CQI analyzed in the study. As this was a random approach, we consider the speci fi ed number of repetitions in an attempt to achieve statistical signi fi cance.

In this case, we are not interested in how similar the random partitions are to the original groups, and the external CQI is not used to assess this aspect . The aim of evaluating random partitions with the internal CQIs is to compare these assessmentswith evaluations using the clustering algorithms and output the percentage of random executions that scored better values than clustering algorithm validations.
The results are shown in Table 5. Table 5 shows that Silhouette and Gamma were the two more logical indices. Logical means indices whose partitioning evaluation results with clustering algorithms were not usually outperformed (less than 0.66% of times ) by random partitioning. On the other hand, random partitions assessed with Calinski, C-index and DB indices scored different percentages depending on the data type and the clustering algorithm. In the  X  X alinski-data type X  tandem, when noi2 data sets are partitioned, clustering algorithms are beaten only by a maximum of 0.66% of executions. In all the other data sets, this percentage is signi fi cantly greater, ranging from 4.91% of random partitions, which beat the score with hierarchical clustering in out10 data sets, to 11.13% using the same algorithm to partition noi1 data set. In the case of C-index, when this index evaluated partitions output with K-means, the results were beaten by random partitioning from a 4.58% of cases in noi2 data sets to 13.17% in out5 data sets. When out5 data sets are partitioned with the EM-based clustering algorithm, the percentage of cases in which random partitioning scored a better val ue for C-index is 0.59%; in all other cases using EM or hierarchical clustering, this value incr eased up to a maximum of 7. 95%. Random pa rtitioning evaluated with the DB index outperformed the clustering algorithms in fewer than 1% of the cases for clear data sets, but again this value increased up to 8.85% for out10 data sets with EM-based clustering.
Another interesting result was the clear tendency of each internal CQI to choose an  X  X xtreme X  number of clusters as correct. In the case of Silhouette and C-index, this number of clusters was 2 (which was the minimum number of clusters used in this study). On the other hand, Calinski and DB tended to choose 5 clusters, which was the maximum number of clusters. Gamma was the only index that was not so biased to a set number of clusters. 5. Conclusions The work of Milligan an d Cooper [16] established an interesting ranking presenting a lot of internal CQIs. A conclusion of that work was that the data set was an important factor in fl uencing the good or bad behaviour of internal CQIs. This is a recurrent scenario, and it is very hard to fi nd a dataset independent index. In spite of this, it is important to know how the most important indices behave in more complex databases to be able to choose one or another depending on the characteristics of the problem.
This work throws light on the behaviour of some of the best known index is used to cluster data sets with outliers or noise. Some conclusions that should b e taken wisely were that C-index was the worse index presented here due to its generally low precision, unchanged even when noisy dimensions were added to the database. Besides, this index does not behave as expected, because it achieved better results in data sets with outliers than in da ta sets without outliers or noisy dimensions. In Milligan and Cooper X  X  ranking, C-index was placed third, but this index does not appear to be so interesting if the data set contains impurities. On the other hand, Calinski achieved the best mean of correct decisions. Note, however, how the performance dropped considerably using this index when the second noisy dimension was added to the database. It dropped again when the number of dimensions was incremented.

Another important issue was to fi nd a stable index. In this respect, Gamma was not outperformed by random groups, was not biased to a set number of clusters and was not so much affected by the introduction of the second noisy dimension did as the other indices. Silhouette X  X  performance was not bad when noisy dimensions were added, but it was affected by outliers and also by the increased number of dimensions. A similar thing applies to the DB index, but its quality is generally slightly fi nd clear patterns indicating the best algorithm-index combinations. In general, hierarchical clustering returned more promising results than K-means or the EM algorithm, but this should not be seen as a categorical conclusion because the differences depended on the characteristics of each data set. Based on these conclusions, if these indices were to be ranked, Gamma would placed fi rst, followed by Silhouette and Calinski, with DB one step below and C-index at the bottom of the ranking. Finally, in an attempt to clarify the conclusions drawn from the study, Table 6 summarizes the studied parameters for each internal CQI.
 All these conclusions are obtained using data with outliers and with noisy dimensions as indicated. A possible future line of this work is to include other kinds of data, like data with missing values for example. Also following this line, other clustering algorithms can be used to partition the data. Assessing this work provides new guidelines on for using a speci fi c index depending on the characteristics of the data set.
 Acknowledgments
This research is partially supported by the SpanishMinistry ofScience and Innovation projectTIN2010-20900-C04-04, the Cajal Blue Brain project and also Consolider Ingenio 2010-CSD2007-00018.
 References
