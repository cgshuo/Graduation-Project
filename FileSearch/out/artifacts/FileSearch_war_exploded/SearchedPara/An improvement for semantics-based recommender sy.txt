 1. Introduction
Discovering products that meet the needs of the consumers are crucial in such competitive environments as online shopping. Recommender systems assist in advertising tasks by automati-cally selecting the most appropriate items for each user as per his/ her personal interests and preferences ( Adomavicius and Tuzhilin, 2005 ). Research in recommender systems started back in the early 1990s, but the greatest advances have been due to the irruption of recent technologies like those of the Semantic Web ( Berners-Lee et al., ). It has been proved that semantics-based recommender systems can outperform previous approaches by exploiting two main elements: a knowledge base  X  typically an ontology  X  that represents semantic features or attributes of the available items, and filtering strategies based on semantic reasoning techniques that discover relevant relationships between the users X  preferences and the items to be recommended (see examples in Hung, 2005 ;
Middleton et al., 2004 ; Yuan and Cheng, 2004 ; Blanco-Ferna  X  ndez et al., 2008 ; Pazos-Arias Jose  X  et al., 2008 ; Blanco-Ferna  X  ndez et al., 2010 ).

Obviously, keeping the users X  satisfaction high requires means to adapt the selection of items as their interests evolve over time.
For many years, in most of the existing filtering strategies, data collection about the users X  interests was regarded as a static process, weighing equally the ratings given by the users at different times. Later, some researchers proposed time-aware approaches that made the last observations more significant than the older ones, which means assuming that a user X  X  interest in a product always decreases from the moment of the last purchase (see examples in Maloof and Michalski, 2000 ; Schwab et al., 2001 ;
Duen-Ren and Ya-Yueh, 2005 ; Ding and Li, 2005 ; Lee and Park, 2009 ). This may be true in certain areas of application, such as personalized programming guides that recommend TV programs to the users. Notwithstanding, the interest in (or the need for) commercial products in general may actually increase or vary in diverse forms over time. For example, if a user has just bought a dishwasher, it is foreseeable that he/she will not need another one until the average lifetime of such appliances has passed; therefore, the interest estimations should follow an increasing function, and any recommender system should prioritize other products for some time. Likewise, the interest for seasonal clothes may vary along the year, while the interest in books and music may remain constant and school equipment may have a peak at the beginning of the academic year.

The main research contribution of this paper is an improve-ment to the current filtering strategies, aimed at increasing the effectiveness of semantics-based recommender systems in online shopping. The basic assumption is that the influence of time can be radically different not only for different types of items as explained above, but also for different users. For instance, whereas car tires typically have a lifetime of 6 years for average drivers, it is expectable that taxi drivers or users interested in car tuning and motor sports need more frequent replacements (say, every 6 months). Analogously, it makes sense not to recommend dolls for some time after an average user has bought one, but the same is not true for doll collectors. Briefly speaking, our new approach makes tailor-made selections of items by exploiting the semantics formalized in an ontology to link items (and their features) to time functions, whose shapes are corrected by considering the preferences of like-minded individuals and the effects of time in their purchasing behaviors.

The paper is organized as follows. Section 2 includes a review of recommender systems literature to highlight the differences between the management of time in previous works and in our new filtering strategy. Next, Section 3 details the main parts of our personalization framework, while in Section 4 we focus on the algorithmic internals of our time-aware filtering strategy.
Section 5 presents the results of experiments we have carried out (with real users) to assess the personalization quality achieved by the new filtering strategy in comparison with exist-ing approaches. Finally, Section 6 provides a summary of conclu-sions and the motivation of our ongoing work. 2. Related work
Research in recommender systems is hectic nowadays, in an attempt to address the many new questions raised by the growing number of practical applications. Next, we provide an overview of the milestones in recommenders history, and thereafter focus on the issues of producing time-aware recommendations in online shopping, which remain practically unexplored in literature. 2.1. Background on recommender systems
Given a set of items, the goal of a recommender system is to identify the most suitable ones according to the information stored in a user X  X  profile by adopting diverse filtering strategies.
The first strategies merely looked at demographic information (e.g. age, gender or marital status) to recommend items that had interested other users with similar data. The results so obtained tend to be imprecise and fail to reflect changes of the user preferences over time (because personal data are often stable for long periods). This problem was addressed by content-based filtering , that looks for items similar to others that gained the user X  X  interest in the past ( Adomavicius and Tuzhilin, 2005 ; Dias et al., 2008 ). This strategy is easy to adopt, but bears a problem of overspecialization : the recommendations tend to be repetitive for considering that a user will always appreciate the same kind of items. Furthermore, the limited data available about new users makes the first results highly inaccurate.

To tackle these problems, the scientific community came up with collaborative filtering , that proceeds by evaluating not only the profile of the target user (the one who will receive the recommendations), but also those of users with similar interests (his/her neighbors) ( Schafer et al., 2001 ; Montaner et al., 2003 ).
This approach can solve the lack of diversity in the recommenda-tions, but faces problems like the sparsity when the number of items is high (which makes it hard to find users with similar evaluations for the same items) or the treatment given to users whose preferences are dissimilar to the majority (the gray sheep ).
There exist hybrid approaches that attempt to neutralize the weaknesses and combine the strengths of content-based and collaborative filtering, e.g. recommending items similar to the ones listed in the user X  X  profile, but considering two items similar if the individuals who show interest in the one tend to be interested in the other ( Papagelis and Plexousakis, 2005 ; Burke, 2002 ; Li et al., 2005 ).

Both in content-based filtering and collaborative filtering, the user profiles are typically initialized from stereotypes which are mechanisms that provide general descriptions for a set to similar users ( Rich, 1979 ). Actually, stereotypes allow to build models of individual users on the basis of a small amount of information about them (e.g. age, occupation, lifestyle, etc.). As described in Montaner et al. (2003) , Shani et al. (2007) , Kobsa et al. (2001) and Krulwich (1997) , stereotypes have also been widely adopted in diverse filtering strategies for the selection of the most appropriate recommendations for each user.

Regardless of the filtering strategy, it is noticeable that most of the recommender systems have relied on syntactic matching techniques, that relate items by looking for common words in their attached metadata. Even though there exist plenty of different approaches, they all miss much knowledge during the personalization process, because they are unable to reason about the meaning of the metadata. A syntactic approach is also a source of overspecialization, because the recommendations so computed can only include items very similar to those the users already know ( Adomavicius and Tuzhilin, 2005 ).

To go one step beyond in personalization quality and diversity, research is now focused on applyi ng techniques from the Semantic
Web, that allow to gain insight into the meaning of words. The key here lies within the use of ontologies to describe and interrelate items and their attributes by means o f class hierarchies and proper-ties ( Staab and Studer, 2004 ). Thus, many authors have enhanced the traditional filtering strategi es with semantic reasoning mechan-isms, to discover the items that b est match the preferences of each user by reasoning about thei r semantic descriptions. Hung (2005) , proposed a recommender system for one-to-one marketing based on a taxonomy of products, revealing the advantages of such semantics when it came to providi ng instant online recommenda-tions and identifying potential customers upon release of a new product. Middleton et al., 2004 explored a novel ontological approach to user profiling within s emantics-based recommender systems, coping with the problem of recommending academic research papers; the experiments s howed that profile visualization and feedback outperformed previo us user modelling approaches, which led the authors to conclude that the semantics captured by their ontological approach made the profiles easier to understand.
The authors of Yuan and Cheng (2004) investigated analogy struc-tures between heterogeneous products (i.e., products with different properties) to recommend items that are disparate from others the users had purchased, using what they called an ontology-driven coupled clustering algorithm.

We have previously explored the benefits of semantics-based recommender systems in other domains. In Blanco-Ferna  X  ndez et al. (2008) , we proposed an ontology-driven recommendation system to select the most appealing TV programs for the users. In Pazos-
Arias Jose  X  et al. (2008) , we incorporated a similar semantics-enhanced approach into a t-learning platform to recommend personalized educational courses according to the users X  prefer-ences and previous knowledge. Finally, in Blanco-Ferna  X  ndez et al. (2010) , we exploited the benefits of semantics-driven reasoning in a tourism recommender system. 2.2. Background on time-aware filtering approaches
For the purposes of this paper, it is important to note that all of the abovementioned approaches were time-unaware, inasmuch as they did not include any mechanisms to take into account the influence of time on the user X  X  interests, preferences and needs. The first attempts to consider this effect consisted in introducing gradual forgetting functions, to make the most recent observations more significant than the older ones during the computation of recommendations ( Koychev, 2000 ; Maloof and Michalski, 2000 ; Schwab et al., 2001 ; Duen-Ren and Ya-Yueh, 2005 ). Specifically, when a new item was added to a user X  X  profile, its weight was set to 1 and the values of the other items were decreased. Most often, this was done as per a constant decay rate, but some authors considered different rates for different item classes and even supplementing recency with other information. Indeed, the authors of Ding and Li (2005) presented an approach to trace changes in the purchase interests of each user and thereby compute personalized decay factor. In Ding et al. (2006) , the same authors extended their initial approach by using weights for items based on their expected accuracy on the future preferences and making decisions based on data arrival time. More recently, the authors of Lee and Park (2009) motivated the exploitation of other temporal information to improve the accuracy of a colla-borative filtering strategy. Specifically, they presented an approach that involved item launch times (indicating the age of the items), purchase times (denoting the age of the users X  preferences) and the time difference between both (representing the temporal gap between when an item is released and when a user purchases it). Although it is clearly more sophisticated, this approach ultimately comes down to the same assumption of gradual forgetting, i.e., that the interest of the user in an item always decreases from the moment of the last purchase.
In Blanco-Ferna  X  ndez et al. (2008) , we presented the first time-aware filtering approach that reckoned the fact that, in general applications of recommender systems (and, particularly, in online shopping), the interest in (or the need for) certain items may actually increase over time. In that paper, we harnessed the conceptualization provided by an ontology to link the classes and attributes of the items to time functions that modelled dependences with regard to absolute dates or purchase times. Although the experimental results showed that this approach could outperform time-unaware filtering proposals (see Blanco-Ferna  X  ndez et al., 2008 ), we guessed that the effectiveness of the recommender system could improve even further by considering that the influence of time can be radically different for different users (recall the motivation examples given in Section 1). There-fore, in this paper, we shall enhance the approach presented in Blanco-Ferna  X  ndez et al. (2008) to involve not only item classes but also user preferences in modelling time dependences. To this aim, we propose to modify the shape of the default time functions (i.e., the ones defined in the ontology for average users) by means of an adaptive group correction , built from consumption stereo-types that cluster together users who share some of their preferences. We do not consider individual corrections  X  as they did in Ding and Li (2005) to tailor decay rates  X  because it would be unfeasible to gather sufficient information from every single user to accurately characterize his/her potential interest in all item classes over time. Instead, it makes more sense to consider the success or failure of the recommendations made to like-minded individuals. 3. Our personalization framework
This section describes the main elements of our new persona-lization framework: the domain ontology and the parameterized time functions attached to its nodes; the individual user profiles and the stereotypes that model the preferences of groups of users; and the group corrections that modify the default time dependence curves. The new time-aware filtering strategy enabled by these elements will be presented in Section 4. 3.1. Including time concerns in the domain ontology
Since we are considering the recommendation of items in the scope of online shopping, we need an ontology that formalizes typical concepts and relationshi ps in this domain. The creation of such an ontology is problematic due to the high degree of specificity (that leads to a very large number of concepts) and the need for timely maintenance, owing to the continuous innovations that take place in the domain of products and services. Therefore, we did not intend to create an ontology covering all possible types of items, but rather to use one that could be easily extracted from some of the classification standards availabl e for industrial products and ser-vices. To this aim, we looked at standards like UNSPSC, 1 eOTD 3 and the RosettaNet Technical Dictionary, 4 which reflect some level of community consensus and contain multiple definitions of hierarchically organized concepts. Finally, we chose eCl@ss as the main input for creating the domain ontology, due to the reasons of completeness, balance and maintenance discussed in Hepp et al. (2007) . More specifically, we have borrowed from eClassOWL  X  the
OWL ontology for products and services developed by Hepp (2006)  X  many concepts referred to categoriz ations of commercial products, and we have also defined new properties and classes to accommo-date some missing features. Along with the multiple hierarchies of classes that serve to categorize the commercial products and their attributes, the ontology contains labeled properties joining each item to its attributes and seeAlso properties to link strongly related items. The ontology was populated by retrieving information from multiple online retailers. A brief excerpt is depicted in Fig. 1 ,where classes, items and attributes are denoted by gray ellipses, white squares and white ellipses, respectively.

Our new approach to time-aware filtering starts out by associating parameterized time functions to item classes and attributes, in order to model the variation of the potential interest of each type of product or any of its features with regard to absolute dates or purchase times. Most commonly, the specific time function associated to a given item is chosen based on the marketing criteria handled by the providers. We handle functions with diverse shapes, including combinations of constant, linear, exponential, sinusoidal, parabolic, hyperbolic and elliptic seg-ments, with values between 0 and 1. As a rule of thumb, low values are intended to prevent the recommendation of the items, whereas high values are intended to promote them. We also require valid functions to take the maximum value (1) at some point, corresponding to the time an item or an attribute is potentially most interesting for a general audience.

Next, we shall exemplify some of the functions (see Table 1 )to explain how the time-aware filtering works:
Monotonically increasing function . Some items are purchased sporadically due to their long average lifetime (e.g. consumer electronics devices, vehicles and household appliances). The interest for such products can be modeled by a function that grows (linearly or exponentially) from the time of purchase.
The zero value of the function coincides with the instant when the user bought the product (denoted by T 1 in Table 1 ), whereas the maximum value 1 is reached once its lifetime has expired ( T 2 ).
Monotonically decreasing function . Some seasonal items (e.g. swimming pool supplies) are useful during a limited period and their utility decreases over time. In such cases, the temporal dependence can be modeled with a function that takes the maximum value up to the beginning of the season (instant T 1 in Table 1 ) and decreases monotonically (linearly or exponentially) afterwards. The zero value is reached once the seasonal period has ended (instant T 2 ).

Rectangle function . A rectangle function (see Table 1 ) can be bound to products that may be repeatedly purchased during a given period of time. This is the case, for example, of nougat bars, which are mainly available around Christmas  X  out of those months, the zero value of the function prevents such products from appearing in any recommendation.

Constant function . A constant (time-unaware) function can be linked to products that the user may purchase daily, such as books or personal hygiene items.

As we shall explain later, the time function to use for a specific item during the recommendation process is computed from the functions linked to the classes it belongs to, and also from the functions linked to its attributes. By default, attributes are associated to a constant function of value 1, which can be modified as per marketing criteria (remember examples about nougat bars given in the description of the rectangle function), while each class inherits the temporal behavior of its immediate superclass. In any case, it is also possible to disregard the inheritance process by manually assigning specific functions to the classes and attributes of specific items. 3.2. Building group corrections from user profiles and stereotypes
Up to this point, everything is independent of the individual preferences and needs of any user (as it was in Blanco-Ferna  X  ndez et al., 2008 ), so we need additional artifacts to incorporate the users X  personal interests into the filtering process. To this aim, for the reasons explained at the end of Section 2.2, we do not proceed individually, but rather with groups of users who may be clustered together as per some of their preferences. Next, we shall explain the structure of the user profiles we have been handling to capture the knowledge available about the user, and then introduce a notion of stereotypes to characterize the preferences of groups of users (potential audiences for certain products).

In our work, a user X  X  profile stores various data, including a record of the items he/she bought in the past, the classes and attributes that describe those items in the ontology and the time of the last purchase. Furthermore, each item is linked to a number between 1 and 1 that measures the degree of interest (hereafter DOI ) of the user in it ( 1 represents the greatest disliking; 1 the greatest liking). In formal notation, this number is denoted by DOI  X  i , U  X  X  x A  X  1 , 1 and represents the interest of the user U in the item i. DOI indexes may be given explicitly by the user, or inferred indirectly by monitoring his/her interaction with the recommendations (e.g. if a user decides to buy a recommended item, then we can assume a very positive rating for it  X  see Lo  X  pez-Nores et al., 2010 for more examples). In any case, the DOIs of the items propagate to attributes and classes as follows:
The DOI of an attribute is calculated by averaging the ratings of the items that are joined to it in the ontology. In the excerpt from ontology depicted in Fig. 1 , for example, the attributes given by the user to books b 1 and b 2 (0.8 and 1, respectively).
At the bottom of the hierarchy, the DOI of a leaf class is calculated by averaging the ratings of all the items that belong to it. Upwards, each class averages the DOIs of its child classes, assuming a neutral rating (of value 0) for unrated classes. For example,  X  X  History  X  X  in Fig. 1 receives a DOI of 0.9, halfway between those of the books b 1 and b 2 , whereas  X  X  Books  X  X  receives 0.45 as the average of  X  X  History  X  X  and  X  X  Sciences  X  X .
Our stereotypes take the same form as the individual profiles, though completely void of information that might serve to identify individual users. In other words, a stereotype is an excerpt from the ontology with attached DOIs. These DOIs can be anonymously updated from the given/inferred ratings of the users, just knowing their degree of membership to the stereotype in question (a number whose computation will be explained later). Actually, the feedback messages include (i) the user X  X  degree of membership to a given stereotype, (ii) the rating given to (or inferred for) an item, and (iii) the time when the rating was given/inferred. We use that information to build and maintain a function called group correction , intended to modify the default time dependence that results for an item from its classes and attributes. Starting with the zero function that is assumed by default (i.e., in the absence of feedback), we compute one group correction gc  X  C m , S j , t  X  for each class C m of a stereotype S function of time, using the procedure depicted in Fig. 2 :
First, we record the ratings received for items belonging to the class C m in the different time instants.

Second, we build a pulse train by averaging the ratings of each instant, weighed by the degrees of membership to the stereo-type S j of the users who provided them.

Finally, we approximate the pulse train by a natural smoothing spline ( Eubank, 1999 ), so that each piece of feedback has an effect over a period of time and not only at the specific time instant for which it was issued. The resulting curve is trimmed between 1 and 1.

We devised group corrections as an additive adjustment of the items X  time functions, so the res ult of the sum  X  trimmed between 0 and 1 and normalized to take the maximum value 1  X  yields another time function. As shown in Fig. 3 , the corrections can completely modify the shape of the temporal dependence curves, as needed to reckon the fact that the purchasing behaviors of certain people may be radically different from those of the majority.
Furthermore, due to the corrections, it is not really important whether the item providers choose, say, a linearly increasing function or an exponentially increasing one as the default time dependency of their products, because the feedback gathered from the users will end up modelling the desired behavior (the one that optimizes users X  satisfaction with the recommendations). 4. Our filtering strategy
Having introduced the elements of our personalization framework, we can now describe our new semanti cs-based time-aware filtering strategy, which follows a four-step process as depicted in Fig. 4 :
Step 1: Stereotype-driven pre-filtering . Initially, we perform an offline pre-filtering process driven by the available stereotypes, using a semantics-based similarity metric to sort out the different items by their potential interest for different groups of users.
Step 2: Classification of the user into stereotypes . In order to refine the pre-selection and obtain the temporal dependence curves that affect a given user U i , it is necessary to identify the stereotypes in which he/she fits best ( S 2 and S N in Fig. 4 ).
Step 3: Reasoning-driven filtering . Having classified the user U match the pre-selected items against the preferences captured in his/her profile, applying a semantic reasoning procedure that brings together content-based and collaborative filtering.
Step 4: Time-driven filtering . Finally, we assess the current interest of the user U i in the items selected in step 3 by considering the time functions of their classes and attributes and the group corrections computed for the stereotypes in which he/she fits best. 4.1. Step 1: stereotype-driven pre-filtering
The pre-filtering consists of computing a matching level between each item I k in the ontology and each one of the stereotypes, S j (denoted by matching  X  I k , S j  X  ). Intuitively, I marked as a potentially interesting item for users that fit in S when the matching level exceeds a configurable threshold a
The computation of matching le vels relies on a semantic simi-larity metric to compare I k with each item I r rated in S metric considers two items similar when (i) they have a very specific common ancestor in a class hierarchy of the ontology, (ii) they have common attributes, or (iii) they have sibling attributes (i.e., attributes belonging to the same class in some hierarchy). For example, the sunglasses sg 1 and the snow boots sb 1 have  X  X  Skiing equipment  X  X  as their lowest common ancestor in our domain ontology (which is one degree more specific than  X  X  Winter Sports equipment  X  X ); the movies m 1 and m 2 share the attribute of involving the same starring actor; and the books b 1 about the fall of the Bastille and b 2 about the Old Regime Crisis have sibling attributes because they deal with different events bound to the French Revolution . Obviously, we get high similarity values when the compared items are very close in a hierarchy, and when they have many common and sibling attributes. The calculus is given by Eq. (1): SemSim  X  I k , I r , S j  X  X  depth  X  LCA  X  I k , I r  X  X  max  X  depth  X  I In this expression, we have three main contributions: The first addend valuates the relationship between two items
I k and I r by considering their distance in a hierarchy. This process involves the following parameters: The second addend valuates the similarity between the items
I k and I r by taking into account their common attributes and the ratings defined in the stereotype S j , as shown the follow-ing parameters: ; Analogously, the last addend focuses on the similarity between
I k and I r by considering the existence of sibling attributes between both items and the ratings in the stereotype S j . The parameters involved in the computation are:
The matching between an item I k and a stereotype S j is high when I k is very similar to items that appear with high DOIs in S .
 The value is given by Eq. (2): matching  X  I k , S j  X  X  1 NI  X  S where: NI  X  S j  X  is the number of items rated in S j ; I m is the m -th of those items; DOI  X  I m , S j  X  is the rating of I m in S j ;
SemSim  X  I k , I m , S j  X  is the semantic similarity between I the item I m rated in S j . 4.2. Step 2: classification of the user into stereotypes
In order to measure up to what point a user U i is represented by a stereotype S j , we compute a degree of membership (denoted as DOM  X  U i , S j  X  ) as follows:
First, we create a rating vector for U i  X  denoted by V U including the DOI indexes of the most significant classes in his/her profile (i.e., the ones with DOIs close to 1 or 1, representing the items that are most appealing or unappealing to him/her).

Second, we create a rating vector for each stereotype S j denoted by V S j  X  including the DOIs it assigns to the classes of V U i .

Finally, the degree of membership of U i to S j is computed as the Pearson-r correlation ( Middleton, 2003 ) between the two vectors as per Eq. (3): DOM  X  U i , S j  X  X  corr  X  V U i , V S j  X  X 
As usual in the literature related to the creation of users X  neighborhoods ( Adomavicius and Tuzhilin, 2005 ; Montaner et al., 2003 ), we consider that the user U i is represented by the stereotype S j if DOM  X  U i , S j  X  exceeds a configurable threshold 4.3. Step 3: reasoning-driven filtering
After classifying the user, our filtering strategy focuses on the items (identified in step 1) that were found suitable for the stereotypes that represent him/her (identified in step 2). For each one of those items, I k , we compute a time-unaware recommen-dation value for the user U i by content-based filtering and collaborative filtering criteria: like-minded users is driven by the same procedure as the classification of the user into stereotypes: roughly, we create and correlate the rating vectors of U i and the other users, selecting as neighbors the ones who yield the M greatest correlation values. Then, U i  X  s predicted rating for I k denoted by PredRating  X  I k , U i  X   X  is computed by Eq. (5), where the interest of U i  X  s neighbors in I k is measured by the DOIs they have provided for it, or by the matching level between their preferences and I k if no DOIs are available: PredRating  X  I k , U i  X  X  1 M d  X  N p  X  X  J M is the size of U i  X  s neighborhood; J N p is the p -th of U i  X  s neighbors;
J corr  X  V U i , V N p  X  is the correlation between the rating vectors
As indicated by Eq. (6), the time-unaware recommendation value of the item I k for the user U i (denoted as RV  X  I taken as the matching level between I k and the items rated in
U  X  s profile if I k was selected by content-based filtering, or as
U  X  s predicted rating for I k if it was selected by collaborative filtering: 4.4. Step 4: time-driven filtering
The final step of our filtering strategy consists of assessing the current interest of the user in the items selected by semantic reasoning. To this aim, we multiply the time-unaware recom-mendation value given by Eq. (6) by a factor CI  X  I k , U results from valuating the item X  X  time function  X  modified by the pertinent group corrections  X  at the current instant t 0 :
RV  X  I k , U i , t 0  X  X  RV  X  I k , U i  X  CI  X  I k , U i , t 0  X  X  7  X  The computation of CI  X  I k , U i , t 0  X  involves two components:
First, we consider the time functions associated to the classes and attributes of the item I k in the ontology. In the computa-tion of the (uncorrected) time function for the item I k ,as indicated by the first addend of Eq. (8), we average the functions of its classes and reshape the resulting curve multi-plying by the time functions of its attributes.

Second, we take into account the group corrections corre-sponding to the classes of I k as per the stereotypes in which the user U i fits best. As shown in the second addend of Eq. (8), the influence of the group correction corresponding to those classes in each stereotype S j is weighed by the degree of membership of the user U i to it. ci  X  I k , U i , t  X  X 
Having done this, we truncate values to fit the range [0, 1] (Eq. 9) and, finally, we normalize to have the maximum value 1 at some time (Eq. 10). cii  X  I , U i , t  X  X 
CI  X  I , U i , t  X  X  cii  X  I k , U i , t  X  max In these expressions:
NC  X  I k  X  is the number of classes that the item I k belongs to in the ontology, C m being the m -th; NA  X  I k  X  is the number of attributes joined to I k in the ontology,
A l being the l -th;
NS  X  U i  X  is the number of stereotypes in which the user U DOM  X  U i , S j  X  is the degree of membership of U i to the stereotype
S ; f  X  C m , t  X  is the value of the time function associated with class
C f  X  A l , t  X  is the value of the time function associated with attribute A l ; gc  X  C m , S j , t  X  is the value of the group correction corresponding to the class C m as per the stereotype S j .

An item I k is finally recommended to the user U i if the time-aware recommendation value computed by Eq. (7) exceeds a configurable threshold a 5 . The values of our a i thresholds (with i
A f 1 , 2 , 3 , 4 , 5 g ) must be set and tuned empirically, depending on what policies are considered most suitable when it comes to deciding what items are relevant for each stereotype (in case of ), what users belong to each stereotype ( a 2 ), and what items are relevant to each user ( a 3 , a 4 and a 5 ). If the granularity of the items X  and users X  characterization is high enough, we can be picky and choose values 1; if the characterizations are coarse (as it commonly happens when there are few items or users), we have to be more permissive and choose lower values. In the tests we will describe in the next section, we have used a 1  X  0 : 6,  X  0 : 7, a 4  X  0 : 7 and a 5  X  0 : 75. 5. Experiments and evaluation
We have made experiments in laboratory to corroborate two research hypotheses:
First, we postulate that the consideration of time helps improve the accuracy of the recommendations. To validate this hypothesis, we compared the success of the recommenda-tions made by three filtering approaches, which we will be referring to as follows:
J Purely reasoning-based filtering (abbreviated as PRBF ): as
J Uncorrected time-driven filtering ( UTDF ): this approach com-
J Group corrections-driven filtering ( GCDF ): this is the
The second hypothesis focuses on the two time-aware approaches, stating that group corrections serve to achieve more accurate recommendations than the parameterized time functions alone.

The evaluation was organized as per the flow diagram depi-cted in Fig. 5 . First, we gathered information about the prefer-ences of a set of real users, who interacted with a prototype we had developed for the testing of recommender systems in online shopping. Next, we categorized the users into three groups, so that each group would receive only the recommendations pro-duced by one of the three filtering strategies mentioned above. After receiving and processing the feedback provided daily by the users, we repeated the personalization process by making new recommendations for each user day after day over the whole testing period. Next, we processed all the data gathered from the users in statistical tests, previously validating certain conditions required to run these tests. The last step of the evaluation was the interpretation of the attained results. 5.1. Adapting the MiSPOT prototype
The users in our experiments interacted with the MiSPOT system presented in Lo  X  pez-Nores et al. (2010) , which enables a non-invasive and personalized form of advertising to domestic and mobile Digital TV receivers. Originally, the system relied on PRBF to select advertisements suited to the preferences, interests and needs of each individual viewer. Thereupon, it uses multi-media composition abilities defined by the MPEG-4 standard to blend the advertising material with the TV program the user is viewing at any time. The advertisements can be set to launch interactive commercials, as shown in the snapshot depicted in Fig. 6 .

Taking advantage of the modular design of the MiSPOT proto-type, we could modify its personalization logic to run any of the three filtering strategies we wanted to evaluate, so that all the users would be faced with a common interface. 5.2. Real users X  preferences collection
Our tests involved 95 users recruited among graduate/under-graduate students from the University of Vigo, their relatives and friends. We ended up with a diverse audience, with disparate demographic data and educational backgrounds, including nearly as many men as women (53% vs. 47%) whose ages range from 17 to 58 years old.

Prior to making any recommendations, we defined a set of 15 consumption stereotypes by clustering the user profiles that had built up during our previous experiments with MiSPOT (see details in Lo  X  pez-Nores et al., 2010 ).

We started from 14 clusters which contained the profiles that had comparatively high (close to 1) or comparatively low (close to 1) DOIs for items classified under Sports , Nature , Technology , Science , Health , Culture or Traveling . One final cluster gathered the profiles that did not meet any of those conditions. From each cluster, we computed one stereotype by averaging the
DOIs of the profiles they contained. As a result, just to name a few examples, we got one Sports -related stereotype containing mainly items classified as practice equipment for football and basketball; the Technology -related stereotype contained products like smart phones and Digital TV tuners, whereas camping equipment was a prevailing category in the Nature -related stereotype.
Finally, we asked each user to rate his/her interest in topics related to sports, nature, technology, science, health, culture and traveling with a number between 0 and 10, and initialized their individual profiles by weighing the DOIs of the corresponding stereotypes. Finally, we asked the users to identify their most recent purchases out of a list of 355 products. 5.3. Formation of user groups, recommendation and feedback collection
Users were randomly assigned to each one of the three evaluated filtering approaches, resulting groups with 28, 31 and 36 individuals. Users included in each group interacted with the corresponding filtering approach during at least 8 h over a period of 3 months. After each session, they were faced with a fixed-size list of the items recommended by each filtering approach, which they had to rate between 0 and 10 (see Fig. 7 ). At the end, we collected the log files and computed the values of precision attained for each user and each group over the testing period.
The precision value for a user was computed as the percentage of recommended items that he/she had rated equal to or greater than 6 over the 3-month testing period. The precision values for the groups of 28, 31 and 36 individuals were computed by averaging the precision values computed for their members. Formation of Users Checking Conditions of StatisticalAnalysis ANOVATests 5.4. Checking conditions for statistical analysis
As per our research hypotheses, our experiments had to: (i) analyze the effect of the adopted filtering approach on the precision of recommendations, and (ii) consider the impact of group corrections on the resulting time-aware recommendations.
To this aim, as usual in the evaluation of recommender systems ( Huang et al., 2002 ; Kim et al., 2005 ), we conducted ANOVA ( ANalysis Of VAriance ) tests with the aid of the statistical software
SPSS, 5 by considering as target variable the precision values observed for the three groups of users. ANOVA is a statistical test used to determine whether more than two population means are equal ( Gamst et al., 2008 ; Jaccard, 2003 ). The test uses the F probability distribution function and information about the var-iance of each population and grouping of populations to help decide whether variability between populations and variability within each population are significantly different. The goal of our
ANOVA tests was to determine whether the means of the three groups of users were equal (i.e., whether the precision of the recommendations was independent from the filtering approach).
In order to draw correct statistical inferences from the results of ANOVA, the population must be normal in shape, the groups must be independent, and the population variances must be homogeneous (which is typically called the homocedasticity hypothesis). We have corroborated these assumptions with the aid of SPSS. Normality is corroborated both theoretically and empirically:
As we mentioned before, we estimated precision values for individual users as the percentage of recommended items that they had rated equal to or greater than 6 over the testing period. If a user has rated n items, the estimator can be seen as the average of n Bernoulli variables, characterized by the probability p with which he/she would give a rating equal or greater than 6 to a given item. Assuming that those Bernoulli variables are independent (which is a reasonable approximation due to the diversity of items that could be recommended 6 estimator of precision is closely related to a binomial distribu-tion, which can be approximated by a normal distribution if n is large enough (i.e., if we gather a sufficient number of ratings from the user). By computing partial estimations of precision with only the ratings provided in each session, we got histograms like the ones depicted in Fig. 8 which show that partial estimations of precision fit reasonably well with a
Gaussian function, so the overall estimations should fit even better.

On the other hand, when estimating precision for a group of users, we averaged 28, 31 or 36 approximately-normal vari-ables. Just because the users made up a diverse audience, we can reasonably assume that they have provided independent ratings, implying that those variables were also independent.
Therefore, the normal distribution was indeed a good approx-imation for the estimator of the precision achieved by each strategy. We asked SPSS to provide Q X  X  plots to compare the precision values measured for the three groups of users against a standard normal population. As it can be seen in Fig. 9 , the linearity of the points round the principal diagonal suggests that the precision values do not deviate from a random sample from a normal distribution in any systematic manner.

As regards the other conditions, independence of cases is arguably true because the observations come from three ran-domly assigned groups of users. Finally, we used Levene X  X  test for homogeneity of variances in order to confirm the plausibility of homocedasticity. 5.5. ANOVA tests
Having checked the necessary assumptions, we used SPSS (i) to obtain information about means, standard deviations and con-fidence intervals of the precision values computed by the three evaluated filtering approaches (see Table 2 ), and (ii) to carry out the ANOVA tests shown in Table 3 , where F statistics result from dividing the variation existing between the group averages by the variation between the precision values within each group. Besides the quantification of both variation sources (denoted as Sums of
Squares ), Table 3 contains the associated degrees of freedom and the value adopted by each estimator of population variance ( Mean
Squares ), which is obtained by dividing the sum of squares by the corresponding degrees of freedom. 5.6. Discussion on the experimental results
Assessing significant differences among three groups X  means requires to compare the F statistic value in Table 3 against a critical value, which must be queried in predefined tables con-sidering a specific significance value ( a  X  0 : 01 in our tests) and the degrees of freedom of ANOVA tests (2 and 92). Since the resulting F value is 112.703, which is much larger than
F  X  0 : 01 , 2 , 92  X  X  4 : 844, we reject the hypothesis of equal popula-tion means and conclude that the precision of recommendations varies with the adopted filtering strategy. Besides, the P -value at that level.

Up to this point, we have corroborated the existence of significant differences among the three populations, but our two starting research hypotheses are not yet validated. In order to analyze the trend of precision as per the filtering approach, we ran contrasts and post hoc tests provided by SPSS to compare the average values of the three groups. As depicted in Table 4 ,we made two contrasts: the first one compares the purely reasoning-based approach against time-aware approaches jointly, while the second contrast focuses only on the two time-aware approaches by comparing the average precision values of UTDF and GCDF. Next, we used Tukey X  X  and Bonferroni X  X  tests (due to their suitability in case of homocedasticity Jaccard, 2003 ) in order to corroborate the results achieved by the contrasts; the results are given in Table 5 .

The results from contrast 1 confirm that there exist statisti-cally significant differences among the average precision values of PRBF and the joint average of the two time-aware filtering approaches UTDF and GCDF, because the values of the F statistic are much lower than our significance level (1%), as shown in the last column of Table 4 . Specifically, as per the means in Table 2 , we see that the average precision of PRBF (57.4) is lower than the joint average of UTDF and GCDF (68). Regarding contrast 2, the results led to significant differences between the approaches UTDF and GCDF, and Table 2 confirms that average precision values attained through group corrections (in GCDF) are greater that those achieved by uncorrected time functions (in UTDF).

The same results are inferred from Tukey X  X  and Bonferroni X  X  tests depicted in Table 5 : the approaches UTDF and GCDF perform better than PRBF, and parameterized time functions adopted in UTDF lead to less accurate recommendations than the group corrections extracted from consumption stereotypes in GCDF. This way, we have verified our two research hypotheses. 6. Conclusions and future work
As e-commerce provides an increasingly more powerful gate-way for shopping online, serving customers instantly and effi-ciently requires to recognize their particular needs, to recommend personalized shopping lists, and to adapt these lists as the users X  interests change over time. Existing recommender systems miss an important point in the adaptation process, related to the fact that the influence of time can vary greatly for users with very different preferences. This paper introduces an improvement for current semantics-based recommender systems, grounded on a time-aware filtering approach driven by an ontology and a set of consumption stereotypes characterizing the preferences of poten-tial consumers. Actually, our approach exploits the knowledge formalized in an ontology in order to link the available items (and their features) to time functions built from the stereotypes in which the preferences of each user fits best. This way, we identify potentially appealing items for each user at any time, by reckoning both his/her particular interests and shopping history (semanti-cally characterized in the ontology) and consumption behaviors of like-minded users (represented in the stereotypes).

Experiments with real users have proved that associating stereotype-driven time functions to semantically characterized 0 0.2 0.4 0.6 0.8 1 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 5 concepts can greatly improve the precision of the recommendations in online shopping (from 55% to 73% in our tests). In the short term, we plan to evaluate the effectiveness of the personalization logic with more users and over a longer time scale. For this purpose, we have reached an agreement with a regional telecommunications provider to deliver personalized advertisements; our aim is to gather data from nearly 600 viewers over a period of six to ten months.

Finally, we are interested in developing mechanisms to help automate the management of a set of stereotypes. The problem is that stereotypes are difficult to obtain and also difficult to keep up-to-date with regard to the new items that appear every day.
Inspired by the work presented in Jiang and Tuzhilin (2009) , our goal is to develop semantics-driven analysis and visualization  X 2.5  X 2  X 1.5  X 1  X 0.5 0 0.5 1 1.5 2 2.5 56 58 60 62 64 66 68 tools to evolve stereotypes from the relevance feedback gathered from individual users, supporting decisions on when to introduce a new stereotype, when to merge existing ones, or when to split one stereotype into several specialized versions.
 References
