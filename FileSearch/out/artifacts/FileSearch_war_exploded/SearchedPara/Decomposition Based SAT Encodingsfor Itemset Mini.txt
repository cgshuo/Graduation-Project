 Recently, a constraint programming (CP) based data mining (DM) framework other data mining problems using the two well-known AI models: constraint proposed a SAT based formulation of the problem of enumerating the Top-k employe a significantly more high-level modeling language. programming based data mining shows an important research activity in this SAT-based data mining approaches.
 SAT-based itemset mining approach by several orders of magnitude on several well-known datasets. Let  X  be a finite non empty set of symbols, called items .Fromnowon,we assume that this set is fixed. We use the letters a , b , elements of  X  .An itemset I over  X  is defined as a subset of use 2  X  to denote the set of itemsets over  X  and we use the capital letters K , etc to range over the elements of 2  X  .
 transaction identifier ,and I an itemset, i.e., ( i, I )  X  N  X  database D is defined as a finite non empty set of transactions ( where each transaction identifier refers to a unique itemset. Let D be a transaction database and I an itemset. The cover of denoted C ( I, D ), is the following set of transaction identifiers: of
C ( I, D ), i.e., S ( I, D )= |C ( I, D ) | .
 we have C ( { a, b } , D )= { 1 , 2 , 3 } and S ( { a, b } , D In this work, we are mainly interested in the problem of finding frequent itemsets (FIM problem). Given a transaction database D and a natural number n minimal support threshold .
 Indeed, this problem is # P -hard [ 15 ]. The complexity class # the counting problems associated with a decision problem in partially face this problem, condensed representations have been proposed: Definition 1 (Closed Frequent Itemsets). Let D be a transaction database and n a minimal support threshold and I an itemset in FIM ( D ,n I is closed iff, for all J  X  I , S ( I, D ) &gt; S ( J, D ) . Definition 2 (Maximal Frequent Itemsets). Let D be a transaction database and n a minimal support threshold and I an itemset in FIM ( D ,n I is maximal iff, for all J  X  I , S ( J, D ) &lt;n .
 and {{ a, b, c } , { a, c, d } , { a, f } , { g }} .Weuse CFIM to denote the set of closed (resp. maximal) frequent itemsets. Let
Prop be a countably set of propositional variables. We use the letters q , r , etc to range over Prop . The set of propositional formul X  , denoted denoting true, and using the logical connectives  X  ,  X  ,  X  to denote the set of propositional variables appearing in the formula equivalence connective  X  is defined by A  X  B  X  ( A  X  B )  X  propositional formul X  as usual:
I (  X  )=0 I ( )=1 I ( A  X  B )= min ( I ( A ) , I ( B ))
I (  X  A )=1  X  X  ( A ) I ( A  X  B )= max ( I ( A ) , I ( B )) I ( A  X  B )= max (1  X  X  ( A ) , I ( B )) A model of a formula A is a Boolean interpretation I I ( A ) = 1. A formula A is satisfiable if there exists a model of or a theorem , if every Boolean interpretation is a model of to denote the set of models of A .
 propositional formul X . A CNF formula is a conjunction (  X  or a negated propositional variable (  X  p ). The two literals deciding if a given CNF formula admits a model or not. of generality, a transaction database D = { (1 ,I 1 ) ,..., support threshold n .
 D . More precisely, for each item a (resp. transaction identifier I of the considered encoding, the candidate itemset is { a  X   X  |I its cover is { i  X  N |I ( q i )=1 } .
 of the candidate itemset: true) that does not belong to the transaction ( a  X   X  \ I a support greater than or equal to the minimal support threshold: propagation (generalized arc consistency) on the CNF formula. of the two formul X  ( 1 ) and ( 2 ).
 Proposition 1 ([ 7 ]). Let D be a transaction database and threshold. I is a model of E FIM ( D ,n ) iff I = { a  X   X  |I itemset where C ( I, D )= { i  X  N |I ( q i )=1 } .
 We now describe the propositional formula allowing to force the candidate itemset to be closed: This formula means that if we have S ( I, D )= S ( I  X  X  a } , D a  X  I i corresponds to if the item Note that the formula ( 3 ) can be simply reformulated as a conjunction of clauses as follows: This reformulation is obtained using the equivalence A  X  B  X  X  A  X  B work, we give below the encoding of the maximality constraint. Indeed, the be maximal: for every propositional variable q i ,wehave q i  X  X  X  =  X  and et al X  X  encoding proposed in [ 10 ].
 old. I is a model of E CFIM ( D ,n ) iff I = { a  X   X  |I ( itemset where C ( I, D )= { i  X  N |I ( q i )=1 } .
 old. I is a model of E MFIM ( D ,n ) iff I = { a  X   X  |I ( frequent itemset where C ( I, D )= { i  X  N |I ( q i )=1 } us to decompose the encodings described previously.
 the transaction database { ( i, I )  X  X | I  X  S =  X  X  .Let k ( { S an ordering on { S 1 ,...,S k } .
 n propositional formula: where DM  X  X  FIM,CFIM,MFIM } .
 contains at least one item from S . The second subformula ( the partition sequence.
 Proposition 4. Let D be a database, P =( W,  X  ) a k -partition of and n a minimal support threshold. I is a model of  X  DM ( following properties are satisfied: ( i )
I = { a  X   X  |I ( p ( ii )
C ( I, D )= { i  X  N |I ( q ( iii )
I  X  S =  X  ;and ( iv ) I  X  ( ii ). The properties ( iii ) and ( iv ) are directly obtained from the formul X  Part  X  . Using the properties ( i ) and ( ii ), we obtain that of E S =  X  (resp. I  X  Proposition 5. Let D be a transaction database, P =( W,  X  of  X  , S, S  X  W such that S = S and n a minimal support threshold. Then Mod (  X  Proof. Since S = S , we have either S  X  S or S  X  S . We here consider, without loss of generality, that S  X  S . Since all models of satisfy a  X  S  X  p a because of S  X  S and all models of  X  DM p We provide in Figure 1 a simple algorithm using our partition based method input a transaction database D , a minimal support threshold P =( { S enumerate all Boolean models of the propositional formula set R .
 Theorem 1 (Soundness). The algorithm SAT P DM is sound w.r.t. the data mining task DM .
 Proof. The soundness of SAT P DM is a direct consequence of Proposition 4 . Theorem 2 (Completeness). The algorithm SAT P DM is complete w.r.t. the data mining task DM .
 Proof. The completeness of SAT P DM comes from the fact that and Proposition 4 .
 itemset computed in two different steps in the for-loop. E D D S . Let us note that the number of transactions of the size of S :if S is included in S , then the number of transactions of smaller than that of D | S . considered a variety of datasets taken from the FIMI 1 and CP4IM of RAM running at 2.66 Ghz. For each instance, we used a timeout of 2 hours of CPU time. As described in the previous section, the Algorithm 1 takes a we consider a partition P where each S i  X  X  contains a single item and if
S scope of this paper. We compare our partition based approach noted ( SAT -P -CFIM in the figures) with SAT CFIM , the encoding of frequent closed itemsets mining problem without partition (named SAT -CFIM We implemented the Algorithm 1 in C. For the enumeration of all models is based on an extension of MiniSAT 2.2 3 .
 Note that, the time needed to generate the partition does not exceed 1 sec-teristics of the dataset and the size of the CNF formula encoding the whole we mention the number of transactions (# trans ), the number of items (# of clauses of the smallest ( min ) respectively the largest formula ( significantly smaller than those generated without partition (# we mention its name and the number of generated Boolean formulas (in paren-thesis) corresponding to the number of elements in the partition ( tion i , the transactions containing the items from S j ( number of times. To evaluate the performances of our proposed approach, we compare the time needed for our partition based approach SAT P CFIM with (18 instances), where for each instance, we tested 70 different values of using them under the time limit. For instance, for connect data, (for all n 5500).
 Figures 4 and 5 , highlight the results obtained by SAT P on anneal , australian , hepatitis and mushroom instances while varying the tial of our partitioning based approach. mental and complete. The experimental evaluation on several known datasets partition of the set of items is another interesting issue.
