 Currently, the most significant line of defense against mal-ware is anti-virus products which focus on authenticating valid software from a white list, blocking invalid software from a black list, and running any unknown software (i.e., the gray list) in a controlled manner. The gray list, con-taining unknown software programs which could be either normal or malicious, is usually authenticated or rejected manually by virus analysts. Unfortunately, along with the development of the malware writing techniques, the num-ber of file samples in the gray list that need to be analyzed by virus analysts on a daily basis is constantly increasing. In this paper, we develop an intelligent file scoring system (IFSS for short) for malware detection from the gray list by an ensemble of heterogeneous base-level classifiers derived by different learning methods, using different feature rep-resentations on dynamic training sets. To the best of our knowledge, this is the first work of applying such ensem-ble methods for malware detection. IFSS makes it practical for virus analysts to identify malware samples from the huge gray list and improves the detection ability of anti-virus soft-ware. It has already been incorporated into the scanning tool of Kingsoft X  X  Anti-Virus software. The case studies on large and real daily collection of the gray list illustrate that the detection ability and efficiency of our IFSS system out-performs other popular scanning tools such as NOD32 and Kaspersky.  X  The author is also affiliated with Anti-virus laboratory, KingSoft Corporation.
 I.2.6 [ Artificial Intelligence ]: Learning; D.4.6 [ Operating System ]: Security and Protection -Invasive software Algorithms, Experimentation, Security malware detection, gray list, ensemble
Malware is a generic term [5] to denote all kinds of un-wanted software(e.g., viruses, backdoors, spyware, trojans and worms). Numerous attacks made by the malware have posed a major security threat to computer users. Therefore, malware detection is one of the computer security topics that are of great interest. Currently, the most significant line of defense against malware is anti-virus software prod-ucts, such asNOD32, Kaspersky and Kingsoft X  X  Antivirus. These widely-used malware detection software tools mainly use signature-based method to recognize threats. Signature is a short string of bytes which is unique for each known mal-ware so that future examples of it can be correctly classified with a small error rate.

In order to capture as many malware samples as possible, besides authenticating valid software from a white list and blocking invalid software from a black list using signature-based method, most of the existing anti-virus software prod-ucts run any unknown software (i.e., the gray list) in a con-trolled manner. The gray list, containing unknown software programs which could be either normal or malicious, is usu-ally authenticated or rejected manually by virus analysts. Unfortunately, with the development of the malware writ-ing techniques, the number of file samples in the gray list that need to be analyzed by virus analysts on a daily basis is constantly increasing. For example, the gray list collected by the Anti-virus Lab of a large software corporation usually contains more than 100,000 file samples per day. The gray list is not only large in size, but also very complicated since it contains the variants of known malware and previously unknown malware samples. In order to remain effective, it is of paramount importance for the anti-virus companies to be able to quickly analyze the gray list and detect malware samples.

Over the last few years, many research efforts have been conducted on developing intelligent malware detection sys-tems [19, 30, 33, 26]. In these systems, the detection pro-cess is generally divided into two steps: feature extraction and categorization . In the first step, various features such as Application Programming Interface (API) calls and program strings are extracted to capture the characteristics of the file samples. In the second step, intelligent techniques such as decision trees are used to automatically categorize the file samples into different classes based on computational analy-sis of the feature representations. These intelligent malware detection systems are varied in their use of feature represen-tations and categorization methods. For example, IMDS [33] performs association classification on Windows API calls ex-tracted from executable files while Naive Bayes methods on the extracted strings and byte sequences are applied in [26].
Different feature representations and categorization meth-ods have their own advantages and limitations in malware detection. None of the single feature set can immune or resis-tant to mimicry designed to confuse the anti-virus software as different feature representation typically capture differ-ent characteristics of file samples. For example, API calls typically reflect the behavior of program code pieces while program strings consist of reused code fragments, author sig-natures, files names and system resource information. On the other hand, different categorization methods have dif-ferent strengths and may excel at different situations. A natural question arises: can we combine different feature representations and categorization methods to improve the performance of malware detection?
Previous research has shown that ensemble methods, by combining multiple input systems, are a popular way to overcome instability and increase performance in many ma-chine learning tasks, such as classification, clustering and ranking [9, 11]. In this paper, we develop an intelligent file scoring system (IFSS for short) for malware detection from the gray list by an ensemble of heterogeneous base-level clas-sifiers derived by different learning methods, using different feature representations on dynamic training sets. To the best of our knowledge, this is the first work of applying such ensemble methods for malware detection.

Our IFSS system has the following major traits: All these traits make our IFSS a practical solution for help-ing virus analysts identify malware samples in the gray list and improving the detection ability of anti-virus software. The case studies on large and real data collections collected by the Anti-virus Lab of Kingsoft corporation illustrate that: (1) After being scanned by all the popular anti-virus soft-ware products, such as NOD32 and Kaspersky, malware in the gray list still can be effectively detected by our IFSS. (2) The performance and efficiency of our IFSS outperform other classification methods in detecting malware from the gray list. (3) Our IFSS reduces the number of file samples that need to be analyzed by virus analysts. Our case studies show that the percentage of malware samples in the gray list is about 0 . 5% while the percentage of malware samples in the top 100 ranked files samples of the file scoring list gener-ated by our IFSS system is 35%. Therefore IFSS can greatly save human labor. As a result, our IFSS has already been incorporated into the scanning tool of Kingsoft X  X  Anti-Virus software.
The rest of this paper is organized as follows. Section 2 gives an overview of our IFSS system and Section 3 discusses the related work. Section 4 describes the feature representa-tion and extraction; Section 5 introduces the two base classi-fiers; Section 6 presents the ensemble framework used in our IFSS system for generating the file scoring list. In Section 7, we systematically evaluate the effects and efficiency of our IFSS system in comparison with other classification meth-ods. In Section 8, based on the daily data collection obtained from Kingsoft Anti-virus lab, we examine the detection abil-ity and efficiency of IFSS in comparison with other popular anti-virus software such as NOD32 and Kaspersky. Finally, Section 9 concludes.
In this paper, resting on the analysis of Windows API (Application Program Interface) calls which can reflect the behavior of program code pieces and interpretable strings which carry semantic interpretations and reflect an attacker X  X  intent and goal, we develop the Intelligent File Scoring Sys-tem(IFSS) to detect malware from the gray list. Figure 1 shows the malware detection procedure of IFSS: Figure 2: A sample signature database after data transformation
Signature-based methods are widely used in malware de-tection to recognize threats [12]. A signature is a short string of bytes which is unique for each known malware. However, this classic signature-based method always fails to detect variants of known malware or previously unknown malware. The problem lies in the signature extraction and generation process, and in fact these signatures can be eas-ily bypassed [27]. In order to overcome the disadvantages of the widely-used signature-based malware detection method, data mining and machine learning approaches are proposed for malware detection [19, 26, 30, 7]. The performance of such methods used for malware detection critically depend on the set of features and the classifier [10].
 Neural Networks as well as immune system are used by IBM for computer virus recognition [28]. Naive Bayes, Sup-port Vector Machine(SVM) and Decision Tree classifiers are used to detect new malicious executables based on small data collection in the previous studies [19, 26, 30]. Recently, associative classification [22], with its ability to utilize re-lationships among attributes, has been also applied in [33]. Note that the class distribution in the gray list of our col-lection is quite imbalanced with the malware samples as the minority class. Many accuracy driven classifiers may fail on such a large and imbalanced gray list. For example, neu-ral networks and naive Bayes consistently biased towards the majority class at any given size and prone to treat the minority (malware) class as noise [18]. Decision trees algo-rithms (C4.5) are also not performing well in the presence of imbalance: they might lose big parts of the minority (mal-ware) class at the pruning phase or lead to the trees of large size and over-fitting of the minority class [18]. Hence in our work, we choose association classifier and SVM as our base classifiers.
Previous research has shown that ensemble methods, by combining multiple input systems, are a popular way to overcome instability and increase performance in many ma-chine learning tasks, such as classification, clustering and ranking. For example, an ensemble of classifiers is a set of classifiers whose individual predictions are combined in some way (typically by voting) to classify new examples. Gener-ally there are two types of classifier ensemble: 1) Homoge-neous ensemble: the base classifiers are constructed using a single learning algorithm, such as decision trees or neural networks [9]. Typically base classifiers are generated by ma-nipulating the training set (as done in boosting or bagging), manipulating the input features, manipulating the output targets or injecting randomness in the learning algorithm [8]. The individual classifiers are then typically combined by vot-ing or weighted voting. 2) Heterogeneous ensemble: the base classifiers are constructed by applying different learning al-gorithms (with heterogeneous model representations) to a single dataset [24]. More complicated methods such as stack-ing are used for combining classifiers [32]. In our IFSS sys-tem, the base classifiers are constructed by different learning methods (association classification or SVM), using different feature representations (API calls or Interpretable strings) on different training sets ( DB T 1 and DB T 2). We expect that our construction of base classifiers would increase their diversity and improve the classification performance. Our work is the first effort on applying such ensemble classifier methods for malware detection.
Our IFSS system is performed directly on Windows PE code. PE is designed as a common file format for all fla-vor of Windows operating system, and PE malware are in the majority of the malware rising in recent years. If a PE file is previously compressed by a third party binary com-press tool such as UPX and ASPack Shell or embedded a homemade packer, it needs to be decompressed first. We use the dissembler W32Dasm developed by KingSoft Anti-Virus Laboratory to dissemble the PE code and output the assembly instructions as the input for feature extraction.
API Calls: The Windows API execution calls for each benign/malicious executable is generated by a PE parser. Through the API query database, the API execution calls generated by the PE parser can be converted to a group of 32-bit global IDs which represents the static execution calls of the corresponding API functions. For example, the API  X  X ERNEL32.DLL, OpenProcess X  X xecutes the function that returns a handle to an existing process object and it can be encoded as 0x00500E16. Then we use the API calls as the signatures of the PE files and store them in the signature database.

Interpretable Strings: The interpretable strings are ex-tracted using a feature parser. The feature parser reads the PE file. If there is a sequence of consecutive bytes belonging to the same Character Set, such as ASCII, GB2312, Big5 and Unicode, then the parser exacts them as our features. Figure 3 shows a sample interpretable strings extracted by our feature parser. These strings are extracted from a mal-ware named Backdoor  X  Redgirl.exe . From Figure 3, we can see the behaviors of the malware and the attacker X  X  in-tent explicitly.

Since these two sets of features are representation of PE file samples at different semantic levels, we use them for building base classifier respectively.
API Calls: As not all of the API calls are contributing to malware detection, we rank each API call using Max-Relevance algorithm [25] and select a set of API calls with the highest relevance to the target class, i.e. the file type, for later classification. Given a i which represents the API with ID i , and the file type f ( X 0 X  represents benign executables and  X 1 X  is for malicious executables), their mutual informa-tion is defined in terms of their frequencies of appearances p ( a i ), p ( f ), and p ( a i , f ) as follows. With this algorithm, we select the top m APIs in the de-scent order of I ( a i , f ), i.e. the best m individual features correlated to the file types of the PE files. Figure 3: Interpretable strings sample extracted by feature parser
Interpretable Strings: For Interpretable strings, we first use the corpus of natural language to filter the can-didate interpretable strings. If the string consists most of the unusual characters which are not in the corpus, like  X !0&amp;0h0m0o0t0y0 X , it will be pruned by our feature parser. We then also apply Max-Relevance algorithm [25] to select a set of the most representative strings for later classification.
In this section, we briefly describe the base classifiers used in our IFSS. We use association classifier and SVM as our base classifiers for the following reasons: 1) The gray list is large and quite imbalanced and many accuracy driven classifiers including neural networks, naive Bayes and de-cision trees may fail on such a large and imbalanced gray list [18]. On the other hand, association classifier and SVM seems work well on imbalanced datasets. 2) Both associa-tive classification and SVM have been successfully applied in malware detection [33, 19]. In particular, association clas-sification can discover interesting relationships among input features that are explicitly related to malware/benign file class and SVM can identify good classification boundaries for malware detection.
For malware detection in this paper, the first goal is to find out how a set of input features (e.g., API calls) supports the specific class objectives: class 1 = Malicious , and class Benign .
Apriori [1] and FP-Growth [13] algorithms can be ex-tended to associative classification [21, 22]. In general, FP-Growth algorithm is much faster than Apriori for mining frequent item sets. In our work, we use FP-Growth algo-rithm to conduct the classification association rule mining.
Since there is a huge number of rules generated from the training set and it is infeasible to build the classifier used all of rules, post-processing of associative classification is also very important for improving the accuracy and efficiency of the classifier. Rule pruning and rule re-ordering are used for post-processing associative classifier.

Rule Pruning. Several common rule pruning approaches have been developed for associative classifiers to reduce the generated rules [3, 4, 21, 22, 23, 29]: (1)  X  2 (chi-square) testing [21] to measure the significance of the rule itself, (2) database coverage [22] to just keep the rules covering at least one training data object not considered by a higher ranked rule, and (3) pessimistic error estimation [22] to test the estimated error of a new rule. These rule pruning techniques mainly focus on individual rules. We have used the above three pruning techniques in our application.

Rule Re-ordering. Rule re-ordering plays an important role in the classification process since most of the associa-tive classification algorithms utilize rule ranking procedures as the basis for selecting the classifier [22, 21, 34]. In par-ticular, CBA [22] and CMAR [21] use database coverage pruning approach to build the classifiers, where the pruning evaluates rules according to the rule re-ordering list. Hence, the highest-order rules are tested in advance and then in-serted into the classifier for predicting test data objects. For rule re-ordering, there are five popular mechanisms [31]: (1) Confidence Support size of Antecedent (CSA), (2) size of Antecedent Confidence Support (ACS), (3) Weighted Rel-ative Accuracy (WRA), (4) Laplace Accuracy, and (5)  X  2 (chi-square) measure. CSA and ACS are belong to the pure  X  X upport-confidence X  X ramework and have been used by CBA and CMAR for rule ranking. WRA, Laplace Accuracy and  X  2 measure are used by some associative classification al-gorithms, such as CPAR [34], to weigh the significance of each generated rule. In our work, we adopt hybrid rule re-ordering mechanism by combining CSA and  X  2 to re-order the rules. We first rank the rules whose confidences are 100% by CSA and then re-order the remaining rules by  X  2 measure. Because those rules whose confidences are 100% can make the classifier accurate, while the remaining rules should be considered by the combination of their supports and confidences together.
We use  X  X est First Rule X  [31] method to predict the new file samples. We select the first best rule that satisfies the new file sample according to the rule list based on our hybrid CSA/  X  2 rule re-ordering method to predict whether the new case is malware or not.
Support Vector Machine (SVM) is a promising method for data classification and regression and it has also been successfully used in malware detection [16, 2, 15]. The key to the success of SVM is the kernel function which maps the data from the original space into a high dimensional feature space. By constructing a linear boundary in the feature space, the SVM produces nonlinear boundaries in the original space. The output of a linear SVM is u = w  X  x  X  b , where w is the normal weight vector to the hyperplane and x is the input vector. Maximizing the margin can be seen as an optimization problem: where x is the training example and y i is the correct output for the i th training example. Intuitively the classifier with the largest margin will give low expected risk, and hence better generalization.
Base classifiers are constructed by applying associative classifier and SVM using different feature representations on different training sets (denoted by DB T 1 and DB T 2). Coupled with the two different feature representations, we have four different settings for training base classifiers: DB T 1 with API calls, DB T 1 with interpretable strings, DB T 2 with API calls, and DB T 2 with interpretable strings. Us-ing the two different classification methods, we thus obtain 8 different base classifiers. A simple voting scheme is used to combine base classifiers. For an input file, each base clas-sifier casts a vote for its prediction: i.e., 1 if the input file is predicted to be malicious and 0 otherwise. Therefore after classifier voters, each file sample can obtain a score ranging from 8 to 0. If two file sample have the same score, they will be ranked by their matching association classification rules X   X  2 (chi-square) values [21] in descending order. IFSS system then generates a file scoring list which is a ranked list of all input file samples from the gray list. The file score list is simple for virus analysts to interpret and understand. Virus analysts can then look at the top ranked file samples and manually authenticated and rejected those samples. In practice, each virus analyst can analyze 20 new file samples per day and they pick the top 100 file samples from the file scoring list for manual inspection. These manually labeled file samples can then be used as new training data to im-prove the system.
In this section, we conduct two sets of experimental stud-ies using our data collection obtained from the Anti-virus Lab of Kingsoft to compare our IFSS with other classifiers: (1) The first set of experiments is to investigate the effects of feature selection. (2) In the second set of experiments, we compare our IFSS with different ensemble methods ob-tained using different combinations of feature representa-tions, training sets and base classifiers. All the experimen-tal studies are conducted under the environment of Windows XP operating system plus Intel P4 1.83 GHz CPU and 2 GB of RAM.
Identifying the most representative features is critical to improve the performance and efficiency of the classifiers [17, 20]. As not all of the features contributing to malware de-tection, we rank each API call and interpretable string using Max-Relevance algorithm [25] and select top k API calls and interpretable strings as the features for later classification. We obtain a whole week X  X  data collection(from Jan. 1st, 2009 to Jan. 7th, 2009) from Kingsoft Anti-virus lab to tes-tify the validation of the feature selection method in this set of experiments. We use six days X  data collection con-taining 530,448 PE file samples for training ( half of them are recognized as benign executables and the other half are malicious executables mainly consisting of backdoors, tro-jans and worms) and one day X  X  samples including 89,626 files for testing. There are 7,909 API calls and 32,123 inter-pretable strings extracted from these file samples. We use precision [6] and recall [6] of the malware class to evaluate the performance of the classification results, which can be de-TP is the number of malicious files correctly classified, FP is the number of benign files incorrectly classified as malicious and FN is the number of malicious files incorrectly classi-fied as benign. Figure 4 and Figure 5 show that the testing performance of Associative Classifier(AC) changes slightly after the number of API calls reaches 100 and the number of interpretable strings reaches 500. So, we select top 100 API calls and top 500 interpretable strings respectively as the features for later classification.
 Figure 4: AC performance with different number of API Calls Figure 5: AC performance with different number of Strings C1:API-AC-DB T1 13 1244 21.31% 1.05% C2:API-AC-DB T2 13 896 21.31% 1.45% C3:STR-AC-DB T1 30 4173 49.18% 0.72% C4:STR-AC-DB T2 9 444 14.75% 2.03% C5:API-SVM-DB T1 13 747 21.31% 1.74% C6:API-SVM-DB T2 13 568 21.31% 2.29% C7:STR-SVM-DB T1 29 3266 47.54% 0.89% C8:STR-SVM-DB T2 30 803 49.18% 3.74% Table 1: Detection results of different base classifiers on different training sets using different feature rep-resentations. The test data is from the gray list of Jan. 8th, 2009.
In this set of experiments, we compare our IFSS with different ensemble methods obtained using different com-binations of feature representations, training sets and base classifiers. In particular, we use: (1) API calls and inter-pretable strings as diverse features, (2) DB T 1 consisting of 491,733 PE file samples obtained from the history data set of Kingsoft Anti-virus lab, and DB T 2 containing 530,448 PE files which is the data collection of the week from Jan. 1st, 2009 to Jan. 7th, 2009, (3) associative classifier de-scribed in Section 5.1 and linear SVM [14] implemented in LibLinear package as heterogenous base classifiers, to con-struct different classifiers. To evaluate the performance of different classifiers and ensembles, we use the gray list of Jan. 8th, 2009 obtained at Kingsoft Anti-virus lab. We randomly sample 10% from the gray list for testing. The test dataset contains 12,365 files, 61 of which are malware samples.

Table 1 shows the detection results of different base clas-sifiers on different training sets using different feature rep-resentations. From Table 1, we observe that the precision of each classifier is too low and the number of the file sam-ples misclassified as malware is too large. Obviously, the single classification result is infeasible for real applications. Ensemble classifiers are quite popular in many data min-ing applications due to their potential for efficient parallel implementations and high accuracy.

Table 2 and Figure 6 show the detections results of differ-ent ensembles constructed by different combinations of the feature representations, training sets and base classifiers. In particular, E1-E4 are the ensemble methods constructed by a single classifier with a single feature representation on dif-ferent training sets; E5-E6 are the ensemble methods con-structed by a single classifier with diverse feature represen-tations on different training sets. These methods are typi-cal approaches for constructing ensembles. For comparison purpose, we also include the results of human expert. F1 to evaluate the classification performance of different algo-rithms. From the comparison, we observe that our IFSS outperforms other ensembles as well as human experts.
In addition, the detection by our IFSS can be done very efficiently using a couple of minutes (it uses 21.5 minutes to detect these 12,365 file samples, including feature extraction time). A virus analyst has to spend 5 days to analyze the 100 file samples in the gray list, since he/she can analyze 20 Ensemble TP Recall Precision F1 E1:C1+C2 2 3.28% 2% 0.0248 E2:C3+C4 3 4.92% 3% 0.0373 E3:C5+C6 3 4.92% 3% 0.0373 E4:C7+C8 4 6.56% 4% 0.0497 E5:C1+C2+C3+C4 12 19.67% 12% 0.1491 E6:C5+C6+C7+C8 9 14.75% 9% 0.1118 IFSS:C1-C8 35 57.38% 35% 0.4348 Human Expert 2 3.28% 2% 0.0248 Table 2: Detection results of different ensembles. Remarks: We select the top 100 files from the rank-ing list generated by each ensemble according to the simplest voting and ranking mechanism described in Section 6 and evaluate the performances of differ-ent ensembles. For comparison purpose, our virus analysts also select 100 files from the gray list to analyze. new file samples per day. Our case studies shows that the percentage of malware samples in the gray list is about 0 . 5% while the percentage of malware samples in the top 100 files samples of the file scoring list generated by our IFSS system is 35%. Because of its high efficiency and effectiveness, our IFSS system makes it practical for human experts to inspect the top rank files.
 Figure 6: F1 measures of different ensembles based on part of the gray list of Jan. 8th, 2009.
It should be pointed out that our IFSS system for malware detection has already been incorporated into the product of Kingsoft X  X  Anti-virus software. Figure 7 shows the interface of the IFSS system. We call the new scanning tool of King-soft X  X  Anti-Virus software which incorporates IFSS system as KS-IFSS. The old scanning tool of Kingsoft X  X  Anti-Virus software is referred as KS. The main purpose of IFSS is to help virus analysts find out malware samples in the gray list on which all other popular scanners fail and to improve the malware detection ability of anti-virus software. Therefore, we apply KS-IFSS in real applications and compare with other popular scanners(including KS) to testify its malware detection ability and efficiency on the daily data collection.
In this section, we apply KS-IFSS in real applications to testify its detection ability of the daily data collection. Table 3 illustrates the daily data collection obtained from Kingsoft Anti-virus lab for the week of Jan. 25th, 2009 to Jan. 31st, 2009.
Day Date All Files Malware Benign Files 1 2009/01/25 407,882 42,608 51,595 2 2009/01/26 516,715 44,204 59,245 3 2009/01/27 551,120 44,813 50,297 4 2009/01/28 597,767 47,796 38,982 5 2009/01/29 312,372 49,077 65,113 6 2009/01/30 520,761 57,144 66,022 7 2009/01/31 705,620 55,523 54,489 Table 3: Daily data collection for the week of Jan. 25th, 2009 to Jan. 31st, 2009. 3,612,237 file samples are collected in total: 2,885,349 of which are gray files, 385,723 of which are benign files, and 341,165 of which are malware samples detected by all of the four anti-virus scanners. For the gray files, we just review the malware samples detected by KS-IFSS. We examine KS-IFSS X  X  malware detection ability and FP(False Positive)rate which is the ratio of benign files misclassified as malicious in comparison with some of the popular scanning tools like NOD32, Kaspersky and KS. For comparison purpose, we use all of the Anti-virus scanners X  newest versions of the base of signature on the same day. Table 4 and Figure 8 show that KS-IFSS outperforms other Anti-virus scanners on malware detection ability, since it can detect the mal-ware from the gray list while all the popular scanners fail. Figure 9 shows that KS-IFSS outperforms other Anti-virus scanners on FP(False Positive)rate.

Day Perf. KS-IFSS KS NOD32 Kaspersky 1 DRate 91.53% 87.33% 81.56% 72.85% 2 DRate 91.98% 87.72% 82.69% 66.09% 3 DRate 91.28% 88.24% 83.42% 65.72% 4 DRate 92.84% 89.21% 84.95% 62.95% 5 DRate 92.89% 89.97% 86.27% 75.47% 6 DRate 93.02% 89.68% 88.66% 79.12% 7 DRate 91.76% 89.40% 85.37% 86.36% Table 4: Malware detection results of different Anti-Virus Scanners. Remarks: DRate means the detec-tion rate of the Anti-Virus Scanner which is the ratio of malware correctly classified.
In this set of experiments, we compare the efficiency of our KS-IFSS with different Anti-virus scanners. We also use the daily malware data collection, from Jan. 25th, 2009 to Jan. 31st, 2009, described in Section 8.1 to testify the de-tection efficiency of each Anti-virus scanner. The results in Figure 10 illustrate that KS-IFSS achieves higher efficiency than other scanners when being executed in the same envi-ronment.
 Figure 8: Comparisons of malware detection ability for different Anti-Virus Scanners.
 Figure 9: Comparisons of FP rate for different Anti-Virus Scanners.
In this paper, we present an an intelligent file scoring sys-tem (IFSS) for malware detection from gray list. IFSS uses an ensemble framework and it has several favorable traits including diverse feature representations, dynamic training sets, heterogeneous base classifiers and human-in-the-Loop. In addition, IFSS performs simultaneous model construction and testing. With these properties, IFSS makes it practical for virus analysts to identify malware samples from the huge gray list and improves the detection ability of anti-virus soft-ware.

IFSS has already been incorporated into the scanning tool of Kingsoft X  X  Anti-Virus software. The case studies on large data collections on the the gray list and real daily data col-lection obtained from the Anti-virus Lab of Kingsoft cor-poration demonstrate the effectiveness and efficiency of our IFSS system. Figure 10: Malware detection efficiency of different Anti-Virus Scanners The authors would also like to thank the members in the Anti-virus Lab at Kingsoft Corporation for their helpful dis-cussions and suggestions. The work of Y. Ye an Q. Jiang is partially supported by the National Science Foundation of China under Grant #10771176 and Guangdong Province Foundation under Grant #2008A090300017. The work of T. Li is supported in part by the US National Science Founda-tion Under grant IIS-0546280 and by multiple IBM Faculty Awards.
