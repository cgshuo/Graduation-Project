 One of the central tasks of R&amp;D strategy and portfolio man-agement at large technology companies and research insti-tutions refers to the identification of technological synergies throughout the organization. These efforts are geared to-wards saving resources by consolidating scattered expertise, sharing best practices, and reusing available technologies across multiple product lines. In the past, this task has been done in a manual evaluation process by technical domain ex-perts. While feasible, the major drawback of this approach is the enormous effort in terms of availability and time: For a structured and complete analysis every combination of any two technologies has to be rated explicitly. We present a novel approach that recommends technological synergies in an automated fashion, making use of abundant collective wisdom from the Web, both in pure textual form as well as classification ontologies. Our method has been deployed for practical support of the synergy evaluation process within our company. We have also conducted empirical evaluations based on randomly selected technology pairs so as to bench-mark the accuracy of our approach, as compared to a group of general computer science technologists as well as a control group of domain experts.
 H.3.3 [ Information Storage and Retrieval ]: Information Retrieval and Search X  Information Filtering ; I.2.6 [ Artifi-cial Intelligence ]: Learning X  Knowledge Acquisition Algorithms, Human Factors, Experimentation, Measurement Collective wisdom, Web 2.0, semantic similarity, text mining
Now working at The Boston Consulting Group, contact at ziegler.cai-nicolas@bcg.com Copyright 2009 ACM 978-1-60558-483-6/09/07 ... $ 5.00.
Large corporations often operate in diverse business seg-ments across different industries. While these various in-dustry branches (e.g., health-care solutions, electrical power generation, or industrial automation) may appear to have little overlap with regard to their nature and products, they commonly do have significant overlap at a more basic level, namely the level of core or support technologies employed. For instance, Circuit Breakers as well as Switch Gear devices are designed and used in departments subordinate to different operating units and different branches in a com-pany, e.g., industrial automation as well as the energy sector.
To adopt a more competitive market position and allow for significant cost savings, there is an increasing interest in consolidating technologies across operational units and in exploiting existing synergies that have not been discov-ered before. Within the strategic planning process in a com-pany, operating units usually describe their basic technolo-gies, the ones already in use as well as those currently being developed. The resulting technology lists are then matched against each other, comparing pairs of technologies { t i on the basic level for possible synergies and overlap. While this task appears trivial when both compared technologies t , t j bear identical names or when semantic relatedness is re-flected in lexical similarity, it becomes complex when these assumptions do not hold anymore, which is generally the case. For instance, Wastewater Treatment and For-ward Osmosis are related technologies with relatively high overlap, even though they are not lexically similar. However, both are about Hydraulic Permeability and Filtration and, in addition, based on similar concepts and mechanics.
At an integrated technology company like Siemens, the evaluation of synergies has traditionally been done in a man-ual evaluation process by various technical domain experts. Next to being tremendously expensive in terms of resources, the overall duration for completing these reports has been very high. We have addressed this issue by designing and deploying a service that is able to recommend technologi-cal synergies for Siemens operating units in an automated fashion, by applying Web mining and information retrieval techniques [1] that work on data gathered from the Web 2.0 X  X  collective intelligence. Our system X  X  output is twofold: First, there is an N  X  N pivot table 2 that gives the extent of
The term  X  X echnology X  is used in a broader sense in this paper, meaning any craft that expresses progress of any kind (not necessarily IT-related) of human civilization.
Where N is the overall number of technologies being com-pared. Technology Sector Division Computed Tomography Health-Care Div A Flue Gas Desulfurization Energy Div C
Membrane Bio Reactor Industry Div D overlap on different organizational levels; e.g., allowing us to deduce that sector s 1 has more overlap with sector s 2 than s . Second, there is a ranking module that returns the list of pairs in descending order according to their estimated syn-ergetic potential. Next to the ranking itself, the system also delivers an explanation detailing why the technology pair at hand has a high synergy value.

In order to show our system X  X  accuracy, we have conducted empirical evaluations, based on random samples of pairs of technologies { t i , t j } ; these pairs were rated for perceived syn-ergies by two control groups, one being a group of general technologists with a background in computer science, one being a group of experts that used to evaluate technology pairs by hand in the past. Our automated approach X  X  re-sult was then matched against the two groups X  consensus, showing that our system performs considerably well and is virtually indistinguishable from a man X  X  assessment in terms of classification accuracy.

The synergy discovery system is in operative use and saves considerable human effort as we speak, enabling experts to spend their valuable time within the synergy exploitation process more efficiently. Its usage has been likewise em-braced by domain experts and management and counts as paradigmatic example on how to make effective use of the Web 2.0 X  X  intrinsic value for enterprises.
Synergies are identified on the purely technological level, estimating synergy values for two given technologies t i , t well as on aggregated organizational levels. To this end, two levels are considered, namely the top-most organization level of three sectors (industry, energy, and health-care), as well as the subdivision of sectors into 15 divisions. For each division, d , a list of 10 representative technologies is composed. The complete technology list therefore is comprised of 15  X  10 entries, where each entry is a triple ( t i , s j , d k )  X  T  X  S  X  D , with T denoting the technologies, S giving the sectors, and D the divisions. Tab. 1 provides an example excerpt for one such list. Assuming that each technology occurs once, the number of technology pairs to be checked is as follows:
These roughly 11,000 pairs have been inspected annually by domain experts in a manual fashion so far, requiring the effort of several person months of skilled experts. Since our system X  X  deployment, these computations take less than one day and help us to reduce the human effort dramatically to some 5-10%, by virtue of weeding out apparently non-synergetic pairs.
Our system computes scores in an automated fashion by relying on two classifiers. The first one makes effective use of Wikipedia ( http://en.wikipedia.org ) as background knowl-edge source, the second one relies on ODP, the Open Di-rectory Project ( http://www.dmoz.org ). Both sources are maintained and continually updated by several thousands to millions of voluntary users who collectively contribute to the creation of the world X  X  largest knowledge repositories.
In order to come up with one single synergy score for each pair { t i , t j } , the two classifier scores must be merged ap-propriately. However, as the distribution of weights of both classifiers deviates drastically from each other, we decided to rank pairs along each classifier and merge the two ranks into one. An additional confidence score indicates whether the two assigned classifier ranks reach consensus or not.
The two classifiers, denoted C W for Wikipedia and C D for ODP, operate in a different fashion and focus on differ-ent aspects of what makes two technologies appear syner-getic: C W tends to identify synergies by detecting primarily meronymous relationships in both technologies, while C D concentrates more on taxonomic relationships between both. For instance, the synergy between the aforementioned pair Wastewater Treatment and Forward Osmosis can be characterized by referring to components and processes they have in common, i.e., Hydraulic Permeability and Fil-tration ; the focus is therefore on part-whole (i.e., merony-mous) relationships. On the other hand, the synergy can also be quantified by assigning both technologies to classes within a classification scheme and looking for the least com-mon subsumer. For the case at hand, the subsuming cate-gory could be Wastewater Technologies , for both tech-nologies are specializations of that very category.
The following two sections describe the classifiers in detail.
Wikipedia is a massive information source featuring more than 2.3 million articles at the time of writing. In order to compute the synergy score for two technologies t i , t j , iden-tified by their name, our system first downloads the respec-tive articles from Wikipedia, denoted p ( t i ) and p ( t HTML documents can be accessed by using the site X  X  inter-nal search service. We only allow exact matches, which puts some constraints on the input data being used.

Next, we extract all hyperlinks contained in p ( t i ) and p ( t j ), resulting in two link sets L p ( t i ) and L p ( t j internal to Wikipedia are considered, i.e., those links that refer to other articles in Wikipedia. Moreover, non-content related links are discarded from these two sets. Those com-prise of links to disclaimer information, terms of use, as well as hyperlinks to geographical locations, i.e., cities, countries, and so forth. Our investigations have shown that such links are of marginal use for the content X  X  description and rather add noise to the classification process. Non-content related links are held in a black list that we have created manually by probing and analyzing sample sets before deployment.
Eventually, the classifier C W computes the synergy score s
W ( t i , t j )  X  [0 , 1] as follows, where L 0 p ( t i ) and L the hyperlink sets after removing irrelevant links:
The number of common links is normalized by means of dividing by the union of links in both sets.

As has been said before, each classifier also generates a description that indicates why the pair at hand is assigned a high value. For C W , this is simply the link text that comes with the hyperlinks both downloaded documents have in common. For instance, for the technology pair of Combus-tion and Alternative Fuel , we have Fuels , Hydrocar-bons , Internal Combustion Engines , etc.

The distribution of score for the complete set of selected technology pairs is displayed in Fig. 2 and will be discussed in detail later.
The second classifier, C D , is substantially more complex than the simplistic Wikipedia-based one. Its inner mechan-ics are described in depth in [17]; the following paragraphs will therefore only present an outline of the algorithm. The nucleus of the classifier is the ODP, which is a massive direc-tory classifying 4.6 million websites into 590,000 hierarchi-cally arranged categories (see Fig. 1). Websites are attached to nodes in order to indicate that they fall into the respective category with regard to their content. The collaborative con-tributions to this massive projects are controlled by 79,000 volunteering editors who each take care of specific areas of the taxonomy tree.
 Next to the ODP, an integral component of C D is Google Directory ( http://www.google.com/dirhp ). Google Directory is another variant of the traditional search engine and is similar in guise to the flagship Google.com. The major dif-ference is that only sites listed in the ODP are considered as search results. Since most of the major sites are contained in the ODP, this limitation is negligible for our application. The huge benefit of Google Directory refers to the fact that all search results are annotated with the ODP category they are listed in. The classifier C D submits each technology as phrasal search query to Google Directory and only keeps the top-n ODP referrals, which are then considered as the  X  X emantic fingerprint X  of that respective technology. For in-stance, when submitting Desalination as query to Google Directory, one of the top-5 results is annotated with the fol-lowing ODP referral:
Hence, we associate each technology t i with an ordered list L ( t i ) : { 1 , 2 , . . . , n } X  Q of ODP referrals, where Q is the set of all ODP categories.

Parameter n is typically set to values in the range [50 , 100] (see [17]). Therefore, the number of distinct topics for each list L ( t i ) is upper bounded by n , which is considerably lower than | Q | . To address this issue, Ziegler et al. [17] propose a probabilistic inference scheme that assigns a score to each node in the ODP taxonomy for each L ( t i ). Hereby, the hi-erarchical organization of the ODP is exploited, by propa-gating score from leaf nodes to upper nodes in the tree. The intuition behind this approach is that whenever an entity e is classified into category q x , which is a sub-category of q then e will also count as an instance of q y . Nevertheless, q provides a more precise characterization of e than q y . There-fore, score propagated from bottom to top drops off for each level in the taxonomy.

Moreover, score assigned to a leaf category q x also depends on the rank of referrals to q x : The topmost search results are assigned higher scores than those occurring towards the end of the list. For taking the rank into consideration, an exponential decay function with half-life  X  = 7 is proposed by Ziegler et al. [17], which has been empirically shown to outperform greater  X  . 3 The rationale behind this approach is that top results are better matches for t i than lower ones, therefore penalizing lower ranks.

Upon score propagation and assignment of score depend-ing on the referral X  X  rank, we obtain a map function M ( t Q  X  [0 , 1] which assigns a score for every category q x  X  Q , based on L ( t i ). Map M ( t i ), the eventual semantic descrip-tion of t i , is then matched against M ( t j ), which represents the counterpart t j . The matching is hereby achieved by us-ing Pearson X  X  correlation coefficient, commonly known from collaborative filtering applications [14, 16]. As result we ob-tain the synergy scoring function s D ( t i , t j )  X  [  X  1 , 1]
The ODP-based classifier proposed in [17] depends on var-ious parameters, namely half-life  X  and two other parame-
Half-life  X  = 7 denotes that the score assigned to an ODP referral at rank 7 is given half the score of the first rank. As Fig. 2 shows, actual values for s D do not fall below 0. ters that have an impact on the propagation of score from leaf nodes to the root. These parameters have been learned on an external test set of terms which were not included for the classifier X  X  later application to  X  X eal X  technology pairs. To this end, we have composed a small list of primarily IT technologies (see the  X  X ist of IT management topics X  on Wikipedia), had one of the authors rate the synergies of all pairs, and applied non-linear optimization techniques so as to find out optimal values for all three parameters of C D
Classifier C W returns, next to the synergy estimate, an explanation for the recommended score (see Sec. 3.1). For C
D , this is also the case: The ODP-based classifier also re-turns an ordered list of the 20 ODP categories that have been assigned the highest scores both for L ( t i ) and L ( t As a rule of thumb we can say that these 20 categories stem from higher taxonomy levels when the estimated synergy score is low, and come from lower (i.e., more specific) levels when the synergy score is high.
In order to come up with one single classification score for pairs { t i , t j } , the results of C W and C D need to be merged into one. However, Fig. 2 shows that the distribution of score weight for both classifiers is substantially different 5 : Classi-fier C D appears to distribute score in a more homogeneous fashion over the full target value range [0 , 1], while C signs higher scores to much fewer pairs. Adding up C W  X  X  and C D  X  X  score is therefore not an appropriate option for score merging, as C W  X  X  impact would be comparatively low. Scaling C W would likewise fail to address the issue.
We therefore opted for another approach, namely to order all pairs { t i , t j } according to their rank , based on s respectively. Thus, we introduce two ranking maps R W : T  X  T  X  N , R D defined accordingly. So as to merge both ranks into one, we take the average of both, resulting in function s ( t the base for computing the final rank R . The drawback of that approach is that relative differences from pairs are not necessarily preserved, owing to equidepth binning.
In order to verify whether the two classifiers were reaching consensus with regard to the classification task, we intro-duced a simple rating consistency metric c : T  X  T  X  [0 , 1] that would tell for each pair whether C W and C D do comply or not:
When C W and C D assign the same rank, function c re-turns 1, attesting 100% consensus. When they dissent max-imally, the result is 0. Fig. 3 shows averaged consensus over all pairs. The mean consensus is . 71, which hints at largely compliant classifiers. Interestingly, consensus is highest for pairs ranked at positions 4,000 to 6,000. It is lowest for the bottom ranks beyond 10,000. Inspection of the data showed that toward the list X  X  bottom, large blocks of pairs with very low ranks R D and moderate ranks R W appeared. However, an examination of samples gave no indication for misclassi-fication; i.e., virtually no false negatives (true synergies that were predicted as  X  X on-synergetic X ) were discovered.
The distributions have been computed based on the com-plete set of 11 , 175 technology pairs.
Our system takes as input one single list that contains triples ( t i , s j , d k ) made up of technology t i , sector s division d k . However, before the list becomes digestible for the automated classification, the findability of these t i to be verified. That is, for each technology, we must make sure that there is a corresponding article on Wikipedia as well as a search result on Google Directory.

From the original list of 150 selected technologies, only 20% could be found on Wikipedia when searching for the literal text. At the same time, Google Directory search re-sults comprising of more than 5 entries were found for circa 60% of the selected technologies. Recall that we made use of phrasal search queries only, so as to attain higher accuracy. That is, all technologies consisting of more than one word, e.g., Arc-Fault Circuit Interrupter , were put into quo-tations  X  X  in order to have the search engine treat them as one coherent text token. Without query phrasing, results would have been returned for virtually all queries.
For list pre-processing, the domain experts X  task was thus to find technologies t 0 i that were retrievable both on Wikipe-dia and Google Directory and were semantically narrow to the original technology t i . Either replacing t i  X  X  name by its syntactically different but semantically equivalent 6 concept label or, if not feasible, superseding t i by its slightly more general super-concept t 0 i appeared as the most obvious ap-proach. However, the use of similar technologies (rather than the original ones) incurs some risk, namely to add noise to the detection of synergies and thus to deteriorate the result. Interestingly, when an article for t i could be retrieved on Wikipedia, chances were around 95% we could likewise ob-tain results on Google Directory. The noted findability issue was significantly more pronounced for technologies stem-ming from the health-care sector than for the industry and energy sectors. Some investigations have shown that Wikipe-dia tends to cover the latter two areas much better than
As in virtually every company, certain concepts at Siemens have names that are used internally only.

Figure 4: Inter-and intra-sector synergy averages medical technology, which becomes clear when having a glance at the Wikipedia category tree, where medical technology is not explicitly mentioned (as opposed to energy and industry topics).
The processed list was fed into our system and the result-ing list of 11,175 technology pairs used to generate an N  X  N pivot table, where N is the number of technologies, in our case 150. The table is organized in three layers: The bottom layer features the highest degree of detail, displaying the scores for all the technology pairs. The second layer consists of 15  X  15 cells, where each cell represents the compound syn-ergy score for two of the 15 Siemens divisions, d x , d y aggregation function used for computing the cell value of d and d y is the average of scores of technology pairs { t i where t i is one of the technologies assigned to d x , and t one of the technologies assigned to d y , respectively. For cal-culating the average division-internal score, i.e., the synergy score for technologies within one given division d x = d y take all pairs { t i , t j } except those where i = j .
The third and most coarse-grained layer measures the synergetic potential of the selected technologies across and within sectors. Again, the aggregation is computed in the same fashion as for the divisions.

For our pivot tabulation, we use the merged ranking R of all the technology pairs { t i , t j } as basis for score com-putation. Hereby, we subdivide the full rank range into 100 equiwidth bins. A middle-ranked technology pair thus gets score value 50.
Next to providing an integrated overview of all likely tech-nology synergies within the organization on different levels of granularity, the pivot tabulation allows us to easily vali-date the system X  X  classification ability by means of some sim-ple hypotheses. With regard to the sectors, an intuitive hy-pothesis is that the intra -sector technology overlap, i.e., the synergetic potential per se, is greater than the inter -sector overlap. When using an automated classification scheme as ours, we would expect the classifier to likewise reflect this hypothesis.

Fig. 4 shows the average synergy potential for all combina-tions of sectors, likewise comprising of inter-and intra-sector scores; higher cell values indicate higher synergetic potential. Table 2: Averages of inter-and intra-division scores Hereby, the sector pair which exhibits the highest average synergy score for one given sector is decorated with one of three superscripts (I) , (E) , and (H) , being acronyms for the respective sectors. We can thus observe that our hypothe-sis of higher intra-sector scores as opposed to inter-sector scores holds for two of the sectors: For the health as well as the energy sector their intra-sector score is significantly higher than their respective inter-sector scores. This is not the case for the industry sector, though, where the machine suggests a higher synergetic potential for the cross-sector overlap with energy than within its own sector. However, the scores are close to each other (58 . 09 versus 56 . 53). Moreover, it is an established fact that the energy and industry sec-tor are in general much closer to each other than the health sector, which is also reflected in the data.

The same effect can be observed on the finer-grained di-vision level. Here, the increase in overlap of technologies within divisions as opposed to across divisions is even more pronounced than for the sector level. Table 2 lists the aver-age inter-division synergy potential versus the average intra-division synergy score for each sector.

Eventually, we may come to conclude that our intuition of coherently arranged organizational units is reflected in our system X  X  automatic synergy prediction approach, even though the results are based on representative selections rather than the full range of technologies.
Our classifier system attempts to judge the synergetic po-tential of any two technologies t i , t j and computes an explicit ranking R of technology pairs according to their synergy value, enabling us to come up with a synergy recommen-dation. The previous section has shown that the use of the classifier in hierarchical pivot tabulating according to or-ganizational layers reveals several findings we would have intuitively expected, thus serving as means of validation.
However, in order to properly quantify the classification accuracy of the system, benchmark evaluations are required. Owing to the lack of relevant labeled datasets that could be used for cross-validation, the only reasonable option is to have humans judge a subsample of the overall set of tech-nology pairs and to compare the machine X  X  automatically computed result with human ratings.
We have composed one such benchmark test set made up of a subsample of all technology pairs. To this end, we have subdivided the 11,175 pairs, sorted according to R , into four bins and randomly selected 5 pairs from each bin. Each pair is assigned its bin number, which simultaneously expresses the synergy value on a 4-point scale. The selected pairs are shown in Table 3.

Next, we had two groups of people, consisting of 10 mem-Machine Experts Non-Experts 4 1.8 0.63 3.4 0.7 1 1.0 0.0 1.4 0.7 3 2.4 1.26 3.2 0.79 2 1.6 0.97 1.8 0.92 3 3.2 0.79 3.2 0.79 2 2.9 1.10 3.7 0.48 3 1.1 0.32 1.9 0.32 2 3.2 1.03 3 1.05 4 2.0 0.67 2.9 0.99 2 1.6 0.70 1.5 0.71 4 3.2 0.79 3.2 0.63 1 2.2 1.03 2.2 1.14 3 1.6 0.84 1.8 0.63 1 1.4 0.52 2.2 0.79 1 1.0 0.0 1.1 0.32 4 3.0 1.15 2.9 1.1 4 2.9 0.99 3.6 0.52 2 2.8 0.92 2.7 0.95 3 1.6 0.70 2.1 0.74 1 1.0 0.0 1.6 0.7 bers each: The first was made up of computer science re-searchers and IT consultants with an affinity to technology in general but no in-depth knowledge of non-IT production processes and products. This group was considered the non-expert group . The second cluster, dubbed the expert group , only contained people with relevant domain expertise. How-ever, though the latter group is named  X  X xpert group X , not all its members are experts for all three sectors at the same time. Most of them specialize in merely one of them (or even a subset of one, by only focusing on some of the divisions of one given sector).

The 20 technology pairs were shuffled, in order to discard the machine X  X  ranking from top-synergy pairs down to those  X  X oor dogs X . Next, the list was shipped to all 20 participants without them knowing either the machine X  X  rating or their fellows X  estimate. The only directive given to them was to rate the synergetic value of all pairs on a scale of 1 to 4, where 1 denotes no synergy at all and 4 denotes maximum synergetic potential. Moreover, they were not forced to strat-ify their ratings, i.e., to assign the same number of 1 X  X , 2 X  X , 3 X  X , and 4 X  X  to the list of 20. Experts as well as non-experts were allowed to look up technologies and their meanings in whatever resources they deemed useful.
In order to analyze and compare the results, we made use of the popular Pearson correlation coefficient (see, e.g., [14]): The ratings of each participant, i.e., experts, non-experts, and the automated computation scheme, are considered as vectors where each component may adopt values between 1 and 4. The correlation coefficient is then computed for two of these vectors, returning values in the range [-1,+1]. Hereby, +1 denotes 100% consensus and -1 denotes completely op-posed rating behavior.

The advantage of Pearson correlation, as opposed to for example the cosine similarity measure [1], lies in its taking care of the general rating tendency of the two arbiters in-volved. Some people rather assign higher scores while others tend to assign lower values. Pearson only measures, for each individual, her deviation from her mean rating. These devi-ations from mean ratings are then compared for each vector component, that is, for each technology pair being evaluated with regard to synergetic potential.
First, we wanted to analyze how members of each of the two groups would behave internally with regard to their syn-ergy judgment. We therefore computed the correlation coef-ficient for every unordered pair of members { m i , m j } of each group, discounting self-correlations i = j . The result was then averaged across the number of pairs, |{{ m i , m j } , i 6 = j  X  i, j  X  X  1 , 2 , . . . , 10 }}| = 9  X  10 / 2.

For the non-expert group, the average intra-group correla-tion amounted to . 53, which is a fairly high correlation. The fact that the correlation does not reach into higher ranges already indicates that synergy identification is a non-trivial task where humans likewise dissent with each other. The intra-group correlation for the expert group was . 56, which supports our hypothesis that experts are closer to each other with regard to their estimation, owing to their familiarity with the process and the technologies discussed. However, the noted difference in average correlation is relatively small. Fig. 5 provides more insight by exposing the distribution of correlation values for each member pair and group: We ob-serve that there are more pairs for the expert group that have high correlations than there are for the non-experts. However, the expert group also has more pairs that have considerably low correlations &lt; . 3.
Next, we wanted to investigate whether experts and non-experts substantially differed from each other with regard to their estimates. We thus computed the inter-group correla-tion that we defined as the average of correlation coefficient values for pairs { m i , m k } , where m i is an expert and m not. The resulting correlation of . 49 hints at the finding that the within -group coherence is greater than consensus across both groups. That is, experts behave in a certain fashion and non-experts do so as well. However, the figures are too close to each other, with no statistical significance for p &lt; . 05 us-ing Student X  X  two-tailed t -test. More extensive studies on a larger scale would be required in order to support or reject the respective assumption.
Upon measuring the behavior of humans when confronted with the task, we eventually evaluated our approach X  X  clas-sification results by means of comparing with the human groups X  assessments. We thus computed the average corre-lation of the automatically assigned synergy ratings with the synergy weights of all members of each group. Moreover, we also generated a non-stratified random synergy rating vec-tor in order to define the borderline, and likewise matched the vector against both groups.

The random rating vector X  X  fit with the non-expert group amounted to . 12, and to . 17 with the expert group. Our auto-mated classification scheme X  X  fit with the non-expert group exceeded this borderline figure by far, returning . 5 as aver-age correlation. This correlation score is almost as high as the non-experts X  intra-group correlation coefficient and gives us an indication that our automated computation system X  X  performance effectively meets our expectations. The fit with our expert group was lower, though, amounting to . 46.
The results for the benchmark as well as the inter-group and inter-group correlations of both human groups are sum-marized in Fig. 6.
The empirical evaluations have shown that evaluating the synergetic potential is not an easy task for humans either. The level of expertise plays an important role, though, as domain experts appear to more strongly comply with each other than non-experts. However, the difference in inner-group consensus for these two groups was still relatively small. One reason might be that our  X  X on-experts X  effec-tively did have technical backgrounds, keeping their spread of ratings at bay. Moreover, both groups were invited to look up technologies they were not familiar with.

Of particular interest is clearly the performance of our au-tomated classification system, which performed utterly well against the human-set benchmark. In particular for the non-expert group the fit of our classifier appeared high, which would make its result barely distinguishable from a man X  X  assessment. While the correlation of our classifier was lower for the expert group, the fit was still comparatively good.
Hence, we come to find that our system is well-suited for use as surrogate for tedious human effort. While this as-sumption was already made during numerous on-the-fly tri-als throughout the system X  X  deployment phase and during arbitrary probing, the preceding empirical evaluations have confirmed this hypothesis.
To the best of our knowledge, there exists no system that addresses the automatic recommendation of technological synergies per se. However, as our idea of leveraging tech-nological synergies is intrinsically connected to the notion of semantic similarity, literature on the latter subject ap-pears most relevant for positioning our work into current research: Logics-based approaches to deriving semantic sim-ilarity come first and foremost from the realm of descrip-tion logics, which are formalisms used to describe concepts and their characteristic features. Seminal works include [3] and [9]. The drawback of these methods is the need to con-cisely formalize all knowledge used throughout the decision process, which would in our case offset the advantage of machine-supported synergy detection as opposed to manual examination by dedicated domain experts.

Other related work, inspired by statistics and probabilis-tic reasoning, intends to determine the semantic distance of word meanings rather than that of generic concepts . To this end, these approaches mostly rely on electronically available, hierarchically structured dictionaries such as the popular WordNet ( http://wordnet.princeton.edu/ ) [11]. The prob-lem of similarity matching is here reduced to simple graph traversal tasks [4] as well as finding least common subsumers in taxonomy trees (e.g., [7], [6], and [10]). In a similar vein, researchers have proposed information-theoretic approaches, see Resnik [12] and Lin [8]. Unfortunately, these approaches mostly apply to concepts found in dictionaries and not ar-bitrary named entities, e.g., Hydraulic Permeability .
With the advent and the proliferation of the Web, corpora-centric approaches have gained momentum: These efforts compute the semantic similarity between two given words or named entities based on massive document collections (such as the Web) and use language statistics such as point-wise mutual information (see, e.g., [15]), word collocation or occurrence correlation [2] in order to estimate their semantic similarity. More complex examples include [17] and [13].
While these approaches appear related to our computa-tion scheme in terms of some of the principle methods used, none of them addresses the context of deriving the synergetic potential based on meronymous and class-subclass relation-ships of technologies.
In this paper we have laid out our systematic approach for recommending technology synergies in an automated fash-ion. The major advantage of this method is the tremendous reduction of human effort while still returning results that match those of human experts with regard to classification accuracy (see Sec. 5.2.3).

We harness the system in two ways: First, we make use of it in order to generate multi-level N  X  N pivot tables that show the company X  X  synergy potential landscape at one glance. Drill-down and roll-up operations along orga-nizational hierarchies (sections, divisions) allow to refine or coarsen the maintained perspective (see Sec. 4.2). Second, we use the system as some sort of  X  X ynergy recommender X , where we have our software rank technology pairs in de-scending order with regard to their synergetic value and then select the top 5-10% for further in-depth inspection. The filtered results are then offered to domain-specific work-ing groups that decide which synergy recommendations are worthwhile to pursue and which are not.
 For future work, we intend to try classifiers other than the ODP-and Wikipedia-based ones presented here. Moreover, we plan to include more rigid evaluation of classifiers com-peting against each other. So far, we have only conducted informal assessments for comparing the accuracy of the com-bination of both classifiers, as opposed to the use of just one of them. When having several additional classifiers in place, we envision to apply boosting (such as AdaBoost.M1 [5]) and bagging techniques for optimal classifier weighting.
