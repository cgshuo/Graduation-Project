 In the recent years, we have witnessed the increasing use of personalisation and rec-ommendation systems in order to solve the problem of information seeking and infor-mation overload when accessing large archives of content. Whether it is our ever in-creasing digital music collections, digital photo collections, NEWS stories or even web pages, we are becoming more and more reliant on smart information systems to under-stand our needs and recommend content according to our interests. In this paper we present a novel music recommendation system that incorporates both collaborative filtering and mood-based recommendations. We illustrate the performance improve-ments of a music recommender system that incorporates mood-based recommenda-tions and collaborative filtering by evaluating three different approaches for producing recommendations by means of live user experiments over a period of one month. 1.1 Collaborative Recommendation Typically recommender systems have been extensively used within e-commerce and online communities for recommending items like movies and books. More recently, recommender systems have been deployed in online music players, recommending music to users. Content-based filtering and collaborative filtering are two well-known algorithmic techniques for computing recommendations. A content-based filtering system [1] selects items for recommendation based on the correlation between content and the stored user's preferences. A colla borative filtering system [2] recommends items not seen by the user, based on a correlation calculated between the user and other users with similar preferences. In addition, hybrid approaches have been devel-tent-filtering systems to recommend only  X  X ore of the same X  content to a user. 1.2 Music Recommender Systems There has been previous work on music recommender systems. For example Ringo [4] is a collaborative filtering recommendation system where the ratings of users similar to a particular user are utilized to suggest music for recommendation. Lee and Lee [5] have developed a music recommender system based on automatically identifying a person X  X  mood (using temporal and context information). This mood-based recom-mendation is positively evaluated on a closed set of user listening data, retrospectively gathered with recommendations based on user X  X  playback history. Where our research differs from the pre-existing research is in the integration of low-cost, mood-based recommendations with collaborative filtering, based on explicitly gathered mood rat-ings of both music and users, which we know to be accurate. In addition, our recom-mender system is positively evaluated using real-world data in a live implementation, with live users interacting with the system and receiving recommendations on an ongo-ing basis and instantly evaluating them, for a period of just over one month. For our experiment, the music collection employed was a 6,027 song collection, gath-ered by the participants in the experiment, and thus representing the range of musical shown in Table 1, which is used to recommend content to participants. Each song a evaluation and training purposes, as described in subsequent sections. 
In total there were 54 users for this experiment, from three locations (in both the US days. This month long evaluation was divided into three phases of experimentation, mass of user ratings to support subsequent music recommendation using collaborative filtering and collaborative mood filtering. After this first phase, the following two weeks were divided between the non-mood based collaborative filtering (collaborative period) and mood-based (mood-based collaborative period) experiments, as shown in Figure 1. 2.1 Genre-Based Content Filtering During the initial training phase of gathering a critical mass of user ratings, users were recommended music based on their listening history ( X  X ore-like-i-heard-already X ) and genre X  X  that they liked. These recommendation resulted in new (not yet rated) music being recommended from the most important genres for each user. In this way, we maximized the number of ratings stored in the system. The evaluation of recommen-dation quality was ongoing during this phase, and the results are presented in Figure 1 below. Recall that a typical binary scale (like / not-like) was employed for user judg-ments and every time a song was played by a user, they rated each song on this binary scale and also annotated each song with one of the four mood descriptors. 
The key result of this phase of the experiment was that a critical mass of user rat-ings (6,159) was now stored in the system, along with the mood annotation of these songs. This provided a source of data for recommendations in the following two phases of recommendation. 2.2 Collaborative Filtering The content filtering phase (just described) was followed by a week of collaborative filtering recommendations, which recommend music to users on the basis of the simi-larity between users. User similarity was estimated by calculating the well known Mean Squared Difference measure between any two users, as shown below: the ratings differ, msd a,u is 1. Exploiting the ratings of similar users, songs that user a has not rated before, are recommended to user a thereby avoiding recommendation cycles (recommending the same content constantly) 1 . 
During this (and the following) phase of the experiment, ratings were not stored for recommendation purposes, rather only for later evaluation of recommendation performance, so as to avoid any bias in favour of the subsequent collaborative mood filtering phase. In addition, further mood annotation was not performed for this or the following phase. 2.3 Collaborative Mood Filtering Collaborative Mood Filtering is similar to the collaborative filtering, however with the difference that songs are only recommended to a user that match the user X  X  current filter over the recommendations, thereby focusing the recommendations on the par-ticular mood of the user at any given time. The effect of this is to reduce the number of songs that are available for recommendation and once again users rated songs for evaluation purposes only. Once again, songs that the user had not seen were recom-mended to the user and the previously-seen-lis t reset to zero at the start of this phase. 2.4 Results of Evaluation For the evaluation, instead of using a simple Precision value, we have utilised an accuracy measurement which will give a more intuitive evaluation of the quality of the recommendations, by allowing the number of negatively rated songs to influence the score. The accuracy measurement is shown in the following formula: songs recommended on day n , S --n is the number of negatively rated songs recom-mended on day n , and S n is the number of songs recommended on day n . The Accu-racy measure will always be in the range of -1 to +1, with positive scores illustrating a higher number of positive ratings than negative ratings. song, the accuracy of the recommendation techniques could be immediately evalu-ated. The results of the experiment are presented in Figure 2 below, where we plot the accuracy of the recommendations on a day-by-day basis (through the three experi-which only one user requested recommendations, which were two days during two weekends 2 . 
As can be seen from Figure 2, the trendline shows that during the content-based phase, that recommendation accuracy increased during the first few days as ratings are built up, but then remains relatively static, suggesting that genre-based user histo-ries for non-collaborative, genre-based recommendations become effective within a week or so. 
Upon entering the collaborative period, where recommendations are based on pure collaborative filtering, the accuracy of recommendations drops significantly and shows more variance in performance than mood-based filtering. In the mood-based collaborative filtering phase, the climb in accuracy (seen in the collaborative period) continues steadily, suggesting that mood-based collaborative filtering outperforms conventional collaborative filtering. If we compare the average accuracy of both benefit of mood-based collaborative filtering is clear. 
It is difficult at this point to firmly conclude the reason why the performance of the collaborative period (phase 2) is so low, though we believe that this could be due the requirement of a longer first phase of the experiment to gather even more user ratings mood filtering approach does not seem to be affected in the same way by the density of user ratings in the system, which we believe is due to the fact that the mood filtra-tion of recommendations reduces the negative effect of any noisy recommendations from the collaborative filtering technique. 
Although this is early work in the area of mood-based recommendations and is based on a coarse five point scale for music genre and a four point scale for evaluat-ing mood, the application of a mood filter clearly shows benefits for recommendation quality on our experiment. In this paper we have shown that a low-cost, mood-based collaborative filtering mechanism outperforms both conventional collaborative filtering and the genre-based content filtering system in a real-world music recommendation system. We propose that the mood-based recommendations reduce the number of noisy recommendations that are present when compared to a pure collaborative filtering technique. 
In future work, we will maintain a balance between recommending content that the performance. We will also examine scalability issues for real-world collaborative-based recommendations and will examine the effect of automatically estimating user mood. Finally, moving from explicit user feedback of mood and recommendation quality judgments to implicit judgments, we will examine the effect and accuracy of these implicit judgments. 
