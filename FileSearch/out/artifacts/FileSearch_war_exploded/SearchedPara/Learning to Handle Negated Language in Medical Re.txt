 Negated language is frequently used by medical practition-ers to indicate that a patient does not have a given med-ical condition. Traditionally, information retrieval systems do not distinguish between the positive and negative con-texts of terms when indexing documents. For example, when searching for patients with angina, a retrieval system might wrongly consider a patient with a medical record stating  X  X o evidence of angina X  X o be relevant. While it is possible to en-hance a retrieval system by taking into account the context of terms within the indexing representation of a document, some non-relevant medical records can still be ranked highly, if they include some of the query terms with the intended context. In this paper, we propose a novel learning frame-work that effectively handles negated language. Based on features related to the positive and negative contexts of a term, the framework learns how to appropriately weight the occurrences of the opposite context of any query term, thus preventing documents that may not be relevant from being retrieved. We thoroughly evaluate our proposed framework using the TREC 2011 and 2012 Medical Records track test collections. Our results show significant improvements over existing strong baselines. In addition, in combination with a traditional query expansion and a conceptual represen-tation approach, our proposed framework could achieve a retrieval effectiveness comparable to the performance of the best TREC 2011 and 2012 systems, while not addressing other challenges in medical records search, such as the ex-ploitation of semantic relationships between medical terms. Categories and Subject Descriptors: H.3.3 [Informa-tion Search &amp; Retrieval]: Search process Keywords: Medical Records Search; Negation; Regression-trees
Electronic medical records (EMRs) have been used to document the medical history of patients to ensure patient safety and prevent medical errors [30, 32]. These EMRs can be used to improve the quality of healthcare services. Table 1: Examples of sentences in EMRs where the presence of the query term  X  X ancer X  does not always indicate the relevance.
 Moreover, EMRs can also be used to evaluate the effective-n ess of a particular medical procedure. For example, medi-cal researchers may search from the EMRs for the patients with particular medical condition(s), when forming a clini-cal trial for a particular treatment [14, 35, 36]. This requires an effective information retrieval (IR) system that is able to cope with the special characteristics of medical records and queries. To facilitate research on searching medical records, TREC initiated the Medical Records track in 2011 [35, 36].
One of the major challenges of searching from medical records is the use of negated language [18, 20]. Negation is commonly used in medical records to indicate that the pa-tient does not suffer from a particular medical condition [16]. As a result, the presence of a query term does not always imply that the record is relevant to the query [4]. In par-ticular, the relevance also depends on the context of query terms occurring in the medical records. For example, while all the three sentences shown in Table 1 contain the query term  X  X ancer X , only the first sentence indicates that the dis-ease is pertaining to the patient, while the other two sen-tences are irrelevant towards the query searching for patients suffering from  X  X ancer X . Averbuch et al. [4] estimated that ignoring negation in medical records could result in a drop of 40% in retrieval performance. In addition, several top performing search systems (e.g. [11, 17, 20, 24, 39]) at the TREC 2011 and 2012 Medical Records track showed that dealing with negation in medical records improved the re-trieval performance. King et al. [17] reported that by re-moving the negated sentences from a search system, the re-trieval performance could be improved by 5%. In particular, the approaches described in [11, 17, 39] disregard all parts of sentences having a negative context during the search process. Different from the others, Limsopatham et al. [20, 24] proposed a representation approach that could signif-icantly improve the retrieval effectiveness, by representing terms having either negative or positive contexts differently. However, their representation approach [20] could only help to retrieve medical records containing query terms with the correct contexts, but it does not necessarily prevent med-ical records containing query terms with opposite contexts from being retrieved. For example, they represent a medical record such as  X  X eart disease patient with no history of dia-betes X  as  X  X eart disease n $ diabetes X  , where n$diabetes is the negative version of diabetes. In this case, for a typical best m atch retrieval model, a query such as  X  X ind patients with heart disease and diabetes X  would still retrieve this medical record, since two of the three non-stopped terms (i.e. heart, disease) are matched, even though it is a medical record of a patient who is known not to have diabetes.

In this paper, we propose a novel learning framework to prevent medical records clearly stating that their associated patients do not have the medical conditions stated in the query from being ranked highly. In particular, our frame-work consists of three components. Firstly, as we intend to promote medical records having query terms with their intended context and to demote those containing the query terms with the opposite context, we follow [20] and represent terms in medical records and queries by taking their contexts into account. Secondly, we penalise the medical records con-taining the query terms with the opposite context, which we refer to as the opposite context terms , in order to pre-vent medical records having the occurrences of the query terms with the opposite intended context from being ranked highly. For example, for a query  X  X ypertension X , the opposite context term is  X  X $hypertension X . Finally, we set an effec-tive penalising weight for each of the opposite context terms, to reduce the relevance score of medical records containing these terms. Specifically, we deploy a regression technique to identify the penalising weight of an opposite context term using features (e.g. term frequency, and co-occurrence infor-mation), obtained from the query and the medical records.
We evaluate our proposed framework using the standard test collections provided by the TREC 2011 [36] and 2012 [35] Medical Records track. Our results show that the proposed framework can significantly outperform a strong negation handling baseline. When combined with a conceptual rep-resentation using an existing approach [31], our achieved re-trieval performance is comparable to those of the best TREC 2011 and 2012 systems.

The contributions of this paper are three-fold:
The remainder of the paper is organised as follows. In Sec-tion 2, we discuss related work and position our paper in the literature. Section 3 introduces our proposed learning frame-work. Section 4 discusses our proposed learning procedure. Section 5 describes the experimental setup. We empirically evaluate our framework in Section 6.1. In Section 7, we fur-ther evaluate our framework when combined with a concep-tual representation approach, which has been shown to be effective for this medical records search task [21]. Finally, we conclude the paper and discuss future directions in Section 8.
The wide-spread use of negated language is a major chal-lenge in the searching of medical records. Indeed, negated language is extensively used in medical records by practi-tioners to indicate that the patients do not possess a partic-ular symptom or condition [18, 20]. For example, a medi-cal record stating that  X  X he patient has a cough but denies fever X  indicates that the patient has a cough but does not have fever, which is not relevant to a query issued to find patients having both cough and fever. This causes a prob-lem for IR systems that estimate relevance from only the matching between the terms in a document and a query. However, prior work dealing with negation in documents is limited. Table 2 summarises and compares our work in this paper with related work. Specifically, classical/traditional IR approaches (e.g. BM25 [28]) do not explicitly deal with negation. They simply ignore the presence of negated lan-guage in medical records and query [18]. On the other hand, most of the previous works that deal with negated language (e.g. boolean retrieval model, post-retrieval filtering [29, 37], vector negation [37]) only tackled it within queries. For example, the boolean retrieval model focuses on retrieving documents by firstly forming a list of documents contain-ing the query terms and then removing the documents with the occurrence of the negated query terms from the retrieved list. Nevertheless, these approaches do not take into account negated language in documents. Indeed, most phrases indi-cating negation (e.g. no, not) are commonly seen as stop-words and are usually discarded during indexing [10]. In contrast, there have been recent attempts to deal with nega-tion in medical records search (e.g. [11, 17, 20, 24, 39]). In particular, these approaches commonly deploy a negation detection tool (e.g. NegEx [10] or NegFinder [26]) to deal with negated language in medical records. For example, King et al. [17] and Zhu et al. [39] proposed to effectively d isregard terms with the negated context from a medical search system. Specifically, they removed from a search sys-tem parts of the sentences that contain the negated context identified using the NegEx tool. Limsopatham et al. [20] introduced a document representation approach that distin-guishes the negated terms from their corresponding terms with the positive context within a search system. Indeed, they firstly deployed the NegEx tool to identify negated terms from the medical records. Then, during indexing, they represent a term and its corresponding term with the opposite context differently. Hence, during retrieval, medi-cal records do not gain a relevance score from negated query terms, if the query terms are in a positive context.
However, all aforementioned approaches suffer from a num-ber of limitations. Indeed, traditional approaches that sim-ply ignore the presence of negated language in medical records and queries might prevent a search system from being effec-tive, since the context of the terms in the search system is not recognised. On the other hand, while approaches such as post-retrieval filtering [29, 37] and vector negation [37] im-prove the representation of the queries, they are still ineffec-tive in demoting the medical records containing the opposite context terms, because they do not alter the representation of the medical records. Conversely, the approaches that al-ter the medical records representation in order to discard the negated sentences from the search system (e.g. [11, 17, 39]) cannot cope with the negated language in the queries. For example, for a query searching for  X  X eart disease patients who have no history of diabetes X , the approaches in [11, 17, 20, 39] might retrieve the medical records of patients suffer-ing from both heart disease and diabetes, since the terms  X  X eart X  and  X  X isease X  are still matched with the query, even if these medical records are not relevant.

To overcome these limitations, we propose a novel learning framework to effectively handle negation in medical records search systems. Specifically, we propose to improve the rep-resentation of both medical records and queries by repre-senting terms along with their context. Moreover, we pe-nalise medical records containing the opposite context terms to prevent these medical records from being ranked highly, when they are unlikely to be relevant.

Machine learning techniques, such as linear and logistic re-gressions, have been used to identify weights for query terms when scoring documents. For instance, Cao et al. [9] used SVM for term classification. They distinguished between good and bad terms for query expansion and expanded a query with only those deemed good expanded terms by tak-ing the classification score into account. Lease et al. [19] introduced Regression Ranking , which deploys a linear re-gression to estimate term weights from the past queries us-ing features, such as term and document frequencies and part-of-speech. Later, Bendersky et al. [7] proposed a lin-ear regression approach to parameterise the weights of the terms. As regression has been shown to be effective for esti-mating term weights, in this work, we also deploy regression to estimate the weight of the opposite context terms, to en-sure that the relevance score of the medical records with occurrences of these terms are properly penalised. In this section, we describe our new Learning framework To Handle Negation (LTHN) in medical records search. The Table 3: An example of a sentence processed us-ing the context identification component  X  italicised terms have negative context.
 proposed framework addresses the drawbacks of the existing n egation handling approaches, discussed in Section 2. The major difference between our framework and those exist-ing approaches in the literature is that our framework goes beyond matching terms with the correct context between a medical record and a query, by penalising the medical records that contain the opposite context terms. This pre-vents these medical records from being retrieved, since they are likely to be non-relevant. Specifically, our framework consists of three components: 1. Context identification , to identify and represent the 2. Context-based penalisation , to model the penalisation 3. Penalising weight estimation , to accurately weight the
Next, we discuss in detail the context identification com-ponent in Section 3.1. In Section 3.2, we describe the context-based penalisation component to demote non-relevant med-ical records. Finally, Section 3.3 introduces the penalising weight estimation component that deploys a regression tech-nique to estimate the weight of the opposite context terms for penalising medical records containing these terms.
The context identification phase is an important compo-nent of our framework, as it helps a search system to dis-tinguish between a term with different contexts (e.g. dia-betes and no diabetes). In particular, this component pre-processes medical records and queries by using a negation detection tool to identify negated terms. In this work, we follow [20] and use the NegEx algorithm [10] to differenti-ate between terms having positive and negative contexts in each sentence in both the medical records and queries. Then, terms with the negative context are replaced with their neg-ative version before processing in an IR system. Table 3 shows an example of how our context identification com-ponent deals with a sentence, such that a term  X  X iabetes X  which has a negative context is replaced with its negated form,  X  X $diabetes X . This allows the IR system to match both terms and their context during retrieval.

However, even though the context identification compo-nent can improve the representation of medical records and queries, it could not prevent non-relevant medical records that contain some of the query terms with the correct con-text from being retrieved. We introduce the second compo-nent to deal with this problem in the next section.
To decrease the likelihood that non-relevant medical records (indicated by the occurrence of the opposite context terms) are retrieved, the second component of our framework pe-nalises these medical records based on the occurrences of the Table 4: An example of how our framework deals w ith negation, where w n is the weight of a term. Context identified EMR lung cancer n$diabetes Context identified query diabetes lung cancer
Context-based penalisation opposite context terms. In particular, if a query searches f or a particular context (e.g. positive) of a term but a med-ical record contains the query term with the opposite con-text (e.g. negative), the medical record is likely to be non-relevant. For example, for a query  X  X ind patient with di-abetes and lung cancer X , a medical record stating  X  X atient with lung cancer who does not have diabetes X  X s non-relevant, since the medical record clearly states that the associated patient does not have a medical condition that the query is searching for (i.e. diabetes). However, as shown in Table 4, with only the context identification component, the record is represented as  X  X ung cancer n$diabetes X . As a result, the medical record may still be retrieved since it matches two of the three query terms (i.e.  X  X ung X  and  X  X ancer X ). The context-based penalisation component copes with this issue by re-ducing the relevance score of medical records, if they con-tain a term t  X  with the opposite context to its corresponding query term t (e.g.  X  X $diabetes X  is the opposite context term corresponding to query term  X  X iabetes X ). This component models the relevance score of a medical record based on both the occurrence of the query terms and the opposite context terms, so that the relevance score of the medical records con-taining the opposite context terms will be penalised, while the relevance score will be increased if the query terms with the correct context occur in the medical records. To do so, the terms having the opposite context to their corresponding query terms are added to the query with a particular weight to penalise the relevance score of medical records contain-ing these opposite context terms. For example, in Table 4,  X  X $diabetes X ,  X  X $lung X  and  X  X $cancer X , which are the opposite context terms of the query terms  X  X iabetes X ,  X  X ung X  and  X  X an-cer X , respectively, are added to the query with the penalising weight w n . Equation (1) shows how the second component of the framework calculates the relevance score of a medical record d towards a query Q . where opposites ( Q ) returns a set of the opposite context terms (e.g.  X  X $diabetes X ,  X  X $lung X  and  X  X $cancer X  are the op-posite context terms of the query illustrated in Table 4), w 2 and w 3 in Table 4)  X  typically w ( t  X  ) &lt; 0, to penalise the occurrences of t  X  . score (  X  ) can be calculated using any term weighting model, such as BM25 [28]. Indeed, the first part of the equation is the classical document scoring approach that estimates the relevance of a medical record based on the ap-pearance of a query term t . On the other hand, the second part of Equation (1) aims to penalise the medical records that contain an opposite context term t  X  (e.g.  X  X $diabetes X ).
From Equation (1), we draw attention to w ( t  X  ), which is a crucial parameter for effectively penalising a medical record for the occurrences of t  X  . Indeed, there are different alterna-tives to estimate w ( t  X  ), such as giving a fixed weight to all the opposite context terms. However, to effectively estimate the weight of the opposite context terms, in the next section, we introduce the last component of our framework, which deploys a regression technique to learn an effective weight for the opposite context terms using several statistical features.
The penalising weight estimation component focuses on finding an appropriate weight to penalise the medical records containing an opposite context term (i.e. w ( t  X  ) in Equa-tion (1)), to prevent these medical records from being ranked highly, hence leading to an effective retrieval performance. We hypothesise that not all opposite context terms are equally important for penalising the relevance of medical records. For example, consider the query  X  X ind a patient with dia-betes and lung cancer X  in Table 4, which is represented as  X  X iabetes lung cancer X . For this query, medical records with the term  X  X $diabetes X  should be penalised more than those containing  X  X $cancer X , as in the former, it is likely that the patient does not suffer from diabetes, while a medical record containing  X  X $cancer X  may discuss a patient who does not have another type of cancer (e.g. the patient does not have kidney cancer). In this way, the discriminative power of the opposite context terms should be considered when assigning the penalising weights.

We view this problem of estimating the penalising weights of different opposite context terms as a supervised learning problem, where the objective is to predict an estimated effec-tive penalising weight for each opposite context term, based on the retrieval performance on a training set. By doing so, we benefit from the fact that several features (e.g. term frequency and co-occurrence statistics) of the opposite con-text terms are taken into account to estimate the penalising weights. Indeed, a regression function f (  X  ) calculates the pe-nalising weight of an opposite context term t  X  using a set of features  X  t  X  , which are associated to the term t  X  , as follows: The regression function f ( X  t  X  ) aims to approximate the weight w ( t  X  ) using a particular loss function. As we aim to maximise the accuracy of the weight ( w ( t  X  )), we use the root-mean-square error (RMSE) as the loss function, calculated as follows: where T  X  is the set of the opposite context terms from a training dataset, and O ( t  X  ) is the oracle weight for the term t  X  within the training dataset. The procedure to obtain O ( t  X  ) is discussed in Section 4.
This section describes the procedure to derive the weight of each opposite context term to penalise the relevance score of medical records containing the opposite context terms as discussed in Section 3.3. Indeed, Section 4.1 details the set of features  X  t  X  that are used to estimate the weight w ( t  X  ) for the unseen queries. Then, we explain how the estimated ef-fective penalising weight O ( t  X  ) for an opposite context term scribes in detail the regression technique (learner) and the objective function (i.e. loss function) that we use to learn the penalising weights.
W e firstly identify a set of features  X  t  X  of an opposite con-text term t  X  to be used to train a learner to identify the pe-nalising weight of the opposite term. These features should correlate with the weight O ( t  X  ) that could bring about the optimal performance, and are generalised across terms. Ta-ble 5 lists the 13 features used in this paper. We focus on features that can be obtained directly from the corpus, which makes our experiments reproducible; however, there may be other features that can be explored in future work.
We focus on 4 types of features, namely term frequency, document frequency, frequency of co-occurrence, and query length. Indeed, the first two types include the classical term and document frequency statistics and their variants (Fea-tures 1-8), which model the ubiquity and specificity of a particular term [19]. Specifically, these features consist of the term occurrence statistics of both an opposite context term t  X  and its corresponding query term t . The higher value of these features, the more discriminative the term is. In-deed, we use the term and the document frequencies of both t posite context term t  X  and its corresponding query term t . The next set of features (Features 9-12) are related to the co-occurrence frequency. It has been shown that a term that frequently co-occurs with the query terms often relates to the query [5]. Therefore, it is intuitive that the medical records containing the opposite context terms that frequently co-occur with the query terms should not be highly penalised. In particular, Features 9-12 measure the co-occurrence of the opposite context term t  X  with the query terms using dif-ferent co-occurrence variants, such as the raw number of documents where the term t  X  and its corresponding query term t co-occur and the EMIM (Expected Mutual Informa-tion Measure) [34] of terms t  X  and t . Finally, since a long query tends to be more complex and hence more difficult, Feature 13 counts the number of query terms ( | Q | ). Indeed, a long query provides more evidence to infer the relevance of EMRs, and hence it is possible to derive more opposite context terms to penalise the non-relevant medical records.
To identify the effective penalising weight of the opposite context terms, we follow [9] and assume the independence between the opposite context terms, when estimating the penalising weight of each opposite context term one at a time, when adding them to a query. Indeed, on the train-ing set, when estimating the effective penalising weight of each opposite context term ( w ( t  X  ) in Equation (1)), we add the opposite context term t  X  to the query, and identify the oracle weight O ( t  X  ) of t  X  , which is the weight that provides the highest retrieval effectiveness, in terms of a particular retrieval measure (e.g. MAP or precision at 10), when rank-ing medical records using a particular ranking model (e.g. BM25). In particular, we sweep the penalising weight be-tween -1 and 1 to find the best penalising weight for each opposite context term t  X  . We allow the penalising weight to be between -1 and 1, since it is also possible that the oc-currences of an opposite context term in a medical record may infer the relevance of a medical record. For example, for a query to find patients with  X  X earing loss X , the medical record stating X  X atient presents no signs of hearing X (i.e. rep-resented as  X  X $hearing X ) is likely to be relevant. Therefore, in our model, we allow the penalising weight to be either negative or positive, so that the learner will decide based on the term X  X  features what is the effective penalising weight.
From a training dataset, we have examples of penalising weights for opposite context terms and their corresponding features. We then learn to predict the penalising weight of each unseen opposite context term based on its features. In particular, while any regression technique can be used, we deploy Gradient Boosted Regression Trees (GBRT) [33] (as implemented in the jforest package [13] 1 ) as a learner, since it has been shown to be effective and efficient in several search and regression tasks [23, 33]. We use the root-mean-square error (RMSE) as the loss function (i.e. Equation (3)) when learning the penalising weight of an opposite context term. Our proposed framework leverages term frequency, document frequency, and the co-occurrence statistics of the terms in the corpus, introduced in Section 4.1, as learning features for the GBRT learner.
We have emphasised the challenge of handling negation language in medical records search and proposed our learn-ing framework to deal with such a challenge in Sections 3 and 4. In this section, we discuss our experimental setup to evaluate the effectiveness of our proposed negation han-dling framework. In particular, Section 5.1 describes the used medical test collection. Section 5.2 discusses the rank-ing models used in our experiments. Finally, we discuss the setting of the GBRT learner in Section 5.3.
We use the test collection provided by the TREC 2011 [36] and 2012 [35] Medical Records track to evaluate our pro-posed framework. The task is to identify patient visits rel-evant to a given query topic. Each visit contains all of the medical records associated with a patient X  X  visit to a hospi-tal. Due to privacy concerns [36], a visit is used to represent a patient as a unit of retrieval. The collection contains med-ical records from the University of Pittsburgh NLP Reposi-tory 2 , which consists of approximately 102k medical records. These medical records can be mapped to 17,265 different pa-tient visits. We evaluate our proposed framework using the 34 and 47 topics from the TREC 2011 and 2012 Medical Records track, respectively. Example query topics include: Q101: Patients with hearing loss
Q102: Patients with complicated GERD who receive endo-
Q137: Patients with inflammatory disorders receiving TNF-
Q179: Patients taking atypical antipsychotics without a
We evaluate the effectiveness of our proposed framework, using the TREC Medical Records track official measures, namely the bpref [8] and precision at 10 (P10) measures for TREC 2011, and the infAP [38], infNDCG [38] and P10 measures for TREC 2012. bpref, infAP and infNDCG are used since the gold standard judgements are incomplete [35, 36]. The higher these retrieval measures, the more effective the retrieval system. In addition, the paired t-test is used to measure the statistical significance (at p &lt; 0 : 05 and p &lt; 0 : 01) of the difference between the retrieval performances of our proposed framework and each compared baseline.
We index the medical records using the Terrier retrieval platform [27], applying Porter X  X  English stemmer and remov-ing stopwords. The TREC task encompasses ranking patient visits instead of retrieving medical records directly. Indeed, retrieving patient visits having medical records relevant to the query is similar to the expert search task [6], which aims h ttp://code.google.com/p/jforests/ http://www.dbmi.pitt.edu/nlpfront to rank people (e.g. employees within organisations) based on the relevance of documents associated to them. It has been shown in TREC that the existing expert search ap-proaches (e.g. [24, 39]) could effectively handle the TREC medical records search task. Hence, in this work, we also deploy a well-established approach previously developed for expert search  X  X he Voting Model [25] X  such that patients are ranked based on their medical records [24, 39]. The Voting Model [25] views patient visits ranking as a voting process. The ranked medical records (denoted R ( Q )) literally vote for the relevance of their associated patient visits. Specifically, the score of each medical record in R ( Q ) is used to estimate the relevance of candidate patients by using a voting tech-nique, such as CombMAX and expCombSUM. Indeed, each voting technique firstly ranks medical records based on their relevance towards a query using any traditional document ranking model (e.g. BM25 [28], DFR DPH [2]). Then the relevance scores of medical records are aggregated to define the relevance score of their associated patient visits.
In particular, we use the effective parameter-free DPH term weighting model [2] to rank medical records. Then, to rank the patient visits, we deploy expCombSUM [25], as it focuses more on the highly relevant medical records (i.e. medical records in the top ranks), while voting for the relevance of the patient visits. Specifically, expCombSUM estimates the relevance of a patient visit v with respect to a query Q as follows [24]: where R ( Q )  X  profile ( v ) contains the set of medical records in the ranking R ( Q ) that are also associated to the patient visit v ; score ( d; Q ) is the relevance score of medical record d for query Q , as obtained by a standard weighting model (namely, DFR DPH). The number of medical records in R ( Q ) to vote for the relevance of the patient visits is limited to 5,000, as suggested in [24].
To learn the weight of the opposite context terms (i.e. fault setting of GBRT from the jforest package. Since the number of topics in each topic set is small (i.e. 34 topics for TREC 2011 and 47 topics for TREC 2012), we choose to train the learner using the other topic set, when testing with one particular topic set. For example, we train the GBRT learner on the TREC 2011 topic set, when testing with the TREC 2012 topic set, and vice versa. We refer to this setting as cross-collection validation (x-collections). When train-ing the term weight estimation learner, we aim to minimise the root-mean-square error (RMSE) of the weight w ( t  X  ) of each opposite context term t  X  , as per Equation (3). We train the effective penalising weight based on the achieved retrieval performance, in terms of bpref and infNDCG, when the query topics from the TREC 2011 and TREC 2012 are used as the training topics, respectively.
Next, we discuss the experimental results conducted using our proposed framework in Section 6.1. Moreover, as query expansion techniques have been shown to be effective for the medical records search task [11, 20, 39], we report the results of our framework when a traditional query expansion is also deployed in Section 6.2. Finally, an ablation study to iden-t ify the importance of features is presented in Section 6.3
First, we evaluate the retrieval performance of our pro-posed framework using the TREC 2011 and 2012 Medical Records track test collections. Specifically, we compare the effectiveness of our proposed negation handling framework with that of the baselines, including the post-retrieval filter-ing approach [29, 37] (i.e. using DFR DPH to rank medical records and filtering out medical records with opposite con-text query terms), the context identification [20, 24], and a traditional approach where negation is not explicitly han-dled (i.e. using DFR DPH to rank medical records)
Table 6 compares the retrieval performance of our pro-posed framework with the aforementioned baselines, in terms of bpref, infNDCG, infAP, and P10. Firstly, we observe that the post-retrieval filtering baseline performs worse than the other approaches reported in this paper. This is likely be-cause this approach simply discards all medical records con-taining query terms with the opposite context, while it may be possible that some of these medical records are relevant. Next, both the context identification approach [20] and our proposed learning framework to handle negation, with the fair cross-collection validation setting (namely, LTHN (x-collections) ) outperform the traditional approach baseline, where the negation is not explicitly handled, for most of the official TREC retrieval measures. The only exception is that LTHN (x-collections) does not outperform the tradi-tional approach baseline for P10 on TREC 2011. Indeed, on the TREC 2012 topic set, the proposed framework, LTHN (x-collections) , significantly outperforms the traditional ap-proach (paired t-test, p &lt; 0 : 05), up to 4.6% and 7.4% in terms of infNDCG and infAP, respectively. This shows that to attain an effective retrieval performance, a search sys-tem should be able to distinguish between the context of terms. In addition, we find that our proposed framework, LTHN (x-collections) , did not improve over the context iden-tification baseline (i.e. where only the context identification component of our framework is active). This means that for this setting, the penalising weight estimation component of our framework (introduced in Section 3.3) could not ef-fectively penalise non-relevant medical records. We believe that this is because our framework aims to demote medical records containing query terms with the opposite context from the retrieved ranking list; however, the relevance of the retrieved medical records depends only on the occur-rence of a small number of query terms. As the evidence (i.e. query terms) used to retrieve medical records is lim-ited, our proposed framework could not effectively demote potentially non-relevant medical records while retaining the relevant ones at the top ranks. Next, in Section 6.2, we ex-amine if having more evidence (i.e. query terms) to infer the relevance of medical records, our proposed framework could further improve the retrieval performance.
As local-statistic [1] and external corpus [12] query ex-pansion (QE) approaches have been shown to be effective for the medical records search task [11, 20, 39], in this sec-tion, we apply such approaches to improve the query rep-resentation by adding more evidence (i.e. query terms) to the queries. In particular, we expect that if QE expands the query with more evidence (i.e. informative terms) to in-fer the relevance of medical records, our negation handling framework would effectively demote the non-relevant medi-cal records in the ranking list, and hence improve retrieval performance. Therefore, we improve the representation of the queries by using information from both internal and ex-ternal corpora. Indeed, we apply the DFR Bo1 model [1] to expand the queries with the top 10 informative terms from the top 3 ranked documents retrieved from the med-ical records collection of the TREC Medical Records and the MEDLINE abstract collection of the TREC 2005 Ge-nomics [15] tracks.

Table 7 compares the retrieval performance, after apply-ing the aforementioned QE technique on both our proposed framework and the baselines. In particular, we use the same baselines (i.e. the traditional, the post-retrieval filtering, and the context identification approaches) and the same retrieval effectiveness measures (i.e. bpref and P10 for TREC 2011, and infNDCG, infAP, and P10 for TREC 2012) as in Sec-tion 6.1. In addition, the highest retrieval performance that our framework could achieve is also discussed (i.e. when us-ing the oracle w ( t  X  ) = O ( t  X  )).

From Table 7, we firstly observe that after applying QE, the retrieval performances of our proposed framework (namely, LTHN (x-collections)+QE ) and all of the baselines increase markedly. This shows that, overall, the QE technique could expand the queries with informative terms. Next, as ex-pected, we find that after applying QE, our proposed frame-work with the cross-collection validation setting, LTHN (x-collections)+QE , further improves the retrieval performance. Indeed, our negation handling framework outperforms all of the baselines for all of the reported measures. For TREC 2011, the proposed framework, LTHN (x-collections)+QE , performs significantly (paired t-test, p &lt; 0 : 05) better than the traditional approach where the negation is not explic-itly handled ( traditional approach+QE ), in terms of bpref (0.5786 versus 0.5567), while the performance, in terms of precision at 10, improves from 0.6527 to 0.6647. For the TREC 2012 topic set, LTHN (x-collections)+QE significantly ( p &lt; 0 : 05) outperforms the traditional approach+QE base-line, for all the reported retrieval measures. In particu-lar, the proposed negation handling framework, LTHN (x-collections)+QE , outperforms the traditional baseline ( tra-ditional approach+QE ) by 6.3%, 8.8%, and 14%, in terms of infNDCG, infAP, and P10, respectively. This confirms that the third component of our LTHN framework, namely the penalising weight estimation component, can effectively penalise non-relevant medical records, when several infor-mative terms are used in a query. In addition, we find that with the cross-collection validation setting, our pro-posed LTHN (x-collections)+QE could perform comparably to the best possible setting (i.e. when w ( t  X  ) = O ( t  X  )), LTHN (oracle)+QE . This shows that our learning framework is ro-bust and could be generalised between the training and test topic sets.
Next, in order to examine the importance of each pro-posed feature, we conduct an ablation study. Indeed, using the same experimental setup as discussed in Section 6.2, we remove each of the features from the feature space to exam-ine the impact of each feature on the retrieval performance. For example, when we evaluate the importance of Feature 1, we remove Feature 1 from the feature space, while keep-ing the other 12 features. The increase or reduction in the achieved retrieval effectiveness is an indicator of the impor-tance of the feature. Specifically, the retrieval performance decreases when removing an effective feature, while the per-formance remains the same or increases when removing a non-effective feature. We compare the importance of each feature based on its impact on the retrieval performance, in terms of bpref and infNDCG for TREC 2011 and 2012, respectively. These two measures are selected as representa-tives because they are the measures that we use to train the model to estimate the effective penalising term weights (i.e. the weight that could bring about the highest retrieval per-formance for a particular term), as discussed in Section 5.3. The percentage improvement or reduction, in terms of each retrieval measure, between when a particular feature is re-moved and when all the features are considered, are summed up to measure the overall impact of that feature. Then, we normalise this measure for each feature by dividing it with that of the most important feature (i.e. the feature with the most negative impact on retrieval effectiveness), in order to easily rank the importance of different features. We refer to the normalised measure as feature importance . Hence, the feature whose removal degrades effectiveness most has the highest feature importance . If the feature importance of a particular feature is zero, the feature has no impact on the retrieval performance, while a negative feature importance indicates that the feature is not useful and can be removed from the feature set.

Figure 1 compares the feature importance of each feature in our feature space. We observe that Features 11, 8 and 7, Figure 1: Ablation study of feature importance a cross both TREC 2011 and 2012 which are the co-occurrence between the opposite context term t  X  and the query Q , an IDF variant of the opposite context term t  X  , and an IDF variant of the query term t corresponding to the opposite context term t  X  , respectively, are the most important features. This is intuitive as the co-occurrence of the opposite context term t  X  and the terms in the query Q could be used to measure the relatedness between the opposite context term and the query, while the IDF variant of the opposite context term t  X  and its corre-sponding query term t could measure the informativeness of both associated terms. In contrast, Features 10, 12 and 13, namely the two variants of the co-occurrence frequency be-tween the opposite context term t  X  and its corresponding query term t , and the query length, respectively, are the least importance features. Indeed, adding these features to the feature set has a negative impact on retrieval effective-ness. Overall, we find that 9 out of our proposed 13 features are beneficial to obtaining an effective estimation of the pe-nalising weights for the opposite context terms.
It has previously been shown that an effective retrieval performance of a medical records search system can be ob-tained by combing the relevance scores of a term-based and conceptual-based representations [21, 23, 31]. Hence, we ex-amine whether our proposed framework can further improve retrieval performance when combined with a conceptual-based representation, hence resulting in an improved re-trieval performance. The conceptual representation approach represents medical records and queries in terms of concepts, instead of terms [21, 22, 31]. For example,  X  cerebrovascu-lar accident X  ,  X  X troke X  , and  X  X VA X  are represented with the same concept, as they share a particular conceptual mean-ing. This could help to reduce the mismatch between terms in a medical records and a query. In this work, we follow Limsopatham et al. [21, 23] and deploy MetaMap [3]  X  a medical concept recognition tool  X  to identify concepts in medical records and queries, and represent them in the form of the UMLS Concept Unique Identifier (CUI) 3 . In addition, we also apply the Bo1 QE model to expand the conceptual query with the top 10 informative concepts from the top 3 ranked medical records, retrieved from the TREC Medical Records track X  X  collection.

To combine the representations, we linearly combine the relevance scores of a medical record d towards a query Q , calculated using both our framework ( score LT HN ) and the conceptual representation approach ( score conceptual ), as fol-lows [31]: where  X  is a parameter to emphasise the relevance score com-puted using our LTHN framework, which represents medical records and queries based on terms. We set  X  to 2 : 00, as sug-gested in [21, 31].

Table 8 reports the retrieval performances on the TREC 2011 and 2012 Medical Records track of the representation combination approach (i.e. representation combination ), which combines the relevance scores of the aforementioned con-ceptual representation approach, and our LTHN framework after applying the query expansion strategy, discussed in Section 6.2 (namely, LTHN (x-collections)+QE ). In partic-ular, we compare the retrieval performance of the represen-tation combination with the effectiveness of using only ei-ther the conceptual representation or our negation handling framework. Moreover, the retrieval performances of the best TREC 2011 and TREC 2012 Medical Records track systems are also reported.

From Table 8, we firstly observe that our proposed frame-work ( LTHN (x-collections)+QE ) outperforms the concep-tual representation alone (namely, conceptual representa-tion ) for all reported retrieval measures. For example, in terms of precision at 10, our framework significantly (paired t-test, p &lt; 0 : 01) outperforms the conceptual representation approach by up to 25.6%. Next, we find that the repre-sentation combination approach, which combines the rel-evance scores computed using our LTHN framework and the conceptual representation approach, could further boost the retrieval performance. Indeed, the achieved retrieval
W e leave as future work the integration of our negation handling approach within conceptual representation. performances are significantly better than both the concep-tual representation and our proposed framework ( LTHN (x-collections)+QE ) for almost all the retrieval measures, ex-cept for the precision at 10 on the TREC 2011 topic set. Specifically, in terms of bpref, the representation combina-tion outperforms the conceptual representation baseline by 10% (paired t-test, p &lt; 0 : 05), and LTHN (x-collections)+QE by 0.4%. For TREC 2012, the representation combination achieves an infNDCG of 0.5299, which is significantly bet-ter than the conceptual representation baseline ( p &lt; 0 : 01) and LTHN (x-collections)+QE ( p &lt; 0 : 05) by up to 17% and 7.9%, respectively. In terms of infAP, the represen-tation combination approach performs 15.7% significantly ( p &lt; 0 : 05) better than the conceptual representation , and 14% higher than LTHN (x-collections)+QE . In addition, the precision at 10 on TREC 2012 of the representation combi-nation is significantly better than both the conceptual rep-resentation and LTHN (x-collections)+QE by up to 15.9% and 6.7%, respectively. These improved results support the conclusion that using the representation combination ap-proach [31], our supervised learning framework to handle negation combines effectively with the conceptual represen-tation approach. Indeed, the attained retrieval effective-ness is comparable to those of the best TREC 2011 and TREC 2012 systems, without resorting to other common approaches for medical records search (e.g. leveraging the se-mantic relationships of medical terms to infer the relevance of medical records).
We have motivated the need for a medical records search system to handle negated language, which is commonly used in the medical domain. We introduced our proposed frame-work to handle negation by distinguishing between the con-texts of terms before their processing, and demoting medical records containing the query terms with the opposite context of the query X  X  intent. Specifically, our framework prevents non-relevant medical records from being ranked highly, by demoting those containing occurrences of opposite context terms (i.e. a term having the opposite context to its cor-responding query term). We deploy a supervised learning approach to effectively estimate the penalising weight for the opposite context query terms. In particular, we use the Gradient Boosted Regression Trees (GBRT) to learn the pe-nalising weight of an opposite context term, using features such as term and document frequencies.

We evaluate our proposed framework using the standard test collection from the TREC 2011 and 2012 Medical Records track. Our experimental results show that the proposed framework significantly outperforms several strong baselines. Moreover, our proposed learning framework is effective, as the retrieval performance achieved using a fair setting (i.e . cross-collection validation) is comparable to that of the best possible setting (i.e. the oracle setting, when w ( t  X  ) = O ( t  X  )). In addition, our proposed negation handling framework works effectively with an existing QE approach and could effec-tively combine with a conceptual representation, using an existing representation combination approach. Specifically, the achieved retrieval performance is comparable to the state-of-the-art results among participants in the TREC 2011 and TREC 2012 Medical Records track, while these top-performing systems also deploy approaches to handle other challenges in the medical records search, such as using the semantic relationship of terms to reformulate the query.

For future work, we aim to integrate our proposed nega-tion handling framework within a reasoning model that in-fers the relevance of a medical record based on the presence or absence of medical conditions associated with the query.
