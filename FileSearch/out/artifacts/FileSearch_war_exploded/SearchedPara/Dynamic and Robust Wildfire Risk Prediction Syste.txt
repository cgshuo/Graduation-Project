 Ability to predict the risk of damaging events (e.g. wildfires) is crucial in helping emergency services in their decision-making processes, to mitigate and reduce the impact of such events. Today, wildfire rating systems have been in opera-tion extensively in many countries around the world to es-timate the danger of wildfires. In this paper we propose a data-driven approach to predict wildfire risk using weather data. We show how we address the inherent challenge arising due to the temporal dynamicity of weather data. Weather observations naturally change in time, with finer-scale vari-ation (e.g. stationary day or night) or large variations (non-stationary day or night), and this determines a temporal variation of the predicted wildfire danger.

We show how our dynamic wildfire danger prediction model addresses the aforementioned challenge using context-based anomaly detection techniques. We call our predictive model a Context-Based Fire Risk (CBFR) model. The advantage of our model is that it maintains multiple historical mod-els for different temporal variations (e.g. day versus night), and uses ensemble learning techniques to predict wildfire risk with high accuracy. In addition, it is completely un-supervised and does not rely on expert knowledge, which makes it flexible and easily applied to any region of interest. Our CBFR model is also scalable and can potentially be parallelised to speed up computation. We have considered multiple wildfire locations in the Blue Mountains, Australia as a case study, and compared the results of our system with the existing well-established Australian wildfire rating system. The experimental results show that our predictive model has a substantially higher accuracy in predicting wild-fire risk, which makes it an effective model to supplement the operational Australian wildfire rating system.
  X  Information systems  X  Data streaming; Data ana-lytics; Data stream mining;  X  Computing methodologies  X  Anomaly detection; Wildfires, Bushfires, Risk Prediction, Data Stream Mining, Unsupervised Learning, Context-Based Anomaly Detection Natural disasters are a prevalent reality around the world. Roughly 102 million people worldwide were affected by natu-ral disasters in 2014 alone [8], with a global annual economic loss estimated at over $300B [10]. Researchers link natu-ral disasters with climate change and statistics show that in 2014, 87% of worldwide natural disasters were climate-related [8]. Some countries, including Australia, experience wildfires, locally known as bushfires, as the most damaging disasters. In the Australian state of Victoria, wildfires pose the largest annual risk to the safety of residents [6]. For example, in the recent  X  X lack Saturday X  Victorian wildfire event of February 2009, over 1.1 million acres burnt, 173 people lost their lives and over 400 people were injured [5]. Another notable impactful event was  X  X sh Wednesday X  in February 1983, with 75 fatalities and over 1 million acres burnt in the states of Victoria and South Australia. The impact of these disasters is multi-dimensional, from social and psychological to economic and environmental.

The reality described above makes a strong case for wild-fire research, not only in Australia but also around the world. One of the most pressing problems in this context is the abil-ity to predict the risk of a wildfire event. By knowing the risk, government agencies, communities and individuals can be better informed so they can take the most appropriate measures to mitigate and prepare for of wildfire events, if and when they eventuate (e.g. evacuate people, predeploy firefighting assets etc.).

The McArthur Forest Fire Danger Index (FFDI) [17] is used in Australia by the national Bureau of Meteorology to draw Fire Danger Index maps [2], which in turn are used by state wildfire authorities to determine Fire Danger Ratings (FDR) by taking into account not only the contribution of weather but also other relevant information such as fuel load. The daily FDR are then publicly available and broadcasted to all interested stakeholders.

Along with FFDI, other approaches to predict wildfire danger also exist around the world (summarised later in Section 2, Related Works). However their main drawback, which we address in this paper, is that they generally calcu-lated by feeding the current weather observations into an ex-isting static model, therefore not catering for spatial or tem-poral variations between observations (e.g. between weather stations due to elevation, or between summer and autumn days). With existing approaches, the danger index on any given day or at any given point in space is calculated using the same models, with static parameters that do not change to reflect the actual context of the danger index calcula-tion. This determines a coarse variation between the danger indices of consecutive days and is not indicative of the tem-poral development of the wildfire danger, which is actually the case for most wildfire events.

As an exemplar, consider two weeks of weather observa-tions where the current operational mathematical model or other learned/regression models in the literature is used to compute the risk values. Additionally, suppose that in the middle of this period an actual wildfire is happening. Fig-ure 1 depicts an example of risk values computed using the FFDI model for this example time period. In this graph the vertical axis represents the risk values, horizontal axis shows the time in minutes, and the horizontal line in the middle bottom of the graph represents the actual wildfire period. Now suppose there is bad weather conditions one night be-fore the actual wildfire in comparison to other normal nights. The rectangle in this figure shows the described night. Al-though the night weather information can be used to infer a high risk period in the next few hours, the FFDI model fails to use such information until the actual wildfire is happen-ing. The risk values at night time in this figure (values in the rectangle) are low. Using online learning models which use the whole history of observations cannot be beneficial either, for such models do not differentiate  X  X ight time X  from  X  X ay time X . This differentiation is extremely significant, as the decision makers and firefighters need to be able to pre-dict the high risk days beforehand, to enable them to plan strategically in advance.

Since wildfire danger is mainly dependent on the weather and fuel load, and their variability can be observed both spatially and temporally [24, 22], we claim that wildfire risk models should not be static and generic, but dynamic and representative of the spatial and temporal context. That is, we propose a wildfire danger model that considers finer-scale variations in day or night weather observations (stationary observations) or larger variations during day or night (non-stationary observations) and readjusts itself (i.e. its param-eters) to the context. In this paper, we consider both the temporal variability and spatial variability of weather obser-vations.

Based on the above, we summarise the novel contributions of this paper as follows: Risk Value Figure 1: Wildfire risk values over 20 days of weather observations using FFDI This work follows from the project with Fire &amp; Rescue NSW, the largest emergency management agency in Aus-tralia and one of the largest in the world, where we looked at the spatiotemporal dynamics of wildfire danger. One chal-lenge we found was the inability of the current wildfire dan-ger models (e.g. FFDI) to incorporate the spatiotemporal context in the modelling, and that issue is addressed in this proposal.
There is a vast body of work modelling the risk of wild-fires (a.k.a. bushfires) with diverse focus. Some investigate the likelihood of wildfires (that is, probability of ignition or probability of burning), while others study the intensity or effects of wildfires (based on ecological, social or economic values) [18]. This section reviews a few methods currently used for wildfire danger assessment and that are most rele-vant to the topic of current paper, that is real time assess-ment of changes in wildfire danger due to weather changes. We then present the McArthur Forest Fire Danger Index (FFDI), which is currently widely used by authorities in Australia and is the starting point for our proposal. Lastly, we highlight why a context based real time assessment of wildfire danger is required to supplement FFDI, and show the real world applicability of the proposed method.
Most of the wildfire danger prediction methods use mete-orological observations sourced from weather stations (e.g. temperature, wind speed, wind gust, wind direction rela-tive humidity, precipitations) together with other variables such as topography, vegetation type and vegetation density to predict the wildfire danger/risk for the given conditions based on empirical methods. For example:
In [12], the authors show that there is a correlation be-tween wildfire occurrence and the effect of fuel moisture and thus the rating of wildfire danger. Where wildfire occur-rence is given by the frequency of wildfires recorded in a historical period of time, with data often summarised for different time periods, often by daily, weekly, or monthly in-tervals to help depict variation in wildfire activity through out the season. To counter the issue of spatially limited data (e.g. received from sparse weather stations), a num-ber of studies look at wildfire danger detection using sensor networks. For example, [26] propose a wireless sensor net-work where sensor nodes are used to collect the data (e.g. temperature, relative humidity) and submit the information to specific cluster nodes. The cluster nodes will then con-struct neural networks to produce a weather index showing the likelihood for the weather to cause a wildfire. The paper does not describe the actual model hence the spatiotemporal customisation of the model cannot be assessed. In [16], it is claimed that wildfire risk needs to consider both wildfire be-haviour probability and effect. The former depends on the spatial and temporal factors controlling wildfire spread, in-cluding fuel and weather. Moreover, the authors investigate the burn probability based on historic wildfire data, and highlight the need to move beyond assumptions of spatial and temporal uniformity while modelling that probability. Their approach is in line with [15] that argues that localised spatial properties (topography, fuel, weather) produce local differences in the wildfire behaviour, hence local differences in wildfire risk. This is also in line with our argument to-wards a customisable model that can cater for local spatial and temporal differences in wildfire danger due to weather.
A scientist from the Commonwealth Scientific and Indus-trial Research Organisation (CSIRO) developed the McArthur Forest Fire Danger index in the 1960s to measure wildfire danger in Australian forests. The index is currently used by the authorities in Australia to calculate and broadcast wildfire danger ratings during summer. It is based on tem-perature, humidity, wind speed, dryness and fuel weight as shown in Equations 1 and 2 [21]: Figure 2: Wildfire Danger Categories in Australia (Figure reproduced from [4]) where H  X  is relative humidity, T  X  is air temperature, V is average wind velocity in the open at the height of 10 m, FFDI  X  is forest fire danger index and DF  X  is drought factor which uses precipitation observations Pre  X  , N  X  is time since rain and I  X  is soil X  X  moisture content all at time  X  .
The output FFDI values are further interpreted based on a defined categorisation. Figure 2 depicts the six different categories. Using the above equations and these categories, the Australian emergency management agencies find the rel-evant category and broadcast it daily.

As mentioned in the introduction, the main drawback of operational wildfire rating systems including FFDI is that the danger index is calculated based on the most current weather observations available, using a static model, and not customised to the particular location where the danger index is used. This determines a coarse variation between the danger indices of consecutive days and is not indicative of the temporal development of the wildfire danger condi-tions, which can be observed prior to wildfire events. To the best of our knowledge there are no current wildfire dan-ger prediction frameworks that consider context-based spa-tiotemporal variations to fine-tune the models X  parameters. Our results, from an Australian case study, show that our proposal does not contradict but rather augment FFDI, giv-ing the decision makers more fine-grained information about the increasing wildfire danger and allowing them to take even better informed decision to protect communities and the environment.
In this section we first formally define the problem, then explain the steps of our context-based fire risk prediction solution (CBFR) in detail.
We consider the problem of wildfire risk prediction in dy-namically changing environments based on meteorological observations. Specifically, let H be the relative humidity in %, T be the air temperature of the region in o C, V be the average wind velocity in the open at the height of 10 m in km hr  X  1 and DF be the drought factor which uses precip-itation observations Pre . DF is an indicator of amount of the soil moisture and covering layer of duff moisture in the region of interest R .

Assume that a set of streams of meteorological observa-tions P R 1: X  is collected over time period [1 ..  X ] for a region R . Hence, at time  X  a vector P R  X  = ( H  X  ,T  X  ,V  X  ,Pre served at region R . Our aim is to compute the wildfire risk of observation CBFR P R in a given region R . Note that to make the assumptions Input: Meteorological data observations P 1: X  Context size W Decaying parameter  X  Output: Context-based fire risk CBFR 0 1: X 
C (1)  X  X  X  Cluster ( P 1: W ); // set of clusters C t  X  X  X  1; while t &lt; b  X  end return CBFR 0 1: X  ;
Algorithm 1: Context-Based Fire Risk (CBFR) Algo-rithm more realistic, we consider that the meteorological observa-tions are dynamically changing both temporally and spa-tially. In other words, first the stream of observations are changing during time, i.e. time changing behaviour can oc-cur in finer-scale variation (e.g., daytime versus nigh-time), or even variations during daytime. Second, the stream of observations can change spatially in different regions.
To develop a predictive risk model, one of the big chal-lenges is lack of label information for building supervised predictive models. In fact, we noticed that in case of wild-fire risk, it is really not reasonable to identify which periods of time are risky and which of them are not. One might ar-gue that using wildfire histories can be beneficial. However, we can still have high wildfire risk periods of time where there is no wildfire due to the lack of ignition in the area.
To deal with this challenge an unsupervised algorithm is needed for wildfire risk prediction, where high risk periods are identified without any statistics or expert knowledge. Since wildfire onset is a rare event in comparison to the entire history in time, we believe an anomaly detection al-gorithm can be a very good candidate solution, where the high risk days can be seen as anomalies and detected in an unsupervised manner. Moreover, to capture the temporal dynamicity of input data streams, our solution would bene-fit from a stream mining technique. Figure 3 depicts overall schema of the proposed risk model including the analyti-cal components. Algorithm 1 shows the pseudocode of our CBFR model. In the following, we discuss different compo-nents of our model in detail.
We developed our system based on weather data. Data sources can be any weather company which measures the variables mentioned in problem definition section. In the case study of this paper, weather data was provided by Fire &amp; Rescue NSW from the Bureau of Meteorology (BoM) in Australia [1]. Although we evaluate our model using weather data, our model is not restricted to weather observations and we can incorporate other types of data e.g. vegetation type, fuel load and topographical data into the model to achieve more accurate results.

Reanalysis for high resolution: In addition to the above data sources we conduct a high resolution meteoro-logical reanalysis, running local atmospheric models to re-solve smaller phenomena and provide more detailed data than would otherwise be possible from observations. The simulation was conducted with the Weather and Research Forecasting model (WRF-ARW) [14]. The model outputs in-clude temperature, precipitation, pressure, relative humidity and wind speed.
As mentioned earlier, the temporal dynamics in input data streams is not considered by current operational wildfire risk systems. To deal with this challenge, we propose exploit-ing an online anomaly detection algorithm. In addition, we need to deal with the non-stationarity of temporal weather observations in the input data as well. Hence, the proposed online algorithm in this paper should be able to adapt to the non-stationarity behaviour of data.

This can be solved by modelling different contexts in the underlying behaviour of input data stream separately and maintain multiple models over time.

Definition 1. Context is a specific period of time in which weather observations remain roughly stationary.
 Thus in this step, we identify the defined context based on available resolution of input data. For instance, we may con-sider day context versus night context in weather observa-tions. If we have finer granularity input data, we can further decompose the temporal context into morning, noon, after-noon, evening and etc. The number of weather observations in a context is denoted by parameter W .
After identifying the required context and parameter W , we need an anomaly detection algorithm that captures the temporal dynamicity in weather data streams to detect the anomalous patterns (high risk) periods. Our solution is to use an ensemble based anomaly detection algorithm which is proposed for dynamically changing data streams [23]. Fig-ure 3 shows the schematic of this unsupervised learning al-gorithm in the bottom left of the figure. By dividing data streams into different data chunks based on their contexts, we are able to build anomaly detectors for each context (day and night in Figure 3) separately. Each of these anomaly de-tectors is a risk predictor. In the current temporal context (last  X  X ight X  in the bottom of Figure 3), all relevant histori-cal predictors are considered and a decision on the risk value of current observations are made by participating only the relevant models. We further discuss the subcomponents of this algorithm:
In order to avoid the false positive rates of our anomaly detection solution in very rare cold days, we suggest using the current operational FFDI system as a filter to our model. This can be simply done by computing the FFDI values for incoming weather observations. If these values fall in one of the top five categories (i.e. high, very high, severe, extreme or catastrophic) according to Figure 2, we keep the wildfire risk values ( CBFR 0 P  X  ) intact. Otherwise, we set the values to zero.
In this step of the algorithm, while we have the risk values for the current window observations, we smooth the output in order to find a pattern. By smoothing, we can better identify the temporal sequence of risk values. We use  X  X o-cally weighted X  linear regression smoothing method in this component and a stream of risk values is produced as out-put.
The computational complexity of analytical components in CBFR is near linear with respect to the number of weather observations. This matches the real-time requirement of our risk prediction problem. Also CBFR is scalable and we can further speedup the algorithm by parallelising the compu-tation of  X  X elevancy identification X  and  X  X ncorporation of his-torical data profiles X  steps of the algorithm.
In this section, we compare our proposed model with the operational McArthur FFDI method described in Section 2.
The dataset we used in this case study is the meteorolog-ical data provided by Fire &amp; Rescue NSW from the Blue Mountains region. The reason why we chose this area for study is that a severe wildfires occurred in this area in 2013 from October 17 until October 21. These days are con-sidered as anomalies and the proportion of anomalies and normal observations in this dataset is 7%. The dataset con-sists of temperature, relative humidity, wind speed and pre-cipitation measurements from three different BoM weather stations located in this area (Mt Victoria, Richmond Raaf and Penrith Lake). Figure 4 shows the mentioned locations in Blue Mountains of these weather stations. The meteo-rological measurements are taken every 1 minute and there are 300K observations in total from all stations.

Moreover, we created a higher spatial resolution dataset using our reanalysis model. The model consisted of 3 do-mains nested at 3:1 grid size ratio, the inner domain had a grid spacing of 5 km and covers an area of 275 km  X  275 km centered on the town of Blackheath (-34.80, 138.90) in the Blue Mountains region.

The reanalysis simulated 96 hours from the start of Octo-ber 13, 2013 UTC to the end of October 17, 2013 UTC. The model was initialised and forced with boundary conditions provided by ERA-Interim reanalysis, this analysis is a global atmospheric reanalysis produced by the European Center for Medium-Range Weather Forecasts (ECMWF), it uses a 30 minutes time step and has a spectral T255 horizontal reso-lution which is about a 79km and a vertical resolution of 60 layers [14]. The simulation output is provided at frequency of 1 minute.
In order to compare our model with the operational FFDI, we have used different performance measures: (1) Since our proposed model X  X  output is a fuzzy value between 0 and 1, we used the Area Under ROC curve (AUC) to find the accu-racy of our model. The output value of FFDI on the other hand, is a value between 0 to 100+. To compare our model with FFDI, we consider the trend of both FFDI and CBFR values. (2) The second performance measure is accuracy (
Pos + Neg ), where TPos is the number of true positives (the number of episodes that the high risk of wildfire is pre-dicted correctly), TNeg is the number of true negatives (the number of episodes that the low risk of wildfire is predicted correctly), Pos is the number of total episodes where risk of wildfire is high and Neg is the number of total episodes where risk of wildfire is not high. (3) The third performance measure is sensitivity ( TPos Pos ), which is the ratio of predicting the high risk of wildfire correctly. And finally, (4) Youden In-dex, which is an optimal point on AUC. This is the farthest point from diagonal line and is computed as following [25]: where sensitivity is computed from above, and specificity is
We apply our proposed CBFR approach on the Blue Moun-tains dataset. In other words, all of the analytical compo-nents and subcomponents of our CBFR model (including, decaying factor, FFDI filter and linear regression smoothing) are applied on the Blue Mountains dataset and the final risk values are calculated for each episode of time in this dataset (every minute). Hence the effectiveness and predictability measures which will be shown in this section, indicate how well the combination of all of these components perform.
According to granularity of the observations (measure-ments are taken every 1 minute), we decided to set the window size equal to the number of observations which are measured over daytime and nighttime. A total number of 720 observations are measured during each day/night. The reason in selecting such window size is that we want to dis-tinguish between the clustering models of nighttime and day-time. So if the weather is bad in the nighttime context, our model outputs high values which predicts a high wildfire risk in the next day. Whereas in the current FFDI model, the in-dex is computed based on the weather data and independent of the temporal occurrence of historical observations.
While in this case study, we have used nighttime and day-time length as a window size, there might be some impor-tant and valuable variations in the daytime as well. Hence, if given higher frequency observations (e.g. every 30 or 10 seconds), multiple models can also be considered for a day that represent different variations in various times. The pa-rameter  X  in decaying function is set to 2 and we delete the historical data profiles with very low decaying function values to constraint memory and time complexity.

Note that in order to evaluate our model we need to have the ground truth. However, in this specific application, it is very difficult to find the ground truth. One alternative that is used in the literature of disaster management is to label the onset of disasters as high risk episodes. While the episodes of disasters (wildfire in this paper) represent high risk episodes, there might be some other days that have high risk of onset of wildfire, but because no ignition occurs, no wildfire starts. In these situations it is difficult to evalu-ate whether the proposed model is able to find them as high risk episodes or not. In order to find a more accurate ground truth to evaluate our model with, we decided to further in-vestigate the area of interest.

Figure 4 shows the wildfire onset in different days based on the information provided in the governmental website [3]. On October 16, a wildfire was accidentally sparked in Mar-rangaroo (top-left of the figure) which continued to travel to the northern regions of Blue Mountains national park. The next day, two major wildfires were reported in the south east (Mount Victoria) and south west (Springwood). These areas are depicted with flames and labeled as  X 17th Oct X  in Figure 4. The sparked wildfires were reported to continue burning until October 21.

Given the wildfire history of the region, we consider two different scenarios for the evaluation purposes: In both above scenarios, the episodes are labeled based on the presence of wildfire, weather temperature, relative hu-midity and wind speed. Considering these two scenarios, we want to see how our proposed model is performing in comparison to FFDI model.

For the evaluation purposes, first we applied both our model and FFDI to all observations and compared the out-put risk of both models. The aim here is to find which model can reflect the high wildfire risk days more accurately. Con-sidering the Scenario I, Figure 5a-c depict the AUC results for three different stations in our area of interest. Each point on the ROC Curve is relevant to sensitivity and 1-specificity of both models considering a certain threshold. The three solid graphs in Figure 5a-c show the results of our model and the three dashed graphs show the results of FFDI method. It is shown that in all three stations, the detection accuracy of wildfire risk by our CBFR model is substantially higher than using the current operational FFDI.
Considering Scenario II, the aim is to evaluate the pre-dictability of our CBFR model. Figure 6a-c depict the AUC results for three different weather stations in the area of in-terest. The three solid graphs in Figure 6a-c correspond to the results of our model and the dashed graphs show the results of FFDI method. While the AUC of detecting risk of wildfire by our model is higher than using the current operational FFDI, we noticed that the AUC of our model is either roughly the same as previous scenario for Mt Victoria, or increased by 7% and 8% in Richmond Raaf (Figure 6b) and Penrith Lake (Figure 6c) receptively. Nevertheless, for the FFDI model, the AUC in Mount Victoria increased by 7% but in Richmond Raaf and Penrith Lake, the AUC has even decreased by 2% (Figure 6b) and 1% (Figure 6c) re-spectively.

Lastly, by comparing the results of both scenarios (Fig-ure 5 and Figure 6) it is clear that the AUC of FFDI drops in Scenario II, which shows that it fails to predict the wildfire risk patterns in advance. The AUC of CBFR on the other hand increases and hence it is more effective in predicting the wildfire risk.
In this section we show how incorporating the FFDI cate-gorisation could help in predicting the wildfire risk. As men-tioned earlier, Figure 2 depicts the categorisation and inter-pretation of different values of the FFDI model. Currently the last two categories, namely extreme (FFDI values be-tween 75 and 99) and catastrophic (FFDI values above 100) are introduced as very hot, dry and windy conditions for a wildfire in Australia and hence the periods with such charac-teristics are declared as total fire ban periods. This interpre-tation however can vary in different states of Australia and sometimes the fourth category i.e., severe is also considered as a very bad wildfire condition. Hence, to set a threshold and further evaluate the FFDI X  X  output, we consider both severe (above 50) and extreme (above 75) as thresholds and further compute the measures introduced in Section 4.2.
In addition we compute the optimal point of ROC curves for both CBFR and FFDI to see how the performance mea-sures change by setting a fixed threshold. Figure 7a-c show the results of setting thresholds for both methods in all three different regions for Scenario I. Similarly, Figure 8a-c depicts the same graphs for scenario II. Our method X  X  optimal point has a very high accuracy and sensitivity in both scenarios and in all regions. FFDI on the other hand, has lower ac-curacy in all scenarios and regions. Moreover, it has a very low sensitivity, which suggests that it is not able to pre-dict the high risk periods of time. The results comply with the design of the FFDI model. As mentioned in Section 2, this model originally designed for a specific episode in a day without considering spatiotemporal variations.

While all the above results correspond to the dataset pro-vided from Bureau of Meteorology (BoM) in Australia, Fig-ure 9 shows the visualisation of the risk results by CBFR model for the dataset reproduced by high resolution mete-orological reanalysis described in Section 3.2.1. As an ex-ample, we depict the results at a specific time (12:00:00pm on 16th October 2013), which is related to 12 hours before the actual wildfire in the Blue Mountains. Three arrows in this figure point to the three weather stations depicted in Figure 4. Note that here while building the model, only temporal context is considered.

This visualisation helps in identifying the whole central, northern and western areas on the figure as being at high risk, with a greater level of detail, while FFDI failed to iden-tity all of these areas at risk and only flagged some increased risk in the areas that were already on fire at the time, north of Blue Mountains.
In this paper we discussed the problem of wildfire risk prediction using meteorological observations. The first and most significant challenge in this problem is lack of data labels. This is difficult both in terms of designing effective analytical models on one hand, and evaluating the models on Figure 9: Fire risk values of CBFR model at 12:00:00pm on 16th October 2013-Blue Mountains National Park is located in the center the other hand. Even using the past wildfire histories can-not be completely sufficient as there might be some periods of time without a wildfire history but with high wildfire risk. In this paper we propose using an unsupervised learning al-gorithm (anomaly detection) as a candidate solution to this problem. Our solution does not rely on label information or expert knowledge.

The next challenge is temporal and contextual changes in meteorological observations. The existing operational mod-els or the state-of-the-art methods in wildfire risk literature either focus on the current weather observations and use a mathematical model to estimate the wildfire risk or use the whole historical observations to model risk. However, due to the temporal changes in the context of weather observa-tions, in this paper we proposed to maintain multiple model of historical observations for different contexts. As a result, our context-based fire risk (CBFR) model can predict a high risk day just in advance with 85-90% accuracy and 99% sensitivity in average. Figure 10 shows an example of a sit-uation where our CBFR model estimates high risk values before the actual wildfire period, whereas the operational wildfire danger rating system in Australia postpones it to the actual wildfire day.

One lesson learned from this work was that old models that are used in various contexts and industries can bene-fit from applying modern analytics techniques (in this case a context-based anomaly detection algorithm) to augment the type of knowledge they can produce and positively impact the final outcome for the benefit of the user (in this case community as a final user of the danger risk prediction tech-niques). Potential clients of our proposed CBFR model are decision makers in emergency management agencies. Using the CBFR model can significantly help them predict high risk days beforehand and enable them to plan strategically in advance. Wildfire risk values can be also produced in variety of spatial resolutions, which gives decision makers a better understanding of wildfire risk at a high spatial as well as temporal resolution in real-time.

While the proposed CBFR model has a linear time com-plexity and considers the memory constraints in meteoro-logical stations, we intend to develop the parallelised ver-sion of this model using Spark to further speedup the algo-Risk Value Figure 10: Fire risk values over 20 days of weather observations: FFDI versus CBFR models rithm. Moreover, spatially specific features (such as vege-tation type, fuel load and elevation) can be included as an input to the CBFR algorithm to produce more sophisticated and accurate wildfire risk values in the property levels. We also intend to test our CBFR model on other areas and apply contemporary anomaly detection approaches in comparison to our proposed model. [1] Australian bureau of meteorology weather stations. [2] Australian bureau of meteorology weather stations. [3] Australian emergency management knowledge hub. [4] Australian fire danger ratings. [5] Black saturday bushfires. [6] Emergency management victoria strategic action plan. [7] Google maps. https://www.google.com.au/maps. [8] The human cost of natural disasters 2015: a global [9] Natural resources canada. [10] The united nations office for disaster risk reduction, [11] Wildland fire assessment system. fire danger rating. [12] P. L. Andrews, D. O. Loftsgaarden, and L. S.
 [13] E. Cohen and M. Strauss. Maintaining time-decaying [14] D. Dee, S. Uppala, A. Simmons, P. Berrisford, P. Poli, [15] C. A. Farris, C. Pezeshki, and L. F. Neuenschwander. [16] M. A. Finney. The challenge of quantitative risk [17] A. G. McArthur. Fire behaviour in eucalypt forests. [18] C. Miller and A. A. Ager. A review of recent advances [19] M. Moshtaghi, T. C. Havens, J. C. Bezdek, L. Park, [20] M. Moshtaghi, S. Rajasegarar, C. Leckie, and [21] I. Noble, A. Gill, and G. Bary. Mcarthur X  X  fire-danger [22] B. Saglam, E. Bilgili, B. Dincdurmaz, A. I.
 [23] M. Salehi, C. A. Leckie, M. Moshtaghi, and [24] C. Vasilakos, K. Kalabokidis, J. Hatzopoulos, and [25] B. Vidakovic. Statistics for bioengineering sciences: [26] L. Yu, N. Wang, and X. Meng. Real-time forest fire
