 Business Intelligence has emerged as a key driver for growth among business organi-zations. The term business intelligence was first coined in an article in 1958 by IBM Researcher Hans Peter Luhn. He described a system comprising of data-processing machines for auto-abstraction of documents and creating interest profiles for each of BI include concepts and methods to improve business decision making by using fact-based support systems. 
Since then, numerous products and services have been rolled out by various modeling products. Let us review the existing products that are currently available in enterprise resource planning tools (ERP) from companies like SAP, Oracle etc. These function and have certain well defined analytical models that help in making business decisions. The second classes of products are commercial-off-the-shelf (COTS) data warehousing / reporting tools. These tools can be connected to an enterprise system to models. Analysts and other decision makers can then query and analyze the informa-tion to do a trend analysis, find key bottlenecks to growth or predict future demands. products is implementation of operations research methodologies viz: statistical analysis, mathematical optimization, simulation etc. These tools can be used to build mathematical models and then feed the organizational information to get specific insights e.g.: statistical models can be built to predict the demand for certain key sea-sonal products or an optimization model to efficiently map the rout for delivery tucks. system. Domain specific systems only provide a small subset of BI capabilities. Their main objective is to provide efficiencies in the operational systems. The off-the-shelf data warehousing tools provide the basic extract, transform &amp; load (ETL) functional-capabilities. The products based on operations research are stand-alone tools and it is time and effort. 
Hence there remains a need for an agile fr amework and tool that can overcome the Research set out to design a framework and build first-of-a-kind application using the framework that showcases a truly integrated system having deep analytics embedded and interfaces, in this paper, we will focus on presenting our solution which can effi-ciently enable a COTS data warehousing/reporting system with prescriptive and predictive capabilities offered by the operatio ns research methodologies. We use IBM Cognos v8 to build a reporting dashboard capability. Also, IBM ILOG OPL Studio is used to build an optimization model. These two are integrated together using analyti-cal application integration framework (AAIF). This framework integrates predictive and optimization capabilities to an otherwise descriptive information platform. To showcase an end-to-end capability we use the Multi-Period workforce evolution model. This model enables decision makers to understand the composition of the business needs. 
In our implementation, although we have used these two tools and AAIF to dem-customized analytical engine to any comme rcial product or a custom application. get the combined power to understand past, as well as suggestions of future optimized actions, all from one integrated environment. focusing on effectively reporting on large and usually high dimensional data. To serve this purpose, the usual assumption is that the data is static, and only changes periodi-often the case with optimization and what-if type of analysis. In order to accomplish this task, two levels of challenges need to be addressed: first from application middle tier and second from the back end tier. Fr om application middle tier we need to pro-vide mechanism to allow the system to take end user inputs and effectively invoke the backend predictive or prescriptive models; on the backend tier, we need to provide an integration between the optimization model and high dimensional BI data objects designed as a star schema type of data model. 
To address the first level of challenge, various BI systems are implementing exten-sions to allow plug-ins into external computational processes. This implementation needs significant development effort. Further, most of the mathematical modeling this problem by building a framework that can be applied to a host of modeling tools and is efficient to implement. The premise of our framework is based on the observa-tion that all the existing BI reporting systems have data access via SQL through data-discuss our approach in detail which is a novel method for enabling an external com-putational processes being exposed as dynamic data sources through standard data-base interfaces, such as ODBC or JDBC. These computational processes can then be consumed by existing BI reporting systems using standard SQL queries. The frame-work we developed for this purpose is called Analytic Application Integration Framework (AAIF) which enables an efficient plug of an ILOG optimization solver to optimization results back to data mart. 
The second level of challenge which arises from the back end data integration tier is the sheer number of optimization scenarios that can be created when the user drills very fine grained data existing in BI data warehouse makes the predictive and optimi-zation models X  computation time exorbitantly expensive. To address this issue, we have defined a meta-structure for the optimization model data. We have also designed an efficient binding/mapping schema between the optimization vector space and BI Star Schema X  X  high dimensional data space. This enables an optimization model to be run on multiple scenarios regardless of the scenario being selected by the user. illustrate how optimization is used in business context. This workforce planning use mathematics and computer science, optimization or mathematical programming refers LP formula, which optimizes a linear objective function subject to linear equal-ity/inequality constraints. practical use. For example, we are considering a workforce management business problem, the HR analyst wants to know the optimal staffing level for US by different with variables including headcounts denoted as X(N,T), hiring H(N,T) and mandatory attritions F(N,T) where T is a vector including all the periods in the planning horizon, and salary costs. Constrains of this LP problem come from two parts, one is external demands, we would like the headcounts be small or equal than the demands. The other set of constrains defined by the workforce its own internal structure and dynam-ics. We have been using Markov network to model the workforce transitions between different workforce types, e.g. junior employee evolves to be experienced with certain refer to [2]. and ease of understanding. However the integration approach, data mapping method established in this paper can be extended to other optimization problems besides LP. 
Following is a chart illustrates the information flow of the solution. As mentioned earlier ILOG has be used to provide optimization capability and Cognos is providing optimization module an ODBC wrapper and transparent to the BI reporting environ-ment just like one of the normal data sources. AAIF helps to relieve developer from optimization environment he/she is familiar with (green blocks in the chart). tion path. The framework allows for integration of analytical models spanning a vast array of languages viz: C/C++, Java, Matlab, SAS, SPSS, PHP, Pearl etc. The power-analytical model execution can be in-process or out-of-process; Engine boundaries: request can be marshaled to engines line MATLAB, R, SPSS, SAS etc.; Protocol that the AAIF architecture is independent of the business problem and can be used to integrate any two component application. We now discuss the framework in detail. 3.1 Integrating External Processes Using AAIF between applications that manipulate data sources and those that provide data analy-independent. Of particular interest are tools like COGNOS, which provides a rich data access, data organization, and reporting interface. One sub-component of the AAIF is the BAMS ODBC Driver, is registered as a data source just as any other ODBC proxy for another real data source through a real ODBC driver. The second dimension is that it provides a proxy for a virtual data source through a driver extension. The real data source is defined through registration of another ODBC driver and its configura-tion. The BAMS ODBC Driver is responsible for loading the real driver and redirect-ing calls from the client application through the real driver. 
The extension driver is provided by the end user and is the mechanism for adding language such as Java, Perl, or PHP. 
As the BAMS ODBC Driver processes requests, the user extension may post process the results of the real driver. Some of the implications of this capability are that the driver may 3.2 BAMS ODBC Driver The ODBC Driver is a key component of the AAIF framework. It is, for the most part implemented by code generated from an xml encoding of the ODBC specification. An XSD is used for auto generation of the ODBC interface. The current code generation process uses an XML document and XSLT processing to generate driver code. 
The default generation has two dimensions along which the core ODBC driver That is, is provides a mechanism for deployment time registering and runtime ena-bling an ODBC driver to a real database. As an example, the ODBC driver provided by db2cli.dll on the Windows platform may be registered to provide access to a DB2 database. The second dimension provides a mechanism for passing ODBC requests in an extension library. The functionality of the extension library is not specified and is extension capability to provide extensions to the platform that cross:  X  language boundaries, for example to Java, PHP, or Perl  X  process boundaries so that analytical model execution may either be in-process or  X  engine boundaries so that requests may be marshaled to engines like MATLAB,  X  protocol boundaries so that requests may be marshaled across Web services or  X  provide control points to implement non-functional requirements such as per-3.3 Request / Response Interaction ODBC interface. The pattern used is one in which an initialization method is used to set up the interface. The default implementa tion of the initialization method is to set invocation and to do nothing on all subsequent invocations. The next call to ODBCThunkerEnter is used for performance monitoring and request tracking. The ODBCThunkerCallback call is used to invoke the corresponding extension function with additional arguments providing the current state of method call, a pointer to the methods on the real driver, and an argument indicating the current position, either on entry or exit, of the current invocation. If no SQLError is flagged, the real driver method is invoked. Once again, the ODBCThunkerCallback call is used to give th e extension driver a chance to postproc-formance, logging or other generic tasks. SQLRETURN SQL_API SQLPrepare( SQLHSTMT StatementHandle, SQLCHAR * StatementText, SQLINTEGER TextLength ) { SQLRETURN ret; ODBCThunkerInit(); ODBCThunkerEnter("SQLPrepare"); if((ret=ODBCThunkerCallback(SQL_SUCCESS,&amp;ODBCThunker,"SQL Prepare","enter", StatementHandle, StatementText, TextLength))==SQL_SUCCESS){ ret=ODBCThunker.SQLPrepare( StatementHandle, StatementText, TextLength); The optimization model formulation of the workforce management problem is to The data that is used in the problem formulation is tabular and is available in Cognos BI data mart. The user interface we provide is a simple COGNOS report which allows periods, and expected change in demand and service level. When the report is run, the optimal revenue and assignment of resources are computed and displayed including the charts reflecting some of the business metrics based on the settings of these deci-sion variables 
To support the integration of the analytical models into the COGNOS platform we need to provide a mechanism for communicating the parameters and data of a workforce optimization formulation to the implementation of the linear programming problem and to capture the results of the optimization. 
COGNOS uses an object model to construct potentially complex SQL queries for components. The BAMS ODBC Driver uses this property of the COGNOS interac-addition to using the BAMS ODBC Driver to provide a semantic filter for generated The optimization algorithm is written in Java. 
Although there are alternatives for implementing this scenario, we will use a con-query filter is two fold. First, since the objective is to tie analytical model execution to the most granular level of COGNOS user interface component, using query filters enables us to bind a COGNOS reports with the backend analytical models. Second, using query filters enables AAIF use non-invasive approach to integrate the backend analytical models. Hence a detail filter is added to the query subject in the data table clause of the select statement. select "MIDS_BAMS_RESULTS"."VALUE" "VALUE" , "MIDS_BAMS_RESULTS1"."INTERNET" "INTERNET" , "MIDS_BAMS_RESULTS"."OOH" "OOH" , "MIDS_BAMS_RESULTS"."DG" "DG" from "BAMS"."RESULTS" "MIDS_BAMS_RESULTS" where bamsFunction ('Internet', '0.75..2.0', '1.00..1.00', 'OOH', '1.00..1.00', '1.00..1.00', 'DG', '0.75..2.0', '1.00..1.00', "MIDS_BAMS_RESULTS"."VALUE") = 0 modifying the bamsFunction part of the where clause predicate resulting in select "MIDS_BAMS_RESULTS"."VALUE" "VALUE" , "MIDS_BAMS_RESULTS1"."INTERNET" "INTERNET" , "MIDS_BAMS_RESULTS"."OOH" "OOH" , "MIDS_BAMS_RESULTS"."DG" "DG" from "BAMS"."RESULTS" "MIDS_BAMS_RESULTS" where 0 = 0 optimization are stored in the table referen ced by the select statement the real ODBC driver is invoked using the modified SQL to return the correct results. 
In order to accomplish this, the developer can use the Java driver extension that is provided. This extension reflects all the native ODBC calls through to Java. When the Java ODBC driver is used, it is registered with the core BAMS ODBC driver through a driver registration xml document. &lt;?xml version="1.0" encoding="UTF-8"?&gt; &lt;root mlns="http://com.ibm.bams/odbcdriver/config/" xmlns:tns=http://com.ibm.bams/odbcdriver/config/ xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation= "http://com.ibm.bams/odbcdriver/config / config.xsd "&gt; &lt;library name="odbcextensionjava.dll"&gt; &lt;/library&gt; &lt;driver name="db2cli.dll"/&gt; &lt;/root&gt; This document is used to identify both the real ODBC driver, in this case provided by db2cli.dll, as well as the extension driver and properties that it requires. The extension driver is the odbcextensionjava.dll which is a generic Java extension. It is specialized to a particular purpose by specifying a class name that implements that specific pur-pose. The named class is responsible for extending a base class and overriding those ODBC methods required to accomplish its goals. 
In the example above, only a few Java methods in the ODBC class need to be overwritten to bind the optimization method into the COGNOS platform. In this paper, we describe a framework called AAIF which allow predictive and pre-rently working on enhancing it with tooling to allow the advanced integration project be created, managed and deployed more conveniently. 
