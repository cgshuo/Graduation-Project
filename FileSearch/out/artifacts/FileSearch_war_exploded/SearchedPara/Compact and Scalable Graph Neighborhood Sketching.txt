 The all-distances sketch (ADS) has recently emerged as a promising paradigm of graph neighborhood sketching. An ADS is a probabilistic data structure that is defined for each vertex of a graph. ADSs facilitate accurate estima-tion of many useful indicators for network analysis with the guarantee of accuracy, and the ADSs for all the vertices in a graph can be computed in near-linear time. Because of these useful properties, ADS has attracted considerable at-tention. However, a critical drawback of ADS is its space requirement, which tends to be much larger than that of the graph itself. In the present study, we address this issue by designing a new graph sketching scheme, namely, sketch retrieval shortcuts (SRS) . Although SRSs are more space-efficient than ADSs by an order of magnitude, an ADS of any vertex can be quickly retrieved from the SRSs. The re-trieved ADSs can be used to estimate the aforementioned indicators in exactly the same manner as with plain ADSs, inheriting the same accuracy guarantee. Our experiments on real-world networks demonstrate the usefulness of SRSs as a practical back-end of large-scale graph data mining. Graphs; Min-hash sketches; All-distances sketches
Many types of indicators and measures play key roles as building blocks for graph analysis and mining. Vertex cen-tralities constitute one of the the most fundamental classes of indicators. They are defined for a vertex to measure the relative importance of every other vertex [9 , 8, 12]. Other common classes include vertex similarities , which are de-fined for a pair of vertices to estimate their similarity or strength of relevance [23 , 13 ]. Graph properties, which are defined for a whole graph, have also attracted considerable  X  Y. Yano X  X  current affiliation: Recruit Holdings Co., Ltd. attention for understanding the underlying mechanisms and developing realistic models [21 , 4, 6].

Computing these measures in an ad-hoc manner is almost always unrealistic for large-scale graphs. Let us take vertex centralities as an example. Most types of centralities require time at least proportional to the graph size. Moreover, cen-tralities are usually employed to compare vertices in a graph; thus, centrality values are necessary for a subset of vertices, or sometimes, even for all vertices.

Therefore, algorithmic frameworks called sketching or in-dexing are employed to compute these indicators and prop-compute a data structure called a sketch or an index from a graph, which can substantially accelerate the computation of these useful indicators. This not only results in better scal-ability of graph analysis but also makes it possible to use such indicators in applications that require quick interactive response, such as drill-down analytics and network-aware search systems [ 27 , 24 ].

The all-distances sketch (ADS) [11,12 ] has recently emerged as a paradigm of graph neighborhood sampling. An ADS is defined for a vertex, and is an extension of the min-hash sketch [18 , 11] (see Section 3.1 for the definition). The ADSs for all the vertices in a graph can be computed efficiently, and once they are obtained, the values of the many useful in-dicators can be efficiently and accurately estimated. To the best of our knowledge, ADS is the only sketching paradigm that combines the following three properties.  X  Multi-Functionality : Using ADSs, we can estimate  X  Guaranteed Accuracy : Estimation using ADSs is quite  X  Scalability (in theory): The ADSs for all the vertices in
Because of these useful properties, ADS has attracted con-siderable attraction. However, in practice, ADS has turned out to be not as scalable as expected theoretically. The main drawback is its space requirement. An ADS is an ar-ray of length approximately k ln n , where n is the number of vertices and k is an accuracy-space trade-off parameter. In order to achieve accurate estimation, k is set to a value of the order of tens or hundreds. Thus, the length of an ADS is of the order of hundreds or thousands. Therefore, ADSs require more space than the graph itself, which is un-reasonable for large graphs. Moreover, because there are few repetitions in an ADS, standard compression methods, such as the LZ family, do not work well, as discussed in Sec-tion 8.2 . Thus, substantial space reduction techniques are required to make ADS practical.
To address the above-mentioned issue, we propose a new graph sketching data structure, namely, sketch retrieval short-cuts (SRS) . Instead of ADSs, we propose that SRSs be com-puted for the all vertices in a graph. Then, using the SRSs, an ADS of a vertex can be quickly retrieved. SRSs can be computed with acceptable additional computation cost in comparison to ADSs. Although SRSs are an order of mag-nitude smaller than ADSs, once we obtain them, an ADS of a vertex can be quickly retrieved from the SRSs; thus, the various aforementioned measures and indicators can be esti-mated in exactly the same manner as with ADSs, inheriting the same accuracy guarantee.

The idea underlying the definition of SRSs is to consider the ADSs of a graph as another weighted graph, and spar-sify it such that an ADS of a vertex can still be quickly retrieved by a restricted search on it. The retrieval algo-rithm is designed such that it visits only vertices in an ADS; thus, an ADS is efficiently retrieved in time that is almost linear to the ADS size. SRSs are carefully defined to ensure that an ADS of any vertex can be correctly retrieved using this procedure.

We propose two types of construction algorithms: the first constructs SRSs from ADSs, whereas the second constructs SRSs directly from graphs. The former is faster, whereas the latter requires less working memory and provides a flexible trade-off between time and space consumption.

Our experiments on real-world networks demonstrate the usefulness of SRSs as a practical back-end of large-scale graph data mining. Specifically, we can confirm that (1) SRSs can be constructed for very large graphs with millions of vertices and hundreds of millions of edges, (2) SRSs are an order of magnitude smaller than ADSs, and (3) ADS re-trieval is sufficiently quick, i.e., the retrieval time is of the order of milliseconds.
 Organization. The remainder of this paper is organized as follows. Section 2 provides the relevant definitions and no-tations. Section 3 reviews the definition and usage of ADSs. Section 4 presents the definition and crucial properties of our SRSs. Sections 5 and 6 propose efficient SRS construc-tion algorithms with different performance characteristics. Section 7 proposes techniques to further improve the practi-cality of SRSs. Section 8 presents our experimental results. Section 9 concludes the paper. Table 1 lists the frequently used notations in the paper. Let G = ( V,E ) be a graph where V and E are a vertex set and an edge set, respectively. We denote | V | and | E | by n and m , respectively. For generality, we assume that G is a weighted and directed graph. We denote the length of an edge e by ` ( e ). Further, we assume that ` ( e ) &gt; 0 for any e  X  E . Our discussions can be applied to unweighted graphs by introducing a constant length function, e.g., ` ( e ) = 1 for any e  X  E . Let d ( u,v ) denote the distance from u to v . Let P ( u,v ) denote the vertices on the shortest paths from u to v , i.e., P ( u,v ) = { w  X  V | d ( u,w ) + d ( w,v ) = d ( u,v ) } .
We always compare tuples by lexicographic order. For example, ( a,b ) &lt; ( c,d ) if and only if (1) a &lt; c or (2) a = c and b &lt; d . We also use this lexicographic comparison in sorting and priority queues, unless otherwise stated.
The strict definition of ADSs assumes that distances are unique [ 12]. In theory, an arbitrary tie-breaking rule can be employed. However, when closely looking at algorithms and implementation, the selection of the tie-breaking rule is highly important for simplicity and performance.

In this paper, we propose that the following tie-breaking rule be used. We conduct lexicographic comparison using the pair of (1) the original distance and (2) the destination vertex ID. In other words, v is closer to u than w if and only if ( d ( u,v ) ,v ) &lt; ( d ( u,w ) ,w ). For the definition of ADSs, we do not need to break all the ties among any pairs of vertices; instead, we just need to break the ties among the distances from a single vertex to other vertices. Therefore, this simple tie-breaking rule works, and we find that this rule can be effectively accommodated in our algorithms.

In this paper, this tie-breaking rule is explicit: the defi-nition of  X  X istance X  d ( u,v ) remains unchanged, and we ex-plicitly conduct this tie-breaking as part of our algorithm. On the other hand, our algorithms and data structures are essentially compatible with any other tie-breaking rule. In this section, we review the all-distances sketch (ADS). We first explain the definition and basic properties, and then introduce the examples of the useful indicators that can be accurately estimated by ADSs.
All-distances sketches (ADSs) are defined with respect to an integer parameter k and a random rank assignment to vertices. The parameter k gives the trade-off between sketch size and estimation precision. Throughout this paper, we use a random function r : V  X  [0 , 1] as the rank function, where r ( v )  X  U [0 , 1] for any vertex v . In other words, r ( v ) is independently drawn from the uniform distribution on [0 , 1].
For u,v  X  V , we define N ( u,v ) as the set of vertices that are closer to u than v , i.e., N ( u,v ) = { w  X  V | ( d ( u,w ) ,w ) &lt; ( d ( u,v ) ,v ) } . For a vertex subset X  X  V , we define the func-tion k th r ( X ) as the k -th smallest value of ranks for vertices in X . If | X | &lt; k , we define k th r ( X ) = 1. For vertices u and v , we define threshold rank  X  ( u,v ) as  X  ( u,v ) = k th which denotes the k -th smallest value of ranks for vertices that are closer to u than v . Using  X  ( u,v ), ADSs are defined as follows 1 .
 Definition 3.1 (ADS [ 12]) : The all-distances sketch (ADS)  X  ( u,v ) } , where  X  uv = d ( u,v ) .

In this paper, we use the singular form, i.e.,  X  X n ADS, X  to indicate the sketch of a single vertex (i.e., A ( v ) for a vertex v ), and the plural form, i.e.,  X  X DSs, X  sometimes indicates the whole set of sketches for all the vertices in a graph (i.e., {A ( v ) } v  X  V ). For directed graphs, we distinguish between the forward ADS the forward ADS the above definition), and, for the backward ADS use the distances to u . Note that, on an undirected graph, the forward and backward ADSs are exactly the same. The size of an ADS can be calculated as follows.
 Lemma 3.2 (ADS Size [ 12 ]) : For a vertex u , let n the number of reachable vertices from u , and H ( i ) be the i -th harmonic number. The expected size of A ( u ) is k (1 + H ( n u )  X  H ( k )) .
 As n u  X  n and H ( n ) = O (log n ), the expected size of A ( u ) is O ( k log n ). Therefore, the expected total storage usage of the ADSs for all vertices is O ( nk log n ).
There are two efficient approaches for computing ADSs from a graph. The first is the pruned-search approach [11 ], which conducts a pruned version of shortest-path searches from all vertices in ascending order of their ranks. The other approach is the scan-and-merge approach [25, 6], which re-peats iterations until convergence. In each iteration, the ADS of each vertex is grown by scanning all outgoing edges and merging the ADSs of the neighbors into it.
Once we obtain ADSs, many types of graph properties and features can be efficiently estimated with the guarantee of accuracy, as follows.
 Neighborhood Function [ 11, 16, 12]. The neighborhood function n  X  ( v ) is the number of vertices that can be reached from v within distance  X  . The value of n  X  ( v ) can be es-timated from ADS A ( v ), and its coefficient of variation is bounded by 1 / p 2( k  X  1).
 Shortest-Path Distance [ 13, 26]. For u,v  X  V , dis-tance d ( u,v ) can be estimated by ADSs A ( u ) and A ( v ). It is O (log n )-approximation for constant k , and (2 a  X  1)-approximation when k = n 1 /a (for some a  X  1).
 Closeness Centrality [12 ]. Closeness centrality is one of the most fundamental measures of vertex importance. it is
The definition of an ADS has some variations, though, in this paper, we focus on the bottom-k ADS [12]. Cohen proved that they have similar estimation ability, but, among them, the bottom-k ADSs are slightly better [ 12 ]. defined for a vertex u , distance decay function  X  , and ver-Using ADS A ( u ), the estimation of C  X , X  ( u ) can be obtained with coefficient of variation bounded by 1 / p 2( k  X  1). Closeness Similarity [13 ]. Closeness similarity is a prox-imity measure that is used to estimate the strength of rel-evance of a pair of vertices. It is based on the similarity of their distances to all other nodes. For two vertices u,v  X  V , the closeness similarity between u and v can be estimated using ADSs A ( u ) and A ( v ), and the root of its expected square error is guaranteed as O (1 / Average Distance and Effective Diameter [ 6]. Aver-age distance and effective diameter are fundamental proper-ties of a graph, and of considerable interest because of their relation to so-called small world phenomenon . They can be accurately estimated with confidence intervals.
 Reverse Raking and Nearest Neighbors [ 10]. Reverse ranking measures the relevance of vertex u to vertex v by the number of vertices that are closer to v than u . Based on the neighborhood function estimation, approximated reverse nearest neighbors (rNNs) of arbitrary size can be efficiently obtained.
 Continuous-Time Influence [17 ,15, 14]. The continuous-time influence model is an influence propagation model with the time decay property. The expected influence of vertex set S can be estimated using a combined ADS A ( S ), which can be computed from ADSs A ( v ) for all v  X  S . Its coeffi-cient of variation is bounded by 1 / p 2( k  X  1). ADSs can also facilitate efficient influence maximization for such a model.
In this section, we present our new graph sketching scheme, namely, sketch retrieval shortcuts (SRS) . First, we explain the underlying idea. Then, we mathematically define SRSs. Finally, we present the retrieval algorithm that quickly in-stantiates an ADS from SRSs.
Before explaining the idea underlying SRSs, we discuss the difficulty in ad-hoc ADS retrieval, i.e., we cannot obtain an ADS quickly from a graph without any preprocessing. Fig-ure 1a shows a graph. Each vertex is drawn as a box, where its ID and rank are denoted in the upper and lower parts, respectively. In, Figure 1b the vertices in the ADS A (1) are highlighted ( k = 2). We observe that in this example, vertex 6 is isolated from the other vertices in A (1), in the sense that we cannot reach vertex 6 from vertex 1 without passing vertices that are not in the ADS. This suggests that without any preprocessing, we cannot avoid a full search on the graph to collect all the vertices that are contained in an ADS. A full search requires time at least linear to the graph size, and is thus too time-consuming for large-scale network analysis. On the other hand, full precomputation of ADSs for all vertices requires too much storage. Therefore, we aim to achieve a good trade-off such that an ADS can be quickly retrieved with less precomputed data.

The general idea underlying SRSs is to overcome the need for a full search on a graph and realize the retrieval of an ADS by a smaller search on another graph. Toward this end, we consider a search that starts from a specified vertex u and is allowed to visit only vertices in the ADS A ( u ). As Figure 1: Examples of a graph and an ADS ( k = 2). the number of vertices in an ADS is O ( k log n ) and usually k log n is much smaller than n , we expect that this search is much more efficient than a full search.

To realize such searches for ADS retrieval, we first take a different view of ADSs. We consider the ADSs of the graph as another weighted graph, where each entry ( v, X  uv )  X  X  ( u ) corresponds to an edge from u to v with weight  X  uv (Fig-ure 2a ). In this  X  X raph X , obviously, the vertices in an ADS A ( u ) are directly connected from vertex u ; thus, the above-mentioned search from u can successfully visit all these ver-tices (with only 1 hop).

Intuitively, for this purpose, this ADS graph has a consid-erable number of redundant edges, and herein lies the con-cept of our SRSs. In general, SRSs are yet another weighted graph whose edges are selected from the ADS graph such that the above-mentioned search can always succeed from any vertex (Figure 2b ). In other words, SRSs are defined such that, when considering a subgraph induced by the ver-tex set of A ( u ), the subgraph is connected, and the distances from u to all these vertices remain unchanged (Figure 3). We call this the reachability property .

This might seem like an intuitive and simple idea. How-ever, to guarantee the above property, the definitions and algorithms need to be designed carefully. Indeed, there is a common misunderstanding about the definition of SRSs, which is explained with a counterexample in Appendix A. Now, we mathematically define SRSs. As with ADSs, SRSs are defined for a graph G = ( V,E ), a trade-off param-eter k , and a random rank function r : V  X  [0 , 1].
Let  X  be the set of distances between any pair of ver-tices, i.e.  X  = { d ( u,v ) | u,v  X  V } . We assume that  X  = { d 0 ,d 1 ,...,d h } , where d 0 &lt; d 1 &lt;  X  X  X  &lt; d h d 0 = 0 and d h corresponds to the diameter of the graph. We define B i ( i = 0 , 1 ,...,h ) and C i , D i ( i = 1 , 2 ,...,h ) recursively as follows.  X  B 0 ( u ) =  X  and B i ( u ) = B i  X  1 ( u )  X  X  i ( u ) for i &gt; 0 .  X  C i ( u,v ) = { w  X  P ( u,v ) | w  X  X  ( u ) ,v  X  X  i  X  1 ( w ) } .  X  D i ( u ) = { ( v, X  uv )  X  X  ( u ) |  X  uv = d i , C i ( u,v ) =  X  X  .
Intuitively, C i ( u,v ) corresponds to possible transit vertices from u to v for the reachability property, and B i ( u ) contains ADS entries with distance at most d i that have no such transit vertices. The SRSs are defined as follows. Definition 4.1 (SRS) : The sketch retrieval shortcuts (SRS) of vertex u is B h ( u ) . Hereafter, for simplicity, we simply denote B h ( u ) by B ( u ). Similarly to ADSs, we use the singular form to indicate the sketch of a single vertex, and the plural form to indicate the whole set of sketches for all vertices in a graph. For directed graphs, as with ADSs, we distinguish between the forward SRS SRS, we use the forward ADS backward SRS is similarly defined on backward ADSs.
The following lemma mathematically states the property discussed in Section 4.1 .
 Lemma 4.2: If v  X  X  ( u ) , there exists a sequence of vertices W ( u,v ) = ( w 1 ,w 2 ,...,w p ) such that, (1) w 1 = u , w (2) w i  X  A ( u ) for all 1  X  i  X  p , (3) w i +1  X  B ( w 1  X  i  X  p  X  1 , and (4) P p  X  1 i =1 d ( w i ,w i +1 ) = d ( u,v ) . Proof. We prove the lemma by mathematical induction on the distance d ( u,v ). Since W ( u,u ) = ( u ) satisfies the above conditions, it is true for distance zero. Now, we assume that it holds for pairs within distance d i  X  1 and prove it also holds for pairs with distance d i . Let u,v be a pair of vertices such that v  X  X  ( u ) and d ( u,v ) = d i . If v  X  X  ( u ), then W ( u,v ) = ( u,v ) satisfies the conditions. Otherwise, v 6 X  D i thus, C i ( u,v ) 6 =  X  . Let w  X  C i ( u,v ). Then, W ( u,v ) can be obtained by appending v to W ( u,w ). By definition, B ( u ) is a subset of A ( u ) for any vertex u . Therefore, the upper bound of the expected size is as below. Lemma 4.3: The expected size of B ( u ) is O ( k log n ) .
In total, the theoretical upper bound of the expected space usage of the all SRSs is O ( nk log n ). This bound is tight, as it is  X ( k log n ) on some pathological cases such as a clique. In practice, SRSs are much smaller than ADSs, as seen in our experiments. The main feature of SRSs is to enable quick retrieval of an ADS of any vertex. By obtaining an ADS, the various graph properties can be estimated in exactly the same manner as with a plain ADS as mentioned in Section 3.2 . The retrieval algorithm Retrieve-ADS is explained as Algorithm 1. Note that, unless otherwise stated, sorting and priority queues on tuples use the ascending order in lexicographic comparison.
To retrieve the ADS of vertex u , in general, the retrieval algorithm conducts a pruned version of Dijkstra X  X  algorithm Algorithm 1: Retrieving the ADS of vertex u from u on the SRSs such that it only visits vertices in A ( u ) (Figure 3). We start with an empty sketch A , and entries are added in increasing order of distances to build A . For each visited vertex v with distance  X  uv , we check whether ( v, X  uv ) is necessary for A , i.e., whether ( v, X  vu ) should be included in A ( u ) (Line 5). As A contains all the entries in A ( v ) with smaller distances at this point,  X  ( u,v ) can be computed from A . We can use a priority queue that manages the top-k ranks in A to obtain  X  ( u,v ) quickly. If v is unnecessary for A , we prune the search and do nothing. Otherwise, we add v to A and expand the search by entries in B ( v ). Note that the lexicographic comparison in the priority queue substantiates the distance tie-breaking rule discussed in Section 2.2 . Lemmas 4.4 and 4.5 state the correctness and complexities of the algorithm.
 Lemma 4.4: Retrieve-ADS returns A ( u ) .
 Proof Sketch. This is almost immediate from Lemma 4.2 . From the lemma, any vertex in A ( u ) can be reached with correct distance on SRSs through other vertices in A ( u ). Lemma 4.5: Retrieve-ADS runs in O ( k 2 log 2 n log( k log n )) expected time and O ( k 2 log 2 n ) expected space. Proof Sketch. Line 8 is executed for |B ( v ) | time for each ver-tex v  X  A ( u ), and the expected size of B ( u ) and A ( v ) is O ( k log n ). The priority queue takes O (log( k log n )) time to push an element.

We stress that the retrieval time only has a logarithmic dependence on the graph size. Therefore, ADSs can be effi-ciently retrieved even on very large graphs.
Then, we study construction algorithms for SRSs. In this section, we design algorithms that construct SRSs from Algorithm 2: Constructing SRSs from ADSs (naive).
 ADSs. First, we explain the basic algorithm with our retrieve-and-verify principle, which is common to all of our construc-tion algorithms. Second, we speed up the algorithm by in-troducing eager entry generation .
We know that SRSs are recursively defined, and the in-clusion of pairs with longer distances depends on pairs with shorter distances. Therefore, in general, we need to con-struct SRSs in ascending order of distances. Algorithm 2 outlines algorithm Construct-SRS-Naive , our first construc-tion algorithm. It examines the entries of all the ADSs in ascending order of distances. We check each ADS entry to determine whether it is necessary for the SRSs, and if so, we add it.

The tricky part of this algorithm is that, even for con-struction, we use the retrieval algorithm Retrieve-ADS . At Line 5, algorithm Retrieve-ADS retrieves an  X  X DS X  A from the current incomplete SRSs B . As the current SRSs are in-complete, A does not always match the correct ADS A ( u ). However, interestingly, we can use A to check whether entry ( v, X  uv ) is necessary for the SRS of u as follows. Lemma 5.1: At Line 5 in Algorithm 2, assuming B [ w ] con-tains SRS entries with distances less than  X  uv for any w  X  V , ( v, X  uv ) 6 X  A if and only if ( v, X  uv )  X  X  ( u ) . Proof Sketch. Let  X  uv = d i . If ( v, X  uv )  X  A , then C  X  , and thus ( v, X  uv ) 6 X  B ( u ). Otherwise, from Lemma 4.2 , ( v, X  uv ) must be in B ( u ).

As a corollary of this lemma, we obtain the correctness of the algorithm with mathematical induction on the distance. Corollary 5.2: Construct-SRS-Naive returns {B ( u ) } u  X  V
The time and space complexities of this algorithm can be bounded as follows.
 Lemma 5.3: Construct-SRS-Naive runs in O ( nk 3 log 3 n log( k log n )) expected time and O ( nk log n ) expected space. Proof Sketch. The ADSs contain O ( nk log n ) entries, and Retrieve-ADS is called for each entry.
Algorithm 3 describes another SRS construction algorithm called Construct-SRS-Fast that shares the general idea, but is faster than the previous algorithm. In the previous algo-rithm, repeated call of Retrieve-ADS was the bottleneck. The high-level difference from the previous algorithm is that, in-stead of calling Retrieve-ADS , we eagerly generate what can be retrieved from the current incomplete SRSs, immediately after adding an entry to a SRS. Algorithm 3: Constructing SRSs from ADSs (fast).

The eager generation corresponds to Lines 6 X 7. As the inclusion of entry ( v, X  uv ) in SRS B ( u ) has been determined, we generate the ADS entries that can be retrieved through that SRS entry. Compared to the previous algorithm, the time complexity is improved as follows.
 Lemma 5.4: Construct-SRS-Fast runs in O ( nk log n log( nk log n ) + |B| k log n ) expected time and O ( nk log n ) expected space, where |B| is the total size of whole SRSs.
 Proof Sketch. We first sort the whole O ( nk log n ) ADS en-tries, and then, for each SRS entry, we traverse O ( k log n ) ADS entries. Finally, we present a direct construction algorithm for SRSs. Previous algorithms explicitly instantiate ADSs in memory once, the required working space for which may be too large. The following direct algorithm achieves a trades-off between the time consumption and the space efficiency by building SRSs and virtually constructing ADSs simulta-neously. We start by explaining the basic form, and then make the trade-off more flexible by introducing the partial ADS caching technique .
For simplicity, we first assume that G is an unweighted graph. Our direct algorithm Construct-SRS-Direct is de-scribed as Algorithm 4. At a high level, this algorithm combines the retrieve-and-verify principal of the previous indirect SRS construction algorithms with scan-and-merge ADS construction algorithms.

We generally repeat iterations until convergence, where each iteration merges ADSs of neighbors into the SRS of each vertex. Specifically, in the i -th iteration, the SRSs are grown so that the retrieved ADS of any vertex is correct with regard to entries with distances less than or equal to i . In i -th iteration, for each vertex u , we first retrieve the incomplete  X  X DSs X  of its neighbors by Retrieve-ADS , and extract the entries with distance i  X  1 as possible entries for u with distance i (Lines 5 X 9). Then, we again use Retrieve-ADS to retrieve an incomplete  X  X DS X  A of vertex u to judge whether (1) the entry is an actual ADS entry (Line 13 ), and (2) the entry is necessary as an SRS entry (Line 14).
The correctness and complexities of the algorithm are as follows. This space consumption is almost just for the graph and SRSs themselves and essentially minimal.
 Lemma 6.1: Construct-SRS-Direct returns {B ( u ) } u  X  V . Proof Sketch. By mathematical induction on the distance  X  , we can prove that B always matches the SRSs for entries Algorithm 4: Constructing SRSs directly.
 with distances at most  X  . From the initial condition, it holds for  X  = 0. Assuming it holds for distances less than  X  , re-trieved ADSs are also correct for entries with distances less than  X  ; thus, all ADS entries with distance  X  are obtained from them. Then, similarly to Lemma 5.1 , we can prove that B is also updated for distance  X  .
 Lemma 6.2: Construct-SRS-Direct runs in O ( D ( n + m ) k log 2 n log( k log n )) expected time and O ( n + m + |B| + k log n ) expected space, where D is the diameter of G .
 Proof Sketch. The number of iterations is at most D . In each iteration, Retrieve-ADS is called for each edge. With regard to space consumption, we just need additional space for an ADS and extracted possible entries.
To improve the running time of the above algorithm, we here introduce a caching technique that can flexibly adjust the trade-off between space and time consumption. The most time-consuming part is retrieving the current ADS of each neighbor (Line 7 in Algorithm 4). We cache these re-trieval results to reuse them.

We propose to use the following strategy, which is sim-ple but sufficiently effective in practice. Let us first assume that we receive a parameter  X  (0  X   X   X  1). Before each iteration, we retrieve and cache the current ADSs for the top- X n vertices with the highest degrees. As each cached ADS takes O ( k log n ) expected space, the expected space consumption increases to O ( n + m + |B| +  X nk log n ). On the other hand, as the ADSs of the ends of at least  X m edges are cached, the expected running time improves to O ( D ( n + (1  X   X  ) m ) k 2 log 2 n log( k log n ) +  X mk log n ). The latter term is the total time consumption for reading cached entries, as the total number of entries that pass through each edge in total corresponds to the size of an ADS.

The space consumption can be further improved as fol-lows. During the i -th iteration, the entries of our interest in cached ADSs are only those with distance i  X  1, and thus other entries are unnecessary to store in the cache. Therefore, interestingly, even with the full cache setting (i.e.,  X  = 1), this algorithm may work with less space than the size of a full ADS.

In practice, if necessary, we can adjust the space consump-tion more precisely as below. Given the cache size limit, we retrieve and cache ADSs of vertices in the decreasing order of their degrees, until the total cache size exceeds the limit. as Construct-SRS-Fast perfectly work with weighted graphs, the direct approach has some difficulty with them. If weight values are small integers, the above direct algorithm still works fine. Otherwise, one way is to consider a little re-laxed version of ADSs called the (1 + ) -ADSs [12], which is designed to be efficiently built with scan-and-merge-based algorithms.
To further reduce the storage requirement of SRSs, we propose the implicit neighborhood technique . The idea un-derlying this technique is that, when we use SRSs for ana-lyzing a graph, the original graph itself is often also available for access. Therefore, under such circumstances, we do not need to store what we can immediately obtain from the orig-inal graph, i.e., the neighbors in the original graph.
The implicit neighborhood technique redefines the SRS of vertex u as
B 0 ( u ) = { ( v, X  uv )  X  X  ( u ) | ( u,v ) 6 X  E or ` ( u,v ) &gt;  X  That is, we basically remove v in B ( u ) if ( u,v ) is in E . However, if  X  uv &lt; ` ( u,v ), then it cannot be removed, since otherwise the correct distance from u to v cannot be ob-tained. We modify the retrieval algorithm Retrieve-ADS as follow. When we expand the search from v (Line 7 in Algorithm 1), in addition to entries in B 0 ( v ), we also use ( w,` ( v,w )) for all ( v,w )  X  E . The time complexity be-comes O ((deg max + k log n ) k log n log( k log n )), where deg is the maximum degree in the original graph. To construct {B 0 ( u ) } entries that correspond to original edges.

As seen in Section 8, this technique reduces the storage requirement of SRSs drastically. On the other hand, the retrieval time does not degrade significantly.
The construction algorithms described above can be easily parallelized to exploit the thread-level parallelism of modern computer systems. As confirmed in our experiments, their performance well scales with the number of threads.
Specifically, in Construct-SRS-Fast , different tuples in the list can be processed in parallel. To guarantee the same result, we need to restrict the tuples processed in parallel to those with the same distance. Similarly, in Construct-SRS-Direct , different vertices can be processed in parallel. Environment. All the experiments were conducted on a Linux server with two Intel Xeon X5650 processors (2 . 67 GHz, 6 cores, 12 threads) and 96 GB of main memory. All the algorithms were implemented in C++ and compiled us-ing gcc 4.8.4. We used Google Snappy as a general-purpose LZ-family compression algorithm. Each entry of ADSs and SRSs was represented by 32 bits, where 26 bits are for the vertex ID and 6 bits are for the distance.
 Methods. We compared five sketch construction meth-ods in our experiments. (1) ADS denotes the all-distances sketches construction method. (2) ADS-c denotes an ADS construction method with compression, which simply com-presses sketches using an LZ-family compressor for each ver-tex. (3) SRS denotes the SRS construction algorithm using ADSs (Algorithm 3). (4) SRS-d denotes the direct SRS con-struction algorithm (Algorithm 4). (5) SRS-i denotes the SRS construction algorithm with the implicit neighborhood technique described in Section 7.1 . Note that the algorithm of SRS and SRS-i are the same, and the constructed indexes of SRS and SRS-d are also the same. The SRS construction algorithms are parallelized, and run for 24 threads unless otherwise specified. For SRS-d , we set  X  = 1 unless other-wise specified.
 Datasets. We used publicly available real-world networks from the Stanford Large Network Dataset Collection [22 ], the Koblenz Network Collection [20 ] and Laboratory for Web Algorithms [ 5, 7], which include social networks and web graphs of various sizes. Table 2 summarizes the details of the real-world networks used in the experiments, where (d) and (u) stand for directed and undirected networks, re-spectively. It shows the number of directed edges, i.e., an undirected edge corresponds to two directed edges. For di-rected graphs, we constructed forward ADSs and SRSs.
Table 3 summarizes the performances of each method for k = 16. The sketch size for each method and dataset is shown in the upper-left part of the table. ADS-c performed slightly worse than ADS , which suggests that simple com-pression does not work for ADSs. This is because an ADS for each vertex is too small to compress, although the ADSs for all the vertices can be large. SRS consistently gener-ated smaller sketches than ADS , which ranged in 7% to 34% of the sizes of the original ADSs. The SRSs become even smaller with the implicit neighborhood technique, i.e., less than half of the size of the original SRSs in some datasets. Effect of k . Figures 4a and 4b show the sketch size for dif-ferent k values in web-Google and com-DBLP, respectively. It is should be emphasized that the relative size of SRSs as compared to ADSs further decreases as the value of k in-creases in both datasets, which suggests that SRS is more efficient when k is large. In contrast, the implicit neighbor-hood technique is more effective when k is small because the ratio of entries of neighboring vertices in an SRS will also be small when the size of the SRS increases.
The right-hand side of Table 3 compares the construction time and space for k = 16. The construction time for SRS includes the ADS construction time. In all datasets, ADS and ADS-c perform the best in terms of construction time. SRS constructed sketches for the com-Orkut dataset with 234 million edges in around 75 minutes. SRS-d took more time for SRS construction, i.e., up to 21 times longer than SRS , and it processed the indochina-2004 dataset in around 10 hours, which was the toughest instance for SRS-d in the experiments. In social networks, however, SRS-d took up to four times longer than SRS . This is attributed to the differ-ence of diameters between web graphs and social networks.
As for the construction space, SRS-d performs the best in most of the datasets, and shows quite similar performance to ADS in the other datasets. The construction space of SRS-d tends to be small when the SRSs themselves are also small, since it does not keep the whole ADSs during the construction. SRS basically required two to four times more space than ADS because it internally keeps ADSs and other data structures linear to the size of the ADSs.
 Effect of k . Figures 5a and 5b show the construction time for different values of k in web-Google and com-DBLP, re-spectively. Although the construction time of SRS-d grows slightly faster than that of the other methods, all the meth-ods constructed sketches for k = 256 within several hours in web-Google.
 Effect of Partial ADS Caching. Figure 6 shows the trade-off between time and space consumption of our direct construction algorithm for varying  X  , which is the ratio of cached ADSs ( k = 16). Partial ADS caching significantly improves the construction time even when  X  = 0 . 2. This is because a small fraction of vertices cover a large number of Figure 7: The effect of parallelization for varying numbers of threads in web-Google.
Figure 8: Retrieval time for varying values of k . number of edges in real-world networks owing to their power law degree distributions. In contrast, the construction space does not seem to increase fast and it is not very large even when  X  = 1.
 Effect of Parallelization. Figure 7 shows the effect of par-allelization of SRS construction algorithms ( k = 16). These methods, especially SRS-d , have quite high parallelizabil-ity. SRS-d constructed SRSs around 12 times faster for 24 threads than for a single thread, which makes the algorithm more practical.
The lower-left part of Table 3 shows the average time of re-trieval of an ADS for k = 16. For each method and dataset, we conducted retrievals from 10,000 randomly chosen ver-tices and took their average. The retrieval times of SRS are within around 1 ms in those datasets. SRS-i showed similar performance to SRS in some datasets, whereas it took up to seven times longer in other datasets. The retrieval times of these methods seem to depend not only on the size of ADSs or SRSs. We can observe that the retrieval tends to takes a long time when the sketch size is small compared with the original ADS.
 Effect of k . Figures 8a and 8b show the retrieval time for different k values in web-Google and com-DBLP. The re-trieval times of SRS and SRS-i grow almost linearly to k . The difference between SRS and SRS-i becomes less signifi-cant as k increases.
Further, we conducted experiments for estimating graph properties to examine the practical applicability of SRS. It has been shown that several indicators of graphs can be esti-mated using ADS, as discussed in Section 3.2 . We estimated the closeness centrality [ 12 ] and closeness similarity [13 ] of 1,000 uniformly chosen vertices or pairs of vertices for each dataset using the constructed ADSs and SRSs, and evalu-ated the approximation error and estimation time for vary-ing values of k . Note that the accuracy results of SRSs and ADSs are exactly the same.
 Accuracy. Figures 9a and 9b show the root-mean-square error (RMSE) of estimated centrality and similarity values compared with the exact values. For the three datasets shown in the figures, the RMSEs of both centrality and sim-ilarity basically decrease as the value of k increases. The other datasets also showed similar results, as suggested the-oretically.
 Estimation Time. Figures 10a and 10b show the average estimation time of closeness centrality and closeness similar-ity values in web-Google. The bottleneck of the estimation is ADS retrieval because a vertex centrality or similarity is estimated in linear time to the size of the ADSs. Thus, these figures show a similar trend to retrieval time. The values can be estimated within 20 ms even for k = 256, which should be acceptable in typical situations.
In this paper, we proposed a new scheme for graph neigh-borhood sketching, called the sketch retrieval shortcuts (SRS). The SRS complements the recently-emerging powerful sketch-ing method all-distances sketches (ADS) [11 , 12]. The ADS combines preferable properties: multi-functional, accuracy guaranteed, and scalable (in theory). However, in practice, it is not as scalable as expected, due to its large storage consumption. The SRS is designed so that, while it is much smaller than the ADS, from SRSs, an ADS of any vertex can be quickly retrieved. Therefore, once we have obtained SRSs, various graph properties can be estimated on mas-sive graphs with the exactly same procedure as that of plain ADSs. In our experiments, we observed that SRSs are orders of magnitude smaller than ADSs, we can construct SRSs for million-scale graphs, and the retrieval time is in milliseconds and sufficiently quick. These results show the high practi-cality of SRSs as a back-end for large-scale graph analysis.
A common misunderstanding about the definition of SRSs is that B ( u ) is equivalent to Intuitively this may seem true, but it is false. Figure 11 shows a counterexample ( k = 1). As vertex 4  X  A (1) and 4  X  P (1 , 6), 6 6 X  E (1). However, 6  X  B (1), and indeed, the SRS entry from vertex 1 to vertex 6 is necessary for retrieval; otherwise, vertex 6 would be isolated. Figure 11: A counterexample where B (1) 6 = E (1) .
To estimate the expected influence of a vertex set under the continuous-time influence model, we need its combined ADS [17, 15 ]. The combined ADS can also be quickly re-trieved from SRSs by slightly modifying the retrieval algo-rithm. At Line 2 in Algorithm 1, we push all all vertices in O ( | S | + k 2 log 2 n ) space.
