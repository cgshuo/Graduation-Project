 XUNING TANG and CHRISTOPHER C. YANG , Drexel University In recent years, online social networking sites have attracted significant attention and achieved unanticipated success based on continued increase in the numbers of users. For example, Facebook and Twitter attract millions of visits daily and significantly impact the traditional news industry due to their rapid means of disseminating details about current events. In addition, the advance of Web 2.0 technologies have allowed the number of websites with embedded social networking functions (e.g., Flickr, Delicious, and Digg) to continue to experience exponential growth. As a result, social network data has become valuable information for improved understanding of the characteristics of our society and for detecting evolving community networks. Among several research topics of social media analysis, community detection has attracted substantial atten-tion due to its broad applications. Identifying user groups with similar interests can foster sharing resources (e.g., in Flickr or Delicious); detecting potential gang or ter-rorist groups in suspicious online forums is critical for national security; identifying consumer communities from online shopping sites is beneficial to target potential cus-tomers and promote new business. Moreover, by extending the static social network analysis techniques to detect evolving communities from dynamic social networks, we can broaden its potential for future applications. Detecting evolving communities is useful for analyzing dynamic online social media to predict the development of com-mon interest groups for marketing and business intelligence purposes. We can also monitor the evolution of social movements to ensure public safety.

In light of the benefit of community detection, a large body of research work has been devoted to this topic, largely detecting communities from a static network based on modularity, cliques, betweenness, graph spectrum, or generative models. However, none of them takes time stamps into account, and therefore is not applicable to dy-namic networks. Some other works represent dynamic networks by a stream of static networks [Asur et al. 2007; Berger-Wolf and Saia 2006; Falkowski et al. 2006; Sun et al. 2007; Toyoda and Kitsuregawa 2003]. They employ a two-stage approach which identifies communities from a static network of each time epoch, and then examine communities in adjacent epochs to identify their evolutionary relationships. However, since a two-stage approach detects communities from each time epoch independently, it often results in communities with high temporal variation [Lin et al. 2008]. Some recent works propose novel techniques to detect communities and to identify their evo-lutionary relationships under a unified framework [Fu et al. 2009; Lin et al. 2008; Yang et al. 2009]. However, these works require the number of communities to be either fixed or restricted to a narrow range.

In view of limitations of existing community detection techniques, we characterize a community detection algorithm with capabilities that enable it to support the following applications. First of all, it should be able to detect dynamic communities. In addition, community detection and evolutionary relationship identification should be conducted in a unified framework rather than in two separate stages. Second, the number of communities should be determined automatically without human intervention. Third, a good community detection algorithm should be able to handle node addition and attrition flexibly as nodes in dynamic graphs appear and disappear over time. Finally, the  X  X ich-gets-richer X  effect is common in scale-free social networks [Arenas et al. 2004] which typifies an ideal community detection algorithm.

Stochastic blockmodels [Nowicki and Snijders 2001; Snijders and Nowicki 1997] have been widely studied to detect user communities in social networks. However, the original stochastic blockmodel is too simple to achieve the goals mentioned in the last paragraph. In this work, we extend the stochastic blockmodel by incorporating a tem-poral Dirichlet process. In our proposed model, community detection and evolutionary relationship identification are conducted simultaneously under a unified framework. The temporal Dirichlet process not only enables our model to deal with dynamic net-work but also allows the number of communities at each time epoch to be determined automatically. The major contributions of this work include (1) the development of an integration of the temporal Dirichlet process and stochastic blockmodel to alleviate the problem of fixed community number, particularly for dynamic social networks; (2) the derivation of a Gibbs Sampling algorithm to infer community assignments and model parameters; (3) rigorous experimentation to test the model thoroughly on a simulated dataset, a large-scale Flickr dataset, and a Digg dataset. Our proposed model out-performs the benchmark technique. Meanwhile, the experiment results confirm the effectiveness and validity of our model. Community detection has been widely studied in various research domains for many years. For instance, Scott [2000] employed a hierarchical clustering approach to find communities in social networks. Girvan and Newman [2002; Newman 2004] devel-oped methods based on edge removal to identify community structure in a biological network with strong modularity. Similarly other research employed spectral clustering algorithms to divide a graph into multiple subgraphs [Dhillon et al. 2004; Shi and Malik 2002; Zha et al. 2002]. Besides community detection techniques based on modularity, cliques, betweenness, or graph spectrum, another group of research [Airoldi et al. 2008; Kemp et al. 2004; Nowicki and Snijders 2001; Snijders and Nowicki 1997] proposed probabilistic model-based techniques to estimate hidden communities based on user interaction in social networks. In addition, the Infinite Relational Model incorporated Dirichlet processes into the stochastic blockmodel so that the number of communities can be determined automatically [Kemp et al. 2004; Xu et al. 2006]. Unfortunately, none of these works can be applied to dynamic networks.

Recently, there has been a growing body of research which take the time features into account on the analysis of dynamic networks [Asur et al. 2007; Berger-Wolf and Saia 2006; Falkowski et al. 2006; Sun et al. 2007, 2010; Tantipathananandh et al. 2007; Toyoda and Kitsuregawa 2003]. Among them, Sun et al. [2010] proposed a dynamic Dirichlet-Process-based model to detect communities in heterogeneous information networks. However, their approach did not model the relationships between objects within heterogeneous information networks. Asur et al. [2007], Falkowski et al. [2006], and Toyoda and Kitsuregawa [2003] detected communities in each time epoch of a network stream, and then employed similarity metrics to identify evolutionary rela-tionships between communities in adjacent time epochs. Sun et al. [2007] developed a parameter-free algorithm to mine time-evolving networks using information theoretic principles. Berger-Wolf and Saia [2006] and Tantipathananandh et al. [2007] proposed an optimization-based approach which formulated the community detection problem as a coloring problem in a network stream. These works adopt a two-stage approach where community detection and community evolution are analyzed in two separated stages. However, the two-stage approach usually does not make use of the community information of previous epochs to infer hidden communities of the current epoch. As a result, there is a high variation of the detected communities in different epochs.
To reduce the variation of detected communities in different epochs, some recent works analyzed dynamic social networks by detecting communities and identifying evolutionary relationships under a unified framework. Yang et al. [2009] extended the stochastic blockmodel and proposed a dynamic stochastic blockmodel which can de-tect communities and their evolution simultaneously. Fu et al. [2009] extended Airoldi et al. X  X  (2008) work to model the evolution of mixed membership blockmodel. However, the number of communities was fixed over time in Yang et al. [2009] and Fu et al. [2009]. It is difficult to predefine the number of communities in a real-world applica-tion. Lin et al. extended the graph-factorization clustering technique and proposed a FacetNet algorithm to analyze dynamic communities, which relaxed the restriction of the number of communities within each time epoch by setting a range of candidates and searching for the optimal number by multiple trials [2008], which is computation-ally complex. In order to allow countably infinite community and to find the optimal number of communities naturally, we propose to incorporate temporal Dirichlet pro-cesses into a stochastic blockmodel to detect communities and their evolution in a unified framework. In addition, our model enables the number of communities to be determined automatically at each time epoch. In this section, we present the notation used in this article and formulate the research represents the number of nodes in E (t) . To simplify the problem, we only studied undirected graphs with binary edges which can be extended to weighted directed graphs in the future. Given an undirected graph with binary edges, if there is an edge A hidden community (or community) is a group of nodes that are closely connected. Community assignment of a node tells us which community this node belongs to. We consider that nodes within the same community have a common community assignment. Nodes within the same community have a higher chance to connect to each other than nodes from different communities. Let K (t) denote the total number of hidden communities at time t, and let P a , b denote the parameter of a Bernoulli distribution upon which an edge between two nodes from community a and community the community assignment of node i at time t by c (t) i .C (t) 1:i  X  1 denotes the community assignments from node 1 to node i  X  1attimet,c (t)  X  i denotes the community assignments of all nodes except node i at time t, and C (t) denotes the community assignments of total number of nodes that are assigned to community k at time t  X  1.
 In this study, given a stream of social networks over T epochs E T ={ E ( 1 ) , (2) estimating the community assignments for nodes of each network snapshot ( { A hidden community is a group of social media users who interact with each other frequently. It relies on a probabilistic model to determine to which community a user belongs. In addition, we are interested in discovering the evolution of identified com-munities to learn how these communities evolve from time to time based on user behaviors, as users may move from one community to another. In Sections 4.1 and 4.2, we introduce two basic models, the Dirichlet Process Mixture Model and the Stochastic Blockmodel. Each of these models possesses some desired properties. The Dirichlet Process Mixture Model is a well-studied clustering model which can automatically determine the number of clusters in a static dataset. Stochastic Blockmodel can be considered as a clustering model specifically designed for a static network. However, neither of them can handle data or network streams. In Section 4.3, we extend the Dirichlet Process Mixture Model to a Temporal Dirichlet Process Mixture Model to manage dynamic data streams. Finally, in Section 4.4, we propose our model, namely, the Dynamic Stochastic Blockmodel with Temporal Dirichlet Process, by synthesiz-ing the temporal Dirichlet process mixture model with the stochastic blockmodel. Our proposed model can estimate the community assignments for nodes at different time periods, where each community consists of a group of nodes closely connecting together. In addition, using the community assignments of nodes at previous time periods and the community assignments of nodes at the current time period, we can track the variations of user communities in terms of their size and members. Finite Mixture Models are well-studied clustering models which assume that each observation o i is generated by one of K unknown distributions parameterized by K different parameters  X  1 , X  2 ,..., X  K . However, in a Finite Mixture Model, the number K is fixed and hard to be predefined appropriately without prior knowledge. To determine the number of clusters automatically, the Dirichlet Process Mixture Model (DPM) is proposed which assumes that the parameter  X  is drawn from a distribution G, denoted as  X  i | G  X  G . In DPM, this distribution G is considered to be generated by a Dirichlet Process (DP) with a base measure G O and a concentration parameter  X  , denoted as G  X  DP(  X , G infinite number of components. Neal [2000] defined the DPM model as where f( . ) is the likelihood function of observing o i given  X  i . The DPM model in Eq. (1) can be expressed in an equivalent way which is easier to understand and sample. Given a Finite Mixture Model with K components having the following form, where c i indicates the latent component that is associated with observation o i ,theDPM model in Eq. (1) can be obtained by allowing K to extend to infinity. By integrating  X  and letting K go to infinity, the conditional probabilities of c i in Eq. (2) become with n i , k being the number of c j for j &lt; i that is assigned to the component k. We can better understand this Dirichlet Mixture Model by a well-known metaphor, the Chinese Restaurant Process (CRP). In the CRP, there is a Chinese restaurant with an unbounded number of tables. When a customer c i enters this restaurant, he can either customers with probability n i , k i  X  1 +  X  . To summarize, from the CRP metaphor, we observe that the DPM not only can determine the final number of mixture models flexibly but also reflects a  X  X ich-get-richer X  effect.

However, the DPM Model only works for general clustering problems, which is not dedicated to network data. In other words, it cannot be used directly to detect user communities from a social network. Nevertheless, it is worth emphasizing that DPM can detect countably infinite components. This is a desired feature for clustering algo-rithms. A stochastic blockmodel is a generative model which is widely studied by computer scientists to analyze static social networks. A major underlying assumption of the stochastic blockmodel is that each node i of a network belongs to one of K-hidden com-Assuming that node i belongs to a community a and node j belongs to another commu-nity b, the probability of observing an edge between these two nodes is generated by By following this definition, Nowicki and Snijders [2001; Snijders and Nowicki 1997] proposed a technique which can identify the hidden community membership of each node in a social network with maximum posterior probability given the observed edges.
However, the stochastic blockmodel alone is not sufficient to achieve our research goals mentioned in Section 1 for two main reasons: (1) the stochastic blockmodel does not consider time features of a network so that it can only deal with static communities instead of dynamic ones; and (2) the community number, K, needs to be predefined and cannot change once it is defined.

Since the stochastic blockmodel is capable of identifying hidden communities in a static network and the DPM is good at determining the number of hidden components automatically, we can integrate the stochastic blockmodel with the DPM to detect an unbounded number of hidden communities. However, similar to the stochastic block-model, the DPM also does not consider time features. As a result, the DPM cannot directly deal with temporal data and inhibits our goal to study dynamic social net-works. To address this problem, we employ a modified version of the Dirichlet process mixture Model, the temporal Dirichlet process mixture model [Ahmed and Xing 2008], and then integrate the stochastic blockmodel with the temporal Dirichlet process mix-ture model to detect and model community evolution. The Dirichlet Process Mixture Model has been extended recently to address the evolu-tionary clustering problem [Ahmed and Xing 2008; Xu et al. 2008]. Specifically, Ahmed and Xing proposed a Temporal Dirichlet Process Mixture Model (TDPM) [2008] which operates in discrete time epochs, that is, days. In the TDPM, both the popular dishes and the seating plan of the current time epoch will impact the customers X  selections in the next time epoch, leading to a rich-gets-richer phenomenon not only within a time epoch but also in adjacent time epochs. Formally speaking, let X  X  consider the generative process for a finite dynamic mixture model with K components. Within a given time epoch t , the generative process for each observation i is defined as follows (please refer to Section 3 for notation): in Eq. (4) is defined as Similarly, we can better understand Eq. (5) by another metaphor known as the Re-current Chinese Restaurant Process (RCRP). In the RCRP, customers entered the restaurant in a given day are not allowed to stay beyond this day. At the end of day t  X  1, the owner of the restaurant records on each table the dish served on this table and the number of customers who shared it, since he believes that popular dishes will remain popular in the next day [Ahmed and Xing 2008]. Given this information, when acustomerc (t) i enters this restaurant at day t, he can pick a non-empty table k that already has n (t) i , k customers at day t with probability n ( t this table at day t  X  1. Alternatively, he can pick an empty table that nobody is sitting at at day t but n ( t  X  1 ) k customers sit at at day t  X  1 with probability n ( t n k equals 0. Finally, he can pick an empty new table with probability putting these alternatives together, we arrive at Eq. (5). The table in this metaphor corresponds to community. To model dynamic social networks, we propose the Dynamic Stochastic Blockmodel with the Temporal Dirichlet Process (DBTDP), which incorporates the temporal Dirichlet process introduced into the stochastic blockmodel to identify community evolution in network streams. More precisely, we make use of the RCRP derived by Ahmed and Xing to determine the community assignments of nodes in a given network. Once the nodes X  community assignments are decided, a Bernoulli distribution is employed to generate the edges of the given network. In Ahmed and Xing X  X  Temporal Dirichlet Process Mixture Model (Equation (4)), observation o i is generated directly based on a function f( . ) parameterized by  X  (t) proposed model is a bit different. Each observation in our model is an edge connecting two nodes. The community assignment of each node is decided by a RCRP. But each observed edge in our model is generated by a Bernoulli distribution. The DBTDP model have been assigned to k communities by following the CRP, we either assign the i th node and then assign the i th node to this new community with probability  X  i  X  1 +  X  . Since CRP is exchangeable, the order of assigning nodes to communities can be permuted without edges between nodes in E ( 1 ) are generated stochastically by probabilities P. Recursively, nodes have been assigned to k communities by following the RCRP, for the i th node, we either assign it to one of k existing communities with the probability n ( t add a new community and then assign it to this new community with the probability  X  1 ) + i  X  1 +  X  . Given that the community assignments C t is available, the edges between nodes in E ( t ) are decided stochastically by probabilities P. The generative process of the DBTDP is shown as follows.
 ALGORITHM 1 : Pseudocode of the Generative Process of DBTDP To illustrate the DBTDP model, we present a plate notation of the DBTDP in Figure 1. In Figure 1, at the first time epoch, parameters  X  (1) are generated based on the concen-tration parameter  X  . For the following time epochs t when t &gt; 1, parameters  X  (t) are generated based on both the concentration parameter  X  and the community assign-ments of the latest time epoch C (t  X  1) . The community assignments of the current time epoch are decided by  X  (t) . Within each time epoch, once the community assignments of ure 1, the shaded nodes represent the observed edges, while the white nodes represent these hidden variables based on the observed edges. For convenience, we summarized the notations used throughout article in Table I. In Section 4, we introduced the DBTDP model. In this section, we derive the likelihood function of the DBTDP model, P ( E T , C T |  X , P ) . Since it is difficult to maximize this likelihood function directly, we derive the posterior probability, posterior probability. The Gibbs sampling algorithm is a moderately efficient method for approximating the conditional probability of community assignments. We first introduce three reasonable independent assumptions, which can help us to derive the likelihood of the data.

A1 . For the initial network where t = 1, the community assignment of a node, say i, as
A2 . Similarly, for the networks where time t &gt; 1, the community assignment of a node, for example i, in E ( t ) is decided by the community assignments of all nodes before A3 . Following the definitions of Stochastic Blockmodel defined in Nowicki and Snijders [2001] any edge (i,j) in E ( t ) is generated independently of the other nodes/edges given the community assignments of node i and j. The generative process follows a Bernoulli distribution, defined as where equals the number of existing edges between two nodes of community a and b, respec-tively. On contrary, Eq. (10) equals the number of missing edges between two nodes of community a and b, respectively. Eq. (8) represents the probability of observing the given network, including both existing edges and missing edges, by following a Bernoulli distribution.
 With the preceding assumptions, the dynamic stochastic blockmodel with temporal Dirichlet process is then given by the joint distribution of ( E T , C T ): Given the likelihood function P ( E T , C T |  X , P ) derived from Equation (11), the objective is to maximize the likelihood in order to infer the optimal community assignments. However, in the DBTDP, maximizing P ( E T , C T |  X , P ) directly by estimating {  X , P } is nontrivial. A typical Bayesian treatment for this case is to estimate the posterior probability instead of directly maximizing the likelihood of the data. Since edges are generated by a Bernoulli distribution with different parameters, in this section, we first define a Beta distribution and incorporate it into the model as a conjugate prior ments C ( t ) is represented as where B stands for a beta function.

Second, we employ Maximum A Posteriori Probability estimation (MAP) to uncover the community assignments C T , defined as Finally, instead of finding the global optimization of C T , given an incoming stream of words, we assume that we do not observe the whole network sequence because social networks are arriving in a streaming fashion. Instead, we optimize the community assignments of the current time t based on the community assignments in the previous time epoch. Formally speaking, the objective posterior probability that we want to maximize is Based on our assumptions A2 and A3, by following the Bayesian theory, the posterior probability of C ( t ) can be represented as where P (C ( 1 ) |  X  ) is defined in Eq. (3) and Eq. (6). Given the previous construction for the DBTDP model, we derive a collapsed Gibbs sampling algorithm to maximize the posterior probabilities. A Gibbs sampling algo-rithm is a moderately efficient method used to approximate the conditional probability of community assignments in Equations (16) and (17) when analytical solutions to them are difficult. We first elaborate two key steps within our Gibbs sampling algorithm and then summarize the entire algorithm in Algorithm 2.
 Step 1: Initialization . For the input network E ( 1 ) , we initialize the model by creating K (init) empty communities, and then assigning each node into one of K (init) communities we initialize the model by maintaining their community assignment according to the randomly to one of K (t  X  1) communities.

Step 2: Community Assignment Estimation . For each node, we repeat the following two steps until reaching the iteration number.  X  Step 2.2 . Sample each of the objects into existing communities or a new community, following the posterior probabilities: when t &gt; 1andc (t) j = k for all j = iand  X  i , c (t  X  1) i = k, when t &gt; 1and  X  j , c (t  X  1) j = kor  X  j = i , c (t) j = k, when t = 1andc (1) j = k for all j = i, when t = 1and  X  j = i , c (1) j = k .
 The Gibbs Sampling algorithm is summarized in Algorithm 2.
 ALGORITHM 2 : Frequency Number Computation We conducted three experiments to evaluate our proposed model. Initially we tested our model on two simulated datasets with different noise levels. We also tested the sensitivity of our model under different parameters settings. In order to investigate its scalability, we applied our model to a dynamic Flickr user network with more than 2.5M nodes and 33M edges. Finally, we tested our model on a dataset crawled from Digg.com. Experiment results demonstrated the effectiveness of our proposed model. In this study, we adopted the metrics of previous works [Newman and Girvan 2004; Yang et al. 2009] to measure the performance of our model. These metrics are Normal-ized Mutual Information (NMI) and Robustness. NMI is used when there is a ground truth, for example in a simulated dataset. Formally speaking, given a true community partition, denoted as C ={ C 1 , C 2 ,..., C K } , where C i is a group of users of community i , also given the estimation of community partition C ={ C 1 , C 2 ,..., C K } ,theNMIis defined as where H ( C ) and H ( C ) are the entropies of C and C . According to Eq. (20), NMI is a value between 0 and 1. The higher the NMI score, the more similar the ground truth and the estimation are.

When the ground truth is not available, we adopted the robustness to measure the performance [Henderson et al. 2010; Karrer et al. 2008]. The argument is that a valid community detection algorithm should be resistant to a small perturbation of the network structure. Specifically, we perturb a given network by randomly reassigning r percent of its edges, where r  X  [0 , 1]. Then the community detection algorithm is applied to the original network and the perturbed network, and the variation of information is calculated between the two community assignments C (with r = 0) and C (with 0 &lt; r  X  1) to measure the community detection algorithm X  X  robustness, denoted as where H ( C | C ) is the conditional entropy, which quantifies the uncertainty of commu-nity assignment C given that another community assignment C is known. To sum up, the lower the robustness score, the stronger robustness a community detection algorithm has. 6.2.1. Data Generator. By modifying Newman and Girvan [2004] and Yang et al. [2009] proposed a procedure to automatically generate a stream of social networks, each of which contains 128 nodes and 4 hidden communities. In their procedure, with time t = 1, each node was randomly assigned to one community. Each community contained 32 nodes. Yang predefined two probability values p in and p out , and the average degree of nodes in the network as 16. To generate edges for a network, for each pair of nodes of the same hidden community, an edge was draw by probability p in . Similarly, for each pair of nodes of different communities, an edge was drawn by probability p out . At each time epoch after time epoch 1, they randomly chose 10% of the nodes to leave their original community and join the other three communities at random. After reassigning the nodes, edges of the network were decided by probability p in and p out as before. The researchers simulated dynamic networks in this way spanning ten time epochs.
However, Yang X  X  procedure can only generate evolving networks with a constant num-ber of hidden communities. To study the network evolution with a varying a number of communities, we further modified Yang X  X  procedure by randomly adding one commu-nity with the probability of p a , deleting one community with the probability of p d ,or keeping the same number of communities with the probability p r at each time epoch (p from each old community to join this new community (P is computed to make sure that each community has approximately the same number of nodes), and then chose 10% of the nodes from each existing communities to leave their original community and join other communities randomly. If an old community was deleted, we randomly assigned the nodes of that community to other communities, and then chose 10% of the nodes to leave their original community and join other communities randomly. If the number of hidden communities did not change, we randomly chose 10% of the nodes to leave their original community and join other communities randomly. Edges of the network were determined by the probabilities p in and p out after reassigning the nodes. We generated the evolving networks in this way for ten iterations. We tested our algorithm under two different noise levels by setting the ratio of p in / p out approximately equal to 4, 3, respectively. Networks with lower ratios are characterized by stronger noise levels. 6.2.2. Comparison with a Baseline Algorithm. In this article, we compared the performance of our proposed DBTDP algorithm with the online version of the Dynamic Stochastic Blockmodel (DSBM) algorithm proposed by Yang et al. [2009]. The DSBM outperformed all other state-of-the-art algorithms, such as FacetNet [Lin et al. 2008] and EvolSpect [Chi et al. 2007]. It is important to note that DSBM algorithm needs a predefined numbers of communities as input and this number remains unchanged. To compare the DBTDP with the DSBM fairly, we provided DSBM with different numbers of com-munities, from 3 to 6, and then compared the DBTDP with all of them. For the DBTDP model, we empirically set  X  a , a = 200,  X  a , b = 40,  X  a , a = 1,  X  a , b = 30, and  X  = 1(we will discuss the parameters setting in Section 6.2.3). DBSM-3 represents the DBSM model with the predefined number of communities equal to 3. DBSM-4 represents the DBSM model with the predefined number of communities equal to 4, and so forth. Since we have the ground truth of the community assignments for all nodes over these ten epochs, we employed NMI to evaluate the performance of the algorithms. Figure 2 presents the performance of DBTDP, DBSM-3, DBSM-4, DBSM-5, and DBSM-6 on two datasets with different noise levels over ten epochs (t from 1 to 10). Figure 2(a) corresponds to a lower noise level, while Figure 2(b) corresponds to a higher noise level. Both of them demonstrated that the DBTDP algorithm achieved the highest NMI score most of the time on both datasets. On the contrary, DSBM algorithm performed well only when the true number of communities was close to the predefined number of communities, while DBTDP can automatically adjust the number of communities and maintain a relatively high NMI score. Concretely, by using two-tail student t-test, we observed that in Figure 2(a), DBTDP significantly outperformed DBSM-3 (p = 1.8E-7), DBSM-4 (p = 9.5E-5), and DBSM-5(p = 0.0002), but DBTDP did not significantly outperform DBSM-6 (p = 0.2). Similarly, in Figure 2(b), the DBTDP significantly outperformedo DBSM-3 (p = 1.1E-6), DBSM-4 (p = 0.0005), and , DBSM-5 (p = 0.0035), but did not outperform DBSM-6 (p = 0.011) significantly. In Figure 3, we plotted the number of communities over ten epochs (t from 1 to 10 in x-axis) along with the number of communities estimated by the DBTDP for both datasets. T1 and E1 represent the true number of communities and the estimated number of communities of the dataset with noise level 1. T2 and E2 represented the true number of communities and the estimated number of communities of the dataset with noise level 2. Figure 3 shows that the DBTDP algorithm nearly found all the correct numbers of hidden communities in both datasets. 6.2.3. Hyper-Parameter. In this section, we tested the DBTDP algorithm with different settings of hyper-parameters. As introduced in Section 5.1,  X  and  X  represent the prior knowledge that users within the same hidden community have a higher probability of interaction with each other than in different hidden communities. As a result,  X  a , a should be set larger than  X  a , b ,witha = b. Similarly,  X  a , a should be set smaller than  X  b ,witha combinations of hyperparameters. In this part, we empirically fixed  X  = 1 , X  a , b = 40, The experiment results in Figure 4 shows that DBTDP had the worst performance when  X 
In addition, the concentration parameter  X  is crucial to RCRP. We let  X  a , a = 200 and  X   X  that when  X  equals 0.1, 0.5, and 1, the performances of our proposed model are close. When  X  equals 5 or 10, the performances of our model become worse. One explanation is that our proposed model will generate a larger number of communities when  X  is set too high. In other words, the DBTDP, to some extent, is sensitive to parameter  X  . It could be a limitation of our proposed model.
 6.3.1. Data Description. In the second experiment, we used the public Flickr dataset mentioned in Cha et al. [2009] to test the scalability of our proposed model. Cha et al. crawled the Flickr social network graph once per day for the period of 104 consecutive days from November 2nd X  X ecember 3rd, 2006 and February 3rd X  X ay 18th, 2007. 2.5 million Flickr users and 33 million edges were observed in these two periods. We aggregated the historical data from November 2nd X  X ecember 3rd to form the social network of time epoch one. Similarly, we aggregated the data from February 3rd X  X arch 3rd, March 4th X  X pril 4th, and April 5th X  X ay 18 th to form the social networks of epochs two, three, and four. Our proposed model was applied to these networks to identify hidden communities. It is worth mentioning that due to the power law, most Flickr users have very low-degree centrality. In this study, we removed the nodes that have low-degree centrality and kept the core nodes (  X  11K nodes) and their relationships (  X  6.3M edges). 6.3.2. Performance of DBTDP on Flickr Dataset. According to our experience on a large-scale dataset, the DBTDP is not as sensitive to the parameters when the number of nodes of networks is large. We empirically set  X  a , b = 1000 and  X  a , a = 10 in this experiment. Figure 6 shows the convergence of our model along with the iteration time. It demonstrated that the DBTDP detected seven communities in the first time period by starting from the initial value two, and then quickly converged to seven. In the following time epochs, the number of communities was stable at seven, which means that no more communities were detected (epochs two, three, and four overlap in Figure 6 because the community number was stable at seven). Since there are is ground truth about the number of communities and the community assignments of the nodes, instead of judging the results produced by the DBTDP alone, we compared it with the results produced by DBSM using robustness as an evaluation measurement. To compare the DBTDP with the DBSM fairly, we set the number of communities to seven for DBSM. Figure 7 demonstrates that in all four time epochs, the DBTDP consistently achieved a lower robustness score, which showed that the communities detected by the DBTDP were more robust and convincing. Finally, we summarized the computational time of the DBTDP and the DBSM-7 in Table II. We ran our program on a personal computer with a 2.1GHz Intel Core (TM) 2 Duo CPU, 1.96GB of RAM and Windows XP. Table II demonstrats that DSBM-7 took less time than DBTDP (18 minutes) but not very substantialy. Figure 8 demonstrates the detected hidden communities, size, and their evolution paths. Each community was denoted by one color and labeled by its size. Arrows from one community to another between adjacent epochs represented the number of users transitioning from one community to another. The thickness of the arrow corresponded to the user amount (we omitted insignificant transition with less than 100 users). We observed that C1 and C2 became smaller, while C4, C5, and C7 continued growing. In addition, users of C2 kept moving to C7. Moreover, users in C3, C4, C5, C6 were less stable than the users of other communities. 6.4.1. Data Description. In the final experiment, we tested the DBTDP model on an online social media dataset, namely the Digg dataset. We built this dataset by using the Digg API to collect data for the period of 92 consecutive days from March 1st  X  X ay 31st, 2011. Similarly, we filtered out inactive users and studied only the active users. Finally, we collected 286 nodes (users) and 16.8K edges (temporal user interactions) in total. We divided the whole dataset into three time epochs, one for each month. Our proposed model was then applied to identify hidden communities and their evolution. 6.4.2. Performance of the DBTDP on a Digg Dataset. Figure 9(a) demonstrates that the DBTDP detected four communities in the first time period by starting from the initial value two, and then quickly converged to four. In the second time period, the number of detected communities increased and converged to six. In the last time period, the number of detected communities increased to eight. Similarly, there are no ground truths about the number of communities and the community assignments of the nodes. Instead of judging the results produced by DBTDP alone, we compared it with the re-sults produced by DBSM using robustness as an evaluation measurement. To compare DBTDP with DBSM fairly, we set the community number for DBSM in the first time period to four, the number in the second time period to six, and the number in the third time period to eight. Figures 9(b) X (d) demonstrate that in all three time epochs, the DBTDP always achieved a lower robustness score than DBSM. Similarly, we summa-rized the computational time of the DBTDP and the DBSM in Table III. We ran our program on a personal computer with a 2.1GHz Intel Core(TM)2 Duo CPU, 1.96GB of RAM and Windows XP. Table III demonstrated that the DBTDP saved more time than the DBSM (220 seconds) on the Digg dataset. The DBTDP model can manage the insertion and attrition of nodes in each time epoch in a flexible manner. In the initialization step (step 1), a new node will be assigned randomly to one of the existing communities, and a preexisting node will be assigned to its original community. Whether it is a new node or a preexisting node does not affect the execution of step 1. Similarly, in the sampling step (step 2), according to Eqs. (18.1) and (18.2), given a network E ( t ) with t &gt; 1, the probability of assigning node i to community A is independent of whether i is a new node or not, but depends on the community assignments of i X  X  neighbors as well as the size of community A in epochs t  X  1 and t. This feature enables our model to handle a stream of networks with different nodes at different time epochs. Although the DBTDP model outperformed the benchmark technique and detected high-quality hidden communities in our experiments, the DBTDP model has some limitations. First of all, mixed-membership is a desired feature in community detection, which assumes that nodes can belong to multiple hidden communities. The DBTDP, however, only allows each node to be assigned to one community. In addition, binary edge is not enough to model different types of interactions between users. Fortunately, this problem can be solved by replacing the Bernoulli distribution with a multinomial distribution in our model. Second, besides using a greedy algorithm to estimate com-munity assignments, in the future, it is important to derive algorithms to estimate nodes X  community assignments conditioned on the whole data at the same time. Fi-nally, the DBTDP model does not guarantee community stability, which implies that a node is allowed to switch to different communities in different time epochs. How-ever, it is desirable to have a certain level of stability for a node X  X  assignment in some applications. In this article, we proposed a Dynamic Stochastic Blockmodel with Temporal Dirichlet Process to detect hidden communities and their evolutions from dynamic networks. The DBTDP model considers networks arriving in a stream, allowing insertion of new nodes and attrition of old nodes. Moreover, we incorporated the temporal Dirichlet process into the stochastic blockmodel to adapt our model to network evolution. In addition, the number of hidden communities in our model is theoretically unbounded. This num-ber can be estimated from the input data so that no prior knowledge is required to predefine the target number of communities. Communities in our proposed model can split, merge, retain, disappear, or grow. We also provided some discussions to explain why our model can handle insertion or attrition of nodes. A Gibbs sampling algorithm was proposed to optimize the posterior probability and estimate the community assign-ments of nodes. Experiment results on simulated dataset showed that our proposed DBTDP model outperformed the state-of-art benchmark algorithm, particularly when the number of communities in the simulated dataset changes over time. Large-scale experiment on a Flickr dataset also demonstrated the effectiveness and scalability of our model. Finally, our model achieved satisfactory results on a Digg dataset as well.
