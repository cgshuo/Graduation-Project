 Achieving high translation quality remains the big-gest challenge Machine Translation (MT) systems currently face. Researchers have explored a variety of methods to include user feedback in the MT loop. Similar to our approach, Phaholphinyo and colleagues (2005) proposed adding post-editing rules to their English-Thai MT system with the use of a post-editing tool. However, they use context sensitive pattern-matching rules, which make it impossible to fix errors involving missing words. Unlike our approach, in their system, the rules are created by experienced linguists and their approach requires a large corpus. They mention an experi-ment with 6,000 bilingual sentences but report no results due to data sparseness. 
In general, most MT systems have failed to in-corporate post-editing efforts beyond the addition of corrected translations to the parallel training data for SMT and EBMT or to a translation mem-ory database. 1 Therefore, a largely automated method that uses online post-editing information to automatically improve translation rules constitutes a great advance in the field. 
If an MT-produced translation is incorrect, a bi-lingual speaker can diagnose the presence of an error reliably using the online Translation Correc-tion Tool (Font Llitj X s and Carbonell, 2004). An example of an English-Spanish sentence pair gen-erated by our MT system is  X  Gaud X  was a great artist -Gaud X  era un artista grande  X . Using the online tool, bilingual speakers modified the incor-rect translation to obtain a correct one:  X  Gaud X  era un gran artista  X . 
Bilingual speakers, however, cannot be expected to diagnose which complex translation rules pro-duced the error, and even less, determine how to improve those rules. One of the main goals of this research is to automate the Rule Refinement proc-ess based on just error-locus and possibly some error-type information from the bilingual speaker, relying on rule blame assignment and on regres-sion testing to evaluate and measure the conse-quent improvement in MT accuracy. In this case, our Automatic Rule Refinement system can add the missing sense to the lexicon (great  X  gran) as well as the special cas e rule for Spanish pre-nom inal adje ctives to the gra mmar. 
With this sy stem in place, we envision a modi-fied version of the Translation Correction Tool as a gam e with a purpose, available online through a major web portal. This would allo w bilingual speakers to correct MT in put and get rewards for making good corrections, and com pare their scores and speed with other users. For the MT comm unity this means h aving a free and easy wa y to get MT output feedback and potent ially im prove their s ys-tems ba sed on such feedback. Furthermore, a fully interactive sy stem would b e a great opportunit y to show users that their corrections have a visible im -pact on tech nology, since they would see the ef-fects their c orrections have on other sentences. Last but not least, this new method is also expected to be particularly useful in resource-poor scenarios, such as the ones the Avenue project is devoted to (Font Llitj X s et al., 2005b), where statistical sy s-tems are not an option and where there might be no experts with knowledge o f the resource-poor lan-guage (Figure 1). The main challenge of the error eli citation part of this work is how to elicit mini mal post-editing i n-formation from non-expert bilingual speakers. Th e Translation Correction Tool (TCTool ) is a user-friendl y onlin e tool that allows users to add, delete and modify words and al ignm ents, as well as to drag words around to cha nge word ord er. A set of user studies was conducted to discov er the right am ount of err or inform ation that bilingual speakers can detect rel iably when using the TCTool. These studies show ed that si mple error infor mation can be elicited much m ore reliably (F1 0.89) than error type inform ation (F1 0.72) (Font Llitj  X s and Car-bonell, 200 4). Most im portantly, it becam e appar-ent that for o ur Rule R efinement purposes, the li st of correction action(s) with inform ation about error and correction words is sufficient. 
Building on t he exam ple introduced ab ove, Fig-ure 2 shows the initial state of the TCTool, once the user has decided that the translation produced by the MT s yste m is not correct. 
In this case, the bilin gual speaker changed  X  X rande X  to  X  gran X  and dra gged  X  X ran(d e) X  in front of  X  X rtista X , effectively flipping the or der of these two words. Figure 3 shows the state of the TCTool after the user corrections. User correcti on actions are register ed into a log file. The Automatic Rule Refinement (RR) module extracts all the relevant inform ation from the TCTool log files and stores it into a Correction Instance. See Figure 4 for a n exa mple. 
The Rule Refinem ent (RR) module processes one action at a ti me. So in this approach, the order in which user s corre ct a s entence does h ave an i m-pact on the or der in which r efinem ents appl y. After having stored all the relevant inform ation from the log file, the Rule Refinement module starts proces sing the Correction Instance. In the exa mple abo ve, it first goes into the lexicon and, after double checking that there is no l exical entry for [ great  X  gran ], it proceeds to add on e by dupli-cating the le xical entry for [gre at  X  grande] . Since these two lexical entries ar e identical at the featur e level, the RR m odule postulates a new binar y fea-ture, say feat1 2 , which serves the purpose of distin-guishing bet ween two words that are otherwise identical (according to o ur lexicon): Now the RR m odule moves on to process the next action in the Correction Instance and the first step is to look at the parse trace output b y the MT sy s-tem , so that the grammar rule responsible for the error can be identified: 
At this point, the sy stem extracts the relevant rule (NP,8) f rom the grammar, and h as two op-tions, either to make the r equired changes directly onto the origi nal rule (REFINE) or to make a copy of the origi nal rule and modif y the cop y (BIFUR-CATE). If th e sy ste m ha s correctly applied the rule in the past (perhaps becau se users have evaluated the translation pair  X  She saw a dan gerous man  X  Ella vio un hombre peligroso  X  as corre ct), then the RR module opts for the BIFURCATE operation. In this case, the RR module makes a copy of the original rule (NP,8) and then m odifies the copy (NP,8 X ) by flipping the order of the no un and ad-jective constituents, as indicated by the user. This rule needs to unif y with  X  X ran X  but not with  X  X rande X , an d so the RR module proceeds to add the constraint that the Spa nish adjective (now y 2) needs to have the feat1 with value +: 
These two re fine ments re sult in the MT sy stem generating the desired tra nslation, namely  X  Gaud X  era un gran artista  X  and not the previous incorrect translation. B ut can the syste m also eli minate other incorrect tran slations automatically ? In addition to generating th e correct translation, we would also like the RR module to pr oduce a refin ed grammar that is as tig ht as possible, given the data that is available. Si nce the sy stem alr eady has the infor-mation that  X  un artista gran  X  is not a correct se-quence in Spanish, the grammar can be further re-fined to also rule out this incorrect translation. This can be done by restricting the application of the general rule (NP,8) to just post-nominal adjectives, like  X  X rande X , which in this example are marked in the lexicon with ( feat1 =  X  ). The difference between this approach and mere post-editing is that the resulting refinements affect not only to the translation instance corrected by the user, but also to other similar sentences where the same error would manifest. After the refinements have been applied to the grammar in our example sentence, a sentence like  X  Irina is a great friend  X  will now correctly be translated as  X  Irina es una gran amiga  X , instead of  X  Irina es una amiga grande  X . We plan to evaluate the RR module on its ability to improve coverage and overall translation quality. This requires identifying sensible evaluation met-rics. Initial experiments have shown that both BLEU [Papineni et al . , 2001] and METEOR [La-vie et al . , 2004] can automatically distinguish be-tween raw MT output and corrected MT output, even for a small set of sente nces. In addition to the presence of the corrected translation in the lattice produced by the refined system, our evaluation metrics will also need to take into account whether the incorrect translation is now prevented from being generated and whethe r the lattice of alterna-tive translations increased or decreased. A decrease of lattice size would mean that the refinement also made the grammar tighter, which is the desired effect. The Rule Refinement process is not invariable. It depends on the order in which refinement opera-tions are applied. In batch mode, the RR module can rank Correction Instances (CI) in such a way as to maximize translation accuracy. Suppose that the first CI (CI1) triggers a bifurcation of a gram-mar rule, like the one we see in the example de-scribed in Section 5. After that, any CI that affects the same rule that got bifurcated, will only modify the original rule (NP,8) and not the copy (NP,8 X ). If the constraint that enforces determiner-noun agreement were missing from the original rule, say, the copy (NP,8 X ) would not have that con-straint added to it, and so another example with the pre-nominal adjective ex hibiting that agreement error would be required (CI2: * Irina es un gran amiga ), before the system added the relevant con-straint to NP,8 X . However, if we can detect such rule dependencies before the refinement process, then we can try to find an optimal ranking, given the current set of CIs, which should result in higher translation accuracy, as measured on a test set. 
Another interesting future direction is enhancing the Rule Refinement system to allow for further user interaction. In an interactive mode, the system can use Active Learning to produce minimal pairs to further investigate which refinement operations are more robust, treating the bilingual speaker as an oracle. We hope to explore the space between batch mode and a fully interactive system to dis-cover the optimal setting which allows the system to only ask the user for further interaction when it cannot determine the appr opriate refinement opera-tion or when it would be impossible to correctly refine the grammar and the lexicon automatically. 
