 In the domain of software, evolution refers to a process of continually updating software systems in accordance to changes in their working environments such as business requirements, regulations and standards. While some evolutions are unpredictable, many others can be predicted albeit with some uncertainty (e.g. a new standard does not appear overnight, but is the result of a long process).
The term software evolution has been introduced by Lehman in his work on laws of software evolution [17, 18], a nd was widely adopted since 90s. Recent studies in software evolutions attempt to understand causes, processes, and ef-fects of the phenomenon [2, 14, 16]; or focus on the methods, tools that manage the effects of evolution [19, 25, 28].

Requirement evolution has also been th e subject of significant research [12, 15, 24, 26, 31]. However, to our understanding, most of these works focus on the issue of management and consistency of requirements. Here, we tackle a more fundamental question of modeling uncertain evolving requirements in terms of evolution rules. Our ultimate goal is to support the decision maker in answer-ing such a question  X  X iven these anticipated evolutions, what is a solution to implement an evolution-resilient system? X .

This motivates our research in modeling and reasoning on a requirement model of a system which might evolve sometime in the future. We assume that stake-holders will know the tentative possible evolutions of the system-to-be, but with some uncertainty. For example, the Feder al Aviation Authority (FAA) document of the System Wide Information Management (SWIM) for Air Traffic Manage-ment (ATM) lists a number of potential alternatives that subject to other high-level decisions ( e.g., the existence of an organizational agreement for nation-wide identity management of SWIM users). Such organization-level agreements do not happen overnight (and may shipwreck at any time) and stakeholders with expe-rience and high-level positions have a clear visibility of the likely alternatives, the possible but unlikely solutions, and the politically impossible alternatives.
Our objective is to model the evolution of requirements when it is known to be possible, but it is unknown whether it would happen: the known unknown . 1.1 The Contributions of This Paper We set up a game-theoretic foundation for modeling and reasoning on evolution-ary requirement models:  X  A way to model requirement evolutions in terms of two kinds of evolution  X  A game-theoretic based explanation for probabilities of an observable  X  Two quantitative metrics to help the designer in deciding optimal things to This paper is started by a sketch of a case study (  X  2). To our purpose, we only focus on requirements of a part of the system-under-study. We distinguish which requirements are compulsory, and which are optional at design time. Based on these, we construct simple evolution scenario to illustrate our approach in subsequent sections, i.e. some compulsory requiremen ts become obsoleted, and some optional ones turn to be mandatory.

Then, we discuss how to model requirement evolution (  X  3) using evolution rules and probabilities of evolution occurrences. We employ the game-theoretic interpretation to account for the semantic of probabilities.

We also introduce two quantitative metrics to support reasoning on rule-based evolutionary requirement models (  X  4). The reasoning is firstly performed on a simple scenario. Then we show a programmatic way to adapt the technique to a more complex scenario ( e.g., large model, multiple evolutions) (  X  5).
In addition, we discuss current limits of our work, but not the approach, as well as our plan to address them (  X  6). Finally, we review related works (  X  7) and conclude the paper(  X  8). Throughout this work, to give a clearer understanding of the proposed approach we draw examples taken from the design architecture of SWIM [23, 7] in ATM.
SWIM provides a secure, overarching, net-centric data network, and intro-duces a Service-Oriented Ar chitecture (SOA) paradigm for airspace manage-ment. The United States FAA [7] has proposed a logical architecture of SWIM which consists of several function blocks, among which we choose to consider the Security Services block. At high level analysis of Security Services, there are five security areas: i) Enterprise Information Security System (ISS-ENT), ii) Bound-ary Protection ISS (ISS-BP), iii) SWIM Core ISS, iv) National Air Space (NAS) End System ISS, and v) Registry control. To avoid a detailed discussion on the architecture of SWIM Secure Services, which are not main topic of this work, while providing enough information for illustrating our work we refine our scope of interest on two areas: ISS-ENT and ISS-BP.  X  ISS-ENT includes security requirements that are provided as part of an  X  ISS-BP includes requirements with regard to control connections and in-Table 1 lists high level requirements of ISS-ENT and ISS-BP. For convenience, each requirement has a corresponding id entifier: two characters for the security area (RE -stands for ISS-ENT requirements, RB -stands for ISS-BP ones), and a sequence number. There ar e compulsory requirements ( i.e. they are es-sential at the time the system is designed) and optional ones ( i.e. they can be ignored at present, but might be critical sometime in the future). Solutions for these requirements are listed in Table 2. Each solution has an IDentifier, a short description and a checklist of requirements that it can fulfill. In this section, we describe how we model evolution, which essentially affects to any further analysis. We capture evolutions by classifying them into two groups: controllable and observable . Furthermore, we include in this section the game-theoretic account for probability. 3.1 Evolution on Requirement Model: Controllable and Observable Stakeholder requirements, mostly in textual format, are their wishes about the system-to-be. Analyzing requirements in such format is difficult and inefficient. Designer thus has to model requirements and design decisions by using various approaches ( e.g., model-based, goal-based) and techniques ( e.g., DFD, UML).
Generally, a requirement model is a set of elements and relationships, which depend on particular approach. For instance, according to Jackson and Zave [30], model elements are Requirements , Domain assumptions , Specifications ; in a goal-based model ( e.g., i*), elements are goals, actors and so on.

Here we do not investigate any specific requirement model ( e.g., goal-based model, UML models), nor go to details about how many kinds of element and relationship a model would have. The choic e of a one X  X  favorite model to represent these aspects can be as passionate as the choice of a one X  X  religion or football team, so it is out of scope. Instead, we treat elements at abstract meaning, and only be interested in the satisfaction relationship among elements. In our work, we define the satisfaction relationship in terms of usefulness. That an element set X is useful to another element set Y depends on the ability to satisfy (or fulfill) Y if X is satisfied. We define a predicate useful(X, Y) which is true (1) if X can satisfy all elements of Y, otherwise false (0). The implementation of useful depends on the specific requirement model. For examples:  X  Goal models [20]: useful corresponds to Decomposition and Means-end re- X  Problem frames [13]: useful corresponds to requirement references and domain For evolutionary software systems which may evolve under some circumstances ( e.g., changes in requirements due to changes in business agreements, regula-tions, or domain assumption), their requirement models should be able to ex-press as much as possible the information about known unknowns i.e. potential changes. These potential changes are analyzed by evolution assessment algo-rithms to contribute to the decision making process, where a designer decides what would be in the next phase of the development process.

Based on the actor who can decide which evolution would happen, we cate-gorize requirement evolutions into two classes:  X  controllable evolution is under control of designer to meet high level require- X  observable evolution is not under control of designer, but its occurrence can Controllable evolutions, in other words, are designer X  X  moves to identify differ-ent design alternatives to implement a system. The designer then can choose the most  X  X ptimal X  one based on her experience and some analyses on these alternatives. In this sense, controllable evolution is also known as design choice.
Observable ones, in contrast, correspond to potential evolutions of which real-ization is outside the control of the designer. They are moves of reality to decide how a requirement model looks like in the future. Therefore, the stakeholder and designer have to forecast the reality X  X  choice with a level of uncertainty. The responses are then incorporated into the model.

We capture the evolution in terms of evolution rule. We have controllable rule and observable rule corresponding to controllable and observable evolution. Definition 1. A controllable rule r c is a set of tuples RM, RM i that consists of an original model RM and its possible design alternative RM i . Definition 2. An observable rule r o is a set of triples RM, p i ,RM i that con-sists of an original model RM and its potential evolution RM i . The probability that RM evolves to RM i is p i . All these probabilities should sum up to one.
Fig. 1 is a graphical representation of evolution rules taken from SWIM case study. Left, Fig. 1(a) describes a controllable rule where a requirement model containing IKMI (RE1) has four design choices: A, B1, B2, and B4 (see Table 1 and Table 2). Right, Fig. 1(b) shows that the initial model ISS-ENT-1 (including RE1 and RE4) can evolve to ISS-ENT-2 (including RE1 to RE4), or remain unchanged with probabilities of  X  and 1  X   X  . These rules are as follows: 3.2 Game-Theoretic Account for Probability Here, we discuss about why and how we employ game-theoretic (or betting interpretation) to account for probabilities in observable rules.

As mentioned, each potential evolution in an observable rule has an associ-ated probability; these probabilities sum up to 1. However, who tells us? And what is the semantic of probability? To answer the first question, we, as sys-tem Designers, agree that Stakeholder will tell us possible changes in a period of time. About the second question, we need an interpretation for semantic of probability.

Basically, there are two broad categories of probability interpretation, called  X  X hysical X  and  X  X vidential X  probabilities. Physical probabilities, in which fre-quentist is a representative, are associ ated with a random process. Evidential probability, also called Bayesian probability (or subjectivist probability), are considered to be degrees of belief, defined in terms of disposition to gamble at certain odds; no random process is involved in this interpretation. To account for probability associated with an observable rule, we can use the Bayesian probability as an alternative to the frequentist because we have no event to be repeated, no random variable to be sampled, no issue about measurability (the system that designers are going to build is often unique in some respects). However, we need a method to calculate the value of probability as well as to explain the semantic of the number. Since probability is acquired from the requirement eliciting process involving the stakeholder, we propose using the game-theoretic method in which we treat probability as a price. It seems to be easier for stakeholder to reason on price (or cost) rather than probability. The game-theoretic approach, discussed by Shafer et al. [27] in Computational Finance, begins with a game of three players, i.e. Forecaster, Skeptic, and Re-ality. Forecaster offers prices for tickets (uncertain payoffs), and Skeptic decides a number of tickets to buy (even a fractional or negative number). Reality then announces real prices for tickets. In this sense, probability of an event E is the initial stake needed to get 1 if E happens, 0 if E does not happen. In other words, the mathematics of probability is done by finding betting strategies.
In this paper, we do not deal with stock market but the design of evolving software, i.e. we extend it for software design. We then need to change rules of the game. Our proposed game has three players: Stakeholder , Designer ,and Reality . For the sake of brevity we will use  X  X e X  for Stakeholder,  X  X he X  for Designer and  X  X t X  for Reality. The sketch of this game is denoted in protocol 1. Protocol 1 Game has n round, each round plays on a software C i FOR i = 1 to n
The game is about Stakeholder X  X  desire of having a software C .HeasksDe-signer to implement C , which has a cost of M $. However, she does not have enough money to do this. So she has to borrow money from either Stakeholder or National Bank with the return of interest (ROI) p or r , respectively.
Stakeholder starts the game by announcing p which is his belief about the minimum ROI for investing M $on C . In other words, he claims that r would be greater than p .If M equals 1, p is the minimum amount of money one can receive for 1$ of investment. Stakeholder shows his belief on p by a commitment that he is willing to buy C for price (1 + p ) M if Designer does not believe him and borrow money from someone else.

If Designer believes Stakeholder, she will borrow M from Stakeholder. Later on, she can sell C to him for M (1 + r ) and return M (1 + p ) to him. So, the final amount of money Designer can earn from playing the game is M ( r  X  p ). If Designer does not believe Stakeholder, she will borrow money from National Bank, and has to return M (1 + r ). Then, Stakeholder is willing to buy C with M (1 + p ). In this case, Designer can earn M ( p  X  r ).

Suppose that Designer has an initial capital of K 0 . After round i-th of the game, she can accumulate either K i = K i  X  1 + M ( r  X  p )or K i = K i  X  1 + M ( p  X  r ), depend on whether she believes Stakeholder or not. Designer has a winning strategy if she can select the values under her control (the M $) so that she always keeps her capital never decrease, intuitively, K i &gt; = K i  X  1 for all rounds.
The law of large numbers here corresponds to say that if unlikely events happen then Designer has a strategy to multiply her capital by a large amount. In other words, if Stakeholder estimate s Reality correctly then Designer has a strategy for costs not to run over budget. One of the main objectives of modeling evolution is to provide a metric (or set of metrics) to indicate how well a system design can adapt to evolution. Together with other assessment metrics, designe rs have clues to decide what an  X  X ptimal X  solution for a system-to-be is.

The major concern in assessment evolution is answering the question:  X  X hether a model element (or set of elements) becomes either useful or useless after evolu-tion? X . Since the occurrence of evolution is uncertain, so the usefulness of an ele-ment set is evaluated in term of probability. In this sense, this work proposes two metrics to measure the usefulness of element set as follows.
 Max Belief. (MaxB): of an element set X is a function that measures the max-Residual Risk. (RRisk): of an element set X is the complement of total belief Given an evolutionary requirement model RM = RM, r o, r c where r controllable rule, the calculation of max belief and residual risk is illustrated in Eq. 1, Eq. 2 as follows. where S is set of potential evolutions in which X is useful.

One may argue about the rationale of these two metrics. Because he (or she) can intuitively measure the usefulness of an element set by calculating the Total Belief which is exactly the complement of our proposed Residual Risk . However, using only Total Belief (or Residual Risk ) may mislead designers in case of a long-tail problem.

The long-tail problem, firstly coined by Anderson [1], describes a larger pop-ulation rests within the tail of a normal distribution than observed. A long-tail example depicted in Fig. 2 where a requirement model RM might evolve to several potential evolutions with very low probabilities (say, eleven potential evolutions with 5% each), and another extra potential evolution with dominat-ing probability (say, the twelfth one with 45%). Suppose that an element A appears in the first eleven potential evolutions, and an element B appears in the last twelfth potential evolution. Apparently, A is better than B due to A X  X  total belief is 55% which is greater than that of B, say 45%. However, at the end of the day, only one potential evolution becomes effective ( i.e. chosen by Reality) rather than  X  X everal X  potential evolutions are together chosen. If we thus consider every single potential evolution to be chosen, the twelfth one (45%) seems to be the most promising and Max Belief makes sense here. Arguing that A is better than B or versa is still highly debatable. Ones might put their support on the long tail [1], and ones do the other way round [5]. Therefore, we introduce both Residual Risk and Max Belief to avoid any misleading in the decision making process that can be caused when using only Total Belief.

For a better understanding of Max Belief and Residual Risk , we conclude this section by applying our proposed m etrics to the evolution of SWIM Security Services discussed in previous section. In Fig. 3, here we have an initial re-quirement model RM0(ISS-ENT-1,ISS-BP-1) that will evolve to RM1(ISS-ENT-2,ISS-BP-1), RM2(ISS-ENT-1,ISS-BP-2), and RM3(ISS-ENT-2,ISS-BP-2) with probabilities of 28%, 18% and 42%, respectively. There are 12% that RM0 stays unchanged. Each requirement model is represented as a bubble in which there is a controllable rule with several design alternatives. Each design alternative is an element set represented as a rounded rectangle that contains elements (such as A, D, and G) to support (fulfill) requirem ents of that requirement model.
Table 3 shows some examples, where the first column displays element sets, and the two next columns show values of max belief and residual risk. Notice that the max belief and residual risk in the first row, where the element set is {
A, D } ,are n/a which means that we are unable to find any potential evolution that { A, D } can support all top requirements.

In Table 3, { B 3 ,D,E,G } and { B 2 ,D,E,F,G } seem to be the best choices, since they have a high max belief (42%) and low residual risk (0%). The zero residual risk means these element sets are surely still useful after evolution. If the cost of implementation is the second criteria and assume that each element has equal cost, then { B 3 ,D,E,G } seems to be better. If a model is too large and complex, instead of dealing with the evolution of the whole model, we can consider evolution in each subpart. If a subpart is still too large and complex, we can recursively divide it into smaller ones, each with its local evolution rule, until we are able to deal with.
We then need to combine these local rules together to produce a global evo-lution one for the whole model. For simplicity, we assume that: ASS-1: Independence of evolutions. All observable rules are independent. ASS-2: Order of evolutions. Controllable evolutions are only considered af-As discussed, observable rules are analyzed on independent subparts. Prevail-ing paradigms of software development ( e.g., Object-Oriented, Service-Oriented) encourage encapsulation and loosely coupling. Evolutions applying to subparts, therefore, are often independent. Neverth eless, if there are two evolution rules which influent each other, we can combine them into a single one. We assume that dependent evolutions do happen, but not a common case. Hence manual combination of these rules is still doable.

The second assumption is the way we deal with controllable rules. If we apply controllable rules before observable ones, it means we look at design alternatives before observable evolutions happen. This makes the problem more complex since under the effect of evolution, some design alternatives are no longer valid, and some others new are introduced. Here, for simplicity, we look at design alternatives for evolved requirement models that will be stable at the end of their evolution process.

After all local evolutions at subparts are identified, we then combine these rules into a global evolution rule that applies to the whole model. The rationale of this combination is the effort to reuse the notion of Max Belief and Residual Risk (  X  4) without any extra treatment. In the following we discuss how to combine two independent observable evolution rules.
 Given two observable rules: Let r o is combined rule from r o 1 and r o 2 ,wehave:
Fig. 4 illustrates an example of combining two observable rules into a single one. In this example, there are two subparts of SWIM Security Service: ISS-ENT and ISS-BP. The left hand side of the figure displays two rules for these parts, and in the right hand side, it is the combined rule.

In general case, we have multiple steps of evolution i.e. evolution happens for many times. For the ease of reading, step 0 will be the first step of evolution, where no evolution is applied. We use RM d i to denote the i-th model in step d , and r od,i to denote the observable evolution rule that applies to RM d i , i.e. r od,i takes RM d i as its original model.

The multi-step evolution begins with an original model RM 0 1 . This model can evolve to one of the potential evolutions RM 1 i . In the second step, each RM 1 i then also evolves to one of many potential evolutions RM 2 j . The evolution stops after k steps. If we represent a model as a node, and connect a model to its potential evolutions as we have done as aforementioned, then we have a tree-like graph, called evolution tree with k -depth.

Fig. 5 illustrates a two-step evolution, in which observable rules are denoted as dotted boxes. The original model lays on top part of a box, and all potential evolutions are in sub boxes laid at the bo ttom. There are direct ed edges connect-ing the original model to potential evolutions. The label on each edge represents the probability such that original model evolves to target model.

In Fig. 5, an initial requirement model RM 0 1 evolves to either RM 1 1 , RM 1 2 or RM 1 3 . Likewise, RM 1 i evolves to RM 2 j , where i=1..3 and j=1..9. Here, we have a ternary complete tree of depth 2 . Generally, the evolution tree of a k -step consecutive evolution is a complete k -depth, m -ary tree.

We can always collapse a k -step evolution into an equivalent 1-step one in terms of probability by letting the original model evolve directly to the very last models with the probabilities that are multiplication of probabilities of interme-diate steps. Therefore, any k-step evolution has an equivalent 1-step evolution. Hence all analyses discussed in  X  4 are applicable without any modification. Obviously there are limitations in this work:  X  Real world applicability. Even though we work on a real world case study,  X  Obtaining probability. Since evolution probabilities are obtained from stake- X  Independence of evolution. Complex models may require many probabilities A majority of approaches to software evolution has focused on the evolution of architecture and source code level. Ho wever, in recent years, changes at the requirement level have been identified as one of the drivers of software evolu-tion [4, 12, 31]. As a way to understand how requirements evolve, research in PROTEUS [24] classifies changing requirements (that of Harker et al [11]) into five types, which are related to the develop ment environment, stakeholder, devel-opment processes, requirement understanding and requirement relation. Later, Lam and Loomes [15] present the EVE framework for characterizing changes, but without providing specifics on the problem beyond a meta model. Several approaches have been proposed to support requirements evolution. Zowgi and Offen [31] work at meta level logic to capture intuitive aspects of managing changes to requirement models. Their approach involves modeling requirement models as theories and reasoning changes by mapping changes be-tween models. However, this approach has a limitation of overhead in encoding requirement models into logic.

Russo et al [26] propose an analysis and revision approach to restructure re-quirements to detect inconsistency and manage changes. The main idea is to allow evolutionary changes to occur first and then, in the next step, verify their impact on requirement satisfaction. Al so based on this idea, Garcez et al [4] aim at preserving goals and requirements during evolution. In the analysis, a spec-ification is checked if it satisfies a given requirement. If it does not, diagnosis information is generated to guide the mo dification of specification in order to satisfy the requirement. In the revision, the specification is c hanged according to diagnosis information generated. Similar to Garcez et al, Ghose X  X  [9] frame-work is based on formal default reasoning and belief revision, aims to address the problem of inconsistencies due to requirement evolution. This approach is supported by automated tools [10]. Also relating to inconsistencies, Fabrinni et al [6] deal with requirement evolution expressed in natural language, which is challenging to capture precisely requirement changes. Their approach employs formal concept analysis to enable a system atic and precise verification of consis-tency among different stages, hence, controls requirement evolution.
Other notable approaches include Brier et al. X  X  [3] to capture, analyze, and understand how software systems adapt to changing requirements in an organiza-tional context; Felici et al [8] concern wit h the nature of requirements evolving in the early phase of systems; Stark et al [29] study the information on how change occurs in the software system and attempt to produce a prediction model of changes; Lormans et al [21] use a formal requirement management system to motivate a more structural approach to requirement evolution. We have discussed a rule-based representa tion of evolutions on requirement mod-els. We proposed game-theoretic approach to explain the uncertainty of evolu-tions. We also introduced two notions of max belief and residual risk to reason on evolutionary models, in which the higher max belief and lower residual risk models seem to be more evolution-resilient than others. Together with other analyses ( e.g., cost, risk), these values can hel p designers in making decision.
During the discussion, we provided many examples taken from a real world project, SWIM. These examples not only help to explain better our idea, but also show the promising applicability of our approach.

For future work, we plan to instantiate our approach to a concrete modeling language ( e.g., goal-based language) and apply to a more convincing case study. We shall interact with stakeholder and designers, show them our approach and get their feedback to validate the usability of proposed approach.

