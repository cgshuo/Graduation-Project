 Predicting and ranking future influence of scientific articles has increasingly at-tracted attention of young researchers. The citation of articles change all the time since the papers keep getting new citations every day. So, it is a big challenge in literature mining for the dynamic characteristics of the evolving literature network. Meanwhile, choosing influencial papers may be innovative for young research to deeply study. Moreover, the accurate prediction of the future impact Motivated by these real applications, we focus on predicting and ranking the future influence of scientific articles, especially for the newly published articles. portance of scientific articles instead of their future influence. Traditional ranking models can be divided into citation-count-based [5,11] methods and graph-based ranking [12, 18]. The h-index [6], g-index [4], and s-index [13] are proposed based on citation-count-based methods. But these approaches focus on computing the quality of scientific articles by counting citations. The graph-based approach leverage the network information to ranking publications. Zhou.et al [18] pro-posed to combine citation, authorship, and co-authorship network to rank papers and author. Fig. 1: Papers X  corresponding average citation counts from 1990 to 2011 in 2016 of ArnetMiner data set.
 is failed to measure newly publications due to the neglect of using published time. Newly published papers without many citations would not recommend to users in the website. Moreover, with the development of scientific research level, the average citation rate of literature has been greatly reduced. Figure 1 shows the the papers X  corresponding average citation counts from 1990 to 2011 in 2016 of ArnetMiner data set. Due to the rapid growth in the number of papers, the newly published literature is not well known to cite. Another issue is that the text information of the papers is largely ignored, while the texts of the papers may provide clues to judge their innovativeness and novelty. It is based on the intuition that innovative papers may contain more novel text features. For example, the papers, containing famours words in  X  X witter X  or  X  X acebook X , become increasingly popular in recent publications. So, how to modeling the time and text information of papers in the sensor of text feature words or pairs is the key point of our paper. For text sensitive modeling, how to find the latent relationship between the text of the current articles and the text of all the articles is also a challenge.
 dict and rank the future influence of publications by modeling their time and text (titles, abstracts and keywords), which used to calculate the innovativeness and importance of scientific articles separately. In time sensitive modeling, we adjust recent citation weights of papers according to an exponential decay func-tion in terms of time. In text sensitive modeling, we use a burst-detection-based method to measure the innovative degree of two kinds of text feature words and word pairs. Then for the plain and long characteristic of literature text, we nov-elty using topic model LDA to calculate the importance of text features, words and pairs.
  X  We propose a Time and Text Sensitive Ranking Model to predicting and  X  To modeling the text information of articles, we use the latent topic model  X  We conduct evaluation on the ArnetMiner data set to prove the performance The rest of the paper is organized as follows: Section 2 introduces related work; proposed model; Finally we conclude the paper in Section 5. There are many earlier efforts on scientific articles ranking. One of the Citation count methods proposed by Garield et al. [5], called the impact factor. It is a widely used method to measure the importance of scientific journals, although very simple. The impact factor calculate the average number of citation within a year according to the set of articles in a journal published during past two years. Impact factor is a statistic value, which is failed to rank the valuable of newly coming scientific articles by simply counting citations. Based on the citation count, several more complicated metrics are proposed, such as the h-index [6], g-index [4], and s-index [13]. In general Citation count methods consider articles popularity but ignore their future prestige.
 literature collection as a network by utilizing the structure information of the citation and establishing time information. There are many proposed researches computing the adjacency matrix, for example, Zhou et al. [18] used the mu-tual reinforcement between hubs and authorities mentioned in HITS algorithm, which took advantage of the citation network, the co-authors social network, and the authors social network. Chen et al. [2] and Ma.et al. [10] leveraged pager-ank algorithm to accurate the citation network of papers to access the relative importance of publications. Ding et al. [3] also proposed the ranking method to access the importance of publications based on the PageRank algorithm. More-over, Jiang et al. [7] proposed the MRR to co-rank the future popularity of four type objects: papers, authors, terms and venues through mutual reinforcement. higher score than newly articles. To use the temporal information, Walker et al. [15] proposed Citerank that uses the publication time of the articles and defines a random work o predict the number of future citation. Meanwhile Wang et al. [16] add the time information to the author-paper relationship to rank the future citation. However, the problem of these works is that the context information is not fully utilized in various literature network, leading to a lower ranking score of recent publications. The abstract information not only reflect the degree of innovation of scientific papers, but also the can overcome the problem of the lack of influence brought by the establishing time of this article. In our method, we propose a novel method that combines the establishing time information and context information to co-rank the scientific articles prestige. parts: time sensitive method and text sensitive model based on LDA. Section 3.1 introduces the extracting of text feature words and pairs and the burst-detection-based method in calculating the innotiveness of articles. In Section 3.2, we give the generative process of LDA in the weight of text features as the importance dgree of articles.
 Fig. 2: The framework of TTRM: The yellow parts show the process of innova-tiveness degree; The blue parts show the preocess of importance degree. model the text semantic analysis to help to improve the predicting and ranking performance. 3.1 Text Features Extraction In this section, we use text feature words and word pairs regarded as the sen-sors of their innovativeness. In order to identify indicative text features, we also use the burst-detection-based method [9] to qualititatively measure the innova-problem that may contain more new text features such as new terminologies or new words, which is more likely to get citations. Which kinds of text features we will extract and how to measure their innovativeness will be described next. especially in the title and abstracts of papers. As mentioned in introduction, most of these word, such as  X  X witter X  and  X  X eibo X , which are relatively new to traditional topics. We also use the co-occurring word pairs as text features. Although separate words may be not new, the co-occurring word pairs may be a new topic. For example  X  X ext mining X  may imply the new topic of deep learning or semantic analysis.
 { x 1 ,x 2 ,....,x n } . Each text feature pairs and words x i can be denoted as a tripe { x innovativeness degree of feature x i . 3.2 Time Sensitive Modeling Then the innovativeness measure of the text feature pairs is proposed by a burst-detection-based method. Burst detection is used in event detection in social media [17]. In event detection , a term is defined as bursty if it frequently occurs in a specified time line. Similarly, we define that papers X  text feature is innovative if its frequency increases remarkably in a specified time window. Our model for ranking is based on the assumption that influential articles contain a certain proportion of innovative and important feature pairs. The more feature pairs in a scientific articles indicate a higher prestige in the future. So how to determin the proportion of feature pairs has become a problem.
 articles. Then the distribution of frequency of text features can be presented as: represent the probability of a given number of events occurring in a fixed interval of time. Where x i denote the frequence of text feature  X  i , and is the mean frequency of x i . In other word, the x i denote the times of feature i appearing in the papers published in j year, and  X  i is the average appearing times of cluster in all the years. The maximum likelyhood estimation of  X  i is the sample mean  X   X  i = 1 n P n i =1 x i , and the maximum likelihood estimation of all the features is  X  windows &lt; t j  X  1 ,t j &gt; as: timated mean frequency of all the text features. u is the number of previous time winsows, and  X  is the time-dacaying parameter. There is three parts in the measurement: ;
P frequency, and the frequencies in its nearest past s time windows. u is a param-; e  X   X  ( t j  X  t 0 ) is a time-weighted exponential function, which is used to highlight the very early features occutting recently. Definition1-3 give the details of time modeling of text features, the innovativeness degree of one paper a m is the sum of all features. 3.3 Text Sensitive Modeling in LDA Measuring importance of text features in the academic field is an open prolems. Previous studies use TF-IDF and other statistical methods to calculate the im-portance, but these approaches ignore the semantic analasis of papers. In this paper, we use the latent topic model LDA to mining the importance of each features.
 information from text corpus [1].
 multinomial topic distribution  X  for document d under the Dirchlet prior with paprameter  X  . (2)For the word in document d, one choose a topic z by a multi-nomia topic distribution of  X  . (3)The word is generated accroading to word distributions  X  over topic, which is a multinomial under a Dirchlet prior with papramete  X  mation. By LDA, we obtain the text feature words and pairs distribution  X  to latent topics and topics distribution  X  to each paper. In  X  matrix, we do the first matching to find latent topic with max probabilities, to which the current ond matching to find the probality of current paper allocated to matched topic:  X  3. Finally, the future influence of papers P m is equation 4.
 inforcing relationship between existing academic literature and papers X  quality. Before the judgment of the importance of the article, if proposed model can understand the meaning of the article first, then the importance will be more accurate.
 lows:  X  Input: LDA; A m = { a 1 .a 2 ,...,a m } ; iteration 1000 times, K =100,  X  = 0.1  X  Matching between text features and the topic-word  X  and document-topic  X  Output: The importance degree of the literature articles a m 4.1 Experimental Settings The proposed model uses the publicly available dataset, ArnetMiner 1 , to eval-uate the proposed TTRM. It contains papers and corresponding citations pub-lished before 2011. We select the metadata of each paper contain paper ID, abstract, publication year and citation count. The text information containing abstract, title and key words, which enable us to extract and utilize text fea-tures. Before using, the papers with no citations and do not cite other papers are removed, since it is difficult to evaluate the influence of papers without ci-tations. Meanwhile, the metadata for the old papers are incomplete, so that we also remove the papers published after 1990. After processing there are remain-ning 809,765papers and 1,275,671 citations. The stop words are removed and the words pairs are adding the short line munually in content preprocess. In this re-search, we compare our ranking method to PageRank (PR:citation-based ranking algrithom), Mutual Reinforcement Rank(MRR: graph-based ranking algrithom) and TTRM-T(proposed model without temporal information), whose limitations are discussed in section 2. 4.2 Metric and Evaluation Paper Ranking We used a well-known metric, the Discounted Cumulated Gain(DCG) [16], in order to compare the four different rankings of papers, as following: and submitted for human judgment. 7 CS graduate student volunteers partici-pated in evaluation and there are 3 feedbacks for one query in average. They are required to rate the ranked papers with a score from 0 to 2, where 0 represents non relevance, 1 represents marginal relevance, and 2 represents high relevance. The assumption in DCG is the lower the ranked position of a paper the less by users. To show the effectiveness of proposed model, entire dataset and the artifical intelligence dataset are used to evaluate ranking. Figure 3 shows that our proposed method outperforms all other baseline methods. This is because user generated text reflects the mutual reinforcing relationship between users X  expertise and papersquality, which is modeled by a sementic topic model LDA. This result also gives us an understanding of the impact of incorporating the user generated content and that of incorporating the temporal factor.
 Table 1 as the statistic information for Figure 3. Both the curve and statistics show that our algorithm signiflcantly outperforms the other three algorithms for documents ranked after rank 10. Table 1: The DCG score for the four ranking-n algorithms in entire dataset Convergence Analysis In order to measure the rank correlation by using rank accuracy metrics, we study the convergence of the proposed ranking model by measuring the partial orderings. Here, we use the Kendall  X  [8] to calculate coefficient of the two ranking lists to measure how similar the two ranking lists are. The Kendall  X  coefficient is defined as: The process of it can be described as:  X  N ordered is the number of elements if both x i &gt; x j and y i &gt; y j or if both  X  N disordered is the number of elements if both x i &gt; x j and y i &lt; y j or if both Figure 4 shows the increase trends of  X  coefficients with the increase of iteration number for papers. One can see that the proposed TTRM algorithm converges very fast:  X  coefficients of both paper ranking tend to become stable after about 18 iterations. MRR is a strong baseline in ranking and predicting future prestige of articles. Fig. 5: Fit intensity curve of three models. For the TTRM-T is LDA model, it is no temporal characteristic to show the evolution of fit intensity. The red and respectively. Paper Predicting In order to test the ability of TTRM in predicting the influence of literature in the future. We first select 3,234 articles in 1995 as newly published article to be trained and then calculat their future impact in each year from 1996 to 2011 by TTRM. The future influence calculates by TTRM in 2011 is the ground truth results. In other words, P m, t =2011 value as the fitting target. in time sequence in Figure 5 for baseline models. The intuition is based on the text information is variation in each year. For eample, one paper publised in 1995, whose importance degree calculated in 1996 is different to in 2000, since the incremental of articles in each year. This assumption is derived that each article has published and retrieval cycle, and these new methods and technologies have been tested and validated, whose influence is increasing and regional stability [12].
 information to balance the importance of new text features. With the increment of literature quality. Meanwhile, MRR algorithm is a powerful baseline in this paper, which uses TF-IDF in the importance of text features computing. TF-IDF statistically calculates word frequency, which is narrow since that new method Table 2 shows the first year after publication in 1995 of the fitting stability and optimal intensity. TTRM gives better fitin 6th years. PR takes a long time to get a btter fit with real prediction.
 Table 2: Table 2 shows the first year of the fitting stability and optimal intensity after publication in 1995.
 In this paper, we proposed a framework called Time and Text sensitive Ranking Model (TTRM) to accurately predict the future influence and ranking literature articles. For young researches, it is important to judege the future influence of newly published papers and select a valuable research direction. TTRM extracts text feature words and pairs of papers as the sensors of their innovativeness dgree by burst-detection-based method. We also use the latent topic model LDA to measure the importance of text feature words and pairs. Our experiments show the accurately prediction and ranking of future influence of literature articls in ArnetMiner dataset. In future, we are going to prove our model in more literatures filed to improve the generalization performance of our model.
