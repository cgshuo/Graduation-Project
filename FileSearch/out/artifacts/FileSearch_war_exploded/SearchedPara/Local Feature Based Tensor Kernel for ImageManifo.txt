 Conventionally, raster grayscale images can be represented by vectors by stack-ing pixel brightness row by row. It is convenient for computer processing and storage of images data. However, it is not natural for recognition and percep-tion. Human brains are more likely to handle images as collections of features laying on a highly nonlinear manifold [ 4]. In recent research, learning image manifold has attracted great interests in computer vision and machine learning community. There are two major strategies towards manifold learning for within class variability, appearance manifolds from different views [5]: (1) Local Feature based methods; and (2) Key Points based methods.

There exist quit a few feature extraction algorithms such as colour histogram [6], auto-associator [7], shape context [8] etc. Among them, local appearance based methods such as SIFT have draw n a lot of attention as their success in generic object recognition [3]. Never theless, it was also pointed out in [3] that it is quite difficult to study the image manifold from the local features point of view; moreover, the descriptor itself throws an obstacle in learning a smooth manifold because it is not in vect or space. The authors of [3] proposed a learning framework called Feature Embe dding (FE) which takes local features of images as input and constructs an interim layer of embedding in metric space where the dis/similarity measure can be easily defined. This embedding is then utilized in following process such as classification, visualization etc. As another main stream, key points based methods have been successful in shape modeling, matching and recognition, as demonstrated by the Active Shape Models (ASM) [9] and the Shape Contexts [10].

Generally speaking, key points focus on s patial information/arrangement of the interested objects in images while loca l features detail object characteriza-tion. An ideal strategy for image manifold learning shall incorporate both kinds of information to assist the learning procedure. Actually the combination of both spatial and feature infor mation has been applied in o bject recognition in recent work, e.g., visual scene recognition in [11]. This kind of approaches has close link with the task of learning from multiple sources, see [12,13]. Kernel method is one of the approaches which can be easily adapted to the multiple sources by the so-called tensor kerne ls [14] and additive kernels [15,16]. The theoretical assumption is that the new kernel function is defined over a tensor space de-termined by multiple source space. In our scenario, there are two sources, i.e., the source for the spatial, denoted by y , and the source for the local feature, denoted by f . Thus each hyper  X  X eature X  is the tensor y  X  f . For the purpose of learning image manifold, we aim at constructing appropriate kernels for the hyper features in this paper.

The paper is organized as follows. Section 2 proposes tensor kernels suit-able for learning image manifold. Section 3 gives a simple introduction to the Twin Kernel Embedding which is used for manifold embedding. In Section 4, we present several examples of using propo sed tensor kernels for visualization. In the sequel, we assume that a set of K images { P k } K k =1 is given, each of which P k is actually represented by a data set a s a collection of tensors of spatial and y i and N k is the number of features extracted from P k . y feature in image k and { y k i  X  f k i } N k i =1 can be regarded as a tensor field.
A tensor kernel was implicitly defined in [3] based on two kernels, k y ( y i , y j ) and k f ( f i , f j ), which are for spatial space and fe atures space respectively and the kernel between two hyper features is defined as where i =1 , ..., N k ,j =1 , ..., N l and k, l =1 , ..., K . In other words, when two only the features, otherwise k p (  X  ,  X  ) focuses on only coordinates. If we denote K y as kernel Gram matrix of k y (  X  ,  X  )and K f , K p likewise. K p will have K y blocks in main diagonal and K f elsewhere.

A kernel is associated with a particula r feature mapping function from ob-ject space to feature space [15] and kernel function is the inner product of the images of the objects in feature space. There is seldom any proof that any two kernels share the same feature mapping and hence kernels are working on dif-ferent feature spaces. If we see kernels a s similarity measures [17], we conclude that every kernel represents an unique measure for its input. This leads to the observation that the above k p is problematic where two kernels are integrated together without any treatment. k y and k f operate on different domains, coor-dinates and features respectively. Thus the similarity of any two hyper features is determined by the similarity of either spatial or feature information while the joint contribution of two sources is totally ignored in the above construction of the tensor kernel. Thus a successive dimensionality reduction algorithm based on the above separated tensor kernels may erroneously evaluate the embeddings in a uninformed measure. Every feature in images will be projected onto this lower dimensional space as a point. However, under this framework, the relationships of projected features from one image are not comparable with other projected features from different images. As a consequence, the manifold learnt by the di-mensionality reduction is distorted and therefore not reliable and interpretable.
To tackle this problem, we need a universal kernel for the images bearing in mind that we have two sources of information, i.e. spatial information as well as feature description. Multiple sources integration property of tensor kernel [14] brings ho-mogeneous measurement for the similari ty between hyper features. What follows is then how to construct a suitable tenso r kernel. Basically, we have two options to choose from, productive and additive tensor kernel which are stated below As we can see, tensor kernel unifies the spatial and features information together in harmony. It is symmetric, positive semi-definite and still normalized.
We are particularly interested in the additive tensor kernel. The reason is that the productive tensor kernel tends to produce very small values thus forcing the Gram matrix to be close to identity matrix in practice. This will bring some numer-ical difficulties for dimensionality reduction. Additive tensor kernel does not have this problem. However, the additive tensor kernel k t defined in (2) takes into ac-count the spatial similarity between two different images which makes little sense in practice. So we adopt a revised version of additive tensor kernel as In both (2) and (3) we need to dete rmine two extra parameters  X  y and  X  f .Tothe best knowledge of the authors, there is no principal way to resolve this problem. In practice, we can optimize them using cross validation. Given a tensor kernel k t defined in either (2) or (3) and a set of images, a kernel matrix K t can be calculated. K t contains all the similarity information among hyper features contained in the given images. The matrix can then be sent to a kernel-based dimensionality reduction algorithm to find the embedding.
We start with a brief introduction of TKE algorithm and then proceed to image manifold learning with tensor kernel described in last section. In this section, for the sake of simplicity, we use o i  X  X  to denote the super feature data we are dealing with and x i the corresponding embeddings of o i .So o i could be an image P i as collection of features as we mentioned before. 3.1 Twin Kernel Embedding Twin Kernel Embedding (TKE) preserves the similarity structure of input data in the latent space by matching the similari ty relations represented by two kernel gram matrices, i.e. one for input data and the other for embedded data. It simply minimizes the following objective function with respect to x i  X  X  where k (  X  ,  X  ) is the kernel function on embedded data and k t (  X  ,  X  )thekernel function on hyper feature data of images. The first term performs the similarity matching which shares some traits with Laplacian Eigenmaps in that it replaces the W ij by k t (  X  ,  X  ) and the Euclidean distance on embedded data x i  X  x j 2 by k (  X  ,  X  ). The second and third terms are regularization to control the norms of the kernel and the embeddings.  X  k and  X  x are tunable positive parameters to control the strength of the regularization. The logic is to preserve the similarities among input data and reproduce them in lower dime nsional latent space expressed again in similarities among embedded data. k (  X  ,  X  ) is normally a Gaussian kernel, i.e. because of its analytical form and strong relationship with Euclidean distance. A gradient-based algorithm has to be employed for minimization of (4). The conjugate gradient (CG) algorithm [18] can be applied to get the optimal X which is the matrix of the embeddings X =[ x 1 ,..., x N ] . The hyper-parameters of the kernel function k (  X  ,  X  ),  X  and  X  , can also be optimized as well in the minimization procedure. It frees us from setting too many parameters. To start the CG, initial state should be provided. Any other dimensionality reduction methods could work. However, if the non-vectorial data applicability is desirable, only a few of them such as KPCA [19], KLE [20] would be suitable.

It is worth explaining the method of locality preserving in TKE. This is done will be artificially set to 0 if o j is not one of the k nearest neighbors of o i . The parameter k ( &gt; 1) in k -nearest neighboring controls the locality that the algorithm will preserve. This process is a kind of filtering that retains what we are interested while leaving out minor details. However, the algorithm also works without filtering in which case TKE turns out to be a global approach.
The out-of-sample problem [21] can be easily solved by introducing a kernel mapping as where K t is the Gram matrix of kernel k t (  X  ,  X  )and A is a parameter matrix to be determined. Substitute (6) to TKE and optimize the objective function with respect to A instead of X will give us a mapping from original space to lower dimensional space. Once we have the new input, the embedding can be found by and we denote O as collection of all the given data for training. This algorithm is called BCTKE in [22] where details were provided. 3.2 Manifold Learning Process An elegant feature of TKE is that it can handle non-vectorial data since in its objective function, it involves only the kernels that can accept non-vectorial in-puts. It is particularly useful in this case since the only available information about the images is the tensor kernel which is built on the local features rep-resented in non-vectorial form. In last section, we discussed the additive tensor kernel k t . For each hyper feature in every image expressed as y i  X  f i , we can find apoint x i in d dimensional space through TKE where d is pre-specified. It yields P k in the so-called feature embedding space.

This feature embedding space is only an interim layer of the final image man-ifold learning. The reason for it is to transform the information in form of local features to objects in metric space wh ere some distance can be easily defined. There are several distance metrics to eval uate two sets of coordinates [23]. Haus-dorff based distance is a suitable candidate since it handles the situation where the cardinalities of two sets are different which is common in real application. Once we get the distance between two sets o f coordinates, i.e. two images, we can proceed to manifold learning using TKE again. Suppose the distance is d (  X  P i ,  X  P j ), we revise the objective function of TKE as follows which differs from (4) in that the kernel k t (  X  ,  X  ) is replaced by a distance metric. We can still minimize (7) with respect to z i . The logic is when two images are close in feature embedding space, th ey are also close in the manifold.
Another easier way to learn the manifold using TKE is to convert the distance to a kernel by and substitute this kernel in (4) in TKE where  X  k is positive parameters. So we minimize the following objective function
As a conclusion of this section, we restate the procedures here. 1. We apply ten-sor kernel k t to the images as collections of hyper features; 2. Use TKE with K t to learn the feature mapping space and projections of the images i.e.  X  P i  X  X ; 3. Finally, we obtain the image manifold by using TKE again or other DR methods. In follow-ing experiments, we use KLE, KPCA for comparison. Actually, in step 2, we could use other methods which are kernel applicable such as KPCA, KLE etc. Interest-could be seen as a kernel Gram matrix on the original images and therefore the whole step 1 and 2 could be a kernel construction on histograms (collections of local features). The dimensionality of feature embedding space and image mani-fold could be detected using some automated algorithms such as rank priors [24]. If visualization is the purpose, 3D or 2D manifold would be preferable. We applied the tensor kernel and TKE to image manifold learning on several image data sets: the ducks from COIL data set, Frey faces and handwritten digits. They are widely available online for machine learning and image process tests. For TKE, we fixed  X  x =0 . 001 and  X  k =0 . 005 as stated in original paper. We chose Gaussian kernel for k x ,Eq.(5),asdescribedinSection3. Its hyperparameters were set to be 1 and they were updated in runtime. We used additive tensor kernel (3) and set  X  y =0 . 3and  X  f =0 . 7whichwere picked from doing the same experiment with different  X  y and  X  f repeatedly until best combination is found. It shows the preference to local features over coordinates. The dimensionality of feature embedding space d e and number of features extracted from images are maximized according to the capability of computational platform. For the demonstration purpose, we chose to visualize those images in 2D plane to see the structure of the data. 4.1 COIL 3D Images We used 36 128  X  128 greyscale images of ducks and extracted 60 features from each images. TKE projected all the feat ures to 80 dimensional feature embed-ding space. Since all the images are perfectly aligned and noise free, traditional methods like PCA, MDS can achieve good embedding using vectorial represen-tation. As we can see from Fig. 1, tensor kernel on local features can capture the intrinsic structure of the ducks, that is the horizontal rotation of the toy duck. The is revealed successfully by KLE which gives a perfect circle like embedding. The order of the images shows the rotation. TKE seems to focus more on the classification information. Its embeddi ng shows 3 connected linear components each of which represents different facing direction. KPCA tries to do the same thingasKLE,butnotassatisfactoryasKLE. 4.2 Frey Faces In this subsection, the objects are 66 images extracted from the whole data set with 1,965 images (each image is 28  X  20 grayscale) of a single person X  X  face. The data set was from a digital movie which is also used in [25]. Two parameters control the images, that is the face direction and expression. Ideally, there should be two axes in 2D plane for th ese two parameters respectively, one for face direction from left to right and one for face expression from happy to sad. However, the understanding like this is somewhat artificial. This may not even close to the truth. But we hope our algorithms can show some idea of these two dimensions. In this case, d e = 30 and 80 features were extracted from each image. The choice of d e reflects high computational cost of TKE which is a major drawback of this algorithm. As the number of samples grows, the number of objectives to be optimized in TKE increases linearly. So when the number of images doubled, d e has to be half for the limitation of computation resources.
In this case, KLE does not reveal any meaningful patterns (see Fig. 2). On the other hand, TKE X  X  classification property is very well exhibited. It successfully classifies happy and not happy expressions into two different groups. In each group, from top to bottom, the face direction turns from right to left. So we can draw two perpendicular axes on TKE X  X  result, horizontal one for mood, and vertical one for face direction. KPCA reveals similar pattern as TKE does. The only difference is that TKE X  X  result shows clearer cluster structure. 4.3 Handwritten Digits In this section, a subset of handwritten digits images was extracted from a binary alphadigits database which contains 20  X  16 digits of  X 0 X  through  X 9 X  and capital  X  X  X  through  X  X  X  with 39 examples in each class. It is from Algoval system (available at http://algoval.essex.ac.uk/). Because of limited resources of the computation platform, we used only the digits from 0 to 4 with 20 images per class. We extract 80 features from each image and casted them to d e =20 feature embedding space.

Compared with previous tw o experiments, this experiment is much harder for dimensionality reduction algorithms. It is not clear what the intrinsic dimension-ality is. If we choose too small dimension, DR methods will have to throw away too much information. As a matter of fact, we do not know what the manifold should be. The images of the digits are not simply governed by some parameters as we can see in previous experiments. So we could only expect to see clusters of digits which is a quite intuitive interpretation.

It is worth mentioning that for TKE plus tensor kernel, we use KPCA in the last step instead of TKE for computational difficulty. Fig. 3 shows results of final image manifold learnt by three different algorithms with tensor kernel. TKE shows good classification capability even clearer in this experiment. All classes have clear dominant clusters with some overlapping. Interestingly, by examining the visualization by TKE closely, we can see digit  X 1 X  class has two subclasses of two different types of drawing. They are p roperly separated. Moreover, because they are all  X 1 X  from the local feature point of view, these two subclasses are very close to each other whereby forms a whole digit  X 1 X  class. KLE does a very good job separating digit  X 1 X  from others . However, other classes are overlapped significantly. KPCA has clear  X 2 X  and  X 4 X  classes but the other classes were not distinguishable.

This experiment once again confirms th e classification ability of TKE and effectiveness of tensor kernel on local feat ures in depicting the structural rela-tionships between images in terms of classification, recognition and perception. In this paper, we proposed using tensor kernel on local features and TKE in image manifold learning. Tensor kernel provides a homogeneous kernel solution for images which are described as collect ion of local features instead of conven-tional vector representation. The most attractive advantage of this kernel is that it integrates multiple sources of information in a uniform measure framework such that the following algorithm can be applied without difficulty in theoretical interpretation.

TKE shows very strong potential in classification when it is used in con-junction with local feature focused ker nel, for example tensor kernel. So it is interesting to explore more applications of this method in other areas such as bioinformatics and so on. One drawback of TKE which may limit its application is its high computational cost. The number of parameters to be optimized is about O ( n 2 )where n is the product of target dimension and number of samples. Further research on whether some effici ent approximation is achievable would be very interesting.

