 We explore in this paper a practicably interesting mining task to retrieve frequent itemsets with memory constraint. As opposed to most previous works that concentrate on im-proving the mining e ffi ciency or on reducing the memory size by best e ff ort, we fi rst attempt to constrain the upper mem-ory size that can be utilized by mining frequent itemsets in this paper.
 Categories and Subject Descriptors: H.2.8 [Database Applications]: Data mining General Terms: Algorithms, Management Keywords: Frequent patterns, association rules, memory constraint
The discovery of frequent relationship among a huge data-base has been known to be useful in selective marketing, de-cision analysis, and business management. A popular area of its applications is the market basket analysis, which stud-ies the buying behaviors of customers by searching for sets of items that are frequently purchased together.

Unfortunately, discovering frequent itemsets su ff ers from an inherent obstacles, namely, the unbounded memory con-sumption. A large memory, which may not be prevalent in most computers nowadays, is in general required when the database is large or the minimum support is small. That will result in the serious "out of memory" system crash, making users shy away from executing the frequent itemset mining.
As a result, we in this paper attempt to discover fre-quent patterns in the presence of the memory constraint. Speci fi cally, the memory constraint does not mean that the memory consumption is small as claimed in previous works. We attempt to broaden the applicability of mining frequent itemsets towards the case that the available memory is lim-ited.

The contribution of this paper can be summarized: while previous works on mining frequent patterns mostly concen-trate on improving the mining e ffi ciency or on reducing the memory size by best e ff ort, we further investigate in this paper the important issue of mining frequent itemsets with the explicit memory constraint.

Let sup ( X ) denote the support of itemset X in the data-base D . Our goal in this paper is to discover frequent item-sets in the presence of the memory constraint. We resort to level-wise search algorithms to achieve such a goal. We then formally present the support distribution plot, which willprovideagoodperspectivetoanalyzetheproblemof mining top-k frequent itemsets.
 The support distribution plot: Given the support of each l -itemset, where l  X  1 , the support distribution plot will consist of lines, where the i th line presents the range of supports of all i -itemsets, and each i -itemset can be plotted in the i th line with respect to its support. Note that accord-ing to the downward closure property, the line with respect to i -itemsets will be shorter than the line with respect to j -itemsets, where i&gt;j .  X 
Note that, without loss of generality, the memory con-sumption of level-wise search algorithms is solely propor-tional to the number of itemsets residing in the memory, including the candidate itemsets and the stored itemsets 1 As such, Remark 1 below gives inspiration that we can limit the memory consumption in leve l-wise search algorithms by constraining the size of candidates tested in each database scan.
 Remark 1: Suppose that the upper bound of the memory size is speci fi ed as M . M can be equivalently transformed to the upper number of itemsets concurrently residing in the memory. Let the corresponding upper number of itemsets in memory be denoted by M c . As such, the memory consump-tion will be limited below M if at most M c candidates will be concurrently generated-and-tested in each database scan
Clearly, Remark 1 states that a level-wise search algo-rithm is able to limit its memory consumption by only test-ing a fi xed number of candidate itemsets in one database scan. For example, suppose that M c =300 , 000 ,meaning that at most 300,000 candidate itemsets can be generated-and-tested in one database scan. Assuming we have 1,000 frequent 1-items, we can only select 775 1-items to gener-ate candidate 2-itemsets since 775 2 =299 , 925 ,whichis
We assume that discovered freq uent itemsets will be stored in the menory for further use.
It is reasonable to assume that M c is much larger than the desired number of frequent itemsets, i.e., k . Therefore, without loss of generality, we simply assume M c only indi-cates the upper number of candidate itemsets which will be concurrently generated-and-tested in each database scan. Figure 1: The illustration of mining top-k frequent itemsets under the memory constraint. bounded below M c .These 299 , 925 candidate 2-itemsets will be tested in one database scan, and the remaining 1000 2  X  2 =199 , 575 candidate 2 itemsets will be generated-and-tested in the next database scan. Note that using such an approach may incur extra database scans, which may con-fl ict the spirit of previous works to reduce the number of database scans. But as we claimed above, the guarantee of the memory bound is in practice equally or more impor-tant than the guarantee of the small number of database scans. Fortunately, in case that the available memory is not much small, the number of database scans required by our proposed algorithm is even smaller than that required by traditional level-wise algorithms such as algorithm DHP. We will show and discuss such an advantage in the next sec-tion. It is worth mentioning that, in the implementation, the memory required to store a candidate i -itemsets and a candidate j -itemsets are indeed di ff erent, for i 6 = j .Wewill also postpone the discussion of this issue to the next sec-tion. For simplicity, we assume the memory required by a candidate itemset of any size is identical in this section.
Accordingly, we then need a solution to constrain the number of generated candidates. One intuitive solution is to utilize the Apriori candidate generation technique [1] to directly generate candidate (i+1)-itemsets by combining all frequent i-itemsets until the number of candidate reaches the constrained number of candidates M c . In fact, such a brute force approach will be costly to compute top-k fre-quent itemsets. We therefore resort to the recent advanced technique presented in [3] to select the appropriate set of fre-quent i-itemsets to generate their candidate (i+1)-itemsets. While deferring the description of the algorithm proposed, we highlight the technique in [3] to estimate the tight upper bound of candidate itemsets. Speci fi cally, given a set of j -itemsets F j , after the mathematical manipulation, the upper bound of candidate ( j + i ) -itemsets, where i  X  1 , generated from F j can be estimated as e C j,i ( N )= m j j + i + m s + i +1 , where s is the smallest integer such that m s &lt;s + i . If no such an integer exists, s = r  X  1 [3].

Accordingly, we can devise the extension of level-wise search algorithms to discover frequent itemsets under the memory constraint as the following way: Approach: Without loss of generality, we illustrate the idea in Figure 1, where Figure 1(a) shows the process of database scans in the perspective of the support distribution plot and Figure 1(b) shows the perspective of candidates generated in the bounded memory. Assuming the given minimum sup-port is sup min , we can initially obtain the set of 1-items whose supports exceed sup min after the fi rst database scan. Suppose that L i denotes the set of i -itemsets whose supports exceed sup min ,and | L i | denotes the number of itemsets in L . We then select the most n 1 frequent items of L 1 , i.e., { X 1 , 1 ,X 1 , 2 ,..., X 1 ,n 1 } to generate candidate 2-itemsets in the second database scan, where For example, n 1 =775 if M c is speci fi ed as 300,000 (  X  e C 1 , 1 (775) = 299 , 925 ). As such, only candidate 2-itemsets from the most frequent 775 1-items will be generated in memory and tested in the second database scan.

Afterward, if e C 1 , 1 ( | L 1 | )  X  e C 1 , 1 ( n 1 ) &lt;M candidate 2-itemsets and partial candidate 3-itemsets from the most frequent n 2 2-itemsets will be generated and tested in the third database scan, where For example, suppose | L 1 | = 1000 . Wewillgenerateand and at most 2  X  300 , 000  X  499 , 500 = 100 , 500 candidate 3-itemsets in the 3 rd database scan, where candidate 3-itemsets are generated from most frequent 3,620 2-itemsets since n 2 =3620 (  X  e C 2 , 1 (3620) = 99 , 995 ).
Explicitly, at most M c candidate itemsets, possibly in-cluding candidate itemsets with various lengths, will be gen-eratedandtestedinonedatabasescanuntilnofurthercan-didates will be generated-and-tested. Following the proce-dure of traditional level-wise search algorithms except the strategy of the candidate generation, we will retrieve fre-quent itemsets fi nally. In case M c is large enough, we may directly generate candidate i -itemsets from L i  X  2 or L long as the candidate count is below M c . It can be achieved by the technique similar to the scan-reduction technique dis-cussed in [2].
We in this paper studied an interesting mining problem, namely mining frequent itemsets in the presence of the mem-ory constraint. An approach was proposed to e ffi ciently solve this problem, which will improve the feasibility of min-ing frequent itemsets.
 The work was supported in part by the National Science Council of Taiwan, R.O.C., under Contracts NSC93-2752-E-002-006-PAE. [1] R. Agrawal and R. Srikant. Fast algorithms for mining [2] M.-S. Chen, J.-S. Park, and P. S.Yu. E ffi cient Data [3] F.Geerts,B.Goethals,andJ.V.D.Bussche.Tight
