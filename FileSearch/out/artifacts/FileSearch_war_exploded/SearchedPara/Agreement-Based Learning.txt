 Many problems in natural language, vision, and computational biology require the joint modeling of many dependent variables. Such models often include hidden variables, which play an important role in unsupervised learning and general missing data problems. The focus of this paper is on models in which the hidden variables have natural problem domain interpretations and are the object of inference.
 Standard approaches for learning hidden-variable models involve integrating out the hidden vari-ables and working with the resulting marginal likelihood. However, this marginalization can be in-tractable. An alternative is to develop procedures that merge the inference results of several tractable submodels. An early example of such an approach is the use of pseudolikelihood [1], which deals with many conditional models of single variables rather than a single joint model. More generally, composite likelihood permits a combination of the likelihoods of subsets of variables [7]. Another approach is piecewise training [10, 11], which has been applied successfully to several large-scale learning problems.
 All of the above methods, however, focus on fully-observed models. In the current paper, we develop techniques in this spirit that work for hidden-variable models. The basic idea of our approach is to create several tractable submodels and train them jointly to agree on their hidden variables. We present an intuitive objective function and efficient EM-style algorithms for training a collection of submodels. We refer to this general approach as agreement-based learning .
 Sections 2 and 3 presents the general theory for agreement-based learning. In some applications, it is infeasible computationally to optimize the objective function; Section 4 provides two alternative objectives that lead to tractable algorithms. Section 5 demonstrates that our methods can be ap-plied successfully to large datasets in three real world problem domains X  X rammar induction, word alignment, and phylogenetic hidden Markov modeling. Assume we have M (sub)models p m ( x , z ;  X  m ) , m = 1 ,...,M , where each submodel specifies a distribution over the observed data x  X  X and some hidden state z  X  Z . The submodels could be parameterized in completely different ways as long as they are defined on the common event space X  X Z . Intuitively, each submodel should capture a different aspect of the data in a tractable way. To learn these submodels, the simplest approach is to train them independently by maximizing the sum of their log-likelihoods: combining the posteriors p m ( z | x ;  X  m ) of the trained submodels.
 If we view each submodel as trying to solve the same task of producing the desired posterior over z , then it seems advantageous to train the submodels jointly to encourage  X  X greement on z . X  We propose the following objective which realizes this insight: The last term rewards parameter values  X  for which the submodels assign probability mass to the same z (conditioned on x ); the summation over z reflects the fact that we do not know what z is. O agree has a natural probabilistic interpretation. Imagine defining a joint distribution over M inde-probability that the submodels all generate the same observed data x and the same hidden state: p ( x 1 =  X  X  X  = x M = x , z 1 =  X  X  X  = z M ;  X  ) .
 O agree is also related to the likelihood of a proper probabilistic model p norm , obtained by normalizing the product of the submodels, as is done in [3]. Our objective O agree is then a lower bound on the likelihood under p norm : The inequality holds because the denominator of the lower bound contains additional cross terms. The bound is generally loose, but becomes tighter as each p m becomes more deterministic. Note that p norm is distinct from the product-of-experts model [3], in which each  X  X xpert X  model p m has one set of hidden variables z common to all submodels, which is what provides the mechanism for agreement-based learning. 2.1 The product EM algorithm We now derive the product EM algorithm to maximize O agree . Product EM bears many striking similarities to EM: both are coordinate-wise ascent algorithms on an auxiliary function and both applying Jensen X  X  inequality, we can lower bound O agree with an auxiliary function L : The product EM algorithm performs coordinate-wise ascent on L (  X  ,q ) . In the (product) E-step, we optimize L with respect to q . Simple algebra reveals that this optimization is equivalent to mini-uct) M-step, we optimize L with respect to  X  , which decomposes into M independent objectives: term corresponds to an independent M-step, just as in EM for maximizing O indep .
 submodels are multiplied together to produce one posterior over z rather than M separate ones. Assuming that there is an efficient EM algorithm for each submodel p m , there is no difficulty in performing the product M-step. In our applications (Section 5), each p m is composed of multinomial distributions, so the M-step simply involves computing ratios of expected counts. On the other hand, the product E-step can become intractable and we must develop approximations (Section 4). Thus far, we have placed no restrictions on the form of the submodels. To develop a richer under-standing and provide a framework for making approximations, we now assume that each submodel p m is an exponential family distribution: where  X  m are sufficient statistics (features) and A m (  X  m ) = log P x  X  X  , z  X  X  the log-partition function, 2 defined on  X  m  X   X  m  X  R J . We can think of all the submodels p m as being defined on a common space Z  X  =  X  m Z m , but the support of q ( z ) as computed in the E-step is only the intersection Z  X  =  X  m Z m . Controlling this support will be essential in developing tractable approximations (Section 4.1).
 In the general formulation, we required only that the submodels share the same event space X  X  Z . Now we make explicit the possibility of the submodels sharing features, which give us more structure for deriving approximations. In particular, suppose each feature j of submodel p m can be decomposed into a part that depends on x (which is specific to that particular submodel) and a part that depends on z (which is the same for all submodels): where  X  X m ( x ) is a J  X  I matrix and  X  Z ( z ) is a I  X  1 vector. When z is discrete, such a decompo-component corresponding to z . Fortunately, we can usually obtain more compact representations of  X  Z ( z ) . We can now express our objective L (  X  ,q ) (4) using (5) and (6): convenience, define b T m =  X  T m  X  X m ( x ) and b = P m b m , which summarize the parameters  X  for the E-step. Note that for any  X  , the q maximizing L always has the following exponential family form: where A Z  X  (  X  ) = log P z  X  X  It will be useful to express (7) using convex duality [12]. The key idea of convex duality is the existence of a mapping between the canonical exponential parameters  X   X  R I of an exponential Fenchel-Legendre conjugate of the log-partition function A Z  X  (  X  ) is to  X  . Substituting  X  and A  X  Z Note that the two objectives are equivalent: sup  X   X  R I L (  X  , X  ) = sup  X   X  X  ( Z The mean parameters  X  are exactly the z -specific expected sufficient statistics computed in the prod-uct E-step. The dual is an attractive representation because it allows us to form convex combinations of different  X  , an operation does not have a direct correlate in the primal formulation. The product EM algorithm is summarized below: requires explicitly summing over all possible z  X  X   X  , often an exponentially large set. We will thus consider alternative E-steps, so it will be convenient to succinctly characterize an E-step. An E-step is specified by a vector b 0 (which depends on  X  and x ) and a set Z 0 (which we sum z over): Using this notation, E ( b m , Z m ) is the E-step for training the m -th submodel independently using EM and E ( b, Z  X  ) is the E-step of product EM. Though we write E-steps in the dual formulation, in practice, we compute  X  as an expectation over all z  X  X  0 , perhaps leveraging dynamic programming. If E ( b m , Z m ) is tractable and all submodels have the same dynamic programming structure (e.g., can incorporate all the features into the same dynamic program and simply run product EM (see Section 5.1 for an example).
 However, E ( b, Z  X  ) is intractable in general, owing to two complications: (1) we can sum over each Z m efficiently but not the intersection Z  X  ; and (2) each b m corresponds to a decomposable graphical model, but the combined b = P m b m corresponds to a loopy graph. In the sequel, we describe two approximate objective functions addressing each complication, whose maximization can be carried out by performing M independent tractable E-steps. 4.1 Domain-approximate product EM Assume that for each submodel p m , E ( b, Z m ) is tractable (see Section 5.2 for an example). We propose maximizing the following objective: with each  X  m  X  X  ( Z m ) . This objective can be maximized via coordinate-wise ascent: The product E-step consists of M separate E-steps, which are each tractable because each involves the respective Z m instead of Z  X  . The resulting expected sufficient statistics are averaged and used in the product M-step, which breaks down into M separate M-steps. While we have not yet established any relationship between our approximation L  X  dom and the original Z  X  with Z  X  in (10).
 Proposition 1. L  X  dom (  X  , X  1 ,..., X  M )  X  L  X   X  (  X  ,  X   X  ) for all  X  and  X  m  X  M ( Z m ) and  X   X  = is well-defined. Subtracting the L  X  version of (10) from (12), we obtain L  X  dom (  X  , X  1 ,..., X  M )  X  L  X  (  X  ,  X   X  ) = A since Z m  X  X   X  , A Z  X  (  X  m )  X  A Z m (  X  m ) ; by inspecting (9), it follows that A  X  Z 4.2 Parameter-approximate product EM Now suppose that for each submodel p m , E ( b m , Z  X  ) is tractable (see Section 5.3 for an example). We propose maximizing the following objective: with each  X  m  X  X  ( Z  X  ) . This objective can be maximized via coordinate-wise ascent, which again consists of M separate E-steps E ( Mb m , Z  X  ) and the same M-step as before: We can show that the maximum value of L  X  par is at least that of L  X  , which leaves us maximizing an upper bound of L  X  . Although less logical than maximizing a lower bound, in Section 5.3, we show that our approach is nonetheless a reasonable approximation which importantly is tractable. Proposition 2. max  X  L (  X  , X  ) for all  X   X  M ( Z  X  ) . If we maximize L  X  par with M distinct arguments, we cannot end up with a smaller value.
 The product E-step could also be approximated by mean-field or loopy belief propagation variants. These methods and the two we propose all fall under the general variational framework for approx-imate inference [12]. The two approximations we developed have the advantage of permitting exact tractable solutions without resorting to expensive iterative methods which are only guaranteed to converge to a local optima.
 While we still lack a complete theory relating our approximations L  X  dom and L  X  par to the original objective L  X  , we can give some intuitions. Since we are operating in the space of expected sufficient statistics  X  m , most of the information about the full posterior p m ( z | x ) must be captured in these statistics alone. Therefore, we expect our approximations to be accurate when each submodel has enough capacity to represent the posterior p m ( z | x ;  X  m ) as a low-variance unimodal distribution. We now empirically validate our algorithms on three concrete applications: grammar induction using product EM (Section 5.1), unsupervised word alignment using domain-approximate product EM (Section 5.2), and prediction of missing nucleotides in DNA sequences using parameter-approximate product EM (Section 5.3). Figure 1: The two instances of IBM model 1 for word alignment are shown in (a) and (b). The graph shows gains from agreement-based learning. 5.1 Grammar induction Grammar induction is the problem of inducing latent syntactic structures given a set of observed sentences. There are two common types of syntactic structure (one based on word dependencies and the other based on constituent phrases), which can each be represented as a submodel. [5] proposed an algorithm to train these two submodels. Their algorithm is a special case of our product EM algorithm, although they did not state an objective function. Since the shared hidden state is a tree structure, product EM is tractable. They show that training the two submodels to agree significantly improves accuracy over independent training. See [5] for more details. 5.2 Unsupervised word alignment Word alignment is an important component of machine translation systems. Suppose we have a set of sentence pairs. Each pair consists of two sentences, one in a source language (say, English) and its translation in a target language (say, French). The goal of unsupervised word alignment is to match the words in a source sentence to the words in the corresponding target sentence. Formally, is a set of alignment edges between positions in the English and positions in the French. Classical models for word alignment include IBM models 1 and 2 [2] and the HMM model [8]. These are asymmetric models, which means that they assign non-zero probability only to alignments in which each French word is aligned to at most one English word; we denote this set Z 1 . An corresponding to the English word (if any) that French word f j is aligned to. We define the first submodel on X  X Z 1 as follows (specializing to IBM model 1 for simplicity): log-probabilities { log t 1; ef } for each English word e (including N ULL ) and French word f . if and only if English word e i is aligned to French word f j and z N ULL j = 1 if and only if f j is not these can be computed independently for each j . We can define a second submodel p 2 ( x , z ;  X  2 ) on X  X Z 2 by reversing the roles of English and French. Figure 1(a) X (b) shows the two models. We cannot use product EM algorithm to train p 1 and p 2 because summing over all alignments in Z  X  = Z 1  X  Z 2 is NP-hard. However, we can use domain-approximate product EM because E ( b 1 + b 2 , Z m ) is tractable X  X he tractability here does not depend on decomposability of b but the asymmetric alignment structure of Z m . The concrete change from independent EM is slight: we and change the M-step to use the average of the edge posteriors obtained from the two E-steps.
Figure 2: The two phylogenetic HMM models, one for the even slices, the other for the odd ones. in b 1 + b 2 . Their M-step uses the elementwise product of  X  1 and  X  2 , whereas we use the average (  X  1 +  X  2 ) . Finally, while their algorithm appears to be very stable and is observed to converge empirically, no objective function has been developed; in contrast, our algorithm maximizes (12). In practice, both algorithms perform comparably.
 We conducted our experiments according to the setup of [6]. We used 100K unaligned sentences for training and 137 for testing from the English-French Hansards data of the NAACL 2003 Shared Task. Alignments are evaluated using alignment error rate (AER); see [6] for more details. We trained two instances of the HMM model [8] (English-to-French and French-to-English) using 10 iterations of domain-approximate product EM, initializing with independently trained IBM model 1 parameters. For prediction, we output alignment edges with sufficient posterior probability: { ( i,j ) : (  X  1; ij +  X  2; ij )  X   X  } . Figure 1 shows how agreement-based training improves the error rate over independent training for the HMM models. 5.3 Phylogenetic HMM models Suppose we have a set of species s  X  S arranged in a fixed phylogeny (i.e., S are the nodes ( d s 1 ,...,d sL ) . Let d = { d s : s  X  S } denote all the nucleotides, which consist of some observed ones x and unobserved ones z .
 A good phylogenetic model should take into consideration both the relationship between nucleotides of the different species at the same site and the relationship between adjacent nucleotides in the same species. However, such a model would have high tree-width and be intractable to train. Past work has focused on traditional variational inference in a single intractable model [9, 4]. Our approach is to instead create two tractable submodels and train them to agree. Define one submodel to be p 1 ( x , z ;  X  1 ) = p 1 ( d ;  X  1 ) = where C H ( s ) is the set of children of s in the tree. The second submodel p 2 is defined similarly, only with the product taken over j even. The parameters  X  m consist of first-order mutation log-probabilities and second-order mutation log-probabilities. Both submodels permit the same set of assignments of hidden nucleotides ( Z  X  = Z 1 = Z 2 ). Figure 2(a) X (b) shows the two submodels. Exact product EM is not tractable since b = b 1 + b 2 corresponds to a graph with high tree-width. We can apply parameter-approximate product EM, in which the E-step only involves computing  X  nucleotide slice of the sequence. In the M-step, the average 1 2 (  X  1 +  X  2 ) is used for each model, which has a closed form solution.
 Our experiments used a multiple alignment consisting of L = 20 , 000 consecutive sites belonging to the L1 transposons in the Cystic Fibrosis Transmembrane Conductance Regulator (CFTR) gene (chromosome 7). Eight eutherian species were arranged in the phylogeny shown in Figure 3. The data we used is the same as that of [9]. Some nucleotides in the sequences were already missing. In addition, we held out some fraction of the observed ones for evaluation. We trained two models using 30 iterations of parameter-approximate product EM. 3 For prediction, the posteriors over heldout Figure 3: The tree is the phylogeny topology used in experiments. The graphs show the predic-tion accuracy of independent versus agreement-based training (parameter-approximate product EM) when 20% and 50% of the observed nodes are held out. nucleotides under each model are averaged and the one with the highest posterior is chosen. Figure 3 shows the prediction accuracy. Though independent and agreement-based training eventually obtain the same accuracy, agreement-based training converges much faster. This gap grows as the amount of heldout data increases. We have developed a general framework for agreement-based learning of multiple submodels. View-ing these submodels as components of an overall model, our framework permits the submodels to be trained jointly without paying the computational cost associated with an actual jointly-normalized probability model. We have presented an objective function for agreement-based learning and three EM-style algorithms that maximize this objective or approximations to this objective. We have also demonstrated the applicability of our approach to three important real-world tasks. For grammar in-duction, our approach yields the existing algorithm of [5], providing an objective for that algorithm. For word alignment and phylogenetic HMMs, our approach provides entirely new algorithms. Acknowledgments We would like to thank Adam Siepel for providing the phylogenetic data and acknowledge the support of the Defense Advanced Research Projects Agency under contract NBCHD030010.

