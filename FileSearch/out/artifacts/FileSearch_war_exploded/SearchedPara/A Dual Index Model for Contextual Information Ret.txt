 In this paper, we propose a dual index model for contextual IR. For each query, we search against both document level and passage level indexes, and use the corresponding merge function to update the weights for both documents and para-graphs by combining the results from both indexes according to the granularity information in metadata. Experiments on 2004 TREC data show that a significant improvement can be made by using the dual index model.
 H.3.3 [ Information Systems ]: Information Search and Re-trieval Experimentation High Accuracy Retrieval, Metadata, Contextual IR In a recent workshop, contextual retrieval was identified as one of the major challenges for IR in the long term [3]. It is defined as  X  X ombining search technologies and knowledge about query and user context into a single framework in order to provide the most  X  X ppropriate X  answer for a user X  X  information needs X . HARD (High Accuracy Retrieval from Documents) is an information retrieval project, the goal of which is to retrieve highly accurate answers to queries by leveraging additional information about the searcher and/or the search context. The main challenge of this research is how to map and merge metadata into the retrieval system to obtain highly accurate results.

In the 2004 HARD track of TREC, different approaches have been exploited to improve the retrieval accuracy by us-ing provided contextual information. Sun et al.used meta-data to expand query terms [7]. Harper et al. exploited the metadata to manually generate a query for re-ranking pur-pose [5]. UIUC focused on the evaluation of a new method for identifying variable-length passages using HMMs [6]. UMass used related text to create a language model and used genre and geography metadata to build a classifier [1]. We used related text for query expansion, geography metadata for fil-tering and granularity for improving retrieval accuracy [4].
In this paper, we focus on using granularity metadata and building both document and passage indexes for improving retrieval performance. Based on granularity, three merge functions are used to combine the results from both indexes. We explore these three merge functions and evaluate their performance.

The rest of the paper is organized as follows. Section 2 introduces our search system. Section 3 presents the dual index model. We describe our experiments and results in Section 4. Conclusions are given in Section 5. In this section, we briefly introduce our search system. Fig-ure 1 depicts the overall structure of our search system. We use Okapi BSS as the underlying retrieval system, based on which we developed our dual index module and query pro-cessing module.
 The system takes a topic in the format provided by TREC. Each topic is associated with some metadata, which include the following fields: Genre, Geography, Granularity, Famil-iarity, Subject and Related Text 1 . The topic processing module loads these topic files, extracts relevant fields and converts them into the format acceptable by the term pro-cessing module. The resulting terms are searched against
In our experiments, only granularity, geography and related text are used. the dual index module, which returns two lists of results The result processing module takes both lists, re-weights the documents and passages based on the two lists and generates a new ranking list for both passage and document retrieval. Our basic assumption for the dual index model is: if a doc-ument is hit by searches on both document and passage indexes, it should be assigned more weight than others that are hit by only one index. For each topic, we search against both indexes and use a merge function to update the weights for paragraphs and documents by combining the results from both indexes. If the given granularity is  X  X assage X , either function (1) or function (2) is used. If the paragraphs found in a document are not adjacent, we use the following merge function to assign a new weight to each of these paragraphs: where W pnew is the new weight of the paragraph, W p is the weight of the paragraph we obtain from the paragraph level index, W d is the weight of the document containing the para-graph, obtained from the document level index, | P | is the total number of paragraphs retrieved from this document, and h 1 is a tuning constant.

If there are several adjacent paragraphs found in a doc-ument, we merge these paragraphs into one and use the following function to assign the weight to the newly merged paragraph:
W pnew = ( W p 1 + h 1  X  W d )  X  log 10 (10  X  X  P | )+ 1 where W pnew is the weight of the newly merged paragraph, W p 1 is the weight of the first of these adjacent paragraphs from the passage index, W d is the weight of the document we get from the document level index, | P | is the total number of paragraphs retrieved from this document. W p k is the weight of the kth of these n adjacent paragraphs, and h 1 and h 2 are two tuning constants.

If the give granularity is  X  X ocument X , the following merge function is used to assign a new weight to the document: where W dnew is the new weight of the document, W d is the weight of the document we get from the document level index, | P | is the total number of paragraphs retrieved from this document. W p k is the weight of the kth paragraph we get from the passage index, and h 3 is another tuning constant. We evaluate the proposed merge functions on the 2004 HARD data sets. In total, 635,650 documents and 9,279,957 para-graphs have been indexed in our experiments from this cor-pus. Three performance measures are used here. They are (1) R-Precision for document level evaluation: precision af-ter the number of documents retrieved is equal to the num-ber of known relevant documents for a topic; (2) R-Precision for passage level evaluation: the passage precision after R
One is passage-based and the other is document-based. passages have been retrieved, where R is the number of rel-evant passages for the topic; (3) Bpref@12000 for character-based measure at 12,000 characters [2].

The following table shows the performance for 5 runs in terms of document and passage retrieval evaluation. The first row describes the performance for the run without using the merge function, which is used as the base run in our experiments. The second row is our official submission to the 2004 HARD track 3 , where h 1 , h 2 and h 3 are set to be 3, 2 and 1 respectively. We set h 1 , h 2 and h 3 to be 2, 2 and 3 log 10 (10  X  X  P | ) for the 3rd run where | P | is the total number of paragraphs retrieved from this document. The 4th run is obtained by disabling the  X  X eography X  filter for the 3rd run, while the last run is obtained by disabling the  X  X eography X  filter and without using the blind feedback for the 2nd run. The value in the parentheses is the relative rate of improvement over the base run.

In this paper, we presented a novel dual index model with three merge functions. We investigate the use of granular-ity metadata to improve the retrieval performance. We also investigate the performance of the merge functions with dif-ferent values of the three tuning constants. Our experiment results demonstrate that the dual index model can signifi-cantly improve the retrieval performance for both passage level and document level retrieval.
 This study was supported in part by a research grant from the Natural Sciences and Engineering Research Council (NSERC) of Canada. [1] N. Abdul-Jaleel, J. Allan, W. Bruce and et al. UMass [2] J. Allan. HARD Track Overview in TREC 2004. In [3] J. Allan and et al. Challenges in IR and Language [4] X. Huang, Y. Huang and M. Wen et al. York University [5] D. Harper and et al. The Robert Gordon Univ. X  X  HARD [6] J. Jiang and C.X.Zhai. UIUC in HARD 2004:Passage [7] L. Sun, J. Zhang, and Y. Sun. ISCAS at TREC-2004:
In the 2004 HARD track, the best result on passage re-trieval in terms of Bpref@12000 is 0.3576 and the best result on document retrieval in terms of R-Precision is 0.377.
