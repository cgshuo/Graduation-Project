 Data mining tasks such as Anomaly Detection (AD) and Information Retrieval (IR) require a ranking measure in order to rank data instances. Distance or density based methods are widely used to rank instances in these tasks. The main problem of these methods is that they are computationally expensive in large data sets because of the ir high time complexities.

Isolation Forest (iForest) [1] is an anomaly detector that does not use distance or density measure. It performs an operation to isolate each instance from the rest of instances in a given data set. Beca use anomalies have characteristics of being  X  X ew and different X , they are more susceptible to isolation in a tree structure than normal instances. Therefore, anomalies have shorter average path lengths than those of normal instances over a c ollection of isola tion trees (iTrees).
Though iForest has been shown to perform well [1], we have identified its weakness in detecting local anomalies in data sets having multiple clusters of normal instances because the local ano malies are masked by normal clusters of similar density; thus they become less susceptible to isolation using iTrees. In other words, iForest can not detect local anomalies because the path length measures the degree of anomaly globally. It does not consider how isolated an instance is from its local neighbourhood.
 iForest has its foundation in mass estimation [2]. Ting et al [2] have shown that the path length is a proxy to mass in a tree-based implementation. From this basis, we analyse that iForest X  X  inability to detect local anomalies can be overcome by replacing the global ranking measure based on path length with a local ranking measure based on relative mass using the same iT rees. In general, relative mass of an instance is a ratio of data mass in two regions covering the instance, where one region is a subset of the other. The relative mass measures the degree of anomaly locally by considering the data distribution in the local regions (superset and subs et) covering an instance.

In addition to AD, we show the generality of relative mass in IR that over-comes the limitation of a recent IR system c alled ReFeat [3] that uses iForest as a core ranking model. Even though ReFeat p erforms well in content-based multi-media information retrieval (CBMIR) [3], the ranking scheme based on path length does not guarantee that two instances having a similar ranking score are in the same local neighbourhood. The new ranking scheme based on relative mass provides such a guarantee.

The contributions of this paper are as follows: 1. Introduce relative mass as a ranking measure. 2. Propose ways to apply relative mass, instead of path length (which is a proxy 3. Demonstrate the utility of relative mass in AD and IR by improving the
The rest of the paper is organised as follows. Section 2 introduces the notion of relative mass and proposes ways to apply to AD and IR. Section 3 provides the empirical evaluation followed by conclusions in the last section. Rather than using the global ranking measure based on path length in iForest, an instance can be ranked using a local ranking measure based on relative mass w.r.t its local neighbourhood. In a tree st ructure, the relative mass of an instance is computed as a ratio of mass in two nodes along the path the instance traverses from the root to a leaf node. The two nodes used in the calculation of relative mass depend on the task specific requirement.  X  In AD, we are interested in the relative mass of x w.r.t its local neigh- X  In IR, we are interested in the relative mass of x w.r.t to a query q . Hence,
We convert iForest [1] and ReFeat [3] using the relative mass, and named the resultant relative mass versions, R eMass-iForest and ReMass-ReFeat, re-spectively. We describe iForest and Re Mass-iForest in AD in Section 2.1; and ReFeat and ReMass-ReFeat in IR in Section 2.2. 2.1 Anomaly Detection: iForest and ReMass-iForest In this subsection, we first discuss iForest and its weakness in detecting local anomalies and introduce the new anomaly detector, ReMass-iForest, based on the relative mass to overcome the weakness. iForest sub-sample ( D i  X  D , |D i | =  X &lt;n ) by recursively dividing it into two non-empty nodes through a randomly selected attribute and split point. A branch stops splitting when the height reaches the maximum ( H max )orthenumberof instances in the node is less than MinPts . The default values used in iForest are H max =log 2 (  X  )and MinPts = 1. The anomaly score is estimated as the average path length over t iTrees as follows: where  X  i ( x ) is the path length of x in T i
As anomalies are likely to be isolated early, they have shorter average path lengths. Once all instances in the given data set have been scored, the instances are sorted in ascending order of their scores. The instances at the top of the list are reported as anomalies. iForest runs very fast because it does not require distance calculation and each iTree is constructed from a small random sub-sample of data. iForest is effective in detect ing global anomalies (e.g., a 1 and a 2 in Figures 1a and 1b) because they are more susceptible to isolation in iTrees. But it fails to detect local anomalies (e.g., a 1 and a 2 in Figure 1c) as they are less susceptible to isolation in iTrees. This is because the local anomalies and the normal cluster C 3 have about the same density. Some fringe instances in the normal cluster C 3 will have shorter average path lengths than those for a 1 and a 2 . ReMass-iForest In each iTree T i , the anomaly score of an instance x w.r.t its local neighbourhood, s ( x ), can be estimated as the ratio of data mass as follows: of T i ( x ), and m (  X  ) is the data mass of a tree node.  X  is a normalisation term which is the training data size used to generate T i . s i (  X  )isin(0 , 1]. The higher the score the higher the likelihood of x being an anomaly. Unlike  X  i ( x )iniForest, s i ( x ) measures the degree of anomaly locally.
The final anomaly score can be estimated as the average of local anomaly scores over t iTrees as follows:
Once every instance in the given data s et has been scored, instances can be ranked in descending order of their anomaly scores. The instances at the top of the list are reported as anomalies.
 Relation to LOF and DEMass-LOF The idea of relative mass in ReMass-iForest has some relation to the idea of rel-ative density in Local Outlier Factor (LOF) [4]. LOF uses k nearest neighbours to estimate density  X  f k ( x )= set of k nearest neighbours of x . It estimates its anomaly score as the ratio of the bourhood is defined by k nearest neighbours which requires distance calculation. In contrast, in ReMass-iForest, the local neighbourhood is the immediate parent in iTrees. It does not require distance calculation.

DEMass-LOF [5] computes the same anomaly score as LOF from trees, with-out distance calculation. The idea of relative density of parent and leaf nodes was used in DEMass-LOF. It constructs a forest of t balanced bina ry trees where the height of each tree is b  X  d ( b is a parameter that determines the level of division on each attribute and d is the number of attributes). It estimates its anomaly score as the ratio of average density of the parent node to the average density of the leaf node where x falls. The density of a node is estimated as the ratio of mass to volume. It uses mass to estimate density and ranks instances based on the density ratio. Like iForest, it is fast because no distance calcula-tion is involved. But, it has limitation in dealing problems with even a moderate number of dimensions because each tree has 2 ( b  X  d ) leaf nodes.
In contrast to LOF and DEMass-LOF, Re Mass-iForest does not require den-sity estimation, it uses relative mass directly in order to estimate the local anomaly score from each iTree.

The ranking measure and complexities (time and space) of ReMass-iForest, iForest, DEMass-LOF and LOF are provided in Table 1. 2.2 Information Retrieval: ReFeat and ReMass-ReFeat In this subsection, we first describe how ReFeat uses iForest in IR and its weak-ness. Then, we introduce a new IR system, ReMass-ReFeat, based on the relative mass to overcome the weakness.
 ReFeat is a normalisation constant) to each T i . The relevance feedback process [6] allows user to refine the retrieved result by providing some  X  X elevant X  and  X  X rrelevant X  examples for the query. Let Q = P X  X  is a set of feedback instances to the query q where P and N are the sets of positive and negative feedbacks, respectively. Note that P includes q . In a relevance feedback round, ReFeat assigns a weight to T using positive and negative feedback instances as: w i ( Q )=  X  1 |N| contribution of positive and negative feedbacks. The relevance of x w.r.t Q is estimated as the weighted average of its path lengths over t iTrees as follows:
Even though ReFeat has been shown to hav e superior retrieval performance over other existing methods in CBMIR, the ranking scheme does not guarantee that two instances having similar ranking scores are in the same local neighbour-hood. Two instances can have similar sco re if they have equal path lengths in an iTree even though they lie in two different branches which shares few common nodes. This effect will degrade the perf ormance of ReFeat especially when the tree height ( h ) is increased. Hence, ReFeat must use a low h (2 or 3) in order to reduce this weakness. The superior performance of ReFeat is mainly due to its large ensemble size ( t = 1000). We will discuss the effect of h and t in ReFeat in Section 3.2. In a nutshell, ReFeat does not consider the positions of instances in the feature space as it comput es the path length in iTrees.
 ReMass-ReFeat mass as follows: where T i ( x , q ) is the smallest region in T i where x and q appear together.
In equation 5, the numerator corresponds with w i ( q ) in ReFeat. The denom-pendent of q (it does not examine whether x and q are in the same locality [3]); T sure gives a high score to an instance which lies deeper in the branch where q lies. The final relevance score of x w.r.t q , R ( x | q ), is the average over t iTrees:
Once the relevance score of each instanc e is estimated, the scores can be sorted in descending order. The instances at the top of the list are regarded as the most relevant instances to q .

ReMass-ReFeat estimates the relevance score with relevance feedback as fol-lows:
Note that equations 5 and 6 do not make use of any distance or similarity measure, and R ( x | q ) is not a metric as it does not satisfy all metric axioms. It has the following characteristics. For x , y  X  D , i. 0 &lt;R ( x | y )  X  1 (Non-negativity) ii. R ( x | x )= R ( y | y ) = 1 (Equal self-similarity; maximal similarity) iii. R ( x | y ) = R ( y | x ) (Asymmetric)
Note that ReMass-ReFeat and ReFeat have the same time complexities. If indices of data instances falling in each node are recorded in the modelling stage, the joint mass of q and every x  X  D can be estimated in one search from the root to T i ( q ) in each tree. But, it will incr ease the space complexity as it requires to store n indices in each iTree. The time and space complexities of ReMass-ReFeat and ReFeat are provided in Table 2. In this section, we evaluate the utility of relative mass in AD and CBMIR tasks. In AD, we compared ReMass-iForest with iForest [1], DEMass-LOF [5] and LOF [4]. In CBMIR, we compared ReMass-ReFeat with ReFeat [3] and the other ex-isting CBMIR systems: MRBIR [7], InstRank [8] and Qsim [9]. Both the AD and CBMIR experiments were conducted in unsupervised learning settings. The labels of instances were not used in the model building process. They were used as the ground truth in the evaluation stage. The AD results were measured in terms of the area under ROC curve (AUC). In CBMIR, the precision at the top 50 retrieved results (P@50) [3] was used as the performance measure. The presented result was the average over 20 runs for all randomised algorithms. A two-standard-error significance test was conducted to check whether the differ-ence in performance of two methods was significant.

We used the same MATLAB implementation of iForest provided by the au-thors of ReFeat [3], the JAVA implementation of DEMass-LOF in the WEKA [10] platform, and the JAVA implementation of LOF in the ELKI [11] platform.
We present the empirical evaluation results in the following two subsections. 3.1 Anomaly Detection: ReMass-iForest versus iForest In the first experiment, we used a synthetic data set to demonstrate the strength of ReMass-iForest over iForest to det ect local anomalies. The data set has 263 normal instances in three clusters and 12 anomalies representing global, local and clustered anomalies. The data distribution is shown in Figure 2a. Instances a ,a 2 and a 3 are global anomalies; four instances in A 4 and two instances in A 5 are clustered anomalies; and a 6 ,a 7 and a 8 are local anomalies; C 1 , C 2 and C 3 are normal instances in three clusters of varying densities.

Figures 2b-2d show the anomaly scores of all data instances obtained from iForest and ReMass-iForest. With iForest, local anomalies a 6 ,a 7 and a 8 had lower anomaly scores than some normal instances in C 3 ; and it produced AUC of 0.98. In contrast, ReMass-iFores t had ranked local anomalies a 6 ,a 7 ,a 8 higher than any instances in normal clusters C 1 ,C 2 and C 3 along with global anomalies a 1 ,a 2 and a 3 . But, ReMass-iForest with MinPts = 1 had some problem in ranking clustered anomalies in A 4 and produced AUC of 0.99. One fringe instance in the cluster C 3 was ranked higher than two clustered anomalies in A 4 .Thisis because cluster anomalies have similar mass ratio w.r.t their parents as that for the instances in sparse normal cluster C 3 . Clustered anoma lies were correctly ranked and AUC of 1.0 was achieved when MinPts was increased to 5. The performance of iForest did not improve when MinPts was increased to any values in the range (2, 3, 4, 5 and 10).

In the second experiment, we used the ten benchmark data sets previously employed by Liu et al (2008) [1]. In ReMass-iForest, iForest and DEMass-LOF, the parameter t was set to 100 as default and the best value for the sub-sample size  X  was searched from 8, 16, 32, 64, 128 to 256. In ReMass-iForest, MinPts was set to 5 as default. iForest uses the default settings as specified in [1], i.e, MinPts = 1. The level of subdivision ( b ) for each attribute in DEMass-LOF wassearchedfrom1,2,3,4,5,and6.InLOF,thebest k was searched between 5 and 4000 (or to n 4 for small data sets), with steps from 5, 10, 20, 40, 60, 80, 150, 250, 300, 500, 1000, 2000, 3000 to 4000. The best results were reported. The characteristics of th e data sets, AUC and runtime (seconds) of ReMass-iForest, iForest, DEMass-LOF a nd LOF are presented in Table 3.

In terms of AUC, ReMass-iForest had better or at least similar results to iForest. Based on the two-standard-error significance test, it produced better results than iForest in the ForestCover and Ionosphere data sets. Most of these datasets do not have local anomalies. So, both methods had similar AUC in eight data sets. Note that iForest did not improve AUC when MinPts was set to 5. ReMass-iForest had produced significantly better AUC than DEMass-LOF in relatively high dimensional da ta sets (Arrhythmia -274, Satellite -36, Ionosphere -32, ForestCover -10, Shuttle -9). These results show that DEMass-LOF has problem in handling data sets with a moderate number of dimensions (9 or 10). ReMass-iForest was competitive to LOF. It was better than LOF in the Mammography data set, worse in the Smtp and Satellite data sets, and equal performance in the other seven data sets.
 As shown in Table 3, the runtime of ReMass-iForest, iForest and DEMass-LOF were of the same order of magnitude whereas LOF was upto three order of magnitude slower in large data sets. Note that we can not conduct a head-to-head comparison of runtime of ReMass-iForest and iForest with DEMass-LOF and LOF because they were implemented in different platforms (MATLAB versus JAVA). The results are included here just to provide an idea about the order of magnitude of runtime. The difference in runtime of ReMass-iForest and iForest was due to the difference in  X  and MinPts . MinPts = 5 results in smaller size iTrees in ReMass-iForest than those in iForest ( MinPts = 1). Hence, ReMass-iForest runs faster than iForest even though the same  X  is used. 3.2 CBMIR: ReMass-ReFeat versus ReFeat The performance of ReMass-ReFeat was evaluated against that of ReFeat in music and image retrieval tasks with GTZAN music data set [12] and COREL image data set [13], respectively. GTZAN is a data set of 1000 songs uniformly distributed in 10 genres. Each song is represented by 230 features. COREL is a data set of 10,000 images uniformly distributed over 100 categories. Each image is represented by 67 features. These are the same data sets used in [3] to evaluate the performance of ReFeat. The results of the existing CBMIR systems InstRank, Qsim and MRBIR were taken from [3].
 We conducted our experiments using the same experimental design as in [3]. Initially five queries were chosen randomly from each class. For each query, in-stances from the same class were regarded a s relevant and the other classes were irrelevant. At each round of feedback, two relevant (instances from the same class) and two irrelevant (instances fr om the other classes) instances were pro-vided. Upto five rounds of feedback were conducted for each query. The instance was not used in ranking if it was used as a feedback instance. The feedback process was repeated five times with different relevant and irrelevant feedbacks. The above process was repeated 20 times and average P@50 was reported.
In ReMass-ReFeat, the parameters  X  and MinPts were set as default to 256 and 1, respectively. In ReFeat,  X  wassetto4forGTZANand8forCORELas reported in [3]. Other settings of  X  in ReFeat were found to perform worse than these settings. In order to show how their retrieval performance varies when ensemble size was increased, we used two settings for t : ReMass-ReFeat and ReFeat with (i) t = 100 (RM-100 and RF-100) and (ii) t = 1000 (RM-1000 and RF-1000). The feedback parameter  X  was set as default to 0.5 in ReMass-ReFeat and 0.25 in ReFeat (as used in [3]).

P@50 of ReMass-ReFeat (RM-100 and RM-1000), ReFeat (RF-100 and RF-1000), InstRank, MRBIR and Qsim in the GTZAN and COREL data sets are shown in Figure 3. P@50 curves in both th e data sets show that ReMass-ReFeat (RM-1000) has better retrieval performance than all contenders, especially in feedback rounds. In round 1 or no feedback (query only), ReMass-ReFeat (RM-1000) and ReFeat (RF-1000) produced similar retrieval performance but in latter feedback rounds, RM-1000 produced better results than RF-1000.
 It is interesting to note that the performance of RF-100 was worse than that of RM-100 in all feedback rounds including query only (no feedback). In GTZAN, RF-100 had worst performance than all contenders. The increase in P@50 from RF-100 to RF-1000 was a lot larger than that of RM-100 to RM-1000. This result shows that the retrieval performance of ReFeat is mainly due to the large ensemble size of 1000. The difference in P@50 of RM-100 and RF-1000 was decreasing in subsequent feedback rounds. This indicates that ReMass-ReFeat produces better result than ReFeat even with a smaller ensemble size if more feedback instances are available.

In terms of runtime, ReMass-ReFeat had slightly higher runtime than ReFeat because of the higher  X  that allows trees to grow deeper (256 vs. 4 in GTZAN and 8 in COREL). The model building time of RM-1000 was 21 seconds (vs. 4 seconds of RF-1000) in COREL and 20 seconds (vs. 2 seconds of RF-1000) in GTZAN. The on-line retrieval time for one query of RM-1000 was 0.9 seconds (vs. 0.3 seconds of RF-1000) in COREL and 0.2 seconds (vs. 0.2 seconds of RF-1000) in GTZAN.
Figure 4 shows the effect of  X  on the P@50 of ReMass-ReFeat and ReFeat at feedback round 5 (one run) in the GTZAN data set. In ReFeat, when  X  was increased above 4, the retrieval performance degraded. This is due to the increase in the height of iTrees ( h =log 2 (  X  )) and instances falling in two distinct branches hav-ing similar relevance score based on the same path lengths. In contrast, ReMass-ReFeat improved its retrieval performanceupto64andthenre-mained almost flat beyond that. Sim-ilar effect was observed in the COREL dat a set where the performance of ReFeat degraded when  X  was set above 8. While the relative mass was motivated to overcome the weakness of iForest in detecting local anomalies, we have shown that the idea has a wider application. In information retrieval, we apply it to overcome the weakness of a state-of-the-art system called ReFeat. Our empirical evaluations show that ReMass-iForest and ReMass-ReFeat perform better than iForest and ReFeat, respectively, in terms of task-specific performance. In comparison with other state-of-the-art systems in both tasks, ReMass-iForest and ReMass-ReFeat are found to be either competitive or better.

The idea of relative mass in ReMass-iForest is similar to that of relative den-sity in LOF and our empirical results show that ReMass-iForest and LOF have similar anomaly detection performance. However, ReMass-iForest runs signifi-cantly faster than LOF in large data sets because it does not require distance or density calculations.
 Acknowledgement. This work is partially supported by the U.S. Air Force Research Laboratory, under agreement#FA2386-13-1-4043. Sunil Aryal is sup-ported by Australian Postgraduate Award (APA), Monash University. The paper on mass-based similarity measure [14] has inspired us in creating the relevance score based on relative mass used in ReMass-ReFeat; though the motivations of the two papers differ.

