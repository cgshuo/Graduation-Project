 Bitmap indexes are widely used in Decision Support Sys-tems (DSSs) to improve query performance. In this paper, we evaluate the use of compressed inverted indexes with adapted query processing strategies from Information Re-trieval as an alternative. In a thorough experimental evalu-ation on both synthetic data and data from the Star Schema Benchmark, we show that inverted indexes are more com-pact than bitmap indexes in almost all cases. This com-pactness combined with efficient query processing strategies results in inverted indexes outperforming bitmap indexes for most queries, often significantly.
 Categories and Subject Descriptors: H.2.2 Database management: Physical design -access methods General Terms: Experimentation, Performance.
Decision Support Systems (DSSs) support queries over large amounts of structured data, and bitmap indexes are of-ten used to improve the efficiency of important query classes involving selection predicates and joins [16, 17].
 Bitmap indexes were formerly also used in Information Retrieval (IR), but are today mainly replaced by inverted indexes . Part of the reason why inverted indexes gained popularity in IR was that they easily support integrating new fields required to support ranked queries. The switch from bitmap indexes to inverted indexes lead to a flood of research on efficient inverted indexes [25, 30, 6, 13, 24, 3, 31, 29], and inverted indexes are now the preferred indexing method in search engines [30].

In this paper, we are asking (and answering) the ques-tion: What are the trade-offs of using inverted indexes in DSSs, and should they be considered a serious alternative to bitmap indexes? The main contributions of this paper are (1) the study of how to use and implement inverted in-dexes in DSSs, and (2) a thorough performance evaluation intermediate results by processing all inverted lists in a query in parallel [6, 24], and are well suited for boolean query processing. They can be combined with skipping, which is used in search engines to avoid reading and decompressing parts of inverted lists that are not required to process a query [13]. We give a brief description of how we use these ideas in the query processing in this paper in the next section.
Recall that we use document-at-a-time strategies that av-oid materializing intermediate results to process inverted in-dex queries in this paper. We support three operators which can be combined to answer complex queries. They all sup-port skipping to the next result with a given minimum TID value, in addition to standard Volcano-style iteration [9]. The SCAN operator can iterate through an inverted list. To support skipping, each k th TID in each inverted list is stored in an external list. The external list is kept in mem-ory during scans, and supports binary searches to find the correct part of the inverted list to process when skipping.
The OR operator provides an iterator interface over the sorted merge of its multiple input iterators. The iterators are organized in a priority-queue based on a heap, which is maintained to make sure that the input with the smallest next TID is at the top. Skipping in the OR operator is based on a breadth-first search in the heap. A skip may not result in an actual skip for a given input iterator. If so, we know that neither of its children in the heap can do any skipping either, and we therefore avoid testing. After the search, we make sure that only the part of the heap involving itera-tors that actually skipped is maintained. This approach is reasonably efficient when actually performing skips in both large and small fractions of the set of input iterators.
The AND operator expects that the input iterators are sorted in ascending order according to the expected num-ber of returned results. To find the next result, we start with a candidate from the iterator with the fewest number of expected results. We then try to skip to the candidate in the other input iterators, re-starting with a new candidate if the current candidate is absent in one iterator. A candi-date found in all inputs is returned as a result. To support skipping, we start with the value to skip to as the candidate and proceed as in normal iteration.
To investigate the trade-offs between inverted indexes and bitmaps, we experiment with FastBit and our inverted index solutions with and without support for skipping. We present results from experiments with synthetic data and data from the Star Schema Benchmark (SSB) [14].

All experiments are run on a quad-core Intel Xeon CPU at 3 . 2 GHz with 16 GB main memory. All indexes are stored on disk, but queries are run warm by performing 10 runs during one invocation of the system, and reporting the av-erage from the last 8, thus measuring the in-memory query processing performance. We run FastBit version 1 . 0 . 5 (im-plemented in C++), with extra stack space to enable pro-cessing queries with many operands. Our approaches are im-plemented in Java (version 1 . 6). We use additional warm-up for our system to enable run-time optimizations in the Java virtual machine that reduce variance between runs. Addi-tional warm-up did not change the performance for FastBit. All queries compute the sum of the primary keys of the matching tuples, to ensure that the output from the index is used to perform table look-ups. In the table with uniform distributions, there were no tuples with value 0 for the high-est cardinality attribute, so all single valued predicates on this attribute was changed to require the value to be 2. The results are shown in Figure 2.

Compared to bitmaps, decompressed inverted lists are well suited for looking up other attributes for the qualify-ing tuples, a factor contributing to faster scans for uniform data. The difference in index size also seems to have an im-pact. All scans are relatively slow for Zipfian data because we always search for the most common attribute value in a skewed distribution, except for in the highest cardinality attribute as noted above.

Skewed AND favors methods capable of taking advantage of the different density in the operands. Inverted indexes with skipping are therefore efficient for uniform data, but introduce overhead for Zipfian data because both operands are dense when the most common values in skewed distribu-tions are accessed. FastBit performs well on dense operands, both because it can combine multiple logical TIDs using one CPU instruction, and because it performs the operator be-fore extracting the tuple references. Because neither input is smaller than the output for AND operators, FastBit decodes fewer references compared to the inverted indexes.

The multi-way OR operators in our solution demonstrate better scalability than FastBit with respect to the number of inputs for both tables.

The idea of skipping in OR operators is ideally suited for query type AND-OR , but it is only useful when the other operands to the AND return data that enables reasonable skip lengths, which occurs for high cardinality attributes with uniform distributions.
Star schemas represent a best practice for how to organize data in decision support systems, and are characterized by a central fact table that references several smaller dimension tables. Typical queries on such schemas involve joins of the fact table with relevant dimension tables called star joins. Figure 4: Query processing time in seconds for SSB queries. is over the attribute with the lowest cardinality, contribut-ing to the smaller performance difference between FastBit and inverted indexes for this query.
Several alternatives to the compression schemes discussed in this paper have been suggested both for bitmaps [4, 10, 5, 15, 21] and inverted indexes [25, 20, 1]. Experiments have shown that the query processing efficiency of WAH remains attractive, even though there are approaches resulting in smaller indexes. WAH is known to result in smaller indexes when the table is sorted on the indexed attribute [19, 12]. Due to space restrictions, we do not experiment with sorted tables in this paper. Experiments with compression in in-verted indexes in IR have shown that PForDelta currently is the most efficient technique [29], and further improvements to the technique have also been suggested recently [28].
As an alternative to compression, there are several ap-proaches that reduce the number of bitmaps in the index [17, 7, 8, 11, 22]. Strategies for operating on many bitmaps by processing two at a time have been explored for WAH-compressed bitmap indexes [26], and a recent paper suggests using multi-way operators for bitmaps, but the idea is not tested [12]. Query processing approaches in inverted indexes in IR have focused on term-at-a-time strategies in addition to the document-at-a-time approach used in this paper [6, 24, 18, 2, 3, 23].
In this paper, we have evaluated the applicability of com-pressed inverted indexes as an alternative to bitmap in-dexes in DSSs. Inverted indexes are generally significantly more space efficient. The only case where WAH-compressed bitmaps are clearly more compact is when the cardinality of the indexed attribute is very low. FastBit performs well on simple queries with dense operands, but inverted indexes are better in other cases, often significantly.

Acknowledgments: This material is based upon work supported by New York State Science Technology and Aca-demic Research under agreement number C050061, by Grant NFR 162349, by the National Science Foundation under Grants 0534404 and 0627680, and by the iAd Project funded by the Research Council of Norway. Any opinions, findings
