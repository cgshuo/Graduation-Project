 Thorsten Joachims tj@cs.cornell.edu For some applications, the examples for which a pre-diction is needed are already known when training the classifier. This kind of prediction is called Transduc-tive Learning (Vapnik, 1998). An example of such a task is relevance feedback in information retrieval. In relevance feedback, users can give positive and neg-ative examples for the kinds of documents they are interested in. These documents are the training ex-amples, while the rest of the collection is the test set. The goal is to generalize from the training examples and find all remaining documents in the collection that match the users information need.
 Why is the transductive setting different from the reg-ular inductive setting? In the transductive setting, the learner can observe the examples in the test set and potentially exploit structure in their distribution. Several methods have been designed with this goal in mind. Vapnik introduced transductive SVMs (Vap-nik, 1998) which were later refined by (Bennett, 1999) and (Joachims, 1999). Other methods are based on s-t mincuts (Blum &amp; Chawla, 2001) or on multi-way cuts (Kleinberg &amp; Tardos, 1999). Related is also the idea of Co-Training (Blum &amp; Mitchell, 1998), which exploits structure resulting from two redundant repre-sentations. We will study what these approaches have in common and where they have problems. In partic-ular, we will focus on s-t Mincuts, Co-Training, and TSVMs and show that they have undesirable biases that require additional, difficult to control heuristics. To overcome this problem, we first propose and moti-vate a set of design principles for transductive learn-ers. Following these principles, we introduce a new transductive learning method that can be viewed as a transductive version of the k nearest-neighbor ( k NN) rule. One key advantage is that it does not require greedy search, but leads to an optimization problem that can be solved efficiently and globally optimally via spectral methods. We evaluate the algorithm em-pirically on 6 benchmarks, showing improved and more robust performance than for transductive SVMs. Fur-thermore, we show that Co-Training emerges as a spe-cial case and that the new algorithm performs substan-tially better than the original Co-Training algorithm. The setting of transductive inference was introduced by V. Vapnik (see (Vapnik, 1998)). The learning task is defined on a fixed array X of n points ( x 1 , x 2 , ..., x Each data point has a desired classification Y = ( y 1 ,y 2 , ..., y n ). For simplicity, let X  X  assume the labels y i are binary, i.e. y i points x are vectors in N . For training, the learner receives the labels for a random subset of l&lt;n (training) data points. The goal of the learner is to predict the labels of the remaining (test) points in X as accurately as possible.
 Vapnik gives bounds on the deviation of error rates observed in the training sample and in the test sam-ple (Vapnik, 1998) . The bounds depend on the ca-pacity d L X of the hypothesis space H L X ,whichcanbe measured, for example, as the number of different la-belings the learner L can potentially produce on X . The smaller d L X , the smaller the bound. Following the idea of structural risk minimization (SRM) (Vap-nik, 1998), one can consider a sequence of learners L , L 2 , ... with nested hypothesis spaces so that their ture is well aligned with the learning task, the bound limits the generalization error. What information can we exploit to built a good structure? In contrast to inductive learning, the transductive learner can analyze the location of all data points x  X  X , in particular those in the test set. Therefore, a transductive learner can structure its hypothesis space based on X . How can the location of the test points help design a good hypothesis space? Imagine we knew the labels of all examples x i  X  X ,in-cluding both the training and the test examples. Let X  X  call this the perfect classification. If we gave all these examples to an inductive learner L ind ,itwouldbe learning from a large training set and it might be rea-sonable to assume that L ind learns an accurate classi-fier. For example, our experience might tell us that for text classification, SVMs typically achieve low predic-tion error if we have at least 10,000 training examples. Therefore, if X contains 10,000 data points, we would expect that an SVM given all labels Y achieves low leave-one-out cross-validation error Err L SV M loo ( X, Y )on ( X, Y ), since Err L loo ( X, Y ) is an (almost) unbiased es-timate of the prediction error that typically has low variability.
 How can this help a transductive learner that has ac-cess to only a small subset Y l of the labels? Assum-ing that an inductive learner L ind achieves low pre-diction error when trained on the full X implies that the perfect classification of the test set is highly self-consistent in terms of leave-one-out error. If a trans-ductive learner L trans uses only those labelings of the test set for which the corresponding inductive learner L trans has low leave-one-out error, the transductive learner will not exclude the perfect classification, while potentially excluding bad labelings. This suggests the following SRM structure for a transductive learner leading to a general principle for defining a transduc-tive learner from an inductive learner. A transductive learner should label the test set so that Postulate 1: it achieves low training error, and Postulate 2: the corresponding inductive learner is While initially not phrased in these terms, a trans-ductive SVM (Vapnik, 1998)(Joachims, 1999) follows these two postulates (Joachims, 2002). A trans-ductive SVM labels the test examples so that the margin is maximized. A large-margin SVM can be shown to have low leave-one-out error (Vapnik, 1998). Other transductive learning algorithms like transduc-tive ridge-regression (Chapelle et al., 1999) and min-cuts (Blum &amp; Chawla, 2001) minimize leave-one-out error as well. However, leave-one-out is not the only measure of self-consistency. The co-training algorithm (Blum &amp; Mitchell, 1998) maximizes consistency be-tween two classifiers. It will be discussed in more detail in Section 5.2.
 However, the following shows that Postulates 1 and 2 are not enough to define an effective transductive learner. Consider the case of k-Nearest Neighbor ( k NN) (k odd). The k NN-rule makes a leave-one-out error on example ( x i ,y i ), if the majority of the nearest neighbors are not from the same class. For a similarity-weighted k NN, we can define a margin-like quantity where w ij reflects the similarity between x i and x j . The similarity weighted k NN-rule makes a leave-one-out error whenever  X  i  X  0. Therefore, an upper bound on the leave-one-out error is While it is computationally difficult to find a label-ing of the test examples that minimizes the leave-one-out error of k NN while having a low training error, there are efficient algorithms for minimizing the upper bound (4). We can write this as the following opti-mization problem: In matrix notation, the objective can be written equiv-alently as y T A y where A ij = w ij among the k nearest neighbors of x i and zero oth-erwise. While the problem is typically not convex, there are efficient methods for its solution. In par-ticular, A can be thought of as the adjacency ma-trix of a graph, so that vertices represent examples and edges represent similarities (see Figure 1). At the solution y  X  ,denotewith G + the set of examples (i.e. vertices) with y i =1,andwith G  X  those with y of the graph. For an undirected graph, the cut-value edge-weights across the cut. Since the maximum of (5) is determined by the matrix entries A ij with y i y j  X  1, minimizing y mizes (5). Therefore, for undirected graphs, maximiz-ing (5) subject to (6)-(8) is equivalent to finding the s-t mincut where the positive examples form the source, and the negative examples form the sink. The s-t min-cut is a cut that separates positive and negative exam-ples while minimizing the cut value. This connects to the transduction method of Blum and Chawla (Blum &amp; Chawla, 2001). They use mincut/maxflow algo-rithms, starting from the intuition that the separation of positive and negative examples should put strongly connected examples into the same class. Blum and Chawla discuss the connection to leave-one-out error inthecaseof1-NN.
 While the s-t mincut algorithm is intuitively appeal-ing, it easily leads to degenerate cuts. Consider the graph in Figure 1, where line thickness indicates edge weight A ij . The graph contains two training examples which are labeled as indicated. All other nodes repre-sent test examples. While we would like to split the graph according to the two dominant clusters, the s-t mincut leads to a degenerate solution that just cuts off the positive example. The behavior is due to the fact that s-t mincut minimizes the sum of the weight, and that balanced cuts have more potential edges to cut. While using a sparser graph would help in the example, this degenerate behavior also occurs for k NN graphs whenever the correct partitioning has more  X  X rong X  neighbors than edges connecting the training exam-ples to the unlabeled examples. This is practically always the case for sufficiently large numbers of un-labeled examples. Consider an (undirected) 100-NN graph, where each example has 99 of its neighbors in the correct class, and 1 in the incorrect class. If there is one positive training example, then this example will on average have 200 in/out edges. So, if there are more than 200 unlabeled examples, s-t mincut will return a degenerate cut even for such a strongly clus-tered graph. Since these degenerate cuts fulfill Postu-late 1 (i.e. zero training error) and Postulate 2 (high self consistency in terms of leave-one-out), Postulates 1 and 2 do not yet specify a transductive learner suffi-ciently. One other reasonable constraint to put on the transductive solution is the following postulate. Postulate 3: Averages over examples (e.g. average Again, this postulate can be motivated using the per-fect classification. For example, the average margin of k NN should fulfill for the perfect classification, since the distribution P ( Y l ) of drawing a training set is uniform over all sub-sets.
 The s-t mincut violates Postulate 3 both for the pos/neg ratio, as well as for the average margin. In particular, training examples have negative mar-gins, while test examples have large margin. Other functions are conceivable as well (Joachims, 2002). Blum and Chawla experiment with different heuris-tics for pre-processing the graph to avoid degener-ate cuts. However, none appears to work well across all problems they study. Other transductive learning algorithms have similar degeneracies. For example, in transductive SVMs (Joachims, 1999) and in Co-Training (Blum &amp; Mitchell, 1998) the fraction of pos-itive examples in the test set has to be fixed a priori. Such constraints are problematic, since for small train-ing sets an estimated pos/neg-ratio can be unreliable. How can the problem of degenerate cuts be avoided in a more principled way? The problem of s-t mincut can be traced to its objec-tive function (5), which aims to minimize the sum of the edge weights cut through. The number of elements in the sum depends directly on the size of the two cut sets. In particular, the number of edges a cut with |
G + | vertices on one side and | G  X  | vertices on the other side can potentially cut through is | G + || G  X  | .Thes-t mincut objective is inappropriate, since it does not account for the dependency on the cut size. A natural way to normalize for cut size is by dividing the objec-tive with | G + || G  X  | . Instead of minimizing the sum of the weights, the following optimization problem mini-mizes the average weight of the cut. This problem is related to the ratiocut (Hagen &amp; Kahng, 1992). However, the traditional ratiocut prob-lem is unsupervised, i.e. there are no constraints (11) and (12). Solving the unconstrained ratiocut is known to be NP hard (Shi &amp; Malik, 2000). However, effi-cient methods based on the spectrum of the graph exist that give good approximations to the solution (Hagen &amp; Kahng, 1992). The following will generalize these methods to the case of constrained ratiocuts for transduction.
 Let X  X  denote with L = B  X  A the Laplacian of the graph with adjacency matrix A and diagonal degree matrix B , B ii = j A ij . We require that the graph is undi-rected, so that L is symmetric positive semi-definite. Following (Dhillon, 2001) and ignoring the constraints, the unsupervised ratiocut optimization problem can equivalently be written as straightforward to verify that z T z = n and z T 1=0 for every feasible point. While this problem is still NP hard, the minimum of its real relaxation is equal to the second eigenvalue of L and the corre-sponding eigenvector is the solution. Using this solu-tion of the relaxed problem as an approximation to the solution of (14) is known to be effective in practice. Moving to the supervised ratiocut problem, we pro-pose to include constraints (11) and (12) by adding a quadratic penalty to the objective function. For each labeled example, the corresponding element of  X  is equal to  X   X  + ( X   X   X  ) for positive (negative) exam-ples, and it is zero for test examples.  X   X  + and  X   X   X  are estimates of  X  + and  X   X  (e.g. based on the number of observed positive and negative examples in the train-ing data). We will see later that these estimates do not need to be very precise. c is a parameter that trades off training error versus cut-value, and C is a diagonal cost matrix that allows different misclas-sification costs for each example. Taking the eigen-decomposition L = U  X  U T of the Laplacian, one can introduce a new parameter vector w and substitute z = U w . Since the eigenvector of the smallest eigen-value of a Laplacian is always 1, the constraint (16) be-comes equivalent to setting w 1 =0. Let V ( D )bethe matrix with all eigenvectors U (eigenvalues  X ) except the smallest one, then we get the following equivalent optimization problem. Defining G =( D + cV T CV )and b = cV T C  X  ,the objective function can also be written as w T G w  X  2 b
T w + c  X  T C  X  , where the last term can be dropped since it is constant. Following the argument in (Gan-der et al., 1989), Problem (19)-(20) is minimized for w  X  =( G  X   X   X  I )  X  1 b ,where  X   X  is the smallest eigenvalue of I is the identity matrix. From this we can compute the optimal value of (17) and (18) as z  X  = V w  X  , producing a predicted value for each example. We can use this value to rank the test examples, or use a threshold to make hard class assignment. An obvious choice for the threshold is the midpoint  X  = 1 2 ( X   X  + + X   X   X  )whichwe will use in the following, but more refined methods are probably more appropriate. The basic method for computing supervised rati-ocuts suggests the following algorithm for trans-ductive learning, which we call a Spectral Graph Transducer (SGT). An implementation is available at http://sgt.joachims.org . Input to the algorithm are the training labels Y l , and a weighted undirected graph on X with adjacency matrix A . In the following, we will use the similarity-weighted k nearest-neighbor graph A over X symmetricized by A = A + A T . The first step preprocesses the graph, which has to be done only once:  X  Compute diagonal degree matrix B , B  X  Compute Laplacian L = B  X  A , or compute nor- X  Compute the smallest 2 to d + 1 eigenvalues and  X  To normalize the spectrum of the graph, replace Thefollowingstepshavetobedoneforeachnewtrain-ing set:  X  Estimate  X   X  + = l  X   X  To give equal weight to positive and negative ex- X  Compute G =( D + cV T CV )and b = cV T C  X  and  X  Compute predictions as z  X  = V ( G  X   X   X  I )  X  1 b ,  X  Threshold z  X  wrt.  X  = 1 5.1. Connection to Transductive SVMs The following argument shows the relationship of the SGT to a TSVM. We consider the TSVM as described in (Joachims, 1999). For hyperplanes passing through the origin, the TSVM optimizes For our analysis, we simplify this problem by adding the constraint  X  1 =  X  2 = ... =  X  n . Since the objective (23) can now be written as n X   X  1 2  X  2 y T A y where  X  is a scalar, the maximum is achieved for  X   X  = n y T A y . Substituting the solution into the objective shows that the value of the maximum is 1 2 n 2 yA y . This shows that the simplified TSVM problem is equivalent to an s-t mincut on graph A , where the balance of the cut is fixed by (27). The SGT removes the need for fixing the exact cut size a priori. 5.2. Connection to Co-Training Co-training can be applied, if there are two redun-dant representations A and B of all training exam-ples (Blum &amp; Mitchell, 1998). The goal is to train two classifiers h A and h B , one for each representation, so that their predictions are maximally consistent, i.e. h A ( x )= h B ( x ) for most examples x . With this goal, Blum and Mitchell propose a greedy algorithm that it-eratively labels examples for which one of the current classifiers is most confident. However, also for this al-gorithm the ratio of predicted positive and negative examples in the test set must be fixed a priori to avoid degenerate solutions.
 Co-training emerges as a special case of the SGT. Con-sider a k NN classifiers for each of the two representa-tions and note that n i =1 (2  X   X  A i  X   X  B i ) (see Eq. (3)) is an upper bound on the number of inconsistent pre-dictions. Therefore, to maximize consistency, we can apply the SGT to the graph that contains k links for the k NN from representation A, as well as another k links per example for the k NN from representation B. 5.3. Connections to other Work Several other approaches to using unlabeled data for supervised learning exist. Most related is the approach to image segmentation described in (Yu et al., 2002). They aim to segment images under higher level con-straints. One difference is that they arrive at con-strained cut problems where all the constraints are homogeneous, leading to a different technique for their solution. The spectrum of the Laplacian is also consid-ered in the recent work in (Chapelle et al., 2002) and (Belkin &amp; Niyogi, 2002). They use the leading eigen-vectors for feature extraction and the design of kernels. In addition, Chapelle et al. use the same normaliza-tion of the spectrum. Szummer and Jaakkola apply short random walks on the k NN graph for labeling test examples, exploiting that a random walk will less likely cross cluster boundaries, but stay within clusters (Szummer &amp; Jaakkola, 2001). There might be an in-teresting connection to the SGT, since the normalized cut minimizes the transition probability of a random walk over the cut (Meila &amp; Shi, 2001). This might also lead to a connection to the generative modeling approach of Nigam et al., where the label of each test example is a latent variable (Nigam et al., 2000). To evaluate the SGT, we performed experiments on six datasets and report results for all of them. The datasets are the ten most frequent categories from the Reuters-21578 text classification collection follow-ing the setup in (Joachims, 1999), the UCI Reposi-tory datasets OPTDIGITS (digit recognition), ISO-LET (speech recognition), IONOSPHERE, as well as the ADULT data in a representation produced by John Platt. To evaluate the Co-Training connection, we use the WebKB data of Blum and Mitchell with TFIDF weighting.
 The goal of the empirical evaluation is threefold. First, we will evaluate whether the SGT can make use of the transductive setting by comparing it against induc-tive learning methods, in particular k NN and a linear SVM. Second, we compare against existing transduc-tion methods, in particular a TSVM. And third, we evaluate how robustly the SGT performs over differ-ent data sets and parameter settings.
 For all learning tasks, both k NN and the SGT (with normalized Laplacian L = B  X  1 ( B  X  A )) use the cosine as the similarity measure. While this is probably sub-optimal for some tasks, the following results indicate that it is a reasonable choice. Furthermore, it equally affects both k NN and the SGT, so that relative com-parisons between the two remain valid. If an example has zero cosine with all other examples, it is randomly connected to k nodes with uniform weight.
 To make sure that performance differences against the other learning methods are not due to bad choices for their parameters, we give the conventional learning methods (i.e. k NN, SVM, TSVM) an unfair advan-tage. For these methods we report the results for the parameter setting with the best average performance on the test set . For the SGT, on the other hand, we chose c = 3200 and d = 80 constant over all datasets. The choice of k for building the k nearest-neighbor graph is discussed below.
 All results reported in the following are averages over 100 stratified transductive samples 1 . So, all substan-tial differences are also significant with respect to this distribution. Samples are chosen so that they contain at least one positive example. While we report er-ror rate where appropriate, we found it too unstable for a fair comparison with very unbalanced class ra-tios. We therefore use rank-based measures for most comparisons. The most popular such measure in infor-mation retrieval is the Precision/Recall curve, which we summarize by its Break-Even Point (PRBEP) (see e.g. (Joachims, 1999)). For tasks with multiple classes (i.e. Reuters, OPTDIGITS, and ISOLET), we summa-rize the performance by reporting an average over all classes (i.e. macro-averaging).
 Does the Unlabeled Data Help Improve Predic-tion Performance? The results are summarized in Table 1. On all tasks except Ionosphere, the SGT gives substantially improved prediction performance compared to the inductive methods. Also, the SGT performs better than k NN (as its inductive variant), on each individual binary task of Reuters and Optdig-its. For Isolet, the SGT performs better than k NN on 23 of the 26 binary tasks.
 The improvements of the TSVM are typically smaller. On Adult, the TSVM was too inefficient to be applied to the full dataset, so that we give the results for a subsample of size 2265. The TSVM failed to produce reasonable results for Isolet. While the TSVM does improve performance on Reuters, the improvement is less than reported in (Joachims, 1999). There, the as-sumption is made that the ratio of positive to negative examples in the test set is known accurately. However, this is typically not the case and we use an estimate based on the training set in this work. If the true fraction is used, the TSVM achieves a performance of 62.3. While (Joachims, 2002) proposes measures to de-tect when the wrong fraction was used, this can only be done after running the TSVM. Repeatedly trying different fractions is prohibitively expensive. How Effective is the SGT for Co-Training? Ta-ble 2 shows the results for the co-training on WebKB. We built the graph with 200NN from the page and 200NN from the links. The table compares the co-training setting with just using the page or the links, and a combined representation where both feature sets are concatenated. The SGT in the co-training set-ting achieves the highest performance. The TSVM also gives large improvements compared to the induc-tive methods, outperforming the SGT. However, the TSVM cannot take advantage of the co-training set-ting. The results from (Blum &amp; Mitchell, 1998) are added in the last column.
 For which Training Set Sizes is Transductive Learning most Effective? Figure 2 shows the dif-ference in average PRBEP between the SGT and k NN for different training set sizes. For all learn-ing tasks, the performance improvement is largest for small training sets. For larger sets, the performance of the SGT approaches that of k NN. The negative values are largely due to the bias from selecting the param-eters of k NN based on the test set. If this is also allowed for the SGT, the differences vanish or become substantially smaller.
 How Sensitive is the SGT to the Choice of the Number of Eigenvectors? Figure 3 plots the loss of PRBEP compared to the PRBEP achieved on the test set for the optimal number of eigenvectors. On all tasks, the SGT achieves close to optimal performance, if more than 40 eigenvectors are included. We conclude that d  X  40 should be sufficient for most tasks. How Sensitive is the SGT to the Choice of the Error Parameter? Analogous to Figure 3, Figure 4 plots the loss of PRBEP compared to the best value of c . Due to the normalization of the spectrum of the Laplacian, the optimum values of c are comparable between datasets. For most tasks, the performance is less than two PRBEP points away from the optimum for any c between 1600 and 12800. An exception is Isolet, which requires larger values. We conclude that any c between 3200 and 12800 should give reasonable performance for most tasks.
 How Sensitive is the SGT to the Choice of the Graph? Unlike c and d , the choice of k for building the k nearest-neighbor graph has a strong influence on the performance. The top part of Figure 5 shows aver-age PRBEP depending on k . How should we select k ? For small training set sizes (often only one positive ex-ample), cross-validation is not feasible. However, the value of the objective function can be interpreted as a measure of capacity and might be suitable for model selection. The bottom half of Figure 5 shows the aver-age value of the objective function after normalization. In particular, the objective value o ik for training set i and choice of k is normalized to o norm ik = o ik min The average normalized objective tracks the perfor-mance curve very well, suggesting that there might be an interesting connection between this value and the capacity of the SGT. For all experiments reported in the previous section, we used the value of k that min-imizes the average normalized objective. For Adult, this is k = 100, for Reuters k = 800, for Optdigits k = 10, for Isolet k = 100, for Ionosphere k = 100, and for Co-Training k =2  X  200. Such a kind of model selection might be particularly useful for tasks like rel-evance feedback in information retrieval, where there are many learning tasks with few examples on the same collection of objects.
 How Efficiently can the SGT be Trained? Due to our naive implementation, most of the time is spent on computing the k -NN graph. However, this can be sped up using appropriate data structures like inverted indices or KD-trees. Computing the 81 smallest eigen-values takes approximately 1.5 minutes for a task with 10,000 examples and 100 neighbors on a 1.7GHz CPU using Matlab. However, these preprocessing steps have to be performed only once. Training on a particular training set and predicting 10,000 test examples takes less than one second. We studied existing transductive learning methods and abstracted their principles and problems. Based on this, we introduced a new transductive learning method, which can be seen as the a transductive ver-sion of the k NN classifier. The new method can be trained efficiently using spectral methods. We evalu-ated the classifier on a variety of test problems showing substantial improvements over inductive methods for small training sets. Unlike most other algorithms that use unlabeled data, it does not need additional heuris-tics to avoid unbalanced splits. Furthermore, since it does not require greedy search, it is more robust than existing methods, outperforming the TSVM on most tasks. Modeling the learning problem as a graph offers a large degree of flexibility for encoding prior knowledge about the relationship between individual examples. In particular, we showed that Co-Training arises as a special case and that the new algorithm outperforms the original Co-Training algorithm. The algorithm opens interesting areas for research. In par-ticular, is it possible to derive tight, sample dependent capacity bounds based on the cut value? Furthermore, it is interesting to consider other settings beyond co-training that can be modeled as a graph (e.g. temporal drifts in the distribution, co-training with more than two views, etc.).
 This research was supported in part by the NSF projects IIS-0121175 and IIS-0084762 and by a gift from Google. Thanks to Lillian Lee, Filip Radlinski, Bo Pang, and Eric Breck for their insightful comments. Belkin, M., &amp; Niyogi, P. (2002). Semi-supervised learning on manifolds. NIPS .
 Bennett, K. (1999). Combining support vector and mathematical programming methods for classifica-tion. In B. Sch  X  olkopf et al. (Eds.), Advances in ker-nel methods -support vector learning . MIT-Press. Blum, A., &amp; Chawla, S. (2001). Learning from labeled and unlabeled data using graph mincut. ICML . Blum, A., &amp; Mitchell, T. (1998). Combining labeled and unlabeled data with co-training. COLT .
 Chapelle, O., Vapnik, V., &amp; Weston, J. (1999). Trans-ductive inference for estimating values of functions. NIPS .
 Chapelle, O., Weston, J., &amp; Schoelkopf, B. (2002). Cluster kernels for semi-supervised learning. NIPS . Dhillon, I. (2001). Co-clustering documents and words using bipartite spectral graph partitioning. KDD Conference .
 Gander, W., Golub, G., &amp; von Matt, U. (1989). A constrained eigenvalue problem. Linear Algebra and its Applications , 114/115 , 815 X 839.
 Hagen, L., &amp; Kahng, A. (1992). New spectral meth-ods for ratio cut partitioning and clustering. IEEE Transactions on CAD , 11 , 1074 X 1085.
 Joachims, T. (1999). Transductive inference for text classification using support vector machines. ICML . Joachims, T. (2002). Learning to classify text using support vector machines  X  methods, theory, and al-gorithms .Kluwer.
 Kleinberg, J., &amp; Tardos, E. (1999). Approximation algorithms for classification problems with pairwise relationships: Metric labeling and markov random fields. FOCS .
 Meila, M., &amp; Shi, J. (2001). A random walks view of spectral segmentation. AISTATS .
 Nigam, K., McCallum, A., Thrun, S., &amp; Mitchell, T. (2000). Text Classification from Labeled and Unla-beled Documents using EM. Machine Learning , 39 , 103  X  134.
 Shi, J., &amp; Malik, J. (2000). Normalized cuts and image segmentation. PAMI .
 Szummer, M., &amp; Jaakkola, T. (2001). Partially labeled classification with markov random walks. NIPS . Vapnik, V. (1998). Statistical learning theory . Wiley. Yu, S. X., Gross, R., &amp; Shi, J. (2002). Concurrent object recognition and segmentation by graph par-
