 Probabilistic and Statistical Inference Group Ranking is the central problem for many information retrieval applications such as web search, collaborative filtering and document retrieval [8]. In these problems, we are given a set of objects to be ranked and a series of observations where each observation consists of some subset of the objects, a feature vector and some ordering of the objects with highly ranked objects corresponding to a higher relevance or degree of importance. The goal is to then learn a model which allows us to assign a score to new test objects: this often takes the form of a ranking function [2, 4] which assigns a higher score to objects with higher rankings. Unlike the canonical problems of regression or classification in which we predict outputs independently of one another, in ranking we are interested in predicting structured outputs, as the rank of one item can only be determined given the scores of all other items, and so complex inter-dependencies exist between outputs. This requires measures of loss which are multivariate and structured. However, such ranking measures are typically difficult to optimize directly [3], making the problem of learning difficult. A previous approach has been to treat the problem as one of structured prediction [7], where the aim is to directly optimize ranking measures. Another approach has been to approximate these ranking measures with smooth differentiable loss functionals by formulating probabilistic models on pairwise preferences between objects (RankNet; [2]), or on ordered lists of objects (ListNet and ListMLE; [4, 13]). In practice, these methods either require approximating a learning problem with an intractable number of constraints, or they require observations containing complete orderings over the objects to be ranked or one must make independence assumptions on pairwise preferences.
 In practice however, we can take advantage of the fact that each observation in the training set only provides preference information about a small subset of the objects to be ranked, so that a sensible probabilistic representation would be the probability of observing a partial ordering over nodes for a given observation. We will show that 1) a probability over orderings is equivalent to a probability over pairwise inequalities between objects to be ranked and 2) this amounts to specifying a joint cumulative distribution function (CDF) over pairwise object preferences. We will present a framework for ranking using the recently-developed probabilistic graphical modelling framework of CDNs which compactly represents this joint CDF as a product of local functions [5]. While the problem of inference in CDNs was addressed in [5], here we address the problem of learning in CDNs in the context of ranking learning where we estimate model parameters under a structured loss functional that accounts for dependencies between pairwise object preferences. We will then test the proposed framework on the OHSUMED dataset [8], a benchmark dataset used in information retrieval research. Finally we will show that the frameworks proposed by [2, 4, 13] can be viewed as particular types of CDNs so that novel classes of flexible structured loss functionals for ranking learning can be specified under our framework. The CDN [5] is an undirected graphical model in which the joint CDF F ( z ) over a set of random variables is represented as a product over functions defined over subsets of these variables. More formally, where  X  c ( z c ) is a function defined over some subset of variables. An example of a CDN is shown in Figure 1(a), along with an example bivariate density which can be obtained by differentiating a product of 2 Gaussian CDF functions (Figure 1(b)).
 In contrast to undirected models for probability density functions, the global normalization con-straint on the CDF does not require computing a partition function and can be enforced locally for functions  X  c satisfy all of the properties of a multivariate CDF. These properties include the require-ments that each CDN function  X  c be bounded between 0 and 1, and that each  X  c is monotonically non-decreasing with respect to all of its argument variables z c , so that the joint CDF F ( z ) is also bounded between 0 and 1 and is monotonically non-decreasing with respect to any and all subsets of variables. In a CDN, disjoint sets of variables A, B are marginally independent if they share no functions in common, and disjoint sets of variables A, B are conditionally independent given vari-able set C if no path linking any variable in A to any variable in B passes through C . In addition, marginalization of variables in a CDN can be done in constant-time via a trivial maximization of the joint CDF with respect to the variables being marginalized. The problem of inference in a CDN can be solved efficiently using a message-passing algorithm called derivative-sum-product. For detailed derivations of the properties of CDNs, including marginal and conditional independence properties, we refer the reader to [5]. The CDN framework provides us with a means to compactly represent multivariate joint CDFs over many variables: in the next section we will formulate a loss functional for learning to rank which takes on such a form. Figure 1: a) Cumulative distribution network representing the joint CDF F ( z 1 ,z 2 ,z 3 ,z 4 ,z 5 )= We now proceed to formulate the problem of learning to rank in a structured setting. Suppose we wish to rank N nodes in the set V = { V 1 ,  X  X  X  ,V N } and we are given a set of observations D 1 ,  X  X  X  ,D T . Each observation D t consists of an ordering over the nodes in a subset V t  X  X  , where each node is provided with a corresponding feature vector x  X  R L which may be specific to the given observation. The orderings could be provided in the form of ordinal node labels 1 ,orinthe form of pairwise node preferences. The orderings can be represented as a directed graph over the nodes in which a directed edge e =( V i  X  V j ) is drawn between 2 nodes V i ,V j iff V i is preferred to node V j , which we denote as V i V j . In general, we assume that for any given observation, we observe a partial ordering over nodes, with complete orderings being a special case. We denote the above graph consisting of edges e =( V i  X  V j )  X  X  t and the node set V t as the order graph G over 4 nodes is shown in Figure 2(a). Note that under this framework, the absence of an edge between two nodes V i ,V j in the order graph indicates we cannot assert any preference between the two nodes for the given observation. We now define  X  : V X  R as a ranking function which assigns scores to nodes via their feature vectors so that for node V i , given multiple observations D 1 ,  X  X  X  ,D T so that we minimize the probability of misranking on test observations (Figure 2(b)). The above model allows us to account for the fact that the amount of uncertainty about a node X  X  rank may depend on unobserved features for that node (e.g.: documents associated with certain keywords might have less variability in their rankings than other documents). Under this model, the preference relation V i V j is completely equivalent to where we have defined  X  ij as a preference variable between nodes V i ,V j .
 preferences, we must select an appropriate loss measure. A sensible metric here [13] is the joint probability of observing the order graph G t =( V t , E t ) corresponding to the partial ordering of nodes in V t . From Equation (3), this will take the form of a probability measure over events of the type  X  e  X  r (  X  ; e, D t ) so that we obtain where F  X  is the joint CDF over the preference variables  X  e . Given an observation D t , the goal is to learn the ranking function  X  by maximizing Equation (4). Note that under this framework, the set of edges E t corresponding to the set of pairwise preferences are treated as random variables which may have a high degree of dependence between one another, so that F  X  r (  X  ; G t ) is a joint CDF over multiple pairwise preferences. The problem of learning the ranking function then consists of scoring multiple nodes simultaneously whilst accounting for dependencies between node scores. Now, if we are given multiple independent (but not necessarily identically distributed) observations D = { D 1 ,  X  X  X  ,D T } , we can define a structured loss functional where each term in the loss functional depends on multiple preference relationships specified by the order graph for observation t . The problem of learning then consists of solving the optimization problem In general, the above structured loss functional may be difficult to specify, as it takes on the form of a joint CDF over many random variables with a high degree of inter-dependency which may require a large number of parameters to specify. We can, however, compactly represent this using the CDN framework, as we will now show. 3.1 Tranforming order graphs into CDNs Figure 3: Transforming the order graph G t into a CDN. For each edge e =( V i  X  V j ) in the order graph The representation of the structured loss functional in Equation (5) as a CDN consists of transform-ing the order graph G t for a each observation into a set of variable nodes in a CDN. More precisely, for each edge e =( V i  X  V j ) in the order graph, the preference variable  X  ij is created. All such variables are then connected to one another in a CDN (Figure 3), where the pattern of connectivity used will determine the set of dependencies between these preferences  X  ij as given by the marginal and conditional independence properties of CDNs [5]. Thus for any given CDN topology, each preference node  X  e is a member of some neighborhood of preference nodes  X  e so that neighboring preferences nodes are marginally dependent of one another.
 One possible concern here is that we may require a fully connected CDN topology over all possible pairwise preferences between all nodes in order to capture all of these dependencies, leading to a model which is cumbersome to learn. In practice, because any observation only conveys information about a small subset of the nodes in V and because in practice we observe partial orderings between these, the order graph is sparse and so the number of preference nodes in the CDN for the given observation will be much smaller than the worst-case number of all possible pairwise preferences between nodes. Furthermore, we do not have to store a large CDN in memory during training, as we only need to store a single CDN over a relatively small number of preference variables for the current observation. We can thus perform ranking learning in an online fashion by constructing a single CDN for each observation D t and optimizing the loss  X  log F  X  r (  X  ; G t ) defined by that CDN for the given observation. Suppose now that each node in the training set is provided with an ordinal node label y along with a feature vector x . For any given order graph over some subset of the nodes, the node labels y allow us to establish edges in the order graph, so that an edge V i  X  V j exists between two nodes V i ,V j iff y &gt;y j . We can then parametrically model the ranking function  X  ( V )  X   X  ( x ; a ) (where a is a set of parameters) using a Nadaraya-Watson [10, 12] local estimator with a Gaussian kernel so that where the summations are taken over all feature vector-label pairs in the training set, with A = diag ( a 2 1 ,  X  X  X  ,a 2 L ) . Consider now an edge e =( V i  X  V j ) in the order graph and define r e  X  r given by where  X  = a w 1 w 2 is the parameter vector and the function  X  ( r 1 ,r 2 ) set to a multivariate sigmoidal function so that where w 1 ,w 2 are weights parameterizing the CDN function  X  ( r 1 ,r 2 ) . It can be readily shown that all of the necessary and sufficient conditions required for the CDN to represent a valid CDF, as 0  X   X  ( r 1 ,r 2 )  X  1 and is monotonically non-decreasing with respect to all of its arguments. For the given CDN and ranking functions, the learning problem for the current observation D t then becomes inf where we have introduced a regularizer in the form of an L 1 -norm constraint. Notice that our model has one parameter per data feature and 2 parameters defining the CDN for any given observation. The gradient  X  a L (  X  ; D t ) and the derivatives with respect to the CDN function weights w 1 ,w 2 for a given observation D t are provided in the Supplementary Information. To compare the performance of our proposed framework to other methods, we will use the following three metrics commonly in use in information retrieval research: Precision, Mean Average Precision (MAP) and Normalized Discounted Cumulative Gain (NDCG) [6]. The NDCG accounts for the fact that less relevant documents are less likely to be examine by a user by putting more weight on highly relevant documents than marginally relevant ones.
 We downloaded the OHSUMED dataset provided as part of the LETOR 2.0 benchmark [8]. The dataset consists of a set of 106 query-document pairs, with a feature vector and relevance judgment Figure 4: a) Average NDCG as a function of truncation level n for the OHSUMED dataset. NDCG values are provided for each pair, where queries correspond to medical searches associated with patient and topic information. There are a total of 16,140 query-document pairs with relevance judgments pro-vided by humans on three ordinal levels: definitely relevant , partially relevant or not relevant .For any given query, we used the ordinal labels y for each document in the query in order to establish preferences between documents for that query. Each node in the order graph is provided with 25 query-specific features including term frequency, document length, BM25 and LMIR features as well as combinations thereof [1, 11, 14]. In accordance with the nomenclature above, we use the terms query and observation interchangeably.
 The OHSUMED dataset is provided in the form of 5 training/validation/test splits of sizes 63/21/22 observations each. To ensure that features are comparable across all observations, we normalized each feature vector within each observation as described in [8]. We performed learning of our model using a constrained stochastic gradients algorithm where for each observation, we prevent updates from violating the inequality constraints in the optimization problem defined by Equation (10) by reducing the learning rate  X  until the update becomes feasible. We set the default learning rate to  X  =0 . 5 and we randomly initialized the model parameters a ,w 1 ,w 2 in the range [0 , 1] . This optimization was run for 10 epochs (passes through the training set) and  X  was scaled by 1  X  2 at the end of each epoch. We set the regularization parameter using the validation set for a given data split. Due to the nonconvex nature of the optimization problem, for each cross-validation split, we performed learning using 3 random initializations, and we then selected the model which achieved the best MAP score on the validation set.
 We tested a fully connected CDN which models full interdependence between preferences, and a completely disconnected CDN which models preferences independently of one another. The above 3 performance metrics are shown in Figures 4(a),4(b),4(c) in addition to the performances of seven state-of-the-art methods which are part of the LETOR 2.0 benchmarks. At the time of submission, numerical performance scores for ListMLE [13] were not available and so were not included in these plots. With the exception of ListNet and ListMLE, none of the above methods explicitly model dependencies between pairwise preferences. As can be seen, accounting for dependencies between pairwise preferences provides a significant gain in performance compared to modellling preferences as being independent. Additional results on the TREC2004 dataset from LETOR 2.0 are provided in Supplemental Information. We have proposed here a novel framework for ranking learning using structured loss functionals. We have shown that the problem of learning to rank can be reduced to maximizing a joint CDF over multiple pairwise preferences. We have shown how to compactly represent this using the CDN framework and have applied it to the OHSUMED benchmark dataset. We have demonstrated that representing the dependencies between pairwise preferences leads to improved performance over modelling preferences as being independent of one another. 6.1 Relation to RankNet and ListNet/ListMLE The probability models for ranking proposed by [2, 4, 13] can all be expressed as special cases of models defined by different CDNs. In the case of RankNet [2], the corresponding probability over a was optimized using cross-entropy loss. The joint probability of preferences can thus be represented as a completely disconnected CDN with logistic functions in which all pairwise object preferences are treated as being independent. In the case of ListNet [4] and ListMLE [13], the probability of observing a complete ordering V 1  X  X  X  V N over N objects are defined as products of functions of the type P ( V 1  X  X  X  V N | D )= which we see is equivalent to a CDN with N multivariate sigmoids. As noted by the authors of [13], the above model is also an example of the Plackett-Luce class of probability models over object scores [9]. In addition, the ListNet/ListMLE frameworks both require a complete ordering over objects by definition: under the CDN framework, we can model partial orderings, with complete orderings as a special case. The connections between RankNet, ListNet and ListMLE and the CDN framework are illustrated in Supplementary Figure 2. Our proposed framework unifies the above views of ranking as different instantiations of a joint CDF over pairwise preferences and hence as particular types of CDNs. This allows us to consider flexible joint CDFs defined over different subsets of object preferences and over different families of CDN functions so as to capture various data specific properties. 6.2 Future directions Our work here suggests several future directions for research. In [13], it was shown that the log-likelihood corresponding to the probability of an ordering is a good surrogate to the 0-1 loss be-tween the predicted ordering and the true ordering, as the former is differentiable and penalizes mis-orderings in a sensible way. One could investigate connections between the structured loss functionals proposed in this paper and other ranking measures such as NDCG. Another possible di-rection is to generalize StructRank to products over Gaussian multivariate CDFs or other classes of functions which satisfy the requirements of CDN functions , as in this paper we have elected to use a product of bivariate sigmoids  X  ( r e ,r e ) to represent our loss functional. Also, it may be fruitful to investigate different CDN topologies: for example, we found that averaging randomly connected CDNs are very fast to learn and perform comparably to the fully-connected CDN we used in this paper (data not shown). In addition, we have only investigated representing the loss functional using a single CDN function: this could easily be generalized to K functions. Lastly, alternatives to the Nadaraya-Watson local estimator, such as the neural networks used in [2, 4, 13], can be investigated. [1] R. Baeza-Yates and B. Ribeiro-Neto. Modern information retrieval. Addison Wesley , 1999. [2] C.J.C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton and G. Hullender.
Learning to rank using gradient descent. In Proceedings of the Twenty-Second International Con-ference on Machine Learning (ICML) , 2005. [3] C.J.C. Burges, R. Ragno and Q.V. Le. Learning to rank with nonsmooth cost functions. In Pro-ceedings of the Nineteenth Annual Conference on Neural Information Processing Systems (NIPS) , 2007. [4] Z. Cao, T. Qin, T.Y. Liu, M.F. Tsai and H. Li. Learning to rank: from pairwise approach to listwise approach. In Proceedings of the Twenty-Fourth International Conference on Machine
Learning (ICML) , 2007. [5] J.C. Huang and B.J. Frey. Cumulative distribution networks and the derivative-sum-product al-gorithm. In Proceedings of the Twenty-Fourth Conference on Uncertainty in Artificial Intelligence (UAI) , 2008. [6] K. Jarvelin and J. Kekalainen. Cumulated evaluation of IR techniques, ACM Information Sys-tems , 2002. [7] T. Joachims. A support vector method for multivariate performance measures. In Proceedings of the Twenty-Second International Conference on Machine Learning (ICML) , 2005. [8] T.Y. Liu, J. Xu, T. Qin, W. Xiong and H. Li. LETOR: Benchmark dataset for research on learning to rank for information retrieval. LR4IR 2007, in conjunction with SIGIR 2007 , 2007. [9] J. I. Marden. Analyzing and modeling rank data. CRC Press , 1995. [10] E.A. Nadaraya. On estimating regression. Theory of Probability and its Applications 9(1) , pp. 141-142, 1964. [11] S.E. Robertson. Overview of the OKAPI projects. Journal of Documentation 53 (1) , pp. 3-7, 1997. [12] G.S. Watson. Smooth regression analysis. The Indian Journal of Statistics. Series A 26 , pp. 359-372, 1964. [13] F. Xia, T.Y. Liu, J. Wang, W. Zhang and H. Li. Listwise approach to learning to rank -theory and algorithm. In Proceedings of the Twenty-Fifth International Conference on Machine Learning (ICML) , 2008. [14] C. Zhai and J. Lafferty. A study of smoothing methods for language models applied to ad hoc
