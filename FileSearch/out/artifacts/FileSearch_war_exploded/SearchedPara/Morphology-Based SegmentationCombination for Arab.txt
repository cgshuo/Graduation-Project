 YASSINE BENAJIBA Center for Computational Learning Systems, Columbia University and IMED ZITOUNI IBM T. J. Watson Research Center 1. INTRODUCTION Information extraction is a crucial step toward understanding a text, as it iden-tifies the important conceptual objects in a discourse. Examples of information extraction tasks are identification of the actors and the objects in written text. It includes classification, filtering, and selection based on the language con-tent of the source data, that is, based on the meaning conveyed by the data. These tasks have applications in summarization, information retrieval, data mining, question answering, language understanding, etc. We address in this article one important and basic task of information extraction that is men-tion detection (MD), adopting the Automatic C ontent Extraction (ACE) [NIST 2007] nomenclature. The goal of this task is to identify and characterize the main actors in a document: people, locations, organizations, geo-political en-tities, etc. It represents one of the most important steps in the information extraction processing pipeline, as identifying the participants in a discourse is essential to the understanding of the text: it is the first step in determin-ing who did what and where . This task is similar to named entity recognition (NER), as the objects of interest represent very similar concepts, but the latter will identify only named references, while the former identifies named, nomi-nal and pronominal references. In this article, we call the resulting references mentions to differentiate the concept from entities which are the real-world ob-jects (the actual person, location, etc.) to which the mentions are referring. For instance, in the sentence there are four mentions: President , Barack Obama , he ,and Middle East .The first three mentions are nominal, named, and pronominal mentions respec-tively referring to a person, while the last one is a named mention referring to a geopolitical entity.
 Marcus 1995], named entity recognition [Tjong Kim Sang 2002], and previous work on mention detection [Florian et al. 2004; Zitouni et al. 2005; Benajiba et al. 2008], we formulate mention detection as a sequence classification prob-lem by assigning a label to each token in the text, indicating whether it starts a specific mention, is inside a specific mention, or is outside any mentions. Us-ing such an approach requires us to pay great attention to the selection of unit of analysis (i.e., token), which is an important step toward a better classifica-tion. When processing languages such as English, using a word as the unit of analysis after separating punctuations leads to good performance [Florian et al. 2004]. For other languages, such as Chinese, character is considered as the unit of analysis (i.e., split all words into individual characters), thus for every character in the document, the system decides whether it is the begin-ning of a mention, inside a mention, or outside a mention [Jing et al. 2003]. of analysis when building Arabic mention detection systems. Arabic employs a very complex morphology where a word is composed of zero or more prefixes, one stem and zero or more suffixes. For instance, Table I shows some of the possible prefixes and suffixes which could be agglutinated to the word ( ktAb  X   X  X ook X ) together with a Roman transliteration and a translation to English. The table shows that the English word  X  X ook X  has appeared in the same surface form in all the expressions, whereas its equivalent in Arabic has appeared in a different surface form in each one of them. From a statisti-cal viewpoint this means that the Arabic text has a more reduced vocabulary and thus the data is sparser. From an NLP viewpoint, especially the super-vised tasks such as the one we present in this article, this implies that a large amount of annotated data is necessary in order to be able to train efficient models. One approach to tackle this problem is to segment Arabic words into several units of analysis. If we consider a character as the unit of analysis for Arabic MD, as is the case for Chinese [Jing et al. 2003], the presentation of the context becomes very difficult. On the other hand, it is better than using the white-space delimited word as the analysis unit since it leads to data sparse-ness. Zitouni et al. [2005] used Arabic morphologically segmented data and claimed to have very competitive results in ACE 2005 and ACE 2007 data. On the other hand, Benajiba et al. [2008] report good results for the NER system on ACE 2003, 2004, and 2005 data using Arabic TreeBank (ATB) segmenta-tion. None of these authors explained their motivation for the used segmenta-tion scheme.
 build an Arabic MD system that has very competitive results when compared to other systems in the ACE evaluation campaign [NIST 2007]. We also in-vestigate different segmentation schemes and we show how the use of more than one segmentation scheme can lead to an improvement of the overall sys-tem performance. We explore here the f our known and linguistically moti-vated sorts of segmentations: punctuation separation, ATB, morphological and character-level segmentations. We conducted experiments with Arabic MD systems built with a varied number of features, starting with a case where only access to lexical information is available to a case where we use all the resources we could gather. Results show that ATB and morphological seg-mentations are more appropriate for Arabic. When limited resources are used (lexical and syntactic information), the use of morphological segmentation leads to a better performance when compared to ATB segmentation and oth-ers. This is because it better handles the data sparseness problem and at the same time appropriately manages the contextual information. When larger resources become available, the two segmentation approaches become very competitive and their combination leads to further improvement in Arabic MD system performance.
 segmentation schemes to define the unit of analysis that fits best Arabic MD. In all published works, authors do not mention a specific motivation for the segmentation scheme they have adopted. Only for the machine translation task, Habash and Sadat [2006] report several results using different Arabic segmentation schemes. They report that the best results were obtained when the ATB-like segmentation was used.
 ferent segmentation schemes for Arabic data in Section 2. In Section 3 we introduce the mention detection system that we used in our experiments and the employed feature pool. We give details about our data in Section 4, we show our experiments and the obtained results in Section 5, and we draw our conclusions in Section 6.
 thesis its transliteration and English translation separated by  X  X  X . 2. ARABIC SEGMENTATION SCHEMES This section briefly presents the different kinds of possible and known segmen-tations for Arabic: punctuation separation, Arabic Treebank, morphological, and character-level segmentations.
 that each character is a separate token. Consequently, the character-level segmentation for the word (wmktbth  X  and his library) would be: segmenting all affixes of a word. Thus, all the prefixes and suffixes that are attached to the stem are separated. The morphological segmentation for the example mentioned earlier could be: +h). As one may notice here, the suffix ( t  X  feminine marker) is separated from the word. The parse tree of this word after full segmentation is as follows: tation adopted to build parse trees in the Arabic TreeBank (ATB) corpus [Maamouri et al. 2004]. This type of segmentation considers splitting the word into affixes only and only if it projects an independent phrasal constituent in the parse tree. As an example, in the word (wmktbth  X  and his library) mentioned earlier, the phrasal independent constituents are (i) conjunction ( w  X  and), (ii) noun and the head of a noun phrase (NP) and (iii) a pronoun (PRON) (h  X  his). This would lead to the following parse tree: separate the suffix ( t  X  feminine marker) from the word library). Since the (and generally all the suffixes which are gender marks) are not independent constituents as shown in the previous parse tree, they are not considered for ATB segmentation. Thus, the ATB segmentation scheme considers splitting only a subset of prefixes and suffixes from the stem. For the word (wmktbth  X  and his library), the ATB segmentation would be mentation are 1 (1)  X  , X  ( l  X  X o),(2) X   X ( b  X  X n),(3) X   X ( w  X  and), and (4)  X   X  ( k  X  as). Possible segmented suffixes are the possessive personal pronouns such as  X   X ( y  X  X y), X   X , ( hm  X  X heir), X   X ( km  X  yours), etc.
 rating the punctuation marks from the word. For instance, the Arabic word  X  comma from the word).
 mentation. When using the punctuation separation or character-based seg-mentations, the unit of analysis is the word itself (without the punctuation marks attached) or the character, respectively. The ATB and morphologi-cal segmentations are language specific and are based on different linguis-tic viewpoints: ATB segmentation aims at defining the independent phrasal constituents whereas morphological segmentation segments all affixes. When using one of these two segmentation schemes, the unit of analysis is the morph (i.e., prefix, stem, or suffix). As a reminder, the classifier will attribute a tag to each unit of analysis mentioning whether it is the beginning of a mention, inside a mention, or outside a mention. Our goal is to find the unit of analysis (token) that fits best Arabic MD. 2.1 ATB and Morphological Segmentation Models Both ATB and morphological segmentation systems are based on weighted finite state transducers (WFST) as described by Mohri et al. [1998]. The segmentation process consists of separating the Arabic normal white-space delimited words into (hypothesized) prefixes, stems, and suffixes, which be-come the subject of analysis (tokens). The decoder implements a general Bellman dynamic programming search for the best path on a lattice of seg-mentation hypotheses that match the input characters [Lee et al. 2003]. ATB and morphological segmentation systems have a performance of 99 . 3and97 . 8 F -measure respectively on ATB data. The model was initially trained from a small corpus of hand segmented examples of about 110 , 000 words, and then refined using unsupervised learning on a larger corpus of 155 million words [Graff 2003]. notes an original text of Arabic white-space delimited words to segment, and S (segments) obtained by choosing for each word in W one of its possible seg-mentations into prefix(es), stem, and suffix(es). All the possible segmentations for each word w i can be obtained from a lookup table of all the prefixes and suffixes. We have acquired the prefix/suffix table from 110 , 000 words in a manually segmented LDC corpus (51 prefixes and 72 suffixes) and from an ad-ditional in-house manually segmented corpus (additional 14 prefixes and 122 suffixes). Since not all words have a pr efix and/or a suffix, and since words can have multiple prefixes and/or suffixes, the term L k is necessarily greater than Q ( L k  X  Q ). Among all the possible segmentations S k of the input document, we chose the one  X  S that has the highest probability: The probability P ( S k ) is estimated using an n -gram language model on segment (morpheme) sequences: The n -gram language models can be estimated in different ways, we use in particular a Kneser-Ney based back-off trigram language model as described by Chen and Goodman [1998].
 ferent correct segmentations:  X   X  X nd X  . X  In the first segmentation (i.e.,  X   X ), we find one prefix  X  , X  one stem  X  , X  and no suffixes. Based on this segmentation, the word has the meaning of  X  X nd in, X  such as in the fragment example  X  ond segmentation (i.e.,  X   X ), we find no prefixes, one stem, and no suffixes. In this case, the word means  X  X aithful X  such as in the example  X  mean  X  X aithful man. X  Another segmentation is to split the word  X   X  into one prefix, one stem, and one suffix:  X  has a likelihood close to zero and consequently it will be discarded. For a sentence that contains the word  X  process first extracts possible segmentations into prefix(es), stem, and suf-fix(es):  X  the word  X  ters are not part of our lookup table of prefixes and suffixes. Once the possible segmentations are defined, a segment n -gram language model is used to define the segmentation that has the highest probability. As an example, the proba-bility of the segment phrase  X  hand, based on the context, the probability of the segment phrase  X  is higher than the probability of the segment phrase  X  quently, the result of our segmentation decoder on the sentence  X  the segment phrase  X  segmentation strategy as the composition of three distinct finite state ma-chines. The first machine encodes the prefix and suffix expansion rules, pro-ducing a lattice of possible segmentations. The second machine is a dictionary that accepts characters and produces id entifiers corresponding to dictionary entries. The final machine is a trigram language model, specifically a Kneser-Ney based back-off language model [Chen and Goodman 1998]. Differing from Lee et al. [2003], we introduced an explicit model for unknown words based upon a character unigram model, although this model is dominated by an em-pirically chosen unknown word penalty. mentation model based upon a dictionary of stems and words, we also ex-perimented with models based upon character n -grams. For these models, both Arabic characters and spaces and the inserted prefix and suffix markers appear on the arcs of the finite state machine. The language model is condi-tioned to insert prefix and suffix markers based upon the frequency of their appearance in n -gram character contexts that appear in the training data. An analysis of the errors indicated that the character-based model is more effec-tive at segmenting words that do not appear in the training data. We then decided to exploit this ability to improve the dictionary-based model. As in Lee et al. [2003], we used unsupervised training data, which is automatically segmented, to discover previously unseen stems. In our case, the character n -gram model is used to segment a portion of the Arabic Gigaword (AG) cor-pus [Graff 2003]. Thereafter, we create a vocabulary of stems and affixes by requiring tokens that appear more than twice in the supervised training data or more than ten times in the unsupervised segmented corpus. 3. MENTION DETECTION SYSTEM As stated earlier, we consider the MD task as a sequence classification problem where the class we predict for each unit of analysis (i.e., token) is the type of the entity which it refers to. This is similar to classical NLP tasks such as base noun phrase chunking [Ramshaw and Marcus 1994], text chunking [Ramshaw and Marcus 1995] or named entity recognition [Tjong Kim Sang 2002], where we assign a label to each token in the text, indicating whether it starts a specific mention, is inside a specific mention, or is outside any mentions. shown to depend heavily on integrating many sources of information [Florian et al. 2004; Zitouni et al. 2005]. Given this goal, we are interested in algorithms that can easily integrate and make effective use of diverse input types. We select an exponential classifier, the Maximum Entropy (MaxEnt) classifier that can integrate arbitrary types of information and make a classification deci-sion by aggregating all information available for a given classification, but the readers can replace it with their favorite feature-based classifier throughout the article. The fact that any type of feature can be used within the MaxEnt framework enables the system designer to experiment with interesting fea-ture types, rather than worry about specific feature interactions. In contrast, in a rule-based system, the system designer would have to consider how, for instance, information derived from a di ctionary for a particular example in-teracts with POS-based information and chunking information. That is not to argue that, ultimately, rule-based systems are in some aspect inferior to statis-tical models. Rule-based systems are built using valuable insight that is hard to obtain from a statistical-model only approach. Instead, we are just merely suggesting that the output of such a rule-based system can be easily integrated into the maximum entropy framework as one of the input features, most likely leading to improved performance.
 { y F = { 0 , 1 } t be a feature space. Each example x  X  X has associated a vector is to associate examples x  X  X with either a probability distribution over the label y  X  Y (if we are interested in hard classification).
 f j i , and computes the probability distribution as ing the training phase to maximize the likelihood of the data [Berger et al. 1996]. In this article, the MaxEnt model is trained using the sequential condi-tional generalized iterative scaling (SCGIS) technique [Goodman 2002], and it uses a Gaussian prior for regularization 3 [Chen and Rosenfeld 2000]. sentence or a document) in the source language. The goal of the mention de-that best matches the input x N 1 . We will use a Viterbi dynamic-programming search to compute the probability of the output sequence y 1 ... y N given the input sequence x 1 ... x N . In our case of mention detection, and similar to the approach described in Florian et al. [2004], each token x i in x N 1 is tagged with a label y i as follows: 4  X  X he token is not part of any mention.  X  X f it is part of an entity, it is composed of a sub-tag specifying whether it starts a mention ( B -) or is inside a mention ( I -), and a sub-type correspond-ing to mention type (e.g., B-PERSON ). In ACE, there are seven possible main types: person, organization, location, facility, geopolitical entity (GPE), weapon, and vehicle.
 Since we are interested in sequence classification, we use the chain rule to compute the sequence assignment (we denote x 1 ... x n by x n 1 ): tion (3). Two things are worth mentioning about the model: (1) the probabili-ties are conditioned on the previous k  X  1 tags and can use the entire observed sequence x n 1 (for instance, use the following words as features), and (2) there is no explicit separation between the transition and prediction probabilities (such as in Lafferty et al. [2001]). 3.1 Mention Detection: Features The particular features used in our mention detection system can be divided into four different categories: lexical, stem n -grams, syntactic, and semantic features. We also use the two previously assigned classification tags as addi-tional features. (1) Lexical Features: Lexical features are implemented as token n -grams (2) Stem n -gram Features: The stem n-gram features are implemented as (3) Syntactic Features: The syntactic features include POS tags [Toutanova (4) Semantic Features: It consists of extracting features from the output of 4. DATA Experiments are conducted on the Arabic ACE 2007 data 5 [NIST 2007]. There are 379 Arabic documents and almost 98,000 words. We find seven types of mentions in ACE X 07 data: facility, geopolitical entity (GPE), location, organi-zation, person, vehicle, and weapon [NIST 2007]. Since the evaluation test sets are not publicly available, we have split the publicly available training corpus into an 85%/15% data split. We use 323 documents (80,000 words) for training and 56 documents (18,000 words) as a test set. This results in 17,634 mentions (7,816 named, 8,831 nominal, and 987 pronominal) for training and 3,566 for test (1,673 named, 1,682 nominal, and 211 pronominal). To facilitate future comparisons with work presented here, and to simulate a realistic sce-nario, the splits are created based on article dates: the test data is selected as the latest 15% of the data in chronological order in each of the covered genres (newswire and webblog). The time span of the test set is intention-ally non-overlapping, and posterior to that of the training set within each data source, as this models how the system will perform in the real world. purpose measure, the ACE value metric [NIST 2007], given that we are inter-ested in the mention detection task only, we decided to use the more intuitive and popular (unweighted) F -measure, the harmonic mean of precision and recall.
 segmentation, building the following corpora:  X  Word s : A corpus which is the result of running punctuation separation.  X  ATB s : A corpus obtained by running punctuation separation and ATB segmentation.  X  Moph s : A corpus where we conduct punctuation separation and morpholog-ical segmentation.  X  Char s : A corpus where the original text is separated into a sequence of characters.
 analysis is the word, the ATB token, the morph, and the character, respectively. 5. EXPERIMENTS AND RESULTS We show in this section the experimental results when using an Arabic MD system with different segmentation schemes and different feature sets. We explore in this article four categories of features:  X  Lex f : lexical features.  X  Stem f : Lex f + morphological features.  X  Synt f : Stem f +syntacticfeatures.  X  Sem f : Synt f + output of other MD classifiers.
 feature sets will show the impact of segmentation relative to initial system performance: a feature set with riche r information leads to a more accurate MD system [Florian et al. 2004]. To measure whether the improvement in performance of a particular system over another one is statistically significant or not, we use the stratified bootstrap resampling significance test [Noreen 1989]. This approach was used in the NER shared task of CoNLL-2002. 6 based on the used segmentation style. This is different for Sem f :werunclas-sifiers on morphologically segmented data and we transfer output labels to the other corpora: Word s , ATB s ,and Char s . This is because we use classifiers ini-tially trained on morphologically segmented data such as ACE X 03, ACE X 04, and ACE X 05 data. In such data, two morphs belonging to the same word or ATB token may have two different mentions: for example, the ATB token (syArathm  X  their car) contains two morphs ( vehicle mention and have the label of the corresponding stem in the morphologically segmented data. In the previous example, the token lar to ACE X 07 guidelines. One motivation for not retraining classifiers on each corpus separately is to be able to extract Sem f features from classifiers with similar performance. This is in additi on to the fact that we do not have access to the training data of all used classifiers.
 petitive and perform better than classifiers trained on data with other seg-mentation styles. When the system uses character as the unit of analysis, performance is poor. This is because the word itself becomes insignificant in-formation to the classifier. On the other hand, when only punctuation sepa-ration is performed ( Word s ), the data is significantly sparse and the obtained results achieve a high F -measure (77.1) only when outputs of other classifiers are used. As mentioned earlier, classifiers used to extract those features are trained on morphologically segmented (less sparse) data, which explains their remarkable positive impact since they resolve part of the data sparseness prob-lem in Word s . We also notice that the stem-based feature has a better im-pact on classifiers trained on Morph s . This is because for classifiers trained on other segmentation style data, this feature is just a replica of the Lex f feature (c.f. Section 3). 5.1 ATB vs. Morphological Segmentations When using lexical, stem n -gram and syntactic features, Table II shows that classifiers trained on Morph s have better performance than similar ones trained on ATB s . We believe that this is due to the fact that Morph s is less sparse than ATB s . However, when using all features, the best performance is achieved when a classifier is trained on ATB s (79 . 02 vs. 78 . 35). The improve-ment is statistically significant [Noreen 1989]. We think this is because the use of output of classifiers trained on Morph s resolved some of the data sparseness issue in ATB s . At the same time, when using ATB s ,wehaveaccesstogreater context. We remember that Sem f features are extracted from classifiers that are trained on morphologically segmented data.
 leads to less Out-Of-Vocabulary tokens (OOVs): the number of OOVs in the Morph s data is 1,518 whereas it is 2,464 in the ATB s .Asanexample,the word ing data. This word is kept unchanged after ATB segmentation and is seg-mented to  X  same word appears in its dual form without definite article, that is, This word is unchanged in ATB s and is segmented to  X  +yn) in Morph s . For the model built on ATB s , this word is an OOV, whereas for the model built on Morph s the stem has been seen as part of a person men-tion and consequently has a better chance to tag it correctly. This phenomena happens frequently, which makes the classifier trained on Morph s more robust for such cases. Also, we observed that models trained on ATB s perform better on long-span mentions. A representative example of a frequent case would be the organization named mention: which is kept unchanged in the ATB s and appears in the Morph s as: word  X  model trained on Morph s has mistakenly assigned that same class to the word  X  X lmslmyn X  because the lexical context, that is,  X  / +2 tokens, does not indicate that this word is part of a multi-word mention and thus it should be classified differently. On the other hand, the whole mention has been correctly tagged as an organization mention by the model trained on ATB s because it has access to larger context.
 separately. This is using classifiers built on ATB s and Morph s . Results show similar behavior on each type separately: morphological segmentation is more effective when the model has access to Lex f , Stem f ,or Synt f features. However, when larger sets of resources that reduce the data sparseness problem become available, ATB segmentation becomes more effective.
 might be obtained if we use a wider context window than the one used for ATB s in order to have similar contextual information. In order to confirm this statement, we have carried out a set of experiments using all features over Morph s data for a context window up to  X  / + 5, the obtained results show no improvement because as the contextual window becomes longer the number of features increases significantly and the obtained behavior is very different from the one obtained with a  X  / +2contextwindowover ATB s . 5.2 Discussion When limited resources are available (e.g., Lex f , Stem f ,or Synt f ), we be-lieve that it is more effective to morphologically segment the text ( Morph s ) as a preprocessing step. The use of morph as a unit of analysis reduces the data sparseness issue and at the same time allows better context han-dling when compared to character. On the other hand, when larger sets of resources are available (e.g., Sem f ), the use of ATB tokens as the unit of analy-sis combined with morph-based features leads to better performance (79.0 vs. 78.3 on Morph s ). The improvement is statistically significant [Noreen 1989]. This is because (1) classifiers trained on ATB s handle better the context, and (2) the use of morph-based features (output of classifiers trained on morpho-logically segmented data) removes some of the data sparseness from which the classifiers trained on ATB s suffer. As stated earlier, MD classifiers used to produce resources for Sem f are trained on data that is morphologically seg-mented. Hence, the model trained on ATB s using Sem f feature sets can be viewed as a model that combines both ATB and morphological segmentation. We believe that for an accurate MD syst em it is appropriate to benefit from both ATB s tokens and Morph s . We investigate the combination of these two segmentation styles in the following section. 5.3 Combination of ATB and Morph To be able to benefit from both ATB and morphological segmentation, we trained a model on ATB s that uses output of the model trained on Morph s as additional information ( M 2 A f feature). We proceed similarly by training a model on Morph s using output of the model trained on ATB s ( A 2 M f feature). Two features for the training data were obtained using a 15-way round-robin features. Table IV shows the obtained results.
 using information from Morph s in addition to Lex f , Stem f ,and Synt f features. This again confirms our claim that the use of features from morphologically segmented text reduces the data sparseness and consequently may lead to better performance. For Sem f features, only 0.1 F -measure points have been gained. This is because we are already using output of classifiers trained on morphologically segmented data, which resolved some of the data sparseness issue.
 ( ATB s + M 2 A f ) and morphological ( Morph s + A 2 M f ) segmentations. Results show again that morphological segmentation reduces data sparseness and con-sequently helps improve classifiers trained on ATB segmented text. When larger resources become available, data sparseness problem is reduced and ATB segmentation becomes more effective. 6. CONCLUSIONS We show in this article a step-by-step technique in how to use diverse sources of information to build an Arabic mention detection system. We also discuss the importance of selecting the appropriate unit of analysis for Arabic mention detection tasks. We investigate the effectiveness of four different segmenta-tion schemes on Arabic mention detection systems that use different levels of feature richness. Results show that when only punctuation separation is per-formed the data is very sparse and the MD model is not able to achieve good performance. On the other hand, when the chosen unit of analysis is the char-acter, that is, the segmentation separates all the characters, the MD model behaves very poorly because both the analysis unit and the lexical context are insignificant.
 schemes are used. These segmentation schemes differ from each other in that the former one aims at separating only the affixes which would result in in-dependent phrasal constituents in the parse tree. The latter one, however, separates all the affixes which results in a less sparse data set. Results show that when only limited resources (lexical and syntactic features) are avail-able, using morphological segmentation leads to the best results. On the other hand, the model trained on ATB segmented data becomes more powerful and effective when data sparseness is reduced by the use of other classifier out-puts trained on morphologically segmented data. The main difference lies in that: (1) models trained on ATB segmented data perform better on long span mentions, and (2) models trained on morphologically segmented handle bet-ter mentions which have appeared with different sets of affixes in the training and development sets. More improvement is obtained when both segmentation styles are combined. Interestingly, the model trained on morphologically seg-mented text using only Stem f combined with the outcome of the model trained on ATB segmented test has almost the same performance as the model that has access to syntactic information (75.2 vs. 75.5). When limited resources are available (e.g., lexical feature) the combination of different segmentation schemes would be a very important technique to consider in order to improve performance. It is cheaper than building a POS tagger and a chunker (required for syntactic features) and it helps get a similar performance.

