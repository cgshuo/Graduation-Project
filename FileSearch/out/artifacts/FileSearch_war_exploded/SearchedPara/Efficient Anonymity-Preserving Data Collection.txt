 The output of a data mining algorithm is only as good as its inputs, and individuals are oft en unwilling to p rovide accu-rate data about sensitive topics such as medical history and personal finance. Individuals may be willing to share their data, but only if they are assured that it will be used in an aggregate study and that it cannot be linked back to them. Protocols for anonymity-preserving data collection provide this assurance, in the absence of trusted parties, by allow-ing a set of mutually distrustful respondents to anonymously contribute data to an untrusted data miner.

To effectively provide anonymity, a data collection proto-col must be collusion resistant , which means that even if all dishonest respondents collude with a dishonest data miner in an attempt to learn the associations between honest re-spondents and their responses, they will be unable to do so. To achieve collusion resistance, previously proposed proto-cols for anonymity-preserving data collection have quadrat-ically many communication rounds in the number of re-spondents, and employ (sometimes incorrectly) complicated cryptographic techniques such as zero-knowledge proofs.
We describe a new protocol for anonymity-preserving, col-lusion resistant data collection. Our protocol has linearly many communication rounds, and achieves collusion resis-tance without relying on zero-knowledge proofs. This makes it especially suitable for data mining scenarios with a large number of respondents.
 E.3 [ Data ]: Data Encryption; H.2.8 [ Information Sys-tems ]: Database Applications X  Data Mining Algorithms, Security Anonymity, Privacy, Data Mining Copyright 2006 ACM 1-59593-339-5/06/0008 ... $ 5.00.
Consider a scenario in which a data miner wishes to collect data from a large set of respondents for use in a data min-ing experiment. The miner queries each respondent, who in turn transmits her response back to the miner. If the re-spondents are willing to truthfully answer the miner X  X  query, then the miner is able to proceed with his experiment. In some cases, however, a respondent X  X  willingness to answer truthfully is dependent on a guarantee that her answer will be used only in the aggregate and cannot be linked back to her. For example, the miner may be conducting a survey on illegal activities, or on sensitive medical conditions. If the miner can convince the respondent that her response will be anonymous among her peer respondents then she will participate truthfully in the survey; otherwise, she will not.
Data collected with the simple query/response protocol described above will not be anonymous, because the data miner can easily observe which respondent transmits which response. One way to achieve anonymity would be to shuffle the responses, so that the miner receives the responses in a random order. This is easy to do with the assistance of a trusted third-party shuffler, as the respondents can submit their responses to the shuffler, who collects all responses and then forwards them to the miner in a random order.
The goal of this research is to achieve the same security guarantees without the need for trusted parties. We give a protocol that allows mutually distrustful respondents to submit their responses to an untrusted data miner in a man-ner which guarantees that their responses will be received by the miner, but that the probability that the miner can link a response to a respondent is essentially no better than random guessing. Furthermore, our protocol is col lusion resistant . Even if all malicious respondents freely share in-formation with the malicious miner, they will be unable to learn the associations between honest respondents and their responses. This strong form of collusion resistance is impor-tant in online data collection scenarios where respondents cannot communicate directly with one another, and there-fore are unable to determine whether other respondents are genuine participants, or shills set up by a malicious miner.
Our protocol consists of two parts. In the first part, re-spondents encrypt their responses and shuffle them under encryption, so that it will be impossible to determine which encrypted response belongs to which respondent. In the second part, the integrity of the shuffle is verified, and the respondents provide information to the data miner so that he can decrypt the responses.
 In order to be practical for use in data mining applications with large numbers of respondents, protocols for anonymous data collection need to be efficient as well as secure. In the online data collection scenario, it is especially important to limit the number of messages that must be transmitted be-tween the data miner and the respondents. Our protocol requires that the data miner send and receive only O ( N ) messages when there are N respondents. Furthermore, our protocol does not rely on zero-knowledge proofs. The most efficient currently known zero-knowledge proofs for verifiable shuffles [13, 15] require 7 rounds of communication for each proof. Moreover, it is unclear whether these proofs preserve their properties when composed in parallel. Therefore, if multiple proofs are needed at any step of the protocol, they have to be carried sequentially, rendering the communica-tion complexity of the protocol impractical.
 The problem of collecting data so that the miner is unable to link any honest respondent to her response was investi-gated by Yang et al. [21]. Their solution is to choose t of N respondents as  X  X eaders, X  and have respondents encrypt their responses with the leaders X  public keys. Each of the leaders shuffles and rerandomizes the ciphertexts, proving to every respondent in zero-knowledge that the shuffle has been carried out correctly . This protocol requires O ( t knowledge proofs, each of which involves several rounds of communication. (To achieve the same anonymity guaran-tees as our protocol, t should be equal to N ,inwhichcase communication complexity is quadratic in the number of re-spondents.) The protocol of Yang et al. does not achieve collusion resistance because if the last leader is corrupt and colludes with the data miner, they can break the anonymity of all honest respondents. This attack is due to an incorrect use of zero-knowledge proofs, and is explained in detail in Appendix A.

A related problem is secure multiparty computation, in which several parties wish to compute a function on their joint input, but without revealing their input to one an-other. There are generic protocols [22, 11] that allow any polynomial functionality to be computed securely in the semi-honest [9] model, but they are too inefficient for prac-tical data mining purposes. Several papers [14, 5, 20] have given efficient special-purpose protocols for the computa-tion of particular data mining functionalities. The scenario in this paper is different from a secure multiparty compu-tation scenario, because the respondents do want to reveal their inputs to the data miner. Our security property is un-linkability rather than secrecy of inputs, that is, we want to prevent the data miner from learning which input came from which respondent.

Instead of submitting their responses anonymously within a peer group, respondents submitting sensitive data might randomly perturb their responses. In this case, privacy would be based on the inexactness of the responses, rather than on the lack of association between respondent and re-sponse. Several methods for random perturbation have been proposed and their applicability to data mining problems investigated [2, 1]. In all perturbation-based privacy meth-ods, there is an inherent tradeoff. The more perturbed the data are, the more privacy is guaranteed, but the less use-ful the collected data are for data mining applications. By contrast, our techniques provide the data miner with exact, unperturbed responses.

Respondents submitting data using randomized response lie with a certain probability, so that the data miner is never certain of the truthfulness of a sensitive response. Data min-ing algorithms must be modified to accept randomized re-sponse data. For instance, Du and Zhan [8] modify the pop-ular ID3 decision tree classification algorithm. By contrast, after a successful execution of our algorithm the data miner knows the exact responses and can use any unmodified data mining algorithm.

Research on k -anonymization [17, 16] observes that in some cases the information contained in the anonymous re-sponse may be specific enough to identify the respondent if the malicious data miner has access to auxiliary information such as a voter or census database. This problem is orthog-onal to the problem investigated in this paper. If responses and respondents are linkable by content, then no amount of shuffling in an anonymity-preserving data collection proto-col will make them unlinkable. Likewise, if responses and respondents are linkable by the collection procedure, then no amount of k -anonymization will make them unlinkable. In this paper we assume that responses and respondents are not linkable by content.

Finally, so-called mix networks such as onion routing [18, 7] have been proposed to enable anonymous communications on public networks. Mix networks aim to hide the identities of message senders, and thus seem to be a poor match for data mining scenarios, where the data miner may need to know exactly who the respondents are. Using a mix net-work to collect responses while ensuring that respondents are members of a well-defined set and that each respondent contributes no more than one response requires complicated cryptographic techniques such as group signatures, and is unlikely to be efficient for practical use. Also, because of the possibility that one or more network nodes may be compro-mised, mix networks provide only probabilistic anonymity guarantees, whereas our goal in this paper is cryptographi-cally strong anonymity.
In this section we define cryptographic concepts and no-tation that are used throughout the remainder of the paper.
We take the standard definition of a public-key cryptosys-tem from [3]. A public-key (or  X  X symmetric X ) encryption scheme AE =( K , E , D ) consists of three algorithms, as fol-lows: We require that dec x ( { m } y )= m . This means that the owner of the private key x can recover a message encrypted with the public key y .

Many times in this paper we will need to serially encrypt a text under multiple public keys y N , ..., y i , and we will use the following notation to make this less cumbersome:
At times throughout this paper we will refer to a  X  X ecurity parameter X   X  . The security parameter has a specific cryp-tographic meaning, but intuitively can be thought of as the length of the key in bits [10].
We require that the cryptosystem used in our protocol have the property of indistinguishability under adaptive chosen ciphertext attack (IND-CCA2) [3]. Intuitively, this means that it is impossible to learn any information a plaintext m from an encryption { m } y ,evenwhengiven access to a decryption oracle for all ciphertexts other than { m } y . Although IND-CCA2 is a very strong property, there are cryptosystems that are known to satisfy it [6, 4].
In our definition of an IND-CCA2 encryption scheme, we will make use of the distinguishing game .
The distinguishing game is played between a challenger and an oracle. This game is slightly different from, but equivalent to, the standard adaptive chosen ciphertext game [3]. 1. The oracle chooses a keypair ( x, y ), and gives y to the 2. The challenger may encrypt polynomially many mes-3. The challenger chooses two plaintexts m 0 and m 1 . 4. The oracle chooses a bit b  X  X  0 , 1 } uniformly at ran-5. The challenger may encrypt polynomially many mes-6. The challenger attempts to guess whether b =0or Let A be a polynomial-time challenger. Then is the probability that A outputs 1 when the bit b =0,and is the probability that A outputs 1 when the bit b =1. In both cases, the probability is taken over the randomness of the key generation in step 1. The challenger X  X  advantage is equal to Now we can define indistinguis hability under adaptive cho-sen ciphertext attack as follows:
Definition 1. A cryptosystem is IND-CCA2 if, for all probabilistic polynomial-time challengers, the advantage in the distinguishing game is negligible (dominated by where f is any polynomial and  X  is a security parameter).
We use the standard definition of digital signature schemes from [3]. A digital signature scheme DS = (
K , sig , VF) consists of three algorithms: The desired security property for a digital signature scheme is unforgeability , which means that without the private key u , it is computationally infeasible to produce a signature sig u ( m ) for a message m that one has not previously seen signed with u . For a more formal treatment, see [3].
The anonymity-preserving data collection protocol takes place between a large set of mutually distrustful parties. One of these parties has a special role and is denoted the  X  X ata miner, X  while the other N parties have interchange-able roles and are denoted  X  X espondents. X  Each respondent i ,1  X  i  X  N has a response d i . All responses are assumed to be of identical length. The goal of the protocol is for the miner to learn the responses from each respondent, but without being able to determine which response came from which respondent. In other words, the miner should learn a random permutation of the set { d 1 , ..., d N } , but should not learn anything about that permutation.

We assume that during the protocol, all participants re-main online. Each respondent has a secure communica-tion channel with the data miner. These are reasonable assumptions in a scenario where the respondents are using a Web interface to communicate with a server operated by the data miner. We assume that prior to the protocol exe-cution each respondent i has obtained a public encryption key pair ( x i ,y i ) for an IND-CCA2 encryption scheme, and asignaturekeypair( u i ,v i ) for a secure (unforgeable) signa-ture scheme. Each respondent and the data miner knows the public keys y i and v i for all respondents. Likewise, the data miner has a public key pair ( x DM ,y DM ), and the public key y DM is known to all respondents.

In a practical implementation, the distribution of these public keys is delegated to a trusted certification authority , whose job is to associate individuals with their public keys. Note that this is the only assumption of trust required by the protocol. There are several businesses providing trusted certification authority functionality, so this is a reasonable (and standard) assumption.

We prove the correctness of our protocol in the malicious model [9], where protocol partici pants may deviate arbitrar-ily from the protocol specification. In this model any partic-ipant can prevent the protocol from completing by refusing to participate, so we are unable to prove that the protocol always terminates, much less that it always terminates with correct results. Instead, we prove that if the protocol ter-minates, certain properties are maintained. In this section, we give three properties that together define a correct proto-col for anonymity-preserving data collection in the malicious model.
In an online data collection scenario, a respondent knows nothing about her peer-respondents except their public keys. Some (or all) of the other participants may be shills con-trolled by the data miner who exist only to lure honest par-ticipants into a false sense of anonymity. Because dishonest respondents colluding with the data miner is a legitimate threat, we require that our protocol be collusion resistant . This means that even if k of the N respondents are corrupt and in collusion with the data miner, the data miner will be unable to determine which of the N  X  k honest participant responses belongs to which honest participant. Of course the data miner will be able to determine whether a response comes from an honest respondent or a colluding respondent, because a colluding respondent can tell the data miner which response is hers. Note that if there is only a single honest respondent, the data miner will be able to collude with all other respondents and learn her response.

We formalize our notion of anonymity for a data collection protocol when k out of the N respondents are dishonest by defining an  X  X nonymization game X  which is similar to the distinguishing game given in section 2.2.1. The anonymiza-tion game is played between a challenger and an oracle, who participate in the data collection protocol together. The challenger plays the roles of the data miner and the k dis-honest colluding respondents, while the oracle plays the role of the honest respondents. The challenger is assumed to not know the private keys of any honest respondent. The protocol is anonymous if the challenger can win the game only with negligible probability. Prior to playing the game, the challenger may choose plaintext responses for all hon-est respondents and give them to the oracle, who will then participate in the anonymity-preserving data collection pro-tocol using those responses for the honest respondents. The challenger may repeat this process polynomially many times. Then the actual game begins, and the following happens: 1. The challenger chooses two honest participants h  X  and 2. The oracle chooses a bit b  X  X  0 , 1 } uniformly at ran-3. The oracle participates in the anonymity protocol with 4. After observing the protocol run, the challenger Let D be a probabilistic polynomial-time challenger. Then is the probability that D outputs 1 when the bit b =0,and is the probability that D outputs 1 when the bit b =1. In both cases, the probability is taken over the randomness of the key generation and encryption algorithms used by the oracle. The challenger X  X  advantage is equal to Pr[ D ( m 0 ,m 1 ,h  X  ,h  X  , 1) = 1]  X  Pr[ D ( m 0 ,m 1 ,h
Definition 2. A data collection protocol is anonymous if, for all probabilistic polynomial-time challengers, the ad-vantage in the anonymity game is negligible.
 Note that this definition is valid only when there are at least two honest respondents, which corresponds to our notion that it is impossible for any anonymity to exist when there is only a single honest respondent.
Ideally, we would like to ensure that an honest data miner always receives an unaltered response from each respondent. However, this is difficult in a protocol where responses pass through every respondent during the anonymization process, as any of those respondents could be malicious (but not in collusion with the data miner) and choose to substitute some subset of the responses with other data while they are under her control. Since it seems difficult to provide authenticity guarantees on the responses while maintaining anonymity, we are satisfied to detect the occurrence of substitutions. We will say that our protocol maintains integrity if, at the end of protocol execution with an honest data miner, one of the following two statements is true: 1. The data miner has the correct plaintext responses for 2. The data miner is informed that some honest respon-We are unable to make integrity claims when the data miner is dishonest, as a dishonest data miner has the power to cor-rupt whichever responses he wishes. However, the assump-tion is that the data miner is genuinely interested in learning the responses, and therefore has no such incentive.
In our scenario, the respondents are taking part in a con-fidential survey with the data miner. The data miner should learn all plaintext responses at the end of the protocol, but a respondent should not learn any response other than her own. If the data miner is dishonest, then he can reveal the set of responses { d 1 , ..., d N } after they have been decrypted, even though he will not know which response belongs to which respondent. We want to insure that dishonest behav-ior on the part of the data miner is the only way that the set of plaintext responses can be revealed. In other words, no coalition of dishonest respondents should be able to learn any response belonging to an honest respondent if the miner is honest.
 In this section we present our protocol for Anonymous Data Collection. We then prove that it satisfies all of the properties stated in section 4, and is therefore secure in the malicious model.
Prior to the protocol execution, the participants must learn one another X  X  public encryption keys and public signa-ture keys. As is standard in cryptographic protocols, the as-sociations between identities and keys are handled by a cer-tification authority . The certification authority is a trusted party with whom every participant is assumed to have a se-cure communication channel. To learn the public encryption key y i and verification key v i for respondent i ,participants query the certification authority who responds with ( y i Likewise, participants learn the public encryption key y DM for the data miner.

The participants must also all agree upon a canonical or-dering of the respondents. This can be done, for instance, by having each respondent sign an ordering sent by the data miner, and then verifying the signatures of all other respon-dents.

Note that this setup needs only to be done once, and afterwards the protocol participants can perform multiple protocol executions with no need to make additional contact with the certification authority. Our protocol for anonymous data collection is shown in Algorithm 1. It consists of 5 phases: keypair generation, data submission, anonymization, verification, and decryp-tion. These phases are described in more detail below. In this phase, every respondent i chooses a fresh secondary key pair ( w i ,z i ) which is distinct from the primary key pair ( x i ,y i ) that is registered with the certification authority. Each respondent i then self-certifies her secondary public key z i by sending the message to the data miner, who forwards these messages to the other respondents. In this way every respondent learns the second public key z i for each other respondent i , which is guaran-teed to be freshly chosen by i because signatures are not forgeable.
 In the data submission phase, respondents encrypt their re-sponses first with the data miner X  X  public key, then with all respondents X  secondary public keys, and finally with all respondents X  primary public keys. The encryptions are ap-plied in the canonical ordering determined during the pro-tocol setup. The primary key encryptions are stripped off during the anonymization phase. Because the cooperation of all respondents is necessary to remove the secondary key en-cryptions, every respondent will have a chance to abort the protocol before anonymity is compromised if the anonymiza-tion phase did not go according to protocol specification. In the anonymization phase, the respondents take turns shuffling the encrypted responses and removing a level of en-cryption. Since every level of encryption must be removed in order for the verification to pass, every respondent is ensured an opportunity to shuffle the encrypted responses. If two ci-phertexts are identical, this means a dishonest participant has attempted to duplicate a response, and the protocol is aborted.
 In this phase the respondents verify that the shuffles have been done correctly. By taking advantage of the fact that each respondent knows one of the responses, this is done without the use of zero-knowledge proofs. Each respondent i signs a message only if he sees his own ciphertext, C i {
C i } z N : z 1 among the set of permuted ciphertexts. These signatures are then verified by all respondents. If all of the signatures verify, an honest respondent can reason as follows: Since the respondent knows her ciphertext is anonymous among the honest respondents X  ciphertexts, she gives the data miner her secondary private key.
 In this phase the data miner uses the respondents X  sec-ondary private keys and his own private key to decrypt the responses. He learns the plaintext responses, but not the associations between responses and respondents.
In this section we argue that the security properties in-troduced in section 4 are satisfied by the protocol given in algorithm 1.
An intuitive argument for the anonymity of the protocol is that the data miner and colluding respondents have two choices for their behavior. On the one hand, they can behave honestly, in which case they will learn the final decrypted plaintexts, but they will not learn the associations between C and C ciphertexts. On the other hand, they can behave dishonestly and learn some associations between C and C ciphertexts, but then the verification phase will fail and they will not learn the decryptions of the C ciphertexts.
Our proof is in two parts. First, we show that when hon-est respondents receive ciphertexts for decryption in phase 2, then either there is exactly one copy of the correct ci-phertext for each honest participant, or the deviation from the protocol is detected and the protocol is aborted before the challenger is able to win the verification game. Sec-ond, we show that a challenger who can win the anonymity game while maintaining the above property can also win
Algorithm 1: Protocol for Anonymous Data Collection the distinguishing game, which is a contradiction because the underlying encryption scheme is IND-CCA2.

Part 1: Suppose that during step h i of phase 2, hon-est respondent h i receives ciphertexts ( D 1 , ..., D N ), but that there is some honest respondent h p for which the ciphertext {
C h p } y N : y h i appears either more than once or not at all. If any ciphertext appears more than once, this is detected by honest respondent h i and the protocol is aborted before the challenger learns the secondary private keys.

Now we wish to show that if an honest ciphertext is dis-honestly replaced so that it does not appear in step h i of phase 2, then the verification in phase 3 will fail. Suppose that honest participant h i does not receive { C h p } y N part of the set ( D 1 , ..., D N ).

In this case it is infeasible for the challenger to learn {
C participant h i . However, they must learn C h p to satisfy honest participant h p in the verification step. This is in-feasible without the private key x h i . Therefore verification fails and the protocol is aborted before the challenger learns the secondary private keys.

Now we must show that the challenger cannot win the anonymization game when he does not learn the secondary private keys. It is possible that by duplicating or substi-tuting ciphertexts of honest respondents, the challenger can learn the partially-decrypted ciphertexts C h  X  and C h  X  the honest respondents h  X  and h  X  he has chosen in the game. For example, the challenger could substitute known informa-tion for all encrypted responses except C h  X  .Thenafterthe decryption phase, he would know C h  X  . However, even if the challenger learns C h  X  and C h  X  , each of these ciphertexts is encrypted with the key z h  X  (as well as the keys of all other honest participants) which is unknown to the challenger. Therefore determining which decrypts to m 0 and which de-crypts to m 1 is exactly equivalent to the distinguishing game, and cannot be done due to the assumption that the encryp-tion scheme is IND-CCA2.

Part 2: Now suppose that the challenger honestly han-dles all ciphertexts belonging to honest participants. Sup-pose also that there is a probabilistic polynomial time algo-rithm D that allows this challenger to win the anonymiza-tion game with non-negligible probability. We will show how to use D as a subroutine to probabilistic polynomial-time algorithm A that wins the distinguishing game with non-negligible probability. Because of the assumption that the underlying encryption scheme is IND-CCA2, this is a contradiction, and we will conclude that no such D exists. Let the set of k honest respondents in the anonymization protocol be H = { h 1 , ..., h k } .Let D be an algorithm that allows the challenger to win the anonymization game with non-negligible probability. Then there exist honest partici-pants h  X  and h  X  such that for some polynomial f ,andfor sufficiently large values of  X  , To apply D , A must simulate the oracle in the anonymiza-tion game to reproduce the view of the challenger. We show how A is able to do this.
 Algorithm A begins by asking the distinguishing game oracle to generate a keypair ( x o ,y o ). A will use y o the public key belonging to the last honest respondent h k will be able to simulate all messages from honest respondents despite not knowing x o or y o .

A applies D to learn its choices in step 1 of the anonymiza-tion game. A therefore learns the following: Then, for each honest respondent h i , A chooses A selects plaintexts m 0 and m 1 to be the plaintext responses for h  X  and h  X  .

A is now ready to play the role of the oracle in the anonymization game by simulating the messages of honest participants in the protocol execution. For each phase of the protocol, we will explain how A is able to reproduce the messages sent in that phase.

Phase 0 : A has all the necessary keys to reproduce this phase exactly.

Phase 1 : For all honest respondents h i other than h  X  and h , A encrypts response d h i using the appropriate public keys (and the encryption oracle to encrypt with y h k )which results in the ciphertext C i . A then encrypts m 0 and m aspecialway. First, A encrypts using the secondary public keys: Next, A encrypts with all keys that come after h k in the sequence: Next, A gives M 0 and M 1 to the distinguishing game oracle, getting back: Finally, A encrypts M b and M  X  b with the remaining public keys to get the final encryptions:
Phase 2 : For all honest participant rounds h i of phase 2 other than round h k , A has the key x h i necessary to decrypt the ciphertexts ( D 1 , ..., D N ) provided by the challenger (who is playing the role of the miner). A permutes the resulting decryptions and sends them to the challenger.

Round h k is more difficult, because A does not know the key x h k . Here we must use our assumption that ev-ery honest participant X  X  ciphertext appears exactly once in ( D 1 , ..., D N ). In particular, the ciphertexts appear exactly once. For all ciphertexts D j in ( D 1 , ..., D other than M b and M  X  b , A may use the decryption oracle provided by the distinguishing game to obtain dec x h k ( D However, A is not allowed to use the decryption oracle on M b or M  X  b . Instead, when A sees the ciphertexts { m b } and { m  X  b } y N : y h k , he can either simulate decryption as which are the values M 0 and M 1 known to A .Because A sends the challenger a random permutation of the decryp-tions, the challenger cannot distinguish between A making the correct choice and permuting, or A making the incorrect choice and permuting. Thus either choice will suffice, and A may randomly choose one or the other.

Phases 3 and 4 : A has all the necessary keys to reproduce these phases exactly.
 Now A simulates the view of the challenger and applies D to the view. If D outputs 1, then A outputs 1, and if D outputs 0, A outputs 0.

We will now analyze the probability of A outputting 1 if the distinguishing oracle chose b = 0 and if the distin-guishing oracle chose b =1. If b = 0, then the view of the challenger is ( m 0 ,m 1 ,h  X  ,h  X  , 0). If b = 1, then the view of the challenger is ( m 0 ,m 1 ,h  X  ,h  X  , 1). Let Based on our assumption that D wins the anonymity game, we have that p 1  X  p 0 &gt; 1 f (  X  ) . Now we make a simple substi-tution, We conclude that A can win the distinguishing game with non-negligible probability, which contradicts the IND-CCA2 property of the underlying encryption scheme.
The honest respondents verify the presence of their C i ciphertext in phase 3 of the protocol; all ciphertexts must be present for any decryption to take place. When the sec-ondary private keys are handed over to the data miner for decryption, he can easily confirm whether the private key w i actually corresponds to the public key z i by encrypting data with z i and determining whether it decrypts with w i Then the data miner uses verified keys to decrypt verified ciphertexts, and as a result learns the correct plaintext re-sponses.

If the verification in phase 3 fails, then the data miner has not received sig u i ( D 1 , ..., D N ) from some honest participant h . In this case the data miner learns that participant h i response has been substituted. Thus our two-part definition of integrity given in section 4.2 is satisfied.

The inner-most level of encryption on each response is with y DM . Therefore only the dat a miner can perform the final decryption and learn the responses.
Our protocol is efficient in terms of communication and computational complexity. In this section we will quantify the complexity of the protocol.
 Operations requiring computation include key pair genera-tion, encryption, decryption, signing, and signature verifica-tion. In phase 0, each respondent generates 1 key pair, signs 1 message, and performs N signature verifications. In phase 1, each respondent performs 2 N +1 encryptions. In phase 2, each respondent performs N decryptions. In phase 3, each respondent performs 1 signature and N signature verifica-tions. In phase 4, the data miner performs N 2 + N decryp-tions. We conclude that the total computational complexity is O ( N 2 ). Note, however, that the computational complex-ity for each individual respondent is only O ( N ). This is advantageous because the respondents are more likely to be computationally bounded than the data miner.
 Phase 0 is parallelizable and requires 2 rounds. Phase 1 is parallelizable and requires only 1 round. Phase 2 cannot be parallelized and requires 2 N rounds. Phase 3 can be paral-lelized and requires 4 rounds. Phase 4 does not involve com-munication. We conclude that the protocol requires O ( N ) communication rounds.
 Let us assume that the size of a response is S bits, the size of a key is T bits, and that the size of a signature is Q bits. Phase 0 requires the transmission of N 2 signatures and keys, for a total of ( Q + T ) N 2 bits. In phase 1, NS -bit cipher-texts are transmitted. In each iteration of phase 2 , 2 SN bits are transmitted, for a total of 2 SN 2 bits. Phase 3 trans-mits SN 2 bits for the broadcast of ( D 1 , ..., D N ), ( Q + T ) N bits to transmit signatures and keys to the miner, and QN bits to broadcast the signatures from the miner back to the respondents. We conclude that the protocol transmits O (( Q + S + T ) N 2 ) bits. Since Q and T are constant param-eters of the cryptosystem, we can simplify this to O ( SN bits.
We have presented an efficient protocol for anonymity-preserving data collection that does not rely on zero-knowledge proofs to be secure in the malicious model. We have provided anonymity by having the respondents func-tion as mix-servers which shuffle the set of responses. The critical insight of our research is that by taking advantage of the fact that each respondent/mix-server knows her own response, we can confirm the validity of the shuffles without using zero-knowledge proofs. In a traditional mix-net sce-nario, the mix-servers and the data providers are distinct entities, so validity confirmation of this type is not possible. It is our hope that the data-mining community will find our protocol useful when collecting sensitive data from respondents.
In this appendix, we show an attack against the data col-lection protocol of Yang et al. [21, section 5.2]. We will refer to this protocol as the YZW protocol. This protocol is intended to be collusion resistant so that t  X  1 dishonest leaders (out of t total leaders), in collusion with a dishonest data miner, cannot learn any associations between honest respondents and their responses. Due to a subtle flaw in the use of zero-knowledge proofs, it is actually possible for a single dishonest leader to collude with the data miner and learn all associations.

This appendix is organized as follows. In section A.1 we provide a complete description of the malicious-model ver-sion of the protocol from [21]. Then, in section A.2, we ex-plain how the protocol has misused zero-knowledge proofs, and how this can be exploited by a malicious data miner and a malicious respondent to break anonymity of all hon-est respondents. Finally, in section A.3, we argue that even with correct zero-knowledge proofs, the YZW protocol still has impractical communication complexity.
 Unlike our protocol, which is compatible with any IND-CCA2 cryptosystem, the YZW protocol relies on the El-Gamal encryption scheme. In ElGamal, the public key is ( p, g, g x ) and the private key is x ,where p is a large ran-dom prime, g is the generator of the multiplicative group of integers modulo p ,and x is a random integer such that 1  X  x  X  p  X  2. A ciphertext of message m is a pair ( g k mod p, m  X  ( g x ) k mod p ), where k is a random integer such that 1  X  k  X  p  X  2.

An important property of ElGamal ciphertexts is that they can be easily rerandomized without access to the pri-vate key, i.e. , given a ciphertext ( C (1) ,C (2) ), it is easy to produce, without decrypting, another ciphertext ( C (1)  X  mod p, C (2)  X  ( g x ) k mod p ) which encrypts the same plain-text. Moreover, given two ciphertexts, it is not feasible to determine whether they encrypt the same plaintext.
The protocol also makes use of the following three zero-knowledge proofs, which are intended to prevent any of the protocol participants from deviating from the protocol:  X  PoK ( C ), where C is an ElGamal ciphertext. This is a  X  PoR (( C 1 , ..., C N ) , ( C 1 , ..., C N )), where all C  X  PoD ( q, C (2) ,y ), where C (2) is the second component of
We restate the protocol below. There are N respondents, of whom t are designated as  X  X eaders. X  Each leader i has an ElGamal key pair, in which x i is the private key, and the public key includes y i = g x i . The public key is known to all respondents, while the private key x i is known only to leader i .Let be the product of all public y i values. The protocol consists of three phases:  X  Phase 1: N -round data submission.
  X  Phase 2: t -round anonymization.
  X  Phase 3: Decryption
The flaw in the YZW protocol is that the zero-knowledge proof of permuted rerandomization PoR is not a proof of knowledge. It guarantees that the plaintexts of two cipher-text sets are the same, but this is not enough for anonymity. As long as ( C 1 , ..., C N )is some permuted rerandomization of ( C 1 , ..., C N ), then an attacker can provide the required proof even if he does not know the actual permutation.
In this section, we show how this can be exploited by a malicious data miner who colludes with the last leader and substitutes original ciphertexts (for which associations with respondents are known) for the honestly permuted cipher-texts. This enables them to pass all proofs required by the protocol, and then learn all associations between respon-dents and responses. Collusion resistance thus fails com-pletely: it is sufficient for the data miner to corrupt the last leader in order to completely break security of the protocol. 1. All participants behave honestly until the beginning of 2. At the beginning of the t th round, the data miner sends 3. The proof PoR (( D 1 , ..., D N ) , ( R 1 , ..., R N )) from leader 4. Leader t tells  X  t to the data miner, who is then able to
It may appear that this attack is caused simply by an im-precise description of PoR given in [21], and that any actual implementation of the PoR proof would not allow a party to pass the proof PoR (( D 1 , ..., D N ) , ( R 1 , ..., R knowing the permutation. Unfortunately, the implementa-tion suggested in [21] (and originally proposed in [12]) allows precisely this attack.

The proof in [12, 21] relies on the multiplicative homomor-phism property of ElGamal. If ( C (1) 1 ,C (2) 1 )and( C (1) are ElGamal encryptions of plaintexts P 1 and P 2 ,then is an ElGamal encryption of P 1 P 2 . In order to prove that two sets of ciphertexts ( C 1 , ..., C N )and( R 1 , ..., R to the same set of plaintexts, participants are asked to prove that the products of the ciphertexts decrypt to the same values (which are products of the origi-nal plaintexts). If plaintexts are chosen in such a way that it is difficult to find a set of plaintexts with the same product as the original, then equality of the products of plaintexts implies equality of the plaintexts themselves.

The reason the protocol of [21] fails is that the above statement about equality of products is true, and a mali-cious leader can prove it, even if he does not know the per-mutation. In [19], Wikstr  X  om presents a clever attack that effectively allows the k th leader to present a convincing zero-knowledge proof that his output ( R 1 , ..., R N )isapermuted rerandomization of the output from the k  X  1st leader, when in fact ( R 1 , ..., R N ) is a permuted rerandomization of the original ciphertexts in their original order. (In [19], the at-tack is described in the context of mix networks, but it also works in the anonymous data collection setting with very slight modifications.)
The YZW protocol can potentially be fixed by substi-tuting zero-knowledge proofs of knowledge for the incorrect proofs of [12]. Research on so called verifiable shuffles [13, 15] has led to zero-knowledge proofs in which a participant in an ElGamal rerandomization protocol proves not only that the output ciphertexts decrypt to the same set of plaintexts as the input ciphertexts, but also that the prover knows the the permutation from input ciphertexts to output cipher-texts.

Requiring this additional proof of knowledge makes the at-tack described above impossible, since a malicious last leader will no longer be able to rerandomize original input cipher-texts instead of the ciphertexts provided by the previous leader and pass the proof of knowledge. Fixing the YZW protocol in this way, however, still requires O ( N 2 )commu-nication rounds and the use of expensive zero-knowledge proofs, where N is the number of participants. It is not clear whether the proofs of [13, 15] can be carried out in parallel (in general, zero-knowledge proofs do not preserve their properties under concurrent composition), and execut-ing them sequentially results in a protocol with impracti-cal communication complexity. By contrast, our protocol achieves the same security guarantees with O ( N ) communi-cation rounds and without any zero-knowledge proofs.
