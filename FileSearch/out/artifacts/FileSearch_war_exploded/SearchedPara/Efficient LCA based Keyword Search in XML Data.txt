 Keyword search in XML documents based on the notion of lowest common ancestors ( LCAs ) and modifications of it has recently gained research interest [2, 3, 4]. In this paper we propose an efficient algorithm called Indexed Stack to find answers to keyword queries based on XRank X  X  semantics to LCA [2]. The complexity of the Indexed Stack algorithm is O ( kd | S 1 | log | S | ) where k is the number of keywords in the query, d is the depth of the tree and | S 1 | ( | S | ) is the occur-rence of the least (most) frequent keyword in the query. In comparison, the best worst case complexity of the core al-gorithms in [2] is O ( kd | S | ). We analytically and experimen-tally evaluate the Indexed Stack algorithm and the two core algorithms in [2]. The results show that the Indexed Stack algorithm outperforms in terms of both CPU and I/O costs other algorithms by orders of magnitude when the query contains at least one low frequency keyword along with high frequency keywords.
 Categories and Subject Descriptors: H.3.3 [ Information Systems] :INFORMATION STORAGE AND RETRIEVAL X  X nformation Search and Retrieval General Terms: Algorithms Keywords: LCA, XML, Keyword, Search
Keyword search in XML documents based on the notion of lowest common ancestors in the labeled trees modeled after the XML documents has recently gained research interest in the database community [2, 3, 4]. One important feature of keyword search is that it enables users to search infor-mation without having to know a complex query language or prior knowledge about the structure of the underlying data. Consider a keyword query Q consisting of k keywords w , . . . , w k . According to the LCA-based query semantics proposed in [2], named Exclusive Lowest Common Ances-tors ( ELCA ) in the sequel, the result of the keyword query Q is the set of nodes that contain at least one occurrence of all of the query keywords either in their labels or in the labe ls of their descendant nodes, after excluding the occurrences of the keywords in the subtrees that already contain at least one occurrence of all the query keywords. For example, the answers to the keyword query  X  X ML David X  on the data in 0 . 4 . 2]. The answers show that  X  X avid X  is an author of five papers that have  X  X ML X  in the titles (rooted at 0 . 2 . 2, 0 . 3 . 2, 0 . 3 . 3, 0 . 3 . 4 and 0 . 4 . 2); and that  X  X avid X  is the chair of two sessions that have  X  X ML X  in the titles (rooted at 0 . 2 and 0 . 3), and the chair of the conference (rooted at 0) whose name contains  X  X ML X . Notice that the node session with id 0 . 4 is not an ELCA answer since the only  X  X ML X  instance which already contains keyword instances of both  X  X ML X  and  X  X avid X . Therefore under the exclusion requirement in the ELCA definition, the session node 0 . 4 is not an ELCA answer. The node Conference rooted at 0 is an ELCA an-swer since it contains the node 0 . 1 . 1 and the node 0 . 5 . 1 which are not under any child of the node 0 that contains instances of both keywords  X  X ML X  and  X  X avid X .

We propose an efficient algorithm called Indexed Stack to answer keyword queries according to the ELCA query se-mantics proposed in XRank [2] with complexity of O ( kd | S 1 | log | S | ) where k is the number of keywords in the query, d is the depth of the tree, | S 1 | ( | S | ) is the occurrence of the least (most) frequent keyword in the query. In compari-son, the complexity of the core algorithms in [2] is O ( kd | S | ) maximum number of children of any node in the tree. The algorithm in [2] with complexity O ( k 2 d | S | p log | S | + k is tuned to return only the top m answers for certain queries where it may terminate faster than other algorithms.
In Section 2 we provide the ELCA query semantics and definitions used in the paper. Section 3 describes related work. Section 4 presents the Indexed Stack algorithm, and also provides the complexity analysis of the Indexed Stack algorithm and the algorithms in [2] for both main memory and disk accesses.
The notation v  X  a v  X  denotes that node v is an ancestor of node v  X  ; v a v  X  denotes that v  X  a v  X  or v = v  X  .
The function lca ( v 1 , . . . , v k ) computes the Lowest Com-mon Ancestor ( LCA ) of nodes v 1 , . . . , v k . The LCA of sets S , . . . , S k is the set of LCA  X  X  for each combination of nodes in S 1 through S k . lca ( S 1 , ..., S k ) = { lca ( n 1 , . . . , n k ) | n 1
For example, in Figure 1, lca ( S 1 , S 2 )=[0, 0 . 2, 0 . 2 . 2, 0 . 3, 0 . 3 . 2, 0 . 3 . 3, 0 . 3 . 4, 0 . 4, 0 . 4 . 2].
A node v is called an LCA of sets S 1 , . . . , S k if v  X  lca ( S 1 , . . . , S k ).

A node v is called an Exclusive Lowest Common Ancestor (ELCA) of S 1 , . . . , S k if and only if there exist nodes n S , . . . , n k  X  S k such that v = lca ( n 1 , ..., n k ) and for every n i (1  X  i  X  k ) the child of v in the path from v to n i is not an LCA of S 1 , . . . , S k itself nor ancestor of any LCA of S , . . . , S k .

According to the ELCA query semantics proposed in XRank [2], the query result of a keyword query Q consisting of k keywords w 1 , . . . , w k is defined to be where elca ( S 1 , . . . , S k ) = { v | X  n 1  X  S 1 , . . . , n lca ( n 1 , ..., n k )  X  X  X  i (1  X  i  X  k )  X  x ( x  X  lca ( S child ( v, n i ) a x )) } , S i denotes the inverted list of w i.e., the list of nodes sorted by id whose label directly con-tains w i and child ( v, n i ) is the child of v in the path from v to n i . Notice that the above definition is based on LCAs and is expressed differently than but it is equivalent to [2]. In Figure 1 elca ( X  X ML X ,  X  X avid X )= elca ( S 1 , S 2 )=[0, 0 . 2, 0 . 2 . 2, 0 . 3, 0 . 3 . 2, 0 . 3 . 3, 0 . 3 . 4, 0 . 4 . 2]. The Smallest Lowest Common Ancestor (SLCA) of k sets S , . . . , S k is defined to be slca ( S 1 , . . . , S k ) =
A node v is called a Smallest Lowest Common Ancestor (SLCA) of S 1 , . . . , S k if v  X  slca ( S 1 , . . . , S node in slca ( S 1 , . . . , S n ) cannot be an ancestor node of any other node in slca ( S 1 , . . . , S n ).
 Clearly slca ( S 1 , . . . , S k )  X  elca ( S 1 , . . . , S
Similarly to [2, 4], each node is assigned a Dewey id pre ( v ) that is compatible with preorder numbering, in the sense that if a node v 1 precedes a node v 2 in the preorder left-to-right depth-first traversal of the tree then pre ( v 1 ) &lt; pre ( v Dewey numbers provide a straightforward solution to locat-ing the LCA of two nodes. The usual &lt; relationship holds between any two Dewey numbers. Given two nodes v 1 , v 2 and their Dewey numbers p 1 , p 2 , lca ( v 1 , v 2 ) is the node with the Dewey number that is the longest common pre-fix of p 1 and p 2 . The cost of computing lca ( v 1 , v 2 where d is the depth of the tree. For example, in Figure 1 lca (0 . 2 . 2 . 1 . 1 , 0 . 2 . 2 . 2 . 1)=0 . 2 . 2.
Extensive research has been done on keyword search in both relational and graph databases. We focus on the three most closely related works: XRank ([2]), Schema-Free XQuer y ([3]) and XKSearch ([4]), all of which base keyword search in XML on the notation of LCAs of the nodes containing keywords.
 XRank ([2]) defines the answer to a keyword search query Q  X  w 1 , . . . , w k  X  to be elca ( S 1 , . . . , S k ) where S verted list of w i . It also extends PageRank X  X  ranking mech-anism to XML by taking the nested structure of XML into account.
 XKSearch ([4]) defines the answers to a keyword query Q of  X  w 1 , . . . , w k  X  to be slca ( S 1 , . . . , S k verted list of the keyword w i . The complexity of the Indexed Lookup Eager algorithm in [20] is O ( kd | S 1 | log | S | ). [4] also extends the algorithm computing slca ( S 1 , . . . , S k ) to com-pute all LCA s of k sets (i.e., lca ( S 1 , . . . , S k )). Schema-Free XQuery ([3]) uses the idea of Meaningful LCA (MLCA), and proposes a stack based sort merge algo-rithm which scans to the end of all inverted lists. The com-plexity of the algorithm in [3] is O ( kd | S | ). [3] shows that keyword search functionality can be easily integrated into the structured query language XQuery as built-in functions , enabling users to query XML documents based on partial knowledge they may have over underlying data with differ-ent and potentially evolving structures. The demonstrated integration of MLCA based keyword search functionality into XQuery can also apply to the ELCA query semantics.
In this paper we will only focus on the algorithmic as-pects of the problem of efficiently finding answers to key-word queries in XML documents, and we will not attempt a comparison of the quality of different query semantics. Intuitively answering a keyword query according to the ELCA query semantics is more computationally challeng-ing than according to the SLCA query semantics. In the latter the moment we know a node l has a child c which contains all keywords, we can immediately determine that the node l is not a SLCA node. However we cannot deter-mine that l is not an ELCA node because l may contain keyword instances that are not under c and are not under any node that contains all keywords. Notice that given the same query, the size of the answers of the SLCA semantics cannot be more than that of the ELCA semantics because slca ( S 1 , . . . , S k )  X  elca ( S 1 , . . . , S k ).
This section presents the Indexed Stack (IS) algorithm that computes elca ( S 1 , . . . , S k ). We choose S 1 to be the smallest among S 1 , . . . , S k since elca ( S 1 , . . . , S k ) = elca ( S j 1 , . . . , S j k permutation of 1 , 2 , . . . , k , and there is a benefit in using the smallest list as S 1 as we will see in the complexity analy-sis of the algorithm. We assume | S | denotes the size of the largest inverted list. The Indexed Stack algorithm, levera g-ing key tree properties described in this section, starts fr om the smallest list S 1 , visits each node in S 1 , but does not need to access every node in other lists.

The algorithm X  X  efficiency is based on first discovering the nodes of a set elca can ( S 1 ; S 2 , . . . , S k ) (short for ELCA Candidates) defined in Section 4.1, which is a superset of elca ( S 1 , . . . , S k ) but can be computed efficiently in O ( kd | S 1 | log | S | ), as shown in Section 4.2. Section 4.3 de-scribes an efficient function isELCA () that determines whether a given node of elca can ( S 1 ; S 2 , . . . , S k ) is a member of elca ( S 1 , . . . , S k ). Section 4.4 presents a stack-based algo-rithm that puts together the computation of elcan can and isELCA , avoiding redundant computations. Section 4.4 also presents the complexity analysis of the algorithm.
We define next the set elca can ( S 1 ; S 2 , . . . , S k members are called ELCA CAN nodes (of S 1 among S 2 , . . . , S k ). elca can ( S 1 ; S 2 , . . . , S k ) = [
For example, in Figure 1 elca can ( S 1 ; S 2 )=[0, 0 . 2, 0 . 2 . 2, 0 . 3, 0 . 3 . 2, 0 . 3 . 3, 0 . 3 . 4, 0 . 4 . 2].
Note that elca can ( S 1 ; S 2 , . . . , S k ) may contain nodes that are ancestors of other nodes of elca can ( S 1 ; S 2 , . . . , S following inclusion relationship between elca and elca can applies.

Property 1.  X  i  X  [1 , . . . , k ] ,
Of particular importance is the instantiation of the above property for i = 1 (i.e., elca ( S 1 , . . . , S k )  X  elca can ( S 1 ; S 2 , . . . , S elca can ( S 1 ; S 2 , . . . , S k ) has the most efficient computation (recall S 1 is the shortest inverted list).

In Figure 1, elca ( S 1 , S 2 ) and elca can ( S 1 ; S 2 ) happen to be the same. However if we remove the node 0 . 3 . 1 . 1 from the tree of Figure 1, then elca can ( S 1 ; S 2 ) stays the same but the node 0 . 3 would not be in elca ( S 1 , S 2 ) anymore. Therefore, it would be elca ( S 1 , S 2 )  X  elca can ( S 1 ; S 2 ).
For presentation brevity, we define elca can ( v ) for v  X  S to be the node l where { l } = elca can ( { v } ; S 2 , . . . , S clusive lowest common ancestor candidate or ELCA CAN of v (in sets of S 2 , . . . , S k ). Note that each node in and elca can ( v ) is the lowest among all nodes in lca ( { v } , S 2 , . . . , S k ). Consider S 1 and S 2 in Figure 1. The following shows elca can ( v ) for each v in S 1 . elca can (0 . 1 . 1) = elca can (0 . 4 . 2 . 1 . 1) = 0 . 4 . 2.
In this section we briefly describe how prior work ([4]) can be used to efficiently compute elca can ( v ).
The key property of SLCA search in [4] is that, given two keywords k 1 and k 2 and a node v that contains key-word k 1 , one need not inspect the whole node list of key-word k 2 in order to discover potential solutions. Instead, one only needs to find the left and right match of in the list of k 2 , where the left (right) match is the node with the greatest (least) id that is smaller (greater) than or equal to the id of v . The property generalizes to more than two keywords. Since elca can ( v ) for v  X  S 1 is the node l where { l } = elca can ( { v } ; S 2 , . . . , S k )= slca ( { v } , S complexity of computing elca can ( v ) is O ( kd log | S | ) by us-ing the algorithm in [4].
This section presents the function isELCA which is used to determine whether an ELCA CAN node v is an ELCA node or not. Let child elcacan ( v ) be the set of children of v that contain all keyword instances. Equivalently child elcacan ( v ) is the set of child nodes u of v such that either u or one of u  X  X  descendant nodes is an ELCA CAN node, i.e., where child ( v ) is the set of child nodes of v . We use ELCA CAN in the above definition because we can efficiently compute elca can ( S 1 ; S 2 , . . . , S k ) as discussed in Section 4.2. For S and S 2 of the running example in Figure 1, Assume child elcacan ( v ) is { u 1 , . . . , u c } (See Figure 2). By definition, there must exist witness nodes n 1 , . . . , n der an ELCA node v such that n 1  X  S 1 , . . . , n k  X  S k every n i is not in the subtrees rooted at the nodes from child elcacan ( v ).
 To determine whether v is an ELCA node, we probe every S i to see if there is a node x i  X  S i such that x i is either in the forest under v to the left of the path vu 1 , or in the forest under v to the right of the path vu c , or in any forest F i that is under v and between the paths vu i and vu i +1 , i = 1 , . . . , c  X  1. The last case can be checked efficiently by finding the right match of the node y in S i where y is the immediate right sibling of u i among the children of v . Assume pre ( v ) = p , pre ( u i ) = p.c where c is a single number, then pre ( y ) = p. ( c + 1), as shown in Figure 2. Let the right match of y in S i be x . Then x is a witness node in the forest F i if and only if pre ( x ) &lt; pre ( u i +1 ).

Given the list ch which is the list of nodes in child elcacan ( v ) sorted by id, the function isELCA ( v, ch ) returns true if v is an ELCA node by applying the operations described in the previous paragraph. As an example, consider the query  X  X ML David X  and the inverted lists S 1 and S 2 in Fig-ure 1. child elcacan (0)= [0 . 2 , 0 . 3 , 0 . 4]. We will see how isELCA (0 , [0 . 2 , 0 . 3 , 0 . 4]) works and returns true. In this example, the number of keywords is two. First the func-tion isELCA searches and finds the existence of an ELCA witness node (i.e., the node 0 . 1 . 1) for 0 . 2 in the first key-word list S 1 in the subtree rooted under 0 to the left of the path from 0 to 0 . 2 (0 . 2 is the first child ELCA CAN node of 0). Then the function searches the existences of an ELCA witness node in the second keyword list S 2 for 0 in the forest to the left of the path from 0 to 0 . 2; in the forest between the path from 0 to 0 . 2 and the path from 0 to 0 . 3; in the forest between the path from 0 to 0 . 3 and the path from 0 to 0 . 4; in the forest to the right of the path from 0 to 0 . 4. All of the above searches fail except that the last search successfully finds a witness node (0 . 5 . 1) true. The time complexity of isELCA ( v, child elcacan ( v )) is O ( kd log | S || child elcacan ( v ) | ).
In Section 4.1 we stated that elca can ( S 1 ; S 2 , . . . , S superset of elca ( S 1 , . . . , S k ). Section 4.2 described how to efficiently compute elca can ( S 1 ; S 2 , . . . , S k ) and Section 4.3 described how to efficiently check whether an ELCA CAN node in elca can ( S 1 ; S 2 , . . . , S k ) is an ELCA node, when the list of child nodes of v that contain all keyword instances are given. Therefore, the only missing part of efficient computa-tion of elca ( S 1 , . . . , S k ) is how to compute child elcacan ( v ) for each ELCA CAN node v . Since we can easily com-pute child elcacan ( v ) if we know every ELCA CAN node x i under v 1 , we can just compute all ELCA CAN nodes and then compute child elcacan ( v ) for each ELCA CAN node v .

A straightforward approach would compute all ELCA CAN nodes and store them in a tree which keeps the original ancestor-descendant relationships of all ELCA CAN nodes in the input document. However, such an approach has the following disadvantages: 1) the complexity of the approach is O ( d | S 1 | 2 + | S 1 | kd log | S | ) where the O ( d | S comes from the cost of creating and maintaining the tree structure; 2) and all ( O ( | S 1 | )) ELCA CAN nodes have to be computed first and kept in memory before we can start to recognize any ELCA nodes.
 We propose a  X  X ne pass X  stack-based algorithm named the Indexed Stack algorithm. The algorithm need not keep all ELCA CAN nodes in memory; it uses a stack whose depth is bounded by the depth of the tree. At any time during the computation any node in the stack is a child or descendant node of the node below it (if present) in the stack. Therefore the nodes from the top to the bottom of the stack at any time are from a single path in the input tree.

The challenging issue that the Indexed Stack Algorithm has to deal with is illustrated with the running example  X  X ML David X . Before we compute elca can (0 . 3 . 5 . 1)=0 . 3, we have already computed 0 . 3 . 2, 0 . 3 . 3, 0 . 3 . 4 as ELCA CAN nodes which are the child ELCA CAN nodes of 0 . 3. We have to store these three ELCA CAN nodes in order to determine whether 0 . 3 is an ELCA node or not before we see 0 . 3 in the processing. Note that if the node 0 . 3 . 1 . 1 was not in the tree in Figure 1, we would still see 0 . 3 in the processing as an ELCA CAN node and still see 0 . 3 after not be an ELCA node, which could be determined only if child elcacan ( v ) is the set of child nodes u i of v on the paths from v to x i , which can be efficiently computed with Dewey numbers without any disk lookup. Table 1: Main memory and Disk Complexity Anal-ysis of Indexed Stack, DIL and RDIL we have kept the information that 0 . 3 . 2, 0 . 3 . 3 and 0 . 3 . 4 are ELCA CAN nodes until we see 0 . 3 and know that 0 . 3 would not have any child or descendant ELCA CAN nodes in the processing later after we see 0 . 3. It is possible that we would not see 0 . 3 at all in the processing (i.e., if the node 0 . 3 . 5 . 1 was not in the tree, 0 . 3 would not be an ELCA CAN node) the point we are sure that those nodes cannot be child or descendant of any other ELCA CAN nodes.
 The time complexity of the Indexed Stack algorithm is O ( | S 1 | kd log | S | ) where k is the number of keywords in the query, d is the depth of the tree and | S 1 | ( | S | ) is the oc-currence of the least (most) frequent keyword in the query. The time complexity comes from two primitive operations: elca can () and isELCA (). The total cost of calling elca can ( v ) is O ( kd | S 1 | log | S | ) as discussed in Section 4.2. The cost of calling the function isELCA ( v, | child elcacan ( v ) | ) once is | child elcacan ( v ) | kd log | S | (Section 4.3). The accumulated total cost of calling isELCA is O ( | S 1 | . Each node in elca can ( S 1 ; S 2 , . . . , S k ) increases the value of Z by at most one. Thus O ( Therefore the time complexity of the Indexed Stack algo-rithm is O ( | S 1 | kd log | S | ).

The number of disk access needed by the Indexed Stack algorithm is O ( k | S 1 | ) because for each node in S 1 dexed Stack algorithm just needs to find the left and match nodes in each one of the other k  X  1 keyword lists. Note that the number of disk accesses of the Indexed Stack al-gorithm cannot be more than the total number of blocks of all keyword lists on disk because the algorithm accesses all keyword lists strictly in order and there is no repeated scan on any keyword list. Since B+ tree implementations usually buffer non-leaf nodes in memory, we assume the number of disk accesses of a random search in a keyword search is O (1) as in [2, 4]. The complexity analysis of the Indexed Stack, the two algorithms in [2], DIL and RDIL are summarized in Table 1 for both main memory and disk accesses for find-ing all query answers and only top m query answers where | S 1 | ( | S | ) is the occurrence of the least (most) frequent key-word in the query, B is the total number of blocks of all inverted lists on disk, d is the maximum depth of the tree and p is the maximum number of children of any node in the tree. Algorithm details and experimental results on finding all query answers and only top m answers are in the full version of the paper [1].
