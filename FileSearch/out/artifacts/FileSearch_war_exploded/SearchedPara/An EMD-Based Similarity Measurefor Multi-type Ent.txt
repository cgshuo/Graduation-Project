 Today most users X  activities are pivoted around entities in Web browsing and search [3]. To help users explore further, more and more online systems, such as Google and Baidu, provide entity recommendation services based on background knowledge base, including public knowledge bases (e.g., DBpedia [2], YAGO [10], etc.) in the Linking Open Data (LOD) cloud. As we know, the user X  X  intuitive understanding of entity is linked to the types of the entity. For example, when we talk about Albert Einstein , he is usually considered as an instance of the type  X  JewishScientists  X . Entity type is used to describe and distinguish the entities. Therefore recommending entities with similar types is an important part of entity recommendation.

In general, an entity is associated to a set of types in a knowledge base. For example, the entity Albert Einstein in DBpedia has 55 types, such as Person , JewishScientists and NobelLaureatesInPhysics ,justtonameafew.All those types are correct but some may be too general to be important (e.g., Person ), while some others may be particular and meaningful to the user (e.g., JewishScientists , NobelLaureatesInPhysics ). Moreover, there is a hierarchy of types like  X  JewishScientists is a subtype of Person  X .

In previous research, the traditional similarity measures between two multi-type entities are determined by collectio n intersection, such as the overlap mea-sure and the Jaccard measure [1]. Since the i ntersection-based similarity measure only takes into account the common types, it is unable to identify types that have a similar meaning but do not match exactly. In order to solve this problem, pairwise type similarity measures have been proposed by exploiting hierarchi-cal structure in some domain (e.g., WordNet [7]), such as the Lowest Common Ancestor (LCA) [5]. Subsequently, several pairwise multi-type entity similarity measures have been presented based on ty pe vector similarity, such as the cosine similarity measure [5,9], and a type co llection is represented by a type vector. However, the weighting of type is paid little attention in similarity computation.
The weighting of each type within a type c ollection, repres ents the contribu-tion to the similarity between the two entities. For example, some types (e.g., JewishScientists , NobelLaureatesInPhysics ) are crucial when we talk about Albert Einstein . On the contrary, other types describe non-salient facts (e.g., Person ). Thus, the Person is the least important one and has little or no con-tribution to similarity computing. There has been a lot of work related to  X  X erm weighting X  in information retrieval (IR), such as TF-IDF. However, it does not take into account the relationships between types within type hierarchy.
In this study, we measure multi-type entity similarity based on the earth mover X  X  distance (EMD) [8], which not only takes into account pairwise type similarity, but also the weighting of entity type. The EMD is based on a solu-tion to the transportation problem. It computes the minimal  X  X ork X  that must be paid to transport goods from several suppliers to several consumers. The weighting of types is the key factor in the EMD. In this paper, we also present a PageRank-based weighting scheme by using type hierarchy.

The rest of the paper is structured as follows. Section 2 introduces the multi-type entity similarity measure based on EMD. Section 3 introduces two base-line weighting schemes and presents our PageRank-based weighting scheme. Our evaluation is reported in Section 4. Sect ion 5 describes related work and Section 6 concludes this paper. The Earth Mover X  X  Distance (EMD) is one of the most popular distance func-tions, which is used in various fields, such as searching similar multimedia con-tents [8] and measuring document similarity [13].

The EMD is modeled as a solution to the transportation problem. Suppose that several suppliers, each with a given amount of goods, are required to sup-ply several consumers, each with a giv en limited capacity. For each supplier-consumer pair, the cost of transporting a single unit of goods is given. The transportation problem is then to find a least-expensive flow of goods from the suppliers to the consumers that satisfies the consumers X  demand.

Measuring multi-type entities similarity can be naturally cast as a transporta-tion problem. We define one entity as the supplier and the other as the consumer, and set the cost for a supplier-consumer pair to equal the ground distance be-tween a type in the first entity and a type in the second. Intuitively, the solution is then the minimum amount of  X  X ork X  required to transport types from one entity to the other. The problem is formalized as follows:
Given two multi-type entities a and b ,  X  Let D =[ d ij ] the ground distance matrix where d ij is the ground distance
We want to find a flow F = { f ij } , with f ij the flow between t ai and t bj ,that minimizes the overall cost subject to the following constraints:
Constraint (2) allows moving types from A to B and not vice versa. Constraint (3) limits the amount of supplies that can be sent by the types in A to their weights. Constraint (4) limits the types in B to receive no more supplies than their weights; and constraint (5) forces to move the maximum amount of supplies possible. Once the transportation problem is solved, the EMD is defined as the work normalized by the total flow:
Finally, the similarity between entities a and b is defined as follows: sim EMD ( a , b ) is in the range of [0, 1]. The higher the value of sim EMD ( a , b )is, the more similar entities a and b are.

Efficient algorithms for solving the EMD problem are available. However, the computational complexity is a major hurdle to the EMD computing, which is between O ( N 3 )and O ( N 4 ) in general ( N represents the total number of the types in entity a and b ). In our context, the performance is not the key consideration since the size of the collection of entity types is not very large. We used the transportation-simplex method [8] to compute the EMD, which is a streamlined simplex algorithm. Givenanentity a and its type collection T a = { t a 1 ,t a 2 ,...,t am } in a given knowledge base, we define a type weighting function w : T a  X  [0 , 1], and let i =1 w ( t ai )=1. w ( t ai ) &gt;w ( t aj )representsthatthetype t ai is more important than t aj among the type collection T a .InRDFS/OWL,the T a can be derived from triples in the form ( uri, rdf : type, t ), where uri identifies the entity a .
In this section, we introduce two base-line weighting schemes, including statistics-based and depth-based schemes. Finally, we propose a novel PageRank-based weighting scheme by using type hierarchy. 3.1 Base-Line Schemes Statistics-Based Scheme. The tf-idf [9], short for term frequency-inverse document frequency, is a numerical statistic that is intended to reflect how im-portant a word is to a document in a collection or corpus. It is often used as a weighting factor in IR and text mining.

We adopt the tf-idf for weighting an entity type. In our context, an entity is regarded as a document, an entity type is regarded as a word. First, we compute the tf and idf values of an entity type. where n tai,a is the number of times that the type t ai occurs in the type collection of the entity a , in this case the n tai,a equals 1 or 0. N is the total number of entities in the dataset and df ( t ai ) is the number of entities having the type t ai .
Finally, the tfidf -based weighting scheme for entity type is derived as follows: Depth-Based Scheme. The large-scaleknowledge bases (e.g., DBpedia, YAGO, etc.) provide very rich ontologies, which consist of a set of concepts and relations among them.
In our context, we focus on the hierarchy of classes. In RDFS/OWL, the class hierarchy is specified in triples in the form ( c 1 ,rdfs : subClassOf, c 2). A simple example of the type hierarchy is shown in Figure 1.

Knowing the relations among types and their depth in the hierarchy is often helpful when automatically weighting entity types. Tonon et al. [12] introduced an approach ( ancDepth ) for ranking entity types. Note that the type hierarchy of an entity is usually not a tree, but forms a directed acyclic graph (DAG). To obtain a single type tree from DAG, they eliminated the cycles manually, and added some relationships by domain experts. We use the ancDepth for weighting an entity type. Given an entity type hierarchy, the ancDepth is defined as follows: where Ancestor ( t ai ) is the ancestors of t ai inthetypehierarchy,the depth ( t aj ) is the depth of t aj in the type hierarchy. Finally, the ancDepth -based weighting for entity type is defined as follows: 3.2 PageRank-Based Scheme The process of understanding entity type is regarded as a random surfing on entity type graph. In general, there are two common ways of thinking ( vertical thinking and horizontal thinking ). The former is sequential pathway thinking and can deepen the understanding of things. The latter is to investigate the thinking wider not deeper.

In our context, the two kinds of thinking are reflected in process of under-standing entity type. Given an entity type hierarchy, we define two kinds of edge: vertical edge and horizontal edge .  X  Vertical Edge: There is a vertical edge starting at one type t u and ending  X  Horizontal Edge: There is a horizontal edge starting at one type t u and
Furthermore, the user may have a preference on which kind of edge to follow, when a user is navigating inside the entity type graph. We characterize the preference by a parameter p , which is a value between 0 and 1 representing the probability of following vertical edges, and thus 1-p of following horizontal edges.
To characterize the user X  X  preference edges, we derive a weighted type graph as follows: First, the type hierarchy is usually a directed acyclic graph (DAG) in the knowledge base. We extracted an en tity type hierarchy from DAG, which is Hasse diagram and denoted by TT .

Then a graph G =( V,E,W ) is a weighted and directed graph, where each vertex represents an entity type. Given i,j  X  V and i = j, ( i,j )  X  E iff there exists at least one vertical edge or horizontal edge from i to j ,where V and E stand for the set of vertices and edges. W is weighting function, which is defined in (12). where p is the navigational preference of a surfer. The weighted type graph of Albert Einstein in DBpedia is shown in Figure 2.
Next, we devise the focused PageRank (PR) [4], to measure importance of entity type based on weighted type graph. The PR value of entity type can be computed as following: where d is the damping factor and N is the total number of vertices.
The PageRank -based weighting for entity type is defined as follows: In this section, we evaluate the performance of the PageRank(PR) -based type weighting scheme and the EMD-based similarity measure on real-world datasets (i.e., DBpedia, Last.fm).

We use DBpedia as the knowledge base, and select four entities from different popular types as our test case. Using crowdsourced judgments on the test case, we create a  X  X olden standard X  including two parts, one is about type ranking for each of the four entities, the other is about similar entities for each of the four entities. We compare the effectiveness of our PR -based scheme with the tfidf -based and the ancDepth -based weighting schemes. We also evaluate the perfor-mance of our EMD-based similarity measure and traditional similarity measures (i.e., Jaccard , Cosin tfidf ).

Next, we create a ground truth of artist recommendation from Last.fm. For the recommendation accuracy, we compare our EMD-based similarity measure with two traditional recommendation methods (i.e., Simple Tag-Cloud Comparison [11], Tag Vector Similarity [11]). 4.1 Experiment on DBpedia Dataset. We used the DBpedia dataset and sel ected 4 common types (i.e., actor, scientist, city, company). Some characteristics of these datasets are shown in Table 1.
 Crowdsourced Judgement. We invited 24 participants (comprising graduate and undergraduate students majoring in computer science) to take part in the eval-uation.

For each dataset, we constructed a ran ked entity list according to the number of related entities [3] of each entity in DBpedia. Then we selected one entity from top 500 entities of each list at random. Altogether there are four entities, Jackie Chan (383 related entities, 21 types), Albert Einstein (129 related entities, 55 types), Sydney (2948 related entities, 24 types) and IBM (508 related entities, 22 types) separately, to be regarded as  X  X elections X  for the testing tasks. We prepared the tasks as follows:  X  Extract the important entity type . For each  X  X election X , the user is asked to pick  X  Extract the similar entity . Meanwhile, for each  X  X election X , the user is asked Note that, for each  X  X election X , we can hardly ask users to give a ranking of all the other entities by the similarity in dataset, but rather, we apply the depth-10 pooling technique, which is widely adopted for evaluating IR systems. To be specific, we apply three similarity measures (i.e., Jaccard , Cosin tfidf , EMD )to score all the other entities in dataset resp ectively. Then, for ea ch result, we retain those having positive relatedness values, and collect the top-10 ones. Finally, we obtain the recommended entities by combining the three top-10 ones together. Evaluation Metric. WeusedtheNormalizedDiscou ntedCumulativeGain(NDCG) [6], which is a widely used metric for IR evaluation. NDCG@k, inside the interval [0,1], measures the quality of the top-k ranked element list against the golden stan-dard list. The NDCG is defined for a cut-off level k as: and DCG ideal @ k is the maximum attainable DCG value, g ( e i ) is the gain as-signed to element e i .Inourexperiment, k =3 , 5 , 8 , 10.
 Experimental Results for Type Weighting Schemes. We present the performance comparison between PR-based weighting s cheme and the two base-line weighting schemes (i.e., tfidf , ancDepth ).

For the fitness of the PR-based scheme, we set navigation preference p with the different values (i.e., p =0.0, 0.2, 0.5, 0.8, 1.0). An interesting observation in Figure 3 is that: when p increases, the NDCG scores keep ascend or stable. It shows that the specific type is more important, as it is closer to human intuition. However when p = 1, the approach has a poor effectiveness. It can be interpreted as following: p = 1 means the horizontal edges are ignored. The weighted type graph becomes simplified, only consideri ng the vertical edges in the weighted type graph. By observing the result, we set p = 0.8 in latter evaluation.
Next, we compare the PR-based sch eme with other two schemes (i.e. tfidf , ancDepth ). In addition, we combine the above three kinds of scheme by using simple linear combination to see whether better results can be achieved. The result is shown in Figure 4. In all cases, the PR -based scheme performs better than the tfidf -based and the ancDepth -based schemes. We also observe that the combined weighting scheme has the worse performances compared with the PR -based scheme.
 Experimental Results for Different Similarity Measures. The performance com-parison among EMD-based measures with different weighting schemes is de-picted in Figure 6.

For the fitness of the EMD-based measure, we chose a commonly used method (i.e. LCA [5]) as the pairwise type similarity measure, and used four kinds of type weighting scheme (i.e. 1/m , tfidf , ancDepth , PR ). Notice that  X 1/m X  represented that  X  w ai =1 /m and w bj =1 /n  X . We observe that EMD PR performs better than EMD 1 /m , EMD tfidf and EMD ancDepth , as seen in Figure 5.

Next, we consider the NDCG scores for d ifferent similarity measures as shown in Figure 6. It illustrates that the EMD-based similarity measure outperforms the Jaccard and the Cosin tfidf measures.
 4.2 Experiment on Last.fm Dataset. Last.fm is a music website, allows us ers to tag their music collection, and uses the wisdom of the crowd to generate recommendations. We selected the top-1000 popular artists, and collected all of the artists similar to each artist through the API of Last.fm 1 . For each artist, we extra cted the top-50 similar artists from returned data, and created the ground truth recommendation as baseline. We get 16,285 music artists from recommendation of Last.fm in total.
Next, we use DBpedia as the knowledge base, and select all instances of db-pedia:MusicalArtist from DBpedia as our test case, including 10288 entities. Through the  X  X tring match X  of the artist X  X  name, we finally identify only 4076 common artists between Last.fm and DBpedia.
 Evaluation Metric. We use precision and recall, which are standard metrics in Top-N recommendation ( N ranging over 3 to 50 in our experiment).

For an entity e , R(e) denotes the similar entities recommended from our method. U(e) denotes the baseline from Last.fm. The precision and recall for an entity e are calculated as follows: Experimental Results for Entity Recommendation. Our EMD-based similarity measure can be applied to the tag-based Top-N recommendation.

We present the performance compari son on recommendation accuracies be-tween our EMD-based measure with two traditional recommendation methods. One is called Simple Tag-Cloud Comparison (STCC) method [11], which is sim-ilar to the Jaccard measure. The other, Tag Vector Similarity (TVS) [11], which is similar to the Cosin tfidf measure. For the fitness of the EMD-based measure, we chose the LCA as the ground distance, and used two kinds of type weighting scheme (i.e. 1/m , PR ).

The result is shown in Figure 7. In all cases, the EMD-based measures out-perform STCC and TVS, and the EMD PR measure has the best performance. As indicated in Figure 7, all methods hav e low precision and recall scores, it can be explained by the fact that our  X  X round truth X  recommendation from Last.fm includes many new artists, which do not appear in DBpedia.
 The traditional similarity measures be tween two collections of types have been proposed by using the set-intersection, such as the Jaccard measure and the overlap measure [1]. Since the intersection-based similarity measure only uses the common types, it does not take into account pairwise similarity between two types. To solve this problem, similarity measures between two types have been proposed by exploiting type hierarchical structure, such as using the depth of the lowest common ancestor (LCA) [5] between two concepts. Subsequently, several pairwise multi-type entity similarity me asures have been presented based on type vector similarity. Salton and Buckley [9] used the cosine-similarity measure based on tf-idf for evaluating document similarity, and the document is modeled as bag of words. Ganesan et al. [5] introduced the cosine-similarity measure based on LCA for computing object similarity.

The Earth Mover X  X  Distance (EMD) is proposed by Rubner et al. [8] to mea-sure dissimilarity between two multi-dimensional distributions in a feature space, which is widely applied in various fields, such as searching similar multimedia contents [8], measuring document similarity [13] and so on. Moreover, entity type weighting has played an important role in various fields, such as entity summary, ranking search results [12] and so on. Existing weighting approaches are mainly based on statistics analysis (e.g., TF-IDF) [9] and the type hierarchy (e.g., the depth of ancestors of entity type) [12]. For recommending entities with similar t ypes, we investigated the similarity measure between type collections. In t his paper, we proposed an EMD-based similarity measure for multi-type entity recommendation, and also devised a PageRank-based weighting scheme by using type hierarchy. By using a hand-crafted golden standard on real dataset, we compared our type weighting scheme with the base-line weighting schemes, and also compared our EMD-based simi-larity measure with the traditional similarity measures. Moreover, we compared our EMD-based similarity measure with two traditional recommendation meth-ods by using a ground truth of artist recommendation from Last.fm.

The evaluation results demonstrate that our PageRank-based type weighting scheme is more effective than the base-line weighting schemes, and also show that our EMD-based measure outperforms traditional similarity measures.
For future work, we would like to take more empirical study to compare different weighting schemes and entity recommendation methods by using other semantic information in the background knowledge base.
 Acknowledgements. This work is supported by the National Natural Science Foundation of China (NSFC) unde r Grants 61170068 and 61100040, and it is also supported by National Social Science Foundation of China under Grant 11AZD121. We would like to thank Dr. Gong Cheng for his valuable suggestion on this work. We are also grateful to the 24 students who participated in the construction of the  X  X olden standard X  of recommendation lists for the selected four entities.

