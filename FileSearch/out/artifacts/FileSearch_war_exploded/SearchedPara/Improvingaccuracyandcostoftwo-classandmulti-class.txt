 The nai ve Bayes classifier has the seemingly paradoxical property that, while the assumption of conditional inde-pendence of the attrib utes is violated in man y domains, the predictions deri ved from its probability estimates are often fairly accurate. The paradox can be resolv ed by noting that in order to get good classification performance it is suf fi-cient that the posterior class probability estimates are well-separated. It doesn X  t matter that the posterior estimates are uncalibrated, as long as positi ve instances tend to be as-signed higher predicted probabilities of being positi ve than negati ve instances. As far as the nai ve Bayes classifier is concerned, the posterior estimates are simply scores from which it mak es predictions by applying a decision criterion. The usual decision criterion is  X  X redict the class with the highest posterior probability X , or in two-class problems  X  X redict the class whose posterior probability exceeds 0.5 X . Ho we ver, given that the probability estimates are inaccu-rate, there is no real justification for such a decision cri-terion. In our vie w, the nai ve Bayes decision criterion is an additional model parameter that has to be learned from the data. In the two-class case, the decision criterion is simply a threshold, which can be ele gantly learned from the data using (tw o-class) ROC analysis. Ho we ver, there is no straightforw ard way to upgrade this method to more than two classes, because the necessary apparatus of multi-class ROC analysis is lacking. The main contrib ution of this paper is a method to learn a decision criterion from the data by tuning class weights using greedy optimisation. The method is experimentally sho wn to lead to significant impro vements in classification accurac y. 1.1. ROC analysis ROC analysis (Recei ved Operating Characteristic) was in-troduced in signal detection theory to describe how well a recei ver could distinguish a signal from noise. It has a long history in medical data analysis where it is used to inves-tigate sensiti vity/specificity trade-of fs of diagnostic tests. It was introduced in machine learning relati vely recently (see e.g. (Pro vost &amp; Fawcett, 2001)) and is quickly gain-ing popularity as a tool for analysing and visualising man y aspects of machine learning algorithms. Some recent de-velopments are described in (Fawcett, 2003); man y of our notations are borro wed from that paper .
 A two-class ROC curv e is a two-dimensional curv e in which the True Positi ve rate ( T Pr ) is plotted on the Y axis and the False Positi ve rate ( F Pr ) is plotted on the X axis. Those rates are estimated as follo ws:
T Pr = A discrete classifier , e.g. a decision tree, produces a single ROC point ( F Pr ; T Pr ) . Man y classifiers, such as Bayesian classifiers or neural netw orks, naturally assign to each in-stance i a score f ( i ) expressing the degree to which i is thought to be positi ve. In particular , probabilistic classi-fiers such as nai ve Bayes output posterior probability dis-trib utions over classes. In classification, it is often more con venient to work with scores as the y can be manipu-lated without the need for re-normalisation. Probabilities can be con verted into scores by the follo wing monotonic transformation: let f ( P ; i ) (resp. f ( N ; i ) ) denote the esti-mated probabilities that i is positi ve (resp. negati ve), then f ( turned into a cate gorical classifier by setting a threshold on the score, i.e. instance i is classified as positi ve if f is greater than a fix ed threshold t , and negati ve otherwise. In the absence of any other information, this threshold is usually set to 1, which corresponds to a uniform posterior distrib ution in the case of a probabilistic classifier . Ho w-ever, we argue that this decision threshold should in fact be learned from the data in order to maximise accurac y or minimise cost. 1.2. Lear ning the decision thr eshold ROC analysis pro vides an ele gant way to do this. Each value of the decision threshold corresponds to an ROC point, and a piece wise linear ROC curv e can be dra wn by varying the threshold and plotting the corresponding points. (There is a more efficient algorithm based on order -ing the instances according to their predicted scores, which will be explained in Section 2.) This curv e gives an aggre-gated assessment of the classification power of the scoring classifier , without reference to a decision threshold. The area under the curv e estimates the probability that a ran-domly chosen positi ve instance obtains a higher score than a randomly chosen negati ve instance (Hand &amp; Till, 2001). Figure 1 sho ws an ROC curv e corresponding to the per -formance of a first-order nai ve Bayes classifier , 1BC2 , on predicting a desired property of drugs against Alzheimer X  s disease (see Section 4). The crossing vertical and hori-zontal lines indicate the point corresponding to the def ault threshold f ( i ) = 1 (i.e., classifying i as positi ve if f f (
N ; i ) ). The diagonal line through this point is the iso-accurac y line corresponding to all points in the ROC space having the same accurac y a = p ( P ) T Pr + p ( N )( 1 F Pr as the def ault threshold, where p ( P ) and p ( N ) are the prior class probabilities. The main point to note is that a lar ge part of ROC curv e lies abo ve this iso-accurac y line, and consequently there are man y thresholds that would achie ve a higher accurac y (on the same set of instances) than the def ault threshold. In this particular case these thresholds are found to the right of the def ault point, corresponding to an increased number of positi ve predictions, hence a lower decision threshold. The optimal decision threshold can be found graphically by sliding the iso-accurac y line upw ards until it intersects with the ROC curv e in a single point. It is easy to factor misclassification costs into this anal-ysis. The equation of the iso-accurac y line of all points achie ving accurac y a is T Pr = p ( N ) an ROC curv e, the optimal point on this curv e is uniquely determined by the slope of the iso-accurac y lines, i.e., the class distrib ution. If we denote by c ( N ; P ) (resp. c the cost of misclassifying a positi ve (resp. negati ve) in-stance, the expected cost of applying the classifier cor -responding to a point ( F Pr ; T Pr ) in the ROC space is c = p ( P )( 1 T Pr ) c ( N ; P ) + p ( N ) F Prc ( P ; N ) line could be dra wn with all points having the same cost misclassification costs can be simply tak en into account by modifying the class ratio and thus the slope of the iso-performance lines. We could similarly tak e correct clas-sification profits into account, or use a class ratio that is dif ferent from the one in the set of instances from which the ROC curv e is constructed. 1.3. Contrib ution of this paper An algorithm to find the optimal point on a given two-class ROC curv e is thus a fairly straightforw ard construction, and all essential ingredients (probabilistic ROC curv es, iso-performance lines) were already present in (Pro vost &amp; Fawcett, 2001). Ho we ver, a generalisation to more than two classes is problematic, because there is no fully de-veloped multi-class ROC analysis. A full n -class ROC analysis would require n ( n 1 ) dimensions, distinguish-ing all possible misclassifications (one-against-one). By aggre gating all misclassifications per class we obtain a n -dimensional approximation (one-against-all). We briefly revie w the few results in multi-class ROC analysis that we are aware of. An analysis of the special case of 3 classes (one-against-all) is given in (Mossman, 1999), concentrat-ing on the proper statistical interpretation of the volume un-der the ROC surf ace (in analogy with the two-class area un-der the ROC curv e). (Srini vasan, 1999) pro ves that, given a set of one-against-one misclassification rates, there is a unique con vex polytope enclosing those points (in analogy with the two-class con vex hull). (Hand &amp; Till, 2001) pro-pose a multi-class version of area under the ROC curv e by averaging the areas of the n one-against-all curv es. None of these works addresses the issue of constructing a multi-class ROC hypersurf ace for a given probabilistic model. Current indications are that such a construction, which would be necessary to find a globally optimal multi-class decision criterion, is computationally intractable (we discuss this at the end of the paper). Our approach works as follo ws. The kind of decision criterion that we consider simply assigns the class with maximum score, taking into account positi ve weights for each class. The n 1 weights (one can be set arbitrarily) are learned using greedy hill-climbing search assuming a fix ed ordering of classes. The two-class procedure for finding a global optimum outlined abo ve is a special case of this procedure.
 The outline of the paper is as follo ws. In Section 2 we present in detail the optimisation algorithm for two-class domains. Section 3 presents the main contrib ution of the paper , which is an optimisation algorithm for multi-class domains. In Section 4 we give experimental results vali-dating our approach on a variety of propositional and first-order datasets. Section 5 discusses issues related to finding the global optimum. Section 6 concludes. Given the relationships between a point on a two-class ROC curv e and the accurac y or cost of the corresponding classifier , accurac y/cost can easily be optimised by con-sidering all the points of the ROC curv e. We now sho w how this optimisation can be achie ved by a variant of the practical method for constructing an ROC curv e given by (Fawcett, 2003). The basic idea of such an algorithm is to sort the instances i according to decreasing scores f ( starting in (0,0), the curv e is dra wn by mo ving 1 = P up if the next instance is an actual positi ve, and mo ving 1 = N to the right if it is an actual negati ve, until we reach (1,1) ( P and N are the total number of positi ve and negati ve instances). In the case of dra ws, i.e. x positi ves and y negati ves get-ting the same score, we dra w a single diagonal segment by mo ving x = P steps up and y = N steps to the right at once. Table 1 modifies this algorithm such that it returns the best threshold from a list of instances i and their scores f ( If desired, this algorithm can be mer ged with the pre vious one into a single algorithm for dra wing the curv e and calcu-lating the optimal threshold simultaneously . The threshold is always chosen in between two successi ve scores f and f 0 by setting it to p f f 0 (since our implementation of the nai ve Bayes classifier actually maintains logarithms of the scores, this corresponds to averaging the log scores). Algorithm findBestThreshold is optimal in the sense that it results in the highest accurac y or lowest cost achie v-able with the given scores on the given set of instances. In practice, the quality of the optimisation depends on the quality of the scores, i.e. of the probabilistic model. If the model is overfitting, then what appears to be the optimal point on the ROC curv e may actually lead to worse perfor -mance. On the other hand, if the model is good then the optimisation will not decrease performance. In this section we adapt the two-class optimisation method to deal with more than two classes. In our approach, a multi-class probabilistic classifier is turned into a cate gori-cal classifier by setting weights on the class scores f ( for all classes Q , and assigning the class which maximises the weighted score. The main dif ficulty is that there is no simple algorithm tracing the ROC surf ace by sorting in-stances. We are not aware of any algorithm that, given the scores f ( Q ; i ) , efficiently calculates all possible classifica-tions of a set of instances that can be achie ved by setting weights on these scores. Section 5 gives some further con-siderations regarding the comple xity of this problem. In the absence of such a method, we develop in this section a hill-climbing algorithm that optimises the weights separately . 3.1. Fr om ROC cur ves to ROC polytopes Let r ( P ; A ) be the proportion of instances of actual class A that are predicted in class P . Then the ex-pected accurac y is  X  A p ( A ) r ( A ; A ) and the expected cost is  X 
A  X  P 6 = A p ( A ) r ( P ; A ) c ( P ; A ) , where p ( A ability of class A , and c ( P ; A ) is the cost of misclassify-ing an instance of A as class P . Therefore, for an n -class domain, an ( n 2 n ) -dimensional ROC space has to be considered where points have coordinates ( r ( P ; A )) , for all classes A ; P 6 = A . That is, any n -class classifier produces an ( n 2 n ) -tuple of misclassification rates, which corresponds to a single point in ROC space. The two-dimensional ROC curv e becomes an ( n 2 n ) -dimensional polytope. In order to obtain a multi-class decision criterion that can be optimised, the single decision threshold used with two classes is replaced by weights w A associated with each class A (one weight can be set to 1, since there are n 1 degrees of freedom). The weighted probabilistic classifier classi-fies instance i into class P maximising w P f ( P ; i ) , where f (
P ; i ) denotes the probabilistic classifier X  s estimate of the probability that instance i belongs to class P . For two classes, this reduces to classifying an instance as positi ve plays the role of the threshold on f ( P ; i ) w
P has been set to 1). In the multi-class case, howe ver, there is no direct relation between weights and global prob-ability thresholds. For any two classes P and Q , the only thing we can say is that an instance will not be classified in class Q , but possibly in class P , if f ( P ; i ) 3.2. Setting the weights The trick of the two-class algorithm in Table 1 is not to consider all possible thresholds, but only those such that the classification of a single instance changes from posi-tive to negati ve. To achie ve this, the instances are sorted according to f ( i ) : f ( i 1 ) &gt; f ( i 2 ) &gt; : : : &gt; ering any threshold value between f ( i k ) and f ( i k + fies the k first instances as positi ve and the m k remaining instances as negati ve. As a result, the algorithm only con-siders at most m + 1 classifications out of the 2 m possible distrib utions of m instances over 2 classes. Our aim is to upgrade this algorithm from two classes to n classes. The main dif ficulty is that there are n 2 n 2 orderings of the m instances, according to f ( P ; i ) Definition 1 Given two classes P and Q, and two instances i and j, &gt; P Given two classes P and Q , Q 6 = P , it would be straight-forw ard to fix all other weights w R to 0, w P to 1 and tune w
Q in order to change step by step the classifications of all instances from class P to class Q , in order to find the opti-mal accurac y or cost. This could be repeated for all classes P ;
Q 6 = P . Ho we ver, it is obvious that such an approach does not consider all possible classifications of the instances, for instance those classifications corresponding to more than two weights being strictly greater than 0. At the other ex-treme, a blind exhausti ve search algorithm could enumer -ate all possible classifications of the m instances. Ho w-ever, there are n m ways of classifying m instances into n classes. Ob viously this is untractable in most cases, for in-stance in the diterpene domain (cf. Section 4.2), there are Therefore we propose a hill-climbing approach. Given an ordering of the classes and assuming the y are labelled 1 ; 2 ; : : : ; n , the weights are fix ed in that order , by consid-ering only instances of the class currently being optimised against all classes whose weights already have been fix ed. The optimisation consists either in minimising the expected cost, or in maximising the expected accurac y. Table 2 gives the main steps of this algorithm. It starts by fix-ing the first weight w 1 = 1. At step P , the first P 1 weights have been fix ed, and weight w P is tuned by call-ing findBestWeight , taking into account only predic-tions into classes Q P (since the weights of the remaining classes are still zero).
 The findBestWeight algorithm (Table 3) is actually a variant of the findBestThreshold algorithm (Table 1). Since there are more than 2 classes, and the misclas-sification costs depend on the actual and predicted classes, three changes are required. The  X  X redicted X  class is Q = would be classified if only the first classes R &lt; P were considered; this is stored for each instance before calling findBestWeight . The score f ( i ) of each instance is calculated as follo ws: the  X  X ositi ve X  class is P , and the  X  X e g-score is f ( i ) = f ( P ; i ) the predicted and actual classes of each instance, the third novelty of the findBestWeight algorithm is the addi-tion of class P as input, to estimate the appropriate costs when instances become misclassified into the class P due to an increase of its weight w P .
 3.3. Discussion In the three-class case, the effect of reweighting the nai ve Bayes scores can be visualised as follo ws. 1 For each in-stance to be classified, the nai ve Bayes classifier predicts a triple of probabilities, one for each class (here we as-sume normalised scores). These triples can be visualised as points in a probability cube; since the probabilities add up to 1, the points lie in an equilateral triangle connect-ing three corners of the cube. Each corner of this triangle represents a particular class to which it assigns probability 1; each side of the triangle represents a probability of zero for the class opposite that side (Figure 2). More generally , the probability for a particular class in a given point corre-sponds to the distance to the side opposite that class. The decision criterion of assigning the class with maxi-mum probability corresponds to class boundaries that are perpendicular to the sides of the triangle; in the case of equal weights these lines intersect at the triangle X  s centre of gra vity (dotted lines in Figure 2). Our algorithm will first adjust class 2 against class 1; this fix es the vertical de-cision boundary . By taking class 3 into account, we find the optimal point on this vertical boundary . Notice that this last step may change some class 1 or 2 predictions into class 3 predictions, but it will never change class 1 predictions into class 2 or vice versa.
 The algorithm is not guaranteed to find a local optimum: for instance, it might be possible to find, given the weights for classes 2 and 3 just determined, a better weight for class 1. Also, the approach depends on the order of the classes: if we start by adjusting class 3 against class 1 (i.e., mo v-ing the decision boundary perpendicular to the 1-3 side), we may end up in a dif ferent point altogether . Intuiti vely , it seems a good idea to start with the lar gest classes, since adjustments involving those classes have (potentially) the biggest impact. This has been verified experimentally by comparing with random orderings as well as the reverse or-dering (smallest classes first). A more sophisticated strat-egy would be to tak e the unweighted predictions (and the cost matrix) into account.
 It should be noted that, when adjusting class 3 against classes 1 and 2, it is possible to distinguish between dif-ferent kinds of misclassifications (3 misclassified as 1, 3 misclassified as 2, 1 misclassified as 3, etc.) and thus tak e class-against-class misclassification costs into account. In fact, even when adjusting class 2 against class 1, we tak e class 3 instances into account, because misclassifying them as class 1 may have dif ferent cost from misclassifying them as class 2. Experiments have been carried out to evaluate the impro ve-ment in accurac y of a nai ve Bayes classifier obtained with our method. Two first-order Bayesian classifiers were used: 1BC (Flach &amp; Lachiche, 1999) and its successor 1BC2 (Lachiche &amp; Flach, 2002). 1BC applies dynamic propo-sitionalisation, while 1BC2 is a true first-order classifier which works by decomposing probability distrib utions over structured terms. On propositional domains both classifiers return the same probabilistic model. We considered propo-sitional (i.e., attrib ute-v alue) as well as relational datasets. All experiments were performed using a 10-fold cross-validation: training the probability model as well as the de-cision criterion on the training set, evaluating the weighted classifier thus obtained on the test set and averaging the re-sults. 4.1. Pr opositional datasets All 25 propositional datasets were tak en from the UCI ma-chine learning repository (Blak e &amp; Merz, 1998). Table 4 reports the number of classes and the accuracies of 1BC without optimisation, 1BC with optimisation, and Weka Nai ve Bayes (W itten &amp; Frank, 2000), for each dataset (sometimes for dif ferent tar gets of a given dataset). Fig-ures are indicated in boldface whene ver the observ ed dif-ference of the accurac y between 1BC with optimisation and the other classifier is significant using a one-sided paired t-test with a confidence of 95%.
 Table 5 summarises the significance results. The optimisa-tion decreases accurac y significantly only once when com-pared with unoptimised 1BC , and twice when compared with Weka Nai ve Bayes (indicating that in one of these cases the lower accurac y was caused by the poorer prob-ability model learned by unoptimised 1BC ). 4.2. Relational datasets Three relational datasets have been considered. The first dataset is about drugs against Alzheimer X  s dis-ease (Bostr  X  om &amp; Ask er, 1999), with four distinct tar gets. The second dataset concerns identifying mutagenic com-pounds (Srini vasan et al., 1994; Muggleton et al., 1998). We considered the  X  X e gression-friendly X  dataset of 188 molecular compounds. In these experiments, we used the atom and bond structure of the molecule as one setting, adding the lumo and logp properties to get a second set-ting, and finally adding boolean indicators I a and I 1 as well. We also considered the latter propositional proper -ties separately . The third dataset is concerned with Diter -penes, which are one of a few fundamental classes of nat-ural products with about 5000 members kno wn (D  X  zeroski et al., 1998). The classification task consists of identify-ing types of diterpenes from NMR spectra. Table 6 reports the accuracies of 1BC without and with optimisation, and of 1BC2 without and with optimisation, for each of these datasets, tar gets, and settings .
 Table 7 summarises the significance results on the rela-tional data. The results are a bit more mix ed than in the propositional case, but still there are only three significant losses out of 24 experiments. The optimisation seems to work better for 1BC , but this may be due to the fact that in man y cases unoptimised 1BC2 comes already quite close to the optimised accurac y. There is one quite spectacu-lar failure of the optimisation method for the propositional version of mutagenesis (only lumo, logp, inda and ind1). Clearly , the probability model is overfitting here so that the optimum on the training data does not correspond to the optimum on the test data. In Section 3.2, a brute-force algorithm, enumerating all possible classifications of the m instances, was discarded due to an exponential number of possible distrib utions of m instances over n classes. Ho we ver, given a probabilis-tic classifier and a set of instances, man y of those com-binations are impossible using weighted maximisation as the decision criterion. In this section, we investigate some properties of multi-class ROC space in the hope of finding a more efficient algorithm to find the global optimum. We can use the &gt; P classifications.
 Theor em 1 Given two instances i and j, if i &gt; P ther e are no weights w P , w Q suc h that i is classified in class Q and j is classified in class P.
 Proof: i is classified in class Q implies that w P f ( P ; w
Q f ( Q ; i ) , so that w P f ( P ; j ) &gt; w Q f ( Q ; j ) , so f ( P ; j Another issue consists in finding a set of weights corre-sponding to a given classification. Notice that the classi-fication of an instance i in class P corresponds to n 1 inequalities: 8 Q 6 = P ; w P f ( P ; i ) &gt; w Q f ( Q ; two classes P and Q , each instance i classified in class P implies the constraint f ( P ; i ) w
Q . Since the instances are ordered according to &gt; P considering the instance classified in class P minimising ing to &gt; P cally , only the top instance classified in class Q according to &gt; P = Q should be considered.
 Theor em 2 Let I P be the set of instances that are classi-fied in class P, and let m P min i Proof: For all instances i 2 I Q , w P f ( P ; i ) &lt; w stances i 2 I P , w P f ( P ; i ) &gt; w Q f ( Q ; i ) , i.e. Suppose that the n classes are labelled 1 ; 2 ; : : : ; n . w be fix ed to an arbitrary value, e.g. 1. Then the weights w should satisfy the constraint: max P &lt; Q ( m P constraints is always satisfiable. If it is, it would mean that the orderings &gt; P impossible classifications.
 Note that this process of finding possible weights, which is linear in the number of instances m and quadratic in the number of classes n , has to be repeated for each possible classification. In other words, it does not pre vent enumerat-ing all classifications. Moreo ver, preliminary experiments indicated that the number of possible classifications is ex-ponential itself. So it might be impractical to find the global optimum by upgrading the algorithm in Table 1 from two-class to multi-class domains.
 As we noticed earlier , two dif ferent possible classifications of the instances might lead to the same point. So an alter -nati ve approach considering the ROC space might be more successful. This is a perspecti ve for future work. The probability estimates of a nai ve Bayes classifier are inaccurate if some of its underlying independence assump-tions are violated. The decision criterion for using these estimates for classification therefore has to be learned from the data. This paper proposes the use of ROC curv es to ex-perimentally find better decision boundaries. The method can easily tak e non-uniform misclassification costs into ac-count. For two classes, the algorithm is a simple adaptation of the algorithm for tracing a ROC curv e by sorting the instances. There is no obvious way to upgrade this algo-rithm to the multi-class case. We propose a hill-climbing approach which adjusts the weights for each class in a pre-defined order , determining the weight for class P only on the basis of the weights of classes Q already determined. The method starts from an initial probabilistic model and constructs an ROC curv e and a set of weights determining the decision boundaries. This mak es the approach applica-ble to any learning method which outputs class scores: for instance, our method could equally well be applied to recal-ibrate decision trees. Experimental evaluation on a range of propositional and relational datasets demonstrates that the method works very well in practice. For instance, when used in combination with 1BC we achie ved 13 significant wins, 22 dra ws and only 2 losses.
 Future work includes a further study of the feasibility of finding a global optimum. The main open problem here is how a set of weights on class scores constrains the possi-ble classifications of a test set. It might be a good idea to start from decision tree classifiers rather than nai ve Bayes classifiers, since a decision tree ROC curv e can be obtained by ordering lea ves rather than instances (Ferri et al., 2002) and therefore the constraints on possible classifications and weights will be stronger . Another topic for future work is to emplo y stochastic optimisation techniques.
 Part of this work was supported by the EU project Data Mining and Decision Support for Business Competitive-ness: Solomon Virtual Enterprise (IST -1999-11495). Sup-port from National ICT Australia and the Uni versity of Ne w South Wales, where the second author was a Visiting Research Fello w during completion of the paper , is grate-fully ackno wledged. Thanks are due to the anon ymous re-vie wers for helpful comments; to Henrik Bostr  X  om and Sa  X  so D X  zeroski for pro viding us with the Alzheimer and Diter -pene datasets, respecti vely; and to all contrib utors to the UCI repository .
 Blak e, C., &amp; Merz, C. (1998). UCI repository of machine learning databases.
 Bostr  X  om, H., &amp; Ask er, L. (1999). Combining divide-and-conquer and separate-and-conquer for efficient and ef-fecti ve rule induction. Proceedings of the 9th Interna-tional Workshop on Inductive Lo gic Programming (pp. 33 X 43). Springer -Verlag.
 D X  zeroski, S., Schulze-Kremer , S., Heidtk e, K. R., Siems,
K., Wettschereck, D., &amp; Block eel, H. (1998). Diterpene structure elucidation from 13 c NMR spectra with induc-tive logic programming. Applied Artificial Intellig ence , 12 , 363 X 383. Special Issue on First-Order Kno wledge Disco very in Databases.
 Fawcett, T. (2003). ROC graphs: Notes and practical consider ations for data mining resear cher s Tech report HPL-2003-4). HP Laboratories, Palo Alto, CA, USA.
Available:http://www .purl.or g/ne t/tf awcett/p aper s/HPL-2003-4.pdf.
 Ferri, C., Flach, P., &amp; Hern  X  andez-Orallo, J. (2002). Learn-ing decision trees using the area under the roc curv e. Proceedings of the 19th International Confer ence on Mac hine Learning (pp. 139 X 146). Mor gan Kaufmann. Flach, P., &amp; Lachiche, N. (1999). 1BC: A first-order
Bayesian classifier . Proceedings of the 9th Interna-tional Workshop on Inductive Lo gic Programming (pp. 92 X 103). Springer -Verlag.
 Hand, D., &amp; Till, R. (2001). A simple generalisation of the
Area Under the ROC Curv e for multiple class classifica-tion problems. Mac hine Learning , 45 , 171 X 186.
 Lachiche, N., &amp; Flach, P. (2002). 1BC2: A true first-order Bayesian classifier . Proceedings of the 12th Inter -national Confer ence on Inductive Lo gic Programming . Springer -Verlag.
 Mossman, D. (1999). Three-w ay ROCs. Medical Decision Making , 19 , 78 X 89.
 Muggleton, S., Srini vasan, A., King, R., &amp; Sternber g, M. (1998). Biochemical kno wledge disco very using Induc-tive Logic Programming. Proceedings of the first Con-fer ence on Disco very Science . Berlin: Springer -Verlag. Pro vost, F., &amp; Fawcett, T. (2001). Rob ust classification for imprecise environments. Mac hine Learning , 42 , 203 X  231.
 Srini vasan, A. (1999). Note on the location of optimal clas-sifier s in n-dimensional ROC space (Technical Report
PRG-TR-2-99). Oxford Uni versity Computing Labora-tory , Oxford.
 Srini vasan, A., Muggleton, S., King, R., &amp; Sternber g,
M. (1994). Mutagenesis: ILP experiments in a non-determinate biological domain. Proceedings of the 4th
International Workshop on Inductive Lo gic Program-ming (pp. 217 X 232). Gesellschaft f  X  ur Mathematik und Daten verarbeitung MBH.
 Witten, I., &amp; Frank, E. (2000). Data mining: Practical mac hine learning tools and tec hniques with java imple-
