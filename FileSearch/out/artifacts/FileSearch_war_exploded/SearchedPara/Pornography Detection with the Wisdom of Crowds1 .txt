 The Internet is increasingly prominent in young people X  X  lives. A global Internet usage survey in the year of 2008 revealed that, among young people between 12 and 14 years old in the United States, 88% used the Internet; the percentage of Internet users in this age group was 100% in the United Kingdom, 98% in Israel, 95% in Canada, and over 70% in Singapore[1].

Coupled with the very large number of pornographic Web pages, concern has been raised that increasing accessibility could l ead to a rise in pornography seeking among children and adolescents, with potentially serious ramifications for their sexual devel-opment. Ropelato X  X  statistics shows that there are 420 m illion por nographic Web pages on the Internet, and 42.7% of Internet users saw pornographic content in 2006 [2].
In many countries, sexual materials on the Internet are subject to censorship and legal restraints on their publication on the grounds of that they are obscene and that adolescents must be protected from inappropriate information[3][4]. However, the In-ternet has no boundaries, which means that pornography from a place where there are no effective restrictions imposed on Internet pornography can be easily accessed.
There have been several proposals to protect children from pornographic informa-tion on the Web. Traditional filtering techniques regard it as a classification problem which relies on features extracted from cont ents. Different types of page content are taken into account, such as texts, images and videos. Many approaches, including neural networks[5], statistical natural language pr ocessing[6] and pattern recognition[7], have been used to train a classifier to identify Web pages with pornographic content. Most of these content-based methods are usually dependent on the form of pornographic ma-terial and are limited by the efficiency of the algorithms. It is sometimes difficult to adopt these methods on practical Web environment due to the costs of a large amount of computational resources, especially for those with multimedia contents.

With explosive growth of Web resources, search engine become one of the most important portals for all kinds of Web pages including pornographic ones. The click be-haviors on pornographic pages usually reflect the  X  X earch for porn X  intent of the users. Because of this similar search intent, differe nt users often use similar queries to search for pornography on the Web. Therefore, the a ggregation of a large number of user clicks is likely to provide valuable implicit evidence of whether one page being pornogra-phy or not. We can utilize the correlations between queries and URLs to detect porno-graphic Web pages. In other words, this approach can be regarded as a type of wisdom of crowds. Inspired by this idea, we try to utilize the correlations between queries and URLs to detect pornographic Web pages. We construct a bipartite graph from click-through data with queries/URLs as nodes and user clicks as edges. After that, a propa-gation based algorithm is performed on the graph to estimate the possibility of a Web page containing pornography.

The major contribution of this work is that we propose a highly efficient method to identify pornography based on a click-through bipartite graph. In this way, there is no need to crawl Web pages and perform time-consuming content analysis on them. To the best of our knowledge, we are among the first to address the problem of pornography detection using only click-through data.

The remainder of this paper is organized as follows: Section 2 provides a brief review of the related literature. Section 3 presents our motivations for detecting pornography, discusses our algorithm in detail and gives a proof of its convergence. In Section 4, an experimental validation is conducted, and the analysis of the results demonstrates that our method can detect pornography both effectively and efficiently. Our conclusions are giveninSection5. To fight against pornographic content on the Web, there are a number of major content-filtering approaches that are adopted, including the Platform for Internet Content Selec-tion (PICS), URL blocking, keyword filtering, and intelligent content analysis.
PICS is a voluntary labeling system that allows Web publishers to associate labels or metadata with Web pages[8]. RSACi and SafeSurf are the two most popular PICS systems. Currently, Microsoft Internet Explorer and several other popular Web browsers offer PICS support with embedded PICS rating labels. However, PICS is not adopted by all major content providers and is not very reliable because of the mislabeling problem, either by negligence or by intent.

The second common approach focuses on URL blocking systems that restrict or allow access by comparing the requested Web page X  X  URL with URLs in a stored list. Usually, two types of lists are maintained, namely a black-list and a white-list[9]. Lee et al. proposed an inverse chi-square based classification method and an incremental updating mechanism[10]. It X  X  not necessary for URL blocking t echnology to consume a large amount of computational resources to perform content analysis. It also avoids the risk of virus infections. However, it is quite difficult to maintain a black-list for the practical Web environment because of the rapid growth of the Web pages.

Keyword filtering[11] blocks access to Web pages when the occurrence of harmful words or phrases exceeds a predefined threshold by comparing the text in the retrieved Web page to a dictionary of prohibited words and phrases. Gui-yang et al. proposed a keyword-matching method to filter harmful text[12]. One of the greatest challenges of keyword blocking is over-blocking. Nevertheless, it can be adopted to decide whether further content analysis is needed, which might require more time.

Intelligent content analysi s attempts to gain a semantic understanding of the context on a Web page. Existing methods usually train a model using statistical computing of the discriminative features extracted from texts or images to make a decision. Lee et al. used the frequency that keywords appear in a text and the relevant Web page feature to train a neural network classifier[5]. Polpinij et al. proposed a filtering system that combines both text and images[7].

To summarize, while adopted to practical Web environment, PICS and URL blocking meet the problem of keeping prior information both credible and up-to-date. Keyword filtering can be regarded as a kind of conten t analysis method because they both rely on content features and suffer from the problem of obtaining and dealing with contents from Web pages that are usually noisy, ill-formed and unreliable. For those methods which adopt multimedia content features, the y are further constrained by limited com-putational resources and high-efficiency re quirement. Different from these detection methods, we utilize user behavior informatio n stored in search engine click-through logs and therefore avoid the problem of (multimedia) content analysis of numerous Web pages. Because search engines have oriented a large part of user visits for most Web sites including pornography ones, we believe that this method can deal with most pornography problems on the Web although it doesn X  X  require crawling these pages. 3.1 Motivation Traditional pornography detection systems us ually focus on various content analysis techniques. The major limitation of the approaches mentioned above might be the com-putational cost. The behavior of search engine users offers some information that is helpful for pornography detection. Pornogr aphic Web pages usually select some at-tractive keywords that reflect the  X  X earch for porn X  intent to boost the ranking of their pages/sites in corresponding search results lists. In the other way, the users who want to access pornography by search engine most likel y issue similar queries. Therefore, our basic assumption is that users share similar queries to search for pornography, which are most likely to be popular on Web pages that contain pornographic materials. The collection of queries that are related to a certain URL can be considered to be a profile of a Web page. If a large percentage of queries contain implicit pornographic intent, then the reason is most likely that there was pornographic content on the Web page.
By noticing the relationship between pornographic Web pages and porn-intent queries, we designed a label propagation algorithm on click-through data. First, a small number of seed pages are selected and each labeled with a pornographic score. Then, their labels are propagated on the click-thr ough bipartite graph to identify other possible instances of pornography. The input comprises a set of labeled URLs, a set of unlabeled URLs and a set of constraints between URLs and the queries in the log. The goal is to find unlabeled pornographic pages from labeled pages. 3.2 Problem Formulation Before formulating our problem, some definitions should be given.
 I. Click-through data C and bipartite graph G .

The click log is a set of triples q,u,f qu ,where q is a query, u is a URL, and f qu is the times URL u is clicked when query q is issued. Define Q = { q | q appears in C } ,and U = { u | u appears in C } . Click-through data C can be presented as another equiva-lent form  X  a click-through bipartite graph G =( Q, U, E ) . There are two types of nodes in the graph, queries and URLs. For a certain edge ( q,u ) , each q / u is assigned a score p / p u , which denotes how likely this query/URL is to be a pornographic query/page. A sample portion of a bipartite graph constructed with search engine log, as shown in Figure 1.

The click-through graph can be constructed either at the page level or at the site level. In this study, we choose the URL itself to construct graph because the structure and content of a Web site might be very comprehensive.
 II. Labeled Seed URL set L .
 All of the URLs in L are selected from C (or G ) and are manually labeled as porn. Formally, L = { u | u is labeled as a pornographic page } . We will discuss the construction details of L in Section 4.1.
 III. URL result set RU and query result set QU .

Respectively, RU and QU contain all of the u, p u and q,p q pairs. After the al-gorithms ends, each URL u or query q in C (or G ) will receive a score p u / p q ,which denotes the possibility that this URL or query is a porn one.
 Given G =( Q , U , E )and L  X  U , the goal of this problem is to obtain the results set RU , which is by definition the set contains al l of the possible pornographic pages in G . 3.3 Algorithm Design First we will propose a label propagation algor ithm for the the detection of pornography. Specifically, for every URL u , we could calculate the probability p u of a certain URL u by incorporating all of the l abel information o f its adjacent query nodes. Similarly we could calculate p q for every query q . This procedure can be described formally as follows.

For  X  q/u, l q /l u denotes its label, which is P for pornography and N for non-pornography. Thus, every URL u in L would receive a label, such as P or N ,which means that P( l u = P )=1 or P( l u = P )=0 initially while every URL u in the set U  X  L has P( l u = P )=0. Then, we have where and t qu can be interpreted as the transition probability from query q to URL u and  X  qu is the weight of edge ( q,u ) in the bipartite graph. From equations (1) and (2) that q  X  X  label is determined by both its neighbors X  labels and the relationship of the connection. The larger the value of  X  qu is, the more influence its corresponding node has on the label determining the label of q .
 Similarly, for each query q in Q, the probability P( l q = P ) is computed as where t uq can be interpreted as the transition probability from URL u to query q .
Using the equations above, we can obtain P( l q = P )andP( l u = P ) recursively for all of the queries and URLs in the click-through bi partite graph. A concise representation of this iterative process is stated as follows.
Suppose that there are | Q | queries and | U | URLs. Define possibility vectors as fol-lows: and the transition probability matrixes as: Then, in the i th iteration,
It should be noted that the possibility of the labeled nodes should be clamped before each round of iteration, which means that all of the URLs in the seed set L should be re-assigned their initial label. In this way, the algorithm converges. The convergence will be proved in Section 3.5. 3.4 Bidirectional Edge Weight Definition In the naive definition of the edge X  X  weight shown in Equation(3), the weight is related only to the amount of clicks in click-through log. However, we find that in experiment the naive definition has to face the positive feedback problem and the reliability prob-lem. More specifically, the problems that naive definition faces are stated as follows: The Positive Feedback Problem. Label propagation algorithms or random walks on click-through bipartite graphs usually face positive feedback problems. For example, u 3 in Figure 1 is connected only to q 1 . If we use the naive weight definition for iteration, P( l u 1 = P ) to be 1 because u 1 is a seed URL. It is easy to see that P( l u 3 = P )is0.75after the second iteration and converges to 1 as th e iteration process proceeds. The reason is that u 3 is a 1-degree node, which means that the score of u 3 will flow back to q 1 ; from this process, it obtains its original pornography score. We call this effect the positive feedback problem, which would magnify the noise and distort the final results.
Suppose that a non-typical user issues a query q to the search engine and then clicks a pornographic page while most of the other users use this query to navigate to ordinary sites. After applying this label propagation algorithm, all of the pornography scores of the URLs will converge to 1 after our algorithm is applied on the graph. Although the 1-degree nodes will be removed from results, it will most likely misinterpret the real explanation of other pages.
 The Reliability Problem. Another important challenge that we must face is the reli-ability problem. In a naive label propagatio n algorithm, the score of one specific node comes from its adjacent nodes, and the wei ght of each score is related only to the weight of the edge, which is click times in the query log. However, the correlation between a query node and an URL node should be determined by the click distribution of both of these nodes jointly. The naive definition fa ils to take this factor into account. Consider another sample portion of a bipartite graph, as shown in Figure 2.

Based on the naive weight definition, for query node q 2 , the score of u 1 and u 4 are equally weighted. Let us focus on u 1 and u 4 ; u 1  X  X  clicks are almost all from q 2 while u 4 has the same clicks from q 2 , but most of its clicks are from q 4 . Obviously, the score from u 1 is more convincing for q 2 than for u 4 .

Based on these two observations, we take the click distribution of both the query and the URL into account and propose a novel b idirectional edge weight definition. For edge ( q,u )  X  E , the weight is defined as:
Essentially, our bidirectional edge weight definition will help the iterative process to magnify the influence from nodes with a close relationship and to minimize the effect of noisy nodes(e.g., a query seldom issued or URLs with few clicks). To summarize, the outline of our algorithm is as follows: Algorithm 1. Pornography detection algorithm 3.5 Convergence of the Algorithm Let us look into M qu and M uq , each of whose rows is composed of nonnegative real numbers, with each row summing to 1. They are right stochastic matrixes. Consider M For each element t ij in T uu ,  X  ij = j  X  ik  X  kj ,where  X  ik  X  T uq and  X  kj  X  T qu . Thus, we have T uu is also a right stochastic matrix. Next, look into P U ; the iteration process can be represented as, Let T l be the top l rows of T (the labeled pages), and let T u be the remaining u rows. Note that T l never really changes because it is re-assigned in every iteration.Define the probability vector P U = P L P R ,where P L are the top l rows of P U (the labeled pages) while P R are the remaining rows. We can split T uu into 4 sub-matrixes
It is noted that P L never really changes. Zhu et al. proved that P L converges to ( I  X  T is inconsequential. Using the same approach, we could prove that P Q also converges. 4.1 Experiment Setups The goal of our experiments is to evaluate whether our algorithm is effective in detecting pornographic Web pages. Given a labeled seed set L , our algorithm will return a list of pages that are ranked according to the possi bility of being pornography. Seed pages are not included in this list, and the pages connected with only one query are also removed from this list because we thin k it is arbitrary to make a decision from only one query.
We use two datasets to build the bipartite graphs separately. From both datasets, we extract the information of the query, URL and timestamp. Private information is reduced as much as possible without introducing any ID or IP information.

The first query log dataset was collected from May 1, 2012 to May 14, 2012, with the help of a popular commercial search engine company in China. We pruned all of the query-URLs that appear only once in dataset because they could be noisy and poten-tially private. After that, the query log comprised 2,625,029 unique queries, 4,699,150 unique URLs and 72,106,874 query-URL pairs, which involve 717,916,107 individual clicks.

The second dataset is the America Online(AOL) query logs released in 2006 for re-search 1 [14].This dataset contains 16,946,938 unique(normalized) queries, which were collected from March 1, 2006 to March 31, 2006. 4.2 Seed Set Selection and Labeling Criteria The seed set contains labeled pages for our detection algorithm. On the Chinese dataset, we obtained a pornographic page list that contains 700 popular Web pages with the help of the same search engine that provides click-through data. This list was annotated by professional assessors, and each of the pages was double checked by us. A total of 691 pages appear in our click-through data, and we use them as the seed set for our algorithm.

For the English dataset, we picked out the URLs which contains  X  X ex X  or  X  X orn X  in the domain name to generate a candidate set. From the candidates, we randomly select a group of Web pages and have three human annotators with professional skills to label them as pornography or not. The labeling process stops when there are 500 pornographic pages in the seed set. The labeling criteria is stated as follows:  X  NONPORN -The page contains no porn materials.  X  BORDERLINE -The page contains some sexual material but no pornography.  X  PORN -The page contains pornographic material.  X  CAN NOT CLASSIFY -The page can not be accessed or the accessor could not
We also use these criteria to evaluate the results of our algorithm. It should be noted that we adopt a a relatively strict judgment rule on the pornographic pages in the seed selection step. All of the  X  X ORDERLINE X  pages are as  X  X ONPORN X , because the cost of mislabeling a normal page as pornography seed is much higher than the oppo-site situation. All of the  X  X AN NOT CLASSIFY X  pages are removed in both the seed selection step and the result evaluation step.

When we labeled the seed set and results, some of the pages could not be accessed for different reasons. We attempted to label them according to the snapshots obtained from commercial search engines. If snapshots could not be obtained, we labeled them as  X  X AN NOT CLASSIFY X . 4.3 Performance Comparison We conducted our algorithm on both the Chinese dataset and the English dataset and compared their performances by the area under the receiver operating characteristic curve (AUC) and precision score.
 We observed that the possib ility of por nography change d little after 20 iterations. Specifically, we ran the iteration process 20 times in our experiment and then output the results. On a PC with a Intel CPU of 3.3 GHz and 32 GB RAM, the algorithm finished 20 iterations in 45 minutes on Chinese datas et and in 20 minutes on English dataset.
After the algorithm ends, we rank the UR Ls by the possib ilities of por nography in descending order. Similar with the annotation approaches adopted by Gy  X  ongyi et al in[15] , we separate the URLs into ten b uckets sequentially and make sure that each bucket has an equal sum of possibilities that belong to the URLs in it. From each bucket, we randomly label 50 URLs with the criteria in Section 4.2, and we rank all of the URLs by their probabilities in descending order to generate the results list. We evaluate this list with both AUC and the precision, which are calculated based on the list. Content analysis based methods were not used for com parison in this step because their methods mainly focus on the classification of speci fic Web page sets while our method addresses the pornography detection within a large set of Web pages.

The experiment results are shown in Figure 3.
From this figure, we can see that the AUC values are greater than 0.83 and the pre-cision values are greater than 0.91, which suggests that our algorithm is effective in detecting pornography. The performance on th e Chinese dataset is slightly better than on the English dataset, probably because the s ize of the English dataset is smaller and the Chinese dataset is more up-to-date.

We also want to see our algorithm X  X  performance on detecting various forms of pornography. We randomly selected 280 URLs from the Chinese results that represent pornography on the Web page and manually cl assified their main pornographic forms into 4 categories: Text, Image, Video and Others(e.g., pornographic audio, pornographic chatting service). Of all the Web pages, 42% represent pornography information with text, most likely because this venue is the c heapest way to attract traffic from a search engine. Other research regarding anti-spam[16] shows that pornographic terms are one of the most important categories that lead to spam pages on Chinese Web pages. In our experiment, we also find that many of the porn pages are spammy with the purpose of cheating. 4.4 Discussion: Pornography Score as Feature In practical Web application, it is difficult to identify pornography Web pages only with the pornography scores given by our algorithm. However, we can use this method to generated candidates for further context a nalysis. This will help to reduce the number of pages to be analyzed. Also, we can use the pornography score as a feature to classify whether the Web pages contains inappropriate material. We implement a text-analysis method on the Chinese dataset and compar e the performance by adding the pornography score(PS) as a feature. In our implementation, each Web page is represented as a vector of TF-IDF values. Classification results on 812 Web pages(4-fold cross-validation) is shown in Table 1.

Experiment result shows that we can get be tter classification performance by adding the feature of pornography scores. However, the improvement is limited because clas-sifiers have already reach a quite good performance with only text features. 4.5 Discussion: Algorithm Robustness Seed selection is very important in semi-supervised algorithms. Therefore, an experi-ment was conducted to see how robust our algorithm is. We only conducted this exper-iment on the Chinese dataset because it is ne wer and much larger than the English one. We randomly split the pornographic page s eed set into 14 subsets(each one contains approximately 50 seed sites) and then gradually added the subsets into the seed set to observe the influences on the performance. The results are summarized in Figure 4.
It can be observed that our algorithm is very robust because it can achieve a relatively stable AUC value after only 400 pornographic pages are added. This experiment shows that our algorithm gained a stable performance in detecting pornography from a small number of seed set. The very large number of pornographic Web pages has raised concerns about protect-ing children and adolescents. Traditional pornography detection methods focus on the extraction of textual or multimedia features from Web content, which consumes a large amount of computational resources. This paper attempts to solve the problem from a new perspective by proposing a novel method that is based on label propagation on a large scale bipartite click-through graph. Fi rst, a bidirectional edge weight definition is introduced to measure the correlation betw een the query and the URL reasonably. Then, we propagate the pornographic possibilities for all of the URLs iteratively on the click-through graph from a small set of seed URLs. The experiment that was conducted on both the Chinese and English datasets indicates that our method can detect pornography in different forms both effectively and efficiently. We hope that this method will be use-ful for protecting children and adolescents from pornography. For future work, we plan to combine our pornography detection met hod with traditional content-based methods to improve performance. More specifically, our algorithm could return a candidate set for further content analysis efficiently.

