 Multi-tenant data management is a major application of Software as a Service (SaaS). Many companies outsource their data to a third party which hosts a multi-tenant database system to provide data management service. The system should have high performance, low space and excellent scala-bility. One big challenge is to devise a high-quality database schema. Independent Tables Shared Instances and Shared Tables Shared Instances are two state-of-the-art methods. However, the former has poor scalability, while the latter achieves good scalability at the expense of poor performance and high space overhead. In this paper, we trade-off between the two methods and propose an adaptive database schema design approach to achieve good scalability and high perfor-mance with low space. To this end, we identify the important attributes and use them to generate a base table . For other attributes, we construct supplementary tables . We propose a cost-based model to adaptively generate the tables above. Our method has the following advantages. First, our method achieves high scalability. Second, our method can trade-off performance and space requirement. Third, our method can be easily applied to existing databases (e.g., MySQL) with minor revisions. Fourth, our method can adapt to any schemas and query workloads. Experimental results show our method achieves high performance and good scalability with low space and outperforms state-of-the-art method. H.2.1 [ Information Systems ]: Database Management X  Logical Design Design,Performance Multi-Tenant Database, Adaptive Schema
Software as a service (SaaS) has attracted significant at-tention recently and become a common software delivery model for many business applications  X  . And multi-tenant data management is a major application of SaaS. Today many companies want to outsource their data to a third party which hosts a multi-tenant database system to provide data management service. Each company is called a ten-ant. The multi-tenant data management system amortizes the cost of hardware, software and professional services to a large number of tenants and thus significantly reduces per-tenant cost by increasing the scale. Thus the multi-tenant database system requires to have excellent performance, low space requirement and good scalability. One big challenge is to devise a high-quality database schema.

To our best knowledge, Independent Tables Shared In-stances (ITSI) and Shared Tables Shared Instances (STSI) are two state-of-the-art approaches to design schema. How-ever, the former has poor scalability since it needs to main-tain large numbers of tables. The latter achieves good scal-ability at the expense of poor performance and high space.
In this paper, we propose an adaptive database schema design method for multi-tenant applications. We trade-off between ITSI and STSI to achieve good scalability and high performance with low space. To this end, we identify im-portant attributes and use them to generate a base table . For each of other attributes, we construct supplementary ta-bles . We develop a cost-based model to adaptively generate the base table and supplementary tables . To summarize, we make the following contributions. (1)We propose an adaptive database schema design method for multi-tenant applications which has following advantages. First, our method achieves high scalability. Second, our method can trade-off between performance and space. Third, our method can be easily applied to databases (e.g., MySQL) with minor revisions. Fourth, our method can adapt to any schemas and workloads. (2)We analyze the importance of attributes and discuss how to identify the important at-tributes.(3)We propose a cost-based model to automatically generate high-quality schema.(4)Experimental results reveal our method achieves high performance, good scalability with low space and outperforms state-of-the-art method.
The rest of this paper is organized as follows. In Section 2 we firstly formulate the problem of multi-tenant database schema design and then introduce the basic idea of our method. We try to find important attributes through the evaluation of different operations in Section 3. We introduce a cost-based schema design method in Section 4. Experi-mental results are provided in Section 5. We review related work in Section 6. In Section 7 we conclude the paper. h ttp://en.wikipedia.org/wiki/Software as a service
In multi-tenant data management applications,each ten-ant outsources a database with a set of tables {T 1 , T 2 Each table is called a source table . The service provider de-velops multi-tenant databases to manage the data from large numbers of tenants. To achieve good scalability and high performance, the provider needs to redesign schemas. The redesigned tables in the multi-tenant databases are called physical tables . Each tenant poses queries based on its own source tables to the multi-tenant database, then the queries are translated from source tables to physical tables and answers will be returned according to physical tables. Therefore, one big challenge of multi-tenant databases is to devise high-quality schemas (designing high-quality physical tables). Here we use table CUSTOMER in TPC-H[1] as source table example in Table 1 and there are three tenants. In STSI, the physical table layout is described as Table 2. The STSI approach achieves high scalability at the expense of involving large numbers of NULLs by consolidating differ-ent tenants into one table. It will waste much space and degrade the performance. Compared with STSI, the ITSI method does not waste space and has excellent performance which has the same layout as depicted in Table 1. However, the scalability of ITSI is poor since the number of tables in-creases in proportion to the number of tenants. In this pa-per, we trade-off between the two methods to achieve good scalability, high performance and low space requirement. Basic Idea: We first extract the important attributes from the tenants and build a base table using such attributes. The base table here is similar to the big table in STSI, however, in the base table there will not be many NULLs since the important attributes in the base table are usually shared by most of tenants. Then for other attributes, we build supplementary tables for each of them, like column-based tables. In other words, we build tables from the attribute level instead of the tenant level. To this end, we propose an adaptive method (called Adapt ) to build the base table and supplementary tables based on database schemas of differ-ent tenants and query workloads. Next we discuss how to design the base table and supplementary tables. For ease of presentation, we first introduce several concepts.
Definition 1 (Common Attributes). An attribute from the source tables is called a common attribute if it is a highly shared attribute, i.e., the ratio of the number of ten-ants containing the attribute to the total number of tenants is not smaller than a given threshold  X  .

As common attributes are highly shared by multiple ten-ants, we will add them into base table, e.g., in Table 2, supposing  X  = 0 . 8, as C_NAME and C_ADDRESS are shared by all the tenants 1, 4, 9, thus they are the common attributes.
Definition 2 (Star Attributes). An attribute from the source tables is called a star attribute if it is a primary key and it may be referenced by some other source tables.
As the star attributes will be used by multiple tables, they will lead to low performance since they may involve many costly joining operations. Thus we will add them into the base table. In table CUSTOMER the attribute C_CUSTKEY is the primary key and may be referenced by other source tables. T hus C_CUSTKEY is a star attribute.

Besides the common and star attributes, the left are the uncommon attributes and some of them are also important which need to be added into base table. For example, con-sider the following SQL query from a tenant.

If C_SALARY and the common attribute C_NAME are from different physical tables, there will be a joining operation. Because C_SALARY occurs only in the SELECT clause and the tuples containing C_SALARY account for 80 percent of the total, thus the joining cost is large. On the contrary, if C_SALARY is inserted into the base table, the costly joining operation will be avoided. Moreover it will not involve huge space as only one NULL is produced. Thus attribute C_SALARY is very expensive in terms of query processing but very light in terms of space, and we call it the dependent attribute (We will formally define it later).

For example, in the given workload Table 3 lists the num-ber of occurrence times of those expensive attributes in the costly operation and the number of NULLs if they are inserted into the base table. Section 3 and Section 4 will further in-troduce which attributes are expensive and light and how to choose the dependent attributes.

Thus we use common attributes, star attributes and de-pendant attributes to construct base table. For the left at-tributes, we build supplementary tables for each of them. Notice that similar to STSI, for both base table and supple-mentary tables we need to add a column -Tenant ID (TID) to distinguish which tenants own the tuple. In addition, we add the column of the primary key of the source table to join base table and supplementary tables when necessary. Table 4 describes the table layouts in our running example.
As we discussed, if we put the dependent attributes into the base table, it will avoid expensive query processing cost and have light space cost. To evaluate the expensiveness of an operation, we need to analyze the cost of each kind of operation in our Adapt method. The traditional database system usually consists of 4 basic operations, selection , in-sertion , deletion and update . Since the update operation can be accomplished by a deletion operation followed by an in-sertion operation, we focus on the first three operations in this paper.
We divide selection into 3 types based on selected at-tributes. (1)Query without Uncommon Attributes: W hen the tenant just wants to know some general information it will submit a query: where C_NAME and C_ADDRESS are both the common attributes coming from the base table. This query does not involve the uncommon attributes. And the number of tuples in the base table is less than or equalled to the number in STSI method. Further, the number of columns in the base table is much smaller. Thus we can use fewer I/Os to locate and return the tuples which satisfy the query. Obviously, this kind of query in our method is much faster than STSI. (2) Query with Uncommon Attributes in the WHERE Clause: When the tenant wants to know the result which satisfies its specific condition it may submit a query: where C_NATION is an uncommon attribute. In this type of queries, the WHERE clause contains selection operations on uncommon attributes. In this case, Adapt may in-volve more joining operations than STSI. However, Adapt still outperforms STSI method. First, in this kind of work-load the queries have already specified these uncommon at-tributes with selection in the WHERE clause and the interme-diate results can be small. Second, we usually build efficient indexes on the frequently queried attributes. (3) Query with Uncommon Attributes only in the SELECT Clause: A tenant just wants to query some in-formation related to its detailed application but does not specify the condition and it will submit a query: where C_SALARY is an uncommon attribute. Different from the former two cases, this kind of query is costly. There are no selection on the uncommon attributes in the WHERE clause and we need to scan all the tuples of this uncommon attribute table. Therefore when many of the uncommon at-tributes occur in the workload only in the SELECT clause, the performance will be degraded. Therefore, these uncommon attributes which are often queried and only occur in the SE-LECT clause can produce large costs. These operations are very expensive and those uncommon attributes occur only in the SELECT clause in this operation meet the requirements expensive of the dependent attributes.
In our method, when a tenant inserts a tuple to a source table, this insertion can be divided into several insertions to corresponding physical tables: an insertion to the base ta-ble and several insertions to the supplementary tables. The insertion in our method can be fast. Firstly, Adapt can directly insert the tuples into the base table and other sup-plementary tables. Unlike STSI, Adapt does not need to insert many unnecessary NULLs and this will save some time. Furthermore, the size of the indexes in supplementary tables is much smaller than those in STSI. Thus the maintenance cost on indexes in our Adapt method is much smaller.
In our method, when a tenant submits a delete operation, it will also be divided into several deletions. Our method is slower than STSI. Because we cannot directly delete the tu-ples, we have to locate the tuples which satisfies the  X  X elete X  requirements first. Thus we have to do more selection be-fore the deletion. But deletion is rare in real applications and hardly affects the workload performance .

To sum up, the selection operation that query the un-common attributes but does not specify the condition in the WHERE clause are expensive and these uncommon attributes meet the demand expensive of the dependent attributes .
To improve performance, we want to add expensive at-tributes into the base table. However if large numbers of expensive attributes are inserted into the base table, it will produce lots of NULLs and also degrade the performance of other operations. Thus we want to identify the light expen-sive attributes which involve a smaller number of NULLs .
We study that if the service provider has a space budget B , we want to use the budget to achieve the best performance. Usually, we can use the number of NULLs to denote the B .To achieve our goal, we will choose expensive and light dependent attributes and add them into the base table. For example, recall expensive attributes maintained in Table 3. If the number of NULLs B permitted by the service provider is set 2, C_SALARY is a dependent attribute.

The dependent attributes are expensive and light . We in-troduce the concept weight , then light is easy to understand.
Definition 3 (Weight of Attribute). The weight w of an attribute is the number of NULLs if it is inserted into the base table.
Suppose there are n t enants who share the same attribute in their source tables and each source table has T i tuples, the total number of tuples for the attribute from different supplementary tables is T s = P n i =1 T i . And the number of total tuples in the base table is T b , when the common attributes and the star attributes in the base table are shared by all the tenants then w = T b  X  T s .

Definition 4 (Cost of Expensive Attribute). The cost of expensive attribute is the occurrence times of the ex-pensive attribute in the costly operation.

Consider the source table, a budget B and a query work-load. Suppose there are m expensive attributes e 1 , . . . , e in the workload. Let v i denote e i  X  X  cost and w i denote e weight. We want to maximize P m i =1 v i  X  x i which subjects to P
Suppose X = x 1 , . . . , x m is the optimal solution of the above problem. If x i = 1, attribute e i is a dependent at-tribute. Now we formally define this concept.

Definition 5 (Dependent Attributes). An attribute e is a dependent attribute if x i = 1 in the optimal solution X = x 1 , . . . , x m .
 The problem to find dependent attributes can be proved NP-hard by an induction from the 0-1 Knapsack problem. Due to space constraints we omit the details.
In this section, we evaluate our proposed technique and compare it with the state-of-the-art method.
TPC-H and TPC-C are two well-known benchmarks. How-ever, they are not suited to evaluating multi-tenant database because different tenants may have their own schema. In our experiments we design MTPC-H benchmark for multi-tenant database which is fully based on the traditional TPC-H benchmark with minor revisions. Here we select five core tables: PARTSUPP , LINEITEM , PART , ORDERS and CUSTOMER . For each table, we extend the total number of attributes to 100. In each of the table, the TID and the key are in-cluded. In addition, we also choose several other common attributes for each source table. The data type of the com-mon attributes is the same as that in the corresponding table in the TPC-H. Except for the common and star attributes the rest are the uncommon attributes configured by tenants. The data type for the uncommon attributes is varchar. We build compound indexes on all the common attributes and those uncommon attributes involved in the query workload. The MTPC-H Benchmark consists of 2 components.
 Schema Generator: We use schema generator to produce schema for each tenant. This generator contains such pa-rameters: the number of tenants Tnum , the average number of total attributes for each private table is  X  , the derivation  X  . To generate private schema for each tenant, the gener-ator randomly selects Unum uncommon attributes for each source table and collects them plus the Cnum common and star attributes defined for each source table to form the final private database schema. The total number of attributes for each private table satisfies the normal distribution N (  X  ,  X  ). Tenanter: Tenanter is conceptually equivalent to the Driver in TPC-H. We run Tenanter and the multi-tenant database system in a  X  X lient/server X  model. We place the Tenan-ter and the database system in different machines intercon-nected by a network. The Tenanter is written in C++. Each Tenanter runs its queries in its own thread.
In both TPC-H and TPC-C benchmark, the maximal number of attributes in tables is 21. Thus, in MTPC-H benchmark we set 21 as the upper bound of  X  . For each tenant, we generate 3 sets of schemas by setting  X  to 10, 15, 21 respectively and fixing  X  =2. We generate 3 groups of schemas for 200, 500 and 1,000 tenants. For each ten-ant, we generate 2000 tuples for table CUSTOMER , 2000 tuples for PARTSUPP , 1500 tuples for PART , 3000 tuples for LINEITEM and 2000 tuples for ORDERS . The Tenanters and database are run on two Windows XP machines with the same configura-tion. Each machine is equipped with a 3.2GHz Pentium (R) dual-core E5800 cpu and a 4GB of memory. We conduct ex-periments using MySQL. To compare different methods in a fair way, for each workload we repeat 5 times and obtain the average. We restart both database server machine and client machine to flush the buffers between experiments. We compare the cost of different operations in this part. Here the source tables are shared by 500 tenants. There are mainly 5 operations. They are queries without uncom-mon attributes, queries with uncommon attributes in the WHERE clause, queries with uncommon attributes only in the SELECT clause, insertion and deletion. For simplicity, we call the selection operations sel1 , sel2 and sel3 respectively. We compare the operation costs among STSI, our ADPAT method without putting dependent attributes into base ta-ble(Adapt) and ADAPT method using different B , where B is set 5 percent(Adapt+5%), 10 percent(Adapt+10%) and 20 percent(Adapt+20%) of the total number of NULLs in-volved in STSI. Each of the operation cost obtained is the average of 1,000 operations. Figure 1 shows the results.
Compared with STSI, sel1 and sel2 have much better per-formance. For sel3 , when  X  = 10, Adapt without putting the dependent attributes into the base table is a little slower than STSI. When  X  = 21 the gap becomes larger. If we use some B to put the dependent attributes into the base ta-ble, sel3 improves obviously especially for the higher  X  . For the insertion, STSI is the slowest because it needs to insert many NULLs and maintaining the big index is costly. While the delete operation of STSI is the best as other methods have more deletions and locating the tuples to be deleted will cost some time.

To sum up, except for the deletion, the sel1 , sel2 and insertion in our method with different B are all more efficient than STSI, even if when  X  is larger sel3 can still achieve obvious priority over STSI with a small B .
Since sel3 is very costly and in the real workload the in-sertion and deletion do not often occur, we set sel3 as the dominate operation and analyze the performance. In such workload if we can have better performance, our adaptive schema can have excellent performance in other workloads because sel1 and sel2 in our method is much faster than STSI. In this set of experiments, the test workload contains 10,000 operations, 20 percent are sel1 , 20 percent are sel2 , 50 percent are sel3 , 8 percent are insertion and 2 percent are deletion. Figure 2 illustrates the performance of the source table shared by different tenants and we also vary the num-ber  X  to evaluate the performance.

In our workload, when  X  is 21 and the source tables are shared by 1,000 tenants, for sel3 operation our Adapt method is slower than STSI and degrades the performance obviously. However, when the B is 5 percent, after we put some depen-dent attributes into base table, the improvement for sel3 is obvious and helps to improve the overall performance. When the number of tenants is 200 and  X  = 5, sel3 is not costly and a small B can improve performance obviously.
Predictably, our adaptive schema design can achieve good performance across all kinds of workloads.
There exists plenty of prior work to design schema for multi-tenant database in [8, 5, 2, 3, 7, 6]. In [5], it needs to maintain large numbers of indexes from the tenant level and this will increase the chances to contend the memory. Many index pages will be loaded into memory using plenty of ran-dom I/Os. And the basic schema needs to be fixed. If one tenant adds a new attribute the cost is large because it will affect the data storage, while our Adapt method has good extensibility. Aulbach et al. [2] focuses on providing exten-sibility for multi-tenant databases. They introduce chunk tables to store data in extension attributes. However, its table is too big and plenty of costly self-joining operations will happen and is proved to be slower than conventional ta-bles. Similarly, Aulbach et al. [2] also mentioned the exten-sion table layout which is well suited to the customization of the multi-tenant application. While the number of ta-bles grows linearly with the number of tenants. Aulbach et al. [3] uses object-oriented thoughts to design schema which can be extended and evolved but its main purpose is to serve for the main-memory database. Lang et al. [7] fo-cuses on how to deploy resources for different tenants with various performance requirements. Besides schema design, the multi-tenant application also involves other important issues. Zhang et al. [9] introduces data privacy problem and data migration is discussed in [4].
In this paper, we study the problem of adaptive multi-tenant database scheme design. We first identified the im-portant attributes including common attributes, star at-tributes and dependent attributes. We built a base table with important attributes. For each of other attributes, we built supplementary tables. We proposed a cost-based model to adaptively generate schema. Experimental results show our method achieves high performance, good scalabil-ity with low space and outperforms state-of-the-art methods.
This work was partly supported by the National Natu-ral Science Foundation of China under Grant No. 61003004, the National Grand Fundamental Research 973 Program of China under Grant No. 2011CB302206, a project of Ts-inghua University under Grant No. 20111081073, and an IBM SUR project.
