 Mohsen Pourvali 1( The abundance of available electronic information is rapidly increasing with the advancements in digital processing. Furthermore, huge amounts of textual data have given rise to the need for efficient techniques that can organize the data in manageable forms. One of the common approaches for this aim is the use of clustering algorithms, in which sets of similar documents are grouped in clusters. In text clustering, a text or document is always represented as a bag of words. This representation raises one severe problem: the high dimensionality of the feature space and the inherent data sparsity. Obviously, a single document has a sparse vector over the set of all terms [ 8 ]. The performance of clustering algorithms will decline dramatically due to the problems of high dimensionality and data sparseness [ 1 ]. Therefore it is highly desirable to reduce the feature space dimensionality. There have some works that deal with this problem by utilizing two popular approaches: feature selection [ 3 ] and feature extraction [ 13 ]. Graph-based ranking is one of the popular unsupervised approaches for extracting features (keyphrases) from texts. Specifically, TextRank [ 10 ]isoneof the most well-known graph-based approaches for keyphrase extraction. In this paper we investigate how we can improve the effectiveness of text clus-tering by summarizing some documents in a collection, specifically the ones that are much significantly longer than the mean. Our method could be considered as one for unsupervised feature selection, because it chooses a subset from the original feature set, and consequently reduces vector space for each document. In particular, as mentioned above, it is particular effective when applied to longer documents, since these documents reduce purity of clustering. To this end, we propose a novel method in which n-tsets (i.e., non-contiguous sets of n terms that co-occur in a sentence) are extracted through a graph-based approach. Indeed, the proposed summarization method is a keyphrase extraction-based summa-rization method in which the goal is to select individual words or phrases to tag a document. We have utilized HITS algorithm [ 5 ], which is designed for web page ranking, in order to boost the chance of a node to be selected as a keyphrase of the document, although other graph-based algorithms have been proposed to summarize texts, For example, we can mention [ 9 ] in which sentences, instead of key-phrases, are extracted through undirected graphs.
 algorithm is presented in Sect. 2 . Section 3 discusses our graph-based ranking algorithm to extract n-tsets from documents. In Sect. 4 we present the exper-imental setup, and Sect. 5 discusses the experimental results obtained for two human-labelled datasets, namely BBC NEWS and Classic4, used for clustring purposes. In addition, we also use the DUC2002 dataset for evaluating the qual-ity of text summarizations provided. Finally, Sect. 6 draws some conclusions. In this section we discuss the baseline used for testing. We start from this method because it is a simple form of graph-based ranking approach. In addition, we exploit it to boost the score of keyphrases to include in a text summary. [ 5 ] to rank terms. HITS is an iterative algorithm that was designed for ranking Web pages. HITS makes a distinction between  X  X uthorities X  (pages with a large number of incoming links) and  X  X ubs X  (pages with a large number of outgoing links). Hence, for each vertex V i , HITS produces an  X  X uthority X  and a  X  X ub X  score: extracted from text documents in order to identify the most significant blocks (words, phrases, sentences, etc.) for building a summary [ 7 , 10 ]. Specifically, we applied HITS to directed graphs whose vertexes are terms, and edges repre-sent co-occurrences of terms in a sentence. Before generating the graph, stop-word removal and stemming are applied. Once computed the HITS HITS H ( V i ) scores for each vertex V i of the graph, we can rank the graph nodes by five simple functions of the two scores: where  X  corresponds to different ways of combining the two HITS scores. Namely avg / max / min / sum / prod (average/maximum/minimum/sum/product of the Hub and Authority scores). After the scoring of the nodes by F can rank them, and finally return the K-top ranked ones. To create a keyphrase-based summary of a document, we devised a unsupervised technique, called N-tset Graph-based Ranking ( NG -Rank ) for which n-tset is a set of one or more terms co-occurring in a sentence.
 In a document, the discussed subjects are presented in a specific order. For each document paragraph, the first sentence represents a general view of the discussed subject, which is examined in depth in the rest of the sentences. The rest sentences might be ended by a conclusion sentence, which is the final close of the discussed subject. In general, the first and last sentences likely include the main concepts of the document. Therefore, let D be a document of the collection, P are thus partitioned as follows:  X  First Sentences (FS): which are the first f consecutive sentences occurring of
P .  X  Middle Sentences (MS): which are the middle sentences of P  X  Last Sentences (LS): which are the last l consecutive sentences of P Once denoted the sentences of each paragraph, our algorithm preprocesses these sentences by removing stop words and applying the Porter stemmer. Sup-pose that after these processing step, the number of stemmed terms in a doc-ument is m . The next step of our algorithm builds an m  X  of matrix A 0 is given by t ij t term j co-occur within the various sentences of the documents, and t number of times term i occurs in the document. We can have: In case a ij = a ji =1and t ij &gt; 1, then the terms i and j always co-occur for the same number of times within the various sentences of the documents. Then we merge them as a new n-tset term, and rebuild the matrix, by merging the i and j th rows (columns). This process is iterated, namely A h +1 i, j such that a ij = a ji =1and t ij &gt; 1. The number of iteration is I = N where N is the biggest n-tset found in the document.
 tences, partitioned into the sets FS , LS ,and MS (First, Last, and Middle Sentences) 1 , where the stemmed terms are represented as capital letters: In the first iteration, terms C and D are merged as a new term C -D . In addition, also terms M and S are merged as a new term M -S . In the second iteration, terms C -D and G are merged as a new term C -D -G . Note that at the end of this iterative process, each row/column will correspond to n-tsets, n loss of generality, hereinafter we call  X  X -tset X  both single and multiple terms (identified by our algorithm). The final sentences after the merging is thus: sponding to a row a i of the final matrix A last , is defined as follows: If an n-tset appears in long sentences or appears multiple times in short sen-tences, its row a i in the matrix is not so sparse, in comparison with n-tsets occurring in a few short sentences. If this property holds, this decreases the value of PScore .
 of relationships between n-tsets. Each node corresponds to an n-tset occurring in the document, and each edge models the co-occurrence of a pair of n-tsets in a sentence. Indeed, the graph is directed. If a i  X  a j , then a one or more sentences. The graph of n-tsets for our running example is shown in Fig. 1 . Note that the nodes of the graph are subdivided into three partitions: FS, LS, and MS. This means that each node associated with an n-tset must be univocally assigned to one partition. When the same n-tset occurs in more than one set of sentences  X  i.e., first, last, or middle sets of sentences  X  we must choose only one of the three partitions FS, LS, or and MS. Specifically, we assign the n-tset to a partition according to a priority order: we choose FS if the n-tset appears in some of the first sentences, then LS if the n-tset appears in some of the last sentences, MS otherwise.
 Since n-tsets in FS and LS are considered more discriminative than the others, we increase the primary scores of n-tsets whose associated nodes are in the FS or LS partition. In addition, we also boost the primary scores of nodes in MS that are connected to nodes in FS or LS, i.e., there exist a path that connects these nodes in MS to nodes in FS or LS partitions. Specifically, we use two boosting methods that exploit graph properties The first one simply exploits the in/out degree of each node: The second boosting method exploits function  X  = max among the HITS func-tions discussed in Sect. 2 : We obtained better results with  X  = max than with any other alternative func-tions  X  . It shows that the words occurred at the beginning or at the end of a paragraph are much more important candidates as keywords of the document. It is worth noting that the nodes in MS that are not boosted maintain, however, the old primary score, i.e., Score ( a i )= PScore ( a still considered in the following phase.
 Specifically, once all the nodes in the graph are scored by Score ( a them, and finally return the n-tsets associated with the K -top ranked ones, where the value of K depends on the length of document to be summarized. Indeed, we sort in decreasing order of Score the nodes within each partition of the graph (FS, MS, or LS). After this separated reordering of each partition, we return a summary that contains the same fraction  X  ,0 &lt; X &lt; 1, of the top-scored n-tsets for each of the three partitions. Specifically, we return  X   X   X | MS | nodes (n-tsets) from the sets FS, MS, and LS.
 Finally, the order of the terms in the generated summary is the same as the one in the original document. This step is important to evaluate the quality of the extracted summaries with respect to human-generated ones (using the DUC 2002 dataset).
 Hereinafter, we call the summarization algorithm that exploits the boosting methods of Eq. ( 4 ) NG -Rank M , whereas we call the ones adopting the alterative boosting method of Eq. ( 5 ) NG -Rank H .
 The principal idea of the experiments is to show the efficacy of the text sum-marization on clustering results through a manually predefined categorization of the corpus. In addition, in order to evaluate the absolute quality of our sum-marization method, we further need a standard dataset to compare our method with the baseline. We used  X  X lassic4 X  and  X  X BC NEWS X  to test the benefits of summarization on clustering quality , and  X  X UC 2002 X  for testing the quality of our summarization method.
 them, and finally the evaluation measures used for in the experimental tests. Datasets. The three corpora used in the experiments are described in the following: Classic4: This dataset is often used as a benchmark for clustering and co-clustering 2 . It consists of 7095 documents classified into four classes denoted MED, CISI, CRAN and CACM.
 BBC NEWS: This dataset consists of 2225 documents from the BBC news website corresponding to stories in five topical areas, which are named Business, Entertainment, Politics, Sport and Tech, from 2004 X 2005 [ 4 ]. We have used four classes of BBC news in our experiments. Unlike Classic4, the BBC NEWS corpus is full of names of athletes, politicians, etc. These proper names are challenging, because they could be important to be extracted as keyphrase of text. On the other hand, they could reduce the similarity between two related texts. DUC 2002: This dataset is a collection of newswire articles provided during the Document Understanding Evaluations 2002 3 . DUC 2002 contains 567 document-summary pairs which are clustered into 59 topics. We have used the 100-words summary provided for each document.
 Preprocessing. Preprocessing is an essential step in text mining. The first classing preprocessing regards stop words removal, lower case conversion, stem-ming 4 , and finally identifying sentences and paragraphs.
 them two new datasets. Specifically, since our aim is to evaluate the efficacy of summarizing longer documents to improve clustering, for each original dataset we generated a sub-collection of documents of different sizes: a large part of them approximatively contains the same number of terms sz , while the others are much longer than sz . Specifically, longer documents contain a number of terms not less than 3  X  sz . In more details, we stratified the sampling of each original labeled dataset as follows. Let L = { L 1 ,L 2 , ..., L c } be the original dataset, where L documents labeled with the i th class. From each L i we thus extract a subset thus generating the sub-collection D = {L 1 , L 2 , ..., L where R i = { d  X  L i | a  X  size ( d )  X  b } and E i = { d while
M is the average size of the documents in R i , i.e. M = d  X  R The constants a and b limit the size of documents in R i . We tested our method on different sampled sub-collections D , using diverse a and b . The results obtained are similar. 4.1 Evaluation Measures For evaluating quality of summaries produced by NG-Rank, we used the ROUGE-v.1.5.5 5 evaluation toolkit. It is a method based on N -gram statis-tics, found to be highly correlated with human evaluations [ 6 ]. The ROUGE-N is based on n-grams and generates three scores Recal l , Precision , and the usual F-measure for each evaluation.
 R (recall) counts the number of overlapping n-gram pairs between the candidate summary to be evaluated and the reference summary created by humans (See [ 6 ] for more details). P n (precision) measures how well a candidate summary over-laps with multiple human summaries using n-gram co-occurrence statistics (See [ 11 ] for more details). We used two of the ROUGE metrics in the experimental results, ROUGE-1 (unigram) and ROUGE-2 (bigram).
 For evaluating the clustering results, we used Purity measure. The purity is a simple and transparent evaluation measure which is related to the entropy concept [ 12 ]. To compute the purity criterion, each cluster P is assigned to its majority class. Then we consider the percentage of correctly assigned documents, given the set of documents L i in the majority class: The final purity of the overall clustering is defined as follows: where N is the number of all documents, P = { P 1 ,P 2 , ..., P and L = { L 1 ,L 2 , ..., L c } is the set of classes. As previously stated, we first evaluate NG -Rank as a keyphrase extraction-based summarization method, by comparing the automatically generated summaries with human-generated ones. Then we indirectly assess the quality of the sum-maries, automatically extracted by our algorithm, by evaluating the clustering improvement after applying NG -Rank . 5.1 Assessing the Quality of the Summarization For the former tests, we thus utilize DUC 2002, and adopt the ROUGE eval-uation toolkit to measure the quality of summaries. DUC 2002 provides ref-erence summaries of 100-words (manually produced) to be used in the eval-uation process. We stemmed tokens and removed stop words from reference and extracted summaries. In our experiments, we tested both NG -Rank NG -Rank H 6 for extracting keyphrases from documents. To compare our method with the HITS-based algorithm (our baseline), we considered the best results obtained for the possible  X  functions presented in Sect. 2 . The size of the sum-mary we have to extract for each documents should be equals to the manually produced reference summary, Since we also remove from them stop words, thus making the reference summaries smaller than the original 100-words ones, we had to choose a suitable parameter  X  for NG -Rank . Recall that  X  determines the percentage of top-scored graph nodes in each partition FS, LS, or MS that NG -Rank returns (see Sect. 3 ).
 gram) and ROUGE-2 (bigram). The obtained results are showed in Table 1 .The convergence time of HITS algorithm increases the execution time of NG -Rank but it is negligible considering the significant results obtained by NG -Rank Due to this encouraging result, we always applied NG -Rank long documents in our experiments on clustering. 5.2 Assessing the Clustering Improvement Due to Summarization In previous experiments, we applied NG -Rank H to summarize longer documents in our corpus, before applying a text clustering algorithm. The algorithm adopted for clustering documents was K-Means, while the vectorial representation of documents was based on a classical tf -idf weighting of terms, and the measure of similarity between two vector was Cosine similarity. Specifically, we utilized RapidMiner 7 , which is an integrated environment for analytics, also providing tools for text mining.
 Indeed, we tested and evaluated clustering with/without applying NG -Rank H , to show the improvements in clustering purity due to summariza-tion. Before reporting and examining the various results, we have first to discuss the features of the sampled corpora, which contain some longer documents. These longer documents are exactly our candidates for summarizations. As stated in Sect. 4 , for each sampled corpus D = {L 1 , L 2 , ..., L where E i denotes the set of documents of the i th class that are significantly longer than the average length M . More specifically, the documents in E a size that is at least 3 times M . In our test we used five sampled datasets with different sizes of | E i | = { 7 , 12 , 18 , 25 } .
 Another important remark concerns the size of the summaries extracted by NG -Rank H from each longer document in E i . This size is determined by the parameter  X  of the algorithm (see Sect. 3 ). For each d  X  where | d | and M denote, respectively, the length of d and the average length of the shorter documents in the sampled class. Figure 2 shows the size of the documents belonging to a given class, namely the class Sport in a dataset sampled from the BBC corpus, before and after summarizing larger documents. Figure 3 shows the average purity obtained by clustering documents in each sampled corpus D , with/without summarizing longer documents. The best improvements in the average purity, due to summarization of longer documents, were about 10 %.
 Table 2 (a) shows the clustering results without summarizing the longer doc-uments. The dataset used in the test were obtained from the BBC NEWS cor-pus, where the longer documents were added to the classes Polit and Sport only. Specifically, we have | E Polit | =25and | E Sport | ments was: | R Bus | = 116, | R Enter | = 117, | R Polit | Table 2 (b) reports the results obtained by first applying NG -Rank rize the longer documents, and by then clustering all the document collection. We obtained an improvement in the average purity of about 10 %.
 Classic4. Specifically, we have | E Cisi | = 18, | E Cran | E
Cacm | = 7. The size of each class before adding these longer documents was: | R improvement in average purity was smaller than for the BBC dataset. However, we registered a similar behaviour, and thus summarizing longer documents by using our algorithm is always valuable. We conclude with some final remarks about our methodology based on doc-ument summarization. When we add longer documents to a class, we likely increase the frequency of terms that are not relevant to the main topic of the class. Indeed, each document contains several topics, for each of which there are relevant terms in documents [ 2 ]. Therefore, when we increase the length of a document, we may cause the number of topics to get larger. We can think of NG -Rank H as a method to remove some of these less important/relevant topics, by retaining the main topics only, hopefully those topics that are common to all the documents in a given class. In this paper, we have presented a new graph-based algorithm for keyphrase extraction, in turn used to summarize big documents in a textual corpus, before applying a clustering algorithm. Our experiments indicate the big documents, i.e., document whose size is significantly larger than the mean size in the cor-pus, introduce noise that can worsen the quality of clustering result. We tested our keyphrase extraction algorithm to summarize these big documents, thus retaining only the terms that are relevant to the main topics discusses in the documents, and observed a significant improvement in clustering quality. sion. In particular, we plan to utilize background knowledge like WordNet to also enrich small documents, with the aim of further improving clustering quality.
