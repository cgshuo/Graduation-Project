 Given a network, intuitively two nodes belong to the same role if they have similar structural behavior. Roles should be automatically determined from the data, and could be, for example,  X  X lique-members, X   X  X eriphery-nodes, X  etc. Roles enable numerous novel and useful network-mining tasks, such as sense-making, searching for similar nodes, and node clas-sification. This paper addresses the question: Given a graph, how can we automatically discover roles for nodes? We propose RolX ( Role eXtraction ), a scalable (linear in the number of edges), unsupervised learning approach for auto-matically extracting structural roles from general network data. We demonstrate the effectiveness of RolX on sev-eral network-mining tasks: from exploratory data analy-sis to network transfer learning. Moreover, we compare network role discovery with network community discovery. We highlight fundamental differences between the two (e.g., roles generalize across disconnected networks, communities do not); and show that the two approaches are complimen-tary in nature.
 H.2.8 [ Database Applications ]: Data mining; E.1 [ Data Structures ]: Graphs and networks Algorithms, Design, Performance, Experimentation. Graph mining, structural role discovery, network classifica-tion, similarity search, sense-making
Given a network, we want to automatically capture the structural behavior (or function) of nodes via roles . Exam-ples of possible roles include: centers of stars, members of cliques, peripheral nodes, etc. To this end, we propose a novel approach, called RolX ( Role eXtraction ), which auto-matically and effectively summarizes the behavior of nodes in large graphs. More precisely, RolX achieves the follow-ing two objectives. First, with no prior knowledge of the kinds of roles that may exist, it automatically determines the underlying roles in a network. Second, it appropriately assigns a mixed-membership of these roles to each node in the network. RolX is important because its roles form a basis for a number of novel and interesting network data analysis tasks such as network transfer learning, measuring structural similarity, sense-making (i.e., understanding the underlying behavior in a network), and network visualiza-tion. For instance, given two IP communication graphs from enterprise networks, we can use the extracted roles in one graph to build a relational classifier that can be used for a classification task in the other graph, effectively performing across-network classification or transfer learning on graphs.
RolX is an unsupervised learning approach for automat-ically extracting structural roles from general network data sets. Through extensive experiments, we demonstrate that the derived roles are effective in exploratory data analysis tasks (such as sense-making and node-similarity) and in pre-diction tasks such as across-network transfer learning. In the latter setting, we use the ability of roles to generalize behav-ior across networks as a way to perform network learning without relying on homophily, or on the availability of class labels in the target graph.

In our framework, roles are derived from structural fea-tures. In the absence of any other information, the prob-lem of extracting roles from a network dataset is ill-defined, since there can be an infinite number of structural features that can be derived from the data. Once we choose a set of such features, the problem of role extraction can be well-formulated. Given a set of structural features that are ex-tracted for a dataset, we define the role extraction problem as (1) finding the basis vectors in this structural feature space (where the number of basis vectors is determined by model selection), and (2) determining how much each net-work node belongs to each role. The structural features that are used for role extraction are domain-dependent. For ex-ample, for social networks, we propose a set of structural features that agree with the domain knowledge of sociolo-gists.

The contributions of our work are as follows: Figure 1: Role discovery and community discovery a re complementary approaches to network analy-sis. Left: The 4 roles that RolX discovers on the largest connected component of the Network Science Co-authorship Graph:  X  X ridge X  nodes (as red dia-monds),  X  X ain-stream X  nodes (gray squares), etc -see text. Right: The 22 communities that Fast Mod-ularity [6] finds on the same co-authorship graph. Roles capture node-level behaviors and generalize across networks whilst communities cannot.
We want to emphasize that RolX as a role discovery ap-proach is fundamentally different from (and complementary to) community detection: the former groups nodes of similar behavior ; the latter groups nodes that are well-connected to each other.

Figure 1 depicts the difference between role discovery and community discovery for the largest connected component of a weighted co-authorship network [25]. RolX automatically discovers 4 roles vs. the 22 communities that the popular Fast Modularity [6] community discovery algorithm finds. RolX is a mixed-membership approach, which assigns each node a distribution over the set of discovered, structural roles. The node colors for RolX correspond to the node X  X  primary role, and for Fast Modularity correspond to the node X  X  community. Our four discovered roles represent these behaviors:  X  X ridge X  nodes (red diamonds) representing cen-tral and prolific authors, X  X ain-stream X  X odes (gray squares) representing neighborhoods of bridge nodes,  X  X athy X  nodes (green triangles) representing peripheral authors with high edge-weight, and  X  X ight-knit X  nodes (blue circles) represent-ing authors with many coauthors and homophilic neighbor-hoods.

The rest of the paper is organized as follows: proposed method, experimental results for the mining tasks outlined above, related work, and conclusions.
R olX is a mixed-membership approach, which assigns each node a distribution over the set of discovered roles.
Given a network, the goal of RolX is to automatically dis-cover a set of underlying (latent) roles, which summarize the structural behavior of nodes in the network. RolX consists of three components: feature extraction, feature grouping, and model selection.
In its first step, RolX describes each node as a feature vec-tor. Examples of node features are the number of neighbors a node has, the number of triangles a node participates in, etc. RolX can use any set of features deemed important. Among the numerous choices for feature extraction from graphs, we choose the structural feature discovery algorithm described in [15] since it is scalable and has shown good per-formance for a number of tasks. For a given node v , it ex-tracts local and egonet features based on counts (weighted and unweighted) of links adjacent to v and within and ad-jacent to the egonet of v . It also aggregates egonet-based features in a recursive fashion until no informative feature can be added. Examples of these recursive features include degree and number of within-egonet edges, as well as ag-gregates such as  X  X verage neighbor degree X  and  X  X aximum neighbor degree. X  Again, RolX is flexible in terms of a fea-ture discovery algorithm, so RolX  X  X  main results would hold for other structural feature extraction techniques as well.
After feature extraction, we have n vectors (one per node) of f numerical entries each. How should we create groups of nodes with similar structural behavior/features? How can we make it fully automatic, requiring no input from the user?
We propose to use soft clustering in the structural feature space (where each node has a mixed-membership across var-ious discovered roles); and specifically, an automatic version of matrix factorization.
 Given a node-feature matrix V n  X  f , the next step of the RolX algorithm is to generate a rank r approximation GF  X  V where each row of G n  X  r represents a node X  X  membership in each role and each column of F r  X  f specifies how mem-bership in a specific role contributes to estimated feature values. There are many methods to generate such an ap-proximation (e.g., SVD, spectral decomposition) and RolX is not tied to any particular approach. For this study, we chose Non-negative Matrix Factorization because it is com-putationally efficient and non-negative factors simplify the interpretation of roles and memberships.

Formally, we seek two non-negative low rank matrices G and F to satisfy: argmin G,F k V  X  GF k fro , s.t. G  X  0 , F  X  0, where || || fro is the Frobenius norm. The non-negativity constraint generally leads to a sparse, part-based represen-tation of the original data set, which is often semantically more meaningful than other factorization methods. While it is difficult to find the optimal factorization of a matrix be-cause of the non-convexity of the objective function, several efficient approximation algorithms exist (e.g., multiplicative update [18] and projective gradient decent [20]). RolX uses multiplicative update because of its simplicity. It is worth pointing out that RolX can naturally incorporate other vari-ants of matrix factorization such as imposing sparseness con-straint on F and/or G by incorporating some regularization terms in the objective function [10]). RolX can also use a general Bregman divergence [8] to measure approximation Figure 2: Errors do not appear to be normally dis-t ributed when approximating V in the Network Sci-ences Co-authorship graph. The spike at zero sug-gests that the Frobenius norm is not a good mea-sure of model likelihood. RolX uses KL divergence to compute error description costs. accuracy instead of using the Frobenius norm  X  this enables RolX to use other divergence functions (e.g., KL divergence) that can be more appropriate in some cases, as explained in Section 2.3.

One practical issue with feature grouping algorithms is that the model size (i.e., the number of roles) must be pre-specified. In general, it is unrealistic to expect a practitioner to manually select an appropriate value for this parame-ter. Therefore, we explore several approaches for automatic model selection.
Since roles summarize behavior, they can be used to com-press the feature matrix V . We propose to use the Minimum Description Length criterion [27], to select the model size r that results in best compression. For a given model, we can compute the resulting description length in two parts: (1) the number of bits required to describe the model itself, and (2) the cost of describing the reconstruction errors in V  X  GF (to achieve lossless compression). The selected model is the one that minimizes the description length L , which is the sum of model description cost M and the coding cost (or equivalently, the cost of correcting the errors of our model) E . That is, L = M + E .

Assuming G and F are not sparse, the cost of describing the model using b bits per value is M = br ( n + f ).
How should we determine the representation cost of cor-recting errors in the reconstruction? That is, how do we compute the log-likelihood of a given model? Figure 2 sug-gests that the errors in V  X  GF are not distributed normally, making the standard Frobenius norm a poor choice. Instead, we use KL divergence to compute the error description cost:
Because the model can contain high-precision floating point values, we combine Lloyd-Max quantization [22, 21] with Huffman codes [17] to increase compression. Note that with Huffman codes, the cost of encoding the model changes to  X  br ( n + f ), where  X  b is the mean number of bits required per value. As a default, we choose log 2 ( n ) quantization bins. However, the number of bins can be selected through param-Figure 3: Description length (in bits) is minimized w hen using 2 4 bins and 3 or 4 roles in the Net-work Science Co-authorship graph. Too many bins or roles increases the model description cost, while too few increases the cost of describing errors. eter selection by choosing the number of bins and roles that minimizes description length. Figure 3 shows that for the Network Science Co-authorship graph, description lengths are minimized when we use 2 4 = 16 quantization bins and 3 or 4 roles.
Let n be the number of nodes, m be number of edges, f = number of features, and r = number of roles.

Lemma 1. The running time complexity of RolX is linear on the number of edges, and specifically is O ( mf + nf r ) .
Proof. We give the complexity of each of the three steps of RolX .
 Feature Extraction . This is O ( f ( m + nf )) [15].
Model Selection . The error computation takes O ( nrf ) to multiply an n  X  r matrix by an r  X  f matrix. Quantization has a complexity of O ( nf ilog ( K )), where K is the number of quantization bins and i is the number of iterations that we run the quantizer. Default for K is log ( n ), so this becomes O ( nf ilog ( log ( n ))). Notice that the term of O ( log ( log ( n ))) is a very small number. For example, for a graph with 1 billion nodes, this term is just about 3 . 1. So, the complexity for the quantization is roughly O ( nf i ). There is also a term for the Huffman coding which is O ( nf + Klog ( K )). The O ( Klog ( K )) term is to build the tree that holds the codes. But this number is very small and therefore can be neglected.
Feature Grouping . We use the multiplicative update method for RolX , which has worst case complexity O ( nf r + nr 2 f r 2 ) = O ( nf r ).
W e experimented with several other options for clustering, model sizes criterion, and compression. For example, the information criterion proposed by Akaike (AIC) [1] can be used in place of compression. RolX can use as a drop-in replacement any other matrix factorization method, either in the usual form or the sparse counterpart (e.g., [10]).
Similarly, there are several representational choices for compressing floating points. We experimented with numer-ous of these choices, but we omit the details for brevity. Thus, unless otherwise stated RolX employs the feature ex-traction algorithm described in [15], non-negative matrix factorization for clustering, MDL for model selection, and KL divergence to measure likelihood.
T able 1: Extracted real-world network trace data
In this section, we present experiments on role effective-ness for the across-network classification task (i.e., network transfer learning).

Data. We conduct experiments on two real-world data sets: IP communication networks and bluetooth proximity networks.

IP data : IP-A and IP-B are real network-trace data sets collected roughly one year apart on separate enterprise net-works. The nodes are IP addresses and the links are com-munications between the IPs. The IP-A trace begins at midnight on day 1 and continues up to 12pm on day 5. The IP-B trace begins at midnight on day 1 and continues up to  X  5pm on day 6. For days 1-4 of the IP-A dataset (IP-A1 to IP-A4), we extract flows in the period from 12pm-1pm. We exclude day 5 because the trace ended at 12pm. For IP-B, we extract flows from 12pm-1pm for day 3 only. We then label all flows using a payload signature-based classification tool. Once network flows are labeled, we transfer labels to hosts by selecting the most frequent class-labels from among the host X  X  flows. The payload classifier can distinguish between over 15 classes of traffic (e.g., Web, DNS, SMTP, P2P). How-ever, since we found that 3 classes (namely, Web, DNS, and P2P) made up the dominant traffic type for over 90% of the labeled hosts, we remove all other labels and focus on the 3-class classification problem. Table 1 summarizes the data that we extracted. Notice the differences in the size and class distribution across these networks.

Reality Mining Device data : This dataset is con-structed based on the data provided by the Reality Mining project [9]. That study was conducted in July 2004-June 2005 at the MIT Media Laboratory, with the participation of 94 human subjects using mobile phones pre-installed with several pieces of software, which recorded and sent to the re-search center various data including information about Blue-tooth devices in proximity of approximately 5 meters. Sub-jects were tracked over 12 months and included students and faculty from the MIT Media Lab and the Sloan Busi-ness School. Within that period, about two million device scans were reported.

Classifiers. To test the predictive ability of the roles dis-covered by RolX , we use logistic regression with the RolX role memberships as features. In order to compare the pre-dictive power of the RolX roles to the raw features that RolX uses as input, we also compare to a classifier that uses these raw features as input. The classifiers we compare are: Train Graph T able 2: Across-network experiments performed on the network trace data
The standard relational classifiers are not applicable for these transfer learning tasks since these methods rely on the availability of some known class labels in the test graph to seed the inference process. The test graphs here are com-pletely unlabeled.

Methodology. For each experiment, the training graph has all known labels available. The test graph is completely unlabeled. Each classifier is evaluated on all known ground truth labels in the test graph. We use an identical set of roles for all data sets, which comes from running RolX on the IP-A1 data set. Table 2 summarizes the across-network experiments.
 Results. We discuss predictive performance of roles next.
IP data : We ran RolX on a series of across-network transfer learning tasks (see Table 2). We train on one net-work where all known labels are available, and test on a sep-arate network that is completely unlabeled. These tasks are difficult, given the (sometime extreme) differences in class distributions between data sets (see Table 1). The perfor-mance of the Default classifier is a good indicator of the diffi-culty of each task, since this model makes predictions based solely on the most frequent class from the training set. Feat uses the full set of 373 structural features extracted from IP-A1. RolX summarizes these features into 9 roles.
We see from Figure 4 that the roles produced by RolX effectively summarize the behavior of hosts in an IP network. In particular, RolX is able to generalize more effectively than Feat from network A to network B ( RolX =85%, Feat =71% accuracy, p-value=0.01 2 ). The results for transfer learning tasks across different days of network A are omitted since we cannot differentiate the performance of RolX and Feat (p-value=0.25).

Figures 5 and 6 demonstrate that the model selection cri-terion used by RolX is quite effective for our IP network clas-sification task. RolX chooses a model size of 9 roles, which is right in the middle of the peak accuracy range shown in Figure 5. Figure 6a shows that the model selection crite-rion used by RolX is highly correlated with classification accuracy (Pearson correlation is -0.91). Figure 6b shows the default RolX model selection criterion decomposed into its constituent parts. Model cost is the cost associated with representing the model itself while error cost is the cost of
T he p-values are obtained from a one-tailed paired t-test. Figure 4: R olX provides better generalization per-formance between enterprise IP networks A and B (mean accuracy of RolX =85%, Feat =71%, p-value=0.01). Figure 5: R olX chooses a high accuracy model size of 9 roles, in the middle of the peak accuracy range of 7-11 roles. The Y-axis depicts the mean classifi-cation accuracy using RolX (over all 4 test sets) by model size. representing the differences between the original feature val-ues and the estimated feature values reconstructed using the model. As expected, we see a consistent increase in model cost and a consistent decrease in error cost as the number of roles increases.

Figure 7 shows that IP traffic classes are well-separated in the RolX  X  X ole space X , with as few as 3 roles (extracted from the original 373 structural features). Note that we achieve even better separation with the automatically se-lected model size of 9 roles (see Figure 4), but we can only clearly visualize up to 3.
 We omit for brevity the X  X ense-making X  X able for the 3-role IP experiment. It shows that Roles 1 and 2 are lower-volume IPs while Role 3 is high-volume servers or P2P nodes. Role 3 contains nodes of all three types (Web, DNS, P2P). This Role is overloaded since the model size of 3 is not as predic-tive as larger model sizes (see Figure 5).

Reality Mining Device data : We conducted two sets of transfer learning experiments on this data. The first set of experiments involves a binary classification task where we try to predict whether a given subject is a business school student or not. The second set is similar, where we try to predict whether a subject is a graduate student in the Media Lab or not. As train and test sets, we used each pair of consecutive months in our dataset. In Figure 8, we show the accuracy of RolX . The Baseline is a classifier that learns to always predict the majority class of the training set on the test set. The time labels denote the month for the train data, and the month following that is used as the test F igure 6: RolX  X  X  model selection is effective: (a) Classification accuracy is highest when RolX selec-tion criterion is minimized. Red markers indicate the peak performing model sizes of 7-11 roles (b) RolX  X  X  model selection criterion balances model size and reconstruction accuracy. data. We also use all the data in 2004 and 2005 as train and test data, respectively. Notice that RolX outperforms the baseline classifier most of the time with an average of 83% and 76% accuracy for the two experiment sets, respectively. We notice that RolX  X  X  accuracy drops when September and May data is used as training, possibly because these months correspond to the start and end of the school semesters; the behavior of the subjects would be generally different than usual in these months, thus providing not as much predictive information as the other months would.
Here we describe experiments in which RolX is used for its most basic task: grouping nodes based on their structural similarity.

Network Science Coauthorship Data. Our first data set is a weighted co-authorship graph with 1589 authors (from the network science community) and 2743 weighted edges [25]. Figure 9 shows (a) the role-colored graph (where each node is colored by the primary role that RolX finds) and (b) the role affinity heat map. RolX finds four roles. Based on further analysis of the network and its roles, we discovered that the roles correspond to the following: (Dis-claimer: The relative position in the graph does not reflect the total magnitude of contributions of the individual re-searchers. It is just a snapshot of networks-science-related data, and specifically in 2006.) F igure 7: IP traffic classes are well-separated in the RolX  X  X ole space X  with as few as 3 roles. (a) Ternary plot showing the degree of membership of each DNS, P2P, and Web host in each of three roles. (b) Pseudo-density plot obtained by adding uniform noise to (a) to reveal overlapping points. !""#$%"&amp;' !""#$%"&amp;' F igure 8: RolX (in blue) effectively generalizes be-havior across time (higher is better). Figure shows results of across-network transfer learning on the Reality Mining Device dataset with RolX . Notice that RolX almost always performs well on the two different learning tasks with an average accuracy of 83 % and 76 %, respectively. F igure 9: RolX effectively discovers roles in the Network Science Co-authorship Graph. (a) Author network RolX discovered four roles, like the het-erophilous bridges ( red diamond ), as well as the ho-mophilous  X  X athy X  nodes ( green triangle ) (b) Affin-ity matrix (red is high score, blue is low) -strong homophily for roles #1 and #4.
RolX  X  X  roles allow us to find similar nodes by compar-ing their role distributions. Figure 10 depicts node sim-ilarity for three (target) authors for the Network Science Co-authorship Graph: Mark Newman, F. Robert, and J. Rinzel. The primary roles for these three authors are dif-ferent. Mark Newman X  X  primary role is a broker (a prolific author); F. Robert X  X  primary role places him in a tight-knit group (an author with homophilous neighborhood), and J. Rinzel X  X  primary role places him in the periphery (an au-thor with homophilous but  X  X athy X  neighborhood). In each node-similarity picture, the target author is colored in yel-low. The more similar nodes are red and less similar nodes a re blue. Due to the generality of roles, RolX is able to find similar nodes across the entire graph even though it has many disconnected components.
 Political Books Co-purchase Data. We gave the 2000 Amazon Political Books Co-purchasing Network 3 to RolX . This graph has 105 nodes (representing books) and 441 edges (representing frequent co-purchasing of the books by the same buyers). RolX is able to effectively capture the pur-chasing behavior of customers by separating the X  X ocally cen-tral X  books from the  X  X eripheral X  books. Figure 11 depicts the  X  X ocal central-ness X  and  X  X eripheral-ness X  of the books.
For the readers X  convenience, we also present the human-provided labels for the nodes: conservative books (in cir-cles), liberal books (in squares), and neutral books (in di-amonds). Examples of highly central books are  X  X ff With Their Heads X  (conservative) and  X  X ushwhacked X  (liberal). Highly peripheral books include  X  X he Right Man X  (conser-vative) and  X  X hrub X  (liberal).

Node positions in Figure 11 are determined by a stan-dard force-directed layout. Communities (conservative vs. liberal) are separated while nodes within a community are organized by role (central vs. peripheral) RolX can be used in conjunction with community discovery algorithms to find similar nodes in disparate communities or networks.
To make  X  X ense X  of roles, we introduce two methods. One based on node measurements ( NodeSense ) and another based on neighbor measurements ( NeighborSense ).

NodeSense takes as input RolX  X  X  node-by-role matrix, G , and a matrix of node measurements, M . For our experi-ments, we use the following node measurements: a node X  X  degree, weighted degree, clustering coefficient, eccentricity (i.e., the longest geodesic from a node), PageRank, gate-keeper (i.e., whether a node is an articulation point for some pairs of nodes), local gatekeeper, pivot (i.e., a node with high betweenness), and structural hole (i.e., to what extent are a node X  X  links redundant). NodeSense then computes a non-negative matrix E such that G E  X  M . The matrix E repre-sents the role contribution to node measurements. A default matrix E  X  is also computed by using G  X  = ones ( n, 1), where the n nodes belong to one role. Then, for each role r and ratio provides the role-contribution to node-measurements compared to the default contribution.

NeighborSense is similar to NodeSense  X  X xcept instead of the matrix M , we use a neighbor matrix N , where the rows represent nodes and columns represent roles. N ( i, j ) is the fraction of node i  X  X  neighborhood that is in role j . Then NeighborSense computes a nonnegative matrix Q such that G Q  X  N . The matrix Q represents the role affinities. A default matrix Q  X  is also computed using G  X  = ones ( n, 1), where the n nodes belong to one role. Then, for each pair of roles r 1 and r 2 , NeighborSense computes Q ( r 1 ,r 2 ratio is the role-affinities compared to the default affinities.
Figure 12 depicts the results of NodeSense and NeighborS-ense on the Network Science Co-Authorship Graph. Recall that RolX found four roles on this graph. Role 1 nodes
V aldis Krebs, http://www.orgnet.com/. A third  X  X uper-peripheral X  role is omitted for brevity. These nodes are gray in both (a) and (b). F igure 11: RolX effectively discovers roles in the 2000 Amazon Political Books Co-purchasing Net-work  X  illustrating how RolX  X  X  roles can be used to find similar nodes in disparate communities. RolX finds two roles: locally central nodes and periph-eral nodes. The redness of a node corresponds to its percentage membership in Role 1 (its  X  X ocal central-ness X ). Similarly, the blueness of a node corre-sponds to its percentage membership in Role 2 (its  X  X eripheral-ness X ). The node shapes corresponds to the human-provided labels of conservative (circle), liberal (square), and neutral (diamond). ( blue circles in Figure 9a) are authors with many coauthors and homophilic neighborhoods. They have high degree, high clustering coefficient, and high homophily. They are never gatekeepers (i.e. articulation points for some pairs of nodes) or pivotal nodes (i.e., with high betweenness). Role 2 nodes ( red diamonds in Figure 9a) represent authors who are cen-tral and prolific with high total weight. They have low clus-tering coefficient but high degree, high PageRank, and high affinity for Role 3 nodes (i.e., gray rectangles ). Removal of Role 2 nodes severely interrupts graph connectivity because they are often gatekeepers and pivotal nodes. Role 3 nodes ( gray squares in Figure 9a) are peripheral authors. They have low degree and high eccentricity (i.e., nodes in the net-work periphery). They are almost never gatekeepers, but can be pivotal (i.e. they do not disconnect the graph, but they often increase geodesic lengths when removed). Role 4 nodes ( green triangles in Figure 9a) are isolated authors with high average edge weight and homophilic neighborhoods. Their links are not redundant (w.r.t. structural holes), but have low scores for most other measures (except homophily).
This sense-making analysis can be extremely useful for large networks, which cannot be easily visualized. By using form small chains. Figure 12: N odeSense and NeighborSense explain roles in the network science co-authorship graph. The blue circle authors (Role 1) are members of tight-knit communities and are role-homophilous.
 The red diamond authors (Role 2) are least ho-mophilous. They are mostly brokers/bridges and are neighbors of gray rectangles (Role 3). The gray rectangle nodes (Role 3) are peripheral authors (i.e., have unusually high eccentricity). The green trian-gle nodes (Role 4) are isolated authors with discon-nected coauthors. role-homophily and topological measures, we can interpret roles regardless of network size.
Related research can be categorized into three parts: (1) graph features, (2) role discovery, and (3) transfer learning.
Graph Features . Features have been extracted from graphs for several data mining tasks. In [19], the authors propose extracting topological features for pairs of nodes for link prediction. In [14], the authors develop a multi-level framework to detect anomalies in time-varying graphs based on graph, sub-graph, and node level features. Their approach relies on extracting graph-level (global) features and tracking these metrics over time. In [2], the authors pro-pose to detect abnormal nodes from weighted graphs based on features and patterns from egonets. There has also been work on using local and global structural features to improve the performance of network classifiers [12]. Some methods for feature extraction explicitly preserve the multi-cluster structure in the data [4]. Our work builds upon the ap-proach of recursive feature extraction [15].

Role discovery. We propose using recursive graph fea-tures for role discovery of nodes. The task of role discovery has been studied in different types of graphs (e.g., social net-works [23]). Different approaches have been used for role dis-covery, including Bayesian frameworks using MCMC sam-pling algorithm for learning multiple roles of data points [28], semi-supervised semantic role labeling [11], etc. These ap-proaches do not scale up to handle large graphs.

There is another related body of work in role mining, a nice overview of which is given by Molloy et al. [24]. Role mining is somewhat different from the role discovery prob-lem we discuss in this paper. It addresses the access per-missions for different users in different roles in an access-controlled system. However, role mining algorithms use techniques similar to role discovery for inferring roles for nodes in a graph (e.g., hierarchical clustering).
In addition to using the inferred roles for exploratory graph mining (such as structural similarity and sense-making tasks), we use the inferred roles for improving classification. Previous approaches include using cluster structure for pre-dicting class labels on graphs [16], and using cluster kernels for semi-supervised classification [30]. RolX is scalable.
RolX is different than generalized blockmodeling [26], which is commonly used in social network analysis. In particular, (1) RolX roles generalize across networks; (2) RolX is scal-able; and (3) RolX incorporates local structure in addition to regular equivalence, and natively supports node attributes when they are available.

Transfer learning . Another aspect of our work is effec-tive transfer learning in graphs. In the context of graph data, nonparametric models have been proposed for transfer learn-ing for the task of collective link prediction [5]. The general framework of EigenTransfer constructs a graph to represent the source-target transfer learning task [7], while similarity matrix approximations of a hybrid graph have been explored for transfer learning [29]. Relevant supervision has also been t ransferred across domains to improve the performance of clustering algorithms [3]. In all existing work, the features are given as the input and the goal is to leverage the given features to boost performance in the target domain.
Our main contribution is the careful design and exten-sive experimental validation of RolX , a novel role discovery approach with the following properties:
This work was performed under the auspices of the U.S. De-partment of Energy by Lawrence Livermore National Labo-ratory under Contract No. DE-AC52-07NA27344, and sup-ported in part by IARPA via AFRL Contract No. FA8650-10-C-7061 and in part by DAPRA under SMISC Program Agreement No. W911NF-12-C-0028 and ARL No. W911NF-09-2-0053. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwith-standing any copyright annotation thereon. The views and conclusions contained in this document are those of the au-thors and should not be interpreted as representing the offi-cial policies, either expressed or implied, of IARPA, AFRL, DARPA, or the U.S. Government. [1] H. Akaike. Information theory and an extension of the [2] L. Akoglu, M. McGlohon, and C. Faloutsos. Oddball: [3] I. Bhattacharya, S. Godbole, S. Joshi, and A. Verma. [4] D. Cai, C. Zhang, and X. He. Unsupervised feature [5] B. Cao, N. Liu, and Q. Yang. Transfer learning for [6] A. Clauset, M. Newman, and C. Moore. Finding [7] W. Dai, O. Jin, G.-R. Xue, Q. Yang, and Y. Yu. [8] I. S. Dhillon and S. Sra. Generalized nonnegative [9] N. Eagle, A. Pentland, and D. Lazer. Inferring social [10] J. Eggert and E. Korner. Sparse coding and NMF. In [11] H. F  X  urstenau and M. Lapata. Semi-supervised [12] B. Gallagher and T. Eliassi-Rad. Leveraging [13] B. Gallagher, H. Tong, T. Eliassi-Rad, and [14] K. Henderson, T. Eliassi-Rad, C. Faloutsos, [15] K. Henderson, B. Gallagher, L. Li, L. Akoglu, [16] M. Herbster. Exploiting cluster-structure to predict [17] D. Huffman. A method for the construction of [18] D. D. Lee and H. S. Seung. Learning the parts of [19] R. N. Lichtenwalter, J. T. Lussier, and N. V. Chawla. [20] C.-J. Lin. Projected Gradient Methods for [21] S. P. Lloyd. Least squares quantization in PCM. IEEE [22] J. Max. Quantizing for minimum distortion. IRE [23] A. Mccallum, X. Wang, and A. Corrada-Emmanuel. [24] I. Molloy, N. Li, T. Li, Z. Mao, Q. Wang, and J. Lobo. [25] M. E. J. Newman. Finding community structure in [26] A. F. Patrick Doreian, Vladimir Batagelj. Generalized [27] J. Rissanen. Modeling by shortest data description. [28] M. Somaiya, C. Jermaine, and S. Ranka. Mixture [29] Z. Wang, Y. Song, and C. Zhang. Knowledge transfer [30] J. Weston, C. Leslie, E. Ie, D. Zhou, A. Elisseeff, and
