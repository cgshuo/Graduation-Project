 Query suggestion plays an important role in improving the usability of search engines. Although some recently pro-posed methods can make meaningful query suggestions by mining query patterns from search logs, none of them are context-aware  X  they do not take into account the immedi-ately preceding queries as context in query suggestion. In this paper, we propose a novel context-aware query sugges-tion approach which is in two steps. In the offline model-learning step , to address data sparseness, queries are sum-marized into concepts by clustering a click-through bipar-tite. Then, from session data a concept sequence suffix tree is constructed as the query suggestion model. In the online query suggestion step , a user X  X  search context is captured by mapping the query sequence submitted by the user to a sequence of concepts. By looking up the context in the con-cept sequence suffix tree, our approach suggests queries to the user in a context-aware manner. We test our approach on a large-scale search log of a commercial search engine containing 1 . 8 billion search queries, 2 . 6 billion clicks, and 840 million query sessions. The experimental results clearly show that our approach outperforms two baseline methods in both coverage and quality of suggestions.
 H.2.8 [ Database Management ]: Database Applications X  Data Mining Algorithms, Experimentation Query suggestion, click-through data, session data  X  The work was done when Huanhuan Cao, Qi He, and Zhen Liao were interns at Microsoft Research Asia.

The effectiveness of information retrieval from the web largely depends on whether users can issue queries to search engines, which properly describe their information needs. Writing queries is never easy, because usually queries are short (one or two words on average) [19] and words are am-biguous [5]. To make the problem even more complicated, different search engines may respond differently to the same query. Therefore, there is no  X  X tandard X  or  X  X ptimal X  way to issue queries to search engines, and it is well recognized that query formulation is a bottleneck issue in the usability of search engines.
 Recently, most commercial search engines such as Google, Yahoo!, Live Search, Ask, and Baidu provide query sugges-tions to improve usability. That is, by guessing a user X  X  search intent, a search engine suggests queries which may better reflect the user X  X  information need. A commonly used query suggestion method [1, 3, 19] is to find similar queries in search logs and use those queries as suggestions for each other. Another approach [8, 10, 11] mines pairs of queries which are adjacent or co-occur in the same query sessions.
Although the existing methods may suggest good queries in some cases, none of them are context-aware  X  they do not take into account the immediately preceding queries as context in query suggestion.

Example 1 (Search intent and context). Suppose a user raises a query  X  gladiator  X . It is hard to determine the user X  X  search intent, i.e., whether the user is interested in the history of gladiator, famous gladiators, or the film  X  X ladia-tor X . Without looking at the context of search, the existing methods often suggest many queries for various possible in-tents, and thus may have a low accuracy in query suggestion.
If we find that the user submits a query  X  beautiful mind  X  before  X  gladiator  X , it is very likely that the user is inter-ested in the film  X  X ladiator X . Moreover, the user is probably searching the films played by Russell Crowe. The query con-text which consists of the recent queries issued by the user can help to better understand the user X  X  search intent and enable us to make more meaningful suggestions.

In this paper, we propose a novel context-aware query sug-gestion approach by mining click-through data and session data. We make the following contributions.

First, instead of mining patterns of individual queries which may be sparse, we summarize queries into concepts. A con-cept is a group of similar queries. Although mining concepts of queries can be reduced to a clustering problem on a bi-partite graph, the very large data size and the  X  X urse of dimensionality X  pose great challenges. We may have mil-lions of unique queries involving millions of unique URLs, which may result in hundreds of thousands of concepts. To tackle these challenges, we develop a novel, highly scalable yet effective algorithm.

Second, there are often a huge number of patterns that can be used for query suggestion. How to mine those pat-terns and organize them properly for fast query suggestion is far from trivial. We develop a novel structure of concept sequence suffix tree to address this challenge.

Third, we empirically study a large-scale search log con-taining 1 . 8 billion search queries, 2 . 6 billion clicks, and 840 million query sessions. We explore several interesting prop-erties of the click-through bipartite and illustrate several important statistics of the session data. The data set in this study is several magnitudes larger than those reported in previous work.

Last, we test our query suggestion approach on the search log. The experimental results clearly show that our ap-proach outperforms two baseline methods in both coverage and quality of suggestions.

The rest of the paper is organized as follows. We first present the framework of our approach in Section 2 and re-view the related work in Section 3. The clustering algorithm and the query suggestion method are described in Sections 4 and 5, respectively. We report an empirical study in Sec-tion 6. The paper is concluded in Section 7.
When a user submits a query q , our context-aware ap-proach first captures the context of q which is represented by a short sequence of queries issued by the same user im-mediately before q . We then check the historical data and find what queries many users often ask after q in the same context. Those queries become the candidate suggestions. There are two critical issues in the context-aware approach. First, how should we model and capture contexts well? Users may raise various queries to describe the same information need. For example, to search for Microsoft Research Asia, queries  X  Microsoft Research Asia  X ,  X  MSRA  X , or  X  MS Re-search Beijing  X  X ay be formulated. Using specific queries to describe context directly cannot capture contexts concisely and accurately.

To tackle this problem, we propose summarizing individ-ual queries into concepts , where a concept is a small set of queries that are similar to each other. Using concepts to describe contexts, we can address the sparseness of queries and interpret users X  search intents more accurately. To mine concepts from queries, we use the URLs clicked for queries as the features of the queries. In other words, we mine con-cepts by clustering queries in a click-through bipartite. In Section 4, we will describe how to mine concepts of queries.
With the help of concepts, a context can be represented by a short sequence of concepts about the queries asked by the user in the session. The next issue is how to find the queries that many users often ask in a particular context.
It is infeasible to search a huge search log online for a given context. We propose a context mining method which mines frequent contexts from historical sessions in search log data. The contexts mined are organized into a concept sequence suffix tree which can be searched quickly. The mining process is conducted offline. When a user context is presented, we look up the context in the concept sequence suffix tree to find out the concepts to which the user X  X  next query most likely belongs, and suggest the most popular queries in those concepts to the user. The details about mining sessions, building concept sequence suffix tree, and making query suggestions are discussed in Section 5.
Figure 1 shows the framework of our context-aware ap-proach, which consists of two steps. The offline model-learning step mines concepts from a click-through bipartite constructed from search log data, and builds a concept se-quence suffix tree from sessions in the data. The online query suggestion step matches the current user X  X  concept sequence against the concept sequence suffix tree, finds the concepts that the user X  X  next query may belong to, and suggests the most popular queries in the concepts.
A great challenge for search engines is to understand users X  search intents behind queries. Traditional approaches to query understanding focus on exploiting information such as users X  explicit feedbacks (e.g., [14]), implicit feedbacks (e.g., [18]), user profiles (e.g., [4]), thesaurus (e.g., [13]), snip-pets (e.g., [17]), and anchor texts (e.g., [12]).
Several recent studies use search logs to mine  X  X isdom of the crowds X  X or query understanding. For example, Huang et al. [10] mined search session data for query pairs frequently co-occurring in the same sessions. The mined query pairs were then used as suggestions for each other. Fonseca et al. [8] and Jones et al. [11] extracted query pairs which are often adjacent in the same sessions. The extracted adjacent query pairs were utilized for query expansion [8] and query substitution [11]. We call these methods session-based ap-proaches.

Some other studies focus on mining similar queries from a click-through bipartite constructed from search logs. The basic assumption is that two queries are similar to each other if they share a large number of clicked URLs. After the clustering process, the queries within the same cluster are used as suggestions for each other. We call these meth-ods cluster-based approaches. For example, Beeferman et al. [3] applied a hierarchical agglomerative method to ob-tain similar queries in an iterative way. Wen et al. [19] com-bined query content information and click-through informa-tion and applied a density-based method, DBSCAN [7], to cluster queries. These two approaches are effective to group similar queries, however, both methods have high computa-tional cost and cannot scale up to large data. Baeza-Yates et al. [1] used the k-means algorithm to derive similar queries. The k-means algorithm requires the user to specify the num-ber of clusters, which is difficult for clustering search logs.
There are some other clustering methods such as BIRCH [21] though they have not been adopted in query under-Table 1: A search log as a stream of query and click events. standing. We find, however, those algorithms may not be able to handle the following two challenges. First, many al-gorithms cannot address the X  X urse of dimensionality X  X aused by the large number of URLs in logs. Second, most algo-rithms cannot support the dynamic update of clusters when new logs are available.

The approach developed in this paper has three criti-cal differences from previous ones. First, unlike the exist-ing session-based methods which only focus on query pairs, we consider variable-length contexts of queries, and pro-vide context-aware suggestions. Second, different from the cluster-based methods, we do not simply use queries in the same cluster as candidate suggestions for each other. In-stead, we suggest queries that a user may ask next in the query context, which are more useful than queries simply replaceable to the current query. Finally, instead of using individual queries to capture users X  search intents, our sug-gestion method summarizes queries into concepts.
In this section, we summarize queries into concepts. We first describe how to form a click-through bipartite from search log data, and then present an efficient algorithm which can mine from a very large bipartite.
To group similar queries into a concept, we need to mea-sure the similarity between queries. When a user raises a query to a search engine, a set of URLs will be returned as the answer. The URLs clicked by the user, called the clicked URL set of the query, can be used to approximate the information need described by the query. We can use the clicked URL set of a query as the set of features of that query. The information about queries and their clicked URL sets is available in search log data.

A search log can be regarded as a sequence of query and click events. Table 1 shows an example of a search log. From the raw search log, we can construct a click-through bipartite as follows. A query node is created for each unique query in the log. Similarly, a URL node is created for each unique URL in the log. An edge e ij is created between query node q and URL node u j if u j is a clicked URL of q i . The weight w ij of edge e ij is the total number of times when u j is a click of q i aggregated over the whole log. Figure 2 shows an example click-through bipartite.

The click-through bipartite can help us to find similar queries. The basic idea is that if two queries share many clicked URLs, they are similar to each other [1, 3, 19]. From the click-through bipartite, we represent each query q i as an L 2 -normalized vector, where each dimension corresponds to one URL in the bipartite. To be specific, given a click-through bipartite, let Q and U be the sets of query nodes and URL nodes, respectively. The j -th element of the feature
Figure 2: An example of click-through bipartites. vector of a query q i  X  Q is where u j  X  U and norm ( w ij ) = w ij q P
The distance between two queries q i and q j is measured by the Euclidean distance between their normalized feature vectors. That is,
There are several challenges in clustering queries effec-tively and efficiently in a click-through bipartite. First, a click-through bipartite from a search log can be huge. For example, the data set in our experiments consists of more than 151 million unique queries. Therefore, the clustering algorithm must be efficient and scalable to handle large data sets. Second, the number of clusters is unknown. The clus-tering algorithm should be able to automatically determine the number of clusters. Third, since each distinct URL is treated as a dimension in a query vector, the data set is of ex-tremely high dimensionality. For example, the data set used in our experiments includes more than 114 million unique URLs. Therefore, the clustering algorithm must tackle the  X  X urse of dimensionality X . Last, the search logs increase dy-namically. Therefore, the clustering needs to be maintained incrementally.

To the best of our knowledge, no existing methods can address all the above challenges simultaneously. We develop a new method as shown in Algorithm 1.
 Algorithm 1 Clustering queries.
 1: for each query q i  X  Q do 2: C -Set =  X  ; 3: for each non-zero dimension d of  X  X  X  q i do 4: C -Set  X  = dim array[d]; 9: for each non-zero dimension d of  X  X  X  q i do 11: return  X ;
In our method, a cluster C is a set of queries. The normal-ized centroid of the cluster is  X  X  X  c = norm ( | C | is the number of queries in C . The distance between a query q and a cluster C is given by We adopt the diameter measure in [21] to evaluate the com-pactness of a cluster, i.e.,
We use a diameter parameter D max to control the gran-ularity of clusters: every cluster has a diameter at most D
Our method only needs one scan of the queries. We create a set of clusters as we scan the queries. For each query q , we first find the closest cluster C to q among the clusters obtained so far, and then test the diameter of C  X  X  q } . If the diameter is not larger than D max , q is assigned to C and C is updated to C  X  X  q } . Otherwise, a new cluster containing only q is created.

The potential major cost in our method is from finding the closest cluster for each query since the number of clusters can be very large. One may suggest to build a tree structure such as the CF-Tree in BIRCH [21]. Unfortunately, as shown in previous studies (e.g., [9]), the CF-Tree structure may not handle high dimensionality well: when the dimensionality increases, BIRCH tends to compress the whole data set into a single data item.

How can we overcome the  X  X urse of dimensionality X  and find the closest cluster fast? We observe that the queries in the click-through bipartite are very sparse. For example, in our experimental data, a query is connected with an average number of 8.2 URLs. Moreover, each URL is also involved in only a few queries. In our experiments, the average degree of URL nodes is only 1.8. Therefore, for a query q , the average size of Q q , the set of queries which share at least one URL with q , is only 8 . 2  X  (1 . 8  X  1) = 6 . 56 . Intuitively, for any cluster C , if C  X  Q q =  X  , C cannot be close to q since the distance of any member of C to q is is the farthest distance calculated according to Equation 2 (please note that the feature vectors of queries have been normalized). In other words, to find out the closest cluster to q , we only need to check the clusters which contain at least one query in Q q . Since each query belongs to only one cluster in our method, the average number of clusters to be checked is not larger than 6 . 56 .

Based on the above idea, we use a dimension array data structure (Figure 3) to facilitate the clustering procedure. Each entry of the array corresponds to one dimension d i and links to a set of clusters  X  i , where each cluster C  X   X  contains at least one member query q j such that  X  X  X  q j [ i ] 6 = 0 . As an example, for a query q , suppose the non-zero dimen-sions of  X  X  X  q are d 3 , d 6 , and d 9 . To find the closest cluster to q , we only need to union the cluster sets  X  3 ,  X  6 , and  X  which are linked by the 3rd, the 6th, and the 9th entries of the dimension array, respectively. The closest cluster to q must be in the union.

Since the click-through bipartite is sparse, one might won-der whether it is possible to derive clusters by finding the connected components from the bipartite. To be specific, two queries q s and q t are connected if there exists a query-and URL in the path are connected by an edge. A clus-ter of queries can be defined as a maximal set of connected queries. An advantage of this method is that it does not need a specified parameter D max . However, in our experi-ments, we find that the bipartite is highly connected though sparse. In other words, almost all queries, no matter similar or not, are included in a single connected component. More-over, the path between dissimilar queries cannot be broken by simply removing a few  X  X ubs X  of query or URL nodes as shown in Figure 6. Thus, clusters cannot be derived from connected components straightforwardly.

Although Algorithm 1 is efficient, the computation cost can still be very large. Can we prune the queries and URLs without degrading the quality of clusters? We observe that edges with low weights are likely to be formed due to users X  random clicks, and should be removed to reduce noise. To be specific, let e ij be the edge connecting query q i and u and w ij be the weight of e ij . Moreover, let w i be the sum of the weights of all the edges where q i is one endpoint, i.e., w weight w ij  X   X  abs or the relative weight w ij w  X  abs and  X  rel are user specified thresholds. After pruning low-weight edges, we can further remove the query and the URL nodes whose degrees become zero. In our experiments, we set  X  abs = 5 and  X  rel = 0 . 1 . After the pruning process, the algorithm can run efficiently on a PC of 2 GB main memory for the experimental data.
In this section, we first introduce how to derive session data from a search log. We then develop a novel structure, concept sequence suffix tree , to organize the patterns mined from session data. Finally, we present the query suggestion method based on the patterns mined.
As explained in Section 2, the context of a user query consists of the immediately preceding queries issued by the same user. To learn a context-aware query suggestion model, we need to collect query contexts from user query sessions.
We construct session data in three steps. First, we extract each individual user X  X  behavior data from the whole search log as a separate stream of query/click events. Second, we segment each user X  X  stream into sessions based on a widely-used rule [20]: two consecutive events (either query or click) are segmented into two sessions if the time interval between them exceeds 30 minutes. Finally, we discard the click events and only keep the sequence of queries in each session.
Query sessions can be used as training data for query suggestion. For example, Table 2 shows some real sessions as well as the relationship between the queries in the ses-Table 2: Examples of sessions and relationship be-tween queries in sessions. sions. We can see that a user may refine the queries or explore related information about his or her search intent in a session. As an example, from the last session in Ta-ble 2, we can derive three training examples, i.e.,  X  X okia N73 themes X  is a candidate suggestion for  X  X okia N73 X , and  X  X ree themes Nokia N73 X  is a candidate suggestion for both single query X  X okia N73 themes X  X nd query sequence X  X okia N73  X  Nokia N73 themes X .
Queries in the same session are often related. However, since users may formulate different queries to describe the same search intent, mining patterns of individual queries may miss interesting patterns. To address this problem, we map each session qs = q 1 q 2  X  X  X  q l in the training data into a sequence of concepts cs = c 1 c 2  X  X  X  c l , where a concept c is represented by a cluster C i derived in Section 4.2 and a query q i is mapped to c i if q i  X  C i . If two consecutive queries belong to the same concept, we record the concept only once in the sequence.

How can we mine patterns from concept sequences? A straightforward method can first mine all frequent sequences from session data. For each frequent sequence cs = c 1 . . . c we can use c l as a candidate concept for cs 0 = c 1 . . . c then can build a ranked list of candidate concepts c for cs based on their occurrences following cs 0 in the same sessions; the more occurrences c has, the higher c is ranked. For each candidate concept c , we can choose from the corresponding cluster C the member query which has the largest number of clicks as the representative of c . In practice, we only need to keep the representative queries of the top K (e.g., K = 5 ) candidate concepts. These representative queries are called the candidate suggestions for sequence cs 0 and can be used for query suggestion when cs 0 is observed online.
The major cost in the above method is from computing the frequent sequences. Traditional sequential pattern min-ing algorithms such as GSP [16] and PrefixSpan [15] can be very expensive, since the number of concepts (items) and the number of sessions (sequences) are both very large. We tackle this challenge with a new strategy based on the fol-lowing observations. First, since the concepts co-occurring in the same sessions are often correlated in semantics, the actual number of concept sequences in session data is far less than the number of possible combinations of concepts. Sec-ond, given the concept sequence cs = c 1 . . . c l of a session, since we are interested in extracting the patterns for query suggestion, we only need to consider the subsequences with lengths from 2 to l . To be specific, a subsequence of the con-cept sequence cs is a sequence c 1+ i , . . . , c m + i , where i  X  0 and m + i  X  l . Therefore, the number of subsequences to be considered for cs is only l  X  ( l  X  1) 2 . Finally, the average num-Algorithm 2 Building the concept sequence suffix tree. 7: return T ; 1: if | cs | = 0 then return T .root; 3: if cn == null then 5: return cn ; ber of concepts in a session is usually small. Based on these observations, we do not enumerate the combinations of con-cepts, instead, we enumerate the subsequences of sessions.
Technically, we implement the mining of frequent concept sequences with a distributed system under the map-reduce programming model [6]. In the map operation, each ma-chine (called a process node ) receives a subset of concept sequences as input. For the concept sequence cs of a ses-sion, the process node outputs a key-value pair ( cs 0 , 1) to a bucket for each subsequence cs 0 with a length greater than 1. In the reduce operation, the process nodes aggregate the counts for cs 0 from all the buckets and output a key-value pair ( cs 0 , freq ) where freq is the frequency of cs 0 . A con-cept sequence cs 0 is pruned if its frequency is smaller than a threshold.

Once we get the frequent concept sequences, we organize them into a concept sequence suffix tree (Figure 4). Formally, a (proper) suffix of a concept sequence cs = c 1 . . . c l empty sequence or a sequence cs 0 = c l  X  m +1 . . . c l , where m  X  l ( m &lt; l ). In a concept sequence suffix tree, each node corresponds to a frequent concept sequence cs . Given two nodes cs i and cs j , cs i is the parent node of cs j if cs longest proper suffix of cs j . Except the root node which corresponds to the empty sequence, each node on the tree is associated with a list of candidate suggestions.

Algorithm 2 describes the process of building a concept sequence suffix tree. Basically, the algorithm starts from the root node and scans the set of frequent concept se-quences once. For each frequent sequence cs = c 1 . . . c the algorithm first finds the node cn corresponding to cs c . . . c l  X  1 . If cn does not exist, the algorithm creates a new node for cs 0 recursively. Finally, the algorithm updates the list of candidate concepts of cs if c l is among the top K candidates observed so far. Algorithm 3 Query suggestion.
 1: map qs into cs ; 2: curC = the last concept in cs ; 3: while true do 4: chN = curN  X  X  child node whose first concept is curC ; 5: if ( chN == null ) then break; 7: if ( curC == null ) then break; 8: if curN != T .root then 9: S -Set = curN  X  X  candidate suggestions; 10: return S -Set ;
In Algorithm 2, the major cost for each sequence is from the recursive function findNode , which looks up the node cn corresponding to c 1 . . . c l  X  1 . Clearly, the recursion executes at l  X  1 levels. At each level, the potential costly operation is the access of the child node cn from the parent node pn (the last statement in line 2 of Method findNode ). We use a heap structure to support the dynamic insertion and access of the child nodes. In practice, only the root node has a large number of children, which cannot exceed the number of concepts N C ; while the number of children of other nodes is usually small. Therefore, the recursion takes O (log N time and the whole algorithm takes O ( N cs  X  log N C ) time, where N cs is the number of frequent concept sequences.
Suppose the system receives a sequence of user input queries q  X  X  X  q l . Similar to the procedure of building training ex-amples, the query sequence is also mapped into a concept sequence. However, unlike the queries in the training ex-amples, an online input query q i may be new and may not belong to any concept derived from the training data. More-over, when q i is a new query, no click-through information is available. In this case, the mapping process stops and the concept sequence corresponding to q i +1  X  X  X  q l is returned.
After the mapping procedure, we start from the last con-cept in the sequence and search the concept sequence suffix tree from the root node. The process is shown in Algo-rithm 3. We maintain two pointers: curC is the current concept in the sequence and curN is the current node on the suffix tree. We check whether the current node curN has a child node chN whose first concept is the same as curC . If so, we move to the previous concept (if exists) of curC and visit the child node chN of curN . If no previous concept exists, or no child node chN of curN matches curC , the search process stops, and the candidate suggestions of the current node curN are used for query suggestion. A special case is that curN is the root node when the search process stops. This means no match for the last concept in the concept sequence is found on the suffix tree. In this case, the system cannot provide suggested queries according to the current user input.

The mapping of a query sequence qs into a concept se-quence cs (line 1) takes O ( | qs | ) time. The aim of the while loop (lines 3-8) is to find the node which matches the suffix of cs as much as possible. As explained in Section 5.2, the cost of this operation is O (log N C ) . In fact, when generating suggested queries online, we do not need to maintain the dy-namic heap structure as during the building process of the tree. Instead, we can serialize the children of the root node Table 3: The size of the click-through bipartite be-fore and after pruning. into a static array structure. In this case, the search cost can be reduced to O (1) . To sum up, the time for our query suggestion process is O ( | qs | ) , which meets the requirement of online process well.
We extract a large-scale search log from a commercial search engine as the training data for query suggestion. To facilitate the interpretation of the experimental results, we only focus on the Web searches in English from the US mar-ket . The log contains 1,812,563,301 search queries, 2,554,683,191 clicks, and 840,356,624 query sessions, which involve 151,869,102 unique queries and 114,882,486 unique URLs.
We build a click-through bipartite to derive concepts. As described in Section 4.2, we set  X  abs = 5 and  X  rel = 0 . 1 to prune low-weight edges. Table 3 shows the sizes of the click-through bipartite before and after the pruning process.
It has been shown in previous work (e.g., [2]) that the occurrences of queries and the clicks of URLs exhibit power-law distributions. However, the properties of the click-through bipartite have not been well explored.

Figure 5(a) shows the distribution of the edge weights (please note the x-and y-axes in Figure 5 are in log scale). The distribution follows power law. Therefore, although the pruning process removes 76% edges and 96% nodes, there are still 51 . 1% of the query occurrences and 51 . 7% of the URL clicks remained in the pruned data.

Figure 5(b) shows the number of query nodes versus the degree of nodes. The curve can be divided into three in-tervals. In the first interval (degree ranging from 1 to 10), the number of queries drops sharply from about 300 , 000 to 80 , 000 . This interval consists of the major part ( 73 . 8% ) of the queries. In other words, most queries are associated with a small number of URLs. The second interval (degree spanning from 11 to 200) approximates a power-law distribu-tion. There are about 26 . 2% queries falling in this interval. This means a small part of the queries are associated with a moderate number of URLs. The last interval (degree be-tween 201 and 600) includes only 22 queries. It would be interesting to further study how such a degree distribution is formed, though it is beyond the scope of this paper. The average degree of query nodes is 8.2.

Figure 5(c) shows the number of URL nodes versus the degree of nodes. The curve fits a power-law distribution well. The average degree of URL nodes is 1.8. The curves in Figure 5(b) and (c) illustrate why the clustering algorithm in Section 4.2 is efficient: since the average degrees of query and URL nodes are both low, the average number of clusters to be checked for each query is small.

We then explore the connectivity of the click-through bi-partite. First, we find the connected components in the nodes. bipartite and plot the number of connected components ver-sus the number of queries in the components (Figure 6(a)). The bipartite consists of a single large connected component (about 88 . 6% of all queries) and many small connected com-ponents (with size from 1 to 20). We further test whether the large connected component can be broken by removing a few  X  X ubs X , i.e., nodes with high degrees. To do this, we keep removing the top 1%, 2%, . . . , 99% query nodes with the largest degrees and measuring the percentage of the size of the largest component over the total number of remain-ing query nodes. Figure 6(b) shows the effect of removing top degree query nodes. We can see the percentage of the queries held by the largest component gradually drops when more top degree query nodes are removed. However, even when half of the query nodes are removed, the largest com-ponent still holds about one third of the remaining query nodes. This suggests that the click-through bipartite is highly-connected, and the cluster structure cannot be ob-tained by simply removing a few  X  X ubs X . Figure 6(c) shows the effect of removing the top degree URL nodes. Removing the top degree URL nodes can break the largest connected component faster than removing the top degree query nodes. However, removing the URL nodes loses the correlation be-tween queries since the URLs are considered as the features of queries.

We apply the clustering algorithm on the pruned click-through bipartite with D max = 1 and obtain 218,673 clus-ters with size  X  2. These clusters cover 707,797 queries while the remaining queries form singleton clusters.
After clustering queries, we extract session data to build the concept sequence suffix tree as our query suggestion model. Figure 7 shows the distribution of session lengths. We can see that it is prevalent that users submit more than one query for a search intent. That means in many cases, the context information is available for query suggestion. Table 4: The number of nodes on the concept se-quence suffix tree at different levels.

We then construct the concept sequence suffix tree as de-scribed in Section 5.2. Each frequent concept sequence has to occur more than 5 times in the session data. Table 4 shows the number of nodes at each level of the tree. Note we prune the nodes containing more than 4 concepts (349 nodes pruned in total), since we find those long patterns are not meaningful and are likely to be derived from query sequences issued by robots.
We compare the coverage and quality of the query sugges-tions generated by our approach, called the context-aware concept-based approach or CACB for short, with the follow-ing two baselines.

Adjacency . Given a sequence of queries q 1 . . . q i , this Figure 8: The coverage of the three methods on (a) Test-0 and (b) Test-1.
 Figure 9: The quality of the three methods on (a)
Test-0 and (b) Test-1. method ranks all queries by their frequencies immediately following q i in the training sessions and outputs top queries as suggestions.

N-Gram . Given a sequence of queries qs = q 1 . . . q i , this method ranks all queries by their frequencies of immediately following qs in training sessions and outputs top queries as suggestions.

We extract 2,000 test cases from query sessions other than those serve as training data. To better illustrate the effect of contexts for query suggestion, we form two test sets: Test-0 contains 1,000 randomly selected single-query cases while Test-1 contains 1,000 randomly selected multi-query cases.
The coverage of a query suggestion method is measured by the number of test cases for which the method is able to provide suggestions over the total number of test cases. Figures 8(a) and (b) show the coverage of the three meth-ods on Test-0 and Test-1, respectively. The CACB method has a higher coverage than the other two methods on both test sets, and the N-Gram method has the lowest cover-age. Given a test case qs = q 1 . . . q i , the N-Gram method is able to provide suggestions only if there exists a session qs 1 = q 1 . . . q i q i +1 . . . q l in the training data. The Adjacency method is more relaxed; it provides suggestions if there ex-ists a session qs 2 = . . . q i q i +1 . . . q l in the training data. Clearly, qs 1 is a special case of qs 2 . The CACB method is the most relaxed. If no session such as qs 2 exists in the training data, then the Adjacency method cannot provide suggestions. However, as long as there exists any sequence qs 2 = . . . q 0 i q i +1 . . . q l in the training data such that q q belong to the same concept, the CACB method can still provide suggestions.

Another trend in Figures 8(a) and (b) is that for each method, the coverage drops on Test-1, where the test cases contain various lengths of context. The reason is that the longer the context is (the more queries a user submits), the more likely a session ends. Therefore, the training data avail-able for test cases with context are not as sufficient as those for test cases without context. In particular, the coverage of the N-Gram method drops drastically on Test-1, while the other two methods are relatively robust because the N-Gram method depends more on training examples.

We then evaluate the quality of suggestions generated by our approach and the two baselines. For each test case, we mix the suggested queries ranked up to top 5 by individual methods into a single set. We then ask human judges to label for each suggested query whether it is meaningful or not. To reduce the bias of judges, we asked 10 judges with or without computer science background. Each suggested query is labeled by at least three judges.

If one suggested query provided by a method is judged as meaningful, that method gets one point; otherwise, it gets zero point. Moreover, if two suggested queries provided by a method are both labeled as meaningful, but they are near-duplicate to each other, then the method gets only one point. The overall score of a method for a particular query is the total points it gets divided by the number of suggested queries it generates. If a method does not generate any suggested query for a test case, we skip that case for the method. The average score of a method over a test set is then the total score of that method divided by the number of cases counted for that method. Figures 9(a) and (b) show the average scores of the three methods over the two test sets, respectively.

Figure 9(a) shows that, in case of no context information, the suggestions generated by the Adjacency method and the N-Gram method have the same quality, since the N-Gram method reduces to the Adjacency method in this case. The CACB method shows clear improvement in suggestion qual-ity. This is because the CACB method considers the sugges-tions at the concept level and recommends queries belonging to related but not exactly the same concept with that of the current query (see the first two examples in Table 5).
Figure 9(b) shows that, in cases when context queries are available, the CACB method and the N-Gram method are better than the Adjacency method. This is because the first two methods are context-aware and understand users X  search intents better. Moreover, the CACB method provides even better suggestions than the N-Gram method (see the last two examples in Table 5). This is because the CACB method considers users X  search intents at the concept level instead of the detailed query level.
We test the robustness and the scalability of our algo-rithms. We first compare the suggestions generated under various values of parameter D max . To be specific, given a test case, let S 1 and S 2 be the suggestions generated under two parameter values. We define the similarity between S 1 ity between the suggestions generated under default value D max = 1 and those under various values. The cluster-ing results do not change much under different parameter settings. Figures 10(b) and (c) show the scalability of the algorithms of clustering queries (Algorithm 1) and building the concept sequence suffix tree (Algorithm 2). We run the algorithms on 10%, 20%, . . . , 100% of the entire data to il-lustrate the trend of scalability. Both algorithms are almost linear to the input size. building the concept sequence suffix tree (Algorithm 2).
In this paper, we proposed a novel approach to query sug-gestion using click-through and session data. Unlike pre-vious methods, our approach considers not only the cur-rent query but also the recent queries in the same session to provide more meaningful suggestions. Moreover, we group similar queries into concepts and provide suggestions based on the concepts. The experimental results on a large-scale data containing billions of queries and URLs clearly show our approach outperforms two baselines in both coverage and quality.
