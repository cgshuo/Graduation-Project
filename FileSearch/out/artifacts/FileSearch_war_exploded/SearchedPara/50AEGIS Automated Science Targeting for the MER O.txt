 TARA A. ESTLIN, BENJAMIN J. BORNSTEIN, DANIEL M. GAINES, ROBERT C. ANDERSON, DAVID R. THOMPSON, MICHAEL BURL, REBECCA CASTA  X  NO, and MICHELE JUDD, The Mars Pathfinder (MPF) and Mars Explora tion Rover (MER) missions have demon-strated that mobile rovers are a viable and productive option for exploring the sur-face of other planets. The MER rovers have traveled over many kilometers of terrain and survived harsh planetary conditions, including Martian winters and major dust storms, to continue collecting data. The mission X  X  extensive scientific observations have uncovered profound new insights into Mars X  X  current and past environment, the his-tory of its rocks, and the various roles and abundances of water [Squyres and Knoll 2005].

Surface rovers offer scientists the ability to move around a planetary surface and explore different areas of interest. Advances in rover mobility have increased daily traverse range and with it, the opportunity for scientific discovery. While the Sojourner rover traveled a distance of approximately 100 meters in the entire mission, the two MER rovers (Spirit and Opportunity) have now traveled over 27 kilometers combined. Long traverses have become commonplace on the Opportunity rover. Currently Opportunity is trying to reach a new scientific target X  X he Endeavour crater (shown in Figure 1). The distance to Endeavour from Opportunity X  X  current position (  X  11 kilometers) is more than half the 20 kilometer distance Opportunity has traveled since landing in 2004. Many long drives will be used to reach this target over a several year time period.

Unfortunately, communications bandwidth has not grown as fast as rover traverse range. As rover traverse distances continue to increase with each mission, the quantity of data that can be returned to Earth per meter traversed is reduced. Thus, much of the terrain the rover visits on a long traverse may never be examined by scientists. This article discusses a system developed to autonomously recognize and characterize high value science targets during and after drives without requiring large amounts of data to be transmitted to Earth.

The Autonomous Exploration for Gathering Increased Science (AEGIS) system pro-vides automated targeting for remote-sensing instruments on the Mars Exploration Rover (MER) mission. Currently, targets for remote-sensing instruments, especially narrow field-of-view instruments, must be selected manually based on wide angle im-agery already on the ground with the operations team (i.e., with Earth-based mission control). Examples of narrow field-of-view instruments include the MER Miniature Thermal Emission Spectrometer (Mini-TES), the MER Panoramic Camera (especially when collecting subframed images), and the 2011 Mars Science Laboratory (MSL) Laser-Induced Remote Sensing for Chemi stry and Micro-Imaging (ChemCam) spec-trometer. AEGIS enables the rover flight software to autonomously analyze imagery onboard, select a target based on scientist input, and carry out remote-sensing obser-vations in an opportunistic fashion.

AEGIS operates by analyzing MER navigation camera images to identify terrain features of interest, which are typically rock s with certain characteristics. Scientists on the ground specify these target characteristics in the command sequence sent to the rover. For example, scientists could request measurements of large rocks with high spectral reflectance. Once a target is identi fied onboard in a navigation camera image, its location is determined and a remote-sensing instrument is repointed to collect high-resolution followup data. Currently, AEGIS is run at the end of traverses when images of the new terrain have not yet been downlinked to Earth. This capability is especially useful for multi-sol (i.e., multi-day) plans where a drive occurs on the first sol and only untargeted remote sensing can be performed on the second and third sols, since another communication cycle with Earth have not yet occurred.

AEGIS was uploaded to the MER Opportunity rover in December 2009. The system passed checkout tests onboard Opportunity and is fully operational. On Opportunity, AEGIS is used to collect high-resolution, multispectral images of selected targets us-ing the narrow field-of-view Panoramic ca mera. AEGIS X  X  autonomous targeting ca-pabilities enable the rover to collect a subframed image tightly focused on the target of interest and the immediate surrounding area. As a result, AEGIS provides the ability to collect high-quality data on a target of interest while conserving downlink volume. Further, if no target is found to match the scientists X  interest, then no data is collected.

In this article, we provide an overview of the AEGIS automated targeting sys-tem. We first describe the general steps used by AEGIS to select new targets and autonomously collect new data of those targets as part of the MER onboard flight soft-ware. Next, we discuss each of the compon ents in more detail and describe how AEGIS was integrated and tested with the MER flight software. We then discuss results from AEGIS X  X  use onboard the MER Opportunity rover. Finally, we discuss related work and mention some potential future directions for AEGIS expansion. The AEGIS system enables autonomous operation of science instruments that target specific terrain features, especially rocks, with certain properties. A number of rover remote-sensing instruments have a very narrow field-of-view and thus require selec-tion of specific focused targets for data collection. Selecting targets for these instru-ments has traditionally been a lengthy process. Typically, scientists would manually identify the interesting targets in context images that have already been downloaded on a previous sol. These context images a re collected with wide field-of-view (FOV) cameras, such as the MER navigation came ras, which have a 45-degree FOV, or the MER panoramic cameras in a full-frame low-resolution (single-filter) mode using a 16-degree FOV. After reaching the end of a traverse, the rover performs only untargeted data collection until the context images can be downlinked, analyzed, and new mea-surement commands uplinked. At best, this will happen on the next sol, and it may require the rover to remain at the same location for several sols. Further, it may never happen if it is decided the rover should immediately proceed to a new location due to other goals or engineering constraints.
 AEGIS was designed to provide additional image data for the mission scientists. By analyzing image data onboard, within the power and computational constraints, AEGIS can autonomously select targets for onboard instruments and execute a set of measurement activities. The capabilities of AEGIS are presently being demon-strated on the MER Opportunity rover by taking additional measurements with the Panoramic camera in a quarter-frame high-quality (multiple-color filter) mode, which uses a 4-degree FOV.

The MER Mini-TES spectrometer is another example of a limited FOV instrument where the AEGIS automated targeting technology would be beneficial. The Mini-TES has a FOV of 8 X 20mrad. Unfortunately, since the MER rovers have been in operation for over six years, the Mini-TES instrument on the Opportunity rover is not currently functional. For this reason, AEGIS has used MER panoramic cameras exclusively. On afutureMSLrovermission,AEGIScouldbeusedtoselecttargetsthattheChemCam spectrometer instrument should sample at the end of a long rover drive.

AEGIS is run as part of the MER onboard flight software, which imposes strict computational and resource constraints. All AEGIS components run onboard the MER 20MHz RAD6000 flight processor, which has an early PowerPC instruction set, with 128MB of RAM and 256MB flash memory. Even though it processes full-frame images of over 1MB each, AEGIS was required to run using less than 4MB of total RAM to ensure other onboard processes were not impacted. Time efficiency was another important limitation on the complexity of image analysis algorithms, since operations requiring a fraction of a second on a modern commercial processor could easily take tens of minutes on the MER flight processor. Operator-modifiable time limits allow controllers to specify the maximum duration of AEGIS processing; any run exceeding this allowed time will terminate early without affect. The AEGIS target selection process typically runs in less than 15 minutes on the MER processor. (On a quad-core 3.0GHz Intel Core 2 with 8GB of memory, AEGIS requires less than one second to process a typical image.)
AEGIS was originally developed as part of a large autonomous science frame-work called OASIS (Onboard Autonomous Science Investigation System) [Castano et al. 2007]. OASIS is designed for use onboard a rover to identify and react to serendipitous science opportunities by analyzing the data collected by the rover and then, using machine learning techniques, prioritizing the data based on criteria set by the science team. This prioritization can organize the data for transmission back to Earth or search for specific targets specified by the science team. If one of these specified targets appears, the system attempts to act on the new science opportunity by taking new instrument measurements. The AEGIS technology focuses on this second task of using onboard data analysis to acquire new instrument data on science targets, typically rocks, which have been identified in an opportunistic fashion.

AEGIS performs seven major steps to autonomously acquire new targeted data on an interesting science target. These st eps are shown in Figure 2 and described as follows.  X  Acquire an image with the MER navigation camera. Scientists and other sequence team members select image parameters, s uch as the pointing direction and reso-lution, during the AEGIS sequencing process. The navigation camera is typically pointed at a terrain area where potential science targets may be in view.  X  Analyze the navigation camera image for potential terrain targets .Targetsfor AEGIS typically correspond to rocks . AEGIS uses an algorithm called R OCKSTER to look for enclosed boundary contours (defined by intensity edges) in grayscale im-agery. This algorithm is further detailed in Section 2.2.  X  Extract relevant target features. AEGIS calculates a set of target features (or proper-ties) for each candidate rock. These properties include measures of size, reflectance, shape, and rock location.  X  Prioritize targets and select top target . This component uses a prioritization algo-rithm to analyze rock property data and determine a top candidate. Scientists pro-vide a  X  X arget rock signature X  in the command sequence. This signature specifies what property values are of interest in the local terrain. Example signatures are high reflectance, round shape, large r ocks with high eccentricity, etc.  X  Determine 3D target pointing requirements. After identifying the best scoring can-didate rock, AEGIS selects a center poin t on the target using an inscribed circle method.  X  Point remote sensing instrument. AEGIS points the panoramic cameras at the new target using the resulting center point.  X  Acquire new data. AEGIS acquires additional data with the panoramic cameras.
The ground sequencing team can preselect the exact filters and other imaging pa-rameters to use for each individual run. Typical command sequences take a quarter-framed, multiple-filter image with both left and right cameras. The rover downlinks these opportunistic images with other standard data products.
 The next few sections provide additional details on these system components. AEGIS uses the R OCKSTER algorithm to identify a set of targets in the initial navigation camera image. R OCKSTER identifies edge segments in grayscale imagery and searches for objects with an enclosed bo undary. Such objects typically correspond to rocks when looking at the Mars terrain bu t could also correspond to small craters or other terrain features. R OCKSTER initially locates partial boundary contours of targets using a procedure similar to the Canny edge detector [Canny 1986]. Specif-ically, R OCKSTER calculates the intensity gradient over the image. Ridges in the intensity gradient are linked together using non-maximum suppression, hysteresis thresholding, and edge following, yielding a set of raw contours.

This initial set of contours does not directly provide a usable segmentation of the rocks from the background due to various problems, including spurious contours from the sky-ground boundary (horizon line) and texture within individual rocks and the background. R OCKSTER attempts to resolve these problems by splitting the initial contours into low-curvature fragments.

A gap-filling mechanism joins nearby contour fragments whose endpoints lie within a predefined radius. The final step is to regroup the edge fragments into coherent contours, which is accomplished through background flooding. Figure 3 shows a high-level view of the process that R OCKSTER uses to detect and generate usable target contours.

R OCKSTER distinguishes a variety of Martian geologic features including outcrop, cobbles, boulders, and sediment. While detecting many of these features is a natural fit to R OCKSTER image segmentation approach, the detectability of outcrop may be less obvious. Outcrop is often distinct in intensity from surrounding regolith, making for well defined edges. However, since portions of each outcrop can be obscured by small amounts of soil debris, detected edges have a tendency to fragment into smaller edge segments. The R OCKSTER gap-filling procedure rejoins many of these disconnected segments. In contrast, stereo imaging and range-based techniques pose a number of detection challenges, as outcrop is often flush with the surrounding terrain and there-fore does not present significant depth discontinuities.

For automated targeting of limited FOV instruments, false detections are costly and high precision is important. Thus, for this application, R OCKSTER is typically run in a mode that reduces false positives; however, this also has the effect that fewer overall targets are found. This behavior is a trade-off that can be adjusted depending on the application, that is, for some applications it may be more important to find a larger percentage of the true targets despite the higher risk of returning some false positives (i.e., non-interesting targets). The sequencing team can also choose to limit target detection to specific rectangular sub regions of the image. This option is useful for excluding image regions that contain the deployed rover arm, rover tracks, or other features that could generate spurious detections.

Due to the limited processing capacity and memory available onboard the MER rovers, R OCKSTER relies on techniques that can perform quickly and robustly in such an environment. Image preprocessing, in particular, smoothing reduces the total num-ber of edge elements detected. Considering fewer edges saves considerable computa-tional effort in downstream gap-filling and contour following. R OCKSTER also tracks a number of internal space and time complexity measures related to the overall seg-mentation computation. As a measure of last resort, if these limits are exceeded, R
OCKSTER and AEGIS terminate gracefully, but prematurely. While not ideal for meeting science objectives, monitoring and bounding the usage of precious onboard computational resources that correlate di rectly to mission timelines and available power is essential.

Although AEGIS is using terrain targets identified from monocular grayscale im-agery, the overall approach is not tied to any particular type of target, data source, or instrument type. For example, the general OASIS system has been applied to ana-lyze spectrometer data as well as identifying atmospheric targets, such as clouds and dust-devils, in MER imagery [Castano et al. 2006, 2007]. Once candidate targets are identified, the AEGIS system computes numerical at-tributes corresponding to properties of each target image region. Some examples of these properties are shown in Figure 4.

Surface Reflectance. The surface reflectance (or albedo) of a target is an indicator of the integrated reflectance properties of a targ et X  X  surface. The reflectance properties of a rock can provide important information about its mineralogical composition. AEGIS measures surface reflectance by computing the mean gray-scale value of the pixels within the target. Note that this value can be affected by shadowing, so the calculation does not provide a perfect measure of physical surface albedo. However, it provides some useful information about surface prope rties. It has proved use ful for discriminat-ing between shaded rocks protruding above the sediment and flat rock outcrop that generally appears brighter to the sensor. AEGIS calculates additional moments of the pixel intensity distribution, including variance, skew, and kurtosis; these higher mo-ments serve as a rough proxy for texture. Examples of rocks with varying reflectance are shown in Figure 4.

Size. One of the most important properties of rocks on the surface is their size, which can be used to identify sorting and geologic contacts. Several features describe the target size. The pixel area of the rock is one simple measure. AEGIS also calculates the radius of the largest inscribed circle that fits within the contour. It computes this latter measure efficiently using an image distance transform. A third measure of size is the length of the semimajor and semiminor axes of the best fitting ellipse. AEGIS fits an ellipse to the rock X  X  outline using a least-squares criterion [Fitzgibbon et al. 1999; Halir and Flusser 1998]. Unfortunately, AEGIS does not have access to range data on the acquired navigation camera images. Thus stereo information could not be used to determine true target size, though it has been used in other versions of the system.

Shape. Although the shape of a rock is complex and often difficult to describe, sig-nificant geologic information can be extracted from this property to better understand provenance (source of material) and environmental conditions. Various shape param-eters are used to classify rocks in terrestri al studies, including elongation (or aspect ratio), ruggedness (or angularity), and sur face area. AEGIS uses the eccentricity of the fit ellipse as well as a ruggedness score based on the square of the perimeter divided by the contour X  X  pixel area [Hentschel and Page 2002].

Pixel Location. The x and y coordinates of the ellipse centroid and inscribed circle are also treated formally as features. Incorporating these values in the feature vector lets operators favor or exclude candidates based on their position in the image. (Note that masking out the rover deck or solar panel when it appears in images is performed as a separate process.) Once features are computed for identified targets, AEGIS next prioritizes candidate targets and selects a top target. To guide the prioritization process, AEGIS uses a pre-specified target signature corresponding to particular feature attributes (e.g., prefer rocks that are large in size and have high reflectance) provided by the MER science team during ground sequencing. This algorithm enables scientists to efficiently and easily stipulate the importance of each particular feature. For each run of AEGIS, scientists can specify one target signature but can change this signature each time the system is run. AEGIS gives each candidate target a score f corresponding to a weighted sum of up to two feature values x1 and x2. Two coefficients  X  1 and  X  2 control whether the algorithm prefers high or low feature values, while a weighting coefficient  X  describes the comparative importance of the second feature. Note that one need not specify a second feature at all, in which case  X  =0.Wehave. Earlier versions of AEGIS allowed an arb itrary number of features to be used in the preceding function and multiple targets; however, due to limitations on the number of parameters available for the AEGIS commands on MER, the number of features for each run was limited to two for the MER deployment of AEGIS.

Scientists can also specify a filter that re moves from consideration any target where the value of a specified feature falls outside a threshold (either above or below). This is useful for excluding targets that are likely spurious detections, such as very small rocks or objects in the distant background. The sequencing team sets all feature selec-tion and filter parameters manually and can change them each time AEGIS is used. In addition to feature-based filtering, AEGIS can optionally remove all contours that intersect the known locations of the rover deck. Deck masking projects a polygonal model of the rover solar panels and High Gain Antenna into the image. Operators can instruct AEGIS to ignore any contour that intersects this image area. This step is im-portant, because the solar panels and antenna contain many closed features and sharp edges that may be detected and labeled as targets.

AEGIS selects the top target from the filtered candidates and uses it to acquire new targeted data. Figure 5 shows two potential targets selected in MER navigation cam-era images with selection criteria favoring large size (on the left) and round shape (on the right). In both cases the AEGIS target finder is run in a mode that decreases the number of false positives (e.g., a shadowed area of sand) but finds fewer of the overall rocks in the image. Several software tools and documentation manuals are available to help the sequencing team select appropriate target signature and filter parameters for different AEGIS runs. Further, several standard profiles have been developed that can be used to find common occurrences (such as outcrop or loose surface rock). Once AEGIS selects a top target, it commands a dditional science measurements. First, it selects a center point on the target using the center point of the largest inscribed cir-cle that fits within the target contours. The software then points the MER panoramic left and right cameras at the target.

The type of follow-up observations of the top target are defined in advance by the ground team but can be set each time the AEGIS capability is used. Typically, AEGIS is used to collect multiple-filter, subframed images with both left and right panoramic cameras. This approach provides high quality images that are smaller in size due to subframing and thus less expensive to downlink. The resulting panoramic camera images are downlinked with other standard MER data products for that sol.

The ground team preallocates resources such, as power, time, and onboard memory, whenever AEGIS is scheduled to ensure that sufficient resources exist onboard to col-lect the new data. This approach ensures tha t the correct resources and required rover states are fully verified before any extra activities are commanded. However, since it is possible that AEGIS might not find any unfiltered, unmasked targets (e.g., if an image contains only dunes), a more optimal approach would be to allocate resources only if a good target was actually found. The original AEGIS system contained an automated planning and scheduling system that could perform this allocation dynamically only if and when a new science target is found [Estlin et al. 2008]. Due to computing re-quirements, the planning component was not used in the final version of AEGIS for the MER mission. However, we hope to use it in future versions of AEGIS. We faced a number of constraints and challenges when integrating AEGIS with MER mission flight software. Due to funding and time limitations, we did not have the option of creating a new version of MER flight software that included AEGIS, which is how past new software technology updates to the mission had been performed. Instead, we developed AEGIS as a standalone software module that coopts an existing onboard autonomy technology to enable AEGIS to be commanded and executed. We also delegated part of the AEGIS response to a third onboard autonomy technology, visual target tracking (VTT), for mast motion and pointing. The standalone nature of AEGIS and its use of and delegation to other established MER autonomy technologies afforded a more manageable integration and test effort.

AEGIS is designed as a standalone software object module that is loaded into rover memory prior to each use and unloaded from memory after each use. This loading pro-cess takes less than 30 seconds to complete, and the unloading process is performed automatically through normal operations, since the MER Opportunity rover comput-ers are shutdown and restarted several times each sol. Once the AEGIS software is loaded, it leverages previous MER autonomy technology developments [Hayati et al. 2007]. In particular, it uses the same interface as for the MER dust devil detection software [Casta  X  no et al. 2008], which shares several similarities with AEGIS, includ-ing providing rover autonomy capability and analyzing navigation camera imagery for targets of interest. The particular sequencing command used to execute AEGIS has 33 algorithm parameter command arguments that we are able to map to the specific needs of the AEGIS algorithm, including speci fying science criteria for prioritizing tar-gets. We were also able to use previously designed telemetry data to report AEGIS run statistics and up to ten image locations that bound detected targets.

Figure 6 highlights AEGIS X  X  interaction with MER flight software components. Al-though AEGIS does not actually drive the rover, the mobility module is well suited for running autonomy algorithms, such as AEGIS. The design of MER flight software, including the roles of flight software tasks and task priority levels, allows the mobil-ity task to run computationally intensive algorithms, such as hazard detection and visual odometry, without compromising the ability of other flight software tasks from meeting time-critical deadlines. When AEGIS is used, the operations team prepares a sequence specifying where to point the navigation camera in order to collect the image that AEGIS will process along with a specification of the type of targets the science team is interested in for this run. When the AEGIS command is executed by the rover, the MER mobility module coordinates with other flight software components to acquire the appropriate navigation camera image and then runs the AEGIS target detection algorithm passing in a pointer to the acquired image. In addition, the mobility module provides convenient access to memory-management capabilities used by AEGIS. While running, AEGIS interacts with a few other flight software components. AEGIS uses the timing service to periodica lly check the current spacecraft time. When the operations team sequences AEGIS, they can specify how long AEGIS is allowed to run or a specific time by which AEGIS must complete. This is an important feature for allowing an autonomous algorithm to be used operationally, as it gives the operations team the ability to set hard constraints on the timing of AEGIS, which allows them to schedule AEGIS around other activities X  X ncluding other science observations, com-munication passes, or planned rover shutdowns X  X s well as to ensure the algorithm complies with resource allocations made o n the ground. If AEGIS detects that it has approached its deadline, it will give up its search for targets and exit gracefully. AEGIS also queries the imaging flight software component to determine the current viewing angle of the navigation camera. Using this information, AEGIS is able to mask out regions of the image, as explained in Section 2.4.

One of the last steps of the AEGIS process is to acquire a followup measurement of the top target with a high-resolution, narro w field-of-view science instrument. Unless the top AEGIS target happens to be centered in the science instrument X  X  field-of-view, this follow-up measurement requires some motion on the part of the rover mast. To acquire the follow-up measurement, AEGIS leverages another piece of onboard auton-omy technology, a visual target tracking (VTT) system [Kim et al. 2009].

In order to center the MER panoramic camera on a select target, AEGIS uses the following process. First, AEGIS determines a two-dimensional image (pixel) location for its top target. This location is communicated to the onboard VTT subsystem as a seed (initial) point. After AEGIS seeds VTT, the AEGIS target detection algorithm completes. The onboard sequence containing the call to the AEGIS command then calls VTT to acquire a stereo image pair and compute a three-dimensional location and distance-to-target from the two-dimensional seed point. If VTT succeeds in determin-ing the target in space, a pointing sequence is called which uses the distance-to-target and known rover mast geometries to center the target in the panoramic camera field-of-view. With the panoramic camera centered on the top AEGIS target, additional measurements, dictated by a sequence of commands, can be acquired. By placing the follow-up imaging in a sequence, the operations team can easily change the type of follow-up imaging acquired for the selected target on each run. For example, if, on a given day, data is extremely limited, the operations team can prepare a follow-up sequence that uses only a small number of panoramic camera filters and employ higher levels of compression. If data is more plentiful, the follow-up sequencing could include many filters and make use of loss-less compression of the images.

In addition to integrating the AEGIS with flight software components, the AEGIS detection algorithm itself was optimized in order to be effectively deployed on Oppor-tunity. In particular, the algorithm was modified to run more efficiently and to require less memory. The original version of the target detection algorithm consumed 64MB of memory but was ultimately reduced to 4MB to fit within our allotted onboard memory budget. This modification resulted in no appreciable difference in selection of a top target but did result in a small increase in overall algorithm runtime. AEGIS was extensively tested before being approved for upload to the MER mission Opportunity rover. The AEGIS test plan includ ed several levels of testing at increasing levels of system integration. At the lowest level were unit tests, used to verify the behavior of individual functions, followed by regression tests, and rover system-level tests with both avionics simulators, and eventually, full rover hardware. The AEGIS code was also regularly scanned for errors with the Coverity Prevent TM [Bessey et al. 2010] static source code analysis tool. The entire source code underwent three separate peer reviews by AEGIS developers, MER flight software developers, and JPL flight software and autonomy technology developers who were not familiar with the software intricacies of either AEGIS or MER.

Unit tests were automated and run regularly as part of the normal development cycle and nightly build process. Whenever functions were updated, all unit tests were run to identify any negative ripple effects that could have been caused by the code change. As each bug was discovered, a unit test was written that fails in order to prove the existence of the bug. The passage of this unit test then proved the bug has been fixed and also guarded against the inadvertent reintroduction of the same bug at a later time. When AEGIS software development was finished, low-level functionality was verified by 348 unit tests.

Regression tests, also automated and run as part of the nightly build process, were used to verify correct end-to-end algorith m behavior. To assemble the regression test set, we collected 246 MER navigation camera images. The images represent a broad sampling of the various geologic terrain types both MER rovers have encountered throughout their long missions (e.g., cobbl es, dunes, craters small and large, outcrop and regolith, etc.). Before regression testing began, we ran a series of performance tests and parameter tunings on this image suite. In particular, we used this image set to select parameter defaults for steps, such as smoothing level and gap-filling dis-tance, so the system could operate robustly on future images. By including images from a broad range of terrain types, we attempted to safeguard the system from being overly tuned for any one specific terrain category. In addition to running regression tests on our build server and development workstations, we adapted our software test harness to work with the MER avionics simulators. This proved invaluable in quickly identifying subtle issues caused by comp iler and hardware platform differences.
When algorithm development was complete and the AEGIS had been well tested in isolation, we froze (did not modify) the AEGIS code in order to proceed with system-level tests. The purpose of these tests was to verify the AEGIS algorithm in the context of MER mission flight software and the entire rover hardware system. The first set of tests was in the MER avionics simulator environment and the second with full rover hardware situated in a building-sized Martian-like terrain sandbox. The full hardware testbed is shown in Figure 7. Tests conducted at this level were of the highest possible fidelity. Each test was driven by onboard sequences similar to those used daily by the MER tactical operations teams. This is also when we developed our initial Martian surface checkout sequences (see Section 5). Test input was obtained from both onboard sequences and navigation camera hardware. Test output was en-coded as standard MER data product telemetry and flowed through a UHF downlink from the engineering rover hardware to our test workstation. In this environment, we verified AEGIS either functioned correctly or degraded gracefully and, in either case, without harming the rover system. We tested a variety of situations, including nominal operations, off-nom inal parameters, reduced me mory availability, stress tests, and multiple types of preempted and interrupted operations. After a MER project software review board examined our test plans, procedures, and results, we were given final approval to begin planning and coordinating the uplink of AEGIS software to the MER mission Opportunity rover. The AEGIS software was uploaded to the MER mission Opportunity rover in Decem-ber of 2009. Over the next few months, a series of checkout steps was performed to exercise different AEGIS components. All of these checkout steps executed success-fully. Figures 8 and 9 show the result of the final checkout, which was run in March 2010 and was the first time all AEGIS components were exercised together onboard the Opportunity rover. During this run, Opportunity was located near the Mars Concepci  X  on Crater. The analyzed navigation camera image contained a scattering of loose crater ejecta, providing a number of potential targets. For this run, the sequenc-ing team parameterized AEGIS to look for targets of large size and low reflectance. Figure 8 shows the top target selected (indicated by the yellow marker) and other targets that comprise the top ten ranked targets (indicated by the blue markers). Note that AEGIS does not downlink the detected target contours due to telemetry constraints.

Figure 9 shows the resulting panoramic camera image taken of the top target. Over-all, these results were excellent. All syst em components were run successfully with no errors. All top ten targets were good selections that matched the specified target signa-ture. Further, the resulting panoramic images nicely captured the top target, showing that the automated pointing and data acquisition components of the systems were operating correctly.

As of March 2010, AEGIS has been run sixteen times on Mars (Table I) and has regularly chosen appropriate targets based on the specified target signature profile. On most runs, AEGIS has successfully detected either rock outcrop or loose rocks that were likely crater ejecta. For example, Fig ure 10 shows the target selection results of sol 2221 where the system identified a number of rock outcrop targets in an area primarily dominated by sand dunes. In one run (sol 2204), there were no rocks in the navigation camera image, but the system did detect targets consisting of compressed sediment features in rover tracks. Detecting tracks as potential targets is a known be-havior and in some cases, can be arguably appropriate, since interesting MER science discoveries have been made on disturbed material in rover tracks. In this particular case, tracks were not expected in the image (the drive faulted out early during a turn maneuver and in an unexpected location), thus the track detections could be consid-ered false positives.

On several runs (sols 2332 and 2407), only soil was visible in the image, and AEGIS correctly returned a result of no targets found. False positives have also occurred. On sol 2325, cable pulls on the rover deck were detected when they slightly extended outside of the deck masking polygon in the image field-of-view. On sol 2428, AEGIS was allowed to consider very small targets (less than 25 pixels), and found a set of very small false positive targets. In both these runs, no significant rocks were in the scene, and AEGIS parameters have been modifie d since to prevent similar occurrences.
During these runs, AEGIS has also shown its ability to not only collect interesting science data, but also to save valuable operation time. On sol 2550, AEGIS detected several large boulders, which were of high interest to the science team. Because the system had already collected a multiple-color filter panoramic image of these targets, the operations team was able to devote more time in the next sol X  X  plan to driving and other science activities that would have been shortened if the AEGIS data had not been collected. Future runs should provide additional data with which to further evaluate system performance. The MER mission plans to continue the use of AEGIS to enable automated targeting for the MER panoramic camera.

This article is intended to report on our experience and results gathered during actual flight usage. Related publications discuss comparisons of R OCKSTER to other approaches for image rock detection [Thompson and Castano 2007] and a study that compared a separate rock finding approach (explored as part of previous work) to a strawman approach for using blind sampling to select targets [Castano et al. 2006, 2007]. AEGIS builds on a foundation of related work in autonomous rover science systems. Terrestrial platforms have demonstrated c lassification of terrain types or features in analog planetary surface environments, as well as automatic follow-up utilizing cameras and spectrometers. One early system autonomously identified meteorites in Antarctica [Pedersen 2001; Wagner et al. 2006]. Here, the Nomad rover segmented dark rocks against an ice background an d guided the robot to perform follow-up measurements with an arm-mounted spectrometer. Another early system provided techniques for analyzing field test data by the Marsokhod rover [Gulick et al. 2001]. These experiments demonstrated rock detection on a soil background using shadows as a cue to infer three-dimensional shapes. Other research focusing on the problems of feature extraction and prioritization includes work by Roush [2004] and Dunlop [2006]. Other experiments have focused on autonomous science during longer traverses. A field campaign demonstrated the utility of rover science autonomy during long over-the-horizon drives as part of a broader survey to characterize the distribution of life in the Atacama Desert [Smith et al. 2007]. Later work at Amboy Crater demon-strated rock detection and spectrometer follow-up, as well as adaptive survey tech-niques [Calder  X  on et al. 2008; Thompson et al. 2008]. More recently researchers have investigated automated target selection for the upcoming 2018 ESA ExoMars rover mission [Pugh et al. 2010; Woods et al. 2009]. Woods et al. use a graph-based growing algorithm to separate rocks from terrain and then edge-detection techniques to iden-tify when layering or bedrock is present.

In this context, AEGIS now contributes the first deployment of autonomous rover geology to a planetary rover mission. The integration with flight software and deploy-ment to a space mission is a key advance since it imposes challenging constraints on processing power and memory. Finally, AEGIS provides an important example of how autonomous target prioritization has been used in practice by scientists and how the processing and follow-up has been integrated into standard mission operations.
A separate image-processing approach has been used on the MER rovers to detect dynamic atmospheric phenomena, such as dust devils, in rover images [Casta  X  no et al. 2008]. However, this approach to event detection is quite different from analyzing images for terrain features. The dust devil detector looks for differences between a series of images to detect areas where motion has occurred between images. A large challenge of this process is to detect what are often subtle feature changes in the presence of significant image noise. Further, the dust devil detector only performs image prioritization by deciding what images should and should not be downlinked. In comparison, AEGIS detects a large range of static terrain targets in single images, prioritizes these targets based on geological features, and enables the acquisition of new data on targets of high priority. In future work, we plan to expand AEGIS on several fronts. As already mentioned, AEGIS could be applied for automated targeting of the MSL ChemCam spectrometer instrument. We are currently working w ith the MSL ChemCam team to determine how AEGIS could be best applied and/or expanded to select high-quality targets for this instrument. For instance, one extension could be to incorporate the evaluation of new target features, such as texture, layering, or color. Use of these features has been explored in past work on the full OASIS system [Castano et al. 2007] but has not yet been flown.

We would also like to expand AEGIS to evaluate onboard when resources are avail-able to acquire additional opportunistic measurements. For work with the JPL re-search rovers, the CASPER automated planning system has been applied to perform online sequence modification in support of opportunistic science [Estlin et al. 2008]. Currently on AEGIS, resources must be prea llocated by the ground before the capabil-ity is executed, regardless of whether an interesting target is found. A more efficient approachwouldbetoallocatere sources onboard only if a top target is determined. This extension would also enable the capability to be run more frequently, since resource levels could be evaluated at runtime.

Another new area of work be to would use AEGIS to select targets for close-contact instruments (such as the MER Microscopic Imager). These instruments are typically located on a rover arm and require close p roximity to the target of interest. AEGIS could select the initial target and use existing rover technology to autonomously drive and place a rover instrument [Bajracharya et al. 2005] to collect the final measure-ment. A further area of inquiry would be to use data collected from other types of instruments (such as spectrometers or ground-penetrating radar) to enable AEGIS to select interesting science targets. In summary, AEGIS enables autonomous recognition of scientifically interesting tar-gets in MER rover navigation camera imagery. These targets can then be successfully characterized without requiring a communication cycle with mission operations on Earth. New measurements with the MER panoramic cameras can be acquired dur-ing or immediately after a long drive and before images of the rover X  X  current location have been acquired and analyzed by human operators. AEGIS was uploaded to the MER Opportunity rover in December 2009. The system has been successfully checked out onboard Opportunity and is fully operational. AEGIS has been run a number of times on the surface of Mars and has consistently picked out appropriate targets. The MER mission plans to continue the use of AEGIS to enable automated targeting for the MER panoramic camera. Future runs should provide additional data that can be used to further evaluate AEGIS performance.

