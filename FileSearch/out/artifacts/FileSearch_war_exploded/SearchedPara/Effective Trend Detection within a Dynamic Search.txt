 In recent years, studies about trend detection in online social media streams have begun to emerge. Since not all users are likely to always be interested in the same set of trends, some of the research also focused on personalizing the trends by using some predefined personalized context.

In this paper, we take this problem further to a setting in which the user X  X  context is not predefined, but rather de-termined as the user issues a query. This presents a new challenge since trends cannot be computed ahead of time using high latency algorithms. We present RT-Trend, an online trend detection algorithm that promptly finds rele-vant in-context trends as users issue search queries over a dataset of documents.

We evaluate our approach using real data from an online social network by assessing its ability to predict actual ac-tivity increase of social network entities in the context of a search result. Since we implemented this feature into an ex-isting tool with an active pool of users, we also report click data, which suggests positive feedback.

Nowadays, large social media sites such as Twitter, Face-book and LinkedIn generate huge amounts of information. These social networks expose activity streams which are composed of actions generated by hundreds of millions of users over time. As such, some characteristics are likely to change over time. In recent years, many research papers have focused specifically on the problem of detecting trends over such data [2, 3, 5]. In addition, since not all trends may warrant the same level of attention from all users. Some research effort was directed at detecting trends within some predefined context such as regional [2] or a predefined user profile [9]. Yet, such approaches require a context to be provided in advance.

In contrast to such predefined contexts, users have tradi-tionally relied on keyword search to explore textual content. However getting a list of relevant documents is only a partial solution. As an extension, Faceted search [8] allows users to explore these results by applying multiple filters. For exam-ple, in a social network settings such as Twitter, documents can be defined as microblogs and their authors can be added as facets. Using faceted search, the top-k users that appear in the microblogs of the search results can also be displayed. Other examples of facets can also be categories, topics, or when the social network contains structured data [1], enti-ties such as the communities that the search results belong to.

In this paper we present a framework that utilizes faceted search along with a novel realtime algorithm called RT-Trends which calculates trending facets related to the search results. This approach employs a two phase solution. First, during indexing, we associate, as facets, to each document the trending candidate entities along with their correspond-ing information. Then, when a search query is issued, we collect and aggregate, in real time, trend scores for each candidate trend. We then rank them, and select the top-k to be displayed.

We implemented the feature of detecting trending entities within a search context into the Streamz [4] application. In our experiments we examine how well the RT-Trends algo-rithm can actually predict which entities exhibit increased activity levels. As further validation we analyze the Streamz query log and report on some encouraging results.
In this section, we describe the method for calculating trend scores for a stream of events.
We begin by describing the intuition behind our trend scoring algorithm. Consider a community in a social net-work (a trend candidate in the example), which for the past month has had a relatively stable volume of activity within it. As such, predicting future activity volumes can be based on previous activity levels, even when they are not very re-cent. Note that the term stability here implies relatively small changes in daily frequencies. However, if a sudden trend appears in the amount of activity then we except our predicted value to significantly deviate from the actual vol-ume of activity. This is due to the fact that our prediction does not give high significance to recent activity volumes. The idea is therefore to use this predicated error to derive a trend score.
Let C = c i ,..,c n denote the time series representing the occurrences of a trending entity candidate e in a sequence of time intervals T = t 1 ,..,t n . We begin by assuming that the dataset behaves in a predictable manner (as described in the intuition above) and we predict its volume based on an Exponential Moving Average [6] as follows:
We define the starting condition for the recursion to be  X  ( e ) = 0. Note that  X   X  (0 , 1) is a smoothing parameter, which controls the weights of older versus newer values. As stated before, when an entity is trending there is a sudden and abrupt change in it X  X  arrival rate (volume per time in-terval) which can not be predicted based on its previous be-havior. In practice we set a high value to  X  . This captures the underlying assumption that the rate of change is pre-dictable. If there is a trend then this calculation will result in an error. By aggregating these errors we get a quantita-tive measure of how much the new behavior deviates from the predicted one. The trend score can thus be based on this aggregated error by the recursive formula bellow:
The starting condition for the recursive formula is set to be TS 0 ( e ) = 0. Note that not every time series that is not predicted well by this Exponential Moving Average will produce a high aggregated error. For example, white noise will constantly exhibit prediction errors, yet when summing these errors, since there are likely to be an equal number of under predictions and over predictions, the aggregated error will be close to zero. This is good since we would not like such cases to be determined as being trendy.
Since an entity is not necessarily active at each time in-terval in the series it is possible to optimize Equation (2) such that TS i +1 ( e ) will be dependent solely on the values of TS j ( e ) ( j  X  i ) for which c j ( e ) 6 = 0. This is an important optimization since indeed the volumes in each time interval yield a sparse vector. As a result, the trend score of an entity can be updated only for time slots in which it actually oc-curs. Let j be an index such that for every index j &lt; k &lt; i it follows that c k ( e ) = 0 and c j ( e ) 6 = 0. First, note that based on Equation (1) as c k ( e ) = 0 it follows that  X  k +1 =  X   X   X  and therefore:
We can now develop Equation (2) as follows: (Note that we use a shorthand notation here in which  X  i denotes  X  i 0 20 40 60 80 100 120 Figure 1: The trend score is based on the difference between the actual and predicted arrival rate. The actual arrival rates in this Figure have been synthet-ically generated for the purpose of illustration. (*) c i + TS j  X   X  j  X 
We can now rewrite Equation (2) based on previous values that have been calculated only when the entity e occurs within the corresponding time window.

TS i ( e ) = c i ( e ) + TS j ( e )  X   X  j ( e )  X 
In Figure 1, we see an example of the gap between the predicted arrival rate, based on the exponential smoothing method proposed above and actual arrival rate of an entity as it becomes a trend. The figure also shows the trend score as calculated by Equation (4). Note that the trend score increases as the difference between the actual and predicted rate grows and levels when the entity X  X  arrival rate conver-gence to a new constant value. The problem is however, that this new constant value is high and is the result of mis-predictions (errors) that have occurred for older values. In fact, note that for values of around i = 30 (in the x-axis) the predictions become very accurate, i.e., the arrival rate no longer deviates from its predicted value yet the trend score remains high due to the fact that the entity  X  X as X  trending in the past. We therefore need to add a decay factor to  X  X orget X  past trends. Therefore, we introduce a slight modi-fication to Equation (4) by multiplying it by a Decay Factor  X   X  (0 , 1).

TS i ( e ) =  X   X  ( c i ( e ) + TS j ( e )  X   X  j ( e )  X 
The  X  X rends with decay X  line in bright green now shows the new trend score with the decay for the example of the trending entity presented in Figure 1. We now see that once the entity X  X  rate is correctly predicted the trends score starts to slowly decrease, as would be expected.
In this section we describe our dataset and the algorithm that calculates trend scores based on the description in Sec-tion 2 over our data and within a faceted search context. We also present our experimental evaluation of the results.
To construct the dataset for our experiments we used so-cial data from the activity stream of an enterprise social network called IBM-Connections [1]. This data consists of more than 800,000 individuals including employees, contrac-tors and ex-employees. The activities consist of generating and modifying several types of web entities, such as Blogs, Wikis, Files and Discussion Forums. Another web entity form is a Community [7] which groups together Blogs, Wikis, Files and Forums pertaining to a certain topic.
 To keep things simple, we defined our documents as Blogs, Wikis, Files and Forums and, since each of them is con-tained within a community, we define the communities as our trending candidates (which are added as facets).
In addition, we implemented the  X  X n-context trending com-munities X  feature into a web application called Streamz [4] which is deployed in our organization and has more than a thousand internal users. This allowed us to track click rates for each trending community shown based on its rank in the top-5 trends results (1-5) including the overall clicks ratio of the trends feature in general.
We next describe how we implemented our trends score within a search context using the Apache Lucene Open Source search framework. During the indexing phase a document is created for social entities (in our case Blogs, Wikis, Files and Forums) and the unique id of the containing community is associated to that document as a facet 1 . Note that we could similarly add other associations like categories, top-ics, users and others using the same method. The document along with its facets are then indexed. In addition, during indexing we also calculate our time intervals span denoted T = { t 1 ,t 2 ,...,t n } .

The next phase occurs during search. Given a search query q we retrieve the matching documents D q along with their associated facets denoted F ( D q ). For a given facet f  X  F ( D q ), let V T f = { V T i 1 ,V T i 2 ,...,V T i fn set of non-zero volumes per time intervals in T , i.e., V T represents the number of times facet f appears in F ( D within time interval T j  X  T . Note that zeros are not needed due to the trend score calculation optimization described in Section 2. We next compute the facet X  X  trend scores. This can be done efficiently, in memory, by using Lucene X  X  facets mechanism as next described. We start by mapping each facet to its time interval in T and then aggregate the counts to find V T f for each facet. This represents the volume within the corresponding time interval. Each V T f is maintained in https://lucene.apache.org/core/4 0 0/facet/org/apache/ lucene/facet/doc-files/userguide.html ascending order and is therefore a time series which we can apply our trend score algorithm over. The trend score al-gorithm of each V T f is calculated in parallel. As the trend scores are updated we also maintain a top-k list of the 5 trends with the highest trend scores. Based on trial and er-ror we selected the values for the trend scoring to be  X  ,  X  which we report in the subsections below.
In order to evaluate the RT-Trends algorithm we exam-ined its ability to identify trending communities that con-tain documents (Blogs, Wikis, Files and Forums) from the search results of a given search query. We evaluate this by checking to see if, in retrospect, these exhibit an actual in-crease in their activity volume. Specifically, we examined the algorithm X  X  ability to predict a volume increase within a predefined time span  X , called the Query Activity Time Span , from the moment the search query is issued. Given a community c and a search query at time t , we compare the volume of activity in the community c during the time window before the query, [ t  X   X  ,t ), namely the Prequery Activity to that after the query, [ t,t +  X ), herein the Post-query Activity . If for a community c the postquery activity is greater than the prequery activity we consider c to be an Accurate Prediction with respect to the query and the ac-tivity time span. To make sure the trends are meaningful, we also report the average factor by which the postquery activity actually increases.

In our experiments, we distinguish between short and long-term trends. The former represent current and immedi-ate topics of interests in the organization. Announcements about new appointments, annual report publishing and in-ternal conferences are just a few examples of events that can trigger short term trends. These events are classified as short term since they need to be quickly detected and their effect usually subsides within a few days. Long term trends, on the other hand, suggest slower but often more significant changes that affect the organization. Examples include adopting new technologies, releasing new products, and starting a new line of business. Oftentimes, such trends tend to exhibit slow and gradual changes but are neverthe-less quite meaningful. Taking this into account, we sepa-rately examined how well the algorithm can predict both types of trends.

We began by selecting a random sample of user queries from the query log of the Streamz application. Note that these queries are typically more than just a set of keywords. They commonly also contain constraints on employees or departments as well as combinations of all the above. For short term trends, we then picked the date and time d s of each day within a time period of one month (the month was selected arbitrarily) and set the query activity time span  X  s to be twelve hours. The queries above were then issued while limiting them to return results before the date d s each retrieved community, the prequery activity was com-pared to the postquery activity. Similarly, for long term trends we picked a date and time d l at the beginning of ev-ery forth day in a time period of three months. We then applied the RT-Trends algorithm as well as two baseline al-gorithms to retrieve the trending communities relevant to the given query. The first baseline algorithm, called Ran-dom , merely selects ten communities relevant to the query by random (in fact this is not really an algorithm, its merely Table 1: Average percentage of accurate predictions for each algorithm for short and long term trends. the ratio of communities whose postquery activity is greater than its prequery activity). The second baseline algorithm called Volume selects ten communities from all the relevant communities such that their volume of activity in a given time window is the highest. For short term trends this time window is defined to be the day prior to the query date and for long term trends it is defined as the prior month. We summarize the average percentage of accurate predictions made by each algorithm for short and long term trends in Table 1. The table also includes the activity time span and values of  X  and  X  , and the time interval size denoted | t | used for the RT-Trends algorithm.
We start by looking at the, more important, long term trends. Note that the volume of activity in the previous month is a very weak indicator for long term trends whereas the RT-Trend algorithm, which examines a finer granularity, is able to significantly outperform both Random and Volume by almost a factor of 2 . 5. Intuitively, the key difference lies in the fact that the RT-Trends algorithm is based on a weighted moving average which gives more weight to recent activities.
For short term trends, the Volume algorithm performs much better than Random. This means that the activity volume of the previous day is a significant indicator for the activity volume of the next day. RT-Trends does not signif-icantly outperform Volume in detecting short term trends since looking at levels of activities of smaller time units than a single day is not that significant. The reason is that in our data the amount of activity in a single community per one day is not high enough to merit such a fine-grained granu-larity. In addition, short-term trends are somewhat noisier and thus more difficult to predict than long-term trends.
We also report that the average factor by which the activ-ity in communities found trendy by RT-Trends is 2 . 354 for short term trends and 3 . 057 for long term trends. That is, the algorithm finds communities that exhibit a significant increase in their activity.
When displaying search results Streamz also depicts what we refer to as a Search Analytics Box . This box con-tains information about the search results such as the most active people, topics, and the new addition of trending com-munities. Since the launch of the trends feature in Streamz we tracked user activity and found that in 19 . 8% of the searches, the search analytics box was clicked. Out of these clicks, 80% were on the trends feature, indicating that users found this feature to be interesting. As the ranking of the trending communities in the search context is based on the trend score, we expect that the number of user clicks should correlate with the rank. Table 2 depicts the percentage of Table 2: Percentage of user clicks on trending com-munities based on their rank in the results. clicks on the trending communities by users based on their rank in the results. The main point of this is to show that there is no evidence of mis-ranked communities by the RT-Trends algorithm.
In this paper, we introduce a new problem, namely finding trending entities, in real time and within a dynamic search context which is not known in advance. We devise a novel framework and an algorithm called RT-Trends, which re-trieves scores, ranks, and selects the top-k trending items that are relevant to the search results. We implement the al-gorithm using Apach Lucene X  X  Faceted Search and deployed it into a web application used within the organization to track its usage. The tool is used by thousands of users in our organization and enables search and analytics capabili-ties over streaming social media data.

In our experiments, we analyze the algorithm X  X  ability to predict trends. We show that it predicts an actual growth in the level of activity within communities relevant to answers of user queries. Moreover, we show that the average factor by which the activity increases is also significant. Analysis of the Streamz query log shows that a high percentage of users that use the Search Analytics Box click specifically on the trends feature. Finally, we also show that a correlation exists between how we rank trending communities and the number of clicks they receive in the analytics box by users. [1] IBM-Connections. [2] Z. Al Bawab, G. H. Mills, and J.-F. Crespo. Finding [3] N. G. Golbandi, L. K. Katzir, Y. K. Koren, and R. L. [4] I. Guy, T. Steier, M. Barnea, I. Ronen, and T. Daniel. [5] J. Kleinberg. Bursty and hierarchical structure in [6] S. Roberts. Control chart tests based on geometric [7] I. Ronen, I. Guy, E. Kravi, and M. Barnea.
 [8] D. Tunkelang. aceted search (synthesis lectures on [9] X. Zhou, S. Wu, C. Chen, G. Chen, and S. Ying.
