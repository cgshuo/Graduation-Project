 Web search functionality is increasingly integrated into op-erating systems, software applications, and other interac-tive environments that extend beyond the traditional web browser. In particular, intelligent virtual assistants (e.g., Microsoft Cortana or Apple Siri) often  X  X all-back X  to generic web search in cases where utterances fall outside the set of scenarios known to the agent. In this paper we analyze a 3 month log of web search queries posed via the Cortana virtual assistant. We report that, in this environment, users frequently ask questions that implicitly pertain to the sys-tems or devices from which they are searching (e.g., ask-ing: [ how do I take a screenshot ]). Unfortunately, accu-rately answering these implicit system queries poses signifi-cant challenges to general web search engines, due in part to the lack of available context. We show that such queries: (1) can be detected with high precision, (2) are common, and (3) can be automatically reformulated to substantially improve retrieval performance in these fall-through scenarios.  X  Information systems  X  Query intent; Reformulation; Implicit system search; virtual assistants
Web search queries are often short and underspecified. To compensate, contemporary web search engines consider the contexts in which queries arise in an effort to better infer searchers X  information needs [2]. For example, one can often expect to be directed to local establishments when search-ing [ where can I get sushi ], despite the query X  X  failure to explicitly communicate a desire for geographic localization. Such queries are said to be implicitly localizable [11], and gains in retrieval performance can be achieved from strate-gies as simple as learning when to automatically reformulate by considering 3 months of spoken web search queries issued to the Bing.com search engine via the Cortana virtual as-sistant on Windows Phone devices. We begin by situating our work with respect to past research, then describe our dataset. We then separately consider two classes of implicit system searches, namely: semi-implicit system queries, in which a user X  X  device is specified via a pronominal reference (e.g.,  X  can this phone be a hot spot  X ); and fully implicit system queries, which lack such lexical cues (e.g.,  X  how do I enable a hot spot  X ). The paper concludes with a discus-sion of future work.
To ground the remainder of the discussion, we consider web search queries posed to virtual assistants on smart phone devices. Virtual assistants allow users to engage in a con-versational style of spoken interaction to access a device X  X  commands, settings, and integrated services. Virtual assis-tants can also be asked to query the web, and often default to this behavior when a user X  X  intent is unclear. Whether issuing commands or performing a web search, users are en-couraged, by convention and instruction [1, 9], to structure their utterances as if they were talking with a person.
As we will show, this confounding of command &amp; con-trol functionality with web search, results in an environment where implicit system queries are common, and where web search results leave much to be desired. In the literature, there are two general strategies for coping with these chal-lenges: Working from the top-down, recent research [5, 10] has sought to develop general classifiers that can detect or-phaned utterances  X  queries in domains that one might sus-pect to be covered by virtual assistants, but which instead fall-back to a generic web search. Many of these orphaned utterances are device-related, and their detection can help to identify common ill-served intents.

Working from the bottom-up, earlier work has sought to leverage system context to improve the retrieval perfor-mance of underspecified system-related searches [3, 12]. For example, Ekstrand et al. demonstrate how software ver-sion information, together with details of a system X  X  state, can be leveraged when evaluating web search queries related to image editing software [3]. These bottom-up efforts show promise, but assume all queries posed to the retrieval engine are system-related. This assumption is violated by intelli-gent virtual assistants that field queries about many topics.
The work presented in this paper represents a hybrid ap-proach, striving first to detect implicit system queries, then to augment those queries with contextual details of the user X  X  system. As noted in the introduction, our approach is most similar to work done in implicit local search [4, 11].
Our dataset consists of 3 months of spoken queries is-sued to the Bing.com search engine via the Cortana vir-tual assistant. The dataset contains tens of millions of En-glish language queries, originating from within the United States, collected from July 1 st , 2015 through September 30 th , 2015. Prior to analyses, queries were normalized by removing punctuation, and by converting text to lowercase. Additionally, compound nouns containing the word  X  phone  X  were normalized as follows: Compound nouns synonymous with phone, such as  X  telephone  X  or  X  mobile phone  X , were (a) semi-implicit system queries precision (b ) fully implicit system queries precision qu eries selected via LR test (sample N = 300) 0 .90 and found that such searches were frequently difficult to in-terpret (e.g., [ look the phone ], and [ ok my phone ]). Such queries may constitute non-unique speech input errors or false activations.
Applying the query detection heuristics to the complete 3 month query log reveals that users are 1 . 52 times more likely to refer to their devices with semi-implicit phrases like  X  my phone  X , or  X  the phone  X , than to explicitly mention the type of device they are using. (Table 2a,c). Moreover, when semi-implicit phrases were used, searchers were only about half as likely to click on a search result. These differences are highly statistically significant (  X  2 goodness of fit, p 0 . 0001), and, together, strongly support this paper X  X  focus on improving the retrieval performance of implicit system queries.
Finally, we characterize the retrieval performance of the automatic query alteration strategies outlined above. For each of the 300 sampled queries (i.e., those mentioned in section 4.2), we retrieved web search results with: the unal-tered query, the device-specific alteration, and the platform-specific alteration. Crowd workers again provided judgments  X  this time rating relevance on a 5-point scale ranging from Poor to Perfect. We focus on the top three search results in each condition, as the phones in our dataset could only display two or three results at a time (Figure 1). Table 3a reports the mean nDCG@3 for the various conditions, as well as the number of individual queries whose nDCG@3 scores were improved (wins) or hindered (losses) by the al-roring past work [6], we leverage the likelihood ratio test to detect these non-accidental reformulations. We define a query pair ,  X  q 1 ,q 2  X  , to be a pair of successive queries, issued by the same user, occurring no more than 30 minutes apart in the log dataset. The second query, q 2 is then abstracted as a boolean event, s 2 , which occurs whenever q 2 mentions a user X  X  system, platform or device by name. We then con-sider the goodness of fit of two competing hypotheses that explain the observed occurrence frequencies of  X  q 1 ,s 2  X  pairs:
The first hypothesis, H 0 , asserts that s 2 occurs indepen-dently from q 1 . Conversely, H 1 asserts a dependence; and, lihood ratio test statistic,  X  2 =  X  2 log ( L ( H 0 ) /L ( H 1 )), can be computed directly from observed data, and is known to be asymptotically Chi-squared distributed, with 1 degree of freedom [6]. In this paper, we reject H 0 when the test statistic is larger than 28.00. This corresponds to a p -value &lt; 10  X  7 , and is strong evidence that q 1 requires an explicit system reformulation. Once discovered, such queries are placed in a lookup table used to identify future instances.
As before, we report values for precision (Table 1b), traf-fic impact (Table 2b), and retrieval performance (Table 3b). By many measures, implicit system searches perform sim-ilarly to semi-implicit queries. Notably, classifier precision is again judged to be 0.90, and the query alteration strate-gies again lead to mean nDCG@3 values approaching 0.7 in all three conditions. For implicit system queries, re-formulation improved between 60% -65% of all individual queries (wins), and negatively impacted 25% -29% of queries (losses). The slightly lower win/loss ratio, compared to semi-implicit queries, can be attributed to the higher baseline performance in the fully implicit case. The chief distinction between semi-and fully implicit system queries, however, is one of traffic volume: We find that fully implicit system searchers occur 5 . 7 times more frequently than semi-implicit searches, and 8 . 6 times more frequently than those that ex-plicitly specify a device or platform.
When users speak queries to intelligent virtual assistants, their utterances often implicitly pertain to the devices from which they originate. In this paper, we have we have shown that such queries: (1) can be reliably detected, (2) account for a meaningful proportion of search traffic, and (3) can be reformulated to greatly improve retrieval performance. Nevertheless, our analysis is limited in several ways, and there are numerous opportunities for future research. We elaborate below.

Citing a desire to filter accidental query activations and speech recognition errors, our methods consider only queries that have been issued by more than one person. However, we believe there is little risk in lifting this restriction, as user are unlikely to attend to search results in cases of false acti-vation. Further study is necessary to more fully investigate this issue.

We are also sensitive to the possibility that users may use virtual assistants to query about other devices or platforms, and that the proposed reformulation strategies may hinder
