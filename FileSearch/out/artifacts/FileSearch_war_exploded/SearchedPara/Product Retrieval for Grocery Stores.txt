 We introduce a grocery retrieval system that maps shopping lists written in natural language into actual products in a grocery store. We have developed the system using nine months of shopping basket data from a large Finnish super-market. To evaluate the system, we used 70 real shopping lists gathered from customers of the supermarket. Our sys-tem achieves over 80% precision for products at rank one, and the precision is around 70% for products at rank 5 . H.3.3 [ Information Search and Retrieval ]: [Retrieval models, Search process]; H.1.2 [ User/Machine Systems ]: [Human information processing] Algorithms, Languages, Experimentation Grocery Retrieval, User Evaluation, Retrieval Models More than 50% of customers create written shopping lists for major shopping visits [6]. Stores tend to use structured formats, e.g., product-category hierarchies (or taxonomies), that contain formal language, whereas customers tend to use a more free form natural language to describe items. As an example, a typical handwritten grocery list can contain everything from generic item descriptions (e.g., milk, juice) to very specific items (e.g., a specific package of washing powder).

The discrepancy between the way people create shopping lists and the way stores maintain product information raises the question of how to design an easy to use, intelligent mobile shopping assistant. While some design suggestions have been given in the literature [1, 2, 3], relatively little This work was supported in part by the Finnish Funding Agency for Technology and Innovation TEKES, under the project Personalised Ubiservices in Public Spaces, and by the IST Programme of the European Community, under the PASCAL Network of Excellence IST-2002-506778. The pub-lication only reflects the authors X  views.
 attention has been paid to the actual creation and use of shopping lists.

We describe and evaluate a grocery product retrieval sys-tem that can be used to map products expressed in natu-ral language into products in a grocery store. Our system has been built using nine months of anonymized shopping data from a large Finnish supermarket (more than 12 mil-lion products bought). As the data is from a Finnish store, also the retrieval operates in Finnish. However, most of the techniques we employ are common information retrieval techniques, which suggests that our approach could also be used with other languages.

In addition to the shopping data, we have collected 132 real shopping lists from customers. Out of the lists, 62 were used to derive requirements for our retrieval system. The remaining 70 shopping lists were used to evaluate our sys-tem. In the following we briefly describe the main functionality of our retrieval system.
 Indexing The retrieval system was constructed using nine months of shopping basket data. From the data, we constructed a database of product and category names, as well as indexes for words occurring in product and category names. We also stemmed the words and created indexes for stems appearing in product and category names. Before creating the indexes, units and package sizes were removed from product and cat-egory names. Stemming was performed using the Snowball Finnish language stemmer 1 .
 Index Expansion In order to handle compound words, we use prefix and suffix index expansion. More specifically, we expand the index of every word j with product and category names that have a word that starts or ends with word j . For example, we add the product name Vipset appelsiinit  X  aysmehu (Vipset orange juice) to the index of word appelsiini (orange) since appelsiini is a prefix of appelsiinit  X  aysmehu .
 Query Preprocessing We lemmatize queries by removing partitive (singular and plural) and nominative plural case endings.

In order to handle colloquialisms, slang expressions and abbreviations, we constructed a lookup table. For example, omppu is a colloquialism that is mapped to omena (apple). http://snowball.tartarus.org/algorithms/finnish/ stemmer.html [Retrieved 27-01-2008]
We expand queries with additional words when a query word is extremely common (e.g., cheese ) or when the cate-gory name is a compound word that does not occur in any of the product names of the products in the corresponding category (e.g., ananass  X  ailyke (tinned pineapple, category) vs. ananasmurska, (mashed pineapple, product) ).

Words that span several product categories are considered stop words as they can cause the search to return a large number of potentially irrelevant products. Examples of stop words include manufacturer names and generic adjectives that describe characteristics of products.
 Ranking Items are ranked using an approximation of the posterior probability of an item given the query Q : where BM 25 is the value of the BM25 Okapi function for query term q j and  X  is a weight term. The BM25 function is given by [4]: The variables  X  and b are predefined constants. In the ex-periments we use Xapian 2 default values  X  = 1 and b = 0 . 5 . The variable f j is the term frequency of word j , n j is the number of product names in which term j appears, and N is the total number of product names. Finally, L is the nor-malized product name length, i.e., the length of the current product name divided by the average length of a product name. The variable  X  was set to 0 . 75 on the basis of prelim-inary experiments.
 Rank Augmentation Intuitively, products that match both in product name and category name should receive higher ranks than other prod-ucts. To achieve this behavior, we use a weighted extension of BM25 where the term and document frequencies are re-placed with weighted linear sums [5]: n 0 j = dm j + n j and f = dv j c j + w j f j .

Here d, v j and w j are weight terms. In the experiments, we use d = 2 and the weights v j and w j are set using edit distance calculations. Let p be an arbitrary word and let q be a query term. We set w j = 1 . 0  X  d ( q j , p ) / max {| p | , | q where d (  X  ,  X  ) is the edit distance between two strings and | p | is the length of word p . The weights v j are set similarly. We also use package sizes and stop words to augment rank scores. When the query contains a package size, we multiply the BM25 scores of matching products by d . If the product name matches a stop word that is part of the original query, we add the BM25 score of the stop word to the rank score. Misspellings To support misspellings, we maintain a distance index that contains word pairs and the edit distance between the two words. When the original query does not return any re-sults, we consult the distance index using words within edit distance one. If this query does not return enough (ten or more) results, we use words within edit distance two. http://xapian.org/docs/bm25.html
Table 1: Results for precision at different ranks. Experiment Setting In the experiment, we input the shopping lists into our search engine, one list at a time. The ten topmost results for each item in the shopping list were shown to an external evaluator who was asked to give positive or negative feed-back on each result. The evaluator was also allowed to leave an item unrated if (s)he was not sure of the result. Each eval-uator gave feedback on five shopping lists. The evaluators were recruited from students and staff of our department. Results The experiment resulted in a total of 7454 (subjective) rele-vance assessments. From the results, we calculated the mean average precision (MAP), as well as precision measures at different ranks (i.e., P@N). The resulting precision measures for the top 5 results are shown in Table 1.

We examined separately those queries whose top result was evaluated negatively. The main sources of negative feed-back were (1) slang expressions that were not included in our lookup table, and (2) some complex queries where the prod-uct name was misspelled (e.g., query ottermanni 17% , result Valio Oltermanni 1kg  X  this was rated negatively because the package did not match). These two types accounted for 23 cases of negative feedback and when ignoring these assess-ments, precision at one equals 84 . 3% . Hence, the perfor-mance of our system could be increased by collecting more slang expressions, colloquialisms, abbreviations etc. [1] R. Bellamy et al. Designing an e-grocery application for [2] P. Kourouthanassis and G. Roussos. Developing [3] E. Newcomb, T. Pashley, and J. Stasko. Mobile [4] S. Robertson et al. Okapi at TREC-4. In NIST Special [5] S. Robertson, H. Zaragoza, and M. Taylor. Simple [6] A. Thomas and R. Garland. Grocery shopping: list and
