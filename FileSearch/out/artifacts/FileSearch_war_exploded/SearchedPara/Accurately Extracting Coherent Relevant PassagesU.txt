 In this paper, we present a principled method for accurately extracting coherent relevant passages of variable lengths us-ing HMMs. We show that with appropriate parameter esti-mation, the HMM method outperforms a number of strong baseline methods on two data sets.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Retrieval Models Algorithms Passage Retrieval, Hidden Markov Models
It is often desirable for information retrieval (IR) sys-tems to retrieve relevant passages as opposed to whole doc-uments to further filter out irrelevant information. A criti-cal problem in passage retrieval is how to accurately locate the boundaries of coherent relevant passages ,whichwere-fer to as passage extraction . Passage retrieval involves both passage extraction and passage ranking. Accurate passage extraction not only allows an IR system to precisely point to the most relevant parts of a document, but can also poten-tially improve document ranking and relevance feedback by using short, relevant passages rather than long, noisy whole documents. Despite its importance, passage extraction has not been seriously addressed in existing work. Passage re-trieval methods have so far been evaluated for document ranking[3, 4], passage ranking[1], and question answering[6]. In all three tasks, however, ranking is the main component being evaluated. As a result, existing passage retrieval meth-ods are not designed to extract passages that are both query dependent and coherent in content.
 by R . Transition probabilities between R and B 2 adjust the degree of smoothing. Finally the document switches from state R to background state B 3 , where another non-relevant segment is generated from the background language model. The last state E generates only a special symbol, which is appended to each document to enforce that a document goes through the complete HMM. When all the output probabil-ities and all the transition probabilities in the HMM are set, we can use Viterbi algorithm to find the state sequence that has most likely generated the word sequence of a document, and hence locate the relevant passage in the document.
The language models are estimated as follows. For the background language model, we use the whole document collection as samples and maximum likelihood estimator to estimate the probability of each word. For the relevance language model, we explored three estimation strategies, all using maximum likelihood estimator. The first is to simply use the original query words. We call this method HMM-q . The second strategy incorporates within-document pseudo feedback . The idea is to first extract from the document a short passage highly likely to be relevant to the query, and then use words in this starting passage as samples for estimation. Such an estimated language model should pre-sumably attract the text surrounding the starting passage that is similar to the starting passage, and thus extend the passage to the true relevant passage that is coherent in con-tent and has natural topical boundary. We call this method HMM-wd . The third strategy incorporates cross-document pseudo feedback . The idea is similar to HMM-wd , but we use a set of starting passages from different documents that are relevant to the same query to estimate a relevance lan-guage model for this query. We call this method HMM-cd . Once all output probabilities are set, we can train the transi-tion probabilities. Since passage length is document specific, and transition probabilities affect passage length, we train the transition probabilities for each document.
We implemented a number of baseline methods for com-parison. BL-simple returns the passage between the first and the last query words in the document. BL-win uses a fixed-size sliding window to search for the passage with the most query words. BL-cos and BL-pivoted are similar to BL-win , but use a cosine measure and a pivoted cosine measure to find the most relevant passage. Experiments were car-ried out on two data sets: a synthetic data set created from TREC DOE abstracts, and a subset of TREC 2004 HARD track data. We use precision, recall and F1 for evaluation. Let T be the true relevant passage, E be the extracted pas-sage, and O be the overlap between T and E .Precisionis the length of O (in number of words) divided by the length of
E ,recallisthelengthof O divided by the length of T , and F1 is the harmonic mean of precision and recall.
Table 1 shows the experiment results. Stars indicate the best performance figures among all methods on the same data set. For the window-based methods, we set the win-dow size to the average relevant passage length, which is the best the system can do. HMM-wd and HMM-cd use passages extracted by HMM-q for feedback. We see from Table 1 that HMM-cd performed the best among all methods if we use F1 as the measure. This shows that with good parameter esti-mation from feedback, the HMM-based method outperforms all baseline methods. HMM-q achieved high precision but
