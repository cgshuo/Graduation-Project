 In large scale online systems like Search, eCommerce, or social network applications, user que ries represent an important how to detect, characterize and classify bursts in user queries in a large scale eCommerce system. We build upon the approaches discussed in KDD 2002  X  X ursty and Hierarchical Structure in Streams X  [3] and apply them to a high volume industrial context. We describe how to identify bursts on a near real-time basis, classify them, and apply them to build interesting merchandizing applications.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval  X  Information filtering; H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval  X  Clustering. Algorithms, Measurement, De sign, Experimentation. Temporal burst mining, wavele t-based feature extraction, temporal classification.  X  X hen a dog bites a man, that is not news, because it happens so editor of New York Sun more than a hundred years ago. Surprising and interesting events are an important part of our, otherwise, mundane lives. They are unusual, happen infrequently, and are worth displaying in headlines. Most of all they carry significantly more information than otherwise expected events. From Claude Shannon X  X  theory we know that information is inversely proportional to the probability of something happening or being expected. In an online content or electronic commerce system, this information is critical and can be used for a wide variety of purposes like merchandizi ng, creating traffic stickiness, load handling on applications, and fraud detection. Queries coming into an online system provide a good proxy for information flowing through a system in the form of streams. In online communities query frequenc y and variation on frequencies carry information about wisdom of crowds and about events, trends, things in vogue or products in demand. For large scale online systems, it is important that we detect and characterize query bursts in a scalable and near real-time manner to leverage them for applications. Occurrence of low probability events and unexpected changes in large scale datasets have been extensively researched [2][21]. Change Detection using Cubes of Models (CDCM)[2] is used in Change detection models [2][1] provide a standard approach to detecting deviations from baselin e where deviations from normal are measured using generalized likelihood ratio. Methods for detecting buzz and trends in web data have also been proposed [9][19] . Techniques fo r finding bursty patterns in data discussed in [3][8]. Temporal e volution of tags and the detection of interesting tags given a time sli ce is described in [10]. [11] and [12] are publicly available buzz display applications. Offline burst detection from query logs and analyzing similarities among them using FFT based methods is described in [16]. In the study of the dynamics of neural activity Spike Sorting [20] is used to detect spikes in the presence of noise and when waveforms are not complete or are overlapping (coming from multiple sensors). More recently, Wavelet transforms have been proposed for this [6]. Wavelet transform coefficients have been used for classifying 1-D physi ological signals obtained by electrocardiography and electroencephalography [13][14]. Using wavelet based approaches for data mining problems including temporal pattern studies has been described in [17] and [18]. Although extensive work has been done in related fields for mining temporal patterns, we be lieve that very little work has been done to find interesting bursty patterns from large-scale eCommerce query logs on an incremental or real-time basis. Also, not much work has been done in further analyses on classification of such temporal bursts based on both cause and effect periods. In this paper we present a practical method to detect bursts in query logs. We use state-based burst detection techniques and also build models for queries that can look at newly arriving incremental data to continually detect newer bursts with minimal computation. We also provide a mechanism to rank these bursts based on a number of factors like burst concentration, burst intensity and burst interestingness. We introduce a novel mechanism to classify these bursts. We analyze our algorithms and compare them to other approaches and show that in practice our techniques work significantly better than simple rate based methods. This paper is organized as follows : The next section describes our model used for mining bursts and studying them. Section 4 describes our burst mi ning experimental set up and also discusses model that was used to work with data that continuously arrives in increments. Section 6 describe s how we used wavelet based describes how our burst mining a pproach is better than other simpler approaches to find abrupt changes in data. Section 9 shows an application that uses the daily bursts that are mined. Finally, we state our conclusions and draw out the plan for future work in section 10. Mining for interesting query patterns can be seen as a problem in identifying bursts in event streams [3]. Topics in event streams are identified by  X  X urst of activity X  with certain feature terms rising sharply in frequency as the topic emerges. Event stream arrival itself can be exemplified by email arrivals, news item state automaton where bursts correspond to state transitions. structure where a long burst of low intensity potentially contains several bursts of higher intensity inside it in a recursive way. Thus a temporal stream of events can be decomposed into a hierarchical structure of bursty episodes. To avoid short bursts cost is associated with each state transition. Thus, given an event stream the method identifies a low cost state sequence that is minimization problem and is solv ed by dynamic programming. By introducing a cost for state transitions and solving for an optimal state sequence, the ve ry high frequency and, hence, uninteresting components of the event stream, which might have caused the automaton to keep on jumping between its states continuously, are filtered out. The cost minimization techniques used are analogous to those used in finding state sequences for given observation sequences in Hidden Markov Models [4]. stream. We are interested in identifying bursts in this query stream. We are not interested in the hierarchical structure of bursts but in identifying high intensity burst transitions. So we adopt a 2-state automaton based generative model [3][8] (q ). We assume that we always start in the low rate state q gaps x between consecutive query arrivals distributed independently according to a memory-less exponential density distributed independently according to () x e x f 1  X  . The automaton changes state with probability p  X  (0, 1), remaining in its current state with probability 1  X  p, independently of previous query arrivals and stat e changes. This models the cost associated with a state jump. The generative model can be applied to find a likely state sequence, given a set of query arri vals. Assuming there is a given set of n + 1 query arrivals, w ith specified arrival times, we where x i &gt; 0. Let Q = (q i1 , q i2 ... q gaps, which has the form f Q (x 1 , x 2 ...x n ) = ( ) number of indices i t where of Q is equal to Let i 0 = 0, since we assume the automaton to start in q conditional probability of a state sequence Q given inter-arrival gaps X is given using Bayes Theorem as where Z is the normalizing constant ) ( ] ' Pr[ equivalent to finding one that minimizes Since the third and fourth terms are independent of the state sequence, the problem is equiva lent to finding a state sequence Q that minimizes the following cost function: The state sequence that minimizes this cost would depend firstly on how easy it is to jump from one state to another (transition cost) and secondly on how following that sequence would conform well to the rates of query arrivals. tune the behavior of this automa ton model; the low rate of arrival  X  state to another in the automaton vs. staying in the same state which we denote as the cost C. The next section describes the query set used for burst mining, the scrubbing process utilized to make the set conform to the auto maton model and the parameters used for the automaton model while extracting bursts. We built a model as described in section 3 for eBay queries and detected bursts from those queries. We also found a possible cause for some of the bursts that we detected. eBay is one of the biggest eCommerce sites on the WWW today. There are around 80+ million users buying and selling on eBay across thousands of different cat egories ranging from antiques and collectibles to video games and tickets. There are more than 75+ million findable items available on eBay at any time. The site serves over 50+ million queries a day. We use 5 months of queries from eBay.com in 2007 as the dataset for this experiment. After so rting through sample user session logs (75+ TB of data) we extracted the unique queries and their corresponding counts for every day and sorted queries for every day by their frequencies. Not all bursts detected by the automaton model described above would be interesting and useful. Only positive deviations in popular queries would really be interesting. Hence we applied mining algorithms only for queries that had at least moderate popularity at some point during the 5 month window. Queries selected as per section 4.1 were used to analyze temporal patterns and mine bursts. For every query we first convert the daily frequency information arrival of queries, hence each such time series is representative of the arrival rate of the query. Also, we convert the time series for every query to a series of inter-arrival times (gaps) between queries. The extracted data that we use does not have any information about times of day when the query was received; it only has accumulated information about the number of times the particular query happened per day. Hence, to convert this information to uniform. Thus a query with a frequency of 2880 per day would have one query arrival every 30 sec onds for that particular day in the corresponding time series. absolute rate of arrivals for our mining work, we limit the maximum number of segments of que ry arrivals per day to 48. This results in lesser processor running times when we apply the This means we will have 48 equi-spaced samples for the query on the day it occurred most frequently. The number of samples on other days would be (frequency on that day * 48) / (frequency on the day with maximum frequency). Each arrival is represented by a UNIX timestamp. So the patterns for these queries, although the amplitude information (the mass of the queries) is not available because of the scaling. Consider the query  X  X phone X . Figure 1 plots the time series that was formed as discussed above. The Y axis has a constant magnitude of 1 as it just indicates the presence of a sample. The X axis indicates time; however absolute time labeling has been omitted. Basically the line indicates query arrivals over a certain frequency of the query iphone during that time period. We can higher frequency of the query  X  X phone X  during that period. This is confirmed by looking at Figure 2 which plots the daily frequency of the query  X  X phone X  per day during the same time period. Figure 1 shows the time-series for the query  X  X phone X . The Y-axis has a constant magnitude of 1 (indicating presence in the sample). X axis is the time axi s with absolute time labeling omitted. It can be seen that the points are denser towards the end indicating higher frequency of the query during that time period. Figure 2 shows the daily frequency of the query  X  X phone X  per day during the same time period shown in Figure 1. One can see the peak towards the end. Y axis shows relative query frequency. We did experiments with different values for cost C and different cost introduce lot of noise in the mined bursts, whereas higher values of cost cause some genui nely interesting query bursts not to be detected. Similarly, differe nt relationships between the rates of the 2 states also affect the amount of noise in the bursts detected. Based on the experime nts we conducted in order to detect most interesting query burst s with minimal noise we set the parameters for the model as follows:  X  samples for the query divided by the total time spanned by the query. The total time spanned by the query is determined by subtracting the unix time stamp co rresponding to the first sample from the unix time stamp corresponding to the last sample, hence the time is in seconds.  X  1 = 2.5  X  0, C = -ln (0.38). We calculated the optimal state sequences using the methodology described in section 3 for the query set described in section 4.1. significantly from the average rate at any point in time, and hence the automaton for the query  X  X ii X  always remains in state 0. Figure 4 shows the temporal patte rn and optimal state sequence guitar X . For these queries we see that the automaton jumps to state 1 from state 0 when the rate of queries deviates significantly from the average rate. Figure 3 Temporal Pattern in Dotted Line and Optimal State Sequence in Solid Line for th e Query  X  X ii X . Note that the horizontal line showing optimal st ate sequences is flat and is close to the X axis. Figure 4 Temporal Pattern in Dotted Line and Optimal State Sequence in Solid Line for Qu ery 'paris hilt on'. We see various peaks (spikes) and corresponding automaton jumps indicating multiple burst periods. Figure 5 Temporal Pattern in Dotted Line and Optimal Sequence in Solid Line for Query 'gibson guitar'. Figure 4, Figure 5), the amplitude (query frequency information on the Y axis) has been normalized to be between 0 and 1. The X axis represents day of the year and absolute time labels have been omitted. After finding the optimal state sequences, we searched for patterns where the automaton had jumped from low state to high instances and we refer to them as state sequence snippets of that for one particular query we might have multiple points in time when the automaton jumped from low state to high state and then went down to a low state again as seen in Figure 4 above. We analyzed the bursts to see what their causality was by manually matching external events that might have caused the bursts to be recognized. Table 1 shows a list of bursts, the period over which they qualified as burst s, and possible explanation for these bursts. 
Table 1 shows the detected burst, the burst period, and the possible causality as manually identified from external events. days, some last about a week, and a few last longer than a week. Our general observation is that a burst related to a news item generally lasts for a day, a launch of a product or a landmark television episode lasts for about a week, an expected occasion like Father X  X  day, or July 4 th lasts for the period of a week around the date of the expected event. Bursts related to campaigns typically last during the period of the campaign. While these are general observations with examples and exception cases, deeper study is required to see the nature of the bursts and their lasting or recurring period. need to be able to detect and use bursts in an incremental and scalable way as the new query data arrives. Near real-time detection of these patterns aid in building applications that take immediate action like fraud detec tion or product merchandizing. In this section we describe a m odel that is more resistant to do continual incremental burst detection on daily queries. Our model views queries as a mixture of the query for which we want to detect bursts and other que ries flowing in the system (this mixture is modeled to be produced by a binomial distribution [3]). This model is based on the rate of change of percentage volume for a query. The advantage of this model over an exponential that as this model is based on change of percentage volume vs. change of absolute volume it is more resistant to noise introduced due to missing samples or differen ces in query volumes that may be dependant on the day of the week. In other words, it can new queries. Currently we look at a daily batch but the model could be used for any reasonable interval batched arrival, say hourly arrival. For every query Q for which we want to detect bursts we build this model based on fraction of this query Q as compared to total queries in the system. We seeded the system with 120 days of temporal data for queries which is equivalent to 120 batches of queries. For every query Q, let the t th batch contain r t instances of Q out of a total of d Let  X  batches (120). We use a 2-state automaton B with states q of the automaton being in state q 0 or q 1 given by p respectively. We select p 0 = R / D for state q 0 and a probability p &lt; p 1 &lt;= 1) for state q 1. The cost of a state sequence q = (q i1 ... q automaton B is defined as follows. If the automaton is in state q when the t th batch arrives,  X  cost of be present in total volume of que ries using a binomial distribution with probability p i. There is also a cost of with the state transition from ln c where c is the probability that the automaton jumps from one state to another. Based on our e xperiments we use a value of s= 5.0 and a value of c = 0.10. We calculate the optimal state sequence for every query Q for this 120 day seeding period and store the value of the last state in the optimal state sequence along sequence path. being in the previous states (through a recurrence relation), we that we don X  X  have to recalculate the entire state sequence. Whenever a newer batch of queries arrives we update the models (p 0 and p 1 ) for every query Q to take into account the newer volume of Q . By incrementally changing p 0 and p tests and found that this appr oximation works very well in practice to detect interesting bursts from queries. When a new batch arrives we calculate () t C cached values of () 1 to reflect the newer rate of arrival. The newer computed costs as well as new state in the optimal sequence are cached again for the next iteration. This way the amount of computation to do for a new batch arrival of queries is mi nimized. If we see that the new state in the optimal sequence is a high state and the previous state for the query. Based on these model parameters we find on an average 100 interesting query bursts every day. Absolute change based methods ca nnot detect interesting bursts in queries that are not extremely popular. Relative change based moderately popular for a small time period. Our state based method applied to lots of popular queries arriving in every batch, is an effective way to interpol ate between absolute and relative changes. We apply this model to new queri es on a daily basis. Algorithm is implemented in C++ code us ing a single CPU (i386 processor at 2.6GHz) on a Supermicro H8QC8. Every batch of daily eBay queries has millions of unique queries that follow an expected powerlaw distribution. There is a long tail of queries which is not thousand queries from the daily list as candidates for our burst detection algorithms. Dropping some part of the tail also saves us unnecessary computation costs. Running the model described above on these thousands of queri es just takes computation time in the order of minutes. When we looked at the temporal query frequency patterns for the bursty queries, we observed that there were many interesting patterns. Our belief was that cl assifying them based upon their shapes (spanning over cause and effect periods) and durations would help us get a deeper understanding of the nature of bursts and the related causes or events. There has not been much work in the careful classification or taxonomy of the full range of burst patterns [19]. We believe our classification work for retrospective analysis of past bursts is a step towards understanding how the future temporal pattern for a query can be predicted based on the observation of an emerging burst. We use an unsupervised clusteri ng technique to classify these temporal query patterns in to different classes. For every burst, we get the daily frequency information of the center. Thus, we get a time varyi ng waveform for our bursts, of which we normalize the amplitude between 0 and 1. We get such waveforms for 350 random bursts from the ones we detected in section 4 (normalized amplitude between 0 and 1, 32 day samples, burst period at cen ter) before we cluster them. classification/clustering system is not purely causal. For the period after the burst (which could be the effect or something else). In order to extract features to classify bursts we use methods biomedical signals [20][13][14]. Wavelet transforms preserve the amplitude, time and frequency information for non-stationary signals; hence they are suited to our work. Application of Daubechies transform [5] to our 32 length waveform sample s gives us wavelet transform coefficients of length 32 which we use as feat ures for classification. Although the Daubechies transform is much more complex and computationally intensive as compared to the simpler Haar transform, we use Daubechies because it can pick up details that transformation maps the bursts to a 32 dimensional space where every coefficient in the obtained transform is 1 dimension. Classifying bursts help aid app lication decisions based upon the nature of the bursts. Shapes of bursts could be indicative of a celebrity news event, fraud, or an emerging trend. We use K-means [6][7] and Euclidean distance measure to cluster the bursts. With appropriate expe rimentation we found k = 4 to provide the ideal set of classes. We label these 4 classes as described below. We found the shapes of the bursts we mined to match shapes of mountain peaks. Hence we chos e to name them Matterhorn X ,  X  X uesta X ,  X  X ogtooth X  and  X  X ogback  X  based on names of peaks in the Canadian Rockies [15]. To illustrate our results we plot the centroids of the 4 classes and one example from each of the 4 classes in time domain in the following Figure 6. Figure 6 Labeling of Classes. Classes are named based upon the representative shapes of their centroids. X axis represents the time axis (day of the year), wi th burst period at the center. Y axis shows the relative normalized query frequencies, which gives an indication of the differences in amplitudes between burst and non burst periods for each of the 4 classes.  X  X itten X  is a Matterhorn,  X  X opranos X  is a Cuesta,  X  X lli X  is a Dogtooth and  X  X oundwave X  is a Hogback kind of burst. These bursts seem to be the most interesting with sharp narrow spikes. Products for which there was a pre-launch hype fell in this class. They were very popular for a transitory period and and movie launches also seemed to fall in this class. Some examples include queries like  X  X he simpsons X  and  X  X phone X . These stand out as moderately in teresting, bursty patterns mostly with broad peaks or dual peaks.. Usually dual peaks are seen for products which have an initial limited release and a follow up wide spread public release or for players performing well on multiple occasions. Some queries seen in this class included  X  X ebron james X  and  X  X lex rodriguez X . These seem to be slightly inte resting with various peaks and distribution having some elements of uniformity over time. Some  X  X ongaberger baskets X  and  X  X anna andersson X . These kinds of bursts seem to have steadily increased over time as if the initial burst was evolving into some kind of a trend. Some products penetrate the market and their popularity steadily grows examples were Treo and T-Mob ile products and launch of some toys like Transformers. Thus we see that if we were to build a merchandizing application community, the window of opportunity for reaction is the least for Matterhorns, followed by Cuestas, Dogtooths and Hogbacks respectively. Also Hogback kind of bursts seem to evolve into advertisements. We ranked the bursts mined in section 4 based on a number of measures. We built upon concentration based techniques described in [8] and also used wavelet transforms to quantify intensity of bursts. Concentr ation based and intensity based methods are ideal for quickly de tecting bursts which might be on interestingness and merchandi zing value we use a scoring technique described in section 7.3. We observe the time series information and samples as well as the optimal state sequence for every burst. During observation we look at the time period when the automaton was in the high state, this is the burst period of interest for us. Now for each such burst period of interest we calculate various quantities which are later used for ranking and sorting. Duration of burst (D): This is defined as the number of seconds for which the burst lasted. Mass (Popularity) of Burst (M): Number of queries received for the bursty term during the burst period. Arrival Rate for Burst (A): This is the rate of arrival of bursty queries during the burst period. The inverse of the average value of gaps between query arrivals gives us the arrival rate A. Span Ratio (SR): For a burst with duration D, we find the non-burst period duration before the burst period (D1) and after the Thus SR indicates the relative shortness of D. Momentum of Burst (Mo): This is defined as the product of arrival rate for burst and popularity of burst. Thus Mo = (M . A). Concentration of Burst (Xc): This is defined as a function of SR (SR 0.1 ) . Mo. We believe this work s better for ranking bursts mined score that we use for ranking and sorting bursts. burst is ranked higher if it is more popular or has a high arrival rate. As a result, bursts in popular queri es get ranked higher as the mass spiky bursts for popular queries. This is because for a constant mass (popularity), the momentum, and hence, the concentration varies with arrival rate. The approach shown in section 7.1 uses a number of factors apply the mining algorithms only on a set of frequent (popular) non-interesting burst and then rank th e other bursts based on how much they deviate from the ideal burst. We define an ideal burst as a func tion close to an impulse function, something that gained transient popularity without any cause and then vanished. Figure 7 depicts an ideal interesting burst. Figure 7 An Ideal Burst, X axis represents relative time with burst centered, Y axis represents normalized relative amplitude between 0 and 1. Let I be an ideal interesting burst and S be the burst that we wanted to rank, also let the Euclidean distance in wavelet transform domain as We measure the distance of bursts from the ideal burst in the wavelet transform domain and rank them based on increasing distances. The lesser the distance of a burst from the ideal burst, the greater is the burst intensity and vice versa. We define the the ideal burst is infinite. Some examples enumerating this ranking approach are shown below in Table 2. Table 2 Bursts ranked using Distance Based Ranking. For the bursty waveforms X axis indicate s time and Y axis indicates relative query frequency Bursty Query Bursty wallet (Rank 1) 1.011 paris hilton (Rank 5) treo 755p (Rank 341) Interestingness of burst for adve rtising and merchandizing utility for merchandizing each identified burst is assigned a score S as a linear function: S =  X  In +  X  D +  X  I +  X  J ; where In = interestingness of the buzz as measured through current news articles also. The idea of this scor e is to align bursts in queries to another dimension of current events. D = a score based on the demand for the buzz term on eBay measured in terms of the number of unique eBay users [9] searching for the term. I = a score based on the total inventory matching the burst query that is available for sale. J = a score based on the increase in the number of queries for the burst term as compared to previous day.  X  ,  X  ,  X  ,  X  are coefficients used to control the weightage of different factors. The bursts found by processing daily batch of queries are ranked using this scoring function. Sample daily top bursts are shown in Table 3. Table 3 Top Burst for 10 days in February 2008. These bursts were found using the incrementa l algorithm described in We would like to see if there are obvious ways to find bursts and, if so, how they differ from our approach. We try to find the start of burst periods for queries using a simpler measure and try to compare it with the results obtai ned using our approach. The measure used here is the rate of change in the frequency of a query as measured over two consecutiv e days. We refer to this as the Rate Change Method (RCM). We built an inverted index of bursts mined in section 4. This helps us find all the bursts that started on a particular day; it also helps us find all the terms that were in a high automaton state for a particular day. Note that bursts usually last more than a day, so the set of terms bursty for day x is usually a superset of the set of bursts that started on day x . We also found the rate of cha nge of query frequencies from one day to another and sorted them by the ratio of increase. For example, for June 3, 2007, we have a list that has the rate of one entry each for all the queries. The score (ratio of frequencies decrease in the frequency. Our goal is to find if a burst period for some query started on the day, by just looking at these frequency changes. Let, x = the day for which we want to compare bursts between our method and RCM Gs = set of all bursts that started on day x retrieved from our inverted index described above. Ga = set of all terms qualifying as bursty for day x retrieved from our index. n(Gs) = number of elements in set Gs. n(Ga) = number of elements in set Ga.
 As discussed above Ga Gs  X  . Also, N = n(Ga) . To do a fair comparison between the 2 methods we retrieve the top N entries from RCM for the day x . R = set of N top terms retrieved from RCM for day x . Thus, n(R) = n(Ga) = N . We define 2 measures for our comparison. =  X  and Note that  X   X  1 and  X   X  1 as the bursts detected by both the systems converge to the same set;  X   X  0 as the RCM starts missing bursts compared to our method. Similarly,  X   X  0 as RCM starts detecting bursts wh ich are not detected by our method. Table 4 shows the measurement of these 2 quantities  X  and  X  for 5 different days. Table 4 Table indicating calculated values of  X  and  X  for five different days using method discussed above Sample Number ( ) As we see from the table a bove the average values of  X  and  X  are close to 0.3 which means that the commonality in the top bursts detected between the 2 systems is not significant. RCM detects only 30% of the bursts detected by our system. Through qualitative analysis we know that our method detects most interesting burst terms with minimal false positives. As shown in section 8.3 about 70% of bursts from our system which are not detected by RCM are actually false negatives. Also 70% of the bursts detected by the RCM are just noise as they are transient spikes which are not interesting enough to detect for our use cases. RCM might see an increase in the rate of query as compared to however when looked at the query for a longer period, an external examples are shown below in Figure 8. Figure 8 Shapes of false positives detected by RCM. Each graph shows the query term and the period for which RCM wrongly detected the noisy burst. These seem to be the kind of bursts that ramped up slowly. As our model looks at longer time periods, it can see that the frequency of a query is slowly increasing and once it increases some rate of arrival, it will jump to a higher state and declare it as previous day X  X  frequency it is not be able to detect these kinds of bursts, some of which are shown below in Figure 9. For the query  X  X indsay lohan car X  example the second peak was detected by our system as a burst but not by RCM. For RCM the rate of change interesting burst.  X  X oach coupon 3-12 Jun X   X  X indsay lohan car/3 rd Jun X  
Figure 9 Examples of bursts missed by RCM. Each graph Thus we see that the RCM det ects many noisy bursts and also misses interesting bursts as compared to our model. traffic. Such examples can be found in [22][23]. We built an online application that presents daily bursts[See Figure 10].The application picks the top burst of the day and shows the trend, news items, information from wikipedia and allied sources, related queries and most importan tly relevant merchandise for the same. Figure 10 shows the page for Feb 16 th . The bursty query is  X  X harlize theron X , the online interest and buzz is probably because of the fact that during that time she announced that she would not be attending the Oscar awards . The application shows merchandize in the form of signed photos, movie tapes and also shows a link to the official site. Figure 10 Screenshot of an application using top burst of day to create a mash-up and attract online users based on curiosity In this paper we described bur st detection from queries, burst classification and ranking. We used models based on KDD technology and modified them to fit the needs of a high volume industrial context. The contribution of our work is as follows:  X  A state based system that can extract bursts from large scale  X  A practical methodology to rank and sort these bursts.  X  A way to cluster these bursts into various classes for a study.  X  A merchandizing application utilizing these bursts that are The bursts can be used for onlin e merchandizing, fraud detection, online user acquisition and also as a traffic driver. work we would like to study the demand and supply dynamics of products falling into those cla sses from an economics standpoint. [1] Baseville, M. and Nikiforov, I. V. Detection of Abrupt [2] Curry, C., Grossman, R., Locke, D ., Vejcik, S. and Bugajski, J. [3] Kleinberg, J. Bursty and Hierarchical Structure in Streams. [4] Rabiner Lawrence R., A Tutorial on Hidden Markov Models [5] Aboufadel Edward, Schlicker St even., Discovering Wavelets. [6] Hulata Eyal, Segev Ronen, Be n-Jacob Eshel., A method for [7] Vlachos Michail, Lin Jessi ca, Keogh Eamonn, Gunopulos [8] Yi Jeonghee, Detecting buzz from time-sequenced document [9] Wang X., Zhai C., Hu X, Sproat R. Mining Correlated Bursty [10] Dubinko M., Kumar R., Magnani J., Novak J., Raghavan P., [11] http://buzz.yahoo.com [12] http://www.google.com/trends [13] Shaker M. EEG Waves Classi fier using Wavelet Transform [14] Chazal P., Celler B., Reilly R. Using Wavelet Coefficients for [15] Cruden D., Hu X. The shapes of some mountain peaks in the [16] Vlachos M., Meek C ., Gunopulos D., Vagena Z. Identifying [17] Shahabi C., Chung S., Safar M. A Wavelet-Based Approach [18] Li T., Li Qi., Zhu S., Ogihara M. A Survey on Wavelet [19] Kleinberg J. Temporal Dynamics of On-Line Information [20] Lewicki M. Bayesian Modeling and Classification of Neural [21] Shyang Ho S., Wechsler H. De tecting Changes in Unlabeled [22] http://www.woot.com [23] http://wordsmith.org/awad/ 
