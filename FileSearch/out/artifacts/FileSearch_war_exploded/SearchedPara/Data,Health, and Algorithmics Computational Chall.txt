 In the decade following the completion of the Human Genome Project in 2000, the cost of sequencing DNA fell by a factor of around a million, and continues to fall. Applications of sequenc-ing in health include precise diagnosis of infection and disease, lifestyle management, and development of highly targeted treat-ments. However, the volume and complexity of the data produced by these technologies presents a severe computational challenge. Breakthroughs in methods for search, storage, and analysis are re-quired to keep pace with the flow of data, and to make use of the changes in biomedical knowledge that these technologies are cre-ating. This keynote is an overview of some of these technologies and the new computational obstacles they have engendered, and reviews examples of algorithmic innovations and approaches cur-rently being explored. These illustrate both the kinds of solutions that are required and the challenges that must be addressed to allow this data to be fully exploited.
 J.3 [ Computer applications ]: Life and medical sciences X  Biology and genetics Algorithms, Performance Knowledge of DNA and its function is key to the understanding of living organisms. A first step is to read an organism X  X  DNA, which consists of a simple alphabet of four nucleotides, or bases, into a digital form, allowing it to be processed computationally. Such reading is accomplished by sequencing, a technology employing chemistry and visual analysis that is increasingly automated, and is plummeting in cost. Within a year or so the price of reading an individual human genome could easily be less than $1000.
Sequencing is now a standard tool for biomedical research, and the use of sequencing is producing massive quantities of genetic data, and leading to innovations that have the potential to drasti-cally change medicine. This data presents biomedical scientists with opportunities to pursue new approaches to research and prac-tice. For example, such data makes it possible to identify organ-isms; to examine how bacterial communities respond to stresses such as new drugs; to examine how lifestyle and genetics inter-act; and to cheaply assemble and annotate of the complete genomic sequence of an individual. Sequencing also has sweeping implica-tions for agriculture, biofuels, and ecology.

However, the raw data produced by sequencing machines cannot be immediately used for these kinds of biomedical investigation. The most successful of the current technologies reads the DNA as fragments of 35-500 bases. The DNA is first replicated many times, as twenty-to thirty-fold redundancy is needed to give a reasonable likelihood of usable data. The fragmentation is highly non-uniform, and the read process introduces errors such as missing or misread bases. Further issues arise from the fact that genome sizes vary greatly, from a few kilobases for a virus to over 100 gigabases for some plants; the human genome is 3 gigabases. Other problems arise from the data volume. For example, on the order of a hundred gigabases of sequencing data is required to construct the genome of a human individual or to quantify activity within a cell. The computational cost of analysis may greatly exceed that of the se-quencing that produced the data, and the cost of reliable storage of the raw data for a single year could soon exceed that of production.
There are several elementary computational challenges, includ-ing storage, mapping and search, and assembly. Storage can be addressed through compression, but methods are required that take advantage of repetition between genomes rather than within an in-dividual genome. The task of mapping involves identifying the ge-nomic source of a given read. Effective techniques have been de-veloped for this task, but they do not scale well, and it is plausible that genomic repositories will soon be of the same scale as the web. The task of assembly involves finding from amongst a billion reads those that contain substrings that approximately match each other, and then stitching them together in a consistent way.

There are also more sophisticated challenges, including (to take two arbitrary examples) automated interpretation of genetic data in the context of human-curated knowledge such as annotated data-bases, and linkage of genetic data to outcomes captured in medical records. In the longer term, there is the need to link data at level of gene, molecule, cell, organ, individual, and populations  X  a task that, computationally, rivals that of climate modelling. But the po-tential benefits for human health are enormous, and solutions to these problems require widespread involvement of research com-munities such as that at CIKM.

