 Nowadays, with the rapid development of the Internet of Things (IoT)[1,4] technology, condition monitoring systems (CMS) have been widely applied to monitor varieties of equipments. For example, KOMTRAX 1 and IEM 2 both are well-known CMS, which monitor equipments through the Internet, GPS and so on. By means of CMS, a wide variety of monitor data from a large number of equipments are widely collected within a very short period of time, e.g., the data si ze of monitor data fro m equipments collected by IEM exceeding 30 G in a normal workday. If we can detect potential anomalies from these monitor data efficiently, it will e nhance the efficiency of maintenance task scheduling, reduce the loss of failing and improve the design of equipments.
Unlike most of the previous studies on anomaly detection, we focus on the latent rela-tions of multiple correlative monitor data series but not each single monitor data series. For instance, there are two sensors in an e quipment, which collect the engine tempera-ture and the engine speed respectively. Since the engine temperature varies along with the variation of the engine speed, there exists a relation between the two corresponding monitor data series. During the normal work time this relation varies within a normal range. When anomalies occur, this relation m ay exceed the normal range. We define this relation as Latent Correlation , which depicts dependencies among multiple correlative monitor data series.

However, based on the latent correlation of correlative monitor data series, detecting potential anomalies from a large amount of m onitor data faces a set of challenges. First, during design and manufacture phases, most of potential anomalies of equipments in real work circumstances are not easily foreseen and identified. For example, in the operations and poor working circumstances, which lead to all kinds of anomalies that are not identified in the design phase. Furthermore, we analyze more than 5000 real maintenance records from one kind of construction machinery and confirm that most of equipments X  anomalies are indeed not recorded or identified. Second, the amount of monitor data is too large to quickly detect anomalies. As it is not easy to foresee what kind of anomaly will happen on the equipment in real work circumstances, CMS have to collect a vast variety of monitor data as much as possible. This blind collection strategy makes the volume of collected monitor dat a increase dramatically. For example, our experimental datasets are collected from less than 300 equipments over a half year period, which have more than 50 , 000 , 000 records.

In this paper, we address the above challenges by positing that abnormal ones are a small portion in a large number of similar individuals. We present Latent Correlation based Anomaly Detection(LCAD) that can quickly detect potential anomalies from a large amount of monitor data. In LCAD, we use Latent Correlation Vector(LCV) to represent the latent correlation among multiple correlative monitor data series. Thus we model these LCVs using Latent Correlation Probabilistic Model(LCPM), a probabilis-tic distribution model which depicts the probabilistic distribution of LCVs. Based on the LCPM, we can detect anomalies accordin g to their relations with the LCPM. The anomalies detected by LCAD are defined as Abnormal Patterns . In order to validate our approach, we conduct experiments on real-world datasets and the experimental results illustrate that LCAD outperforms the previ ous approaches when facing a large amount of correlative monitor data series.

We believe that this paper mainly makes three contributions as. Firstly, we define the relation of multiple correlative monitor data series as the latent correlation. Fur-thermore, we formulate the latent correlation as the LCV, which depicts the pairwise relations of these monitor data series. Sec ondly, based on LCVs of multiple correlative monitor data series, we model these LCVs using LCPM, a probabilistic distribution model which depicts the variation range of LCVs. Thirdly, based on LCPM, we present LCAD, an anomaly detection approach which can quickly detect abnormal patterns from a large amount of monitor data. The rest of this paper is organized as follows. Section 2 reviews the related work. In Section 3 we talk about the details of LCAD. Section 4 shows the results of experiments to validate our approach. Section 5 gives a summary about this study. Most of the previous studies on anomaly detection(also called outlier detection) focused on individual time series. Figure 1 illustrates a hierarchy of individual time series for anomaly detection in the literature . There are mainly four categories in taxon-omy: (1) Classification based. Classification based anomaly detection consists of rules based[10], neural networks based[8,7] and SVM based[13]. (2) Nearest neighbor based. Nearest neighbor based anomaly detection consists of density based[2] and distance based[12,14]. (3) Cluster based. Cluster based anomaly detection like FindOut[15] and CBLOF[6], which assumes that normal data records belong to large and dense clusters while anomalies do not belong to any of the clusters or form very small clusters. (4) Sta-tistical. Eskin et al.[5] also used stochastic distribution to detect anomalies depending on their relations with this model.

There are some existing methods proposed for anomaly detectio n of multiple time series. Zhang[16] et al. detected abnormal t rend evolution from m ultiple data streams. However, it could not manage a large amount of time series, e.g. the monitor data se-ries in this paper. Papadimitriou[11] et al. proposed SPIRIT that is a streaming pattern discovery approach in multiple time serie s data streams. Chan[3] et al. proposed box modeling for multiple training series. Alt hough both approaches are able to efficiently mine multiple homogeneous time series, they are not suitable to directly mine multiple correlative time series in different dimensions. For instance, there are two categories of time series: one represents the engine temperature(temperature series) and the other time series represents the engine revolving speed(revolving series). Since the engine temperature rises with the increase of the engine revolving speed, there exists a latent positive correlation between the two time series. However, the above methods such as SPIRIT just model multiple temperature series or revolving series and lose sight of the latent correlation between two time series. Generally, existing works can not well ad-dress anomaly detection for multiple time ser ies based on a large amount of correlative time series.
 Latent Correlation based Anomaly Detection(LCAD) focuses on the latent correla-tion among multiple correlative monitor data series. For d efiniteness and without loss of generality, we first give some notations to help us explain our anomaly approach LCAD. Given there is a number of equipments of the same category denoted as E = {
E 1 ,E 2 ,...,E M } ,where E m represents an equipment. For the equipment E m ,there exist a sequence of sensors denoted as S = { S 1 ,S 2 ,...,S K } , intended to monitor dif-ferent components of equipments that produce K categories of monitor data series de-represents a monitor data series corresponding to the k -thsensorofthe m -th equipment, where v m k ( n ) is denoted as the collected values at time T n . 3.1 Segmentation of Monitor Data Series Definition 1 (Work Cycle Series). A work cycle of equipment E m is a complete work process, a complete usage of the equipment which is from the starting up to the shut-down of the equipment. A work cycle series is a segment of monitor data series in a work cycle, which is corresponding to a work cycle of an equipment. Illustrated in Fig-ure 2, there are three work cycles shown in a monitor data series(values collected with lines). Hence, this monitor data series consists of three work cycle series.
Since different equipments are operated in d ifferent work circumstances, the monitor data series collected from different equipmen ts are entirely different. As a consequence, it is not suitable to compare the monitor data series along all the collection time directly. However, no matter what kind of work circumstances and operations, the work cycle se-ries is more suitable for comparisons than th e original monitor data series because work cycle series have similar behaviors in a work cycle in spite of different equipments. 3.2 Latent Correlation Extraction Given there are a number of work cycle series in a work cycle denoted as D = { D 1 ,D 2 ,...,D K } where D k means a work cycle series of one sensor denoted as D lation Matrix(LCM) to represent the latent correlations of work cycle series. We denote the LCM of K work cycle series as LCM = { C ij } KK , where the element C ij means the Latent Correlation Par ameter(LCP) between the i -thworkcycleseries D i and j -th work cycle series D j , hence the LCP is calculated as follows: matrix, where if i = j ,theLCP C ij is the covariance of the i -thworkcycleseriesand the j -thworkcycleseries,if i = j ,theLCP C ij (diagonal element) is the variance. In order to ease the difficulty of modeling, we compress the LCM to the Latent Correlation Vector(LCV) denoted as LCV = {  X  1 , X  2 ,..., X  K } illustrated as Formula 2. The element  X  k of LCV is the k -th eigenvalue of LCM.

In formula 2, U is an unit matrix. Hence, we conduct the LCVs of these work cycle series to depict the latent correlations among these work cycle series in a work cycle. 3.3 Latent Correlation Probabilistic Model In each work cycle, there are a corresponding LCV to represent the latent correlation of these correlative work cycle series. Hence, let LCV 1 , LCV 2 ,..., LCV M denote as a sequence of LCVs, where LCV m = {  X  m 1 , X  m 2 ,..., X  m T } . Central Limit Theorem 3 in statistic also tells us that most similar individuals have similar behaviors and abnormal ones behave differently from the others. Sim ilarly there is a conclusion: abnormal LCVs are a small portion in the sequence of LCVs, which is corresponding to abnormal pat-terns. According to Central Limit Theorem , we choose the Multidimensional Normal Distribution to formulate these LCVs.
In Formula 3,  X  and  X  represent the covariance matrix and the average vector of the multivariate gaussian distribution resp ectively, which determine the LCPM of this sequence of LCVs. We apply the maximum likelihood estimation(MLE) to calculate these parameters. 3.4 Abnormal Pattern Detection BasedontheLCPM,wedefine Abnormal Pattern Detection Function (APDF) of the LCVs denoted as follows:
In the APDF, parameters  X  and  X  mean the covariance matrix and the average vector of LCPM calculated as shown in Formula 3. In the experiment the parameter  X  is equal to 3 . The input of APDF is an LCV or a sequence of LCVs. The output of APDF is a boolean value, 1 means that the input LCV is an anomaly corresponding to an abnormal pattern of equipments and 0 means the input LCV is normal. 4.1 Data Preparation We conduct experiments on real-world datasets which come from a Chinese well-known construction machinery manufacturer. The original datasets contains three sub-datasets, corresponding to the three main components of pump concrete trucks: pumping system( Pump-sys ), cantilever system( Can-sys ) and underpan system( Under-sys ) of pump concrete trucks. The statistics of the three sub-datasets from pump con-crete trucks are shown in Table 1.

AsshowninTable1,weapply 52 , 837 , 512 monitor data records to the real ex-periments collected from 279 pump concrete trucks. There are 376 sensors in each equipment that produce 376 monitor data series over half a year period. Further-more, there are 12 , 269 , 632 work cycle series( 32 , 632 work cycle multiplies 376 types of monitor data series.). The three sub-datasets Pump-sys , Can-sys and Under-sys have 5 , 775 , 864 , 4 , 437 , 952 and 2 , 055 , 816 work cycle series respectively. Each sub-datasets has its corresponding LCPM, as there are too much parameters, we will not illustrate the three LCPMs in the experiment. 4.2 Baselines and Evaluation Methodology Baselines. We consider our proposed LCPM for anomaly detection on the three sub-datasets: Pump-sys , Can-sys and Under-sys . Actually there are not relative approaches for anomaly detection, LCPM focuses on a sequence of work cycle series but the previ-ous focus on one single work cycle series. In the experiments we compare our proposed LCPM with three baseline approaches: (1) Local Outlier Factor (LOF) approach[2] . For each work cycle series D k = average local reachability density of D k k-nearest neighbors and local reachability density of this work cycle series. (2) Connectivity Outlier Factor approach[14] .For each work cycle series D k = liers as points whose neighborhoods is sparser than the neighborhoods of their neigh-bors. (3) Cluster based Local Outlier Factor (CBLOF)[9] . For each work cycle series D determine CBLOF for each work cycle series measured by both the size of the cluster and the distance to the cluster.
 Evaluation Metrics. We evaluate the prediction performance of the above algorithms using 3 metrics: Recall (detection rate), P recision and AUC(area under the ROC curve). Generally, Recall measures the ratio between the number of correctly detected anoma-lies and the total number of anomalies, Precision measures the ratio between the number of correctly detected anomalies and the t otal number of detected anomalies, and AUC measures the tradeoff between Recall and Precision. 4.3 Experimental Results and Analysis We present the evaluation results in Table 2. As highlighted in bold, latent correlation anomaly detection(LCAD) consistently outperforms other approaches on most sub-datasets and most metrics. The performan ces of LCAD far exceeds that of the other approaches on most metrics, demonstrating the importance and effectiveness of latent correlations among condition data series in LCAD and extracting the latent correlation vector in LCPM.

LOF is a nearest neighbor approach based o n the reachability distance, another work which calculates the local reachability density to determine the LOF of data records. COF almost achieves better performan ces as compared to LOF, which is based on the average chain distance. Furthermore, CBLOF outperforms than the two KNN ap-proaches LOF and COF on Can-sys and Under-sys , which is a cluster approach for anomaly detection based on LOF. However, it fails on Pump-sys because data are sparse and distances between any two data record s may become quite similar in high dimen-sional spaces.

Though the precision ratio of LCPM on Can-sys is 0.005 less than that of CBLOF, the recall ratio and AUC of LCPM both are much higher than that of CBLOF. There are similar experimental results on Under-sys . As a whole, LCAD is not only accurate but also stable than others. This convinces us that the latent relation among work cycle series can help detect more potential anomalies. 4.4 Implementation and Discussion In real detecting circumstances, there ar e two ways to implement LCAD: offline detec-tion and online detection. Offline detection focuses on the pre-existing monitor data and ignores the real time incremental monitor data. It detects all the monitor data in batch at regular intervals. This paper X  X  experiments are based on offline detection. Online de-tection focuses on the real time monitor data only. It detects the real-time incremental monitor data in real time. We have also applied this type of detection method in a real CMS. Quickly detecting potential anomalies from a large amount of monitor data is very im-portant for us to better know the working condition of equipments. In this paper, we model the latent correlations of monitor data using LCPM, a probabilistic distribution which assumes that abnormal ones are a small portion in most of similar individu-als. Based on LCPM, we proposed LCAD, an anomaly detection approach which can quickly detect potential anomalies from a large amount of monitor data. Our approach achieves promising performances in experi mental studies, which leads us to draw the conclusion that our proposed LCAD indeed detect more potential anomalies as com-pared to the previous approaches.

Our future work mainly includes the model selection, the model training and the conduction experiments on different datasets . Furthermore, the further analysis of the abnormal patterns detected by LCAD is also an interesting question.

