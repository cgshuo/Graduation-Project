 Modeling aggregate market response is a core issue in marketing research. In this research, we extend previous forecasting comparative research by comparing the forecasting accuracy of feed-forward neural network models to the premier market modeling technique, Multiplicative Competitive Interaction (MCI) models. Forecasts are compared in two separate studies: (1) the Information Resources Inc. (IRI) coffee dataset from Marion, IN and (2) the A.C. Nielsen catsup dataset from Sioux Falls, SD. Our results suggest neural networks are a useful substitute for MCI models when there are too few observations available to estimate a fully-extended MCI model. Implications are discussed. neural networks, market response model, sales/market share forecasting Modeling aggregate market response is a core issue in marketing research (Cooper and Nakanishi 1988), and the most widely used market share modeling approach is the multiplicative competitive interaction (MCI) model (Cooper and Nakanishi 1988). To model market response, a variety of parametric and non-parametric modeling techniques are available to the researcher, and there is a history of forecasting comparisons between linear, multiplicative and MCI market models. Kumar (1994) summarizes and extends this important stream of research, and recent research suggests the MCI model produces market share forecasts superior to those from simpler linear or multiplicative models (Kumar and Heath 1990). lying between zero and one, while summing over all brands to unity (Naert and Bultez 1973; Nakanishi and Cooper 1974; McGuire and Weiss 1976). This modeling technique offers many alternative model formulations, such as the fully-extended MCI formulation (Carpenter, et al 1988), which can estimate the cross-effects of one brand X  X  marketing mix on the attraction of another brand. amount of data due to the large number of parameters that are estimated. For N brands and M marketing mix variables, there are (M*N) variables in each market share equation. If serial correlation is not a concern, then each equation can be estimated promotions and advertising, serial correlation is often pronounced in market response data. In such a case, a system of N-1 simultaneously. This requirement often overwhelms the number of observations in the data available. market response include non-linearities, asymmetric cross-effects and interactions among the input variables over short time periods (Sharda 1994; Hanssens, Parsons and Schultz 1990: 37-45). Therefore, the MCI model formulation often requires dramatic simplification to ensure that the model parameters can be estimated. neural networks (Rumelhart and McClelland 1986), have been methodologies such as time series techniques (Sharda and Patil 1990), regression based techniques (Refenes, Zapranis and Francis 1994; Gorr, Nagin and S zczypula 1994; Chiang, Urban and Baldridge 1996), ANOVA analysis (Bejou, Wray and Ingram 1996), and traditional clustering techniques (Chen, Mangiameli and West 1996). traditional forecasting techniques in certain c onditions (e.g. Hornik et al 1989), such as when non-linearities are present (e.g. Rumelhart and McClelland 1986; White and Stinchcombe 1992), discontinuities are present (e.g. Hill et al 1996), and when there are significant interactions among inputs (e.g. Rumelhart and McClelland 1986). These are the same type of data complexities commonly faced by those modeling market res ponse. comparative research by comparing the forecasting accuracy of feed-forward neural network models to several MCI model formulations. Comparisons are performed in two separate studies: the Information Resources Inc. (IRI) coffee dataset from Marion, IN and the A.C. Nielsen catsup dataset from Sioux Falls, SD. description of the market models used in this study is followed by a description of the comparison criteria. Following this is a description of the studies. The paper closes with a discussion of the results and concluding comments. In this section we briefly describe the structural market models used in this comparative study. The neural network market models utilized in this study are fully-connected 3-layer feed-forward neural networks estimated using Backpropagation (Rumelhart and McClelland 1986). training parameters are at the core of many criticisms of neural networks (Tam and Kiang 1992). To estimate these architecture sample into estimation and hold-out samples. Following Gorr, Nagin and Szczypula ( 1994), we (1) trained a network with the parameter values of a grid point and calculated the resulting SSE for the estimation set, (2) performed a complete enumeration of SSE for all grid points and selected the minimum SSE grid point, and (3) trained the resulting network to this minimum SSE and forecast the hold-out sample using a one-step-ahead rolling design. connected neural networks were estimated, one for each brand The input for each network include price, feature index, display index for each of the 7 brands plus lagged market share, resulting in 22 (3*7+1) inputs, the output was market share for that brand. The best-fit model configuration resulting from the grid search (detailed previously) contained 7 intermediate nodes, learning constant of 0.2, and momentum constant of 0.8. Market share forecasts were made using a one-step-ahead rolling design. connected neural networks were estimated, one for each brand. The input for each network include price for each of the 4 brands plus lagged market share, resulting in 5 (1*4+1) inputs, the output was market share for that brand. The best-fit model configuration resulting from the grid search (detailed previously) contained 4 intermediate nodes, learning constant of 0.2, and momentum constant of 0.8. Market share forecasts were made using a one-step-ahead rolling design. MCI model formulation and estimation has been extensively detailed in the forecasting and modeling (e.g. C ooper and Nakanishi 1988) literatures. The general form of a market share attraction model has the following structure: (1) m i = a i /  X  j a j share, for brand i, and: (2) a i = exp(  X  i +  X  i mix variable h for brand j,  X  i is a white noise error term, and a attraction value of brand i. model given by equation (1) yields logically consistent estimates of market share for each brand, i.e. 0  X  m i  X  1 and following assumptions: a i  X  0,  X  n a n &gt; 0, if a i a then m 1 = m 2 , and if the attraction of a competitor of a product i increases by some amount  X  , then the new market share of product i will not depend on which competitor made the increase. formulations. The constant-effects MCI model assumes that all brands have the same coefficients (  X  hii - X  hjj =  X  for each marketing mix variable (  X  hij = 0 for i  X  j). The fully-extended asymmetric cross-effects model has no restrictions on the parameters. The complex denominator of the MCI model requires a transformation in order to derive estimation equations. In these applications, we use the log-ratio transformation (Theil 1969), developed in a marketing context by McGuire, Weiss and Houston (1977). influence of past marketing actions on current consumer behavior, requires modification of the basic model formulation. Following Durbin (1960), we formulated a regression model with spherical disturbances by including lagged dependent and independent resulting equations is accomplished using Zellner X  X  ( 1962) Seemingly Unrelated Regression (SUR) procedure. brands and three (price, feature and display) marketing mix variables. A fully-extended MCI market share model (adjusted for serial correlation) would require the estimation of 259 parameters. Estimating this many parameters would require at least 260 estimation sample, the fully-extended MCI model could not be estimated from the available data. Therefore, we estimated a reduced form of the MCI model, specifically the differential differential-effects MCI model, it may appear that we have stacked the deck in favor of the neural network modeling approach, an issue which is addressed in the catsup studies. We estimated the log-ratio (McGuire, Weiss and Houston 1977) version of the differential effects MCI model adjusted for serial correlation (Durbin 1960) using Zellner X  X  (1962) SUR procedure as implemented in SAS. MCI model with price as the only current period marketing mix variable. We estimated a four brand, one variable fully-extended (main and cross effects) MCI model adjusted for serial correlation. As in the coffee market study, we used the log-ratio transformation, and estimated the coefficients using SUR as implemented in SAS. Forecasting accuracy for the estimation and hold-out samples were evaluated using MAPE -the mean absolute percentage error (Makridakis 1993). Two studies were performed using two scanner panel data sets. Each study will be discussed separately. Using the IRI BehaviorScan scanner panel data provided from the Marion, IN market, we computed the weekly shares for the top 7 brands in the ground regular coffee market by aggregating store level scanner panels data across all grinds, sizes and stores. These brands represent more than 90% of all panelist purchases from March 1981 to April 1982, resulting in 58 week of data 3 . We split the 58 week sample into a 49 week estimation sample and a 9 week hold-out sample. dependent and independent variables. The dependent variable, market share, was aggregated across all grinds, sizes and stores. The independent variables include price, feature, display, and lagged market share. Price was measured in dollars per ounce, net of any discounts. activities, we utilized the distinctiveness index (Nakanishi, Cooper and Kassarjian 1974) which takes on values of 1.0 if all or none of the brands are on feature (display) in a given week. For other circumstances, the index is: brands on feature (display) in a given week. The sample profile for the independent and dependent variables are presented in Table 1. Using the A.C. Nielsen catsup dataset provided from the Sioux Falls, SD market, we computed the weekly shares for the top 4 brands by aggregating store level scanning records across sizes and stores. These brands represent more than 90% of all purchases from August 1985 to August 1988, resulting in 156 weeks of data. We split the 156 week sample into a 146 week estimation sample and a 10 week hold-out sample. dependent and independent variables. The dependent variable, market share, was aggregated across all sizes and stores. The independent variables were price and lagged market share. Price was measured in cents per pound. The sample profile for the independent and dependent variables are presented in Table 2. Folg. Folg. Std dev Folg. Folg. Std dev Folg. Folg. Std dev Market Share Folg. Folg. Std dev Price Hunts Del Std dev 0.04 0.06 0.05 0.02 Hunts Del Std dev 0.08 0.06 0.10 0.02 We compared forecasting accuracy for the estimation and hold-out sample. These forecasting results are presented in Table 3. For the estimation sample, the neural network had a lower MAPE for six of seven brands. For the hold-out sample, the forecasts from the neural network had lower MAPE for all brands. Neither model predicted the hold-out sample for Chase &amp; Sandborn well, due, in part, to its very low market share. For the estimation sample, the neural network had a lower MAPE for six of seven brands. For the hold-out sample, the forecasts from the neural network had lower MAPE for all brands. Neither model predicted the hold-out sample for Chase &amp; Sandborn well, due, in part, to its very low market share. two models were small for the estimation sample. However, there were large differences in forecast accuracy in the hold-out sample. the brands. better than the MCI model (for 7 of 7 brands using MAPE). This estimation data. If they were, the neural networks would be unable to predict well in the hold-out sample (e.g. Refenes, et al 1994). The forecasting accuracy for the fully-extended MCI and neural network models were compared for both the estimation and hold-out samples. The results are presented in Table 4. neural network model directly, the MCI model fit the estimation networks forecast better than the MCI model only for the largest brand, Heinz. network models perform compared to existing leading-edge models of market response. The empirical comparisons presented here were not chosen at random. The coffee dataset was utilized b ecause there were too few observations to estimate the fully-extended MCI model, and the catsup dataset was utilized because there were enough observations to exploit the power of the fully-extended model. Overall, the neural network models performed better than the MCI models when insufficient data forced the estimation of an under-specified MCI model. When there was sufficient data to estimate a fully-extended MCI model, the MCI model had marginally better performance than the neural network. techniques tend to model human decision tasks as in Gorr, et al which compare neural networks and regression models using real multivariate forecasting data. While there is one such marketing application (Hruschka 1993), it compares a simple neural network to a linear sales model in a non-competitive (monopoly) situation using monthly data. Our study uses state-of-the-art data sources (household-level and store-level data) and market response models in competitive markets. might be a useful substitute for MCI models. Neural networks are trained using an iterative optimization procedure, where the MCI model was estimated using SUR that is based on asymptotic theory. present, and there are too few observations to estimate a fully-extended MCI model, our research shows that a neural network will outperform a simplified MCI model. Otherwise, we found that there is no advantage to neural networks in stable markets with few brands. This finding is consistent with previous research, which suggests that the advantages of neural networks are restricted to specific types of forecasting problems (Hill et al 1994). Namely, few product categories exist where there are no product introductions or withdrawals for enough periods to estimate a fully-extended MCI model. In these instances, neural networks offer the brand manager a rich and powerful tool that can be used to model complex relationships and forecast sales. Information Resources Inc., A.C. Nielsen and the Marketing Science Institute graciously provided access to the data used in this study. 
Neural network formulation and estimation issues have been extensively detailed in the forecasting literature (Gorr 1994), and are therefore omitted from this paper for brevity. The neural networks were written in Visual Basic 4.0 using NeuroWindows 4.0 DLL. All networks were trained on an IBM-type Pentium II 233 PC running Windows  X  95. In IRI-coded week 78, there was an entry of a major new brand -Master Blend. Some previous research using this database seems to have ignored this event (e.g. Gupta 1988). [1] Bejou, D., Wray, B., and Ingram, T.N. Determinants of [2] Bell, D.E., Keeney, R.L. and Little, J.D. A Market Share [3] Carpenter, G.S., Cooper, L.G., Hanssens, D.M., and Midgley, [4] Chen, S.K., Mangiameli, P., and West, D.The Comparative [5] Chiang, W.C., Urban, T.L., and Baldridge, G.W. A Neural [6] Cooper, L.G. Market Share Models. In Handbook of [7] Cooper, L.G. and Nakanishi, M. Market-Share Analysis. [8] Durbin, J. Estimation of Parameters in Time-Series Models. [9] Gorr, W.L. A Research Prospective on Neural Network [10] Gorr, W.L., Nagin, D., and Szczypula, J. Comparative Study [11] Gupta, S. Impact of Sales Promotion on When, What and [12] Hanssens, D.M., Parsons, L.J., and Schultz, R.L Marketing [13] Hill, T., O  X  Connor, M., and Remus, W. Neural Network [14] Hornik, K., Stinchcombe, M., and White, H. Multilayer [15] Hruschka, H. Determining Market Response Functions by [16] Kumar, V. Forecasting Performance of Market Share Models: [17] Kumar, V. and Heath, T.B. A Comparative Study of Market [18] Makridakis, S. Accuracy Measures: Theoretical and Practical [19] McGuire, T.W. and Weiss, D.L. Logically Consistent Market [20] McGuire, T.W., Weiss, D.L., and Houston, F.S. Consistent [21] Naert, P.A. and Bultez, A. Logically Consistent Market Share [22] Nakanishi, M. and Cooper, L.G. Parameter Estimation for a [23] Nakanishi, M., Cooper, L.G., and Kassarjian, H. Voting for a [25] Rumelhart, D.E., and McClelland, J. Parallel Distributed [26] Sharda, R., Neural Networks for the MS/OR Analyst: An [27] Sharda, R., and Patil, R.B. Neural Network as Forecasting [28] Tam, K.Y. and Kiang, M.Y. Managerial Applications of [29] Theil, H. A Multinomial Extension of the Linear Logit [30] White, H. and Stinchcombe, M. Approximating and Learning [31] Zellner, A. An Efficient Method of Estimating Seemingly Thomas S. Gruca Ph.D. is an Associate Professor in Marketing at the University of Iowa. His areas of research interest include marketing strategy and market structure. Bruce R. Klemz is an Assistant Professor of Marketing at the University of Nebraska at Kearney. His areas of research interest include advanced software tools to address such areas as competitor analysis, positioning and customer service. E. Ann Furr Petersen is a doctoral student in Marketing at the University of Iowa. Her dissertation research focuses on consumer choice among the complex options present in cafeteria-style 
