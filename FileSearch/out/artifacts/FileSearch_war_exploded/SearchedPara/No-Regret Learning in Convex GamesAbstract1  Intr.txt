 Geoffrey J. Gordon ggordon@cs.cmu.edu Amy Greenwald amy@cs.brown.edu Casey Marks casey@cs.brown.edu We wish to build agents that can learn to act effec-tively in multiagent decision problems. We represent such problems as general-sum games: each agent i is given a feasible region A i from which to choose an ac-tion a i . The payoff to agent i depends not only on i  X  X  choice, but also on the actions a  X  i chosen by other agents. Since we are modeling learning, we assume that each agent knows only its own feasible region and observes only its own payoff structure. So, an agent cannot simply compute an equilibrium of the game and play it (even leaving aside the complexity of such a computation and the problem of coordinating with other agents on an equilibrium). All an agent can do is learn a preferred course of action by playing the game repeatedly and observing its own payoffs.
 What, then, is an appropriate goal for a learning agent? Unlike zero-sum games, general-sum games do not have a well-defined value : even if we had com-plete knowledge of the game and all players were com-pletely rational, we would not be able to predict how much payoff we should receive. Instead, researchers have defined other goals for learning agents. One popular one is regret minimization. For example, a number of previous algorithms have been designed to minimize external regret (defined in Sec. 2) in convex games, including Generalized Gradient Descent (Gor-don, 1999b), GIGA (Zinkevich, 2003), Follow the Per-turbed Leader (Kalai &amp; Vempala, 2003), Lagrangian Hedging (Gordon, 2006), and algorithms based on Fenchel duality (Shalev-Shwartz &amp; Singer, 2006). However, no external regret may not be a sufficient goal: a set of agents can all achieve no external re-gret (which guarantees that the empirical distribution of joint play converges to the set of coarse correlated equilibria , defined in Sec. 4) and still have an incentive to change their play. For example, a no-external-regret learner can consistently observe that its average pay-off per trial would have been higher if it had chosen action a 0 every time that it actually played a , and yet never switch to playing action a 0 in these situations. To avoid such behavior, we seek algorithms that pro-vide guarantees stronger than no external regret. In a seminal paper, Foster and Vohra (1997) present an algorithm that exhibits no internal regret (defined in Sec. 2) in matrix games, and further, show that if all players achieve no internal regret, the empirical distri-bution of joint play converges to the set of correlated equilibria (see Sec. 4). This guarantee rules out pre-cisely the anomalous behavior described above. Stoltz and Lugosi (2007) generalize these results to convex games. Extending the framework of Greenwald and Jafari (2003) for matrix games, they define a con-tinuum of regret measures called  X -regret, as well as corresponding  X -equilibria, for convex games. Given a feasible region A ,  X  is a collection of action transfor-mations ; that is, each  X   X   X  is a function from A to itself. An agent calculates its  X -regret by comparing the losses it obtained during its past history of play to the losses it would have obtained had it transformed each action it played according to some  X   X   X . Different choices of  X  lead to different types of regret and corresponding equilibria. In matrix games, the only two regret types known to be of interest are the above-mentioned external and internal regret. No in-ternal regret is equivalent to no swap regret, in which  X  is the set of all transformations from A to itself. In convex games, by contrast, there is a much richer va-riety of regret concepts. We identify and analyze two novel regret types, which we call extensive-form and finite-element regret. We also analyze linear regret. Each of these regret types is distinct from the others and from external and swap regret. In fact, they form a progression: no swap regret (the strongest property) implies no finite element regret, which implies no linear regret, which implies no extensive-form regret, which implies no external regret (the weakest property). Different regret types require different regret-minimization algorithms. For convex games, until re-cently, most algorithms minimized only external re-gret. More recently, Stoltz and Lugosi (2007) proved the existence of a no-swap-regret algorithm, and Hazan and Kale (2007) derived an algorithm that exhibits no  X -regret for any set  X  which is the convex hull of a fi-nite set of transformations. Simultaneously and inde-pendently, we developed an algorithm similar to Hazan and Kale X  X : our algorithm handled more-general rep-resentations of transformation sets, but required exact fixed-point calculations (Gordon et al., 2007). Unfortunately, constructing an algorithm according to Stoltz and Lugosi X  X  proof would be prohibitively ex-pensive: both the time and space requirements would grow exponentially with the number of rounds. And, Hazan and Kale X  X  algorithm, which runs in time poly-nomial in the number of corners of  X , can also be pro-hibitively expensive: for example, if A is the unit cube in R d and  X  is the set of linear transformations that map A to itself, then  X , which is the Cartesian product of d copies of the unit L 1 ball, has (2 d ) d corners. In this work, we extend our earlier algorithms and proofs, unifying them with Hazan and Kale X  X . The result is an algorithm which accommodates more-efficient representations of  X . In the example above, the natural representation of  X  is as a set of d  X  d matrices satisfying certain linear constraints. Using this representation, our algorithm runs in time poly-nomial in d  X  X n exponential speedup. In general, we can efficiently achieve no linear regret so long as we can efficiently optimize over the set of linear mappings from A to itself.
 We also instantiate our algorithm for extensive-form and finite-element regret. These regret types are im-portant in practice: extensive-form regret corresponds to extensive-form correlated equilibrium (Forges &amp; von Stengel, 2002), arguably the most natural notion of equilibrium in extensive-form games. And, our no-finite-element-regret algorithm, with a simple modi-fication described below, guarantees that the empiri-cal distribution of joint play converges to a correlated equilibrium.
 For extensive-form regret, our algorithm is polynomial in the dimension of the action set A ; we are not aware of any prior no-extensive-form-regret algorithms. For finite-element regret, our algorithm is polynomial in the dimension of the action set and in the size of a finite-element mesh that covers  X . Although the nec-essary mesh for some choices of  X  is quite large, our algorithm is still by far the most efficient known that guarantees convergence to correlated equilibrium. When playing a repeated convex game, a single agent X  X  learning problem is called an online convex pro-gram (OCP): in each round t , the agent chooses an action a t  X  A . At the same time, forces external to the agent choose a convex loss function l t  X  L . (A loss is just a negative payoff.) The agent observes l t and pays l ( a t ). The action space A is assumed to be a convex and compact subset of R d . The set L includes convex loss functions with bounded subgradients. The com-monly studied experts problem is a special case of an OCP in which the feasible region is the probability simplex in R d .
 A learning algorithm takes as input a sequence of loss functions l t and produces as output a sequence of actions a t . Action a t may depend on l 1 ...l t  X  1 , but not on l t or later loss functions. The learner X  X  objective is to minimize its cumulative loss, L t = P T t =1 l t ( a t The minimum achievable loss depends on the specific sequence l t . To measure how well a learning algorithm performs against a given sequence, we calculate its re-gret . The simplest type of regret is called external regret, and is defined as follows: That is, the external regret is the difference between the actual loss achieved and the smallest possible loss that could have been achieved on the sequence l t by playing a fixed a  X  A .
 We say that an algorithm A exhibits no external re-gret for feasible region A and set L if we can guarantee that its average external regret per trial eventually falls below any &gt; 0, regardless of the particular sequence l . In other words, A exhibits no external regret if there is a function f ( T,A,L ) which is o ( T ) for any fixed A and L , such that for all a  X  A, t  X  1 The function f can depend on A and L in complicated ways, but usually depends on properties like the di-ameter of A under some norm, or the length of  X  X  ( a ) under some norm for a  X  A and l  X  L .
 More generally, an agent can consider replacing its se-quence a 1 ...a t with  X  ( a 1 ) ... X  ( a t ), where  X  is some action transformation , that is, a measurable func-tion that maps A into itself. If  X  is a set of such action transformations, we define an algorithm X  X   X  -regret as and we say that it exhibits no  X  -regret if it satisfies the following analogue of Eq. 1: for all  X   X   X  , t  X  1 where g ( T,A,L,  X ) is o ( T ) for any fixed A , L , and  X . Note that external regret is just  X -regret with  X  equal to the set of constant transformations: i.e.,  X  EXT = {  X  x | x  X  A } , where  X  x ( a ) = x . By setting  X  to larger, more flexible transformation sets, we can define stronger varieties of regret. However, before studying any specific regret types in detail, we next discuss how to achieve no  X -regret for general  X . 2.1. General  X  In this section, we develop an algorithm A that ex-hibits no  X -regret for any suitable  X   X  A 7 X  A . The algorithm itself is fairly simple, and embodies essen-tially the same idea that was proposed earlier by Gor-don et al. (2007) and Hazan and Kale (2007). How-ever, we develop the idea here so that it applies to a more general class of transformation sets  X  than con-sidered previously, and provide a proof that it achieves no  X -regret under more general conditions. Our ex-tra generality is crucial for developing efficient imple-mentations for important choices of  X  including linear, extensive-form, and finite-element transformations. 1 Our  X -regret minimizing algorithm A is described in Fig. 1. It takes as input a sequence of loss functions l  X  L and outputs a sequence of actions a t  X  A , which, we will show, satisfies Eq. 2.
 In designing A , we assume that we have access to sub-routines A 0 and A 00 . The subroutine A 0 computes ap-proximate fixed points of transformations  X   X   X . That is, given any  X   X   X  and any &gt; 0, A 0 returns some a  X  A such that k a  X   X  ( a ) k A  X  . Here, k X k A is an arbi-trary norm on R d . The subroutine A 00 is an external-regret minimizing algorithm whose feasible region is  X ; we assume that its regret bound is o ( T ) whenever we can provide a bound (in an appropriate norm) on the subgradients of the loss functions it encounters. Since algorithm A accesses the transformation set  X  only through the subroutines A 0 and A 00 , it does not depend on any special properties of  X  beyond the ex-istence of these subroutines. To state our theorem, though, we will embed  X  in a vector space, as follows. Since A  X  R d , we can write  X   X   X  as a d -tuple of  X  X oordinate X  functions (  X  1 , X  2 ,..., X  d ),  X  i : A  X  R For all  X   X   X  and i = 1 ...d , we assume  X  i is a mem-ber of some reproducing-kernel Hilbert space (RKHS) H  X  A 7 X  R . 2 Finally, we assume that  X  is a convex and compact subset of H d .
 To make these assumptions concrete, suppose for ex-ample that  X  is the convex hull of a finite set of trans-formations {  X  1 ,..., X  p } : i.e., (This is the case treated by Hazan and Kale.) If we take H to be the span of all of the coordinate functions  X  , then  X  is a simplex in H d with corners  X  j , for j = 1 ...p . (In general,  X  X  X  shape may be much more complicated than a simplex, as we will see for example in the definition of  X  FE below.) To bound the  X -regret of algorithm A , we will need bounds on the actions a and the loss-function subgra-dients  X  X  ( a ), for all l  X  L and a  X  A . In particular, we will suppose that k a k A  X  C 1 and k  X  X  ( a ) k A  X   X  C 2 any a  X  A , any l  X  L , and some constants C 1 ,C 2 &gt; 0. Here k  X  k A  X  is the norm that is dual to k  X  k A . Theorem 1 Fix a convex and compact feasible region A and a set of loss functions L satisfying the above norm bounds, as well as a set of transformations  X   X  H d , where H  X  A 7 X  R is a RKHS. Assume we are given an algorithm A 00 which, for any set of possible loss functions M with bounded subgradients, achieves no external regret on  X  . Also assume we are given an algorithm A 0 which can compute an approximate fixed point of any  X   X   X  . Then algorithm A , using subroutines A 0 and A 00 , achieves no  X  -regret. Proof: Define the set of functions M  X   X  7 X  R as M = { l (  X  ( a )) | l  X  L,a  X  A } . Note that each m  X  M is convex because each l  X  L is convex and  X  ( a ) is linear in  X  . Moreover, the norm of the subgradient of any m  X  M at any point  X   X   X  is bounded by C 1 C 2 . (A proof of this fact, as well as a definition of the appropriate norm, is given by Gordon et al. (2008).) Because A 00 exhibits no external regret on  X  with the bounded-subgradient set of potential loss functions M , where f is sublinear in T . So, by the definition of m t ,
X But, since k  X  t ( a t )  X  a t k A  X  t and k  X  X  t ( a t ) k C , we have by H  X older X  X  inequality that l t ( a t )  X  l (  X  t ( a t )) + t C 2 . So, X no- X -regret guarantee.
 Clearly, the run-time of A depends on the run-times of its subroutines. In particular, since A requires that A  X  X  accuracy parameter approach 0 as T increases, it is important that A 0 run efficiently even for small . We will discuss run-times in more detail in the con-text of specific examples below. For now, we note the following trivial generalization of a result due to Hazan and Kale: if the fixed-point algorithm A 0 is a FPTAS, and if the no-external-regret algorithm A 00 runs in polynomial time, then A can process T actions and loss functions in time polynomial in T . Hazan and Kale allow run-times to be polynomial in the number of corners of  X  (among other parameters); this ren-ders their efficiency guarantees meaningless when  X  has many corners. With our more-efficient represen-tations of  X , we can replace the dependence on the number of corners with parameters like the dimension of  X  and the norm bounds for a  X  A and  X  X  for l  X  L ; since these latter parameters can be much smaller, the result will be a much faster run-time.
 As described so far, the algorithm A is deterministic if its subroutines A 0 and A 00 are. Below, we will also define a randomized variant of A , to strengthen the connection to game-theoretic equilibria. 2.2. Finite-dimensional  X  We defined algorithm A in terms of a generic set of transformations  X   X  H d , where H is a RKHS, and each element of H is a real-valued function on A . (So, each  X   X   X  is a d -tuple of real-valued functions on A , which we interpret as a function from A to R d .) Because of the reproducing-kernel property, comput-ing component  X  i ( a ) of some  X   X  H d for a  X  A is the same as computing the inner product  X   X  i ,K ( a )  X  . In other words, each  X  i is the composition of a fixed, possibly-nonlinear function K (  X  ) with a linear mapping  X   X  i ,  X  X  . This is the so-called  X  X ernel trick X  (Cortes &amp; Vapnik, 1995): first, K computes a vector of features of the action a . The inner product with  X  i then com-bines all of these features to produce the final output  X  ( a ). To evaluate  X  ( a ) in its entirety, we can compute K ( a ) once, and then evaluate the d inner products  X   X  1 ,K ( a )  X  ,...,  X   X  d ,K ( a )  X  .
 In this paper, we are chiefly interested in cases where the dimension of H is manageable, so that we can di-rectly write down and work with the transformations  X   X  H d . So, for the remainder of the paper, we will assume that H is isomorphic to R p for some finite p . We will also restrict our interest to linear loss func-tions l t ( a ) = a  X   X  X  t . This is without loss of generality, since we can achieve no regret for a sequence of convex loss functions l t by working with appropriately-chosen linear lower bounds on each l t (Gordon, 1999a). With these additional assumptions, the steps of A can be simplified: each derived loss function m t is linear, and can be described by its subgradient as follows:  X  X  t (  X  ) =  X  ( l t (  X  ( a t ))) =  X  (  X  ( a t )  X   X  X  t The subgradient  X  X  t is a d  X  p matrix, since  X  X  t is a d -vector and K ( a t ) is a p -vector. Each transforma-tion  X  also corresponds to a d  X  p matrix (a d -tuple of p -vectors). To evaluate the loss function m t on a transformation  X  , we take the dot product  X  X  t  X   X  , which is defined to be tr(  X  X  t T  X  ) = tr( K ( a t )  X  X  t tr(  X  X  t T  X K ( a t )) =  X  X  t T  X K ( a t ).
 As we will see in the next section, a number of interest-ing transformation sets can be represented as d  X  p ma-trices. Representing transformations and subgradients in this way means we can manipulate them efficiently, and, in turn, design efficient no-regret algorithms. We now instantiate our algorithm with various trans-formation sets  X . We define each  X  as a set of d  X  p ma-trices  X  , together with a kernel function K : A 7 X  R p , with the guarantee that  X K ( a )  X  A for all a  X  A and  X   X   X . To minimize each ensuing regret type, we go on to identify efficient subroutines A 0 and A 00 for find-ing fixed points and achieving no external regret. (All other calculations in our algorithm are O ( pd ), so these subroutines will usually be what limits our efficiency.) For completeness, we also mention  X  EXT , the set of constant transformations on A , and  X  SWAP , the set of all measurable transformations on A .  X  EXT is the weakest form of regret of interest here, and  X  SWAP the strongest. These are the only two regret types known to be of interest in matrix games (no swap regret and no internal regret are equivalent in this setting). In convex games, however, there is a much richer va-riety of interesting regret concepts. Below, we analyze linear, finite-element, and extensive-form regret, corre-sponding to transformation sets  X  LIN ,  X  FE , and  X  EF . As we will see, in general,  X  EXT  X   X  EF  X   X  LIN  X   X 
FE  X   X  SWAP . So, no swap regret implies no finite-element regret, which implies no linear regret, which implies no extensive-form regret, which implies no ex-ternal regret. We show in the long version of this paper (Gordon et al., 2008) that these five regret varieties are in fact distinct: it is possible to have, e.g., no  X  LIN -regret while still having positive  X  FE -regret. Linear Regret The set  X  LIN includes all linear transformations that map A into itself. To achieve no linear regret, we can take K to be the identity.  X  will then be a set of square d  X  d matrices. To find a fixed point of  X   X   X , we choose an appropriate element of the null space of  X   X  I , which takes time polynomial in d . The more expensive task is to achieve no external regret on  X : depending on the form of A ,  X  may or may not lend itself to a description in terms of a small number of simple constraints.
 If A is a probability simplex, then  X  is the set of stochastic matrices, which can be expressed with O ( d 2 ) linear constraints on the entries of  X  (this set-ting yields an algorithm very similar to that of Blum and Mansour (2005)). If A is a unit Euclidean ball, then  X  consists of those matrices whose largest singu-lar value is  X  1; this set can be represented using a sin-gle semidefinite constraint. For general (convex com-pact) A , the best choice may be to use either GIGA or lazy projection (Zinkevich, 2003): the difficult step in these algorithms is a Euclidean projection onto  X , which can be achieved via the ellipsoid algorithm. Finite-Element Regret The finite-element trans-formations only apply to polyhedral feasible regions A . For finite-element regret, we will define K as a mapping from a polyhedral feasible set A to a high-dimensional space K ( A ) called the barycentric co-ordinate space . To construct K ( a ), we first associate each of the p corners of A with one dimension of R p . We then triangulate A by dividing it into mutually ex-clusive and exhaustive d -simplices, so that each corner of A is a corner of one or more simplices.
 Now, to calculate K ( a ), we first determine the sim-plex in which a lies (or choose one arbitrarily if it is on a boundary) and calculate the weights of a with respect to the d + 1 corners of that simplex. That is, if j (1) ...j ( d + 1) are the indices of the corners of the simplex containing a , and if c j (1)  X   X   X  c j ( d +1) their coordinates, we find the weights b 1 ...b d +1 by solving a = P i b i c j ( i ) , P i b i = 1. We then set entry entries of K ( a ) to 0.
 For example, if A = [0 , 1] 2 , we can divide A into two triangles, one with corners (0 , 0), (0 , 1), and (1 , 1), and the other with corners (0 , 0), (1 , 0), and (1 , 1). triangle. If we associate corners of A with dimen-sions of K ( A ) in the order (0 , 0), (0 , 1), (1 , 0), (1 , 1), ( , 2 3 ) as a convex combination of corners 1, 2, and 4. Given this definition of K ,  X  FE is the set of matrices  X  that map K ( A ) into A . If A is a simplex, then K will be a linear mapping and  X  FE =  X  LIN . (In general,  X  FE  X   X  LIN .) For another example, see Fig. 2. We note that  X  FE can be factored: it is the Cartesian product of p copies of A , since it just needs to map each corner of A to a point inside A . So, to achieve no external regret in  X , we can separately run p copies of any no-external-regret algorithm for A . A typical cost for doing so might be O ( pd 3 ). 3 To find a fixed point of  X  , we just need to check each of its linear pieces separately. Each individual check costs O ( d 3 ), and there is one for each simplex in our mesh. Extensive-Form Regret Let T be a player X  X  se-quence tree , describing all possible sequences of choices and observations in an extensive-form game (e.g., Fig. 3 (left)). Suppose that each element of the feasible region A is a sequence weight vector on T (Forges &amp; von Stengel, 2002), specifying a behav-ior strategy for the game. Define an extensive form transformation as follows: fix a set D of choice nodes in T , along with pure-strategy sequence weight vec-tors w b for each b  X  D . If the original strategy is ever about to play b  X  D , the transformed strategy devi-ates, and instead follows w b . We assume that there are no b,b 0  X  D with b 0 an ancestor of b (so that all b  X  D are reachable), and that each b  X  D has a sibling a with w b ( a ) = 1. Extensive-form transfor-mations are interesting since they correspond to the incentive constraints in extensive-form correlated equi-librium (Forges &amp; von Stengel, 2002).
 We show (Gordon et al., 2008) that each extensive form transformation can be represented by a matrix  X  , whose rows and columns are indexed by choices, so that any action w  X  A is transformed into another action  X w  X  A . The entries of  X  are as follows: ( T b 0 is the subtree of T rooted at b 0 , so that b 6 X  T b 0 means b is not a descendent of b 0 ; b a means b is an ancestor or a sibling of an ancestor of a in T .) This equation says that column b of  X  is either: a copy of w b with entries w b ( a ) replaced by 0s for b 6 a (if b  X  D , cases 1, 3); a single 1 on the diagonal (if neither b nor any of its ancestors is in D , cases 2, 3); or all 0s (if b 6 X  D , but one of b  X  X  (strict) ancestors is in D , case 3). Now, if we take  X  EF to be the convex hull of all such  X  s, then  X  EF  X   X  LIN , and no  X  EF -regret immediately implies no regret vs. any extensive form transforma-tion. (So, no  X  EF -regret is related to extensive-form correlated equilibrium; see Sec. 4).
 For example, if T is as shown in Fig. 3 (left), elements of A are vectors of 4 sequence weights, one each for a ...a 4 . The weight for, e.g., a 3 is P ( a 2 | root) P ( a o ), the product of the conditional probabilities of all choice nodes along the path from the root to a 3 . So, strategy a 1 ,a 3 yields weights w = (1 , 0 , 0 , 0) T , while a ,a 3 yields w 0 = (0 , 1 , 1 , 0) T .
 The set  X  EF for this game is shown in Fig. 3 (right). The parameters a , d , e , and f determine the probabil-ity that each choice node is included in D : a  X  0 is P ( a 1  X  D ), d  X  0 is P ( a 2  X  D ), e  X  0 is P ( a 3  X  D ), and f  X  0 is P ( a 4  X  D ). If a 1  X  D , parameters b and c specify a strategy for the subtree rooted at a 2 . (If a 1 6 X  D , the game ends right after we reach D , and so we need not specify further choices.) The inequalities listed in Fig. 3 are consistency constraints: e.g., the events a 2  X  D and a 3  X  D are mutually exclusive, so we must have d + e  X  1.
 To represent the transformation  X  X lay a 2 ,a 3 instead of a 1 , X  we construct a matrix  X  by setting a,b = 1 and c,d,e,f = 0. It is easy to verify that  X w = w 0 as expected. On the other hand, the transformation  X  X lay a 1 instead of a 2  X  corresponds to  X  with d = 1 and a,b,c,e,f = 0; again, it is easy to check  X w 0 = w . Algorithm A achieves no  X -regret in an online convex program, for any suitable  X . In this section, we relate this guarantee back to equilibria in convex games. A game consists of a set of players N , a set of ac-tions A i for each player i  X  N , and a payoff function r :  X  i A i  X  R for each player i  X  N . A matrix game is one in which each action set is finite. A variant on a matrix game is an experts game in which each ac-tion set is a probability simplex. Generalizing experts games, a convex game is one in which each action set is a convex and compact subset of Euclidean space and each payoff function is multi-linear. In experts games and convex games, players can play interior points; but, assuming polyhedral action sets (PAS), we can generate a corresponding corner game by restricting each player X  X  actions to the corners of its action sets. Following Stoltz and Lugosi (2007), who generalize the definition for matrix games given in Greenwald and Jafari (2003), we define equilibria in convex games in terms of transformation sets.
 Definition 2 Given a game and a collection of trans-formation sets,  X   X  i  X  i  X  N , with each  X  i  X   X  SWAP , a probability distribution q over  X  i A i is a  X   X  i  X  i  X  N equilibrium iff the expectation over a  X  q satisfies
E [ r i (  X  ( a i ) ,a  X  i )  X  r i ( a )]  X  0  X  i  X  N,  X   X   X  Intuitively, an equilibrium is a distribution from which no player prefers to deviate using any transformation in its set. Taking each  X  i to be the set of swap transfor-mations defines correlated equilibria ; taking each  X  i to be the set of external (i.e., constant) transfor-mations defines coarse correlated equilibria . These definitions lead to the following propositions, proved by Marks (2008) and Gordon et al. (2007).
 Proposition 3 A correlated equilibrium of the corner game generated from a PAS convex game is also a cor-related equilibrium of the convex game itself. Proposition 4 For every correlated equlibrium in a PAS convex game, the corresponding corner game has a payoff-equivalent correlated equilibrium. 4.1. Repeated Games As described above, we assume the agents play some game repeatedly and learn by observing the relation-ship between their actions and their payoffs. In re-peated matrix games, Greenwald and Jafari (2003) have shown that if each agent plays according to a no  X  -regret algorithm, then the empirical distribution of joint play converges to the set of  X   X  i  X  i  X  N -equilibria with probability 1. The empirical distribution of joint play at step t is the following distribution over the joint action set, where a t  X   X  i A i is the joint action played at time step t : z t (  X  ) = {  X  | a  X  =  X  } /t . The analogous result holds for  X   X  i  X  i  X  N -equilibrium in re-peated convex games (e.g., Stoltz and Lugosi (2007)). Because extensive-form games are one class of convex games (Forges &amp; von Stengel, 2002), this result im-plies that, if the agents all play extensive-form regret-minimization algorithms, their play will converge to the set of extensive-form correlated equilibria. (Marks (2008) also provides algorithms with this property, using the less-efficient normal-form representation of extensive-form games.) We can also say something about convergence to full-fledged correlated equilibria in repeated convex games: define a randomized variant of A as follows. On a trial where the deterministic algorithm would have played  X  a t , the randomized algorithm samples its play a t from any distribution D such that (We still use  X  a t , rather than a t , in constructing m With such a D , if loss functions are linear, our  X -regret on A and external regret on  X  differ by a zero-mean random variable; so, we can use standard stochastic convergence results to prove: Corollary 5 Under the conditions of Thm. 1, the ad-ditional assumption (4), and restricting L to include only linear loss functions, the randomized variant of A achieves no  X  -regret with probability 1.
 For  X  FE -regret, we can always find a D that satisfies Equation (4); so (Gordon et al., 2007): Corollary 6 If, in a repeated PAS convex game, each agent plays only corner points and uses an algorithm that achieves no internal regret for the corner game (such as the randomized version of A with  X  =  X  FE ), then the empirical distribution of joint play converges to the set of correlated equilibria of the convex game with probability 1.
 To our knowledge, ours is the most efficient algorithm which can make this claim, by a factor which is expo-nential in the dimension d . We have presented several new forms of regret for on-line convex programs, analyzed their relationships to one another and to known regret types, and given the first efficient algorithms that directly minimize some of these forms of regret. These algorithms are by far the most efficient known for several purposes, including guaranteeing convergence to a correlated equilibrium in a repeated convex game, and to an extensive-form correlated equilibrium in an extensive-form game. By contrast, most previous OCP algorithms only guaran-tee convergence to coarse correlated equilibrium, an outcome which may yield much lower payoffs and may leave incentives for rational agents to deviate. In the process of designing our algorithms, we derived efficient representations of the transformation sets for each of our regret types except  X  SWAP : we wrote each as a nonlinear kernel mapping followed by a linear transformation chosen from an appropriate set of ma-trices. These representations may be of separate inter-est for designing future algorithms. In this paper, we were chiefly interested in cases where the dimension of the kernel mapping was manageable, so that we could directly work with the transformation matrices. How-ever, it would be very interesting to try to design  X  X er-nelized X  no- X -regret algorithms. In such algorithms we would never explicitly write down a transforma-tion  X  , but instead represent it in terms of observed actions and loss functions, thereby making it feasible to use very high-dimensional sets of transformations. Important application areas for OCPs and convex games include multi-agent planning (in which the fea-sible region for each player is a set of plans, and inter-actions include contending for resources) and learning in extensive-form games such as poker. We are partic-ularly interested in extensive-form games; this appli-cation requires further developments such as learning efficiently from bandit feedback and abstracting large games into smaller representations which we can work with in real time.
 Acknowledgments The authors would like to thank Martin Zinkevich for very helpful discussions during an early phase of this work. This work was supported in part by a grant from DARPA X  X  Computer Science Study Panel program and in part by a grant from the Sloan Foundation.
