 We present an adaptive load shedding approach for win-dowed stream joins. In contrast to the conventional ap-proach of dropping tuples from the input streams, we ex-plore the concept of selective processing for load shedding. We allow stream tuples to be stored in the windows and shed excessive CPU load by performing the join operations, not on the entire set of tuples within the windows, but on a dynamically changing subset of tuples that are learned to be highly beneficial. We support such dynamic selec-tive processing through three forms of runtime adaptations : adaptation to input stream rates, adaptation to time cor-relation between the streams and adaptation to join direc-tions. Indexes are used to further speed up the execution of stream joins. Experiments are conducted to evaluate our adaptive load shedding in terms of output rate. The results show that our selective processing approach to load shedding is very effective and significantly outperforms the approach that drops tuples from the input streams.
 H.2.4 [ Database Management ]: Systems X  Query pro-cessing Algorithms, Design, Performance Load Shedding, Stream Joins
With the ever increasing rate of digital information avail-able from on-line sources and networked sensing devices [14], the management of bursty and unpredictable data streams has become a challenging problem. It requires solutions that will enable applications to effectively access and extract in-formation from such data streams. A promising solution for this problem is to use declarative query processing engines specialized for handling data streams, such as data stream management systems (DSMS), exemplified by Aurora [3], STREAM [1], and TelegraphCQ [5].

Joins are key operations in any type of query processing engine and are becoming more important with the increasing need for fusing data from various types of sensors available, such as environmental, traffic, and network sensors. Here, we list some real-life applications of stream joins. We will return to these examples when we discuss assumptions about the characteristics of the joined streams.  X  Finding similar news items from two different sources :As-suming that news items from CNN and Reuters are repre-sented by weighted keywords (join attribute) in their respec-tive streams, we can perform a windowed inner product join to find similar news items.  X  Finding correlation between phone calls and stock trad-ing : Assuming that phone call streams are represented as { ..., ( P a ,P b ,t 1 ) ,... } where ( P a ,P b ,t 1 )means P at time t 1 , and stock trading streams are represented as { ..., ( P b ,S x ,t 2 ) ,... } where ( P b ,S x ,t 2 )means P at time t 2 ; we can perform a windowed equi-join on person to find hints, such as: P a hints S x to P b in the phone call.  X  Finding correlated attacks from two different streams :As-suming that alerts from two different sources are repre-sented by tuples in the form of ( source, target, { attack descriptors } ,time ) in their respective streams, we can per-form a windowed overlap join on attack descriptors to find correlated attacks.

Recently, performing joins on unbounded data streams has been actively studied [9, 12, 10]. This is mainly due to the fact that traditional join algorithms need to perform a scan on one of the inputs to produce all the result tuples that match with a given tuple from the other input. However, data streams are unbounded. Producing a complete answer for a stream join requires unbounded memory and process-ing resources. To address this problem, several approaches have been proposed.

One natural way of handling joins on infinite streams is to use sliding windows. In a windowed stream join, a tuple from one stream is joined with only the tuples currently available in the window of another stream. A sliding window canbedefinedasa time-based or count-based window. An example of a time-based window is  X  X ast 10 seconds X  tuples X  and an example of a count-based window is  X  X ast 100 tuples. X  Windows can be either user defined, in which case we have fixed windows, or system-defined and thus flexible ,inwhich case the system uses the available memory to maximize the output size of the join. Another way of handling the problem of blocking joins is to use punctuated streams [19], in which punctuations that give hints about the rest of the stream are used to prevent blocking. The two-way stream joins with user defined time-based windows constitute one of the most common join types in the data stream management research to date [2, 9, 12].
 In order to keep up with the incoming rates of streams, CPU load shedding is usually needed in stream processing systems. Several factors may contribute to the demand for CPU load shedding, including (a) bursty and unpre-dictable rates of the incoming streams; (b) large window sizes; and (c) costly join conditions. Data streams can be unpredictable in nature [13] and incoming stream rates tend to soar during peak times. A high stream rate requires more resources for performing a windowed join, due to both in-creased number of tuples received per unit time and the increased number of tuples within a fixed-sized time win-dow. Similarly, large window sizes imply that more tuples are needed for processing a windowed join. Costly join con-ditions typically require more CPU time.

In this paper, we present an adaptive CPU load shedding approach for windowed stream joins, aiming at maximizing the output rate of stream joins. The proposed approach is applicable to all kinds of join conditions, ranging from sim-ple conditions such as equi-joins defined over single-valued attributes (e.g., the phone calls and stock trading scenario) to complex conditions such as those defined over set-valued attributes (e.g., the correlated attacks scenario) or weighted set-valued attributes (e.g., the similar news items scenario). Our adaptive load shedding approach has several unique characteristics. First, instead of dropping tuples from the input streams as proposed in many existing approaches, our adaptive load shedding framework follows a selective pro-cessing methodology by keeping tuples within the windows, but processing them against a subset of the tuples in the opposite window.

Second, our approach achieves effective load shedding by properly adapting join operations to three dynamic stream properties: (i) incoming stream rates, (ii) time correlation between streams and (iii) join directions. The amount of selective processing is adjusted according to the incoming stream rates. Prioritized basic windows are used to adapt join operations to the time-based correlation between the input streams. Partial symmetric joins are dynamically em-ployed to take advantage of the most beneficial join direction learned from the streams.

We employ indexes to speed up the selective processing of joins. Experiments were conducted to evaluate the ef-fectiveness of our adaptive load shedding approach. Our experimental results show that the three adaptations can effectively shed the load in the presence of any of the follow-ing; bursty and unpredictable rates of the incoming streams, large window sizes, or costly join conditions.
Based on the metric being optimized, related work on load shedding in windowed stream joins can be divided into two categories. The work in the first category aims at maximiz-ing the utility of the output produced. Different tuples may have different importance values based on the application. For instance, in the news join example, certain type of news, e.g., security news, may be of higher value, and similarly in the stock trading example, phone calls from insiders may be of higher interest when compared to calls from regulars. In this case, an output from the join operator that contains highly-valued tuples is more preferable to a higher rate out-put generated from lesser-valued tuples. The work presented in [18] uses user-specified utility specifications to drop tuples from the input streams with low utility values. We refer to this type of load shedding as semantic load shedding .
The work in the second category aims at maximizing the number of output tuples produced [6, 12, 17]. This can be achieved through rate reduction on the source streams, i.e., dropping tuples from the input streams, as suggested in [4, 12]. The work presented in [12] investigates algorithms for evaluating moving window joins over pairs of unbounded streams. Although the main focus of [12] is not on load shedding, scenarios where system resources are insufficient to keep up with the input streams are also considered.
In summary, in the context of windowed stream joins most of the existing techniques used for shedding load are tuple dropping for CPU-limited scenarios and memory allocation among windows for memory-limited scenarios. However, dropping tuples from the input streams without paying at-tention to the selectivity of such tuples may result in a sub-optimal solution. Based on this, heuristics that take into account selectivity of the tuples are proposed in [6]. Figure 1: Examples of match probability density functions between the streams. Concretely, the probability of having a match between a tuple just received from one stream and a tuple residing in the window of the opposite stream, may change based on the difference between the timestamps of the tuples (assuming timestamps are assigned based on the arrival times of the tuples at the query engine). Under this observation, memory is conserved by keeping a tuple in the window since its reception until the average rate of output tuples generated using this tuple reaches its maximum value. For instance, in Figure 1 case I, the tuples can be kept in the window until they reach the vertical line marked. This effectively cuts down the memory needed to store the tuples within the window and yet produces an output close to the actual output without window reduction.

Obviously, knowing the distribution of the incoming streams has its peak at the beginning of the window, the age-based window reduction can be effective for shedding memory load. A natural question to ask is:  X  X an the age-based window reduction approach of [17] be used to shed CPU load? X  This is a valid question, because reducing the window size also decreases the number of comparisons that have to be made in order to evaluate the join. However, as illustrated in Figure 1 case II, this technique cannot di-rectly extend to the CPU-limited case where the memory is not the constraint. When the distribution does not have its peak close to the beginning of the window, the window reduction approach has to keep tuples until they are close to the end of the window. As a result, tuples that are close to the beginning of the window and thus are not contribut-ing much to the output will be processed until the peak is reached close to the end of the window. This observation points out two important facts. First, time-based correla-tion between the windowed streams can play an important role in load shedding. Second, the window reduction tech-nique that is effective for utilizing time-based correlation to shed memory load is not suitable for CPU load shedding, especially when the distribution of the incoming streams is unknown or unpredictable.
Unlike the conventional load shedding approach of drop-ping tuples from the input streams, our adaptive load shed-ding encourages stream tuples to be kept in the windows. It sheds the CPU load by performing the stream joins on a dynamically changing subset of tuples that are learned to be highly beneficial, instead of on the entire set of tuples stored within the windows. This allows us to exploit the charac-teristics of stream applications that exhibit time-based cor-relation between the streams. Concretely, we assume that there exists a non-flat distribution of probability of match between a newly-received tuple and the other tuples in the opposite window, depending on the difference between the timestamps of the tuples.

There are several reasons behind this assumption. First, variable delays can exist between the streams as a result of differences between the communication overhead of re-ceiving tuples from different sources [16]. Second and more importantly, there may exist variable delays between related events from different sources. For instance, in the news join example, different news agencies are expected to have dif-ferent reaction times due to differences in their news collec-tion and publishing processes. In the stock trading example, there will be a time delay between the phone call contain-ing the hint and the action of buying the hinted stock. In the correlated attacks example, different parts of the net-work may have been attacked at different times. Note that, the effects of time correlation on the data stream joins are to some extent analogous to the effects of the time of data creation in data warehouses, which are exploited by join al-gorithms such as Drag-Join [11].
Our load shedding approach is best understood through its two core mechanisms, each answering a fundamental question on adaptive load shedding without tuple dropping.
The first is called partial processing and it answers the question of  X  how much we can process  X  given a window of stream tuples. The factors to be considered in answering this question include the performance of the stream join op-eration under current system load and the current incom-ing stream rates. In particular, partial processing dynami-cally adjusts the amount of load shedding to be performed through rate adaptation.

The second is called selective processing and it answers the question of  X  what should we process  X  given the constraint on the amount of processing, defined at the partial processing phase. The factors that influence the answer to this ques-tion include the characteristics of stream window segments, the profitability of join directions, and the utility of different stream tuples. Selective processing extends partial process-ing to intelligently select the tuples to be used during join processing under heavy system load, with the goal of maxi-mizing the output rate of the stream join.
A two-way windowed stream join operation takes two in-put streams denoted as S 1 and S 2 , performs the stream join and generates the output. For notational convenience, we denote the opposite stream of stream i ( i =1 , 2) as stream i . The sliding window defined over stream S i is denoted as W , and has size w i in terms of seconds. We denote a tuple as t and its arrival timestamp as T ( t ). Other notations will be introduced in the rest of the paper as needed.
A windowed stream join is performed by fetching tuples from the input streams and processing them against tuples in the opposite window. For a newly fetched tuple t from stream S i , the join is performed in the following three steps.
First, tuple t is inserted into the beginning of window W Second, tuples at the end of window W i are checked in order and removed if they have expired. A tuple t o expires from window W i iff T  X  T ( t o ) &gt;w i ,where T represents the current time. The expiration check stops when an unexpired tuple is encountered. The tuples in window W i are sorted in the order of their arrival timestamps by default and the window is managed as a doubly linked list for efficiently performing insertion and expiration operations. In the third and last step, tuple t is processed against tuples in the window W and matching tuples are generated as output.
The first step in our approach to shedding CPU load with-out dropping tuples is to determine how much we can pro-cess given the windows of stream tuples that participate in the join. We call this step the partial processing based load shedding. For instance, consider a scenario in which the limitation in processing power requires dropping half of the tuples, i.e. decreasing the input rate of the streams by half. A partial processing approach is to allow every tuple to enter into the windows, but to decrease the cost of join processing by comparing a newly-fetched tuple with only a fraction of the window defined on the opposite stream.

Partial processing, by itself, does not significantly increase the number of output tuples produced by the join operator, when compared to tuple dropping or window reduction ap-proaches. However, as we will describe later in the paper, it forms a basis to perform selective processing, which exploits the time-based correlation between the streams, and makes it possible to accommodate utility-based load shedding, in order to maximize the output rate or the utility of the output tuples produced (see [7] for output utility maximization).
Two important factors are considered in determining the amount of partial processing: (1) the current incoming stream rates, and (2) the performance of the stream join operation under current system load. Partial processing employs rate adaptation to adjust the amount of process-ing performed dynamically. The performance of the stream join under the current system load is a critical factor and it is influenced by the join algorithm and optimizations used for performing join operations.
The partial processing-based load shedding is performed by adapting to the rates of the input streams. This is done by observing the tuple consumption rate of the join opera-tion and comparing it to the input rates of the streams to Algorithm 1: Rate Adaptation determine the fraction of the windows to be processed. This adaptation is performed periodically, at every T r seconds. T r is called the adaptation period . We denote the fraction parameter as r , which defines the ratio of the windows to be processed. In other words, the setting of r answers the question of how much load we should shed.
 Algorithm 1 gives a sketch of the rate adaptation process. Initially, the fraction parameter r is set to 1. Every T seconds, the average rates of the input streams S 1 and S are determined as  X  1 and  X  2 . Similarly, the number of tuples fetched from streams S 1 and S 2 since the last adaptation step are determined as  X  1 and  X  2 . Tuples from the input streams may not be fetched at the rate they arrive due to an inappropriate initial value of the parameter r or due to a change in the stream rates since the last adaptation step. As input tuples fetched by the join algorithm. Based on the value of  X  , the fraction parameter r is readjusted at the end of each adaptation step. If  X  is smaller than 1, r is multiplied by  X  , with the assumption that comparing a tuple with the other tuples in the opposite window has the dominating cost in join processing. Otherwise, the join is able to process all the incoming tuples with the current value of r .Inthis case, the r value is set to min (1 , X  r  X  r ), where  X  r is called the fraction boost factor . This is aimed at increasing the fraction of the windows processed, optimistically assuming that additional processing power is available. If not, the parameter r will be decreased during the next adaptation step. Higher values of the fraction boost factor result in being more aggressive at increasing the parameter r .The adaptation period T r should be small enough to adapt to the bursty nature of the streams, but large enough not to cause overhead and undermine the join processing.
Stream indexing [8, 20] can be used to cope up with the high processing cost of the join operation, reducing the amount of load shedding performed. However, there are two important points to be resolved before indexing can be em-ployed together with partial processing and thus with other algorithms we introduce in the following sections. The first issue is that, in a streaming scenario the index has to be maintained dynamically (through insertions and removals) as the tuples enter and leave the window. This means that the assumption made in Section 4.1 about finding matching tuples within a window (index search cost) being the domi-nant cost in the join processing, no longer holds. Second, the index does not naturally allow processing only a certain por-tion of the window. We resolve these issues in the context of inverted indexes, that are predominantly used for joins based on set or weighted set-valued attributes. The same ideas apply to hash-indexes used for equi-joins on single-valued attributes. Our inverted-index implementation reduces to a hash-index in the presence of single-valued attributes.
An inverted index consists of a collection of sorted identi-fier lists. In order to insert a set into the index, for each item in the set, the unique identifier of the set is inserted into the identifier list associated with that particular item. Similar to insertion, removal of a set from the index requires finding the identifier lists associated with the items in the set. The removal is performed by removing the identifier of the set from these identifier lists. In our context, the inverted index is maintained as an in-memory data structure. The collec-tion of identifier lists are managed in a hash table. The hash table is used to efficiently find the identifier list associated with an item. The identifier lists are internally organized as sorted (based on unique set identifiers) balanced binary trees to facilitate both fast insertion and removal. The set identifiers are in fact pointers to the tuples they represent. Query processing on an inverted index follows a multi-way merging process, which is usually accelerated through the use of a heap [15].
Although the usage of inverted indexes speeds up the pro-cessing of joins based on set-valued attributes, it also intro-duces significant insertion and deletion costs. This problem can be alleviated by exploiting the timestamps of the tu-ples that are being indexed and the fact that these tuples are received in timestamp order from the input streams. In particular, instead of maintaining identifier lists as balanced trees sorted on identifiers, we can maintain them as linked lists sorted on timestamps of the tuples (sets). This does not effect the merging phase of the indexed search, since a timestamp uniquely identifies a tuple in a stream unless dif-ferent tuples with equal timestamps are allowed. In order to handle the latter, the identifier lists can be sorted based on (timestamp, identifier) pairs.
Selective processing extends partial processing to intelli-gently select the tuples to be used during join processing un-der heavy system load. Given the constraint on the amount of processing defined at the partial processing phase, the se-lective processing aims at maximizing the output rate or the output utility of the stream joins. Two important factors are used to determine what we should select for join pro-cessing: (1) the characteristics of stream window segments and (2) the profitability of join directions. We describe time correlation adaptation and join direction adaptation, which form the core of our selective processing approach. The main ideas are to prioritize segments (basic windows) of the windows in order to process parts that will yield higher out-put (time correlation adaptation) and to start load shedding from one of the windows if one direction of the join is produc-ing more output than the other (join direction adaptation).
For the purpose of time correlation adaptation, we divide the windows of the join into basic windows . Concretely, window W i is divided into n i basic windows of size b seconds each, where n i =1+ w i /b . B i,j denotes the j th basic window in W i , j  X  [1 ..n i ]. Tuples do not move from one basic window to another. As a result, tuples leave the join operator one basic window at a time and the basic windows slide discretely b seconds at a time. The newly fetched tuples are inserted into the first basic window. When the first basic window is full, meaning that the newly fetched tuple has a timestamp that is at least b seconds larger than the oldest tuple in the first basic window, the last basic window is emptied and all the basic windows are shifted, last basic window becoming the first. The newly fetched tuples can now flow into the new first basic window, which is empty. The basic windows are managed in a circular buffer, so that the shift of windows is a constant time operation. The basic windows themselves can be organized as linked lists (if no indexing is used) or as inverted/hashed indexes.

Time correlation adaptation is periodically performed at every T c seconds. T c is called the time correlation adaptation period . During the time between two consecutive adaptation steps, the join operation performs two types of processing. For a newly fetched tuple, it either performs selective pro-cessing or full processing . Selective processing is carried out by looking for matches with tuples in high priority basic windows of the opposite window, where the number of basic windows used depends on the amount of load shedding to be performed. Full processing is done by comparing the newly fetched tuple against all the tuples from the opposite win-dow. The aim of full processing is to collect statistics about the usefulness of the basic windows for the join operation.
The details of the adaptation step and full processing are given in Algorithm 2 and in lines 1-5 of Algorithm 3. Full processing is only done for a sampled subset of the stream, based on a parameter called sampling probability , denoted as  X  . A newly fetched tuple goes through selective processing with probability 1  X  r  X   X  . In other words, it goes through full processing with probability r  X   X  . The fraction parameter r is used to scale the sampling probability, so that the full processing does not consume all processing resources when the load on the system is high. The goal of full process-ing is to calculate for each basic window B i,j , the expected number of output tuples produced from comparing a newly fetched tuple t with a tuple in B i,j , denoted as o i,j .These values are used later during the adaptation step to prioritize windows. In particular, o i,j values are used to calculate s values. Concretely, we have: s j i = k ,where o i,k is the j th item This means that B i,s 1 i is the highest priority basic window in W i , B i,s 2 i is the next, and so on.

Lines 7-14 in Algorithm 3 give a sketch of selective pro-cessing. During selective processing, s j i values are used to guide the load shedding. Concretely, in order to process a newly fetched tuple t against window W i ,firstthenumberof tuples from window W i , that are going to be considered for processing, is determined by calculating r  X  X  W i | ,where denotes the number of tuples in the window. The fraction parameter r is determined by rate adaptation as described in Section 4.1. Then, tuple t is processed against basic win-dows, starting from the highest priority one, i.e. B i,s 1 ing in decreasing order of priority. A basic window B i,s Algorithm 2: Time Correlation Adaptation Algorithm 3: Tuple Processing with Time Corr. Adapt.
ProcessTuple () searched for matches completely, if adding | B i,s j of tuples to the number of tuples used so far from window W i to process tuple t does not exceeds r  X  X  W i | . Otherwise an appropriate fraction of the basic window is used and the processing is completed for tuple t .
Due to time-based correlation between the streams, a newly fetched tuple from stream S 1 may match with a tu-ple from stream S 2 that has already made its way into the middle portions of window W 2 . This means that, most of the time, a newly fetched tuple from stream S 2 has to stay within the window W 2 for some time, before it can be matched with a tuple from stream S 1 . This implies that, one direction of the join processing may be of lesser value, in terms of the number of output tuples produced, than the other direction. For instance, in the running example, processing a newly fetched tuple t from stream S 2 against window W 1 will produce smaller number of output tuples when compared to the other way around, as the tuples to match t has not yet arrived at window W 1 . In this case, symmetry of the join operation can be broken during load shedding, in order to achieve a higher output rate. This can be achieved by decreasing the fraction of tuples processed from window W 2 first, and from W 1 later (if needed). We call this join direction adaptation .

Join direction adaptation is performed immediately after rate adaptation. Specifically, two different fraction param-eters are defined, denoted as r i for window W i , i  X  X  1 , 2 During join processing, r i fraction of the tuples in window W i are considered, making it possible to adjust join direc-tion by changing r 1 and r 2 . This requires replacing r with r in line 7 of Algorithm 3 and line 5 of Algorithm 2. Algorithm 4: Join Direction Adaptation
The constraint in setting of r i values is that, the num-ber of tuple comparisons performed per time unit should stay the same when compared to the case where there is a single r value as computed by Algorithm 1. The number of tuple comparisons performed per time unit is given by 2 i =1 ( r i  X   X  i  X  (  X  i  X  w i )), since the number of tu-ples in window W i is  X  i  X  w i . Thus, we should have
The valuable direction of the join can be determined by comparing the expected number of output tuples produced from comparing a newly fetched tuple with a tuple in W i , denoted as o i , for i = 1 and 2. This can be computed as o we can set r 1 = min (1 ,r  X  w 1 + w 2 w 1 ). This maximizes r respecting the above constraint. The generic procedure to set r 1 and r 2 is given in Algorithm 4.

Join direction adaptation, as it is described in this section, assumes that any portion of one of the windows is more valu-able than all portions of the other window. This may not be the case for applications where both match probability distribution functions, f 1 ( t )and f 2 ( t ), are non-flat. For in-stance, in a traffic application scenario, a two way traffic flow between two points implies both directions of the join are valuable. A more advanced join direction adaptation al-gorithm was introduced in [7], that can handle such cases, as part of utility-based load shedding.
The adaptive load shedding algorithms presented in this paper have been implemented and successfully demon-strated as part of a large-scale stream processing prototype at IBM Watson Research. Here, we report two sets of exper-imental results to demonstrate their effectiveness. The first set demonstrates the performance of the partial processing-based load shedding step  X  keeping tuples within windows and shedding excessive load by partially processing the join through rate adaptation. The second set shows the perfor-mance gain in terms of output rate for selective processing, which incorporates time correlation adaptation and join di-rection adaptation. The effect of basic window size on the performance is also investigated experimentally. Note that the overhead cost associated with dynamic adaptation has been fully taken into account and it manifests itself in the output rate of the join operations.
The join operation is implemented as a Java package, named ssjoin.* , and is customizable with respect to sup-ported features, such as rate adaptation, time correlation adaptation and join direction adaptation, as well as various parameters associated with these features. Streams used in the experiments reported in this section are timestamp or-dered tuples, where each tuple includes a single attribute, that can either be a set, weighted set, or a single value. The sets are composed of variable number of items, where each item is an integer in the range [1 ..L ]. L is taken as 100 in the experiments. Number of items contained in sets follow a normal distribution with mean  X  and standard deviation  X  .Intheexperiments,  X  is taken as 5 and  X  is taken as 1. The popularity of items in terms of how frequently they occur in a set, follows a Zipf distribution with parameter  X  . For equi-joins on single-valued attributes, L istakenas5000 with  X  =1and  X  =0.
The time-based correlation between streams is modeled using two parameters, time shift parameter denoted as  X  and cycle period parameter denoted as  X  . Cycle period is used to change the pop-ularity ranks of items as a function of time. Initially at time 0, the most popular item is 1, the next 2, and so on. Later at time T ,the most popular item is a = a + 1, and so on. Time shift is used to introduce a delay between matching items from different streams. Applying atimeshiftof  X  to one of the streams means that the most popular item is a = 1+ L  X  ( T  X   X  )mod  X   X  at time T , for that stream.
Figure 2 shows the resulting probability of match distri-bution f 1 , when a time delay of  X  = 5 8  X   X  is applied to stream S 2 and  X  =2  X  w ,where w 1 = w 2 = w . The two histograms represent two different scenarios, in which  X  is taken as 0 . 6 and 0 . 8, respectively. These settings for  X  and  X  parameters are also used in the rest of the experiments, unless otherwise stated. We change the value of parameter  X  to model vary-ing amounts of skewness in match probability distributions. Experiments are performed using time varying stream rates and various window sizes.

The default settings of some of the system parameters are as follows: T r = 5 seconds, T c = 5 seconds,  X  r =1 . 2,  X  =0 . 1. We place input buffers of size 1 seconds in front of the inputs of the join operation. We report results from overlap and equality joins. The experiments are performed on an IBM PC with 512MB main memory and 2.4Ghz Intel Pentium4 processor, using Sun JDK 1.4.2.

For comparisons, we also implemented a random drop scheme. It performs load shedding by randomly dropping tuples from the input buffers and performing the join fully with the available tuples in the join windows. It is imple-mented separately from our selective join framework and does not include any overhead due to adaptations.
We study the impact of rate adaptation on output rate of the join operation. For the purpose of the experiments in this subsection, time shift parameter is set to zero, i.e.
Figure 3: Stream rates and frac-tion parameter r Figure 6: Stream rates and fraction parameters r 1 and r 2  X  = 0, so that there is no time shift between the streams and the match probability decreases going from the beginning of the windows to the end. A non-indexed overlap join, with threshold value of 3 and 20 seconds window on one of the streams, is used.

Figure 3 shows the stream rates used (left y -axis) as a function of time. The rate of the streams stay at 100 tuples per second for around 60 seconds, then jump to 500 tuples per seconds for around 15 seconds and drop to 300 tuples per second for around 30 seconds before going back to its initial value. Figure 3 also shows (right y -axis) how fraction parameter r adapts to the changing stream rates.

The graphs in Figure 4 show the resulting stream output rates as a function of time with and without rate adaptation, respectively. No rate adaptation case represents random tu-ple dropping. It is observed that rate adaptation improves output rate when the stream rates increase. That is the time when tuple dropping starts for the non-adaptive case. The improvement is around 100% when stream rates are 500 tuples per second and around 50% when 300 tuples per sec-ond. The ability of rate adaptation to keep output rate high is mainly due to the time aligned nature of the streams. In this scenario, only the tuples that are closer to the begin-ning of the window are useful for generating matches and the partial processing uses the beginning part of the window, as dictated by the fraction parameter r .

The graphs in Figure 5 plot the average output rates of the join over the period shown in Figure 4 as a function of skewness parameter  X  , for different window sizes. It shows that the improvement in output rate, provided by rate adap-tation, increases not only with increasing skewness of the match probability distribution, but also with increasing sizes of the join windows.
Here, we study the impact of time correlation adaptation and join direction adaptation on output rate of the join oper-ation. For the purpose of the experiments in this subsection, time shift parameter is taken as  X  = 5 8  X   X  . A non-indexed overlap join, with threshold value of 3 and 20 seconds win-dows on both of the streams, is used. Basic window sizes on both windows are set to 1 second for time correlation adaptation.

Figure 6 shows the stream rates used (on the left y -axis) as a function of time. Figure 6 also shows (on the right y -axis) how fraction parameters r 1 and r 2 adapt to the changing stream rates with join direction adaptation. Note that the reduction in fraction parameter values start with the one ( r in this case) corresponding to the window that is less useful in terms of generating output tuples when processed against a newly fetched tuple from the other stream.

The graphs in Figure 7 show the resulting stream out-put rates as a function of time with three different join set-tings. It is observed that, when the stream rates increase, the time correlation adaptation combined with rate adap-tation provides improvement on output rate (around 50%), when compared to rate adaptation only case. Moreover, ap-plying join direction adaptation on top of time correlation adaptation provides additional improvement in output rate (around 40%).

The graphs in Figure 8 plot the average output rates of the join as a function of skewness parameter  X  , for differ-ent join settings. This time, the overlap threshold is set to 4, which results in lower number of matching tuples. It is observed that the improvement in output rates, provided by time correlation and join direction adaptation, increase with increasing skewness in match probability distribution. The increasing skewness does not improve the performance of rate adaptive-only case, due to its lack of time correla-tion adaptation which in turn makes it unable to locate the productive portion of the window for processing, especially when the time lag  X  is large and r is small.
We study the impact of basic window size on output rate of the join operation. The graphs in Figure 9 plot average join output rate as a function of basic window size, for different  X  values.
 The graphs on the left represents a non-indexed overlap join, with threshold value of 3 and 20 seconds windows, respectively, on both of the streams.
 The graphs on the right represents an indexed overlap join, with threshold value of 3 and 200 seconds windows, respectively, on both of the streams. For the indexed case, both identifier sorted and time sorted inverted indexes are used. The  X  X one X  value on the x -axis of the graphs represent the case where basic windows are not used (note that this is not same as using a basic window equal in size to join window). For both experiments, a stream rate of 500 tuples per second is used. As expected, small basic windows provide higher join output rates. However, there are two interesting observations for the indexed join case. First, for very small basic window sizes, we observe a drop in the output rate. This is due to the overhead of processing large number of basic windows with indexed join. In particular, the cost of looking up identifier lists for each basic window that is used for join processing, creates an overhead. Further decreasing basic window size does not help in better capturing the peak of the match probability distribution. Second, identifier sorted inverted indexes show significantly lower output rate, especially when the basic window sizes are large. This is because, identifier sorted inverted indexes do not allow partial processing based on time.
We have presented an adaptive CPU load shedding ap-proach for stream join operations. In particular, we showed how rate adaptation, combined with time-based correlation adaptation and join direction adaptation, can increase the number of output tuples produced by a join operation. Our load shedding algorithms employed a selective processing approach, as opposed to commonly used tuple dropping. Our experimental results showed that (a) our adaptive load shedding algorithms are very effective under varying input stream rates, varying CPU load conditions, and varying time correlations between the streams; and (b) our approach sig-nificantly outperforms the approach that randomly drops tuples from the input streams.
