
A Sequence OLAP (S-OLAP) system provides a platform on which pattern-based aggregate (PBA) queries on a sequence database are evaluated. In its simplest form, a PBA query consists of a pat-tern template T and an aggregate function F . A pattern template is a sequence of variables, each is defined over a domain. For ex-ample, the template T = ( X , Y , Y , X ) consists of two variables X and Y . Each variable is instantiated with all possible values in its corresponding domain to derive all possible patterns of the tem-plate. Sequences are grouped based on the patterns they possess. The answer to a PBA query is a sequence cuboid (s-cuboid), which is a multidimensional array of cells. Each cell is associated with a pattern instantiated from the query X  X  pattern template. The value of each s-cuboid cell is obtained by applying the aggregate function F to the set of data sequences that belong to that cell. Since a pattern template can involve many variables and can be arbitrarily long, the induced s-cuboid for a PBA query can be huge. For most ana-lytical tasks, however, only iceberg cells with very large aggregate values are of interest. This paper proposes an efficient approach to identify and evaluate iceberg cells of s-cuboids. Experimental re-sults show that our algorithms are orders of magnitude faster than existing approaches.
 H.2.8 [ Database Management ]: Database Applications-Data Mining
OLAP; Iceberg; Probabilistic Algorithm
Sequence data is ubiquitous. Examples include workflow data, data streams and RFID logs. Techniques for processing various kinds of sequence data have been studied extensively in the litera-ture (e.g., [12, 13, 10, 1, 3, 14]). Recently, issues related to ware-housing and online analytical processing (OLAP) of archived se-quence data (e.g., stock ticks archive, passenger traveling histories) have received growing attentions [7, 6, 9]. In particular, [9] de-veloped a sequence OLAP system (called S-OLAP) that efficiently supports various kinds of pattern-based aggregate queries.
While traditional OLAP systems group data tuples based on their attribute values , an S-OLAP system groups sequences based on the patterns they possess. Common aggregate functions such as COUNT/SUM/AVG can then be applied to each group. The result-ing aggregate values form the cells of a so-called sequence data cuboid, or s-cuboid .

Since an s-cuboid displays the aggregate values of sequences that are grouped by the patterns they possess, one can view an s-cuboid as the answer to a pattern-based aggregate ( PBA ) query . To illus-trate PBA queries and s-cuboids, let us consider the sequence data set shown in Figure 1. The dataset models a collection of passenger traveling records registered by the Washington DC X  X  metro system. The records are captured electronically by SmarTrip , which is an RFID-card-based stored-value e-payment system. Each row in Fig-ure 1 shows a sequence of passenger events. An event consists of a number of attributes, such as Time , Station , Action and Amount . For example, the event [ t 9 ; Wheaton; exit; 1.9] of passenger s623 indicates that the passenger exited Wheaton Station at time t paid $1.9 for the trip.
 Figure 1: An example sequence data set  X  Passenger traveling log of Washington DC X  X  metro
Figure 2 shows a PBA query  X ( X,Y,Y,X ), COUNT  X  and a few cells of the resulting s-cuboid. A PBA query  X  T , F  X  consists of two components: A pattern template T (e.g., ( X,Y,Y,X )) and an ag-gregate function F (e.g., COUNT ). A pattern template is a sequence of pattern symbols (e.g., X , Y ) defined over an attribute A of event records. The pattern symbols are instantiated by the values of A to generate various patterns . Data sequences are grouped based on the patterns. Finally, the function F is applied to each sequence group to derive aggregate values.
 For example, the pattern template ( X,Y,Y,X ) defined on the Station attribute specifies that passenger sequences are grouped to-gether if they have traveled round-trip between stations X and Y (i.e., he first entered station X and exited station Y in his first trip, and then entered station Y and come back to station X in the next). The symbols X and Y are instantiated with various station names to form patterns, such as (Clarendon, Pentagon, Pentagon, Claren-don). Data sequences that possess a given pattern are grouped into a cell 1 . Each data sequence gives a value (or measure ) to be ag-gregated. For example, a passenger sequence could be associated with the amount of fare paid, or simply  X 1 X  if we only care about the cardinality of a cell. The aggregate function F is then applied to the values of the sequences of each cell to obtain an aggregate value of the cell. In this paper we use C ( P ) to denote the cell of a pattern P (i.e., C ( P ) = the set of sequences containing pattern P ), and we use F ( C ( P )) to denote the aggregate value of the cell. For example, Figure 2 shows that there are 16,289 sequences that pos-sess the pattern (Clarendon, Pentagon, Pentagon, Clarendon). In our notation: COUNT ( C ((Clarendon, Pentagon, Pentagon, Claren-don))) = 16,289. We write P ` T if pattern P is an instantiation of the template T . (e.g., (Clarendon, Pentagon, Pentagon, Clarendon) ` ( X,Y,Y,X ) ). An s-cuboid consists of all the aggregate values of the cells derived from all possible instantiations of the pattern template. A PBA query (e.g.,  X  ( X,Y,Y,X ) , COUNT  X ) is evalu-ated by computing all the cells of the corresponding s-cuboid (e.g., all the cells and their counts listed in Figure 2).

In [9], a basic implementation of an S-OLAP system is pre-sented. In that study, data sequences were indexed by inverted lists. Given a pattern P , its inverted list L [ P ] is a list of sequence id X  X  such that each sequence s listed in L [ P ] contains the pattern P . An s-cuboid cell C ( P ) can thus be represented by the inverted list L [ P ] . The inverted list of a pattern P can be obtained by either (1) scanning the data sequences and checking which sequences contain P , or (2) joining the lists of P  X  X  sub-patterns. For example, con-sider the query pattern template ( X,Y,Z,X ) . To materialize an s-cuboid cell, say, C (( a,b,c,a )) , one can intersect (or  X  X oin X ) the inverted lists L [( a,b,c )] and L [( c,a )] (if these lists are available). This is because a sequence that contains the pattern ( a,b,c,a ) must contain the sub-patterns ( a,b,c ) and ( c,a ) . (More details on this list joining operation will be given in Section 2.)
In some cases, the computation of a full s-cuboid could be ex-pensive. This is especially true when the pattern template is long with many pattern symbols, which results in a high-dimensional s-cuboid with large numbers of cells. We note that in many cases, computing the full s-cuboid is not necessary. More often, a user is interested in only those cells of an s-cuboid that return very large aggregate values. For example, a marketing manager of the Metro company may be interested in the pairs of stations for which most people commute roundtrip in order to design a fare and discount structure strategically. As another example, an online store man-ager may want to know what products X , Y , Z give high visiting counts of the product webpage visiting pattern ( X,Y,Z,X ) . This pattern reveals that a customer interested in product X is likely to compare it against products Y and Z , but will eventually commit to X .

Given a pattern template T , an aggregate function F , and a user-specified threshold  X  , our objective is to compute the iceberg cells , which are those whose aggregate values exceed the threshold  X  .
A data sequence may contain more than one pattern. A sequence can, therefore, belong to multiple cells.
 We call the query  X  T , F ,  X   X  an Iceberg Pattern-Based Aggregate Query (or IPBA query). Formally,
D EFINITION 1. (IPBA Query) The answer to the IPBA query  X  T , F ,  X   X  is the set of all iceberg cells and their aggregate values, i.e., { ( P,F ( C ( P ))) | ( P ` T )  X  ( F ( C ( P ))  X   X  ) } .
One straightforward way to answer an IPBA query is to com-pute the full s-cuboid of the PBA query and return only the iceberg cells. In [9], two methods for computing full s-cuboids, namely, the counter-based method (CB) and the inverted-list method (II), are studied. The CB method scans the relevant sequences in the database to compute the cells X  aggregate values in batch, while the II method computes the s-cuboid using list joining. Both of these methods could be expensive for very large sequence databases. For example, computing an inverted list requires I/O (to retrieve sub-patterns X  inverted lists) and CPU processing (to join the sub-patterns X  lists). Yet, most of these costs are wasted since the ma-jority of cells are non-iceberg ones. In this paper, we propose sta-tistical estimation techniques that allow very efficient identification and computation of iceberg cells. Our idea is to retain a very small synopsis of the database in main memory. Through statistical tests, the synopsis allows us to decide whether a cell is iceberg or not and whether the decision meets a given significance level require-ment . For the identified iceberg cells, we estimate their aggregate values based on the small synopsis and check whether the estimated values satisfy an accuracy requirement with a high confidence re-quirement . Through this mechanism, we show that we are highly confident that the reported cells are all and only iceberg cells and their reported aggregate values are highly accurate. We remark that our approach results in a very efficient method of answering IPBA queries. This is because we avoid heavy I/O (by not accessing disk-resident data) and reduce CPU processing (by processing the small synopsis instead of scanning big data sequences or joining large inverted lists).

The rest of this paper is organized as follows. Section 2 reviews the basic algorithm for evaluating PBA queries based on inverted indices. Section 3 presents our system architecture. We discuss how sequence data, inverted indices, and a synopsis are stored. In Section 4, we discuss how a synopsis is constructed and present our synopsis-based algorithm for evaluating IPBA queries. Section 5 evaluates our methods through an experimental study. Section 6 discusses some related works, and finally, Section 7 concludes the paper.
In [9], two methods for computing s-cuboids are studied, namely, the counter-based method (CB) and the inverted-list method (II). It is shown that while CB is suitable for computing a full s-cuboid from scratch, the II method is more efficient if the system has already materialized and cached a significant number of inverted lists, or if only a portion of the s-cuboid cells have to be computed. As we have mentioned, our approach to answering an IPBA query is to identify iceberg cells and compute only them, the II method is more suitable. In this section we describe the inverted index struc-ture and explain how to compute s-cuboids using inverted indices. For reference, symbols that are frequently used in our discussion are shown in Table 1.

An inverted index consists of a set of inverted lists. An inverted list, L [ P ] , is associated with a length-m pattern P = ( v Each element ( v i ) in pattern P is a value of a chosen attribute X  X  domain. The inverted list L [ P ] is a list of postings which record the occurrences of P in the sequence dataset. Each posting is of the form ( s i : p 1 ,...,p f i ), where s i is a sequence identifier, f is the number of occurrences of P in s i , and p 1 ,...,p starting positions at which pattern P occurs in s i . Given a pattern template T , the inverted index I T is the set of inverted lists L [ P ] such that P ` T . Figure 3 shows three example inverted indices: I l in I ( X,Y,Y ) indicates that sequences s 2 , s 27 and s 34 all contain the pattern (Clarendon, Pentagon, Pentagon) 2 . The first posting ( s 2 :1,4) indicates that there are two occurrences of the pattern in sequence s 2 at positions [1..3] and [4..6].

The answer of a PBA query  X  T , F  X  is an s-cuboid, which can be obtained from the inverted index I T by applying the aggregate function F to each inverted list L [ P ] in I T . For example, given the set of inverted indices shown in Figure 3 and the PBA query  X ( Y,X ), COUNT  X , the value of the cell C ((Pentagon, Clarendon)) is 4 because the inverted list l 8 contains four sequences. Evaluating an s-cuboid cell of a pattern P thus requires the inverted list L [ P ] .
Symbols in a pattern template are unbound variables. So, the in-verted indices I ( X,Y ) and I ( Z,U ) are the same. Multiple occur-rences of the same variable in a template, however, have the same binding. So, I ( X,X ) and I ( X,Y ) are different.
 If L [ P ] is not previously computed (and thus is not available), it can be materialized by joining the inverted lists of shorter patterns. For example, the inverted list L [( v 1 ,v 2 ,v 2 ,v 1 )] can be obtained sequence s appears in a posting of L [( v 1 ,v 2 ,v 2 )] with a starting position i and in another posting of L [( v 2 ,v 1 )] with a starting posi-tion i + 2 , then s is recorded in a posting of L [( v 1 ,v a starting position i . We use L [( v 1 ,v 2 ,v 2 ,v 1 )] = L [( v 1
L [( v 2 ,v 1 )] to denote this join operation. For example, the in-verted list L [(Clarendon, Pentagon, Pentagon, Clarendon)] can be obtained by considering l 1 and l 8 . From the lists, we see that s 27 at position 3 is in l 1 and s 27 at position 5 is in l 8 , so the posting ( s 27:3) is added to L [( v 1 ,v 2 ,v 2 ,v 1 )] .
Figure 4 shows the system architecture of our S-OLAP imple-mentation for answering IPBA queries. We remark that a general S-OLAP system should also be able to answer general PBA queries and to support a set of S-OLAP operations 3 . Since we focus on evaluating IPBA queries in this paper, only components that are relevant to IPBA query processing are shown in Figure 4.

In our system, a set of data sequences S is stored on secondary storage. As the S-OLAP system operates and answers queries (PBA or IPBA), certain inverted indices and inverted lists are material-ized. These materialized indices (lists) are stored in an inverted index store (II store). The II store serves as a disk-resident cache of the previously materialized lists. A replacement policy is em-ployed by the system to control the II store X  X  content when the II store overflows 4 . To compute an s-cuboid cell C ( P ) (for example, in answering a PBA/IPBA query), the query engine could consult the II store and check if the inverted list L [ P ] is present (i.e., ma-terialized). If so, L [ P ] could be retrieved for computing the ag-gregate value F ( C ( P )) . If L [ P ] is not present in the II store, it is materialized by joining the lists of P  X  X  sub-patterns. These sub-patterns X  lists are retrieved from the II store if they are present, or are recursively constructed otherwise. We assume that the indices of all length-2 pattern templates are materialized in the II store. We call this set of inverted indices the core index CI , which is always present in the II store. This approach is similar to bigram indexing in document retrieval systems and is shown to be effective in PBA query processing [9].

To speed up IPBA query processing, we should avoid disk ac-cesses, such as in retrieving lists from the II store. We achieve this by maintaining a synopsis  X  S in main memory, which is a small sample of the sequence dataset S . Accompanying  X  S is the synop-sis X  II store (SII store), also stored in main memory. The SII store is similar to the disk-resident II store except that inverted lists in the SII store contain the id X  X  of only those sequences found in the synopsis  X  S . We use  X  L [ P ] to denote such a list of the pattern P . In other words, a posting ( s i : p 1 ,...,p f i ) is in  X  quence s i contains P at starting positions p 1 , ... , p Moreover, while the core index CI of the dataset S must be present in the disk-resident II store, we do not assume the presence of any particular inverted lists in the SII store. The SII store is simply a fixed-size temporary cache of previously materialized inverted lists of the sequences in the synopsis.
Readers are referred to [9] for a discussion of the six S-OLAP op-erations for s-cuboids manipulations. These S-OLAP operations are analogous to traditional OLAP operations such as slice and dice.
A study on various II store replacement policies can be found in [4].
Given an IPBA query  X  T , F ,  X   X , for each P ` T , we estimate the aggregate value F ( C ( P )) by processing the synopsis and the SII store. Our objectives are: 1. Derive statistical tests that decide whether C ( P ) is or is not 2. For each cell C ( P ) declared iceberg by the tests, we esti-
We remark that (  X  , ,  X  ) could be system-wise parameters or could be specified by the user of each IPBA query. We call R = (  X  ,  X  , ,  X  ) the statistical requirement of an IPBA query. An interest-ing feature of our system is that given R , we can mathematically determine how big  X  S should be in order to meet the requirement. This information is very useful in designing the S-OLAP system because it allows us to decide how much memory the system needs to store an effective synopsis.

In this section we first discuss how to obtain a random sample  X  S from the sequence dataset S . Next, we describe our synopsis-based algorithm (SBA), which answers IPBA queries with results that satisfy the queries X  statistical requirements R  X  X .
We obtain the synopsis  X  S by drawing uniform random samples from S . Given an amount of memory for storing the synopsis, we determine a budget B , which is the number of sequences in the synopsis that the memory can hold. For example, if 100 million se-quences occupy 250GB of disk space, then 500MB of memory for the synopsis gives a budget B of 200,000 sequences. We adopt the sampling technique proposed in [8] to obtain  X  S . First, we randomly pick a hash function h : S 7 X  [0 , 1] from a family of universal hash functions H . Let { s 1 ,...,s | S | } be the set of all data sequence id X  X . The hash values, h ( s 1 ) ,...,h ( s |S| ) , form an i.i.d. sequence of the uniform distribution over the range [0,1]. To obtain a size-B sample of S , we collect into  X  S all sequences in S whose ids X  hash values are  X  x , where x = B/ | S | . That is,  X  S = { s i  X  S | h ( s expectation, |  X  S | = B and so x = |  X  S | / | S | . Given an IPBA query  X  T , F ,  X   X  and its statistical requirement R = (  X  ,  X  , ,  X  ), our algorithm, SBA, needs to return the aggregate values of the iceberg cells of an s-cuboid. Also, the reported results should satisfy R . Given a pattern P ` T , SBA uses  X  L [ P ] , which is the inverted list of P for the synopsis  X  S , to decide if the cell C ( P ) is iceberg and if so, to compute the cell X  X  aggregate value F ( C ( P )) . In this process, SBA accesses the SII store (Figure 4) to retrieve  X  L [ P ] . For those cells C ( P )  X  X  whose lists not found in the SII store, the small synopsis  X  S is scanned once to build the missing  X  L [ P ]  X  X . In the following discussion, we assume that  X  L [ P ] has been made available (either by retrieval from the SII store or by construction from  X  S ). To simplify our discussion, we only consider the COUNT aggregate function in this paper. Other functions, such as SUM and AVG , can be similarly handled.
Let D P be the count of the cell C ( P ) , i.e., D P = | L [ P ] | . SBA computes an estimate  X  D P of D P based on  X  L [ P ] . SBA then con-ducts three tests to evaluate if the cell C ( P ) is iceberg, and if so, whether the estimate  X  D P is accurate enough. Figure 5 abstracts SBA X  X  logic. It involves the following steps: (1) Test if we can reject the hypothesis  X  H 1 : C ( P ) is an iceberg cell , X  with a sig-nificance level  X  . If so, discard the cell. (2) Otherwise, test if we can reject the hypothesis  X  H 2 : C ( P ) is not an iceberg cell , X  with a significance level  X  . If we cannot reject H 2 (and because we failed to reject H 1 ), the synopsis is insufficient for us to determine if C ( P ) is iceberg or not. In this case, SBA computes the exact count of C ( P ) by reverting to the disk-based list-joining algorithm (see Section 2). (3) If H 2 is rejected, then SBA tests if the estimate  X  D
P satisfies the error bound with confidence  X  . If so, C ( P ) is reported as an iceberg cell with count  X  D P . If the error tolerance re-quirement is not met, SBA again reverts to the disk-based algorithm to compute the exact count.
 The probability is equivalent to that of obtaining no more than k successes in D P trials, each with a success probability x . It is thus a monotonically decreasing function of D P . Hence, given D we have, Note that PH 1 ( P ) can be computed from k P (the observed size of  X  L [ P ] ) and  X  . Given a significance level  X  , we reject hypothesis H if We call this test the pruning test because if it holds we have strong evidence that the cell C ( P ) is not iceberg. In this case, the cell is pruned . Otherwise, we consider another hypothesis: and the following p-value: It can be shown that for D P &lt;  X  , Similar to PH 1 ( P ) , PH 2 ( P ) can be computed from k We reject hypothesis H 2 if We call this the accepting test because if it holds, we have strong evidence that the cell C ( P ) is iceberg. In this case, the cell is accepted and we proceed to estimate the accuracy of the estimate  X  D
Let  X  P be the probability that the relative error of our estimate, i.e., | (  X  D P  X  D P ) | /D P , is less than or equal to . Based on [2], we can prove the following theorem 6 : Note that  X  P depends on D P , which is unknown. It is shown in [2] that the probability can be practically approximated by substituting D P by  X  D P in the beta function. Hence, we approximate  X   X  Now, we report the cell C ( P ) and its estimated count satisfies the accuracy test :
Due to space limitation, we skip the proof of the theorem in this paper.
 In case  X  0 P &lt;  X  , we do not have sufficient confidence in the ac-curacy of the estimation. In this case, the exact value of D determined by the disk-based list-joining procedure. Algorithm 1 summarizes the SBA algorithm.
 Algorithm 1 The SBA algorithm 1: for all P ` T do 3: for all P ` T do 5: Continue 8: else 9: Compute the true count D P by disk-based list joining In this section we evaluate SBA through an experimental study. The algorithms were implemented in Python and the experiments were conducted on a machine with a 2.5GHz Pentium dual core CPU and 8GB RAM running Ubuntu 11.04.

In order to study the algorithms X  performance under various data characteristics, we generate synthetic data. This allows us to con-trol various parameters, from database size to pattern selectivities. Our synthetic sequence data generator follows that of [4]. The de-fault synopsis size is 100,000 sequences. In the experiment, the II store (Figure 4) contains only the core index CI and the SII store is empty. We remark that the algorithms X  performance is better if more materialized inverted lists are cached in the stores. The results shown in this section are thus conservative ones of our algorithms. Below shows the parameters and their default values. We also show in the table the default settings of the query requirement. We have conducted experiments using various pattern templates T . In this paper we show the results of two templates T 1 and T 2 = ( X , Y , Z , X ). As we have mentioned in the introduction, the first template is related to the round-trip query for metro data while the second template is related to the comparison-shopping query for an online store X  X  web log data. The results of these two templates are illustrative of the algorithms X  performance  X  the general observations drawn from these queries are found to be consistent with those of other templates we tested on the system. For reference, we have also implemented the disk-based CB algo-rithm [9], which computes the s-cuboid in full to identify iceberg cells. The CB algorithm generally takes more than an hour to exe-cute on our 2-million-sequence dataset. In contrast, SBA take only seconds to a couple of minutes across our experiment settings. We do not explicitly show CB X  X  performance in this section because it is at least an order of magnitude slower than SBA.
 Varying  X   X  . The first experiment studies the effect of the iceberg threshold  X  as controlled by the iceberg selectivity  X  Figures 6(a) and 6(b) show the execution times of SBA for the tem-plates T 1 and T 2 , respectively. Note that since the s-cuboid for T of a higher dimension than that of T 1 , there are more cells to com-pute for T 2 . The execution times shown in Figure 6(b) are therefore generally larger than those shown in Figure 6(a). Also, patterns de-rived from T 2 are less restrictive than those from T 1 , therefore, the s-cuboid cells of T 2 are of much higher counts. To stay focus on the iceberg cells, we use a range of  X   X  of larger values for T
From the figures, we see that in general, as  X   X  increases, the ex-ecution times decrease. This is because a larger  X   X  gives a larger iceberg threshold  X  . Hence, (1) there are more non-iceberg cells and (2) the gaps between their counts and the iceberg threshold are generally larger. These translate into (1) more pruning opportuni-ties and (2) more effective pruning (i.e., more likely that the pruning test is satisfied), respectively. Moreover, for a larger  X  , the count of an iceberg cell C ( P ) has to be larger for C ( P ) to be classified as iceberg. Therefore, C ( P ) has to have a bigger presence in the synopsis, i.e.,  X  L [ P ] has to be larger. This allows D accurately estimated and so the accuracy test is easier to satisfy. Varying |  X  S | . Next, we study the effect of the synopsis size | Figure 6(c) shows the algorithms X  execution times for template T when |  X  S | varies from 1K to 400K. Let us first look at the perfor-mance of SBA. From the figure, we see that SBA X  X  execution time first drops then rises as |  X  S | increases. There are two effects of the synopsis size: (1) A bigger synopsis results in longer time spent on processing the synopsis (e.g., to compute the lists  X  L [ P ]  X  X ). Hence execution time rises. (2) A bigger synopsis results in more effective pruning/accepting/accuracy tests. It is thus less likely that SBA has to resort to disk-based list-joining. Hence, execution time drops. The net effect of these two factors is a U-shaped performance curve for SBA. In our future work, we will try to automatically decide the optimal sample size for each query. Before PREDATOR [13], traditional database systems do not for-mally support sequence data. PREDATOR stores sequence data based on the object-relational model. The DEVise system [10] sup-ports sequence data processing using the relational model. To query sequence data, Sadri et al. [11] develop an extension to SQL, called SQL-TS, to express various kinds of pattern-based queries. These systems do not directly support OLAP operations or the processing of pattern-based aggregate queries
Iceberg query on relational data was first studied by Fang et al. [5]. The computational issue addressed in their work is the dif-ficulty of housing a large multidimensional array in memory for effective computation of cuboids (and thus iceberg cells). Two techniques, namely, sampling and coarse counting are devised to identify candidate iceberg cells. Full scans of the disk-resident data is needed to eliminate false positives and false negatives in the an-swer. In contrast, our approach is to compute the iceberg cells of an s-cuboid via statistical tests. As we have shown in the experiments, disk accesses are mostly avoided, resulting in very fast processing.
In this paper we studied the problem of answering iceberg pattern-based aggregate (IPBA) queries. We put forward a synopsis-based solution, which samples and stores a small synopsis of a sequence database in main memory. We devised three statistical tests that process the synopsis to confidently classify a cell as iceberg or non-iceberg, and to confidently compute aggregate estimates of the ice-berg cells. Experimental study shows that our proposed algorithm outperforms the existing algorithms in order of magnitude.
This work is partly supported by the Research Grants Council of Hong Kong (GRF PolyU 525009, 521012, 520413), Amazon Research Grant, and Microsoft Hong Kong Gift. [1] B. Babcock, et al. Models and issues in data stream systems. [2] K. Beyer, P. J. Haas, B. Reinwald, Y. Sismanis, and [3] J. Chen, et al. NiagaraCQ: a scalable continuous query [4] C. K. Chui, B. Kao, E. Lo, and R. Cheng. I/O-efficient [5] M. Fang, N. Shivakumar, H. Garcia-Molina, R. Motwani, [6] H. Gonzalez, J. Han, and X. Li. FlowCube: Constructing [7] H. Gonzalez, J. Han, X. Li, and D. Klabjan. Warehousing [8] M. Hadjieleftheriou, X. Yu, N. Koudas, and D. Srivastava. [9] E. Lo, B. Kao, W.-S. Ho, C.-K. Chui, and D. Cheung. OLAP [10] R. Ramakrishnan, D. Donjerkovic, A. Ranganathan, K. S. [11] R. Sadri, C. Zaniolo, A. Zarkesh, and J. Adibi. Optimization [12] P. Seshadri, M. Livny, and R. Ramakrishnan. Sequence query [13] P. Seshadri, M. Livny, and R. Ramakrishnan. The design and [14] F. Wang, et al. Temporal management of RFID data. In
