 In statistical machine translation (SMT), the qual-ity of the translation model is highly dependent on the amount of parallel data used to build it. Paral-lel data has usually been generated through the pro-cess of human translation, which imposes signifi-cant costs when building systems for new languages and domains. To alleviate this problem, researchers have considered comparable corpora X  X  collection of multilingual documents that are only topically aligned but not necessary translations of each other (Fung and Cheung, 2004). While most previous ap-proaches for mining comparable corpora heavily de-pend on initializing the learning process with some translation dictionaries or parallel text, we use mul-tilingual topic models to detect document transla-tion pairs and extract parallel sentences with only minimum cross-language prior knowledge: the pub-lication dates of articles and the tendency of some vocabulary to overlap across languages. Processing only four years of Gigaword news stories in English and Spanish, we are able to outperform the WMT X 11 baseline system trained on parallel News Commen-tary corpus (Table 1). Most previous, if not all, approaches for mining comparable corpora heavily depend on bilingual re-sources, such as translation lexica, bitext, and/or a pretrained baseline MT system. This paper, in con-trast, investigates building MT systems from com-parable corpora without such resources. In a widely cited early paper, Munteanu and Marcu (2005) use a bilingual dictionary and a collection of parallel sen-tences to train IBM Model 1 and a maximum en-tropy classifier to determine whether two sentences are translations of each other. Tillmann and Xu (2009) and Smith et al. (2010) detect parallel sen-tences by training IBM Model 1 and maximum en-tropy classifiers, respectively. In later work on de-tecting sentence and phrase translation pairs, Cettolo et al. (2010) and Hoang et al. (2014) use SMT sys-tems to translate candidate documents; Quirk et al. (2007) use parallel data to train a translation equiva-lence model; and Ture and Lin (2012) use a trans-lation lexicon to build a scoring function for par-allel documents. More recently, Ling et al. (2013) trained IBM Model 1 on bitext to detect translation-ally equivalent phrase pairs within single microblog posts. Abdul-Rauf and Schwenk (2009), Uszkoreit et al. (2010), and Gahbiche-Braham et al. (2011), rather than trying to detect translated sentence pairs directly, translate the entire source language side of a comparable corpus into the target language with a baseline SMT system and then search for corre-sponding documents.

On the other hand, there exist approaches that mine comparable corpora without any prior trans-lation information or parallel data. Examples of this approach are rarer, and we briefly mention two: En-right and Kondrak (2007) use singleton words (ha-pax legomena) to represent documents in a bilingual collection for the task of detecting document trans-lation pairs, and Krstovski and Smith (2011) con-struct a vocabulary of overlapping words to repre-sent documents in multilingual collections. The lat-ter approach demonstrates high precision vs. recall values on various language pairs from different lan-guages and writing systems when detecting transla-tion pairs on a document level such as Europarl ses-sions. Recently proposed approaches, such as (Kle-mentiev et al., 2012) use monolingual corpora to es-timate phrase-based SMT parameters. Unlike our paper, however, they do not demonstrate an end-to-end SMT system trained without any parallel data.
Our approach differs from these and other previ-ous approaches by not relying on any initial trans-lation dictionary or any bitext to train a seed SMT system. Therefore, the primary experimental com-parison that we perform is between no bitext at all and a system trained with some bitext. Our bootstrapping approach (Figure 1) is a two-stage system that used the Overlapping Cosine Distance (OCD) approach of Krstovski and Smith (2011) as its first step. OCD outputs a ranked list of candidate document pairs, which are then fed through a sentence-alignment system (Moore, 2002). A polylingual topic model (PLTM) (Mimno et al., 2009) is then trained on the aligned portions of these documents. Using the trained model, we infer topics on the whole comparable training set. Once represented as points in the topic space, documents are then compared for similarity using divergence based metrics such as Hellinger (He) distance. Re-sults from these comparisons create a single ranked list of text translation pairs, which are on a sub docu-ment length level. From this single ranked list, using thresholding, we again extract the top n candidate translation pairs that are then fed to an aligner for further refinement. 3.1 Discovering Document Translation Pairs For a given comparable corpus, OCD assumes that there is a set of words that exist in both languages that could be used as features in order to discrimi-nate between documents that are translations of each other, documents that carry similar content, and doc-uments that are not related. Firstly, for each lan-guage in the collection a vocabulary is created which consists of all word types seen in the corpora of that language. Words found in both source ( s ) and tar-get ( t ) languages are extracted and the overlapping list of words are then used as dimensions for con-structing a feature vector template. Documents in both languages are then represented using the tem-plate vector whose dimensions are the tf  X  idf val-ues computed on the overlapping words which we now consider as features. While the number of overlapping words is dependent on the families of the source and target languages and their orthogra-phy, Krstovski and Smith (2011) showed that this approach yields good results across language pairs from different families and writing systems such as English-Greek, English-Bulgarian and English-Arabic where, as one would expect, most shared words are numbers and named entities.

We compare these vector representations effi-ciently using Cosine (Cos) distance and locality sen-sitive hashing (Charikar, 2002). This results in a sin-gle ranked list of all document pairs. Compared to the traditional cross-language information retrieval (CLIR) task where a set of document queries is known in advance, there is no prior information on the documents in the source language that may or may not have translation documents in the target language of the collection. Due to the length in-variance of Cos distance, the single ranked list may contain document pairs with high similarity value across all documents in the target language. This issue in OCD is resolved by applying length and di-versity filtering. Length filtering removes translation pairs where the length of the target document t is not within  X  20% of the source document s length, lf : 0 . 8  X  | s | / | t |  X  1 . 2 . For a given source doc-ument, diversity filtering is done by allowing only the top five ranked target document pairs to be con-sidered in the single ranked list. Limiting the num-ber of target documents for a given source document may discard actual document translation pairs such as in a comparable corpus of news stories where doc-uments in the target language originate from large number of news source. While it may restrict more document translation pairs to be discovered, the di-versity filtering, on the other hand prevents from limiting the number of discovered similar and trans-lation documents to be from the same topic and do-main and thus introduces diversity on another, do-main or topic based, level. 3.2 Representing Multilingual Collections with Latent topic models are statistical models of text that discover underlying hidden topics in a text collec-tion. We use PLTM (Mimno et al., 2009), a mul-tilingual variant of LDA, which assumes that doc-ument tuples in multilingual parallel and compara-ble corpora are drawn from the same tuple-specific multinomial distribution over topics  X  . For each doc-ument in the tuple, PLTM assumes that words are generated from a language L specific topic distribu-tion over words  X  L . Using this generative model we represent documents in multiple languages in a com-mon topic space which allows us to perform similar-ity comparisons across documents in different lan-guages.

The original PLTM posterior inference is approx-imated using collapsed Gibbs sampling (Mimno et al., 2009). While more straightforward to imple-ment, this inference approach requires iterating over the multilingual collection multiple times to achieve convergence. This incurs a computational cost that could be significant for large collections such as Gi-gaword. Moreover, detecting and retrieving docu-ment translation pairs requires all-pairs comparison across documents in both languages with a worst case time complexity of O ( N 2 ) which is imprac-tical for large comparable corpora. One solution to this problem is to parallelize the brute-force ap-proach through the MapReduce framework (Ture et al., 2011; Ture and Lin, 2012) but this approach re-quires special programming methods.

In order to use the PLTM on large collections and avoid the bottleneck introduced by Gibbs sampling, we use the online variational Bayes (VB) approach originally developed by (Hoffman et al., 2010) for LDA model to develop a fast, online PLTM model. As in the regular VB approach, online VB approx-imates the hidden parameters  X  , z and  X  using the free variational parameters:  X  ,  X  and  X  . Rather than going over the whole collection of documents to bring the variational parameters to a convergence point, Krstovski and Smith (2013) perform updates of the variational parameters  X  and  X  L on docu-ment batches and update the  X  L variational param-eter as a weighted average of its stochastic gradi-ent based approximation and its value on the pre-vious batch. The approximation is done through Expectation-Maximization (EM).

Unlike the usual metric spaces where two vec-tors are compared using distance metrics such as Euclidean (Eu) or Cos distance, in the probability simplex similarity is computed using information-theoretic measurements such as Kullback-Leibler, Jensen-Shannon divergence and He distance. We alleviate the O ( N 2 ) worst case time-complexity in the probability simplex by utilizing approximate nearest-neighbor (NN) search techniques proven in the metric space. More specifically, we use the for-mulaic similarity between He and Eu: He ( p,q )  X  Eu ( x,y ) , when  X  i : i = 1 ,n of x i and y i , x i = and y i = Eu based, approximate NN computation approaches We demonstrate the performance of the bootstrap-ping approach on the task of extracting parallel sen-tences to train a translation system. We evaluate MT systems trained on extracted parallel sentences and compare their performance against MT systems cre-ated using clean parallel collections. MT systems were evaluated with the standard BLEU metric (Pa-pineni et al., 2002) on two official WMT test sets that cover different domains: News (WMT X 11) and Europarl (WMT X 08). We trained the Moses SMT system (Koehn et al., 2007) following the WMT shared task guidelines for building a baseline system with one of two parallel training collections from WMT X 11: English-Spanish News Commentary (v6) and Europarl (v6). MT systems were trained us-ing test-domain specific language models (LM)  X  English News Commentary for News test and En-glish Europarl for the Europarl test. Our compara-ble corpus consists of news stories from the English (LDC2011T07) and Spanish (LDC2011T12) Giga-word collections.

We perform the following processing in each step of the pipeline. We run OCD on days of news origi-nating from multiple news agencies or more specifi-cally on news stories originating from the same day which we consider as the  X  X inimal supervision X  in initiating the bootstrapping process. Since the OCD approach generates a single list of ranked document translation pairs, for the second stage of our pipeline we consider the top n document translation pairs. We define n to be all document translation pairs whose Cos similarity is between the range of the max (i.e. the top 1 scored document translation pair in the single ranked list) and max ous thresholding based on absolute values (Ture et al., 2011), this approach allows us to utilize thresh-old values that are automatically adjusted to the dy-namic range of the Cos distance of a particular cor-pus. Sentences from the top n news stories are ex-tracted and are further aligned. The output of the aligner is then used as a training set for the PLTM model. We represent each of the news stories using the per story aligned sentences. Once trained, we use the PLTM model to infer topics back on to the news stories. We then again create a single ranked list of translation news story pairs by computing di-vergence based similarity using He distance (  X  3.2). Keeping the top n ranked news story pairs, we ob-tain a list of what we believe are parallel documents which we then use to extract sentence pairs. Sen-tences are finally processed through an aligner and then used as the training corpus to our MT system. Training Source Bitext Extr. Test Set News Comm. (NC) 131k 0 23.75 Europarl (EP) 1,750k 0 23.91 Gigaword (GW) 0 926k 24.28 * NC+GW 131k 926k 24.92 * EP+GW 1,750k 926k 25.90 *
The Gigaword collection contains news stories generated from various agencies in different lan-guages. On any given day, a news story in English may or may not cover the same topic as one in a dif-ferent language. To perform a fair evaluation with the WMT X 11 News test, we considered stories pub-and 2004. Table 1 shows the performance compar-ison, on the News test set (WMT X 11), of the MT system trained on extracted parallel sentences from four years of Gigaword data (GW) with a MT system trained on two WMT X 11 baseline parallel collec-tions: Europarl (EP) and News Commentary (NC). While over 10 times bigger than NC, EP is out of do-main and thus performs only slightly better. On the News test set, parallel sentences automatically ex-tracted from only four years of Gigaword data out-perform systems trained on clean NC or EP bitext.
In order to determine statistically significant dif-ferences between the results of different MT systems we ran the randomization test (Smucker et al., 2007) on the News test set with 10k iterations. In each it-eration we performed permutations across the trans-lation sentences obtained from the two MT systems whose statistical difference in performance we eval-uate.
 Table 2 shows the performance comparison on the Europarl test set (WMT X 08) between the MT system trained on the extracted parallel sentences and the two MT baseline systems. On this test set, unsur-prisingly, EP training performed very well.
Table 3 gives a summary of ablation experiments that we performed across the two stages of our bootstrapping approach. More specifically, we ex-Training Source Bitext Extr. Test Set News Comm. (NC) 131k 0 25.43 Europarl (EP) 1,750k 0 32.06 Gigaword (GW) 0 926k 23.88 NC+GW 131k 926k 25.61 EP+GW 1,750k 926k 31.59 plored using bitext extracted by OCD alone, with-out PLTM reestimation, to train a MT system. Both extracted bitext sets also contained many duplicate sentence pairs. In this set of experiments we also explored the effect of deduplicating them, i.e. going over the extracted set of English-Spanish sentence pairs and removing the duplicate ones. Bitext ex-tracted by OCD alone without PLTM reestimation performed only slightly worse on WMT X 11. The OCD-only data, however, only showed 70% over-lap with OCD+PLTM (GW). Deduplicating the two bitexts (dedup.) hurts OCD somewhat more than OCD+PLTM. On the Europarl test set, however, deduplicating OCD+PLTM bitext caused a signifi-cant boost from 23.88 to 24.67, while causing slight performance drop for OCD (cf. NC-trained 25.43). These interactions of test domain, redundancy, and model settings leave room for further studies of the performance of our bootstrapping approach. We introduced a bootstrapping approach for de-tecting document translations and extracting paral-lel sentences through latent topic models that are trained with minimal prior knowledge and no lexical resources. The proposed approach is able to extract parallel sentences from comparable corpora to train MT models that outperform a baseline model trained on a parallel collection.
 This work was supported in part by the Harvard-Smithsonian CfA predoctoral fellowship, in part by the Center for Intelligent Information Retrieval and in part by NSF grant #IIS-0910884. Any opinions, findings and conclusions or recommendations ex-pressed in this material are those of the authors and do not necessarily reflect those of the sponsor.
