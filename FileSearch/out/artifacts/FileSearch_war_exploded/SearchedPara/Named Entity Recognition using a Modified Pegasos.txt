 In this paper, we describe a named entity recognition using a modified Pegasos algorithm for structural SVMs. We show the modified Pegasos algorithm signi ficantly outperformed CRFs and the training time for the modified Pegasos algorithm is reduced 17~26 times compared to CRFs. I.2.7 [ Natural Language Processing ]: Text analysis . Algorithms, Experimentation, Languages. Modified Pegasos algorithm , named entity recognition. The named entity recognition (NER) task is one of the most important subtasks in natural language processing (NLP) and information extraction (IE). It is defined as the identification and classification of named entities in natural language text. While early studies were mostly based on handcrafted rules, most recent ones use supervised machine learning as a way to automatically induce rule-based systems or sequence labeling algorithms starting from a collection of tr aining examples. Supervised machine learning techniques incl ude Hidden Markov Models [1], Maximum Entropy Models [2], Support Vector Machines (SVM) [3], and Conditional Random Fields (CRF) [4]. In this paper, we present a NER using a modified Pegasos algorithm for structural SVMs. First, we describe structural SVMs [5][6][7] for NER. Then we extend the Pegasos algorithm originally designed to fit binary classification SVMs [8] to structural SVMs. Structural SVMs are proposed for structured prediction problem by Tsochantaridis et al. [5]. Joachims et al. proposed 1-slack formulation to structural SVM [6]. It is based on an alternative To find this solution, Joachims et al. proposed 1-slack cutting plane algorithms [6]. The pseudo code of the algorithm is given in algorithm 1. The Pegasos algorithm is a stoc hastic gradient decent (SGD) method that is originally designed to fit binary classification SVMs [8]. SGD methods use approximate gradients estimated from subsets of the training data and update the weights of the features in an online fashion. For large-scale problems, SGD methods are claimed to be sufficiently precise while delivering the best performance vs. training time trade-off [9]. Among SGD methods, the Pegasos algorithm has shown a promising performance for binary classification SVMs. The Pegasos algorithm shares the simplicity and speed of online learning algorithms but is guaranteed to c onverge to an actual binary SVM solution. The Pegasos algorithm minimizes the following objective function for bina ry classification SVMs. Parameter k is the number of examples used for calculating the i =1,2,..., m } (| A t | = k ). The subgradient of f ( w ; A t ) is The Pegasos consists of two major steps in updating w t : 1) substeepest gradient update w t+1/2 and 2) projection step. Specifically, in each iteration, the Pegasos looks for a steepest gradient search direction given A t and projects the updated w t+1/2 onto the set { w :|| w ||  X  1/sqrt(  X  )}. We extend the Pegasos algorithm for structural SVMs. We replace the objective of Pegasos with an approximate objective function parameter): number of mislabelings for output y relative to the correct output, y . The subgradient of f ( w ; A t ) is subgradient projection method. For the case of k =1, we obtain a variant of the stochastic gradient method. A pseudocode of the modified Pegasos for stru ctural SVMs (Pegasos-struct) is depicted in algorithm 2. The algorithm receives as input two parameters: T , the number of iterations to perform; and k , the number of examples to use for calculating the We used 1-slack structural SVMs using a modified FSMO [10][11][12]. We implemented Pegasos-struct algorithm in C++. For all experiments, a linear kernel was used. Regularization constant C from {10, 100, 1000, 10000, 100000} was chosen based on optimization of the test set for all experiments. For a precise stopping condition, we set e = 0.1. In Pegasos-struct algorithm, we use k = 100 and  X  = 1/ C . For comparison, we also implemented the CRFs using L-BFGS algorithm. Gaussian prior for CRFs from {0.01, 0.1, 1, 10, 100} was chosen based on optimization of the test set for al l experiments. We performed 500 iterations for training. All experi ments were conducted on an Intel Core i7 CPU PC with 3.33 GHz and 12 GB of RAM. 
CRFs (baseline) 16,738 96.78 84.99 1-slack S-SVMs 11,239 96.92 85.14 Pegasos-struct 649 96.94 85.43 Table 2 shows the performance of NER on TV domain. We obtained the performance, 84.99% F1, 85.14% F1, and 84.3% F1 using CRFs, 1-slack structural SVMs, and Pegasos-struct respectively. We found 1-slack structural SVMs and Pegasos-struct significantly outperform s CRFs. The improvement of 1-slack structural SVMs over CRFs is highly significant with a significance level less than 0.01 using a paired t-test 1 (the two-tailed p-value is 0.0037). Pegaso s-struct X  X  improvement over CRFs is also highly significant with a significance level less than 0.01 using a paired t-test (the two-tailed p-value is 0.0018). However, the difference of Pegaso s-struct and 1-slack structural SVMs is not significant (the two-tailed p-value is 0.69). Moreover, the training time for Pegasos-stru ct is reduced 26 times and 17 times compared to CRFs and 1-slack structural SVMs, respectively. Table 3 shows the performance of NER on food domain. The improvement of Pegasos-struct over CRFs is highly significant with a significance level less than 0.05 using a paired t-test (the two-tailed p-values are 0.038). However, the improvement of 1-slack structural SVMs over CRF s is not significant with a significance level less than 0.05 (t he two-tailed p-values are 0.102 respectively). The difference of Pegasos-struct and 1-slack structural SVMs is not significant (the two-tailed p-value is 0.38). The training time for Pegasos-struct is reduced 17 times and 3 We used a paired t-test on labeling disagreements. We compared the correctness of the labeling decisions of two methods. The null hypothesis is that the disagr eements (correct vs. incorrect) are due to chance. 
