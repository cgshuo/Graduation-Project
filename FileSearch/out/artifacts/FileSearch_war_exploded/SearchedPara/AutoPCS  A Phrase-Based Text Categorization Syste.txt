 When there is a research paper submitted to a conference, some submission systems would ask its contributor to choose several relevant topics for the paper from a given corresponding reviewers to judge the paper. Those given predefined topics may cover most of the research areas in a certain domain. A snapshot of a manual relevant topic selection system can be seen in Fig. 1. 
This topic selection process can be regarded as a manual text classification way. It the domain. But it becomes much unreliable and time-consuming if the researcher is a freshman of the research field who do not know most of those topics. In addition, there are also some conferences which would not ask contributors but some experts in this domain to choose relevant topics for the paper. This might spend lots of time and they may disagree in whether or not to classify a document under a certain category. Besides, manual classification is incautious, which may also bring false classification. In order to solve these problems, we would like to provide some automatic relevant topics recommendation or checkout functio n to the manual categorization submission system by developing an Auto matic P ublication C ategorization S ystem, AutoPCS . 
As a fundamental task in Information Retrieval and Data Mining, text categorization (or text classification) has been studied extensively in the past several decades. The classical approach to text categorization has so far been using a document representation in a word-based space, however, the main drawback of which is it destructs the semantic relations between words by using words in a phrase separately [7]. A classical example which has been proposed in [7] is  X  X hite House X  or  X  X ill Gates X  . Given a BOW ( B ag-O f-W ords) of a document in which words  X  X ill X  and  X  X ates X  occur, one can suggests that the document is about accounting or gardening, but not about computer software. Whereas given a document representation that contains a phrase  X  X ill gates X  , the reader will hardly be mistaken about the topic of discussion. 
These fairly obvious observations led researchers to an idea of enriching the BOW representation by phrases. B ag-O f-B igrams (pairs of consequent words) was proposed firstly in early 90s [8]. However, it always showed only marginal improvement or even a certain decrease. As far as we co ncerned, the word-based BOW is efficient enough for text classification because we are always classifying texts from different fields like  X  X orporate/Industrial X ,  X  X arkets X  and  X  X overnment Finance X  in Reuters dataset. Since each category has some solely-used domain words, adding phrases into the bag cannot improve much. But the situation becomes quite different when it almost share the same word set, e.g. texts from two similar topics  X  X ata mining X  and  X  X ext Mining X  . The three words  X  X ata X  ,  X  X ining X  and  X  X ext X  are very common in text about either topic. only by words (or BOW). But different topics have respective terms which are usually or simply BOP) is expected to be more efficient. In this paper we would like to overview some related works in recent years on the problem of using phrases for text classification. Then we try to use BOP in classifying similar texts in our dataset. 
The rest of the paper is organized as follows: in Section 2 we describe the problem classification in history, especially the mo st recent works on the problem of using incorporating words and phrases in document representations; Section 5 presents our automatic new paper categorization system (AutoPCS) we developed for paper submission system. Finally we make a conclusion in Section 7. In order to better state the problem in text classification, we would like to give a simple formulation to text classification as follows. Assume we are given a training set: 
In this formula (1), each document  X   X  belongs to a document set  X  and the label  X   X  algorithm which can generate a classifier or a hypothesis  X  X  X : X  that can label unlabeled each document in D accurately, with the help of the training set  X  . 
Designing a learning algorithm for text classification usually follows the classical approach in pattern recognition, where data instances (i.e. documents) first undergo a transformation of dimensionality reduction, and then a classifier learning algorithm is applied to the low-dimensionality representations. This transformation is also performed prior to applying the learned classifier to unseen instances. 
The incentives in using dimensionality reduction techniques are to improve classification quality and to reduce the computational complexity of the learning algorithm and of the application of the cl assifier to unseen documents. Typically, dimensionality reduction techniques fall into two basic schemes: feature selection and feature generation. Feature selection can also be called as feature reduction, which tries to select the subset of features (words in text classification) that are most useful for text classification. In contrast, feature generation which can also be called as feature induction, tries to generate new features which are not necessarily words for representation. 
After feature selection or feature generation, the next step is to choose a proper classifier. There have been lots of excellent algorithms proposed by researchers in this field such as Na X ve Bayes, Bayes Networks, K Nearest Neighbors, Decision Trees, Decision Rules, Neural Networks, SVMs and so forth. Different classifier performs best in different situation. The classical approach to text categorization has so far been using a document representation in a word-based space which re lies on classification algorithms that are trained in a supervised learning manner. In the early days of text categorization, classifier design has been significantly advanced [1] with lots of strong learning algorithms emerged such as [2], [3], [4]. Later, despite numerous attempts to introduce more sophisticated techniques for document representation, the simple minded independent word-based representation, known as bag-of-words (BOW), remains very effective. Indeed, to date the best multi-class, multi-labeled categorization results for the well-known Reuters-21578 dataset are based on the BOW representation [5] [6]. 
A sufficient effort has been expended on attempting to come up with a document representation which is richer than BOW. A widely explored approach is in using n-However, after many years of unsuccessful attempts to improve the text categorization results by applying n-grams (usually n=2), many researchers agree that there might be a certain limitation in usability of phrases for text categorization. According to [7], this can probably be explained by two considerations: (a) the results achieved on these corpora are so high that they probably cannot be improved by any technique, because all the incorrectly cla ssified documents are basically mislabeled; and (b) the corpora are  X  X imple X  enough so only a few extracted keywords can do the entire job of distinguishing between categories. 
There are mainly two kinds of approaches to incorporate n-gram of words into the document representation: the first one applies n-grams together with unigrams, while the second one excludes unigrams from the representation and bases on n-grams only. However, in most cases the second appr oach leads to a certain decrease in the categorization results, while the first approach can potentially improve the results. This observation indicates that the simple BOW representation is powerful enough, so the classification results cannot be probably improved by replacing the BOW representation but only by extending it. 
Now we give a particular presentation to the state-of-the-art of using n-gram of words into the document representation. [9] uses document representation based on Noun Phrases (obtained by a shallow parsing) and Key Phrases (the most meaningful phrases obtained by the Extractor system). The results achieved by either scheme are roughly the same as their baseline with BOW representation. [10] uses both unigrams and bigrams as document features and extract the top-scored features using various feature selection methods. Their results indicate that in general bigrams can better predict categories than unigrams. However, despite the fact that bigrams represent the majority of the top-scored features, the use of bigrams does not yield significant improvement of the categorization results while using the Rocchio classifier. [11] combines BOW and Bag-Of-Ngrams (BON) as document features. By n-grams the authors mean all continuous word sequences in texts. They use several common induction with combination of single words and word pairs. The word pairs are of the Head/Modifier type, i.e. nouns are extracted with their modifiers. The authors show that using pairs without BOW, the results of both classifiers decrease, while using both pairs and BOW, the results are marginally above the BOW baseline. For extracting bigrams, [13] use the following method: first, they sort words according to their document frequency and consider only highly ranked words. Then they extract bigrams such that at least one of their components belongs to those highly ranked Mutual Information with respect to a category. One of few relatively successful attempts of using bigrams is demonstrated by [14], who propose a very sophisticated feature induction technique to improve the text categorization results on Reuters and ComputerSelect datasets. They apply a string distance measure which is similar to the String Kernel [15]. Basing on this measure the authors introduce a score according to which they rank bigrams. Then they extract highly ranked bigrams so that less than 1% of all bigrams are extracted. Using the SVM classifier, the authors achieve a significant improvement on the ComputerSelect dataset, while the improvement on the Reuters dataset is again statistically insignificant. Nevertheless, this result on Reuters is highly noticeable: 88.8% break-even point is clearly the state-of-the-art result. The success of this technique may be explained by the fact that documents of the Reuters dataset are very well structured (many of them are even not free text but tables) and the string similarity method used by the authors manages to capture this clear structure. Now we propose our own method for classifying similar texts. Most of the time, we are classifying texts from totally different fields, each of which has some solely-used domain words, so the word-based BOW is effective enough for text classification. But the situation becomes quite different when it comes to classifying similar texts. 4.1 Similar Texts Analysis we cannot classify them only by words. In this situation, a phrase-based representation (BOP) is expected to be mu ch more effective than BOW. Take the example we mentioned above: We have collected a small document set which contains 158 documents from two similar topics  X  X ata mining X  and  X  X ext Mining X  . There are 120 documents from  X  X ata Mining X  while other 38 from  X  X ext Mining X  . As it is performed in the table 1 below, the average number of the three words  X  X ext X ,  X  X ata X  and  X  X ining X  contained in documents of the two topics are not quite different, but the number of  X  X ext mining X  in documents of  X  X ext Mining X  is apparently more than those of  X  X ata Mining X  . On contrast, the number of  X  X ata mining X  in documents of  X  X ata Mining X  is much more than those of  X  X ext Mining X  . 
The same problem also exists between some other similar topics such as  X  X nformation Retrieval X  and  X  X eb Search X  ,  X  X nformation Security X  and  X  X rivacy and Trust X  , and so forth. There are still some other similar topics which may not have this situation, BOW is not very applicable either. Therefore, in order to classify documents from similar topics more effectively, we propose to use phrases combined with words in classifying similar texts. 4.2 Using BOP in Text Categorization It is necessary to explain that phrases we defined in bag-of-phrases (BOP) method are different from those in [10]. In [10] phrases are only Noun Phrases (obtained by a shallow parsing) and Key Phrases (the most meaningful phrases obtained by the Extractor system); while in our BOP method, phrases are frequently-used continuous word sequences (including a single word) in texts. In order to extract them from texts, we use an n-gram word sequence extractor which can get all word sequences no longer than n (including unigram), then only those word sequences which have method. 
After we get all potential phrases and words (word can also be seen as single-word phrase) as features for BOP, feature selection is necessary to reduce dimensionality and overcome the statistical sparseness of document representations. After feature results. Those previous attempts to incor porate phrases or n-grams in the past decade lead us to the following two strategies: (a) There are too much n-gram phrases (not words) in our phrase bags, it is necessary to make sure that the phrases we will use are all highly discriminative features. That means we should only choose those n-gram phrases which are  X  X etter X  than all their components ( X  X etter X  means more discriminative). Just like the phrase  X  X ata mining X , which can be chosen only if it is  X  X etter X  than both  X  X ata X  and  X  X ining X  ; (b) In order to improve results that have been achieved, we should enrich the existing model rather than propose a new one. That implies that we prefer to choose feature selection method and classifier from existing ones [7].

Based on the two strategies above, we would like to find out which phrases are  X  X etter X  than their components firstly. For each category we sort all the unigrams according to their Mutual Information measure with respect to the category [7]. Then we compare the rank of each n-gram phrase to its component unigram words. If the rank of n-gram phrase is better than all of its components, then it can be chosen, otherwise it should be removed from the phrase bag. After this process, the number of phrases left in the bag decrease sharply. 
For the next step, we have to select a feature selection (FS) method for the phrases in the bag. There are lots of FS methods proposed. There are some class-independent measures such as document frequency . It is the simplest feature selection method which based on Zipf X  X  Law . By this method, N most common phrases and those terms that appear in fewer than M documents (M usually 1 or 2) should be removed. However, we prefer to use other methods which consider classes while selecting features such as Information Gain [16] , Chi-Square (CHI) [17] , Gain Ratio [18] and so forth. 1) Information Gain, which is also known as Expected Mutual Information, tries to 2) Chi-square measures the lack of independence between a term t and a category 3) Gain Ratio is commonly used as a splitting criterion in decision tree induction. It Since we don X  X  know which FS method performs better for similar texts, we would choose a proper classifier to learn the relationships between features and predefined categories. There have been lots of ex cellent algorithms proposed such as Na X ve Bayes [19], Bayes Networks [20], K Nearest Neighbors (KNN) [21], Decision Trees [22], SVMs [23] and so forth. 1) Na X ve Bayes : A very cheap but very successful classifier which assumes that all 2) Bayes Networks : This is a classifier which tries to improve the results of Na X ve 4) Decision Trees : The basic idea of decision tree is to classify texts through a 5) SVMs : A SVM is an algorithm which computes the linear separation surface Our experimental data set contains 917 abstracts from 15 different categories. These abstracts come from conference papers in Databases field from ACM Digital Library 1 ( ACMDL). To make this data set, we collected thousands of abstracts of conference papers from famous conferences of Databases in ACMDL, and then we label category for each abstract according to the name of session it belongs to, e.g. if a paper belongs to a session named  X  X ata Mining X , then the category of its abstract can be labeled as  X  X ata Mining X . Since the limitation of our resources, although we find hundreds of different session names, most of them only contain no more than 10 abstracts. Therefore, we only have chosen some popular categories, each of which contains no less than 30 abstracts. All categories and the number of abstracts in each category of the data set are given in Fig. 2. 
Firstly, we use an 3-gram word sequence extractor to extract all phrases no longer than 3 (including words), and only those word sequences which appear more than 3 times in all texts are chosen as features in our BOP method. Secondly, we remove those less discriminative phrases from the bag with the consideration we described in section 4.2. In order to make a comparison between BOP and BOW, we also use the third step (The second step of BOP is not necessary for BOW) 
In the third step, in order to choose a proper feature selection (FS) method for the phrases in the bag, we use some common FS methods including Information Gain (IG), Chi-Square (CHI), Gain Ratio respectively. After feature selection, we have to Gain Ratio 100 120 140 Gain Ratio Gain Ratio Gain Ratio Gain Ratio choose a proper classifier from the following algorithms: Na X ve Bayes, Bayes Networks, K Nearest Neighbors, Decision Trees, SVMs and so forth. The results with ten-fold cross-validation on the data set are given in the Table 2 to Table 6 and Fig. 3. 
As we can see from Table 2 to Table 6, BOP performs better than BOW in most situations here, which proves that BOP is more effective for our data set. What X  X  more, Bayes Networks performs much better than the other classifiers on our data set. it performs the best when there are only 80-100 words and phrases chosen in the BOP by using Information Gain feture selection method. According to the experimental study in the last section, we decide to use BOP + Information Gain + Bayes Networks to do text classification for AutoPCS. Different from classifying unseen text into one of the predefined category, AutoPCS tries to find out three most relevant topics for each text. Therefore, we have to make a small adjustment to the classifier. We still use the BOP representation combining Information Gain feature selection method to get about 500 high-discriminative phrases and words in the bag. However, for an unseen text, the modified Bayes Networks classifier does not categorize it with only one category, but top three categories which ranked according to their relevant values. 
AutoPCS is a domain-irrelevant tool. To have AutoPCS categorize new papers into three relevant topics according to its ab stract effectively, it should be given a papers which have been categorized with their most relevant topics (only the most certain domain are changing every year, the AutoPCS can be updated if only we add the newly accepted papers with their categorizations as additional input. A snapshot of AutoPCS is shown in Fig. 4. In this paper, we try to develop a tool named AutoPCS which can be used to help experts in choosing relevant topics for newly coming papers from a predefined topic classification problem. Therefore, we tried to use classical BOW based text categorization method to help us but failed. The reason we concluded is that papers submitted to the same conference are all about a certain domain. Although concerning about different topics, they still share lots of common words. But different topics have their respective terms which are usually phrases, so a phrase-based representation (BOP) is expected to be more effective. In fact, a sufficient effort has been taken on attempting to use phrases or n-grams to represent a document which is richer than BOW. However, they are unsuccessful in improving the text categorization results on some famous data sets. 
After an overview to related works in history, we design our own way to extract phrases classifier for our case. Finally, we decide to use BOP + Information Gain + Bayes Networks to do text classification for AutoPCS. Since AutoPCS has to label each new paper with three most relevant topics, we also have to make some adjustment to the output of our classifier. We believe that AutoPCS can be a good helper for conference organizations. This work was supported in part by the National Natural Science Foundation of China under Grant No. 70871068, 70621061, 70890083, 60873017, 60573092 and 60496325. 
