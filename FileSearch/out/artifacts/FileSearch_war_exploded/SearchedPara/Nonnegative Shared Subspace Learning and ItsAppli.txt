 Although tagging has become increasingly popular in online image and video sharing systems, tags are known to be noisy, ambigu-ous, incomplete and subjective. These factors can seriously affect the precision of a social tag-based web retrieval system. There-fore improving the precision performance of these social tag-based web retrieval systems has become an increasingly important re-search topic. To this end, we propose a shared subspace learn-ing framework to leverage a secondary source to improve retrieval performance from a primary dataset. This is achieved by learning a shared subspace between the two sources under a joint Nonnegative Matrix Factorization in which the level of subspace sharing can be explicitly controlled. We derive an efficient algorithm for learning the factorization, analyze its complexity, and provide proof of con-vergence. We validate the framework on image and video retrieval tasks in which tags from the LabelMe dataset are used to improve image retrieval performance from a Flickr dataset and video re-trieval performance from a YouTube dataset. This has implications for how to exploit and transfer knowledge from readily available auxiliary tagging resources to improve another social web retrieval system. Our shared subspace learning framework is applicable to a range of problems where one needs to exploit the strengths existing among multiple and heterogeneous datasets.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval Algorithms, Theory nonnegative shared subspace learning, transfer learning, social me-dia, image and video retrieval
Social tagging by users is a defining characteristic of Web 2.0 and has had a huge impact on the way we use the Web in a rela-tively short time. Social tagging systems exist that allow users to annotate and retrieve any Web-accessible item of interest, includ-ing web pages, images, sounds, videos, blog posts, tweets, links, URLs, locations, and even people. Similar to keywords in Infor-mation Retrieval (IR), short textual descriptors, termed tags, pro-vide concise summarization of resources, often at topical or con-ceptual levels, which are difficult or impossible to infer using au-tomatic, content-based IR methods. The resulting aggregation of tags forms a folksonomy , which acts as a proxy for a controlled taxonomy created by information science experts, and can be used to facilitate retrieval from the resources covered by the folkson-omy. Folksonomy-enabled search has been instrumental in the ris-ing popularity of social image and video sharing platforms, such as Flickr, Picassa and YouTube.

However, the use of tags poses serious challenges; The lack of constraints when creating free-text tags are part of their appeal, but as a result they tend to be noisy, ambiguous and incomplete [18, 14, 8], and could seriously degrade the retrieval performance. Re-search has attempted to improve the accuracy of tags [18, 24, 14, 27], but a common characteristic of the proposed solutions is a fo-cus solely within the internal structure of a given tagging system. However, so long as only internal data is sought, these methods are less likely to be able to break the retrieval barriers caused by the uncertainty and noise inherent within the tags. Therefore, we offer in this paper an alternative approach that diverges from these meth-ods. Our goal is to develop models to leverage external auxiliary sources of information to improve retrieval precision and recall in a target tagging system, presumably to be much noisier. The key intuition is that, by exploiting the common and disparate charac-teristics of a target domain with an appropriate auxiliary source, the retrieval performance in the target domain could be improved thanks to the reduction in the uncertainty of tags achieved through the auxiliary source. However, this gain is not always obvious  X  thus, it rises another important issue: what is the optimal level of joint modelling for which the target domain still benefits from the auxiliary source. To this end, we propose in this paper a shared subspace learning framework based on a joint nonnegative matrix factorization framework. The key advantage in our framework is the modeling flexibility to explicitly vary the level of joint model-ing between data sources  X  and, as demonstrated experimentally, modeling optimal level of sharing results in significant improve-ment over existing method that perform joint matrix factorization without proper guidance (e.g. [27, 16]).

Specifically, our proposed shared subspace factorization learns co-occurrences from the subspaces of the target and auxiliary datasets by explicitly learning a common subset of basis vectors, but cru-cially number of shared basis vectors can be varied. This model also imposes the non-negativity constraint on the decomposed ma-trices, meaning that the basis vectors are part-based and hence rep-resent the important, locally meaningful semantic features of the Web media. Significantly, the learnt subspace is a sparse represen-tation of the data. NMF is also desirable for its ability to resolve the well-known  X  X olysemy X  and  X  X ynonymy X  problems, known to exist in collaborative tagging applications which can cause performance degradation [8].

Our contributions are as follows. A novel formulation to ex-ploit and transfer knowledge from auxiliary tagging resources to improve social image and video retrieval. We derive an efficient al-gorithm for learning the factorization, analyze its complexity, and provide proof of convergence. We provide evidence to validate our framework on image and video retrieval tasks from a Flickr and a YouTube dataset respectively using the LabelMe dataset to improve performance.

The novelty of our approach lies in the flexibility that permits the amount of subspace sharing to be varied from none to full sharing. Whilst these extremes have been considered before [13, 16], our re-sults show that the best performance is achieved when both individ-ual and joint subspaces are present together. Our work shares cer-tain intuition with self-taught learning [20] and multi-view learn-ing [9]. However, self-taught learning targets a supervised learning task using an auxiliary source of information, whereas we address an unsupervised learning task. Multi-view learning formulations, such as canonical correlation analysis (CCA) [9], learn two max-imally correlated subspaces from two datasets without explicitly controlling the shared basis vectors and require two datasets such that each example in the first dataset correspond to one example in the second dataset and therefore can not be used in contexts when such one-to-one correspondences are not available (e.g. context of this paper). Our framework doesn X  X  require any such one-to-one correspondences and hence provides potentially wider applicabil-ity.

The significance of the proposed shared subspace learning frame-work is firstly increased efficacy of image retrieval in Flickr and video retrieval in YouTube, Secondly, the framework has broader application to unsupervised learning with knowledge transfer from one domain to another of different quality. For example, the spe-cific learning experiment we focus on can be perceived as trans-ferring the view of LabelMe images provided by its folksonomy X  static, visual objects, typified by nouns X  X o the Flickr images; But it might be just as desirable to transfer learning from an event or action-oriented folksonomy, typified by verbs, onto the LabelMe dataset. The Web continues to spawn new and specialized folk-sonomies, and the ability to cross-leverage these otherwise frag-mented resources is desirable.

The rest of the paper is organized as follows. Section 2 briefly covers the necessary background for the paper. Section 3 presents the Joint Shared NMF (JSNMF) framework and describes the shared subspace learning. Section 4 describes the tag based social im-age/video retrieval using JSNMF. Section 5 presents the experi-mental results and conclusions are drawn in Section 6. Necessary proofs and derivations are pushed back to Appendix A and B.
From a broad perspective, previous work on tagging systems has been aimed at finding tag relevance, often improving tags by mod-ifying them or recommending additional tags. Marlow et al. [18] present a taxonomy of social tagging systems, and highlight the effect of different design parameters and user communities on the make-up of the resulting tags. Folksonomies acquire differing char-acteristics by virtue of the myriad contextual factors and design de-cisions that lead to their creation. E.g., tagging systems that allow users to see the tags of others allow for rapid vocabulary conver-gence as opposed to  X  X lind X  systems; Users who tag solely for the purposes of retrieving their own resources are more likely to tag with idiosyncratic terms. Some folksonomies may be rich in con-ceptual labels, subsidiary descriptions etc., whilst others may con-sist predominantly of precise labels for visible objects. present information on potential evaluative frameworks by provid-ing a simple taxonomy of incentives and contribution models. Sig-urbj X rnsson and Zwol [24] investigate how users tag photos and the information contained in Flickr tags. Their analysis includes comment on the characteristics of tags in social web sites such as Flickr, and they provide a method to recommend a set of relevant tags at different levels of exhaustiveness from the original tags. Re-cent works by Li et al. [14, 15] present a method to learn social tag relevance by finding visual neighbors and voting based on tag fre-quency. The authors list all images for a given tag and then count the number of images which are visually similar to calculate tag relevance. Wang et al. [25] propose a search-based method which uses content-based retrieval technology to get visually similar im-ages from an image collection and fuse it with text-based retrieval results. These methods perform poor in practice as visual simi-larity techniques have not yet matured. In addition, due to their need to search for visual neighbors, these methods are computa-tionally expensive. In another work by Wu et al. in [27], authors note problems caused by irrelevant tags and describe the seman-tic loss caused when users do not tag a complete image but only one or two objects in the image. They propose a multi-modality tag recommendation method based on both tag and visual correla-tion by generating a ranking feature that uses each modality and therefore again suffer from problems faced by content-based tech-niques. Note that all the aforementioned approaches are confined to the noisy tags within the primary dataset of interest. Often, the quality of user-contributed tags is so poor that none of the above methods work well and an alternative method for improving re-trieval performance must be sought.

One such alternative is to use auxiliary sources of information, resonating with the call in [11] which emphasizes the importance of the use of auxiliary source in the form of web-data and propose that the judicious use of such easily available data can substantially improve precision and recall. They also emphasize the need to for-malize the notion of auxiliary sources of information in a rigorous framework. There exist many tagged datasets which are suitable for the purpose of enhancing performance of social media retrieval from a primary dataset, and are readily available. In particular, La-belMe [21] and Caltech-101 [7] are often used for evaluating and benchmarking object detection and classification techniques. In these datasets, users follow certain guidelines and\or a controlled vocabulary to construct groundtruth labels or tags, making them ideal auxiliary sources of information. To provide an assessment of how much sharing some of these datasets have with respect to tags, we provide, in Table 1, the Jensen-Shannon divergence between the tag distributions of different dataset pairs used in this paper.
On the technical side, our work falls in the field of transfer learn-ing [19, 5] which deals with the transfer of knowledge across dif-ferent domains (or tasks) which share some underlying structure.
For example, a comparative analysis of the LabelMe and Flickr datasets reveals the Flickr tags to contain five times more function words (which exist only for grammatical purposes, and do not cor-respond directly to visual existents within an image) than LabelMe, and also contains less nouns. Table 1: Jensen-Shannon Divergence between the tag distributions of different dataset pairs. For example, by  X  X abelMe-LabelMe X , we mean two different subsets of LabelMe data .
 In this setting, our proposed framework assumes that there is a common underlying subspace shared by the primary and secondary domains. However, unlike multi-task transfer learning approaches which focus on enhancing all the tasks, our approach focuses on only enhancing the performance of primary task using the sec-ondary task. In particular, our work can be categorized as an in-stance of unsupervised transfer learning since there are no labels in either domains. Important difference from the previous unsu-pervised transfer learning approaches (see survey in [19]) is that our approach uses the representation of the data by not just using the shared subspace (common features) but also their private sub-spaces (individual features). Moreover, we are the first to present an unsupervised transfer learning framework for social tag based web retrieval task.

Our joint shared subspace learning method is formulated under the framework of nonnegative matrix factorization (NMF), a model widely used in text mining applications [23, 4, 3]. Formally, NMF aims to factorize a data matrix X into a product of a matrix whose columns span the latent subspace and an encoding matrix : where X is a M  X  N nonnegative data matrix containing N doc-uments in terms of M vocabulary words , F ( M  X  R nonnegative matrix) represents R basis vectors and H ( R  X  N nonnegative ma-trix) contains the co-ordinates (if imagined in Euclidean space) of each document in the space spanned by the columns of the matrix . The part based nature of NMF comes from the nonnegativity constraint which is imposed on the matrices X , F and H in the above factorization. Also, the decomposition achieves some level of sparsity [13] due to the nonnegativity of matrix H as the basis vectors (parts) can only be added and hence participate in a sparse manner to create the  X  X hole X . A special case of the proposed model is utilized for social and semantic analysis using NMF framework in Wu et al [28]. Another instance to discover temporal patterns in social media streams is proposed in [16].
We present a framework that captures the shared basis vectors between the two datasets and their individual bases corresponding to the discriminant subspace. This interpretation leads to the parti-tioning of the subspace into two parts. The first one is common to the datasets and the second is representative of the dataset in con-sideration. Let us represent the two datasets by X , Y with dimen-sion M  X  N 1 and M  X  N 2 respectively and write the decomposition and partition of the matrices in the following manner as : where W is a M  X  K matrix whose columns span the common subspace; U and V represent the remaining subspaces having di-mension of M  X  ( R 1  X  K ) and M  X  ( R 2  X  K ) respectively. the number of shared basis vectors and R 1 and R 2 are the dimen-sionality of low-rank underlying subspaces for X and Y . R 2 can be interpreted as the number of topics similar to the basic NMF case. H and L are the encoding matrices and have the di-mension of R 1  X  N 1 and R 2  X  N 2 respectively and F [ W | U and G [ W | V ] . Note that though usually X and Y have dif-ferent vocabularies but they can be merged together to construct a common vocabulary that has M words.

We further impose a constraint of nonnegativity to achieve part-based representation. By nonnegativity, we mean that the elements of matrices W , U , V , H , and L are restricted to take only nonneg-ative values. To learn the required subspaces, we minimize the Frobenius norm of the joint decomposition error in the following manner: which can be translated into an minimizing problem with the fol-lowing objective function where . F is the Frobenius norm and  X  = X 2 F / Y 2 F is de-fined to be the relative ratio between Frobenius norms of the two data matrices.

Expressing D elementwise, this optimization can be efficiently solved in similar fashion to the original formulation of NMF [13], yielding the following multiplicative update equations for the appendix for the detailed proof): where ( S ) ab is given by
Similar multiplicative update equations are obtained for U , V , H and L : These multiplicative update equations 2 obtained in our joint sub-space learning case carry a similar intuition as in the NMF: if the perfect factorization is achieved, the multiplicative factors in the update equations reduce to unity. That is, it can be verified by in-spection that if the factorization for the two data sets X equations (1) and (2) are exact, then the multiplicatives on the RHS of the update equations from (3) to (7) are unity. A pseudo code for our proposed nonnegative joint subspace factorization is shown in Algorithm 1. The convergence of this algorithm can also be proved with details given in the Appendix B.
 Algorithm 1 Joint Shared Nonnegative Matrix Factorization (JS-NMF). 1: Input : Datasets X , Y , Parameters R 1 , R 2 , K and a threshold 2: let  X  = X 2 F / Y 2 F 3: initialize W 0 , U 0 , V 0 , H 0 , L 0 randomly 4: set r =1 5: while ( r&lt; MaxNumIters) or ( C&lt; ) do 6: update W r , U r , V r , H r , L r according to eqs (3) X  (7) 7: normalize each column of W r , U r and V r to 1. 8: let X r =[ W r | U r ] H r and Y r =[ W r | V r ] L r 9: compute error C = X  X  X r 2 F +  X  Y  X  Y r 2 F 10: r = r +1 11: end while 12: Output : return W , U , V , H , L
We note two special cases from our joint factorization frame-work. When there is no sharing (i.e., K =0 or W does not exist, and hence no common basis vectors between the two subspaces), the update equations for U , V , H and L reduce to individual NMF for X and Y described in [13]. Similarly, when we force a sin-gle shared subspace for the two datasets i.e., dim ( U )=0 and dim ( V )=0 , the update equations reduce the fully joint formu-lation (recently studied in [28]).

For complexity analysis, we compare the cost of the basic NMF algorithm in [13] and our proposed JSNMF. For an M  X  N 1 matrix and an M  X  N 2 matrix Y , assuming that K basis vectors are shared and the latent space dimensionality for decomposition of is R 1 and that of Y is R 2 , then computational complexity for the JS-NMF per iteration is O (max { MN 1 R 1 ,MN 2 R 2 } ) . The basic NMF algorithm in [13] applied for X and Y separately will have com-plexity of O ( MN 1 R 1 ) and O ( MN 2 R 2 ) respectively. This shows that JSNMF enjoys the same complexity as the basic NMF.
As far as the shared subspace dimensionality ( K ) is concerned, there does not seem to be any straight forward way to determine it exact value. However, empirical  X  X ule of thumb X  methods have been used to a good degree of success. In our case, the value of K is bounded between 0 and min ( R 1 ,R 2 ) i.e. ranges from no sharing to full sharing. Its optimal value depends on nature of the target and auxiliary data. Intuitively, K increases with the level of sharing between the two data sources. For an rough estimate on K , we find the number of the common features (tags in our case) between the two datasets, say M xy , then the rule of thumb is to use K = M xy / 2 as suggested by Mardia et al in [17]. An-other way to estimate K is based on rank-estimation and as follows. Supposedly if subspaces spanned by W , U and V are mutually-orthogonal then K = rank X T Y . In our case, however, W , U and V are only approximately mutually-orthogonal, suggesting
Note that in the implementation, a common practice is to add a small number  X  (we used  X  =10  X  9 ) in the denominator to avoid division by zero. that optimal K can be approximated by rank X T Y . Intuitively, projection of X on Y implies the sharing level and hence deter-mines K . However, this approach is computationally expensive.
In the light of JSNMF algorithm presented in previous section, the matrix X is taken as the tf-idf weighted [22] term-document matrix generated from the tags of target dataset and the matrix the equivalent matrix generated from the tags of auxiliary dataset. We learn the joint shared subspace W , the discriminant subspace U for target dataset, co-ordinate matrix H for target dataset, the discriminant subspace V for auxiliary dataset and co-ordinate ma-trix L for auxiliary dataset. Given a query sentence S Q , a query vector q x is constructed by expanding the query so that it includes all the unigrams (from vocabulary) which contain the words from the specified query sentence S Q . The vector q x is projected on the column space of matrix [ W | U ] to find out the query encod-ing vector (let us denote by q h ). We compute the cosine similarity between q h and the columns of matrix H to find out the similarly tagged images (or videos), and the results are ranked based on these similarity scores.

More formally, let the image (or video) dataset on which retrieval is to be performed, be represented as I = { I 1 ,I 2 , ......., I the collection of associated tags as T . We prepare term document matrix X =[ x 1 , x 2 , ........, x N 1 ] where x k ( k =1 , ...N weighted term-document vector prepared using the tags of image (or video) I k . We decompose matrix X to generate the matrices W , U and H using the joint shared NMF technique described in section 3. Algorithm 2 provides pseudo-code for the social im-age/video retrieval using the proposed shared subspace learning framework where  X  and denote element-wise matrix multipli-cation and division respectively.
 Algorithm 2 Image/Video Retrieval using JSNMF. 1: Input :Given W , U , H (learnt using Algorithm 1), query sen-2: prepare q x using tf-idf method from S Q 3: set  X  =10  X  9 , =10  X  2 , F [ W | U ] and project q x onto 4: while F q h  X  q x 2  X  do 6: end while 7: compute cosine similarities sim ( q h ,h i ) between query sen-8: sort the cosine similarities sim ( q h ,h i ) in descending order and 9: Output : return the top N retrieved images (or videos) as
Our experiment is setup to utilize tags from LabelMe (auxiliary) to improve two social web retrieval tasks (target) in two media do-mains : image (Flickr) and video (YouTube). We denote by X target dataset from which retrieval is to be performed and by the auxiliary data source (LabelMe dataset). Using the algorithm described in section 3, we learn a jointly shared subspace the two datasets and the discriminant subspaces U and V using the proposed JSNMF.

For comparison, we consider two baseline performances cor-responding to two existing methods. In the first case, Flickr (or YouTube) data is used alone to learn NMF latent subspace U ing the NMF algorithm [13]. In the second baseline, we consider a recent method proposed for social semantic analysis temporal pat-terns discovery in social media streams, which can also be utilized for image retrieval problem [16]. This method forces whole la-tent subspace to be shared between the two dataset, i.e., V vanishes. We shall call these two baselines BaselineI and BaselineII respectively. We note that in these two cases, it is likely that data faithfullness in each individual domain is not pre-served. This is where the attractiveness of our framework lies: it provides a freedom to exploit as much sharing information as pos-sible, but at the same time, respect the individual differences in each domain. Our experiment is centrally designed to evaluate this point in retrieval tasks. In the end, we also compare our best results with contemporary state-of-the-art techniques [15, 25] on image retrieval using Flickr dataset and present the comparison in Table 2.

We evaluate the proposed JSNMF framework against the two baseline methods outlined above in regard the two aspects (1) the effect of different level of sharing on the retrieval performance (2) and improvement in performance when auxiliary source of infor-mation is used with JSNMF compared to the use of tags from the same data source.
Since there is no standard groundtruth data available to eval-uate the proposed tasks, we construct a subset of images/videos crawled from Flickr, YouTube and LabelMe and manually evaluate the retrieval results. To obtain the data, we designed a set of con-cepts varying from indoor (e.g.,  X  X hair X ,  X  X omputer X ,  X  X up X ,  X  X oor X ,  X  X esk X ,  X  X icrowave X ) to outdoor (e.g.,  X  X each X ,  X  X oat X ,  X  X uilding X ,  X  X lane X ,  X  X hip X ,  X  X ky X ,  X  X ree X ) and generic ( X  X ook X ,  X  X ar X ,  X  X en X ,  X  X er-son X ,  X  X hone X ,  X  X icture X ,  X  X indow X ).
 Flickr Dataset. We downloaded 50000 images from Flickr web-site using its APIs [2]. On average, the number of distinct tags are 8. We removed the rare tags (appearing less than 5 times in the entire corpus), images with no tags and the images having non-English tags. After the cleaning process, we obtained around 20,000 labeled images. From this data, 7000 examples are kept aside to be used as an auxiliary dataset (needed to investigate the use of auxil-iary data from within domain).
 YouTube Dataset. We downloaded 18000 videos X  metadata (in-cluding tags, URL, category, title, comments etc) using YouTube API service [1]. On average, YouTube folksonomy has 7 distinct tags per video. As above, we remove the rare tags (appearing less than 2 times in the entire corpus), videos with no tags and non-English tags. After the cleaning process, we obtain around a dataset corresponding to 12000 videos. Again, we keep aside 7000 exam-ples to be used as an auxiliary dataset (needed to investigate the use of auxiliary data from within domain).
 LabelMe Dataset. Further we add around 7000 images with its tags from LabelMe. On average, there are 32 distinct tags per image. We removed the rare tags appearing less than 2 times in the entire data corpus. This process does not reduce the size of dataset.
For the purpose of evaluation, we defined a query set Q = { X  X loud X ,  X  X amp X ,  X  X ed X ,  X  X able X ,  X  X us X ,  X  X ole X ,  X  X aptop X ,  X  X late X ,  X  X itchen X ,  X  X iver X ,  X  X ool X ,  X  X lower X  X . Again, since there is no benchmark dataset available for evaluation, we construct the ground truth by manu-ally going through each example in the two datasets (Flickr and YouTube) and annotating them with respect to this query set. We consider a query term and an image (or video) relevant if the con-cept is clearly visible in the image (or video).

To evaluate the overall retrieval performance, we use popular 11-point Average Precision-Recall Curve. For the web retrieval task, typically web users would like every item (images or videos) to be highly relevant with respect to the query in the first few retrieved results. Therefore, we also present the well-known precision-scope (P@N) curve 3 to clearly demonstrate the ranking of the relevant images (or videos) in the retrieved set. This measure is not calcu-lated for the entire retrieved set. By looking at the retrieval result at various scope level, it is easier to appreciate the ranking perfor-mance of the method.
To compare the retrieval performance at different levels of shar-ing K , we consider the popular precision-at-fixed-recall metric in information retrieval. We fix the recall at 0.1, which is adequate since most of the time users are interested in only first few results. For the subspace learning, we set R 1 =60 and R 2 =40 respec-tively, interpreted as the latent dimensionalities in the data. Figure 1 presents the precision figures for the query set Q defined in sub-section 5.2 in increasing values of the sharing dimension
As can be seen, the average precision follows an interesting bell-shape curve when K increases, suggesting that there is an optimal level of sharing to achieve the best level transfer from one data source to another. It also indicates that the two baselines with no or total sharing are highly non-optimal approaches. On an average across the query set Q , K =15 results in 58% precision and is the optimal level of sharing for our dataset. This contrasts with 50%( K =0 , BaselineI ) and 46%( K =40 , BaselineII ) and thus our method delivers around 10% improvement.

One might explain these results as follows: when K is much smaller than 15, the learnt subspace shares very few basis vectors with LabelMe dataset and therefore does not benefit fully by its ac-curately tagged nature -this is caused by an under-representation between two datasets. On the other hand, when K becomes much larger than 15, it forces many basis vectors in the learnt subspace to represent both the datasets which can be difficult and therefore, the approximation in JSNMF factorization becomes poor -and this is caused by an over-representation between two datasets. Neither extreme is desirable. The optimal sharing K =15 in our frame-work represents a case in which an appropriate level of representa-tion for the two datasets is achieved. To further highlight this effect, the retrieval performance in terms of average precision for different values of shared subspace dimensionality K is plotted in Figure 1
In this curve N represents the number of top retrieved images with which we compute the precision. For example P @20 is the retrieval precision when considering only the first 20 images re-trieved. Figure 1: Retrieval performance with respect to shared subspace dimensionality for Flickr and YouTube. where one can observe the bell-shape behaviors. We also note the correlation between the number of common basis vectors with the Jensen-Shannon divergence values given in Table 1.

To demonstrate the ranking capabilities of the JSNMF based re-trieval, we compute the precision at various scope levels. Figure 2a depicts the retrieval performance in terms of average precision (
P @ N ) with respect to scope values and MAP metrics and it is evident from the graph that JSNMF with K =15 achieves much better performance than both BaselineI and BaselineII . To examine the overall performance across all recall values, we present the standard 11-point average precision-recall curve for 15 . To compare the performance against the two baselines, we also present these curves for BaselineI and BaselineII aver-aged over all queries in Q . Figure 2b depicts these precision-recall curves. That shows that across all recall values, the JSNMF frame-work consistently demonstrates its benefits against the two baseline methods.
To demonstrate the flexibility of applying the framework, we conducted YouTube experiments in the same way as for the Flickr dataset. Again we fix the recall at 0.1 (due to users X  interest in only first few results) and generated results at various levels of sub-space sharing by varying K . This time the latent dimensionality for YouTube ( R 1 ) was set to be 30 and that of LabelMe ( set to be 40 as before. Figure 1 presents the precision figures for the query set Q by increasing the sharing dimensionality ( step of 4.

Similar to the Flickr case, the average precision follows a curve indicating an optimal level of sharing corresponding to K =8 Using this optimal level of sharing ( K =8 ) between YouTube and LabelMe, we achieve improvement in precision performance by around 10% compared to BaselineI and by around 12% com-pared to BaselineII . This clearly repeats the under-representation and over-representation observations made above for Flickr case .
To demonstrate the ranking capability along with overall perfor-mance, we, once again, present the Precision-Scope (P@N) and MAP results shown in Figure 3a. Note that the best performance in terms of both metrics has been achieved at the optimum sharing level ( K =8 ) and this result is consistently better than the two baselines.
 To evaluate the overall performance across all recall values, we present the standard 11-point average precision-recall curve for 8 found above to be optimal sharing level. To compare the perfor-mance against the two baselines, we also present these curves for BaselineI and BaselineII averaged over all queries in Q . Figure 3b depicts these precision-recall curves. Again this figure shows that across all recall values, JSNMF method consistently demon-strates its benefits against the two baseline methods.
 One might argue on the usefulness of auxiliary data; specifically, what if more data from within the internal system is used instead of the use of external data. Addressing this question, we investigate the benefits of LabelMe (external auxiliary source) vis- X -vis the tags from the same domain (internal auxiliary source), we denote YouTube dataset as X and another YouTube dataset as Y . Then JSNMF algorithm is used to learn both W and U . We repeat the experiment as conducted for YouTube and LabelMe sharing case and find that the optimal sharing in this turns out to be Figure 3c clearly shows that improvement due to LabelMe data is much better than that achieved by internal auxiliary data (the sec-ond YouTube dataset). We believe that this improvement is due to the controlled, more complete and objective nature of LabelMe tags which helps in discovering the right term co-occurrences. Similar result is shown in Figure 2c for Flickr dataset where we compare the retrieval performance of Flickr dataset by sharing with another Flickr dataset (optimum sharing achieved at K =18 ) and with La-belMe dataset (external). Again, the improvement due to LabelMe over noisy auxiliary Flickr data (the second Flickr dataset) is sig-nificant.

Finally, Table 2 presents the comparison of our results with the two contemporary works done [15, 25] on image annotation (for image retrieval) for Flickr dataset. This comparison is based on the precision figures presented by authors in [15]. Though the dataset used by the authors in [15, 25] is not identical but it is similar to us in the sense that both of these works use Flickr data and dataset size is of the same order. Instead of comparing the results at various parameter values, we compare the best results achieved by all three methods. In our work, we got the best results on Flickr dataset by sharing the subspace with LabelMe dataset at K =15 which is significantly better than the results presented by the authors in [15] for 200 textual neighbors and 200 visual neighbors.
Our proposed joint subspace learning framework requires the specification of the sizes of the latent dimensionalities from the two datasets in the same way a standard NMF [13] re-quires the latent dimensionality for its subspace. This suggests that further regularization techniques such as analysis on sparsity as in [10] can be analyzed for our JSNMF. The additional require-ment of K will inevitably incur some extra modeling in the reg-ularization process, but still appears possible to be carried out in the same way as in [10]. Another limitation in the current set-ting of the JSNMF in this paper is that we limit our analysis to only two datasets. Extension to multiple datasets is also possible. Two apparent approaches are either to impose a common shared subspace W among all datasets, or perform a pairwise shared sub-space learning W i,j for each pair of the datasets. Both of these suggestions are feasible within the framework provided in this pa-(b) per. Alternatively, one might consider a more advanced statistical modeling and regularization among the subspaces of several vari-ables [12], or probabilistic graphical modelling [26].
 Recall Values Table 2: Comparison of our results with contemporary state-of-the arts on Flickr dataset.
We have presented a novel nonnegative shared subspace learning framework and applied it to improve tag-based image and video re-trieval in online social image tagging systems (Flickr) and video sharing system (YouTube) respectively by leveraging an auxiliary source of information (LabelMe). Apart from possessing the same features as a typical NMF approach to text analysis, such as the ability to capture tag co-occurrences and part-based decomposi-tion, a key feature of our proposed JSNMF is the ability to discover the shared structures between the two datasets and the flexibility in controlling the optimal level of sharing between them. This fea-ture is important in dealing with real-world datasets since the prac-tice of forcing the subspaces to be identical or totally different as done in current existing works is highly unrealistic. Our experi-mental results have consistently validated this point, showing that an appropriate level of subspace sharing can significantly boost the retrieval performance -an average of over 10% for retrieval preci-sion on the Flickr dataset and an average of over 11% for retrieval precision on the YouTube dataset using LabelMe as the auxiliary source. Although applied to image and video retrieval in this pa-per, our shared subspace learning framework is generic and can be applied to a wider setting in machine learning and data mining tasks. [1] http://code.google.com/apis/youtube/overview.html.
 [2] http://www.flickr.com/services/api/. Accessed in July, 2009. [3] H.D. Abdulla, M. Polovincak, and V. Snasel. Search results [4] M.W. Berry and M. Browne. Email surveillance using [5] R. Caruana. Multitask learning. Machine Learning , [6] A.P. Dempster, N.M. Laird, D.B. Rubin, et al. Maximum [7] L. Fei-Fei, R. Fergus, and P. Perona. One-shot learning of [8] S.A. Golder and B.A. Huberman. Usage patterns of [9] D.R. Hardoon, S. Szedmak, and J. Shawe-Taylor. Canonical [10] P.O. Hoyer. Non-negative matrix factorization with [11] M.S. Kankanhalli and Y. Rui. Application potential of [12] J.R. Kettenring. Canonical analysis of several sets of [13] D.D. Lee and H.S. Seung. Algorithms for non-negative [14] X. Li, C. G. M. Snoek, and M. Worring. Learning social tag (b) [15] X. Li, C.G.M. Snoek, and M. Worring. Annotating images [16] Y.R. Lin, H. Sundaram, M. De Choudhury, and A. Kelliher. [17] K. V. Mardia, J. M. Bibby, and J. T. Kent. Multivariate [18] C. Marlow, M. Naaman, D. Boyd, and M. Davis. Ht06, [19] S.J. Pan and Q. Yang. A survey on transfer learning. [20] R. Raina, A. Battle, H. Lee, B. Packer, and A.Y. Ng. [21] B.C. Russell, A. Torralba, K.P. Murphy, and W.T. Freeman. [22] G. Salton and C. Buckley. Term-weighting approaches in [23] F. Shahnaz, M.W. Berry, V.P. Pauca, and R.J. Plemmons. [24] B. Sigurbj X rnsson and R. Van Zwol. Flickr tag [25] C. Wang, F. Jing, L. Zhang, and H.J. Zhang. Scalable [26] X. Wang, C. Pal, and A. McCallum. Generalized component [27] L. Wu, L. Yang, N. Yu, and X.S. Hua. Learning to tag. [28] Z. Wu, C.W. Cheng, and C. Li. Social and semantics analysis We provide derivations for the optimization problem posed in sec-tion 3 which leads to a set of multiplicative updates equations (3) X  (7) used in Algorithm 1. Then, we provide a proof of convergence.
Recall the form of the objective function D to be minimized from section 3: where  X  = X 2 F / Y 2 F . We express D explicitly in terms of the elements of the involved matrices to get: To minimize D , we take the derivative with respect to W mi V mi , H in and L in . For example, the derivative with respect to W mi is given by: In general we can observe a decomposition of the gradient into the shared components (those first terms in the bracket), discrimi-nant components (second terms) and the residuals (last two terms). To minimize the cost function, we follow the optimization proce-dure similar to Lee and Seung [13] and derive multiplicative update equations using Gradient-Descent method: Substituted with the above derivative, we obtain the general update rule: To achieve a similar effect of multiplicative updating as in [13], we choose the step-size  X  W mi as Substituting into the previous expression the update equation for W mi then can be obtained as: where S mi is given by (compact form is given in section 3 after Eq. (3)) Similarly, derivatives of D with respect to U mi , H in ( L in can be written by symmetry) are:
Similar to the case of W mi , we choose appropriate step-size in each case for U mi , V mi , H in and L in to obtain the update equations in (4) X (7). In particular, the following step-sizes for U mi , H in are chosen (step sizes for V mi and L in can be written by symmetry): B. PROOF OF CONVERGENCE
The proof of convergence makes use of an auxiliary upper bound function similar to the auxiliary lower bound used in the EM-algorithm [6] and extends the proof of convergence of basic NMF given in [13] to Joint Shared NMF (JSNMF) case.

Using the auxiliary function defined in [13], G ( w, w ) is defined as an upper bound function for D ( w ) if G ( w, w ) D ( w equality is satisfied iff w = w . Note that minimizing the up-per bound function G at every update of w leads to non-increasing function D on every update. Hence if w t +1 = argmin then Also note that when D w t +1 = D w t , it implies that w t a local minimum of G w, w t and if derivatives of D exist and are continuous in a small neighborhood w t  X   X w &lt; 0 , this also implies that  X  w D w t =0 . Denote 1 a,b to be the identity function, i.e., return 1 if a = b and 0 otherwise, we shall prove the following lemma extended from [13] to our JSNMF case: Lemma. If K ( w i ) is the diagonal matrix with its ( a, b ) given by then is an auxiliary function for D ( w i )= 1 where x i , w i , u i and v i are the row vectors of matrices
P ROOF . T he first and second derivative of F ( w i ) are given by Comparing D ( w i ) with G w i ,w t i , we see that all we need to prove is the following To prove the positive semi-definiteness, consider the matrix with elements which is just a rescaling of the elements of matrix K ( w )  X  H  X  L w L T w . Then K ( w )  X  H w H T w  X   X  L w L T w is positive semi-definite if and only if M is. Equivalently we need to prove  X  T M X   X  0 ,  X   X  This is indeed the case. By explicitly expressing  X  T M X  , we can show that it is a sum of nonnegative terms. To avoid lengthy deriva-tion, we only state the main results here:  X 
M X  =
Back to our main proof of convergence, the gradient of the aux-iliary function G is given by To obtain the local minimum of G w i ,w t i , we equate  X  to zero and get the following update equation : Comparing the above update equation to the Gradient-Descent up-date equation, we get the following step-size,  X  w t
For brevity, hereafter we shall drop the update iteration super-script t, t +1 and use  X  notation to denote the update, i.e., After substituting for  X  w i D ( w i ) , we get the following update for w ( w Now, the above expression can be written in terms of matrix nota-tion as the following : Similar to the case of w i , if we choose Then we can prove that G u i ,u t i is an auxiliary function for D ( u i ) . The first and second derivatives are given by Comparing D ( u i ) with G u i ,u t i , we see that all we need to prove is the following The proof for this case is exactly similar to that of the case of Doing that, we get the gradient-descent step size as follows and the updates for U (update expression for V can be written by symmetry) as below The update expression for V can be written by symmetry between U and V and those for H and L are similar to basic NMF updates.
