 1. Introduction
Business process simulation is a powerful tool for process analysis and improvement. One of the main challenges is to create simulation models that accurately reflect the real-world process of interest. Moreover, we do not want to use simu-lation just for answering strategic questions but also for tactical and even operational decision making. To achieve this, dif-ferent sources of simulation-relevant information need to be leveraged. In this paper, we present a new way of creating a simulation model for a business process supported by a workflow management system, in which we integrate design, his-toric, and state information.

Fig. 1 illustrates our approach. We consider the setting of a workflow system that supports some real-world process based on a workflow and organizational model . Note that the workflow and organizational models have been designed before enact-ment and are used for the configuration of the workflow system. During the enactment of the process, the performed activ-an event may be  X  X ary completes the approval activity for insurance claim XY160598 at 16.05 on Monday 21-1-2008 X .
The right-hand side of Fig. 1 is concerned with enactment using a workflow system while the left-hand side focuses on analysis using simulation. In order to link enactment and simulation we use three types of information readily available in workflow systems to create and initialize the simulation model.

Design information. The workflow system has been configured based on an explicit process model describing control and data flows. Moreover, the workflow system uses organizational data, e.g., information about users, roles, groups, etc.
Historic information. The workflow system records all events that take place in  X  X vent logs X  from which the complete his-tory of the process can be reconstructed. By analyzing historic data, probability distributions for workflow events and their timing can be extracted.

State information. At any point in time, the workflow process is in a particular state. The current state of each process instance is known and can be used to initialize the simulation model. Note that this current state information includes the control-flow state (i.e.,  X  X okens X  in the process model), case data, and resource data (e.g., resource availability).
By merging the above information into a simulation model, it is possible to construct an accurate model based on observed behavior rather than a manually-constructed model which approximates the workflow X  X  anticipated behavior. Moreover, the state information supports a  X  X ast-forward X  capability, in which simulation can be used to explore different scenarios with respect to their effect in the near-future . In this way, simulation can be used for operational decision making .
Based on this approach, the system design in Fig. 1 allows different simulation experiments to be conducted. For the  X  X s-is X  situation, the simulated and real-world processes should overlap as much as possible, i.e., the two process  X  X louds X  in Fig. 1 need to coincide. For the  X  X o-be X  situation, the observed differences between the simulated and real-world processes can be explored and quantified. In our implementation we ensure that the simulation logs have the same format as the event logs recorded by the workflow system. In this way we can use the same tools to analyze both simulated and real-world processes.
To do this, we need state-of-the art process mining techniques to analyze the simulation and event logs and to generate the simulation model. To demonstrate the applicability of our approach, we have implemented the system shown in Fig. 1 using ProM [1] and YAWL [2]. YAWL is a workflow management system that, as reported in this paper, has been extended to provide high-quality design, historic, and state information. The process mining framework ProM has been extended to merge the three types of information into a single simulation model. Moreover, ProM is also used to analyze and compare the logs in various ways.

In [3] three common pitfalls in current simulation approaches were presented. (1) modeling from scratch rather than using existing artifacts , which leads to mistakes and unnecessary work, (2) focus on design rather than operational decision making , which is helpful for the initial design of a business process but (3) insufficient modeling of resources , i.e., the behavior or resources is typically modeled in a rather na X ve manner.
This paper addresses the first two pitfalls. While addressing the third problem is a challenging research topic in itself [3], we concentrate here on the first two problems. That is, we integrate existing artifacts that can be extracted from a workflow system into a ready-to-use simulation model, and we incorporate the current state of the workflow system in our simulation model to enable short-term simulation.

This paper extends our previous work [20], in that we go into more detail about the architecture of the realized system, describe the generated simulation models and how they can load a specified initial state more closely, and present a new XML file format for workflow states that enables other workflow systems to interface with our tools in a standardized way.
The paper is organized as follows. Related work is reviewed in Section 2. Section 3 describes the approach proposed. Sec-tion 4 presents a running example, which is then used in Section 5 to explain the implementation realized using YAWL and
ProM. Section 6 describes our approach to incorporate state information in more detail and presents the new XML file format for workflow states. Section 7 concludes the paper by discussing the three main innovations presented in this paper. 2. Related work
Our work combines aspects of workflow management, simulation, and process mining. Some of the most relevant con-tributions from these broad areas are reviewed below.

Prominent literature on workflow management [7,14,22] focuses on enactment, and research on workflow analysis usu-ally focuses on verification, rather than simulation. Conversely, publications on simulation typically concentrate on statisti-cal aspects [12,17,13] or on a specific simulation language [11]. Several authors have used simulation or queuing techniques to address business process redesign questions [5,6,15] , and most mature workflow management systems provide a simu-lation component [8,9]. However, none of these systems uses historic and state information to learn from the past and to enable operational decision making. We are not aware of any toolset that is able to extract the current state from an oper-ational workflow management system and use this as the starting point for transient analysis.

In earlier work we first introduced the notion of using historic and state information to construct and calibrate simulation models [16,23] , and used Protos, ExSpect, and COSA to realize the concept of short-term simulation [16]. However, this re-search did not produce a practical publicly available implementation and did not use process mining techniques. user to reflect on the process. Previously we showed that process mining can be used to generate simulation models [19,18] , but design and state information were not used in that work. 3. Approach
A crucial element of the approach in Fig. 1 is that the design , historic and state information provided by the workflow sys-tem are used as the basis for simulation. Table 1 describes this information in more detail.
 design time. This information is used to create the structure of the simulation model. The historic and state information are dynamic, i.e., each event adds to the history of the process and changes the current state. Historic information is aggregated and is used to set parameters in the model. For instance, the arrival rate and processing times are derived by aggregating ulation parameters are not very sensitive to individual changes. For example, the average processing time typically changes only gradually over a long period. The current state, however, is highly sensitive to change. Individual events directly influ-can be treated as static, while historic information evolves gradually, and state information is highly dynamic.
To realize the approach illustrated in Fig. 1 we need to merge design, historic and state information into a single simu-lation model. The design information is used to construct the structure of the simulation model. The historic information is
Following this, traditional simulation techniques can be used. For example, using a random value generator and replication, an arbitrary number of independent simulation experiments can be conducted. Then statistical methods can be employed to estimate different performance indicators and compute confidence intervals for these estimates.

By modifying the simulation model, various  X  X hat-if X  scenarios can be investigated. For example, one can add or remove resources, skip activities, etc. and see what the effect is. Because the simulation experiments for these scenarios start from the current state of the actual system, they provide a kind of  X  X ast-forward button X  showing what will happen in the near-future, to support operational decision making. For instance, based on the predicted system behavior, a manager may decide to hire more personnel or stop accepting new cases.

Importantly, the simulations yield simulation logs in the same format as the event logs. This allows process mining tech-niques to be used to view the real-world processes and the simulated processes in a unified way . Moreover, both can be com-pared to highlight deviations, etc.
 4. Running example
To illustrate the approach let us consider a credit card application process. The corresponding YAWL workflow model is shown in Fig. 2 . The process starts when an applicant submits an application. Upon receiving an application, a credit clerk checks whether it is complete. If not, the clerk requests additional information and waits until this information is received before proceeding. For a complete application, the clerk performs further checks to validate the applicant X  X  income and credit history. Different checks are performed depending on whether the requested loan is large (e.g., greater than $500) or small.
The validated application is then passed on to a manager to decide whether to accept or reject the application. In the case of acceptance, the applicant is notified of the decision and a credit card is produced and delivered to the applicant. For a re-jected application, the applicant is notified of the decision and the process ends.

Here we assume that this example workflow has been running for a while. In YAWL but also any other workflow system the following runtime statistics can be gathered about the long-term behavior of this process.
 Case arrival rate: 100 applications per week.
 Throughput time: 4 working days on average.

With respect to resources, there are eight members of staff available, which include three capable of acting as  X  X anagers X  and seven capable of acting as  X  X lerks X . (One person can have more than one role.)
Further assume that due to a successful Christmas promotion advertised in November, the number of credit card appli-cations per week has temporarily doubled to 200. The promotion period is now over and we expect the rate to decrease to 100 applications per week again. However, as a result of the increased interest, the system now has a backlog of 150 appli-cations in various stages of processing, some of which have been in the system for more than a week. Since it is essential that most applications are processed before the holiday season, which begins in a fortnight from now (the  X  X ime horizon X  of inter-est), management would like to perform simulation experiments from the current state ( X  X ast-forward X ) to determine whether or not the backlog can be cleared in time. 5. Realization through YAWL and ProM
We now use the example introduced in Section 4 to describe our proof-of-concept implementation supporting the ap-proach depicted in Fig. 1 . The realization is based on the YAWL workflow environment [2] and the process mining framework ProM [1]. For the actual simulation we use CPN Tools [10].

In this section, we first provide an overview about how YAWL, ProM and CPN Tools have been integrated to realize our approach (Section 5.1). Then we focus on the new capabilities that have been added to these systems, and briefly explain the main steps that need to be performed to extract simulation-relevant information from YAWL (Section 5.2), create a simula-lyze the simulation runs (Section 5.5). The concrete structure of the simulation models and how they incorporate the current state are described in more detail in Section 6. 5.1. Architecture
Consider Fig. 3 , which provides an overview of the tools and data sources that are involved in the realization of our approach.

The YAWL system enacts the business process and provides design information (YAWL X  X  workflow specification and orga-nizational model), historic information (workflow log file in MXML format), and state information (workflow state in our newly defined WFState format). The design and historic information are used to create and configure the simulation model, which is output as a Coloured Petri net (CPN) file. The generated CPN file is accompanied by an SML file (a CPN input file), which represents the (empty) initial state. This initial state can be repeatedly replaced by the actual current workflow state without changing the simulation model. Finally, CPN tools generates various output files from a simulation run. Among these simulation logs are MXML files, which can be loaded in ProM and analyzed in the same way as the actual workflow logs.
A detailed step-by-step description of how to generate a simulation model including operational decision support is pro-vided in our technical report [21]. 1
Note that through the use of standardized interfaces  X  the OrgModel format for organizational models, MXML for event logs, and the newly defined WFState format presented in this paper  X  it is very easy to extend our toolset for other environ-ments (e.g., YAWL can be replaced by another workflow management system). To apply our approach to another type of workflow system, the same file formats can be used and only an import facility for the new type of workflow specification (plus potentially a conversion of the new type of process model into a Petri net) needs to be provided. 5.2. Extracting simulation-relevant information
As illustrated in Fig. 3 , the information contained in the YAWL workflow specification is supplemented with historical data obtained from the event logs and data from the organizational model database. This was achieved by implementing two new functions in the workflow engine to export historical data from the logs for a particular specification and to export the organizational model (i.e., information about roles and resources). Furthermore, the current workflow state can be ex-ported, which is not used to create the simulation model, but loaded afterwards to initialize the simulation model.
In the YAWL workflow system, event logs are created whenever an activity is enabled, started, completed or cancelled, together with the time when this event occurred and with the actor who was involved. Logs are also kept for data values that have been entered and used throughout the system. Therefore, we can retrieve historical data about process instances that have finished execution. In this work we assume that the simulation experiments are being carried out on  X  X s-is X  process from the workflow engine and exports audit trail entries in the M ining XML (MXML) log format. Some sample data for the distribution functions for the data values used in future simulation experiments.

Similarly, the YAWL workflow system gives access to the organizational model through a function which extracts all available role and resource data in an organization and exports this information in the OrgModel XML format that is used by ProM. Some sample data with the roles of clerk and manager is shown in Fig. 4 b. This information is used to identify avail-able roles and resources that are relevant for a given specification.

Finally, a function has been created to extract the current workflow state from YAWL in the WFState XML format, which we introduce and explain in more detail later in this paper. 5.3. Generating the simulation model
From (1) the extracted workflow specification, (2) the newly extracted organizational model, and (3) the event log file, we can now generate a simulation model that reflects the process as it is currently enacted. The direct use of design information avoids mistakes that are likely to be introduced when models are constructed manually, and the automated extraction of data from event logs allows the calibration of the model based on actually observed parameters.

To capture simulation-relevant information independently of a concrete workflow language (e.g., YAWL) we created a generic data structure in ProM that we call  X  X  X igh-level process X . With high-level information we refer to process information beyond the pure control-flow, i.e., additional information like data and time that can be either attached to the process as a whole, or to certain elements in the process. Fig. 5 shows the data structures that are produced by each step in the simulation while global process information is listed textually at the bottom of each high-level structure. Because this extra information is orthogonal to the actual control-flow, it is separated and different types of process models can be enriched with high-level information. Currently, Petri nets, YAWL and Protos models can be enriched with simulation-relevant information, and there are several plug-ins that either deal with, or produce, high-level structures that can be used to generate simulation models.
Fig. 5 illustrates how the different pieces of simulation-relevant information are integrated and transformed to create the simulation model. For example, while the YAWL 2.0 Import produces a YAWL-based high-level process including information about link conditions, data, and roles, the Log Analysis step produces a set of activities with associated time information but grating the YAWL-based high-level process with the information obtained from the OrgModel Import and the Log Analysis as illustrated by the Merge operation in Fig. 5 , the control-flow model is translated into a Petri net (the Convert operation in Fig. 5 ), which then yields a Petri net-based high-level process that can be used as input for the CPN Export .
In summary, four basic steps need to be performed within ProM to generate the simulation model for a running YAWL process (a sample screenshot of the implementation is shown in Fig. 6 ):
Step 1: The workflow, the organizational model and the event log are imported from the YAWL workflow system and
Step 2: Simulation-relevant information from the organizational model and log analysis are integrated into the YAWL
Step 3: The YAWL model is converted into a Petri net model (because our simulation tool is based on Coloured Petri Nets), Step 4: Finally, the integrated and converted model is exported as a CPN model.

We can then use the CPN Tools system [10] to simulate the generated model. However, to produce useful results we do not want to start from an empty initial state. Instead we load the current state of the actual YAWL system into the CPN Tools for simulation. 5.4. Loading the current state
To carry out simulation experiments for operational decision making purposes (the  X  X ast-forward X  approach), it is essential to include the current state of the workflow system. This allows us to make use of the data values for the current cases as well as the status of the work items for current cases within the simulation experiments. A new function has been created to extract current state information of a running workflow from the YAWL system and to export this information as a CPN Tools input file ( InitialState node in Fig. 3 ).
 The following information is obtained about the current state and is introduced as the initial state of a simulation run. All the running cases of a given workflow and their marking.
 All the data values associated with each case.
 Information about enabled work items.
 Information about executing work items and the resources used.
 The date and time at which the current state file is generated.

When the empty initial state file of the generated simulation model is replaced with the SML file as depicted in Fig. 3 , tokens are created in the CPN model that reflect the current system status (see Fig. 7 ). For example, we can see that there are three tokens in the Case data place, which each correspond to a credit card application being processed. We will go into more detail about the CPN representation and the SML input file in Section 6.

We now experiment with the various scenarios described in Section 4. Recall that due to the Christmas promotion 150 cases are in the system. We load the state file containing these 150 cases into the model and perform simulation experiments for the coming two weeks assuming no changes in terms of resource availability. We also add more resources to the model and observe how this influences the backlog and the throughput times for processing credit card applications within this time horizon. 5.5. Analyzing the simulation logs We simulate the process from the generated CPN model for four different scenarios.
 (2) After loading the current state file with the 150 applications that are currently in the system and no modifications to (3) After loading the current state file but adding four extra resources (two having the role  X  X anager X  and three having the (4) After loading the current state file and adding eight extra resources. Of these eight additional resources four have the
We can see the difference among these four scenarios in Fig. 8 , which depicts the development of the number of cases (i.e., applications) in the workflow system over the coming two weeks for an example simulation run per scenario. In the case of Scenario 1 the simulation starts with having 0 credit card applications in the system. This neither reflects the normal situation nor does it capture our current backlog of cases. Note that after a while (the  X  X  X arm-up period X ) this simulation stabilizes to normal behavior of the credit card application process (i.e., with ca. 100 applications arriving per week). The other three scenarios load a defined initial state, which contains the 150 applications that we assume to be currently in the system. Furthermore, one can observe that in the scenarios where we add extra resources to the process, the case load decreases more quickly to a normal level than without further intervention. However, the scenario  X  X o be B X  does not seem to perform much better than the scenario  X  X o be A X  although twice as many resources have been added. This way, we can assess the effect of possible measures to address the problem at hand, i.e., we can compare different  X  X hat-if X  scenarios in terms of their estimated real effects.

CPN Tools has powerful simulation capabilities, which we can leverage. For example, it is possible to automatically rep-acteristics. For instance, Fig. 9 depicts the 95% confidence intervals of the average case throughput times based on 50 replicated simulations for each of the four simulation scenarios. One can observe that the estimated throughput time for the  X  X mpty X  scenario is ca. 4 days, while the expected throughput time for the  X  X s-is X  scenario (i.e., actually expected based on the current backlog situation) is almost 6 days.

While CPN Tools already provides powerful logging facilities and even generates gnuplot scripts that can be used to plot certain properties of the simulated process, we also generate MXML event log fragments during simulation, similar to the one shown in Fig. 4 a for the workflow log. These fragments can then be combined using the CPN Tools filter of the ProM im-port framework, which facilitates the conversion of event logs from various systems into the MXML format that is read by ProM.

The ability to use the same toolset for analyzing the simulation logs and analyzing the actual workflow logs constitutes a big advantage because the simulation analysis results can be more easily related to the initial properties of the process. In the system at this point in time).

Fig. 10 shows a screenshot of ProM while analyzing the simulation logs generated by CPN Tools. Various plug-ins can be plug-in (bottom left), the Performance Analysis plug-in (bottom right), and the LTL Checker (top right) are shown. The former two provide a general overview about the cases and activities in the process, whereas the Performance Analysis plug-in finds used to verify specific properties of interest (e.g.,  X  X  X ow many cases could be processed until they are in the stage where a decision can be made in under 3 days? X ). 6. The current state
Having demonstrated the importance of incorporating an initial state into the simulation model, we now want to explain in more detail how the state of a workflow system can be specified and incorporated. In this section, we describe how a workflow state can be exported from the YAWL engine using a generic workflow state XML schema format and how this could be translated into a CPN input file for simulation purposes using the running example. 6.1. From workflow state-XML to SML file
Fig. 11 depicts the XML schema definition of the WFState schema. The key elements of interest for simulation purposes are as follows:
WorkFlowState : This is the root element of the schema and contains information about the workflow state, including among others, the time at which this snapshot is taken. In addition, it contains a set of sents the set of active YAWL specifications.

Process : Each process element may contain a set of data attributes and values as well as a set of running cases of a YAWL specification ( ProcessInstance elements).

ProcessInstance : Each process instance element may contain a set of data attributes and values as well as the identifier of a parent process instance in the case of hierarchical models. In addition, it contains the start time of a particular case ( Timestamp ) and a set of currently executing YAWL tasks and enabled YAWL conditions ( elements).

WFModelElementRecord : Each WFModelElementRecord element may contain a set of data attributes and values. In addition, it contains information regarding a task or a condition ( an enabled condition or the status executing for an executing task, the start time ( a currently running task ( Originator ).

An example WFState XML file is given in Fig. 12 for the running example. For the credit card application process, three currently running process instances (39, 40, and 41) with their respective values for the three data attributes ( X  X oanAmt X ,  X  X ompleteApp X , and  X  X ecideApp X ) are shown. You can see that for process instance 39, condition  X  X 2 X  is enabled, and the input condition is enabled for process instance 40. For process instance 41, it shows that the  X  X heck for completeness X  task is cur-rently being worked on by  X  X onesA X . All the timestamps are represented as instances of the dateTime datatype.
A ProM plug-in has been implemented to translate this information into a CPN Tools input file for the initial state. The state to the simulation model in Section 6.3. 6.2. CPN representation
Coloured Petri nets (CPNs) are a modeling formalism that combine Petri nets with a high-level programming language [10]. Petri nets can be used to model processes based on a bi-partite structure that consists of places, which may hold tokens, and transitions, which under certain rules may fire and move tokens in that structure to change the state of the process. In tinguished and used in computations). CPN Tools is a tool for Coloured Petri nets, where the values of tokens are typed, and can be tested and manipulated with a functional programming language, which is called Standard ML (SML). Furthermore, the CPNs are extended by the notion of hierarchy and time, and their behavior can be simulated. In the following, we provide a brief summary of the CPN representation for business processes our simulation approach is based on. We then describe in detail how we modified this CPN representation to dynamically load an initial state into the simulation model in Section 6.3.
Consider Fig. 14 , which illustrates the hierarchical structure of the generated CPN models. A model is distributed over several modules called pages , and next to the depicted decomposition relationships these pages may be linked by shared places (so-called fusion places). For example, in Fig. 7 one can see that the data attributes ( X  X oanAmt X ,  X  X ompleteApp X , and  X  X ecideApp X ) for each newly created case are stored in a separate token in the Case data place. The same Case data place ness X , where the outcome of the check activity is randomly determined and stored in the corresponding case data token.
Furthermore, the concept of time allows us to delay the progress of tokens in the process, which we used to model the time completeness X  takes on average 1800 s (i.e., 30 min) and the actual delay during simulation is randomly determined based on sources place, where available resources reside. Further details on our CPN representation can be found elsewhere [19]. 6.3. Incorporating the current state
Now we explain how the SML functions depicted in Fig. 13 for the running example are used by the parameterized sim-ulation model to dynamically load tokens for executing cases, busy resources, etc.
The functions that are defined in the SML file are included in the CPN model by the declaration shown in the following CPN declaration fragment. After this declaration clause, the SML functions defined in the external file can be used as if they were defined within the CPN itself and, thus, dynamically changed. ... colset slist = list STRING; use "creditApp.sml"; val busy:slist = getBusyResources(); fun freeResources i = not (mem busy i); colset FREE = subset ANYBODY by freeResources; ...

Fig. 7 shows the environment page of the CPN model where the simulation parameters are set up and the information rent cases.
 Similarly, the next case ID place makes use of the getNextCaseID() function to generate a token with  X 42 X  as the starting case ID. The function getBusyResources() is used to identify available resources by removing busy resources from all resources (which were previously obtained from the OrgModel file and are defined elsewhere by the ANYBODY data type) to create a subset of FREE resources (see also CPN declaration fragment above). This set of free resources is then used to populate the initial tokens for the Resources place before starting the simulation.

Fig. 15 shows the actual process status after loading the SML file. The figure depicts the subpage for task  X  X heck for com-the CPN model with an appropriate number of tokens that mark the progress of a case but that do not represent a currently ongoing action.

Finally, the functions getCurrentTimeStamp() and getTimeUnit() are used to translate the CPN model X  X  time into the actual process time. This is needed to create simulation logs with time stamps that can be related to the real process and the sim-ulated time horizon. 7. Discussion
In this paper we presented an innovative way to link workflow systems, simulation, and process mining. By combining these ingredients it becomes possible to analyze and improve business processes in a consistent way. The approach is fea-sible, as demonstrated by our implementation using YAWL and ProM. To conclude, we would like to discuss the three main challenges that have been addressed in this research. 7.1. Faithful simulation models
Although the principle of simulation is easy to grasp, it takes time and expertise to build a good simulation model. In prac-ulation models it is assumed that resources are completely dedicated to the simulated processes and are eager to start ior of resources accurately. Moreover, in manually-constructed models steps in the processes are often forgotten. Hence sim-ulation models are usually too optimistic and describe a behavior quite different from reality. To compensate for this, artificial delays are added to the model to calibrate it and as a result its predictive value and trustworthiness are limited.
In the context of workflow systems, this can be partly circumvented by using the workflow design (the process as it is en-the simulation model. However, the generated CPN models in this paper can be improved by a better modeling of resource behavior. Furthermore, this resource behavior needs to be approximated in some way. Here, the mining of historic data can help to automatically choose suitable simulation parameters. As a consequence, more advanced process mining algo-rithms that extract characteristic properties of resources are needed to create truly faithful simulation models. 7.2. Short-term simulation
Although most workflow management systems offer a simulation component, simulation is rarely used for operational decision making and process improvement. One of the reasons is the inability of traditional tools to capture the real process (see above). However, another, perhaps more important, reason is that existing simulation tools aim at strategic decision making. Existing simulation models start in an arbitrary initial state (without any cases in the pipeline) and then simulate the process for a long period to make statements about the steady-state behavior. However, this steady-state behavior does not exist (the environment of the process changes continuously) and is thus considered irrelevant by the manager. Moreover, valuable, i.e., of higher quality and easier to interpret and apply. The approach and toolset presented in this paper enable short-term simulation. A drawback is that in the current implementation three different systems are used. For example, the translation of insights from simulation via ProM and CPN Tools to concrete actions in the workflow system YAWL can be improved. Further research is needed to provide a seamless, but generic, integration. An interesting question regarding short-term simulation is how long this  X  X  X hort-term X  can actually be. In general, the time horizon of interest depends on the questions that people have. However, assuming that a business process owner has a short-term simulation tool at hand, one also needs to consider the delay of decisions, or the delay of the realization of decisions, which has an impact on the estimated values in the predicted interval. 7.3. Viewing real and simulated processes in a unified manner
Both simulation tools and management information systems (e.g., BI tools) present information about processes. It is remarkable that, although both are typically used to analyze the same process, the results are presented in completely different ways using completely different tools. This may be explained by the fact that for a simulated process different data is available than for the real-world process. However, the emergence of process mining techniques allows for a unification of both views . Process mining can be used to extract much more detailed and dynamic data from processes than traditional data warehousing and business intelligence tools. Moreover, it is easy to extend simulation tools with the ability to record event it is easier to both compare and to interpret  X  X hat-if X  scenarios. Finally  X  while a detailed evaluation of the generated sim-ulation models is beyond the scope of this paper  X  a unified view of real-life logs and simulation logs enables the validation of the simulation model by re-analyzing the simulation logs in a  X  X econd pass X  [18]. This way, we can ensure that the  X  X s-is X  situation is captured appropriately by the simulation model (by comparing process run times, availabilities, etc.) before starting to analyze  X  X hat-if X  scenarios.

It can be anticipated that further topics become relevant for operational decision support systems in the future. In par-ticular, for dynamic processes additional challenges might emerge. For example, by then additional runtime information (e.g. change logs, application context data) might exist, which, in turn, raises additional challenges with respect to the merging of different build-and runtime information in one simulation model.
 Acknowledgements This research was supported by the IOP program of the Dutch Ministry of Economic Affairs and by Australian Research Council Grant DP0773012. The authors would like to especially thank Michael Adams, Eric Verbeek, Ronny Mans, and also
Christian G X nther, Minseok Song, Lindsay Bradford, and Chun Ouyang plus the code review team for their valuable support in implementing the approach for YAWL and ProM. We also would like to thank Marlon Dumas for sharing his valuable in-sights during the many discussions we had about this topic.

References
