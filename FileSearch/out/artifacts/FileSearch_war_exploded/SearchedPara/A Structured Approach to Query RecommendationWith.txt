 Query recommendation has been recognized as an important mean to help users search and also improve the usability of search engines. Existing approaches mainly focus on helpin g users refine their search queries and the recommendations typically stick to users X  search intent, named search interests in this paper. However, users may also have some vague or delitescent interests which they are unaware of until they a re faced with one, named exploratory interests . These interests may be provoked within a search session when users read a web page from search results or even follow links on the page. By considering exploratory interests in query recom-mendation, we attract more user clicks on recommendations. This type of query recommendation has not been explicitly addressed in previous work. In this paper, we propose to recommend queries in a structured way for better satisfying both search and exploratory interests of users. Specificall y, we construct a query relation graph from query logs and social annotation data which capture two types of interests respectively. Based on the query relation graph, we em-ploy hitting time to rank possible recommendations, lever-age a modularity based approach to group top recommen-dations into clusters, and label each cluster with social ta gs. Empirical experimental results indicate that our structur ed approach to query recommendation with social annotation data can better satisfy users X  interests and significantly e n-hance users X  click behavior on recommendations.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Query formulation,Search Process Algorithms, Experimentation, Performance, Theory Query Recommendation, Structured Approach, Social An-notation Data, Search Interests, Exploratory Interests
Nowadays query recommendation has been widely used in search engines, and considered as an important mean to help search users in their information seeking activities. In ex ist-ing work, query recommendation mainly aims to provide al-ternative queries which typically stick to user X  X  search in tent, called search interests in this paper. For example, when a user issues a query  X  X phone X , the search engine would sug-gest him equivalent or highly related queries such as  X  X pple iphone X ,  X  X phone 3g X  and  X  X phone price X . In this way, query recommendation is mostly limited to help users to refine their queries and find what they need more quickly.
Search users may also have some vague or delitescent in-terests, named as exploratory interests , which users are un-aware of until they are faced with one [21, 13]. Exploratory interests may be provoked within a search session, especial ly when users read some web pages from the search results or even further follow links. For example, when a user searches for  X  X phone X  and notices another type of smartphones from search results,  X  X lackberry X  for example, he may become cu-rious about X  X lackberry X  X nd would like to know more about it. If we can provide recommendations from exploratory in-terests, e.g.,  X  X lackberry X  or  X  X exus one X  in this particul ar case, we can attract users to make more clicks on recom-mendations and thus spend more time on search engines. It will also increase the advertisement revenue for service providers. However, the importance of exploratory interes ts is less emphasized in previous work.

In this paper, therefore, we propose to recommend queries to satisfy both search and exploratory interests of users si -multaneously. First of all, we propose a structured represe n-tation for query recommendation, where recommendations are organized into clusters and each cluster is explicitly l a-beled with some keywords (e.g., tags). It provides a clear view of the recommendations and can not only help users quickly refine their queries but also invoke their explorato ry interests even before reading search results. Compared to the traditional query recommendations that are presented in a simple flat list, our approach has evident advantages. Grouping recommendations into clusters and further naming each cluster with keywords would greatly improve the read-ability of recommendations and help users digest them more easily, especially when query recommendations are diverse , e.g. containing both search and exploratory interests.
Data sources are another important fact in our recommen-dation problem. Previous work on query recommendation mostly focused on search logs, which merely capture the in-teractions between search users and search engines. Specif -ically, click-through data [3, 2, 25], search query session s [20, 8] and query frequency [23, 11] are commonly employed to conduct query recommendation. In this paper, we first introduce social annotation data into query recommenda-tion as an additional resource. Social annotation data is basically a collection of meta-data, or social tags , on URLs. Social tags are normally keywords created by millions of web users according to the content of the pages referred by the URLs. The nature of the  X  X isdom of crowds X  makes social annotation data as reliable summaries of web pages. We can leverage the social tags to infer what people might think when reading the pages and more precisely predict the exploratory interests of users.

To conduct recommendation, we first construct a query relation graph from query logs and social annotation data, which captures both the search and browsing behaviors and reflects users X  search and exploratory interests respectiv ely. Based on the query relation graph, we employ hitting time to rank possible recommendations, leverage a modularity based approach [4] to group top recommendations into clus-ters, and label each cluster with social tags. Empirical ex-perimental results indicate that our structured approach t o query recommendation with social annotation data can bet-ter satisfy users X  interests and significantly enhance user s X  click behavior on recommendations.

The rest of the paper is organized as follows. Section 2 in-troduces the structured approach to query recommendation considering both search and exploratory interests. Sectio n 3 describes the proposed query recommendation approach in details. Section 4 shows the experimental results. Related work is discussed in Section 5 and conclusions are made in the last section.
In this paper, we argue that search users conceive two types of different interests while using search engines:  X  X e arch interests X  and  X  X xploratory interests X . Search interests are explicit information needs when people do search, while ex-ploratory interests are just vague or delitescent interest s which can be provoked when people consume search results. To verify our statements, we made use of one-week search log data to study the shift of user interests during a search session. Specifically, we collected the next queries submit -ted after an initial query within a short time interval (i.e. , less than 10 minutes), and analyzed the causality between the initial query and the consequent queries. The results indicate that the formulation of the next queries is not only determined by the initial query but also significantly affect ed by the clicks on the search results.

Taking query X  X phone X  X s an example, we present the most frequent queries from real users issued after initial query  X  X phone X  in Table 1. On average, in the first line of Ta-ble 1, we can see that all the top queries submitted after  X  X phone X  closely stick to users X  search interests, since mo st next queries are just immediate refinements on the initial query. However, if users click a certain result URL (indi-cating users may read the webpage), the top next queries become different. For example, after clicking the wikipedia page of  X  X phone X , users would show much boarder interests in other types of smartphones ( X  X lackberry X ), iphone relat ed software ( X  X tunes X ), or even a new apple product ( X  X pad X ). These interests are already beyond the original search inte r-ests, and fit our definition of exploratory interests. More-over, we can also see that the top next queries will change when the clicked URL is different. It indicates that user interests, especially exploratory interests, will be affec ted visibly by what they have read.

We further conducted statistical tests to verify whether the existence of exploratory interests is common and signifi -cant. We would like to testify the following statement: give n an initial query, the overall next queries and the next queri es with clicks on a specific URL were generated from different underlying distributions as opposed to the same distribu-tion. In other words, we are going to test the hypothesis: H 1 : p qo 6 = p qu i against the null hypothesis: H 2 : p qo where p qo and p qu i denote the overall next queries distribu-tion and the next query distribution after clicking a specifi c URL u i given an initial query q respectively. These distribu-tions can be estimated using Maximum Likelihood method.
We employed the likelihood ratio test proposed in [9] to calculate a confidence value for rejecting the null hypothes is, and the significance level p was set to 0 . 01. Users X  random behaviors, e.g., clicking on irrelevant URLs or issuing arb i-trary queries, may lead to a false rejection of null hypothes is. To reduce these false positives, we also removed the URLs having less clicks and infrequent queries from the one-week search log data. The results indicate that, in 80 . 9% of cases, clicks indeed affect the formulation of the next queries, i.e ., rejecting the null hypothesis that users issue the same next queries no matter whether a result URL is clicked or not. Similarly, we also studied whether the clicks on different URLs will lead to different distributions on next queries. The results show that, in 43 . 1% of cases, users would issue different next queries if they clicked on different result URL s. These two tests prove that the existence of exploratory in-terests is common and significant, and users X  interests will be affected by what they have read during a search session.
Search interests and exploratory interests can be consid-ered as two different heading directions of query recommen-dation. If query recommendations emphasize search inter-ests, it would help searchers to easily refine their queries iphone 3g apple iphone iphone price iphone review unlock iphone iphone plans iphone jailbreak iphone apps iphone ringtones iphone verizon Figure 1: Examples of recommendations for the query  X  X phone X  (a) list-based recommendation with search interests, (b) list-based recommendation with search and exploratory interests, and (c) structured recommendation with search and exploratory inter-ests. and quickly find what they need in search. Thus it basically enhances the  X  X earch-click-leave X  behavior. While if the r ec-ommendations more focus on exploratory interests, it would attract more user clicks on recommendations and further in-crease the staying time of users on search engines. However, the importance of exploratory interests is less emphasized in previous work. Traditional evaluation approaches, e.g. th e similarity or relevance between recommendations and orig-inal queries [2, 24], can hardly be applied to measure the goodness of recommendations for exploratory interests. In -creasing the number of clicks on recommendations can also be considered as an essential goal of query recommendations , and more importantly, applicable to evaluating recommen-dations for both search and exploratory interests. We will discuss more details in Section 4.4.
In this paper, we propose to recommend queries in a struc-tured way for better satisfying both search and exploratory interests of users simultaneously.

Traditionally, query recommendations are presented in a simple flat list. For example, Fig. 1(a) shows a typical list of recommendations for query  X  X phone X  and the recommen-dations are mostly related to users X  search interests. One may also leverage the list-based approach to recommend queries with both search and exploratory interests as shown in Fig. 1(b). However, since recommendations are quite di-verse in this case, the readability of these recommendation s will not be very good and searchers may not be able to con-sume the recommendations easily. Moreover, without any additional information on what the recommendations are about, users also may not have a strong will to make a click on them because of their limited knowledge on the recom-mendations. For example, users may not be likely to click the recommendation  X  X exus one X  if they have never known it is also a smartphone like  X  X phone X .

An effective solution for these above problems is to provide a structured query recommendation as shown in Fig. 1(c), Figure 2: The Illustrated Query Formulation Model Within a Search Session. where recommendations are organized into clusters and each cluster is explicitly labeled with some keywords (e.g., tag s). In this way, it provides a clear view of the recommenda-tion results and can not only help users quickly refine their queries but also stimulate their exploratory interests eve n before reading search results.
The main idea of our structured approach to query recom-mendation considering both search and exploratory interes ts is as follows. We first construct a query relation graph from both query log and social annotation data, which captures the relationships between queries from the two types of in-terests. Based on the query relation graph, we take two steps to provide structured recommendation. Firstly, we apply a random walk on the graph and employ hitting time to rank possible recommendations with respect to the given query. We then leverage a modularity based approach to group top recommendations into clusters, and label each cluster with social tags. In this way, we can provide query recommen-dation in a structured way by ranking the obtained clusters according to their average hitting time.
We construct a query relation graph which can capture both search and exploratory interests for our recommenda-tion task. The query relation graph is a one-mode graph with the nodes representing all the unique queries and the edges capturing relationships between queries. To constru ct the query relation graph, we first introduce a query formula-tion model to help derive the relationships between queries .
We consider the process how users formulate queries se-quentially within a search session. Typically, the user beg ins with an initial query which represents his information need s and obtains some search results. After checking the search results, he may decide to refine the query to better repre-sent his information needs, and thus issues a next query. Alternatively, he may read web pages from search results or even follow the links to browse some other web pages before he comes up with a next query. Such a query formulation model can be illustrated as Fig. 2.

Most previous work on query recommendation focused on the formulation process shown in the blue dashed box in Fig. 2, which mainly describes how users formulate their next queries with search interests (i.e., query refinement p ro-cess). Such a process can be captured by a basic query formulation model proposed in [12]. Query logs, a resource which captures the interactions between searchers and sear ch engines, have often been leveraged for recommendation [12, 16, 25] based on the basic model.

However, the missing part of the basic model is the read-ing/browsing process shown as the red part in Fig. 2. In fact, this process mainly describes how users generate next queries with exploratory interests. In order to describe th e proposed query formulation model, we further introduce the social annotation data as an important resource for express -ing the exploratory interests in this model. Social anno-tation data is basically a collection of meta-data, or social tags , on URLs. Social tags are normally keywords created by millions of web users according to the content of the pages referred by the URLs. The nature of the  X  X isdom of crowds X  makes social annotation data as reliable summaries of web pages. We can leverage the social tags to infer what people might think when reading the pages and more pre-cisely predict the exploratory interests of users. Moreove r, social annotation data is publicly available large scale da ta set which can be easily accessed.
We construct a query relation graph according to the pro-posed query formulation model by leveraging both query logs and social annotation data. Such a graph models the relationships between queries considering both search and exploratory interests.

Typically, query logs can be represented by a Query-URL bipartite graph, as shown in the left side rectangle in blue dashed line in Fig. 3. Formally, the Query-URL graph can be denoted as G qu = ( V qu , E qu ), where V qu = V q  X  V notes the node set and E qu denotes the edge set. Here, V consisted of unique queries and URLs respectively. E qu rep-resents the edges between queries and URLs. The weight w qu ( i, j ) on each edge e ( i, j )  X  E qu is defined by the clicks between query q i and URL u j .

Similarly, a URL-Tag bipartite graph can be constructed from the social annotation data. An example URL-Tag graph is shown in the right side rectangle in red dashed line in Fig. 3. The URL-Tag graph can be denoted as G ut = ( V ut , E ut ), where V ut = V u  X  V t denotes the node set and E ut denotes the edge set. Here, V t = { t 1 , . . . , t represent the sets consisted of unique tags. E ut represents the edges between URLs and tags. The weight definition is similar as that in Query-URL graph.

We obtain a Query-URL-Tag tripartite graph by connect-ing query logs to social annotation data through URLs as shown in Fig. 3. The proposed query formulation model can then be approximated by a transition process among query, URL and tag nodes on the tripartite graph, as illus-trated by the green dot arrow lines in Fig. 3. As we can see, the forward transition from query to tags imitates the process of reading web pages related to a query and identi-fying some exploratory interests, while the backward trans i-tion from tags to queries imitates the process of thinking of next queries from these interests. Note that the traditiona l transition process over the Query-URL bipartite graph (i.e . Query  X  URL  X  Query  X  ) is in fact part of our transition process since each URL is always allowed to transit back to Figure 3: Example of a Query-URL-Tag Tripartite Graph. itself through tags. In other words, the basic model where users issue queries after checking search results can also b e captured by our transition process. Therefore, our transit ion process over the tripartite graph can well approximate the proposed query formulation model and capture both search and exploratory interests in a simple and unified way. Note that one may also design other transition processes over the tripartite graph to approximate the proposed query formu-lation model.

Based on the transition process on the tripartite graph, we can derive the relationships between queries and thus construct a query relation graph G q = ( V q , E q ). The query relation graph here is a weighted directed graph, with the edge weight from query node q i to q j defined by the transi-tion probability under the above process as follows Here the probabilities P V u | V q ( k | i ), P V t | V u are defined in the form It seems natural to prefer the most-clicked URL for the query, the most-annotated tag for the URL and the most-clicked query for URL, respectively. However, to use the same definition for the probability from tags to URLs (i.e., P u | V t ( m | l )) may not be very appropriate. A potential dis-advantage is that, for a given tag, it may prefer popularly annotated URLs (i.e., URLs annotated by a large number of people) since the absolute frequency of the tag on such URLs may be larger than other annotated URLs (i.e., P V u is larger for the popularly annotated URLs). However, a popularly annotated URL does not necessarily contain more information expressed by that tag as the tag may be just a tail tag for such URL (i.e., P V t | V u is low for that tag given the popularly annotated URL). To avoid this bias, we define the probability from tags to URLs as a uniform distribution Algorithm 1 Ranking Queries using Hitting Time where d l denotes the degree of the node l  X  V t . An intuitive explanation for this probability is that when using tag to explore web pages, a user will equally prefer all the web pages annotated by the tag.
Based on the query relation graph, we can apply a Markov random walk on the graph and employ hitting time as a measure to rank queries. In this way, we can identify top recommendations for the given query.

The hitting time h ( j | i ) of a random walk is the expected number of steps before node j is visited starting from node i . The hitting time from node i to node j has the property of decreasing when the number of paths from i to j increases and the lengths of the paths decrease [15]. Therefore, we can employ hitting time as a measure to rank queries with respect to the given query. Specifically, Let q s be the given query. We compute the hitting time h V q | V q ( j | s ) for all the other queries q j ( j 6 = s ) based on the random walk. We then use this measure to rank queries q j ( j 6 = s ), and find the top k queries that is closest to q s .

It can be easily verified that the hitting time satisfies the following linear system The meaning of the above recurrence formulae is quite ob-vious: in order to jump from node q i to node q j , one has to go to any adjacent node q k of q i and proceeds from there. Therefore, we can use the linear system to compute the hit-ting time iteratively. However, it would be extremely time consuming if we directly solve the linear system on the whole query graph. Since most nodes are irrelevant to the original query, we can use a width first search strategy to construct a subgraph to save the computational cost. Therefore, we propose an efficient algorithm for ranking recommendations using hitting time as shown in Alg. 1.

Note that hitting time has also been used for query rec-ommendation by Mei et al. [25]. For a given query q s , their approach employ hitting time from other queries q j s to q for ranking. In this way, they try to boost long tail queries to improve diversity in query recommendation. However, the problem with long tail queries is that they are usually unpopular queries which may not be familiar to users. Al-ternatively, we recommend queries considering both search and exploratory interests, and employ hitting time from the given query q s to other queries q j s for ranking. Therefore, we can recommend diverse as well as popular queries. Algorithm 2 Clustering Queries using Modularity
The top k recommendations obtained above may form sev-eral groups as shown in Fig. 1(c). Therefore, we further group these recommendations into clusters and label each cluster explicitly with social tags for better understandi ng. Since the recommendations are nodes on the query relation graph, it is natural to apply a graph clustering approach to group them.

Clusters on a graph are basically groups of nodes in which nodes have denser connections with each other than with nodes in other clusters. There are many algorithms for graph clustering [6, 27, 10]. Recently, [26] introduced the  X  X odu -larity function X  Q , which measures the quality of a particular clustering of nodes in a graph. It is defined as: where e ii is the fraction of edges within cluster i , and a the fraction of all ends of edges that are attached to nodes in cluster i . Hence, discovering the underlying clustering of a graph becomes a process to optimize the value of modular-ity over all possible clustering of the graph. The modular-ity based approaches represent the  X  X tate-of-the-art X  gra ph clustering methods and can be easily extended to handle weighted directed graphs, e.g. the query relation graph in our problem.

Although modularity provides a quantitative method to determine the goodness of a certain clustering of a graph, brute force search of the optimal value of modularity is not always possible due to the complexity of the graph and the large number of possible divisions. Several heuristics hav e been proposed for optimizing modularity [17, 26]. In this paper, we will employ the fast unfolding algorithm [4] to perform clustering, as it is most efficient and performs well on graph clustering. The algorithm conducts an agglomera-tive clustering process on the query relation subgraph con-sisted of the top k recommendations as shown in Alg. 2, in which one node is merged with another to obtain the max-imum gain of the modularity. The specific fast unfolding algorithm can be found in [4].

With the clusters in hand, we can label each cluster ex-plicitly with social tags for better understanding. As we can see in Section 3.1.2, the forward transition from query to tags approximates the query X  X  interests through search and annotation activity. Therefore, we can leverage the ex-pected tag distribution over the URLs clicked by query q i approximate q i  X  X  interests, which is in the form We can then approximate cluster c j  X  X  interests by the aver-age tag distribution over recommendations under it as fol-lows where N C ( j ) denotes the size of the j -th cluster. We choose the top ranked k  X  tags to label the cluster.
We conducted experiments to verify the effectiveness of our query recommendation approach. In this section, we first introduce the data sets and the baseline methods used in experiments. Then we present some empirical results to show the differences among these methods. Finally, we eval-uate the effectiveness of our approach by comparing users X  click behavior on recommendations with baseline methods.
In our experiments, we made use of two types of data sets, i.e. query logs and social annotation data. For query logs, we used  X  X pring 2006 Data Asset X  distributed by Mi-records that were sampled over one month in May, 2006. The queries were processed via the following normalization steps (i) trimming of each query, (ii) converting letters in to lower case, and (iii) space sequence reduction to one space character. Queries and corresponding click-through data containing adult content were filtered out. Finally, we ob-tained about 2 . 7 million unique queries and about 4 . 2 mil-lion unique URLs. For social annotation data, we collected 2008. The data set consists of over 167 million taggings, which include about 0 . 83 million unique users, 57 . 8 unique URLs and 5 . 9 million unique tags. We disregarded user in-formation, merged all the tags of the same URL together, and normalized each tag into lower case.

We constructed a Query-URL-Tag tripartite graph based on these two data sets by connecting queries and tags through URLs. Here we disregarded all the URLs that are not asso-ciated with either queries or tags. In this way, we obtained a tripartite graph with over 1 . 3 million nodes and 3 . 8 million edges. Table 2 gives some specific statistical numbers of the graph. Based on the tripartite graph, we finally obtained a query relation graph with 538 , 547 query nodes. For exper-iments, we randomly sampled 300 queries for testing, and evaluated the quality of top 15 recommendations for each test query with three groups of human judges.
We implemented a query recommendation system pro-posed by Mei et al. [25], which is based on the basic query formulation model and only leverages query logs (i.e., Quer y-URL bipartite graph) to construct a one-mode query rela-tion graph. They employed hitting time from other queries to the current query as the rank of recommendations. In later parts, we will refer their method as BiHit .
Another baseline method is a list-based approach to query recommendation considering both search and exploratory interests. That is, we constructed the query relation graph based on the new formulation model, employed our proposed hitting time algorithm to rank queries, and presented the to p k recommendations in a simple flat list. Since the query re-lation graph here is obtained based on the Query-URL-Tag tripartite graph, we will refer this method as TriList , and refer our structured approach as TriStructure .
We present the comparison of recommendations generated by our approach and baseline methods. Table 3 shows two samples from our test queries including their top 15 recom-mendations generated by three methods.

We can see from Table 3, the recommendations generated by BiHit method closely stick to users X  search interests. Fo r example, all the recommendations for  X  X spn X  X imit to equiva -lent expressions (e.g.,  X  X spn go X  and  X  X spn sports X ) and sub -concepts of  X  X spn X  (e.g.,  X  X spn mlb X  and  X  X spn radio X ). It can help users to clarify their search intent, i.e., what the y want to know about ESPN.

Both the TriList and TriStructure methods can bring in some recommendations with diverse topics which are related but not close to user X  X  search queries. For example for query  X 24 X , the recommendations include entertainment websites like  X  X v guide X  and tv series like  X  X rey X  X  anatomy X . Most of them would be interesting to the searchers. It confirms that we can actually infer some exploratory interests from social annotation data which are leveraged in both TriList and TriStructure methods.

From Table 3, we can also easily see that TriStructure method provides a clear view of the recommendation results and can not only help users refine their queries but also stimulate their potential exploratory interests. For exam -ple, when searching query  X 24 X , the user can easily refine their queries with the recommendations in the first clus-ter. Meanwhile, he can also learn about, for example  X  X rey X  X  anatomy X , is another hot tv series, and thus probably make a click on the recommendation. The TriList method mixes all the recommendations in a simple flat list which may not be easy for users to read.

However, we also noticed that the tag labels chosen for a cluster in TriStructure method may sometimes not be so appealing as they have duplicated semantics. For example,  X  X v X  and  X  X elevision X  both appeared as labels for a cluster for query  X 24 X ;  X  X ebmail X ,  X  X mail X  and  X  X ail X  co-occurred a s labels for a cluster for query  X  X ahoo mail X . This is due to that we directly leverage the expected tag distribution ove r the recommendations under a cluster to approximate the cluster X  X  interests, and choose the top ranked tags to label it. We can further apply some tag selection approaches to alleviate this problem.
In this experiment, we compare the performances of differ-ent recommendation methods by users X  click behavior. We created a label tool to simulate the real search scenario as shown in Figure 4. For each test query, the human judge is presented with the search results of the query from a com-mercial search engine, and the recommendations generated by one method. We ask the human judge to label for each recommendation how likely he would like to click it given the search result list . A 6-point scale (0, 0 . 2, 0 . 4, 0 . 6, 0 . 8, and 1) is defined to measure the click willingness, in which 0 means  X  X otally unwilling to click it X  while 1 indicates  X  X b -solutely would like to click it X . Note that this evaluation method is largely different from traditional evaluation for query recommendation where judges are required to label the similarity or relevance between recommendations and the original query [24, 8]. We believe our evaluation method can better approximate the real search scenario where users check recommendations after seeing the search results. Be-sides, increasing the number of clicks on recommendations can also be considered as an essential goal of query recom-mendations.

We asked 9 judges with or without computer science back-ground to label the recommendations. Specifically, the 300 queries were randomly divided into 3 sets with 100 each, named QuerySet1, QuerySet2, and QuerySet3. We also ran-domly grouped the 9 judges into 3 sets with 3 judges each, named JudgeGroup1, JudgeGroup2, JudgeGroup3. Our la-beling procedure was then conducted by 3 rounds as shown in Table 4, where each judge group labeled the recommen-dations from QuerySet1 to QuerySet3 successively. In this way, we can reduce the bias of judges as (1) each method X  X  recommendations on each query will be labeled by three judges; (2) each method will be labeled by all the judges (on different query sets); (3) each query will be labeled by all the judges (on different methods). Moreover, no judge will label the recommendations for a same query generated by different methods successively, thus we can reduce the bias arose by the labeling order of different methods. We made the evaluation at query level and used the Clicked Recommendation Number (CRN) , Clicked Recommendation Score (CRS) , and Total Recommendation Score (TRS) as evaluation measures. Given a query q , let R = { r 1 , . . . , r denote the k recommendations generated by a certain ap-proach (note k = 15 in our experiments), and L = { l 1 , . . . , l denote the corresponding label scores on these recommen-dations. Here we define a non-zero label score on a recom-mendation as a click on it. That is, if l i &gt; 0 then the i -th recommendation for query q receives a click with the will-ingness of l i . The three measures for a query q are then defined as follows where | X  X  denotes the size of a set. For each query q , we calculate the three measures for each human judge X  X  label results and average over them to obtain its evaluation re-sults. We then average over all the queries to obtain the final performance of each method.

Table 5 shows the final evaluation results of the three methods. The numbers in the parentheses are the relative improvements compared with BiHit method. From the re-sults in Table 5, we can see that TriList method can outper-form BiHit method in terms of all measures while TriStruc-ture method performs best. It shows that by recommending queries with both search and exploratory interests, we can improve both the click rate and click willingness on recom-mendations. Moreover, by using a structured approach, the improvements become even more significant. When com-pared with BiHit method, the relative improvements ob-tained by TriStructure method are about 46 . 5%, 19 . 7% and 63 . 6% in terms of average CRN, average CRS and average TRS, respectively. We conducted T-Tests on the results be-tween each pair of methods, which indicates that all these improvements are statistically significant (p-value &lt; 0 . 01). Table 5: Comparisons between Our Approach and Baselines on Click Performance by Query in terms of Average Clicked Recommendation Number (Ave.
 CRN), Average Clicked Recommendation Score (Ave. CRS), and Average Total Recommendation Score (Ave. TRS) Ave. CRN 5.594 6.458 (+15.4%) 8.186 (+46.3%) Ave. CRS 0.331 0.366 (+10.6%) 0.395 (+19.3%) Ave. TRS 0.129 0.158 (+22.5%) 0.211 (+63.6%)
Table 6 further shows the detailed distributions of label scores on recommendations under different methods. From the results, we can see that both TriList and TriStructure methods receive more labels at each specific non-zero score level than BiHit method. In other words, we can attract more user clicks on recommendations at different levels by considering exploratory interests. Among the results, al-though there are not many recommendations which users absolutely would like to click (i.e., score level  X 1 X ), the n um-ber of such recommendations under Tristructure method reaches about 3 times of that under BiHit method. More-over, we can see that TriStructure method obtains consis-tent improvements at all non-zero score levels over TriList method although they both contain the same recommen-dations for each query. It further demonstrates the effec-tiveness of structured approach for query recommendation addressing both search and exploratory interests.
The above experiments study the overall performance of the three methods and show the effectiveness of our ap-proach TriStructure for query recommendation. An inter-esting result is that the structured method TriStructure ca n significantly outperform the list-based method TriList eve n Table 6: Distributions of Labeled Score over Rec-ommendations under Different Methods (%). BiHit 62.70 17.88 11.26 6.42 1.67 0.07 TriList 56.95 18.28 13.48 8.73 2.45 0.11
TriStructure 45.43 20.41 18.04 12.09 3.82 0.21 though they recommend a same set of queries for each in-put query. Here we conducted more analysis over these two methods to study how the structure affects users X  click behavior on recommendations. That is, we want to figure out the changes of users X  click pattern and click willingnes s on each recommendation for a given query under these two methods. In this way, we can show the benefits of struc-tured approach for recommending queries with both search and exploratory interests.

We first analyzed how the structured approach affects users X  clicks. Note here we only focus on the clicks on the recommendations (i.e. non-zero labels) but not care about the specific label scores. We compared the click entropy of these two methods, which measures how users X  clicks dis-tribute over the clusters of recommendations. The click en-tropy on a single query is defined as follows where P C ( i ) = click C ( i ) / P j click C ( j ) and click number of clicks in the i -th cluster of the given query X  X  rec-ommendations. For TriStructure method, the calculation of click entropy is quite direct. For TriList method, since its recommendations for each query are exactly the same as that of TriStructure method, we can map the clicks on TriList X  X  recommendations into the corresponding cluster s of TriStructure method and thus obtain the click entropy on each query. We show the average click entropy over queries under the two methods in Fig. 5. Here we arrange the queries Ave. Click Entropy Figure 5: The Average Click Entropy over Queries under the TriList and TriStructure Methods. by a descent order according to their average click entropy under TriStructrure method for a clear look. As we can see from Fig. 5, the average click entropy under TriStructure method is higher than TriList method on most queries, and the improvement is statistically significant under T-Test ( p-value &lt; 0 . 01). A higher click entropy means that users X  clicks are more scattered among clusters. Therefore, it in-dicates that without clustering, users X  clicks may not only decrease but also concentrate on certain interests. While with the structured approach where recommendations are well organized by clusters, we will be able to encourage user s to click more recommendations in different clusters.
We further analyzed how the structured approach affects users X  click willingness. We compared the average label scores on the same recommendation for a query under the two methods. The correlation between the two scores over all the queries is shown in Fig. 6. The x-axis and y-axis de-note the average label scores of the same recommendation for a query under the TriList and TriStructure methods re-spectively, and the color represents the number of such rec-ommendations. Here we focus on the score range between 0 and 0 . 6, since 96 . 58% of recommendations X  average label scores are within this area. From Fig. 6 we can see that more points (around 75 . 2%) are close to the y-axis in the graph. It shows that for the same recommendation of a query, more of them will receive a higher label score under TriStructure method than under TriList method. That is, the willingness for users to click a same recommendation will be raised under TriStructure method. This indicates that with the structured approach, especially with the tags labeling each cluster explicitly, we can effectively stimul ate user X  exploratory interests even before reading any search result.
Query recommendation has been employed as a core util-ity by many industrial search engines. The general idea of query recommendation is similar to that of query expansion [29, 14], query substitution [20, 1] and query refinement [22 , 18], which all focus on transforming an initial query into a  X  X etter X  query to help users search. We deviate from these traditional approaches which mainly focus on users X  search interests by addressing both search and exploratory intere sts Figure 6: Correlation between the Average Label Scores on Same Recommendations for Queries under the TriList and TriStructure Methods. simultaneously with a structured approach to query recom-mendation.

While most early query recommendation methods explore document information, query log data has been widely used recently. Query click-through [3, 2, 25], search query ses-sions [20, 8] and query frequency [23, 11] are among the most used types of information in query logs. In this pa-per, we further introduce the social annotation data for rec -ommendation, a resource which mainly reflects exploratory interests on URLs with the  X  X isdom of crowds X .

Most of the work on query recommendation is focused on measures of query similarity. Some of these studies can be categorized as cluster-based approaches. For example, Beeferman et al. [3] applied a hierarchical agglomerative method to obtain similar queries in an iterative way. Baeza-Yates et al. [2] used the k-means algorithm to derive similar queries, but the specific number of clusters is often difficult for clustering search logs. Wen et al. [28] proposed a cluste r-ing method for query recommendation that combine query content and click-through information. In [8], Cao et al. co n-ducted context-aware query recommendation by clustering queries into concepts and mining the concept sequence pat-terns.

Recently, there are different query recommendation meth-ods proposed based on random walks on a query graph. Boldi et al. [5] proposed recommending queries based on short random walks on the query-flow graph. Both PageR-ank [7] and personalized PageRank [19] values are used in their approach. Mei et al. [25] described a random walk on the one-mode query graph and employed hitting time to recommend queries, which is closely related to our work. However, their approach only relies on query logs and com-putes the hitting time from recommendations to the original query.
In this paper, we propose to recommend queries in a struc-tured way for better satisfying both search and exploratory interests of users. We introduce the social annotation data as an important resource for such recommendation. Specif-ically, we construct a query relation graph from query logs and social annotation data, which captures the relation-ships between queries considering the two types of interest s. Based on the query relation graph, we employ hitting time to rank possible recommendations, leverage a modularity base d approach to group top recommendations into clusters, and label each cluster with tags. Empirical experimental resul ts indicate that our structured approach to query recommen-dation with social annotation data can better satisfy users interests and significantly enhance user X  X  click behavior o n recommendations.

When recommending queries in a structured way, we will face some alternative options. For example, we can show more clusters with less recommendations presented in each to bring more diversity in recommendation. Alternatively, we can show less clusters with more recommendations pre-sented in each to concentrate on the major search and ex-ploratory interests. There might be some trade-off between the two cases which is worth of further study.

Moreover, the social annotated data is still very sparse comparing with query logs. Many URLs clicked by long tail queries might not be annotated yet, and thus the recom-mendation for these queries is difficult with our approach as usual. One possible solution is to propagate the tags with the query logs or hyperlinks between URLs, so that we can enlarge the size of annotated data. This might be another interesting topic for our future work.
This research work was funded by National Natural Sci-ence Foundation of China under grant number 60933005 and Microsoft Research Asia Internet Service Theme Project 2009.
