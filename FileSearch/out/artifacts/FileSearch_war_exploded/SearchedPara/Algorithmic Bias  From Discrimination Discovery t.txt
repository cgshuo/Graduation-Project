 Algorithms and decision making based on Big Data have be-come pervasive in all aspects of our daily lives lives (offline and online), as they have become essential tools in personal finance, health care, hiring, housing, education, and poli-cies. It is therefore of societal and ethical importance to ask whether these algorithms can be discriminative on grounds such as gender, ethnicity, or health status. It turns out that the answer is positive: for instance, recent studies in the con-text of online advertising show that ads for high-income jobs are presented to men much more often than to women [5]; and ads for arrest records are significantly more likely to show up on searches for distinctively black names [16].
This algorithmic bias exists even when there is no discrim-ination intention in the developer of the algorithm. Some-times it may be inherent to the data sources used (soft-ware making decisions based on data can reflect, or even amplify, the results of historical discrimination), but even when the sensitive attributes have been suppressed from the input, a well trained machine learning algorithm may still discriminate on the basis of such sensitive attributes because of correlations existing in the data. These considerations call for the development of data mining systems which are discrimination-conscious by-design. This is a novel and chal-lenging research area for the data mining community.
The aim of this tutorial is to survey algorithmic bias, pre-senting its most common variants, with an emphasis on the algorithmic techniques and key ideas developed to derive ef-ficient solutions. The tutorial covers two main complemen-tary approaches: algorithms for discrimination discovery and discrimination prevention by means of fairness-aware data mining. We conclude by summarizing promising paths for future research.
 Algorithmic bias; Discrimination discovery; Discrimination prevention
At the beginning of 2014, as an answer to the growing concerns about the role played by data mining algorithms in decision-making, USA President Obama called for a review of big data collecting and analysing practices. The resulting report 1 concluded that  X  X ig data technologies can cause so-cietal harms beyond damages to privacy. X  In particular, it expressed concerns about the possibility that decisions in-formed by big data could have discriminatory effects, even in the absence of discriminatory intent, further imposing less favorable treatment to already disadvantaged groups.
In the data mining community, the effort to design discrimination-conscious methods has developed two groups of solutions: (1) techniques for discrimination discovery from databases [13] and (2) discrimination prevention by means of fairness-aware data mining , developing data min-ing systems which are discrimination-conscious by-design [8]. Discrimination discovery in databases consists in the actual discovery of discriminatory situations and practices hidden in a large amount of historical decision records. Dis-crimination prevention in data mining consists of ensuring that data mining models automatically extracted from a data set are such that they do not lead to discriminatory decisions even if the data set is inherently biased against protected groups. Different discrimination prevention meth-ods have been proposed considering different data mining algorithms such as na  X   X ve bayes models, logistic regression, decision trees, hinge loss, support vector machines, adaptive boosting, classification, and rule and pattern mining. Three approaches are conceivable for discrimination prevention: preprocessing by means of transforming the source data; in-processing by means of integrating the anti-discrimination constrains in the design of algorithm; postprocessing by means of modifying the results of data mining models.
The tutorial is at researchers interested in the technical aspects behind the societal and ethical problems of discrim-ination and privacy introduced by data mining and machine learning algorithms. No special knowledge is assumed other than familiarity with algorithmic techniques from a standard computer science background.
The tutorial is structured in three main technical parts, plus a concluding part where we discuss future research http://www.whitehouse.gov/sites/default/files/docs/big data privacy report may 1 2014.pdf agenda. All three technical parts include both theory and real-world applications. 1. Introduction, context, and fundamental results: 2. Discrimination discovery: Measures of discrim-3. Fairness-aware data mining: Pre-processing ap-4. Challenges and directions for future research.
We developed a mini-website for the tutorial: http:// francescobonchi.com/algorithmic bias tutorial.html. It con-tains the tutorial slides and a full list of references. Sara Hajian is a Researcher at Eurecat. She received her Ph.D. degree from Computer Engineering and Maths De-partment of the Universitat Rovira i Virgili (URV). Her research interests include data mining methods and algo-rithms for social media and social network analysis, privacy-preserving data mining and algorithmic bias. The results of her research on algorithmic bias featured in Communications of ACM journal [15].
 Francesco Bonchi is Research Leader at the ISI Foun-dation, Turin, Italy, where he leads the  X  X lgorithmic Data Analytics X  group. Before he was Director of Research at Ya-hoo Labs in Barcelona. He is PC Chair of the 16th IEEE International Conference on Data Mining (ICDM 2016). He has also been PC Chair of ECML PKDD 2010 and of sev-eral workshops on privacy-aware data mining including f the first and second ACM SIGKDD International Workshop on Privacy, Security, and Trust in KDD (PinKDD 2007 and 2008), the 1st IEEE International Workshop on Privacy As-pects of Data Mining (PADM 2006). He is co-editor of the book  X  X rivacy-Aware Knowledge Discovery: Novel Applica-tions and New Techniques X  (Chapman &amp; Hall/CRC Press). Homepage: http://www.francescobonchi.com.
 Carlos Castillo is Director of Research for Data Science at Eurecat. Carlos is an active researcher with more than 70 papers in top-tier international conferences and journals, including an upcoming book on Big Crisis Data, a book on Information and Influence Propagation, and a monograph on Adversarial Web Search. He has been PC Chair of ACM Digital Health 2016 and WSDM 2014, organized the Adver-sarial Information Retrieval Workshop in 2007 and 2008, the ECML-PKDD Discovery Challenge in 2010 and 2014, the Web Quality Workshop from 2011 to 2014, and the Social Web for Disaster Management Workshop in 2015. Home-page: http://chato.cl/research/.
This tutorial is partially supported by the EU H2020 inno-vation action programme, TYPES project (grant No 653449) and Catalonia Trade and Investment Agency (ACCI  X  O). [1] S. Barocas and A. D. Selbst. Big data X  X  disparate [2] F. Bonchi, S. Hajian, B. Mishra, and D. Ramazzotti. [3] T. Calders and S. Verwer. Three naive bayes [4] B. Custers, T. Calders, B. Schermer, and T. Zarsky, [5] A. Datta, M. C. Tschantz, and A. Datta. Automated [6] C. Dwork, M. Hardt, T. Pitassi, O. Reingold, and [7] M. Feldman, S. A. Friedler, J. Moeller, C. Scheidegger, [8] S. Hajian and J. Domingo-Ferrer. A methodology for [9] S. Hajian, J. Domingo-Ferrer, and O. Farr`as. [10] S. Hajian, J. Domingo-Ferrer, A. Monreale, [11] F. Kamiran and T. Calders. Data preprocessing [12] B. T. Luong, S. Ruggieri, and F. Turini. k-nn as an [13] D. Pedreshi, S. Ruggieri, and F. Turini.
 [14] S. Ruggieri, S. Hajian, F. Kamiran, and X. Zhang. [15] N. Savage. When computers stand in the schoolhouse [16] L. Sweeney. Discrimination in online ad delivery.
