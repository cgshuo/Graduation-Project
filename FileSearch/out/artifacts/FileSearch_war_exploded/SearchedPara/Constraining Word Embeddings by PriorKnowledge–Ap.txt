 Continuous word representations, called word embeddings, have known widespread uses in general NLP tasks [ 4 , 6 , 15 , 17 , 26 , 27 ]. They offer an effective and ef way of encoding semantic/syntactic relationships between words in semantic space, which typically relies on the distributional hypothesis that two words sharing similar contexts should be associated with similar vectors in the embedding space. Word embedding, and more generally, deep learning, has also been used in IR in recent years available. An alternative approach is to train word embeddings on a document col-lection in an unsupervised manner. Word embeddings trained in this way may re some general syntactic or semantic relations between words in a language such as which may have been established manually. For example, word embeddings trained on a medical collection fail to capture the strong relationship between heart and cor (a strongly related word used in prescriptions), while this relationship has been speci in the domain resource UMLS [ 3 ]. It is natural to leverage the knowledge to constrain or to adjust word embeddings so as to better fi t the speci The principle we use in this paper to constrain word embeddings is that related words in our prior knowledge (e.g. synonyms) should have similar embeddings. The idea of using prior knowledge to constrain word embeddings has been used in medical IR, and evaluate them on several test collections -OHSUMED [ 11 ] and CLEF [ 9 , 18 ]. The contributions of this paper are as follows: We propose modi strained training methods for word embeddings and show that they can bring more improvements to MIR than the original word embeddings.
 The rest of the paper is organized as follows. Section 2 gives an overview of word embedding. Sections 3 and 4 present our approach to constrain word embeddings and to document reranking. Section 5 describes our experiments and analyses. Section 6 goes through the related work and Sect. 7 presents the conclusion and future work. In this section, we describe the standard and regularized word embeddings. 2.1 Continuous Bag-of-Words (CBOW) Proposed by Mikolov et al. [ 15 ], the word2vec models create a vector representation for a word according to the context words frequently appearing around it. In this section, we will only describe one of the word2vec models the following objective loss function: where T is the total number of words in the corpus and w t k window of size k centered at position t and excluding w t given its context is de fi ned as: where the context embedding c is simply the sum of the embeddings of words occurring in the text window. 2.2 Regularized Word Embedding Several approaches have been proposed in recent years to constrain (regularize) unsupervised word embeddings, and we describe two approaches below. Online Training Approach. Online training approaches alter the learning objective in word embedding estimation by adding a knowledge-based regularization term [ 4 , 26 We only describe the approach by Yu and Dredze [ 27 ]. The modi follows: number of links in R ,and C is a hyper-parameter controlling the strength of the regularization. Similarly to Eq. ( 2 ), the probability p product between w i and w j . Therefore, the regularizer sums up a similarity measure over all pairs of related words in the resource.
 the resource is considered to be a constraint of equal importance (1/|R|) in the regu-used words) should play a more important role in the regularization. Second, as the two terms in the objective function sum over different elements links in the resource, Yu and Dredze have to de fi ne two sets of separate learning parameters, one for the CBOW objective and another for the regularization, which are updated separately in turn. This means that when updating the parameters of the regularization, the context of a word (considered in the fi into account. The risk of this process is that the second update could undo the earlier update, making the update process quite random at the end. In this paper, we propose a solution to these problems.
 Of fl ine (Retro fi tting) Approach. Of fl ine approaches (also called retro word embeddings outside the original training process as follows: the new embeddings should be close to the original embeddings and respect the constraints of the external resource, i.e. minimize: where w v and w 0 v are the original and the new embeddings and We propose modi fi cations to solve the problems discussed above. A tighter regular-ization is used in the online method: the original CBOW cost function is combined with the requirement that if a word can be well generated from a given context, its related word should also be well generated from the same context, i.e.: where | R t | is the number of words related to w t in the resource. A possible drawback of the above formulation is that every related word is w by its relative frequency in the document collection as follows: where f ( w s ) is the frequency of w s in the collection. The follows:
L  X  where a is a weighting parameter.
 The above loss function solves both problems of [ 27 ]: the collection frequency of words in a relation is taken into account naturally, and the embeddings for related words are tightly related to their contexts.
 We also propose a slightly modi fi ed version of retro fi weighting in it: As we will see in our experiments, our modi fi ed models can outperform the original regularized embeddings in MIR. Many resources exist in the medical domain. In this paper, we use UMLS Metathe-different sub-domains in a uniform framework. Each concept (identi Concept Unique Identi fi er) in UMLS contains a set of expressions, which we use as synonyms. For example, the CUI C0018681 contains the expressions: { heart, cor, hearts, cardiac, heart nos, heart structure }. There are more types of relations de in UMLS, but we only use synonymy relations in this paper. In addition, we only consider single-word concept expressions (i.e. heart, cor, hearts, cardiac ), and leave multi-word expressions to future work. This results in 302,323 synonymy relations between single words from UMLS.
 sentation for the whole document or query. We use a simple approach commonly used in this area, by summing up all the word embeddings in the document or the query. Cosine similarity is used to measure the similarity between the document and query that a simple sum will make the global embedding of a document tuned towards frequent words which are not discriminative for IR. Therefore, we use the traditional IDF weighting to weight the embedding of a word.
 traditional baseline method (BM25 or language model); then, the results are re-ranked by the following re-ranking function: where c is a hyper-parameter of our model, BOW is the score of a bag-of-word method such as BM25 or LM (language model); and Cosine is the cosine similarity between the query and the document embeddings. Both BOW and Cosine scores are normalized as follows: where MaxScore , MinScore are the maximum and minimum scores in the list, Score and NormScore are the non-normalized and normalized scores of a document. 5.1 Test Collections The experiments are performed on the following test collections: OHSUMED [ 11 ] and CLEF-eHealth 2014 [ 9 ] and 2015 [ 18 ]. We use short queries (title some statistics of the collections.
 We use P@10 as the main performance indicator, and MAP and NDCG@10, which are often used on these collections, as the second indicators for OHUMED and CLEF. Two-tailed t-test ( p &lt; 0.05) is performed for statistical signi 5.2 Word Embedding Training In our experiments, we use CBOW model and negative sampling [ 15 ] to train the basic word embeddings. The CBOW program is then modi fi ed to incorporate the constraints context window size (k) to 5. This setting is common in word embedding [ 15 ] and has been shown to be reasonable in [ 30 ]. We choose 10 negative samples and we words appearing less than 5 times in the collection. The collections are not prepro-cessed before embedding training, i.e. no stemming and stopword removal. Our intuition is that stopwords could provide useful context information for word embed-dings. However, this remains to be con fi rmed. After training, our embedding vocab-ulary size is 164,434 for OHSUMED and 3,989,059 for CLEF. 5.3 Retrieval Results BM25 (with the default setting) and LM (language model with Dirichlet smoothing with  X  = 2000) are used as the basic retrieval methods to retrieve 1000 candidates for reranking. In order to test the effectiveness of CBOW, we also use the standard CBOW model alone (i.e. c in Eq ( 9 ) is set to 0). The original and modi constrained word embeddings are used to rerank the documents as in Eq. ( 9 ). We use 2-fold cross-validation to set hyper-parameters ( a , b , lection. We report the performance of different methods in Table 2 . We observe that the traditional CBOW alone (line c ) leads to poor retrieval effectiveness. This could be explained by the noisy nature of word embedding for a whole document. However, when it is combined with a traditional IR method ( d and e ), we observe signi fi cant improvements. Similar observations have been made in [ 30 ]. Next, we observe that our online method (lines g and i ) outperforms signi CBOW and Yu  X  s method when combined with BM25 or LM. This con constraints imposed by UMLS relations are helpful in training better word embeddings for MIR. We also see that the method of Yu does not always produce better results than CBOW, and the differences between Yu and CBOW are not statistically signi used by Yu does not necessarily lead to better word embeddings.
 Retro fi tting has shown better performance in several NLP tasks [ 7 ] than the method However, the differences are not statistically signi fi cant. Our modi ( k and m ) makes larger improvements. The differences with the original CBOW are statistically signi fi cant on CLEF collections. The only change between the original retro fi tting ( Faruqui ) and our modi fi ed version ( Of fl ine ) is the weighting of embed-dings we added. This suggests the usefulness of embedding weighting in IR. constrained methods could be reasonably used to incorporate prior knowledge. better understand the effect of constraining embeddings, we analyze a speci of word  X  heart  X  , a common medical term. The most similar words, based on word embeddings trained on OHSUMED with different methods, are shown in Table 3 . without using UMLS: hearts , cardiovascular , cardiorespiratory . The words synergist , acyanotic and ventricular are also concepts often used in association with heart . However, ouvrier (name of an author) and thrive are not strongly related to heart . UMLS contains three synonym words to heart : hearts , cor and cardiac , which are incorporated in the constrained embeddings. As we can see, these words have been added or promoted (with higher similarities) in the list using constrained methods. First, we observe that CBOW is unable to discover alone the similar word cor , which is often used in prescriptions for heart diseases. The prior domain knowledge provides complementary means to link this word. This is part of the bene using prior knowledge for embedding training.
 Second, we can also observe that in addition to the synonyms, other strongly related words such as biventricular and cyanotic have also been promoted in the constrained embeddings. In fact, requiring synonym embeddings to be closer also makes the embeddings of their related words closer. In this speci fi expect to fi nd the word cor in the relevant documents to heart in OHSUMED, the words related to cor such as cyanotic could be found in them. This indirect constraint effect can affect many more words than just synonyms.
 We do not see clear differences between the lists of the Online and Of Both method are capable of fi nding some strongly related words. 5.4 Parameter Sensitivity The methods we propose contain some hyper-parameters ( a , retrieval effectiveness to these parameters. We will show the variation of P@10 on OHUSMED and CLEF2015 (CLEF2014 is very similar to CLEF2015).
 Figures 1 , 2 , 3 , and 4 show that the retrieval effectiveness (P@10) varies depending on the setting of a and b . The impact of parameters depends on the test collection (OHSUMED and CLEF), and on the basic retrieval model used (BM25 and LM). Globally, the setting of parameters a and b tends to have a larger impact on CLEF than on OHSUMED. This can be explained by the nature of documents in the collections: OHSUMED contains documents written by professionals while CLEF contains web pages crawled from the Web. The domain knowledge is naturally better encoded in OHSUMED than in CLEF. So, using domain knowledge as constraint will make smaller impact on word embeddings in OHSUMED than in CLEF.
 We can also see that it is preferable to set these parameter to smaller values when combined with LM than with BM25. This could indicate that less regularization is preferred with LM. Further analyses are needed to understand the reason. It is dif fi cult to compare directly the parameters a and different constraint processes. We can still observe the general trend that set to a large value than a . This may mean that the of fl regularization than the online method to adjust word embeddings.
 On the parameter  X  (Fig. 5 ), we observe more consistent behavior on different The best setting is always around 0.5  X  0.6. 6.1 Medical Information Retrieval A number of studies have attempted to exploit the existing resources in medical area such as UMLS. Two categories of approaches have been proposed in the literature. The fi rst approach is based on concepts: One fi rst identi ments and queries using a concept identi fi cation tool such as MetaMap [ 1 ]; then documents and queries are matched through their concepts and related concepts. Although improvements using concepts have been observed on some test collections than the one considered in this paper, the improvements on the test collections con-the relatively low accuracy of concept identi fi cation: about 70 fi ed are correct, and a number of concepts are unidenti fi ed [ 21 ].
 A second method performs query expansion using the relations stored in a the-related terms of the query terms, and this score is combined with that of the original score. Concept phrases can also be used in this method.
 In the previous experiments on the test collections we consider, query expansion approaches have been found more effective than concept-based matching [ 21 ]. All the top performing systems at CLEF 2014 and 2015 have used query expansion approa-ches [ 9 ].
 To position our methods with respect to the existing approaches, we show the top three results in CLEF 2014 and CLEF 2015 in Table 4 . For CLEF 2014, our results are comparable to those of the best team [ 21 ], which used MetaMap and all concept expressions in UMLS to perform phrase-based retrieval and query expansion. On CLEF 2015 [ 18 ], our results are clearly below the best participating system. However, this best system leveraged Google search results, and this gave a consider-able advantage to the system. It is unfair to compare our results with that system. Our methods compare favorably to the other participating systems that do not use Google results. Overall, our methods compare favorably to the state of the art in MIR. 6.2 Word Embeddings for IR Several studies in IR used word embeddings. [ 24 ] used word embedding in cross-language IR task. The goal was to train word embeddings in the same repre-sentation space for words in both languages. In [ 23 ], word embeddings (CBOW) are used to generate an additional feature to be embedded in a learning to rank framework embeddings in IR as well as the impact of different parameters. They made similar observation that word embeddings can signi fi cantly improve IR effectiveness. De Vine on word embeddings outperforms the others.
 dings are useful for IR. However, none of the above studies used constrained word embedding. In this paper, we showed that constrained word embeddings can further improve IR effectiveness. In this paper, we explored the utilization of constrained word embedding for IR in a specialized domain. Our assumption is that constrained word embeddings can better the application domain and lead to better retrieval results. This is con experiments.
 In our experiments, we showed that the modi fi cations we made lead to better retrieval results than their original versions. In particular, our modi important problems in the original online training method and we added embedding weighting. The modi fi cations resulted in signi fi cant changes in IR effectiveness. incorporate prior knowledge. More investigations are needed to determine the best method to incorporate domain knowledge in word embeddings.
 interesting to extend our study to cover more types of relation.
 method to build a representation for the entire document and query. It will be interesting to investigate how an appropriate phrase embedding [ 6 , 19 ], as well as a representation for the entire document and query, could be built for IR. These are some interesting topics for our future work.

