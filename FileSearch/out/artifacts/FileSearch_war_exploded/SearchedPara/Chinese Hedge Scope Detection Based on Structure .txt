 Huiwei Zhou, Junli Xu, Yunlong Yang, Huijie Deng, Long Chen, and Degen Huang Hedges indicate uncertain or unreliable information, which are usually used in science sentences in the full paper section contain uncertain information on BioScope corpus [1] . In Chinese, 29.30% of the sentences contain speculative fragments on CBHI co r-pus [2] . In order to distinguish facts from uncertain information , hedge detection is becoming an important task for information extraction . The CoNLL -2010 Shared Task [3] was dedicated to detecting uncertainty cues and their linguistic scopes on English corpus. Chinese hedge information detection has also attracted considerable attention [4] . This paper focuses on Chinese hedge scope detection on the CBHI co r-pus. A hedged sentence taken from the CBHI corpus is shown as follows:
Sentence 1 :  X  X  X  X  X  X  X  X  X  X  X  X  &lt;scope&gt; PCAF &lt;ccue&gt;  X  X  &lt;/ccue&gt;  X  X  X  HCC  X  X  X  X  X  X  X  &lt;/scope&gt;  X  X  X  X  X  X  X  X  X  X  HCC  X  X   X   X  X  X  X  X  X  X  X  X  X  X  X  X   X  a tumor suppres sor factors of HCC&lt;/scope&gt;, and has become a predict postoperative HCC prognosis biomarkers.)
In sentence 1 , the word  X   X  X  (may)  X  is hedge cue and its scope is the statement that  X  PCAF  X  X  X  X  X  X  HCC  X  X  X  X  X  X  X  (PCAF may be a tumor suppressor factors of HCC)  X  .

Researches on hedge cue identification have been developed rapidly [ 5 , 6 ] . Howe v-er, hedge scope detection remains a challenge, since hedge scope detection is depe n-dent on syntactic and semantic information. T his paper focuses on hedge scope dete c-tion from s tructure and semantic perspective.

Existing studies on hedge scope detection contain feature -based and tree kernel -based methods. Feature -based methods define a set of discrete fe atures with  X  X ne -hot X  representations based on lexical and flat syntactic information. Tree kernel -based methods could capture structured syntactic information by counting the number of could not capture deep semantic information between cues and their linguistic scopes.
This problem motivates us to develop neural network models which could capture deep semantic information for scope detection. We propose a novel syntactic and semantic information exploitation method, which consists of a composite kernel and LSTM model. Composite kernel model is designed to capture lexical and structured syntactic information. LSTM model is a dopt ed to explore deep semantic information. information, we explore a hybrid system to integrate composite kernel and LSTM model into a unified framework. In this section, w e review the literature related to this paper from two aspects: hedge scope detection and neural network approaches for Nature Language Processing ( NLP ) tasks. 2.1 Hedge scope detection Existing research es for hedge scope detection mainly contain: rule -based and ma chine learning -based methods. Rule -based methods [ 8 , 9 ] compile heuristic rules by exploi t-ing lexico -syntactic patterns for scope detection. Rule -based methods are simple and effective, but the extracted rules are hard to be developed to a new resource.
Machine learning -based methods formulate scope detection task as a classification ment of the scope (F -scope), the last (L -scope), or neither (None). Machine learning -based methods mainly include feature -based and tree kernel -based methods. Feature -based methods design a set of discrete features with  X  X ne -hot X  representations based on lexical and flat syntactic information. Morante and Daeleman s [ 10 ] explore lexical exploit flat syntactic features for scope detection. The above researches take tokens as classification u nits, which inevitably generate plenty of instances. To decrease i n-nel -based methods could capture structured syntactic information by counting the spectively to c apture structure d syntactic information for scope detection .
Feature -based and tree kernel -based methods could effectively capture lexical and syntactic information . However, the extracted features with feature -based and tree kernel -based methods are discrete and could not captur e deep semantic information . 2.2 Neural Network for NLP tasks Neural networks could learn deep semantic representation s without feature enginee r-sequences . Xu et al. [ 19 ] use LSTM to pick up semantic informa tion along the shor t-est dependency path between two entities for relation extraction. Zhou et al. [ 2 0 ] e x-plore a series of semantic representations with LSTM model and further integrate diverse informa tion for chemic al -disease relation extraction.

M otivated by the success of LSTM model and Zhou et al. [ 2 0 ] , we propose a hyb r-id system which consists of composite kernel and LSTM model to capture lexical, syntactic and semantic information for scope detection. The corpus is preprocessed with Stanford Parser 1 to get lexical and synta ctic inform a-given cue, the left most (rightmost) word is F -scope (L -scope) .

The hybrid system architecture consists of training and test phases as shown in Fig. 1. In training phase, lexical and syntactic features are captured by composite kernel model, and semantic representations are learned by LSTM model . In test phase, two models are applied to detect hedge scope. T he predict e d results of the two models are combined to optimize system performance finally. 3.1 Composite kernel for hedge scope detection The polynomial kernel.
 The feature -based model is learned from lexical features with polynomial kernel
K x x x x  X   X   X  , where d is the dimension of polynomial kernel. We s e-lexical information of hedge and its candidate.  X  Word Context : word s of cue and its candidate in the window [ -2 , 2 ].  X  CandidateType : the constituents of candidate phrase, such as NP, VP.  X  HedgePoS : the part -of -speech ( PoS ) of hedge.
 The convolution tree kernel.
 The convolution tree kernel c ould effectively capture structured syntactic information. This paper focuses on the information combination, so we only adopt the extending phrase path tree (EPPT) [ 15 ] to explore the structured syntac tic information for scope neighbor tokens of both the hedge and its candidate in the phrase tree . The path from the hedge and its candidate. Adding the neighbor structures c ould provide rich context 2(a), the EPPT about the hedge  X   X  X  ( may ) X  and its L -scope candidate  X  HCC  X  is shown in Fig. 2(b) .
 The composite kernel . combining the polynomial kernel and the convolution tree kernel : w here (0 1)  X  X  X   X  X  is the composite factor . The polynomial kernel volution tree kernel 3.2 Long Short -Term Memory ( LSTM ) for hedge scope detection LSTM model is a kind of recurrent neural network (RNN), which introduces a gating mechanism to avoid gradient vanishing and exploding. LSTM cell comprises four components: an input gate f W h x b  X   X   X   X   X  , an output gate c i W h x b f c  X  X   X   X   X   X   X  X  X  . These gates adaptively remember input vector, forget previous history and generate output vector, where  X  denotes comp o-nent -wise multiplicatio n ,  X  represents the sigmoid function, W , den state vector computing its internal hidden state tanh( ) is that context semantic information of hedge and its candidate is important for scope detection. W e develop four LSTM models to explore deep semantic information r e-lated to hedge scope as following.
 CanHedSeq -LSTM . CanHedSeq sequence feeding to LSTM for recursively capturing context semantic representations of hedge scope. The dimension of word representations 1 d d . A n illustration of the CanHedSeq -LSTM model is shown in Fig. 3.
 Bi_CanHed -LSTM . We use two LSTM models: one LSTM model captures semantic information for co n-text words of candidate in the window [ -2, 2], and another LSTM model computes regression layer to detect scope. An illustration of the Bi_CanHed -LSTM model is shown in Fig. 4 .
 Bi_ CanHedSeq -LSTM . scope detection. In order to obtain the history and future information of CanHedSeq sequence, we use a forward LSTM and a backward LSTM to model the forward and backward CanHedSeq sequence, respectively. Afterwards , the last hidden vectors of two LSTM models are concatenate d and fed to a logistic regression layer to detect scope . A n illustration of the Bi_CanHedSeq -LSTM model is shown in Fig. 5 . Bi_ CanHedSeq _Con -LSTM .
 To further represent the information of CandidateType and HedgePos , we construct B i_CanHedSeq_Con -LSTM model based on the B i_CanHedSeq -LSTM . In the B i_CanHedSeq_Con -LS TM model , the representation of CandidateType 2 d concatenated to the representations of the context words 1 d form a vector representation 12 , dd xR  X  is concatenated to the representations of the context words 1 d hedge to form a vector representation 12 , dd shown in Fig. 6. 3.3 Hybrid system for hedge scope detection Both the composite kernel model and the LSTM model have their own advantages and could capture different information for scope detection. W e propose a hybrid system integrating the composite kernel model () LSTM model ()
The predict ed results of the composite kernel model are the distances between the instances and the separating hyperplane, while those of the LSTM model are the probabilities of the instances. We adopt a uniform framework with sigmoid function  X  to transform the distance into a probability as shown in equation (2). w here presentations of the hedge scope controlled to investigate the impacts of composite kernel model vs. LSTM model. The sigmoid function  X  is monotonic, and the point ( 1 ) 0.5 P y f  X  X  occurs at the sep a-rating hyperplane 0 f  X  . Therefore, the boundary probability is set to 0.5 to separate boundaries from non -boundaries. 3.4 Postprocessing To guarantee that all scopes are continuous sequences of tokens , we apply the follo w-ing rules to hedge scope detection system. (1) If one token is predicted as F -scope and one token as L -scope, the sequence will (2) If one token is predicted as F -scope, and none /more than one token is predicted as (3) If one token is predicted as L -scope, and none /more than one token is predicted as Experiments are conducted on the CBHI corpus . The training and test data contain 7510, 1875 sentences respectively. We detect the linguistic scope s with golden sta n-dard cues. Stanford Word Segmenter toolkit 2 is employed to segment words and get P o S tag . SVM -LIGHT -TK toolkit 3 is used to c onstruct the composite kernel model. LSTM model is developed based on Theano system 4 [ 2 1 ] . The evaluation of scope the token as the evaluation unit, and evaluates the performance of the F -scope and L -scope boundaries for each cue . 4.1 Effects of composite kernel for hedge scope detection The detailed performances of the lexical features with polynomial kernel under the condition 2 d  X  are summarized in Table 1. Fro m the results, we can see that W or d-Context features achieve poor results. With other features added one by one, the pe r-formance improve s continuously and reaches 63.95 % F 1 -score. All of the lexical features are effective for scope detection. Lexical features with polynomial kernel c ould obtain acceptable perf ormance. However, the feature engineering is labor inte n-captu r ing shallow information for hedge scope detection.

W e use composite kernel model to capture lexical features and structured syntactic information . Fig. 7 shows the performance of composite kernel with different comp o-site factor  X  . We vary  X  from 0 to 1with an interval of 0.1. From Fig. 7 , we can see that: (1) The sole tree kernel ( =1  X  ) obtains 49.92 % F 1 -score, which is worse than the sole (2) The performance of L -scope classifiers is usually better than that of F -scope cla s-4.2 Effects of LSTM for hedge scope detection In our experiments, we use Word2Vec 5 toolkit to pre -train word representation s on the SogouCS corpus 6 . The dimension tation s of HedgePos and CandidateType are initialized randomly with dimension 10 . Table 2 shows the performance with four LSTM models. (1) Performance of scope detection obtains acceptable result under any LSTM mo d-(2) CanHedSeq -LSTM achieves 55.73 % F 1 -score, which is 1.22 % higher than the (3) Bi_CanHed -LSTM obtains worse performance than CanHedSeq -LSTM. The (4) Bi_CanHedSeq -LSTM achieves better performance , which obtains 55.15% F 1 -(5) Bi_CanHedSeq_Con -LSTM obtains best F 1 -score 5 9.09 %, which is 3.94 % hig h-4.3 Effects of weighting parameters W e investigate the impact of the parameter s  X  that control the weighting of LSTM model vs. the composite kernel model. The composite kernel model under the cond i-tion =0.3  X  ( 68.91 % F 1 -score) and each LSTM model are used in the hybrid system. From Fig . 8 , we can see that the trends of the four curves are similar. All starts from the initial F 1 -score of LSTM model, and then increase s to the individual highest F 1 -score, finally falls below the initial F 1 -score (68.91%) of composite kernel model. The composite kernel is combine d with CanHedSeq -LSTM ( 55.73 % F 1 -score ) , Bi_CanHed -LSTM ( 53.97 % F 1 -score ) , Bi_CanHedSeq -LSTM ( 55.15% F 1 -score ) and Bi_CanHedSeq_Con -LSTM ( 59.09 % F 1 -score ) obtaining 6 9.92 %, 6 9.76 %, kernel model and the four LSTM models have their own advantages and could ca p-ture different information f or scope detection. Their combination could further i m-prove the performance of scope detection. Lexical features, syntactic structure features, and semantic representations are all particularly effective for hedge scope detection. W e pr opose a hybrid system to int e-grate these information for Chinese hedge scope detection , which achieves 69.92% F1 -score on the CBHI corpus. The hybrid system consists of t he composite kernel model and t he LSTM model . The composite kernel model c ould effectively capture lexical and syntactic information. The LSTM model c ould explore deep sema ntic information of hedge scope. In addition, four LSTM models are develop ed to explore deep semantic information related to hedge scope .

For the future work, we will explore other deep neural network models to capture more effective semantic information . Besides, we will explore other hybrid methods which integrate diverse information to further improve the performance of scope d e-tection.
 Acknowledgements . This research is supported by Natural Science Foundation of China (No. 61272375) .
