 Topics form a crucial component of a test collection. We show, through visualization, that the INEX 2008 topics have shortcomings, which questions th eir validity for evaluating XML retrieval effectiveness. H.3 [ Information Storage and Retrieval ]: Information Search and Retrieval  X  Retrieval models, Search process . Reliability, Experimentation, Hu man Factors, Verification. INEX, XML-IR, Element Re trieval, IR Methodology. Hawking et al . [2] outline 12 desirable features of search engine evaluation of which 4 apply to topics, paraphrasing: (1) Many topics should be used; (2) When comparing maximal (not typical) effectiveness, the full range of search facilities should be exploited; (3) Topics should be representative of genuine user needs; (4) Topics should represen t the full range of information needs. Although originally formulat ed for web-IR, these features apply equally well to any form of text-IR evaluation. We ask if the INEX 2008 topics satisfy these features, and one other  X  (5) Topics should be inde pendent from each other. It is shown visually and through statis tical analysis that the INEX 2008 topics only satisfy FEATURE 1 . This provides further evidence of the Trotman &amp; Lalmas [6] claim that users, in our case INEX participants, are particularly bad at specifying structural hints, and the first evidence to refute the Lehtonen [4] claim that this is a consequence of the (IEEE) document collection used at INEX up to 2005. We use the INEX Wikipedia co llection of 659,388 documents, the INEX 2008 topics (v4) consisti ng of 135 participant submitted topics (the INEX set) and 150 topics drawn from a New Zealand high school proxy log (the Proxy set). The INEX topics contain two fields of interest: the CO query and the CAS query; the former are typical of queries seen by online search engines, the latter additionally contain support a nd target structural hints. CO queries are used throughout, except in section 3 which uses CAS. It is typical for 50 topics to be used at TREC and for about 100 at INEX. Buckley &amp; Voorhees [1] sugge st that 50 topics is sufficient size. Lehtonen observed structural hints in the IEEE collection targeting result size; this is seen in the Wikipedia topics too. Although the topics test many facilities, the use of structural hints for XML-retrieval is not well repres ented in the topic set, so it is reasonable to conclude that FEATURE 2 is not satisfied. Figure 2 shows the Zipfian distribu tion of terms in the Wikipedia document collection and a sliding window count of the number of topic terms in each set. Search terms in both sets tend to occur in tens of thousands of documents . Topic lengths are plotted in Figure 3. Length is inversely pr oportional to topic frequency in the Proxy set, but in the INEX set there is a preference for topics of length 3. FEATURE 3 is not well satisfied. 
Figure 2: Term frequencies in the two topic sets are similar Figure 4 shows the thematic rela tionships in the INEX topics. Each topic title was stopped and st emmed; then if two topics shared a stem an edge was drawn between them (edgeless vertices were excluded). Vertex size is a function of topic length (in terms). The top left black topic, 585 ( international brigades spanish civil war ) shares terms with topics: 562 ( algerian war ); 618 ( lebanon militias war ); 553 ( spanish classical guitar players ); 615 ( spanish transition ); and 645 ( cellular phone international roaming ). A war theme is shared with two other topics and a Spain theme with two more. There are 71 edges in total. If the number of edges (topics sharing a theme) is larger than that expected by chance then the topics are not independent. That is, a random selection of terms draw n from the Wikipedia vocabulary (of 2,012,641 terms) should result in a graph similar to Figure 4. To test this using the Bootstra p [5], 135 random queries matching the lengths shown in Figure 3 we re generated and the number of links counted. Repeated a million times, it suggests that the 
