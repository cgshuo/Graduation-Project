 1. Motivation
Currently, research in the area of the semantic web is in a state where ontologies are ready to be applied in real applications such as semantic web portals, information retrieval or information integration. In order to lower the effort of building ontology-based applications, there is a clear need for a representational and computational infrastructure in terms of general purpose tools for building, storing and accessing ontolo-gies. A number of such tools have been developed, i.e. ontology editors [1,2] , reasoning systems [3,4] and more recently storage and query systems (e.g. [5] ). Most of these tools, however, treat ontologies as mono-lithic entities and provide little support for specifying, storing and accessing ontologies in a modular manner. 1.1. Why modularization?
There are many reasons for thinking about ontology modularization. Our work is mainly driven by three arguments. These also bias the solution we propose, as it focuses on the following aspects.
Distributed Systems : Indistributedenvironmentslikethesemantic web,thequestionformodularizationarises naturally.Ontologiesindifferentplacesarebuiltindependentofeachotherandcanbeassumedtobehighlyhet-erogeneous. Unrestricted referencing of concepts in a remote ontology can therefore lead to serious semantic problemsasthedomainofinterpretationmaydifferevenifconceptsappeartobethesameonaconceptuallevel. The introduction of modules with local semantics can help to overcome this problem.

Large Ontologies : Modularization is not only desirable in distributed environments, it also helps to manage very large ontologies that we find in medicine or biology. These ontologies, which sometimes contain more than a hundred thousand concepts, are hard to maintain as changes are not contained locally but can affect large parts of the model. Another argument for modularization in the presence of large ontologies is re-use: in most cases, we are not interested in the complete ontology when building a new system, but only in a specific part. Experiences from software engineering shows that modules provide a good level of abstraction to support maintenance and re-use.

Efficient reasoning : A specific problem with distributed ontologies as well as with very large models is the efficiency of reasoning. While the pure size of the ontologies causes problems in the latter case, hidden dependencies and cyclic references can cause serious problems in a distributed setting. The introduction of modules with local semantics and clear interfaces will help to analyze distributed systems and provides a basis for the development of methods for localizing inference. 1.2. Requirements
There are three requirements a modular ontology architecture has to fulfill in order to improve ontology maintenance and reasoning in the way suggested above. The requirements will be the main guidelines for the design of our solution proposed in this work.

Loose Coupling : In general, we cannot assume that two ontology modules have anything in common. This tecture has to reflect this by providing an extremely loose coupling of modules. In particular, we have to prevent unwanted interactions between modules. For this purpose, mappings between modules have to be distinguished from local definitions on the semantic as well as the conceptual level.

Self-Containment : In order to facilitate the re-use of individual modules from a larger, possibly intercon-nected system, we have to make sure that modules are self-contained. In particular, it should be possible to perform certain reasoning tasks such as subsumption or query answering within a single module with-out having to access other modules. This is also important if we want to provide efficient reasoning. Fur-ther, we have to ensure correctness, and whenever possible completeness, of local reasoning, for obvious reasons.

Integrity : The advantages of having self-contained ontology modules have their price in terms of potential inconsistencies that arise from changes in other ontology modules. While there is in our architecture no need to access other modules at reasoning time, the correctness of reasoning within a self contained module may still depend on knowledge in other ontologies. If this knowledge changes, reasoning results in a self-contained module may become incorrect with respect to the overall system, and we will not even notice it.
We have to provide mechanisms for checking whether relevant knowledge in other systems has changed and for adapting the reasoning process if needed to ensure correctness. 1.3. Related work
Our work relates to two main areas of research on representing and reasoning about ontological knowl-edge. The first is concerned with distributed and modular knowledge representation where we use ideas from theorem proving and knowledge engineering. The second area of related work is concerned with managing knowledge models. Here previous work exists in the area of knowledge engineering and semantic web technologies.

While the principle of modularity has widely been adopted in software engineering it has got less attention in the area of knowledge representation and reasoning. Some fundamental work on the modularization of rep-resentations can be found in the area of theorem proving. Farmer and colleagues promote the use of combi-nations of  X  X ittle Theories X , representations of a specific mathematical structure in order to reason about complex problems [6] . They show the advantages of this modular approach in terms of reusability and reduced modeling effort. The idea of reusing and combining chunks of knowledge rather than building knowledge bases from scratch has later been adopted by the knowledge engineering community for building real-world knowledge bases (e.g. see [7] ). McIlraith and Amir argue that a modularization of knowledge bases has also advantages for reasoning, even if the modularization is done a posteriori. They present algorithms for break-ing down existing representations into a set of modules with minimal interaction and define reasoning proce-techniques from uncertain reasoning, where an a posteriori modularization of large theories is a common way to reduce runtime complexity (e.g. see [10] ).

As we are interested in representations of ontological knowledge, approaches from the area of logics for find the same arguments for a modularized representation as in the area of theorem proving. Rector proposes a strategy for modular implementation of ontologies using description logics [11] . The approach is based on a set of orthogonal taxonomies that provide a basis for defining more complex concepts. Rector argues for the benefits of this strategy in terms of easier creation and re-use of ontological knowledge. Buchheit and others propose a similar structuring on the language level by dividing the terminological part of a knowledge base tion can be used to achieve better run-time behavior for complex view languages. While these approaches still assume the overall model to be a single ontology providing a coherent conceptualization of the world, Giun-chiglia and others propose a more radical approach to distributed representations. They propose the local mappings between different modules. Recently, Borgida and Serafini defined a distributed version of descrip-tion logics based on local model semantics that has all advantages of the contextual representations [14] .
As already mentioned, the problem of combining and reasoning with ontological modules has become of cen-tral importance in research on knowledge representation and reasoning on the semantic web. Standard lan-guages for encoding ontological knowledge on the World Wide Web, i.e. the RDF schema [15] and the web ontology language OWL [16] provide some basic mechanisms for combining modular representations. The abil-made for statements from imported models, however, this is strictly speaking not required. As a consequence, a detailed analysis of the drawbacks of using OWL import statements for combining heterogeneous ontologies and show that local model semantics, which is also the basis for our work solves these problems. Volz and col-leagues discuss different interpretations of the import statement that range from purely syntactic to schema-aware interpretations of the imported knowledge [18] . An alternative way of relating different RDF models to each others that is much closer to our ideas is discussed by Oberle [19] who defines a view language for RDF.
Recently, there has been some interest in formal models for modular ontologies that can be seen as com-nections [20] as a suitable formalism for inter-module links and investigated the logical properties of ontologies. Others have proposed to strengthen distributed description logics by adding requirements to the links between different local models resulting in a formalism called P-DL [21] . These models, however, take a slightly different view on modular ontologies. While in this paper, we assume that modular ontologies are created by linking previously unrelated, possibly inconsistent ontologies that can also have overlap in their scope, the above mentioned approaches focus on a scenario where an existing ontology is partitioned into a number of modules for the sake of enhancing (re-)usability and thus assume a tighter coupling of the dif-ferent modules which requires a stronger formalism for specifying links between the modules. 1.4. Our approach
In the following, we describe our approach to ontology modularization on an abstract level. We emphasize the main design decisions and motivate them on the basis of the requirements defined above. The technical details of the approach will be given in the subsequent sections.
 View-Based Mappings : The first design decision concerns the way different ontology modules are connected.
In our work, we adopt the approach of view-based information integration. In particular, ontology mod-ules are connected by conjunctive queries and the extension of a concept in one module can be claimed to be equivalent to the (intentional) answer set of a conjunctive query over the vocabulary of another module.
This way of connecting modules is more expressive than simple one-to-one mappings between concept names. Further, the same technique can be used to define relations of any arity based on other modules.
Compared to the use of arbitrary axioms, our approach is less expressive. We decide to sacrifice a higher expressiveness for the sake of conceptual simplicity and desirable semantic properties that are discussed in the remainder of this paper.

Interface Compilation : The use of conjunctive queries guarantees a loose coupling on a conceptual and semantic level. However, it does not provide self-containment, because reasoning in an ontology module depends on the answer sets of the queries that are used to connect it to other modules. These answer sets have to be determined by actually querying the other ontology module. In order to make local reasoning independent from other modules, we use a knowledge compilation approach. The idea is to compute the result of each mapping query off-line and add the result as an axiom to the ontology module. At reasoning time these axioms replace the query, thus enabling local reasoning. As the results of queries are considered instances retrieved from other modules, but a set of axioms that contains all the information necessary to perform local reasoning.

Change Detection and Automatic Update : Our approach of compiling mappings and adding the result to the different ontology modules is very sensitive against changes in ontology modules. Once a query has been compiled, the correctness of reasoning can only be guaranteed as long as the queried ontology module does not change. On the other hand, not every change in the system does really influence the compiled result.
Problems only arise if concepts used in the query change or if the set of concepts subsuming the query is changed. In the second case, we will have to compile the interface again. In the first case we might even have to consider a redefinition of the query. In order to decide whether the compiled axiom is still valid, we propose a change detection mechanism that is based on a taxonomy of ontological changes and their impact on the concept hierarchy in combination with the position of the affected concept in the hierarchy.
In the following, we first introduce a representational framework for modular ontologies that builds on top of existing work on distributed description logics (DDL) as a framework for reasoning about distributed ontologies. In Section 3 we define reasoning mechanisms for modular ontologies as a special case of general inference in distributed description logics. We further introduce the compilation of implied subsumption rela-tions as a mechanisms for localizing reasoning and compare it with the distributed reasoning methods pro-posed for DDL. Section 4 discusses the problem of handling changes in external ontologies and their impact on compiled knowledge and proposes a heuristic for checking whether compiled knowledge has to be recomputed. We conclude with an example from a case study on ontology evolution in Section 5 and a discussion of the tradeoffs of our approach and possible extensions in Section 7 . 2. Modular ontologies In this section, we present a formal model for modular ontologies that will be used throughout the paper. Our starting point is the use of description logics  X  a special kind of logics for representing terminological semantics. We then formally introduce the logic SHIQ which is the basis for our work. We then proceed with the definition of our model for modular ontologies by briefly recalling an extension of SHIQ with mappings between different models known as Distributed Description Logics (DDL). As our model turns out to be a framework of DDL that apply to the modular ontologies. 2.1. Ontologies and description logics
An Ontology usually groups objects of the World that have certain properties in common (e.g. cities or to further discriminate objects into subgroups (e.g. capitals or European countries). Concepts can be defined in two ways, by enumeration of its members or by a concept expression. The specific logical operators that can be used to formulate concept expressions can vary between ontology languages ( Table 1 ).

Description Logics are decidable subsets of first order logic that are designed to describe concepts in terms of complex logical expressions 1 The basic modeling elements in Description Logics are concepts (classes of objects), roles (binary relations between objects) and individuals (named objects). Based on these modeling elements, Description Logics contain operators for specifying so-called concept expressions that can be used to specify necessary and sufficient conditions for membership in the concept they describe. These modeling elements are provided with a formal semantics in terms of an abstract domain interpretation mapping I map-ping each instance onto an element of an abstract domain D defined as subsets of D I D I . Concepts are interpreted as a subset of the abstract domain D . Intuitively, a concept is a set of instances that share certain properties. These properties are defined in terms of concept expressions. Typical operators are the Boolean operators as well as universal and existential quantification over relations to instances in other concepts.

A Description Logic Knowledge base consists of two parts. The A-box contains information about objects, their type and relations between them, the so-called T-Box consists of a set of axioms about concepts (poten-tially defined in terms of complex concept expressions and relations). The first type of axioms can be used to labeled graphs. The other types of axioms describe relations between concepts and instances. It can be stated we can define a relation to be a subrelation or the inverse of another relation. These axioms are used to for-malize the legal ontology described in the last section.
 The formal semantics of concepts and relations as defined by the interpretation into the abstract domain D can be used to automatically infer new axioms from existing definitions.

It has been argued that encoding ontologies in Description Logics is beneficial, because it enables inference engines to reason about ontological definitions. In this context, deciding subsumption between two concept expressions, i.e. deciding whether one expression is more general than the other one is one of the most impor-uct and service matching [25,26] and Query answering over ontologies [27] .

In this paper, we consider ontologies represented in the description logic SHIQ . This choice is motivated by the fact that SHIQ covers a large part of the expressive power of the Web Ontology Language OWL [16] , more specifically of the language OWL-DL, a decidable sublanguage of OWL that directly corre-sponds to the logic SHOIQ that extends SHIQ with nominals [28] . We omit this extension in order to be able to base our framework on recent results on Distributed Description Logics [29,30] that provide us with basic mechanisms for specifying links between concepts in different ontologies in a loose way.
Before defining our notion of modular ontologies, we briefly introduce the logic SHIQ as well as the basic notions of Distributed Description Logics. For further information about notation and naming in Descrip-tion Logics, we refer to [31] . 2.2. The SHIQ description logic
Let C be a set of concept names and RN a set of role names. Further let there be a set R subroles with respect to the transitive closure of the role inclusion relation. Concept expressions are now formed by applying special operators to concept and role names. In particular, new concept expressions can be formed from existing ones using the Boolean operators or by imposing constraints on the type and number of objects related to objects of the described concept. The corresponding operators are summarized below
Expression Intuition : C All objects that are not of type C C u D All objects that are of type C and of type D
C t D All Objects that are of type C or of type D 9 r : C All Objects that related to some objects of type C via 8 r : C All Objects that are only related to objects of type C via  X  P nr : C  X  All objects that are related to at least n objects of type C  X  6 nr : C  X  All objects that are related to at most n objects of type C
Formally, the set of concepts (or concept expressions) in SHIQ is the smallest set such that:  X  &gt; and ? are concept expressions for the most general concept and the unsatisfiable concept, respectively;  X  every concept name A is a concept expression; C u D , C t D , 8 r : C , 9 r : C ,  X  P nr : C  X  and  X  6 nr : C  X  are concept expressions.
A general concept inclusion axiom is an expression C v D where C and D are concepts. A terminology is a set of general concept inclusion and role inclusion axioms.
 The semantics of SHIQ is defined in terms of an interpretation I  X  X  D maps every concept on a subset of D I and every role on a subset of D and D and for roles r where #M denotes the cardinality of M and  X  r I  X  have  X  &gt; I  X  D I and ? I  X ;  X  r I  X  X  r I  X   X  for r 2 R  X  and r  X f X  y ; x  X j X  x ; y  X 2 r I g  X   X : C  X  I  X  D I C I ,  X  C u D  X  X  C I \ D I and  X  C t D  X   X   X 8 r : C  X  I  X f x j8 y :  X  x ; y  X 2 r I ) y 2 C I g  X   X 9 r : C  X  I  X f x j9 y :  X  x ; y  X 2 r I ^ y 2 C I g  X   X  P nr : C  X  I  X f x j # f y :  X  x ; y  X 2 r I ^ y 2 C I g P n g  X   X  6 nr : C  X  I  X f x j # f y :  X  x ; y  X 2 r I ^ y 2 C I g
An interpretation satisfies a terminology T if C I D I for all general concept inclusions C v D in T and concept C in T if C v D holds for all models of T . In the remainder of the paper we will focus on the task of deciding whether a concept subsumes another one. 2.3. Distributed description logic
Distributed Description Logics as proposed in [29] provide a language for representing sets of terminologies and semantic relations between them. For this purpose DDLs provide mechanisms for referring to terminol-ogies and for defining rules that connect concepts in different terminologies. On the semantic level, DDLs extend the notion of interpretation introduced above to fit the distributed nature of the model and to reason about concept subsumption across terminologies.
 index of the terminology they belong to (i.e. i : C denotes a concept in terminology T inclusion axiom from terminology T j ). Note that i : C and j : C are different concepts. Semantic relations between concepts in different terminologies are represented in terms of axioms of the following form, where
C and D are concepts in terminologies T i and T j , respectively:  X  i : C ! v j : D (into-rule)  X  i : C ! w j : D (onto-rule)
These axioms are also called bridge-rules . The into-rule states that concept C in terminology T minology T i is intended to be more general than concept D in terminology T is defined as the conjunction of the two rules above, stating that the two concepts are intended to be equiv-alent. A distributed terminology T is now defined as a pair  X f T minologies and f B ij g i 6  X  j 2 I is a set of bridge rules between these terminologies.

The semantics of distributed description logics is defined in terms of a global interpretation I  X  a domain relation connecting elements of the interpretation domains of terminologies T r  X  x  X  to denote f y 2 D I j j X  x ; y  X 2 r ij g and r ij  X  C  X  to denote
A distributed interpretation I satisfies a distributed terminology T if:  X  I i satisfies T i for all i 2 I 2.4. Modular ontologies
We can now define our notion of a modular ontology in terms of Distributed Description Logics. In fact, our notion of a modular ontology is a restricted form of distributed terminology as defined above.
The restrictions we impose concern the architecture of the distributed terminology as well as the expressiveness of semantic relations between terminologies. These restrictions are motivated by the aims of (1) providing an alternative to the standard notion of import in OWL and (2) the goal of providing support for localized reasoning and maintenance of the modular ontology. In the following, we will first discuss the architecture of a modular ontology and then introduce the restrictions imposed on semantic relations. 2.4.1. Architecture
As described above, DDL makes a clear distinction between terminologies and semantic mappings between them in terms of bridge rules, which in principle are independent of the terminologies. This makes the model
Description Logics as it makes the semantic links to other models part of the terminology. Being part of the terminology implies that there is only one way of connecting to these external definitions which is assumed to be agreed on by the users of the local terminology.

We achieve this localization of semantic relations by introducing the notion of externally defined concepts in a terminology. We divide the set of concept names in a terminology into internally defined concepts C externally defined concepts C E resulting into the following description of the set of all concept names C  X  C  X  C I [ C E ; C I \ C E  X ; X  .

We consider externally defined concepts to be concept names linked to a concept expression defined in another terminology using bridge rules. An external concept definition in terminology T the form: i : C T j : D where C is a concept name in T i , T the external concept is defined and D is a concept expression in T concepts defined in T j . This definition is very close to the OWL mechanism of using concept and role names from other name spaces in definitions.

We give external concept definitions a semantics in terms of distributed description logics by defining exter-nal concept definitions to be an alternative notation for a pair of bridge rules:
The correspondence between external concept definitions and bridge rules allows us to base our further inves-tigations on the formal results that have been established for distributed SHIQ terminologies. 2.4.2. Restricting mapping expressiveness
In Distributed Description Logics, there are no restrictions on the antecedent of a bridge rule X  X xcept that it has to be a valid concept of the source terminology. In our framework, we restrict this freedom for the sake of an easier maintenance of the semantic relations between terminologies. This restriction is motivated by our earlier work on keeping integrity in modular ontologies reported in [32] . In that work, we proposed a heuristic approach for determining the impact of changes in other modules on the correctness of local subsumption reasoning. The approach relied on the fact that changes were only monotonically propagated to other modules. In order to achieve this effect also in the framework of distributed description logics, we restrict the language used to specify externally defined concepts to a sublanguage of SHIQ that does not contain operators that can have a non-monotonic effect, in particular negation, universal restrictions and qualified number restrictions that limit the number of related concepts. More precisely, we allow concept expressions that are defined in the following sublanguage of SHIQ :
In order to restrict the semantic correspondences between terminologies in our model, we now only allow the concept expressions D in the definition of external concepts to be valid concepts over terminology T respect to the sublanguage defined above. We denote such concepts as D expressions of the form i : C j : D Q . 3. Reasoning in modular ontologies
The direct correspondence of our framework to Distributed Description Logic allows us to base inference in modular ontologies on known results for the corresponding DDL. In particular, we can provide complete-ness and complexity results for reasoning in modular ontologies. We extend the existing work on reasoning in
DDL with the notion of compilation of implied subsumption relations. Specifically, we use reasoning methods for Distributed Description Logics to derive subsumption relations between externally defined concepts in modules and explicitly add the derived subsumption relations as axioms to the module. The results of [30] guarantee that after this compilation step reasoning can be performed locally without considering other mod-ules unless there are changes in the system.

In the following, we first briefly review basic definitions of reasoning in distributed description logics and prove that it has the same worst-case complexity as reasoning in SHIQ . We then present the compilation of subsumption relations and discuss conditions for completeness and consistency. 3.1. Reasoning based on DDL
Reasoning in DDL differs from reasoning in traditional Description Logics by the way knowledge is prop-agated between T-Boxes by certain combinations of bridge rules. The simplest case in which knowledge is propagated is the following:
This means that the subsumption between two concepts in a T-Box can depend on the subsumption between two concepts in a different T-Box if the subsumed concepts are linked by the onto-and the subsuming concepts by an into rule. In languages that support disjunction, this basic propagation rule can be generalized to sub-sumption between a concept and a disjunction of other concepts in the following way:
It has been shown that this general propagation rule completely describes reasoning in DDLs that goes beyond well known methods for reasoning in Description Logics. To be more specific, adding the inference rule in Eq. 2 to existing tableaux reasoning methods leads to a correct and complete method for reasoning in DDLs. A corresponding result using a fixpoint operator is given in [30] . Based on these results, we can define a general inference rule for the case of modular ontologies in the following way: There are a number of consequences of this result for reasoning in modular ontologies.

Correctness and Completeness : From the basic propagation rule, we can see that subsumption between externally defined concepts follows from subsumption of their definitions in the (same) external module. This is because each external concept definition corresponds to an into and an onto rule between the concept name and its definition. The language we consider is SHIQ and therefore we have to consider the general propaga-tion rule because we have disjunction in our language. This means that it is not enough to simply check whether subsumption between the definitions of two externally defined concepts in the external module is com-plete, but we have to consider all subsets of the set of external concepts. We will discuss this point in more detail in the next section.

Complexity : As we reduce reasoning in modular ontologies to reasoning in DDLs with SHIQ as a local language, complexity results can be derived from known results on reasoning in SHIQ and Distributed Description Logics.
 Theorem 1 (Complexity). Reasoning in modular ontologies is Exp-Time Complete.

Proof. We show that reasoning in modular ontologies has the same complexity as reasoning in SHIQ . As rea-soning in SHIQ is Exp-Time Complete [33] , this establishes the result.  X  Reasoning in modular ontologies is at least as hard as reasoning in SHIQ : in the extreme case a modular ontology consists only of a single module without external concepts, thus reasoning in modular ontologies is equivalent to reasoning in SHIQ .  X  Reasoning in modular ontologies is not harder than reasoning in SHIQ because we reduce reasoning in modular ontologies to reasoning in DDLs. There exists a reduction of reasoning in DDLs with SHIQ as a local language to SHIQ [30] . Both reductions are linear in the size of the resulting terminology and there-fore do not change the complexity class.

This result shows that the complexity of reasoning in modular ontologies is not worse than reasoning in the web ontology language. Using the reduction of DDL to SHIQ it is even possible to use existing OWL reason-ers for reasoning with modular ontologies. Although practical implementations of OWL reasoners have shown that good average case performance can be achieved, the worst case complexity is still very high and asks for further optimization. 3.2. Compilation and integrity
Existing reasoners for expressive Description Logics are highly optimized with respect to deciding sub-sumption in the context of a single T-Box. Serafini and Tamilin present a distributed reasoning system that propagation rules described above and has X  X s we have argued X  X he same worst-case complexity. In prac-tice, however, reasoning with multiple, possible distributed modules, brings some new problems with respect to completeness and reasoning performance. First of all the completeness of the distributed reasoners depends on the availability of local reasoners for all T-Boxes in the system. In a loosely coupled network without central control this cannot always be guaranteed as network nodes can be unreachable or even leave the network. In this case, necessary subsumption tests cannot be performed at these nodes leading to a possible incompleteness. Another problem currently not addressed in the work of Serafini and Tamilin are performance problems due to communication costs between the different nodes in the system. Work in the area of distributed databases has shown that communication costs often become serious bottlenecks in distributed systems.

In order to overcome these problems we propose to compute subsumption relations between external con-reasoner mentioned above we have the guarantee that reasoning about subsumption in each module can be done without caring about the availability of other nodes in the network. This also has the advantage that no communication costs occur as part of online reasoning.

Of course these runtime benefits have their price in terms of computational complexity of the compilation step. The completeness of the propagation rule given in Eq. 2 tells us that to be independent from other mod-ules we only have to consider subsumption relations between externally defined concepts, as only such sub-sumption relations can be propagated from outside. What we have to check is subsumption between each external concept and the disjunction of all combinations of other external concepts. For a local module, this process is defined in Algorithm 1 .
 Algorithm 1. Compile
Require : An T-Box T with external concepts C E forall c 2 C E do end for
If we denote the number of external concepts C E as n , the worst-time complexity of the compilation method tional statement of the algorithm itself is already Exp-Time Complete and this test has to be carried out an exponential number of times with respect to the number of external concepts, compiling all implied statements is computationally very expensive. We therefore do not want to perform the compilation step more often than absolutely necessary to guarantee that local reasoning is still complete.

While the results of Serafini and others [34] guarantee that local reasoning is correct and complete at the time the compilation is carried out, a problem occurs when changes are made to the system. Changes in modules can make local reasoning incomplete or inconsistent. In order to prevent situations in which local reasoning is not correct and complete any more we introduce the notion of integrity of a modular ontology.
Definition 1 ( Integrity ). Let T  X  X f T i g i 2 I ; f B ij
I  X  X f I i g i 2 I ; f r ij g i 6  X  j 2 I  X  then we say that integrity holds for T if for all T
I i we have: for any pair of legal concept expressions C and D in T 0 i
The notion of integrity gives us a criterion for deciding whether compiled results are still valid. What the definition does not provide is an operational account for checking it. A direct use of the definition would involve a complete check of all derivable subsumption relations. As we have argued above this approach is ular ontologies that is driven by changes made to the ontology. The approach is capable of determining sit-uations in which changes to a modular ontology do not affect integrity and therefore no re-compilation is necessary. 4. Evolution management
As we have argued above, guaranteeing integrity of compiled subsumption relations is the main problem in modular ontologies. In principle, all compiled subsumption relations have to be recomputed to test whether pilation approach in terms of local reasoning and reduced complexity. Fortunately, we can do better than checking all compiled axioms each time we perform reasoning.

The first possible improvement is to move away from an active checking for changes towards a mechanism where each local module remembers and records changes made to it. We can also think of a system where individual modules actively notify other modules of changes to its local knowledge. This frees us from doing a complete check of the compiled knowledge and allows us to concentrate on these parts of the knowledge that actually were subject to changes.

The second improvement is in terms of an analysis of the impact a change in another module actually has on compiled knowledge. This is important as in real-world scenarios it turns out that a large part of the changes do not really affect the logical theory but are rather changes to the syntactic representation or changes in the naming of concepts and relations. While the latter have to be propagated to the definitions of the external concepts, they do not actually affect the compiled subsumption relations. Further, even if the logical theory underlying the ontology is affected by a change, this does not mean that it affects the com-piled subsumption relations. This means that we have to find ways to distinguish changes that do have an impact on compiled relations from those that do not have an impact. In fact, the choice to restrict the lan-guage admissible in the definitions of external concepts allows us to precisely characterize these kinds of changes.

In the following, we concentrate on the analysis of the impact of changes on the validity of compiled subsumption relations. We first give a characterization of harmless and harmful changes. Here harmless changes are those that do not have an effect on compiled subsumption relations. Harmful changes are changes that do have a potential influence on compiled knowledge. We present mechanisms for classi-fying changes as harmless or harmful based on a syntactic analysis of changes made to an ontology. Finally, we present a simple mechanism that uses this information to decide whether the knowledge in a module has to be re-compiled. 4.1. Determining harmless changes
As compiled knowledge reflects subsumption relations between a query concept and a disjunction of other query concepts a harmless change is a set of modifications to an ontology that does not change these subsump-subsumption relation between a query concept and a disjunction of other query concepts. It is quite obvious that a complete decision procedure for this problem has the same complexity as general subsumption reason-ing in the modular ontology and does therefore not improve the situation. For this reason, we propose a sound but incomplete method that abstracts from the detailed definition of concepts and uses the semantic relation between the old and the new version of a concept in the following way.
 The method considers every concept and relation in an ontology module that has been subject to a change.
Assuming that C represents the concept under consideration before and C are four ways in which the old version C may semantically relate to the new version C (1) the meaning of a concept is not changed: C C 0 (e.g. because the change was in another part of the (2) the meaning of a concept is changed in such a way that the concept becomes more general: C v C (3) the meaning of a concept is changed in such a way that the concept becomes more specific: C (4) the meaning of a concept is changed in such a way that there is no subsumption relationship between C
We can define the semantic relation between different versions of the same concept based on the set of pos-sible interpretations of the old and the new ontology in the following way.

Definition 2 ( Semantics of Change ). Let C and C 0 be two version of the same concepts in ontologies O and O respectively, then we say that C is more general than C 0 and for all x 2 D I we have I ; O x 2 C I implies I ; O 0 that C 0  X  C v C 0 ) if an only if for all possible interpretations I and for all x 2 D implies I ; O x 2 C I .
 semantic relations between the old and the new version of a concept influences compiled knowledge. In order to understand this influence, we have to look at the influence of changes on the interpretation of query con-nal ontology and implied changes to the query concepts using these concepts:
Lemma 1 (monotonicity of effect). Let C T j : Q an external concept expression. Let c  X  Q  X  be the set of all Analogously, a change of R has the same effect on Q.

Proof Sketch We prove lemma 1 by structural induction over expressions in the sublanguage defined in Sec-operator that the whole expression becomes more general (specific) if either a concept or a relation occurring in the expression becomes more general (specific). For conjunction and disjunction this directly follows from their correspondence to set operations on the interpretation domain. It remains to be shown that lemma 1 also  X  P nR : C  X  and C v C 0 this holds because all R-successors of C in C  X  P nr : C 0  X  I  X  P nr : C  X  0 I . Further, there are no R-successors in C the subsumption follows from the fact that there are less members of C that are potentially in the relation R with objects in Q 0 .

We can exploit this relation between the interpretation of external concepts and the concept names in their definitions in order to identify the effect of changes in the external ontology on the subsumption relations between different query concepts. First of all, the above result directly generalizes to multiple changes with the same effect, i.e. a query Q becomes more general (specific) or stays the same if none of the elements in c  X  Q  X [ r  X  Q  X  become more specific (general). Further, the subsumption relation between an external concept
C and the disjunction of other external concepts does not change if all concepts in the disjunction become more general or if the concept C becomes more specific. Combining these two observations, we derive the fol-lowing characterization of harmless change.

Theorem 2 (harmless change). Let C 0 T j : D 0 ; C 1 T j : D if:  X  X 0 v X for all X 2 c  X  D 0  X [ r  X  D 0  X  ,  X  X 0 w X for all X 2 c  X  D i  X [ r  X  D i  X  , i  X  1 ; ... ; m Note again that the implication does not hold in the opposite direction.

The theorem provides us with a correct but incomplete method for deciding whether a change is harm-less given that we know the semantic relation between the old and the new definition of concepts and relations that were subject to changes. This method is a very basic version of the underlying idea of assessing the impact of changes. We can think of more complete versions of the method that use a deeper analysis of the structure of the concept expressions involved. Our experiences are, however, that this basic heuristic already covers most cases that occur in practice, especially, because the definition above includes cases where most of the concepts stay unchanged. 4.2. Characterizing changes
Now that we are able to determine the consequence of changes in the concept hierarchy on the integrity of without having to do classification, we describe what theoretically could happen to a concept as result of a modification in the ontology. To do so, we have listed all possible change operations to an ontology according able to other knowledge models.

The list of change operations consists of two types of operations: (1) atomic change operations , such as ple atomic operations and/or incorporate some additional knowledge. Complex changes are often more use-ful to specify effects than the atomic changes, as they incorporate some of the semantic consequences. For example, for operations like concept moved up ,or domain enlarged , we can specify the effect more accurately than for the atomic operations superconcept changed and domain modified . at a structural level, i.e. by comparing the old and new definition of a concept, and are therefore compu-tationally cheap with a linear complexity. To identify complex changes, we also need to take some of the semantic relations in the ontology into account. This makes the complexity of the identification of complex changes potentially as bad as determining subsumption in SHIQ , i.e. Exp-Time Complete. However, in practice many complex changes can be detected at a structural level, e.g. by looking at explicitly stated sub-class relations.

Table 2 contains some examples of operations and their effect on the classification of concepts. The table only shows a few examples, although our full ontology of change operations contains around 120 operations.
This number is not fixed, as new complex changes can be defined. A snapshot of the change ontology can be and that for some operations the effect is  X  X  X nknown X  X  (i.e. unpredictable). If the method X  X  output is  X  X  X nknown X  X  this means that in order to determine the semantic relation between the two versions we would have to perform logical reasoning. In contrast to [37] who provide complete semantics of changes, we prefer to use heuristics in order to avoid expensive reasoning about the impact of changes. By restricting the change is linear. 4.3. Update management
With the elements that we described in this section, we now have a complete procedure to determine whether compiled knowledge in an ontology module is still valid when the external ontology modules are changed. The complete procedure is as follows. For each external concept C : (1) determine the changes that are performed in the external ontology (e.g. by using the record of changes); (2) heuristically determine the effect of the changes on the interpretation of the concepts and relations (3) create a list of all concept and relation names that occur in the external concept expression D for each (4) check whether all concepts and relations in this list remained unchanged or became more general; (5) create a list of all concept-and relation names that occur in the external concept expression D for each (6) check whether all concepts and relation in this list are unchanged or became more specific.
In cases where we cannot guarantee that integrity is preserved, we recompute and re-compile the implied subsumption statements. We thus restore integrity and make correct local reasoning possible. Algorithm 2. Update Require : Ontology Module M
Require : Ontology Module M j end for
We describe the procedure in a more structured way in Algorithm 2 . The algorithm triggers a (re-)compi-ously compiled knowledge is still valid. In principle, all the steps can be automated. A tool that helps to the list of change operations that is necessary to transform the one into the other.

The worst-time complexity of the update procedure once the effects of changes are known is linear in the number of concept and relation names occurring in compiled subsumption statements (in the worst case the effect of a change on every concept and relation name in the compiled axioms has to be checked).
In practice, we expect the number of compiled axioms to be relatively small leading to a quite efficient procedure. 5. Application in a case study
In order to support the claims made about the advantage of modular ontologies, we applied our model in a small case study that has been carried out in the course of the WonderWeb project. show that the update-management procedure presented in the last section can be used to avoid the computa-tion of subsumption relations in many cases. For this purpose, we defined a small example ontology using mappings to an ontology in the human resource (HR) domain. We used the changes that occurred in the HR ontology during the different steps of the case study and determined the impact on our example ontology.
Besides this, the case study provides us with examples of implied subsumption some of which are non-trivial but likely to occur in real-life situations. 5.1. The WonderWeb case study
WonderWeb is a EU/IST project that ran from 2002 till 2004. The aim of the project was to develop and demonstrate the infrastructure required for the large-scale deployment of ontologies as the foundation for the
Semantic Web. In the context of this project the Descriptive Ontology for Linguistic and Cognitive Engineering (DOLCE) [39] has been developed. DOLCE is the first module in a library of foundational ontologies. The ticipant X  X  and  X  X  X egion X  X . Fig. 1 shows the core part of the DOLCE ontology, the complete DOLCE ontology can be found online. 6
One of the roles of foundational ontologies in general and DOLCE in particular is to clarify hidden assumptions underlying existing ontologies or linguistic resources by manually mapping existing categories into the categories defined in the foundational ontology [40] . Inconsistencies in the combined ontology point to modeling errors or wrong assumptions in the original ontology. Solving the inconsistencies will improve the quality of the initial ontology. The methodology around DOLCE describes a three step procedure for map-ping existing ontologies to DOLCE: alignment, refinement and tidying.

The case study that has been carried out in the project integrates different methods in the life-cycle of an ontology that is used on the Semantic Web, i.e. ontology creation, ontology refinement and ontology deployment. The case study starts from an existing database schema in the human resource (HR) domain. matically converts a database schema into an ontology [41] . In the next phase, the quality of the ontology is improved by manually mapping this ontology to DOLCE. First, the HR ontology is aligned with DOLCE, and in several successive steps the resulting ontology is further refined. During this process, the ontology changes continuously, which causes problems when other ontologies refer to definitions in the evolving ontology.

The original HR ontology combined with DOLCE is referred to as the DOLCE + HR ontology. In order to demonstrate the update management procedure, we created another ontology (which we call the local ontol-ogy ) that uses terms and definitions from the evolving DOLCE + HR ontology (the external ontology ). The local ontology defines the concept FulltimeEmployee with a superconcept Employee and two subconcepts DepartmentMember and HeadOfDepartment , using terms from the DOLCE + HR ontology.

The specific problem in our case is that the changes in the DOLCE + HR ontology could affect the reason-ing in the local ontology. We want to be able to predict whether or not the reasoning in the local ontology is still valid for specific changes in the external ontology.

The evolution of the DOLCE + HR ontology consisted of several steps. Each of these steps involves some typical changes. We will briefly summarize them and show some changes that are typical for a specific step. In tions in the local ontology.  X  In the first step, the extracted HR ontology is aligned with the DOLCE foundational ontology, i.e. the con-cepts and roles in the HR ontology are connected to concepts and roles in the DOLCE ontology via sub-sumption relations. For example, the concept Departments from the HR ontology is made a subconcept of
Social-Unit in DOLCE.  X  The refinement step involves a lot of changes. Some role restrictions are added, and some additional con-cepts and roles are created to define the HR concepts more precisely. For example, the concept Adminis-trative-Unit is introduced as a new subconcept of Social-Unit , and the concept Departments is made a subconcept of it. Also, the range of the role email is restricted from Abstract-Region to its new subconcept Email and the range of manager-id is specialized by restricting its range from Employee to the subconcept
Manager .  X  In the next step, a number of concepts and roles are renamed to names that better reflect their meaning. For example, Departments is renamed to Department (singular), and the two different variants of the role man-ager-id are renamed to employee-manager and department-manager .  X  In the final step, the tidying step, all roles and concepts that are not necessary any more are removed and transformed into role restrictions. For example, the role employee-email is deleted from Employee and replaced by an existential restriction in the concept Person on the role abstract-location to the concept
Email . 5.2. Modularization in the case study
If we now consider the modularization in the case study, we have a local ontology with a concept hierarchy that is built up by the following explicitly stated subsumption relations:
This ontology introduces FulltimeEmployee as a new concept, not present in the case study ontology. Conse-quently, this concept is only defined in terms of its relation to other concepts in the local ontology. All other concepts are externally defined in terms of ontology based queries over the case study ontology.
The first external definition concerns the concept Employee that is equivalent to the Employee concept in the case study ontology. This can be defined by the following trivial view:
Another concept that is externally defined is the HeadOfDepartment concept. We define it to be the set of all instances that are in the range of the department-manager role. The definition of this view given below shows that our approach is flexible enough to define concepts in terms of relations
An example of a more complex external concept definition is the concept DepartmentMember , which is defined department-member role with a department 5.2.1. Implied subsumption relations
To allow for local reasoning, we need to determine the implied subsumption relations. If we now consider logical reasoning about these external definitions, we immediately see that the definition of Employee sub-sumes the definition of DepartmentMember , as the former occurs as part of the definition of the latter.
At a first glance, there is no relation between the definition of HeadOfDepartment and the two other state-ments as it does not use any of the concept or role names. However, when we use the background knowledge provided by the case study ontology we can derive some implied subsumption relations. The reasoning is as follows. Because the range of department-manager is set to Employee and the domain to Department , the def-inition of HeadOfDepartment is equivalent to:
As we further know that department-manager is a subrole of department-member , we can derive the following subsumption relation between the externally defined concepts:
Besides the subsumption relations between the external concepts themselves, we also need to determine the subsumption relations between the external concepts and the disjunction of all combinations of other external concepts. For our example, with HeadOfDepartment v DepartmentMember v Employee , this results in the fol-lowing relations:
When the relations (5) X (10) are added to the local ontology, it possible to do subsumption reasoning without having to access the DOLCE + HR ontology any more. 5.3. Updating the models
We will now illustrate that the conclusions of the procedure are correct by studying the impact of some
For the other changes, a similar analysis could be done. 5.3.1. Example 1: The employee concept
For the Employee concept, the last step resulted in the removal of the employee-email relation. Our rules tell us that this change makes the new version more general compared to its old version: According to our procedure, this should not be a problem because employee is in the  X  X  X ubsuming list X  X . When we analyze this change, we see that it has an impact on the definition of the concept Department-to a new definition of DepartmentMember with DepartmentMember v DepartmentMember
Member was already more general than HeadOfDepartment and the Employee concept is not used in the def-inition of the latter, the implied subsumption relation indeed still holds. 5.3.2. Example 2: The department-manager relation
In the second example, we have to deal with a change affecting a relation that is used in an external defi-a subconcept of Employee ) making it a subrelation of its previous version (i.e. more specific): According to our procedure, this change is harmful as department-manager is in the  X  X  X ubsuming list X  X . Calculation and an analysis proves that this change indeed has impact on the definition of the concept
HeadOfDepartment . Because the old version of the role department-manager is more general than the new of the department-member relation. Therefore, the implied subsumption relation HeadOfDepartment v DepartmentMember no longer holds. We have to recompute and compile the implied subsumption relations in order to guarantee integrity. 5.3.3. Example 3: The department concept For the Department concept, different changes happened. For example, it has been made a subconcept of
Social-Unit , it has been renamed from Departments and a relation has been removed. These changes have a contradictory effect, according to our heuristics, and as a consequence we cannot predict the relation between the old and the new versions. In this case our current heuristics leave us with no other option than recomput-ing the implied subsumption relations. 6. Summary
In this article, we discussed an infrastructure for the representation of and reasoning with modular ontol-ogies. The intention was to enhance the existing semantic web infrastructure with notions of modularization that have been proven useful in other areas of computer science, in particular in software engineering. We defined a set of requirements for modular ontologies that arise from expected benefits such as enhanced re-use and more efficient reasoning. Taking the requirements of loose coupling, self containment and integrity as a starting point, we defined a framework for modular ontologies providing the following contributions to the state of the art in ontology representation for the semantic web: (1) We presented a formal model for describing dependencies between different ontologies. We proposed (2) We compared our model with the existing standard, i.e. the web ontology language OWL and showed (3) We described a method for detecting changes in an ontology and for assessing their impact. The main 7. Discussion
There are three major questions connected to the approach for reasoning and managing change in modular above, we use a heuristic approach to tackle this problem, which raises the question about the adequacy of the heuristics used. We argued that we chose a trade-off that works well in the context of OWL and typical seman-of the approach. We discuss these three basic questions in the following. 7.1. Feasibility
Reasoning in modular ontologies is complex. We have shown that the complexity is essentially the same as for reasoning in Classical Description Logics which are the basis for OWL. We cannot escape this complexity, but we can move parts of the reasoning effort offline by compiling implied subsumption relations as described such computations are done  X  X vernight X  when the system load can be assumed to be low. An alternative for implied subsumption relations whenever they are computed in order to answer a user query to the system. This kind of  X  X azy compilation X  has the advantage that the enormous effort for compiling implied knowledge is done as part of the normal reasoning process. In the beginning, users will not benefit much from this approach, but the time savings increase with each query answered. In this way, we also prevent the compilation of knowledge that is never used.

The main problem connected with the compilation approach, which is also a central aspect of this paper, is the integrity of the compiled knowledge. In general compilation approaches only pay off if the computation time saved by being able to use compiled knowledge is not larger than the effort of updating the compiled knowledge. This means that compilation only makes sense in rather stable systems. In principle, we can assume that knowledge on the terminological level as it is represented in ontologies is normally more stable than instance data as normally found in databases. While changes to ontologies will occur less frequently they of the heuristics chosen. 7.2. Adequacy
Our method for detecting harmful changes is a conservative one. We basically identify changes that are obviously not harmful and refrain from updating when only such changes occurs. The criteria used for this purpose are rather weak as we do not consider the specific changes made to a concept but restrict our analysis to the semantic relation between the old and the new version of the concept definition. The advantage of this respect to the number of concept names involved. We further weaken the method by not actually computing the semantic relation between the old and the new version of the concept, but rather determine the relation based on a set of change operations determined by syntactic analysis. This method also constitutes an incom-plete heuristic as, for some changes, we cannot determine the relation between the old and the new version. without Description Logic reasoning.

The question that arises is whether the degree of incompleteness of our approach is justified. Currently sions, the library of change operations covers all possible change operations and most of them have a known effect that can be exploited in our approach. The cases in which the effect is not known can be assumed to be that a change is only harmless if all concepts and relations satisfy certain properties. This can certainly be changes in concepts that occur in both the subsumed and the subsuming concepts are not relevant due to the the subsumption proof and consider changes in other parts of the definitions as harmless as well. These improved heuristics still fit into the approach proposed and are subject of future work. For the time being, we conclude that the general mechanisms are in place and that the heuristic described in this paper already covers many relevant cases as we show in the examples from the WonderWeb case study. In principle, the siveness used in the models. 7.3. Generality
A final point for discussion is the generality of the approach described. Throughout this paper, we based our discussions on Description Logics as a representation language for ontologies, Distributed Description
Logics for providing the semantics of mappings as well as the equivalent of conjunctive queries for describing relations between different modules. All of these choices are carefully made and are motivated by practical as well as theoretical considerations. Probably the most uncontroversial choice is that of Description Logics for encoding ontologies. In the context of semantic web research, Description Logics have become the primary language for describing terminological knowledge mostly in terms of the Web Ontology Language OWL.
Our approach covers most of the expressiveness of OWL-DL with the exception of nominals. As a result, most existing OWL ontologies will fit in our framework and could easily be turned into modular ontologies by add-ing external concepts.

A choice that is less obvious is Distributed Description Logics as a basis for the semantics of mappings. In a recent survey, we compared different approaches for describing mapping semantics [42] . One result of this comparison was that Distributed Description Logics provide the highest degree of de-coupling between differ-ent T-Boxes. This is important for our purposes as we want to support localized reasoning. A generalization of afini and Ghididi [43] . We could have chosen this more general framework as the basis for our work, however, the drawback of this is the lack of existing reasoning methods. Distributed Description Logics come with a well investigated and implemented proof system that can be used to implement our approach.
The most controversial choice is to restrict the language that can be used to define external concepts. The framework of Distributed Description Logic allows us to use arbitrary SHIQ expressions in the definitions. A corresponding more general approach would have the same properties with respect to logical consequence, compilation and local reasoning. The restriction to the equivalent of conjunctive queries was motivated by the importance of the monotonicity property for the definition of update heuristics. This means that external concepts can be defined using a more expressive language. This, however, would come at the price that implied subsumption relations concerning this concept would have to be recomputed every time a change occurs. We also resembles view-based information integration, the dominant approach for describing mappings between database schemata.

References
