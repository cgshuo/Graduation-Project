 In the highly relational world of NLP, graphs are a natural way to represent relations and constraints among entities of interest. Even problems that are not obviously graph based can be effectively and productively encoded as a graph. Such an encoding will often be comprised of nodes, edges that repre-sent the relation, and weights on the edges that could be a metric or a probability-based value, and type information for the nodes and edges. Typed graphs are a frequently-used formalism in natural language problems including dependency parsing (McDonald et al., 2005), entity disambiguation (Minkov and Co-hen, 2007), and social networks to just mention a few.

In this paper, we consider the problem of iden-tifying a personal attribute such as ethnicity from only an observed first-name/last-name pair. This has important consequences in targeted advertising and personalization in social networks, and in gathering intelligence for business and government research. We propose a parametrized typed graph framework for this problem and perform the hidden attribute in-ference using random walks on typed graphs. We also propose a novel application of a gradient-free optimization technique based on grid search for pa-rameter estimation in typed graphs. Although, we describe this in the context of person-attribute learn-ing, the techniques are general enough to be applied to various typed graph based problems. Name ethnicity detection is a particularly challeng-ing (and practical) problem in Nigeria given that it has more than 250 ethnicities 1 with minor vari-ations. We constructed a dictionary of Nigerian names and their associated ethnicity by crawling baby name sites and other Nigerian diaspora web-sites (e.g. onlinenigeria.com) to compile a name dic-tionary of 1980 names with their ethnicity. We re-tained the top 4 ethnicities  X  Yoruba, Igbo, Efik Ibibio, and Benin Edo 2 . In addition we also crawled Facebook to identify Nigerians from different com-munities. There are more details to this dataset that will be made available with the data itself for future research. Consider a graph G = ( V,E ) , with edge set E de-fined on the vertices in V . A typed graph is one where every vertex v in V has an associated type t v  X  T V . Analogously, we also use edge types T
E  X  T V  X  T V . Some examples of typed edges and vertices used in this paper are shown in Table 1. These will be elaborated further in Section 4.
With every edge type t e  X  X  E we associate a real-valued parameter  X   X  [0 , 1] . Thus our graph is pa-rameterized by a set of parameters  X  with |  X  | = |T
E | . We will need to learn these parameters from the training data; more on this in Section 5. We re-lax the estimation problem by forcing the graph to be undirected. This effectively reduces the number of parameters by half.

We now have a weighted graph with a weight matrix W ( X ) . The probability transition matrix P ( X ) for the random walk is derived by noting P ( X ) = D ( X )  X  1 W ( X ) where D ( X ) is the diagonal weighted-degree matrix, i.e, d ii ( X ) = P j w ij ( X ) .
From this point on, we rely on standard label-propagation based semi-supervised classification techniques (Zhu et al., 2003; Baluja et al., 2008; Talukdar et al., 2008) that work by spreading proba-bility mass across the edges in the graph. While tra-ditional label propagation methods proceed by con-structing graphs using some kernel or arbitrary sim-ilarity measures, our method estimates the appro-priate weight matrix from training data using grid search. Our graphs have two kinds of nodes  X  nodes we want to classify  X  called target nodes and feature nodes which correspond to different feature types. Some of the target nodes can optionally have label infor-mation, these are called seed nodes and are excluded from evaluation. Every feature instance has its own node and an edge exists between a target node and a feature node if the target node instantiates the fea-ture. Features are not independent. For example the trigram aba also indicates the presence of the bi-grams ab and ba . We encode this relationship between features by adding typed edges. For in-stance, in the previous case, a typed edge (32BACK-OFF) is added between the trigram aba and the bi-gram ab representing the backoff relation. In the absence of these edges between features, our graph would have been bipartite. We experimented with three kinds of graphs for this task: First name/Last name (FN LN) graph As a first attempt, we only considered first and last names as features generated by a name. The name we wish to classify is treated as a target node. There are two typed relations 1) between the first and last name, called CONCURRENCE, where the first and last names occur together and 2) Where an edge, SHARED NAME, exists between two first (last) names if they share a last (first) name. Hence there are only two parameters to estimate here.
 Character Ngram graph The ethnicity of personal names are often indi-cated by morphophonemic features of the individ-ual X  X  given/first or family/last names. For exam-ple, the last names Polanski, Piotrowski, Soszyn-ski, Sikorski with the suffix ski indicate Polish de-scent. Instead of writing suffix rules, we generate character n-gram features from names ranging from bigrams to 5-grams and all orders in-between. We further distinguish n-grams that appear in the begin-ning (corresponding to prefixes), middle, and end (corresponding to suffixes). Thus the last name, mosun in the graph is connected to the follow-ing positional trigrams mos-BEG , osu-MID , sun-END besides positional n-grams of other or-ders. The positional trigram mos-BEG connected to the position-independent trigram mos using the typed edge POSITION. Further, the trigram mos is connected to the bigrams mo and os using a 32BACKOFF edge. The resulting graph has four typed relations  X  32BACKOFF, 43BACKOFF, 45BACKOFF, and POSITION  X  and four corre-sponding parameters to be estimated.
 Combined graph Finally, we consider the union of the character n-gram graph and the FirstName-LastName graph. Ta-ble 2 lists some summary statistics for the various graphs. The typed graph we constructed in the previous sec-tion has as many parameters as the number of edge types, i.e, |  X  | = |T E | . We further constrain the val-ues taken by the parameters to be in the range [0 , 1] . Note that there is no loss of representation in doing so, as arbitrary real-valued weights on edges can be normalized to the range [0 , 1] . Our objective is to find a set of values for  X  that maximizes the classi-fication accuracy. Towards that effect, we quantize the range [0 , 1] into k equally sized bins and con-vert this to a discrete-valued optimization problem. While this is an approximation, our experience finds that relative values of the various  X  i  X   X  are more important than the absolute values for label propa-gation.

The complexity of this search procedure is O ( k n ) for k bins and n parameters. For problems with small number of parameters, like ours ( n = 4 or n = 2 depending on the graph model), and with fewer bins this search is still tractable although com-putationally expensive. We set k = 4 ; this results in 256 combinations to be searched at most and we evaluate each combination in parallel on a cluster. Clearly, this exhaustive search works only for prob-lems with few parameters. However, grid search can still be used in problems with large number of edge types using one of the following two techniques: 1) Randomly sample with replacement from a Dirichlet distribution with same order as the number of bins. Evaluate using parameter values from each sample on the development set. Select the parameter values that result in highest accuracy on the development set from a large number of samples. 2) Perform a coarse grained search first using a small k on the range [0 , 1] and use that result to shrink the search range. Perform grid search again on this smaller range. We simply search exhaustively given the na-ture of our problem. We evaluated our three different model variants un-der two settings: 1) When only a weak prior from the dictionary data is present; we call this  X  X ut-of-domain X  since we don X  X  use any labels from Face-book and 2) when both the dictionary prior and some labels from the Facebook data is present; we call this  X  X n-domain X . The results are reported using 10-fold cross-validation. In addition to the proposed typed graph models, we show results from a smoothed-Na  X   X ve Bayes implementation and two standard base-lines 1) where labels are assigned uniformly at ran-dom ( UNIFORM ) and 2) where labels are assigned according the empirical prior distribution ( PRIOR ). The baseline accuracies are shown in Table 3.
We performed similar in-domain and out-of-domain experiments for each of the graph models proposed in Section 4 and list the results in Table 4, without using grid search.
 Some points to note about the results reported in Table 4: 1) These results were obtained without us-ing parameters from the grid search based optimiza-tion. 2) The character n-gram graph model performs better than the first-name/last-name graph model by itself, as expected due to the smoothing induced by the backoff edge types. 3) The combination of first-name/last-name graph and the n-gram improves ac-curacy by over 30%.

Table 5 reports results from using parameters es-timated using grid search. The parameter estimation was done on a development set that was not used in the 10-fold cross-validation results reported in the table. Observe that the parameters estimated via grid search always improved performance of label prop-agation.
 We considered the problem of learning a person X  X  ethnicity from his/her name as an inference prob-lem over typed graphs, where the edges represent la-beled relations between features that are parameter-ized by the edge types. We developed a framework for parameter estimation on different constructions of typed graphs for this problem using a gradient-free optimization method based on grid search. We also proposed alternatives to scale up grid search for large problem instances. Our results show a sig-nificant performance improvement over the baseline and this performance is further improved by param-eter estimation resulting over 30% improvement in accuracy using the conjunction of techniques pro-posed for the task.

