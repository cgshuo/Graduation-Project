
Xiaolong Tang 1 , 2 ,XinWang 1 , 2 , , Zhiyong Feng 1 , 2 , and Longxiang Jiang 1 , 2 The Resource Description Framework (RDF)[1] is a standard data model for describing the Semantic Web whose goal is making the information machine-readable. Linked Data[3] refers to graph-structured data that encoded in RDF and accessible via Hypertext Transfer P rotocol (HTTP). In recent years, with the development of Linked Data, the researchers focus on constructing semantic search engines to access more accurate kn owledge by taking advantage of the graph structure of Linked Data. However, the realization of the semantic search engine implies two major challenges: the system must scale to large amount of data and the search on Linked Data must be efficient and accurate.
 A number of semantic search engines have been developed in past few years. But our survey on these semantic search engines reveals that although they im-prove the traditional IR technologies, a lot of vulnerabilities lie in these systems. For example, some of them[2,4,5] are not suitable for naive users who are not necessarily proficient in the semantic data and the structured query language. The others[9,13,14,8,10] have considered the importance of user-friendly, but the accuracy of their query results is at a low-level.

In order to address aforementioned issues, we present a distributed semantic keyword search approach, which can provide an efficient and accurate search on Linked Data. Our work can be regarded as an extension to the traditional IR prob-abilistic retrieval model. More specifically, the main contributions of this paper include:  X  A distributed inverted index scheme is proposed for Linked Data. And based  X  We devise a new ranking algorithm, called OntRank, which is designed to im- X  We perform comprehensive experiment s to demonstrate th e performances of The rest of the paper is organized as fo llows: Section 2 reviews related work. Section 3 describes the distributed inverted index schemes which are built from the RDF data and the ontology. The OntRank algorithm, which contains the semantic factor, will be proposed in Sect ion 4. Section 5 reports the experimental results. In Section 6, we conclude and outlook the future work. Since Semantic Web develops rapidly in recent years, users look forward to mak-ing full use of the large amount of RDF data. For this purpose, lots of semantic search engines have been developed. Mo st of them are constructed based on the RDF query language, such as[2,4]. The characteristic of these search engines is that they provide a very complex structured query language, such as SPARQL[6] and SeRQL[11], to support RDF data accessing. However, they do not support keyword search on RDF data, so in order to access RDF data with these search engines, end users have to be quite familiar with the structure of RDF data and the syntax of structured query language.

To satisfy the requirements of ordinary end users, some keyword-based seman-tic search engines have been built. Currently, there are two main approaches on doing keyword search on RDF data: one of which uses the traditional IR tech-nologies, the other one converts the keywo rd query into the stru ctured query lan-guage. In the first approach, Semplore[8], K-Search[9] and Swoogle[10] combine the keyword retrieval with graph-stru ctured RDF data, then compute a ranked list for the semantic documents. SWSE[13] is also a semantic keyword search engine. The main difference between SW SE and the aforementioned search en-gines is that, it provides an entity-centric search on RDF data. But all of them only adopt the traditional IR technologies to build the inverted index from RDF data, and they do not consider the semantic that exists in the keyword queries. SemSearch[14] is an example of the second approach, it transforms a keyword search into a structured SeRQL[11] query based on finding the matches of the two parts of the keyword search. However, this method may lose a lot of necessary matches when the length of the keywords is more than two.
Our work is developed based on Jingwei system[15] and it is quite different from the aforementioned search engines. First, our inverted indexes are built both from RDF data and the ontology. Second, our method can recognize the semantics in the queries. In our system, the keyword query contains two parts, the main keywords and the auxiliary keywords, such as red apple @ banana .We get the semantics by checking the relations between the two kinds of keywords. Third, our approach can get more accurate results for the keyword queries ac-cording to the semantics. In this section, we will introduce two distributed inverted index schemes in our system, one of which is built from Linked Data, the other one is from the on-tology. And we refer to the inverted index constructed on the assertional part of Linked Data as A-index , and the inverted index on the terminological part as T-index . 3.1 Distributed A-Index Unlike traditional unstructured data, RDF data has no clear boundaries on documents. However, documents are the essential elements for inverted indexes, so we first give the definition of RDF documents .
 Definition 1. Assume that there are two disjoint infinite sets U and L, where U is the set of RDF URIs and L is the set of RDF literals. An RDF triple is a tuple of the form In this tuple, s is called the subject, p the predicate, and o the object. Definition 2. An RDF graph is a finite set of RDF triples. Let G be an RDF graph. 1) A subgraph of G is a subset of G. 2) subj(G) denotes the set of all subjects in G.
 Definition 3. Given an RDF graph G and a subject s  X  subj(G), an RDF docu-ment for s is a subgraph D s of G where subj( D s )= { s } .
 In Definition 3, we define the RDF documents as the collection of triples with the same subject , and the documents ID is s . From the traditional IR viewpoint, the documents have several fields, such as title, abstract and text, and each of them has different weights. Similarly, RDF documents also have the concept of fields, which is divided based on the meaning of p . Since BM25F[16], the variant of BM25, has considered the influence of fields in the ranking algorithm, we decide to devise our A-index on top of BM25F. To satisfy the BM25F ranking algorithm, we have divided RDF data into 4 fields, i.e. label, comment, type and others , and the information of the fields will be stored in A-index . Figure 1 shows Algorithm 1. Construction of A-index the structure of A-index , which is a 3-layer key-value structure, and the name of them are the row key (RK), the column name (CN), the column value (CV). In the design of A-index , we consider both efficiency and scalability, thus the MapReduce framework is adopted to build the index on top of Cassandra that is a distributed key-value NoSQL database. The constructing process of A-index is shown in Algorithm 1.

In the map phase, we only process the triple ( s,p,o )whose o is in L . In lines 3-9, we get the field ID and the document ID, for each term, and then emit them to the reduce function. And in the re duce phase, we first receive the term and document ID from map. Then in lines 11-15, we use a hash table to collect the detailed term frequency information, the key of the hash table is the field ID and the value is the corresponding term frequency. Line 16 inserts the term, the document ID and the hash table into the A-index . 3.2 Distributed T-Index Although the A-index can accomplish the mission of doing keyword search on RDF data, the semantics in RDF data is not exploited. Thus, we build the T-index as a supplement of the A-index by indexing the ontology. And in order to use the ontology conveniently, an ontology encoding scheme is also proposed. This section will introduce the expression of the ontology and the construction of the T-index in detail. 3.2.1 Ontology Encoding As we know, the ontology contains abundant semantics, which can be applied to express relations of entities. However, r ecognizing relations of entities is quite difficult if we directly store and use the ontology. In addition, the ontology is usually updated to enrich its semantics, so the management of the ontology will have a high cost. ORDPATH[7] is a hierarchical coding scheme whose ben-efits are two-fold. The first one is that the ORDPATH scheme allows insert-ing new nodes at arbitrary positions in the tree structure without relabeling any old nodes, so the update costs of ORDPATH will be at a low-level. The other one is that the code of ORDPATH can be compressed into a binary form which is easy for comparing ORDPATH values. In this way, we can recognize whether two nodes are child-parent nod es or sibling nodes by only compar-ing their binary code length. Obviously, ORDPATH is appropriate to ontology encoding, and the application of ORDPATH can represent the subsumption re-lationship appropriately. Thus, we adopt ORDPATH as the ontology encoding scheme.
 Example 1. In Fig. 2, G is a part of the tree structure of entity classes which encoded with ORDPATHs. We can see that there are five layers from the root node owl:Thing to the leaf node Pine and the corresponding ORDPATHs code is under them. It is easy to identify the subsumption relationship of entity classes based on the comparison of ORDPATH. The code of Plant is 1.25.3, and we can infer that its ancient nodes is encoded with 1, 1.25, its sibling node is 1.25.5 and one of its children nodes is 1.25.3.75, the corresponding entity classes are owl:Thing, Creature, Animal and Tree . According to the insertion strategy of ORDPATH, we can insert new nodes 1.25.1 to the left of Plant and 1.25.7 to the right of Animal . In addition, we can also insert the nodes at arbitrary positions, such as the position between Plant and Animal , with an even integer. 1.25.4.1 is an example of sibling nodes between Plant and Animal , and we can see that the even integers do not count for ancestry: 1.25.4.1 is a child of 1.25. This property shows that ORDPATHs is scalable and the old nodes need not to be relabeled when we update ORDPATHs, so it has a high update performance. 3.2.2 T-index Architecture Definition 4. Given a set of all terms T, an RDF document D and an entity class C. t is an element of T, if the entity class of subj(D) is C and t is in D, then we call that t relates to the entity class C, which is expressed as t  X  C, and we use class(t) to express the set of entity classes that relate to t. For T i thatisasubsetofT,ift  X  Candt  X  T i ,wecall T i  X  C. We define CLASS( T i ) as the set of all the entity classes that relate to t i in T i , and CLASS( T i )= 5 Since each s has at least one entity class and the relation between the entity classes can describe the relation betw een the corresponding subjects, we con-sider that a similar correlation exists between the terms of RDF documents and entity classes. Thus, we decide to construct the T-index according to the rela-tion between terms and entity classes, which is defined in Definition 4. The index structure and the method for creating the T-index are like what we discussed in section 3.1. But a little difference betw een them is that the construction of the T-index has two mappers and two reducers. Algorithm 2 is the pseudo-code of building the T-index . The inputs are two files in DBpedia, where the o in the instance type is the type of the s and the o in the short abstract is the abstract of the s .

In the map phase of the first MapReduce, lines 2-7 identify which file the triple ( s,p,o ) belongs to, and then emit the s , o and an identifier to the reducer. Then in the corresponding reduce phase, lines 10-13 get the most accurate ORDPATH of the entity classes of the s ,when o is the type of s .Afterthat,weemitthe ORDPATHs and the abstracts of the same s as an intermediate file, which is the input of the second MapReduce job. And in the second MapReduce job, we first emit each term in the abstracts and the corresponding ORDPATHs in lines 20-22. Then lines 24-26 make a statistic on class ( t )foreachterm t ,which contains the ORDPATHs and the corresponding weights. Finally, we insert the terms, the ORDPATHs and the weights into the T-index . Algorithm 2. Construction of T-index Based on the indexes built in section 3, we propose an improved ranking algo-rithm, called OntRank, which take advantage of the relation between the data to improve the effectiveness of document ranking. 4.1 RO Calculation Definition 5. Given a set of entity classes C , the entity classes C 0 ,C 1 and C main keywords T 1  X  C 1 and the auxiliary keywords T 2  X  C 2 , the distance between C 1 and C 2 through C 0 is called RO(Rank Order), which reveal the relevance of T 1 and T 2 , and expressed as RO( C 1 , C 2 ). RO( T 1 , T 2 )isasetofRO( C i , C j ) that C i  X  CLASS ( T 1 ) and C j  X  CLASS ( T 2 ) .
 Algorithm 3. Calculating RO ( T 1 , T 2 ) In Definition 5, the main keywords and the auxiliary keywords are the two parts of our keyword query introduced in sectio n 2, and both of them are sets of terms, so they have the characteristics of Definition 4. Since the semantics in the queries is essential to our ranking algorithm, we define RO as the semantic factor which is calculated by the correlation of enti ty classes related to the keywords. The corresponding pseudo-code of calculating RO ( T 1 , T 2 ) is shown in Algorithm 3.
In Algorithm 3, we obtain the corresponding ORDPATHs of CLASS ( T 1 ) in line 1. To avoid too many classes related to the auxiliary keywords that may influence the query accuracy, line 2 gets the top-k correlative ORDPATHs based on the weights of ORDPATHs. Lines 3-14 calculate RO . Line 5 gets the minimum parent class of the chosen classes, such as A and B . Then in line 6, we calculate the min-imum path length between A and B . In case 1, the hash table RO ( T 1 , T 2 )donot have the element of RO ( A,* ), where * can be any ORDPATHs of setofOrdpathB , then we add RO ( A,B ) into the hash table as RO ( A,* ). In lines 10-12, although RO ( T 1 , T 2 ) have the element of RO ( A,* ), the minimum path length between A and B is less than RO ( A,* ), we update RO ( A,* ) with RO ( A,B ).
Obviously, the time complexity of Algorithm 3 is O ( | M | X | N | ), that | M | is the number of CLASS ( T 1 )and | N | is the number of top-kCLASS ( T 2 ). The main space cost is the storage of entity classes which related to keywords. Hence, the overall space complexity is O ( | M | + | N | ).
 Example 2. G (Fig.2) in section 3.2.1 is an example of entity classes which encoded with ORDPATHs. We suppose that CLASS ( T 1 )is { Poplar,Grass } and CLASS ( T 2 )is { Pine } . First, we get the shortest path between Poplar and Pine ,whichis Poplar-Tree-Pine ,so RO ( Poplar,Pine ) = 2, then we add it to RO ( T 1 , T 2 ). Similarly, we can also conclude RO ( Grass,Pine )=3when T 1  X  Grass 4.2 OntRank Algorithm Algorithm OntRank uses RO as the semantic factor to improve the effectiveness of the BM25F ranking function. In this section, a detailed description will be presented, which is about calculating the score of documents.

First of all, the BM25F ranking function should set several boost factors before calculating the score of documents. In our system, the boost factors are: label = 30.0, comment = 5.0, type = 10.0, others = 1.0. Moreover, BM25F also requires additional parameters, whose value is K 1 = 4.9, b label = 0.6, b comment = 0.5, b type = 0.5 and b others = 0.4. And in this paper, we use score BM 25 F ( Q, D )to express the score of the query which based on the BM25F ranking algorithm. So the score of the OntRank ranking algorithm is calculated by where RO is the concept defined in section 4.1.
 In our method, RO is a list of non-negative integers, and with the value of RO decreasing, the correlation between the main keywords and the auxiliary keywords becomes higher. Here, we use RO + 1 to avoid the condition that RO = 0. Moreover, it can be seen that RO +1 , the differences between neighboring values are that the value of RO improves more significantly wh en the relationship between the two kinds of keywords is getting closer. Meanwhile, the class of a returned document must be one of the classes related to the main keywords. It means that RO is also the relationship between returned documents and the auxiliary keywords. Thus, the score of documents can be distinguished clearly according to the different relevance levels of the documents and the auxiliary keywords. In this section, we describe our evaluation method on the proposed indexes and algorithms, and show the experimental results. Since the solutions mentioned in the INEX 2009 is designed for semi-structured data and up to now we have not found a open source semantic search engine for RDF data, we only compare our method with the BM25F model. 5.1 Setting All experiments are carried out by using a 4-nodes cluster as the underlying stor-age system. Each node has Intel Q8400 CPU and 8 GB memory. The operating system is Ubuntu 10.04. The database is Cassandra 0.8.1, and the Cassandra heap was set to 4GB. We use Apache Tomcat 7.0 as the Web server. 5.2 Dataset and Queries For the evaluation we use the DBpedia 3.7 dataset excluding pagelinks; each characteristic of the DBpedia dataset is listed in Table 1. Although we only use the DBpedia, our method is not optimized for the dataset. In other words, our method is general enough to be used for other datasets.

For the reasons that a) we adopt the INEX evaluation framework to provide a mean for evaluating the semantic keyword search approach b) Wikipedia is the source of the INEX collection. We have to preprocess the dataset that is build from the intersection of DBpedia and the INEX-Wikipedia collection[12]. The result is listed in Table 2.

The query set in our evaluation framework is taken from the INEX 2009 con-test. INEX2009 offers the judgments of 68 queries. Each query consists of three parts with the same topic: title, description and narrative. In our experiments we adjust the titles by adding the semantics of descriptions and narratives into them. In this way the query will be more expressive and fit better to the seman-tic search. The average length of the queries is around 4 words. However, not all the semantics of queries suit for the OntRank algorithm, we take 50 of them as the final query set.

We take the IR metrics as the evaluation criterion. These metrics are gener-ally oriented in two main directions: the ability to retrieve relevant documents and the ability to rank them properly. In our experiment, we use part of them: Mean Average Precision (MAP), which provides a single-figure measure of qual-ity across recall levels; Geometric Mean Average Precision (GMAP) that is a variant of MAP by using a geometric mean; Precision after K documents (P@K) which measures the precision after K documents have been retrieved; and R-Precision that measures the precision after R documents have been retrieved, where R is the total number of relevant documents for a query. 5.3 Results: Indexing Cost We performed an experiment on measuring the indexing cost with the increase of the number of nodes. The results are shown in Figure 3. Note that the index-ing cost of T-index is the total executing time of two MapReduce jobs. From the results, we observe that the time of c onstructing index will decrease by in-creasing the number of nodes. However , because of the information exchange between nodes, the downward trend of executing time are not linear. In addi-tion, the scalability of our system is also reflected in the results, the problem of the explosive growth of Linked Data ca n be resolved merely by increasing the computer numbers. 5.4 Results: Query Accuracy The query accuracy is measured by using a tool named trec eval[17].Thistoolis implemented for producing the IR metrics. Figure 4 shows the evaluation results obtained by two different methods, one is with OntRank and the other is only use the BM25F ranking function.

The results draw from the experiments show that the OntRank ranking al-gorithm is better than BM25F in every single measure, especially P@K. This is not surprising since we add the semantics into the queries, so the search system can return more relevant documents after K documents have been retrieved. We can see that OntRank obtains the best performance, although some of the IR criteria do not improve significantly, such as MAP, GMAP and R-Prec. We have analyzed the reason for it, and find that there are many factors restricting the improvement of the results: 1. The relevant documents of some querie s is about concepts, such as theories 2. Some entities do not have abstract, so some relevant documents may not be 3. There are some mistakes in the classification of DBpedia, for example, the en-
