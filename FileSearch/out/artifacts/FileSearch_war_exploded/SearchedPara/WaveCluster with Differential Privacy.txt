 WaveCluster is an important family of grid-based clustering algo-rithms that are capable of finding clusters of arbitrary shapes. In this paper, we investigate techniques to perform WaveCluster while ensuring differential privacy. Our goal is to develop a general tech-nique for achieving differential privacy on WaveCluster that ac-commodates different wavelet transforms. We show that straight-forward techniques based on synthetic data generation and intro-duction of random noise when quantizing the data, though gener-ally preserving the distribution of data, often introduce too much noise to preserve useful clusters. We then propose two optimized techniques, PrivTHR and PrivTHR EM , which can significantly re-duce data distortion during two key steps of WaveCluster: the quan-tization step and the significant grid identification step. We conduct extensive experiments based on four datasets that are particularly interesting in the context of clustering, and show that PrivTHR and PrivTHR EM achieve high utility when privacy budgets are properly allocated, conforming to our theoretical analysis.
 H.2.7 [ Database Administration ]: [Security, integrity, and protec-tion]; H.2.8 [ Database Applications ]: [Data mining] Data mining, Privacy Differential Privacy, Wavelet Transform, Clustering
Clustering is an important class of data analysis, which allows data analysts to gain valuable insights into data distribution when it is challenging to make hypotheses on raw data. Among vari-ous clustering techniques, a grid-based clustering algorithm called WaveCluster [33, 34] is famous for detecting clusters of arbitrary shapes. WaveCluster relies on wavelet transforms, a family of con-volutions with appropriate kernel functions, to convert data into a c  X  Figure 1: Inaccurate clustering result produced by Baseline . (a) shows the WaveCluster results on the original data and (b) shows the WaveCluster results of Baseline , which leverages the adaptive-grid [31] approach to generate the synthetic data. Points in different clusters are shown in different colors, and the points marked by red are considered as noises. transformed space, where the natural clusters in the data become more distinguishable.

In many data-analysis scenarios, when the data being analyzed contains personal information and the result of the analysis needs to be shared with the public or untrusted third parties, sensitive pri-vate information may be leaked, e.g., whether certain personal in-formation is stored in a database or has contributed to the analysis. For example, the participation of one record may causes two clus-ters to be merged as one in the WaveCluster results. Thus, merely from the number of clusters returned (rather than which data points belong to which cluster), an adversary may infer a user X  X  participa-tion. Due to such potential leak of private information, data holders may be reluctant to share the original data or data-analysis results with each other or with the public.

In this paper, we develop techniques to perform WaveCluster with differential privacy [12, 14]. Differential privacy provides a provable strong privacy guarantee that the output of a computation is insensitive to any particular individual. In other words, based on the output, an adversary has limited ability to make inference about whether an individual is present or absent in the dataset. Differen-tial privacy is often achieved by the perturbation of randomized al-gorithms, and the privacy level is controlled by a parameter called  X  X rivacy budget X . Intuitively, the privacy protection via differential privacy grows stronger as grows smaller.

WaveCluster provides a framework that allows any kind of wavelet transform to be plugged in for data transformation, such as the Haar transform [3] and Biorthogonal transform [26]. There are various wavelet transforms that are suitable for different types of applications, such as image compression and signal processing [4]. Plugged in different wavelet transforms, WaveCluster can leverage different properties of the data, such as frequency and location, for finding the dense regions as clusters. Thus, in this paper, we aim to develop a general technique for achieving differential privacy on WaveCluster that accommodates different wavelet transforms.
We first consider a general technique, Baseline , that adapts exist-ing differentially private data-publishing techniques to WaveClus-ter through synthetic data generation. Specifically, we could gener-ate synthetic data based on any data model of the original data that is published through differential privacy, and then apply WaveClus-ter using any wavelet transform over the synthetic data. Baseline seems particularly promising as many effective differentially pri-vate data-publishing techniques have been proposed in the litera-ture, all of which strive to preserve some important properties of the original data. Therefore, hopefully the  X  X hape X  of the original data is also preserved in the synthetic data, and consequently could be discovered by WaveCluster. Unfortunately, this synthetic data-generation technique often cannot produce accurate results, and the reasons are as follows. Differentially private data-publishing techniques such as spatial decompositions [10], adaptive-grid [31], and Privelet [37], output noisy descriptions of the data distribution and often contain negative counts for sparse partitions due to ran-dom noise. These negative counts do not affect the accuracy of large range queries (which is often one of the main utility mea-sures in private data publishing) since zero-mean noise distribution smooths the effect of negative counts. However, in the synthetic dataset, negative counts cannot be smoothed away, which are typ-ically set to zero counts. Thus, such synthetic data generation sig-nificantly distorts the data distribution and reduces the accuracy of the WaveCluster results, such as the example shown in Figure 1.
Motivated by the above challenge, we propose three techniques that enforce differential privacy on the key steps of WaveCluster, rather than relying on synthetic data generation. WaveCluster ac-cepts as input a set of data points in a multi-dimensional space, and consists of the following main steps. First, in the quantization step WaveCluster quantizes the multi-dimensional space by divid-ing the space into grids, and computes the count of the data points in each grid. These counts of grids form a count matrix M . Second, in the wavelet transform step WaveCluster applies a wavelet trans-form on the count matrix M to obtain the approximation of the multi-dimensional space. Third, in the significant grid identifica-tion step WaveCluster identifies significant grids based on the pre-defined density threshold. Fourth, in the cluster identification step WaveCluster outputs as clusters the connected components from these significant grids [21].

To enforce differential privacy on WaveCluster, we first propose a technique, PrivQT , that introduces Laplacian noise to the quan-tization step. However, such straightforward privacy enforcement cannot produce usable private WaveCluster results, since the noise introduced in this step significantly distorts the number of signifi-cant grids ( k ) in the output. To address this issue, we further pro-pose two techniques, PrivTHR and PrivTHR EM , which enforce dif-ferential privacy on both the quantization step and the significant grid identification step. These two techniques differ in how to ac-curately determine k 0 , the private version of k . To quantify the proposed techniques X  utility, we present theoretical bounds for k and the noise magnitude introduced in the quantization step, which allow a theoretical comparison between different techniques.
Traditionally, the effectiveness of WaveCluster is evaluated through visual inspection by human experts (i.e., visually determining whether the discovered clusters match those reflected in the user X  X  mind) [33, 34]. Unfortunately, visual inspection is not quantitative, and thus it is inappropriate to systematically compare the impact of different techniques through visual inspection. Generally, researchers use quantitative measures to assess the utility of differentially private results, such as relative or absolute errors for range queries and ac-curacy for classification. But there is no existing utility measures for density-based clustering algorithms with differential privacy.
To mitigate this problem, we propose two types of utility mea-sures. The first is to measure the dissimilarity between true and private WaveCluster results by measuring the differences of signif-icant grids and clusters, which correspond to the outputs of the two key steps (the significant grid identification and the cluster identi-fication) in WaveCluster. To more intuitively understand the use-fulness of discovered clusters, our second utility measure considers one concrete application of cluster analysis, i.e., to build a classifier based on discovered clusters, and then use that classifier to predict future data. Thus, the prediction accuracy of the classifier from one aspect reflects the actual utility of private WaveCluster.
To evaluate the proposed techniques, our experiments use four datasets containing different data shapes that are interesting in the context of clustering [1, 9]. Our results show that PrivTHR and PrivTHR EM achieve high utility for both types of utility measures, and are superior to Baseline and PrivQT . The results also indicate that PrivTHR and PrivTHR EM can accurately estimate k 0 when proper budgets are allocated in the quantization and significant grid iden-tification steps, which conforms to our theoretical analysis.
The syntactic approaches for privacy preserving clustering [18] is to output k -anonymous clusters. Friedman et al. [17] presented an algorithm to output k -anonymous clusters by using minimum spanning tree. Karakasidis et al. [22] created k -anonymous clus-ters by merging clusters so that each cluster contains at least k key values of the records. However, these approaches only satisfy syn-tactic privacy notions such as k-anonymity, and cannot provide for-mal guarantees of privacy as differential privacy.

In this work, our goal is to perform WaveCluster under differen-tial privacy. The focus of initial work on differential privacy [12 X  15, 23] concerned the theoretical proof of its feasibility on various data analysis tasks, e.g., histogram and logistic regression. More recent work has focused on practical applications of differential privacy for privacy-preserving data publishing. An approach pro-posed by Barak et al. [6] encoded marginals with Fourier coeffi-cients and then added noise to the released coefficients. Hay et al. [20] exploited consistency constraints to reduce noise for his-togram counts. Xiao et al. [37] proposed Privelet , using wavelet transforms to reduce noise for histogram counts. Cormode et al. [10] indexed data by kd -trees and quad -trees, building the noisy trees with effective budget allocation strategies. Qardaji et al. [31] pro-posed uniform-grid and adaptive-grid methods to derive appropri-ate partition granularity in differentially private synopsis publish-ing. Xu et al. [38] proposed the NoiseFirst and StructureFirst tech-niques for constructing optimal noisy histograms, using dynamic programming and Exponential mechanism. These differentially private data publishing techniques are specifically crafted for an-swering range queries. However, synthesizing the dataset and ap-plying WaveCluster on top of it often render WaveCluster results useless, since these techniques do not capture the essence of WaveClus-ter and introduce too much unnecessary noise.

Another important line of prior work focuses on integrating dif-ferential privacy into other practical data analysis tasks, such as regression analysis, model fitting, classification and etc. Chaud-huri et al. [7] proposed a differentially private regularized logistic regression algorithm that balances privacy with learnability. Zhang et al. [40] proposed a differentially private approach for logistic and linear regressions that involve perturbing the objective function of the regression model, rather than simply introducing noise into the results. Friedman et al. [16] incorporated differential privacy into several types of decision trees and subsequently demonstrated the tradeoff among privacy, accuracy and sample size. Using decision trees as an example application, Mohammed et al. [29] investigated a generalization-based algorithm for achieving differential privacy for classification problems.

Differentially private cluster analysis has also been studied in prior work. Zhang et al. [39] proposed differentially private model fitting based on genetic algorithms, with applications to k -means clustering. McSherry [27] introduced the PINQ framework, which has been applied to achieve differential privacy for k -means clus-tering using an iterative algorithm [36]. Nissim et al. [30] pro-posed the sample-aggregate framework that calibrates the noise magnitude according to the smooth sensitivity of a function. They showed that their framework can be applied to k -means clustering under the assumption that the dataset is well-separated. These re-search efforts primarily focus on centroid-based clustering, such as k -means, which is most suited for separating convex clusters and presents insufficient spatial information to detect clusters with complex shapes, e.g. concave shapes. In contrast to these research efforts, we propose techniques that enforce differential privacy on WaveCluster, which is not restricted to well-separated datasets, and can detect clusters with arbitrary shapes.
Differential privacy [12] is a recent privacy model, which guar-antees that an adversary cannot infer an individual X  X  presence in a dataset from the randomized output, despite having knowledge of all remaining individuals in the dataset.

D EFINITION 1. ( -differential privacy) : Given any pair of neigh-boring databases D and D 0 that differ only in one individual record, a randomized algorithm A is -differentially private iff for any S  X  Range ( A ) :
The parameter indicates the level of privacy, and we refer to it as the privacy budget . Appropriate allocation of the privacy budget for a computational process is important for reaching a favorable trade-off between privacy and utility. The most common strategy to achieve -differential privacy is to add noise to the output of a function. The magnitude of introduced noise is calibrated by the privacy budget and the sensitivity of the query function. The sen-sitivity of a query function is defined as the maximum difference between the outputs of the query function on any pair of neighbor-ing databases:
There are two common approaches for achieving -differential privacy: Laplace mechanism [14] and Exponential mechanism [28].
Laplace Mechanism : The output of a query function f is per-turbed by adding noise from the Laplace distribution with proba-bility density function f ( x | b ) = 1 2 b exp(  X  | x | b lowing randomized mechanism A l satisfies -differential privacy:
Exponential Mechanism : This mechanism returns an output that is close to the optimum, with respect to a quality function. A quality function q ( D,r ) assigns a score to all possible outputs r  X  R , where R is the output range of f , and better outputs receive higher scores. A randomized mechanism A e that outputs r  X  R with probability satisfies -differential privacy, where S ( q ) is the sensitivity of the quality function.

Differential privacy has two properties: sequential composition and parallel composition. Sequential composition is that given n independent randomized mechanisms A 1 ,A 2 ,...,A n where A ( 1  X  i  X  n ) satisfies i -differential privacy, a sequence of A the dataset D satisfies -differential privacy, where = P n Parallel composition is that given n independent randomized mech-anisms A 1 ,A 2 ,...,A n where A i ( 1  X  i  X  n ) satisfies -differential privacy, a sequence of A i over a set of disjoint data sets D -differential privacy.
WaveCluster is an algorithm developed by Sheikholeslami et al. [33, 34] for the purpose of clustering spatial data. It works by using a wavelet transform to detect the boundaries between clusters. A wavelet transform allows the algorithm to distinguish between ar-eas of high contrast (high frequency components) and areas of low contrast (low frequency components). The motivation behind this distinction is that within a cluster there should be low contrast and between clusters there should be an area of high contrast (the bor-der). WaveCluster has the following steps:
Quantization : Quantize the feature space into grids of a speci-fied size, creating a count matrix M .

Wavelet Transform : Apply a wavelet transform to the count matrix M , such as Haar transform [3] and Biorthogonal transform [26], and decompose M to the average subband that gives the approxi-mation of the count matrix ( W ) and the detail subband that has the information about the boundaries of clusters.

Significant Grid Identification : Identify the significant grids from the average subband W . WaveCluster constructs a sorted list L of the positive wavelet transformed values obtained from W and compute the p th percentile of the values in L . The values that are below the p th percentile of L are non-significant values, and their corresponding grids are considered as non-significant grids. The data points in the non-significant grids are considered as noise.
Cluster Identification : Identify clusters from the significant grids using connected component labeling algorithm [21] (two grids are connected if they are adjacent), map the clusters back to the orig-inal multi-dimensional space, and label the data points based on which cluster the data points reside in.

Parameters. WaveCluster has four parameters to specify: num _ grid ( g 1 ,g 2 ,...,g n ): the number of grids that the n -dimensional space is partitioned into along each dimension. For the brevity of description, we simply use g to refer to the partitions of the n -dimensional space ( g 1 ,g 2 ,...,g n ). densitythreshold ( p ): a percentage value p that specifies p % of the values in L are non-significant values. For ease of presentation, we use k = (1  X  p ) | L | to represent the top k values in L and their corresponding grids are considered as significant grids. level : a wavelet decomposition level, which indicates how many times a wavelet transform is applied. The larger the level is, the more approximate the result is. In our techniques, we set level to 1 since a smaller level value provides more accurate results [34]. wavelet : a wavelet transform to be applied. Haar transform [3] is one of the simplest wavelet transforms and widely used, which is computed by iterating difference and averaging between odd and even samples of a signal (or a sequence of data points). Other com-monly used wavelet transforms include Biorthogonal transform [26], Daubechies transform [11], and so on.
Motivating Scenario. Consider a scenario with two partici-pants: the data owner (e.g. hospitals) and the querier (e.g. data miner). The data owner holds raw data and has the legal obligation to protect individuals X  privacy while the querier is eager to obtain cluster analysis results for further exploration. The goal of our work is to enable the data owner to release cluster analysis results using WaveCluster while not compromising the privacy of any individ-ual. The data owner has a good knowledge of the raw data and it is not difficult for her to choose the appropriate parameters (e.g. num _ grid , densitythreshold ) for non-private WaveCluster. The parameters chosen for the non-private setting are directly used for the private setting, and thus the data owner does not need to infer another set of parameters for the private setting.

Problem Statement. Given a raw data set D , appropriate WaveClus-ter parameters for D and a privacy budget , our goal is to investi-gate an effective approach A such that A (1) satisfies -differential privacy, and (2) achieves high utility of the private WaveCluster results with regard to the utility metrics U .
In this section, we present four techniques for achieving differ-ential privacy on WaveCluster. A straightforward technique to achieve differential privacy on WaveCluster is as follows: (1) adapt an existing -differential pri-vacy preserving data publishing method to get the noisy descrip-tion of the data distribution, such as a set of contingency tables or a spatial decomposition tree [10, 31, 37, 38]; (2) generate a synthetic dataset according to the noisy description; (3) apply WaveCluster on the synthetic dataset. We refer to this technique as Baseline and its pseudocode can be found in [8].

Discussion. Baseline achieves differential privacy on WaveClus-ter through the achievement of differential privacy on data publish-ing. The adapted -differential privacy preserving data publishing method is designed for answering range queries. The noisy de-scriptions of the data distribution may contain negative counts for certain partitions since the noise distribution is Laplacian with zero mean. These negative counts do not affect the range query accuracy too much since zero-mean noise distribution smooths the effect of noise. However, when the method is used for generating a synthetic dataset, the noisy negative counts are reset as zero counts, causing the data distribution to change radically and further leading to the severe deviation in differentially private WaveCluster results.
To address the challenge faced by Baseline , we propose tech-niques that enforce differential privacy on the key steps of WaveClus-ter. Our first approach, called Private Quantization ( PrivQT ), in-troduces independent Laplacian noise in the quantization step to achieve differential privacy. In the quantization step, the data is di-vided into grids and the count matrix M is computed. To ensure differential privacy in this step, we rely on the Laplace mechanism that introduces independent Laplacian noise to M . Clearly, if we change one individual in the input data, such as adding, removing or modifying an individual, there is at most one change in one entry of M . According to the parallel composition property of differen-tial privacy, the noise amount introduced to each grid is Lap ( given a privacy budget . Since the following steps of WaveCluster Algorithm 1 PrivTHR 1: procedure PrivTHR ( D,g,p,w,, X  ) 10: end procedure 12: M = Quantization( D,g ) 13: W = WaveletTransform( M , w ) 14: | Z | = CountOfNonPos( W ) 17: end procedure are carried on using the differentially private count matrix M clusters derived from these steps are also differentially private. The pseudocode of PrivQT can be found in [8].

Discussion. Although PrivQT achieves differential privacy, the noisy count matrix M 0 significantly distorts the number of noisy positive values in M 0 and consequently the clustering results. As Laplacian distribution is symmetric and has zero-mean, approxi-mately half of the zero-count grids become noisy positive-count grids due to positive noise. These noisy positive-count grids may cause their corresponding wavelet transformed values in W become positive (depending on the targeted wavelet transform), which will inappropriately participate in the computation of k private version of k . Due to the significant distortion of k ity of PrivQT improves marginally even for a large privacy budget.
The limitation of PrivQT lies in the severe distortion of k Laplacian noise introduced into count matrix M 0 . To mitigate the distortion, we propose a technique, PrivTHR , which prunes a por-tion of noisy positive values in W 0 to refine the computation of k Algorithm 1 shows the pseudocode of PrivTHR .

PrivTHR first introduces random noise to the count matrix M , similar to PrivQT , and obtains a noisy count matrix M 0 (Line 2). PrivTHR then applies a wavelet transform on M 0 to obtain W (Line 3). W 0 is then turned into a list L 0 that keeps only posi-tive values and the values in L 0 is sorted in ascending order (Line 4). Thus, only the positive values in W 0 will be used for computing k based on the specified density threshold p . To reduce the distor-tion of k 0 , starting from the smallest noisy positive values in L PrivTHR discards the first | Z | 0 2 values (Line 6), where Z represents the non-positive (negative or zero) values in the W and | Z | noisy estimate of | Z | (Line 5). The reason why PrivTHR removes 2 values from L that approximately | Z | 2 non-positive values in W are turned into positive values due to the randomness of Laplacian noise. Since | Z | partially describes the data distribution and releasing | Z | with-out protection may leak private information, PrivTHR also intro-duces Laplacian noise to | Z | , ensuring the whole process correctly enforces differentially privacy (Lines 11-17). The noise introduced to | Z | depends on the wavelet transform used to compute W . For example, if we use Haar transform for n -dimensional data, a value in W is computed by applying average for two neighboring ele-ments along each dimension. Since any single change in the input only causes one entry of the count matrix M to change by 1, the change of M causes at maximum one value in W to change, and thus causes | Z | to change by 1 at maximum, i.e., the sensitivity of | Z | is 1 1 . Finally, PrivTHR obtains d 0 as the top k (Line 8), where any value in L 00 greater than d 0 is considered as a significant value, and applies the connected component labeling algorithm to identify clusters of significant grids (Line 9).
Budget Allocation. PrivTHR first introduces Laplacian noise in the quantization step using a privacy budget 1 =  X  , where 0 &lt;  X  &lt; 1 . In the significant grid identification step, PrivTHR fur-ther introduces Laplacian noise to | Z | using the remaining privacy budget 2 = (1  X   X  ) . Based on utility analysis in Section 5.2.2, should be allocated with a smaller amount of budget than 1 Our empirical results in Section 7 further show the impact of  X  on clustering accuracy.
Besides pruning noisy positive values in W 0 , we propose an al-ternative technique that employs Exponential mechanism for deriv-ing k 0 from the sorted list of L . Algorithm 2 shows the pseudocode of PrivTHR EM .
 PrivTHR EM first introduces Laplacian noise to the count matrix M , which is similar to PrivQT and PrivTHR . After that, we obtain a noisy count matrix M 0 (Line 2) and the corresponding W 0 Different from the previous two techniques that compute k W 0 , PrivTHR EM derives k 0 from W using Exponential mechanism (Lines 7-15). In this case, although the sorted list derived from W is severely distorted in PrivTHR EM , the derivation of k not affected by the distorted W 0 . Given sufficient privacy budget, k derived from W using Exponential mechanism is reasonably ac-curate, compared to the case when k 0 is derived from W 0
The quality function fed into the Exponential mechanism is [10]: where L represents the sorted positive values in W with Min and Max values (Line 10), and X represents the possible output space, i.e., all the possible values in the range of (0 ,Max ] . Given a W with m positive values and their relationships are W 1  X  W ...  X  W m , these m values divide the range (0 ,Max ] into m par-titions: (0 ,W m ] , ( W m ,W m  X  1 ] , ..., ( W 2 ,W 1 ] , and the ranks for these partitions are m , m  X  1 , ... , 2, 1. For any x  X  ( W its rank is rank ( W i ) . For example, if x  X  ( W 2 ,W 1 rank ( W 1 ) = 1 . Similar to PrivTHR , when using Haar trans-form, any single change in the input causes only one value in W to change. Thus, at maximum one value will be added into or re-moved from L , causing the outcome of q ( L,X ) to be changed by 1, i.e., the sensitivity of q ( L,X ) is 1 2 .

Plugging in the above quality function into Exponential mecha-nism, we obtain the following algorithm: for any value x  X  (0 ,Max ] , the Exponential mechanism (EM) returns x with probability
For other wavelet transforms that use circular convolutions, such as Biorthogonal transform, the sensitivity of | Z | depends on the count of positive values and the count of negative values in the matrix computed by the coefficient vector [26].
Similar to PrivTHR , for other wavelet transforms that use circu-lar convolutions, the sensitivity of q ( L,X ) depends on the count of positive values and the count of negative values in the matrix computed by the coefficient vector [26]. the values in a partition have the same probability to be chosen, a random value from the partition Pt i = ( W i  X  1 ,W i ] will be cho-sen with the probability proportional to | Pt i | X  exp (  X  In other words, once k 0 is chosen, PrivTHR EM further computes a uniform random value d 0 from Pt i (Line 13), and any value in L greater than d 0 is considered as a significant value.

Budget Allocation. Similar to PrivTHR , the privacy budget is split between two steps: introduction of Laplacian noise in quan-tization and obtaining k 0 using Exponential mechanism. Previous empirical experiments [10] on splitting budgets between obtaining noisy median and noisy counts suggest that, 30% vs. 70% bud-get allocation strategy performs best. Specifically, 70% of budget is allocated for obtaining noisy count matrix M 0 (Line 2) and the remaining budget is allocated for computing k 0 (Line 4). Algorithm 2 PrivTHR EM 6: end procedure 8: M = Quantization( D,g ) 9: W = WaveletTransform( M , w ) 10: L = ConvertToPosSortedArray( W ) 11: k = (1  X  p ) | L | 14: return d 0 15: end procedure
In this section, we present the privacy analysis and utility analy-sis of the proposed techniques PrivQT , PrivTHR and PrivTHR
PrivQT introduces independent Laplacian noise Lap ( 1 ) to grid counts, which are computed on disjoint datasets. According to the parallel composition property of differential privacy described in Section 3.1, the privacy cost depends only on the worst guarantee of all computations over disjoint datasets. Therefore, PrivQT is -differentially private.

PrivTHR splits privacy budget into two parts. First, for private quantization, adding Laplacian noise Lap ( 1  X  ) achieves strict  X  -differential privacy. The proof is same as PrivQT . Second, PrivTHR introduces Laplacian noise Lap ( 1 (1  X   X  ) ) to the true count of non-positive values in W , which achieves (1  X   X  ) -differential privacy. Using the composition property of differential privacy, PrivTHR achieves -differentially private since =  X  + (1  X   X  ) .

Similar to PrivTHR , PrivTHR EM has two steps of randomization: private quantization and obtaining k 0 . Private quantization achieves  X  -differential privacy according to Laplace mechanism and paral-lel composition property. Sampling k 0 by Exponential mechanism consumes budget of (1  X   X  ) , which achieves (1  X   X  ) -differential privacy. According to the composition property of differential pri-vacy, PrivTHR EM is -differentially private.
In this section, we present utility guarantees of PrivQT , PrivTHR and PrivTHR EM with theoretical analysis. In the private results of WaveCluster, PrivQT , PrivTHR and PrivTHR EM return a list of noisy significant grids. To quantify the utility of PrivQT , PrivTHR and PrivTHR EM , we consider finding significant grids whose wavelet transformed values surpass a threshold to be similar to finding the top-k frequent itemsets whose frequencies surpass a threshold. In significant grid identification, L is the list of positive wavelet trans-formed values from W sorted in ascending order, Z represents the set of non-positive values from W , and all the top-k values in L correspond to significant grids, where k = (1  X  p ) | L | .
We first provide the analysis of difference between k and k PrivQT . In PrivQT , the difference between k 0 and k depends on two factors: (1) a set of non-positive values in Z becoming noisy posi-tive, Z 0 p = { W 0 Z | W 0 Z = W Z + Noise,W Z  X  Z,W 0 Z W
Z is the noisy value of zero value in Z , and (2) a set of posi-tive values in L becoming noisy non-positive, L 0 n = { W W
L + Noise,W L  X  L,W 0 L  X  0 } , where W 0 L is the noisy value of positive value in L . That is, k 0 = (1  X  p )( | L | + | Z
Analysis of | Z 0 p | . In PrivQT , since we are adding Lap ( 1 ) noise to each grid count and the Haar transform computes the average from four adjacent grids, the noise added into a wavelet trans-formed value is the sum of four i.i.d. samples from the Laplace distribution. The sum of h i.i.d. Laplace distributions with mean 0 is the difference of two i.i.d. Gamma distributions [24], referred to as distribution T . Distribution T is a polynomial in | x | divided by e | x | , which is a symmetric function and thus the probability for distribution T to produce positive values is 1 2 . Thus, the events of values in Z adding positive noise from distribution T conform to the Binominal Distribution with parameters | Z | and 1 expected value is | Z | 2 .

Analysis of | L 0 n | . For L 0 n , each value is added the noise con-forming to the symmetric distribution T . The probability density function of | L 0 n | is f | L 0 f ( y &gt;  X  W i ) ,W i  X  L , and its expected value E [ | L f ( y  X  X  X  W i ) . E [ | L 0 n | ] is large when W i is small and there is lim-ited privacy budget. The datasets that are interesting for clustering always have high-density cluster centers and low-density cluster borders. Only those values corresponding to border grids are pos-sible to become noisy non-positive and the size of border grids is relatively small. Therefore, E [ | L 0 n | ] is a small constant. We refer to the value of | L 0 n | as  X  in the following analysis.
Analysis of k 0  X  k . In PrivQT , E [ k 0  X  k ] = (1  X  p )( For those datasets that are interesting in the context of clustering, | Z | is pretty large compared to the whole space since Z is used to separate different clusters. What is more, dense areas within clusters are typically larger than the space of cluster borders with low density, i.e.  X  is far smaller than | Z | 2 . In PrivQT , the difference between k 0  X  k , which increases false positive rate. In PrivTHR and PrivTHR EM , we use different strategies to minimize the difference between k 0 and k .

T HEOREM 1. In PrivQT with Haar transform, given 0 &lt;  X  &lt; value in L greater than W k 0 k + (1  X  p )(  X  1  X   X  ) , and (2) no values in L less than W are output, where k 0 max = k + (1  X  p )(  X  2  X   X  ) .

P ROOF . In PrivQT , k 0 = (1  X  p )( | L | + | Z 0 p | X  X  L follows Binominal distribution with parameters | Z | and 1 is noted as a small value  X  , k 0 follows the Binomial distribution and decides the number of values in L that become output. Let 1  X   X  = Pr ( k 0  X  k 0 min ) = Pr ( | Z 0 p | X   X  1 ) . As Pr ( | Z 1 -Pr ( | Z 0 p |  X   X  1 ) and Pr ( | Z 0 p |  X   X  1 )  X  e will suffice.

We can also derive the bound of  X  , i.e., the noise added to each value in L  X  Z based on  X  . For Haar wavelet transform, each value in L  X  Z is added the noise that is the sum of 4 Lapla-cian random variables divided by 2 (i.e., 4 Lap ( 1 in L  X  Z , let all 4( | L | + | Z | ) Laplacian random variables gen-erate noise within [  X   X  4 ,  X  4 ] . The probability that no Laplacian ran-dom variable X  value is outside [  X   X  4 ,  X  4 ] is 1  X  Pr ( A ) , where A is that at least one Laplacian random variable X  X  value is outside [  X  B i is that i th Laplacian random variable X  X  noise is outside [  X  and Pr ( B i ) = e  X   X  8 . Thus, we can derive that with at least the probability 1  X  4( | L | + | Z | ) e  X   X  8 , no Laplacian random variable X  value is outside [  X   X  4 ,  X  4 ] , and each value in L  X  Z has their noise amount within [  X   X  2 ,  X  2 ] . Let  X  = 4( | L | + | Z | ) e
Subclaim (1) can be derived based on (a) with probability at least 1  X   X  , k 0  X  k 0 min and (b) with probability at least 1  X   X  , the noise of each value in L being within [  X   X  2 ,  X  2 ] . Detailed proof can be found in [8]. Subclaim (1) requires both conditions (a) and (b) to hold, and thus the probability is at least (1  X   X  ) 2 .

Similar as k 0 min , we can derive the upper bound k 0 max  X  . Let 1  X   X  = Pr ( k 0  X  k 0 max ) = Pr ( | Z 0 p |  X   X  | Z p | follows Binomial distribution ( | Z | , 1 2 ) , which is symmetric with respect to | Z | 2 . Thus, the probability of sampling a value from the range [0 , X  2 ] is the same as sampling a value from the range [  X  , | Z | ] , and we have  X  2 = | Z | X   X  1 = | Z | 2 + constant  X  ,  X  2 = O ( | Z | 2 + q | Z | 2 ) will suffice.
Subclaim (2) can be proved based on (c) with probability at least 1  X   X  , k 0  X  k 0 max and (b) with probability at least 1  X   X  , the noise of each value in L being within [  X   X  2 ,  X  2 ] . As subclaim (2) requires both conditions (c) and (b) to hold, the probability is at least (1  X   X  ) 2 .

For other wavelet transforms that use circular convolutions, such as Biorthogonal transform, the derivation for the bounds of k  X  and  X  2 remains the same since | Z 0 p | following Binomial distribu-tion is independent of any wavelet transform being adapted. Thus, our framework is extensible to other wavelet transforms, and the bound of noise magnitude  X  depends on the amount of adjacent grid counts involved in computing a wavelet transformed value.
T HEOREM 2. In PrivTHR with Haar transform, given 0 &lt;  X  &lt; (1  X   X  ) 3 , (1) all values in L greater than W k 0 where k 0 min = k + (1  X  p )(  X  1  X   X   X  | Z | 2  X   X  ) , and (2) no values in L less than W k 0 max  X   X  are output, where k 0 max = k + (1  X  p )(  X  2  X   X   X  | Z | 2 +  X  ) .

P ROOF . In PrivTHR , we allocate 1 for private quantization and for obtaining | Z | 0 , which makes k 0 = (1  X  p )( | L | + | Z 2 + Lap ( has the noise amount within  X  . Let 1  X   X  = 1  X  e  X  2  X  we get  X  = 2 The proofs of  X  1 ,  X  2 ,  X  and subclaims (1) and (2) are the same as T
Difference between PrivTHR and PrivQT : PrivTHR removing 2  X   X  positive values from L guarantee than PrivQT . The reason is the difference between k k becomes O ( q | Z | 2 )  X  (  X  +  X  ) by T HEOREM s 4 and 5, where  X  is a small constant and  X  is small when sufficient budget is provided.
T HEOREM 3. In PrivTHR EM with Haar transform, given 0 &lt;  X  &lt; 1 , let  X  1 = | L | X  k  X  1 + 2 ability at least (1  X   X  ) 2 , (1) all values in L greater than W are output, where k 0 min = k  X   X  1 , and (2) no values in L less than W
P ROOF . In PrivTHR EM , we allocate 2 for deriving k 0 from W by employing Exponential Mechanism, a general method proposed in [28]. The probability of selecting a rank i is | Pt i | X  exp (  X  2 k | ) , where Pt i is the range ( W i  X  1 ,W i ] decided by the i  X  1 th and i th wavelet transformed values.

Let 1  X   X  be the probability of sampling a k 0 where k  X  k then For constant  X  ,  X  1 = O ( | L | X  k + 1
Let 1  X   X  be the probability of sampling a k 0 where k 0  X  k  X   X  then For constant  X  ,  X  2 = O ( k + 1 proof of  X  and subclaims (1) and (2) are the same as T HEOREM 4.

Analysis of PrivTHR and PrivTHR EM . By T HEOREM s 5 and 6, the accuracy for sampling k 0 in PrivTHR is dominated by 1 in PrivTHR EM the accuracy is dominated by 1 Depending on the data distribution, PrivTHR EM may present better or worse utility guarantee than PrivTHR : ln( | W k | | W PrivTHR EM becomes more sensitive to 2 than PrivTHR ; ln( ) becomes negative when | W k | | W guarantee for PrivTHR EM becomes better.
To quantitatively assess the utility of differentially private WaveClus-ter, we propose two types of measures for measuring the dissimi-larity between true and differentially private WaveCluster results. The first type, DSG C , measures the dissimilarity of the signifi-cant grids and the clusters between true and private results. The second type focuses on observing the usefulness of differentially private WaveCluster results for further data analysis. The reason is that a slight difference in the significant grids or clusters may cause a significant difference when using the WaveCluster results. In this paper, we choose a typical application of further data analy-sis: building a classifier from the clustering results to predict unla-beled data [19]. The classifier built from true WaveCluster results is called the true classifier clf t while the classifier built from differ-entially private WaveCluster results is called the private classifier clf p . To measure the dissimilarity between clf t and clf p pose two metrics: OCM and 2 CE .
DSG C considers the dissimilarities of significant grids and clus-ters. Assume that there are t clusters of true significant grids and s clusters of differentially private significant grids. t might not be equal to s , and the cluster labels in t true clusters and s private clus-ters are completely arbitrary. To accommodate these differences, we adopt the Hungarian method [25], a combinatorial optimization algorithm, to solve the matching problem between t true clusters and s private clusters while minimizing the matching difference.
When cluster C i matches to cluster C j , we define that the dis-tance d between cluster C i and cluster C j is max {| C i Consider a cluster C i = { g 1 ,g 3 ,g 5 } and a cluster C The distance d between clusters C i and C j is max {|{ g 3 = 2 . Given t true clusters, s private clusters, and t  X  s , a match-ing M t,s of t true clusters and s private clusters is a set of cluster pairs, where each private cluster is matched with a true cluster. We then define the cost of a matching ( M cost ) as the sum of all the distances between each cluster pair in the matching M t,s count of significant grids in the non-matched clusters: M
Here, i x and j y indicate the subscripts of clusters in a matched pair. | C z | represents the count of significant grids in the non-matched true clusters. Among all the possible matchings of clus-ters, we use the Hungarian method to find the optimal matching with the minimum M cost , and computed DSG C as:
Here T denotes the set of significant grids in the true WaveClus-ter results.
OCM and 2 CE measure the dissimilarity between clf t and clf p . We name this way of evaluation as  X  X lustering-first-then-classification X : given a set of unlabeled data points, we use a por-tion of the data points (e.g., 90%) to compute WaveCluster results, where each cluster is a set of significant grids. Using the significant grids with cluster labels as training data, we build classifiers clf and clf p , and use them to predict the classes for the remaining data points (e.g., 10%).

Dissimilarity of Classifiers based on Optimal Class Matching ( OCM ). OCM measures the dissimilarity between the two sets of classes predicted by clf t and clf p for the same test samples. We use L t to denote the set of classes predicted by clf denote the set of classes predicted by clf p . Since L t completely arbitrary, we exploit the Hungarian method to find the optimal matching between L t and L p .
 Assume that a class L t,i predicted by clf t is matched to a class L p,j predicted by clf p , forming a class pair. We compute the count of common test samples in the class L t,i and the class L (c) DS3 , g = 36, p = 23 (d) Gowalla , g = 80, p = 31 sum the common test samples in each class pair to compute CT : Here c 1 is the count of classes in L t and c 2 is the count of classes in L p , and we assume c 1  X  c 2 . Since there are many possible map-pings from the classes in L t to the classes in L p , we use the Hun-garian method to find the optimal mapping that maximizes CT . Based on CT and the total count of the test samples TT , we derive the dissimilarity OCM :
When the dissimilarity is smaller, the differentially private WaveClus-ter results are more similar to the true WaveCluster results and maintain high utility for classification use.

Dissimilarity of Classifiers based on 2-Combination Enumer-ation ( 2 CE ). 2 CE measures the dissimilarity between clf clf p based on relationships of every pair of test samples, i.e., whether two samples are in the same class. Essentially, given a pair of test samples A and B , we say A and B are classified consistently either (1) clf t ( A ) = clf t ( B ) and clf p ( A ) = clf clf t ( A ) 6 = clf t ( B ) and clf p ( A ) 6 = clf p ( B ) . 2 CE is the ratio of the count of test sample pairs that are not classified consistently over the total number of test sample pairs, which is the set of 2-combination of the test samples. 2 CE uses pairs of test samples to eliminate the need of finding the optimal matching between the classes predicted by clf t and clf p .
We evaluate the proposed techniques using three datasets that are widely used in previous clustering algorithms [1], and one large scale dataset derived from the check-in information in Gowalla geo-social networking website [9], which was used to evaluate grid-based clustering algorithms in [35].
In our experiments, we compare the performances of the four techniques, Baseline , PrivQT , PrivTHR , and PrivTHR EM four datasets using two types of measures proposed in Section 6. We use Haar transform as the wavelet transform and set the wavelet decomposition level to 1 for the four techniques. Baseline uses the adaptive-grid method [31] for synthetic data generation. The clas-sification algorithm used for measuring OCM and 2 CE is C4.5 decision tree algorithm [32]. We conduct experiments with privacy budgets ranging from 0.1 to 2.0; for each budget and each metric, we apply the techniques on each dataset for 10 times and compute their average performances. All experiments were conducted on a machine with Intel 2.67GHz CPU and 8GB RAM. https://snap.stanford.edu/data/loc-gowalla.html.

Datasets. The four clustering datasets contain different data shapes that are specially interesting for clustering. Figures 2 shows the WaveCluster results on the four datasets under certain param-eter settings of grid size g and density threshold p . Any two adja-cent clusters are marked with different colors. The points in red color are identified as noise, which fall into the non-significant grids. DS 1 is a dataset containing 15 Gaussian clusters in con-vex shapes. It contains 30000 data points. The center area of each cluster has higher density and is resistant to noise. However, the overlapped area of two adjacent clusters has lower density and is prone to be affected by noise, which might turn the correspond-ing non-significant grids into significant grids and further connect two separate clusters. DS 2 is a dataset with 3 spiral clusters. It contains 31200 data points. Some noisy significant grids are very likely to bridge the gap between adjacent spirals and merge them into one cluster. DS 3 is a data dataset with 5 various shapes of clusters, including concave shapes. It contains 31520 data points. There are two clusters that both contain two sub components and a narrow line-shape area that bridges those two sub components. The narrow bridging area has low density and might be turned into non-significant grids, causing a cluster to split into two clusters. Gowalla is the check-in dataset resembling the world map, which records time and location information of users X  check-ins. We use only the location information for evaluation. There are about 6.4M records. Such large size makes it infeasible to run experiments with C4.5 and Baseline due to memory constraints. Thus, similar to [31], we sampled 1M records from the dataset for evaluation.
We first measure the differences between the true k and private k s on each dataset with ranging from 0.1 to 2.0. Detailed results can be found in [8]. Our results show that for all datasets, when  X  are less than 4.7% on average, while the relative errors of k Baseline and PrivQT range from 32.2% to 150.5%. For example, in DS 2 , the true k is 144. When is 1, the average private k 141.0 ( 2 . 1% ) for PrivTHR and 142.8 ( 0 . 8% ) for PrivTHR Baseline and PrivQT obtain 284.0 ( 97 . 2% ) and 249.2 ( 73 . 1% ) for the average k 0 respectively. Note that | Z | is 241 in DS 2 , and the difference between the average k 0 and k is 105.2 for PrivQT , which is quite close to the theoretical bound (1  X  p ) | Z | 2 = 108 . 45 derived from our utility analysis in Section 5.2.1. When is 0.1, the k in PrivTHR EM deviates from k more significantly than the k PrivTHR , indicating that PrivTHR EM is more sensitive to than PrivTHR as discussed in Section 5.2.3. For example, in DS 2 , the average k 0 in PrivTHR EM is 82.8 ( 42 . 5% ) while the average k PrivTHR is 131.2 ( 8 . 9% ).
Figure 3 (a)-(d) show the results of DSG C for the four tech-niques when the privacy budget ranges from 0.1 to 2.0. As shown in the results, both PrivTHR and PrivTHR EM achieve smaller DSG values than Baseline and PrivQT on all four datasets for all bud-gets. The reason is that though the noisy significant grids gener-ated by Baseline and PrivQT may be similar to the true significant grids, these noisy significant grids result in very different shapes of clusters and thus a large value of DSG C , while PrivTHR and PrivTHR EM preserve more accurate cluster shapes. For example, in DS 3 , the narrow line-shape areas and the gap between two adja-cent clusters are sensitive to noise. If some noisy significant grids appear in these areas, two clusters may be merged into one; if some significant grids disappear due to noise, one cluster might be split into two. Such changes cause DSG C to increase significantly.
Unlike the other techniques, PrivQT benefits little from the in-creased privacy budgets. For PrivQT , the difference between k k in PrivQT is dominated by | Z | 2 . Increasing privacy budgets can only reduce noise magnitude and cannot smooth such difference.
Comparison to F-Measure Results. Clustering analysis usu-ally uses F-measure as a representative external validations to mea-sure the similarity between the ground truth (known class labels) and the clustering results [2]. In our experiments, we consider the true WaveCluster results as the ground truth. The detailed results can be found in [8]. Our results show that PrivQT and Baseline achieve high F-measure scores (more than 0.8) for almost all bud-gets in DS 1 , even though the private results produced by PrivQT and Baseline are quite different from the true results. For example, when = 0 . 1 , the private results of PrivQT and Baseline have more than 30 clusters while the true results have only 15 clusters. On the contrary, Figure 3 (a) shows that DSG C is able to clearly differ-entiate the performances of the four techniques. The reason is that unlike DSG C that allows only one-to-one mapping between true and private clusters, F-measure allows one-to-many or many-to-one mapping between true and private clusters. If the size of true clus-ters is larger than that of private clusters, F-measure allows many to one mapping, and vice versa. Thus, DSG C presents more strict evaluation than F-measure in computing similarity/dissimilarity.
Results of OCM . Figure 3 (e)-(h) show the results of OCM for the four techniques. As shown in the results, PrivTHR and PrivTHR EM achieve smaller OCM values than Baseline and PrivQT for all datasets when ranges from 0.5 to 2.0. When is greater than 0.5, the OCM values of PrivTHR and PrivTHR EM are less than 0.15 on DS 1 , DS 3 , and Gowalla , indicating the private clas-sifier clf p maintains highly similar prediction results as the true classifier clf t . On DS 2 that contains 3 spirals, PrivTHR maintains a very low OCM value ( &lt; 0.1) when is greater than 0.5 while PrivTHR has a slightly worse OCM value (ranging from 0.1 to 0.2). Such results show that PrivTHR EM is more resilient to noise for concave-shaped data than PrivTHR .

Results of 2 CE . Figure 3 (i)-(l) show the results of 2 CE for the four techniques. As shown in the results, PrivTHR and PrivTHR achieve smaller 2 CE values than Baseline and PrivQT for all datasets when ranges from 0.5 to 2.0.

In general, all four techniques exhibit similar trends of 2 CE as their trends in OCM . On DS 1 , all four techniques have very low 2 CE values ( &lt; 0.1) though their corresponding OCM values are much higher (ranging from 0.05 to 0.5). The reason is that 2 CE captures the relationships between data points while OCM focuses on the mappings of classes. If there are k test samples out of N total samples having different prediction results in the true and private results, 2 CE expresses the differences as C ( k, 2) + k ( N  X  k ) over the total combinations of test samples C ( N, 2) , while OCM expresses the differences as k over N . On DS 1 , the k test samples C ( k, 2) becomes close to 0. In this case, only k ( N  X  k ) matters in the computation of 2 CE . Given that C ( N, 2) is much larger than N and k ( N  X  k ) when N of DS 1 is about 30,000, 2 CE has a smaller value than OCM for measuring the differences, and thus is less sensitive to the noise on DS 1 .
 Budget Allocation for PrivTHR . Based on the utility analysis Section 5.2.2, 1 for private quantization affects the accuracy of  X  , and 2 for obtaining | Z | 0 affects the accuracy of  X  . As the constant factor of  X  , 8  X  , 2 better utility. We evaluate the values of DSG C of PrivTHR on DS 1 under different budget allocation strategies, ranging from 1% for to 99% for 1 . Based on the results, the budget allocation strategy with 90% for 1 and 10% for 2 performs the best. The results of other measures on DS 1 show the similar results, and the results of all the two types of measures on other datasets also show the similar results.
In this paper we have addressed the problem of cluster analysis with differential privacy. We take a well-known effective cluster-ing algorithm called WaveCluster, and propose several ways to in-troduce randomness in the computation of WaveCluster. We also devise several new quantitative measures for examining the dissim-ilarity between the non-private and differentially private results and the usefulness of differentially private results in classification. In the future, we will investigate under differential privacy other cate-gories of clustering algorithms, such as hierarchical clustering.
Acknowledgments. This work is supported in part by the Na-tional Science Foundation under the awards CNS-1314229. [1] Clustering datasets. http://cs.joensuu.fi/sipu/datasets/. [2] E. Achtert, S. Goldhofer, H.-P. Kriegel, E. Schubert, and [3] A. N. Akansu and R. A. Haddad. Multiresolution Signal [4] A. N. Akansu, W. A. Serdijn, and I. W. Selesnick. Emerging [5] N. Alon and J. H. Spencer. The Probabilistic Method . Wiley, [6] B. Barak, K. Chaudhuri, C. Dwork, S. Kale, F. McSherry, [7] K. Chaudhuri and C. Monteleoni. Privacy-preserving logistic [8] L. Chen, T. Yu, and R. Chirkova. Wavecluster with [9] E. Cho, S. A. Myers, and J. Leskovec. Friendship and [10] G. Cormode, C. Procopiuc, D. Srivastava, E. Shen, and T. Yu. [11] I. Daubechies. Ten Lectures on Wavelets . Society for [12] C. Dwork. Differential privacy: A survey of results. In [13] C. Dwork and J. Lei. Differential privacy and robust [14] C. Dwork, F. McSherry, K. Nissim, and A. Smith.
 [15] D. Feldman, A. Fiat, H. Kaplan, and K. Nissim. Private [16] A. Friedman and A. Schuster. Data mining with differential [17] A. Friedman, R. Wolff, and A. Schuster. Providing [18] B. C. M. Fung, K. Wang, R. Chen, and P. S. Yu.
 [19] P. Green, F. J. Carmone, and S. M. Smith. Multidimensional [20] M. Hay, V. Rastogi, G. Miklau, and D. Suciu. Boosting the [21] B. K. P. Horn. Robot Vision . The MIT Press, 1988. [22] A. Karakasidis and V. S. Verykios. Reference table based [23] S. P. Kasiviswanathan, H. K. Lee, K. Nissim, [24] S. Kotz, T. Kozubowski, and K. Podg X rski. The Laplace [25] H. W. Kuhn. Variants of the hungarian method for [26] S. G. Mallat. A Wavelet Tour of Signal Processing. Academic [27] F. McSherry. Privacy integrated queries: an extensible [28] F. McSherry and K. Talwar. Mechanism design via [29] N. Mohammed, R. Chen, B. C. Fung, and P. S. Yu.
 [30] K. Nissim, S. Raskhodnikova, and A. Smith. Smooth [31] W. H. Qardaji, W. Yang, and N. Li. Differentially private [32] J. R. Quinlan. C4.5: Programs for Machine Learning . [33] G. Sheikholeslami, S. Chatterjee, and A. Zhang.
 [34] G. Sheikholeslami, S. Chatterjee, and A. Zhang.
 [35] J. Shi, N. Mamoulis, D. Wu, and D. W. Cheung.
 [36] M. Winslett, Y. Yang, and Z. Zhang. Demonstration of [37] X. Xiao, G. Wang, and J. Gehrke. Differential privacy via [38] J. Xu, Z. Zhang, X. Xiao, Y. Yang, G. Yu, and M. Winslett. [39] J. Zhang, X. Xiao, Y. Yang, Z. Zhang, and M. Winslett. [40] J. Zhang, Z. Zhang, X. Xiao, Y. Yang, and M. Winslett.
