 Language boundary plays a significant role in human language acquisition. La n guage boundar y is a basic explicit feature of language unit, on which research is known as a basic research in linguistic 1 . In Chinese , different terms are used in d e scription of the wor d  X  ,  X  rhythm phrase  X  etc 2 . Different inner sentence units are defined for various applications in Natural Language Processing (NLP), like Chinese word segmentation, chunking, rhythm phrase recognition etc, which also require different computing methods.

Wit h the development of Internet , as to corpora construction, data scale is no lon g-er the main difficulty . With the improvement of hardware performance and distribu t-ed computing technology, algorithm barrier s decrease a lot. All these influ ence the NLP resear ch and attract considerable attentions to exploring methods of automat i-cally acquiring linguistic knowledge from raw corpus. [Sun, 2011] proposed the co n-cept of  X  NLP based on massive scale natural annotated corpora  X  and stated that Nat u-ral Language Proces s ing Based on Huge -scale Natura lly Annotated Corpora should be the future direction of NLP research 3 .

A natural sentence is made up of words, among which exist cohesion and trans i tion relation s . I n massive scale of corpora, these relations could be relie v ed by n atural a nnotations. Theory of Prefabricated Chunk, rooted in cognitive linguistic, states the existence of lots of directly used poly -word strings with solidification and prefabric a-tion. Combining the theory of Prefabricated Chunk with N atural A nnotat ion oriented NLP research, we put forward a new l anguage unit, define the solidified string s that frequent and stably appear in various contexts as  X  Natural Chunks  X  .

Natural c hunk is a kind of language unit observed from pragmatic level. N atural c hunk reco gnition aims to meet various application requirements on l a ngua ge boun d-aries within a united framework. B oundar ies  X  strength should be maintained , so as to support the further recognition of other language units  X  boundaries among a sentence. natural annotation in massive scale of corpora. This task contains 3 parts, namely natural annotation mining, natural chunk boundary modeling, and eva l uation. B y parameters modification, different chunking for one sentence could be approached. Existed rel a tive work shows that chunking based on natural annotation is feasible, and has pos i tive influences in Chinese computing. Natural a nnotation r esource consists of various resource data generated by users in all means, like web pages, forums, twitters, Wikipedia , etc. In the view of natural la n-guage processing (NLP), these data can be seen as partially tagged. A nd the natural a nnotations are quite worthy to be utilized .
 On its application in NLP, first, massive scale is the necessary condition to make Natural Annotation computing into play. Second, shallow processing is the basic tone of calculation on massive scale corpora . At last, professional linguist knowledge should not be refused in any case in analysis and processing 3 . Relative research es in Chinese word segmentation, rhythm phrase recognition, information extraction, social co m puting, sentiment analysis, text classificat ion and information retrieval ha ve came to appear in recent years.

Natural a nnotation s are rich of lexical information . Experimental and research r e-sults indicate that they can benefit language boundary recognition. L anguage boun d-ary recognition researches t ook advantage s of natural annotations are mainly about Chinese word segmentation and rhythm phrase recognition. [Rao etc,.2013] explored the lex i con knowledge containing by punctuations, Latin letters and Arabic number in small data set 4 . [Zhongguo Li et c,. 2009] used punctuation as segmentation fe a tures offering positive cases, increasing word segmentation performance of CRF model, especially for OOV (words Out Of Vocabulary) in BakeOff test 5 . [ Yuhang Yang etc,. 2008] research about Chinese term extracti on based on delimiter 6 . [Xing Li et c , . 2006] introduced punctuations as a important feature into hierarchical Chinese chunking 7 . [Thomas etc,. 2005] increased precision on Ch i nese -English sentence pair alignment by adding punctuation as feature 8 . [Qian Yil i etc,. 2008, Xun Endong etc,. 2005] pr o posed method of building rhyme structure binary tree, based on the feature of punctuation location. H igh precision was reached with low training cost 9 ,10 . [ Valentin etc., 2010] increased unsupervised chunking 5 perce nt with features of HTML tags (anchor, bold, italic and underline). P unctuations were also used in chunking 11 . [Valentin etc,. 2011 ; Weiwei Sun etc., 2011] merged punctuations into other traditional statistic features, resulting to better pe r formance in OO V 1 2,13 . 
In brief, Natural annotations are unconsciously annotated by users, which avoid the problem of tagging cost. With massive scale corpora , both explicit and implicit ann o-tation mining will partially conquer the difficulty in quality assurance and qu antity limit, benefitting various tasks in NLP. Theory of Prefabricated Chunk (PC), rooted in cognitive linguistic, states the exis t-ence of lots of directly used poly -word strings with solidification and prefabrication. Prefabricati on indicates that syntax generation and inner syntax analysis are not in need in the usage of PC each time. A natural sentence is made up of words, among which exist hierarchy and cohesion relations . With a massive scale of corpora, these properties could be relieved by the n atural annotations which richly contain boundary information , appear in a specific form of language uni t . T his language unit is defined as  X  Natural Chunk  X  .

Definition The language units that continuous stable and frequent appear with d istinctive boundary features i n massive scale corpus are  X  Natural Chunks  X  .
In Chinese , natural annotations like punctuations, Arabic numbers, Latin letters match the definition of n atural c hunk, and they are special ones.

Propert ies of  X  Natural Chunks  X  (a) I n tegrity ( inner cohesion ) . A n atural c hunk is a continuous string. Conventio n-(b) S tabl ilty . In massive scale corpora, frequently used in various contexts. (c) B oundary F eatures . Natural c hunks is strings with disti n ct boundar ie s . T he (d) Application Oriented. T he propert ies of n atural c hunks depend on the prope r-
Properties of  X  integrity  X  and  X  stab ility  X  are quite similar to the principles of Ch i-nese word segmentation. I f punctuations are used as Natural Annotation in recogn i-tion, chunks also often match rhyme structures in one sentence. Natural Chunking has advantages in Chinese language boundary computation , for it is no t bound with sy n-tactical rules as the others do , and also due to its unsupervised mining process in ma s-sive scale co r pora . The work in this section is consisted by three parts, namely the mining of n atural annotations with distinctive boundary information, the boundary modeling and eval u-ation. A ll these work are concentrating on the boundary computing of n atural c hunks. 4.1 Natural a nnotations with distinctive boundary informa tion We use BIC (Boundary Information Carrier) to signify n atural a nnotation s carr y ing distinctive boundary information expressed . Base on whether a BIC is in t u itive and easy to extract, c lassify BICs into explicit BICs and implicit BICs . A explicit BIC sh ould be intuitive and easy to extract. To be specific, Punctuation, line break, Arabic numbers and Latin letters are explicit BICs, because they are easy to be ident i fied and extract ed from Chinese sentences , since they do not belong to Chinese cha r acter s et and never associate with other Chinese characters as a word. Ex1 present how pun c-tuations and Arabic numbers separate the chunk out of a sentence .  X   X   X  (of) ,  X   X   X  (and) and  X   X  X  X   X  (confront) are implicit BICs. By the way, using explicit BICs to a c quire implicit BICs, is one of our studies in the future.

Ex.1 (a) ......  X   X  X  X  X  X  X  X  X   X   X  X  X  X  X  X  X  X  X  X ...... (b)  X   X  X  X   X   X  X  X  X  X  X  X  X  X  X  X  X  X ...... (c) ...... X  X  X  X  X  X  X  X  X  X  2293.08  X  X  X  X  4.55  X ...... (d)  X  X  X  X  X  X  X  X  X  X   X   X  X  X  X   X   X  X  X  X  X  X  X  X  X  X  X  (e)  X  X  X  X  X  X   X  X  X  X  X  X  X  X  X  X  X  X  X  [org]  X  X  X  ......

As subset of n atural annotations , BICs contain rich linguistic knowledge, inclu d ing shallow formats and pragmatic patterns etc. High coverage of various lingua ph e-nomena could be approached. B y iterations, more BICs especially implicit ones could be gained. Ex.3 shows how to gain a chunk  X   X  X  X  X  X  X  X  X  X   X  (tampering with fina n-cial accounts) in d) from  X   X  X  X  X  X   X  (reform and opening up) in a) by  X  X  X  X  X  X  (especially) in b) and  X   X  X  X  X  X  X   X  (by taking) in c). BIC mining, boundary strength computing and iteratio n strategy is critical in this part.

Ex.2 (a)  X  X  X  X   X   X  X  X  X  X  X  X  X   X  X  X  X  X  X  X  X  X ...... (b)  X   X  X  X  X   X  X  X  X  X  X  X  X  X  X   X  X  X  X  X  X  X  X  X ...... (c)  X  X  X  X  X   X  X  X  X  X  X   X  X  X  X  X  X  X  X  X  X  X ...... (d)  X  X  X  X  X  X  X  X   X  X  X  X  X  X  X  X  X   X   X  X  X  X  X  X  X  X  4.2 Natural c hunk boundary mod e ling informa tion in boundary modeling . O n the other hand, a n atural c hunk is stably and frequently used in massive scale corpora. I ts inner cohesion is another influ e ncing factor of boundary modeling. A natural chunk  X  s b oundary could be gained at the low point of inne r cohesion. I n brief, both inner cohesion and autonomy in co n text are import features in boundary mode l ing.

Similar with Chinese word segmentation, frequency, mutual information (MI), boundary entropy (BE) and accessor variety ( A I) are often used to descri be the coh e-sion and isolation of a  X  word  X  14 . [Hanshi Wang etc, 2011] proposed algorithm of  X  Evaluation -Segmentation -Adaption  X  merging boundary entropy, frequency and length , and obtained a segmentation after a convergence iteration pr o cess 1 5 .
Natural c hun k s are flexible in granularity . However within a specific application, a sentence has only one specific and rational natural chunk recognition result , m atching the needs of various application s by parameter adaption. B oundar y strength is nece s-sary informat ion in natural chunk recognition . A ny string s in a sentence, its isol a tion to be a natural chunk could also be described by boundary strength in boundary mo d-eling. W e will investigate the cohesion and isolation of n atural c hunk and its bound a-ry modeling co mbi n ing both. 4.3 Evaluation of n atural c hunk recognition N atural c hunk recognition , like Chinese word segmentation as well as rhythm reco g-ni tion , is a kind of re search on language boundary identification . But it should be pointed out that n atural c hunk recogn ition aims to gain a united framework for var i-ous kinds of language boundary recognition. Within the framework, b y modification of parameters and decoding strategies, different needs of applications in language boundaries should be matched . And further e va luations should also fit the a p plication needs.

To make it simple, Chinese lexicon is in natural small natural chunks solidified in pragmatics, while rhythm phrase can be viewed as natural chunks in coarse granula r-ity. From this point, fine natural chunkin g of small granularity for segmentation while coarse granularity for phrase recognition.

I f Chinese word segmentation is viewed as application context, parameter tuning can be realized comparing with tagged corpus, and made its chunking result close to the granularity of word. I ts test result would also be evaluated with the standard of word segmentation. S imilarly is the application context of rhyme phrase. 5.1 Corpus and Dataset In this paper, t he corpus in use is a massive scale balanced monoling ual corpus, co n-sisted of Beijing Language and Cultural University International R&amp;D Centre for Chinese Education. The corpus contains News (People Daily), Literature, Weibo (Chinese Tweeter, 3 months data) and Blog (3 months data), of total size 102.8 GB ( ASCII). Size of each part is shown in Table.1.
 5.2 Lexicon Knowledge in BICs
Punctuations are special n atural c hunks. In Chinese , punctuation is a close set and easy to recognize, carrying distinctive boundary information. A ll punctuations in the previously mentioned massive scale corpus are replaced by  X   X   X , and used as a se g-menta t ions  X  symbol and segment ed the co r pus.

The Modern Chinese Dictionary (5th version) ,  X  MCD5  X  for short , contains 62777 different Chinese word types . Substrings of 1 -3 characters and 4 -8 characters are e x-tracted from the segmented corpus mentioned above . Among them , over 96% words of MCD5 have be en covered. I n fact, [Rao Gaoqi etc, 2013] reported in the small data set of 350MB (ASCII), 87.84% words can be co v ered. Fig.1 shows the increasing of word coverage with pruning frequency 4 . By then , we can come to an conclusion th at explicit Natural annotations like punctuation in big data set richly contain language boundary knowledge.
 5.3 Word Segmentation Experiments with explicit B ICs C for short) or I i = 0 . S traightforwardly p( B i )=p( I i =1 ) 1 6 ,17 .

Assumption 1 Boundary strength (statistically indicates the probability for a character boundary being a word boundary) is only relative to the adjacent context. T herefore in massive corpus, the boundary information carried in BICs could highly cover various langua ge boundaries. Assumption 2 Boundary strength is positive correlated to the isolation of its co n-text, while negative correlated to the cohesion of i ts context.

According to the assumption that BICs richly contains boundary knowledge , co n-sidering p ositive correlation exists between boundary strength and its co -occur r ence frequ e ncy with the punctuations , while negative correlation exists between boundar y strength and its co -occurrence frequency of context in a massive scale corp us . H e nce hav ing f ( B i ) formulated as (4) in a context window of width 4 characters, within which  X   X   X  stands for any pun c tuation. T est set1 and 2 are extracted from People  X  s Daily (Jan. 1998). 5328 sentences from January (19.1 characters in average length) and 5328 sentences from December (19.3 characters in a verage length). 
Tuning point distinction is chosen as decodin g strategy. F or each character boun d-p ( I boundary B i ; or I i=0 and I i is not a word boundary.

Precision (P in short ) , Recall (R in short) and F -0.5 were used for evaluation. F -0.5 value combin es precision a nd recall , and it emphasize s precision . Th ey are defined as formula (3), (4) and (5). A denotes word boundaries by manual annotated , while N A is set A  X  s count. B denotes word boundaries tagged by our algorithm, and N B is the count of set B .

Why not F1? For the natural chunk recognition  X  s result  X  natural chunks might be somehow rough than the words. As a string  X  AB  X  is stably and fr e quently appear with BICs in a massive scale corpora, according to definition of nat u ral chunk, we might take  X  AB  X  as a na t ural chunk, however in segmentation, it might be take in the form of  X  A  X  and  X  B  X  . Since we are more interested in natural chunk recognition than rarely Chinese word s e g mentation, we  X  d prefer to take F -0.5 value than F -1.
BE, AV and MI are often used statistic features. W e build a baseline system, based on character entropy. Means of left entropy and right entropy are used as d e scription of boundary strength. 5.4 Results and Analysis Table.4 present s the result based on assumption 1 , and Table.5 shows the result of experiments based on assumption 2 . it is easy to observe that just by the boundary information contained in explicit BICs, tri -gram method could beat baseline system (nearly 18 percentages increased in both precision and F -0.5). Even if we a l ternate the corpus resource to Sina Blog (different type of writing to People X  s Daily), this a d-vantage changes little . By about 3 percentages in precision and 1 percentage in F -0.5 increas es .

Mentioned results suggest the effectiveness of the natural boundary computing in massive scale of corpus. I t is also easy to observe that stylistic difference influences little on boundary recog nize, that will benefit cross domain research. 
I f we valued 1 for the word boundary in golden standards and 0 for none word boundary. Boundary scoring is normalized by the division of the scoring of the whole se n tence. Fig.2 presents the boundary scoring of sentence  X   X  X  X  X  X  X  X  X  X  X  X  X  X  X  X   X  (Tow ards a new century which is full of hope) and its manual segmentation. An opt i-mal segment point could be found, and sentence will be split into two. Recursively pr o cessed by the same steps until the segmented strings match the expectation as a  X  word  X  . Fig. 3 is the binary segment tree formed in recursive process on the sentence . We could find strong isomorphism of our result with word segment a tion standard, and in some levels of binary segment tree, chunk boundaries can also match the rhyme structure of this sentence.

Ex.3 indicates the good performance in named entity recognition, especially in long senten ces, using punctuations and implicit BICs.  X  X  X   X  (and) ,  X   X   X  (for)  X   X   X   X  (and) ,  X   X   X  (of) etc. , are character s (single character word) with strong boundary strength . T hey are quite worthy to be used in boundary computing. As for futu r e work, it would be natural for r esearchers to enhance the implicit Natural Annotation utiliz a tion as well as modeling both cohesion and autonomy of a string .

Ex.3 Segmentation Examples (a)  X  X  X  X   X  X  X   X  X  X   X  X  X  X   X  X  X  X   X  X  X  X   X  X  X  X   X  X  X  X   X  X  X  X   X  X  X  (b)  X  X  X   X  X  X  X  X  X  X   X  X  X   X  X  X   X  X  X  X   X  X  X  X  X  X  X  X   X  X  X  X   X  (c)  X  X  X  X  X  X  X  X  X  X   X   X  X  X   X  X  X   X  X  X  X  (d)  X  X  X  X   X  X  X   X  X  X   X  X  X   X  X  X  X   X  X  X   X  X  X   X  X  X   X  X  X   X  X  X  X   X  X  X  X  X  A natural sentence is made up of words, among which exist cohesion and trans i tion relation s . I n massive scale of corpora, these relations c ould be relieved by utilizing the co -occurrence with n atural annotations in massive scale corpora . Theory of Prefabr i-cated Chunk (PC), rooted in cognitive linguistic, states the existence of lots of directly used poly -word strings with solidification and p refabrication. Combining this ph e-nomena and natural annotation oriented NLP research, we define that the  X  Natural Chunk  X  is the solid i fied, frequent string that stably collocate with various contexts.
Natural c hunk s are language units observed from pragmat ic level. N atural c hunk recognition aims to meet various application requirements on language boundaries in a united framework. Information of boundary strength should be contained, so that the further description on different boundaries from characters to sentence could be po s-sible. The task of Natural Chunk recognition is in fact the word boundary prediction based natural annotation in massive scale of corpora. This task contains 3 parts, namely natural annotation mining, chunk boundary modeling, and chun king evalu a-tion. B y parameters modification, different chunking for one sentence could be a p-proached. Existed work shows that chunking based on natural annotation is quite effective and has promising future. 
As for boundary prediction based on massive sca le of corpora, it is a new task serving other relative applications. I t is worth noting that, current work still ongoing. B oundary modeling combining isolation and inner cohesion, features selection and pruning criteria are all worthy task waiting to resea rch.

