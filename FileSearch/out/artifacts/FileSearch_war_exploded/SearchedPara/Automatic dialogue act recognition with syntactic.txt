 Abstract This work studies the usefulness of syntactic information in the context of automatic dialogue act recognition in Czech. Several pieces of evidence are presented in this work that support our claim that syntax might bring valuable information for dialogue act recognition. In particular, a parallel is drawn with the related domain of automatic punctuation generation and a set of syntactic features derived from a deep parse tree is further proposed and successfully used in a Czech dialogue act recognition system based on conditional random fields. We finally discuss the possible reasons why so few works have exploited this type of information before and propose future research directions to further progress in this area.
 Keywords Dialogue act Language model Sentence structure Speech act Speech recognition Syntax 1 Introduction 1.1 Definition Modelling and automatically identifying the structure of spontaneous dialogues is very important to better interpret and understand them. The precise modelling of dialogues is still an open issue, but several specific characteristics of dialogues have already been clearly identified. Dialogue Acts ( DAs ) are one of these characteristics.
Although the term  X  X  X ialogue acts X  X  that is commonly used nowadays has been defined by Austin ( 1962 ), a number of other seminal works have proposed very similar notions, including speech acts proposed by Searle ( 1969 ), conversational game moves introduced by Power ( 1979 ), adjacency pairs proposed by Schegloff ( 1968 , Sacks et al. 1974 ) or acts of communication in the plan-based approaches to understanding introduced by Litman et al. ( 1985 ), Kautz ( 1987 ), Carberry ( 1990 ). The theory of the dialogue acts has been further developed by Bunt ( 1994 ). The dialogue acts represent the meaning of an utterance in the context of a dialogue, where the context is divided into several types, with both global and local views: linguistic, semantic, physical, social and cognitive. Bunt also developed a multidimensional taxonomy of the dialogue acts, while David R. Traum developed the notion of speech acts in Traum ( 1999 ) with dialogue agents. A better overview of the notion of dialogue acts can be found in Stolcke ( 2000 ).

In this work, the dialogue act is seen as a function of an utterance, or its part, in the dialogue. For example, the function of a question is to request some information, while an answer shall provide this information.

Table 1 illustrates the dialogue acts that may occur in a dialogue between the passenger (P) and the agent (A) in a ticket reservation task. The corresponding dialogue act labels are also shown. Each utterance is labelled with a unique dialogue act. This example is taken from our Czech corpus (see Sect. 5.1 ).

Dialogue acts represent useful and relevant information for many applications, such as dialogue systems, machine translation, automatic speech recognition, topic tracking (Garner et al. 1996 ) or talking head animation. For instance, in dialogue systems, dialogue acts might be used to recognize the intention of the user and thus differentiate situations where the user is requesting some information from situations where the user is simply giving some information or backchannels. In the former case, the system has to react, while in the latter case, a system reaction may be perceived as intrusive. In the machine translation domain, recognizing dialogue acts may bring relevant cues to choose between alternative translations, as the adequate syntactic structure may depend on the user intention. Automatic recognition of dialogue acts may also be used to improve the word recognition accuracy of automatic speech recognition systems, as proposed for instance in Wright ( 1998 ), where a different language model is applied during recognition depending on the dialogue act. Finally, dialogue act recognition is a fundamental building block of any understanding system and typically completes semantic role labelling and semantic frame inference.

The usefulness of dialogue act recognition has thus been demonstrated in a number of large applicative systems, such as the VERBMOBIL (Alexandersson et al. 1997 ), NESPOLE (Lavie et al. 2006 ) and C-STAR (Blanchon and Boitet 2000 ) machine translation and dialogue systems that rely on dialogue act classification. 1.2 Objectives The main objective of this work is to propose and investigate the usefulness of syntactic features to improve dialogue act recognition in Czech. In previous works, we have first designed a baseline dialogue act recognition system for the Czech language that was based on generative models (Kra  X  l et al. 2005 ). Although reasonably good results have been obtained, this approach was limited because it only exploits the local context around any given word of the utterance. We then and include global features in the model that represent the sentence structure. One of these approaches consists in modelling the word position in the sentence as a random variable and integrating this variable in the generative model. Intuitively, this information is important for dialogue act recognition, as for instance, the word  X  X  X ho X  X  is often located at the beginning of sentences for questions and at other positions for declarative sentences. In the following, we propose a different approach to model such global information implicitly, via a conditional stochastic model. The second and most important contribution of this work concerns the design and exploitation of syntactic features for dialogue act recognition in Czech. As summarized in Sect. 2 , only a few types of features are generally used in the literature to automatically recognize dialogue acts: lexical, part-of-speech (POS) tags, dialogue history and prosody. Furthermore, word sequences are most of the time modelled by statistical n-gram models, which encode the relationship between words and dialogue acts only locally. While we have already shown the importance of global information such as word position in the utterance for dialogue act recognition, the current work goes beyond this type of information by investigating whether the conditional distribution of the target dialogue act depends on the syntactic structure of the utterance.

In the following section, we briefly review the state of the art about dialogue act recognition, with a focus on how syntactic information has already been considered for this task and for related tasks. In Sect. 3 , we propose and describe new syntactic features. The proposed model is described in Sect. 4 . The relative importance of each of these features is evaluated on a Czech dialogue corpus in Sect. 5 In the last section, we discuss these results and propose some future research directions. 2 Related work We will now briefly review the standard definitions of dialogue acts, the different types of models classically used for dialogue act recognition and the standard types of information used in such models. Then, we review and discuss the previous design of syntactic features for dialogue act recognition as well as in closely related domains.

Some generic sets of domain-independent dialogue acts have been proposed in the state-of-the-art and are now commonly used to create the baseline tag set for most types of applications. Hence, in Stolcke ( 2000 ), 42 DAs classes are defined for English, based on the discourse annotation and markup system of labelling (DAMSL) tag-set (Allen and Core 1997 ). The switchboard X  X AMSL tag-set (Jurafsky et al. 1997 ) (SWBD X  X AMSL) is an adaptation of DAMSL in the field of telephone conversations. The meeting recorder dialogue act (MRDA) tag-set (Dhillon and Carvey 2004 ) is another very popular tag-set, which is based on the SWBD X  X AMSL taxonomy. MRDA contains 11 general dialogue act labels and 39 specific labels. Finally, Jekat ( 1995 ) defines for German and Japanese 42 dialogue acts, with 18 dialogue acts at the illocutionary level, in the context of the VERBMOBIL corpus. The ISO standard 24617-2 for dialogue annotation has been published in 2012. DIT ?? 1 is a recent implementation of this standard. Because of the limited size of the available corpus, as well as several other technical reasons, these tag sets are frequently reduced by merging several tags together, so that the number of final actual generic tags is often about 10. Part of such typical generic dialogue acts, also referred to as speech acts, include for instance (Shriberg et al. 1998 ) statements, questions, backchannels, commands, agreements, appreciations as well as a broad  X  X  X iscellaneous X  X  class. In addition to such generic tags, application-specific tags may be defined, such as  X  X  X equest booking X  X  for a hotel booking application.

Manually annotating dialogue acts on every new corpus may be very costly and efforts have been put into developing semi-automatic methods for dialogue act tagging and discovery. Hence, the authors of Orkin and Roy ( 2010 ) propose a predictive paradigm where dialogue act models are first trained on a small-size corpus and used afterwards to predict future sentences or dialogue acts. In a related vein, unsupervised dialogue act tagging of unlabelled text has recently raised a lot of following on supervised approaches.

The dialogue act recognition task is often considered jointly with the segmentation task. We assume in our work that sentence segmentation is known, because we rather prefer to concentrate on the challenge of designing relevant syntactic features for dialogue act recognition. Yet, many related works propose powerful solutions for the segmentation task as well. In particular, the work described in Petukhova and Bunt ( 2011 ) considers the input text as a stream of words and segments and tags it incrementally with a BayesNet model with lexical, prosodic, timing and dialogue act-history features. Zimmermann et al. ( 2006 ) successfully use in for joint DA segmentation and classification hidden-event language models and a maximum entropy classifier. They use word sequence and pause duration as features. The authors of Dielmann and Renals ( 2008 ) exploit a Switching Dynamic Bayesian Network for segmentation, cascaded with a condi-tional random field for dialogue act classification, while Quarteroni et al. ( 2011 ) jointly segments and tags with a single model.

The dialogue act modelling schemes that are commonly used for dialogue act recognition are traditionally chosen from the same set of general machine learning methods used in most natural language processing tasks. These include Hidden Markov Models (Stolcke 2000 ), Bayesian Networks (Keizer and Nijholt 2002 ), Discriminative Dynamic Bayesian Networks (Ji and Bilmes 2005 ), BayesNet (Petukhova and Bunt 2011 ), memory-based (Lendvai and van den Bosch 2003 ) and transformation/based learning (Samuel et al. 1998 ), decision trees (Mast 1996 ), neural networks (Levin et al. 2003 ), but also more advanced approaches such as boosting (Tur et al. 2006 ), latent semantic analysis (Serafin and Di Eugenio 2004 ), hidden backoff models (Bilmes 2005 ), maximum entropy models (Ang et al. 2005 ), conditional random fields (CRFs) (Dielmann and Renals 2008 ; Quarteroni et al. 2011 ) and triangular-chain CRF (Jeong and Lee 2008 ).

Regarding features, most dialogue act recognition systems exploit both prosodic and lexical features. The dialogue history is also often used as relevant information. Some cue words and phrases can also serve as explicit indicators of dialogue structure (Webb 2010 ). For example, 88.4 % of the trigrams  X  X  h start i do you X  X  occur in English in yes / no questions (Jurafsky 1997 ).

Prosody is an important source of information for dialogue act recognition (Shriberg et al. 1998 ). For instance, prosodic models may help to capture the following typical features of some dialogue acts (Kompe 1997 ):  X  a falling intonation for most statements  X  a rising F0 contour for some questions (particularly for declaratives and yes/no  X  a continuation-rising F0 contour characterizes (prosodic) clause boundaries,
In Shriberg et al. ( 1998 ), the duration, pause, fundamental frequency (F0), energy and speaking rate prosodic attributes are modelled by a CART-style decision trees classifier. In Mast et al. ( 1996 ), prosody is used to segment utterances. The duration, pause, F0-contour and energy features are used in Wright ( 1998 ) and Wright et al. ( 1999 ). In both Wright ( 1998 ) and Wright et al. ( 1999 ), several features are computed based on these basic prosodic attributes, for example the max, min, mean and standard deviation of F0, the mean and standard deviation of the energy, the number of frames in utterance and the number of voiced frames. The features are computed on the whole sentence and also on the last 200 ms of each sentence. The authors conclude that the end of sentences carry the most important prosodic information for dialogue act recognition. Shriberg et al. ( 1998 ) show that it is better to use prosody for dialogue act recognition in three separate tasks, namely question detection, incomplete utterance detection and agreements detection, rather than for detecting all dialogue acts in one task.

Apart from prosodic and contextual lexical features, only a few works actually exploit syntactic relationships between words for dialogue act recognition. Some syntactic relations are captured by HMM word models, such as the widely-used n-grams (Stolcke 2000 ), but these approaches only capture local syntactic relations, while we consider next global syntactic trees. Most other works thus focus on morphosyntactic tags, as demonstrated for instance in Verbree et al. ( 2006 ), where a smart compression technique for feature selection is introduced. The authors use a rich feature set with POS-tags included and obtain with a decision tree classifier an accuracy of 89.27, 65.68 and 59.76 % respectively on the ICSI, Switchboard and on a selection of the AMI corpus. But while POS-tags are indeed related to syntax, they do not encode actual syntactic relations.

A very few number of works have nevertheless proposed some specific structured syntactic features, such as for instance the subject of verb type (Andernach 1996 ). The authors of Serafin and Di Eugenio ( 2004 ), Di Eugenio et al. ( 2010 ) exploit a few global syntactic features, in particular POS-tags and the MapTask SRule annotation that indicates the main structure of the utterance, i.e., declarative, imperative, inverted or Wh-question, but without obtaining a clear gain from syntax in their context, hence suggesting that further investigation is needed. Indeed, syntax is a very rich source of information and the potential impact of syntactic information highly depends on the chosen integration approach and experimental setup. We thus propose in the next section other types of syntactic features and a different model and show that syntax might indeed prove useful for dialogue act recognition in the proposed context. But let us first support our hypothesis by briefly reviewing a few other papers that also support the use of syntax for both dialogue act recognition and closely related domains.

First, as already shown, word n-grams features, with n &gt; 1, do implicitly encode local syntactic relations and are used successfully in most dialogue act recognition systems. But more importantly, a recent work (Klu  X  wer et al. 1944 ) concludes that both dialogue context and syntactic features dramatically improve dialogue act recognition, compared to words only, more precisely from an accuracy of 48.1 % up to 61.9 % when including context and 67.4 % when further including syntactic features. They use in their experiments a Bayesian Network model and their syntactic features are the syntactic class of the predicate, the list of arguments and the presence of a negation. Although this work actually focuses on predicate-argument structures, while our main objective is rather to exploit the full syntactic tree without taking into account any semantic-level information for now, this work supports our claim that syntactic information may prove important for dialogue act recognition. In addition, Zhou et al. ( 2009 ) employ in three levels of features: (1) word level (unigram, bigram and trigram), (2) syntax level [POS-tags and chunks recognized as base noun phrase (BNP)] and (3) restraint information (word position, utterance length, etc.). Syntactic and semantic relations are acquired by information extraction methods. They obtain 88 % of accuracy with a SVM classifier on a Chinese corpus and 65 % on the SWBD corpus.

We further investigated closely related domains that have already explored this research track in more depth. This is for instance the case of automatic classification of rhetorical relations, as reviewed in Sporleder and Lascarides ( 2008 ). Another very close task is punctuation recovery, which aims at generating punctuation marks in raw words sequences, as typically obtained from speech recognition systems. In particular, this implies to discriminate between questions (ending with a question mark), orders (ending with an exclamation points) and statements (ending with a period), which is a task that is obviously strongly correlated to dialogue act recognition. Interestingly enough, a richer set of syntactic features have been exploited in the punctuation recovery domain than in the dialogue act recognition area. Hence, the authors of Favre et al. ( 2009 ) design several syntactic features derived from the phrase structure trees and show that these features significantly reduce the detection errors. This is in line with our own previous conclusions published in Cerisara et al. ( 2011 ) regarding the use of syntactic features for punctuation recovery, where a large improvement in performances is obtained thanks to syntactic information derived from dependency trees. Similar gains are obtained on a Chinese punctuation task (Guo et al. 2010 ), where including rich syntactic features, such as the word grammatical function, its ancestors and children, its head, the yield of the constituent or subtree border indicators, improve the F-measure from 52.61 % up to 74.04 %.

Finally, we have shown that there is an increasing amount of work that successfully exploits structural syntactic dependencies both for dialogue act recognition and in related domains such as punctuation recovery. We further believe that parsing of natural language utterances will constitute a fundamental pre-processing step of most if not all subsequent NLP modules, although it has probably not been as widely used as POS tagging for instance because of its complexity and lack of robustness to ill-formed input. However, thanks to the current progress in Bayesian approaches and feature-rich log-linear models, we expect parsing to be more and more robust to automatic speech recognition errors in the near future. Other recent reviews of the literature about dialogue act recognition are realized in Geertzen ( 2009 ) and Webb ( 2010 ). 3 Syntax for automatic dialogue act recognition In our previous work (Kra  X  l et al. 2006a , b , 2007 ), we proposed to include in our DA recognition approach information related to the position of the words within the sentence. In this work, we propose a different approach that derives features from the sentence parse tree and includes these features as input to a conditional random field. The parse trees are defined within the dependency framework (Hajic  X  ova  X  2000 ) and are automatically computed on the input sentences. We evaluate this approach in two conditions, respectively when the input sentences are manually and automatically transcribed.
 3.1 Features We distinguish next two types of features, respectively the baseline and syntactic features. The baseline features are:  X  words inflected form  X  lemmas  X  part-of-speech tags  X  pronoun or adverb at the beginning of the sentence  X  verb at the beginning of the sentence
The syntactic features rely on a dependency parse tree:  X  dependency label  X  root position in the utterance  X  unexpressed subjects  X  basic composite pair (subject X  X erb inversion)
All these features are described in details next. 3.1.1 Baseline features Words inflected form The word form is used as a baseline lexical feature in most modern lexicalized natural language processing approaches (Stolcke 2000 ; Keizer and Nijholt 2002 ;JiandBilmes 2005 ; Jurafsky 1997 ). In our case, sentence segmentation is known but capitalization of the first word of the sentence is removed, which decreases the total number of features in our model without impacting accuracy, thanks to the insertion of a special  X  X  X tart-of-utterance X  X  word. Although word bigrams or trigrams are commonly used in other systems, we only use word unigrams because of the limited size of the training corpus. We rather compensate for this lack of local structural information by investigating global syntactic dependencies. The word forms are obtained in our experiments using both manual and automatic transcriptions of speech audio files.
Lemmas We used the lemma structure from the Prague Dependency Treebank (PDT) 2.0 2 (Hajic  X  et al. 2000 ) project, which is composed of two parts. The first part is a unique identifier of the lexical item. Usually it is the base form (e.g., infinitive for a verb) of the word, possibly followed by a digit to disambiguate different lemmas with the same base forms. The second optional part contains additional information about the lemma, such as semantic or derivational information. Lemmas may in some circumstances bring additional information, notably by removing irrelevant variability introduced by inflected forms. This may have some importance in particular for rare words that may occur with different inflected forms but still may have some impact on the dialogue act decision process. The lemmas are obtained automatically in our experiment with a lemmatizer.

Part-of-speech (POS) tags The part-of-speech is a word linguistic category (or more precisely lexical item), which can be defined by the syntactic or morphological behaviour of the lexical item in question. There are ten POS categories defined in the PDT (Hajic  X  et al. 2000 ) for the Czech language: nouns, adjectives, pronouns, numerals, verbs, adverbs, prepositions, conjunctions, particles and interjections. The part-of-speech tags are inferred automatically in our experiment with a POS tagger.
Pronoun or adverb at the beginning of the sentence This boolean feature indicates whether the utterance starts with a pronoun or an adverb. It can be particularly useful for detecting Wh-questions , which usually start with a Pronoun (When do you come home?) (Fig. 1 ).

Note that similar features that emphasize the importance of initial words in the sentence have already been proposed, for instance in Ang et al. ( 2005 ), Webb ( 2010 ), Jurafsky and Martin ( 2009 ).

Verb at the beginning of the sentence This feature is also a boolean indicator of the presence of a verb as the first word of an utterance. It can be particularly useful for the detection of Commands and Yes  X  no questions , which usually start with a verb, such as in:  X  X  X di domu  X  ! X  X  (Go home!) and  X  X  X u  X  jdes  X  domu  X  ? X  X  (Do you go home?) (Fig. 2 ). 3.1.2 Syntactic features All syntactic features are computed from the syntactic tree obtained after automatic parsing of the target sentence: a detailed description of our automatic parser is given in Sect. 5.2 . We have chosen to represent the syntactic relations with dependencies , as it is commonly done nowadays for many natural language processing tasks. Furthermore, we have chosen the PDT to train our stochastic parser and our annotation formalism thus follows the one used in the PDT.

An example of such a dependency tree is shown in Fig. 3 , where the words represent the nodes of the tree and the arcs the dependencies between words. Dependencies are oriented, with each arrow pointing to the dependent word of the relation. Each dependency is further labelled with the name of a syntactic relation, such as Sb for subject, Pred for predicate, Atr for attribute, Obj for object, etc.
Dependency label The first generic feature derived from the parse tree is the label of the dependency from the target word to its head. For example, the values taken by this feature in Fig. 3 are, for each word: Atr, Sb, AuxP, Atr, Root, Pnom, Obj .
Root position in the utterance In theory, every utterance is parsed into a single dependency tree. The position of the root of this tree is likely to depend on the type of sentence and dialogue act. Hence, intuitively, the root tends to be positioned in the middle of declarative sentences, as in Fig. 3 , while it is more often located at the start of utterances for commands/orders, such as in:  X  X  X avr  X  i dver  X  e! X  X (Close the door!) (Fig. 4 ).
This feature is the absolute position of the root, after normalization of the sentence length to 10 words. The normalization is realized with a standard binning technique, eventually filling empty internal bins with virtual non-root words for short sentences, so that the word at the middle of the sentence is in bin 5 and recursively in the left and right halves of the sentence.

Unexpressed subject This feature is a boolean feature that is true if and only if a subject dependency exists for the first verb in the sentence. Indeed, verbs without subjects may intuitively occur more frequently in commands/orders than in declarative sentences, as illustrated in the previous example. This is however not always true, especially in the Czech language, where unexpressed subjects are quite common and thus often occur in most dialogue acts, such as in:  X  X  X   X  el do kina. X  X  (He went to the cinema.) (Fig. 5 ).

Basic composite pair This feature is a boolean value that encodes the relative position of each pair Subject and verb . When the verb precedes the subject, this is often viewed as strong evidence in favour of detecting a question in many European languages such as English and French. However, in the Czech language, this is not always true because of two main factors: 1. Subjects may be omitted, as explained in the previous section. 2. A statement can start with a Direct Object , followed by a Verb and its Subject , 4 Dialogue act model 4.1 General principle The general principle of our dialogue act recognition approach is to decompose the problem of tagging a complete sentence into the (easier) problems of tagging individual words. Our basic assumption is that every single word contributes to the global dialogue act depending on its form, nature and global context. The proposed approach thus assigns a single dialogue act tag to every word and then combines all the dialogue act tags that contribute to the same sentence to infer a single dialogue act tag for this sentence. The word-tagging process is implemented with a conditional random field (CRF) while the sentence-tagging process is realized with two simple combination models that are described next. 4.2 Training and pre-processing Only the word-level CRF model is trained. The second combination stage is realized by a non-parametric decision process and thus does not need any training.

The manually annotated dialogue act tag associated to each training utterance is first duplicated and assigned to every word of the utterance. Then, these utterances are automatically tagged with POS-tags and parsed with the Malt parser (Nivre et al. 2007 ) to produce a dependency tree. A vector of lexical and syntactic features is then derived from this parse tree for each word of the utterance. A special word is inserted before every utterance, with a single feature that indicates the start of an utterance. This special word is given the same dialogue act tag as the other words of the sentence. Finally, all these feature vectors, along with their associated dialogue act tags are pooled together in sequence and the CRF is trained on this corpus with the classical L-BFGS algorithm.
The data pre-processing procedure described above also applies to the test corpus. 4.3 Testing and dialogue act inference During testing, both word-level and sentence-level models are involved to infer dialogue acts. In the first step, the previously trained CRF is applied on the current words sequence and outputs one dialogue act tag for every word of the sentence. Then, the sentence-level decision process converts this resulting sequence of dialogue act tags into a single dialogue act tag per sentence.

Note that an alternative, single-stage strategy may have been to use a non-stochastic global approach, for instance with a maximum entropy model and global features. However, such an approach usually exploits a bag-of-word hypothesis or otherwise implies to explicitly define sentence-global features. Although we have already used with some success a similar approach in a previous work with words position (Kra  X  l et al. 2007 ), we rather investigate in the current work the proposed two-stage strategy, which focuses on modelling the succession of word-level dialogue act tags.
 Hidden Markov Models, Maximum-Entropy Markov Models (MEMMs) and CRFs are amongst the most common stochastic classifiers. We have chosen CRF because Laferty et al. ( 2001 ) have shown that CRFs avoid the label bias problem, as compared to MEMMs. Furthermore, CRFs are conditional models, and as such, make a better use of their parameters than generative models such as HMMs to model the target distribution of probability. They have also proven in recent years to be superior to most variants of HMMs in many natural language processing tasks and in particular in a punctuation generation application, which is closely related to dialogue act recognition. Hence, Favre et al. ( 2009 ) compared three sequence models: Hidden-Event Language Model (HELM), factored-HELM and CRFs for comma prediction. They have shown that the best results are obtained with CRFs, although CRFs may not scale easily to large databases.
 We thus use CRFs to compute the conditional probability: where F  X h f 0 ; f 1 ; ... ; f n i represents the sequence of features vectors, n is the number of words in the utterance, f 0 the initial start word and DA  X h c 0 ; c 1 ; ... ; c n i is the output sequence of dialogue acts. 4.4 Sentence-level combination and decision process We investigate two approaches for the final decision process, which shall output a single dialogue act tag for the whole utterance: majority voting and Naive Bayes classification. 4.4.1 Majority voting The final dialogue act tag is simply the tag with the highest frequency counts amongst the n tags c 1 ; ... ; c n . Ambiguous cases are resolved by choosing the tag with the largest posterior probability. 4.4.2 Naive Bayes classification In the  X  X  X aive Bayes X  X  classifier (Grau et al. 2004 ), every tag c i is assumed independent from all others given the Markov assumption. Hence, the probability over the whole utterance is given by Eq. 2 : order CRF, when the CRF is constrained to follow the sub-optimal path  X  c used in the  X  X  X ajority voting case X  X , where the global optimal path returned by the CRF is used.

The resulting dialogue act is the one that maximizes the a posteriori probability: 5 Evaluation The proposed two-step model is evaluated on a Czech train reservation corpus and compared with a unigram model and with a baseline CRF model that only exploits lexical and morpho-syntactic features. The evaluation metric is the dialogue act recognition accuracy. In the following, we first describe the Czech corpus, then the two pieces of software that have been used to compute the morphosyntactic tags and the parse tree and we finally discuss the experimental results. 5.1 Corpus The corpus used to validate the proposed approaches is the Czech Railways corpus that contains human X  X uman dialogues. It was created at the University of West Bohemia mainly by members of the Department of Computer Science and Engineering in the context of a train ticket reservation dialogue expert system. The whole corpus has been recorded in laboratory conditions and contains about 12 h of audio recordings. The audio files have been both manually and automatically transcribed. We thus evaluate our dialogue act recognition approach on both types of transcriptions, in order to further assess its robustness to speech recognition errors.

Automatic transcription has been realized with the jLASER (Pavelka and Eks  X  tein 2007 ) recogniser, which has been developed in our LICS 3 laboratory. It is based on a so called hybrid framework that combines the advantages of the hidden Markov model approach with those of artificial neural networks. We use HMMs with state emission probabilities computed from the output neuron activations of a neural network (such as the multi-layer perceptron). jLASER has been trained on 6,234 sentences (about 9 h), while 2,173 sentences (about 3 h) pronounced by different speakers are used for testing. Because of the size of the corpus, a class-based 3-g language model has been used.

All sentences of this  X  X  X est X  X  corpus have been manually labelled by three different annotators with the following dialogue acts: statements (S), orders (O), yes/no questions [Q (y/n)] and other questions (Q). The DA corpus structure is reported in Table 2 ,where the number of dialogue acts is shown in column 2. This choice of dialogue acts has been done because our DA recognition module is designed to be used with a rule-based dialogue system that only exploits these four types of information as an input. The following dialogue act recognition experiments are realized on this labelled corpus using a cross-validation procedure, where 10 % of the corpus is reserved for the test, another 10 % for the development set and 80 % for training of the CRF. 5.2 Tools For lemmatization and POS-tagging, we use the mate-tools http://code.google.com/ p/mate-tools/ . The lemmatizer and POS tagger models are trained on 5,853 sen-tences (94,141 words) randomly taken from the Prague Dependency Tree Bank (PDT 2.0) (Hajic  X  et al. 2000 ) corpus. The PDT 2.0 is a collection of Czech news-paper texts that are annotated on the three following layers: morphological (2 million words), syntactic (1.5 million words) and complex syntactic and semantic layer (0.8 million words). In this work, only the syntactic dependencies of the second layer are considered. The performance of the lemmatizer and POS tagger are evaluated on a different set of 5,181 sentences (94,845 words) extracted from the same corpus. The accuracy of the lemmatizer is 81.09 %, while the accuracy of our POS tagger is 99.99 %. Our tag set contains 11 POS-tags as described in Table 3 .
Our dependency parser is the Malt Parser v 1.3 trained on 32,616 sentences (567,384 words) from PDT 2.0. The dependency set is thus: Adv, AdvAtr, Apos, Atr, AtrAdv, AtrAtr, AtrObj, Atv, AtvV, AuxC, AuxG, AuxK, AuxO, AuxP, AuxR, AuxT, AuxV, AuxX, AuxY, AuxZ, Coord, ExD, Obj, ObjAtr, Pnom, Pred, Sb . The Labelled Attachment Score (LAS) of our parser is about 66 %.

Our CRF toolkit is based on the Stanford OpenNLP library, 4 which has been modified in order to include syntactic features. The resulting model has about 3,200 parameters. 5.3 Baseline rule-based system Our claim in this work is that structured syntactic features, which cannot be simply derived from word forms, bring relevant information that help a classifier to discriminate between some dialogue acts, even in Czech, which is known to be a free-word order language. We actually show next that despite the theoretical linguistic constructions in Czech, which do not a priori strongly constrain the grammatical structures with regard to word orders, common usage in Czech exhibits statistical properties that are discriminative for the few dialogue acts considered here. Furthermore, we show that such statistical properties cannot be captured with simple deterministic rules, but that they must be considered instead in context within a stochastic model like the proposed CRF that is trained on real data.
To illustrate this idea, let X  X  consider the particularly difficult case of yes X  X o questions versus statement. Table 4 shows a typical example of such a case, which cannot be captured by syntactic information in Czech.

However, despite such difficult theoretical constructions, we have automatically parsed our Czech speech corpus and analyzed the relative frequency of subject relations with the verb on the left of the subject (feature  X  X  X asic composite pair X  X ): 48 % of such inverted relations occur in statements, which corresponds to a pure random ratio and complies with the free-word order property of Czech, while this ratio goes up to 88 % in yes/no questions, which demonstrates that such a feature is indeed informative in common usages of Czech. Nevertheless, we also show next that this observation, in itself, is not enough to accurately discriminate between yes/no questions and statements, and that it must be considered in context to be really useful.
In order to validate this claim, we build next a deterministic baseline model that classifies the four proposed dialogue acts using hand-crafted rules that:  X  Include common lexical knowledge, such as interrogative words.  X  Use syntactic rules that match the proposed features described in Sect. 3.1.2 , The set of rules is described in Table 5 . When several rules apply on the same sentence, the chosen dialogue act is decided with a majority vote. In case of equality, the winner amongst competing dialogue acts is the one with the higher prior probability on the corpus, i.e., in decreasing order: Q, S, Q [y/n], O.
The recognition accuracy of the rule-based system is shown in Table 6 .We evaluate two cases: manual word transcription and automatic transcription by jLASER recognizer. Table 6 shows that errors from the speech recognizer don X  X  play an important role for DA recognition, resulting in a decrease of accuracy of about 4 %.
The highest score for class O might result from the precision of the set of rules defined for this class. Conversely, the lower score of class S may be due to the words for S and sentences are mainly classified into this class when no rule from another class is triggered. 5.4 Experiments Two experiments are realized next. The first one performs dialogue act recognition on manual word transcriptions and evaluates and compares the impact of the proposed lexical and syntactic features and the relative performances of both sentence-level combination models. The unigram model corresponds to a very basic baseline approach that only exploits lexical unigram probabilities. We further compare the proposed approach with more advanced baselines that are also based on a CRF but with lexical and morphosyntactic features only ( word forms , lemmas and POS-tags ). In the second experiment, the same set of models is applied on automatic word transcriptions. This allows assessing the robustness of both our parsers and feature sets to speech recognition errors. 5.4.1 Manual transcription evaluation Table 7 shows the dialogue act recognition accuracies obtained with the different proposed models. We have computed statistical significance of the difference between two models with the McNemar test, as suggested in Gillick and Cox ( 1989 ) for a similar classification task. The p value is in general below the traditional threshold of 0.05. The p values of some important comparisons are for instance:  X  SyNB versus B3NB: p &lt; 0.001.  X  SyNB versus B4NB: p = 0.016.  X  SyNB versus BANB: p = 0.002.

We can first observe that the Naive Bayes combination gives in general better results than majority voting, which was expected, as Naive Bayes exploits the posteriors, which are a richer source of information than just the knowledge of the winning class.
This table also shows relatively low recognition scores for the class O. This is probably due to the relatively smaller amount of training data for this class. This analysis is supported by the good recognition accuracy obtained by the baseline rule-based system for this class, which does not depend on any training corpus. The best recognition rate is for the class Q, which is both the most frequent class and which is characterized by strong cues, especially concerning the influence of the first word in the sentence (B4NB) as well as distinctive interrogative word forms (B1NB, B2NB).

The most important remark is that the combination of all proposed syntactic and baseline features significantly outperforms all baseline features, which confirms that the proposed syntactic features bring complementary information. This result supports our claim that structured syntactic information might prove useful for dialogue act recognition. 5.4.2 Automatic transcription evaluation Table 8 shows a similar evaluation to the one in Table 7 , except that the textual transcriptions are now obtained automatically with the jLASER speech recogniser. Sentence recognition accuracy is 39.8 % and word recognition accuracy is 83.4 %. The complete annotation process starts from these imperfect transcriptions, including: lemmatization, POS-tagging, parsing and dialogue act recognition. This experiment thus assess the robustness of the complete processing chain to speech proposed approach in realistic conditions.

We can first observe that the impact of speech recognition errors is moderately large, but not dramatic and thus does not jeopardize the applicability of the proposed approach in real conditions. Hence, while the dialogue act classification errors increase by 30 % with the unigram model, they increase by 113 % with the baseline CRF B3NB, which was expected because the CRF exploits the correlation between successive words and tags, which may propagate errors amongst words. However, despite its lower robustness, the CRF model still performs better in absolute value than the unigram model. The increase in classification error of the syntactic-aware model is about 183 %, which is due to the greater sensibility of the processing chain for this model. Indeed, speech recognition errors are known to have a large impact on POS-tagging and parsing performances. The derived syntactic features are thus also largely impacted by such errors. This also explains why the simple proposed baseline features, such as B4NB, are also the most robust ones. 6 Conclusions This work extends our previous works that tended to demonstrate the importance of global structural information for dialogue act recognition by implicitly modelling local constraints with CRFs and explicitly proposing global syntactic features derived from automatic parsing of the sentence. Regarding the efficiency of syntactic features for dialogue act recognition, we have provided a number of evidence to support our claim that syntactic information might be important for dialogue act recognition and that the main reason why they have not been widely used so far in this domain is due to (1) the difficulty to reliably parse speech and dialogues; (2) the intrinsic complexity of the syntactic material as compared to the classical lexical and morphosyntactic tags; and (3) the lack of robustness of parsers to speech recognition errors. This claim is based on a review of several companion works that show the importance of syntax for both dialogue act recognition and closely related domains such as punctuation generation. Second, we have proposed several simple as well as more complex syntactic features that are derived from a full deep parsing of the sentence and have shown that the use of such features indeed significantly improves the dialogue act classification performance on our Czech corpus. Finally, we have studied the robustness of the proposed system and have shown that, as expected, the most complex syntactic features are also the most sensitive to speech recognition errors.
Hence, given the evidence collected in this work, we conclude that syntax information might prove important for dialogue act recognition, as it has already been shown relevant for many other natural language processing tasks. The main challenge that remains is to increase its robustness to speech recognition errors, but we expect this challenge to be soon overcome, thanks to the great progresses realized in the automatic parsing community in recent years.
 References
 Abstract This work studies the usefulness of syntactic information in the context of automatic dialogue act recognition in Czech. Several pieces of evidence are presented in this work that support our claim that syntax might bring valuable information for dialogue act recognition. In particular, a parallel is drawn with the related domain of automatic punctuation generation and a set of syntactic features derived from a deep parse tree is further proposed and successfully used in a Czech dialogue act recognition system based on conditional random fields. We finally discuss the possible reasons why so few works have exploited this type of information before and propose future research directions to further progress in this area.
 Keywords Dialogue act Language model Sentence structure Speech act Speech recognition Syntax 1 Introduction 1.1 Definition Modelling and automatically identifying the structure of spontaneous dialogues is very important to better interpret and understand them. The precise modelling of dialogues is still an open issue, but several specific characteristics of dialogues have already been clearly identified. Dialogue Acts ( DAs ) are one of these characteristics.
Although the term  X  X  X ialogue acts X  X  that is commonly used nowadays has been defined by Austin ( 1962 ), a number of other seminal works have proposed very similar notions, including speech acts proposed by Searle ( 1969 ), conversational game moves introduced by Power ( 1979 ), adjacency pairs proposed by Schegloff ( 1968 , Sacks et al. 1974 ) or acts of communication in the plan-based approaches to understanding introduced by Litman et al. ( 1985 ), Kautz ( 1987 ), Carberry ( 1990 ). The theory of the dialogue acts has been further developed by Bunt ( 1994 ). The dialogue acts represent the meaning of an utterance in the context of a dialogue, where the context is divided into several types, with both global and local views: linguistic, semantic, physical, social and cognitive. Bunt also developed a multidimensional taxonomy of the dialogue acts, while David R. Traum developed the notion of speech acts in Traum ( 1999 ) with dialogue agents. A better overview of the notion of dialogue acts can be found in Stolcke ( 2000 ).

In this work, the dialogue act is seen as a function of an utterance, or its part, in the dialogue. For example, the function of a question is to request some information, while an answer shall provide this information.

Table 1 illustrates the dialogue acts that may occur in a dialogue between the passenger (P) and the agent (A) in a ticket reservation task. The corresponding dialogue act labels are also shown. Each utterance is labelled with a unique dialogue act. This example is taken from our Czech corpus (see Sect. 5.1 ).

Dialogue acts represent useful and relevant information for many applications, such as dialogue systems, machine translation, automatic speech recognition, topic tracking (Garner et al. 1996 ) or talking head animation. For instance, in dialogue systems, dialogue acts might be used to recognize the intention of the user and thus differentiate situations where the user is requesting some information from situations where the user is simply giving some information or backchannels. In the former case, the system has to react, while in the latter case, a system reaction may be perceived as intrusive. In the machine translation domain, recognizing dialogue acts may bring relevant cues to choose between alternative translations, as the adequate syntactic structure may depend on the user intention. Automatic recognition of dialogue acts may also be used to improve the word recognition accuracy of automatic speech recognition systems, as proposed for instance in Wright ( 1998 ), where a different language model is applied during recognition depending on the dialogue act. Finally, dialogue act recognition is a fundamental building block of any understanding system and typically completes semantic role labelling and semantic frame inference.

The usefulness of dialogue act recognition has thus been demonstrated in a number of large applicative systems, such as the VERBMOBIL (Alexandersson et al. 1997 ), NESPOLE (Lavie et al. 2006 ) and C-STAR (Blanchon and Boitet 2000 ) machine translation and dialogue systems that rely on dialogue act classification. 1.2 Objectives The main objective of this work is to propose and investigate the usefulness of syntactic features to improve dialogue act recognition in Czech. In previous works, we have first designed a baseline dialogue act recognition system for the Czech language that was based on generative models (Kra  X  l et al. 2005 ). Although reasonably good results have been obtained, this approach was limited because it only exploits the local context around any given word of the utterance. We then and include global features in the model that represent the sentence structure. One of these approaches consists in modelling the word position in the sentence as a random variable and integrating this variable in the generative model. Intuitively, this information is important for dialogue act recognition, as for instance, the word  X  X  X ho X  X  is often located at the beginning of sentences for questions and at other positions for declarative sentences. In the following, we propose a different approach to model such global information implicitly, via a conditional stochastic model. The second and most important contribution of this work concerns the design and exploitation of syntactic features for dialogue act recognition in Czech. As summarized in Sect. 2 , only a few types of features are generally used in the literature to automatically recognize dialogue acts: lexical, part-of-speech (POS) tags, dialogue history and prosody. Furthermore, word sequences are most of the time modelled by statistical n-gram models, which encode the relationship between words and dialogue acts only locally. While we have already shown the importance of global information such as word position in the utterance for dialogue act recognition, the current work goes beyond this type of information by investigating whether the conditional distribution of the target dialogue act depends on the syntactic structure of the utterance.

In the following section, we briefly review the state of the art about dialogue act recognition, with a focus on how syntactic information has already been considered for this task and for related tasks. In Sect. 3 , we propose and describe new syntactic features. The proposed model is described in Sect. 4 . The relative importance of each of these features is evaluated on a Czech dialogue corpus in Sect. 5 In the last section, we discuss these results and propose some future research directions. 2 Related work We will now briefly review the standard definitions of dialogue acts, the different types of models classically used for dialogue act recognition and the standard types of information used in such models. Then, we review and discuss the previous design of syntactic features for dialogue act recognition as well as in closely related domains.

Some generic sets of domain-independent dialogue acts have been proposed in the state-of-the-art and are now commonly used to create the baseline tag set for most types of applications. Hence, in Stolcke ( 2000 ), 42 DAs classes are defined for English, based on the discourse annotation and markup system of labelling (DAMSL) tag-set (Allen and Core 1997 ). The switchboard X  X AMSL tag-set (Jurafsky et al. 1997 ) (SWBD X  X AMSL) is an adaptation of DAMSL in the field of telephone conversations. The meeting recorder dialogue act (MRDA) tag-set (Dhillon and Carvey 2004 ) is another very popular tag-set, which is based on the SWBD X  X AMSL taxonomy. MRDA contains 11 general dialogue act labels and 39 specific labels. Finally, Jekat ( 1995 ) defines for German and Japanese 42 dialogue acts, with 18 dialogue acts at the illocutionary level, in the context of the VERBMOBIL corpus. The ISO standard 24617-2 for dialogue annotation has been published in 2012. DIT ?? 1 is a recent implementation of this standard. Because of the limited size of the available corpus, as well as several other technical reasons, these tag sets are frequently reduced by merging several tags together, so that the number of final actual generic tags is often about 10. Part of such typical generic dialogue acts, also referred to as speech acts, include for instance (Shriberg et al. 1998 ) statements, questions, backchannels, commands, agreements, appreciations as well as a broad  X  X  X iscellaneous X  X  class. In addition to such generic tags, application-specific tags may be defined, such as  X  X  X equest booking X  X  for a hotel booking application.

Manually annotating dialogue acts on every new corpus may be very costly and efforts have been put into developing semi-automatic methods for dialogue act tagging and discovery. Hence, the authors of Orkin and Roy ( 2010 ) propose a predictive paradigm where dialogue act models are first trained on a small-size corpus and used afterwards to predict future sentences or dialogue acts. In a related vein, unsupervised dialogue act tagging of unlabelled text has recently raised a lot of following on supervised approaches.

The dialogue act recognition task is often considered jointly with the segmentation task. We assume in our work that sentence segmentation is known, because we rather prefer to concentrate on the challenge of designing relevant syntactic features for dialogue act recognition. Yet, many related works propose powerful solutions for the segmentation task as well. In particular, the work described in Petukhova and Bunt ( 2011 ) considers the input text as a stream of words and segments and tags it incrementally with a BayesNet model with lexical, prosodic, timing and dialogue act-history features. Zimmermann et al. ( 2006 ) successfully use in for joint DA segmentation and classification hidden-event language models and a maximum entropy classifier. They use word sequence and pause duration as features. The authors of Dielmann and Renals ( 2008 ) exploit a Switching Dynamic Bayesian Network for segmentation, cascaded with a condi-tional random field for dialogue act classification, while Quarteroni et al. ( 2011 ) jointly segments and tags with a single model.

The dialogue act modelling schemes that are commonly used for dialogue act recognition are traditionally chosen from the same set of general machine learning methods used in most natural language processing tasks. These include Hidden Markov Models (Stolcke 2000 ), Bayesian Networks (Keizer and Nijholt 2002 ), Discriminative Dynamic Bayesian Networks (Ji and Bilmes 2005 ), BayesNet (Petukhova and Bunt 2011 ), memory-based (Lendvai and van den Bosch 2003 ) and transformation/based learning (Samuel et al. 1998 ), decision trees (Mast 1996 ), neural networks (Levin et al. 2003 ), but also more advanced approaches such as boosting (Tur et al. 2006 ), latent semantic analysis (Serafin and Di Eugenio 2004 ), hidden backoff models (Bilmes 2005 ), maximum entropy models (Ang et al. 2005 ), conditional random fields (CRFs) (Dielmann and Renals 2008 ; Quarteroni et al. 2011 ) and triangular-chain CRF (Jeong and Lee 2008 ).

Regarding features, most dialogue act recognition systems exploit both prosodic and lexical features. The dialogue history is also often used as relevant information. Some cue words and phrases can also serve as explicit indicators of dialogue structure (Webb 2010 ). For example, 88.4 % of the trigrams  X  X  h start i do you X  X  occur in English in yes / no questions (Jurafsky 1997 ).

Prosody is an important source of information for dialogue act recognition (Shriberg et al. 1998 ). For instance, prosodic models may help to capture the following typical features of some dialogue acts (Kompe 1997 ):  X  a falling intonation for most statements  X  a rising F0 contour for some questions (particularly for declaratives and yes/no  X  a continuation-rising F0 contour characterizes (prosodic) clause boundaries,
In Shriberg et al. ( 1998 ), the duration, pause, fundamental frequency (F0), energy and speaking rate prosodic attributes are modelled by a CART-style decision trees classifier. In Mast et al. ( 1996 ), prosody is used to segment utterances. The duration, pause, F0-contour and energy features are used in Wright ( 1998 ) and Wright et al. ( 1999 ). In both Wright ( 1998 ) and Wright et al. ( 1999 ), several features are computed based on these basic prosodic attributes, for example the max, min, mean and standard deviation of F0, the mean and standard deviation of the energy, the number of frames in utterance and the number of voiced frames. The features are computed on the whole sentence and also on the last 200 ms of each sentence. The authors conclude that the end of sentences carry the most important prosodic information for dialogue act recognition. Shriberg et al. ( 1998 ) show that it is better to use prosody for dialogue act recognition in three separate tasks, namely question detection, incomplete utterance detection and agreements detection, rather than for detecting all dialogue acts in one task.

Apart from prosodic and contextual lexical features, only a few works actually exploit syntactic relationships between words for dialogue act recognition. Some syntactic relations are captured by HMM word models, such as the widely-used n-grams (Stolcke 2000 ), but these approaches only capture local syntactic relations, while we consider next global syntactic trees. Most other works thus focus on morphosyntactic tags, as demonstrated for instance in Verbree et al. ( 2006 ), where a smart compression technique for feature selection is introduced. The authors use a rich feature set with POS-tags included and obtain with a decision tree classifier an accuracy of 89.27, 65.68 and 59.76 % respectively on the ICSI, Switchboard and on a selection of the AMI corpus. But while POS-tags are indeed related to syntax, they do not encode actual syntactic relations.

A very few number of works have nevertheless proposed some specific structured syntactic features, such as for instance the subject of verb type (Andernach 1996 ). The authors of Serafin and Di Eugenio ( 2004 ), Di Eugenio et al. ( 2010 ) exploit a few global syntactic features, in particular POS-tags and the MapTask SRule annotation that indicates the main structure of the utterance, i.e., declarative, imperative, inverted or Wh-question, but without obtaining a clear gain from syntax in their context, hence suggesting that further investigation is needed. Indeed, syntax is a very rich source of information and the potential impact of syntactic information highly depends on the chosen integration approach and experimental setup. We thus propose in the next section other types of syntactic features and a different model and show that syntax might indeed prove useful for dialogue act recognition in the proposed context. But let us first support our hypothesis by briefly reviewing a few other papers that also support the use of syntax for both dialogue act recognition and closely related domains.

First, as already shown, word n-grams features, with n &gt; 1, do implicitly encode local syntactic relations and are used successfully in most dialogue act recognition systems. But more importantly, a recent work (Klu  X  wer et al. 1944 ) concludes that both dialogue context and syntactic features dramatically improve dialogue act recognition, compared to words only, more precisely from an accuracy of 48.1 % up to 61.9 % when including context and 67.4 % when further including syntactic features. They use in their experiments a Bayesian Network model and their syntactic features are the syntactic class of the predicate, the list of arguments and the presence of a negation. Although this work actually focuses on predicate-argument structures, while our main objective is rather to exploit the full syntactic tree without taking into account any semantic-level information for now, this work supports our claim that syntactic information may prove important for dialogue act recognition. In addition, Zhou et al. ( 2009 ) employ in three levels of features: (1) word level (unigram, bigram and trigram), (2) syntax level [POS-tags and chunks recognized as base noun phrase (BNP)] and (3) restraint information (word position, utterance length, etc.). Syntactic and semantic relations are acquired by information extraction methods. They obtain 88 % of accuracy with a SVM classifier on a Chinese corpus and 65 % on the SWBD corpus.

We further investigated closely related domains that have already explored this research track in more depth. This is for instance the case of automatic classification of rhetorical relations, as reviewed in Sporleder and Lascarides ( 2008 ). Another very close task is punctuation recovery, which aims at generating punctuation marks in raw words sequences, as typically obtained from speech recognition systems. In particular, this implies to discriminate between questions (ending with a question mark), orders (ending with an exclamation points) and statements (ending with a period), which is a task that is obviously strongly correlated to dialogue act recognition. Interestingly enough, a richer set of syntactic features have been exploited in the punctuation recovery domain than in the dialogue act recognition area. Hence, the authors of Favre et al. ( 2009 ) design several syntactic features derived from the phrase structure trees and show that these features significantly reduce the detection errors. This is in line with our own previous conclusions published in Cerisara et al. ( 2011 ) regarding the use of syntactic features for punctuation recovery, where a large improvement in performances is obtained thanks to syntactic information derived from dependency trees. Similar gains are obtained on a Chinese punctuation task (Guo et al. 2010 ), where including rich syntactic features, such as the word grammatical function, its ancestors and children, its head, the yield of the constituent or subtree border indicators, improve the F-measure from 52.61 % up to 74.04 %.

Finally, we have shown that there is an increasing amount of work that successfully exploits structural syntactic dependencies both for dialogue act recognition and in related domains such as punctuation recovery. We further believe that parsing of natural language utterances will constitute a fundamental pre-processing step of most if not all subsequent NLP modules, although it has probably not been as widely used as POS tagging for instance because of its complexity and lack of robustness to ill-formed input. However, thanks to the current progress in Bayesian approaches and feature-rich log-linear models, we expect parsing to be more and more robust to automatic speech recognition errors in the near future. Other recent reviews of the literature about dialogue act recognition are realized in Geertzen ( 2009 ) and Webb ( 2010 ). 3 Syntax for automatic dialogue act recognition In our previous work (Kra  X  l et al. 2006a , b , 2007 ), we proposed to include in our DA recognition approach information related to the position of the words within the sentence. In this work, we propose a different approach that derives features from the sentence parse tree and includes these features as input to a conditional random field. The parse trees are defined within the dependency framework (Hajic  X  ova  X  2000 ) and are automatically computed on the input sentences. We evaluate this approach in two conditions, respectively when the input sentences are manually and automatically transcribed.
 3.1 Features We distinguish next two types of features, respectively the baseline and syntactic features. The baseline features are:  X  words inflected form  X  lemmas  X  part-of-speech tags  X  pronoun or adverb at the beginning of the sentence  X  verb at the beginning of the sentence
The syntactic features rely on a dependency parse tree:  X  dependency label  X  root position in the utterance  X  unexpressed subjects  X  basic composite pair (subject X  X erb inversion)
All these features are described in details next. 3.1.1 Baseline features Words inflected form The word form is used as a baseline lexical feature in most modern lexicalized natural language processing approaches (Stolcke 2000 ; Keizer and Nijholt 2002 ;JiandBilmes 2005 ; Jurafsky 1997 ). In our case, sentence segmentation is known but capitalization of the first word of the sentence is removed, which decreases the total number of features in our model without impacting accuracy, thanks to the insertion of a special  X  X  X tart-of-utterance X  X  word. Although word bigrams or trigrams are commonly used in other systems, we only use word unigrams because of the limited size of the training corpus. We rather compensate for this lack of local structural information by investigating global syntactic dependencies. The word forms are obtained in our experiments using both manual and automatic transcriptions of speech audio files.
Lemmas We used the lemma structure from the Prague Dependency Treebank (PDT) 2.0 2 (Hajic  X  et al. 2000 ) project, which is composed of two parts. The first part is a unique identifier of the lexical item. Usually it is the base form (e.g., infinitive for a verb) of the word, possibly followed by a digit to disambiguate different lemmas with the same base forms. The second optional part contains additional information about the lemma, such as semantic or derivational information. Lemmas may in some circumstances bring additional information, notably by removing irrelevant variability introduced by inflected forms. This may have some importance in particular for rare words that may occur with different inflected forms but still may have some impact on the dialogue act decision process. The lemmas are obtained automatically in our experiment with a lemmatizer.

Part-of-speech (POS) tags The part-of-speech is a word linguistic category (or more precisely lexical item), which can be defined by the syntactic or morphological behaviour of the lexical item in question. There are ten POS categories defined in the PDT (Hajic  X  et al. 2000 ) for the Czech language: nouns, adjectives, pronouns, numerals, verbs, adverbs, prepositions, conjunctions, particles and interjections. The part-of-speech tags are inferred automatically in our experiment with a POS tagger.
Pronoun or adverb at the beginning of the sentence This boolean feature indicates whether the utterance starts with a pronoun or an adverb. It can be particularly useful for detecting Wh-questions , which usually start with a Pronoun (When do you come home?) (Fig. 1 ).

Note that similar features that emphasize the importance of initial words in the sentence have already been proposed, for instance in Ang et al. ( 2005 ), Webb ( 2010 ), Jurafsky and Martin ( 2009 ).

Verb at the beginning of the sentence This feature is also a boolean indicator of the presence of a verb as the first word of an utterance. It can be particularly useful for the detection of Commands and Yes  X  no questions , which usually start with a verb, such as in:  X  X  X di domu  X  ! X  X  (Go home!) and  X  X  X u  X  jdes  X  domu  X  ? X  X  (Do you go home?) (Fig. 2 ). 3.1.2 Syntactic features All syntactic features are computed from the syntactic tree obtained after automatic parsing of the target sentence: a detailed description of our automatic parser is given in Sect. 5.2 . We have chosen to represent the syntactic relations with dependencies , as it is commonly done nowadays for many natural language processing tasks. Furthermore, we have chosen the PDT to train our stochastic parser and our annotation formalism thus follows the one used in the PDT.

An example of such a dependency tree is shown in Fig. 3 , where the words represent the nodes of the tree and the arcs the dependencies between words. Dependencies are oriented, with each arrow pointing to the dependent word of the relation. Each dependency is further labelled with the name of a syntactic relation, such as Sb for subject, Pred for predicate, Atr for attribute, Obj for object, etc.
Dependency label The first generic feature derived from the parse tree is the label of the dependency from the target word to its head. For example, the values taken by this feature in Fig. 3 are, for each word: Atr, Sb, AuxP, Atr, Root, Pnom, Obj .
Root position in the utterance In theory, every utterance is parsed into a single dependency tree. The position of the root of this tree is likely to depend on the type of sentence and dialogue act. Hence, intuitively, the root tends to be positioned in the middle of declarative sentences, as in Fig. 3 , while it is more often located at the start of utterances for commands/orders, such as in:  X  X  X avr  X  i dver  X  e! X  X (Close the door!) (Fig. 4 ).
This feature is the absolute position of the root, after normalization of the sentence length to 10 words. The normalization is realized with a standard binning technique, eventually filling empty internal bins with virtual non-root words for short sentences, so that the word at the middle of the sentence is in bin 5 and recursively in the left and right halves of the sentence.

Unexpressed subject This feature is a boolean feature that is true if and only if a subject dependency exists for the first verb in the sentence. Indeed, verbs without subjects may intuitively occur more frequently in commands/orders than in declarative sentences, as illustrated in the previous example. This is however not always true, especially in the Czech language, where unexpressed subjects are quite common and thus often occur in most dialogue acts, such as in:  X  X  X   X  el do kina. X  X  (He went to the cinema.) (Fig. 5 ).

Basic composite pair This feature is a boolean value that encodes the relative position of each pair Subject and verb . When the verb precedes the subject, this is often viewed as strong evidence in favour of detecting a question in many European languages such as English and French. However, in the Czech language, this is not always true because of two main factors: 1. Subjects may be omitted, as explained in the previous section. 2. A statement can start with a Direct Object , followed by a Verb and its Subject , 4 Dialogue act model 4.1 General principle The general principle of our dialogue act recognition approach is to decompose the problem of tagging a complete sentence into the (easier) problems of tagging individual words. Our basic assumption is that every single word contributes to the global dialogue act depending on its form, nature and global context. The proposed approach thus assigns a single dialogue act tag to every word and then combines all the dialogue act tags that contribute to the same sentence to infer a single dialogue act tag for this sentence. The word-tagging process is implemented with a conditional random field (CRF) while the sentence-tagging process is realized with two simple combination models that are described next. 4.2 Training and pre-processing Only the word-level CRF model is trained. The second combination stage is realized by a non-parametric decision process and thus does not need any training.

The manually annotated dialogue act tag associated to each training utterance is first duplicated and assigned to every word of the utterance. Then, these utterances are automatically tagged with POS-tags and parsed with the Malt parser (Nivre et al. 2007 ) to produce a dependency tree. A vector of lexical and syntactic features is then derived from this parse tree for each word of the utterance. A special word is inserted before every utterance, with a single feature that indicates the start of an utterance. This special word is given the same dialogue act tag as the other words of the sentence. Finally, all these feature vectors, along with their associated dialogue act tags are pooled together in sequence and the CRF is trained on this corpus with the classical L-BFGS algorithm.
The data pre-processing procedure described above also applies to the test corpus. 4.3 Testing and dialogue act inference During testing, both word-level and sentence-level models are involved to infer dialogue acts. In the first step, the previously trained CRF is applied on the current words sequence and outputs one dialogue act tag for every word of the sentence. Then, the sentence-level decision process converts this resulting sequence of dialogue act tags into a single dialogue act tag per sentence.

Note that an alternative, single-stage strategy may have been to use a non-stochastic global approach, for instance with a maximum entropy model and global features. However, such an approach usually exploits a bag-of-word hypothesis or otherwise implies to explicitly define sentence-global features. Although we have already used with some success a similar approach in a previous work with words position (Kra  X  l et al. 2007 ), we rather investigate in the current work the proposed two-stage strategy, which focuses on modelling the succession of word-level dialogue act tags.
 Hidden Markov Models, Maximum-Entropy Markov Models (MEMMs) and CRFs are amongst the most common stochastic classifiers. We have chosen CRF because Laferty et al. ( 2001 ) have shown that CRFs avoid the label bias problem, as compared to MEMMs. Furthermore, CRFs are conditional models, and as such, make a better use of their parameters than generative models such as HMMs to model the target distribution of probability. They have also proven in recent years to be superior to most variants of HMMs in many natural language processing tasks and in particular in a punctuation generation application, which is closely related to dialogue act recognition. Hence, Favre et al. ( 2009 ) compared three sequence models: Hidden-Event Language Model (HELM), factored-HELM and CRFs for comma prediction. They have shown that the best results are obtained with CRFs, although CRFs may not scale easily to large databases.
 We thus use CRFs to compute the conditional probability: where F  X h f 0 ; f 1 ; ... ; f n i represents the sequence of features vectors, n is the number of words in the utterance, f 0 the initial start word and DA  X h c 0 ; c 1 ; ... ; c n i is the output sequence of dialogue acts. 4.4 Sentence-level combination and decision process We investigate two approaches for the final decision process, which shall output a single dialogue act tag for the whole utterance: majority voting and Naive Bayes classification. 4.4.1 Majority voting The final dialogue act tag is simply the tag with the highest frequency counts amongst the n tags c 1 ; ... ; c n . Ambiguous cases are resolved by choosing the tag with the largest posterior probability. 4.4.2 Naive Bayes classification In the  X  X  X aive Bayes X  X  classifier (Grau et al. 2004 ), every tag c i is assumed independent from all others given the Markov assumption. Hence, the probability over the whole utterance is given by Eq. 2 : order CRF, when the CRF is constrained to follow the sub-optimal path  X  c used in the  X  X  X ajority voting case X  X , where the global optimal path returned by the CRF is used.

The resulting dialogue act is the one that maximizes the a posteriori probability: 5 Evaluation The proposed two-step model is evaluated on a Czech train reservation corpus and compared with a unigram model and with a baseline CRF model that only exploits lexical and morpho-syntactic features. The evaluation metric is the dialogue act recognition accuracy. In the following, we first describe the Czech corpus, then the two pieces of software that have been used to compute the morphosyntactic tags and the parse tree and we finally discuss the experimental results. 5.1 Corpus The corpus used to validate the proposed approaches is the Czech Railways corpus that contains human X  X uman dialogues. It was created at the University of West Bohemia mainly by members of the Department of Computer Science and Engineering in the context of a train ticket reservation dialogue expert system. The whole corpus has been recorded in laboratory conditions and contains about 12 h of audio recordings. The audio files have been both manually and automatically transcribed. We thus evaluate our dialogue act recognition approach on both types of transcriptions, in order to further assess its robustness to speech recognition errors.

Automatic transcription has been realized with the jLASER (Pavelka and Eks  X  tein 2007 ) recogniser, which has been developed in our LICS 3 laboratory. It is based on a so called hybrid framework that combines the advantages of the hidden Markov model approach with those of artificial neural networks. We use HMMs with state emission probabilities computed from the output neuron activations of a neural network (such as the multi-layer perceptron). jLASER has been trained on 6,234 sentences (about 9 h), while 2,173 sentences (about 3 h) pronounced by different speakers are used for testing. Because of the size of the corpus, a class-based 3-g language model has been used.

All sentences of this  X  X  X est X  X  corpus have been manually labelled by three different annotators with the following dialogue acts: statements (S), orders (O), yes/no questions [Q (y/n)] and other questions (Q). The DA corpus structure is reported in Table 2 ,where the number of dialogue acts is shown in column 2. This choice of dialogue acts has been done because our DA recognition module is designed to be used with a rule-based dialogue system that only exploits these four types of information as an input. The following dialogue act recognition experiments are realized on this labelled corpus using a cross-validation procedure, where 10 % of the corpus is reserved for the test, another 10 % for the development set and 80 % for training of the CRF. 5.2 Tools For lemmatization and POS-tagging, we use the mate-tools http://code.google.com/ p/mate-tools/ . The lemmatizer and POS tagger models are trained on 5,853 sen-tences (94,141 words) randomly taken from the Prague Dependency Tree Bank (PDT 2.0) (Hajic  X  et al. 2000 ) corpus. The PDT 2.0 is a collection of Czech news-paper texts that are annotated on the three following layers: morphological (2 million words), syntactic (1.5 million words) and complex syntactic and semantic layer (0.8 million words). In this work, only the syntactic dependencies of the second layer are considered. The performance of the lemmatizer and POS tagger are evaluated on a different set of 5,181 sentences (94,845 words) extracted from the same corpus. The accuracy of the lemmatizer is 81.09 %, while the accuracy of our POS tagger is 99.99 %. Our tag set contains 11 POS-tags as described in Table 3 .
Our dependency parser is the Malt Parser v 1.3 trained on 32,616 sentences (567,384 words) from PDT 2.0. The dependency set is thus: Adv, AdvAtr, Apos, Atr, AtrAdv, AtrAtr, AtrObj, Atv, AtvV, AuxC, AuxG, AuxK, AuxO, AuxP, AuxR, AuxT, AuxV, AuxX, AuxY, AuxZ, Coord, ExD, Obj, ObjAtr, Pnom, Pred, Sb . The Labelled Attachment Score (LAS) of our parser is about 66 %.

Our CRF toolkit is based on the Stanford OpenNLP library, 4 which has been modified in order to include syntactic features. The resulting model has about 3,200 parameters. 5.3 Baseline rule-based system Our claim in this work is that structured syntactic features, which cannot be simply derived from word forms, bring relevant information that help a classifier to discriminate between some dialogue acts, even in Czech, which is known to be a free-word order language. We actually show next that despite the theoretical linguistic constructions in Czech, which do not a priori strongly constrain the grammatical structures with regard to word orders, common usage in Czech exhibits statistical properties that are discriminative for the few dialogue acts considered here. Furthermore, we show that such statistical properties cannot be captured with simple deterministic rules, but that they must be considered instead in context within a stochastic model like the proposed CRF that is trained on real data.
To illustrate this idea, let X  X  consider the particularly difficult case of yes X  X o questions versus statement. Table 4 shows a typical example of such a case, which cannot be captured by syntactic information in Czech.

However, despite such difficult theoretical constructions, we have automatically parsed our Czech speech corpus and analyzed the relative frequency of subject relations with the verb on the left of the subject (feature  X  X  X asic composite pair X  X ): 48 % of such inverted relations occur in statements, which corresponds to a pure random ratio and complies with the free-word order property of Czech, while this ratio goes up to 88 % in yes/no questions, which demonstrates that such a feature is indeed informative in common usages of Czech. Nevertheless, we also show next that this observation, in itself, is not enough to accurately discriminate between yes/no questions and statements, and that it must be considered in context to be really useful.
In order to validate this claim, we build next a deterministic baseline model that classifies the four proposed dialogue acts using hand-crafted rules that:  X  Include common lexical knowledge, such as interrogative words.  X  Use syntactic rules that match the proposed features described in Sect. 3.1.2 , The set of rules is described in Table 5 . When several rules apply on the same sentence, the chosen dialogue act is decided with a majority vote. In case of equality, the winner amongst competing dialogue acts is the one with the higher prior probability on the corpus, i.e., in decreasing order: Q, S, Q [y/n], O.
The recognition accuracy of the rule-based system is shown in Table 6 .We evaluate two cases: manual word transcription and automatic transcription by jLASER recognizer. Table 6 shows that errors from the speech recognizer don X  X  play an important role for DA recognition, resulting in a decrease of accuracy of about 4 %.
The highest score for class O might result from the precision of the set of rules defined for this class. Conversely, the lower score of class S may be due to the words for S and sentences are mainly classified into this class when no rule from another class is triggered. 5.4 Experiments Two experiments are realized next. The first one performs dialogue act recognition on manual word transcriptions and evaluates and compares the impact of the proposed lexical and syntactic features and the relative performances of both sentence-level combination models. The unigram model corresponds to a very basic baseline approach that only exploits lexical unigram probabilities. We further compare the proposed approach with more advanced baselines that are also based on a CRF but with lexical and morphosyntactic features only ( word forms , lemmas and POS-tags ). In the second experiment, the same set of models is applied on automatic word transcriptions. This allows assessing the robustness of both our parsers and feature sets to speech recognition errors. 5.4.1 Manual transcription evaluation Table 7 shows the dialogue act recognition accuracies obtained with the different proposed models. We have computed statistical significance of the difference between two models with the McNemar test, as suggested in Gillick and Cox ( 1989 ) for a similar classification task. The p value is in general below the traditional threshold of 0.05. The p values of some important comparisons are for instance:  X  SyNB versus B3NB: p &lt; 0.001.  X  SyNB versus B4NB: p = 0.016.  X  SyNB versus BANB: p = 0.002.

We can first observe that the Naive Bayes combination gives in general better results than majority voting, which was expected, as Naive Bayes exploits the posteriors, which are a richer source of information than just the knowledge of the winning class.
This table also shows relatively low recognition scores for the class O. This is probably due to the relatively smaller amount of training data for this class. This analysis is supported by the good recognition accuracy obtained by the baseline rule-based system for this class, which does not depend on any training corpus. The best recognition rate is for the class Q, which is both the most frequent class and which is characterized by strong cues, especially concerning the influence of the first word in the sentence (B4NB) as well as distinctive interrogative word forms (B1NB, B2NB).

The most important remark is that the combination of all proposed syntactic and baseline features significantly outperforms all baseline features, which confirms that the proposed syntactic features bring complementary information. This result supports our claim that structured syntactic information might prove useful for dialogue act recognition. 5.4.2 Automatic transcription evaluation Table 8 shows a similar evaluation to the one in Table 7 , except that the textual transcriptions are now obtained automatically with the jLASER speech recogniser. Sentence recognition accuracy is 39.8 % and word recognition accuracy is 83.4 %. The complete annotation process starts from these imperfect transcriptions, including: lemmatization, POS-tagging, parsing and dialogue act recognition. This experiment thus assess the robustness of the complete processing chain to speech proposed approach in realistic conditions.

We can first observe that the impact of speech recognition errors is moderately large, but not dramatic and thus does not jeopardize the applicability of the proposed approach in real conditions. Hence, while the dialogue act classification errors increase by 30 % with the unigram model, they increase by 113 % with the baseline CRF B3NB, which was expected because the CRF exploits the correlation between successive words and tags, which may propagate errors amongst words. However, despite its lower robustness, the CRF model still performs better in absolute value than the unigram model. The increase in classification error of the syntactic-aware model is about 183 %, which is due to the greater sensibility of the processing chain for this model. Indeed, speech recognition errors are known to have a large impact on POS-tagging and parsing performances. The derived syntactic features are thus also largely impacted by such errors. This also explains why the simple proposed baseline features, such as B4NB, are also the most robust ones. 6 Conclusions This work extends our previous works that tended to demonstrate the importance of global structural information for dialogue act recognition by implicitly modelling local constraints with CRFs and explicitly proposing global syntactic features derived from automatic parsing of the sentence. Regarding the efficiency of syntactic features for dialogue act recognition, we have provided a number of evidence to support our claim that syntactic information might be important for dialogue act recognition and that the main reason why they have not been widely used so far in this domain is due to (1) the difficulty to reliably parse speech and dialogues; (2) the intrinsic complexity of the syntactic material as compared to the classical lexical and morphosyntactic tags; and (3) the lack of robustness of parsers to speech recognition errors. This claim is based on a review of several companion works that show the importance of syntax for both dialogue act recognition and closely related domains such as punctuation generation. Second, we have proposed several simple as well as more complex syntactic features that are derived from a full deep parsing of the sentence and have shown that the use of such features indeed significantly improves the dialogue act classification performance on our Czech corpus. Finally, we have studied the robustness of the proposed system and have shown that, as expected, the most complex syntactic features are also the most sensitive to speech recognition errors.
Hence, given the evidence collected in this work, we conclude that syntax information might prove important for dialogue act recognition, as it has already been shown relevant for many other natural language processing tasks. The main challenge that remains is to increase its robustness to speech recognition errors, but we expect this challenge to be soon overcome, thanks to the great progresses realized in the automatic parsing community in recent years.
 References
