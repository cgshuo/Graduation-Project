
State Key Laboratory of Neurobiology, Chinese Academy of Sc iences, Shanghai 200031, China. Understanding how the dynamics of a neural network is shaped by the network structure, and con-population decoding and object categorization.
 the potential applications of CANNs in neural systems.
 We will use a simple, analytically-solvable, CANN model as t he working example. We display dynamics which is otherwise extremely complicated for a lar ge recurrent network, we develop a the tracking behaviors of CANNs, namely, the maximum tracki ng speed to moving stimuli, and the reaction time to sudden changes in external stimuli, both ar e testable by experiments. We consider a one-dimensional continuous stimulus being en coded by an ensemble of neurons. The activity-dependent inhibition. A solvable model that capt ures these features is given by inhibition. The dynamics of the synaptic input U ( x, t ) is determined by the external input I the network input from other neurons, and its own relaxation . It is given by interactions. In our solvable model, we choose Gaussian int eractions with a range a , namely, further discussed at the end of the paper).
 0 &lt; k &lt; k c  X   X J 2 / (8 where U among themselves and have the Gaussian bumped shape peaked a t arbitrary positions z . Consider the network state U ( x, t ) =  X  U ( x | z ) +  X U ( x, t ) . Then we obtain ness of a bump state. 2.1 The motion modes of the quantum harmonic oscillators as the basis, namely, where  X   X  ( x  X  a ) / (  X  2 a ) and H of the bump respectively (see Fig. 1). The eigenvalues of the kernel F are calculated to be basis functions v them, which are u p 1 / 7 v 1 ( x, z ) + p 6 / 7 v 3 ( x, z ) .
 The eigenfunctions of F correspond to the various distortion modes of the bump. Sinc e  X  The eigenfunction for the eigenvalue  X  Central to the tracking capability of CANNs, the eigenfunct ion for the eigenvalue 1 is u is neutrally stable. We note that u the bump, for example, the eigenfunction u 2.2 The energy landscape z , one can define an effective energy function E | by b the displacement of the bump (inset). can be locally described by the gradient descent of E | b neutral stability of the system, and how this neutral stabil ity shapes the network dynamics. We now consider the network dynamics in the presence of a weak external stimulus. Suppose the perturbation analysis using { v of n . This is done by considering solutions of the form stimuli. Making use of the orthonormality and completeness of { v expressions for da where I In practice, low order perturbations already yield very acc urate results. 3.1 Tracking a moving stimulus Consider the external stimulus consisting of a Gaussian bum p, namely, I z simulations with N = 200 and v = 0 . 025 . Lines: n = 5 perturbation. Dashed lines: s and s  X  = 1 , k = 0 . 5 ,  X  = N/ (2  X  ) , J =  X U 0 p (2  X  ) 1 / 2 a exp[  X  ( z 0  X  z ) 2 / 8 a 2 ] / X  , and where R ( t ) = 1 +  X  R t the dynamics is driven by a pull of the bump position towards t he stimulus position z R ( t ) &gt; 1 implies that the increase in amplitude of the bump slows down its response. becomes identical to Eq. (11), with z s = z 0  X  z we have, after the transients, when these two factors match each other, i.e., v = g ( s ) ; otherwise, s diverges. The function g ( s ) is concave, and has the maximum value of g This means that if v &gt; g maximum trackable speed of a moving stimulus. Notably, g neuronal interactions that induce the movement of the bump. g of the network, as this reflects the responsiveness of the net work to external inputs. On the other hand, for v &lt; g denoted by s well agree with the simulation results. 3.2 Tracking an abrupt change of the stimulus the stimulus position jumps from 0 to z ments studying mental rotation behaviors. We first consider the case that the jump size z time increases logarithmically with the jump size, namely, T  X  (  X / X  ) ln( | z Figure 4: (a) The dependence of the reaction time T on the new stimulus position z in Fig.3. (b) Profiles of the bump between the old and new posit ions at z up to n = 1 is required when the jump size z to Eq. (11), with R ( t ) replaced by
R ( t ) = 1 + an excellent agreement with simulation results for z even when z is influenced by the distortion of the width and the skewed sha pe of the bump. We can straightforwardly extend the above analysis to two-d imensional (2D) CANNs. Consider a neural ensemble encoding a 2D continuous stimulus x = ( x network holds a continuous family of stationary states give n by ( x  X  z ) 2 = ( x 1  X  z 1 ) 2 + ( x 2  X  z 2 ) 2 the Euclidean distance between x and z . which are expressed as the product of the motion modes in the 1 D case, i.e., The eigenvalues for these motion modes are calculated to be  X   X  The mode u the position shift in the direction x corresponds to the position shift of the bump in the directio n ( c positions. a = 0 . 5 ,  X  = 1 , J = widely used in the study of CANNs.
 valuable mathematical tool.
 The tracking dynamics of a CANN has also been studied by other authors. In particular, Zhang trackable speed of the network. stationary states and the tracking dynamics analytically.
 dynamics of a CANN is dominated by the motion mode of position shift of the network state, and the inhibition mechanism. We have formally proved that for a CANN model, once the recurrent the position shift mode irrespective of the inhibition mech anism (to be reported elsewhere). This work is partially supported by the Research Grant Counc il of Hong Kong (Grant No. HKUST 603606 and HKUST 603607), BBSRC (BB/E017436/1) and the Roya l Society. [1] P. Dayan and L. Abbott, Theoretical Neuroscience: Compu tational and Mathematical Mod-[2] S. Amari, Biological Cybernetics 27 , 77 (1977). [4] K.-C. Zhang, J. Neurosicence 16 , 2112 (1996). [5] A. Samsonovich and B. L. McNaughton, J. Neurosci. 17 , 5900 (1997). [6] B. Ermentrout, Reports on Progress in Physics 61 , 353 (1998). [7] S. Deneve, P. Latham and A. Pouget, Nature Neuroscience, 2, 740 (1999). [8] X. Xie, R. H. R. Hahnloser and S. Seung, Phys. Rev. E 66 , 041902 (2002). [9] A. Renart, P. Song and X. Wang, Neuron 38 , 473 (2003). [10] C. Brody, R. Romo and A. Kepecs, Current Opinion in Neuro biology, 13 , 204-211 (2003) [11] S. Wu and S. Amari, Neural Computation 17 , 2215 (2005) [12] B. Blumenfeld, S. Preminger, D. Sagi and M. Tsodyks, Neu ron 52 , 383 (2006). [13] C. Chow and S. Coombes, SIAM J. Appl. Dyn. Sys. 5 , 552-574, 2006. [14] J. Hopfield, Proc. Natl. Acad. Sci. USA, 79 2554 (1982). [15] J. Jastorff, Z. Kourtzi and M. Giese, J. Vision 6 , 791 (2006). [17] J. Zhang, J. Mathematical Psychology 48 , 409 (2004) [18] D. Heeger, J. Neurophysiology 70 , 1885 (1993). [19] M. Berry II, I. Brivanlou, T. Jordon and M. Meister, Natu re 398 , 334 (1999). [20] Y. Fu, Y. Shen and Y. Dan, J. Neuroscience 21 , 1 (2001).
