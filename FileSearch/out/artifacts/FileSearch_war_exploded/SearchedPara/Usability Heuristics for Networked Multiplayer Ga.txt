 Networked multiplayer games must support a much wider variety of interactions than single-player games because networked games involve communication and coordination between players. This means that designers must consider additional usability issues that relate to group play  X  but there are currently no usability engineering methods that are specifically oriented towards the needs of multiplayer games. To address this problem, we developed a new set of usab ility heuristics, called Networked Game Heuristics (NGH), which can be used in the design and evaluation of networked multipla yer games. The new heuristics were identified by analyzing problem reports from 382 reviews of networked PC games, covering si x main genres. We aggregated problem reports into ten problem categories (covering issues from session management to cheating to training for novice players) and developed heuristics that describe how these usability problems can be avoided. We test ed the new heuristics by having evaluators use them and an exis ting set to assess the usability of two networked games. Evaluators found more usability problems with NGH, and stated that the new heuristics were better for evaluating multiplayer game usability. Our research is the first to present networked game heuristic s that are derived from real problem reports, and the first to evaluate the heuristics X  effectiveness in a realistic usability test. H5.2 [User Interfaces] : Evaluation/methodology Design, Human Factors. Usability, networked games, multiplayer games, game usability, heuristic evaluation, Networ ked Game Heuristics, NGH. Most of the commercial video game s that have been released in recent years support networked play, in which groups of people can play together from different locations. Current networked games are extremely varied and cover several genres including first-person shooters, strategy game s, sports simulations, and role-playing games. Many of the game s support several different styles of cooperative and competitive play over the network, including free-for-alls where players compete against each other, and team-based play where people work together toward a common goal (e.g., capture the flag). Networked games involve interacti ons between players as well as interaction with the game environment itself, which means that these systems must provide support for communication, coordination, awareness, and soci al interactions between people. As a result, there is a much wi der variety of usability concerns that must be addressed for these systems than in single-player games. These additional usability issues that affect group gaming can collectively be called multiplayer game usability, which we define as the degree to which a player is able to successfully interact with other players and understand their actions. Multiplayer usability is not the only important issue in a networked game  X  but it is distin ct from other aspects of game design that have been studied previously. First, a game X  X  entertainment value is a well-know n but separate concern, and involves issues such as engagement , challenge, fun, and storyline. Second, multiplayer usability is different from single-user usability issues that are important for all games, such as input mappings, control sensitivity, visual representations, and training support [35]. Evaluating multiplayer usability is an important issue, since poor usability can greatly detract from the overall play experience, even if other aspects of the ga me are well designed. However, there are currently very few methods for evaluating multiplayer usability. Playtesting is one of the most common ways to uncover design problems [12], but this method needs playable prototypes that usually only exist in the la ter stages of the development process. Few methods exist to a llow designers to carry out less expensive usability inspections of games, and to also evaluate early, non-functional prototypes. Recent usability inspection techniques look at single-user usab ility issues in games [35,11,7], but there are currently no established methods for evaluating multiplayer usability issues in networked games. In this paper, we address this problem by presenting a new set of heuristics for evaluating multiplayer game usability. The heuristics, called Networked Game Heuristics (NGH), can be used during heuristic evaluations, where evaluators explore an interface while looking for usability problems [31,32]. The heuristic approach has been successfully used in previous game evaluations because it does not make assumptions about task structure, and it is flexible enough to be adapted to specialized domains [32,10]. We devel oped our heuristics using a methodology introduced by Pinelle and colleagues [35], in which heuristics are derived from actual experience reports  X  in this case, public reviews of networked PC games. From these reviews, we derived a set of usability he uristics for assessing multiplayer game usability. Our new heuristics, called th e Networked Game Heuristics (NGH), are the first design principles to focus exclusively on networked game usability, and are the first to be based on a structured analysis of reported usability problems from a large number of games and game genr es. A shortened form of the heuristics is shown in Table 1, a nd they are shown in more detail in Table 4. In the following sections, we describe the development of the new heuristics, and then report on a study in which ten evaluators used tw o different methods (NGH and Baker X  X  groupware heuristics [5]) to evaluate two networked PC games. Evaluators were able to find more multiplayer usability problems with NGH, and also reported that the principles were well-suited to the goals of the evaluation, were easy to learn, and were straightforward to apply. 
Table 1. Short summary of the Network Game Heuristics. Usability inspection techniques can play an important role in the design of networked video games. Most game design processes use playtesting to identify probl ems, but this is only possible during later stages of design a nd development when a functional prototype exists. Usability inspection techniques, where skilled evaluators inspect the prototype to find problems, are a potentially valuable addition to the game design process. They are inexpensive, and they can be used to evaluate prototypes at all stages of development. Most current usability inspection techniques are not appropriate for games, since most current me thods assume a different set of design goals than what are typically seen in games [35]. For example, many games are relatively unstructured compared with productivity applications, and pr omote exploration and varied playing styles rather than the completion of specific tasks. Further, one of the main goals of game designers is to engage and entertain the user  X  video game s emphasize music, voice acting, storyline, and artwork, so they do not follow the conventions seen in other applications. This m eans that evaluation techniques focusing on concepts such as task sequences (e.g., [4]) and desktop design (e.g., [31]) are of ten not appropriate for games. Literature on groupware evaluation provides insight into how usability inspection techniques can be developed for networked games. Groupware applications support multiple users, usually while carrying out cooperative ac tivities. Groupware applications are incredibly varied, but there are several persistent issues that designers have to address in most application areas. These include support for communication and c oordination, and support for helping team members to maintain an awareness of others X  actions, locations, activity leve ls, etc. [16,37]. Gutwin and Greenberg [15] call these common interaction primitives the  X  X echanics of collaboration. X  Gutwin and Greenberg [15] state that evaluations of multi-user applications must address both taskwork, which covers support for single user actions, and teamwo rk, which covers the  X  X ork of working together. X  Most techniques for evaluating the usability of groupware systems have addressed the teamwork aspects of design, and have left the evalua tion of taskwork to single user evaluation techniques. Several techniques have been proposed, many of which have been based on the mechanics of collaboration. These include a set of usability heuristics for groupware [5], a task analysis t echnique for multi-user scenarios [37], and a multi-user walkthrough technique [36]. However, most of these techniques are based on the notion of structured task sequences and focus on cooperation between users, so do not map well to games. The principles that we describe in this paper address  X  X eamwork X  (i.e. multiuser) issues in networked games and rely on the heuristic evaluation technique. Heuristic evaluation has been favored in recent work on game evaluation [e.g. 7,11,35] because it is flexible X  X t does not make a ssumptions about task structure, and it can be used in either formal or informal inspections. In heuristic evaluation, evaluators explore the interface while looking for problems based on a set of usability principles called heuristics [31]. They look for inst ances where there is a mismatch between the principles and the design, and record mismatches when they are real usability problems. In the next section, we describe design principles (i.e. heuristics) that have been developed for ev aluating networked video games. In recent years, several researchers have developed sets of heuristics that can be used to im prove the design of video games. Some researchers have focused on single-user aspects of design, and have not addressed multiplayer issues in detail. For example, both Federoff [11] and Desurvire et al. [7] developed heuristics that include coverage of se veral design issues, including playability, game mechanics, and usability. More recently, Pinelle et al. [35] developed a heuris tic set that provides detailed coverage of usability issues seen in single player games, and that addresses a range of issues in cluding control sensitivity, input mappings, and training and help. Many other researchers have inve stigated issues related to the design of multiplayer games. Much of this work has addressed technical issues that are important to the performance of networked games, including appr oaches for handling network traffic [39] and for designing dist ributed architectures [8]. Other researchers have covered issu es related to making games competitive and engaging [3,17], and some have investigated how games can be designed to foster online communities [9,21]. Few researchers have considered how usability issues should be addressed when designing mu ltiplayer networked games. Researchers that have studied usability have focused on design for specific platforms or specific types of games, such as mobile games and massively multiplayer games. For example, Cornett [6] performed an exploratory study to identify usability issues seen in MMORPGs. He developed a list of 17 usability problems that were found while observing users pl aying games, and he presents potential solutions for each problem. The problem list covers many issues that deal with singl e-player usability, and others are specific to the role playing genre (e.g.  X  X ttempts to buy/sell items were often unsuccessful X ). Korhonen and Koivisto point out that designing games for mobile platforms poses a unique set of challenges not seen elsewhere [23], and they developed a set of heuristics that address how networked multiplayer games can be designed for mobile devices [22]. Even though their heuristics focus on mobile games, many of them cover usability issues that are relevant to other types of networked games, including the need to support communication, the need to control address spoofing, and the need to help people find other players. Korhonen and Ko ivisto also address technical issues related to managing lag and network connections [22]. In summary, current literature does not address the problem of evaluating the usability of general networked games. In the next section, we describe our solution to this problem  X  a new set of heuristics specifically for multiplayer usability. We created a set of heuristics that can be used to carry out usability inspections of networked multiplayer games. We developed the heuristics using an a pproach that is very similar to the one used by Pinelle et al. [35] to develop heuristics for single-player games. We created the heuristics by identifying usability problems reported in 382 reviews of networked multiplayer games, and then developing statem ents that encapsulate how the problems can be avoided by designers. Using actual problem reports (from th e game reviews) as the basis for the heuristics is vital, as it ensures that the heuristics will reflect real usability concerns. Ga mes are incredibly varied, and significant design differences are seen between games and between game genres. Therefore, we felt that it was important that the heuristics represent the range of problems found in current networked games, and that that they provide both breadth and depth coverage of the design space. We addressed this by analyzing problems found in reviews of a large number of commercial games, cove ring six major networked game genres. The new heuristics focus on multi-user aspects of the design, and are not intended to provide complete coverage of all usability problems found in networked games. They can be paired with heuristics that cover single-user aspects of design (e.g., visual representations, control sensitivity, and input mappings) or evaluations that deal with fun, playability, and entertainment value. The next sections outline th e steps we used to develop the heuristics. Our first activity was to identify usability problems that were described in reviews of networ ked games. The reviews were obtained from two popular gami ng websites  X  GameSpy and GameSpot  X  that review a la rge number of games and that maintain archives of game re views. Reviews on both sites are written by professional editors and describe the quality of games, enumerating their strengths and limitations. In many cases, they cover usability problems (both single-user and multiplayer), providing a useful source of information on design problems that are found in games. We analyzed all reviews of netw orked PC games that were posted on GameSpot in 2006 and 2007 and on GameSpy from 2005 to 2007. To guarantee that broad coverage of multiplayer usability problems, we included a large num ber of reviews with coverage of several major genres. The reviews in the set were written by 42 different authors. We included 382 reviews: 29 of the reviews (8%) covered persistent onlin e games (including massively multiplayer online games), and the remaining reviews covered transient games (where player s set up and control the game servers themselves). The distribution of genres in the game reviews were: Strategy 34%, Shooter 23%, RPG 17%, Sports 16%, Simulation 5%, Action 3%, and Other 2% (see Figure 1). Reviewers reported problems about multiuser aspects of the game in 213 of the 382 reviews (56%). From a first pass through this data, we further subdivided problems into those that are specifically concerned with asp ects of the game X  X  design, and those that are caused at least partially by external factors such as network lag or server responsivene ss. After this division, we had 112 reviews (29% of the total) that discussed problems clearly related to multiplayer game usability. A typical example of a usability problem report can be seen in Madigan X  X  review of the game Cold War Conflicts . In discussing the matchmaking features, the reviewer states: 
CWC does include a multiplayer option, but once you take a closer look you see that the developers are just taunting you. The matchmaking mechan ism is all but nonexistent, requiring you to either be on a LAN or enter a computer's 
IP address to connect. There's supposedly a rudimentary search system, but it didn't work [30]. Further analysis of these 213 reviews was carried out by three of the authors who have substantia l experience with playing games and with conducting usability evaluations. Each person worked separately on the review sets, so that they could independently draw conclusions about the problem classes that were found. In this analysis, we identified th e multiplayer usability problems in each review, and also coded other problems related to multiplayer features. We excluded problems related to other aspects of the game (i.e., single-user usability, and fun and engagement). Each researcher devised informal categories based on the problems found, and individually coded pr oblems from the reviews using these initial categories. After all reviews were coded, we discussed the problem classifications to develop a co mmon classification scheme. There were initially 61 problem categorie s, but 18 were removed during the discussions. We aggregated the remaining categories based on similarities between problem desc riptions, and identified ten new problem categories. We also created five categories for the common problems that were relate d to networked play but that were not true multiplayer usability issues. We then recoded the 213 reviews using the new problem categories, and identified 147 multiplayer usability problems and 187 related problems. The usability problem categories are shown in Table 2, which briefly describes the problem covered by each category and lists a set of key issues that provide more detail on how the problem occurred in games from the review set. For example, the first category deals with session mana gement, and the key issues involve  X  X roblems with finding, jo ining, or starting games. X  The problem example listed in the last section was classified as a session management problem since it deals with difficulties encountered when trying to search for and join game servers. Table 3 shows the additional probl em areas that were frequently mentioned, but that are not directly related to usability. We include these because the problems were common, because they can have a serious impact on playability, and because they are related to multiplayer aspects of the games. The problem areas cover issues that have been previously discussed in CSCW, such as network latency, critical mass, and compatibility issues. We separated them from our main set because the problems are caused by elements such as the quality of a network connection, rather than the game design itself. The distribution of game genres seen in our review set was skewed, with four genres accounting for 90% of the reviews. Problems from almost all categories were reported for each of the four most common genres:  X  Strategy (35% of reviews): problems found in all ten  X  Shooters (23% of reviews): problems found in nine of ten  X  Role playing (17% of reviews): problems found in nine of  X  Sports (15% of reviews): problems found in seven of ten There were fewer problems found for some problem categories than for others. For example, th ree problem categories (6, 9, and 10) have fewer than ten problems. These categories were included because they were found in multiple genres, and because they had a substantial impact on the usability of the games. We used the problem categories and problem descriptions to develop ten usability heuristics for networked games. The heuristics, called Networked Ga me Heuristics (NGH), describe design principles that are intended to help designers avoid common problems seen in games. Each heuristic is based on the problem categories listed in Tabl e 2. For example, problem 7, which deals with inadequate support for training, became the heuristic  X  X rovide training opportunities where novice players are not subject to pressures from expe rts. X  The heuristics are listed in Table 4. We did not create heuristics for the problems of Table 3.Each heuristic contains a para graph that provides more detail on ways that related usability problems can be avoided. The paragraphs are grounded in details found in the game reviews. They elaborate on the basic concept stated in the heuristic itself, and were included to help designers map the heuristics to features found in game interfaces. Our heuristics have some simila rities to other heuristic sets presented in previous work (e.g ., [5,22]); however, as described below, there are several differences, and it is clear that deriving the heuristics directly from probl em reports in game reviews provides considerable specificity to the domain. Baker et al. [5] presented a set of groupware heuristics that are based on patterns of collaborative interaction seen in the real world. The heuristics cover three main areas: support for verbal and gestural communication, suppor t for maintaining awareness, and support for group coordination. Our heuristics address many of these same issues, but are more specific to games, and make the mapping between these issues and the game interface more explicit. Further, our heuristics a ddress several issues that are not covered by Baker X  X  heuristics (suc h as matchmaking or cheating). Several sets of game-specific heur istics have also been presented in earlier literature. Our heuristics have few similarities with the heuristics created by Desurvire et al. [7] and Federoff [11]. Our heuristics emphasize multiplayer usability, whereas previous heuristics primarily focus on playability and emphasize single player aspects of design. There are similarities between some of our heuristics and those created by Korhonen and Koivisto [22]. Their heuristics address playability issues related to multiplayer mobile games, so although the focus is somewhat diffe rent, there is some overlap in four of the heuristics related to communication support, matchmaking, awareness, and de viant behavior. There is some divergence in the details of the heuristic descriptions, however, since their principles focus on games for mobile platforms; for example, their heuristics deal w ith design constraints related to mobile phones, such as text entry limitations. We developed NGH using a method that was similar to the one used by Pinelle et al. [35]. They derived their heuristics by first analyzing usability problems found in public game reviews, but they included a different type of game (primarily single-player) and covered a different type of usability problem. Pinelle and colleagues X  heuristics address funda mental usability issues seen in video games, including consistency, customizability, input mapping, and control sensitivity. Our heuristics focus exclusively on multiplayer issues, so there is very little overlap between the two heuristic sets. Several of our heuristics are comp letely new and are not covered in any other heuristic sets. For ex ample, we define heuristics that address avatar design, protected training for beginners, and the need to minimize interaction delays. These issues have not, to our knowledge, been covered in any other game evaluation methodologies. 
Problem category Key issues Example Total 1. Session management 2. Matchmaking 3. Communication 4. Coordination Difficult to coordinate actions with other players 5. Awareness 6. Embodiments 7. Training 8. Social opportunities 9. Interaction timeframe 10. Cheating and unsavory behavior 
Problem category Key issues Example Total 1. Network latency Network lag, where response times interfere with game play 2. Network connections 3. Critical mass 4. Game play balance 5. Bugs and compatibility relevant information about game server s (e.g. ping, number of players online). that do not take the user X  X  atten tion away from events in the game. users that are logged into the game. providing mechanisms so that they can remove or sanction offending players. We conducted an evaluation where ten people used NGH to evaluate two networked multiplaye r games. Our goals were to determine whether knowledgeable evaluators could understand and operationalize the heuristics a nd whether the heuristics would be useful at identifying multiplayer usability problems. We also wanted to evaluate the areas of coverage seen in the set to see whether the heuristics were effective at specializing the evaluation process for networked games. Last, we wanted to determine whether the heuristic s improved on current evaluation approaches by comparing them to an existing set. We compared our heuristics to Baker et. al X  X  [5] groupware usability heuristics. Baker X  X  heuristics are based on the  X  X echanics of collaboration X  [15] and address common issues in shared tasks, including the need for verbal and gestural communication, and the need to coordinate cooperative actions. We chose Baker X  X  heuristics as a comparison case since they address generic collaboration issues that are important in most multi-user applications. We recruited ten participants w ho had previous experience with usability evaluations, and experi ence with multiplayer networked games. The participants evalua ted two networked video games. Participants were divided into two groups of five. One group used our heuristics to evaluate the first game and then Baker X  X  heuristics to evaluate the second. The other group used the heuristic sets in reverse order. We balanced the groups according to their experience with usability evaluation, with an equal number of expert and novice evaluators in each group. Participants evaluated two multiplayer games: BZFlag (www.bzflag.org), a 3D tank game, and Tee Wars (www.teeworlds.com), a 2D side-scrolling shooter. We used open source games in the evaluation because they were not professionally developed and were continually under revision by members of the development community. This means that they had design flaws that were simila r to those seen in functional prototypes, making them well suited to evaluation with usability inspection techniques. Prior to each evaluation, we trained participants on the heuristic sets that they would use during that session, and on classifying problem severity using Nielsen X  X  scale [33]. Participants were given printed copies of the heuristics that they would use to evaluate the game, and they were given forms for recording usability problems. During each session, evaluators were asked to spend 15 minutes playing and familiarizing themselves with the game, using any of the public servers available through matchmaking features. We then set up a testing server so that participants would be able to assess both competitive and cooperative aspects of play, and we asked them to log into our server for the remainder of the session. We asked participants to individually inspect the game interface using the heuristics. When they found a mismatch between the heuristics and the game interface, they were asked to record the mismatch if they felt that it was a usability problem. They were instructed to describe the problem , record the heuristic that they used to find the problem, and give each problem a severity rating using Nielsen X  X  severity scale [ 33]: 1-Cosmetic problem, 2-Minor problem, 3-Major problem, and 4-Usability catastrophe. The study lasted approximately 3 X  hours, and participants had roughly 90 minutes to evaluate each game. At the end of each session, participants completed a questionnaire that asked them to describe the strengths and weakne sses of the heuristics that they used. Once participants complete d both evaluations, they were given a final questionnaire that asked them whether they could identify problems more effectively with one heuristic set or the other, and they were asked wh ich set was easiest to use. We analyzed the problem descri ptions, removing problems that were repeated by the same evaluato r, or that did not describe real multi-player usability problems (e.g., commentary on gameplay). We counted the number of problems found using each heuristic, and we tracked the severity ratings that were assigned to each problem. Participants found a combined total of 49 usability problems using Baker X  X  heuristics (mean of 4.9 problems per evaluator), and found 67 problems with NGH (mean 6.7). The severity rating of problems for both sets was similar, with an average severity for Baker X  X  heuristics of 2.39, and 2.30 for the NGH set. Evaluators found a large number of problems in both games, and it is clear even from our simple study that multiplayer usability evaluations could have a major impact on the success of a networked game. Although it is not our goal to report on the specific evaluations of the games themselves, we briefly summarize the main problems found before analyzing the differences between the heuristic sets. BZFlag . BZFlag is a 3D tank game where people maneuver through the game world while shooti ng other players. Participants found a variety of problems, but their greatest frustration came from the absence of offline training and protected servers, since expert players logged into the evaluation server and dominated game play. People also found pr oblems related to communication support, and had particular difficulty using the text chat due to the real-time demands of the game. Other problems were found with the game X  X  support for coordina ting strategies with team members, understanding what is happing in the game, tracking teammates, and interpreting em bodiments in the mini-map. Tee Wars . Tee Wars is a 2D game where players move their character through the game world, attacking other players with an assortment of weapons. People f ound a wide range of problems, including issues related to finding appropriate servers and players with similar expertise levels, and limited opportunities to train offline. As in BZFlag, people f ound it difficult to find time to use text chat. They found a range of problems relating to awareness and coordination support, including problems with identifying teammates, the absence of a mini-map, and an inability to coordinate strategy with teammates. The problems found by the evaluators differed according to which heuristic set they used. Problem s found using Baker X  X  heuristics reflected the emphasis placed on real-world collaboration, including issues such as verbal and gestural communication, and this set appears to have constraine d the range of issues that people considered. Eleven problems were found using the verbal communication heuristic, but they missed problems with the text chat entirely; instead, they focused on the need for voice chat support:  X  X annot engage in voice chat. This would be good for this game so you can easily play and talk simultaneously. X  People also described eight problem s related to the gestural communication heuristic, although th e described problems related to the appearance of players X  embodiments. Participants described eight problems related to the coor dination heuristics, for example,  X  X o way to make an alternate st rategy or reorganize efforts. X  Problems were found for all other he uristics in the set, but these problems were less frequent (five or fewer). Problems were found using nine of our ten heuristics (see Table 5). No problems were found for heuristic 9 (interaction timeframe), but this heuristic was not very relevant to the real-time games included in the study. As with Baker X  X  heuristics, evaluators found a large number of problems related to communication, awareness, and c oordination. In some of the areas of overlap between the two heuristic sets, the focus of the problem descriptions was di fferent. Additionally, some substantive problems that were found using our heuristics were not found using Baker X  X  (train ing, matchmaking, unsavory behavior, session mana gement). There were some problems found using Baker X  X  heuristics that were not found using ours (a total of 8); however, we inspected each of these and it was clear that the problems could have been found with NGH. For example, a participant found a problem rela ted to mini-map design using Baker X  X  consequential communicati on heuristic:  X  X he direction a tank is facing cannot be determin ed on the mini map. X  Coverage for this problem is provided in our set by the awareness heuristic (H5), which explicitly addresses mini-map design. We believe that these differences were due to normal variation among evaluators. Evaluators found twelve problems using our coordination heuristic (heuristic 4), and the problems are similar to those found when Baker X  X  heuristics were used. People also found ten problems related to training for novices (H7); for example:  X  X ince games seem to be open to anybody it is hard to keep out expert players. X  There were eight problems related to awareness issues (H5), and there was significant overlap with those found with Baker X  X  heuristics. Participants identified eight matchmaking problems (H2), for example:  X  X o way to search for a particular player or a particular expertise level. X  People also found eight communication problems (H3), a nd the problem descriptions covered a broader range of issues than those seen in Baker X  X  heuristics. For example, they d ealt with both chat problems and verbal communication issues:  X  X t is hard to differentiate between status messages and chat X  and  X  X ince the game is quite fast, voice chat would be awesome. I died on a few occasions when texting. X  After each session, we gave partic ipants questionnaires and asked them to describe the benefits and disadvantages of using each heuristic set. For Baker X  X  heuris tics, three people indicated that there were no advantages. The other participants indicated that they helped to focus the evaluation on collaboration issues, with one person writing that they  X  X mphasized coordination and communication which this game l acked X  and another stating that they  X  X ocus on communication and interaction among players. X  All people listed disadvantages, and focused on difficulties that they encountered when mapping the heuristics to the games:  X  X oo task oriented whereas the game is very realtime/action oriented X ,  X  X he groupware issues only loosel y relate to gaming X , and  X  X id not really fit the domain. X  We also asked whether people were able to find problems using the heuristics that they would have missed otherwise. Only three people agreed, and indicated that they found problems related to support for informal encounters, and communication support. Participants listed two main benef its for using the NGH set. First, six people indicated that the heuristics provide a clear path to follow during the evaluation:  X  X ets you focus on the important issues. Provides guidance. X  Second, five people wrote that the heuristics help to focus the evaluation on issues that are important in games:  X  X learly targeted at game specific issues. Surprisingly effective at focusing the evaluati on on salient issues. X  Six people listed disadvantages, and these fell in to two main categories. First, four people wrote that all heuristic s may not apply to all game:  X  X  few heuristics are game specifi c and would not apply to all multiplayer games. X  Second, two people wrote that using heuristics constrains the problems th at they can find in games, and that they could miss problems not covered by the heuristics. Eight people indicated that they found pr oblems with the heuristics that they would have missed otherwise, and these cover a wide range of issues including communica tion, cheating, cooperative strategies, session-findi ng, and matchmaking. At the end of the study, we gave participants a final questionnaire and asked them to compare the effectiveness and ease of use of the heuristic sets. Most people (9/10) found that our heuristics were more effective at discove ring problems than Baker X  X ; one person felt that there was no difference. Most people stated that NGH provided better coverage of multiplayer usability problems. For example, one person wrote:  X  X GH totally trumped Baker X  X . NGH specifically identified multiplayer game-sensitive problems and Baker X  X  didn X  X  come close to identifying them. X  Another participant wrote:  X  X GH by a wide margin because it does look at specific things like session manage ment, training, cheating, and things that you wouldn X  X  have with more general heuristics. X  Most people also felt that our heuristics were easier to use than Baker X  X  (9/10), again with one person indicating no difference. People indicated that they found that Baker X  X  heuristics to be abstract and difficult to map to the game interface: e.g.,  X  X GH was easier and simpler because it was more specific and more easily mapped to the game elements. Baker X  X  was a little abstract X  Another wrote:  X  X GH was better ad apted to the task that I X  X  judging. With Baker X  X , it was just too hard to try to figure out how to apply a heuristic in this particular context. X  Finally, we asked participants which heuristic set they preferred for evaluating multiplayer games. Almost all of them (9/10) preferred NGH, but one person indi cated that they found both sets to be useful. The goal of the evaluation was to determine whether people could operationalize the heuristics and find real usability problems when using them to evaluate ne tworked games. We also wanted to assess whether the heuristics pr ovided adequate coverage of the problem space seen in networked video games. Further, we wanted to determine whether th e heuristics improved on current evaluation approaches. The evaluation shows that the new heuristics were effective at specializing the evaluation process for multiplayer networked games. Almost all participants found that they were a good match for evaluating the games used in the study, and they preferred using NGH instead of Baker X  X  heur istics when carrying out game evaluations. People indicated that it covered game specific problems that were not addressed by Baker X  X  heuristics, and that they were easier to apply because the mappings between features in the game interface were easier to establish. People found more problems using our heuristics than they did using Baker X  X  heuristics. The area of coverage seen in problems found with Baker X  X  set shows some of the limitations of applying generic heuristics to games. The heuristics emphasize verbal communication, which largely led people to overlook problems with chat interfaces that were f ound using our heuristics. Further, there were many areas of covera ge found using our heuristics that were not found using Baker X  X , in cluding training, matchmaking, unsavory behavior, a nd session management. Our heuristics were developed from problem descriptions found in reviews of commercial video games. We considered a large number of games, from several major genres, and we believe that the heuristics will generalize to ot her similar games. However, it is possible that they will not generalize to games that are significantly different than the ones covered in the review set. For example, some of the heuristics ma y not be applicable to simple online games where user interaction is very limited, such as online card games and ot her Web-based games. We based the heuristic set on PC games rather than console games; however, we believe that the heuristics will transfer to most networked console games si nce many commercial games are released concurrently for both pl atforms. We do not believe that the heuristics will transfer well to single-display games where several players use the same cons ole. Single display games do not need the same level of inter action support that is seen in networked games since people can communicate face to face. Therefore, while some of our he uristics may be relevant, it is possible that a different set is needed for single-display settings. Our heuristics focus exclusively on the multiplayer usability issues seen in networked game s. They do not address single player usability, and need to be pa ired with single user heuristics, such as those described by Pinelle et al. [35], to provide full coverage. Further, the heuristics do not address other aspects of design that are important to the success of games, such as the challenge level and entertainment va lue. Other heuristics, such as those described by Federoff [11] a nd Desurvire et al. [7], address these issues, and they could potentially be used in conjunction with our set. NGH, like all heuristic sets, must be viewed as guidelines rather than rules; and it is possible that designers will intentionally violate various heuristics in suppor t of different types of game play. For example, in a spy game designers may want friends and enemies to be difficult to distinguish, which would violate our heuristic that emphasizes the need for identifiable avatars. The point of the heuristics is to provide designers with a set of principles that they can use to clearly decide whether a challenge or difficulty in the game is an intentional part of the gameplay, or whether it is an unnecessary usability problem. It is also likely that expert evaluators can identify many multiplayer usability problems without the need for a heuristic set. However, using the heuristic s provides a structure to help them consider each major design dimension in turn, and to prevent them from becoming distracted by other aspects of the design, such as single user or entertainment issues, which could cause them to miss important multiplayer problems. We also note that the heuristic set was comp iled from problems that were found in commercial games that were released to the market, meaning that many of the issues covered in the set were not addressed by designers prior to the release. Our heuristics are the first gene ral set that covers general multiplayer problems found in networked games. We believe the reviews we used provide thorough coverage of major usability problems seen in networked game s. However, the reviews were not written by usability professionals, and did not focus on usability issues as the main eval uation criteria. Therefore, it is possible that our heuristic set missed subtle usability problems, or problems that occur in early formative stages. We expect the heuristics to continue to grow and evolve in the future as we gain more experience and insights from using them to evaluate more games. There are few methods for evaluating the usability of multiplayer networked games. We developed a new set of heuristics (NGH) to address multiplayer issues during network game design; the heuristics can be used to evaluate both early mockups and functional prototypes. Our heuristics are the first set to focus exclusively on usability problems found in multiplayer features of network games. The heuristics ar e based on problem reports from a large number of games and provi de broad coverage of major game genres. Evaluation results show that evaluators are able to use the heuristics after a brief training session, that they are able find real usability problems related to multiplayer features, that they provide broader coverage of problems seen in games than Baker X  X  groupware heuristics [5], and that people preferred them over Baker X  X  heuristics. The new heuristics contribute a valuable new tool for assessing and improving multiplayer usability. In addition, they also show the va lue of domain-specific heuristic sets, and show the potential for using reviews as a source of usability data. [1] Abner, W. Review of Hero es of Might and Magic V, [2] Accardo, S. Review of Medal of Honor: Airborne, [3] Alexander, T. Massively Multiplayer Game Development . [4] Annett, J. and Duncan, K.D. Task analysis and training [5] Baker, K., Greenberg, S., Gutw in, C. Empirical development [6] Cornett, S. The usability of massively multiplayer online [7] Desurvire, H., Caplan, M., Toth, J. A. Using heuristics to [8] Diot, C., Gautie, L. A Distributed Architecture for [9] Ducheneaut, N., Moore, R. J., &amp; Nickell, E. Designing for [10] Dykstra, D.J. A Comparison of Heuristic Evaluation and [11] Federoff, M. Heuristics and Usability Guidelines for the [12] Fullerton, T., Swain, C., Hoffman, S. Game Design [13] Gamespot staff. Review of Tom Clancy X  X  Rainbow Six [14] GameSpy staff. Review of Dungeons &amp; Dragons Online: [15] Gutwin, C., Greenberg, S. The mechanics of collaboration: [16] Gutwin, C. and Greenberg, S. The effects of workspace [17] Habgood, J., Overmars, M. Game Maker X  X  Apprentice: [18] Harker, C. Review of RYL: Path of the Emperor, [19] Harms, W. Review of The Lord of the Rings: The Battle for [20] Harms, W. Review of Rainbow Six: Lockdown, [21] Koivisto, E.M. Supporting Communities in Massively [22] Korhonen, H. Koivisto, E. M. Playability heuristics for [23] Korhonen, H. and Koivisto, E. M. Playability heuristics for [24] Kosak, D. Review of Crysis, pc.gamespy.com/pc/ea-crytek-[25] Kosak, D. Review of Age of Pirates: Caribbean Tales, [26] Kosak, D. and Lopez, M. Review of Guild Wars, [27] Kuo, L.C. Review of Trackma nia United, pc.gamespy.com/ [28] Kuo, L.C. Review of GTR 2, pc.gamespy.com/pc/gtr-2/ [29] Kuo, L.C. Review of Tom Clancy's Splinter Cell Double [30] Madigan, J. Review of Cold War Conflicts: Days in the Field [31] Nielsen, J., and Mack, R.L. (Eds.), Usability Inspection [32] Nielsen, J. How to Conduct a Heuristic Evaluation. [33] Nielsen, J. Severity Ratings for Usability Problems. [34] Osborne, S. Review of Track Mania Sunrise, pc.gamespy. [35] Pinelle, D., Wong, N, Stach, T. Heuristic Evaluation for [36] Pinelle, D. and Gutwin, C. Groupware Walkthrough: Adding [37] Pinelle, D., Gutwin, C., Greenberg, S. Task Analysis for [38] Rausch, A. Review of He llgate London, pc.gamespy. [39] Smed, ,J., Kaukoranta, T., and Hakonen, H. Aspects of 
