 We compare four tagging-based enterprise services, which respectively stored bookmarks to webpages and documents, to people, to blog entries, and to hierarchically-structured activity records. Analysis of user data and tag data showed relatively small overlaps in tags used. Conventional normalization strategies produced only modest improvement. These results suggest difficulties in combining exploratory searches across multiple social-tagging services. We recommend strategies for cross-service tag integration at the points of tag storage and tag search , rather than at the conventional point of tag entry . We close with a research age nda around this strategy. H.5.3. Group and organizational interfaces/Collaborative computing &amp; CSCW.
 Measurement, Experimenta tion, Human Factors, Social software, tagging, tag-sugge stion, auto-completion, corpus In our research on social computing within the enterprise, we have been interested to unders tand how people interpret and use social tagging services in different contexts (see [14, 16, 19] for general reviews). This paper pr ovides the first look at tag usage across multiple tagging services. Social tagging occurs when a user associates a resource (such as a URL) with a user-chosen descriptor word or phrase (called a tag) in a shared environment in which other users can search and view the user X  X  tags. The first and most well-known form of social tagging occurred in the shared bookmarks of the website del.icio.us (for the first study of th ese practices, see [14]) In this service, users created bookmarks similar to those used in individual X  X  web browsers, usually with the addition of (a) one or more tags and (b) additional free-fo rm descriptive text. The user could search her/his own collecti on of bookmarks, or could search the bookmarks that had been created by other users. Soon, the concept of tagging was extended to shared photographs (www.flickr.com), shared videos (www.youtube.com), shared evaluations of movies ( www.movielens.umn.edu --see also [33]), blogs (www.technorati.com), and an increasing diversity of more specialized resources su ch as books (www.amazon.com), books in one X  X  own library (www.librarything.com), and persons (www.facebook.com). Several e xperimental services have experimented with online collaborative games to expand the set of tags on selected resources (e.g., [35]). These services have in common the concept of a resource with a unique online representation, whic h is tagged by one or more users in an asynchronous shared environment. These services differ from one another in the type of resource being tagged, but also, significantly, in the structure of the tagging record. As mentioned, the original form of social tagging involved an enhanced version of a browser bookm ark (e.g., [14, 20, 21]). This structure preserves the user ID of the tagger, and allows the user (tagger) to return and modify the bookmark if needed. Because this structure associates each us er with one or more bookmarks and one or more tags, is supports some aspects of social networking [16, 20], as well as the possibility of identifying potential domain experts by the frequency with which they use certain tags [10, 11, 17]. By contrast, some services omit the intermediary structure of the bookmark, or make it unavailable to for editing by the user, and thereby apply the tag directly to the resource (e.g., [10]  X  see also [34]). This structure tends to re duce the association of user with tag (or user with resource). This structure also provides for a simpler database and potentially increased computing efficiency. We have been prototyping and studying social tagging systems within IBM Corporation. Tagging services within an enterprise can take advantage of full authentication of users, facilitating the identification of experts [10, 17], people with shared interests [20, 21], features of a shared vocabulary [7], and colleague-based strategies of information search [17]. Some of these strategies may be available, perhaps to a lesser extent, for searches on the public internet. Full authentication also makes it possible to compare users X  tagging practices in multiple tagging-based services, because users authenticate in the same manne r, with the same user ID, in all enterprise services. This paper goes beyond the previous research, by examining tagging behaviors across four distinct tagging-based services, applying to four types of resources, with partially-overlapping user populations, within a single enterprise. This paper takes a comparative view that was not possible in previously published single-service analyses. The comparative view provides insights into the strengths and weaknesses of tag-based storage and tag-based sear ch across services, and suggests new approaches to solving problems of an integrated view across tag-based services. Golder and Huberman [14] described a pattern of vocabulary stabilization with increasing tag usage on a particular resource (i.e., across multiple bookmarks that were created by multiple users to describe that resource) . Similar results were later obtained by Damianos et al. [7] and Sen et al. [33]. This robust finding suggests that groups of users tend to establish a reliable and consistent set of descriptor s for a particular resource, and presumably a consistent usage pattern for each tag. Each of these studies examined a different social-tagging service, and each of these studies restricted its analysis to the data within that respective single social-tagging service. We hope to learn if people expect each tag to have a stable, consistent meaning across multiple social-tagging services, and if their tag usage is consistent across the multiple types of objects stored in the multiple services. Clark X  X  concept of common ground suggests that people need concepts and words in common in order to engage in collective actions (e.g., [6]). Tagging services in general appear to offer a means for achieving such common ground. Tagging services within a work-oriented enterprise would seem to be a particularly promising setting for people to engage in the co-construction of their common understandings. Our studies will help us to understand the semantics of social-tagging services, and thus the extent to which these services can provide a set of common descriptor s for an enterprise X  X  collective knowledge. We collected tag data from the four services summarized in Table 1. Examples of the structure of tag entries are given in Table 2. Dogear is a social-tagging service for resources such as public URLs, company-internal URLs, and other company internal documents (e.g., Wiki pages, Domino documents, etc.) [21]. Dogear bookmarks are readable by any authenticated user in the company. An example of a D ogear bookmark could be a URL to a sourceforge project, with a bookmark title of  X  X ist Manager X , a brief comment about the significance of the content, and  X  X ags such as  X  X jax X ,  X  X I X ,  X  X ist-ma nagement X , and  X  X ourceforge X . Dogear became operational on 12 July 2005, and had accumulated a total of 21072 tags entered by 1710 users on more than 72677 URLs and documents, as of the closing date of this study. Dogear continues to be used for daily work [20, 21]. Bluepages+1 (BP+1) is an enha nced version of the company X  X  online Bluepages employee directory [10]. Among its enhancements is the ability for one person to apply a tag directly to another person X  X  directory page . Bluepages+1 data (including tags) are readable by any authenti cated user in the company. An example of a BP+1 tag could be the name of an employee, tagged with her/his role (e.g.,  X  X roject manager X ), hints about expertise 742 3269 10209 From 0 to several (e.g.,  X  X arge systems X ,  X  X ederal X ), and personal information ( X  X ootball X ,  X  X umismatics X ). Bluepages+1 became operational on 16 November 2005 as an extension of the set of experime ntal Fringe services [9]. Bluepages+1 had accumulated a to tal of 2992 unique tags entered by 731 users describing 7601 people, as of the closing date of this study. BP+1 continues to be used for daily work. Blog Central is an internal blogging service, open to any employee. All entries in Blog Central are readable by any authenticated user in the company. An example of a BlogCentral tagged record could be the blog entry and author-supplied tags such as  X  X ROUP2005report X  and  X  X onference X . Version 1 of Blog Central b ecame operational during October 2003. Blog Central had accumulated a total of 3322 unique tags entered by 2092 users to describe 23143 blog entries, as of the closing date of this study. Blog Central continues to be used for daily work. The Blog Central data structures pr ovide for a separate list of tags for each blog and for each entry within each blog. There is no automatic propagation of tag data from one Blog Central record to another. All tags must be entered manually. Activities [22] is a web-based ve rsion of ActivityExplorer [13, 27], an activity-centric collaboration service in which teams may create a collections of diverse objects in a tree-like structure consisting of a root  X  X ctivity X  and its daughter components. Unlike the other three services, Activities restricts access to each activity to a specified access control list, which may be as small as one person, or as large as se veral hundred people. An example of an activity with tags could be the structured collection of objects (documents, messages, chats, etc.) called  X  X rite GROUP 2007 paper X  with tags such as  X  X onference X ,  X  X ROUP2007 X ,  X  X ocial-tagging X , and  X  X eadline:21May X , and with membership of the co-authors of the paper and selected internal reviewers. Activities became operational on 23 November 2005. The Activities data structures provide a separate list of tags for each object. As of the close of the data collection for this study, there was no automatic propagation of tags from Activities record to another. All tags were entered manually, for a total of 3269 unique tags entered by 742 users to describe a total of 10209 activities and activity components. Since the close of the study, automatic tag inheritance has been added to the Activities system, such that any child object automatically receives (at the time of creation) any tags that had been associated with its parent object. The Activities server continues to be used for daily work. As summarized in Table 1 and shown in Figure 1, each of the services has been used over a long period, and users have accumulated a large number of tagged resources in each service. Dogear has become a standard means of sharing internal and external webpages and addressabl e documents [21]. BP+1 has been used not only for reputation management ([10]; see also [11, 25]), but also for organizing lists of colleagues related to both expertise and project involvement. Blog Central is the primary point of informal publication within the company. Activities [22] is used by several hundred people every week to coordinate intra-and inter-organizational work, surpassing the kinds of uses originally anticipated for an activity -centric service (e.g., [27]). The data in Table 1 and Figure 1 reflect only the addition of new previously-entered resource does not appear in those presentations, and the use of the services by readers is also not visible (see [20] for an analysis of search and readership in Dogear). These additional categor ies of use, while substantial, are beyond the scope of this report. This theme of real work and frequent access will be revisited below in the section on  X  X iscussi on of Low Tag Re-Use Rates. X  For Dogear and BP+1, it was possible to obtain, respectively, a log containing one record for each bookmark as it was entered. These logs were collected and preserved on 21 July 2006. Each record provided full information a bout the date, time, tag, user, and resource. Each log record al so contained additional data that were specific to each service; these additional data will not be analyzed in this paper. For Activities, there was no similar log of bookmark entries, so we obtained a copy of the DB 2 database tables from that production server, as of 21 July 2006. Information pertaining to the contents of activities was considered confidential and sensitive, and was kept within a secure server which could be accessed by fewer than 15 people. Only the less sensitive data of date, time, tag, user, and activity -node-ID were extracted for the analyses in this paper. A dditional data, which will not be reported here, will in future allow an analysis of tag re-use among the parent/child relationships w ithin the hierarchical activity structures (see [13, 22, 27] for details about these hierarchical structures). There was a delay in obtaining a si milar copy of DB2 tables from the Blog Central production server. A copy was finally saved into a highly secure server on 9 August 2006. As with the Activities data, all contents of entries were kept within the secure server environment, and only the less sens itive data of date, time, tag, user, and blog-item-ID were extracted for the analyses in this paper. Additional data, which w ill not be reported here, will in Figure 1. Cumulative resources that were tagged in the four future allow an analysis of tag re-use among the blog-root and blog-node (or blog entry) hierarchical structures. Data from all four services were reduced to a  X  X ormal form X  consisting of date, time, tag, user , and resource ID. The type of resource was of course different fo r the different services, so the resource-ID data were used only to differentiate items within each service. By contrast, dates, times, tags, and users were comparable across services, and were analyzed where appropriate on a cross-service basis. Where possible, data from the peopl e responsible for a particular system were removed from the analyses, in case their usage was somehow unrepresentative, as wa s done in [11, 20, 21]. Very small teams were responsible for the Dogear and BP+1 prototypes, and it was easy remove their data prior to analysis (4955 records or 2% of Dogear records from three users and 384 records or 2% of BP+1 records from four users). However, because Activities was a product, many people had had some form of time-limited relationship with the Activities server. It was not possible to make a simple de termination of a small number of team members whose data could be deleted before analysis, so we analyzed all records from the Activities service. Similarly, because Blog Central was a large internal project that ran two different versions of a producti on server, many people had some form of time-limited relationship w ith one or both versions of the 
Service Dogear 
Blue-pages+1 293 -193 228 Blog-Central 359 193 -289 
Activitie s 613 228 289 -
Number of Services Mean users-in-2 (six pairs) 329.17 41% 3 (four triples) 137.5 19% 4 (one quadruple) 79 11% 2. Iteratively calculate the similarity between pairs of fractions Blog Central service. It was not possible to make a simple determination of a small number of team members whose data could be deleted before analysis, so we analyzed all the data from the Blog Central service. Several of the systems contained logged data from their very first day of beta or alpha operation, even though there were bugs in the data-logging routines. In conse quence, some records contained missing or obviously incorrect data (e.g., dates that were earlier than the first date of service). We rejected the following numbers of normal-form records from each service for these reasons: Dogear: 14545 records (5%); BP+1: 0 records (0%); Blog Central: 361 records (1%); Activities: 0 records (0%). Because each system was has been used for real work by a large population of users, these rejected records constituted only a minimal percentage of our total dataset: 14906 records in across all four datasets, or 4% of all data records. For the purposes of this paper, data consisted primarily of user-tag tuples. Note that previous studies of tagging behaviors within a single service have included not only user and tag (as in our study), but also the tagged object [7 , 10, 14, 17, 21]. By contrast, this paper is concerned with tagging across diverse services , where each service is concerned with different types of tagged objects (e.g., documents vs. pe ople vs. blogs vs. activity components). The same objects cannot appear in different services, because each service stores a different class of objects. Therefore, for this initial report, we omit references to the tagged objects, and focus only on the users and the tags. Analyses showed complex patterns of overlaps (Table 3). Many of the 4987 unique users participated in more than one of the services. On a pairwise basis, the number of people writing tags into each respective pair of services ranged from 193 users (BP+1 and Blog Central) to 613 users (Dogear and Activities), with a mean pairwise users-in-comm on figure of 329.17, or a mean users-in-common percentage of 41% (calculated per [4] as the Overlap Coefficient  X  i.e., by dividing the users-in-common by the smaller of the numbers of users in each of the two source services). Smaller numbers of us ers participated in more complex intersections of the services, with only 79 (11%) of the users participating in all four services. The mean of 329.17 users in common across pairs of services provides ample opportunity to explore the potential for common vocabularies across services. When we examined tags in the four services, we found similar, complex patterns (Table 4). Of the 28460 unique tags, many appeared in more than one service. On a pairwise basis, the number of tags appearing in each respective pair of services ranged from 522 tags (BP+1 &amp; Activities) to 2953 tags (Dogear &amp; Blog Central), with a mean two-service tags-in-common figure of 1394.17, or a mean tags-in-common percentage of 36% (calculated, as above, by dividing the tags-in-common by the smaller of the numbers of tags in each of the two source services).. Smaller numbers of tags appeared in more complex intersections of the services, w ith only 396 (13%) tags appearing in all four services. These are surprisingly small numbe rs of tags-in-common, if we consider that users were engaging in real work  X  and the same real work  X  with all four systems (Figure 1). But how large an overlap should we have anticipated, in view of the well-known phenomenon of users choosing diffe rent words to describe the same computational concept [12]? To answer this question, we adapted a method from the comparison of text corpora. Kilg arriff [18] argued that measures of similarity or dissimilarity between two corpora required a baseline or standard of compar ison. He developed statistical methods that could be applied in identical ways, and with identical power, to ask (a) how similar were two different corpora, and (b) how self-similar was each of the corpora to itself? He used each corpus X  X  self-similarity as a baseline for evaluating similarity or dissimilarity when comparing one corpus with the other. The core of Kilgarriff X  X  method is to split each corpus into equal-sized fractions, and then to perform iterative similarity comparisons among all possible pairs of those fractions. For example, suppose that there ar e two corpora, corpusA and corpusB. Divide each corpus into three equal-sized fractions. This method could be used as follows to calculate both the similarity between corpora and the self-similarity within each corpus, as follows: x Other-similarity (between corpora): One fraction in each x Self-similarity (within each corpus): Both fractions in each Table 5 provides a summary of this simple example. The same respective pairs of fractions are used to calculate the self-similarity of CorpusA, the self-similarity of CorpusB, and the other-similarity of CorpusA vs. CorpusB. It remains to specify the correct number of equal-sized fractions, and the method used to calculate similarity for each pair of fractions. For each service, we took all the tags 1 , randomized their order, and then divided them into ten e qual-sized fractions, or deciles. To calculate the self-similarity measure of each service, we performed 90 similarity calculations, one for each pairwise set of deciles, omitting identical decile s which would of course have had perfect self-similarity (i.e., in Table 5, there are no comparisons along the major diagona l of each corpus X  X  matrix, or no comparisons of A1 with A1, A2 with A2, and so on). The similarity measure was simply the ratio of the number of tags-in-common across the two deciles, di vided by the mean size of the deciles. Thus, perfect similarity would produce a ratio of 1.0, and zero similarity would produce a ratio of 0.0. To calculate the other-similarity measure for two services, we performed 90 similarity calculations, one for each pairwise set of deciles, but in this case we drew one fraction from the first service, and one fraction from the second service. For strict Previous analyses were based on the unique tags in each service. 
We used all the tags in this analysis, because a restriction to unique tags would have led to se lf-similarity figures of zero. comparability, we omitted the analogous ten pairwise fractions to those that were omitted in the sel f-similarity calculations (i.e., the major diagonal), resulting in 90 pairs that were analogous to the 90 pairs in the self-similarity calculations. As a result of this process, for each pair of services, we had (a) 90 measures of other-similarity be tween the services, and (b) two sets of 90 measures of self-similarity within each service. We calculated the median of each of these 90 sets of fractional similarity measures, resulting in six other-similarity summary measures (one for each pair of services), and four self-similarity summary measure (one for each service). These medians are displayed in Figure 2. As Figure 2 shows, all self-simila rities are stronger than all other-similarities. The calculation of sampling variance in these kinds of overlapping analyses is difficu lt, but we can use a simple Mann Whitney U test to show that the four self-similarities are significantly greater than the six other-similarities (U=0, p&lt;.01). By the logic of Kilgarriff X  X  appro ach, this is strong evidence that there is greater tags-in-common w ithin a service than there is between any two services. Th is more detailed approach corroborates the conclusion of the earlier section ( X  X ervice Vocabularies: Tags in Common X ) that there is relatively low commonality of tags across services. Tags occurred with different re lative frequencies in different services. Using the Fisher r-to-z transformations, we calculated the mean correlation of relative tag frequencies across services as r=.286. While significant (p&lt;.001), this correlation explains only 8% of the variance. People appear to use tags in somewhat different ways in the different services. We were surprised at the low commonality of tags across services. Therefore, in addition to comparing lists of users and tags on a service-vocabulary basis (above), we also conducted analyses at the level of each person (personal vocabulary) and each tag (tag membership). When we focused on personal re-use of tags across pairs of services, we found very low tags -in-common rates (mean of 1.06 tags-in-common per person, or mean of 2.65% of per-user opportunities to have tags in common). When we re-focused our analysis on the tags, and asked whether each tag was associated with the same users across services (a relationship that we called  X  X ag membership X ), we again found very low rates of commonality (mean of 0.35 people associated with the same tag in different services, or mean of 4.89% of per-tag opportunities to have users in common). We considered that these results might have been due to a sampling oversight, i.e., the mistake of including people who might have created only a very sma ll number of tags in a service. To test this sampling-error hypothesis, we sorted each set of data in terms of the minimum number of tags created by the user in each of the services under analysis. We then experimented with temporarily removing the users with the lowest numbers of tags in one service or the other. We systematically tried all possible cut-off usage rates. None of the cu t-off rates substantially increased the tags-in-common on a user-by-user basis. None of the cut-off rates substantially increased the number of people associated with each tag. The phenomena of low tags-in-common and low tag-membership appear to be robust across users with any number of tags. It could be argued that these results are not very surprising: If people were describing different types of objects, then shouldn X  X  they use different vocabularies to do so? This explanation is not supported by the data. If people used different vocabularies for differe nt types of objects, then we should have found very few tags in common between services. In fact, we found a minimum of 522 tags in common across pairs of services. Thus, the re-use of the tags, on a service-by-service basis, provided ample opportunity for the re-use of tags on a person-by-person basis. Nonetheless, we found very little personal re-use of tags. We also note that, at a conceptual basis, all four services were designed to support people X  X  daily business work. Furthermore, people in fact do use those services for real and daily work, as briefly summarized above in the section  X  X ervices Used for Real Work X  (see also [10, 11, 13, 20, 21, 22, 23]). On this basis, it appears reasonable to expect peopl e to use similar vocabularies to describe the related aspects of th eir work that involved different types of objects in different tag-ba sed services. That is, we could easily expect that a user woul d bookmark a website (in Dogear) using the same project-related tags that s/he used to bookmark a collaboration partner (in BP+1) and th at s/he used to describe that project in a posting in Blog Central or Activities. But this did not appear to take place very often, as reflected in the low re-use of tags on a person-by-person basis. Another possibility is that people did re-use their tags, but did so with variations in spelling or capitalization or punctuation. We explored the following normalization strategies applied to all of the tags from all four of the services: x  X  X olding X  all alphabetic characters to lower-case x Stemming  X  both Porter stemming ([30]; see also [36]) and x De-prefixing (e.g., removing a prefixed symbol such as  X - X  The best results (achieved with a combination of de-prefixing and Porter stemming) led to a 21.3% im provement. This is promising, but a manual inspection of the most-frequently occurring tags in each combination of services showed many additional missed opportunities to find tagging commonalities. There were three major classes of missed relationships that c ould not be addressed through the three normalization strategies listed above: x Examples of missed semantic-level overlaps included the This is a partial list, to prot ect some sensitive project names. x Examples of missed person-level overlaps included different x Examples of missed concept-level overlaps included Other research within two of thes e services has shown that people devote considerable effort into writing tags [21], that people use the tags to search for relevant items across services [26], and that in some cases people use the ta gs as part of managing their reputations within the enterprise [10, 25]. We are left with the apparent paradox that people work hard to write tags, but seem not to do this consistently for rela ted aspects of their work that are stored in different services. It appears reasonable for a user to expect to re-use tags from one service to another. Our results s uggest that simple tag re-use may prove more difficult than anticipated. Indeed, our work on an experimental aggregation service based on tags showed that, for some users, sparse tag-based sear ch results were a problem [26]. We consider three distinct stra tegies for supporting tag re-use: support during the task of entering a tag into a bookmark ; support during the storage of a tag into a tagging-service database; and support during the task of conducting a tag-based search . Various methods are under investiga tion at internet and intranet sites to assist users during the task of initial tag-entry (i.e., during the creation of a bookmark) to re-u se the tags that are already available at that site. Some site s offer a list of popular tags; other sites provide type-ahead or auto-c omplete suggestions as the user is beginning to enter the first few le tters of a tag; still other sites remind a user of the tags s/he recently used (for review, see [16, 33]). Most of these strategies, if applied to our situation of four distinct services, are likely to prove ineffective for the following reasons: Popular Tags. Popular tags are unlikely to help users who are in the  X  X hin X  part of the  X  X ong tail X  distribution of tag usage (e.g., [1]; see also [3, 15]), at which the greatest differentiation is provided by low-frequency (high information value) tags. In fact, the over-use of popular tags has been shown to decrease their information value [5], and may prove detrimental to providing a strong vocabulary that can help user s with particular queries, with particularly adverse impact upon  X  X inority disciplines X  and communities of practice [24]. This is a fictitious user name , to protect employees X  privacy. Type-Ahead Suggestions. Type-ahead suggestions are useful only for a subset of potential overlaps, namely those that have the same root. For example, type-a head suggestions are relatively ineffective for synonyms that do not occur in dictionary-order proximity. In fact, type-ahead suggestions are substantially similar to stemming strategies di scussed above, and fail to answer the needs of many semantic-level and person-level overlaps. And in practice, the largest of the four enterprise systems in this paper already implements a form of type-ahead-based assistance for tag-entry [21], and its vocabulary continues to contain many variants on what appear to be common tags [22]. One possible compromise would be to provide the user with only her or his own tags, to improve self-consistency. Tag Database Evolution . At a conceptual level, all of these strategies may be flawed because each operates at a single moment in time, whereas a tag da tabase is constantly evolving with new entries. Helping a user to enter an appropriate tag or tags at one moment, tells us little about the appropriate associations with tags that are added to the database at a later moment. It is, of course, possible for a user to edit a bookmark and update the tags associated with it at a later date, but this occurs relatively rarely in practice. Thus, the best we can hope for, with tag-entry support, is to integrate a bookmark with the current state of the database, but not with future states of the database. 4 While this point may seem obvious, it reveals a weakness of the tag-entry strategi es, as contrasted with other kinds of interventions to strengthen tag re-use across services. Summary: Weaknesses with any Method Emphasizing a Moment-in-Time. In summary, the weakness of all of the strategies during initial tag-entry is that the best they can do is to integrate with the available tags at a particular moment in time. If there is evolution within a partic ular tag-based service, then the integration at earlier moments in time provides decreasing help for later moments in time. If there is an addition of a new tag-based service, then there is no historical integration based on previous moments in time. To achieve an integration that works for both present and future states of tag-based services, we need a different strategy. A second approach involves st oring each tag as entered, and storing various processed versions of the tag, using an enhanced set of the methods discussed in  X  X iscussion of Low Tags-in-Common, X  above. For example, a tag that was entered as  X  X rganizationalLearning X  would be stored with that exact text, but would also be stored as  X  X rganizationallearning X  ( X  X olded X  to lowercase),  X  X rganizational-learning X  (normalized punctuation),  X  X rganiz-learn X  (stemmed via Porter stemming, with normalized It may be argued that each tag that is added to a database automatically becomes part of the context for future tags. 
While this is true in principle, the impact of adding a particular tag to a large database is of cour se very small. Only a very few tags are ever visible as  X  X opular tags X  or  X  X ecent tags. X  All of the other low-frequency or slightly -stale tags become invisible in these two tag-entry strategies. Each added tag is of course capable of influencing the list of type-ahead suggestions, but (as noted earlier) these suggestions fa il to capture some semantic and some personal overlaps. punctuation), and possibly  X  X rg aniza-learn X  (stemmed via Paice/Husk stemming, with normalized punctuation). Additional enhancements could include lexical lookups (e.g., synonyms) and a vector of frequently co-occurring tags. Xu et al. [37] and Halpin et al. [15] proposed such methods for finding related tags within a single service (see also [2]). It should be possible to extend that method to recommend related tags in a multiple-service environment, based on the co-occurrence of tags within each component service. Social recommendation provides a nother potential strategy for calculating related tags. This appr oach begins with one or more user-provided tags, and suggests ot her tags that were used by either (a) other people who used the same tags; (b) other people whose overall tagging patterns were si milar to that of the current user; or (c) other people who are cl osely related to the user in a social network analysis. Similar strategies are frequently used in recommendation systems (e.g., [32, 33] ). It should be possible to extend that method by applying ta gs used by related persons within one service, to make ta g suggestions in a multiple-service environment. In general, the strategy of supporting tag storage has the advantage of preserving any special spelling or punctuation conventions of the user [23], while also providing a more standardized representation that may be able to span the kinds of idiosyncrasies that we encountered in this study. A second advantage of this strategy is that it makes relatively few real-time performance demands. The various methods for processing and normalizing tags could be conduc ted overnight or at other moments of low performance demand. A variation of the preceding strategy could be adopted at the point of search specification , rather than of tag-entry or tag storage. At a high level, this strategy calls for (a) providing the means for a user to indicate the names of tags to be searched, and then (b) suggesting or recommending additional tags that the may optionally be added to the search. The step of suggesting could use data from a single tag-based service, or from multiple tag-based services. This strategy would allow for tag re-use at the moment of search , and could make use of one or more of the normalization approaches described in the preceding sections. Additional approaches that leverage the availability of multiple tagged databases could also be include d. Unlike the strategy of supporting tag storage , the search strategy can make use of the current state and context of one or more databases. As a result, the search-time strategy avoids the problems outlined in  X  X ag Database Evolution, X  above. Ho wever, a disadvantage of the search-time strategy is that it increases real-time computing demands. This paper began with descriptions of four tag-based enterprise services which have supported users X  real work for over a year. The paper then explored the extent of overlap (tags-in-common) among the tag vocabularies in those four systems, finding surprisingly little overlap, especially at the level of personal vocabularies. Based on thos e findings, the paper critiqued strategies that encourage tag normalization at the time of initial tag-entry (e.g., during the creation of a bookmark), and recommended instead that mitigation of tag vocabularies be focused at the points of tag-storage and of tag-based search . The strategies of assisting at the moment of storage or the moment-of-search have the additi onal benefit of allowing new, experimental methods to be prototyped once and added to the search menu as a cross-service integration feature, without requiring any changes within multiple participating services. Thus, these strategies may provide a useful and flexible testbed for additional re-use concepts. Such a testbed can support a research agenda based around c onverging comparisons, such as x How do users choose among the various types of search x How do users integrate those search supports with their x Which types of search-supports provide straightforward x How do users X  tagging behaviors change as a result of using x How do users X  information-sharing practices change as a x How well can communities of practice and minority x What indices of search effectiveness can be used to measure x How can the internet tagging-based games of [35] be We anticipate combining these analyses with other examinations of tagging patterns across diverse services and resources, to understand the emerging tag-based work practices, and to clarify the value of social software data and services within the enterprise. [1] Anderson, C.,  X  X he long tail, X  Wired 12 :10, Oct 2004, [2] Begelman, G., Keller, P., &amp; Smadja, F.,  X  X utomated tag [3] Cattuto, C., Loreto, V., &amp; Pietronero, L.,  X  X ollaborative [4] Chapman, S. (n.d.):  X  X am X  X  String Metrics, X  http://www.dcs. [5] Chi, E.H., Kittur, A., Mytkowi cz, T., Pendleton, B., &amp; Suh, [6] Clark, H.H., &amp; Brennan, S.E.,  X  X rounding in [7] Damianos, L., Griffith, J., &amp; Cuomo, D.,  X  X nomi: Social [8] Dugan, C., Muller, M.J., Millen, D.R., Geyer, W., [9] Farrell, S., Campbell, C., &amp; Myagmar, S.,  X  X elescope: An [10] Farrell, S., &amp; Lau, T.,  X  X ringe Contacts: People-tagging for [11] Farrell, S., Lau, T., Wilcox, E., &amp; Muller, M.,  X  X ocially [12] Furnas, G.W., Landauer, T.K., Gomez, L.M., &amp; Dumais, S. [13] Geyer, W., Muller, M.J., Moore, M., Wilcox, E., Cheng, L., [14] Golder, S.A., &amp; Huberman, B.A .,  X  X tructure of collaborative [15] Halpin, H., Robu, V., &amp; Shephe rd, H.,  X  X he dynamics and [16] Hammond, T., Hannay, T., Lund, B., &amp; Scott, J.,  X  X ocial [17] John, A., &amp; Seligmann, D.,  X  X ollaborative tagging and [18] Kilgarriff, A.,  X  X sing word freque ncy lists to m easure corpus [19] Marlow, C., Naaman, M., Boyd, D., &amp; Davis, M.,  X  X osition [20] Millen, D.R., &amp; Feinberg, J.,  X  X sing social tagging to [21] Millen, D.R., Feinberg, J., &amp; Kerr, B.,  X  X ogear: Social [22] Moore, M., Estrada, M., Finley, T., Muller, M.J., &amp; Geyer, [23] Muller, M.J.,  X  X nomalous tagging patterns can show [24] Muller, M.J., &amp; Carey, K.,  X  X  esign as a minority discipline [25] Muller, M.J., Ehrlich, K., and Farrell, S.,  X  X ocial tagging and [26] Muller, M.J., Geyer, W., Brow nholtz, B., Dugan, C., Millen, [27] Muller, M., Geyer, W., Brownholtz, B., Wilcox, E., &amp; [28] Paice, C.D.,  X  X nother Stemmer, X  SIGIR Forum, 24 : 56-61 [29] Paice, C. D.,  X  X ethod for eval uation of stemming algorithms [30] Porter, M.F.,  X  X n algorithm for suffix stripping, X  Program, [31] Rader, E., &amp; Wash, R.,  X  X agging with del.icio.us: Social or [32] Sen, S., Geyer, W., Muller, M.J., Moore, M., Brownholtz, [33] Sen, S., Lam, S.K., Rashid, A.M., Cosley, D., Frankowski, [34] Vander Wal, T.,  X  X xplaining a nd showing broad and narrow [35] von Ahn, L., &amp; Dabbish, L.,  X  X abeling images with a [36] Willett, P.,  X  X he Porter stemming algorithm: Then and now, X  [37] Xu, Z, Fu, Y., Mao, J., &amp; Su, D.,  X  X owards the semantic 
