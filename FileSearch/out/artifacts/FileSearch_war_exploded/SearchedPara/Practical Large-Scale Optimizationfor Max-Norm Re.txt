 Institute of Computational and Mathematical Engineering A foundational concept in modern machine learning is to construct models for data by balancing the complexity of the model against fidelity to the measurements. In a wide variety of applications, observations, matrices offer a natural way to tabulate data. For such matrix models, the matrix rank provides an intellectually appealing way to describe complexity. The intuition behind this approach holds that many types of data arise from a noisy superposition of a small number of simple (i.e., rank-one) factors.
 Unfortunately, optimization problems involving rank constraints are computationally intractable ex-cept in a few basic cases. To address this challenge, researchers have searched for alternative com-plexity measures that can also promote low-rank models. A particular example of a low-rank reg-ularizer that has received a huge amount of recent attention is the trace-norm , equal to the sum of the matrix X  X  singular values (See the comprehensive survey [3] and its bibliography). The trace-norm promotes low-rank decompositions because it minimizes the ` 1 norm of the vector of singular values, which encourages many zero singular values.
 Although the trace-norm is a very successful regularizer in many applications, it does not seem to be widely known or appreciated that there are many other interesting norms that promote low rank. The paper [4] is one of the few articles in the machine learning literature that pursues this idea with any vigor. The current work focuses on another rank-promoting regularizer, sometimes called the max-norm , that has been proposed as an alternative to the rank for collaborative filtering problems [1, 5]. The max-norm can be defined via matrix factorizations: where k X k 2 ,  X  denotes the maximum ` 2 row norm of a matrix: gram; see (4) below. When X is positive semidefinite, we may force U = V and then verify that k X k max = max j x jj , which should explain the terminology.
 The fundamental result in the metric theory of tensor products, due to Grothendieck, states that the max-norm is comparable with a nuclear norm (see Chapter 10 of [6]): The factor of equivalence 1 . 676  X   X  G  X  1 . 783 is called Grothendieck X  X  constant. The trace-norm, on the other hand, is equal to This perspective reveals that the max-norm promotes low-rank decompositions with factors in `  X  , rather than the ` 2 factors produced by the trace-norm! Heuristically, we expect max-norm regular-ization to be effective for uniformly bounded data, such as preferences.
 The literature already contains theoretical and empirical evidence that the max-norm is superior to the trace-norm for certain types of problems. Indeed, the max-norm offers better generalization error bounds for collaborative filtering [5], and it outperforms the trace-norm in small-scale experi-ments [1]. The paper [7] provides further evidence that the max-norm serves better for collaborative filtering with nonuniform sampling patterns.
 We believe that the max-norm has not achieved the same prominence as the trace-norm because of an apprehension that it is challenging to solve optimization problems involving a max-norm regularizer. The goal of this paper is to refute this misconception.
 We provide several algorithms that are effective for very large scale problems, and we demonstrate the power of the max-norm regularizer using examples from a variety of applications. In particular, we study convex programs of the form where f is a smooth function and  X  is a positive penalty parameter. Section 4 outlines a proximal-point method, based on the work of Fukushima and Mine [8], for approaching (2). We also study the bound-constrained problem Of course, (2) and (3) are equivalent for appropriate choices of  X  and B , but we describe scenarios where there may be a preference for one versus the other. Section 3 provides a projected gradient method for (3), and Section 5 develops a stochastic implementation that is appropriate for decom-posable loss functions. These methods can be coded up in a few lines of numerical python or Matlab, and they scale to huge instances, even on a standard desktop machine. In Section 6, we apply these new algorithms to large-scale collaborative filtering problems, and we demonstrate performance su-perior to methods based on the trace-norm. We apply the algorithms to solve enormous instances of graph cut problems, and we establish that clustering based on these cuts outperforms spectral clustering on several data sets. The max-norm of an m  X  n matrix X can be expressed as the solution to a semidefinite program: Unfortunately, standard interior-point methods for this problem do not scale to matrices with more than a few hundred rows or columns. For large-scale problems, we use an alternative formulation suggested by (1) that explicitly works with a factorization of the decision variable X . We employ an idea of Burer and Monteiro [2] that has far reaching consequences. The positive definite constraint in the SDP formulation above is trivially satisfied if we define L and R via Burer and Monteiro showed that as long as L and R have sufficiently many columns, then the global optimum of (4) is equal to that of In particular, we may assume that the number of columns is less than m + n . This formulation of the max-norm is nonconvex because it involves a constraint on the product LR 0 , but Burer and Mon-teiro proved that each local minimum of the reformulated problem is also a global optimum [9]. If we select L and R to have a very small number of columns, say r , then the number of real decision variables in the optimization problems (2) and (3) is reduced from mn to r ( m + n ) , a dramatic improvement in the dimensionality of the problem. On the other hand, the new formulation is non-convex with respect to L and R so it might not be efficiently solvable. In what follows, we present fast, first-order methods for solving (2) and (3) via this low-dimensional factored representation. The constrained formulation (3) admits a simple projected gradient algorithm. We replace X with the product LR 0 and use the factored form of the max-norm (5) to obtain The projected gradient descent method fixes a step size  X  and computes updates with the rule This projection can be computed by re-scaling the rows of the current iterate whose norms exceed  X 
B so their norms equal projected gradient algorithm is elegant and simple, and it has an online implementation, described function, we can guarantee convergence to a stationary point of (3); see [10, Sec. 2.3]. Solving (2) is slightly more complicated than its constrained counterpart. We employ a classical proximal point method, proposed by Fukushima and Mine [8], which forms the algorithmic foun-dation of many popular first-order methods of for ` 1 -norm minimization [11, 12] and trace-norm minimization [13, 14]. The key idea is that our cost function is the sum of a smooth term plus a convex term. At each iteration, we replace the smooth term by a linear approximation. The new cost function can then be minimized in closed form. Before describing the proximal point algorithm in detail, we first discuss how a simple max-norm problem (the Frobenius norm plus a max-norm penalty) admits an explicit formula for its unique optimal solution.
 Consider the simple regularization problem Algorithm 1 Compute W = squash( V , X  ) Require: A d  X  D matrix V , a positive scalar  X  .
 Ensure: A d  X  D matrix W  X  arg min Z k Z  X  V k 2 F +  X  k Z k 2 2 ,  X  . 1: for k = 1 to d set n k  X  X  v k k 2 where W and V are d  X  D matrices. Just as with ` 1 -norm and trace-norm regularization, this problem can be solved in closed form. An efficient algorithm to solve (7) is given by Algorithm 1. We call this procedure squash because the rows of V with large norm have their magnitude clipped at a critical value  X  =  X  ( V , X  ) .
 Proposition 4.1 squash( V , X  ) is an optimal solution of (7) The proof of this proposition follows from an analysis of the KKT conditions for the regularized O ( d max { log( d ) ,D } ) flops. Computing the row norms requires O ( dD ) flops, and then the sort requires O ( d log d ) flops. Computing  X  and q require O ( d ) operations. Constructing W then re-quires O ( dD ) operations.
 With the squash function in hand, we can now describe our proximal-point algorithm. Replace the decision variable X in (2) with LR 0 . With this substitution and the factored form of the max-norm, (5), Problem (2) reduces to For ease of notation, define A to be the matrix of factors stacked on top of one another A = L R . and  X  ( A ) :=  X  f ( A ) +  X  k A k 2 2 ,  X  .
 Using the squash algorithm, we can solve in closed form. To see this, complete the square and multiply by  X  k . Then (9) is equivalent to (7) of (9) is squash A k  X   X  k  X   X  f ( A k ) , X  k  X  .
 We can now directly apply the proximal-point algorithm of Fukushima and Mine, detailed in Algo-rithm 2. Step 2 is the standard linearized proximal-point method that is prevalent in convex algo-rithms like Mirror Descent and Nesterov X  X  optimal method. The cost function  X  f is replaced with a quadratic approximation localized at the previous iterate A k , and the resulting approximation (9) can be solved in closed form. Step 3 is a backtracking line search that looks for a step that obeys an Armijo step rule. This linesearch guarantees that the algorithm produces a sufficiently large de-This algorithm is guaranteed to converge to a critical point of (8) as long as the step sizes are chosen commensurate with the norm of the Hessian [8]. In particular, Nesterov has recently shown that if  X  f has a Lipschitz-continuous gradient with Lipschitz constant L , then the algorithm will converge at a rate of 1 /k where k is the iteration counter [15]. Algorithm 2 A proximal-point method for max-norm regularization Ensure: A critical point of (8). 1: repeat 2: Solve (9) to find  X  A k . That is,  X  A k  X  squash A k  X   X  k  X   X  f ( A k ) , X  k  X  . 3: Compute the smallest nonnegative integer l such that 4: set A k +1  X  (1  X   X  l ) A k +  X  l  X  A k , k  X  k + 1 . For many problems, including matrix completion and max-cut problems, the cost function decom-form: where ` is some fixed loss function, S is a set of row-column indices, Y ij are some real numbers, and L i and R j denote the i th row of L and j th row of R respectively. When dealing with very large datasets, S may consist of hundreds of millions of pairs, and there are algorithmic advantages to utilizing stochastic gradient methods that only query a very small subset of S at each iteration. Indeed, the above decomposition for f immediately suggests a stochastic gradient method: pick one training pair ( i,j ) at random at each iteration, take a step in the direction opposite the gradient of described in 4.
 we project it back so that k L i k = need not look at any other rows of L and R . As we demonstrate in experimental results section, this simple algorithm is computationally as efficient as optimization with the trace-norm. We can also implement an efficient algorithm for stochastic gradient descent for problem (2). If we wanted to apply the squash algorithm to such a stochastic gradient step, only the norms correspond-ing to L i and R j would be modified. Hence, in Algorithm 1, if the set of row norms of L and R is sorted from the previous iteration, we can implement a balanced-tree data structure that allows us to perform individual updates in amortized logarithmic time. We leave such an implementation to future work. In the experiments, however, we demonstrate that the proximal point method is still quite efficient and fast when dealing with stochastic gradient updates corresponding to medium-size batches { ( i,j ) } selected from S , even if a full sort is performed at each squash operation. Matrix Completion. We tested our proximal point and projected gradient methods on the Net-flix dataset, which is the largest publicly available collaborative filtering dataset. The training set contains 100,480,507 ratings from 480,189 anonymous users on 17,770 movie titles. Netflix also provides a qualification set, containing 1,408,395 ratings. The  X  X ualification set X  pairs were selected by Netflix from the most recent ratings for a subset of the users. As a baseline, Netflix provided the test score of its own system trained on the same data, which is 0.9514. This dataset is interesting for several reasons. First, it is very large, and very sparse (98.8% sparse). Second, the dataset is very imbalanced, with highly nonuniform samples. It includes users with over 10,000 ratings as well as users who rated fewer than 5 movies. For the netflix dataset, we will evaluate our algorithms based on the root mean squared error (RMSE) of their predictions. To this end, the objective we seek to minimize takes the following form: where S here represents the set of observed user-movie pairs and Y ij denote the provided ratings. For all of our experiments, we learned a factorization L 0 R with k = 30 dimensions (factors). In our experiments, all ratings were normalized to be zero-mean by subtracting 3.6. To user/movie/rating triplets. Both proximal-point and projected gradient methods performed 40 epochs (or passes through the training set), with parameters { L , R } updated after each minibatch. For both algorithms we used momentum of 0.9, and a step size of 0 . 005 , which was decreased by a factor of 0 . 8 after each epoch. For the proximal-point method,  X  was set to 5  X  10  X  4 , and for the projected gradient algorithm, B was set to 2 . 25 . The running times of both algorithms on this large-scale Netflix dataset is comparable. On a 2.5 GHz Intel Xeon, our implementation of projected gradient takes 20.1 minutes per epoch, whereas the proximal-point method takes about 19.6 minutes. Figure 1 shows predictive performance of both the proximal-point and projected gradient algorithms on the training and qualification set. Observe that the proximal-point algorithm converges consider-ably faster than projected gradient, but both algorithms achieve a similar RMSE of 0.9150 (proximal the max-norm based regularization significantly outperforms the corresponding trace-norm based regularization, which is widely used in many large-scale collaborative filtering applications. We also note that the differences between the max-norm and the weighted trace-norm [7] are rather small, with the weighted trace-norm slightly outperforming max-norm.
 Gset Max-Cut Experiments. In the MAX -CUT problem, we are given a graph G = ( V,E ) , and we aim to solve the problem The heralded Goemans-Williamson relaxation [16] converts this problem into a constrained, sym-metric max-norm problem: In our nonconvex formulation, this optimization becomes Since the decision variable is symmetric and positive definite, we only need one factor A of size | V | X  r . In all of our experiments with MAX -CUT type problems, we fixed r = 20 . We used a diminishing step size rule of  X  k =  X  0  X  Table 1: Performance of projected gradient on Gset graphs. Columns show primal objective within .1% of We tested our projected gradient algorithm on graphs drawn from the Gset, a collection of graphs designed for testing the efficacy of max-cut algorithms [17]. The results for a subset of these appears in Table 1 along with a comparison against a C implementation of Burer X  X  SDPLR code which has been optimized for the particular structure of the MAX -CUT problem [18]. On the same modern hardware, a Matlab implementation of our projected gradient method can reach .1% of the optimal value faster than the optimized and compiled SDPLR code. 2-class Clustering Experiments. For the 2-class clustering problem, we first build a K -nearest a scalar  X  &gt; 0 and define an inverse similarity adjacency matrix Q by Q ij =  X   X  W ij . The parameter  X  controls the balancing of the clusters, a large value of  X  forces the clusters to be of equal size. We solve the MAX -CUT problem on the graph Q to find our cluster assignments.
 As a synthetic example, we generated a  X  X wo moons X  dataset consisting of two half-circles in R 2 embedded into R D and each embedded component is corrupted with Gaussian noise with variance  X  . For the two moons experiments, we fix D = 100 , n = 2000 and  X  = parameters are set to  X  = . 01 and  X  0 = 3 / 2 ; the algorithm was executed for 1500 iterations. For the clustering experiments, we repeat the randomized rounding technique [16] for 100 trials, and we choose the rounding with highest primal objective.
 We compare our MAX -CUT clusterings with the spectral clustering method [20] and the Total Vari-ation Graph Cut algorithm [19]. Figure 2 shows the clustering results for spectral clustering and maxcut clustering. In all the trials, spectral clustering incorrectly clustered the two ends of both half-circles. For the clustering problems, the two measures of performance we consider are mis-classification error rate (number of misclassified points divided by n ) and cut cost. The cut cost is defined as P i  X  V of the 100 trials we performed and smaller cut cost in every trial.
 On the MNIST database, we build the 10-NN graph described above on the digits 4 and 9, where we set  X  = . 001 and r = 8 . The NN-graph is of size 14 , 000 and the MAX -CUT algorithm takes approximately 1 minute to run 1,000 iterations. The same procedure is repeated for the digits 3 and 5. The results are shown in Table 2. Our MAX -CUT clustering algorithm again performs substantially better than the spectral method. In this paper we presented practical methods for solving very large scale optimization problems involving a max-norm constraint or regularizer. Using this approaches, we showed evidence that the max-norm can often be superior to established techniques such as trace-norm regularization and spectral clustering, supplementing previous evidence on small-scale problems. We hope that the increasing evidence of the utility of max-norm regularization, combined with the practical optimiza-tion techniques we present here, will reignite interest in using the max-norm for various machine learning applications.
 Acknowledgements RS supported by NSERC, Shell, and NTT Communication Sciences Laboratory. JAT supported by ONR award N00014-08-1-0883, DARPA award N66001-08-1-2065, and AFOSR award FA9550-09-1-0643. JL thanks TTI Chicago for hosting him while this work was completed.

