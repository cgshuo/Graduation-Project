 FATIH GEDIKLI and DIETMAR JANNACH , TU Dortmund, Germany User-contributed tags are today a popular means for users to organize and retrieve items of interest in the participatory Web. Social Tagging therefore plays an increas-ingly important role both on Social Web platforms such as Delicious 1 and Flickr 2 as well as on large-scale e-commerce sites such as Amazon.com.

Beside the usage of tags for improved item retrieval, various ways of exploiting these additionally available pieces of information have been proposed in recent years to build more effective recommender systems . In general, the main task of such a recom-mender system is to provide its users with personalized buying proposals. Historically, the main knowledge sources in the recommendation process are the users X  past buy-ing and rating behavior as well as information known about the available items, see Jannach et al. [2010] for a recent overview. Tagging information can be exploited in the recommendation process in different ways. Tags can for example be seen as item descriptions and used by a content-based recommender. However, the set of tags a user attaches to resources also provides valuable information about the user him-or her-self. Thus, the relationship between users and tags can be used to find similar users in neighborhood-based collaborative filtering systems. Overall, the goal of many tag-based recommendation approaches is to exploit the existing interactions among users, items, and tags to improve the effectiveness of the recommender system, measured for example in terms of the predictive accuracy or the coverage of the algorithm [Diederich and Iofciu 2006; Hotho et al. 2006; de Gemmis et al. 2008; Tso-Sutter et al. 2008; Zhen et al. 2009; Bogers and van den Bosch 2009; Wang et al. 2010; Sen et al. 2009b].
In most existing approaches to tag-based or tag-enhanced collaborative item recom-mendation, the main assumption is that preference information provided by the user community is only available for the items. Only recently, first ideas have been put forward that consider the possibility to attach preferences also to the tags themselves and use this information to improve different quality aspects of the recommendation process.

In Sen et al. [2009b], for example, the goal is to leverage information about the users X  estimated preference for individual tags to generate more precise recommendations. Assuming that no explicit tag preference information is available, the first step in their  X  X agommenders X  is therefore to estimate the user X  X  attitude toward the different tags. In the movie domain, this would for example mean to estimate if and to which extent user Alice likes movies that are, for example, annotated with the tag  X  X nimated. X  After that, the rating prediction for an item is based on the aggregation of the inferred user preferences for the tags assigned to that item. An analysis of several algorithms and preference inference metrics on a tag-enhanced MovieLens dataset showed that more precise recommendations can be made when the user X  X  estimated tag preferences are taken into account.

Vig et al. [2010] later on report on a first study on using explicit tag preferences, which they called tag expressions . In their field study, the users of the MovieLens recommender were allowed to share tags and the associated affect 3  X  X ike, dislike or neutral X  X o the tags attached to the movies. This way, users could express which fea-tures of a movie they particularly liked or disliked. Among other aspects, their study revealed that users particularly appreciated this new feature, a fact that was measured in increased user satisfaction. Above that, allowing users to express affect associated with tags also helped to increase the volume of the contributed tags as well as their quality.

While the work of Vig et al. for example shows how the users X  satisfaction with the system can be increased, they do not propose any algorithms for improving the recommendation accuracy based on explicit tag preferences. Note that in contrast to Vig et al. X  X   X  X ag expressions, X  the tagommender algorithms proposed by Sen et al. rely on  X  X lobal X  tag preferences, which means that a tag is either liked or disliked by a user, independent of a specific item. Thus, a particular user Alice either likes movies annotated with the tag animated or not.

In our own previous work [Gedikli and Jannach 2010], which was developed inde-pendently of and in parallel with Vig et al. X  X  study, we already proposed first methods aimed at exploiting item-specific tag preferences to compute more precise recommen-dations. The intuition behind this idea was that the same tag may have a positive connotation for the user in one context and a negative in another. For example, a user might like action movies featuring the actor Bruce Willis. At the same time, being used to see this actor mainly in action movies, the user might dislike the performance of Bruce Willis in a romantic movie. First experiments on a tag-enhanced dataset and a neighborhood-based method for estimating item-specific tag preferences revealed that the predictive accuracy can be improved when compared with a similar method that only takes global tag preferences into account [Gedikli and Jannach 2010].

This article extends our previous work in different ways. First, we show how a new metric to derive user-and item-specific tag preferences can help us to produce more accurate recommendations when incorporated in a method based on Support Vector Machines (SVM), which showed superior performance in previous work. Beside comparing our algorithm with the best-performing method from Sen et al., we also compare our work with a recent tag-agnostic matrix factorization method and our own previously presented method. In addition to experiments with the tag-enhanced MovieLens dataset that was also used by Sen et al., we conducted experiments in which we varied the density of the tagging data. Above that, accuracy measurements were taken based on a new dataset consisting of real item-specific tag preferences, which were collected in a user study [Gedikli et al. 2011b] focusing on the explanatory power of tag preferences in the sense of [Vig et al. 2009]. This way, a more precise picture of the potential benefits of item-specific tag preferences could be obtained.

The article is organized as follows. In the next section, we outline the overall prefer-ence inference and recommendation process on an illustrative example. In Section 3, we present a scheme for automatically inferring user-and item-specific tag preferences. Afterwards, we show how the additionally available tag preference information can be exploited to make more accurate predictions. In Section 5, the results of the compar-ative evaluation of the different methods on two different datasets are discussed. The article ends with a discussion of related approaches and an outlook on future work. Before giving details of the algorithms, we illustrate the basic rationale of our method in the following example. Let us assume User1 has attached tags to different movies and given overall ratings on a scale from 1 to 5, as shown in Table I. User1 particularly likes action movies featuring Bruce Willis and romantic movies featuring Sandra Bullock, but appears to dislike romantic movies starring Bruce Willis.

A method that automatically infers global preferences or ratings for tags such as the one described in Sen et al. [2009b] would probably derive a relatively high value for the tags  X  X ruce Willis X  and  X  X ction. X  At the same time, the tag  X  X omance X  would receive a lukewarm rating somewhere between 3 and 4 because the user attached the tag both to a highly-liked and a disliked movie. As a result, the rating prediction for movie M5 based on the inferred tag preferences would may be around 4, that is, the system would tend to recommend M5.

Now let us assume that we knew more about the individual tags and their importance to User1 as shown in Table II (assuming that we acquired this information directly from the user). In Table II, we can see, that X  X erhaps among other reasons X  X he user did not like M2 because of Bruce Willis X  appearance in a romantic movie. Since movie M5 is quite similar to M2 with respect to the attached tags, it is somewhat more intuitive not to recommend M5, which is exactly the opposite decision as in the example above.
We therefore propose a method that is capable of making recommendations based on more detailed rating data for tags. We assume that such data will be available also in future systems, given the findings of the study of Vig et al. [2010], who showed that users enjoy sharing their affect by expressing their feelings with respect to certain features of the recommendable items. In addition, we develop a method to infer this detailed tag preference data automatically for cases in which such information is not available or the data is very sparse. In the example above, we would try to approximate the detailed ratings for the items M1 to M5 as good as possible given only the overall ratings for the movies.

Figure 1 summarizes and visualizes our approach to  X  X ating items by rating tags X  for a movie recommendation scenario in which both explicit and inferred tag preferences are exploited. At the core, the usual user-item matrix is extended not only by a set of user-provided tags for the items, but also by tag preferences describing the user X  X  opinion about the item features represented by these tags. Figure 1(a) shows the process of rating items by rating tags. The user assigns or chooses one or more tags for the item to be rated. The user can either create new tags or select existing quality tags in the sense of Sen et al. [2007] from a list of recommended tags, which can be provided by a tag recommender system such as the ones proposed in Zhang et al. [2009] or J  X  aschke et al. [2007]. After assigning a tag, each individual tag can be given a rating, that is, the user rates selected tags and assigns an overall rating to the movie. Figure 2 shows a tag rating user interface that was used in our own study on the power of tag-based recommendation explanations in Gedikli et al. [2011b].

Figure 1(b), on the other hand, shows scenarios where the augmented rating matrix is exploited by a recommender system. The recommender uses, among others, tag pref-erence data to estimate the prediction for the active user u on the item i . Tag preferences can either be acquired explicitly or derived automatically using the  X  X ag Rater X  com-ponent in Figure 1(b) in case no such explicit information is available. Figure 1(b) also provides another compelling application scenario in which tag preferences are used for explaining recommendations, which, however, is not the focus of this work, but tackled by our current and future work (see Gedikli et al. [2011a] or Gedikli et al. [2011b]).
In the next section, we will present different methods to derive tag preferences from the overall ratings automatically, see the  X  X ag Rater X  component in Figure 1(b). Afterwards, schemes to derive an overall rating prediction for a not-yet-seen item based on the ratings of its tags are proposed and evaluated.

In general, our methods extend the  X  X agommender X  algorithms and metrics pro-posed in Sen et al. [2009b] in a way that they can take into account item-specific tag preferences in the recommendation process. If no explicit tag preferences are given, Sen et al. [2009b] propose different algorithms for estimating global tag preferences from the given item ratings. According to their evaluation, the algorithm movie-ratings is both effective and at the same time rela-tively easy to implement. The algorithm is based on tag relevance weighting , a concept that is also used in the work on tag-based explanations described in Vig et al. [2009].
In our evaluation, we use a simple counting metric w ( i , t ) to measure the relevance of a tag t for an item i . 4 The metric gives more weight to tags that have been used by users more often to characterize the item and is defined as follows: 5
In the movie-ratings algorithm, the prediction  X  r u , t of the general interest of a user u in the concept represented in a tag t , that is, the tag preference, is estimated as follows:
In this equation, I t corresponds to the set of all items tagged with t . The explicit overall rating that u has given to movie m is denoted as r u , m . The general idea of the method is thus to propagate the overall rating value to the tags of a movie according to their importance.

In our work, however, we are interested in predicting the rating for a tag in the context of the target user u and the target item i . Note that the rating prediction in Equation (2) does not depend on the target item i at all. Our tag prediction function,  X  r i , t , for a given user u andanitem i is calculated as follows:
Instead of iterating over all items that received a certain tag as done in Sen et al. [2009b], we only consider items that are similar to the item at hand, thereby avoid-ing the averaging effect of  X  X lobal X  calculations. In Equation (3), the calculation of neighboring items is contained in the function similarItems ( i , I t , k ), which returns the collection k most similar items from I t .

The similarity of items is measured with the adjusted cosine similarity metric. Note that we also ran experiments using the Pearson correlation coefficient as a similarity metric, which however led to poorer results. As another algorithmic variant, we have tried to factor in the item similarity values as additional weights in Equation (3). Again, this did not lead to further performance improvements but rather worsened the results.

Note that when using the user X  X  explicit overall rating r u , m as in Equation (2), no prediction can be made for the tag preference if user u did not rate any item m tagged with t ,thatis,if I t  X  ratedItems ( u ) = X  . In our previous work [Gedikli and Jannach 2010], we therefore also incorporated the recursive prediction strategy from Zhang and Pu [2007] into the tag preference prediction process, which lead to a slight performance improvement. Since such an performance improvement was however also observed for Sen et al. X  X  original methods, we will not further discuss these generally-applicable technique here in greater depth, see Gedikli and Jannach [2010] for details of the evaluation. In Sen et al. [2009b], the best-performing tag-based recommendation algorithm with respect to precision was a hybrid that combined the SVM-based method regress-tag and the tag-agnostic matrix factorization approach funk-svd [Funk 2006]. In our work, we therefore propose to parameterize and evaluate the regress-tag method using item-specific tag preferences. Note again, that these tag preferences can be explicitly avail-able or derived as described above in Equation (3). In addition to that, we also report accuracy results when using item-specific tag preferences for Sen et al X  X  cosine-tag method, in order to study how this approach, which we proposed in our previous work [Gedikli and Jannach 2010], performs on additional datasets.

The regress-tag algorithm. The regress-tag method from Sen et al. [2009b] is based on determining linear equations X  X ne for each movie X  X hich capture the possibly com-plex relationship between the user X  X  tag preferences for the tags of a given item and the overall item rating. The prediction function for a user u and an item i is defined as follows, where h 0 to h n are the coefficients of the linear equations and  X  r u , t (2) corresponds to the estimated tag preferences for the tags t 1 ,..., t n attached to item i :
In Sen et al. [2009b], the coefficients h 0 to h n were chosen with the help of regression support vector machines and the libsvm library [Chang and Lin 2011] because this led to the most accurate results when compared with other methods for choosing the parameters such as least-squares.

In our work and our evaluations, we used the same approach (as well as the same software library and algorithm parameters), but different values for the tag prefer-ences. In our algorithm variant, which we shall call regress-tag-ui , 6 we therefore use the item-specific tag preferences as described in Equation (3):
The cosine-tag algorithm. The cosine-tag method is inspired by an analogy to classical item-to-item collaborative filtering methods. The prediction of a user X  X  rating for a given item is based on the weighted combination of the user X  X  preference for the tags of an item. Let T i be the set of all tags applied to an item i . The rating prediction for a user u andanitem i is calculated as follows:
The individual tag preferences are weighted according to the adjusted cosine simi-larity between items and tags. The similarity metric given in Equation (7) is used to measure the degree of consistency between the item X  X  overall rating received by all users u who rated item i ( U i ), and their predicted tag preferences for that item, that is,
To illustrate the effect of the approach, consider the following example. Table III shows an example of inferred tag preferences for the MovieLens user Bob 7 and the movie Snatch (2000) on a 5-star scale with half-star increments. Bob is a real user in the MovieLens movie recommendation community. From the inferred rating data, we can see that Bob has particularly liked the British elements and tone in the movie and that Bob probably likes the acting of Jason Statham more than the acting of Brad Pitt, at least in this movie.

When we use Equation (6) to combine the estimated tag preferences into one overall rating prediction for that movie, we predict a rating value of 3 . 355 from Bob for Snatch. Note that Bob X  X  overall (explicitly given) rating was 3. Our method in that case therefore predicts a rating value that is a little higher and closer to the next higher 3 . 5-star rating. In order to measure the predictive accuracy of the presented methods we evaluated our approach on two datasets using common experimental procedures and accuracy metrics. The results of this evaluation are described in this section. The goal of our subsequent evaluation is to analyze in which cases the predictions made by the system are more accurate than previous methods when we rely on user-and item-specific tag preferences. We used two datasets in our evaluation. First, we evaluated our methods on the  X  X ovie-Lens 10M Ratings, 100k Tags X  (ML) dataset, 8 which was also used in the analysis by [Sen et al. 2009b]. The dataset consists of movie ratings on a 5-star scale with half-star increments. In addition, it contains information about the tags that have been assigned by the users to the movies. A tag assignment is a triple consisting of one user, one resource (movie) and one tag. No rating information for the tags themselves is available in the original MovieLens database. To the best of our knowledge, the 10M MovieLens dataset is the only publicly available dataset that contains both rating and tagging data. It contains 10,000,054 ratings and 95,580 (unrated) tags applied to 10,681 movies by 71,567 users of the online movie recommender service MovieLens.
Second, we used a new dataset containing explicit tag preferences, which we collected in a user study on the usage of tagging data for explanation purposes reported in Gedikli et al. [2011b]. The dataset contains 353 overall ratings for 100 movies provided by the 19 participants of the study. In addition to these overall ratings, the study participants provided 5,295 explicit ratings for the tags attached to the movies using the graphical interface shown in Figure 2. On average, every user rated about 18 movies and each movie had 15 tags assigned.

Limited tag quality is one of the major issues when developing and evaluating ap-proaches that operate on the basis of user-contributed tags. In Sen et al. [2007], for example, it was observed that only 21% of the tags in the MovieLens system had ade-quate quality to be displayed to the user. Therefore, different approaches to deal with the problem of finding quality tags have been proposed in recent years, see, for example, Gemmell et al. [2009], Sen et al. [2007], or Sen et al. [2009a].

Note that our approach of rating items by rating tags calls for a new quality re-quirement to tags: tags must be appropriate for ratings. For example, there is no point in attaching a rating to a tag like  X  X ad movie X  because the tag already represents a like/dislike statement. It would therefore not be clear how to interpret a preference for such a tag. In our current work and evaluation, we did not take this question into account yet, that is, we did not distinguish between tags that are appropriate for being rated and those that are not. Still, we believe that this is one key question that was not considered before and that should be taken into account in future approaches to extracting rating information for tags automatically. For the MovieLens (ML) dataset, we applied and varied the constraints shown in Table IV in order to remove tags, users or items for which not sufficient data was available. This way, we varied the quality of the existing tag information. We for example only considered movies, for which a minimum number of tags is assigned (Min Tags/Item). This approach was also followed by previous work. Vig et al. [2009], for example, require that  X  X  tag has been applied by at least 5 different users and to at least 2 different items. X  Additionally, content analysis methods were applied in Vig et al. [2009] to detect redundant tags such as  X  X iolent X  and  X  X iolence X , in order to replace them by one representative tag. Similar to their approach, we further automatically preprocessed the data in three dimensions by removing stop-words from the tags, by applying stemming [Porter 1997] and by filtering out noisy tags, that is, tags with a certain amount of characters that are not letters, numbers or spaces, for example, elements such as smileys.

We created three different versions from the tag-enhanced MovieLens data with different constraints on data density; see Table V for an overview. Note that our quality and density requirements are relatively weak when compared for example with the work of Vig et al. [2009], who required that a tag has been used by at least five users to be considered in the evaluation. As a result, the MAE values reported in our work are in general slightly higher than those reported in Sen et al. [2009b], who also used similar types of constraints to prune the dataset.

In contrast to the MovieLens dataset, our second dataset from the user study (US) contains explicit tag preferences. Therefore, no estimation of the tag preferences is required. In our experiments, we however varied the amount of explicitly available tag preference data in order to study the differences when using only explicit ratings, only automatically inferred ratings and a setting where one half of the rating data is real and one half only estimated. See Table VI for an overview.

Note that for all variations of the user study dataset, the number of items, users and ratings, that is, the density levels, are the same as no further quality improvement measures were applied.
 We included the following recommendation algorithms in our comparative evaluation. The schemes proposed in this work are:  X  regress-tag-ui: SVM regression with user-and item-specific tag preferences (Equation (5));  X  cosine-tag-ui: similarity-based prediction as described in Equation (6).

Beside these two methods, we also experimented with the probabilistic approach to content-based recommendation proposed in Mooney and Roy [2000]. Instead of ex-tracting keywords from documents as in the original approach, we simply viewed the tags of the movie as the keywords and used them to derive an estimate of whether a user will like or dislike a movie. An experimental evaluation on the ML dataset how-ever showed that the predictive accuracy of this simplistic approach is not competitive when compared to other techniques. This observation is in some respect in line with the observation made in Pil  X  aszy and Tikk [2009], in which it was also noticed that rating-based collaborative filtering schemes are more accurate than pure content-or metadata-based approaches even if the number of ratings is relatively low.

As a baseline for the comparison, we used the following algorithms:  X  regress-tag: SVM regression as proposed in Sen et al. [2009b] (Equation (4));  X  cosine-tag: As proposed in Sen et al. [2009b] (Equation (2)).

Note that in Sen et al. X  X  work a hybrid algorithm that combined regress-tag with a matrix factorization approach performed slightly better than regress-tag alone. We experimented with this hybridization strategy also on our datasets, but could not re-produce the findings of Sen et al. Given our data, we consistently observed regress-tag to be the best-performing method, which we therefore use as a baseline.

Beside the two tag-aware baseline algorithms, we also measured the predictive ac-curacy of two tag-agnostic techniques.  X  item-item . A classical item-to-item baseline recommendation scheme that does not exploit tag information at all. Adjusted cosine is used as a similarity function. Rating predictions are calculated as follows:  X  funk-svd. The recent, highly-accurate matrix factorization algorithm based on Sin-gular Value Decomposition (SVD) proposed in [Funk 2006], which was also used as a baseline for comparison by Sen et al.
 We used the following algorithm parameters.  X  X e chose adjusted cosine as similarity metric for all schemes because experiments with other similarity metrics such as Pearson X  X  correlation coefficient led to poorer results.  X  X n the user-and item-based scheme cosine-tag , the parameter k that determines the size of the neighborhood containing the k most similar items from I t can be varied, see Equation (3). In order to find an optimal value we varied the parameter systematically. A neighborhood-size of 3 was determined as an optimal choice.  X  X n the regress-tag method, similar to the experiments reported in [Sen et al. 2009b], we set the value of c related to the error penalty to 0.005. For regress-tag-ui we additionally determined 10 as a suitable number of neighbors to include when calculating the item-specific tag preferences.
  X  X or the SVD-based recommender, 30 was empirically chosen as the number of latent features.
 All algorithms were implemented in our Java-based framework called Recommender-Suite , which also includes components to run offline experiments, do cross-validation and measure various metrics such as accuracy or coverage. The regress-tag methods are based on the libsvm implementation [Chang and Lin 2011]; the implementation of the matrix factorization approach was adapted from the Apache Mahout project. 9 We analyzed the quality of the recommendations generated by the different algorithms with the standard information retrieval metrics precision and recall . To determine precision and recall, we followed the evaluation procedure proposed in Nakagawa and Mobasher [2003] and converted the rating predictions into  X  X ike X  and  X  X islike X  state-ments as described in Sandvig et al. [2007], where ratings above the user X  X  mean rating are interpreted as  X  X ike X  statements.

In each of the iterations of a cross-validation procedure, the dataset is split into a training set and a test set. We then determined the set of existing  X  X ike X  statements ( ELS ) in the test set and retrieve a top-N recommendation list of length | ELS | with each method based on the data in the training set. The top-N recommendation lists are created based on the prediction score of each method. The set of predicted like statements returned by a recommender shall be denoted as Predicted Like Statements (PLS), where | PLS | X | ELS | .

Based on these definitions, precision can be defined as ( | PLS  X  ELS | ) / | PLS | and measures the number of correct predictions in PLS . Recall 10 is measured as ( |
PLS  X  ELS | ) / | ELS | and describes how many of the existing  X  X ike X  statements were found by the recommender.

In the evaluation procedure, recommendations and the corresponding precision and recall values were calculated for all users in the dataset and then averaged. These averaged precision and recall values are then combined in the usual F1-score, where F = (2  X  precision  X  recall ) / ( precision + recall ).
 Beside these information retrieval metrics, we also report the usual Mean Absolute Error (MAE) numbers in order to make our results comparable with the results in literature, in particular with Sen et al. X  X  work. Note that we also calculated Root Mean Squared Error values (RMSE), but do not report these numbers here because no significant differences to the MAE values have been observed. 5.4.1. Experiments on Real Data. Table VII shows the Mean Absolute Error values for the different algorithms and the datasets from the user study in increasing order, 11 see Table VI for a description of the datasets obtained from our user study. It is important to recall that the density levels of the datasets are fixed, whereas the amount of explicitly available tag preference data is varied as described in Section 5.1.

We can see that the regress-tag-ui scheme proposed in this work to exploit user-and item-specific tag preferences leads to the smallest Mean Absolute Error values for all dataset variations. The improvement over the previous regress-tag method is particularly strong when only real rating data is used. For the situation in which we only rely on estimates of item-specific tag preferences (US-pred), our method is mini-mally better or at least on a par with the previous method. When using only half of the existing ratings, MAE values somewhere in the middle between the two extremes can be observed. As a result, the numbers indicate that the accuracy constantly increases when more real tag preferences are entered into the system.

Another observation on this relatively dense data from the user study is that the cosine-tag-ui method performs slightly worse than the cosine-tag and even the item-item algorithm. For the dataset US-pred, item-item also slightly outperforms cosine-tag .
 Table VIII shows the corresponding values for precision, recall and the F1-measure. The values were obtained using a 10-fold cross-validation on the relatively small dataset.

Again, the numbers show that regress-tag-ui slightly outperforms regress-tag and the other algorithms and is significantly better than the other methods. The neighborhood-and similarity-based methods show the poorest results on this metric and are also outperformed by the SVD-based algorithm. Note that there are virtu-ally no differences in the observed numbers across the different datasets, which can be accounted to the characteristics of the dense user study dataset and the chosen evaluation metric. 5.4.2. MovieLens Data. Table IX shows the MAE numbers for the different MovieLens datasets. Note that unlike the three datasets considered before, the different MovieLens datasets have different density levels, as described in Section 5.1.

In these experiments, in which only estimated tag preferences are available, the funk-svd method, regress-tag and regress-tag-ui are more or less on a par with respect to the MAE measure. The more traditional neighborhood-based methods are measurably less accurate. These findings are in line with the MAE numbers reported in Sen et al. [2009b], where the funk-svd method was reported be even slightly better on the MAE metric by a very small margin. For the dataset ML-low X  X he largest dataset with the least constraints on the data X  X he performance of funk-svd is slightly worse than the regression-based approaches.

Table X finally shows F1, precision and recall figures for the three MovieLens-derived datasets, in which artificial tag preferences were used. The results show that our new regress-tag-ui scheme outperforms the best-performing algorithm regress-tag from Sen et al. on the denser datasets (ML-high and ML-medium) and is at least on a par with it on the lower-density dataset ML-low. Quite interestingly, the classical tag-agnostic item-to-item algorithm performs relatively well on this metric and is even better than the matrix factorization approach on the datasets ML-high and ML-medium. A further analysis of this phenomenon and the specific characteristics of the datasets is part of our current work.

Note that the findings of our previous work, in which cosine-tag-ui was presented and compared with cosine-tag [Gedikli and Jannach 2010], could be reproduced, that is, that cosine-tag-ui is slightly better than cosine-tag on the F1 metric. On the denser datasets, the cosine-tag-ui method however does not perform as well as the other algorithms.

With respect to the absolute recall and precision, we can observe that the measured precision and recall values are mostly very similar to each other for each algorithm and dataset. This is caused by the nature of the particular accuracy metric that we use in our work (see Section 5.3 and Nakagawa and Mobasher [2003] respectively). 12
The absolute values are also significantly higher for the very sparse dataset ML-low, which is also caused by the characteristics of the chosen evaluation metric, which is not designed for a comparison of the absolute numbers across such different datasets. Note that in our experiments, the data density for the real data from the user study is close to 20%. For the MovieLens datasets, we varied the density levels from 35% for ML-high over 23% for ML-medium to the very low-density dataset ML-low, which has a density of 0.001%.

The main objective of this work is to show that accuracy improvements can be achieved when using tag preference data. Overall, the results achieved showed that the usage of item-specific tag preferences can help to improve the predictive accuracy of recommender systems and that the observed positive effect is stronger, when the tag quality and data density increases. The evaluation on the different datasets demon-strated that especially when using real tag preference data the method regress-tag-ui proposed in this work outperforms the best-performing method from previous work. The results show further that even when all tag preferences are artificially derived from the item ratings our method is still able to slightly outperform or at least is on a par with previous best-performing method. The predictive accuracy increases when more real data is entered into the system. In recent years, many researchers have recognized the value of Social Web tagging in-formation for recommender systems and for example use tagging data as an additional source of information to improve the effectiveness of the recommender system, mea-sured in terms of the predictive accuracy or the coverage of the algorithms [de Gemmis et al. 2008; Tso-Sutter et al. 2008; Liang et al. 2009; Zhen et al. 2009; Sen et al. 2009b; Kim et al. 2010; Wang et al. 2010; Zhou et al. 2009].

Tag-enhanced recommenders. In de Gemmis et al. [2008], for example, the authors exploit tagging data for an existing content-based recommender system in order to increase the overall predictive accuracy of the system. In their approach, the user interests are learned by applying machine learning techniques both on the textual descriptions of items (static data) and on the tagging data (dynamic data). Tags are therefore only considered as an additional source of information used for learning the profile of a particular user. By conducting a user study with 30 users the authors show that a slight improvement in the prediction accuracy of the tag-augmented rec-ommender compared to the pure content-based one can be achieved. Our work rather represents a collaborative filtering approach with multicriteria ratings and is thus better capable to exploit the  X  X isdom of the crowd X  to improve the recommendation accuracy.

In recent times, tags were also used for enhancing the performance of traditional collaborative filtering recommender systems. Tag information was incorporated into existing collaborative filtering algorithms in one or the other way for enhancing the quality of recommendations for example in [Tso-Sutter et al. 2008; Liang et al. 2009; Zhen et al. 2009; Kim et al. 2010] or [Wang et al. 2010]. Most commonly, tags are considered only as an additional source of information for their proposed methods. In Wang et al. [2010], for example, tags are used for building user and item neighborhoods. The underlying idea of this approach is that neighbors that are determined this way will be better predictors than those that are identified only based on explicit rating data. The evaluation on the tag-enhanced MovieLens dataset shows that such an ap-proach outperforms other algorithms based on nonnegative matrix factorization and Singular Value Decomposition. In particular, the observed improvements in predictive accuracy were comparably strong for sparse datasets. Similar to Sen et al. X  X  and our work, Zhou et al. [2009] recently proposed a method based on probabilistic factor anal-ysis framework that exploits the information contained in the user-item rating matrix, the user-tag tagging matrix and the item-tag tagging matrix to produce more accurate recommendations. A comparison with two recent tag-agnostic matrix factorization ap-proaches [Funk 2006; Salakhutdinov and Mnih 2008] showed that their approach leads to better RMSE values in particular when only a small part of the available data is used for training.

Note that the idea of allowing the community to rate items is an important topic not only in the area of recommender research but also in the Semantic Web community. Revyu 13 [Heath and Motta 2007], the winner of the Semantic Web Challenge of the year 2007, is a reviewing and rating Web site that aims to aggregate review data of items (resources) on the Web. Revyu allows people to rate items by writing reviews and gives users the opportunity to add metadata to items in the form of Web 2.0 style tags. Based on this relatively unstructured information, stronger semantics are later on derived. As stated by the authors, this functionality in itself is partially not particularly novel. The real benefit lies in the use of Semantic Web technologies and standards like RDF, SPARQL and the principles of Linked Data [Berners-Lee 2006] in order to expose reviews in a reusable and machine-readable format.

Note that in the Revyu system, tags are merely used for classifying the reviewed items and for automatically extracting additional information. We believe that our work could complement this approach by exploiting the rating information that is implicitly contained in the tags. That way, by deriving individual preferences for the tags provided by a user, a better  X  X nderstanding X  of the free-text reviews could be achieved.

Relation to multidimensional recommenders. In contrast to works in which tags are only used to build better neighborhoods for classical collaborative filtering systems, we follow a different approach of exploiting tags for recommender systems in this work. In principle, we propose an approach, in which users rate items by rating tags, which to some extent also has a correspondence to a multicriteria or multidimensional recom-mendation approach as described in Adomavicius and Tuzhilin [2001] or Adomavicius and Kwon [2007]. Adomavicius and Kwon [2007] conjecture that multicriteria ratings will play an important role for the next generation of recommender systems, in partic-ular because multicriteria ratings can help to handle situations in which users gave the same overall rating but had different reasons for that (which can be observed in the detailed ratings). Besides this, multicriteria rating information can serve as a valuable source for explaining recommendations. Based on these observations, new user similarity metrics and algorithms were designed in Adomavicius and Kwon [2007] that exploit multicriteria rating information leading to recommender systems of higher quality. The authors show on a small dataset how exploiting multicriteria ratings can be successfully leveraged to improve recommendation accuracy. Our approach of  X  X at-ing items by rating tags X  shares the advantages of these multicriteria recommender systems such as improved accuracy and explanations. The rating dimensions are how-ever not static in our approach and require metrics that are different from those put forward for example in Adomavicius and Kwon [2007]. In this respect, our work is also in line with the ideas of Shirky [2005], who was among the first who argued that using predefined (rating) categories leads to different challenges such as the following. First, professional experts are needed who design the rating dimensions; in addition, new rating dimensions may emerge over time that were not covered by the predefined and prethought static rating dimensions designed or foreseen by a domain expert. In collaborative tagging systems, the set of rating dimensions is not limited, which allows users to pick their particular way of stating their preferences. Of course, this comes at the price of a less homogeneous and more unstructured set of item annotations.
Tag preference. To the best of our knowledge, the concept of tag preference was first introduced by Ji et al. [2007]. The authors present a tag preference based recommenda-tion algorithm for a collaborative tagging system, where collaborative tagging means the process of assigning tags to items by many users that is supported by Social Web platforms such as Delicious 14 or Connotea 15 . The authors first compute the target user X  X  candidate tag set , which consists of all tags for which a high tag preference value was predicted. Afterwards a na  X   X ve Bayes classifier is used for making recommendations by exploiting the user X  X  candidate tag set. The proposed algorithm was evaluated on a dataset collected from the social bookmarking site Delicious. In contrast to the work of Sen et al. [2009b] the tag preference predictor in Ji et al. [2007] does not make use of item ratings at all because the Delicious dataset does not support ratings for items (bookmarks) like the tag-enhanced MovieLens dataset.
Vig et al. [2009] propose another concept called tag relevance , which describes  X  X he degree to which a tag describes an item. X  In the example above, tag relevance would measure how well the tag  X  X ruce Willis X  describes a particular movie. Overall, in pre-vious work tag preference was considered a user-specific concept whereas tag relevance is considered to be an item-specific concept. In contrast, in our work our proposed concept of tag preference is user-and item-specific, which has shown to be a helpful means to capture the user X  X  preferences more precisely and thus produce more accurate recommendations.

Beside the relation of the work in Sen et al. [2009b], which we extend by item-specific tag preferences in this article, our approach is also closely related to the recent work of Vig et al. [2010], who experimented with a recommender system interface that allowed users to assign affect to the tags of a movie. Vig et al. [2010], introduce the idea of  X  X ag expressions, X  which, at its heart, represents the same idea of rating items by rating tags proposed in our own previous work [Gedikli and Jannach 2010]. Users are able to assign a so-called affect (preference) X  X ike, dislike or neutral X  X o tags in order to measure a user X  X  pleasure or displeasure with the item with respect to the tag. In contrast to our work the authors are focussing on user interface aspects and how the possibility to express tag preferences affects the tagging behavior of the community. In particular, Vig et al. also analyze the design space of tag expressions and focus on three elements: preference dimensions, affect expression and display of community affect. In our work, however, we present first algorithms that consider tag preferences (tag affects) to generate more accurate predictions, which is one of the main challenges listed in the future work section of Vig et al. [2010]. Additionally we also show how to infer the user opinion regarding a certain feature (tag) for a given item automatically. The main new idea of our work is to incorporate item-specific ratings for tags in the recommendation process. Based on such an approach, users are able to evaluate an ex-isting item in various dimensions and are thus not limited to the one single overall vote anymore. In contrast to previous attempts toward exploiting multidimensional ratings, our work aims to follow a Web 2.0 style approach, in which the rating dimensions are not static or predefined.

The goal of this article was to develop and evaluate different recommendation schemes that take item-specific tag preferences into account when generating rating predictions. In addition, we proposed a metric to automatically derive user-and item-specific tag preferences from the overall ratings based on item similarities in order to demonstrate that quality improvements can be achieved even when the tag preference data is not explicitly given. The results of the evaluation on two datasets show that a measurable accuracy improvement can be achieved.

In our future work we will not only run experiments with other metrics (incor-porating, default tag preferences or hybridization strategies) and more sophisticated methods for estimating tag preferences, but also explore further questions related to tag preferences in the Social Web recommendation process.  X  Further experiments and user interfaces. We plan to conduct further experiments with real tag preference data. A particular question to be answered in that context is that of an appropriate user interface (see also Vig et al. [2010] or Vig et al. [2009]) because Web users are currently not acquainted to the interaction pattern  X  X roviding ratings for tags. X  Intuitively, interfaces that allow users to rate tags on a 5-star scale with half-star increments or allow users to classify tags in two or three categories such as  X  X ike, X   X  X islike, X  or  X  X ndifferent X  seem appropriate. However, we aim to explore different visualizations to stimulate more precise ratings.
  X  Better explanations. Tags can also be a helpful means to generate explanations for the end user. Explanations for recommendations are one of the current research topics in the recommender systems area because they can significantly influence the way a user perceives the system. In Tintarev and Masthoff [2007], for example, seven possible advantages of an explanation facility are described. In Vig et al. [2009], the authors have evaluated explanation interfaces that use tag relevance and tag preference as two key components. In our current work [Gedikli et al. 2011b] we examine the role of tag preferences in helping users understand their recommen-dations. If tags are both user-and item-specific, more personalized and detailed, multidimensional explanations can be provided. Based on appropriately designed explanation interfaces, the different aspects of explanations as discussed in Tintarev and Masthoff [2007] (such as transparency, trust, effectiveness and satisfaction) can be analyzed in different user studies. Again, also the question of the appropriate end-user visualization has to be answered.  X  Combination with tag recommenders. Different techniques to tag recommendation have been developed in the last years to stimulate users to use a more consistent set of tags in the annotation process, see, for example, Zhang et al. [2009]. We expect that the value of item-specific tag preferences is even higher, when the overall set of tags used in the dataset is more consistent.  X  New tag quality metrics. We have stated in Section 5.1 that our approach of rating items by rating tags calls for a new quality requirement to tags: tags must be appro-priate for ratings. Therefore, in our current work, we aim to develop new tag quality metrics in order to improve the overall performance of recommendation algorithms that are based on tag preferences.

Finally, by making the software used in our experiments publicly available, 16 we hope to contribute to the comparability of different algorithms since our study revealed that relevant algorithmic details and parameters are often not reported in sufficient details.

