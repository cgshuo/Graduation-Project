 Scatterplots are not the most efficient way of repre-senting information (Grinstein et al., 2001). How-ever, they are intuitive and stable (Wong and Berg-eron, 1997), and can be supplemented in several ways. We describe some of these augmentations in Section 1, basic Ndaona usage in Section 2, and fi-nally a couple of some embedding methods in Sec-tion 3. Figure 1: Regular and glyph-supplemented scat-terplots showing how a linear kernel can separate happy and sad faces from the Frey Face dataset. 1.1 Glyphs Glyphs are icons that provide a visual representa-tion of a datum. A simple example of a glyph is a filled-in circle whose color and size convey two additional dimensions of information. More com-plex examples have been designed to present more information (Tukey and Tukey, 1981) (Ward, 2002). Partiview can use any image as a glyph, as long as all images used can fit in graphics memory.
 For example, Figure 1 shows faces from the Frey close together then the vectors u and v representing have a high value of u T v . In this case, each point has a natural visual representation  X  the face itself. And we therefore use the faces as lossless glyphs, with each glyph representing a 560-dimensional vector (20 x 28 pixel image).

A second example is in Figure 2. It shows Man-darin syllables in a tone recognition experiment (Surendran et al., 2005), with two syllables close Figure 2: A close-up screenshot of a 3D glyph-supplemented scatterplot showing the performance of a linear Support Vector Machine (SVM) on a 4-way Mandarin syllable tone classification task. Ndaona embedded syllables so that those classified similarly by the SVM are close together. The glyph for each syllable represents the 20-dimensional vec-tor input to the SVM. Syllables with the same tone are represented by glyphs of the same color; the white syllables in the foreground have falling tone. together if the classification algorithm made simi-lar predictions of their tone. The algorithm received for each syllable a 20-dimensional vector that de-scribed its normalized pitch contour of the syllable. In this case, a histogram of the pitch contour, with the area between the pitch contour and the horizon-tal axis shaded for enhanced visibility, results in a highly informative glyph.

A close-up look at the low tone syllables reveals that the algorithm  X  X hinks X  that any syllable whose pitch contour decreases towards the end has a falling tone which is what linguists expect. We can also tell that many of the mistakes made by the algorithm are due to the features and not the algorithm itself. For instance, the several high tone syllables that are close to the cluster of low-tone-syllables (and would thus be classified as having low tone by the algo-rithm) do in fact have a falling pitch contour. 1.2 Three Dimensions Partiview users can smoothly spin, zoom, and move the 3d scatterplot model even when it contains hun-dreds of thousands of points. Interaction and motion deal with difficulties (described in the information visualization and statistical graphics literature) of vi-sually estimating distances when a third dimension is used (Jacoby, 1998). 1.3 Graphs While Partiview is not the best software for display-ing graphs, it can display lines of varying width and color. This permits two bits of information to be dis-played about binary relations between points. 1.4 Information about points While text labels can be placed at points, this often results in visual clutter. It is better to give the user the option of only having labels displayed when ac-tively requested. This option is called  X  X inking X .
Partiview has some linking capability. When a user clicks on a point (and presses  X  X  X ), the com-mand window displays information about it, such as its position, several features, and any  X  X omment X  provided by the user. For example, Figures 3 and 4 show the results of a 13-class dialog act classifica-tion task  X  the user supplied as comments the words said during each dialog act. Some of these can be seen in the command window of each screenshot. 1.5 Brushing Brushing is the ability for users to select subsets of data points and apply certain operations to them, such as toggling their visibility (masking), changing their color or size (Becker and Cleveland, 1987).
Partiview supports this very well, and it is possi-bly the most important feature available for data ex-ploration. For example, we can change the colors of points to be that of any attribute of the data, includ-ing its original features. This helps investigate what original features the algorithm is actually using.
For example, in Figure 3 color represents class, while in Figure 4 color represents duration. The color could just as easily be changed to repre-sent other attributes of the data; Ndaona estimates Partiview parameters required for consistent behav-ior across attributes by normalizing the color map for each attribute. 1.6 Animation Partiview supports animated data. Ndaona has been written so that one can deal with various combina-tions of static and dynamic (time-varying) graphical elements, such as fixed points and varying edges, or dynamic points and fixed edges (i.e. the edges al-ways join the same points), or both dynamic points and edges, fixed points and dynamic attributes, and so on. The only difference to the user is that s/he provides a cell array (list) of matrices for the dy-namic element instead of a single matrix.
 Figure 3: Partiview screenshot of a Ndaona-made model showing the result of a dialog act classifica-tion algorithm. Each point represents a dialog act, and all acts of the same type are colored identically. For flexibility of input, arguments to Ndaona are supplied in parameter-value pairs. For example, say P is a N  X  3 matrix representing the 3D coordinates of
N points and Q is a list of N images representing the glyphs of each point. Ndaona includes tools to create such images, or the user can provide their own JPEGs. Either of the equivalent commands ndaona( X  X OSITIONS X ,P, X  X ICTURES X ,Q) ndaona( X  X OS X ,P,  X  X ICS X ,Q) creates a 3D model with the pictures in Q repre-sented at the positions for each point, such as that in Figures 1 and 3. Graphics parameters controlling picture sizes are automatically estimated by Ndaona.
Now suppose that the N points have time-varying positions. Making P a list of N  X  3 matrices and Figure 4: As for Figure 3 but now color represents duration. Shorter acts (top left) are green. using the same command as above creates a time-varying scatterplot with the images moving about.
If this was classification and the true class of each point is stored in a N -dimensional vector L , then ndaona( X  X OS X ,P, X  X ICS X ,Q, X  X LASS X ,L) creates the 3D model with the pictures colored by class, with the same color for points of the same class, such as that in Figure 2. Also, Partiview provides a button for each class that toggles the visibility of data points in that class. If each point has A attributes stored in a N  X  A matrix F , then ndaona( X  X OS X ,P,..., X  X TTRIBUTES X ,F) creates a model as before, but with brushing avail-able. The colors of each point can be changed ac-cording to the r -th attribute by typing  X  color a r  X , where a r is the automatically assigned name for the r -th attribute. (Users can provide attribute names with another parameter-value pair.)
If the N points also form the nodes of a (con-nected or not) graph with N edges are represented by a N N ndaona( X  X OS X ,P,..., X  X DGES X ,G) creates the same scatterplot, overlaid with edges.
Additional parameter-value pairs in Ndaona can be used to fine-tune graphics parameters, create files in directory structures that are easy to compress and distribute, change background color, etc. When visualizing the results of algorithms, users may not have a three-dimensional embedding al-ready available. However, algorithms have been pro-posed to produce such embeddings, and we now de-scribe some of those available in Ndaona. Ndaona also implements basic dimensionality reduction al-gorithms such as Principal Components Analysis, Laplacian Eigenmaps, and Isomap. 3.1 Classification Probabilities If users have a N  X  K matrix S of prediction proba-bilities from a K -class classification algorithm, with S ( n, k ) having the probability (estimated by the al-gorithm) that the n -th point is in class k , then this can be supplied instead.

Ndaona uses the Parametric Embedding algo-rithm (Iwata et al., 2004) to find a low-dimensional embedding of the N points so that pairs of points that were given similar predictions by the classifica-tion algorithm (i.e. have low Kullback-Leibler dis-tance between their prediction probability distribu-tions) are closer together. 3.2 Kernel Matrices Support vector machines (SVMs) and related meth-ods depend on pairwise similarities of points, in the form of a kernel matrix whos ( i, j ) -th entry rep-resents the similarity of the i -th and j -th points. Shawe-Taylor and Christianini (2004) suggest using the eigenvectors corresponding to the three smallest positive eigenvalues of the Laplacian of the N  X  N kernel matrix to define a N  X  3 positions matrix. Ndaona implements an alternative that, in our expe-rience, works better  X  using the normalized Lapla-cian of the kernel matrix (with negative entries re-placed by zero). Ndaona is an interface package that helps reearchers produce compelling visual representations of their data. Its output is a (time-varying) 3d model that can be displayed by Partiview, an external data viewer. Future plans include adding more scal-able embedding algorithms, and allowing other out-put formats. Ndaona, documentation, and exam-ples of models created with it, can be found at http://people.cs.uchicago.edu/  X  dinoj/ndaona
