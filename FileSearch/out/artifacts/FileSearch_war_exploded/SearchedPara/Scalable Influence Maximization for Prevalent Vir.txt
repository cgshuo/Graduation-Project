 Influence maximization, defined by Kempe, Kleinberg, and Tardos (2003), is the problem of finding a small set of seed nodes in a so-cial network that maximizes the spread of influence under certain influence cascade models. The scalability of influence maximiza-tion is a key factor for enabling prevalent viral marketing in large-scale online social networks. Prior solutions, such as the greedy al-gorithm of Kempe et al. (2003) and its improvements are slow and not scalable, while other heuristic algorithms do not provide con-sistently good performance on influence spreads. In this paper, we design a new heuristic algorithm that is easily scalable to millions of nodes and edges in our experiments. Our algorithm has a sim-ple tunable parameter for users to control the balance between the running time and the influence spread of the algorithm. Our results from extensive simulations on several real-world and synthetic net-works demonstrate that our algorithm is currently the best scalable solution to the influence maximization problem: (a) our algorithm scales beyond million-sized graphs where the greedy algorithm be-comes infeasible, and (b) in all size ranges, our algorithm performs consistently well in influence spread  X  it is always among the best algorithms, and in most cases it significantly outperforms all other scalable heuristics to as much as 100%  X  260% increase in influence spread.
 F.2.2 [ Analysis of Algorithms and Problem Complexity ]: Non-numerical Algorithms and Problems Algorithms, Experimentation, Performance influence maximization, social networks, viral marketing
Word-of-mouth or viral marketing differentiates itself from other marketing strategies because it is based on trust among individuals X  close social circle of families, friends, and co-workers. Research shows that people trust the information obtained from their close social circle far more than the information obtained from general advertisement channels such as TV, newspaper and online adver-tisements [16]. Thus many people believe that word-of-mouth mar-keting is the most effective marketing strategy (e.g. [15]).
The increasing popularity of many online social network sites, such as Facebook, Myspace, and Twitter, presents new opportuni-ties for enabling large-scale and prevalent viral marketing online. Consider the following hypothetical scenario as a motivating ex-ample. A small company develops a cool online application and wants to market it through an online social network. It has a lim-ited budget such that it can only select a small number of initial users in the network to use it (by giving them gifts or payments). The company wishes that these initial users would love the applica-tion and start influencing their friends on the social network to use it, and their friends would influence their friends X  friends and so on, and thus through the word-of-mouth effect a large population in the social network would adopt the application. The problem is whom to select as the initial users so that they eventually influence the largest number of people in the network.

The above problem, called influence maximization , is first for-mulated as a discrete optimization problem by Kempe, Kleinberg, and Tardos as follows [10]: A social network is modeled as a graph with nodes representing individuals and edges representing con-nections or relationship between two individuals. Influence are propagated in the network according to a stochastic cascade model, such as the following independent cascade (IC) model 1 : Each edge ( u, v ) in the graph is associated with a propagation probability pp ( u, v ) , which is the probability that node u independently ac-tivates (a.k.a. influences) node v at step t + 1 if u is activated at step t . Given a social network graph, the IC model, and a small number k , the influence maximization problem is to find k nodes in the graph (referred to as seeds ) such that under the influence cas-cade model, the expected number of nodes activated by the k seeds (referred to as the influence spread ) is the largest possible. Kempe et al. prove that the optimization problem is NP-hard, and present a greedy approximation algorithm guaranteeing that the influence spread is within (1  X  1 /e  X   X  ) of the optimal influence spread, where e is the base of natural logrithm, and  X  depends on the accuracy of their Monte-Carlo estimate of the influence spread given a seed set.
However, their algorithm has a serious drawback  X  it is not scal-able to large networks. A key element of their greedy algorithm is to compute the influence spread given a seed set, which turns out to be a difficult task (in fact, as we point out in Section 2 the com-putation is #P-hard). Instead of finding an exact algorithm, Monte-
Other models are also introduced in [10], but in this paper we focus on the independent cascade model. Carlo simulations of the influence cascade model are run for a large number of times in order to obtain an accurate estimate of the influ-ence spread. Consequently, even with the recent optimizations [14, 4] that could achieves hundreds of times speedup, it still takes hours on a modern server to select 50 seeds in a moderate sized graph (15K nodes and 31K edges) while it becomes completely infea-sible for larger graphs (e.g. more than 500K edges). Given that online social networks are typically of large-scale, we believe that the scalability issue of the greedy algorithm will be a fatal obstacle preventing it from supporting prevalent viral marketing activities in large-scale online social networks.
In this paper, we first show that computing influence spread in the independent cascade model is #P-hard, which closes an open question posed by Kempe et al. in [10]. It indicates that the greedy algorithm of [10] may have intrinsic difficulties to be made scalable for large graphs.

We then address the scalability issue by proposing a new heuris-tic algorithm that is several orders of magnitude faster than ex-isting greedy algorithms while matching the influence spread of the greedy algorithms. Our heuristic gains efficiency by restricting computations on the local influence regions of nodes. Moreover, by tuning the size of local influence regions, our heuristic is able to achieve tunable tradeoff between efficiency (in terms of running time) and effectiveness (in term of influence spread). Our heuris-tic can easily scale up to handle networks with millions of nodes and edges, and at this scale it beats all other existing heuristics of similar scalability in terms of the influence spread.

The main idea of our heuristic scheme is to use local arbores-cence 2 structures of each node to approximate the influence propa-gation. We first compute maximum influence paths (MIP) between every pair of nodes in the network via a Dijkstra shortest-path algo-rithm, and ignore MIPs with probability smaller than an influence threshold  X  , effectively restricting influence to a local region. We then union the MIPs starting or ending at each node into the ar-borescence structures, which represent the local influence regions of each node. We only consider influence propagated through these local arborescences, and we refer to this model as the maximum influence arborescence (MIA) model.

We show that the influence spread in the MIA model is submod-ular (i.e. having a diminishing marginal return property), and thus the simple greedy algorithm that selects one node in each round with the maximum marginal influence spread can guarantee an influence spread within (1  X  1 /e ) of the optimal solution in the MIA model, while any higher ratio approximation is NP-hard. The greedy algorithm on the MIA model is very efficient because (a) computation of the marginal influence spread on the arborescence structures can be done by efficient recursion; and (b) after selecting one seed with the largest influence spread, we only need to update local arborescence structures related to this seed for the selection of the next seed, and we further design a batch update scheme to speed up the update process.

We conduct extensive experiments on several real-world and synthetic networks of different scale and features, and under differ-ent types of the IC model. We compare our heuristic with both the greedy algorithm [10, 14, 4] and several existing heuristics includ-ing the degree discount heuristics of [4], the shortest-path based heuristics of [11], and the popular PageRank algorithm [2] for rank-ing web pages. Our simulation results show that: (a) the greedy
An arborescence is a tree in a directed graph where all edges are either pointing toward the root (in-arborescence) or pointing away form the root (out-arborescence). algorithm of [10, 14, 4] and the shortest-path based heuristic [11] have poor scalability: they take hours or days to select 50 seeds when the graph size reaches a few hundred thousands and become infeasible for larger sized graphs, while in the same range MIA heuristic can finish in seconds (more than three orders of magni-tude speedup), and it continues to scale up beyonds graphs with millions of edges, (b) comparing with the greedy algorithm and the shortest-path based heuristic in real graphs in which they are fea-sible to run, MIA heuristic has influence spread that matches or is very close to those of the two other algorithms, (c) comparing with the rest heuristics, MIA algorithm is always among the best in in-fluence spread, and in most cases it significantly outperforms the rest heuristics, with a margin as much as 100%  X  260% increase in influence spread. Moreover, we show that by tuning the threshold  X  , we can adjust the tradeoff between efficiency and effectiveness at difference balance points on a spectrum.

To summarize, our main contribution is the design and evalua-tion of a scalable and tunable heuristic that handles the influence maximization problem for large-scale social networks. We demon-strate that our heuristic is currently the best one that could handle large-scale networks with more than a million edges, while even for moderate sized networks it is a very competitive alternative to much slower algorithms. The balanced efficiency and effectiveness of our heuristic make it suitable as a generic solution to influence maximization for many large-scale online social networks encoun-tered in practice.
Domingos and Richardson [6, 18] are the first to study influence maximization as an algorithmic problem. Their methods are prob-abilistic, however. Kempe, Kleinberg, and Tardos [10] are the first to formulate the problem as a discrete optimization problem. Be-sides what we mentioned above already, they also study a number of other topics such as generalizations of influence cascade mod-els and mixed marketing strategies in influence maximization. As pointed out, a serious drawback of their work is the scalability of their greedy algorithm.
 Several recent studies aimed at addressing this issue. In [14], Leskovec et al. present a  X  X azy-forward X  optimization in select-ing new seeds, which greatly reduces the number of evaluations on the influence spread of nodes and results in as much as 700 times speedup demonstrated by their experimental results. However, even though the  X  X azy-forward X  optimization is significant, it still takes hours to find 50 most influential nodes in a network with a few tens of thousands of nodes, as shown in [4].

In [11], Kimura and Saito propose shortest-path based influence cascade models and provide efficient algorithms to compute influ-ence spread under these models. The key differences between their work and ours are (a) instead of using maximum influence paths, they use simple shortest paths on the graph, which are not related to propagation probabilities, and (b) they do not utilize local struc-tures such as our arborescences and thus in every round they need global computations to select the next seed. Therefore, their algo-rithms are not scalable, as shown in our experiments.

This paper is the continuation of [4] in the pursuit of efficient and scalable influence maximization algorithms. In [4], we explore two directions in improving the efficiency: one is to further im-prove the greedy algorithm of [10], and the other is to design new heuristic algorithms. The first direction shows improvement but is not significant enough, indicating that this direction could be diffi-cult to continue. The second direction leads to new degree discount heuristics that are very efficient and generate reasonably good influ-ence spread. The major issue is that the degree discount heuristics are derived from the uniform IC model where propagation proba-bilities on all edges are the same, which is rarely the case in reality. Our current work is a major step in overcoming this limitation  X  our new heuristic algorithm works for the general IC model while still maintain good balance between efficiency and effectiveness. We conduct much more experiments than in [4] on more and larger scale graphs, and our results show that the MIA heuristic performs consistently better than the degree discount heuristic in all graphs. The degree discount heuristic can be viewed as a special case of our MIA heuristic restricted on the uniform IC model with all ar-borescences having depth one.
 Paper organization. Section 2 provides preliminaries on the IC model and the greedy algorithm, and also shows that computing the exact influence spread given a seed set is #P-hard. Section 3 presents our MIA model and the algorithm for this model as well as its extension, the PMIA model. Section 4 shows our experimental results. We discuss future directions in Section 5. Further details of our work, including the full explanation of the PMIA model and more experimental results, are presented in our technical report [3].
We consider a directed graph G = ( V, E ) with edge labels pp : E  X  [0 , 1] . For every edge ( u, v )  X  E , pp ( u, v ) denotes the propagation probability of the edge, which is the probability that v is activated by u through the edge in the next step after u is activated.

Given a seed set S  X  V , the independent cascade (IC) model works as follows. Let S t  X  V be the set of nodes that are activated at step t  X  0 , with S 0 = S . At step t + 1 , every node u activate its out-neighbors v  X  V \  X  0  X  i  X  t S i with an independent probability of pp ( u, v ) . The process ends at a step t with S Note that each activated node only has one chance to activate its out-neighbors at the step right after itself is activated, and each node stays as an activated node after it is activated. The influence spread of S , which is the expected number of activated nodes given seed set S , is denoted as  X  I ( S ) .

Given an input k , the influence maximization problem in the IC model is to find a subset S  X   X  V such that | S  X  | = k and  X  max {  X  I ( S ) | | S | = k, S  X  V } . It is shown in [10] that this problem is NP-hard, but a constant-ratio approximation algorithm is available.
 We say that a non-negative real valued function f on subsets of V is submodular if f ( S  X  { v } )  X  f ( S )  X  f ( T  X  { v all v  X  V and all pairs of subsets S and T with S  X  T  X  V . In-tuitively, this means that f has diminishing marginal return. More-over, we say that f is monotone if f ( S )  X  f ( T ) for all S For any submodular and monotone function f with f (  X  ) = 0 , the problem of finding a set S of size k that maximizes f ( S ) can be approximated by a simple greedy algorithm shown as Algorithm 1. The algorithm iteratively selects new seed u that maximizes the in-cremental change of f into the seed set S until k seeds are selected. It is shown in [17] that the algorithm guarantees the approximation ratio f ( S ) /f ( S  X  )  X  1  X  1 /e , where S is the output of the greedy algorithm and S  X  is the optimal solution.

In [10], it is shown that function  X  I (  X  ) is submodular and mono-tone with  X  I (  X  ) = 0 . Therefore, algorithm Greedy ( k,  X  the influence maximization problem with an approximation ratio of 1  X  1 /e .

One important issue, however, is that there is no efficient way to compute  X  I ( S ) given a set S . Although Kempe et al. claim that Algorithm 1 Greedy ( k, f ) 1: initialize S =  X  2: for i = 1 to k do 3: select u = arg max w  X  V \ S ( f ( S  X  { w } )  X  f ( S )) 4: S = S  X  { u } 5: end for 6: output S finding an efficient algorithm for computing  X  I ( S ) is open [10], we point out that the computation is actually #P-hard, by showing a reduction from the counting problem of s -t connectness in a graph.
T HEOREM 1. Computing the influence spread  X  I ( S ) given a seed set S is #P-hard.
 Proof. We prove the theorem by a reduction from the counting problem of s -t connectness in a directed graph [21]. An instance of s -t connectness is a directed graph G = ( V, E ) and two vertices s and t in the graph. The problem is to count the number of subgraphs of G in which s is connected to t . It is straightforward to see that this problem is equivalent to computing the probability that s is connected to t when each edge in G has an independent probability of 1 / 2 to be connected, and another 1 / 2 to be disconnected. We reduce this problem to the influence spread computation problem as follows. Let  X  I ( S, G ) denote the influence spread in G given a seed set S . First, let S = { s } , and let pp ( e ) = 1 / 2 for all e and compute I 1 =  X  I ( S, G ) . Next, we add a new node t directed edge from t to t  X  to G , obtaining a new graph G pp ( t, t  X  ) = 1 . Then we compute influence spread I 2 =  X  Let p ( S, v, G ) denote the probability that v is influenced by seed set S in G . It is easy to see that I 2 =  X  I ( S, G )+ p ( S, t, G ) Therefore, I 2  X  I 1 is the probability that s is connected to t , and thus we solve the s -t connectness counting problem. It is shown in [21] that s -t connectness is #P-complete, and thus the influence spread computation problem is #P-hard. 2
The above theorem shows that computing exact influence spread is hard. Moreover, finding an efficient approximation algorithm for computing the probability of s -t connectivity is a long-standing open problem [22]. Together with the fact that several improve-ments ([14, 4]) of the original greedy algorithm of [10] are still not efficient, we believe that we need to look for alternative ways, such as heuristic algorithms, to tackle the efficiency problem in influence maximization.
For a path P =  X  u = p 1 , p 2 , . . . , p m = v  X  , we define the prop-agation probability of the path, pp ( P ) , as
Intuitively the probability that u activates v through path P is pp ( P ) , because it needs to activate all nodes along the path. To ap-proximate the actual expected influence within the social network, we propose to use the maximum influence path ( MIP ) to estimate the influence from one node to another. Let P ( G, u, v ) denote the set of all paths from u to v in a graph G .
 G , we define the maximum influence path MIP G ( u, v ) from u to v in G as Algorithm 2 ap ( u, S, MIIA ( v,  X  )) 1: if u  X  S then 2: ap ( u ) = 1 3: else if N in ( u ) =  X  then 4: ap ( u ) = 0 5: else 6: ap ( u ) = 1  X  w  X  N in ( u ) (1  X  ap ( w )  X  pp ( w, u )) 7: end if Ties are broken in a predetermined and consistent way, such that MIP G ( u, v ) is always unique, and any subpath in MIP G from x to y is also the MIP G ( x, y ) . If P ( G, u, v ) = MIP G ( u, v ) =  X  .

Note that for each edge ( u, v ) in the graph, if we trans-late the propagation probability pp ( u, v ) to a distance weight  X  log pp ( u, v ) on the edge, then MIP G ( u, v ) is simply the short-est path from u to v in the weighted graph G . Therefore, the max-imum influence paths and the later maximum influence arbores-cences directly correspond to shortest paths and shortest-path ar-borescences, and thus they permit efficient algorithms such as Di-jkstra algorithm to compute them.

For a given node v in the graph, we propose to use the maximum influence in-arborescence ( MIIA ), which is the union of the maxi-mum influence paths to v , 3 to estimate the influence to v from other nodes in the network. We use an influence threshold  X  to eliminate MIPs that have too small propagation probabilities. Symmetrically, we also define maximum influence out-arborescence ( MIOA ) to es-timate the influence of v to other nodes.
 SCENCE ) For an influence threshold  X  , the maximum influence in-arborescence of a node v  X  V , MIIA ( v,  X  ) , is The maximum influence out-arborescence MIOA ( v,  X  ) is:
Intuitively, MIIA ( v,  X  ) and MIOA ( v,  X  ) give the local influence regions of v , and different values of  X  controls the size of these local influence regions.

Given a set of seeds S in G and the in-arborescence MIIA ( v,  X  ) for some v  X  X  S , we approximate the IC model by assum-ing that the influence from S to v is only propagated through edges in MIIA ( v,  X  ) . With this approximation, we can calcu-late the probability that v is activated given S exactly. Let the activation probability of any node u in MIIA ( v,  X  ) , denoted as ap ( u, S, MIIA ( v,  X  )) , be the probability that u is activated when the seed set is S and influence is propagated in MIIA ( v,  X  ) . Let N in ( u, MIIA ( v,  X  )) be the set of in-neighbors of u in MIIA ( v,  X  ) . In the above notations, MIIA ( v,  X  ) and S may be dropped when it is clear from the context. Then ap ( u, S, MIIA ( v,  X  )) can be com-puted recursively as given in Algorithm 2.

Note that because MIIA ( v,  X  ) is an in-arborescence, there are no multiple paths between any pair of nodes in MIIA ( v,  X  ) , and thus there is no dependency issue in the calculation of the activation probability and the calculation in Algorithm 2 exactly matches the IC model restricted onto MIIA ( v,  X  ) .
Since we break ties in maximum influence paths consistently, the union of maximum influence paths to a node do not have undirected cycles, and thus it is indeed an arborescence.

In our MIA model we assume that seeds in S influence every individual node v in G through its MIIA ( v,  X  ) . Let  X  M the influence spread of S in our MIA model, then we have Even though activating multiple nodes from the same set of seeds in the MIA model are correlated events, Equation (3.1) is still cor-rect due to the linearity of the expectation over the sum of random variables.

We are interested in finding a set of seeds S of size k such that  X 
M ( S ) is maximized. It is not surprising that this optimization problem is NP-hard. In fact, the same reduction from set cover problem in [10] together with Theorem 5.3 of [7] is sufficient to show the following.

T HEOREM 2. It is NP-hard to compute a set of nodes S of size k such that  X  M ( S ) is maximized. Furthermore, it is NP-hard to approximate within a factor of 1  X  1 /e +  X  for any  X  &gt; 0 .
It is straight forward to verify the following result, which means we have an approximation algorithm.

T HEOREM 3. Function  X  M is submodular and monotone and  X 
M (  X  ) = 0 . Therefore, Greedy ( k,  X  M ) of Algorithm 1 achieves 1  X  1 /e approximation ratio for the influence maximization problem in the basic MIA model.

Note that the recursive computation of ap ( u ) in Algorithm 2 can be transformed into an iterative form such that all ap ( u )  X  X  with u in MIIA ( v,  X  ) can be computed by one traverse of the arborescence MIIA ( v,  X  ) from leaves to the root. Thus, computing  X  M Equation (3.1) and Algorithm 2 is polynomial-time. Together with Algorithm 1, we already have a polynomial-time approximation al-gorithm. However, we could further improve the efficiency of the algorithm, as we shown in the next section.
The only important step in the greedy algorithm is to select the next seed that gives the largest incremental influence spread. Con-sider the maximum influence in-arborescence MIIA ( v,  X  ) of size t and a given seed set S . To select the next seed u , we need to compute the activation probability ap ( v, S  X  { w } , MIIA ( v,  X  )) for every w  X  MIIA ( v,  X  ) , which takes O ( t 2 ) time if we simply use Algorithm 2 to compute every ap ( v, S  X  { w } , MIIA ( v,  X  )) . We now show a batch update scheme such that we could compute ap ( v, S  X  { w } , MIIA ( v,  X  ))  X  X  for all w  X  MIIA ( v,  X  ) in O ( t ) time.

To do so, we utilize the linear relationship between ap ( u ) and ap ( v ) in MIIA ( v,  X  ) , as shown by the following lemma, which is not difficult to derive from line 6 of Algorithm 2.

L EMMA 1 (I NFLUENCE L INEARITY ). Consider MIIA ( v,  X  ) and a node u in it. If we treat the activation probabilities ap ( u ) and ap ( v ) as variables and other ap ( w )  X  X  as constants, where w is any node in MIIA ( v,  X  ) other than u and v , then ap ( v ) =  X  ( v, u ) of ap ( u ) .

Based on the recursive computation of ap ( u, S, MIIA ( v,  X  )) as shown in line 6 of Algorithm 2, it is straightforward to derive a recursive computation of  X  ( v, u ) , as shown in Algorithm 3. Note that Algorithm 3 can be transformed into an iterative form such that all  X  ( v, u )  X  X  can be computed by one traverse of MIIA ( v,  X  ) from the root to the leaves. Algorithm 3 Compute  X  ( v, u ) with MIIA ( v,  X  ) and S , after ap ( u, S, MIIA ( v,  X  )) for all u in MIIA ( v,  X  ) are known. 1: /* the following is computed recursively */ 2: if u = v then 3:  X  ( v, u ) = 1 4: else 5: set w to be the out-neighbor of u 6: if w  X  S then 7:  X  ( v, u ) = 0 /* u  X  X  influence to v is blocked by seed w */ 8: else 9:  X  ( v, u ) =  X  ( v, w )  X  pp ( u, w )  X  u  X   X  N in ( w ) 10: end if 11: end if
Computing the linear coefficients  X  ( v, u ) as defined in Lemma 1 is crucial in computing the incremental influence spread of a node u . Let us consider again the maximum influence in-arborescence MIIA ( v,  X  ) of size t and a given seed set S . For any w MIIA ( v,  X  ) , if we select w as the next seed, its ap ( w ) increases from the current value to 1 . Since ap ( w ) and ap ( v ) have a linear relationship with the linear coefficient  X  ( v, w ) , the incremental in-fluence of w on v is given by  X  ( v, w )  X  (1  X  ap ( w )) . Therefore, we only need one pass of MIIA ( v,  X  ) to compute ap ( w )  X  X  for all w  X  MIIA ( v,  X  ) , and a second pass of MIIA ( v,  X  ) to compute  X  ( v, w )  X  X  and  X  ( v, w )  X  (1  X  ap ( w ))  X  X  for all w This reduces the running time of computing incremental influence spread of all nodes in MIIA ( v,  X  ) from O ( t 2 ) to O ( t ) .
Our complete greedy algorithm for the basic MIA model is pre-sented in Algorithm 4. Lines (2 X 11) evaluate the incremental influ-ence spread IncInf ( u ) for any node u when the current seed set is empty. The evaluation is exactly as we described above using the linear coefficients  X  ( v, u ) .

Lines (15 X 30) update the incremental influences whenever a new seed is selected in line 14. Suppose u is selected as the new seed in an iteration. The influence of u in the MIA model only reaches nodes in MIOA ( u,  X  ) . Thus the incremental influence spread IncInf ( w ) for some w needs to be updated if and only if w is in MIIA ( v,  X  ) for some v  X  MIOA ( u,  X  ) . This means that the update process is relatively local to u . The update is done by first subtracting  X  ( v, w )  X  (1  X  ap ( w, S, MIIA ( v,  X  ))) before adding u into the seed set (line 19), and then adding u into the seed set (line 22), recomputing the ap ( w, S, MIIA ( v,  X  )) and  X  ( v, w ) under the new seed set (lines 24 X 25), and adding  X  ( v, w )  X  (1  X  ap ( w, S, MIIA ( v,  X  ))) into IncInf ( w ) (line 28). Time and space complexity. Let n i = max v  X  V {| MIIA ( v,  X  ) and n o = max v  X  V {| MIOA ( v,  X  ) |} . Computing MIIA ( v,  X  ) can be done using efficient implementations of Dijkstra X  X  shortest-path algorithm. Assume the maximum running time to compute MIIA ( v,  X  ) for any v  X  V is t i . When MIIA ( v,  X  )  X  X  for all node v  X  V are available, MIOA ( v,  X  )  X  X  can be derived from MIIA ( v,  X  )  X  X , therefore no extra running time for MIOA ( v,  X  )  X  X  is needed. Notice that n i = O ( t i ) .
 For every node v  X  V , our algorithm stores MIIA ( v,  X  ) , MIOA ( v,  X  ) , and for every u  X  MIIA ( v,  X  ) , ap ( u, S, MIIA ( v,  X  )) and  X  ( v, u ) are stored (note that ap ( u, S, MIIA ( v,  X  )) can reuse the same entry for different seed set S ). We also use a max-heap to store and update IncInf ( v ) for all v  X  V . Therefore, the space complexity of the algorithm is O ( n ( n i + n o )) .

During the initialization of Algorithm 4, it takes O ( nt to compute MIIA ( v,  X  ) for all v  X  V , O ( nn i ) time to compute Algorithm 4 MIA ( G, k,  X  ) 1: /* initialization */ 2: set S =  X  3: set IncInf ( v ) = 0 for each node v  X  V 4: for each node v  X  V do 5: compute MIIA ( v,  X  ) and MIOA ( v,  X  ) 6: set ap ( u, S, MIIA ( v,  X  )) = 0 ,  X  u  X  MIIA ( v,  X  ) /* since 7: compute  X  ( v, u ) ,  X  u  X  MIIA ( v,  X  ) (Algo. 3) 8: for each node u  X  MIIA ( v,  X  ) do 9: IncInf ( u ) +=  X  ( v, u )  X  (1  X  ap ( u, S, MIIA ( v,  X  ))) 10: end for 11: end for 12: /* main loop */ 13: for i = 1 to k do 14: pick u = arg max v  X  V \ S { IncInf ( v ) } 15: /* update incremental influence spreads*/ 16: for v  X  MIOA ( u,  X  ) \ S do 17: /* subtract previous incremental influence */ 18: for w  X  MIIA ( v,  X  ) \ S do 19: IncInf ( w )  X  =  X  ( v, w )  X  (1  X  ap ( w, S, MIIA ( v,  X  ))) 20: end for 21: end for 22: S = S  X  { u } 23: for v  X  MIOA ( u,  X  ) \ S do 24: compute ap ( w, S, MIIA ( v,  X  )) ,  X  w  X  MIIA ( v,  X  ) 25: compute  X  ( v, w ) ,  X  w  X  MIIA ( v,  X  ) (Algo. 3) 26: /* add new incremental influence */ 27: for w  X  MIIA ( v,  X  ) \ S do 28: IncInf ( w ) +=  X  ( v, w )  X  (1  X  ap ( w, S, MIIA ( v,  X  ))) 29: end for 30: end for 31: end for 32: return S heap for storing IncInf ( u )  X  X . Therefore, the total running time for initialization is O ( nt i ) . During one iteration of the main loop, it takes constant time to select the new seed from the max-heap, O ( n o n i log n ) time to update IncInf ( w )  X  X  on the max-heap, and O ( n o n i ) time to compute ap ( w, S, MIIA ( v,  X , S ))  X  X  and  X  ( v, w )  X  X  after selecting the new seed. Thus, one iteration of the main loop takes O ( n o n i log n ) time. Together, the total running time of the algorithm is O ( nt i + kn o n i log n )) . Note that with-out applying the improvement of utilizing the linear relationship, the time complexity would be O ( nt i + kn o n i ( n i + log n )) .
Therefore, the algorithm performs the best when n i , n o t i are significantly smaller than n , that is, when the arborescences are small. This typically occurs for a reasonable range of  X  val-ues, when the graph is sparse and the propagation probabilities on edges are usually small, which is the case for social networks. Our experiments in the Section 4 will demonstrate the efficiency of our algorithm.
In the above basic MIA model, it could happen that a seed s on the MIP from another seed s j to a node v , in which case the influence from seed s j to v is completely blocked by seed s better approximate influence propagation in the original graph, we extend the MIA model to allow s j in the above example to find an alternative path to v that does not pass through s i .
Informally, in our extension, when selecting the next seed, for every node v , we recompute its in-arborescence such that every seed candidate w  X  V \ S has a path to v not passing through any seed in S . As a result, all selected seeds form a sequence S accord-ing to the selection order, such that any seed s in S has alternative paths to all nodes v that do not pass through any seed in the prefix of S preceeding s . This treatment allows us to have an efficient algorithm in the same framework as in Algorithm 4. We call this extension prefix excluding MIA (PMIA) model .

More precisely, Let S =  X  s 1 , s 2 , . . . , s m  X  be a sequence of seeds. Define S i =  X  s 1 , s 2 , . . . , s i  X  1  X  and S the subgraph of G induced by V \ S  X  for any sequence S  X  PMIA model, the maximum influence path from a seed s i  X  S to a node v will not pass through any seed nodes in the prefix S after s i in sequence S . We define ineffective seeds with respect to a node v , to be those seeds whose influence to v are blocked by some other subsequent seeds in sequence S .
 D EFINITION 3 (I NEFFECTIVE SEEDS ). For a given node v  X  V \ S , we define the set of ineffective seeds for v as: When computing the maximum influence in-arborescence in the PMIA model, in order to keep the influence linearity of Lemma 1 still applicable, we need to give the following special treatment for the case where the MIP from seed s i to v is blocked by a subsequent seed s j with j &gt; i . Consider a node u  X  X  S located on the MIP from s to s j . If u is selected as a seed later, then its MIP to v should avoid all seeds in S , and thus to compute its incremental influence spread correctly using the linearity property, we need to compute the MIP from u to v in the graph G ( S ) . Moreover, we need to remove the ineffective seed s i and its MIP to v because otherwise s would have two different paths to v , violating the arborescence definition. This leads to the following definition of the maximum influence in-arborescence for the PMIA model.

D EFINITION 4 (MIIA FOR THE PMIA M ODEL ). The maxi-mum influence in-arborescence of v in the PMIA model for v is:
For out-arborescence from v  X  X  S , we need to consider all MIPs from v that avoid all seeds in S . This is because we only need to compute the out-arborescence of a node v when v is just se-lected as the new seed. In this case, the paths in the above com-puted out-arborescence of v match the paths in the corresponding in-arborescences used to compute the incremental influence of v (since those paths avoid all seeds already in S ).

D EFINITION 5 (MIOA FOR THE PMIA M ODEL ). The max-imum influence out-arborescence of v in the PMIA model for v is:
Given the above definition, we can have activation probabilities ap ( u, S, PMIIA ( v,  X , S )) computed by Algorithm 2. Then, sim-ilar to Equation (3.1), we define  X  P ( S ) as the influence spread in the PMIA model given a seed sequence S , which is computed using the following equation:
Notice that different sequences S of the same set of seeds may generate different values of  X  P ( S ) . Therefore, the submodularity defined on set functions does not apply to  X  P . Fortunately, we can define sequence submodularity in a similar way, which also leads to the greedy algorithm with an approximation ratio of 1  X  Sequence submodularity. We now define sequence submodular-ity, which is implicitly used by Streeter and Golovin in [19]. Let S be the set of all sequences of V , including the empty sequence  X  . Let  X  be the binary operator that concatenates two sequences into one. We say that a non-negative function f defined on is sequence submodular if f ( S 1  X  S 2  X  { t } )  X  f ( S f ( S 1  X  { t } )  X  f ( S 1 ) for all sequences S 1 , S 2 f is prefix monotone if f ( S 1 )  X  f ( S 2  X  S 1 ) for all S An important result that matches the one for set submodular func-tions is that if f is sequence submodular and prefix monotone and f (  X  ) = 0 , then the greedy algorithm of Algorithm 1 (with set union  X  replaced by sequence concatenation  X  ) finds a sequence S such included in [3], which is adapted from the original proof in [19].
It is not difficult to verify that  X  P is sequence submodular and prefix monotone, and thus
T HEOREM 4. Function  X  P is sequence submodular and prefix monotone and  X  P (  X  ) = 0 . Therefore, Greedy ( k,  X  P ) of Algo-rithm 1 (with set union  X  replaced by sequence concatenation achieves 1  X  1 /e approximation ratio for the influence maximiza-tion problem in the PMIA model.
 Algorithm in the PMIA model. We now explain the neces-sary changes needed to adapt Algorithm 4 to the PMIA model. The major change is the computation of PMIIA ( v,  X , S ) and PMIOA ( v,  X , S ) . The computation of PMIOA ( v,  X , S ) is rela-tively simple, since we only need to remove S from the graph. Therefore, we can use the Dijkstra algorithm on graph G ( S ) to compute PMIOA ( v,  X , S ) .

To efficiently compute PMIIA ( v,  X , S ) , we maintain the set of ineffective seeds IS ( v, S ) for each node v  X  V \ S . Given IS ( v, S ) , PMIIA ( v,  X , S ) can be calculated as follows. We start a Dijkstra algorithm from v traversing inward edges. Whenever the Dijkstra algorithm hits a seed node s , it stops this branch and does not go further on the in-neighbors of s . After the Dijkstra algorithm completes, we remove all nodes IS ( v, S ) from the com-puted in-arborescence. When a new seed u is selected, we need to update IS ( v, S ) for all nodes v in PMIOA ( u,  X , S ) . This can be done by checking the set of effective seeds (those in S \ that are blocked by u in PMIIA ( v,  X , S ) .

After the above changes, we can essentially use Algorithm 4 for the PMIA model, with all MIIA ( v,  X  ) and MIOA ( u,  X  ) replaced by PMIIA ( v,  X , S ) and PMIOA ( u,  X , S ) respectively, and we recompute PMIOA ( u,  X , S ) after line 14 and recompute PMIIA ( v,  X , S ) after line 23. The full pseudocode of the PMIA model algorithm can be found in [3].
We conduct experiments on our algorithm as well as a number of other algorithms on several real-world and synthetic networks. Our experiments aim at illustrating the performance of our algorithm from the following aspects: (a) its scalability comparing to other
Dataset NetHEPT DBLP Epinions Amazon #Node 15K 655K 76K 262K #Edge 31K 2.0M 509K 1.2M Average Degree 4.12 6.1 13.4 9.4
Maximal Degree 64 588 3079 425 #Connected Com-ponent 1781 73K 11 1 Largest Component Size 6794 517K 76K 262K
Average Compo-nent Size 8.6 9.0 6.9K 262K algorithms; (b) its influence spread comparing to other algorithms; and (c) the tuning of its control parameter  X  . Datasets. We use four real-world networks and a synthetic dataset. The first one, denoted NetHEPT, is the same as used in [4]. It is an academic collaboration network extracted from "High Energy Physics -Theory" section of the e-print arXiv (http://www.arXiv.org), with nodes representing authors and edges representing coauthorship relations. The second is a much larger collaboration network, the DBLP Computer Science Bibliography Database maintained by Michael Ley. The other two datasets are published network data by Jure Leskovec. One is a Who-trust-whom network of Epinions.com [13], where nodes are members of the site and a directed edge from u to v means v trust u (and thus u has influence to v ). Another is the Amazon product co-purchasing network [12] dated on March 2, 2003, where nodes are products and a directed edge from u to v means product v is often purchased with product u (and thus u has influence to v ). 4 We refer to these two datasets as Epinions and Amazon. We choose these networks since it covers a variety of networks with sizes ranging from 30 K edges to 2 M edges. Some basic statistics about these networks are given in Table 1 (Epinions and Amazon networks are treated as undirected graphs in the statistics). Finally, in the scalability test, we use the DIGG package available on the web [5] to randomly generate power-law graphs of difference sizes based on the model of [1].
 Generating propagation probabilities. Since our algorithm is tar-geted at the general IC model with nonuniform propagation proba-bilities, we use the following two models to generate these nonuni-form probabilities. Algorithms. We compare our MIA heuristic with both the greedy algorithm and several heuristics that appear in the literature. The following is a list of algorithms we evaluate in our experiments.
Although the Amazon dataset is for products, we still include it in our experiments to test a variant of a network. Moreover, it also makes sense to find top seed products that lead to the most co-purchasing behaviors. (a) normal scale (b) log-log scale Figure 1: Scalability of different algorithms in synthetic datasets. Each data point is an average of ten runs.
We ignore other centrality measures, such as distance centrality and betweenness centrality [8] as heuristics, since we have shown in [4] that distance centrality is very slow and has very poor influ-ence spread, while betweenness centrality would be much slower than distance centrality.

To obtain the influence spread of the heuristic algorithms, for each seed set, we run the simulation on the networks 20000 times and take the average of the influence spread, which matches the accuracy of the greedy algorithms. The experiments are run on a server with 2.33GHz Quad-Core Intel Xeon E5410 and 32G mem-ory.

We actually conduct further experiments using more datasets, more variants of the IC model, and more heuristic algorithms. The results are similar to the results reported here. These further results are included in our full technical report [3]. Scalability on the synthetic dataset. To test scalability, we gen-erate a family of graphs of increasing sizes using the DIGG pack-age [5], which applies the random power-law graph model of [1] to generate random graphs. We use graphs of doubling sizes  X  2 K , 4 K , 8 K , . . . , up to 256 K in the number of nodes, and a power-law exponent of 2 . 16 . The average degree of these graphs is between 2 and 3 for these graphs, which is lower than the real networks in Table 1. We use the WC model for the graphs, and run PMIA algo-rithm with a fixed  X  = 1 / 320 , as well as other algorithms, to find 50 seeds in every graph. The result is shown in Figure 1, with nor-mal scale shown in (a) and log-log scale of the same figure shown in (b) to differentiate different algorithms better.

The result in Figure 1 (a) clearly separate all algorithms into two groups. Algorithms Greedy and SP1M are not scalable: their run-ning times are in the hour range with around 400 K edge graphs and it becomes infeasible to run them in larger graphs since we want to take average of 10 runs of every algorithm. Note that we already choose low average degree graphs so that they could run faster. Later reports on real graphs will show that they run even slower on those graphs. Our PMIA along with the rest heuristics can all scale up quite well. Figure 1 (b) differentiates the algorithms further. SP1M has the worst slope and is certainly not feasible for large-scale graphs. Greedy has the similar slope as other algorithms but its intercept is too large, because its Monte-Carlo simulation-based estimation of incremental influence spread for every node is too slow. Our PMIA has both good slope and intercept, making it easily scalable to large graphs with millions of edges. Influence spread and running time for the real-world datasets We run tests on the four datasets and the two IC models to obtain influence spread results. The seed set size k ranges from 1 to 50. For ease of reading, in all influence spread figures (best viewed in color), the legend ranks the algorithms top-down in the same order as the influence spreads of the algorithms when k = 50 . Moreover, if two curves are two close to each other, we group them together and show properly in the legend. All percentage difference reported below on influence spreads are the average of percentage differences from selecting one seed to selecting 50 seeds. Taking average is reasonable, since some algorithms may behave better when selecting the first few seeds while other algorithms behave better when selecting more seeds. The running time results are the time for selecting 50 seeds.

Figures 2 X 5 show the results on influence spreads for the four datasets on two IC models, while Figure 6 shows the running time results of the four datasets on the WC model (results on the TRIVA-LENCY model are similar and omitted).

For the moderate sized graph NetHEPT where Greedy is still feasible to run, the influence results in Figure 2 shows that Greedy produces the best influence spread, but PMIA is very close to Greedy : its influence spread essentially matches that of Greedy for the WC model and is only 3 . 8% less than Greedy for the TRIVALENCY model. Comparing with other heuristics, PMIA performs quite well: it matches the influence spread of SP1M while outforms the rest heuristics in both models  X  in the WC model, PMIA is 3 . 9% and 11 . 4% better, while in the TRIVA-LENCY model, PMIA is 6 . 5% and 15 . 4% better, comparing to DegreeDiscountIC and PageRank respectively. Random has a much worse influence spread, indicating that a careful seed selec-tion is indeed important to effective viral marketing results. When looking at the running time in Figure 6 for NetHEPT on WC, we clearly see that Greedy is already quite slow ( 1 . 3 hours), while PMIA only takes 1 second, more than three orders of magnitude better. PMIA is also more than one order of magnitude faster than SP1M , and is comparable with PageRank . DegreeDiscountIC is the best in running time, because it is simple and specially tuned for the uniform IC model.

Figure 3 shows the result on the Epinions dataset, a large net-work with half a million edges. The graph is already too large for Greedy to run, so Greedy is out of the picture. For the WC model, PMIA still matches the influence spread of SPIM while it has a large winning margin over DegreeDiscountIC and PageR-ank  X  PMIA is 96% and 115% better than DegreeDiscountIC and PageRank , respectively. This demonstrates that DegreeDis-countIC and PageRank are rather unstable heuristics while PMIA is very consistent in influence performance. For the TRIVALENCY model, we see that all heuristics, even Random reach a high level of influence spread after only a few seeds, while afterwards the in-crease in influence spread is slow. This behavior is quite different from the behavior of other test results we have seen so far, but it is very similar to a result presented in [10] for a graph when every edge has a propagation probability of 0 . 1 . Therefore, we believe that the explanation is also similar: in this test, after deleting the edges based on their propagation probabilities and only keep the edges that will propagate influence, the resulting graph is likely to have a relatively large strongly connected component, and thus even random node selection would likely to hit this component after a few attempts, drastically increasing the influence spread. How-ever, afterwards, additional seeds could only reach a small por-tion of still unaffected nodes, so further improvement in influence spread is small. But even in this case PMIA is still the best, out-performing the rest heuristics. For running time, we see that PMIA only takes 10 seconds but SP1M now takes 2 . 1 hours, more than 700 times slower than PMIA .

Next, for the one million-edge graph Amazon, Figure 4 shows that in the WC model PMIA again outperforms PageRank and DegreeDiscountIC with a large margin ( 99% and 266% , respec-tively), and in the TRIVALENCY model, it even outperforms SP1M significantly ( 14 . 1% , 23 . 9% , and 41 . 7% better than SP1M , PageRank , DegreeDiscountIC , respectively). Two unique fea-tures for this dataset are: (a) the influence spread is rather small, e.g. in TRIVALENCY, 50 seeds only generate a spread of around 80 nodes, and (b) the increase in influence spread is almost linear. The two features have the same reason  X  influence is very local and cannot propagate very far. It is probably because Amazon is a product co-purchasing network, not a social network. For running time, we now see that SP1M takes 30 hours, reaching its feasibility limit, while PMIA still only takes 10 seconds, showing its superb scalability over SP1M .

Finally, for the two million edge DBLP dataset, Figure 5 shows that this time PageRank and DegreeDiscountIC matches PMIA and are slightly better than PMIA for the WC model. Looking at all test cases (including additional ones in [3]), only a couple of cases where other scalable heuristics have matching influence spread as PMIA . This means that PMIA performs consistently well among the best scalable heuristics while others such as PageRank and DegreeDiscountIC are not stable  X  there exist a few cases that they perform well but in most other cases they performs not as well and sometimes they performs poorly comparing to PMIA . For run-ning time, even at two million edge range, PMIA only takes 3 min-utes to run. Therefore, PMIA has very good scalability and can handle million-sized or even larger graphs well.

Overall, we see that PMIA can scale beyond millions of edges, while Greedy and SP1M become too slow for half million edges or above. In all size ranges, PMIA consistently performs among the best algorithms (including Greedy and SP1M ), while in most cases it significantly outperforms the rest scalable heuristics to as much as 100%  X  260% increase in influence spread.
 Tuning of parameter  X  . We investigate the effect of the tuning parameter  X  on the running time and the influence spread of our algorithm. Figure 7 shows that the running time increases when the  X  value decreases, as expected. More interestingly, the running (a) WC model (b) TRIVALENCY model
Figure 2: Influence spread results on the NetHEPT dataset. (a) WC model (b) TRIVALENCY model
Figure 3: Influence spread results on the Epinions dataset. (a) WC model (b) TRIVALENCY model (a) WC model (b) TRIVALENCY model Figure 5: Influence spread results on the DBLP dataset.
Figure 6: Running time of different algorithms in for datasets time is almost linear to 1 / X  . This can be roughly explained as fol-lows. First, by the running time analysis of Section 3.2, we can see that when n and k are fixed and  X  varies, the dominant term is a quadratic term n o n i , which means the running time is propor-tional to the square of the average arborescence size. Figure 7 fur-ther shows that the average arborescence size is about O ( Therefore together the running time is close to a linear relationship with 1 / X  .

Figure 8 shows the change of influence spread with respect to the running time of our algorithm for the NetHEPT set in the WC model. Since the relationship between running time and 1 / X  is linear, it does not matter much if we use running time or 1 / X  as x -axis. The result indicates that as running time increases (  X  de-creases), the influence spread also increases, meaning that we ob-tain better quality results. Comparing other algorithms also shown in the figure, we see that on one side, we can tune 1 / X  to a larger value so that our influence spread can match the one provided by SP1M with at least 10 times speedup, while on the other side we can tune 1 / X  to a small value to get close to the running time of Figure 7: Running time and average arborescence size of PMIA vs. the threshold 1 / X  in the WC model, for NetHEPT dataset. PageRank with matching influence spread. Therefore, we can use one algorithm to achieve different efficiency-effectiveness tradeoff needs by properly tuning the parameters.
 One noticeable result is the knee in the curve of our algorithm. It means that the increase in influence spread is no longer signifi-cant after we lower  X  to a certain level. This is because as shown in Figure 7, arborescence size increases in square root of 1 / X  (and thus in square root of running time), while influence spread may change much slower after the arborescence grows beyond a certain size. The knee point suggests a good tuning point for the algo-rithm. If we select  X  such that the influence-time tradeoff is close to the knee point, we could obtain the best gain from both influ-ence spread and running time. Correlating with Figure 7, we found that the corresponding knee point to be close to the point where the change of arborescence size slows down (the dot with 1 / X  = 320 ). We observe similar situations in other dataset that we did not report here. Thus, this suggests the following way of tuning parameter  X  . Figure 8: maximal influence spread by 50 seeds w.r.t. running time, for the NetHEPT dataset in the WC model.
 Given a new graph, randomly sample a small portion of nodes in the graph to compute the average arborescence sizes with varying 1 / X  , and find a point where the change of arborescence size slows down, and use the  X  value at that point for the PMIA algorithm. The  X  values selected in our experiments are based on this method.
One possible future research is to further explore the advantages of our MIA heuristic. For example, we believe that MIA heuris-tic fits into the parallel computation framework better than the greedy algorithm and shortest-path based SP1M heuristic. This is because our computation are restricted on local arborescences around nodes, and thus the graph can be easily partitioned for parallel computation, with sharing data only needed for arbores-cences at the boundary. On the contrary, the greedy algorithm and the SP1M heuristic need simulations and computations among the whole graph, so graph partition is difficult, and parallel computa-tion is only possible for different computation tasks that require sharing of the entire graph. Another future direction is to look for hybrid approaches that combine the advantages of different algo-rithms to further improve the efficiency and effectiveness of influ-ence maximization.

Beyond influence maximization, one interesting direction that requires further research is the data mining of social influence from real online social network data sets. A few studies have started to address this issue for blogspace [9] and academic collaboration network [20]. In fact, we used a dataset from [20] with propaga-tion probabilities computed by their algorithm, but the graph size is small and thus we only include the result in [3]. We plan to study social influence mining in other social media and design appropri-ate algorithms for these social media. Social influence mining and influence maximization together will form the key components that enable prevalent viral marketing in online social networks. [1] W. Aiello, F. R. K. Chung, and L. Lu. A random graph model [2] S. Brin and L. Page. The anatomy of a large-scale [3] W. Chen, C. Wang, and Y. Wang. Scalable influence [4] W. Chen, Y. Wang, and S. Yang. Efficient influence [5] L. Cowen, A. Brady, and P. Schmid. DIGG: DynamIc Graph [6] P. Domingos and M. Richardson. Mining the network value [7] U. Feige. A threshold of ln n for approximating set cover. [8] L. Freeman. Centrality in social networks: conceptual [9] D. Gruhl, R. V. Guha, D. Liben-Nowell, and A. Tomkins. [10] D. Kempe, J. M. Kleinberg, and  X . Tardos. Maximizing the [11] M. Kimura and K. Saito. Tractable models for information [12] J. Leskovec. Amazon product co-purchasing network, march [13] J. Leskovec. Epinions social network. [14] J. Leskovec, A. Krause, C. Guestrin, C. Faloutsos, [15] I. R. Misner. The World X  X  best known marketing secret: [16] J. Nail. The consumer advertising backlash, May 2004. [17] G. Nemhauser, L. Wolsey, and M. Fisher. An analysis of the [18] M. Richardson and P. Domingos. Mining knowledge-sharing [19] M. Streeter and D. Golovin. An online algorithm for [20] J. Tang, J. Sun, C. Wang, and Z. Yang. Social influence [21] L. G. Valiant. The complexity of enumeration and reliability [22] V. V. Vazirani. Approximation Algorithms . Springer, 2004.
