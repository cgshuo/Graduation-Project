 The availability of language-specific annotated re-sources is crucial for the efficiency of natural lan-guage processing tasks. Still, many languages lack rich annotated resources that support various tasks such as part-of-speech tagging, dependency parsing and text classification. While the growth of multi-lingual information on the web has provided an op-portunity to build these missing annotated resources, but still lots of manual effort is required to achieve high quality resources for every language separately.
Another possibility is to utilize the unlabeled data present in those languages or transfer knowl-edge from annotation-rich languages. For the first alternative, recent advancements made in learning monolingual distributed representations of words (Mikolov et al., 2013a; Pennington et al., 2014; Levy and Goldberg, 2014) (i.e. monolin-gual word embeddings) capturing syntactic and se-mantic information in an unsupervised manner was useful in numerous NLP tasks (Collobert et al., 2011). However, this may not be sufficient for several other tasks such as cross-language informa-tion retrieval (Grefenstette, 2012), cross-language word semantic similarity (Vuli  X  c and Moens, 2014), cross-language text classification (CLTC, hence-forth) (Klementiev et al., 2012; Xiao and Guo, 2013; Prettenhofer and Stein, 2010; Tang and Wan, 2014) and machine translation (Zhao et al., 2015) due to irregularities across languages. In these kind of sce-narios, transfer of knowledge can be useful.
Several approaches (Hermann and Blunsom, 2014; Sarath Chandar et al., 2014; Gouws et al., 2015; Coulmance et al., 2015) tried to induce monolingual distributed representations into a lan-guage independent space (i.e. bilingual or multilin-gual word embeddings) by jointly training on pair of languages. Although the overall goal of these approaches is to capture linguistic regularities in words that share same semantic and syntactic space across languages, they differ in their implementa-tion. One set of methods either perform offline alignment of trained monolingual embeddings or jointly-train both monolingual and cross-lingual ob-jectives, while the other set uses only cross-lingual objective. Jointly-trained or offline alignment meth-ods can be further divided based on the type of par-allel corpus (e.g. word-aligned, sentence-aligned) they use for learning the cross-lingual objective. Ta-ble 1 summarizes different setups to learn bilingual or multilingual embeddings for the various tasks.
Methods in the Table 1 that use word-aligned parallel corpus as offline alignment (Mikolov et al., 2013b; Faruqui and Dyer, 2014) assume sin-gle correspondence between the words across lan-guages and ignore polysemy. While, the jointly-train methods (Klementiev et al., 2012) that use word-alignment parallel corpus and consider poly-semy perform computationally expensive operation of considering all possible interactions between the pairs of words in vocabulary of two different lan-guages. Methods (Hermann and Blunsom, 2014; Sarath Chandar et al., 2014) that overcame the complexity issues of word-aligned models by us-ing sentence-aligned parallel corpora limits them-selves to only cross-lingual objective, thus mak-ing these approaches unable to explore monolin-gual corpora. Jointly-trained models (Gouws et al., 2015; Coulmance et al., 2015) overcame the issues of both word-aligned and purely cross-lingual ob-jective models by using monolingual and sentence-aligned parallel corpora. Nonetheless, these ap-proaches still have certain drawbacks such as us-age of only bag-of-words from the parallel sen-tences ignoring order of words. Thus, they are missing to capture the non-compositional meaning of entire sentence. Also, learned bilingual em-beddings were heavily biased towards the sampled sentence-aligned parallel corpora. It is also some-times hard to acquire sentence-level parallel corpora for every language pair. To subdue this concern, few approaches (Rajendran et al., 2015) used pivot languages like English or comparable document-aligned corpora (Vuli  X  c and Moens, 2015) to learn bilingual embeddings specific to only one task.
This major downside can be observed in other aforementioned methods also, which are inflexible to handle different types of parallel corpora and have a tight-binding between cross-lingual objec-tives and the parallel corpora. For example, a method using sentence-level parallel corpora can-not be altered to leverage document-level parallel corpora (if available) that might have better per-formance for some tasks. Also, none of the ap-proaches do leverage widely available label/class-aligned non-parallel documents (e.g. sentiment la-bels, multi-class datasets) across languages which share special semantics such as sentiment or corre-lation between concepts as opposed to parallel texts.
In this paper, we introduce BRAVE a jointly-trained flexible model that learns bilingual embed-dings based on the availability of the type of cor-pora (e.g. sentence-aligned parallel or label/class-aligned non-parallel document) by just altering the cross-lingual objective. BRAVE leverages para-graph vector embeddings (Le and Mikolov, 2014) of the monolingual corpora to effectively conceal semantics of the text sequences across languages and build a cross-lingual objective. Method closely related to our approach is by Pham et al. (2015) who uses shared context sentence vector across lan-guages to learn multilingual text sequences.
The main contributions of this paper are:  X  We jointly train monolingual part of parallel  X  Introduced a novel approach to leverage non- X  Experimental evaluation on three different Most of the related work can be associated to the approaches that aim to learn latent topics across lan-guages or distributed representations of the words and larger pieces of text for supporting various cross-lingual tasks. 2.1 Cross-Language Latent Topics Various approaches have been proposed to identify latent topics in monolingual (Blei, 2012; Rus et al., 2013) and multilingual (Mimno et al., 2009; Fuku-masu et al., 2012) scenarios for cross-language se-mantic word similarity and document comparison. Extraction of cross-language latent topics or con-cepts use context-insensitive (Zhang et al., 2010) and context-sensitive methods (Vuli  X  c and Moens, 2014) to build word co-occurrence statistics for doc-ument representations. 2.2 Distributed Representations Continuous word representations (Bengio et al., 2003; Mikolov et al., 2013a; Pennington et al., 2014) was further extended to multilingual (Hermann and Blunsom, 2014; Ko  X  cisk  X  y et al., 2014; Coulmance et al., 2015), bilingual (Gouws et al., 2015; Vuli  X  c and Moens, 2015; Luong et al., 2015) and polylin-gual (Al-Rfou et al., 2013) settings by projecting multiple or pair of languages into the shared seman-tic space. Also, word representations were extended to meet larger textual units like phrases, sentences and documents either monolingual (Socher et al., 2012; Le and Mikolov, 2014) or bilingual (Pham et al., 2015). Some approaches fine tuned the embed-dings for specific tasks such as cross-lingual senti-ment analysis (Zhou et al., 2015b), cross-language POS tagging (Gouws and S X gaard, 2015), machine translation (Cho et al., 2014) etc. In this section, we present the BRAVE model along with its variations whose aim is to learn bilingual embeddings that can generalize across different lan-guages. 3.1 Bilingual Paragraph Vectors (BRAVE) Most of the NLP tasks require fixed-length vectors. Tasks like CLTC also require fixed-length vectors to incorporate inherent semantics of sentences or doc-uments. Distributed representation of sentences and documents i.e. paragraph vectors (Le and Mikolov, 2014) are designed to out-perform certain text clas-sification tasks by overcoming constraints posed by the bag-of-words models.

Here, we leverage paragraph vectors distributed memory model (PV-DM) as the monolingual objec-tive M (  X  ) and jointly optimize with bilingual reg-ularization function  X  (  X  ) for learning bilingual em-beddings similar to the earlier approaches (Gouws et al., 2015; Coulmance et al., 2015). Equation 1 shows the formulation of the overall objective func-tion that is minimized.

Here, C l represent the corpus of individual lan-guages (i.e. l 1 or l 2 ). Given any sequence of words 1 ,w l 2 ...w l T ) in C l , w t is the predicted word in a context h constrained on paragraph p (i.e. sentence or document) and sequence of words.

Formally, the first term (i.e. M (  X  ) ) in the Equa-tion 1 maximizes the average log probability based on word vector matrix W l and a unique paragraph vector matrix P l . Equation 2 represents the average log probability.
 where each y l i is log-probability of predicted word i and is given by Equation 3.
To optimize for efficiency, hierarchical soft-max (Mnih and Hinton, 2009) is used in training with U and b as parameters. Binary Huffmann tree is utilized to represent hierarchial softmax (Mikolov et al., 2013a). Analogous to Pham et al., (2015), we also derive h by concatenating paragraph vec-tor from P l with the average of word vectors in W l . This helps to fine tune both word and paragraph vec-tors independently.

Now, to capture the bilingual cues, the regulariza-tion function (  X  (  X  ) ) is learned in two different ways. In the first approach a sentence-aligned parallel cor-pora is used, while in the second approach a label-aligned document corpora. 3.2 BRAVE with Sentence-Aligned Parallel To compute the bilingual regularization func-tion  X  (  X  ) , we slightly deviate from earlier ap-proaches (Gouws et al., 2015). Instead of simply performing L 2 -loss between the mean of word vec-tors in each sentence pair ( s l 1 aligned parallel corpus (PC) at each training step. We use the concept of elastic net regularization (Zou and Hastie, 2005) and employ linear combination of L -loss between sentence paragraph vectors SP l 1 gual term M (  X  ) with L 2 -loss between the mean of word vectors observed in sentences. This induces a constraint on the usage of monolingual part of parallel training data to learn M (  X  ) . At the same time, it has an advantage of using combination of paragraph and word vectors which combines com-positional and non-compositional meanings of sen-tences.

Also, it eliminates the need for word-alignment and makes an assumption that each word observed in the sentence of language l 1 can potentially find its alignment in the sentence of language l 2 . Theoret-ically, low value of  X  (  X  ) ensures that words across languages which are similar are embedded closer to each other. Equation 4 shows the regularization term.
Where W l 1 obtained for the words w i and w k in each sentence ( s j ) of length m and n in languages l 1 and l 2 respec-tively. 3.3 BRAVE with Non-Parallel Document Sometimes it is hard to acquire sentence-aligned parallel corpora for many languages. Availability of non-parallel corpora such as topic-aligned (e.g. Wikipedia) or label/class-aligned document corpora (e.g. sentiment analysis and multi-class classifica-tion data sets) in different languages can be lever-aged to learn bilingual embeddings for perform-ing CLTC. Earlier approaches like CL-LSI (Du-mais et al., 1997) and CL-KCCA (Vinokourov et al., 2003) were used to learn bilingual document spaces for the tasks comparable to CLTC. Although these approaches provide decent results, they face serious scalability issues and are mostly limited to Wikipedia. Cross-lingual latent topic extraction models (Vuli  X  c and Moens, 2014) showed promising results for the tasks like word-level or phrase-level translations, but have certain drawbacks for CLTC tasks.

Here, we propose a two step approach to build bilingual embeddings with label/class-aligned doc-ument corpora.  X  In the first step, we perform manifold align- X  In the second step, we use the pair of partially Step-1: Let S l 1 and S l 2 be the sets containing languages l 1 and l 2 training documents associated to label or a class. Below, we provide the three step procedure to attain partial alignment between the documents present in these sets.  X  Learning low-dimensional embeddings of the  X  To find the optimal values of transformation,  X  If S l 2  X  represents the new document set obtained From perturbation theory of spectral spaces (Kostrykin et al., 2003) it can be under-stood that the difference between low-dimensional bounded, thus the new alignment obtained between document sets { S l 1 ,S l 2  X  } is insensitive to perturba-tions. Which also means that Procrustes analysis has provided best possible document alignments. Step-2: Now, document pairs ( d l 1 aligned corpus (PAC) is used to compute bilingual regularization function  X  (  X  ) . At each training step, L 2 -loss of precomputed document paragraph the monolingual term M (  X  ) is combined with the L 2 -loss between vector of words weighted by the probability of their occurrence in a particular label/class of entire PAC . Consideration of word probabilities will help to induce label/class specific information. Equation 6 provides the regularization term. Where w i , w k are words and their embeddings W m and n in languages l 1 and l 2 respectively. While, p words w i and w k in a specific label/class of entire PAC . Figure-1 shows overall goal of both the ap-proaches. In this section, we report results on three differ-ent CLTC tasks to comprehend whether our learned bilingual embeddings are semantically useful across languages. First, cross-language document classi-fication (CLDC) task proposed by Klementiev et al. (2012) using the subset of Reuters RCV1/RCV2 corpora (Lewis et al., 2004). Second, a multi-label of Hermann et al. (2014) . Subsequently, a cross-language sentiment classification (CLSC) proposed by Prettenhofer et al., (2010) on a multi-domain sen-timent dataset. 4.1 Parallel and Non-Parallel Corpora For sentence-aligned parallel corpora, Europarl-training data. While for label-aligned non-parallel document corpora, only training and testing collec-tions of the cross-language multi-domain Amazon product reviews(CL-APR) (Prettenhofer and Stein, 2010) corpus with sentiment labels is used. 4.2 Implementation Our implementation launches monolingual para-graph vector (Le and Mikolov, 2014) threads for each language along with bilingual regularization thread. Word and paragraph embeddings matrices are initialized with normal distribution (  X  = 0 and  X  2 = 0 . 1 ) for each language and all threads access them asynchronously. Following Pham et al. (2015) suggested combination (P=5*W) of paragraph and word embeddings, we chose paragraph embeddings with dimensionality of 200 and 640 when word em-beddings are of 40 and 128 dimensions respectively. Asynchronous stochastic gradient descent (ASGD) is used to update parameters (i.e. P l , W l , U and b ) and train the model.

For each training pair in parallel or non-parallel corpora, initially monolingual threads sample con-text h with window size of 8 from a random para-graph (i.e. sentence or document) in each lan-guage. Then the bilingual regularization thread along with monolingual threads make update to pa-rameters asynchronously. Learning rate is set to 0.001 which decrease with the increase of epochs, while  X  is chosen to be 0.6 (can be fine tuned based on empirical analysis) to give more weight to para-graph vectors. All models are trained for 50 epochs. 4.3 Document Representation Documents are represented with tf-idf weighted sum of embedding vectors of the words that are present in them. 4.4 Results The experimental results for each of the CLTC tasks are presented separately. 4.4.1 Cross-language Document Classification
Goal of this task is to classify target language doc-uments with the labeled examples from the source language. To achieve it, we used the subset of Reuters RCV1/RCV2 corpora as the training and evaluation sets and replicated the experimental set-ting of Klementiev et al. (2012). From the En-glish, German, French and Spanish collection of the dataset, only those documents are selected which was labeled with a single topic (i.e. CCAT, ECAT, GCAT and MCAT). For the classification experi-ments, 1000 labeled documents from source lan-guage are selected to train a multi-class classifier using averaged perceptron (Freund and Schapire, 1999; Collins, 2002) and 5000 documents were used as the testing data.
 English-German, English-French and English-Spanish portion of EP corpora (i.e. each with around 1.9M sentence-pairs) is used both as mono-lingual and parallel training data with BRAVE-S approach to build vocabulary of around 85k En-glish, 144k German, 119k French and 118k Spanish. While training and testing collections belonging to all domains in English-German, English-French lan-guages of CL-APR ((i.e. around 12,000 document-pairs)) was used both as monolingual and partially aligned data with BRAVE-D approach to build vo-cabulary of around 21k English, 22k German and 18k French. Further, documents in the training and testing data of RCV1/RCV2 corpora are represented as described in  X  4.3 with the vocabulary built. Ta-ble 2 shows the comparison of our approaches with the existing systems. 4.4.2 Multi-label CLDC -TED Corpus
To understand the applicability of our approaches perform experiments with the subset of TED cor-pus (Hermann and Blunsom, 2014). Aim of this task is same as  X  4.4.1, but experiments were con-ducted with larger variety of languages and class la-bels. TED Corpus contains English transcriptions and their sentence-aligned translations for 12 lan-guages from the TED conference. Entire corpus is further classified into 15 topics (i.e. class labels) based on the most frequent keywords appearing in them.

To conduct our experiments, we follow the single mode setting of Hermann et al. (2014) (i.e. embed-dings are learned only from a single language pair). Entire language pair (i.e. en  X  L2) training data of the TED corpus is used both as monolingual and parallel training data to learn bilingual word embed-dings with dimensionality of 128 using BRAVE-S approach. Bilingual word embeddings of 128 di-mensions learned with EP and CL-APR are also used for comparison. Documents in the training and testing data of TED corpus are represented as de-scribed in  X  4.3 using each of these embeddings. A multi-class classifier using averaged perceptron is built using training documents in source language to be applied on target language testing data for pre-dicting the class labels. Table 3 shows the cumula-tive F1-scores. 4.4.3 Cross-language Sentiment Classification
The objective of the third CLTC task is to iden-tify sentiment polarity (e.g. positive or negative) of the data in target language by exploiting the labeled data in source language. We chose sub-set of publicly available Amazon product reviews (CL-APR) (Prettenhofer and Stein, 2010) dataset mainly English(E), German(G) and French(F) lan-guages belonging to three different product cate-gories (books(B), dvds(D) and music(M)) to con-duct our experiments. For each language-category pair, corpus consists of training, testing sets com-prising 1000 positive and 1000 negative reviews each with an additional unlabeled reviews varying from 9,000 to 170,000.

We constructed 12 different CLSC tasks using dif-ferent languages (i.e. E,G and F) for three categories (i.e. B,D and M). For example, EFM refers English music reviews as source language and French mu-sic reviews as target language. Bilingual word em-beddings with dimensionality of 128 learned with BRAVE-S and BRAVE-D are used to represent each review as described in  X  4.3. To have fair compari-son with earlier approaches, sentiment classification to classify target language test reviews. Table 4 shows the accuracy and standard deviation results after we randomly chose subset of target language testing documents and repeated the experiment for 10 times for all CLSC tasks. First CLTC task (i.e. CLDC) results presented in Ta-ble 2 shows that BRAVE-S was able to outperform most of the existing systems. Success of BRAVE-S can be attributed to its ability to incorporate both non-compositional and compositional meaning ob-served in entire sentence and the individual words respectively. Thus making it different from other models which use only bag-of-words (Gouws et al., 2015) or bi-grams (Hermann and Blunsom, 2014).
Similarly, second CLTC task (i.e. multi-label CLDC) results presented in Table 3 shows that BRAVE-S learned with the training data of TED cor-pus outperformed single mode DOC/* embedding models (Hermann and Blunsom, 2014), BRAVE-S learned with EP and BRAVE-D. The BRAVE-S (TED) was able to capture better linguistic regu-larities across languages that is more specific to the corpus, than the general purpose bilingual embed-dings learned with EP . Though in some cases, all our embedding models could not outperform ma-chine translation baseline. This can be due to the asymmetry between languages induced by the lan-guage specific words which could not find its equiv-alents in English.
 Also, it can be apprehended from the Table 2 and Table 3 that BRAVE-D results are not as expected. Though being a general approach like BRAVE-S which can capture both non-compositional and com-positional meaning from larger pieces of texts, min-imal overlap of vocabulary learned with BRAVE-D using cross-language sentiment label-aligned cor-pora with other domains (i.e. Reuters and TED) pro-duce unfavorable results. Thus, we understand that the choice of label/class-aligned corpora is crucial.
Final CLTC task (i.e. CLSC) results presented in Table 4 shows that BRAVE-D outperforms other baseline approaches in most of the cases. As BRAVE-D learns bilingual word embeddings us-ing CL-APR , it was able to inherently encom-pass sentiment label information effectively like ear-lier approaches (Tang and Wan, 2014; Zhou et al., 2015b) than the general purpose embeddings learned using BRAVE-S with EP and similar ap-proaches (Meng et al., 2012). Thus making it more suitable for sentiment classification task. Also unlike CL-SSMC (Xiao and Guo, 2002) and CL-SLF (Zhou et al., 2015a), BRAVE-D is not highly parameter dependent where the results of the for-mer approaches show big variance based on the pa-rameter settings. To visualize the difference in em-beddings learned with BRAVE-S and BRAVE-D, we selected sentiment words and identified cross-language nearest neighbors in Table 5. It can be observed that BRAVE-D was able to identify better sentiment (either positive or negative) word neigh-bors than BRAVE-S. In this paper, we presented an approach that lever-ages paragraph vectors to learn bilingual word em-beddings with sentence-aligned parallel and label-aligned non-parallel corpora. Empirical analysis ex-hibited that embeddings learned from both of these types of corpora have shown good impact on CLTC tasks. In future, we aim to extend the approach to learn multilingual semantic spaces with more la-bels/classes.
 The research leading to these results has received funding from the European Union Seventh Frame-work Programme (FP7/2007-2013) under grant agreement no. 611346.
