
Nokia Research Center 3 Rutgers University
Recent years have witnessed a revolution in mobile de-vices, which is driven by the ever-increasing needs of mobile services. As mobile services keep evolving, there are clear signs that context modeling of mobile users will have huge demand. A distinct property of mobile users is that they are usually exposed in volatile contexts, such as waiting a bus, walking in a building, driving a car, or doing shopping. Thus, building context-aware services by leveraging the rich contextual information of mobile users has attracted the great attention of many researchers [2], [11], [17].

Mobile context modeling is a process of recognizing and reasoning about contexts and situations in a mobile envi-ronment, which is a fundamental research problem towards leveraging the rich contextual information of mobile users. There are prior work on mobile context modeling such as [1], [17]. However, most of these previous studies have a need to predefine the typical contexts of users and predeter-mine the corresponding rules for detecting them. While these approaches can work well in predefined simple application scenarios, such as guiding tourists for sightseeing [19], it is not flexible to extend these approaches for more general and complex scenarios where it is difficult to manually build context models. In addition, there are some other studies for mobile context modeling through supervised learning methods [12], [20]. In this case, there is also a need to predefine contexts.

It is more attractive to exploit unsupervised techniques for mobile context modeling for the case that domain knowledge is not available, such as learning the personalized contexts which are difficult to be predefined. Indeed, unsupervised learning techniques can automatically learn some semanti-cally meaningful contexts from the low level context data. In contrast, to model personalized contexts, both manual approach and supervised learning approach require users to predefine their own personalized contexts and thus will bring additional cost and complexity to the problem.

Therefore, in this paper, we propose an unsupervised approach to modeling personalized contexts of mobile users. Specifically, we first segment the raw context data sequence of mobile users into context sessions where a context session contains a group of adjacent context records which are mutually similar and may reflect the similar contexts. We use an adaptive segmentation approach named the minimum entropy segmentation [8] to address the challenges of context segmentation on determining the number of segments and the segmentation threshold. Secondly, we take advantage of topic models to learn personalized contexts in the form of probabilistic distributions of raw context data from the context sessions. Due to the structural constraint of context sessions, the state-of-the-art topic models can not directly apply to mobile context modeling. Therefore, we exploit to extend existing topic models for fitting mobile context modeling. We first extend a single-topic-based topic model named Mixture Unigram (MU) [14] to a mobile context model which assumes that each context session reflects one latent context. However, we observe that some context sessions may reflect multiple contexts because the context segmentation stage may not exactly detect all boundaries of context transitions. Based this observation, we also extend a multiple-topic-based topic model named Latent Dirichlet Allocation (LDA) [4] for mobile context modeling. Finally, we conduct extensive experiments on the real-world mobile usage data. Experimental results show that the LDA based model is more effective than that extended from MUC for mobile context modeling but less efficient than the latter in terms of the computational cost.
 Overview. The rest of this paper is organized as follows. First, we briefly review some related works in Section II. The basic idea of unsupervised mobile context modeling is introduced in Section III. Then, the details of context segmentation are presented in Section IV and the details of modeling personalized contexts of mobile users through topic models are presented and discussed in Section V, respectively. In Section VI, we report the experimental results on the real life history context data of users. Finally, we conclude this paper and pinpoint some future research directions in Section VII.

In general, the related work can be grouped into three categories. In the first category, contexts are modeled man-ually based on domain knowledge. For example, Schilit et al. [17] used key-value pairs to model the context by providing the value of a context information (e.g. location information) to an application as an environment variable. Adowd et al. [1] presented the Cyberguide project, in which prototypes of a mobile context-aware tour guide were built. Otzturk and Aamodt [15] proposed modeling the context with ontologies and analyzed psychological studies on the difference between recall and recognition of several issues in combination with contextual information. Indeed, none of the above studies adopted machine learning approach for learning contexts from the raw context data automatically. As a result, they may work well in simple environments, such as guiding tourists in tourist attractions, but are not flexible for applying to more complex environments where it is difficult to build context models manually, e.g., recog-nizing users X  contexts in their daily life.

The second category includes the research work of mobile context modeling though supervised learning approaches. For example, Liao et al. [12] attempted to infer an individ-ual X  X  transportation routine given the user raw GPS data. By leveraging a dynamic Bayesian network, the system learns and infers the person X  X  transportation routines between the significant places. Zheng et al. [20] exploited to use several supervised learning approaches for modeling user X  X  raw GPS data. In their work, four different inference models including decision tree, Bayesian network, support vector machine (SVM) and conditional random field (CRF) are studied for modeling user X  X  transportation mode. Supervised learning approach provides more flexibility than the manual approach for mobile context modeling because it depends on less domain knowledge and can learn from the raw context data automatically. However, it still needs to manually predefine the contexts. Moreover, it needs a number of labeled training data for model training. By contrast, the unsupervised learn-ing approach for mobile context modeling is very flexible because it can learn contexts from an individual user X  X  raw context data without predefined contexts nor labeled training data. Thus, it can greatly improve the user experience due to less dependency on the user.

The third category of related work focuses on user mod-eling through unsupervised approaches. In a latest literature, Eagle et al. [5] proposed to use the eigenvector of user behavior for modeling individual users and infer community affiliations within the subjects X  social network. Though they also used an unsupervised approach to discover the user context and behavior pattern from the user history data, the objective of their research is intrinsically different from our work. Our goal is to discover the personalized mobile contexts which can be applied to context-aware services.
In addition, the proposed approach in this paper exploits topic models, which are widely used generative probability models in document modeling. Typical topic models include the Mixture Unigram (MU) model [14], the probabilistic latent semantic analysis (pLSA) model [10], and the latent Dirichlet allocation (LDA) model [4]. Most of other topic models are extended from them and applied to specific applications. In our approach, we extend MU to MUC and extend LDA to LDAC for satisfying the constraint of context data.

The context collection software on mobile devices can collect rich context data of mobile users through their personal context logs. A context log consists of a number of context records with timestamps, and a context record is formed as a group of raw context data, i.e., contextual feature-value pairs , where a contextual feature denotes a type of context data, such as Day name , Speed , and Cell ID , etc. The contextual value in a contextual feature-value pair indicates the value of the corresponding contextual feature at a particular time point. The context collection software can predefine a set of contextual features whose values should be collected, but a context record may miss the values of some contextual features because these values are not always available. For example, when a user is in door, the mobile device can not receive the GPS signal. In context logs, only the contextual feature-value pairs whose contextual values are not missing are recorded.

From the contextual feature-value pairs in context logs we may be able to discover some meaningful contexts of mobile users. For example, suppose Table I shows a part of the context log of Ada, we can see that in a workday and during time at AM8:00-AM9:00 , Ada X  X  moving speed was high and the background was noisy observed by audio level, which might imply the context is that she was driving a car to her work place . Moreover, in a holiday during time at AM10:00-11:00, Ada was moving in door and the background is noisy. In addition, considering that the cell ID represents a shopping mall, the context might be that Ada was go shopping .

If several adjacent context records in a context log are mutually similar, we say that they make up a context session . The context records in the same context session may capture the similar context information of the mobile user. If two contextual feature-value pairs usually co-occur in same context sessions, they may represent the same context. An unsupervised approach can automatically discover the highly related contextual feature-value pairs which reflect the same context by taking advantage of their co-occurrences. Once a group of highly related contextual feature-value pairs are found, users can assign them meaningful context tags for binding them with multiple context-aware applications, such as context-aware reminder, context-aware recommendations. For example, if an unsupervised approach can discover that the contextual feature-value pairs ( Is a holiday?: Yes ), ( Time range: AM10:00-11:00 ), ( Movement: Moving ), and ( Cell ID: 2552 ) are highly related, Ada will be encouraged to tag this group of contextual feature-value pairs with an explicit context label  X  X o shopping X  and define the services she wants on that context, such as playing a favorite music or recommending the information of fashion dress. This kind of semi-automatic context-aware configuration is more convenient than a manual alternative that lets Ada define the contextual feature-value pairs of  X  X o shopping X  by her-self. Along this line, we propose a two-stage unsupervised approach for learning the personalized contexts of mobile users. In the first stage, we takes advantage of an adaptive segmentation approach to segment the context log into context sessions. In the second stage, we use the extended topic models to learn personalized contexts from the context sessions. The details of the approach are presented in the following sections.

Given a context log  X  =  X  1  X  2 ... X   X  , where  X   X  (1  X   X   X   X  ) denotes a context record, extracting context sessions from  X  is a procedure of segmenting  X  into  X  segments  X  = {  X  1 , X  2 , ...,  X   X  } , where  X   X  (1  X   X   X   X  ) denotes a context session which consists of a group of adjacent and similar context records, and  X  is called a  X  -segmentation of  X  .
There are two challenges for segmenting the context log into context sessions. First, it is hard to estimate the number of context sessions in a context log, i.e., the parameter It is because mobile users may have different frequencies of context transitions due to their life styles, which implies the numbers of context sessions in their personal context logs may also vary significantly. Therefore, the partition based segmentation approach (e.g., [9], [18]) can not apply to context segmentation. Second, it is also difficult to define a unified similarity threshold to determine where the orig-inal context log should be segmented for each individual user X  X  context log. Thus, the similarity threshold based segmentation approach (e.g., [6], [13]) can not apply too. To address the context segmentation problem, we need an adaptive approach which can automatically segment context logs according to their intrinsic statistic properties without external guidance.

Hermes et al. [8] proposed a minimum entropy approach which can segment pixels of an image adaptively without any domain knowledge related parameter. The basic idea of the approach is to transform the objective of finding the optimized segmentation to finding the minimum con-ditional entropy of the pixels given the segmentation. This approach can be easily extended to segment context logs because context segmentation can be also transformed to the problem of seeking the minimum entropy. To be specific, if we measure the similarity between two adjacent context records through the probability that they are assigned into the same context session by a random segmentation, the objective of seeking the optimized segmentation becomes seeking the segmentation  X   X  =argmax  X   X  (  X   X   X  ) , where  X  (  X   X   X  ) denotes the likelihood of all context records given the segmentation  X  . Seeking the maximum  X  (  X   X   X  ) is equal to seeking the maximum  X  X  X  X  X  X  (  X   X   X  ) . If we assume that 1) for each context record  X  , the probability to be assigned into a given context session  X  is independent, and 2) for each context feature-value pair  X  of a given context record  X  ,the probability to be assigned into a given context session  X  independent,  X  X  X  X  X  X  (  X   X   X  ) can be expressed as follows. where  X  denotes a context session in  X  ,  X   X  denotes a context record in  X  ,  X   X   X  denotes a contextual feature-value pair in  X  denotes a unique contextual feature-value pair, and  X   X , X  indicates the occurrence number of the feature-value pair  X  in context session  X  .Ifweuse  X   X , X   X  where  X   X  denotes the number of all feature-value pairs in  X  , Equation 1 can be transformed as follows. (1)=  X   X  where  X  (  X   X   X  ) denotes the conditional entropy of all contextual feature-value pairs given all context sessions. Therefore, the original problem is transformed to  X   X  = argmin  X   X  (  X   X   X  ) .

Hermes et al. [8] have demonstrated that this problem can be addressed by taking advantage of the greedy opti-mization. To be specific, to search a  X  -segmentation with the minimum entropy, we first find a  X  +1 -segmentation with the minimum entropy. Then we try to merge each pair of adjacent context sessions and in this way find a  X  -segmentation  X   X  with the minimum entropy, and  X   X  is the exact solution of  X   X  . Moreover,  X  (  X   X   X  ) has a certain solution when  X  is equal to  X  . It is because in this case there exists only one segmentation that each context record makes up one context session. Therefore, we can easily find the optimized  X  -segmentation (  X   X  [1 , X  ]) .

It is easy to prove that the global minimum entropy appears when  X  =  X  and the local minimum entropy given  X  increases with the decrease of  X  . However, only taking into account the minimum entropy usually causes over-fitting because such a segmentation is usually too complex. Therefore, we also take into account the growth rate of the local minimum entropy to balance the complexity of the segmentation and the corresponding local minimum entropy. To be specific, we start from  X  =  X  and then iteratively set  X  =  X   X  1 and calculate the corresponding local minimum entropy. If the growth rate of the local minimum entropy is larger than  X  , we terminate seeking next local minimum entropy. In practice, we set  X  to be 10%. Figure 1 illustrates the procedure of seeking the global optimized segmentation by balancing the complexity of the segmentation and the minimum entropy. The worst complexity of the adaptive segmentation approach is  X  (  X  X  X  X  X  X  X  ) .

Topic models are generative models that are successfully used for document modeling. They assume that there exist several topics for a corpus  X  and a document  X  in  X  can be taken as a bag of words {  X   X , X  } which are generated by these topics. Intuitively, if we take contextual feature-value pairs as words, take context sessions as bags of contextual feature-value pairs to correspond documents, and take latent contexts as topics, we can take advantage of topic models to learn contexts from context sessions. However, we can not directly apply topic models to mobile context modeling because the occurrences of the contextual features and the corresponding values in contextual feature-value pairs are dependent on different factors. As mentioned above, in a context session, the occurrences of contextual features are dependent on some external conditions, such as the availability of the corresponding signal. In contrast, the occurrences of contextual values are dependent on the latent contexts and the corresponding contextual features. If we simply take contextual feature-value pairs as words in topic models, we will not be able to discriminate the generation of contextual features and that of contextual values. To this end, we extend the existing topic models for fitting mobile context modeling.
 A. Single-Context-based Context Model
If we assume that one context session reflects one latent context, we can extend a typical singe-context-based topic model named the Mixture Unigram (MU) model [14] for mobile context modeling. MU assumes that a document  X  is generated as follows. Given  X  topics and  X  words, to generate the word  X   X , X  in  X  , the model firstly generates a topic  X   X  from a prior topic distribution for the corpus  X  Then the model generates  X   X , X  given the prior word distri-bution for  X   X  . In a corpus, both the prior topic distribution and the prior word distributions for different topics follow the Dirichlet distribution.

We extend the MU model to the Mixture Unigram Context (MUC) model which assumes that a context session is generated by a prior contextual feature distribution and a prior context distribution together. To be specific, given contexts and  X  contextual features, the MUC model assumes that a context session  X  is generated as follows. Firstly, a global prior context distribution  X  is generated from a prior Dirichlet distribution  X  . Secondly, a prior contextual feature distribution  X   X  is generated from a prior Dirichlet distribution  X  . Then, a context  X   X  is generated from  X  . Finally, a contextual feature  X   X , X  is generated from  X   X  the value of  X   X , X  denoted as  X   X , X  is generated from the distribution  X   X   X  , X   X , X  . Moreover, there are totally  X   X   X  conditional distributions of contextual feature-value pairs {  X   X , X  } which follow a Dirichlet distribution  X  . Figure 2 shows the graphical representation of the MUC model. Notice that  X  ,  X  and  X  are represented by parameter vectors  X   X   X  = {  X   X  } ,  X   X   X  = {  X   X  } , and  X   X   X  = {  X   X  } respectively according to the definition of Dirichlet distribution, where  X  indicates a context,  X  indicates a contextual value, and  X  indicates a contextual feature.
In the MUC model, given the parameters  X  ,  X  and  X  ,the joint probability of a context session  X  = { (  X   X , X  :  X   X , X  prior context distribution  X  , a latent context  X   X  , a contextual feature distribution  X   X  , and a set of  X   X   X  conditional contextual value distributions  X = {  X   X , X  } is calculated as follows. where  X  (  X   X , X   X   X   X  , X   X , X  ,  X )=  X  (  X   X , X   X   X   X  , X   X , X  indicates the number of contextual feature-value pairs in
The likelihood of a set of context sessions  X  is calculated as follows.  X  (  X  )=
The representation of the likelihood of MUC is in a too complex form and it may not be feasible to calculate the pa-rameters of the model directly. Alternatively, we use a com-monly used iterative approach for approximately estimating the parameters of MU called Gibbs sampling [7], [16]. In the Gibbs sampling approach, each observed variable is iteratively assigned a label by taking into account the labels of other observed variables. For our problem, the Dirichlet parameter vectors first. Then the Gibbs sampling approach iteratively assigns context labels to each context session according to the labels of other context sessions.

The Gibbs sampler of the context label for a context session  X  , denoted as  X   X  , is defined as follows.  X  (  X   X  =  X   X   X   X   X  , X  )  X   X  (  X   X  =  X , X   X   X  , X  ) where  X   X  means removing  X  from  X  ,  X   X   X  denotes the context labels of other context sessions expect for  X  ,  X   X  denote all contextual values and all contextual features in  X  , respectively, and  X   X  denotes all contextual values in  X 
Moreover, indicating the token (  X ,  X  ) as  X  ,wehavethe following formulas. where  X   X   X , X , X , X  indicates the frequency that the contextual feature-value pair (  X  :  X  ) is labeled with the  X  -th context in all context sessions expect for  X  ,  X   X  denotes the set of contextual values for the contextual feature  X  , and  X   X   X , X  indicates the number of context sessions with the  X  -th context expect for  X  .

After several rounds of Gibbs sampling, eventually each context session will be assigned a final context label. We can derive the personalized contexts of mobile users from the labeled context sessions by estimating the probability distribution of contextual feature-value pairs generated by a particular context. To be specific, the probability that a contextual feature-value pair  X   X  =(  X   X  :  X   X  ) is generated by the context  X   X  is estimated as where B. Multiple-Context-based Context Model
In practice, the stage of context segmentation may not detect the exact boundaries of context sessions. Therefore, it is more general to assume that one context session may reflect multiple latent contexts. To this end, we also propose a multiple-context-based context model which is extended from a multiple-topic-based topic model named the Latent Dirichlet Allocation (LDA) model [4]. Compared with MU, LDA assumes each document is generated by a prior distribution of topics instead of a single topic. To be specific, LDA assumes that a document  X  is generated as follows. Given  X  topics and  X  words, to generate the word  X   X , X  in  X  , the model firstly generates a topic  X   X , X  from a prior topic distribution for  X  . Then the model generates given the prior word distribution for  X   X , X  . Moreover, similar to MU, LDA assumes that both the prior topic distributions for different documents and the prior word distributions for different topics follow the Dirichlet distribution. We extend LDA to the Latent Dirichlet Allocation on Context model (LDAC) for mobile context modeling. In the LDAC model, a context session  X  is generated as follows. Firstly, a prior context distribution  X   X  is generated from a prior Dirichlet distribution  X  . Secondly, a prior contextual feature distribution  X   X  is generated from a prior Dirichlet distribution  X  . Then, for the  X  -th contextual feature-value pair in  X  , a context  X   X , X  is generated from  X   X  , a contextual feature  X   X , X  is generated from  X   X  , and the value of  X   X , X  denoted as  X   X , X  is generated from the distribution  X   X   X , X  , X   X , X  . Moreover, there are totally  X   X   X  prior distributions of contextual feature-value pairs {  X   X , X  } which follow a Dirichlet distri-bution  X  . Figure 3 shows the graphical representation of the LDAC model.
In the LDAC model, given the parameters  X  ,  X  and  X  ,the joint probability of a context session  X  = { (  X   X , X  :  X   X , X  prior context distribution  X   X  , a group of latent context labels  X  = {  X   X , X  } , a contextual feature distribution  X   X  , and a set of  X   X   X  conditional contextual value distributions  X = {  X   X , X  is calculated as follows.  X  (
Similar to the parameter estimation in MUC, we also use the Gibbs sampling approach to estimating the parameters for LDAC. Denoting the token (  X ,  X  ) as  X  , the Gibbs sampler of  X   X  is as follows.  X  (  X   X  =  X   X   X   X   X  , X  )  X   X  (  X   X  =  X , X   X   X  , X  ) where  X   X  means removing the contextual feature-value pair (  X   X  :  X   X  ) from  X  , and where  X   X   X , X , X , X  indicates the frequency that the contextual feature-value pair (  X  :  X  ) is labeled with the  X  -th context in all context sessions after removing the  X  -th contextual feature-value pair, and  X   X ,  X   X , X  indicates the number of contextual feature-value pairs labeled with the  X  -th context in  X  expect for the  X  -th one.

Similar to MUC, in the LDAC model, the personalized contexts of mobile users can be also derived from the labeled contextual feature-value pairs according to Equation 2. From the experimental results on real data we find that LDAC outperforms MUC with respect to the effectiveness of mobile context modeling. However, the effectiveness of MUC is also acceptable and it largely outperforms LDAC in terms of efficiency. Generally, MUC is a good candidate approach to mobile context modeling when the computation resource is limited. Otherwise, we can use LDAC for pursuing the best performance. The detailed comparisons between the practi-cal performance between MUC and LDAC are presented in Section VI.
 C. Determining The Number of Contexts
Both of MUC and LDAC need a predefined parameter  X  to indicate the number of contexts to be learnt. Thus, to select an appropriate  X  , we can assume that the number of personalized contexts for any mobile user falls into a range [  X   X  X  X  X  , X   X  X  X  X  ] , where  X   X  X  X  X  and  X   X  X  X  X  indicate the minimum number and the maximum number of possible contexts, respectively. The values of  X   X  X  X  X  and  X   X  X  X  X  can be empirically determined through the user study which selects users with different backgrounds first and then asks them how many typical contexts exist in their daily life. Thus, we can select the best  X  from [  X   X  X  X  X  , X   X  X  X  X  ] by measuring the performance of the learnt context models. To be specific, we first partition a context session set  X  into a training set and a test set  X   X  . Then we learn a context model from  X  with a given  X  and obtain  X  contexts  X  1 ,  X  2 , ...,  X   X  we calculate the perplexity [3] of the  X   X  by the following equation.  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  (  X   X  )=  X  X  X  X  where  X  (  X   X   X   X  ) means the probability that a context session  X  appears given  X   X  and is calculated as follows.  X  (  X   X   X   X  )= where  X  (  X   X   X   X   X  , X   X  )=  X  (  X   X   X   X   X  ) can be calculated by Equation 2, and  X  (  X   X   X   X   X  ) is calculated differently in MUC and LDAC. In the MUC model,  X  (  X   X   X   X   X  )=  X   X  +  X   X   X  + where  X   X  indicates the number of context sessions la-beled with  X   X  in  X   X  . In the LDAC model,  X  (  X   X   X   X   X  )=  X  textual feature-value pairs labeled with  X   X  in  X  .
Generally, the smaller the perplexity of  X   X  is, the better the learnt contexts will be. However, it is worth noting that the perplexity of test sets usually drops with the increase of  X  . If we only take into account the perplexity, we probably select the maximum  X  of a given range, which may make the learnt model over-fitting. Thus, we balance the above approach by a simple way, that is, if the decline rate of the perplexity is less than  X  , we do not select a larger  X  .In practice, we set  X  to be 10%.

In this section, we evaluate the efficiency and the ef-fectiveness of the proposed approach for mobile context modeling through extensive experiments on real context data sets.
 A. Data Sets and Preprocess The first data set used in the experiments is the Reality Mining data set [5]. Reality Mining data set is a public data set which captures the raw context data from 100 college volunteers at MIT over the course of the 2004-2005 academic year. The raw context data contains the communication, proximity, location, and activity information and can be used for learning personalized contexts of the users. We randomly select 10 volunteers X  context data from the Reality Mining data set to evaluate the performance of the proposed approach of mobile context modeling. Table II lists the details of the Reality Mining data sets used in our experiments, where the Owner ID identifies the owner of the context data,  X  denotes the number of context records,  X  denotes the number of extracted context sessions,  X  denotes the number of unique contextual feature-value pairs,  X   X  denotes the occurrence number of all contextual feature-value pairs.

The evaluation of unsupervised approaches is challenging because of the lack of ground truth. Though some metrics such as perplexity can be applied to evaluating the proposed approach, it is more desirable to ask users to manually evaluate the personalized contexts learnt from their raw context data. However, it is difficult to contact the owners of the reality mining data sets and ask them to conduct manual evaluations. To this end, we collect 10 college volunteers X  context data spanning for one month through their mobile devices by ourselves. The collected context data set includes rich types of contextual features listed in Table III and the owners of these context data are invited to participate the human evaluation of the proposed approach to mobile context modeling. For simplicity, we denote the collected context data set as Rich Context .

We first partition each experimental data set into the training set and the test set as follows. For each Reality Mining data set, we use the last month data as the test set and use the remaining data as the training set. For each Rich Context data set, we use the last week data as the test set and use the remaining data as the training set. Then, we use the proposed approach to learn mobile contexts from each training set and then evaluate the learnt contexts on the corresponding test set.
 B. Efficiency of the Proposed Approaches
For the sake of privacy concern, one simple alternative solution is to model the personalized contexts of mobile users in their mobile devices instead of in a back end server. Thus, the efficiency of mobile context modeling is crucial for in-device applications due to the resource constraint of mobile device. In the experiments we observe that the computation cost of extracting context sessions is trivial compared with that of learning contexts by topic models (averagely less than 20 seconds). Thus, we evaluate the efficiency of the proposed approach by comparing the ef-ficiencies of MUC and LDAC for mobile context modeling. Since both approaches adopt iterative learning methods, we evaluate their efficiencies by taking into account their convergence speeds. The experiments are conducted on a Core2 1.86GZ, 2G memory PC.

The convergence of Gibbs sampling is measured by the log likelihood of the training set. The super parameters  X  ,  X  , and  X  of MUCs and LDACs are empirically set to 50/K, 0.01, and 0.01 according to [7]. Figure 4 compares the request iterations to converge for MUC and LDAC on the Reality Mining data set and the Rich Context data set, respectively. Each label around the circle indicates the owner ID of a data set. For each data set, the most appropriate is selected by the method mentioned in Section V. From this figure we can see that the Gibbs sampling process of LDAC usually converges after hundreds of iterations while that of MUC usually converges after less than 30 iterations. Figure 5 further compares the time cost to converge for MUC and LDAC. From this figure we can see that the Gibbs sampling process of MUC usually converges tens of times faster than that of LDAC. In a summary, though both the proposed approaches can converge within limited iterations, MUC is much more efficient than LDAC for learning personalized mobile contexts. It is because the Gibbs sampling for LDAC is more complex than that of MUC. To train a LDAC model, we need to build a Gibbs sampler for each contextual feature-value pair. In contrast, the training of MUC only needs to build Gibbs samplers for context sessions, which are much fewer than contextual feature-value pairs in practice. Consequently, the Gibbs sampling of MUC largely outperforms that of LDAC in terms of both the time cost of one iteration and the iterations to converge. C. Effectiveness of the Proposed Approaches
In this section, we report the experimental results of the proposed approach with respect to the effectiveness for mobile context modeling. 1) Perplexity: Figure 6 compares the perplexity of each test set with the contexts learnt by MUC and LDAC. Each label around the circle indicates the owner ID of a test set. From this figure we can see that LDAC always outperforms MUC in terms of perplexity, which concludes that LDAC is more effective for mobile context modeling than MUC. 2) Human Evaluation: To find out the quality of the learnt contexts more intuitively, we ask the owners of the Rich Context data sets to evaluate the personalized contexts learnt from their own context data. For each learnt con-text, we select the contextual feature-value pairs  X  where  X  (  X   X   X   X  ) &gt; 0 . 01 to represent the context  X   X  .
For each learnt context to be evaluated, the corresponding testee selects one from the following three remarks:
To ensure the evaluation quality, we do not inform testees that a given learnt context is learnt by which context model. Moreover, we generate a copy for each learnt context and randomly mix them with the original learnt contexts. If a learnt context pattern is assigned different remarks from that of its copy, we will revisit it again. Figure 7 compares the human evaluation results of the contexts learnt by MUC and LDAC for each data set of Rich Context. From the figure we can see that LDAC outperforms MUC for mobile context modeling in terms of perfect cases. But considering all pos-itive cases (P+G), their performance are comparable. Gen-erally speaking, we can conclude that LDAC outperforms MUC in terms of effectiveness for mobile context modeling, which is consistent with the experimental conclusion in the view of perplexity. 3) A Case study: We also manually analyze some mined contexts for intuitively understanding how LDAC X  X  learning result outperforms that of MUC. Limited by space, we just show one typical example as follows. First, we contact one volunteer and know he has a typical personalized context that he usually plays basketball in weekends X  afternoon (PM14:00-17:00) . Then we manually check the learnt con-texts of MUC and LDAC, and find that both of them discover a group of contextual feature-value pairs corresponding to that context. For simplicity, we denote the context learnt by MUC as  X   X  and denote the context learnt by LDAC as  X   X  .
Table V shows  X   X  which is in the form of a group of contextual feature-value pairs. The location ID has been translated to meaningful locations to ease understanding. The most of the contextual feature-value pairs of  X   X  are reasonable, such as ( Day name: Saturday ), ( Day period: Afternoon ), ( Location: Basketball area ). But it also contains two noisy contextual feature-value pairs, namely, ( Time range: PM13:00-14:00 ) and ( Time range: PM17:00-18:00 ), and misses some more relevant contextual feature-value pairs such as ( Time range: PM14:00-15:00 ) and ( Time range: PM15:00-16:00 ). Thus, it is labeled with  X  X ood X . Table VI lists all contextual feature-value pairs in  X   X  .From this table we can see that all listed contextual feature-value pairs are sensible to represent the user context. As expected,  X  is labeled with  X  X erfect X .

In this paper, we proposed an unsupervised approach to mobile context modeling which is a fundamental research problem towards leveraging the rich contextual information of mobile users to support personalized customer experi-ences. Specifically, we first extracted context sessions from the raw context data of mobile users and then extended topic models to learn personal mobile contexts from the context sessions. Two topic models have been extended and exploited for mobile context modeling, namely, MU and LDA. Experiments results on real-world context data show that the LDA based context model outperforms the MU based context model in terms of the effectiveness for mobile context modeling. However, the latter has a better computational performance.

As for future work, it is desirable if we can incorporate some domain knowledge of common contexts, such as  X  X aiting a bus X  or  X  X aving a dinner X , with unsupervised approaches for mobile context modeling. Such a semi-supervised approach may improve the learning performances of common contexts while keeping the flexibility of super-vised approaches for learning personalized contexts.
This work is supported by grants from the National Nat-ural Science Foundation of China (grant No.60775037), the State Key Program of National Natural Science Foundation of China (grant No.60933013), the National High Tech-nology Research and Development Program of China (863 Program) (grant No.2009AA01Z123) and Nokia Research Center China. The authors would like to thank Nokia for giving permission to use their data collection platform.
