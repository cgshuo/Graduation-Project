 Implicit information about temporal durations is crucial to any natural language processing task in -volving temporal understanding and reasoning. This information comes in many forms, among them knowledge about typical durations for events and knowledge about typical times at which an event occurs. W e know that lunch lasts for half an hour to an hour and takes place around noon, a game of chess lasts from a few minutes to a few hours and can occur any time, and so when we in -terpret a text such as  X  X fter they ate lunch, they played a game of chess and then went to the zoo X  we can infer that the zoo visit probably took place in the early afternoon. In this paper we focus on duration. Hand-annotation of event durations is ex -pensive slow (Pan et al., 2011), so it is desirable to automatically determine typical durations. This pa -per describes a method for automatically extracting information about typical durations for events from tweets posted to the Twitter microblogging site.
Twitter is a rich resource for information about everyday events  X  people post their tweets to Twit -ter publicly in real-time as they conduct their activ -ities throughout the day, resulting in a significant amount of mundane information about common events. For example, (1) and (2) were used to pro -vide information about how long a work event can last: In this paper, we sought to use this kind informa -tion to determine likely durations for events and habits of a variety of verbs. This involved two steps: extracting a wide range of tweets such as (1) and (2) and classifying these as to whether they re -ferred to specific event (as in (1)) or a general habit (as in (2)), then summarizing the duration informa -tion associated with each kind of use of a given verb.

T his paper answers two investigative questions: The results presented here show that Twitter can be mined for fine-grain event duration information with high precision using regular expressions. Ad -ditionally, verb uses can be effectively categorized as to their habituality, and duration information plays an important role in this categorization. Past research on typical durations has made use of standard corpora with texts from literature ex -cerpts, news stories, and full-length weblogs (Pan et al, 2006; 2007; 2011; Kozareva &amp; Hovy, 2011; Gusev et al., 201 1 ). For example, Pan et al. ( 2011) hand -annotat ed of a portion of the TIMEBANK corpus that consisted of Wall Street Journal arti -cles. For 58 non-financial articles, they annotated over 2,200 events with typical temporal duration, specifying the upper and lower bounds for the du -ration of each event . In addition they used their corpus to automatically determine event durations with machine learning , predicting features of the duration on the basis of the verb lemma, local tex -tual context. and other information. Their best (SVM) classifier achieved precision of 78.2% on the course-grained task of determining whether an event's duration was longer or shorter than one day (compared with 87.7% human agreement). For de -termining the fine-grained task of determining the most likely temporal unit X  X econd, minute, hour, day, week, etc. X  X chieved 67.9% (human agree -ment: 79.8%). This shows that lexical information can be effectively leveraged for duration predic -tion.

To compile temporal duration information for a wider range of verbs, Gusev et al. (2011) explored an automatic Web-based query method for harvest -ing typical durations of events. Their data consist -ed of search engine  X  X it-counts X  and they analyzed the distribution of durations associated with 1000 frequent verbs in terms of whether the event lasts for more or less than a day (course -grain task) or whether it lasts for seconds, minutes, hours, days, weeks, months, or years (fine -grain task). They note that many verbs have a two-peaked distribu -tion and they suggest that the two-peaked distribu -tion could be a result of the usage referring to a habit or a single episode . ( W hen used with a dura -tion marker, run, for example, is used about 15% of the time with hour-scale and 38% with year-s -cale duration markers). Rather than making a dis -tinction between habits and episodes in their data, they apply a heuristic to focus on episodes only.
Kozareva and Hovy (2011) also collected typi -cal durations of events using Web query patterns. They proposed a six-way classification of ways in which events are related to time, but provided only programmatic analyses of a few verbs using We -b-based query patterns. They have proposed a compilation of the 5,000 most common verbs along with their typical temporal durations. In each of these efforts, automatically collecting a large amount of reliable to cover a wide range of verbs has been noted as a difficulty. It is this task that we seek to take up. Our goal was to discover the duration distribution a s well as typical habit and typical episode dura -tions for each verb lemma that we found in our col -lection . A wide range of factors influence typical event durations. Among these are the character of a verb ' s arguments, the presence of negation and oth -er embedding features. For this preliminary work, we ignored the effects of arguments, and focused only on generating duration information for verb lemmas. Also, t weets that were negated, condition -al tweets, and tweets in the future tense were put aside. 3.1 Data Collection A corpus of tweets was collected from the Twitter web service API using a n open-source module called Tweetstream (Halvorsen &amp; Schierkolk, 2010). T weets were collected that contained refer -ence to a temporal duration. The data collection task began on February 1, 2011 and ended on Sep -tember 28, 2011. Duplicate tweets were identified by their unique tweet ID provided by Twitter, and were removed from the data set . Also tweets that were marked by Twitter as 'retweets' (tweets that have been reposted to Twitter) were removed . The following query terms (denoting temporal duration measure) were used to filter the Twitter stream for tweets containing temporal duration: The number of tweets in the resulting co rpus was 14,801,607 and the total number of words in the corpus was 224,623,447. Tweets were normalized, tokenized, and then tagged for POS, using the NLTK T reebank T agger (Bird &amp; Loper, 2004). 3.2 Extraction Frames To associate each temporal duration with its event, events and durations were identified and extracted using four types of regular expression extraction frames. The patterns applied a heuristic to asso -ciate each verb with a temporal expression, similar to th e extraction frames used in Gusev et al. (201 1 ) . The four types of extraction frames we re: where verb is the target verb and duration is a du -ration-measure term. In (3), for example, the verb work is associated with the temporal duration term 4 4 years . These four extraction frame types were also varied to include different tenses, different grammatical aspects, and optional verb arguments to reach a wide range of event mentions and ordering be -tween the verb and the duration clause. For each matched tweet a feature vector was created with the following features : verb lemma, temporal bucket (seconds, minutes, hours, weeks, days, months or years), tense (past or present), grammat -ical aspect (simple, progressive, or perfect), dura -tion in seconds, and the extraction frame type (for, in, spend, or take) . For example, the features ex -tracted from (3) were: [work, years, past, simple, 1387584000, FOR] Tweets with verbal lemmas that occur fewer than 100 times in the extracted corpus were filtered out. The resulting data set contained 3 90 , 562 feature vectors covering 483 verb lemmas. 3.3 Extraction Precision Extraction frame performance was estimated using precision on a random sample of 400 hand-labeled tweets. Each instance in the sample was labeled as correct if the extracted feature vector was correct in its entirety. The overall precision for extraction frames was estimated as 90.25%, calculated using a two-tailed t-test for sample size of proportions with 95% confidence (p=0.05, n=400). 3.4 Duration Results 
In order to summarize information about dura -tion for each of the 483 verb lemmas, we calculat -ed the frequency distribution of tweets by duration in seconds. This distribution can be represented in histogram form, as in Figure 1 for the verb lemma search, with with bins corresponding to temporal units of measure (seconds, minutes, etc.). This histogram shows the characteristic bi -modal-distribution s noted by Pan et al., (2011) and Gusev et. al., (2011) , an issue taken up in the next section. Most verbs have both episodic and habitual uses, which clearly correspond to different typical dura -tions. In order to draw this distinction we built a system to automatically classify our tweets as to their habituality. The extracted feature vectors were used in a machine learning task to label each tweet in the collection as denoting a habit or an episode, broadly following Mathew &amp; Katz (2009). This classification was done with bootstrapping, in a partially supervised manner. 4.1 Bootstrapping Classifier First, a random sample of 1000 tweets from the ex -tracted corpus was hand-labeled as being either habit or episode (236 habits; 764 episodes). The extracted feature vectors for these tweets were used to train a C4.5 decision tree classifier ( Hall et al., 2009 ). This classifier achieved an accuracy of 83.6% during training . We used this classifier and the hand-labeled set to seed the generic Yarowsky Algorithm (Abney, 2004), iteratively inducing a habit or episode label for all the tweets in the col -lection, using the WEKA output for confidence scoring and a confidence threshold of 0.96 . 
The extracted corpus was classified into 94,643 habitual tweets and 295,918 episodic tweets. To estimate the accuracy of the classifier, 400 ran -domly chosen tweets from the extracted corpus were hand-labeled, giving an estimated accuracy of 85% accuracy with 95% confidence, using the two-tailed t-test for sample size of proportions (p=0.05, n=400). 4.2 Results Clearly the data in Figure 1 represents two com -bined distributions: one for episodes and one for habits, as we illustrate in Figure 2. We see that the verb search describes episodes that most often last minutes or hours, while it describes habits that go on for years. These two different uses are illustrated in (4) and (5). In Table 1 we provide summary information for several verb lemma s, indicating the average dura -tion for each verb and the temporal unit corre -sponding to the largest bin for each verb.
 It is cle a r that the methodology overestimates the duration of episodes somewhat  X  our estimates of typical durations are 2-3 times as long as those that come from the annotation in Pan, et. al. (2009). Nevertheless, the modal bin corresponds approxi -mately to that the hand annotation in Pan, et. al., (2011) for nearly half (45%) of the verbs lemmas. W e ha ve pr e sen te d a hybrid approach for extract -ing typical durations of habits and episodes. We are able to extract high-quality information about temporal durations and to effectively classify tweets as to their habituality. It is clear that Twitter tweets contain a lot of unique data about different kinds of events and habits, and mining this data for temporal duration information has turned out to be a fruitful avenue for collecting the kind of world-knowledge that we need for robust temporal lan -guage processing. Our verb lexicon is available at: https://sites.google.com/site/relinguistics/.
