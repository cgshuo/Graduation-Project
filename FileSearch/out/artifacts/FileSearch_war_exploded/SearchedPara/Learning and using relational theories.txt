 What is a theory, and what makes one theory better than another ? Questions like these are of obvious interest to philosophers of science but are also discussed b y psychologists, who have argued that everyday knowledge is organized into rich and complex syste ms that are similar in many respects to scientific theories. Even young children, for instance, h ave systematic beliefs about domains including folk physics, folk biology, and folk psychology [ 2]. Intuitive theories like these play many of the same roles as scientific theories: in particular, both kinds of theories are used to explain and encode observations of the world, and to predict future obse rvations.
 This paper explores the nature, use and acquisition of simpl e theories. Consider, for instance, an anthropologist who has just begun to study the social struct ure of a remote tribe, and observes that certain words are used to indicate relationships between se lected pairs of individuals. Suppose that anthropologist might discover that the first term is transit ive, and that the second term is symmetric with a few exceptions. Suppose that term T3 (  X  ,  X  ) can be glossed as defers to (  X  ,  X  ) , and that the tribe divides into two castes such that members of the second caste defer to members of the first caste. In this case the anthropologist might discover two latent conc epts ( caste 1 (  X  ) and caste 2 (  X  ) ) along with the relationship between these concepts.
 As these examples suggest, a theory can be defined as a system o f laws and concepts that specify the relationships between the elements in some domain [2]. W e will consider how these theories are learned, how they are used to encode relational data, and how they support predictions about unob-served relations. Our approach to all three problems relies on the notion of subjective complexity. We propose that theory learners prefer simple theories, tha t people remember relational data in terms of the simplest underlying theory, and that people extend a p artially observed data set according to the simplest theory that is consistent with their observati ons. There is no guarantee that a single measure of subjective complexity can do all of the work that w e require [3]. This paper, however, explores the strong hypothesis that a single measure will su ffice.
 Our formal treatment of subjective complexity begins with t he question of how theories are mentally represented. We suggest that theories are represented in so me logical language, and propose a spe-cific first-order language that serves as a hypothesis about t he  X  X anguage of thought. X  We then pursue the idea that the subjective complexity of a theory correspo nds to the length of its representation in this language. Our approach therefore builds on the work of F eldman [4], and is related to other psychological applications of the notion of Kolmogorov com plexity [5]. The complexity measure we describe can be used to define a probability distribution o ver a space of theories, and we develop a model of theory acquisition by using this distribution as t he prior for a Bayesian learner. We also Figure 1: Six possible extensions for a binary predicate R (  X  ,  X  ) . In each case, the objects in the domain are represented as digits, and a pair such as 16 indicates that R ( 1 , 6 ) is true. Below each set of pairs, the simplest theory according to our complexity me asure is shown. show how the same Bayesian approach helps to explain how theo ries support inductive generaliza-tion: given a set of observations, future observations (e.g . whether one individual defers to another) can be predicted using the posterior distribution over the s pace of theories.
 We test our approach by developing two experiments where peo ple learn and make predictions about binary and ternary relations. As far as we know, the app roach of Goodman [1] is the only other measure of theory complexity that has previously been tested as a psychological model [6]. We show that our experiments support our approach and raise c hallenges for this alternative model. Intuitive theories correspond to mental representations o f some sort, and our first task is to char-acterize the elements used to build these representations. We explore the idea that a theory is a system of statements in a logical language, and six examples are shown in Fig. 1. The theory in Fig. 1b is related to the defers to (  X  ,  X  ) example already described. Here we are interested in a domain including 9 elements, and a two place predicate R (  X  ,  X  ) that is true of all and only the 15 pairs shown. R is defined using a unary predicate T which is true of only three elements: 6 , 7 , and 8 . The theory includes a clause which states that R ( X , Y ) is true for all pairs XY such that T ( X ) is false and T ( Y ) is true. The theory in Fig. 1c is very similar, but includes an additional clause which specifies that R ( 1 , 1 ) is true, and an exception which specifies that R ( 1 , 6 ) is false. Formally, each theory we consider is a collection of function-free definite clauses. All variables are universally  X  x  X  y  X  z ( R ( x , z )  X  R ( x , y )  X  R ( y , z )) . For readability, the theories in Fig. 1 include parenthe-ses and arrows, but note that these symbols are unnecessary a nd can be removed. Our proposed language includes only predicate symbols, variable symbol s, constant symbols, and a period that indicates when one clause finishes and another begins.
 Each theory in Fig. 1 specifies the extension of one or more pre dicates. The extension of predicate P is defined in terms of predicate P + (which captures the basic rules that lead to membership in P ) and predicate P  X  (which captures exceptions to these rules). The resulting e xtension of P is defined as P + \ P  X  , or the set difference of P + and P  X  . 1 Once P has been defined, later clauses in the theory may refer to P or its negation  X  P . To ensure that our semantics is well-defined, the predicate s in any valid theory must permit an ordering so that the definit ion of any predicate does not refer to predicates that follow it in the order. Formally, the definit ion of each predicate P + or P  X  can refer only to itself (recursive definitions are allowed) and to any predicate M or  X  M where M &lt; P . Once we have committed to a specific language, the subjective complexity of a theory is assumed to correspond to the number of symbols in its representation. W e have chosen a language where there is one symbol for each position in a theory where a predicate, variable or constant appears, and one symbol to indicate when each clause ends. Given this languag e, the subjective complexity c ( T ) of theory T is equal to the sum of the number of clauses in the theory and th e number of positions in the theory where a predicate, variable or constant appears: c ( T ) = #clauses ( T ) + #pred slots ( T ) + #var slots ( T ) + #const slots ( T ) . (1) of a theory (three predicate symbols, six variable symbols, and one period). Other languages might be considered: for instance, we could use a language which us es five symbols (e.g. five bits) to represent each predicate, variable and constant, and one sy mbol (e.g. one bit) to indicate the end of a clause. Our approach to subjective complexity depends cri tically on the representation language, but once a language has been chosen the complexity measure is uniquely specified.
 Although our approach is closely related to the notion of Kol mogorov complexity and to Minimum Message Length (MML) and Minimum Description Length (MDL) a pproaches, we refer to it as a Representation Length (RL) approach. A RL approach include s a commitment to a specific language that is proposed as a psychological hypothesis, but these ot her approaches aspire towards results that do not depend on the language chosen. 2 It is sometimes suggested that the notion of Kolmogorov complexity provides a more suitable framework for psycholo gical research than the RL approach, precisely because it allows for results that do not depend on a specific description language [8]. We subscribe to the opposite view. Mental representations pre sumably rely on some particular language, and identifying this language is a central challenge for psy chological research.
 The language we described should be considered as a tentativ e approximation of the language of thought. Other languages can and should be explored, but our language has several appealing prop-erties. Feldman [4] has argued that definite clauses are psyc hologically natural, and working with these representations allows our approach to account for se veral classic results from the concept learning literature. For instance, our language leads to th e prediction that conjunctive concepts are easier to learn than disjunctive concepts [9]. 3 Working with definite clauses also ensures that each of our theories has a unique minimal model, which means that the extension of a theory can be defined in a particularly simple way. Finally, human learners deal g racefully with noise and exceptions, and our language provides a simple way to handle exceptions.
 Any concrete proposal about the language of thought should m ake predictions about memory, learn-ing and reasoning. Suppose that data set D lists the extensions of one or more predicates, and that a theory is a  X  X andidate theory X  for D if it correctly defines the extensions of all predicates in D . Note that a candidate theory may well include latent predicates X  X  redicates that do not appear in D , but are useful for defining the predicates that have been observe d. We will assume that humans encode D in terms of the simplest candidate theory for D , and that the difficulty of memorizing D is deter-mined by the subjective complexity of this theory. Our appro ach can and should be tested against classic results from the memory literature. Unlike some oth er approaches to complexity [10], for instance, our model predicts that a sequence of k items is about equally easy to remember regardless of whether the items are drawn from a set of size 2, a set of size 10, or a set of size 1000 [11]. To develop a model of inductive learning and reasoning, we ta ke a Bayesian approach, and use our complexity measure to define a prior distribution over a h ypothesis space of theories: P ( T )  X  2  X  c ( T ) . 4 Given this prior distribution, we can use Bayesian inferenc e to make predictions about unobserved relations and to discover the theory T that best accounts for the observations in data set D [12, 13]. Suppose that we have a likelihood function P ( D | T ) which specifies how the examples in D were generated from some underlying theory T . The best explanation for the data D is the theory that maximizes the posterior distribution P ( T | D )  X  P ( D | T ) P ( T ) . If we need to predict whether ground term g is likely to be true, 5 we can sum over the space of theories: where the final sum is over all theories T that make ground term g true. 1.1 Related work The theories we consider are closely related to logic progra ms, and methods for Inductive Logic Programming (ILP) explore how these programs can be learned from examples [14]. ILP algorithms are often inspired by the idea of searching for the shortest t heory that accounts for the available data, and ILP is occasionally cast as the problem of minimizing an e xplicit MDL criterion [10]. Although ILP algorithms are rarely considered as cognitive models, t he RL approach has a long psychological history, and is proposed by Chomsky [15] and Leeuwenberg [16 ] among others.
 Formal measures of complexity have been developed in many fie lds [17], and there is at least one other psychological account of theory complexity. Goodman [1] developed a complexity measure that was originally a philosophical proposal about scienti fic theories, but was later tested as a model of subjective complexity [6]. A detailed description of thi s measure is not possible here, but we attempt to give a flavor of the approach. Suppose that a basis is a set of predicates. The starting point for Goodman X  X  model is the intuition that basis B 1 is at least as complex as basis B 2 if B 1 can be used to define B 2 . Goodman argues that this intuition is flawed, but his model i s founded on a refinement of this intuition. For instance, since the bin ary predicate in Fig. 1b can be defined in terms of two unary predicates, Goodman X  X  approach requir es that the complexity of the binary predicate is no more than the sum of the complexities of the tw o unary predicates.
 We will use Goodman X  X  model as a baseline for evaluating our o wn approach, and a comparison between these two models should be informed by both theoreti cal and empirical considerations. On the theoretical side, our approach relies on a simple prin ciple for deciding which structural properties are relevant to the measurement of complexity: t he relevant properties are those with short logical representations. Goodman X  X  approach incorp orates no such principle, and he proposes somewhat arbitrarily that reflexivity and symmetry are amon g the relevant structural properties but that transitivity is not. A second reason for preferring our model is that it makes contact with a general principle X  X he idea that simplicity is related to rep resentation length X  X hat has found many applications across psychology, machine learning, and phi losophy. We designed two experiments to explore settings where peopl e learn, remember, and make inductive inferences about relational data. Although theories often consist of systems of many interlocking relations, we keep our experiments simple by asking subject s to learn and reason about a single relation at a time. Despite this restriction, our experimen ts still make contact with several issues raised by systems of relations. As the defers to (  X  ,  X  ) example suggests, a single relation may be best explained as the observable tip of a system involving se veral latent predicates (e.g. caste 1 (  X  ) and caste 2 (  X  ) ). Figure 2: (a) Average time in seconds to learn the six sets in F ig. 1. (b) Average ratings of set com-plexity. (c) Complexity scores according to our representa tion length (RL) model. (d) Complexity scores according to Goodman X  X  model. 2.1 Experiment 1: memory and induction In our first experiment, we studied the subjective complexit y of six binary relations that display a range of structural properties, including reflexivity, sym metry, and transitivity.
 Materials and Methods. 18 adults participated in this experiment. Subjects were re quired to learn the 6 sets shown in Fig. 1, and to make inductive inferences ab out each set. Although Fig. 1 shows pairs of digits, the experiment used letter pairs, and the le tters for each condition and the order in which these conditions were presented were randomized ac ross subjects. The pairs for each condition were initially laid out randomly on screen, and su bjects could drag them around and organize them to help them understand the structure of the se t. At any stage, subjects could enter a test phase where they were asked to list the 15 pairs belongin g to the current set. Subjects who made an error on the test were returned to the learning phase. Afte r 9 minutes had elapsed, subjects were allowed to pass the test regardless of how many errors they ma de.
 After passing the test, subjects were asked to rate the compl exity of the set compared to other sets with 15 pairs. Ratings were provided on a 7 point scale. Subje cts were then asked to imagine that a new letter (e.g. letter 9 ) had belonged to the current alphabet, and were given two ind uctive tasks. First they were asked to enter between 1 and 10 novel pairs tha t they might have expected to see (each novel pair was required to include the new letter). Nex t they were told about a novel pair that belonged to the set (e.g. pair 91 ), and were again asked to enter up to 10 additional pairs that they might have expected to see.
 Results. The average time needed to learn each set is shown in Fig. 2a, a nd ratings of set complexity are shown in Fig. 2b. It is encouraging that these measures yi eld converging results, but they may be confounded since subjects rated the complexity of a set imme diately after learning it. The complex-ities plotted in Fig. 2c are the complexities of the theories shown in Fig. 1, which we believe to be the simplest theories according to our complexity measure. The final plot in Fig. 2 shows complex-ities according to Goodman X  X  model, which assigns each bina ry relation an integer between 0 and 4. There are several differences between these models: for i nstance, Goodman X  X  account incorrectly predicts that the exception case is the hardest of the six, bu t our model acknowledges that a sim-ple theory remains simple if a handful of exceptions are adde d. Goodman X  X  account also predicts that transitivity is not an important structural regularit y, but our model correctly predicts that the transitive set is simpler than the same set with some of the pa irs reversed (the random set). Results for the inductive task are shown in Fig. 3. The first tw o columns show the number of subjects who listed each novel pair. The remaining two columns show th e probability of set membership predicted by our model. To generate these predictions, we ap plied Equation 2 and summed over a set of theories created by systematically extending the th eories shown in Fig. 1. Each extended theory includes up to one additional clause for each predica te in the base theory, and each additional clause includes at most two predicate slots. For instance, e ach extended theory for the bipartite case is created by choosing whether or not to add the clause T ( 9 ) , and adding up to one clause for predicate R . 6 For the first inductive task, the likelihood term P ( D | T ) (see Equation 2) is set to 0 for all theories that are not consistent with the pairs obser ved during training, and to a constant for all remaining theories. For the second task we assumed in add ition that the novel pair observed is Figure 3: Data and model predictions for the induction task i n Experiment 1. Columns 1 and 3 show predictions before any pairs involving the new letter a re observed. Columns 2 and 4 show predictions after a single novel pair (marked with a gray bar ) is observed to belong to the set. The model plots for each condition include correlations with th e human data. sampled at random from all pairs involving the new letter. 7 All model predictions were computed using Mace4 [18] to generate the extension of each theory con sidered.
 The supporting material includes predictions for a model ba sed on the Goodman complexity measure and an exemplar model which assumes that the new letter will b e just like one of the old letters. 8 The exemplar model outperforms our model in the random conditio n, and makes accurate predictions about three other conditions. Overall, however, our model p erforms better than the two baselines. Here we focus on two important predictions that are not well h andled by the exemplar model. In the symmetry condition, almost all subjects predict that 78 belongs to the set after learning that 87 belongs to the set, suggesting that they have learned an abst ract rule. In the transitive condition, most subjects predict that pairs 72 through 76 belong to the set after learning that 71 belongs to the set. Our model accounts for this result, but the exemplar mod el has no basis for making predictions about letter 7 , since this letter is now known to be unlike any of the others. 2.2 Experiment 2: learning from positive examples During the learning phase of our first experiment, subjects l earned a theory based on positive ex-amples (the theory included all pairs they had seen) and nega tive examples (the theory ruled out all pairs they had not seen). Often, however, humans learn theor ies based on positive examples alone. Suppose, for instance, that our anthropologist has spent on ly a few hours with a new tribe. She may have observed several pairs who are obviously friends, but s hould realize that many other pairs of friends have not yet interacted in her presence. Figure 4: Data and model predictions for Experiment 2. The fo ur triples observed for each set are shown at the top of the figure. The first row of plots shows avera ge ratings on a scale from 1 (very unlikely to belong to the set) to 7 (very likely). Model predi ctions are plotted as log probabilities. Our framework can handle cases like these if we assume that th e data D in Equation 2 are sampled from the ground terms that are true according to the underlyi ng theory. We follow [10] and [13] and use a distribution P ( D | T ) which assumes that the examples in D are randomly sampled with replacement from the ground terms that are true. This sampli ng assumption encourages our model to identify the theory with the smallest extension that is co mpatible with all of the training examples. We tested this approach by designing an experiment where lea rners were given sets of examples that were compatible with several underlying theories.
 Materials and Methods. 15 adults participated in this experiment immediately afte r taking Experi-ment 1. In each of five conditions, subjects were told about a s et of triples built from an alphabet of 9 letters. They were shown four triples that belonged to the s et (Fig. 4), and told that the set might include triples that they had not seen. Subjects then gave ra tings on a seven point scale to indicate whether five additional triples (see Fig. 4) were likely to be long to the set.
 Results. Average ratings and model predictions are shown in Fig. 4. Mo del predictions for each condition were computed using Equation 2 and summing over a s pace of theories that included the five theories shown at the top of Fig. 4, variants of these five t heories which stated that certain pairs of slots could not be occupied by the same constant, 9 and theories that included no variables but merely enumerated up to 5 triples. 10 Although there are general theories like R ( X , Y , Z ) that are compatible with the triples observed in all five conditions, Fig. 4 shows that people were sensitive to di fferent regularities in each case. 11 We focus on one condition (Fig. 4b) that exposes the strengths a nd weaknesses of our model. According to our model, the two most probable theories given the triple s for this condition are R ( X , X , 1 ) and the predictions are consistent with people X  X  judgments that 771 is very likely to belong to the set, and that 778 is the next most likely option. Unlike our model, however, pe ople consider 777 to be substantially less likely than 778 to belong to the set. This result may suggest that the variant of R (
X , X , Y ) that rules out R ( X , X , X ) deserves a higher prior probability than our model recogniz es. To better account for cases like this, it may be worth consideri ng languages where any two variables that belong to the same clause but have different names must r efer to different entities. There are many psychological models of concept learning [4, 12, 13], but few that use representa-tions rich enough to capture the content of intuitive theori es. We suggested that intuitive theories are mentally represented in a first-order logical language, and proposed a specific hypothesis about this  X  X anguage of thought. X  We assumed that the subjective c omplexity of a theory depends on the length of its representation in this language, and describe d experiments which suggest that the result-ing complexity measure helps to explain how theories are lea rned and used for inductive inference. Our experiments deliberately used stimuli that minimize th e influence of prior knowledge. Theories, however, are cumulative, and the theory that seems simplest to a learner will often depend on her background knowledge. Our approach provides a natural plac e for background knowledge to be inserted. A learner can be supplied with a stock of backgroun d predicates, and the shortest repre-sentation for a data set will depend on which background pred icates are available. Since different sets of predicates will lead to different predictions about subjective complexity, empirical results can help to determine the background knowledge that people brin g to a given class of problems. Future work should aim to refine the representation language and complexity measure we proposed. We expect that something like our approach will be suitable f or modeling a broad class of intuitive theories, but the specific framework presented here can almo st certainly be improved. Future work should also consider different strategies for searching th e space of theories. Some of the strate-gies developed in the ILP literature should be relevant [14] , but a detailed investigation of search algorithms seems premature until our approach has held up to additional empirical tests. It is com-paratively easy to establish whether the theories that are s imple according to our approach are also considered simple by people, and our experiments have made a start in this direction. It is much harder to establish that our approach captures most of the th eories that are subjectively simple, and more exhaustive experiments are needed before this conclus ion can be drawn.
 Boolean concept learning has been studied for more than fifty years [4, 9], and many psychologists have made empirical and theoretical contributions to this fi eld. An even greater effort will be needed to crack the problem of theory learning, since the space of in tuitive theories is much richer than the space of Boolean concepts. The difficulty of this problem should not be underestimated, but computational approaches can contribute part of the soluti on.

