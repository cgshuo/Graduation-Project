 Boosting is an adaptive approach, which makes it possible to correctly classify an object that can be badly classified by an ordinary classifier. The main idea of Boosting is to build many classifiers who complement each other, in order to build a more powerful classifier. Adaboost ( Ada ptive Boost ing )isthemost known method of Boosting for classifiers generation and combination.
AdaBoost algorithm is iterative. At first, i t selects a subset of instances from the learning data set (different subset fr om the training data set in each itera-the classifier on the learning data set, and it starts again T times.
It has been found that this ingenious manipulation of training data can fa-vorise diversity especially for linear classifiers [11]. However, there is no study concerning the role of diversity on Nominal Concepts classifiers [13]. In this paper, we study how diversity changes according to the nominal classifier num-bers and we show when adding new classifiers to the team can X  X  provide further improvements.

This paper is organized as follows: section 2 presents the principle of Classifier of Nominal Concepts ( CNC )usedin Boosting [7,13]. In section 3, we discuss the diversity of classifiers and the diffe rent measures that can be exploited in the classifiers ensembles generation. Sect ion 4 presents the exp erimental results that prove when the diversity can be useful in Boosting of Nominal Concepts . CNC is a classifier based on the Formal Concept Analysis . It is distinguished from the other Formal Concept Analysis methods by handling nominal data. It generates Nominal Concept that is used as classification rule. Comparative studies and experimental results have proved the benefits of CNC compared to existing ones ( GRAND, RULEARNER, CITREC, IPR )[13]. 2.1 Nominal Concepts A nominal classifier can be build using the whole of training instances O = { o 1 , ..., o N binary).
 At first, the pertinen t nominal concept AN  X  is extracted from the training in-stances by selecting the nominal attribute which minimises the measure of Infor-mational Gain [13]. Then, the associated instan ces are selected with each value v j (j = this attribute as  X  ( AN  X  = v j ). The  X  operator is defined by: Then, the other attributes describing all the extracted instances are determined (using the closure operator  X   X   X  ( AN  X  = v j )) as follows: In [13], a method called BNC ( B oosting N ominal C oncepts ) has been proposed. The advantage of BNC is to build a part of the lattice covering the best nominal inal Concepts ). The BNC has the particularity to decide the number of nominal classifiers in order to control the time of application and to provide the best decision. 2.2 Learning Concept Based Classifiers label associated for each instance o i ( i=1 to N ). To generate T classifiers in AdaBoost , the distribution of the weight of o i is initially determined as : The weight of o i is: On each iteration t from 1 to T , we define: The distribution of weights is calculated by: to the class y i from the entry o i . Three cases are presented: Theerrorrateof h t is calculated on the weighted training set. If an instance o i is the weightis increased. The pseudo-loss of the classifier h t is defined as: The weights are then updated according to  X  t : The procedure is repeated T times and the final result of BNC is determined via the combination of the generated classifier outputs: The first variant of the AdaBoost algorithm is called Adaboost.M1 [5,6] that uses thepreviousprocessandstopsitwhenthe error rate of a classifier becomes over 0.5. The second variant is called AdaBoost.M2 [6] which has the particularity of handling multi-class data and operating whatever the error rate is. In this study, we use AdaBoost.M2 since Adaboost.M1 has the limit to stop Boosting if the learning error exceeds 0.5. In some exp eriments, Adaboos t.M1 can be stopped after the generation of first classifier thus we cannot calculate the diversity of classifier ensemble in this particular case.

Recent researches have proved the import ance of classifier diversity in improv-ing the performance of AdaBoost [1,4,8]. We shall discuss about that in the next section.
 According to [4], linear classifiers should be different from each other, otherwise the decision of the ensemble will be of lower quality than the individual decision. [3].

In [14], the authors found a consistent pattern of diversity showing that at the beginning, the generated linear classifiers are highly diverse but as the learning progresses, the diversity gradually retu rns to its starting level. This suggests that it could be beneficial to stop AdaBoost before diversity drops. The authors confirm that there are a consistent patterns of diversity with many measures using linear classifiers . However, they report that the pattern might change if other classifier models are used. In the paper, we will prove that this pattern is the same with nominal classifiers .
 Many measures can be used t o determine the diversity between classifiers [11]. In this section, we present three(3) of them: Q Statistic , Correlation Coefficient (
CC )and Pairwise Interrater Agreement ( kp ).Thesepairwisemeasureshave the same diversity value (0) when the classifiers are statistically independent. They are called pairwise because they consider the output classifiers, two at a time and then they average the calculated pairwise diversity. These measures are computed based on the agreement a nd the disagreement between each 2 classifiers (see Table 1).

N vw (v,w=1,0) is the number of instances co rrectly or incorrectly classified by the two classifiers: h j and h k ( j,k = 1..T ).
 The Q Statistic: Using table 1, this measure is calculated as follows: Q
Statistic varies between -1 and 1. Classifiers that tend to recognize correctly the same instances, have positive Q values, and classifiers that commit errors on different instances have negative Q values. In [11], the authors showed that the negative dependency of linear classi fiers can offer a dramatic improvement in Boosting . The Correlation Coefficient: The correlation between 2 classifiers is given by: The Pairwise Interrater agreement: For this measure, the agreement be-tween each pair of classifiers is calculated as: For any pair of classifiers, Q and  X  have the same sign. The maximum value of  X  and kp is 1 but the minimum value depends on the individual performance of the classifiers.
 In [11], it is reported that there is not unique choice of diversity measure. But, for linear classifiers, the authors recommended the use of Q Statistic for it X  X  simplicity and it X  X  significant results. Then, it X  X  interesting to compare the previous measures in Boosting Nominal Concept . The goal of this section is to study the relationship between the nominal classi-fiers diversity and AdaBoost performance for 2-class problems.

The experiments are performed on 5 real data sets extracted from UCI Ma-chine Learning Repository 1 [2] and the algorithms are implemented in WEKA 2 ,a widely used toolkit.

The characteristics of these data set s are reported in Table 2. For each data set, we respectively give the number of in stances and the number of attributes. Also, we present the data diversity rate that indicates the samples which are different (including the class label) in the data [9].
The performance of BNC is evaluated in terms of error rates. To calculate this performance, we report the average of 10 experimentations. Each experiment was performed using 10 cross-validations , that is the most used method in the literature for validation [10].
It consists on dividing the data sample into 10 subsets. In turn, each subset will be used for testing and the rest are assembled together for learning. Finally, the average of these 10 runs is reported.

Figures 1, 2, 3, 4 and 5 present the performance of BNC and the values of the 3 diversity measures on the Credit German , Diabetes , Ionosphere , Tic Tac Toc and Transfusion data sets respectively.

In figure 1.1, we remark that the performance of BNC starts to stabilize when using ensembles of 20 classifiers, for high diversity data ( DD =98.59%). The classifiers generated are negatively depend ( Q X  -0.02). The minimum values of Q Statistic are obtained with classifier numbers varying between 10 and 20. From figure 1.3 and figure 1.4, the values of the 2 measures CC and Kp are very divers and the variation curves are ascending, while the curve of the values of Q is upward then downward.

In figure 2.1, the best performance of BNC is obtained with divers classifier ensembles (with Q =-0.3 as minimum average values). In figure 2.2, the min-imum values of Q Statistic are obtained with 20 classifiers. For Diabetes data ( DD =22.83%), there is a relation between Q Statistic and the BNC performance.
With high divers data (figure 3.2), the first generated classifiers are indepen-dent but the rest are negatively depend ( Q X  -0.15). The minimum values of Q Statistic are obtained with classifier numbers varying between 15 and 30. With less than 20 classifiers, the error rate decreases about 40% (figure 3.1).
From figure 4.1, the difference between the error rates of the first classifier and the generated thereafter, is not important. This show that Boosting can converge to the best performance with fe w classifiers. For this case, Q Statistic is informative. In Figure 4.3 and 4.4, the values of Kp and CC vary an a very arbitrary way.

For the Transfusion data set ( DD =1.07%), the classifier generation does not help to increase BNC performance. We conclude that it is not recommanded to use AdaBoost for this type of data.

Concerning diversity measures, we can note that for 2-class problems, the values of  X  and k p are not correlated with AdaBoost performance using nominal classifiers .The Q Statistic seems like a good measure of model diversity that has a relationship with the performance of AdaBoost and then for can be used to stop classifier learning . In this paper, we have study the diversity of nominal classifiers in AdaBoost.M2 . We have compared 3 diversity measures for 2-class problems. We have found that the Q Statistic is significantly correlated with the AdaBoost performance, especially for very divers data sets. Th en, it X  X  possible to use this measure as a stopping criteria for ensemble learnin g . But for very correlated data sets, no measure is useful. This results should be confirmed with more correlated data. The diversity of data sets should then be taken into account in AdaBoost learning in AdaBoost for many class problems.

