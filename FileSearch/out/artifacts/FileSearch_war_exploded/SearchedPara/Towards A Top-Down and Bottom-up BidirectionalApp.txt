 Most high-level information extraction (IE) consists of com-pound and aggregated subtasks. Such IE problems are gen-erally challenging and they have generated increasing inter-est recently. We investigate two representative IE tasks: (1) entity identification and relation extraction from Wikipedia, and (2) citation matching, and we formally define joint op-timization of information extraction. We propose a joint paradigm integrating three factors  X  segmentation, relation, and segmentation-relation joint factors, to solve all rele-vant subtasks simultaneously. This modeling offers a nat-ural formalism for exploiting bidirectional rich dependen-cies and interactions between relevant subtasks to capture mutual benefits. Since exact parameter estimation is pro-hibitively intractable, we present a general, highly-coupled learning algorithm based on variational expectation maxi-mization (VEM) to perform parameter estimation approxi-mately in a top-down and bottom-up manner, such that in-formation can flow bidirectionally and mutual benefits from different subtasks can be well exploited. In this algorithm, both segmentation and relation are optimized iteratively and collaboratively using hypotheses from each other. We con-ducted extensive experiments using two real-world datasets to demonstrate the promise of our approach.
 I.5.1 [ Pattern Recognition ]: Models X  Statistical ; H.2.8 [ Database Management ]: Database Applications X  Data mining ; I.2.7 [ Artificial Intelligence ]: Natural Language Processing X  Text analysis Algorithms, Experimentation  X  This work is supported by two grants from the Research Grants Council of the Hong Kong SAR, China (Project No. CUHK 413210 and Project No. CUHK 415410).
 Factor graphs, top-down and bottom-up bidirectional learn-ing, variational inference, joint information extraction
Information extraction (IE) aiming at extracting struc-tured information from text or semi-structured sources plays an important role for a wide variety of applications and it has been investigated for decades. Among such IE tasks, high-level IE problems consisting of compound subtasks have be-come increasingly popular and they present new challenges to research communities. Typically, two key subtasks are segmentation which identifies candidate records (e.g., word segmentation, chunking and entity recognition), and relation discovery which discovers certain relations between different records (e.g., entity resolution, relation extraction and social relation mining) [23].

The most common and simplest approach to performing compound IE tasks is to use 1-best or K -best pipeline archi-tecture: components are run independently in some order, and there is no feedback from later components to earlier ones [2, 3]. This approach is feed-forward, which is only top-down or bottom-up integrated, and mutual interactions between different components cannot be exploited. Errors cascade and accumulate, and a once-made error can hardly be corrected in the pipeline. Due to this reason, the end-to-end performance is often hampered and upper-bounded.
Ideally, we would like to advocate joint information ex-traction, which is to solve all relevant subtasks in informa-tion extraction jointly, that is, all relevant IE subtasks are optimized simultaneously and decisions of them are made together in a single coherent manner. Joint IE aims to han-dle multiple hypotheses and uncertainty information and to predict many variables at once such that subtasks can aid each other to boost the performance [6, 12, 29, 24, 15, 10, 26, 25]. This is usually very challenging, and often increases the model complexity. It is typically intractable to run a joint model and they sometimes can hurt the performance, since they increase the number of paths to propagate errors. Due to these difficulties, research on building joint approaches is still in the infancy stage.

Recently, a significant amount of work has shown the fea-sibility and effectiveness of discriminatively-trained proba-bilistic graphical models for a variety of IE tasks [18, 20]. The superiority of graphical model is its ability to represent a large number of random variables as a family of probabil-ity distributions that factorize according to an underlying graph, and it can capture complex dependencies between Figure 1: A snapshot of the encyclopedic article about Bill Gates in Wikipedia. variables. This progress has begun to make the joint learning approach possible. While a number of previous researchers have taken steps toward this direction, there are still vari-ous shortcomings: high computational complexity [19], the number of uncertain hypotheses is severely limited [6, 2], the subtasks are only loosely coupled [27], or the approach is feed-forward or top-down integrated and it only allows information to flow in one direction [30].

Exploring bidirectional information and rich interdepen-dencies between relevant subtasks is intuitively appealing. In the following, we use examples from two real-world datasets in our experiments to show the disadvantages of the pipeline architecture and the necessarity of top-down and bottom-up modeling, and to demonstrate the merits of our approach.
For compound, aggregated IE problems, the availability of robust, flexible, and accurate systems is highly desirable. Wikipedia 1 is the world X  X  largest free online encyclopedia, representing the outcome of a continuous collaborative ef-fort of a large number of volunteer contributors. We inves-tigate the task of identifying entities (e.g., person , location , and organization names) and extracting semantic relation-ships (e.g., member of and associate ) between entity pairs in English encyclopedic articles from Wikipedia. For ex-ample, Figure 1 gives a snapshot of Wikipedia Web page about the person Bill Gates . The basic document is an arti-cle, which mainly defines and describes an entity (e.g., Bill Gates ). This document mentions some other entities (e.g., Microsoft , Paul Allen , Seattle , etc) related to the entity Bill Gates . As an illustrative example, consider the following text excerpted from our dataset:
George W. Bush was elected President in 2000 as the Re-publican candidate.

Clearly, our task consists of two subtasks. First, for entity identification, we need to recognize the entities (both the http://www.wikipedia.org/ boundaries and types of them): the person name George W. Bush , the year 2000 and the organization Republican . Second, for relation extraction, we should extract the ex-ecutive relation between George W. Bush and Republican . However, the pipeline approach in our experiments cannot extract the executive relation between George W. Bush and Republican , since the organization name Republican is incor-rectly labeled as miscellaneous in entity identification stage, and the later relation extraction stage consuming this result also produces erroneous output. From the bottom-up view-point, knowing that Republican is an organization is help-ful for the executive relation discovery between this entity and the person George W. Bush . From the top-down view-point, the executive relation is a strong evidence indicating a person name George W. Bush and an organization Republi-can . Modeling top-down and bottom-up simultaneously can therefore explore interdependencies between multiple sub-tasks, and allow information to flow in both directions to exploit mutual benefits.
Citation matching requires extracting bibliographic records (e.g., author , title , and venue fields) from citation lists in technical papers (segmentation), and then identifying dupli-cate records to find the citations referring to the same paper (entity resolution). Citation strings may have different ci-tation styles, different abbreviations, and typographical er-rors. Correct coreference of a messy citation with a clean citation provides the opportunity for an alignment between these two citations to help the model correctly segment the messy one. Also, coreference between two citations can be assessed more accurately if we can compare well-segmented title fields and venue fields. Given the following two cita-tions from the Cora database: Hu, Y. &amp; Kibler, D Generation of Attributes for Learning
Algorithms, in Proceeding of the 13th National Conference on Artificial Intelligence, p806-811, 1996.

Hu, Y., and Kibler, D., Generation of Attributes for Learning Algorithms, Proceedings of the Thirteenth
National Conference on Artificial Intelligence (AAAI96), p.806-811, 1996.
 In the second citation, the author field Hu, Y., and Kibler, D. and the title field Generation of Attributes for Learning Algorithms are clearly separated by a comma, and extract-ing them is fairly straightforward. However, in the first one, there is no clear author-title boundary, and correctly pin-pointing it seems very difficult. Large quantities of labeled training data and an extensive lexicon could help, but they are very expensive to obtain, and even available they are far from a guarantee of success. However, if we notice that the two citations are coreferent and the title of the second one begins with the substring  X  Generation of Attributes for  X , we can hypothesize that the title of the first one also begins with this substring, allowing us to correctly segment it.
To summarize, what appears to be necessary is a mecha-nism to consistently integrate top-down and bottom-up pro-cessing in a bidirectional manner such that segmentation and entity resolution can aid each other to boost the perfor-mance of citation matching. In the following, we summarize our major contributions to show that our approach meets these requirements.
Inspired by the above motivation and to address the prob-lems such as brittle accumulation of errors in pipeline sys-tems, in this paper we propose a general, strongly-coupled, and bidirectional paradigm, based on conditionally-trained factor graphs for both top-down and bottom-up modeling, to attack the problem of joint information extraction. More specifically, we summarize our major contributions of this paper as follows:
Let x = { x 1 ,x 2 ,...,x p } be an observation sequence con-taining p tokens. Let s = { s 1 ,s 2 ,...,s q } be a segmentation assignment of observation sequence x . Each segment s i is a triple s i = {  X  i , X  i ,y i } , where  X  i is a start position,  X  is an end position, and y i ( y i  X  Y ) is the label assigned to all tokens of this segment. It is reasonable to assume that segments have positive lengths, and the segment s i satisfies 0  X   X  i &lt;  X  i  X  p and  X  i +1 =  X  i + 1. s essentially mod-els entity candidates, and each segment s i can be an entity or a non-entity. Without loss of generality, let e m and e ( e m ,e n  X  s ) be two arbitrary entities in the sequence x , and r mn be the relation assignment between them. r is the set of relation assignments of all entity pairs in sequence x . r al-lows a variety of relations and dependencies, and it is built upon the segmentation s which models entity candidates. Note that the definitions of s and r are general and there-fore can be applied to a variety of IE tasks. For example, e m and e n can be entity candidates from segments or entire observation sequences. r mn can be a semantic relation (e.g., employer ) between entity candidates or the boolean corefer-ence variable indicating whether or not two sequences (e.g., paper citations) are referring to each other. r mn can also be an author community or a friendship relation in a social Web.

Based on the preliminaries and notations, we define the concepts of segmentation and relation discovery as follows.
Definition 1. ( Segmentation ). Given an observation sequence x , segmentation is the task of assigning segments s to x such that s  X  = arg max s P ( s | x ) .

Definition 2. ( Relation Discovery ). For a segmen-tation s of sequence x , relation discovery is the process of extracting and discovering relation r between pairs of entity candidates from s such that r  X  = arg max r P ( r | s , x ) .
Let y = { r , s } be the pair of segmentation s and relation r . y must satisfy the condition that both the assignments of the segments and the assignments of the relations of segments are maximized simultaneously. We now formally define the problem of joint information extraction as follows. Definition 3. ( Joint Optimization of Information Extraction ). Given an observation sequence x , the goal of joint information extraction is to find the assignment y  X  = { r  X  , s  X  } that has the maximum a posteriori (MAP) probability where r  X  and s  X  denote the most likely relation assignment and segmentation assignment, respectively.

Note that this definition is different from pipeline mod-els which perform segmentation and relation in sequential order without capturing interactions between them. This problem is more challenging, and offers new opportunities for information extraction.
Following the notations in Section 2, we define a joint con-ditional distribution based on discriminatively-trained fac-tor graphs. Let G be a factor graph [7] defining a probabil-ity distribution over a set of output variables o conditioned on observation sequences x . {  X  i } is a set of factors in G , where each factor is defined as the exponential family of an inner product over sufficient statistics { f ik ( x i , o responding parameters  X  ik as  X  i = exp { P k  X  ik f ik ( x [8, 18]. Using parameter tying, the nature of our modeling enables us to partition the factors of G into three groups, namely the segmentation factor, the relation factor, and the segmentation-relation joint factor. Each factor is a clique template whose parameters are tied. In the following we describe these factors in detail. As we will see, this model-ing offers a natural formalism for exploiting top-down and bottom-up bidirectional dependencies and interactions be-tween relevant subtasks to capture mutual benefits, as well as a great flexibility to incorporate a large collection of ar-bitrary, overlapping and nonindependent features.

Segmentation factor . The segmentation factor  X  S ( i, s , x ) models segmentations s in x . We assume that  X  S ( i, s , x ) fac-torizes according to a set of feature functions g k ( i, s , x ) and a corresponding set of real-valued weights  X  k as where K is the number of feature functions. To effectively capture properties of segmentation, we relax the first-order Markov assumption to semi-Markov [14] such that each seg-ment feature function g k (  X  ) depends on the current seg-ment s i , the previous segment s i  X  1 , and the whole obser-vation sequence x , that is, g k ( i, s , x ) = g k ( s g ( y i  X  1 ,y i , X  i , X  i , x ). In addition, transitions within a seg-ment can be non-Markovian.

Relation factor . The relation factor  X  R ( e m ,e n models relations r mn r mn  X  r between all possible entity candidate pairs ( e m ,e n ), e m ,e n  X  s ,m 6 = n in observation sequence x . Similar to the segmentation factor, the relation factor is written as where W is the number of features, f w ( e m ,e n ,r mn ) are fea-ture functions, and  X  w are corresponding weights. The factor  X  ( e m ,e n ,r mn ) represents dependencies (e.g., long-distance dependencies, relation transitivity, etc.) between any two entity candidates e m and e n . For example, if the same en-tity is mentioned more than once in an observation sequence, all occurrences probably have the same relation to another entity. Using the relation factor  X  R ( e m ,e n ,r mn ), evidences for the same entity segments (or entity candidates) to an-other entity are shared among all their occurrences within the observation sequence.

Segmentation-relation joint factor . Both of segmen-tation and relation factors are local , since they do not take into account dependencies between relevant subtasks. We propose a global factor, the segmentation-relation joint fac-tor, to capture both segmentation-to-relation (bottom-up) and relation-to-segmentation (top-down) dependencies. This joint factor  X  SRJ ( s , r , x ) involves both segmentation and re-lation hypotheses as its input. It captures the rich and com-plex interactions between segmentations and relations bidi-rectionally, which is defined as  X 
SRJ ( s , r , x ) = exp
The newly introduced feature function q t ( s i  X  1 ,s i , r , x ) ex-ploits relation-to-segmentation (top-down) dependencies, which uses relation hypotheses r between different segments for segmentation of observation sequence x . Intuitively, know-ing the relation between two entity segments is very helpful for segmentation and entity identification. For example, the employment relation can only exist between an organization and a person , and cannot exist between an organization and a location , or a location and a person ). On the other hand, the function h t ( e m ,e n ,r mn , s , x ) captures segmentation-to-relation (bottom-up) interactions, which uses segmentation information s for relation discovery. For example, if two segments are labeled as a location and a person , the seman-tic relation between them can be birth place or visited , but cannot be employment .  X  t and  X  t are the corresponding real-valued weights for q t (  X  ) and h t (  X  ), respectively, and T is the number of features. Notably, this joint factor captures bidirectional interactions and mutual benefits between seg-mentations and relations. Such dependencies are crucial and modeling them often leads to improved performance.
 According to the celebrated Hammersley-Clifford theo-Figure 2: Graphical representation of the proposed model consisting of a bidirectional structure. The segmentation-relation joint factor enables both top-down and bottom-up connections with relation and segmentation factors to explore tight dependencies and mutual benefits for multiple subtasks. rem, the joint conditional distribution P ( y | x ) = P ( { r , s }| x ) is factorized as a product of potential functions over cliques in the graph G as the form of an exponential family: P ( y | x ) = 1 where M is the number of arbitrary entity segments in the observation sequence x , | s | is the number of segments of x , Q m,n  X  SRJ ( s , r , x ) is the normalization factor of our model.
In summary, our model consists of three sub-structures: (1) a semi-Markov chain on the segmentations s conditioned on the observation sequences x , represented by  X  S ( i, s , x ); (2) potential  X  R ( e m ,e n ,r mn ) measuring dependencies and relations r mn between two arbitrary entity candidates e and e n from segmentations s ; and (3) a fully-connected graph exploiting tight dependencies between segmentations s and relations r , represented by  X  SRJ ( s , r , x ). It is par-ticularly notable that our model has a dynamic graphical structure. Since the segments (entity candidates) from the semi-Markov chains are dynamically changed, the structure of relation factor will change correspondingly given different segmentations. Moreover, different structures of the rela-tion factor will also have influence on segmentations. This is different from the conventional semi-CRFs [14].

While some special cases of CRFs are of particular inter-est, several major elements make our model different. We emphasize on the differences and advantages of our model against others. Most importantly, our model captures bidi-rectional top-down and bottom-up dependencies between multiple subtasks for joint IE problems. Linear-chain CRFs [8] and semi-CRFs [14] can only perform single IE tasks such as sequence labeling, which lack the ability to capture long-distance dependencies and to represent complex inter-actions between multiple subtasks. Skip-chain CRFs [17] introduce skip edges to model long-distance dependencies to handle the label consistency problem in single sequence labeling and extraction. 2D CRFs [28] are two-dimensional conditional random fields incorporating the two-dimensional neighborhood dependencies in Web pages, and the graphical representation of this model is a 2D grid. Hierarchical CRFs [9] are a class of CRFs with hierarchical tree structure. Our proposed model, on the other hand, has a distinct graphical structure from 2D and hierarchical CRFs. By modeling both segmentations s and relations r simultaneously in a single coherent framework, this paradigm offers a natural way for joint information extraction, avoiding the problems such as error propagation occurred in pipeline approaches. Further-more, this modeling has several advantages over previous probabilistic graphical models, including the employment of semi-Markov chains for efficient segmentation and labeling, the representation of long-range dependencies between dif-ferent segments, and the capture of rich and complex inter-actions between relevant subtasks to exploit mutual benefits.
Given independent and identically distributed (i.i.d.) train-ing data D = { x i , y i } N i =1 , where x i is the i -th sequence in-stance, and y i = { r i , s i } is the corresponding segmentation and relation assignments. The objective of parameter esti-mation is to estimate the whole set of model X  X  parameters assumption, we ignore the summation operator P N i =1 the log-likelihood during the following equations and deriva-tions. We would like to maximize the log-likelihood of the observation given the data:
The above function does not have a closed-form solution because of the marginalization taking place within the log-arithm. Working directly with this function is typically precluded by the need to compute the normalization fac-tor Z ( x ), which is intractable in our model. We exploit variational approximation methods [5, 20] that offer guar-antees in the form of a lower bound on the marginal prob-abilities. This family of approaches aims to minimize the Kullback-Leibler (KL) divergence between an approximated distribution Q and the target distribution P  X  ( s , r | x ) by find-ing the best distribution Q from some family of distributions for which an inference is feasible. The variational inference method provides a fast, deterministic approximation to oth-erwise unattainable posteriors. Also its convergence time is independent of dimensionality [20].

Let Q  X  ( s , r | x ) be the variational distribution which serves as an approximation of the target distribution P  X  ( s , r | x ). According to the mean-field variational theory [5, 21, 4], the optimal solution is the distribution that has the minimum KL divergence between two distributions Q and P . Based on Jensen X  X  inequality we have
As can be seen, Equation 7 is the same as maximizing a lower bound on the log-marginal probability P  X  ( x ), with the following formulation:
According to Equations 7 and 8, optimizing a variational bound on the observed data is equivalent to minimizing the equivalent to minimizing the KL divergence between the dis-the non-negativity property of the KL divergence, the cost function we work is
L = KL ( Q  X  ( s , r | x ) || P  X  ( s , r , x )) tropy of the variational distribution, and E Q  X  n log P  X  spect to Q  X  ( s , r | x ). Notice that the cost L balances two competing goals: assign values to variables r and s with high probability under P  X  ( s , r , x ) (the second term), but at the same time be as less committed as possible (the entropy term). Clearly, L is the lower bound of the log-likelihood L ( X ). Thus by maximizing L we will always recover the log-likelihood of the data L  X  = log P  X  ( x )  X  0.
For efficient learning, it is critical that the variational fam-ily of distributions Q  X  has a tractable form [5, 4]. In the fol-lowing, we use Q  X  ( s , r ) to denote Q  X  ( s , r | x ). According to the mean-field variational theory, we assume that Q  X  ( s , r ) forms a factorized distribution; that is, the variables are in-dependent and the joint distribution is a product of single variable marginal probabilities as where s = { s i } i  X  V s and r = { r j } j  X  V r . Let P torize into a product of pairwise potentials depending only on the variables associated with each undirected edge as P ( s , r , x ) = Q e  X  E  X ( s e , r e , x e ). Mean-field inference algo-rithms exploit this additional factorization structure. Note that we absorb the normalization constant into one of the potentials. The cost function L reduces to a sum of the following terms as where Q  X  ( y e  X  V ) is the variational marginal probability over variables y = { r , s } associated with edge e and V s  X  V
To optimize the function L , let E Q  X  { X | y k } k  X  V be the conditional expectation with respect to Q  X  . We provide a more explicit illustration and the feasibility of evaluating  X  { X | y k } in the updates as
E Q  X  { log P  X  ( s , r , x ) | y k } where V \ k is the set of variables other than k and Q  X i Q  X i ( s i ) Q  X i ( r i ). Note that the expectation specifically does not depend on the variational marginal Q  X k (  X  ) over y k result is a function of the conditional variable y k .
To update the k th variational marginal, we view L as a function of Q  X k (  X  ) while keeping other marginals fixed. We treat the entropy terms H ( Q  X  ) corresponding to remaining marginals as fixed and appeal to the linearity of expectation  X  { X } = P y k Q  X k ( y k ) E Q  X  { X | y k } to obtain where the dependence of L on the marginal Q  X k ( y k ) is ex-plicit. It is easy to verify via straightforward calculation that maximizing this cost function with respect to the marginal Q  X k ( y k ) yields the following mean field equations for all k as:
Obviously, Q  X k ( y k ) is in the form of the exponential fam-ily. This property considerably simplifies the complexity and facilitates the computation. Recall that Q  X  ( s , r ) = Q ( s ) Q  X  ( r ) = Q i  X  V we further assume Q  X  ( s ) to be of the form 1 Z and Q  X  ( r ) to be 1 Z two local normalization factors. Here, we introduce two vari-ational parameters  X  = {  X  i } i  X  V s and  X  = {  X  j } j  X  V  X  and  X  are associated with segmentation and relation, re-spectively, and we rewrite L as L (  X , X  ).

We propose a bidirectional learning algorithm based on variational expectation maximization (VEM) to optimize the variational parameters  X  and  X  efficiently in a collabora-tive manner such that they can benefit from each other. For example, if we have trained segmentation parameter  X  , its decision can guide the learning for relation parameter  X  . As shown in Algorithm 1, we summarize the whole parameter estimation procedure as follows: in the E-step, we maximize the variational distributions Q  X k ( y k ), which is accomplished by computing E Q  X  { log P  X  ( s , r , x ) | y k } based on Equations 15 and 16, and by updating Q  X k ( y k ) based on Equations 18 and 19. After we calculate the cost function L (  X , X  ) based on Equation 17, we perform bottom-up learning to opti-mize the relation parameter  X  using the hypotheses from segmentations. Here we keep the segmentation parameter  X  fixed. In the M-step, we perform top-down learning to opti-mize the segmentation parameter  X  using hypotheses from relations while keeping Q  X k ( y k ) fixed. Such iterative opti-mization allows information to flow bidirectionally to boost
Algorithm 1: The variational expectation maximiza-tion (VEM) algorithm for bidirectional top-down and bottom-up learning
Input : A set of pairwise potentials  X ( s e , r e , x e )
Output : Optimized variational parameters  X   X  and  X   X  while equilibrium states or a threshold number of iterations are not reached do end return  X   X  and  X   X  both the segmentation and relation performance. This two-step max-max algorithm leads to a monotonically increasing cost function L (  X , X  ) and log-likelihood of data. Conse-quently, it is guaranteed to converge to an equilibrium state of the KL divergence between Q and P among all distri-butions Q of the given form Q  X  ( s ) = 1 Z and Q  X  ( r ) = 1 Z gorithm is theoretically sound and correct. Moreover, the variational formulation remains applicable even when we can no longer handle log P  X  ( s , r , x ), this is superior to the con-ventional EM algorithm.
We now investigate and analyze the computational com-plexity of Algorithm 1. Suppose | V | is the number of seg-mentation and relation variables, and d is the number of distinct values each variable (either s or r ) may take. In Equation 17, the evaluation of the first summation term H ( Q  X k ( y k )) takes O ( | V | d ). For computing E Q  X  { log P in the second term of Equation 17, e  X  X  V \ k } is either an empty set or a single node associated with edge e , where each expectation involves at most two variables and there are | E | edges, thus the complexity will be at most O ( | E | d For Algorithm 1, suppose the iteration number is I , then the overall computational complexity is O (( | V | d + | E | d
Ideally, the objective of inference is to find the most likely segmentation assignment s  X  and the corresponding most likely relation assignment r  X  , that is, to find y  X  = arg max y such that both of them are optimized simultaneously. Un-fortunately, exact inference to this problem is generally in-tractable, since the search space is the Cartesian product identification from Wikipedia.
 of all possible segmentation and relation assignments. Con-sequently, approximate inference becomes an inevitable al-ternative. At the equilibrium state of Algorithm 1, varia-tional distributions Q  X  ( s ) and Q  X  ( r ) are obtained such that Q ( s , r ) = Q  X  ( s ) Q  X  ( r ) is an equilibrium state of the KL divergence KL ( Q || P ). Such kind of inference is straightfor-ward, since the maximum a posterior (MAP) segmentation assignment s is constructed from the optimized variational parameter  X   X  , and the MAP or most likely relation assign-ment r is found from the variational parameter  X   X  .
Our dataset consists of 1,127 paragraphs from 441 pages from the online encyclopedic articles in Wikipedia. The la-beled 7,740 entities are classified into 8 categories, yield-ing 1,243 person , 1,085 location , 875 organization , 641 date , 1,495 year , 38 time , 59 number , and 2,304 miscellaneous names. This dataset also contains 4,701 relation instances and 53 labeled relation types, and the 10 most frequent relation types are job title , visited , birth place , associate , birth year , member of , birth day , opus , death year , and death day . The 8 entity categories and 53 relation types are label sets for entity identification and relation extraction in our model. All experiments were performed on the Linux platform, with a 3.2GHz Pentium 4 CPU and 4 GB of memory.

Accurate entities enable features that are naturally ex-pected to be useful to boost relation extraction. A wide range of rich, overlapping features can be exploited in our model. These features include contextual features, part-of-speech tags, morphological features, entity-level dictionary features, and clue word features. Feature conjunctions are also used. In leveraging relation extraction to improve en-tity identification, we employ a combination of syntactic, entity, keyword, semantic, and Wikipedia characteristic fea-tures. More importantly, our model introduces joint factors to capture both top-down and bottom-up dependencies, and function q t (  X  ) uses relation hypotheses and h t (  X  ) uses seg-mentation hypotheses as features. These features capture deep dependencies between entities and relations, and they are natural and effective in enhancing the performance.
We perform four-fold cross-validation on this dataset, and take the average performance. For performance evaluation, we use the standard measures of Precision ( P ), Recall ( R ), and F  X  =1 ( F  X  =1 is the harmonic mean of P and R and F  X  =1 = 2 PR P + R ) for both entity identification and relation ex-traction. We compare our approach with one pipeline model CRF + CRF , one integrated model Single MLN , and one Table 2: Comparative performance of different mod-els for relation extraction from Wikipedia.
 Table 3: Performance comparison with other top-performing systems on relation extraction.
 joint model DCRF . CRF + CRF employs one linear-chain CRFs [8] for entity recognition, and another linear-chain CRF for relation prediction. Single MLN performs joint inference for both subtasks in a single Markov logic network (MLN) [12], which is a highly expressive language for first-order logic and can conduct relational learning between en-tity pairs. DCRF [19] is a factorial CRF applied to jointly solve the two subtasks. All these models exploit standard parameter learning and inference algorithms in our exper-iments. To avoid over-fitting, penalization techniques on likelihood are also performed. Table 1 shows the performance of entity identification and Table 2 shows the overall performance of relation extraction of different models, respectively. For relation extraction in Table 2, we also recorded the token-wise labeling accuracy. Our model substantially outperforms all baseline models on F-measure for both entity identification and relation extrac-tion, and it is statistically significantly better ( p -value &lt; 0.05 with a 95% confidence interval) according to McNemar X  X  paired tests. The pipeline model CRF + CRF suffers from pipeline inherent inferiority such as brittle accumulation of errors. For example, this model cannot correctly extract relations between mis-recognized entities. As discussed, it performs entity identification and relation extraction inde-pendently without considering the mutual correlations be-tween them, leading to reduced performance. By model-ing interactions between two subtasks, boosted performance can be achieved, as illustrated by the integrated model Sin-gle MLN and the joint model DCRF . The Single MLN model captures dependencies between entities and relations via first-order logic; however, limitations of first-order logic
Due to space limitation, we only present the overall perfor-mance, and omit the performance on 53 relation types. make it difficult to specify a relation factor that utilizes the uncertain output of segmentation [15, 22]. Joint inference in Single MLN is only weakly coupled and does not enforce transitivity, since the logic formulas only examine pairs of consecutive labels, not whole fields. As can be seen, our model achieves stronger interactions between two subtasks, which is strongly coupled and bidirectional. The DCRF model applies loopy belief propagation (LBP) for approx-imate learning and inference, which is inherently unstable and may cause convergence problems. Consequently, train-ing a DCRF model with unobserved nodes (hidden vari-ables) makes this approach difficult to optimize. Figure 3 illustrates an example of identified entities and extracted semantic relationships from Wikipedia X  X  encyclopedic arti-cle about Bill Gates by employing our model. As can be seen, different entity types are in different colors, and the relations between them are also linked and labeled. Inter-estingly, these results are versatile for a variety of applica-tions, such as Web data mining, social network analysis and mining, etc.

A large number of engineered systems were developed for identifying relations of interest. Table 3 compares our results with some recently published results on the same dataset. Notably, our approach outperforms previous ones given that we deal with a fairly more challenging problem involving both entity identification and relation extraction. Similar to [13], these systems assume that the golden-standard entities are already known or extracted from text without errors, and they only perform relation extraction (due to this reason, we only compare the performance on relation extraction.). Unfortunately, such assumption is not valid in practice. As a result, our model is more applicable to real-world IE tasks.
We investigate the nature and effectiveness of segmentation-relation joint factors and Figure 4 demonstrates their feasi-bility in our modeling. It shows that the joint factors con-sistently enhance precision, recall, and F-measure for both entity identification and relation extraction subtasks. For example, the joint factors significantly improve the overall F-measure by 2.65% for entity identification. Our approach demonstrates its merits by using joint factors to explore bidi-rectional tight interactions between segmentations and rela-tions and by optimizing them collaboratively in a top-down and bottom-up manner, resulting in improved performance.
Table 4 summarizes the efficiency of different models. The pipeline CRF + CRF takes the least time for learning, due to its simple pipeline architecture. Compared to Single MLN , the running time of our model is only increased slightly, which is reasonable to apply to real IE problems. It is particularly notable that our model takes much less Table 4: Efficiency comparison of different models on learning time (min.) and inference time (min.). time than the joint model DCRF . Specifically, our model is over an order of magnitude (approximately 17.5 times) faster than DCRF for running. When the graph has large tree-width as in our case, the LBP algorithm in DCRF is inefficient and slow to converge.
We apply the Cora dataset to evaluate our approach. This dataset contains 1295 citations and 134 clusters (sets of ci-tations that refer to the same paper), and each citation has three fields  X  author , title , and venue . We run three-fold cross-validation on this dataset. Segmentation is evaluated by P, R, and F 1 . For entity resolution, we measure both pairwise P, R, F 1 and cluster recall. Cluster recall is the fraction of clusters that are correctly output by the system after taking transitive closure from pairwise decisions.
A wide range of rich features can be exploited in our model. For segmentation, these features largely consider field-level similarity using a number of string and token-based comparison metrics (e.g., string edit distance, tf-idf over tokens and n -grams, etc.). We also include feature con-junctions, specialized features for author and title matching, and global features based on distance metrics for entire ci-tations. In leveraging coreference to improve segmentation, we employ a combination of local (e.g., contextual and mor-phological), layout, lexicon membership features.

For performance comparison, the CRF + CRF model ap-plies first CRF for segmentation, and another CRF for entity resolution (which views resolution as a pairwise classifica-tion problem). For the Single MLN model, we follow [12] to design it, engaging features mentioned above. Moreover, we also compare the performance of our model with some recently published results on the same dataset.
Our comparative results are shown in Table 5 and Table 6, demonstrating the promise of our approach with significant improvements on both segmentation and coreference com-pared with the three baseline models CRF + CRF , Single MLN , DCRF , and other previously published results.
Table 5 shows the improvements on F-measure for seg-mentation, where we list both the overall performance and Figure 4: Performance comparison of joint factors on entity identification (left) and relation extraction (right) from Wikipedia.
 Table 5: Comparative performance of different mod-els for segmentation in citation matching.
 the performance on the three fields. Our model outper-forms earlier results such as Isolated MLN [12] and Single MLN [12]. Compared to the three baseline models, the rel-ative error reduction (RER) is 41.45%, 13.84% and 11.68%, respectively. Note that the difference between our Single MLN model and the one in [12] is that we engage different features. Table 6 compares the performance of entity reso-lution for different models on both metrics of F 1 and cluster recall. Our model, which concurrently solves the citation matching task, easily outperforms previously published re-sults in [16] and [12]. It also outperforms the three baseline models by 3.30%, 1.15%, and 0.88% in pairwise F 1 . Even though the Single MLN model in [12] captures interactions between segmentation and coreference, it is only a weak in-teraction. Since the logic formulae in [12] only examine pairs of consecutive labels but not whole fields  X  failing to utilize information from predicted field range and non-consecutive words in the field. As can be seen, our model is highly-coupled and achieves stronger interaction between multiple subtasks. Importantly, Table 6 shows that our approach al-lows cluster recall to improve substantially, resulting in an improvement of up to 6.83% compared to DCRF model. This is particularly notable given that cluster recall is more strict than the pairwise F 1 metric.
Figure 5 illustrates the benefits of the joint factors in our modeling for citation matching. This figure demonstrates the bidirectionality of joint factors using segmentation to aid coreference and vice versa, which is highly coupled and information can flow in both directions to capture mutual benefits and strong interactions between segmentation and resolution. Compared to the pairwise F-measure, the cluster recall is boosted substantially (up to 5.65%) by joint factors. This is particularly interesting as it shows that exploiting joint factors is much more accurate under the strict metric.
Table 7 lists the running times (for both training and in-ference) for CRF + CRF , Single MLN , DCRF , and our Figure 5: Performance comparison of joint factors on segmentation (left) and entity resolution (right) in citation matching.
 Table 6: Comparative performance of different mod-els for entity resolution in citation matching.
 model (we cannot compare it with the models in [16] and [12] since experimental settings are different). The running time of our model is reasonably slower than that of the pipeline model CRF + CRF , and comparable to that of Sin-gle MLN , illustrating the efficiency of our approach. How-ever, the DCRF model takes 458.83 minutes to converge, which is very slow. This disadvantage limits the ability of DCRF for real-world IE problems to a large extent.
Some work has been dedicated to improving the pipeline architecture [2, 3]. Finkel et al.[2] modeled pipelines as Bayesian networks, with each low level task corresponding to a variable in the network. This architecture has the draw-back that it only allows information to flow in one direction. Hollingshead and Roark [3] proposed pipeline iteration, us-ing output from later stages of a pipeline to constrain ear-lier stages of the same pipeline, but it lacks the ability to model internal tight dependencies between stages. However, all these approaches suffer from inherent problems such as brittle accumulation of errors caused by their pipeline archi-tecture.

Integrated and joint models exploring mutual benefits on different subtasks have shown great promise, where several closely related approaches have been proposed. Recently, Zhu et al. [30] proposed an integrated probabilistic approach to Web page understanding. Nevertheless, this model is feed-forward or top-down integrated and it only allows infor-mation to flow in one direction. Ko et al. [6] proposed a joint answer ranking framework based on probabilistic graphical models for question answering. However, they employed N -best list for inference procedure which is a restricted ap-proximation for the full distribution of large-output compo-nents. Thus, the number of uncertain hypotheses in their framework is severely limited. Yu et al.[27] integrated two sub-models, semi-CRFs and MLNs, together, but they are only loosely coupled in that the parameter estimation is per-formed separately and the inference information can only flow in one direction, which is similar to [2]. Luo et al. [10] Table 7: Efficiency comparison of different models on learning time (min.) and inference time (min.). combined Web classification and Web IE based on the CRF model. However, since it was defined according to the DOM tree structure for Web pages, this model cannot be applied to more general tasks that we are investigating.

Furthermore, Poon and Domingos [12] performed joint in-ference in a single MLN to citation matching, and Sutton et al.[19] proposed dynamic CRFs to jointly solve part-of-speech tagging and NP chunking tasks. As shown in our experiments, limitations of first-order logic make the model in [12] only loosely coupled. On the other hand, the dy-namic CRF model in [19] includes complex graphical struc-ture and high computational complexity, which may cause convergence problems. Our proposed model is highly cou-pled and bidirectional, and considerably outperforms both of them.
We presented a strongly-coupled, bidirectional approach to the problem of joint information extraction. We intro-duced joint factors to capture top-down and bottom-up bidi-rectional tight correlations and dependencies between sub-tasks, and we proposed a learning algorithm based on VEM to perform parameter estimation approximately in a top-down and bottom-up manner. This algorithm allows in-formation to flow in both directions and explores mutual benefits from multiple subtasks. Experimental results on two real-world datasets exhibit that our model significantly outperforms recent state-of-the-art pipeline, integrated and joint models while also running much faster than the joint models. Several interesting issues, such as the effect of joint factors on performance and the efficiency of our approach are analyzed and discussed as well. This approach allows extensive further investigation, both for parameter learning and inference. We also plan to apply and test our model to other real-world IE applications.
