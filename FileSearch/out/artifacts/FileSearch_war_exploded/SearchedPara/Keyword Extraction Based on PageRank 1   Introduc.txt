 Keyword extraction is an important technology in many areas of document whole text [4]. A most popular algorithm for keyword extraction is tfidf measure, which extracts keywords that appear frequently in a document while seldom in the remainder documents of the corpus [2]. But tfidf measure has two disadvantages: Sometimes, there is no corpus for computing idf . Synonym X  X  tf is viewed independent and may decrease the precision. 
This paper presents a new algorithm that represents the text as a semantic graph with synset from WordNet, disambiguates the words, and finally extracts keywords from the text based on UW-PageRank. It needs no corpus, has the ability to disambiguate all the words in the text, and extracts keywords by analyzing the semantic structure of the whole text. The experiment result shows that our algorithm is effective and practical. PageRank is an algorithm of deciding the importance of vertices in a graph. WordNet can be viewed as an undirected weighted graph, which defines synsets as vertices and connected synsets. For PageRank formula is defined for directed graph, a modified PageRank formula is applied to use on the undirected weighted graph from WordNet. 2.1 PageRank PageRank [5] which is widely used by search engines for ranking web pages based on importance of vertices within a graph. The ma in idea is that: in a directed graph, when votes one vertex gets, the more important this vertex is. PageRank also takes account the voter: the more important the voter is, the more important the vote itself is. In one word, the score associated with a vertex is determined based on the votes that are cast for it, and the score of the vertex casting these votes. So this is the definition: Let G=(V,E) be a directed graph with the set of vertices V and set of edges E , when vertex V i is d is a damping factor that can be set between 0 and 1,and usually set at 0.85 which is the value we use in this paper [5]. 
PageRank starts from arbitrary values as signed to each vertex in the graph, and ends when the convergence below a given threshold is achieved. Experiments proved that it usually stops computing within 30 iterations [6]. 
PageRank can be also applied on undirected graph, in which case the out-degree of a vertex is equal to the in-degree of the vertex. 2.2 WordNet as Semantic Networks adverbs are organized into synonym sets or synsets related by defined relations such as hypernymy/ hyponymy and holonymy / meronymy. 2.2.1 The Relatedness of Sense Glosses of synset meanings in WordNet and the networked arrangement of synsets are both utilized as sources to determine the relatedness of a pair of synsets. Lesk [7], [11], Wu &amp; Palmer[12], Leacock &amp; Chodorow [13] computed the relatedness of two senses based on the structure of WordNet. 2.2.2 PageRank on WordNet WordNet can be represented as a graph, in which synsets are defined as vertices, and relations of synsets are defined as edges. The graph can be constructed as an undirected graph. The edges can be weighted by the  X  X trength X  of the connection between two vertices, i.e. synsets, and computed by the measures of semantic relatedness. We applied PageRank on the undirected weighted graph from WordNet with a modified formula PageRank. WordNet form the vertices of the graph and the relations are the edges of the graph. At that time, one word usually has more than one corresponding vertices in the graph, by deleting all the other vertices and their connected edges, one word corresponds to one synset and its corresponding vertex is left in the graph. Finally, we use UW-corresponding words in the text are the keywords. 3.1 Text Representation as a Graph To use PageRank algorithm to exact keyword of the text, a graph which represents the made a hypothesis that  X  X he same word in a text segment has the same sense X , which is proved to be acceptable in our experiment s in Section 4. All the words in the text WordNet with its POS. Synsets form the vertices of the graph. Edges are added between the vertices which have a relation in WordNet between them. The weights of the edges which represent the relatedness of two synsets can be computed by the algorithm of Pedersen introduced in Section 2.2.1. 
There is a special situation wh ile building the graph, that co-lexical synsets which is defined as synsets that represent senses of the same word, have a relation defined in WordNet [14]. Co-lexical synsets are competing for one word. Therefore, only one of the co-lexical synsets is the  X  X orrect X  one to be left and the others are all noise. So no edges would be added between co-lexical synsets. 
Assumed that a text containing  X  word1 word2 word3  X  is to be represented in a graph. Word1 has three synsets defined in WordNet which are S1, S2 and S3 represented in graph; Word2 has one synset S4 and Word3 has two, S5 and S6. None co-lexical synsets are linked together with the weight of relatedness. For example, S1 and S4 are connected with an edge weighted 0.2. The graph represented the text is in Fig.1(a). 3.2 Word Sense Disambiguation Based on PageRank The ambiguity problem is reflected in our model as extra senses pertaining to co-synset for each word, thus leave the vertices pertaining to the exclusive synset in the graph while deleting all the others. Th ere are two disambiguation approaches: knowledge-based and corpus-based methods [15]. Knowledge-based method disambiguates words by matching context with information from a prescribed knowledge source, such as WordNet. Agirre and Figau [16] present a method for the resolution of the lexical ambiguity of nouns using the WordNet noun taxonomy and domain information in word sense disambiguation using WordNet. Mihealcea [14,18] use a PageRank-style algorithm applied on a WordNet-based concepts graph to do word sense disambiguation for free text. 
We use UW-PageRank (Formula (2)) to score all the vertices in synset graph built from the text based on WordNet. The higher score one vertex (synset) gets, the more important it is in the graph, therefore more likely the word tends to choose the vertex, i.e. synset. The UW-PageRank score of synsets in Fig.1 is as following. 
Co-reference sense and the serial number of the sense defined in WordNet are also taken into consideration while assign a sens e to a word as well as the UW-PageRank words from the text (recall that different wo rd shapes from the same word are viewed as exactly the same word). For example,  X  X  ask X  pertains 2 senses, and  X  X ob X  pertains 13. For job#2 and task#2 are the same sense  X  X 00708623} X  X  specific piece of work repaired to be done as a duty or for a specific fee X . If word  X  X ask X  and word  X  X ob X  are both in the text, sense {00708623} is the co-reference sense of word  X  X ask X  and  X  X ob X . If other conditions of this sense and other sense pertaining to the word are the similar, this sense should have more chance to be assigned to the word  X  X ask X  and  X  X ob X . Yet this aspect of the sense can not be reflected in the structure of the group, so additional priority should be taken into consider for this situation. 
WordNet makes a statistical comparison of different sense of the same word on a Therefore, words trend to choose more frequent sense as its correct sense. 
Our algorithm combines UW-PageRank score, co-reference sense priority and the frequency priority together, and gives an in tegrated evaluation to each sense. For each word in the text, it will choose the sense having the highest score as its correct synset. Words of graph in Fig.1 are disambiguated that Word1 has the sense of S1, Word2 has S4 and Word3 has S5. So the graph is pruned to Fig.1(b). 3.3 Keyword Extraction Based on UW-PageRank  X  X rong X  vertices bonding to the  X  X rong X  sense and the edges connecting to them. Therefore, there are only vertices bonding to chosen sense and original edges between them in the graph. Consequently, the word, sense and the vertex forms a many-one-one relation. Recall that the essential meaning of UW-PageRank algorithm is to judge the importance of vertices in a graph, so we use UW-PageRank on the pruned have higher UW-PageRank score is considered to be more important in the graph, so the sense bonding to the vertex is considered to be more important in the text. We can defined threshold. Actually, UW-PageRank finds the most important sense of the text, however there may be more than one words bonding to the sense and these words are all synonymous words, so we just choose the most frequent one of them as the keyword. The UW-PageRank score of the synset vertices in Fig.2 is in Table 2. least. The importance serial of the words in text is Word3 , Word1 and Word2 . the words in the document. The performance of word sense disambiguation is tested on SemCor 2.1, which contains 186 documents containing more than 2000 words for each document. Words in the documents are manually annotated with part-of-speech and corresponding senses in WordNet. 
The hypothesis that  X  X he same word in a text segment has the same sense X  is tested with a definition of word-sense-uniform-ratio. word sense uniform ratio segment, and get the word-sense-uniform-ratio. 
Word-sense-uniform-ratio gets lower while the text segment unit gets larger. But even the lowest ratio still could be accepted. So we can accept the hypothesis at any text segment unit from above. 
Our word sense disambiguation algorithm is tested on SemCor2.1. We choose sentence, paragraph and whole text as text segment units to build the semantic graph. Each word is POS tagged and found in WordNet2.1 to get all the senses. If one word can not be found in WordNet2.1, usually is a new word, we just have to discard it. All with the most frequent sense in WordNet and take this performance as the baseline. 
Paragraph as text segment unit gets the highest precision, and  X  X hole text X  gets unit is too large, there are too many irrelevant words and senses involved in the graph, there are not enough words and senses to build a compact graph, therefore the computation of UW-PageRank is not reliable. From the result, we can see that the paragraph as a unit is just suitable for word sense disambiguation, for there are several suitable scale of semantic graph. 
Keywords are attached to the content of th e text; however they are not defined in a consistent way. Therefore, we used author-based evaluation. Fifty technical papers Research) are involved in the experiments as test corpus for keyword extraction evaluation. We choose 5 of the keywords (just words, no phrase) assigned by the words from the paper. As a comparison, tf is also used to extract keywords. Elimination of stop words and stemming are processed ahead and 10 most frequent correct keyword divided by the number of extracted words .Precision has a limitation result of the number of correct keyword divided by the number of keywords the author has assigned. 
Results are shown in Table 5. tf selects terms which appear frequently in a document, however there are many synonyms in the document and tf views these disambiguating each word, synonyms X  term frequencies are added together and the coverage and precision both increase, which proves that our algorithm for word sense document, transforms the document form a string of characters into a sequence of words, and assumes the words is independent. While UW-PageRank represents a text as semantic graph with synset from WordNet, disambiguates all the words in the text, decides the importance of vertices within the semantic graph, and regards those top  X  X  X  important vertices as keywords. Therefore, UW-PageRank can detect some  X  X idden X  keywords even if they do not appear frequently, which are not been extracted by tf. whole text. This paper proposed a keyword extraction algorithm based on WordNet graph based on WordNet which defines synsets as vertices and relations of vertices as edges, and assigns the weight of edges with the relatedness of connected synsets. The second step is to disambiguate words re ferring to UW-PageRank score, co-reference sense priority and the frequency priority. Then, graph is pruned leaving only the vertices in the graph, and the corresponding words are assigned as the keywords. Our algorithm is tested on SemCor2.1 and corpus of CISTR, and the experiment results proves our algorithm to be practical and effective. This study is supported by National Natural Science Foundation of China (60575034). 
