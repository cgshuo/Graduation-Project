 { bangpeng,feifeili } @cs.stanford.edu { walther,dmbeck } @illinois.edu In recent years, machine learning approaches for analyzing fMRI data have become increasingly popular [15, 24, 18, 16]. In these multi-voxel pattern analysis (MVPA) approaches, patterns of voxels are associated with particular stimuli, leading to verifiable predictions about independent test data. Voxels are extracted from previously known regions of interest (ROIs) [15, 31], selected from the brain by some statistical criterion [24], or defined by a sliding window ( X  X earchlight X ) positioned at each location in the brain in turn [20]. All of these methods, however, ignore the highly interconnected nature of the brain.
 Neuroanatomical evidence from macaque monkeys [10] indicates that brain regions involved in visual processing are indeed highly interconnected. Since research on human subjects is largely limited to non-invasive procedures, considerably less is known about interactions between visual areas in the human brain. Here we demonstrate a method of learning the interactions between regions from fMRI data acquired while human subjects view images of natural scenes.
 Determining the category of a natural scene (e.g. classifying a scene as a beach, or a forest) is impor-tant for many human activities such as navigation or object perception [30]. Despite the large variety of images within and across categories, humans are very good at categorizing natural scenes [27, 9]. In our recent study of natural scene categorization in humans with functional magnetic resonance imaging (fMRI), we discovered that information about natural scene categories is represented in pat-terns of activity in the parahippocampal place area (PPA), the retrosplenial cortex (RSC), the lateral occipital complex (LOC), and the primary visual cortex (V1) [31]. We demonstrated that this infor-mation can be read out from fMRI activity with a linear support vector machine (SVM) classifier. Given the highly interconnected nature of the brain, however, it is unlikely that these regions encode natural scene categories independently of each other.
 As previous ROI-based MVPA methods studies, in [31] we built predictors for each ROI indepen-dently, ignoring their interactions. The method in [31] neither explores connections among the ROIs nor uses the connections to build a classifier on top of all ROIs. In this work, we propose a method for simultaneously learning the voxel patterns associated with natural scene categories in sev-eral ROIs and their interactions in a Hidden Conditional Random Field (HCRF) [28] frame-work . In our model, the classifier of each ROI makes predictions based on not only its voxels, but also the prediction results of the ROIs that it connects to. Using the same fMRI data set, we also ex-plore a mutual information based method to discover functional connectivity [5]. Our current model differs from [5], however, by applying a generative model to concurrently estimate the structure of connectivity as well as maximize the end behavioral task (in this case, a scene classification task). Furthermore, we propose a structural learning method to automatically uncover the structure of the interactions between ROIs for natural scene categorization , i.e. to decide which ROIs should be and which ones should not be connected. Unlike existing models for functional connec-tivity, which mostly rely on the correlation of time courses of voxels [23], our approach makes use of the patterns of activity in ROIs as well as the category labels of the images presented to the subjects. Built in the hierarchical framework of HCRF, our structural learning method utilizes information in the voxel values at the bottom layer of the network as well as categorical labels at the top layer. In our method, the connections between each pair of ROIs are evaluated for their potential to improve prediction accuracy, and only those that show improvement will be added to the final structural map. In the remaining part of this paper, we first elaborate on our model and structural learning approach in Section 2. We discuss related work on MVPA and connectivity analysis in Section 3. Finally, we present experimental results in Section 4 and conclude the paper in Section 5. The brain is highly interconnected, and the nature of the connections determines to a large extent how information is processed in the brain. We model the connections of brain regions in a Hid-den Conditional Random Field (HCRF) framework for the task of natural scene categorization and propose a structural learning method to uncover the pattern of connectivity. In the first part of this section we assume that the structural connections between brain regions are already known. We will discuss in Section 2.2 how these connections are automatically learned. 2.1 Integrating Information across Brain Regions Suppose we are given a set of regions of interest (ROIs) and connections between these regions (see the intermediate layer of Fig.1). Existing ROI-based MVPA approaches build a classifier for each ROI independently [15, 24, 18, 16, 31], neglecting the connections between ROIs. It is our objective here to explore the structure of the connections between ROIs to improve prediction accuracy for decoding viewed scene category from fMRI data.
 In order to achieve these goals, we propose a Hidden Conditional Random Field (HCRF) model (Fig.1) to allow each ROI to be influenced by the ROIs that it connects to and build a top-level classifier which makes use of information in all ROIs. In this framework, the classifier for one ROI makes prediction based on the voxels in this region as well as the results of the classifiers of its connected ROIs, thereby improving the accuracy of each ROI. In the absence of evidence about the directionality of connections, we assume them to be symmetric, i.e., to allow the information between two ROIs to go in both directions to the same extent. On the technical side, using an undirected model avoids the difficulties of defining a coherent generative process for graph structures in directed models, thereby giving us more flexibility in representing complex patterns [29]. Our model starts with independently trained classifiers for each ROI as in [31] (the bottom layer of Fig.1). Consider an fMRI data set whose individual brain acquisitions are associated with one of  X  class labels. For an acquisition sample  X  , the decision values of the  X  independent classifiers are are the decision values for the  X  -th ROI, where  X   X   X , X  is the probability that region  X  assigns sample  X  to the  X  -th class, irrespective of the information in any other ROI. Intermediate-layer Given X  X   X  as input, the classifier for ROI  X  can directly predict sample  X  as belonging to the  X   X  -th class if  X   X   X , X   X  is the largest component of X  X   X  . However, this method ignores the dependencies between ROIs. To remedy this, our model allows collaborative error-correction over the ROIs by using the given structure of connections (the intermediate layer of Fig.1). Denoting the prediction for ROI  X  , our model allows for the predictions  X   X  and  X   X  to interact if ROIs  X  and  X  are connected in the given structure (the intermediate layer in Fig.1).
 Based on the ROI-level prediction results  X  , our model outputs the category label of sample  X  :  X   X   X  { 1 ,  X  X  X  X  , X  } (the top layer of Fig.1). Furthermore, because we cannot directly observe the prediction of each ROI when acquiring the fMRI data, we treat  X  as hidden variables. The underlying graphical model is shown in Fig.1. To estimate the overall classification probability given the observed voxel values, we marginalize over all possible values of  X  . The HCRF model is therefore defined as where  X  are the parameters of the model, and  X (  X ,  X  ,  X  ;  X  ) is a potential function parameterized by  X  . We define the potential function  X (  X ,  X  ,  X  ;  X  ) as the weighted sum of edge potential functions defined on every edge  X  (2-clique) of the model: As shown in Fig.1, there are three types of potentials which describe different edges in the model: Type-I Potential  X  = ( X  X  , X   X  ) . Such edges model the distribution of class labels of different ROIs conditioned on the observations X  X  . The edge connects an X  X  node and a  X   X  node where  X  = 1 ,  X  X  X  X  , X  . The edge potential function is defined by: where  X   X , X   X  is the  X   X  -th component of the vector X  X  . A large weight for ( X  X  , X   X  ) implies that the independent classifier trained on voxels of ROI  X  is effective in giving correct predictions. Type-II Potential  X  = (  X   X  , X   X  ) . Such edges model the dependencies between the ROIs. Note that not all pairs of ROIs are connected. The edge potential function is defined by: where  X  &gt; 0 . If two ROIs are connected, they tend to make similar predictions. A large weight for (  X   X  , X   X  ) means the connection between  X   X  and  X   X  is strong.
 Type-III Potential  X  = (  X , X   X  ) . Such edges define a joint distribution over the class label and the prediction result of each ROI. The edge connects a  X   X  node and the  X  node where  X  = 1 ,  X  X  X  X  , X  . The edge potential function is defined by: where  X  &gt; 0 . A large weight for (  X , X   X  ) means ROI  X  has a big contribution to the top-level prediction of the brain.
 Allowing connected ROIs to interact with each other makes our model significantly different from existing MVPA methods [15, 24, 18, 16], and can improve the prediction accuracy of each ROI. Intuitively, if the values of all components in X  X   X  are similar, then ROI  X  is likely to have incorrect one ROI to make better predictions if it can use the information in its connected ROIs. 2.2 Learning the Structural Connections of the Hidden Layer in HCRF Model We have described a method that models the connections between ROIs to build a classification predictor on top of all ROIs. However, for many tasks (e.g. scene categorization), one critical sci-entific goal is to uncover which ROIs are functionally connected for that task. Automatic learning of the structures of graphical models is a difficult problem in machine learning. To illustrate the difficulty, let us assume that we have 4 ROIs and that we want to explore all possible models of connectivity between them. There are 6 possible connections between the ROIs, so in order to in-vestigate whether all possible combinations of connections are present, we need to evaluate 2 6 = 64 different models. For 5 ROIs we have 10 potential connections, leading to 2 10 = 1024 . In general, given  X  ROIs, there are 2  X  (  X   X  1) / 2 possible combinations of connections. In situations with many ROIs, evaluating all possible structures quickly becomes impractical because of the computational constraints. Approximate approaches to learn the structures of directed graphs use the generative process in the model [21, 19, 32]. For undirected graphs, it is usually assumed that the structures are pre-defined [29]. Some incremental approaches [26, 22] were proposed for random fields construc-tion. However the computational complexity of these approaches is still high.
 In our model shown in Fig.1, the potentials represented by solid lines are fixed (type-I and type-III). That is to say, each ROI always makes predictions based on the information in its voxels, and the response at the top level is always influenced by the prediction results of all ROIs. That leaves the dependencies between ROIs (type-II edges, the dashed line in Fig.1) to be learned. Therefore, our structural learning starts from a graphical model containing only type-I and type-III potentials, with-out any interactions between ROIs. Based on this initial model, we evaluate each type-II potential respectively to decide if it should be added to the model.
 As we have described in Section 1, connections among ROIs play a key role in information process-ing. Executing a specific task (e.g., scene categorization) activates certain ROIs as well as rely on connections between some of them. Inspired by this fact, we evaluate whether two ROIs, say ROIs  X  and  X  , should be connected by comparing two models with and without an edge between  X   X  and
Algorithm 1 : The algorithm for uncovering structural connections between ROIs in the HCRF model.  X  . If allowing interactions between ROIs  X  and  X  helps to improve top-level recognition perfor-mance, thus more closely approximating human performance, then  X  and  X  should be connected. Furthermore, we ignore information in all other ROIs when evaluating the connection between ROIs  X  and  X  (Fig.2). So the model will only contain 5 nodes:  X , X   X  , X   X  , X  X  , and X  X  . Although some useful information might be lost compared to evaluating all possible combinations of connections, approximating the algorithm in this way can enable the evaluation of many possible connections in a reasonable amount of time, making this algorithm much more practical.
 The structural learning algorithm is shown in Algorithm 1, and an illustration of evaluating the connection between ROI 2 and 4 is in Fig.2. 2.3 Model Learning and Inference Learning In the step of structural learning, we need to estimate model parameters to compare the models with or without a type-II connection (see Fig.2 for an illustration). Once we have determined which ROIs should interact, i.e. which type-II potentials should be set, we would like to find out the strength of these connections as well as type-I and III potentials. Here the parameters  X  = {  X   X  }  X  are learned by maximizing the conditional log-likelihood of class label  X  on training data  X  : The objective function is not concave due to the hidden variables  X  . Although finding the global optimum is difficult, we can still find a local optimum by iteratively updating the values of  X  using the gradient descent method. To be specific, we first set  X  to be initial values  X  (0) , and for each iteration we adopt the following formula to update  X  (  X  ) to  X  (  X  +1) : where G (  X  ) and H (  X  ) are the gradient vector and Hessian matrix of  X  (  X  ) respectively. This it-erative updating continues until reaching a maximum number of iterations or  X  G (  X  )  X  is smaller than a threshold. When the number of ROIs is large, marginalizing over all possible values of  X  is time-consuming. In such situations we can use Gibbs sampling to compute the gradient vector and Hessian matrix of  X  (  X  ) . In the case of natural scene categorization, evidence from neuroscience studies have postulated that 7 regions are likely to play critical roles in this task [31]. We therefore consider 7 ROIs in our experiment, allowing us to marginalize over all possible values of Y. Inference Given the model parameters  X   X  and a sample  X  , the top-level prediction result is After  X   X  is obtained, we can get the prediction results corresponding to each ROI by In this paper, we model the dependencies between ROIs in an HCRF framework, which improves the ROI-level as well as the top-level decoding accuracy by allowing ROIs to exchange information. Other approaches to inferring connections between brain regions from fMRI data can be broadly separated into effective connectivity and functional connectivity [11]. Models for effective connec-tivity, such as Granger causality mapping [14] and dynamic causal modeling [13], model directed connections between brain regions. These approaches were developed to account for biological tem-poral dependencies, which is not the case in this work. Functional connectivity refers to undirected connections, which can be either model-driven or data-driven [23]. Model-driven methods usually test a prior hypothesis by correlating the time courses of a seed voxel and a target voxel [12]. Data-driven methods, such as Independent Component Analysis [8], are typically used to identify spatial modes of coherent activity in the brain at rest.
 None of these methods, however, has the ability to use the specific relation between the patterns of voxel activations inside ROIs and the ground truth of the experimental condition. The structural learning method proposed in this paper offers an entirely new way to assess the interactions between brain regions based on the exchange of information between ROIs so that the accuracy of decoding experimental conditions from the data is improved. Furthermore in contrast with the conventional model comparison approaches of trying to optimize the evidence of each model [2], our method relates the connectivity structure to observed brain activities as well as the classes of stimuli that elicited the activities. Therefore the model proposed here provides a novel and natural way to model the implicit dependencies between different ROIs. 4.1 Data Set and Experimental Design In order to evaluate the proposed method we re-analyze the fMRI data set from our work in [31]. In this experiment, 5 subjects were presented with color images of 6 scene categories: beaches, buildings, forests, highways, industry, and mountains. Photographs were chosen to capture the high variability within each scene category. Images were presented in blocks of 10 images of the same category lasting for 16 seconds (8 brain acquisitions). Each subject performed 12 runs, with each run containing one block for each of the six categories. Please refer to [31] for more details. We use 7 ROIs that are likely to play critical roles for natural scene categorization. They were determined in separate localizer scans: V1, left/right LOC, left/right PPA, left/right RSC. The data for two subjects were excluded, because not all of the ROIs could be found in the localizer scans for these subjects. For the analysis we use two nested cross validations over the 12 runs for each subject. In the outer loop we cross-validate on each subject to test the performance of the proposed method. For each subject, 11 runs out of 12 are selected as training samples and the remaining run is used as the testing set. For each subject this procedure is repeated 12 times, in turn leaving each run out for testing once. Average accuracy of the 36 experiments across all subjects is used to evaluate the performance of the model. In the inner loop, we use 10 of the 11 training runs to train an SVM classifier for each ROI and each subject, and the remaining run to learn the connections between ROIs and train the HCRF model by using outputs of the SVM classifiers. We repeat this procedure 11 times, giving us 11 models. Results of the 11 models on the test data in the inner loop are combined using bagging [4]. We empirically set both  X  in Equ.(4) and  X  in Equ.(5) to 0.5. 4.2 Scene Classification Results and Analysis In order to comprehensively evaluate the performance of the proposed structural learning and mod-eling approach, we consider different settings of the intermediate layer of our HCRF model. While always keeping all type-I and type-III potentials connected, we consider five different dependencies between the ROIs as shown in Fig.3. The setting in Fig.3(e) possesses all properties of our method: the connections between ROIs are determined by structural learning, and the weights of the connec-tions are obtained by estimating model parameters in Equ.(6). In order to estimate the effectiveness of our structural learning method, we compare this setting with the situations where no connections exists between any of the ROIs (Fig.3(a)), and all ROIs are fully connected (Fig.3(b,c)). In each con-nectivity situation, we either use the same (Fig.3(b,d)) or different (Fig.3(c,e)) weights for type-II Overall classification N/A 31%  X  29%  X  33%  X  X  X  34%  X  X  X  36%  X  X  X 
ROI left PPA 27% 27% 26% 28%  X  31%  X  31%  X  potentials. Note that the type-II potentials of the models in Fig.3(b,d) are also obtaining by learning. Classification accuracy of the five different HCRF models, along with individual SVM classification accuracy for each ROI, is shown in Tbl.1. Note that the model with no type-II potentials (Fig.3(a)) is different from independent SVM classifiers because of the type-I potentials.
 From Table 1 it becomes clear that learning both the structure of the connections and their strengths leads to more improvement in decoding accuracy than either one of these alone. The overall, top-level classification rate increases from 31% for the variant of the model without any connections (Fig.3(a)) to 36% for the variant with the structure of the model as well as the connection strengths learned (Fig.3(e)). We see similar improvements for the individual ROIs: 4-5% for PPA and RSC, 6% for V1, and 9% for LOC. The fact that decoding from LOC benefits most from interacting with other ROIs is interesting and significant. We will discuss this finding in more detail below. 4.3 Structural Learning Results and Analysis Having established that our full HCRF model outperforms other comparison models in the recogni-tion task, we now investigate how our model can shed light on learning connectivity between brain regions. In the nested cross validation procedure, 12  X  11=132 structural maps are learned for each subject. Tbl.2 reports for each subject which connections are present in what fraction of these struc-tural maps. A connection is regarded as a strong connection for a subject if it presents in at least half of the models learned for this subject. In Tbl.2 we use larger font size to denote the connections which are strong on more subjects. Connections that are strong for all subjects are marked in bold. We see that both LOC and PPA show strong interactions between the contralateral counterparts, which makes sense for integrating information across the visual hemifields. We also observe strong interactions between PPA and RSC across hemispheres, which underscores the importance of across-hemifield integration of visual information. We see a similar effect in the interactions between LOC and PPA: strong contralateral interactions. Left LOC also interacts strongly with right RSC. leftLOC-rightLOC 0.66 0.88 0.71 leftPPA-rightRSC 0.61 0.53 0.40 leftLOC-rightPPA 0.75 0.96 0.65 rightPPA-rightRSC 0.93 0.74 0.41 leftLOC-rightRSC 0.75 0.83 0.76 The strong interactions between PPA and RSC are not surprising, since both are typically associated with the processing of natural scenes [25], albeit with slightly different roles [7]. The interactions between LOC and PPA are somewhat more surprising, since LOC is usually associated with the processing of isolated objects. Together with the strong improvement of decoding accuracy for natural scene categories from LOC when it is allowed to interact with other ROIs (see above), this suggests a role for LOC in scene categorization. It is conceivable that the detection of typical objects (e.g., a car) helps with determining the scene category (e.g., highway), as has been shown in [17, 6]. On the other hand, it is also possible that information flows the other way, that scene-specific information in PPA and RSC feeds into LOC to bias object detection based on the scene category (see [3, 1]), and that the classifier decodes this bias signal in LOC. Fig.4 shows the connections which are strong on at least two subjects. In this paper we modeled the interactions between brain regions in an HCRF framework. We also presented a structural learning method to automatically uncover the connections between ROIs. Experimental results showed that our approach can improve the top-level as well as ROI-level pre-diction accuracy, as well as uncover some meaningful connections between ROIs. One direction for future work is to use an exploratory  X  X earchlight X  approach [20] to automatically discover ROIs, and apply our structural learning and modeling method to those ROIs.
 Acknowledgements This work is funded by National Institutes of Health Grant 1 R01 EY019429 (to L.F.-F., D.M.B., D.B.W.), a Beckman Postdoctoral Fellowship (to D.B.W.), a Microsoft Research New Faculty Fel-lowship (to L.F.-F.), and the Frank Moss Gift Fund (to L.F-F.). The authors would like to thank Barry Chai, Linjie Luo, and Hao Su for helpful comments and discussions.
