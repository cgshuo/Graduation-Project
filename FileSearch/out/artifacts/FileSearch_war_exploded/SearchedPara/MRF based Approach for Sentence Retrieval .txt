 This poster focuses on the study of term context dependence in the application of sentence retrieva l. Based on Markov Random Field (MRF), three forms of depe ndence among query terms are considered. Under different a ssumptions of term dependence relationship, three feature functi ons are defined, with the purpose to utilize association features between query terms in sentence to evaluate the relevance of senten ce. Experimental results have proven the efficiency of the proposed retrieval models in improving the performance of sentence retrieval. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval  X  Retrieval models. Algorithms, Experimentation Sentence retrieval, term depe ndency, Markov Random Field. Traditional term based matching approaches are not efficient enough to deal with the task of sentence retrieval. One of the most possible reasons is the limited information contained in each sentence. Term context dependences, which can disclose the implicit associations among terms in appearance, can express the special regularity behind query term s. This kind of information is considered quite useful for senten ce relevance detection. In this poster, a novel sentence retrieva l model based on term context dependence is proposed. The ma in idea is to utilize Markov Random Field (MRF) [1] to simu late the dependence model of variables involved in the problem of sentence retrieval. Based on the simulated dependence model, association features between query terms in sentences are used as the relevance evidence of sentences. Three forms of cont ext dependence among query terms are simulated in this poster. Th ese assumptions consider term context dependence from different points of view. Thus, in the following process, three feature functions are proposed to evaluate the accuracy of each estimated dependency model by considering terms X  co-occurrence and syntactic relationships in sentences. Considering the efficiency of term context dependence in In formula 4, parameters  X  and  X  are ranged between 0 and 1 and are used to control the influence of each component on sentence relevance identification. Function BoolSynR ( q u , ... q v ) is set to 1 if q , ... q v are syntactically connected in the dependency parse tree of S , else is set to 0. Functions d is and h X  denote the distance and height of terms q u ,... q v in the dependency parse tree and are respectively defined as is the number of linkages between q i and q j in parse tree , N is the 3) The third potential function sim ilarly involves with cliques containing two or more query term s. Its difference is that these query terms are syntactic proximity with each other in the dependency parse trees. The third function is defined as: terms in the dependency parse tree of S , else is set to 0. Function d and parameters  X  and  X  have similar definitions as those in formula 4. Function h  X  X  also represents the height of q u , ... q v in the dependency parse tree, but is defined as:  X  Based on the potential functions defined above, the sentence ranking function is formulated as: where set I is a set of cliques containing a query term and a sentence. CD represents a set of cliques involving a sentence and several query terms that appear contiguously within the query. UD denotes a set of cliques, terms of which appear non-contiguously with each other in the query. Parameters  X  I ,  X  SR and  X  PR are valued between 0 and 1 and used to control the influence of each feature function on the relevance estimate. Our experiments are implemented on Aquaint Collection by using the 100 topics: N1-N100. Relevance of sentences that are retrieved is assessed by using th e relevance assessments provided by TREC for the Novelty Task 2003 and 2004. In our experiments, only title portions of these TREC topics are considered as experimental queries. Table 1 and Table 2 show the performance comparisons of our proposed retrieval models, i.e., FIDM: considers full independence among query terms, SDM: considers the dependences among sequential query terms, and FDM: considers the dependences among any query terms, with two traditional retrieval approaches, i.e., TFIDF model (TFIDF) and KL-divergence model (KLD). The metric P@ k represents the precision at the top k ranked sentences. As s hown in these tables, models SDM and FDM produce cl ear improvements over not only the traditional retrieval models but also the model with full independence assumption. It proves the correctness of the assumption of the underlying depe ndences among the query terms. 
