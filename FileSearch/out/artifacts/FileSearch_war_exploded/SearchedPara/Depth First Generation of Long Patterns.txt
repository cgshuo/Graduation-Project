 In this pap er w e presen t an algorithm for mining long pat-terns in databases. The algorithm nds large itemsets b y using depth rst searc h on a lexicographic tree of itemsets. The fo cus of this pap er is to dev elop CPU-ecien t algo-rithms for nding frequen t itemsets in the cases when the database con tains patterns whic h are v ery wide. W e refer to this algorithm as DepthPr oje ct , and it ac hiev es more than one order of magnitude sp eedup o v er the recen tly prop osed MaxMiner algorithm for nding long patterns. These tec h-niques ma y be quite useful for applications in areas suc h as computational biology in whic h the n um b er of records is relativ ely small, but the itemsets are v ery long. This neces-sitates the disco v ery of patterns using algorithms whic h are esp ecially tailored to the nature of suc h domains. H.2.8 [ Database Managemen t ]: Database Applications| Data Mining Asso ciation Rules The asso ciation rule problem has b een recognized in the lit-erature as a fundamen tally imp ortan t problem in the eld of data mining. Applications of asso ciation rules extend to nding useful patterns in consumer b eha vior, target mark et-ing, and electronic commerce. The asso ciation rule mo del w as in tro duced b y Agra w al, Imielinski, and Sw ami [5]. Starting with the pioneering w ork in [5], the asso ciation rule problem and its v ariations ha v e b een studied extensiv ely b y researc hers. Sev eral v ariations of the asso ciation rule prob-lem [4, 8, 10, 19] ha v e b een prop osed whic h can pro vide more in teresting rules than the supp ort-con dence frame-w ork. In addition, a n um ber of metho ds ha v e b een dis-cussed in the literature whic h extend the binary asso ciation rule problem to related scenarios suc h as quan titativ e as-so ciation rules, generalized asso ciation rules, and optimized asso ciation rules [12, 13, 22, 23, 27, 28]. Metho ds for pro vid-ing ad-ho c query capabilities, and online mining ha v e b een discussed in [3, 16, 20, 21].
 Let I b e a set of items. Eac h transaction T in the database is a subset of the items o ccuring in I . A set of items in the database is referred to as an itemset . In particular, a set of items with a cardinalit y of k is referred to as a k -itemset. The measure used to ev aluate the lev el of presence of an itemset in the database is the supp ort . The supp ort of itemset X is equal to the fraction of the transactions con-taining X . A k ey step of asso ciation rule mining is nd frequent itemsets or lar ge itemsets [5]. These are itemsets whose supp ort is larger than a user-sp eci ed threshold. A fast algorithm called Apriori w as prop osed in [6], whic h gen-erates ( k + 1)-candidates using joins o v er frequen t k -itemsets whic hw ere already generated. Th us, for eac h frequen t item-set, all subsets of it need to b e generated b y the algorithm. Because of the inheren t dicult y of the itemset generation problem in terms of computational complexit y , considerable researc h has b een dev oted to w ards nding faster metho ds for generating large itemsets [6, 7, 11, 14, 15, 17, 18, 26, 29]. The large itemset problem is reasonably w ell solv ed at least for the case of v ery sparse sales transaction data, when the pattern lengths are short [1, 6]. An in teresting analy-sis of the impact of di eren t kinds of data on access costs has b een pro vided in [11]. An Apriori -style algorithm with impro v ed coun ting tec hniques using column wise data access for databases with a larger n um b er of items has b een also b een discussed in the same w ork. W e main tain that when the actual frequen t patterns are wide, ev en the CPU-costs of an y algorithm whic h is based on the Apriori -framew ork w ould b e compromised b y the in v estigation of all 2 k subsets of frequen t k -patterns. In suc h cases, the frequen t itemset generation algorithms b ecome CPU-b ound. Some of the al-gorithms in the literature suc has MaxMiner a v oid this b y implemen ting lo okahe ads [7], in whic h sup ersets of frequen t patterns are used in order to prune o p oten tial candidates in the searc h. Other inno v ativ e ideas for handling these problems are discussed in [29]. In spite of these adv ances [7, 11, 29], nding computationally ecien t algorithms for gen-erating long patterns con tin ues to b e a v ery dicult prob-lem. This pap er is written with the primary aim of dev elop-ing an algorithm for long patterns whic h is CPU-ecien t.
Permission to make digital or hard copies of part or all of this work or permission and/or a fee.

KDD 2000, Boston, MA USA  X  ACM 2000 1 -58113 -233 -6/00/0 8 ...$5.00 This pap er is organized as follo ws. In section 2, w e will dis-cuss sev eral formalizations, whic h will b e useful in describing the algorithm. In section 3, w e will in tro duce the depth-rst strategy of generating large itemsets. The database repre-sen tation will b e explained in section 4. In section 5, w e will discuss the buc k eting tec hnique whic h is a useful metho d for sp eeding up the algorithm substan tially . An e ectiv e prun-ing and lo ok ahead strategy for the algorithm is discussed in section 6. W e will compare the results to the MaxMiner algorithm, and presen t the computational results in section 7. Section 8 discusses the conclusions and summary . This pap er prop oses a fundamen tally di eren t tec hnique for nding large itemsets from most of the algorithms prop osed in the recen t past. A large n um b er of algorithms in the re-searc h literature start the pro cess of generating ( k + 1) item-sets only after all k -itemsets ha v e b een generated. Ev en the recen t lo ok-ahead-based algorithm discussed [7] for mining long patterns guaran tees the disco v ery of all ( k + 1)-itemsets only after generation of all k -itemsets, ev en though some of the ( k + 1)-itemsets ma y b e disco v ered earlier than the k -itemsets. The reason for this natural algorithmic design has b een motiv ated b y the desire to restrict the n um b er of passes o v er the database to the length of the longest pattern. This often results in the generation of a large n um b er of subsets of frequen t itemsets. A few metho ds [9] deviate from this natural design in order to reduce the n um b er of I/O passes, but tend to b e Apriori -lik e in their o v erall approac h; con-sequen tly the com binatorial explosion problem con tin ues to b e an issue.
 The long pattern problem is so dicult to solv e computa-tionally , that ev en for databases of relativ ely small sizes, it ma y be v ery dicult to nd long patterns [7]. In the past decade, memory a v ailabilit y has increased b y orders of magnitude. It has recen tly started b ecoming increasingly eviden t that in the near future, man y medium to large size databases are lik ely to b e main memory residen t. F or prob-lems in whic h the patterns are longer than 15-20 items, and the database is to o large to t under the curren t memory limitations (whic h are reac hing the Gigab yte order), most of the algorithms whic h require the generation of all sub-sets of frequen t itemsets are impractical an yw a y . F or the long p attern problem, it ma y p erhaps b e realistic to design algorithms with m uc h greater fo cus on CPU requiremen ts for transaction sets of mo derate sizes whic h can t in main The long pattern problem has considerable applicabilit yin com binatorial pattern disco v ery in biological sequences [24]. In this case, w e ha v e a small set of biological sequences, and w e wish to nd all the rigid patterns (motifs) in these sequences. This is an example of a problem in whic h the n um b er of patterns is small enough to t in main memory , whereas eac h individual pattern can be quite long, and it ma y b e to o time consuming to use Apriori -lik e algorithms 1 If desired, the main memory algorithm in this pap er can b e com bined with a metho d discussed in [26] whic h divides a disk-residen t database in to di eren t main-memory par-titions and then com bines the itemsets from the di eren t partitions in order to generate the nal itemsets. This is ho w ev er not the fo cus of this pap er.
 for suc h problems. Our results in this pap er are tailored to w ards suc h domains in whic h the patterns are to o long to b e handled b y Apriori -st yle algorithms. In this section, w e will in tro duce a conceptual string rep-resen tation of large itemsets whic hw e will refer 2 to as the lexicographic tree [1]. This will pro vide us with the neces-sary mac hinery needed in order to explain the DepthPr oje ct algorithm. W e assume that a lexicographic ordering exists among the items in the database. In order to indicate that an item i o ccurs lexicographically earlier than j ,w e will use the notation i L j . The lexicographic tree is an abstract represen tation of the large itemsets with resp ect to this or-dering. The lexicographic tree is de ned in the follo wing w a y: (1) A no de exists in the tree corresp onding to eac h large itemset. The ro ot of the tree corresp onds to the nul l itemset. (2) Let I = f i 1 ;::: i k g b e a large itemset, where i are listed in lexicographic order. The paren t of the no de I is the itemset f i 1 ;:: :i k 1 g .
 This de nition of ancestral relationship naturally de nes a tree structure on the no des, whic h is ro oted at the nul l no de. The goal in this pap er is to use the structure of the lexico-graphic tree in order to substan tially reduce the CPU time for coun ting large itemsets. An example of the lexicographic tree is illustrated in Figure 1. A frequen t 1-extension of an itemset suc h that the last item is the con tributor to the ex-tension will b e called a fr e quent lexic o gr aphic tr e e extension , or simply a tree extension. Th us, eac h edge in the lexico-graphic tree corresp onds to an item whic h is the frequen t lexicographic tree extension to a no de. W e will denote the set of frequen t lexicographic tree extensions of a no de P b y 2 A set represen tation of this tree is referred to as the en u-meration tree [25]. E ( P ). In the example illustrated in Figure 1, the frequen t lexicographic extensions of no de a are b , c , d , and f . Let Q b e the immediate ancestor of the itemset P in the lexi-cographic tree. The set of pr osp e ctive br anches of a no de P is de ned to b e those items in E ( Q ) whic h o ccur lexicographi-cally after the no de P . These are the p ossible frequen t lexico-graphic extensions of P . W e denote this set b y F ( P ). Th us, w eha v e the follo wing relationship: E ( P ) F ( P ) E ( Q ). The v alue of E ( P ) in Figure 1, when P = ab is f c; d g . The v alue of F ( P ) for P = ab is f c; d; f g , and for P = af , F ( P ) is empt y .
 A no de is said to b e gener ate d , the rst time its existence is disco v ered b y virtue of the extension of its immediate paren t. A no de is said to ha v e b een examine d , when its frequen t lex-icographic tree extensions ha v e b een determined. Th us, the pro cess of examination of a no de P results in generation of further no des, unless the set E ( P ) for that no de is empt y . Ob viously a no de can be examined only after it has b een generated. This pap er will discuss an algorithm whic h con-structs the lexicographic tree in depth-rst order b y starting at the no de nul l and successiv ely generating no des un til all no des ha v e b een generated and subsequen tly examined. An itemset is de ned to b e a fr e quent maximal itemset , if it is frequen t, and no sup erset of that itemset is frequen t. Th us, in the Figure 1, the itemset acd f is maximal. Let P b e a no de in the lexicographic tree corresp onding to a frequen t k -itemset. Then, for a transaction T w e de ne the pr oje cte d tr ansaction T ( P ) to be equal to T \ E ( P ). Ho w ev er, if T do es not con tain the itemset corresp onding to no de P then T ( P )is n ull. F or a set of transactions T ,w e de ne the pro jected transaction set T ( P ) to b e the set of pro jected transactions in T with resp ect to frequen t items E ( P )at P .
 Consider the transaction abcdef g hk . Then, for the example A of Figure 1, the pro jected transaction at no de nul l w ould be f a; b; c; d; e; f ; g ; h; k g\f a; b; c; d; e; f g = abcdef . The pro jected transaction at no de a w ould be bcd f . F or the transaction abdef g , its pro jection on no de ac is n ull b ecause it do es not con tain the required itemset ac .
 W e emphasize the follo wing p oin ts: (1) F or a giv en transaction T , the information required to coun t the supp ort of an y itemset whic h is a descendan tofa no de P is completely con tained in T ( P ). (2) The n um b er of items in a pro jected transaction T ( P )is t ypically m uc h smaller than the original transaction. (3) F or a giv en transaction set T and no de P the ratio of the n um b er of transactions in T ( P ) and T is appro ximately determined b y the supp ort of P .
 In the next section, w e will discuss an algorithm whic h nds the itemsets b y depth rst creation of the lexicographic tree. The follo wing description will discuss a pure approac h in whic h the en tire tree is generated b y the algorithm. In a later section, w e will sho w that it is p ossible to signi can tly Algorithm DepthFirst(Itemset No de: N , b egin C = Gener ateC andidates ( N );
E = C ount ( N; T ;B;C ); f Let E = f i 1 ;::: ;i j Store frequen t itemsets N [f i r g for r 2f 1 ;::: ; j E jg ;
B 0 = C r eateB itv ector ( N; B; T ); if ( P r oj ectionC ondition ) then for r := 1 to j E j end Subroutine Pr oje ct(Datab ase: T , b egin
T 0 = Empt y set of transactions; for eac h transaction T 2T do return ( T 0 ); end Subroutine Cr e ateBitve ctor( N; B; T ) b egin Initialize B 0 = B ;
Let n b e the lexicographically largest item in N ; for eac h transaction T 2T do return ( B 0 ); end sp eed up the algorithm b y pruning a w a y those subtrees whic h are guaran teed to con tain only non-maximal itemsets. In addition, the discussion in the follo wing section do es not include a sp ecialized coun ting tec hnique (called buc k eting) for lo w er lev el no des, whic hw e will also p ostp one to a later section.
 A t this p oin t, w e men tion that a v ery in teresting (but di er-en t) tree based algorithm FP-gr owth has b een prop osed in [15]. This metho d is able to generate itemsets without can-didate generation. The tec hnique has b een compared with the T r e ePr oje ction algorithm [1] in the empirical results pre-sen ted in [15]. Unlik e T r e ePr oje ction , the DepthPr oje ct algo-rithm is sp eci cally designed for nding long max-patterns and is orders of magnitude faster than the former in these cases. Algorithm Gener ateCandidates(Itemset No de:N) b egin if ( N is nul l ) then else end Figure 3: Generating candidate branc hes of a no de Algorithm Count(ItemsetNo de:N, b egin end Figure 4: Coun ting frequen t extensions of a no de In depth-rst searc h, the no des of the lexicographic tree are examine d in depth-rst order. The pro cess of examination of a no de refers to the coun ting of the supp orts of the can-didate extensions of the no de. In other w ords, the supp ort of all descendan t itemsets of a no de is determined b efore determining the frequen t extensions of other no des of the lexicographic tree. A t a giv en no de, lexicographically lo w er item-extensions are coun ted b efore lexicographically higher ones. Th us, the order in whic h a depth-rst searc h metho d w ould coun t the extensions of no des in the Figure 1 is nul l , c , cd , cd f , cf , d , d f , e , and f . Th us, the depth rst strategy quic kly tends to nd the longer patterns rst in the searc h pro cess. Note that the string represen tations of the no des are visited in dictionary order. A tan y p oin t in the searc h, w e main tain the pro jected transaction sets for some of the no des on the path from the ro ot to the no de whic h is cur-ren tly b eing extended. 3 A p oin ter is main tained at eac h no de P to the pro jected transaction set whic his a v ailable at the nearest ancestor of P . Since the pro jected database is substan tially smaller than the original database b oth in terms of the n um ber of transactions, and the n um ber of items, the pro cess of nding the supp ort coun ts is sp eeded up substan tially . The follo wing information is stored at eac h no de during the pro cess of construction of the lexicographic tree: (1) The itemset P at that no de. (2) The set of lexicographic tree extensions at that no de whic h are E ( P ). (3) A p oin ter to the pro jected transaction set T ( Q ), where Q is some ancestor of P (including itself ). The ro ot of the tree p oin ts to the en tire transaction database. 3 In the implemen tation section, w e shall describ e in detail whic h no des are the ones at whic h the pro jected transaction sets are main tained. (4) A bitv ector con taining the information ab out whic h transactions con tain the itemset for no de P as a subset. The length of this bitv ector is equal to the total n um ber of transactions in T ( Q ). The v alue of a bit for a transaction is equal to 1, if the itemset P is a subset of the transaction. Otherwise it is equal to zero. Th us, the n um b er of 1 bits is equal to the n um b er of transactions in T ( Q ) whic h pro ject to P . The bitv ectors are used in order to mak e the pro cess of supp ort coun ting more ecien t.
 Once w eha v e iden ti ed all the pro jected transactions at a giv en no de, then nding the subtree ro oted at that no de is a completely indep enden t itemset generation problem with a substantial ly r e duc e d transaction set. As w as indicated ear-lier, the n um b er of transactions at a no de is prop ortional to the supp ort at that no de. An imp ortan t fact ab out pro jec-tions is the follo wing: By using hier ar chic al pr oje ctions, we ar er eusing the infor-mation fr om c ounting k -itemsets in or der to c ount ( k +1) -itemsets.
 Note that suc h a reuse of information is made p ossible b y the depth rst strategy , since w e only need to main tain the pro jected transaction sets on the path of the tree whic his curren tly b eing explored. Let us consider a k -itemset I at whic h the database is pro jected. If a transaction T do es not con tain this k -itemset I as a subset, then the pro jec-tion strategy ensures that T will not be used in order to coun tan y of the ( k + 1)-extensions of I . This is imp ortan t in reducing the running time, since a large fraction of the transactions will not b e relev an t in coun ting the supp ort of an itemset. F urthermore, the pro cess of pro jection reduces the n um b er of elds in the database to a small n um ber so that the coun ting pro cess b ecomes more ecien t.
 The description in Figure 2 sho ws ho w the depth rst cre-ation of the lexicographic tree is p erformed. The algorithm is describ ed recursiv ely , so that the call from eac hnodeisa completely indep enden t itemset generation problem, whic h nds all frequen t itemsets that are descendan ts of a no de. There are three parameters to the algorithm, a p oin ter to the database T , the itemset no de N , and the bitv ector B . The bitv ector B con tains one bit for eac h transaction in T 2T , and indicates whether or not the transaction T should be used in nding the frequen t extensions of N . A bit for a transaction T is one, if the itemset at that no de is a sub-set of the corresp onding transaction. The rst call to the algorithm is from the nul l no de, the parameter T is the en tire transaction database. Since eac h transaction in the database is relev an t in order to p erform the coun ting, the bitv ector B consists of all \one " v alues.
 The rst step of the algorithm is to generate all the candi-date extensions of N . This is accomplished b y the subrou-tine call Gener ateC andidates ( N ). F or the case of the nul l no de, this call returns all the items in the en tire database. F or the case of other no des, the pro cedure simply returns the set of items in F ( N ). As discussed earlier, the set of items in F ( N ) ma y be determined b y nding all those frequen t extensions of the paren t of N , whic h are lexico-graphically larger than an y item in N . The details of the Gener ateC andidates pro cedure are illustrated in Figure 3. The next step is to coun t the supp ort of eac h of these candi-date extensions. This is done b y the pro cedure C ount . The bitv ector B and the database T are used in order to p er-form the coun ting ecien tly , since it uses information from coun ting ancestral no des. The details of ho w the coun ting is p erformed will b e discussed in a later section. A t the same time, it is desirable to create the bitv ectors for no de N . The bitv ectors for no de N ma y b e deriv ed v ery simply from the bitv ector B . This is b ecause the bitv ector B corresp onds to the paren tof node N , whic h di ers from N b y exactly one item (the lexicographically largest item). Let n b e the lexicographically largest item in N . Th us, the new bitv ector for no de N ma y b e obtained b yc hanging those bits in B to 0, if the corresp onding transactions do not con tain the item n .
 F or some of the no des, it is desirable to pro ject the database, if there is a substan tial reduction in the database size or eld width. A t this stage, w ec ho ose to b e am biguous ab out this condition b y referring to it generally as the Pr oje ction-Condition . A new database is created using the subroutine P r oj ect of Figure 2. If the database is indeed pro jected, then the bitv ector at no de N also needs to b e mo di ed in order to re ect this. Since ev ery transaction in this new database is needed in order to generate the frequen t exten-sions of N ,w e create a new bitv ector B 0 with as man y en-tries as this newly created database. The v alue of eac h bit in this database is 1 b ecause all transactions in this database con tain the itemset corresp onding to N .
 Once the bitv ectors and newly pro jected database has b een created, w e call the algorithm recursiv ely from all frequen t extensions of no de N . The calls to the frequen t extensions of N are made in lexicographic order. These recursiv e calls create the subtrees whic h are ro oted at the corresp onding no des of the lexicographic tree. V arious heuristic rules ma y b e used in order to decide the exact nature of the pro jection condition discussed in Figure 2. F or example, it is p ossible to use the heuristic rule that a pro jected transaction set ma y be main tained at a no de only when the size of the pro jected database is less than a certain factor of the previous database size. Alternativ ely , it is p ossible to main tain a pro jected transaction set at a no de, only when the n um ber of bits to represen t a (pro-jected) transaction at that no de is less than a certain n um-ber i.e. j E ( P ) j falls b elo w a certain n um b er. The primary motiv ation is to pro ject only when the database represen ta-tion b ecomes \sucien tly more ecien t" after p erforming the pro cess. W e will discuss later ho ww ec hose the pro jec-tion condition for our implemen tation. W e will also discuss ho w to com bine the depth rst creation of the lexicographic tree with an e ectiv elook ahead strategy in order to a v oid creation of those subtrees of the lexicographic tree whic h con tain only non-maximal itemsets. An um b er of optimizations w ere p erformed in order to im-pro v e the p erformance of the algorithm. Since the algorithm discussed in this pap er is geared to w ards generating long patterns, w e found that it w as b etter to use the database in the bitstring r epr esentation . In the bitstring represen ta-tion, eac h item in the database has one bit represen ting it. Th us, the length of eac h transaction in bits is equal to the total n um b er of items in the database. Suc h a represen ta-tion is inecien t when the n um b er of items in a transaction is signi can tly less than the total n um b er of items. This is b ecause of the fact that most of the bits tak e on the v alue of 0. Ho w ev er, the DepthPr oje ct algorithm p erforms coun ting on the pro jected transactions whic h are expressed in terms of E ( P ). In this represen tation, most bits tak e on the v alue of 1. F urthermore, for problems in whic h the database con-tains long patterns, the ratio of the maxim um pattern length to the total n um b er of items is relativ ely high for most lo w er lev el no des.
 W eha v e discussed the concept of selectiv e pro jection sligh tly earlier. In the implemen tation of the algorithm o v er sev eral datasets, w e found that the b est strategy w as to pro ject the database only when j E ( P ) j is reduced to less than 32. In this case, pro jected transactions can b e represen ted as 32 bit w ords. Th us, a pro jected database with one million trans-actions can be represen ted in only 4 MB, when j E ( P ) j is less than 32. This illustrates the considerable adv an tages of using the bitstring represen tation for holding the pro jected transactions. Our exp erimen ts sho w that most of the time w as sp en t in coun ting these lo w er lev el no des where the rep-resen tation and coun ting abilit yw as most ecien t. W e will no w discuss ho w the bitstring represen tation is helpful in reducing the coun ting times substan tially . Carefully designed coun ting metho ds are critical in reduc-ing the times for nding supp ort coun ts. Let us consider a no de P , at whic h it is desirable to coun t the supp ort of eac h item in F ( P ). Let Q b e the nearest ancestor of P at whic h the pro jected database T ( Q ) is main tained. Eac h pro jected transaction in T ( Q ) con tains n bits, where n = j E ( Q ) j . W e are assuming that j F ( P ) j is close to n . Otherwise, w ew ould ha v e pro jected the database at some in termediate no de b e-t w een P and Q according to the pro jection condition in order to reduce the database size. Let T b e a transaction in T ( Q ). A naiv e metho d of coun ting w ould b e to main tain a coun ter for eac h item in F ( P ) and add one to the coun ters of eac hof those elemen ts for whic h the corresp onding bit in T tak es on the v alue of 1. Ho w ev er, it is p ossible to reduce the coun ting times greatly b y using a t w o phase b yte coun ting metho d. The rst step in the coun ting tec hnique is to decide whether the transaction T is relev an t in coun ting the supp ort of can-didate extensions of no de P . The transaction T is relev an tin coun ting the supp ort of candidate extensions of no de P ,if P is a subset of T . The bitv ector main tained at the immediate paren t P 0 of P pro vides the information as to whether the transaction T ,w as relev an t in coun ting the supp ort of the frequen t extensions of P 0 . If this is so, then w e need to c hec k additionally whether the lexicographically largest item of P (this item extends P 0 to P ) is presen t in T . Once it has b een determined that the transaction T is relev an t in order to p erform the coun ting at no de P ,w e coun t the supp ort for eac h item in F ( P ). Let us assume that eac h transaction T con tains n bits, and can therefore b e expressed in the form of d n= 8 e b ytes. Eac hb yte of the transaction con tains the in-formation ab out the presence or absence of eigh t items, and the in teger v alue of the corresp onding bitstring can tak eon Algorithm AggregateCoun ts( Counts: buck et [ ::: ]) b egin k = j E ( P ) j ; for i := 1 to k do end an yv alue from 0 to 2 8 1 = 255. Corresp ondingly , for eac h b yte of the (pro jected) transaction at a no de, w e main tain 256 coun ters, and w e add 1 to the coun ter corresp onding to the in teger v alue of that transaction b yte. This pro cess is rep eated for eac h transaction in T ( P ). Therefore, at the end of this pro cess, w eha v e 256 d n= 8 e coun ts. W e follo w up with a p ostpro cessing phase in whic hw e determine the supp ort of an item b y adding the coun ts of the 256 = 2 = 128 coun ters whic h tak e on the v alue of 1 for that bit. Th us, this phase requires 128 n op erations only , and is indep enden t of database size. The rst phase, (whic h is the b ottlenec k) is the impro v emen to v er the naiv e coun ting metho d, since it p erforms only 1 op eration for eac h byte in the transaction, whic h con tains 8 items. Th us, the metho d w ould b e a factor of 8 faster than the naiv e coun ting tec hnique, whic hw ould need to scan the en tire bitstring. The coun ting times are determined b y the time sp en tat the lo w er lev el no des, at whic h the pro jected transactions are inheren tly dense. A t the lo w er lev els in the tree, w e use another sp ecialized tec h-nique called buc k eting in order to p erform the coun ting. W e will discuss this metho d in greater detail in the next section. Most of the no des in the lexicographic tree corresp ond to the lo w er lev els. Th us, the coun ting times at these lev els accoun t for most of the CPU times of the algorithm. F or these lev els, w e used a strategy called buc k eting in order to substan tially impro v e the coun ting times. The idea is to c hange the coun ting tec hnique at a no de in the lexico-graphic tree, if j E ( P ) j is less than a certain v alue. In this case, an upp er b ound on the n um ber of distinct pr oje cte d 9, then there are only 512 distinct pro jected transactions at the no de P . Clearly , this is b ecause the pro jected database con tains sev eral rep etitions of the same (pro jected) transac-tion. The fact that the n um ber of distinct transactions in the pro jected database is small can b e exploited in order to yield substan tially more ecien t coun ting algorithms. The aim is to coun t the supp ort for the en tire subtree ro oted at P with a quic k pass through the data, and an additional p ostpro cessing phase whic h is indep enden t of database size. The pro cess of p erforming buc k et coun ting consists of t w o phases: (1) In the rst phase, w e coun tho w man y of eac h distinct transaction are presen t in the pro jected database. This can coun ters, scanning the transactions one b y one, and adding coun ts to the buc k ets. The time for p erforming this set of op erations is linear in the n um b er of (pro jected) database transactions. coun ts in order to determine the aggregate supp ort coun ts for eac h itemset. In general, the supp ort coun t of an itemset ma y b e obtained b y adding the coun ts of all the sup ersets of that itemset to it. A skillful algorithm (from the eciency p ersp ectiv e) for p erforming these op erations is illustrated in Figure 5.
 Consider a string comp osed of 0, 1, and , whic h refers to an itemset in whic h the p ositions with 0 and 1 are xed to those v alues (corresp onding to presence or absence of items), while a p osition with a is a \don't care". Th us, all itemsets can b e expressed in terms of 1 and , since itemsets are tradi-tionally de ned with resp ect to presence of items. Consider for example, the case when j E ( P ) j = 4, and there are four items, n um b ered f 1 ; 2 ; 3 ; 4 g . An itemset con taining items 2 and 4 is denoted b y 1 1. W e start o with the information on 2 4 = 16 bitstrings whic h are comp osed of 0 and 1. These represen t all p ossible distinct transactions. The algorithm aggregates the coun ts in j E ( P ) j iterations. The coun t for a string with a \*" in a particular p osition ma y b e obtained b y adding the coun ts for the strings with a 0 and 1 in those p ositions. F or example, the coun t for the string *1*1 ma y b e expressed as the sum of the coun ts of the strings 01*1 and 11*1.
 The pro cedure in Figure 5 w orks b y starting with the coun ts of the 0-1 strings, and then con v erts them to strings with 1 and *. The algorithm requires j E ( P ) j iterations. In the i th iteration, it increases the coun ts of all those buc k ets with a 0 in the i th bit, so that the coun tno w corresp onds to a case when that buc k et con tains a in that p osition. This can b e ac hiev ed b y adding the coun ts of the buc k ets with a 0 in the i th p osition to that of the buc k et with a 1 in that p osition, with all other bits ha ving the same v alue. F or example, the coun t of the string 0*1* is obtained b y adding the coun ts of the buc k ets 001* and 011*. In Figure 5, the pro cess of adding the coun t of the buc k et j to that of the buc k et j +2 i 1 ac hiev es this.
 The second phase of the buc k eting op eration requires j E ( P ) j Therefore, the total time required b y the metho d is prop or-the time required b y the second phase of p ostpro cessing is small compared to the rst phase, whereas the rst phase is essen tially prop ortional to reading the database for the curren t pro jection.
 W eha v e illustrated the second phase of buc k eting b y an ex-ample in whic h j E ( P ) j = 3. The pro cess illustrated in Figure 6 illustrates ho w the second phase of buc k eting is ecien tly p erformed. The exact strings and the corresp onding coun ts in eac hofthe j E ( P ) j = 3 iterations are illustrated. In the rst iteration, all those bits with 0 in the lo w est order p osi-tion ha v e their coun ts added with the coun t of the bitstring op erations tak e place during this step. The same pro cess is rep eated t w o more times with the second and third or-der bits. A t the end of three passes, eac h buc k et con tains the supp ort coun t for the appropriate itemset, where the '0' for the itemset is replaced b y a \don't care" whic h is represen ted b y a '*'. Note that the n um b er of transactions in this example is 27. This is represen ted b y the en try for the buc k et ***. Only 2 transactions con tain all three items, whic h is represen ted b y the buc k et 111. In order to sp eed up the p erformance of the algorithm, w e implemen t lo okahe ads [7]. Consider a no de P with a set of prosp ectiv e branc hes F ( P ). If the no de P [ F ( P )is a frequen t itemset, then it is not necessary to explore the sub-tree ro oted at P . One w a y of doing this is to parallelize the pro cess of nding the supp ort coun t for the itemset P [ F ( P ) with that of determining the coun ts of eac hofthe candidate extensions of P . W ec ho ose a simpler alternativ e b y using the follo wing metho d for p erforming lo ok aheads. Let E = f i 1 ;: ::i j a no de. Eac h time after calling the DepthFirst pro cedure from the candidate extension i r 1 of a no de, w e c hec k if the set f i r 1 ::: i j the candidate extensions for f i r :::i j further consideration. This is a sligh tly w eak er v ersion of the pruning pro cedure, but it can b e implemen ted m uc h more ecien tly . The depth rst tec hnique also pro vides the abil-it y to quic kly disco v er maximal patterns, and thereb y prune a w a y all those branc hes of the tree suc h that P [ E ( P )is a subset of some itemset whic h has already b een disco v ered. This kind of lo ok ahead is more e ectiv e with a lexicograph-ically branc h-ordered depth rst strategy , since longer pat-terns are disco v ered earlier on. In particular, an y fr e quent strict sup erset Q of the itemset P [ E ( P ) con tains P and at least one item i whic h is lexicographically smaller than the largest item in P (otherwise i w ould be con tained in E ( P )). This means that Q is lexicographically smaller than P . Th us Q (or a sup erset) w ould b e disco v ered earlier than P .
 The structure of the lexicographic tree is v ery m uc h dep en-den t up on the lexicographic ordering of the items in the database. F or example, consider the case when there are exactly 3 large itemsets: abc , abd , and abe . Let us no w con-sider the cases when the orderings of the items are a; b; c; d; e , and e; d; c; b; a resp ectiv ely . The lexicographic trees for the t w o cases are illustrated in Figures 7(a) and (b). As w e see, in the case of Figure 7(b), since the branc hes of the tree at whic h the maximal itemsets eba , dba , and cba can b e found tend to separate out at v ery high lev el (lev el 1), the pro-cess of using lo ok aheads is lik ely to b e more e ectiv e in this case. The v ery rst no de visited b y the depth-rst searc h pro cedure after the no de nul l in the Figure 7(a) is a . In this case the lo ok ahead pro cess f a g[f b; c; d; e g do es not yield a frequen t itemset. The same is true of the next lev el-1 no de b . On the other hand, in the case of the Figure 7(b), the rst no de whic h is visited b y the depth-rst searc h pro ce-dure is the no de e , and the pro cess of lo ok ahead e [f b; a g yields a frequen t itemset. This example tends to suggest the follo wing heuristic rule for c ho osing go o d orderings: The item which o c curs in the fewest numb er of lar ge itemsets hanging at a no de should b e rst and the item o c curing in the maximum numb er of lar ge itemsets should b e last. Unfortunately , w e do not kno w the large itemsets apriori. Consequen tly ,w e found the strategy of ordering from least supp ort to most supp ort to b e a reasonable appro ximation of the ab o v e goal. This tec hnique has b een discussed earlier b y other researc hers [7] in order to maximize the eciency of lo ok aheads. The eciency of the algorithm is impro v ed further b y using a dynamic ordering as opp osed to a static ordering. In the case of dynamic orderings, w e reorder the items b elo w eac h no de dep ending up on the supp ort of eac h lexicographic tree-extension.
 All itemsets generated in the DepthPr oje ct algorithm are created b y either lo ok aheads, or b y buc k eting at the lo w er lev el no des. Therefore, at the termination of the algorithm, w e are left with a set of frequen t itemsets whic h con tains all frequen t maximal itemsets with some of the subsets of max-imal itemsets. Therefore, at the termination of the Depth-Pr oje ct algorithm, all non maximal itemsets are remo v ed in a pruning phase. The space requiremen ts of the depth rst strategy are not signi can tly more than the size of the transaction set it-self. This is b ecause only one path of the lexicographic tree is b eing explored at an y momen t of time. The space re-quired for main taining all the sets of bitv ectors is a small fraction of the transaction set size. If the geometric reduc-tion rule for selectiv e pro jection is used, and the database is pro jected only if it reduces b y a factor of Q&gt; 1, then the space requiremen ts for all transaction sets on the curren t path are no larger than Q= ( Q 1) of the original transac-tion set size. F urthermore, w eha v e already sho wn that for problems whic h are amenable to the depth rst strategy , the transaction represen tation can b e c hanged to a m uc h more ecien t form. This results in considerable sa vings. The exp erimen ts w ere p erformed on an IBM RS/6000 43P-140 w orkstation with a CPU clo c k rate of 200 MHz, 128 MB of main memory , 1MB of L2 Cac he and running AIX 4.1. The data resided in the AIX le system and w as stored on a 2GB SCSI driv e.
 W e tested the algorithm on a n um b er of datasets whic hha v e b een used earlier [7], for testing the algorithm in the case when it is p ossible to mine long patterns from the data. The algorithm prop osed in [7] is v ery ecien t for the case of nding long maximal patterns b ecause of its abilit y to mine out the max-patterns b y using lo ok-ahead tec hniques. The c haracteristics of the data sets are illustrated in the T able 1. The next to last column in this table illustrates the n um b er of large 1-itemsets at the lo w est supp ort lev el. As w e can see, the ratio of the a v erage record width to j L in these data sets is quite high compared to t ypical retail data. This c haracteristic is true for most datasets whic h ha v e long patterns in them. This ratio increases signi can tly at the lo w er lev el no des, when the database is pro jected. The length of the longest pattern at the lo w est supp ort lev el is in the last column of the T able 1. As w e can see, man y of these patterns are so long that explicit en umeration of all subsets of these patterns w ould ha v e b een unrealistic. In Figures 8(a) and 8(b), w e ha v e illustrated the p erfor-mance of our algorithm v ersus the MaxMiner metho d on the c onne ct-4 and mushr o om datasets. All plots are made on a logarithmic scale in order to illustrate the order-of-magnitude p erformance di erence b et w een the di eren t al-gorithms. As w e see, the DepthPr oje ct algorithm quic kly outstrips the MaxMiner metho d when supp ort v alues are lo w. F or the c onne ct-4 dataset, at the highest supp ort v alue of 90%, the MaxMiner algorithm required 9.4 seconds, while the DepthPr oje ct tec hnique required 5.87 seconds. A t the lo w est supp ort v alue of 10%, the MaxMiner algorithm re-quired 5624.7 seconds, while the DepthPr oje ct algorithm re-quired only 370.38 seconds. Th us, the p erformance gap in-creased at lo w er v alues of supp ort, so that at the lo w est supp ort v alue, the p erformance gap b et w een the t w o meth-ods w as a factor of 15.2.
 The m ushro om dataset also exhibits a large p erformance gap, though the di erence is less dramatic in this case. A t the highest supp ort lev el of 10%, the MaxMiner algorithm required 2 : 35 seconds, whereas the DepthPr oje ct algorithm required 0 : 53 seconds. A t the lo w est supp ort lev el 4 of 0 : 1%, MaxMiner algorithm required 65 : 19 seconds, whereas the DepthPr oje ct algorithm required 16 : 92 seconds. The p erfor-mance gap b et w een the t w o metho ds w as a factor of 4 to 5 for all the supp ort lev els tested.
 The most striking p erformance impro v emen ts w ere observ ed in the case of the chess and pumsb data sets. This is b ecause these data sets corresp ond to cases when there are a large n um ber of v ery long patterns. The p erformance n um b ers for the pumsb dataset are illustrated in Figure 9(a). A t the highest supp ort lev el of 35%, the MaxMiner algorithm required 13 : 91 seconds, whereas the DepthPr oje ct algorithm required 3 : 31 seconds. Th us, the p erformance gap at the highest supp ort lev el w as a factor of 4. A t the lo w est supp ort lev el of 5%, MaxMiner algorithm required 461.19 seconds, while the DepthPr oje ct algorithm required 7378.6 seconds. This is a p erformance gap of appro ximately 16.
 In the case of the chess dataset, whic h is illustrated in Figure 9(b), the most dramatic di erences in p erformance w ere ob-serv ed. A t the highest supp ort lev el of 60%, the MaxMiner algorithm required 9 : 08 seconds, whereas the DepthPr oje ct algorithm required 0 : 58 seconds. This is a p erformance gap of appro ximately 15.655. A t the lo w est supp ort lev el of 20%, the MaxMiner algorithm required 2442 : 58 seconds, whereas the DepthPr oje ct algorithm required 120 : 06 seconds. Th us, at the lo w est supp ort lev el, the p erformance gap w as a factor of 20 : 34.
 The DepthPr oje ct algorithm required a p ostpro cessing phase in whic h the non-maximal itemsets w ere remo v ed. (The times illustrated include the p ostpro cessing phase.) The time for this p ostpro cessing phase dep ended up on the n um-b er of itemsets whic hw ere found b y the tree generation and coun ting phase of the algorithm. As w e can see from the the last t w o columns of T able 2, the n um ber of itemsets found closely matc hes the maximal itemsets for the chess and c onne ct-4 data sets. This indicates that the pro cess of lo ok aheads w as quite e ectiv e in remo ving the non-maximal patterns quic kly . The times for coun ting and pruning are also illustrated in the same table. (The column corresp ond-ing to the coun ting pro cedure ma y b e obtained b y adding the T (+32) and T ( 32) columns, whic h will b e explained b elo w.) 4 Note that the lo w est supp ort lev el for Figure 8(b) is 0 : 1%. The implemen tation of the DepthPr oje ct algorithm assumed that the only time that a database w as pro jected at a no de w as at the highest lev el of the tree at whic h the n um ber of frequen t extensions of the itemset b ecame less than 32. It is instructiv e to compare the time tak en in order to generate ab o v e the lev el of 32 bit pro jection to the time tak en in order to generate the tree b elo w the lev el of 32 bit pro jection. It is apparen t from T able 2 that the time required in order to coun t b elo w the 32 bit lev el ( T (+32)) w as substan tially more than the time required to coun tabo v e the 32 bit lev el ( T ( 32)) for all four data sets. F urthermore, since the most ecien t coun ting of the algorithm on a p er no de b asis w as p erformed b elo w the 32 bit lev el, it follo ws that most of the time w as sp en t in suc h ecien t coun ting. This also establishes that the ecien t represen tation of the database at the lo w er lev els of the tree con tribute substan tially to the sa vings in computational time. This pap er in v estigated a no v el tec hnique for mining long patterns in databases, whic h relies on a depth-rst searc h tec hnique in order to construct the lexicographic tree of itemsets. The use of depth-rst searc h in reducing the n um-ber of itemsets is critical in b eing able to mine v ery long patterns at lo wv alues of supp ort. The tec hnique of depth-rst searc h is optim um from the p ersp ectiv e of no de pruning and p erforming the coun ting ecien tly b y using transaction pro jection. The depth rst tec hnique pro vides the abilit y to generate long patterns of the tree fast, and prune a w a y the non-maximal patterns earlier on. A t the same time, it pro vides the exibilit y for no de-sp eci c pro cessing meth-ods suc h as buc k eting. These c haracteristics explain the excellen t computational prop erties of the DepthPr oje ct al-gorithm. W ew ould lik e to thank Rak esh Agra w al and Rob erto Ba-y ardo for pro viding us with sev eral datasets for testing our algorithms. Rob erto also pro vided us with access to his MaxMiner co de for p erforming exp erimen ts. [1] R. C. Agarw al, C. C. Aggarw al, V. V. V. Prasad. A T ree Pro jection Algorithm for nding frequen t itemsets.
Journal on Par al lel and Distribute d Computing ,to app ear. [2] R. C. Agarw al, C. C. Aggarw al, V. V. V. Prasad. Depth First Generation of Large Itemsets for Asso ciation
Rules. IBM R ese ar ch R ep ort R C 21538 , July 1999. [3] C. C. Aggarw al, P .S.Y u. Online Generation of
Asso ciation Rules. ICDE Confer enc ePr o c e e dings , pages 402{411, 1998. [4] C. C. Aggarw al, P .S.Y u. A New F ramew ork for Itemset Generation. A CM PODS Confer enc e
Pr o c e e dings , pages 18{24, 1998. [5] R. Agra w al, T. Imielinski, A. Sw ami. Mining Asso ciation Rules b et w een Sets of Items in V ery Large
Databases. A CM SIGMOD Confer enc ePr o c e e dings , pages 207{216, 1993. [6] R. Agra w al, R. Srik an t. F ast Algorithms for Mining
Asso ciation Rules. VLDB Confer enc ePr o c e e dings , pages 487{499, 1994. [7] R. J. Ba y ardo. Ecien tly Mining Long P atterns from
Databases. A CM SIGMOD Confer enc ePr o c e e dings , pages 85{93, 1998. [8] R. J. Ba y ardo, R. Agra w al. Mining the Most In teresting Rules. A CM SIGKDD Confer enc e
Pr o c e e dings , pages 145{154, 1999. [9] S. Brin, R. Mot w ani, J. D. Ullman, S. Tsur. Dynamic Itemset Coun ting and implication rules for Mark et
Bask et Data. A CM SIGMOD Confer enc ePr o c e e dings , pages 255{264, 1997. [10] C. Silv erstein, R. Mot w ani, S. Brin. Bey ond Mark et Bask ets: Generalizing Asso ciation Rules to Correlations.
A CM SIGMOD Confer enc ePr o c e e dings , pages 265{276, 1997. [11] B. Dunk el, N. Sopark ar. Data Organization and Access for Ecien t Data Mining. ICDE Confer enc e
Pr o c e e dings , pages 522{529, 1999. [12] T. F ukuda, Y. Morimoto, S. Morishita, T. T okuy ama. Mining Optimized Asso ciation Rules for Numeric
A ttributes. A CM PODS Confer enc ePr o c e e dings , pages 182{191, 1996. [13] T. F ukuda, Y. Morimoto, S. Morishita, T. T okuy ama. Data mining using Tw o-dimensional Optimized Asso ciation Rules for Numeric A ttributes: Sc heme, Algorithms, Visualization. A CM SIGMOD Confer enc e
Pr o c e e dings , pages 13{23, 1996. [14] D. Gunopulos, H. Mannila, S. Saluja. Disco v ering All Most Sp eci c Sen tences b y Randomized Algorithms.

ICDT Confer enc ePr o c e e dings , pages 215{229, 1997. [15] J. Han, J. P ei, Y. Yin. Mining F requen tP atterns without Candidate Generation. A CM SIGMOD
Confer enc ePr o c e e dings , pages 1{12, 2000. [16] C. Hidb er. Online Asso ciation Rule Mining. A CM
SIGMOD Confer enc ePr o c e e dings , pages 145{156, 1999. [17] D. Lin, Z. M. Kedem. Pincer-Searc h: A New Algorithm for Disco v ering the Maxim um F requen t
Itemset. EDBT Confer enc ePr o c e e dings , pages 105{119, 1998. [18] H. Mannila, H. T oiv onen, A. I. V erk amo. Ecien t algorithms for disco v ering asso ciation rules. AAAI
Workshop on KDD , 1994. [19] M. Klemen ttinen, H. Mannila, P . Ronk ainen, H. T oiv onen, A. I. V erk amo. Finding In teresting Rules from Large Sets of disco v ered asso ciation rules. CIKM
Confer enc ePr o c e e dings , pages 401{407, 1994. [20] L. V. S. Lakshmanan, R. Ng, J. Han, A. P ang.

Optimization of Constrained F requen t Set Queries with 2-v ariable Constrain ts. A CM SIGMOD Confer enc e
Pr o c e e dings , pages 157{168, 1999. [21] B. Nag, P . M. Deshpande, D. J. DeWitt. Using a Kno wledge Cac he for In teractiv e Disco v ery of Asso ciation Rules. A CM SIGKDD Confer enc e
Pr o c e e dings , pages 244{253, 1999. [22] R. Rastogi, K. Shim. Mining Optimized Asso ciation Rules for categorical and n umeric attributes. ICDE
Confer enc ePr o c e e dings , pages 503{512, 1998. [23] R. Rastogi, K. Shim. Mining Optimized Supp ort Rules for Numeric A ttributes. ICDE Confer enc e
Pr o c e e dings , pages 126{135, 1999. [24] I. Rigoutsos, A. Floratos. Com binatorial P attern
Disco v ery in Biological Sequences. Bioinformatics , 14(1): pages 55{67, 1998. [25] R. Rymon. Searc h Through Systematic Set En umeration. International Confer enc e on Principles of
Know le dge R epr esentation and R e asoning , 1992. [26] A. Sa v asere, E. Omiecinski, S. B. Na v athe. An Ecien t Algorithm for Mining Asso ciation Rules in
Large Databases. VLDB Confer enc ePr o c e e dings , pages 432{444, 1995. [27] R. Srik an t, R. Agra w al. Mining Generalized
Asso ciation Rules. VLDB Confer enc ePr o c e e dings , pages 407{419, 1995. [28] R. Srik an t, R. Agra w al. Mining Quan titativ e Asso ciation Rules in Large Relational T ables. A CM
SIGMOD Confer enc ePr o c e e dings , pages 1{12, 1996. [29] M. J. Zaki, S. P arthasarath y , M. Ogihara, W. Li. New Algorithms for F ast Disco v ery of Asso ciation Rules.
KDD Confer enc ePr o c e e dings , pages 283{286, 1997.
