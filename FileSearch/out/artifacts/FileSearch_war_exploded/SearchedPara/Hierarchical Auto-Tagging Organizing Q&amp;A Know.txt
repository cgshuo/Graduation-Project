 We propose a hierarchical auto-tagging system, TagHats ,to improve users X  knowledge sharing. Our system assigns three different levels of tags to Q&amp;A documents: category, theme, and keyword. Multiple category tags can organize a docu-ment according to multiple viewpoints, and multiple theme and keyword tags can identify what the document is about clearly. Moreover, these hierarchical tags will be helpful in organizing documents to support everyone because different users have different demands in terms of tag specificity. Our system consists of a hierarchical classification method for as-signing category and theme tags, a new keyword extraction method that considers the structure of Q&amp;A documents, and a new method for selecting theme tag candidates from each category. Experiments with the documents of Oshiete! goo demonstrate that our system is able to assign hierarchi-cal tags to the documents appropriately and is capable of outperforming baseline methods significantly.
 H.3.4 [ Information Search and Retrieval ]: Systems and Software X  Question-answering (fact retrieval) systems ;H.3.5 [ Information Search and Retrieval ]: Online Informa-tion Services X  Web-based services Algorithms, Experimentation Community question answering, auto-tagging, text classifi-cation, keyword extraction, Oshiete! goo
Question-and-answer (Q&amp;A) communities have evolved worldwide as new repositories of collective knowledge. In the communities, anyone can ask and answer any question at anytime, and all users can share all knowledge.
Current representative communities, such as Yahoo! An-swers , Naver Knowledge-iN ,and Oshiete! goo , organize Q&amp;A documents by using category hierarchies. When a user asks a question, the user selects a single submission category, which is the bottom (leaf) category of the hierarchies.
The category hierarchies, however, seem to have reached the limit of their capacities for organizing documents; it is getting more difficult to find appropriate categories for ask-ing and answering questions. Which category is suitable for if the user wants to submit the question  X  X ow do I clean my stuffed animals? X  in: Cleaning &amp; Laundry or Toys ?Many questions touch on multiple topics, and the hierarchies con-tain too-general, non-exclusive, or ambiguous categories.
Tags, short words that are assigned to a piece of infor-mation, are a strong alternative to the category hierarchies. Tag-based organization places no restriction on the number, content, and specificity of tags. The representative com-munities have already stored a huge number of untagged Q&amp;A documents, so we believe that automatically assigning appropriate tags to untagged documents, instead of social tagging, is necessary to improve users X  knowledge sharing.
Therefore, we propose a hierarchical auto-tagging system, called TagHats . Hierarchical tags our system assigns will be useful for everyone because different users have different de-mands in terms of tag specificity: some users may search for various documents by the Toys category tag, while others may search for specific documents by the Teddy b ear key-word tag. This paper can make a contribution to improving knowledge management of untagged (but categorized) doc-uments.
Our system uses two approaches for tagging: text classifi-cation and keyword extraction (Figure 1). Since appropriate words for general tags are not likely to appear in documents; our system uses a classification approach to identifying cat-egory and theme tags. On the other hand, the classification approach has difficulty in handling new and specific key-words. Our system, therefore, extracts keywords from the given document as tags. The keyword extraction is indepen-dent of category and theme tags, and keyword tags can yield links between documents belonging to various categories.
The text classification approach needs the tag candidates to be fixed before tagging can be performed. Any good restaurants in Toronto? Figure 1: Concept image of our TagHats system.

First, our system just uses the names of the submission categories as the candidates of category tags. Our system overcomes the problems caused by the categories with using hierarchical tags instead of re-organizing the categories.
Next, our system prepares theme tag candidates from each category.

Let w be a noun word (or phrase); c be a category;  X  c be all categories except category c ; D be the total number of documents in the training corpus; D c be the number of documents belonging in category c ; D ( w )bethenumberof documents in which word w occurs (document frequency); D ( w ) be the number of documents, in which word w occurs, belonging to category c ;and T c ( w )bethe title frequency ,the number of question titles, in which w occurs, of documents belonging to category c .

Our system statistically tests whether word w is a theme tag candidate, by comparing two proportions, p 1 = T c ( w ) /D (the null hypothesis is p 1 = p 2 , the alternative hypothesis is p &gt;p 2 , and the significance level is  X  ). Note that word w is excluded from theme tag candidates for category c if T c ( w )is less than N low , where N low prevents our system from select-ing too-specific words. Although the  X  2 test and the NGL coefficient (can be viewed as a one-sided  X  2 statistic)[8] are alternatives to the Fisher X  X  Exact test, the  X  2 statistic is known not to be reliable for low-frequency words[10].
Category and theme tags, { c, t } , indicating the high prob-ability of document d belonging to category c and covering theme t , p ( c, t | d ), will be appropriate tags. Our system han-dles many X  X ver 10,000 X  X heme tag candidates, so it is very difficult to distinguish a theme from a similar theme with the straightforward estimation of p ( c, t | d ). Our system, there-fore, decomposes the probability p ( c, t | d )= p ( c | d ) p ( t and estimates p ( c | d )and p ( t | c, d ).

First, our system uses Bayes X  rule to compute p ( c | d ): and assumes that the words contained in the given docu-ment, w 1 ,w 2 ,...,w n  X  X  , are all conditionally independent of one another. Probability p ( d | c )isestimatedas: where f ( w )istermfrequency(numberoftimesthatword w occurs in the given document). p ( w | c )isestimatedas: where the vocabulary set in the training corpus is defined as
V = { w | D ( w )  X  N cutoff } and the value of  X  determines the strength of the smoothing in Equation (3). The value of F c ( w ) is the number of times that word w occurs in the training corpus. Threshold N cutoff is the rare word cutoff[3].
Next, the given document will contain words inappropri-ate for classification. There are not enough documents to cover all categories, so the estimation provided by Equa-tion (3) may be inaccurate for some words. Our system, therefore, selects feature word set defined as:
Definition 1. The feature word set , FW , consists of the words having the N feature highest values of  X  2 max ( w )among the words { w  X  X | D ( w )  X  N cutoff } , where  X  2 max ( w )=max c  X  c ( w )= and our system replaces W with FW in Equation (2). Note that our system selects different feature word set for every given document in order to calculate p ( w | c ) for very short documents surely. Although other feature selection meth-ods ( e.g. , Bi-Normal Separation[3]) are available, our system uses common  X  2 statistics for feature selection because of its good performance and low computational complexity.
Then, the prior probability p ( c ) can be estimated from the training corpus; however, our system ignores p ( c )be-cause the prior probabilities are strongly skewed. p ( d )is also ignored because it does not depend on c .

Moreover, to assign only relevant tags to the given doc-ument, our system compares p ( c | d )with p (  X  c | d ): c is not selected as category tags if log ( p ( c | d ) /p (  X  c |
Furthermore, our system is able to estimate p ( t | c, d )in thesamemanneras p ( c | d ). p ( w | c, t )isestimatedas: where the vocabulary set of category c in the training corpus is
V c = { w | D c ( w )  X  N cutoff } and F c,t ( w )isthenumberof times that word w occurs in the documents belonging to category c and covering theme t . We defined that:
Definition 2. A document is said to cover theme t when the question title or body of the document includes word t . The value of  X  determines the strength of this smoothing,
To summarize, given document d , our system assigns mul-tiple category and theme tags { c, t } to the document, in descending order of the likelihood ratio of the tag-pair, among the tag-pair set satisfying these constraints, log where { c,  X  t } means all themes except theme t in category c .
Keyword tags should identify what the given document is about clearly and link the given document with other relevant documents. We hypothesize that the words in both the question and answer of the given and relevant documents are suitable for keyword tags.

Our system uses the residual inverse document frequency (RIDF), which is defined as the difference between the ob-served IDF and the IDF expected by chance (Poisson)[1], with the section frequency (SF):
SF-RIDF( w )= s ( w )  X  and assigns the keyword tags that have N keyword highest scores of SF-RIDF( w ) among the words contained in the given document w  X  X  . s ( w )isthe section frequency ,the number of sections, in which word w occurs, of the given document and S ( w ) is the total section frequency of w in the training corpus. Note that the document consists of three sections: question title, body, and all (combined) answers. The merits of our SF-RIDF weighting over common TF-IDF weighting are: (1) offer robustness to noise words ( e.g. , abused words, too-specific words, or typographical errors) that are unique to a single section and (2) can extract key-wordsevenifthekeywordsoccurinmanydocuments.

The reasons for the first merit are: such noise words are not likely to occur in multiple sections, and the SF value is not impacted by a large number of noise words in a single section. Next, the reason for the second merit is that RIDF values can be high for words occurring in many documents of the training corpus, unlike IDF values. Independent of the document frequency, the observed IDF values of words that tend to occur many times in a document are farther from the expected IDF.

Note that our SF-RIDF weighting can extract entirely new keywords ( D ( w )=0and S ( w ) = 0) if the words occur in both question and answers ( s ( w )  X  2) in the given docu-ment.
This section evaluates the components of our TagHats sys-tem. Our system used JTAG[4] as the text segmentation system, and all parameters our system used were  X  =0 . 01,  X  =0 . 1,  X  =0 . 1, N low =3, N cutoff =3,and N feature = 100.
The training corpus consisted of the 777 , 266 Q&amp;A docu-ments (389 categories), submitted from 1 April 2008 to 31 March 2009, of the Oshiete! goo community. The test data set consisted of the 10 , 000 documents, submitted from 1 April 2009 to 5 April 2009.
A Japanese ranking website, goo-ranking , provided the top 50 searched disease names of 2009 in Japan 1 .Topsearched words are strongly related to theme words because the con-tents of Q&amp;A documents reflect the questions and inter-ests of the users in the Internet; therefore, we compared http://ranking.goo.ne.jp/ranking/n09/n2009 health keyword/ (in Japanese) Figure 2: Precision-recall curves for the top 50 searched disease names.
 Figure 3: Top 50 theme tag candidates selected from Disease category by proposed method. Bold 22 tags are contained in the top 50 searched disease names. The tags are translated from Japanese. the top searched disease names with the results of selecting the theme tag candidates from the Disease category in the Oshiete! goo community (13,050 documents in the training corpus).

We tested our proposed method (NF Fisher) and six con-ventional methods: DCLY specificity[2] (DCLY), NGL coef-ficient[8] (NGL), NGL coefficient using question titles (NGLT), signed Information Gain[11] (SIG), signed Bi-Normal Sepa-ration[3] (SBNS), and odds ratio [7] (OR). All of the meth-ods excluded words that satisfied T c ( w ) &lt; 3(= N low candidates for category c as in our proposed method.
Figure 2 shows the precision-recall graph; our method clearly yielded the best performance. The NF Fisher and NGLT methods, which focus on question titles, performed better than the other methods. The SBNS, OR, and DCLY methods performed especially poorly because they empha-sized the too-specific words that occurred only in the Disease category. Moreover, the difference between the NF Fisher and NGLT methods was caused by the low reliability of the  X  2 statistic for low-frequency words[10].

Figure 3 shows the top 50 theme tag candidates (having 50 lowest p -values) selected from the Disease category with our method; our method was able to select medical words very accurately.

Note that our system selected 34 , 604 theme tag candidates (26 , 438 kinds, average number of candidates per category: 93 . 3) from the training corpus for all categories. Figure 4: Agreement rates between asker-selected category and any of system-assigned category tags.
We compared hierarchical classification, L ( c, t ), which is shown by Equation (6), to flat category classification, p ( c and flat category-theme classification, p ( c, t | d ).
Figure 4 shows the agreement rates between the cate-gory selected by the asker and any of the category tags that our system assigned. Flat category-theme classification per-formed poorly because there were not enough documents for all categories and themes. When the number of category tags was less than five, hierarchical classification improved the agreement rate statistically significantly compared to flat category classification ( p&lt;. 01, sign test).
We compared the theme and keyword tags that our system assigned with the tags that the users of Hatena Bookmark , which is one of the largest social bookmarking services in Japan, assigned to the Q&amp;A documents of Oshiete! goo. We used 122 documents 2 that were assigned at least three tags by at least two users.

Figure 5 shows the rates that any of the tags that our sys-tem assigned were one of the tags assigned by the users. SF-RIDF achieved statistically significantly higher agreement rates than TF-IDF when the number of assigned tags was greater than three ( p&lt;. 01, sign test).
This paper proposed an auto-tagging system that assigns hierarchical tags to Q&amp;A documents. Our proposed hierar-chical auto-tagging system, TagHats , assigns three different levels of tags X  X ategory, theme, and keyword tags X  X o the documents. Our system consists of a hierarchical classifica-tion method, a new keyword extraction method (SF-RIDF), and a new method for selecting theme tag candidates from each category (NF Fisher).

Related work on auto-tagging for blog entries includes: collaborative filtering[6], text classification [5], and topic crawled from http://b.hatena.ne.jp on 3 February 2010. Figure 5: Rates that any of system-assigned tags are contained in the tags that the users of the Hatena social bookmarking service assigned. model[9]. These methods learn based on user-assigned tags and so are not suitable for Q&amp;A communities that have no such tags. Moreover, they do not yield any tag hierarchy.
Our future work aims to resolve the problems of synonym and to improve the diversity of theme and keyword tags. [1] K. W. Church and W. A. Gale. Inverse document [2] H. Duan, Y. Cao, C.-Y. Lin, and Y. Yu. Searching [3] G. Forman. An extensive empirical study of feature [4] T. Fuchi and S. Takagi. Japanese morphological [5] S. Fujimura, K. Fujimura, and H. Okuda.
 [6] G. Mishne. AutoTag: A collaborative approach to [7] D. Mladenic and M. Grobelnik. Feature selection for [8] H.T.Ng,W.B.Goh,andK.L.Low.Featureselection, [9] X. Si and M. Sun. Tag-LDA for scalable real-time tag [10] Y. Yang and J. O. Pedersen. A comparative study on [11] A. Zheng, X. Wu, and R. Srihari. Feature selection for
