 Although there are many papers examining ambiguity in Information Retrieval, this paper shows that there is a whole class of ambiguous word that past resear ch has barely explored. It is shown that the class is more am biguous than other word types and is commonly used in queries. The lack of test collections containing ambiguous queries is highlighted and a method for creating collections from existing resources is described. Tests using the new collection show th e impact of query ambiguity on an IR system: it is shown that conventional systems are incapable of dealing effectively with such queries and that current assumptions about how to improve search effectiveness do not hold when searching on this common query type. H.3.3 [ Information Search and Retrieval ]: Systems and Software ---performance evaluation.
 Measurement, Experimentation. Ambiguous queries, test collections, diversity. Word sense ambiguity is a topic that has been studied for many years in the Information Retrieval (IR) community, starting with Weiss X  X  small scale e xperiments [21] through to a more thorough examination of the topic in the 1990s. Most of the past disambiguation research focussed on ambiguity of words found in dictionaries, which have poor cove rage of proper nouns or phrases increasingly clear that names of people, locations, organizations, acronyms, etc, are common queries in search engines. Some of these nouns will have high levels of ambiguity, but the extent of the ambiguity is little understood. While disambiguation research wa s studied explicitly, it was also studied implicitly with research on result list clustering, sub-topic retrieval and other algorithms for increasing diversity in search results. While some of this res earch has shown improvement in retrieval effectiveness, studies of this type are hampered by a lack of test collections containing ambiguous queries. Consequently, this paper desc ribes a re-examination of the problem of word ambiguity and an exploration of possible solutions to the lack of appropriate test collections for this area of IR. The work addresses the following research questions:  X  How common is ambiguity in words not normally found in  X  What form does such ambiguity take?  X  How common is ambiguity in que ries to search engines?  X  How well do existing test collections support research in  X  How much does ambiguity impact on IR effectiveness? This paper describes the study, st arting with a review of past literature. The main data set used in the ambiguity study is described next followed by an anal ysis of it. Next, query logs are examined for ambiguity. This is followed by a study of ambiguity on a search engine using a variety of ranking algorithms. In this Section, the past work in the following topics is examined: research on the extent and nature of ambiguity when searching; research seeking to diversify the documents appearing in a ranking; research on word sens e disambiguation and the limited work on building test collecti ons with ambiguous queries. Krovetz [13] conducted a careful examination of the extent of word sense ambiguity in test co llections (e.g. TIME and CACM). He found that the different senses of ambiguous query words provided good separation between relevant and non-relevant documents. In addition, by looking up query words in a dictionary (Longman X  X  Dictionary of Contempor ary English) he was able to calculate the average number of senses per non-stop word in the test collection topics. For CACM it was 5.3, for TIME it was 4.8. However, he found that retrieva l based on the queries, rarely benefited from disambiguation as highly ranked documents tended to match on a number of words in the query. In such situations, ambiguous query word s generally match only on the correct sense. For example, despite the word  X  X at X  being ambiguous, the query  X  X at echoloca tion X  is unlikely to retrieve top ranked documents referri ng a sporting implement. At the time of Krovetz X  X  study, it was largely assumed that queries to ranked retrieval syst ems would typically be sentence like statements expressing detailed information needs. Jansen and Spink amongst others showed that queries are typically much shorter [12], therefore potentially more ambiguous. In addition, Krovetz X  X  work along with other disambiguation research of the time largely focussed on ambiguity as defined in dictionaries or online thesauri such as WordNet. Such reference corpora provided excellent coverage of ambiguous words. However, their coverage of proper nouns was poor. In recent years there has been a gr owth of research into certain types of ambiguous proper nouns with particular focus on people and place names. (Note, the different entities an ambiguous proper noun could refer to are known as referents .) SemEval 2007 ran the Web People Search evaluation (WePS, Artiles, et al, [2]), which focussed on the disambiguation of individuals when their names are searched for on a retrieval system. Artilles et al justified their investigation by stating that the United States Census Bureau record that 90,000 names are shared by 100 million people in the U.S. A training corpus composed of 100 web pages, retrieved by the Yahoo! search engine, for each of 39 person names was built; each page was manually annotated to mark up the different people (i.e. the referents) sharing a name. A test set of the 100 pages retrieved for each of 30 further person names was also created and annotated. Seventeen participants submitted r uns that mostly outperformed a baseline. The authors of the ev aluation campaign noted, however, that there were some unexpected qualities to the test data and it is possible that this may have had an impact on this year X  X  results. There has also been much work examining the task of disambiguation of place names. Leidner provides a thorough survey of this research field [14]. Unlike WePS, there is as yet no common evaluation test bed for comparing the effectiveness of place name disambiguation systems. What is currently missing from work in these two research areas is a study of the extent of such ambiguity in user queries and any impact it might have on retrieval effectiveness. Voorhees [20] conducted the first large scale study of a word sense disambiguation system applie d to the topics and documents of 5 test collections. Words were disambiguated and the retrieval effectiveness of an IR system applied to those collections was compared to the effectiveness of the system searching on the collection without disambiguation. Perhaps unexpectedly, use of disambiguation reduced effectiv eness. Analysing Voorhees X  result, Sanderson [15] used a pr ocess for simulating ambiguity called pseudo-words 1 . He presented results showing the negative impact of disambiguation errors on retrieval effectiveness and suggested that this was the cause of Voorhees X  X  negative result. He also showed how retrieval based on very short queries was affected by ambiguity. Researchers continued to study the topic and in later work, Sanderson et al showed some lim ited value in using word sense disambiguation in retrieval [16], as did Gonzalo et al [11]. Both studies, however, were on small or very small test collections. In the field of cross language retrie val, correct query translation presupposes some form of ambiguity resolution of query words. Work from Darwish and Oard [8], showed success through consideration of sense. In monoli ngual research, Stokoe et al [19] showed a clear value in conducti ng disambiguation using one of the relatively large TREC Web corpora, WT10G. All of the research described in this Section makes a common assumption: that at the time an ambiguous query is submitted to a search engine, it will be known somehow, which sense of each ambiguous word was intended by the person who issued the Developed by both Gale et al [9] and by Sch X tze [17]. query. Such information might be worked out from the query itself (if the query is detailed enough), from a profile of the user held by the search engine, from information on the context of the search, click data from past searches, or simply by asking the user to clarify their information need. However, it is not clear that such information will always be available to an operational search engine. If such data is missing, the only alternative is for the engine to return a diverse ranking composed of documents that are relevant to different interpretations of the ambiguous query. This appears to be a reasonable strategy in the face of such queries, however, there are no publicly available test collections that contain ambiguous queries in order to test such a strategy. Across virtually all test collections used in IR research, topics have a single interpretation, which is explicitly defined in the topic X  X  description and/or narrativ e and implicitly defined in its relevance judgements. Collections are set up in this way as each topic is created to represent the information need of one person. The idea of defining single interpretations for test collection topics started with Cleverdon when building the Cranfield collection. In a reflective piece [7] he described how this feature of Cranfield was introduced after he witnessed the problems of two search groups in the 1950s w ho attempted to compare their retrieval systems. The groups agreed on a common set of documents and topics for tes ting. However, the relevance judgements, and therefore the interpretation of the topics, were left undefined. Cleverdon reported that when the two groups came together to compare effectiveness scores, they discovered they had different relevance judgement s because they had interpreted the topics differently. Cleverdon recounts that the groups spent the whole of the first day of their meeting arguing about the interpretation of just the first topic. One lesson Cleverdon appears to ha ve drawn is the importance of defining relevance judgements in a test collection. The other lesson is to base judgements on one person X  X  interpretation of the topic. While most would agree on the correctness of the first lesson, in the light of the short ill defined queries submitted to modern search engines, it is less clear how many would agree on the universality of the second. There is a collection that test ed an area related to ambiguous queries: the 20 topic collection built for the TREC interactive track. Its topics addressed broad themes that had within them a number of instances or sub-topics that search engines were expected to retrieve. The instances were identified by TREC assessors: on average, there were 20 per topic. To illustrate, topic 353i (selected at random) from TREC 7 has the title  X  Antarctic exploration  X , the user need was to  X  Identify systematic explorations and scientific investigati ons of Antarctica, current or planned  X . In total, 11 instances were identified  X  mining prospection  X  analysis of toxic waste  X  oil resources  X  whale scientific research  X  rhodium exploration  X  antarctic sonar mapping  X  ozone hole / upper atmosphere  X  ice studies  X  greenhouse effect  X  climate studies  X  measuring chemicals in the atmosphere More recently, 20 topics in the Million Query Track of TREC (Allan et al, [1]) were also cr eated with multiple instances: on average 3.1 per topic. Clarke et al [6] pointed out that the TREC 2005 and 2006 Question Answering co llections have similarities to the instance/sub-topic collections and used the QA collections as a proxy for experiments with ambiguous queries. It would appear that the approach used to ensure that different sub-topics of a general query are re trieved, is broadly the same as the approach used to ensure that different interpretations of an ambiguous query are retrieved: the approach being some form of clustering. Most of the early work on clustering (surveyed by Willett, [22]) focused on sub-topi c retrieval. Maximal Marginal Relevance (MMR) from Carbonell et al [3] and more recently the work of Zhai et al [23] continued to study this area. Zhai et al used the 20 TREC interactive track topics to show the worth of their approach. Chen &amp; Dumais [4] reported that users locate relevant items quicker in search results that are organised into well defined clusters. The queries they te sted on were ambiguous. Building search systems to tackle such queries was reported by Zhang et al [24] as well as Chen &amp; Karger [5]. Zhang et al measured effectiveness using an in-house test collection; Chen and Karger found a number of creative ways to test their system using TREC data. However, they were essen tially limited to testing sub-topic retrieval. Without test collections cont aining ambiguous topics with associated relevance judgement s that reflect a range of interpretations of that topic, the worth of much of the work described here may not be fully understood. Although past work has examined many aspects of ambiguity, it is not clear that assumptions behind that work still hold; the assumptions being: queries are long; ambiguous words in queries are not proper nouns and a search engines will know the correct interpretation of a topic at retrieval time. What appears to be missing from the body of past research is an understanding of the extent to which proper nouns are ambiguous and the extent of ambiguity in user queries acro ss all forms of ambiguous words. Finally, as described here and in past work [18], there is a lack of test collections for exam ining topic ambiguity. To re-examine the impact of ambiguity on search engine effectiveness, it was necessary to locate sources of ambiguous words and phrases. The classic study on the extent of ambiguity in test collections from Krovetz acknowledged the dictionary he used did not cover proper nouns. Consequently, we sought sources that had better coverage of such word forms. WordNet (version 3.0), contains 87,633 words in the English language of which 16,882 (19%) are proper nouns 2 . An examination of a randomly selected sample of 1% of these nouns revealed a wide range of place names, scientific terms, names of plants, people, organizations, objects, etc. There was a concern that as a source, WordNet did not cover a sufficient range of proper nouns: Artilles et al described 90,000 These were identified simply by capitalization. person names alone. Type specific lists of nouns and their referents, can be obtained, how ever, ambiguous words are likely to have referents across a numbe r of types: Springfield for example is both the name of many towns and cities, while at the same time being the name of a fictitious place in a popular television program and a relatively common surname. The online encyclopedia, Wikipedia, covers a great many topics that one might assume largely refl ect the interests and information needs of the population of users that access many search engines. Of particular interest are the resource X  X  great many so-called disambiguation pages that list the referents of ambiguous words and phrases most of which are proper nouns. The complete data set can be downloaded and the vast majority of pages relating to ambiguity can be identified relatively easily, by either matching the string  X  X disambiguation X  in the title of the article or, more commonly, finding the  X  X {disambi g}} X  template tag. The vast majority of disambiguation page s conform to an easily parsed format. Therefore, it was decided to use this collection to study ambiguity of Proper nouns. This was complemented with WordNet X  X  lists of other ambiguous word forms. The 12.7Gb collection  X  X nwiki-20071018-pages-articles.xml X   X  a snapshot of the Wikipedia Eng lish language pages without edit history from late 2007  X  was downloaded. It contained  X  2.2 million articles. It was parsed fo r disambiguation pages. In total 69,769 pages, identified just by the  X  X {disambig}} X  tag, were extracted. A further 29,504 pages were identified by the title string  X  X (disambiguation) X . Of the later set of pages, 10,164 were removed as they were found to be pages that simply re-direct to other disambiguation pages, leav ing 19,340 articles remaining. In total the number of ambiguous wo rds and phrases in Wikipedia identified through these two page forms was 89,109. The two page types are a widely used convention in Wikipedia to indicate different forms of ambi guity. If, through the collaborative processes of forming articles, it was  X  X ecided X  that a word or phrase had clearly one main referent , then that referent would be described in an article entitled with that word or phrase. The other referents were then packaged into a disambiguation page with the string  X  X disambiguation X  added at the end of the page title. For example, the article  X  X hicago X  is about the large city in the United States, and the other referents of that word are listed in the page  X  X hicago_(disambiguation) X . If, however, there is no consensus on a dominant sense for a word or phrase, the page for that word will be a disambiguation page. For example, the word  X  X abcock X  has many referents listed (e.g. person names, places, etc), no single referent of which is considered to be dominant. The structure of disambiguation pa ges was found to be consistent. (Determined by examining 182 disambiguation pages randomly selected; of these, 4 (2%) failed to adhere to the format.) Each referent was displayed in a bullete d list and referents of the same type were grouped together with the group given a title (see Figure 1). As can be seen, there is value in referring to the different uses of  X  X abcock X  as referents rather than senses, as the Wikipedia list of the range of ways in which this term can be used clearly are not senses in the trad itional definition of the word. For this particular term, the word is most likely used as part of a longer name. Nevertheless, it is lik ely that a search engine could 
People 
Geographic places 
Science 
History and law 
Fictional characters be presented with such a single word query and in the absence of any context information; the engine would do well to retrieve relevant documents referring to a number of these referents. WordNet v3.0 was downloaded and the word definition information stored in the thesaurus X  X  data files for each of the four main grammatical forms were ex amined. In total, 87,633 words were listed in WordNet, of wh ich 15,302 (17.5%) were found to be ambiguous. Using the heuristic that a proper noun can be identified by the word starting with a capital letter, 16,882 such nouns were found, of which 1,297 (7.7%) were ambiguous. Three lists of ambiguous words/phr ases were created: those from WordNet (labeled WN ); those disambiguati on pages in Wikipedia for which one referent was considered dominant ( Wi D ); and those pages for which no dominant referent existed ( Wi ND ). The lists of particular interest were WN and Wi ND . The former as it represented the words used in past studies of ambiguity; the later because it represented terms that are most likely to be important in further studies of ambiguity. An examination of Wikipedi a X  X  disambiguation pages was conducted, examining the number of referents, the length of the ambiguous words or phrases and the types of referents. Given the consistency of forma tting of disambiguation pages, it was possible to determine the num ber of referents in the pages simply by counting the number of bullet points on the page Table 1 shows the results of the study. The total number of referents in Wikipedia was approximately 617,000. Compared to the total number of English articles in Wikipedia, approximately 2.2 million, one can calculate that 28% disambiguation page. As can be s een, the number of referents per page follows a power law distribution with a long tail: the number of pages with 10 or more refere nts was substantial, constituting 22% of all pages. The average number of referents was 7.39. The distribution of referents was compared to the distribution of senses found in WordNet (shown in Table 2). As above, a power law distribution was observed, but with WordNet, the peak was higher and the tail was not as long. The average number of word senses was 2.96. The correctness of this simple heuristic was checked by analysing the random sample of 182 disambiguation pages from 
Wikipedia. It was found that counting bullet points over estimated the number of referents by under 5%. Note, it was occasionally found that a referent was further broken down into  X  X ub-referents X , these were ignored in this analysis. The size of the ambiguous words/phr ases was also calculated as shown in Table 3. As can be seen, the majority of ambiguous terms in Wikipedia were one wo rd long, however many longer terms exist also. A random sample of terms with &gt;4 words were examined and found to be often titles of songs, films, television programs that have been used by more than one production. 
Table 3. Word length of ambigu ous terms in Wikipedia (left) Table 3 also details the word length of ambiguous terms in WordNet. A comparison was made between the two resources. As can be seen, the relative number of one word entries in WordNet is larger compared to the number in Wikipedia. This is potentially important as in past disambigua tion research, it was assumed that ambiguity was largely restricted to single words. Multi-word queries, were assumed to be relatively unaffected by ambiguity. However, it appeared from this analysis that such queries are potentially ambiguous as well. Th e likelihood of this happening was tested and the results are shown in Sec. 5.2. Given that disambiguation pages often list referents grouped by type, the titles of each groups were extracted and analyzed to determine the referent types pres ent in Wikipedia. The naming of the groups does not follow a strong convention. Therefore, some normalization was conducted: the 40 most used group names were identified and manually arranged into common types. People 27 Science 3 Places 26 Ships 1 Other/Misc 25 Sports 1 Entertainment/Music/Films/TV 11 Military 1 The relative percentages of the identified types are shown in Table 4. As can be seen, names of people and locations are the predominant single type. Names of televisions programs, films, music, etc were also relatively common with other types, less so. This analysis examined the frac tion of referent types within disambiguation pages, what the an alysis did not examine was the fraction of pages who X  X  referent s were entirely one type or another, this was the objective of the next study. To conduct this analysis a ma nual examination of a random sample of 182 disambiguation page s (0.25% of all such pages) was conducted. It was found that 44% of the pages examined had no consistent referent type. The fraction of pages with referents that were exclusively the names of a person was 9%, the fraction that were just locations was 11%. From this analysis, it would appear that the work described in the literature review (Sec. 2.1.1) that primarily studies particular re ferent types in isolation, risks ignoring the heterogeneous refe rents of many ambiguous proper nouns. Many differences between Wo rdNet and Wikipedia were identified, justifying the re-examination of the relationship between ambiguity and information retrieval effectiveness.  X  ambiguous proper nouns are am biguous across a number of  X  the number of ambiguous words which have referents across  X  there are more ambiguous multi-word terms than has  X  the number of referents per ambiguous proper noun is larger What was required next was a study of the extent to which such ambiguity exists in the queries submitted to search engines. The next stage of the analysis was to examine the prevalence of ambiguity in actual searches. To achieve this, the logs of a number of search engines were examined to determine the fraction of the logs that contai ned ambiguous words/phrases in the Wikipedia and in the WordNet lists . It has been established that ambiguous words within a longer multi-word queries tend not to cause reductions in retrieval effectiveness, therefore, only those queries that entirely matched an ambiguous word/phrase were considered in this analysis. It was considered important to examine different queries, therefore (with the permission of the owners) logs from the following two search engines were obtained: a large Web search system from Microsoft (labeled Web) and a large journalistic photo library from the UK X  X  Press Association (PA, searching between 10 and 20 million images). Log Unique The logs were stripped of all us er, session and click related data, leaving just the query text. Query words were reduced to lower case. The frequency of occurrence of each query in a log was counted to produce a histogram file, each line of which contained a query/frequency pair for each unique query in the log. Both the whole log (labeled all ) and a sub set of the log containing the most frequent queries (labeled freq ) were examined. The method for forming freq was to select those queries that occurred at least n times more often than the l east frequent query. The value of n (87) was selected at random from a range of possible values that would create a small subset. The statistics for the log histograms are shown in Table 5. As can be seen, the size of the logs is similar, as is the year(s) in which the logs were gathered. Note, at the request of the log owners, the exact time period over which the logs were gathered was withheld in order not to rev eal information about the traffic volumes. The lack of this detail wa s not judged to have an impact on the results of or the conclusions drawn from the experiments conducted here. The focus of interest in this experiment was in determining the fraction of queries that were listed as being ambiguous. The fraction was measured in the three lists and was measured across the two subsets of each of the logs. The figures detailing the measurements are show n in Table 6. As can be seen, even though the logs are from search engines serving different collections and Examining each column in turn:  X  Column 1 records the overlap with Wi ND : a noticeable  X  Column 2 records the generally smaller number of queries  X  Column 3 details the overlap between the query logs and the  X  Column 4 should be viewed as an upper bound on ambiguity Name Wi ND WN WN+Wi ND WN+Wi Web freq 7.6% 4.0% 10.0% 16.4% PA freq 10.5% 6.4% 14.7% 23.6% 
Table 6. Fraction of queries ma tching in combinations of one Looking across all columns, it is clear that finding whole queries that are ambiguous is a relativel y common event particularly in the more frequent queries submitted to each engine. By including the ambiguous words/phrases fro m Wikipedia, many more ambiguous queries (particularly when measured across the all logs sets) were identified than through the more conventional approach of just using WordNet. Although the percentage figures for ambiguous queries in the all set appear small, it should be remembered that the logs are large: e.g. a 3% overlap on the Web log represents 30,000 dis tinct ambiguous queries. The next analysis was to examine the average length of the matching ambiguous queries. Defining a space as a word separator, the average number of words in the ambiguous queries was calculated for matches in the WN and Wi ND are shown in Table 7. Name Wi ND &gt;1 word WN Web freq. 1.13 10.4% 1.01 PA freq. 1.12 10.8% 1.02 Compared to the average word le ngths in Table 3, the averages here are shorter. With most ambiguous queries being one word long, this being particularly true of the most frequent queries in the logs. It is worth noting, however that for those queries matched in the Wikipedia list (column 1), more multi-word ambiguous queries were found. Co lumn 2 shows the percentage of the queries longer than one word. The results shown here indicate that through analysis of a new source of ambiguous words/phrases , ambiguity in whole queries is common. The ambiguity is pr esent not just for single word queries, but for some multi-word queries as well. That the results were consistent across the logs of two different search engines strengthens our c onclusions. However, it should be remembered that the collections of both engines are large and heterogeneous, which increases the likelihood of finding matches to more than one interpretation of an ambiguous query. Smaller more focused collections, such as a small digital library, might have queries submitted that, according to Wikipedia or WordNet, are ambiguous, but only one interpretation of the query is actually present in the collection, meani ng the ambiguity can be ignored. This study has not examined the actual impact of this ambiguity on retrieval effectiveness, which ha s to be left for future work. Nevertheless, there are a great many large collections and for search engines retrieving from such corpora, it would appear important for them to deal e ffectively with ambiguous queries. It was decided next to conduct an initial exploration of how well current IR systems retrieve documents from queries that are ambiguous. Given an ambiguous query, will a conventional search engine retrieve documents in the top ten ranks that are relevant to more than one of the query X  X  interpretations? As established in Sec.2.3, there are currently no publicly available test collections with ambiguous que ries. Ultimately, we believe it will be necessary to build such a collection. Before engaging in the work of creating such a corpus, it was decided to explore methods of simulating such a collection. To achieve this, an old technique of simulating am biguity was re-examined. Sanderson [15] used pseudo-words to explore the impact of ambiguity on IR. A pseudo-word is an artificial term created out of the concatenation of two or more unrelated words. All occurrences of the words in a te st collection are replaced with a token that represents the pse udo-word (e.g. replacing  X  X anana X  and  X  X agazine X  with  X  X anana#ma gazine X ). By introducing the pseudo-word, the collection becomes additionally ambiguous and by varying the number and si ze of pseudo-words, Sanderson found relationships between am biguity, disambiguation and retrieval effectiveness. In order to evaluate conventi onal search engines retrieving ambiguous queries, it was decided to adapt pseudo-words to create so called pseudo-queries : where two or more topics were merged into a single topic. Taking such an approach, it was possible to merge the topics of an existing test collection to form a collection with ambiguous topics that have distinct sets of relevance judgments, one set for each topic interpretation. This was the methodology adopted here. At the time of conducting his original work, Sanderson had to defend the use of pseudo-words against the concern that they were a poor simulation of ambiguity. It was argued that treating randomly selected words as legitimate pseudo-senses of a new ambiguous word was incorrect as the senses of actual ambiguous words were generally semantica lly related in some manner. Sanderson [16] justified his methodol ogy by citing Gale et al [10] who showed that typically, the real senses of words occur in different discourses. Sanderson argued that this quality of senses was mimicked by pseudo-words. He also presented experimental results showing strong similaritie s between certain properties of pseudo-senses and real senses. He concluded that for the purposes of retrieval experiments, ps eudo-words were a reasonable simulation of ambiguous words. The question of the relatedness of sense is less of a concern for the work described here, as the referents of proper nouns are commonly unrelated. Consequently, it was concluded that for the purposes of this work, pseudo-queries provided an effective simulation of ambiguous queries. The pseudo-query collection was built as follows. The Financial Times (FT) newspaper articles of the TREC collection were indexed. The 150 topics 301-450, which have qrels from the FT, were extracted. A number of topics in TREC are  X  X ard X : search engines fail to retrieve many rele vant documents for those topics. If a pseudo-query was formed from the pairing of a hard topic with an  X  X asier X  topic, it would be challenging for a search engine to ensure that relevant documen ts were retrieved for both pseudo-senses of the query. For this initial experiment, therefore, it was decided to use a subset of easier topics, which were selected as follows. Using titles only, the 150 topics were run on a search engine (Lemur v4.5) and those for which P@10=0 (precision at 10) were removed. This process left 74 topics whose titles were used to form pseudo-queries. The merging of two topics was achieved using the  X  X YN X  operator available in Lemur X  X  structured query language. As described in the Lemur manual pages 4  X  The terms of the operator are treated as instances of the same term  X , this is equivalent to replacement of words with a pseudo-word. To illustrate, the single word titles of the topics 364 and 349 would merged to form the Lemur structured topic #SYN(rabies Metabolism); To merge multi-word topics, only topics containing the same number of words were paired. To illustrate, topics 340 and 313 would be merged as follows #SUM(#SYN(Viral Industrial) #SYN(Hepatitis Espionage)); The components of a  X  X UM X  ope rator (in this case 2  X  X YN X  operators) are treated equally by Lemur when it calculates a document ranking. The resulting query simulated a situation where a single topic has one of two possible interpretations: one related to  X  X iral hepatitis X  the other to  X  X ndustrial espionage X . The selection of which topics, w ith equivalent word length, to pair was chosen at random. Note, because of the restriction of www.lemurproject.org/lemur/StructuredQuery.php (Jan.  X 08) only pairing topics with the same title word count, only 35 pairings were possible from the 74 topics. One might argue that testing an IR system on a type of query it was never designed to work w ith is an unfair experiment. However, the test is less of the system and more of the existing test collections the IR community uses. Like most IR systems, Lemur X  X  default ranking algorithm was built to ensure it produces good results on TREC collections. There is a common assumption the topics of such collections are in some way a representative sample of the topics a search engine will operationally encounter. We have shown that ambiguous t opics are relatively common, if the topics of a test collection like TREC are representative, Lemur should be able to retrieve ambiguous topics successfully. As stated above, the 74 topics se lected were those which Lemur retrieved at least one relevant document in the top 10. One might view therefore, the 74 as relatively easy topics: P@10 measured across them unpaired was 0.37. When the 35 paired ambiguous topics were run on Lemur, the measure of effectiveness used to test the search engine was to determine if at least one relevant document was retrieved in the top 10 for each of the 2 interpretations of the ambiguous topic. As topic pairing was controlled thr ough random selection, the whole experiment was repeated 50 times. The results were that on average for 25 of the 35 pseudo-queries, no relevant document in the top 10 was retrieved for one of the constituent topics. For 72% of th e pseudo-queries, only relevant documents for one of the topic X  X  interpretations were retrieved. Given that each constituent topic was selected because it was relatively easy to retrieve a relevant document in the top 10, this result came as a bit of a surprise. Although it should be remembered experimental search engines such as Lemur have been tuned over many years to perform well on test collections with one interpretation per topic. With that thought in mind, a common technique used by sear ch engines was tested on the newly ambiguous test collection. Pseudo-relevance feedback (P RF) is a well known technique: given a query, the method conducts a search, extracts terms from the resulting top ranked documents, expands the original query with the extracted terms and c onducts another search, which on average produces better retrieval effectiveness than the initial search. Lemur provides support for PRF and so another experiment using PR F was conducted with same 50 sets of random topic pairings used in the experiment above. The results of this experiment were that on average for 34 of the 35 topics no relevant document in the top 10 was retrieved for one of the constituent topics. For 97% of the pseudo-queries, retrieval failed for one interpretation. PRF appears drive a retrieval system to one interpretation per ranking and in the context of these queries, this is completely the wrong thing to do. This study examined ambiguity in words and phrases not normally found in dictionaries or thesauri. It was shown that ambiguity is common and that the referents of such words/phrases are often numerous and cover a wide range of types. Such terms were found to be common in the query logs of two different search engines 5 . We conclude from this set of analyses that query ambiguity is a potential problem in many retrieval situations. A methodology for simulating am biguous topics was described and a test collection was built. Th e collection was used to show that a well established experime ntal IR system does not deal effectively with ambiguous queries. In addition when a process (PRF) normally thought to improve retrieval effectiveness was applied, effectiveness was instead substantially reduced. Test collections are catalysts for research. As described in Sec. 2.3, the relevance judgments of almost all test collections are based on one person X  X  interpretation of a topic. It would appear this is because almost all collections base their design on the Cranfield model. It was estab lished, however, that it is not unusual for a query to have more than one interpretation per topic and that it is important for search engines to retrieve documents covering each interpretation. There is a long history of research into methods that address either sub-topics or ambiguous que ries (e.g. clustering, maximal marginal relevance, sub-topic retr ieval, divergence in ranks, etc.). There is a danger, however, that the true worth of these methods has not been fully realized by the research community because there are no publicly available test collections that have ambiguous topics and a range of relevance judgments that cover more than one interpretation of such topics. From our study we conclude that new test collections are needed to catalyze research into a generally overlooked though important type of query. Thanks to Paul Clough &amp; Nick Craswell for valuable conversations and data. Funding wa s provided by the TrebleCLEF project: EU grant number 215231. [1] Allan, J., Carterette, B., Aslam, J., Pavlu, V., Dachev, B., [2] Artiles, J., Gonzalo, J., Sekine, S. (2007) The SemEval-2007 [3] Carbonell, J.G., Goldstein, J. (1998) The Use of MMR, [4] Chen, H., Dumais, S (2000) Bringing Order to the Web: Subsequent to the completion of this work, we became aware that two additional tags were used to identify disambiguation pages in Wikipedia. The tags identified approximately 20,000 additional ambiguous words (on top of the 89,109 forms in this paper). Not including these words alters the conclusions to the extent that ambiguity in query logs is more common than we calculated and therefore the need for test collections to address such queries is far greater. [5] Chen, H., Karger, D.R. (2006) Less is more: probabilistic [6] Clarke, C.L.A., Kolla, M., Cormack, G.V., Vechtomova, O., [7] Cleverdon, C.W. (1991) The Significance of the Cranfield [8] Darwish, K. and Oard, D. (2003) Probabilistic structured [9] Gale W., Church K.W., Yaro wsky D. (1992a) Estimating [10] Gale W., Church K.W., Yarows ky D. (1992b) One sense per [11] Gonzalo, J., Verdejo, F., Chugur, I. and Cigarran, J. (1998) [12] Jansen, B.J., Spink, A. (2006) How are we searching the [13] Krovetz, R. &amp; Croft, W.B. (1992). Lexical Ambiguity and [14] Leidner, J. (2007) Toponym Reso lution in Text: Annotation, [15] Sanderson M. (1994) Word sense disambiguation and [16] Sanderson, M. &amp; Van Rijsbergen, C.J. (1999) The impact on [17] Sch X tze, H. (1992) Context Space, In AAAI Fall Symp. on [18] Sp X rck-Jones, K., Robertson, S.E., Sanderson, M. (2007) [19] Stokoe, C., Oakes, M.P., Tait J. (2003) Word sense [20] Voorhees, E.M. (1993). Using WordNet X  to disambiguate [21] Weiss, S.F. (1973). Learni ng to disambiguate, in Information [22] Willett, P. (1988) Recent trends in hierarchic document [23] Zhai, C, Cohen, W.W., Lafferty, J.D. (2003) Beyond [24] Zhang, B., Li, H., Liu, Y., Ji, L., Xi, W., Fan, W., Chen, Z., 
