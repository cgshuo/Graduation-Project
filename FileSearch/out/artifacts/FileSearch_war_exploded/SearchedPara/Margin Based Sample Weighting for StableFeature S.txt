 V ar io us feature se l ect ion a l g o r i thms ha v ebee n de v e lo ped in the past wi th a f o cus on i mpr ovin gc l ass i ficat ion accurac yw h il e reduc in gd i me n s ion a li t y. A re l at iv e ly n eg l ected i ssue i sthe stability of feature selection -the in se n s i t ivi t yo ftheresu l t o fafeaturese l ect ion a l g o r i thm t ov ar i at ion s in the tra inin gset .T he stab ili t y i ssue i spart i cu l ar ly cr i t i ca l f o rapp li cat ion s w here feature se l ect ion i susedas ak nowl edge d i sc ov er y t ool f o r i de n t i f yin g character i st i cmarkerst o e x p l a in the o bser v ed phe no me n a [13]. Fo re x amp l e ,in m i cr o arra y a n a ly s i s , b iolo g i sts are in terested in fi n d in gasma ll n umber o ffeatures ( ge n es o rpr o te in s ) that e x p l a in the mecha ni sms dr ivin gd iff ere n tbeha vio rs o fm i cr o arra y samp l es . Curre n t ly, a feature se l ect ion a l g o r i thm o fte n se l ects l arge ly d iff ere n t subsets o ffeaturesu n der v ar i at ion st o the tra inin gdata , a l th o ugh m o st o f these subsets are as g oo daseach o ther in terms o fc l ass i ficat ion perf o rma n ce [9, 2 0]. S uch in stab ili t y dampe n sthe c on fide n ce o fd o ma in e x perts in e x per i me n ta lly v a li dat in gthese l ected features .
A ke y fact o ra ff ect in gthestab ili t yo fafeaturese l ect ion a l g o r i thm i sthe n umber o fsamp l es in the tra inin gset ,o rsamp l es i ze .S upp o se w eperf o rm feature se l ect ion on a dataset D wi th n samp l es a n d p features .I f w era n d o m ly sp li t the data in t o t wo sets D 1 a n d D 2 wi th ha l f o fthesamp l es each , a n dru n a feature se l ect ion a l g o r i thm on them ,i dea lly, w e wo u l d li ke t o see the same feature se l ect ion resu l t (w h i ch i s li ke ly t o happe n g iv e n u nli m i ted samp l es i ze o f D ). How e v er ,in rea li t y, due t o the li m i ted samp l es i ze o f D , the resu l ts fr o m D 1 a n d D 2 no rma lly d ono t agree wi th each o ther .W he n the samp l es i ze i s v er y sma ll, the resu l ts fr o m D 1 a n d D 2 c o u l dbe l arge ly d iff ere n t .Fo rm i cr o arra y data , the t y p i ca ln umber o ffeatures ( ge n es )i sth o usa n ds o rte n s o fth o usa n ds , but the n umber o fsamp l es i s o fte nl ess tha n ahu n dred .T heref o re , ama jo rreas on f o rthe in stab ili t yo ffeaturese l ect ion on h i gh -d i me n s ion a l data i sthe n ature o fe x treme ly sma ll samp l es i ze c o mpared t o the d i me n s ion a li t y(i. e ., p # n ). In creas in gthe n umber o fsamp l es c o u l dbe v er y c o st ly o r i mpract i ca lin ma ny app li cat ion s li ke m i cr o arra y a n a ly s i s .

To tack l ethe in stab ili t y pr o b l em , area li st i c w a yi st o e x te n s iv e ly e x p lo re the a v a il ab l etra inin gsamp l es in o rder t o s i mu l ate a tra inin gset o f l arger s i ze . O n e in tu i t iv e appr o ach i st o app ly the e n semb l e l ear nin g i dea t o feature se l ect ion. S ae y s et al. in tr o duced e n semb l efeaturese l ect ion [1 7 ]w h i ch aggregates the fea -ture se l ect ion resu l ts fr o mac onv e n t ion a l feature se l ect ion a l g o r i thm repeated ly app li ed on a n umber o fb oo tstrapped tra inin gsets .T he b oo tstrapp in gpr o ce -dure used f o rge n erat in geach n e w tra inin g set esse n t i a lly ass i g n sa w e i ght t o each samp l era n d o m ly ( e . g ., samp l es no tdra wn in t o the tra inin gsetha v e zer o w e i ghts ), wi th o ut e x p loi t in g the data character i st i cs o fthe o r i g in a l tra inin gset . T he e ff ect iv e n ess o fth i s appr o ach in i mpr ovin gthestab ili t yo ffeaturese l ect ion i s li m i ted .Mo re ov er ,i t i sc o mputat ion a lly e x pe n s iv et o repeated ly app ly the same feature se l ect ion a l g o r i thm .

In th i spaper ,w epr o p o se t o e x te n s iv e ly e x p lo re the a v a il ab l etra inin gsam -p l es b y a nov e l frame wo rk o fmarg in based samp l e w e i ght in g .T he frame wo rk first w e i ghts each samp l e in atra inin gsetacc o rd in gt oi ts infl ue n ce t o the es -t i mat ion o f feature re l e v a n ce , a n dthe n pr ovi des the w e i ghted tra inin gsett o a feature se l ect ion meth o d .In here n t ly, the resu l t o fafeaturese l ect ion a l g o r i thm fr o mag iv e n tra inin gset i s determ in ed b y the d i str i but ion o fsamp l es in the tra inin gset .Diff ere n tsamp l es c o u l dha v ed iff ere n t infl ue n ce on the feature se -features .I fasamp l esh ow squ i te d i st in ct lo ca l pr o fi l efr o mthe o ther samp l es , i ts abse n ce o rprese n ce in the tra inin gdata will substa n t i a lly a ff ect the feature se l ect ion resu l t .T he d i screpa n c y am on gthe lo ca l pr o fi l es o ffeature i mp o rta n ce at v ar io us samp l es e x p l a in s w h y the resu l t o fafeaturese l ect ion a l g o r i thm i s se n s i t iv et ov ar i at ion s in the tra inin gdata .Ino rder t oi mpr ov ethestab ili t yo f feature se l ect ion resu l t , samp l es wi th o ut lyin g lo ca l pr o fi l es n eed t o be w e i ghted d iff ere n t ly fr o mtherest o fthesamp l es .T heref o re , the pr o p o sed frame wo rk o f marg in based samp l e w e i ght in gass i g n sa w e i ght t o each samp l eacc o rd in gt o the o ut lyin gdegree o f i ts lo ca l pr o fi l e o ffeature i mp o rta n ce c o mpared wi th o ther samp l es .In part i cu l ar , the lo ca l pr o fi l e o ffeature i mp o rta n ce at a g iv e n samp l e i s measured based on the h y p o thes i smarg in o fthesamp l e .

T he ma in c on tr i but ion s o fth i spaper in c l ude : (i) in tr o duc in gthec on cept o f h y p o thes i s -marg in feature space ; (ii) pr o p o s in gtheframe wo rk o fmarg in based samp l e w e i ght in gf o rstab l efeaturese l ect ion; (iii) de v e lo p in ga n effic i e n tsam -p l e w e i ght in ga l g o r i thm u n der the pr o p o sed frame wo rk . E x per i me n ts on aset o f pub li cge n ee x press ion a n dpr o te in m i cr o arra y datasets dem on strate that the pr o p o sed a l g o r i thm i se ff ect iv eat i mpr ovin gthestab ili t yo f SVM-R F Ea l g o-r i thm ,w h il ema in ta inin gc o mparab l ec l ass i ficat ion accurac yo fthese l ected fea -tures .Mo re ov er , the pr o p o sed a l g o r i thm i sm o re e ff ect iv ea n deffic i e n ttha n a rece n t ly pr o p o sed e n semb l efeaturese l ect ion appr o ach .
 T he rest o f the paper i s o rga ni zed as f ollow s .S ect ion 2re vi e w sre l ated wo rk . S ect ion 3 defi n es a n d ill ustrates the c on cept o fh y p o thes i s -marg in feature space a n d descr i bes the pr o cedure o fh y p o thes i s -marg in feature space tra n sf o rmat ion. S ect ion 4prese n ts the meth o d o fsamp l e w e i ght in gbased on h y p o thes i s -marg in feature space a n dthe ov era ll pr o p o sed a l g o r i thm .S ect ion 5 prese n ts emp i r i ca l stud y based on rea l-wo r l dm i cr o arra y data sets .S ect ion 6 c on c l udes the paper a n d o ut lin es future research d i rect ion s . Al th o ugh feature se l ect ion i sa n e x te n s iv e ly stud i ed area [11], there e xi st v er y li m i ted stud i es on the stab ili t yo ffeaturese l ect ion a l g o r i thms . Ear ly wo rk in th i sareama inly f o cuses on the de v e lo pme n t o fstab ili t y measures a n demp i r i ca l e v a l uat ion o fthestab ili t yo fe xi st in gfeaturese l ect ion a l g o r i thms [9, 10].
Mo re rece n t ly, t wo appr o aches w ere pr o p o sed t oi mpr ov ethestab ili t yo ffea -ture se l ect ion wi th o ut sacr i fic in gc l ass i ficat ion accurac y: e n semb l efeaturese l ec -t ion [1 7 ] a n dgr o up based stab l efeaturese l ect ion [1 2 , 2 0]. S ae y s et al . stud i ed bagg in g -based e n semb l efeaturese l ect ion [1 7 ]w h i ch aggregates the feature se l ec -t ion resu l ts fr o mac onv e n t ion a l feature se l ect ion a l g o r i thm repeated ly app li ed on d iff ere n tb oo tstrapped samp l es o fthesametra inin gset .A sd i scussed pre vio us ly, th i s appr o ach tack l es the in stab ili t y pr o b l em o ffeaturese l ect ion b y e x te n s iv e ly e x p lo r in gthea v a il ab l etra inin gsamp l es ;i ts i mu l ates a tra inin gset o f l arger sam -p l es i ze b y creat in ga n umber o fb oo tstrapped tra inin gsets .Y u et al . pr o p o sed a n c o rre l at ion sam on gthe l arge n umber o ffeatures .T he y pr o p o sed a gr o up -based stab l efeaturese l ect ion frame wo rk w h i ch i de n t i fies gr o ups o fc o rre l ated features a n dse l ects re l e v a n tfeaturegr o ups [1 2 , 2 0].

In th i s wo rk ,w ef o cus on the appr o ach o fe x p lo r in gthea v a il ab l etra inin g samp l es .How e v er ,in c on trast wi th bagg in g -based e n semb l efeaturese l ect ion, o ur pr o p o sed frame wo rk d o es no t repeated ly app ly afeaturese l ect ion a l g o r i thm on a n umber o fra n d o m ly created tra inin gsets .I te x p loi ts the data character i st i cs o fthetra inin gsett ow e i ght samp l es , a n dthe n app li es a g iv e n feature se l ect ion a l g o r i thm on as in g l etra inin gset o f w e i ghted samp l es .

Ano ther lin e o f research c lo se ly re l ated t oo ur wo rk i smarg in based feature se l ect ion. M arg in s [ 2 ] measure the c on fide n ce o fac l ass i fier w. r . t .i ts dec i s ion, a n dha v ebee n used b o th f o rthe o ret i ca l ge n era li zat ion b o u n ds a n dasgu i de lin es f o ra l g o r i thm des i g n. T here are t wo n atura lw a y s o fdefi nin gthemarg in o fasam -p l e w. r . t . ah y p o thes i s [3]. S amp l e -marg in (SM) as used b ySVM s [ 2 ] measures the d i sta n ce bet w ee n the samp l ea n d the dec i s ion b o u n dar yo ftheh y p o thes i s . Hy p o thes i s -marg in (HM) as used b yA da Boo st [ 4 ] measures the d i sta n ce bet w ee n the h y p o thes i sa n dthec lo sest h y p o thes i sthatass i g n sa n a l ter n at iv e l abe l t o the g iv e n samp l e .V ar io us feature se l ect ion a l g o r i thms ha v ebee n de v e lo ped u n der the l arge marg in (SM o r HM) pr in c i p l es such as SVM-based feature se l ect ion [ 8 ] a n dRe li ef fam ily o fa l g o r i thms [5]. T hese a l g o r i thms e v a l uate the i mp o rta n ce o f features acc o rd in gt o the i r respect iv ec on tr i but ion st o marg in s , a n dha v ee x-h i b i ted b o th ni ce the o ret i ca l pr o pert i es a n dg oo dge n era li zat ion perf o rma n ce . How e v er , stab ili t yo fthesea l g o r i thms i sa ni ssue u n der sma ll samp l es i ze . C o m -pared t o marg in based feature se l ect ion a l g o r i thms w h i ch use marg in st o d i rect ly e v a l uate feature i mp o rta n ce ,o ur marg in based samp l e w e i ght in gframe wo rk e x-p loi ts the d i screpa n c i es am on gthemarg in sat v ar io us samp l es t ow e i ght samp l es a n dactsasaprepr o cess in gstepapp li cab l et o a ny feature se l ect ion a l g o r i thm . In th i s sect ion, w efirstf o rma lly defi n eh y p o thes i s -marg in feature space , the n in tr o duce a n e x amp l et o ill ustrate i ts e ff ect iv e n ess at captur in gthed i screpa n c y am on g lo ca l pr o fi l es o ffeature i mp o rta n ce , a n dthe n d i scuss the pr o cedure o f tra n sf o rm in gthe o r i g in a l feature space in t o the h y p o thes i smarg in feature space . 3.1 Definition Hy p o thes i s -marg in (HM) o fasamp l emeasuresthed i sta n ce bet w ee n the h y p o th -es i sa n dthec lo sest h y p o thes i sthatass i g n sa n a l ter n at iv e l abe l t o the samp l e [3]. By dec o mp o s in gthe HM o fasamp l ea lon geachd i me n s ion, the samp l e in the o r i g in a l feature space ca n be represe n ted b y a n e wv ect o r in the h y p o thes i s -marg in feature space defi n ed as f ollow s .
 Definition 1. Let X =( x 1 , ... ,x p ) be a sample vector in the original feature space R p ,and X H and X M represent the nearest samples to X with the same and opposite class labels, respectively. The HM feature space R p is transformed from the original space R p , such that for each X  X  R p , X is mapped to X  X  R p according to w here x i i sthe i th c oo rd in ate o f X in the HM feature space .I t i seas y t o pr ov e w here the l eft part o f o fEquat ion ( 2 ) represe n ts the L 1 -no rm o f X in the tra n sf o rmed space a n dther i ght part ca l cu l ates the HM o f X based on L 1 -no rm in the o r i g in a l space .T he l arger the v a l ue o feachc o mp on e n t x i , the m o re the i th feature c on tr i butes t o the HM o fsamp l e X ,w h i ch mea n sh i gher feature i mp o rta n ce .In esse n ce , X captures the lo ca l pr o fi l e o ffeature i mp o rta n ce f o r a ll features at X .HM feature space captures lo ca l feature pr o fi l es f o ra ll samp l es in the o r i g in a l feature space .T he ov era ll pr o fi l e o ffeature i mp o rta n ce ov er the e n t i re tra inin g set ca n be o bta in ed b y aggregat in ga ll lo ca l feature pr o fi l es . 3.2 An Illustrative Example Fi gure 1 ill ustrates the i dea o f HM feature space thr o ugh a 2 -de x amp l e . Each l abe l ed data p oin t ( tr i a n g l e o rsquare )i sasamp l e wi th t wo features . Each samp l e in the o r i g in a l feature space ( a )i spr oj ected in t o the HM feature space ( b ) acc o rd in gt o Equat ion (1) ab ov e .W eca n c l ear ly see that samp l es l abe l ed wi th tr i a n g l es e x h i b i t l arge ly d iff ere n t o ut lyin g degrees in the t wo feature spaces . S pec i fica lly, th o se in the dashed ov a l saree v e nly d i str i buted wi th in the pr oxi m i t y t o the rest o fthetr i a n g l es ( e x cept the o ut li er on the l eftm o st )in the o r i g in a l feature space , but are c l ear ly separated fr o mthema jo r i t yo fthesamp l es in the HM feature space .T he o ut li er tr i a n g l e in the o r i g in a l space bec o mes part o fthe the ma jo r i t y gr o up in the HM feature space .

To dec i de the ov era ll i mp o rta n ce o ffeature X1 v s .X 2 ,on e in tu i t iv e i dea i st o take the a v erage o fthe lo ca l feature pr o fi l es ov er a ll samp l es , as ad o pted b y the w e ll-k nown Re li ef a l g o r i thm [16]. How e v er , s in ce the tr i a n g l es in the dashed ov er e x h i b i td i st in ct lo ca l feature pr o fi l es fr o mtherest o fthesamp l es , the prese n ce o rabse n ce o f these samp l es will a ff ect the g lo ba l dec i s ion on w h i ch feature i s m o re i mp o rta n t .F r o mth i s ill ustrat iv ee x amp l e ,w eca n see that the HM feature space captures the s i m il ar i t y am on gsamp l es w. r . t . the i r lo ca l pr o fi l es o ffeature i mp o rta n ce , a n de n ab l es the detect ion o fsamp l es that l arge ly de vi ate fr o m o thers In S ect ion 4 ,w e will further d i scuss h ow t o e x p loi tsuchd i screpa n c y t ow e i ght samp l es in o rder t o a ll e vi ate the a ff ect o ftra inin gdata v ar i at ion s on feature se l ect ion resu l ts . Algorithm 1. Hy p o thes i s M arg in F eature S pace T ra n sf o rmat ion 3.3 Procedure T he pre vio us defi ni t ion a n de x amp l e o f HM feature space only c on s i der on e n ear -est n e i ghb o rfr o meachc l ass .To reduce the se n s i t ivi t yo fthetra n sf o rmed HM feature space t onoi se o r o ut li ers in the tra inin gset , mu l t i p l e n earest n e i ghb o rs fr o meachc l ass ca n be used t o c o mpute the HM o fasamp l e . Equat ion (1) ca n the n be e x te n ded t o: w here x H j i o r x M j i de no tes the i th c o mp on e n t o fthe j th n earest n e i ghb o rt o X wi th the same ( h i t )o rd iff ere n t ( m i ss ) c l ass l abe l respect iv e ly; k represe n ts the n umber o f n earest n e i ghb o rs take nin t o acc o u n t . k =10i s the defau l t v a l ue .
Al g o r i thm 1o ut lin es the pr o cedure f o rtra n sf o rm in gthe o r i g in a l feature space in t o the HM feature space g iv e n atra inin gset D .T he t i me c o mp l e xi t yo fth i s tra n sf o rmat ion i s O ( n 2 q ), w here n i sthe n umber o fsamp l es a n d q i sthed i me n-s ion a li t yo f D . T he h y p o thes i smarg in (HM) feature space in tr o duced in the pre vio us sect ion captures the d i screpa n c y am on gsamp l es w. r . t . the i r lo ca l pr o fi l es o ffeature i mp o rta n ce , a n da llow sust o detect samp l es that l arge ly de vi ate fr o m o thers in th i s respect .T he n e x tstep in the frame wo rk o fmarg in based samp l e w e i ght in g i st o e x p loi tsuchd i screpa n c y t ow e i ght samp l es in o rder t o a ll e vi ate the a ff ect o f tra inin gdata v ar i at ion s on feature se l ect ion resu l ts .To qua n t i tat iv e ly e v a l uate the o ut lyin gdegree o f each samp l e X in the HM feature space ,w emeasure the a v erage d i sta n ce o f X t o a ll o ther samp l es in the HM feature space ; greater a v erage d i sta n ce in d i cates h i gher o ut lyin gdegree .A s ill ustrated in S ect ion 3, the g lo ba l dec i s ion o ffeature i mp o rta n ce i sm o re se n s i t iv et o samp l es that l arge ly de vi ate fr o mtherest o fthesamp l es in the HM feature space tha n t o samp l es that ha v e low o ut lyin g degrees .Toi mpr ov ethestab ili t yo fafeaturese l ect ion Algorithm 2. M arg in B ased S amp l e W e i ght in g a l g o r i thm u n der tra inin gdata v ar i at ion s ,w eass i g nlow er w e i ghts t o samp l es wi th h i gher o ut lyin g degrees .T heref o re , g iv e n the a v erage d i sta n ce  X  d t o fasamp l e X t t o a ll o ther samp l es in the HM feature space , the w e i ght f o rsamp l e X t in the o r i g in a l feature space i sg iv e n b y the f ollowin gf o rmu l a : Al g o r i thm 2 o ut lin es the ov era ll pr o cess o fmarg in based samp l e w e i ght in g .Sin ce b o th the step o f HM feature space tra n sf o rmat ion a n d the pa i r wi se d i sta n ce ca l cu l at ion in the tra n sf o rmed space take O ( n 2 q ), the ov era ll t i me c o mp l e xi t y f o r Al g o r i thm 2 i sst ill O ( n 2 q ). T he o b j ect iv e o ftheemp i r i ca l stud yi st o e v a l uate the pr o p o sed a l g o r i thm in terms o fstab ili t y a n dc l ass i ficat ion perf o rma n ce , a n da l s o c o mpare the pr o p o sed a l g o r i thm wi th state -o f -the -art feature se l ect ion a l g o r i thms .W efirst in tr o duce stab ili t y measures in S ect ion 5.1, the n descr i be the data sets , c o mpar i s on a l-g o r i thms a n de x per i me n ta l pr o cedures in S ect ion 5. 2 , a n dfi n a lly prese n ta n d d i scuss the resu l ts in S ect ion 5.3. 5.1 Stability Metrics E v a l uat in gthestab ili t yo ffeaturese l ect ion a l g o r i thms requ i res s o me s i m il ar i t y measures f o rt wo sets o ffeaturese l ect ion resu l ts .L et R 1 a n d R 2 de no te t wo sets o fresu l ts b y afeaturese l ect ion a l g o r i thm fr o mt wo d iff ere n ttra inin gsets , w here R 1 a n d R 2 ca n be t wo v ect o rs o ffeature w e i ghts o rra n ks ,o rt wo feature subsets , depe n d in g on the o utput o fthea l g o r i thm .Fo rfeature w e i ght in g , the P ears on c o rre l at ion c o effic i e n tca n be used t o measure the s i m il ar i t y bet w ee n R 1 a n d R 2 .Fo r feature ra n k in g ,w euse S pearma n ra n kc o rre l at ion c o effic i e n tas in [9] a n d [1 7 ]: w here p i sthet o ta ln umber o ffeatures , a n d R i 1 a n d R i 2 are the ra n ks o fthe i th feature in the t wo ra n k v ect o rs , respect iv e ly. Sim R takes v a l ues in [-1,1]; a v a l ue o f 1 mea n s that the t wo ra n k in gs are i de n t i ca l a n da v a l ue o f -1 mea n s that the y ha v ee x act ly inv erse o rders .
 Fo r feature subset se l ect ion, J accard in de xw as used in b o th [9] a n d [1 7 ]. Sim ID takes v a l ues in [0,1], wi th 0 mea nin g that there i s no ov er l ap bet w ee n the t wo subsets , a n d 1 that the t wo subsets are i de n t i ca l.

Sim ID d o es no ttake in t o acc o u n tthes i m il ar i t yo ffeature v a l ues ; t wo subsets o fd iff ere n tfeatures will be c on s i dered d i ss i m il ar no matter w hether the features in on e subset are h i gh ly c o rre l ated wi th th o se in the o ther subset .To capture the s i m il ar i t yin feature v a l ues , a no ther s i m il ar i t y measure i spr o p o sed in [ 2 0], w h i ch i sdefi n ed based on ma xi mum w e i ghted b i part i te match in g : w here M i sama xi mum match in g in the b i part i te graph represe n t in g R 1 a n d R . Each w e i ght w ( X t wo features X i a n d X j ,w here X i  X  R 1 a n d X j  X  R 2 .

G iv e n each measure ab ov e , the stab ili t yo fafeaturese l ect ion a l g o r i thm i sthe n measured as the a v erage o f the pa i r -wi se s i m il ar i t yo f v ar io us feature se l ect ion resu l ts pr o duced b y the same a l g o r i thm fr o md iff ere n ttra inin gsets . 5.2 Experimental Setup In o ur c o mparat iv estud y, w ech oo se SVM-R F E [ 8 ], ah i gh ly p o pu l ar feature se l ect ion a l g o r i thm in m i cr o arra y data a n a ly s i s , as a base lin et o represe n tc on-v e n t ion a l feature se l ect ion a l g o r i thms w h i ch d i rect ly wo rk on ag iv e n tra inin g set .T he ma in pr o cess o f SVM-R F E i st o recurs iv e ly e li m in ate features based on SVM, us in gthec o effic i e n ts o fthe o pt i ma l dec i s ion b o u n dar y t o measure the re l e v a n ce o feachfeature .A teach i terat ion, i ttra in sa lin ear SVM c l ass i fier , ra n ks features acc o rd in gt o the squared v a l ues o ffeaturec o effic i e n ts ass i g n ed b y the lin ear SVM, a n de li m in ates on e o rm o re features wi th the low est sc o res . W ea l s o e v a l uate bagg in g -based e n semb l efeaturese l ect ion [1 7 ](in tr o duced in S ect ion 2 ) a n duse SVM-R F E as the base a l g o r i thm .W e refer t o th i sa l g o r i thm as En -SVM-R F E ( En -R F E in sh o rt ). Our pr o p o sed frame wo rk o fmarg in based samp l e w e i ght in g i sa l s o e v a l uated based on SVM-R F E ;in stead o fthe o r i g i-n a l tra inin gset ,SVM-R F E i sapp li ed on the w e i ghted tra inin gsetpr o duced acc o rd in g Al g o r i thm 2 .W e refer t o th i sa l g o r i thm as as IW -R F E in sh o rt .
W ee x per i me n ted wi th s ix freque n t ly stud i ed pub li cge n ee x press ion m i cr o ar -ra y( C olon, L eukem i a ,P r o state , a n d L u n g ) a n dpr o te in mass spectr o metr y ( O v ar i a n a n d JN C I) datasets , character i zed in T ab l e 1. Fo r L u n g , O v ar i a n, a n d JN C I data sets ,w eapp li ed t -test t o the o r i g in a l data set a n d only kept the t o p 5000 features in o rder t o make the e x per i me n ts m o re ma n ageab l e .

To emp i r i ca lly e v a l uate the stab ili t y a n d accurac yo ftheab ov ea l g o r i thms on ag iv e n data set ,w eapp ly the 10 f ol dcr o ss -v a li dat ion pr o cedure . Each feature se l ect ion a l g o r i thm i s repeated ly app li ed t o9o ut o fthe 10 f ol ds ,w h il ead iff ere n t f ol d i sh ol d o ut each t i me .Diff ere n tstab ili t y measures are ca l cu l ated .In add i-t ion, ac l ass i fier i stra in ed based on the se l ected features fr o mthesametra inin g set a n dtested on the h ol d -o ut f ol d .T he C V accurac i es o f lin ear SVM a n d KNN w ee li m in ate 10 perce n t o frema inin gfeaturesateach i terat ion. Fo r En -R F E ,w e use 2 0 b oo tstrapped tra inin gsetst o c on struct the e n semb l e .Fo r IW -R F E ,w e use k =10 f o rh y p o thes i smarg in tra n sf o rmat ion. W euse W eka  X  s i mp l eme n ta -t ion [19] o f SVM (lin ear ker n e l, defau l t C parameter ) a n d KNN (K=1). W eka  X  s i mp l eme n tat ion o f SVM ca n d i rect ly take w e i ghted samp l es as in put . 5.3 Results and Discussion Fi gure 2 rep o rts stab ili t y pr o fi l es ( stab ili t y sc o res acr o ss d iff ere n t n umbers o f se l ected features )o f SVM-R F E in three v ers ion s (o r i g in a l, E n semb l e , a n d S am -p l e W e i ght in g ) based on Sim ID f o rs ix data sets .W eca n c l ear ly o bser v ethat stab ili t y sc o res o f SVM-R F Ebased on pr o p o sed samp l e w e i ght in g appr o ach ( IW -R F E ) are s i g ni fica n t ly h i gher tha no r i g in a lSVM-R F E .T h i s o bser v at ion v er i fies the e ff ect iv e n ess o fpr o p o sed appr o ach in a ll e vi at in gthee ff ect o fsma ll samp l e s i ze on the stab ili t yo ffeaturese l ect ion. Al th o ugh the e n semb l e appr o ach f o r SVM-R F E ( En -R F E ) a l s o c on s i ste n t ly i mpr ov es the stab ili t yo f SVM-R F E , the i mpr ov eme n t i s no tass i g ni fica n tasb y IW -R F E .T h i sca n be e x p l a in ed b y the b oo tstrapp in gpr o cedure used b y the e n semb l e appr o ach w h i ch d o es no te x p loi t the data character i st i cs o f o r i g in a l tra inin gdataasmarg in based samp l e w e i ght -in g .W ea l s o e x per i me n ted based on the o ther t wo stab ili t y metr i cs Sim V a n d Sim R .Sin ce the resu l ts based on these measures sh ow v er y s i m il ar tre n ds as Sim ID , these resu l ts are no t in c l uded in Fi gure 2 f o rc on c i se n ess .

Fi gure 3 c o mpares the pred i ct iv e accurac y f o r SVM c l ass i ficat ion based on the se l ected features o f SVM-R F E , En -R F E , a n d IW -R F Eacr o ss a ra n ge o f n umbers o fse l ected features fr o m 10 t o 50. A m on gtheses ix data sets , the accurac i es resu l ted fr o m SVM-R F E in three v ers ion sare in ge n era lv er y s i m il ar u n der the same s i ze o fse l ected features .T h i s o bser v at ion ill ustrates that d iff ere n t the i rstab ili t y ca nl arge ly v ar y( as sh own in Fi gure 2 ). W ea l s o e v a l uated these a l g o r i thms based on 1NN c l ass i ficat ion. Sin ce the pred i ct iv e accurac i es o f 1NN sh ow the same tre n das Fi gure 3, the y are no t in c l uded f o rc on c i se n ess . In th i spaper ,w e in tr o duced the c on cept o fh y p o thes i s -marg in feature space , pr o p o sed the frame wo rk o fmarg in based samp l e w e i ght in gf o rstab l efeaturese -l ect ion, a n dde v e lo ped a n effic i e n ta l g o r i thm u n der the frame wo rk . E x per i me n ts on m i cr o arra y datasets dem on strate that the pr o p o sed a l g o r i thm i se ff ect iv eat i mpr ovin gthestab ili t yo f SVM-R F Ea l g o r i thm ,w h il ema in ta inin gc o mparab l e c l ass i ficat ion accurac y. Mo re ov er ,i t i sm o re e ff ect iv etha n the e n semb l efeature se l ect ion appr o ach .W ep l a n t oinv est i gate a l ter n at iv emeth o ds o fsamp l e w e i ght -in gbased on HM feature space a n dstrateg i es t o c o mb in emarg in based samp l e w e i ght in g wi th gr o up -based stab l efeaturese l ect ion.

