 modeling of time series.
 by a each x We assume that both the factors x tool for smoothing and interpolating non-uniform data [8]. Using separate GP models for x w symmetrical w.r.t. space and time.
 which helps reduce overfitting and facilitates learning a mo re accurate model. matrix Y . We use the factor analysis model (1) in which Y has dimensionality M  X  N and the number of N . The m -th row of Y corresponds to a spatial location l map) and the n -th column corresponds to a time instance t We assume that each time signal x instances t where X large covariance matrix K element of K The priors for W are defined similarly assuming that each spatial pattern w of a function  X  ( l ) at different spatial locations l where  X  nels can be used to define the covariance functions  X  K d = I O (  X  noise level  X  2 of possible distributions. An approximate distribution wh ich factorizes as maximization of the lower bound of the marginal log-likelih ood: Free-form maximization of (5) w.r.t. q ( X ) yields that tions here, this boils down to the following update rule: where Z The summation in (7) is over a set O DN  X  DN block-diagonal matrix with the following D  X  D matrices on the diagonal: can interpret U  X  1 estimate or adding a factor factor q (  X  the update rules for the case of isotropic noise  X  2 3.1 Component-wise factorization tween different factors x posterior correlations between different time instances x which can be updated as follows: where c and V shown in Table 1.
 can be addressed using the proposed technique with properly chosen covariance functions. 3.2 Variational learning of sparse GP approximations the variational formulation of sparse approximations pres ented in [15]. latent functions  X  mate posterior: Free-form maximization w.r.t. q ( x ) yields the following update rule: where x is the vector of concatenated auxiliary variables for all fa ctors, K variance matrix of x and K the number of inducing inputs is smaller than then the number of data samples, that is, M N d &lt; N 3.3 Update of GP hyperparameters lower bound for the temporal covariance functions {  X  where U and Z of x equations without the use of auxiliary variables are simila r except that K spatial functions  X  changed to optimize the lower bound (13). 4.1 Artificial example We generated a dataset with M = 30 sensors (two-dimensional spatial locations) and N = 200 suming  X  component: 2) a periodic function with decay to model a quasi-periodic c omponent: where r = | t changing components with different timescales: where r = min(1 , | t  X  additional scale parameter  X  obtained by exploratory analysis of data.
 the spatially smooth priors. latent signals x standard deviations. 4.2 Reconstruction of global SST using the MOHSST5 dataset of the values missing, and thus, consisting of more than 10 6 observations in total. accuracy. We used five time signals x was the scaled squared exponential (17). The distance r between the locations l  X  in (17) allowed automatic pruning of unnecessary factors, w hich happens when  X  also introduced 500 inducing inputs for each spatial function  X  matrix and therefore allow efficient computations.
 level was assumed for all measurements (  X  with weights s of the VBPCA spatial components to reduce the effect of the un certain pole regions. for comparison with the most prominent patterns found with V BPCA. might contain artifacts.
 account the substantial amount of noise in the data. large datasets.
 spatial phenomena on different scales by using properly sel ected GPs. function is given by 1 2 where A = K [12]. Without the sparse approximation, it holds that K simplifies to the regular gradient in GP regression for proje cted observations U  X  1 Z hyperparameters.
 Acknowledgments References
