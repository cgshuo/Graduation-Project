 Multi-task learning (MTL) aims to improve the performance of multiple related tasks by exploiting the intrinsic rela-tionships among them. Recently, multi-task feature learn-ing algorithms have received increasing attention and they have been successfully applied to many applications involv-ing high-dimensional data. However, they assume that all tasks share a common set of features, which is too restrictive and may not hold in real-world applications, since outlier tasks often exist. In this paper, we propose a Robust Multi-Task Feature Learning algorithm (rMTFL) which simulta-neously captures a common set of features among relevant tasks and identifies outlier tasks. Specifically, we decom-pose the weight (model) matrix for all tasks into two com-ponents. We impose the well-known group Lasso penalty on row groups of the first component for capturing the shared features among relevant tasks. To simultaneously identify the outlier tasks, we impose the same group Lasso penalty but on column groups of the second component. We pro-pose to employ the accelerated gradient descent to efficiently solve the optimization problem in rMTFL, and show that the proposed algorithm is scalable to large-size problems. In addition, we provide a detailed theoretical analysis on the proposed rMTFL formulation. Specifically, we present a theoretical bound to measure how well our proposed rMTFL approximates the true evaluation, and provide bounds to measure the error between the estimated weights of rMTFL and the underlying true weights. Moreover, by assuming that the underlying true weights are above the noise level, we present a sound theoretical result to show how to ob-tain the underlying true shared features and outlier tasks (sparsity patterns). Empirical studies on both synthetic and real-world data demonstrate that our proposed rMTFL is capable of simultaneously capturing shared features among tasks and identifying outlier tasks.
 H.2.8 [ Database Management ]: Database Applications X  Data Mining Algorithm Multi-task learning, feature selection, outlier tasks detection
Multi-task learning [8] aims to improve the performance of multiple related tasks by utilizing the intrinsic relationships among these tasks. Multi-task learning has been applied successfully in a wide range of applications including ob-ject recognition [8], speech recognition [28], handwritten dig-its recognition [30] and disease progression prediction [44]. A critical ingredient in these applications is how to model the shared structures among tasks. Existing algorithms can be broadly classified into two categories: explicit parameter sharing and implicit structure sharing.

Under explicit parameter sharing, all the tasks explicitly share some common parameters; examples include hidden units in neural networks [8, 5], prior in hierarchical Bayesian models [4, 31, 36, 38], parameters of Gaussian process [18], feature mapping matrix [1], classification weight [11] and similarity metric [28, 40]. On the contrary, algorithms un-der implicit structure sharing do not explicitly impose all tasks to share certain parameters, but they implicitly cap-ture some common structures; for example, the algorithms in [29, 24] constrain all tasks to share a common low rank subspace and the algorithms in [27, 2, 23, 19, 22, 17, 35, 41] constrain all tasks to share a common set of features.
One key assumption of the above multi-task learning al-gorithms for both categories is that all tasks are related to each other by the presumed structures. However, this may not hold in real-world applications, as outlier tasks often exist. Thus, simply assuming that all tasks share a certain structure may degrade the performance. This motivates the development of several recent multi-task learning algorithms for discovering the inherent relationship among tasks. For example, some multi-task learning algorithms [32, 34, 14, 42, 16] cluster the given tasks into different groups and im-pose the tasks in the same groups to share a certain common structure. Multi-task learning algorithms with a composite regularization [15, 9, 10] have been proposed to capture dif-ferent types of relationships using regularization.
In this paper, we consider the multi-task learning setting where the relevant tasks share a common set of features while outlier tasks exist. We propose a Robust Multi-Task Feature Learning algorithm (rMTFL) which simultaneously captures the shared features among relevant tasks and de-tects outlier tasks. Specifically, we decompose the weight matrix W consisting of the prediction models of all tasks into the sum of two components P and Q .Weemploythe well-known group Lasso penalty on row groups of P such that the relevant tasks capture a common set of features. In addition, we employ the same group Lasso penalty but on column groups of Q to simultaneously identify the outlier tasks. The main contributions of this paper include: (1) We propose a Robust Multi-Task Feature Learning for-mulation (rMTFL) which simultaneously captures a com-mon set of features among relevant tasks and identifies out-lier tasks. We propose to employ accelerated gradient de-scent to efficiently solve the optimization problem involved in rMTFL, and show that the proposed algorithm is scalable to large-size problems. (2) We present a theoretical bound to measure how well rMTFL can approximate the underlying true evaluation, and give bounds to measure the error between the weights estimated from rMTFL and the underlying true weights. Moreover, by assuming that the underlying true weights are above the noise level, we present a sound theoretical result to show how we can obtain the underlying true shared fea-tures and outlier tasks (sparsity patterns). (3) We perform empirical studies using both synthetic and real-world data. Our experiments demonstrate the efficiency of the proposed algorithm. Results also demonstrate the ef-fectiveness of rMTFL for capturing shared features among tasks and identifying outlier tasks simultaneously. Organization : The remainder of this paper is organized as follows: In Section 2, we introduce our proposed rMTFL formulation. In Section 3, we present the proposed opti-mization algorithm for rMTFL. In Section 4, we provide a detailed theoretical analysis on rMTFL. In Section 5, we discuss related work. Experimental results are presented in Section 6 and we conclude the paper in Section 7. Notations : Scalars, vectors, matrices and sets are denoted by lower case letters, bold face lower case letters, capital letters and calligraphic capital letters, respectively. x x ij denote the i -th entry of a vector x and the ( i, j )-th entry of a matrix X . x i ( x i ) denotes the i -th row (column) of a matrix X . X J denotes a submatrix composed of the rows of the j -th column of a matrix X i . Euclidean and Frobenius norms are denoted by  X  and  X  F . p,q -norm of a matrix inner product of X and Y is denoted by X,Y . N m is distribution with mean  X  and standard deviation  X  .
Assume that we are given m learning tasks associated with the training data { ( X 1 , y 1 ) ,  X  X  X  , ( X m , y m ) } R d  X  n i is the data matrix of the i -th task with each column as a sample; y i  X  R n i istheresponseofthe i -th task ( y has continuous values for regression and discrete values for classification); d is the data dimensionality; n i is the number of samples for the i -th task. The data has been normalized such that the ( j, k )-th entry of X i denoted as x ( i ) We consider learning a linear function for each task and decomposing the weight matrix W = [ w 1 ,  X  X  X  , w m ]  X  R d  X  m into the sum of two components P and Q (Please refer to Figure 1 for illustration). We make use of different regularization terms on P and Q to exploit relationships among tasks. Formally, our rMTFL model is formulated as: min s.t. W = P + Q, (2) where the first regularization term on P captures the shared features among tasks and the second term on Q discovers the outlier tasks;  X  1 and  X  2 are nonnegative parameters to control these two terms. Specifically, the first regularization term is based on the well-known group Lasso penalty on row groups of P which restricts the rows of the optimal solution P to consist of all zero or nonzero elements [2]. Thus, all related tasks should select a common set of features. How-ever, the assumption that all tasks share the same set of features may not hold in real applications, as outlier tasks often exist. To address this issue, we introduce the second regularization term based on the same group Lasso penalty but on column groups of Q to discover these outlier tasks. Similarly, the columns of the optimal solution Q consist of all zero or nonzero elements, with the nonzero columns cor-responding to outlier tasks. Intuitively, if the i -th column of Q is nonzero, then the i -th column of W is also nonzero, thus the i -th task does not share a common set of features with other tasks, identified as an outlier task; meanwhile, for the remaining tasks corresponding to the zero columns of Q , they share a common set of features captured by the nonzero rows of P (see Figure 1).
 Figure 1: Illustration of weight matrix decompo-sition for rMTFL, where squares with white back-ground denote zero entries. There are 5 tasks, where the fourth task is an outlier task. Please refer to the text for detailed explanation.
In this section, we show how to solve the rMTFL formu-lation in Eq. (2) efficiently. Denote where l ( P,Q ) is the empirical loss function and r ( P,Q )isthe regularization term. We note that the objective function in Eq. (2) is a composite function of a differential term l ( P,Q ) and a non-differential term r ( P,Q ). Denote T
R,S, X  ( P,Q )= l ( R, S )+ +  X  X  ( R, S )  X  X  ,Q  X  S +  X  2 Q  X  S 2 F , (4) which is the first order Taylor expansion of l ( P,Q )at( R, S ), with the squared Euclidean distance between ( P,Q )and ( R, S ) as the regularization term. The traditional gradient descent algorithm obtains the solution at the k -th iteration r ( P,Q ) with a proper step size  X  k . Here we propose to em-ploy the accelerated gradient descent [25, 26] to solve the optimization problem, which generates the solution at the k -th iteration ( k  X  1) by computing the following proximal operator [20, 19, 21, 12, 37, 3]: where R 1 = P 0 ,S 1 = Q 0 and R k +1 = P k +  X  k ( P k  X  P is set by finding the smallest nonnegative integer m k such We note that ( R k +1 ,S k +1 ) is in fact a linear combination of ( P k ,Q k )and( P k  X  1 ,Q k  X  1 ). The coefficient  X  important role in the convergence of the algorithm. As sug-gested by [6], we set  X  k =( t k  X  1  X  1) /t k ,where t 0 t = 1+ t 2 k  X  1 +1 /2for k  X  1. According to the theo-retical analysis in [6], we present the following convergence result for rMTFL:
Theorem 1. Let ( P k ,Q k ) be generated by Eq. (5) with a properly chosen  X  k satisfying Eq. (6). Then for any k  X  1 , tion and the optimal solution in Eq. (2).
There are two issues that remain to be addressed: how to compute the proximal operator in Eq. (5) and how to select aproperinitialvalue  X  0 .
 Due to the decomposable property of Eq. (5), we can cast Eq. (5) into the following two separate proximal operator problems: P k =argmin Q k =argmin tives of l ( R,S )withrespectto S and R at ( R k ,S k ). The above proximal operator problems admit closed form solu-tions with time complexity of O ( dm ) [19]: u column of V k , respectively.

An appropriate choice for  X  0 is the Lipschitz constant L of the gradient of l ( P,Q ). However, the Lipschitz constant L is unknown and calculating it is computationally expensive. Next, we show how to estimate its lower and upper bounds. constant L is just the squared maximum singular value of D . According to matrix norm properties [13], we can bound L as follows: min We note that D is a block diagonal matrix and it is sparse when m (the number of tasks) is large, which makes the bounds of L very tight. If we set  X  0 as the upper bound of L , then we do not need line search, because when  X  k  X  L , Eq. (6) is always satisfied [6]. Otherwise, line search is neces-sary. Although setting  X  0 as the upper bound of L can elim-inate line search, it may increase the outer iterative steps. On the contrary, it leads to a smaller outer iterative steps by setting  X  0 as the lower bound of L .Inourexperiments, we use the lower bound of L to initialize  X  .
We assume that the responses are given by a linear model plus Gaussian noise 1 , i.e., y where W is the true weight matrix decomposed as the sum of two underlying true components P and Q :
For notation simplicity, we assume that the number of training samples of all tasks are the same. However, the following theoretical analysis can be easily extended to the case with different training sample sizes for different tasks. are respectively the training data and responses of the i -th task;  X  f are the i.i.d. normal noise and the true evaluation, respec-tively. Thus, we have We also define as the index sets for the nonzero and zero rows of P .
The following theorem provides a key property of the op-timal solution of Eq. (2), which is critical for our subsequent theoretical analysis:
Theorem 2. Let (  X  P,  X  Q ) be an optimal solution of Eq. (2) for m  X  2 and n, d  X  1 .Let X i and y i be defined in Eq. (11); let  X  i and f i be defined in Eq. (12) and Eq. (13), respectively. We assume that the data is normalized as in Eq. (1). Choose the regularization parameters  X  1 and  X  2 as where t is a positive scalar. Then with probability of at least 1  X  exp  X  1 2 t  X  dm log 1+ t we have +2  X  1 (  X  P  X  P ) J ( P )
Based on Theorem 2, we present some performance bounds of our rMTFL model in Eq. (2). We first introduce some no-tations to unclutter the equations. Let X  X  R dm  X  mn be a block diagonal matrix with X i  X  R d  X  n ( i  X  N m )asthe i -th block. Define a vectorization operator  X  X ec X  over an arbi-trary matrix A  X  R d  X  m such that vec( A )=[ a T 1 ,  X  X  X  Then, Eq. (17) can be rewritten as mn where F =[ f 1 ,  X  X  X  , f m ]  X  R n  X  m . Next, we make the fol-lowing assumption about the training data and the weight matrix, which generalizes the restricted eigenvalue assump-tion in [7].
 Assumption 1. For a matrix pair  X  P  X  R d  X  m and  X  Q  X  R d  X  m ,let r and c ( 1  X  r  X  d, 1  X  c  X  m )betheupper bounds of |J ( P ) | and |J ( Q T ) | , respectively, and let  X   X  2 be positive scalars. We assume that there exist positive scalars  X  1 ( r ) and  X  2 ( c ) such that where the set R ( r, c ) is defined as
R ( r, c )=  X  P ,  X  Q  X  R d  X  m |  X  P =0 ,  X  Q =0 , |J ( P ) J (  X  ) is defined in Eq. (15) and |J | denotes the number of elements in the set J .

Note that Assumption 1 is related to the restricted eigen-value assumption which is a critical condition in [7]. Some previous studies on multi-task learning [22, 10] also make use of similar assumptions. Our main theoretical result is sum-marized in the following theorem for performance bounds.
Theorem 3. Let (  X  P,  X  Q ) be an optimal solution of Eq. (2) for m  X  2 and n, d  X  1 and take the regularization pa-rameters  X  1 and  X  2 as in Eq. (16). Then under Assump-tion 1, the following results hold with probability of at least 1  X  exp  X  1 mn If in addition, the following conditions hold: then with the same probability, the following two sets estimate the true sparsity pattern J ( P ) and J ( Q T ) ,re-spectively. That is,
Theorem 3 provides important theoretical guarantee for rMTFL. Specifically, these bounds not only measure how well our rMTFL model can approximate the true evalu-ation values defined in Eq. (9) [Eq. (21)], but also mea-sure how well our rMTFL model can approximate the true weight matrices ( P ,Q ,W = P + Q ) [Eq. (22) and Eq. (23)]. Moreover, under the assumption that the un-derlying true weights are above the noise level [Eq. (24) and Eq. (24)], we can also estimate the true sparsity patterns (i.e., J ( P ) , J ( Q T )) with high probability [Eq. (26) and Eq. (27)].
Previous studies in [15, 9, 10] also decompose the weight matrix into two components; rMTFL differs from these work in several aspects: (1) rMTFL employs different regularization terms from the algorithms in [15, 9, 10]. The regularization terms in rMTFL not only have intuitive explanations for feature selection and outlier tasks detection (see Figure 1 and detailed explana-tion in Section 2), but also have sound theoretical guarantee (see Section 4). (2) rMTFL has the mechanism of detecting outlier tasks, unlike the algorithms in [15, 9]. Although the algorithm in [10] has the ability to detect the outlier, it focuses on cap-turing the low rank structure among tasks, while rMTFL has advantages on high dimensional multi-task feature learn-ing problems. Specifically, in terms of the evaluation per-formance, the main difference between our Theorem 2 and Lemma 4.3 in [10] is that the bound of rMTFL is based on (  X  P  X  P ) J ( P ) 1 , 2 , while the bound of RMTL in [10] is based on Q (  X  L  X  L ) tr . In practical multi-task learning prob-lems, the dimensionality is often high and the underlying selected features are few, that is, the number of elements in J ( P ) can be small, which indicates that (  X  P  X  P ) J ( P is small, leading to a tight bound in Theorem 2. However, in the scenario of a large number of tasks, the relevant tasks may share a low rank subspace, resulting in a small value of
Q (  X  L  X  L ) tr . Therefore, rMTFL has an advantage of identifying a few shared features for high dimensional data, while RMTL in [10] focuses on discovering low rank subspace among a large number of tasks. Our experimental results in Section 6.4 demonstrate that rMTFL outperforms RMTL in the high dimensional scenario, and RMTL is preferred when the number of tasks is large but the dimensionality is low. (3) Unlike the analysis in [10], we provide theoretical bounds to measure the error between the estimated weights of rMTFL and the underlying true weights. Moreover, we have theo-retically shown under what conditions we can obtain the underlying true shared features and outlier tasks (sparsity patterns). In addition, both Theorem 2 and Theorem 3 work with probability of at least 1  X  exp  X  1 2 t  X  dm log 1+ t which is higher than 1  X  m exp  X  1 2 t  X  d log 1+ t d pre-sented in Lemma 4.3 and Theorem 4.1 of [10]. (4) Each step of the optimization method in [10] involves SVD operation with a time complexity of O (min( d 2 m, m 2 thus it does not scale to large-size problems (e.g., the num-ber of tasks and the dimensionality are large). As we show in Section 3.1, the optimization method of rMTFL has a much lower time complexity of O ( dm ) and hence can be applied to large-size problems.
Competing Algorithms : We compare our rMTFL al-gorithm on multi-task regression problems with seven rep-resentative algorithms: ridge multi-task regression (ridge), -norm multi-task regression (lasso), trace-norm multi-task regression (trace), 1 , 2 -norm multi-task regression (L1,2), dirty model multi-task regression (DirtyMTL) [15], sparse structures and low rank multi-task regression (SLR) [9] and robust multi-task regression (RMTL) [10]. All eight algo-rithms employ a quadratic loss function. Matlab codes of the rMTFL algorithm are available online [43].

Synthetic data : The synthetic data is generated as fol-lows: we set the number of tasks m =30andeachtask has n i = 200 samples in d = 200 dimension; each entry of the data matrix X i  X  R d  X  n i ( i  X  N m ) is sampled from the distribution N (0 , 25) and it is normalized such that Eq. (1) is satisfied; each entry of the ground truth weight matrices P  X  R d  X  m and Q  X  R d  X  m is generated from the distribu-tion N (0 , 64); we set the first 160 rows of P and the first 20 columns of Q as zero vectors; the elements of the noise vector  X  i  X  R n i ( i  X  N m ) are sampled from the distribution N (0 , 1); the response y i  X  R n i ( i  X  N m ) is computed via y i = X T i ( P + Q )+  X  i . Under this setting, we have con-structed 20 related tasks and 10 outlier tasks.

Real-world Data : We adopt two data sets for our multi-task regression evaluation: School data 2 and MRI data.
The School data set is from the Inner London Educa-tion Authority (ILEA), consisting of examination records of 15362 students (samples) from 139 secondary schools in years 1985, 1986 and 1987. Each sample is represented by 27 binary attributes which include year, gender, examina-tion score, etc., plus 1 bias attribute (In our experiments, the bias attribute is not used). The response (target) is the examination score. So we have 139 tasks with each task corresponding to one school.
 The MRI data set is from the ANDI database. It contains MRI data of 675 patients preprocessed using FreeSurfer 3 . The MRI data include 306 features which can be categorized into 5 types: cortical thickness average, cortical thickness standard deviation, volume of cortical parcellation, volume of white matter parcellation, and surface area. The response (target) is the Mini Mental State Examination (MMSE) score coming from 6 different time points: M06, M12, M18, M24, M36, and M48. We remove the samples which fail the MRI quality controls and with missing entries. After the preprocessing above, we have 6 tasks with each task corre-sponding to a time point and the sample sizes corresponding to 6 tasks are 648, 642, 293, 569, 389 and 87, respectively.
In our experiments, we terminate all the algorithms when the relative change of the two consecutive objective func-http://www.cs.ucl.ac.uk/staff/a.argyriou/code/ www.loni.ucla.edu/ADNI/ nMSE and aMSE. nMSE and aMSE. tion values is less than 10  X  5 . We randomly split the sam-ples (both synthetic and real-world data sets) from each task into training and test samples with different training ratios. We evaluate eight multi-task regression algorithms on the test data set, using normalized mean squared error (nMSE) and averaged means squared error (aMSE) as the regression performance measures [39, 10, 42]. For each training ratio, both nMSE and aMSE are averaged over 10 random split-tings of training and test sets. All parameters of the eight algorithms are tuned via 3-fold cross validation. We set the training ratio of synthetic data generated in Section 6.1 as 20% and 30%, respectively. Experimental re-sults(averagednMSEandaMSE)areshowninFigure2. We observe that rMTFL outperforms all the other competing algorithms, which demonstrates the effectiveness of rMTFL for high dimensional problems with outlier tasks.
Next, we further demonstrate the outlier tasks detection capability of rMTFL. We firstly generate another synthetic data set following the same procedure in Section 6.1, ex-cept that each task has n i = 20 samples. Then, we set  X  1 2  X  run rMTFL on this synthetic data until the relative change of the two consecutive objective function values is less than 10  X  5 . Figure 3 shows the results of P and Q obtained by rMTFL. Specifically, there are 164 zero rows in P and 21 zero columns in Q . These results demonstrate the capability of rMTFL in simultaneously capturing the shared features among tasks (the nonzero rows of P ) and discovering outlier tasks (the nonzero columns of Q ).
We conduct scalability studi es on two algorithms which are capable of identifying outlier tasks: rMTFL and RMTL [10], when the dimension and the number of tasks increase. We firstly fix m = 20 and let the dimension d increase as { 50 i } ,i =0 ,  X  X  X  , 5. Then we run rMTFL and RMTL on the synthetic data generated following the same procedure in Section 6.1. The computational time (CPU time) vs. dimension plot is shown in the left subfigure of Figure 4. Figure 2: Averaged test error (nMSE and aMSE) vs. training ratio for synthetic data.
 Figure 3: Figures of P, Q and W = P + Q generated from rMTFL on the synthetic data. Black points correspond to zero entries. Note that the figures are clockwise rotated 90 degrees.
 Similarly, we fix d = 100 and let the number of tasks m increase as { 10 i } ,i =0 ,  X  X  X  , 5. Then we run rMTFL and RMTL and show the computational time (CPU time) vs. the number of tasks plot as in the right subfigure of Fig-ure 4. We observe that, the CPU time of both rMTFL and RMTL increases when the dimension d (or the number of tasks m ) increases. However, the CPU time of RMTL in-creases significantly faster than rMTFL. Because the SVD computation with a time complexity of O (min( d 2 m, m 2 d )) involved at each step of RMTL is computationally much more expensive than the computation of the 1 , 2 -norm prox-imal operator with a time complexity of O ( dm )involvedat each step of rMTFL. This demonstrates the superior scala-bility of rMTFL over RMTL.
For the School data set, we respectively set the training ratio as 16% , 24% , 32%, and for the MRI data set, we respec-tively set the training ratio as 15% , 20% , 25%. Table 1 and Figure 4: CPU time vs. dimension (left) and num-ber of tasks (right) plots for rMTFL and RMTL. The CPU time is averaged over 10 independent runs.
 Table 2 show the experimental results in terms of averaged nMSE and aMSE.

From these results, we have the following observations: (1) rMTFL outperforms all the other algorithms on the MRI data set. This may be due to the fact that for the MRI data set, the dimension ( d = 306) is high especially when com-paredwiththenumberoftasks( m = 6). (2) For the School data set, the multi-task learning algorithms based on trace norm (low rank) regularization (trace, SLR, RMTL) outper-form the multi-task learning algorithms based on 1 ,q -norm (feature selection) regularization (lasso, L1,2, DirtyMTL, rMTFL). This may be due to the fact that the number of tasks ( m = 139) of the School data set is larger compared with dimension ( d = 27). In this case, restricting all tasks to share a low rank subspace is more reasonable than restricting all tasks to share a few common features. (3) On both data sets, the performance of rMTFL is the best among the fea-ture selection based multi-task learning algorithms (lasso, L1,2, DirtyMTL, rMTFL). This may be due to rMTFL X  X  capability of simultaneously discovering the shared features and identifying outlier tasks.
The proposed rMTFL algorithm is capable of capturing the shared features among tasks and detecting outlier tasks. We next evaluate the outlier tasks detection performance on the MRI data set. Firstly, we run rMTFL on the whole MRI data set and observe that the fourth task is identified as an outlier task. Then, we remove the fourth task, obtaining a new multi-task regression problem with the remaining 5 tasks. Finally, we run 1 , 2 -norm multi-task regression on this  X  X lean X  multi-task regression problem. We call this two-stage procedure as 2S-rMTFL. The test errors (nMSE and aMSE) on the MRI data set are shown in Figure 5. We can clearly see that after removing the outlier tasks, 2S-rMTFL outperforms L1,2 and rMTFL, which demonstrates the effectiveness of rMTFL in detecting outlier tasks. Figure 5: Test errors (nMSE and aMSE) on the MRI data set. See the texts for more details. In this paper, we propose a Robust Multi-Task Feature Learning algorithm (rMTFL) to simultaneously capture the shared features among multiple related tasks and detect out-lier tasks. We analyze the theoretical properties of rMTFL. Our analysis shows how well rMTFL can approximate the true evaluation, and measure how well rMTFL can approx-imate the underlying true weights. Moreover, we show that rMTFL can obtain the true sparsity patterns if the under-lying true weights are above the noise level. In addition, the optimization problem involved in rMTFL can be solved efficiently, and rMTFL scales to large-size problems. In the future work, we will extend our rMTFL algorithm to multi-task learning problems with general loss functions and apply rMTFL to other real-world applications.
 This work is supported in part by NSFC (Grant No. 60835002, 61075004 and 91120301), NIH (R01 LM010730) and NSF (IIS-0953662, CCF-1025177). To prove the theorems presented in Section 4.2, we first pro-vide some basic lemmas and then give the detailed proof.
Lemma 1. For any matrix pair P,  X  P  X  R d  X  m , we have the following inequality: Proof. According to Eq. (15), we have It follows that We note that  X  P  X  P Substituting Eq. (31) into Eq. (30), we verify Lemma 1. Lemma 2. Let  X  i be I.I.D. random variables with  X  i  X  N (0 , X  2 ) ,i  X  N n and n i =1  X  2 i =1 . Then we have is a standard normal random variable, i.e., v  X  N (0 , 1). Proof. Since  X  i are I.I.D. random variables with  X  i  X  N (0 , X  2 ) ,i  X  N n , v must be a normal random variable. Next, we need to show that the mean ( E )andvariance( V )of v are respectively 0 and 1, as given below:
Lemma 3. Let  X  2 ( d ) be a chi-squared random variable with d degrees of freedom. Then, the following holds: Pr  X  2 ( d )  X  d + t  X  exp  X  1 Proof. By the Wallace inequality [33], we obtain where N is a standard normal random variable and z ( t )= t  X  d log(1 + t d ). Lemma 3 follows directly from Eq. (32) and inequality Pr ( N  X  z ( t ))  X  exp  X  z ( t ) 2 2 . Proof of Theorem 2:
Proof. Since (  X  P,  X  Q ) is an optimal solution of Eq. (2), the following holds for any P and Q : Substituting Eq. (14) into the above inequality, we have + 2 try given by and x ( i ) jk denotes the ( j, k )-th entry of data matrix X i -th task. It follows from Eq. (1) that are i.i.d. standard normal random variables (see Lemma 2), i.e., v ji  X  N (0 , 1). Thus, is a chi-squared random variable with dm degrees of freedom, and it follows from Lemma 3: which is equivalent to the following: Pr 2 . Under the event in Eq. (36), we bound 2 mn Z,  X  P  X  P as Similarly, under the event in Eq. (36), we have Combine Eq. (33), Eq. (37), Eq. (38) and Lemma 1, we verify Theorem 2.
 Proof of Theorem 3: Proof. Let  X  P =  X  P  X  P,  X  Q =  X  Q  X  Q . Setting P = P ,Q = Q , P and Q are the true weight matrices in Eq. (10), we have X T vec( P + Q )= X T vec( P + Q )= vec( F ). Following Eq. (18), we obtain 1 mn Under Assumption 1, we have Substituting Eq. (40) and Eq. (41) into Eq. (39), we obtain
X T vec(  X  P +  X  Q )  X  vec( F )  X  which directly leads to Eq. (21).

Following Assumption 1, we have which imply that Substituting Eq. (42) and Eq. (43)) into Eq. (40) and Eq. (41), and considering Eq. (21), we can easily verify Eq. (22) and Eq. (23).

To prove Eq. (28), we need to show the following two: We first prove (a) by contradiction. Assume there exists a j such that j 1  X   X  J 1 ,j 1 /  X  X  ( P ). Then according to the definitions of  X  J 1 and J ( P ), we have  X  p which contradicts with the following fact: We thus verify ( a ). Similarly, if we assume there exists a j Eq. (24) and the definition of  X  J 1 inEq.(26),wehave which contradicts with Eq. (46), thus ( b ) holds. Combining ( a )and( b ), we verify Eq. (28). Similarly, we can prove Eq. (29).
