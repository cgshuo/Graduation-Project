 1. Introduction
Current information technology enables many organizations to collect, store, and use various types of information about individuals. The government and organizations are increasingly recognizing the critical value of sharing such a wealth of information. However, individually identifiable information is protected under the Health Insurance Portability and Account-ability Act (HIPAA). 1 1.1. Motivating scenarios
The National Cancer Institute initiated the shared pathology informatics network (SPIN) country to share pathology-based data sets annotated with clinical information to discover and validate new diagnostic tests and therapies. Fig. 1 shows a sample pathology report section with personally identifying information such as age and med-ical record number highlighted. It is necessary for each institution to de-identify or anonymize the data before having it accessible by the network. This network of shared data consists of both structured and unstructured data of various formats.
Most medical data is heterogeneous meaning that even structured data from different institutions are labeled differently and throughout this paper. 1.2. Existing and potential solutions
Currently, investigators or institutions wishing to use medical records for research purposes have three options: obtain tion or anonymization (both de-identification and anonymization are used interchangeably throughout this paper) where a data custodian distributes an anonymized view of the data that does not contain individually identifiable information to a vacy of patients.

At the first glance, the general problem of data anonymization has been extensively studied in recent years in the data privacy community [11]. The seminal work by Sweeney et al. shows that a dataset that simply has identifiers removed is to meet a privacy principle such as k -anonymity using techniques such as generalization, suppression (removal), permuta-tion and swapping of certain data values so that it does not contain individually identifiable information, such as [15,41,4,1,12,5,47,21,22,43,46] .
 While the research on data anonymization has made great progress, its practical utilization in medical fields lags behind.
An overarching complexity of medical data, but often overlooked in data privacy research, is data heterogeneity. A consid-discharge summaries. While some identifying attributes can be clearly defined in structured data, an extensive set of iden-vacy research focus exclusively on structured data.

On the other hand, efforts on de-identifying medical text documents in medical informatics community [33,34,37,36,14,32,3,39] are mostly specialized for specific document types or a subset of HIPAA identifiers. Most impor-tantly, they rely on simple identifier removal techniques without taking advantage of the research developments from data privacy community that guarantee a more formalized notion of privacy while maximizing data utility. 1.3. Contributions
Our work attempts to fill the above gaps and bridge the data privacy community and medical informatics community by developing a framework and prototype system, HIDE, for Health Information DE-identification of both structured and unstructured data. The contributions of our work are two fold. First, our system advances the medical informatics field by adopting information extraction (also referred to as attribute extraction) and data anonymization techniques for de-identi-fying heterogeneous health information. Second, the conceptual framework of our system advances the data privacy field by integrating the anonymization process for both structured and unstructured data. The specific components and contribu-tions of our system are as follows:
Identifying and sensitive information extraction. We leverage and empirically study existing named entity extraction tech-niques [25,30] , in particular, simple Bayesian classifier and sampling based techniques, and conditional random fields based techniques to effectively extract identifying and sensitive information from unstructured data.

Data linking. In order to preserve privacy for individuals and apply advanced anonymization techniques in the heteroge-neous data space, we propose a structured identifier view with identifying attributes linked to each individual.
Anonymization. We perform data suppression and generalization on the identifier view to anonymize the data with differ-ent options including full de-identification, partial de-identification, and statistical anonymization based on k -anonymization.

While we utilize off-the-shelf techniques for some of these components, the main contribution of our system is that it bridges the research on data privacy and text management and provides an integrated framework that allows the anonymi-zation of heterogeneous data for practical applications. We evaluate our prototype system through a set of real-world data and show the effectiveness of our approach.

In the rest of the paper we first describe related work. Then we describe our de-identification system including privacy models, the conceptual framework, identifier/attribute extraction, data linking, and anonymization. We then describe our experiments and results. Finally we conclude and describe further avenues of future work.
 2. Related work
Our work is inspired and informed by a number of areas. We briefly review the most relevant areas below and discuss how our work leverages and advances the current state-of-the-art. 2.1. Privacy preserving data publishing
Privacy preserving data publishing for centralized databases has been studied extensively in recent years. One thread of work aims at devising privacy principles, such as k -anonymity and later principles that remedy its problems, that serve as large body of work contributes to algorithms that transforms a dataset to meet one of the above privacy principles (domi-nantly k -anonymity) [15,41,29,4,1,12,5,21,22,40,18,43,46,8,7] . The bulk of this work has focused exclusively on structured data. 2.2. Medical text de-identification
In the medical informatics community, there are some efforts on de-identifying medical text documents [33,34,37,36, 14,32,3,39] . Most of them uses a two-step approach which extracts the identifying attributes first and then removes or on differentiating protected health information (PHI) from non-PHI [32]. Most importantly, most of these work rely on sim-ple identifier removal or grouping techniques and do not take advantage of the recent research developments that guarantee a more formalized notion of privacy while maximizing data utility. 2.3. Information extraction
Extracting atomic identifying and sensitive attributes (such as name, address, and disease name) from unstructured text such as pathology reports can be seen as an application of named entity recognition (NER) problem [25,30] . NER systems can mar-based or rule-based techniques [3]. Unfortunately such hand-crafted systems may take the cost of months of work by experienced domain experts and the rules will likely need to change for different data repositories. The second uses statis-tical learning approaches such as support vector machine (SVM)-based classification methods. However, an SVM based method such as [32] only performs binary classification of the terms into PHI or non-PHI and does not allow statistical de-identification that requires the knowledge of different types of identifying attributes. 3. De-identification system
We first present the privacy and de-identification models used in our system, then present the conceptual framework behind our system, followed by a discussion on each component with its research challenges and proposed solutions. 3.1. Privacy model
Protected health information (PHI) is defined by HIPAA as individually identifiable health information. Identifiable infor-address information, etc. We adopt the following privacy models or de-identification options in our framework. 3.1.1. Full de-identification
Information is considered fully de-identified by HIPAA if all of the identifiers (direct and indirect) have been removed and stated identifiers can be removed, the final category of HIPAA identifiers includes  X  X  X ny other unique identifying number,
In addition, a full de-identification would render the data not very useful for many data analysis purposes. 3.1.2. Partial de-identification
As an alternative to full de-identification, HIPAA makes provisions for a limited data set (such as name and address) are removed, but not indirect ones (such as age). This approach provides better data utility. 3.1.3. Statistical de-identification
Statistical de-identification attempts to maintain as much  X  X  X seful X  data as possible while guaranteeing statistically acceptable data privacy. Many such statistical criteria and de-identification techniques are proposed for structured data as we have discussed earlier. Our approach generalizes these notions to heterogeneous data and we will discuss them in de-tail as we discuss the de-identification techniques in a later subsection. 3.2. Conceptual framework
The general conceptual framework of our system consists of a number of key components that integrate de-identification for a heterogeneous data space utilizing advanced anonymization schemes. Fig. 2 presents an illustration of the framework. We present an overview below and give more details on the important components in subsequent subsections.
While some identifying attributes can be clearly defined in structured data, an extensive set of identifying information is ponent extracts the identifying information including HIPAA identifiers as well as sensitive attributes from unstructured data. Note that in order to apply advanced data anonymization techniques, this will be a much broader set of information to be extracted than existing de-identification systems that typically focus on the set or a subset of HIPAA identifiers.
In relational data, we assume each tuple corresponds to an individual entity. This mapping is not present in heteroge-neous medical data repositories. For example, one patient may have multiple pathology and lab reports prepared at different representation of the data.
 of identifier view will allow application of advanced anonymization algorithms that are otherwise not applicable to unstruc-tured data. Given an identifier view, the anonymization component anonymizes the data using generalization and suppres-sion (removal) techniques with different privacy models. Finally, using the generalized values in the anonymized identifier view, we can remove or replace the identifiers in the original data. 3.3. Attribute extraction
Our first challenge is to recognize and extract identifying as well as sensitive information from the unstructured data in order to apply advanced anonymization algorithms on the heterogeneous data. While information extraction is a challenging we take, as well as specific research challenges within our context.

We use a statistical learning approach for extracting identifying and sensitive attributes. Note that we aim at a much broader set of attributes than existing de-identification systems which only focus on the set of a subset of the HIPAA iden-for classifying and retagging which allows the construction of a large training dataset without intensive human efforts in feeding the classified data back to the tagging software for retagging and corrections.
 erated for each token or term in the text. In our current system, the features of a token contain the token itself, previous word, next word, and things such as capitalization, whether special characters exists, or if the token is a number, etc. The features we used were largely influenced by suggestions in the recent executable survey of biomedical NER systems [20].
It is possible to include the use of medical ontologies for extracting attributes but it seems that our system achieves good results by using local features (features about the words and surrounding words) without having to result to using global features (features about or relative to the entire dataset). The use of local features allow our system to be more portable and work across many different types of data.
 text. We discuss below two classification approaches we studied. 3.3.1. Conditional random fields based classification
We first adopted a conditional random fields based named entity recognizer (NER) for extracting identifying and sensitive set based on the sequence. Given a token from the sequence it calculates the probabilities of the various possible labeling (whether it is a particular type of identifying or sensitive attribute) and chooses the one with maximum probability. The graphical model that defines a single log-linear distribution function over label sequences given the observation sequence.
The CRF is trained by maximizing the log-likelihood of the training data. The Mallet toolkit [28] is used for the CRF implementation. 3.3.2. Prioritized classification with cost-proportionate sampling
One of the drawback of the CRF classifier is its long training time. We also experimented with a simple Naive Bayesian classifier on the feature set we have generated. As expected (results will be presented and discussed in next Section), the prise more than 99% of the total terms and hence the prior probability for most of the identifying attributes are extremely
The above observations motivate us to develop a prioritized classification approach through a cost-proportionate sam-pling technique [45]. The basic idea is that random examples from the original dataset (the feature set of all tokens in bute extraction accuracy for the name attribute. 3.4. Data linking the relevant documents and structured information about a person in the data repository. However, this unique identifier problem. However, the heterogeneous data also presents a number of new challenges to the linking problem in our context.
While the traditional record linkage problem assumes structured data where one reference (record) refers to an entity and there are several attributes associated with every reference, the data can be heterogeneous in our context. An entity may contain any number of attributes that can be extracted from the unstructured data. In addition, the associations between attributes and references (entities) are not clearly defined in the heterogeneous data.

Our approach includes an iterative two-step solution involving data linking as well as attribute extraction. The extraction component extracts relevant attributes from the text and link or add them to the existing or new entities in our database.
The linking component links or merges the tuples based on the structured and extracted attributes using existing record linkage techniques. For instance, two tuples with the same or similar name and demographic information but with different the linked information can be used in the extraction process to improve the extraction accuracy and extract new additional attributes.

For linking structured and extracted attributes, probabilistic record linkage techniques [13,42] are used to resolve the po-proach is being used (1) a vector of similarity scores is computed for individual record pairs by comparing their and (3) a transitive closure is computed over matching pairs. We adopted a fine-grained record integration and linkage tool we developed, FRIL [16], for this purpose. We refer readers to [16] for the algorithmic and implementation details of the system.

We note that our extraction component so far only extracts atomic attributes and we use simple heuristics to associate such as age and address correspond to the same patient. But in many cases, the simple heuristics could fail and the problem is much more challenging. We will explore value correlation techniques such as [9] as well as the idea of dependencies or associations between linkage decisions [6,17,10] in our future research agenda. 3.5. Anonymization
Once the identifier view is generated after attribute extraction and linking, we can perform attribute removal (suppres-through anonymization techniques through attribute generalization that guarantees privacy based on a privacy principle while maintaining maximum data utility. Among the many privacy principles or criteria, k -anonymity [35] and its extension work. Below we illustrate the basic ideas behind these principles and present the anonymization approach we used. mation to re-identify individual records. We assume that a quasi-identifier is recognized based on the domain knowledge. tifier, ( Age , Gender , Zipcode ) a quasi-identifer set, and Diagnosis a sensitive attribute.

The k -anonymity model provides an intuitive requirement for privacy in that no individual record should be uniquely anonymous. The l -diversity model provides an extension to k -anonymity and requires that each equivalence class also con-Zipcode ) that satisfies 2-anonymity and 2-diversity.

A large number of algorithms have been developed for structured data anonymization based on a certain privacy principle (dominantly k -anonymity). In this study, we adopt the Mondrian multidimensional approach [22] which is a k -anonymiza-tion algorithm that has been shown to have advantages compared to others. The Mondrian algorithm uses greedy recursive top-down partitioning of the (multidimensional) quasi-identifer domain space. In order to obtain approximately uniform partition occupancy, it recursively chooses the split attribute with the largest normalized range of values, referred to as ing the anonymity constraint, or constraints imposed by value generalization hierarchies. 4. Experiments
We conducted a set of preliminary experiments on a real-world dataset. In this section, we first describe our dataset and experiment setup and then present the preliminary results demonstrating the effectiveness of our approach. 4.1. Dataset and experiment setup Our dataset contains 100 textual pathology reports we collected in collaboration with Winship Cancer Institute at Emory.
In consultation with HIPAA compliance office at Emory, the reports were tagged manually with identifiers including name, date of birth, age, medical record numbers, and account numbers or other if the token was not one of the identifying attri-reports, automatic tagging for the rest of the reports with our attribute extraction component using the small training set, and manual retagging or correction for all the reports.

We used the dataset for evaluating the accuracy of our attribute extraction component (discussed in Section 3.3). Fig. 4 shows a sample pathology report tagged with identifiers as the output of the attribute extraction component. We compared the Naive Bayes on the original dataset, Naive Bayes with cost-proportionate rejection sampling, and the
CRF approach. For cost-proportionate sampling, Table 2 shows the probabilities we used with each type of attributes. We generated a file with 200,000 examples using the sampling from the original feature file with 106,255 examples.
Once the identifying attributes are extracted and the reports are linked to each individual, we applied different de-iden-tification options on the original dataset. For full de-identification, we removed all the identifying attributes.
For partial de-identification, we only removed the direct identifiers including name and record numbers but did not re-bute using the k -anonymization algorithm built in our anonymization component (discussed in Section 3.5). Fig. 5 shows the sample de-identified pathology report as the output of the statistical de-identification component.

We then evaluated the utility of the anonymized data through a set of queries. 4.2. Attribute extraction
To evaluate the effectiveness of our attribute extraction component, we conducted a set of experiments using ten fold cross-validation in which the dataset was divided into 10 subsets and 9 subsets were used for training and the other 1 was used for testing and it was repeated 10 times (once for each subset).
 4.2.1. Metrics butes in the text. We do not report specificity because the non-identifying attributes are dominating compared to the identifying attributes so specificity will be always close to 100% which would not be very informative. 4.2.2. Results the overall accuracy for each of the extraction techniques, respectively. We observe that the results from the Naive Bayes with biased rejection sampling are much better than those without the biased rejection sampling. The results for Naive Bayes with biased rejection sampling are comparable or even better than the CRF-based classifier for certain attributes. This is somewhat surprising to us considering the simplicity of Bayesian and complexity of the CRF classifier. We suspect that the good result achieved by the Bayesian method is largely due to the sampling technique and the fairly homogeneous data-set we have but the result is yet to be generalized and confirmed with other datasets.

In general, the CRF approach achieves the best overall result. In particular, it is much better at detecting account number, which neither Naive Bayes approach ever detects. While finding proper names (and how long those names extend) can be still further improved, most attributes achieve nearly perfect performance. The effectiveness is largely contributed to the well developed CRF method and the relevant features shown useful for personal health information (PHI) extraction as well tagging to further improve the performance for various datasets. 4.3. De-identification
In many public health and outcome research studies, a key step involves sub-population identification where researchers may wish to study a certain demographic population, such as males over 50, and learn classification models based on demo-graphic information and clinical symptoms to predict diagnosis. To evaluate the effectiveness of different de-identification defined as % of correct reports being returned. Concretely, we randomly generated 10,000 queries with a selection predicate with age attribute anonymized to the range [40 X 50] would also be returned. Thus the query result gives perfect recall but varying precision and we report the query precision below.

Fig. 6 presents the query precision on the de-identified dataset using different de-identification options with varying k in de-identification provides the maximum privacy protection, but suffers a low query precision. Statistical de-identification the better the privacy level and the lower the query precision as the original data are generalized to a larger extent. 5. Conclusion and future works
We presented a conceptual framework as well as a prototype system for anonymizing heterogeneous health information including both structured and unstructured data. Our initial experimental results show that our system effectively detects a with a given privacy guarantee while maximizing data utility to the researchers. While our work is a convincing proof-of-concept, there are several aspects that will be further explored.

First, we are exploring innovative anonymization approaches that prioritize the attributes based on how important and (atomic) attribute extraction accuracy, a more in-depth and challenging problem that we will investigate is to extract indi-moved. Finally, we are planning to deploy the developed framework in the cancer patient data warehouse. Integration of the developed techniques into the Cancer Biomedical Informatics Grid (caBIG) Acknowledgements
This research is partially supported by an Emory URC grant and Emory ITSC grant. We thank the guest editors and anon-ymous reviewers for their valuable comments that improved this paper.

References
