 Mariona Taule  X  1  X  Aina Peris 1  X  Horacio Rodr X   X  guez 2 Abstract This article presents the Spanish Iarg-AnCora corpus (400 k-words, 13,883 sentences) annotated with the implicit arguments of deverbal nominaliza-tions (18,397 occurrences). We describe the methodology used to create it, focusing on the annotation scheme and criteria adopted. The corpus was manually annotated and an interannotator agreement test was conducted (81 % observed agreement) in order to ensure the reliability of the final resource. The annotation of implicit arguments results in an important gain in argument and thematic role coverage (128 % on average). It is the first corpus annotated with implicit arguments for the Spanish language with a wide coverage that is freely available. This corpus can subsequently be used by machine learning-based semantic role labeling systems, and for the linguistic analysis of implicit arguments grounded on real data. Semantic analyzers are essential components of current language technology applications, which need to obtain a deeper understanding of the text in order to make inferences at the highest level to obtain qualitative improvements in the results. Keywords Implicit argument Deverbal nominalizations Argument structure Thematic roles Semantic corpus annotation Linguistic resource Iarg-AnCora 1 is the result of enriching the AnCora-Es corpus (Taule  X  et al. 2008 ; Recasens and Mart X   X  2010 ) with the addition of a new layer of semantic annotation: the implicit arguments of deverbal nouns (i.e. arguments that are not expressed syntactically in the local context of these predicates, whose semantic interpretation depends on the linguistic and extralinguistic context). For instance, in sentence (1), the arguments of the Spanish deverbal noun operaci X n ( X  X peration X  or  X  X urgical operation X ) are not explicitly realized in the sentence, but one of them, el paciente ( X  X he patient X ), the entity to be operated on, can be recovered from the previous sentence.

AnCora-Es had only been annotated with the explicit arguments of deverbal nouns (23,439 nominal tokens) (Peris and Taule  X  2012 ) and verbal predicates (56,590 verbal tokens) (Taule  X  et al. 2008 ). Therefore, it had only been tagged with the arguments appearing within the noun phrase (NP) in the case of nouns, or within the sentence in the case of verbs. Iarg-AnCora integrates the annotation of both explicit and implicit arguments. We focused on deverbal nominalizations because the arguments tend to be expressed implicitly (60 % of the cases in the corpus) rather than realized locally in the NP (38 % of the cases in the corpus) in this type of predicate. In the case of verbs, most of the arguments occur explicitly within the verbal phrase (VP) (1.32 explicit arguments vs. 0.19 implicit arguments per verb on average 2 ) (See Table 11 for details). In example (1), the patient argument of the verb operar ( X  X erform surgery X ), that is, al paciente ( X  X n a patient X ), is explicitly realized within the VP, while the patient argument of the noun operaci X n is not explicitly realized. (1) [No han llegado los productos necesarios para [ operar [a l paciente]] VP ] sentence .
We can, therefore, postulate that the degree of optionality of the explicit arguments of deverbal nominalizations is higher than for verbs (see Sect. 5 ), and that to fully understand the meaning of deverbal nouns it is necessary to take into account both explicit and implicit arguments. Since verbs contain more explicit arguments, disposing of the implicit ones is not so critical for obtaining their correct meaning. Due to the limited resources available for annotating the corpus, a costly task, we considered that the annotation of both verbs and nominalizations could not be undertaken and that annotating only the deverbal nominalizations would result in a more valuable resource. In any case, our intention is to enrich Iarg-AnCora with the implicit arguments of verbal predicates in a future work.
This resource is an important contribution to the semantic analysis of texts due to the scarcity of corpora annotated with implicit arguments, most of which are created for English (Ruppenhofer et al. 2010 ; Gerber and Chai 2012 ; Moor, Roth and Frank 2013 ) and have restricted coverage (1250 X 3000 occurrences of nominal and verbal predicates), or need to be extended with artificial examples in order to tackle the problem of sparseness in Machine Learning (ML) tasks, as shown in Table 1 and discussed in Sect. 3 . Iarg-AnCora is the only Spanish corpus that is annotated with the argument structure of deverbal nominalizations, and the only corpus freely available with such a wide coverage (18,397 deverbal noun occurrences). Iarg-AnCora will be a valuable resource to train and test Semantic Role Labeling (SRL) systems and Semantic Parsers using ML techniques, as well as to infer linguistic knowledge about the way the implicit arguments of deverbal nominalizations occur in real data. In fact, a previous version of this corpus was used to train and test the LIARc classifier (Labeling Implicit ARguments in Spanish deverbal nominaliza-tions) (Peris et al. 2013 ). The corpus could also prove interesting in order to study discourse coherence and its modeling (Roth and Frank 2013 ).

Another important strength of Iarg-AnCora is that it integrates different levels of semantic and discourse annotation: argument structure and thematic roles (for both verbs and deverbal nouns), named entities, Spanish WordNet nominal and verbal senses, and coreference. A corpus with all this semantic-discursive information integrated is undoubtedly an interesting and useful resource for semantic analyzers whose aim is a deeper understanding of the text in order to make inferences on the highest level and thereby obtain qualitative improvements in the results. It is a language resource that can be used for many Natural Language Processing tasks and applications that need to go beyond shallow parsing, such as Question Answering, Information Extraction and Machine Translation. (2) [[La operaci X n [ financiera] AP [de este proyecto] PP ] NP no cuenta con la
In a Machine Translation system, the deverbal noun operaci X n in the second sentences of examples (1) and (2) would be ambiguous if we did not take into account the information contained in the previous sentence. However, the recovery of the implicit arguments X  el paciente  X  X he patient X  in (1) and financiera  X  X inancial X  in (2) X  X llows us to translate operaci X n in (1) as  X  X peration X  and operaci X n in (2) as  X  X ransaction X .

This resource may also be of particular interest for SRL systems, especially for those dealing with the explicit arguments of both nominal and verbal predicates and also for those taking into account the implicit arguments of deverbal nouns. It could also be of interest for Coreference Resolution (CR) systems because the linking of implicit arguments to their antecedent can be considered as a special case of coreference (Silberer and Frank 2012 ). In fact, the Implicit Semantic Role Labeling (ISRL) is a task that combines techniques of SRL and CR.
The article is organized as follows. We first introduce the notion of implicit argument (Sect. 2 ), and related work (Sect. 3 ). Then we describe the methodology carried out to create Iarg-AnCora (Sect. 4 ), presenting the annotation scheme and the criteria adopted, the linguistic resources used, the results of the interannotator agreement test conducted, and the annotation interface used. Next, we present some statistics on the annotation (Sect. 5 ), and we briefly describe the use of Iarg-AnCora for learning and testing the LIARc classifier (Sect. 6 ). Finally, conclusions are drawn (Sect. 7 ). An implicit argument, or a null instantiation (NI) in terms of the FrameNet framework (Fillmore 1986 , Fillmore and Baker 2001 ), is an argument syntactically unrealized in the local context of the predicates (verbs, adjectives or nouns) whose semantic interpretation depends on the linguistic or extralinguistic context. The implicit argument can be either a core argument (which represents an essential participant in the action/event evoked by the predicate) or an adjunct (optional) argument. Adjunct arguments are optional by definition and have a limited impact on the semantic interpretation of the predicate. Moreover, predicates usually place few and loose discriminative constraints on their adjunct arguments. Research dealing with implicit arguments therefore focuses on core arguments. In FrameNet, NIs are further classified as definite null instantiations (DNI) X  X naphorically bound within the discourse X  X r indefinite null instantiations (INI) X  X xistentially bound within the discourse. However, Moor et al. ( 2013 ) prefer to distinguish between resolvable and non-resolvable NIs within the discourse, rather than classifying them as DNIs and INIs. Gerber and Chai ( 2010 , 2012 ) do not take into account the distinction between INIs and DNIs.

In this work, we only detect and classify the implicit core arguments of the deverbal nominalizations whose semantic interpretation depends on the linguistic context, which is, in our case, the whole document. If the semantic interpretation depends on the extralinguistic context, it cannot be recovered from the surrounding discourse (3) and (4). In contrast, if the sentence interpretation depends on the linguistic context, implicit arguments can be recovered and linked to an entity (5) and (6). In the case of nominalizations, implicit arguments can be recovered from the sentence containing the nominalization or from the previous or following sentences (6). In this sense, Iarg-AnCora was only annotated with the resolvable implicit arguments of deverbal nominalizations, that is, resolvable NIs as defined by Moor, Roth and Frank, or the DNIs proposed by FrameNet.

In the following examples we provide insights into the use of explicit and implicit arguments both in the cases in which the predicate is realized as a verb and as a deverbal nominalization. Although a detailed account of our annotation scheme is presented in Sect. 4.2 , a short excerpt of our notation is included here in order to allow for the interpretation of the examples below. We use the symbol [ X ] to indicate the presence of an implicit argument. We annotate the implicit arguments with the iargn =  X  X  X :entity x  X  X  tag, with the letter i standing for an implicit argument (explicit arguments are annotated without a prefix), n for an argument position and r for a thematic role. When the implicit argument can be recovered it is linked to an underlined 3 entity identified with a number entity x (x = identifies the entity number). Examples (3) and (5) are cases in which the involved predicates are verbs. Although only deverbal nominalizations are annotated with implicit arguments in Iarg-AnCora, we include these examples for the sake of completeness. In examples (4), (6), and (7) the involved predicates are deverbal nouns, the focus of our work. (4) Todav X   X  a no sabemos nada sobre [la oferta [de la petrolera] &lt;arg0 = X  X  X gt X  X &gt;
In example (3), the agent implicit argument (iarg0 =  X  X  X gt X  X ) of the verbal predicate se cometieron ( X  X ere made X ) cannot be recovered (or resolved) within the linguistic context (it is an INI in FrameNet terminology), therefore, this argument existentially bound within the discourse; we do not know who exactly committed the mistakes, because it is probably irrelevant in communicative terms. This is a general grammatical characteristic of passive constructions, in which the patient argument is nearly always explicitly realized (arg1 =  X  X  X at X  X ), though not the agent argument. Another example of a non-resolvable implicit argument (in terms of Moor, Roth and in this case the specific offer made, cannot be recovered from the linguistic context and cannot, therefore, be linked to an entity in the discourse such as in (3). In Iarg-AnCora, these non-resolvable arguments are not annotated.
However, in example (5) the implicit destination argument ([ X ] &lt;iarg3= X  X  X est:enti-ty1 X  X &gt; ) of the verbal predicate llegamos ( X  X e arrived X ) can be recovered from the linguistic context (it is a DNI in FrameNet terminology). Concretely, it can be (6) shows the deverbal noun apariciones ( X  X ppearances X ) with the explicit locative argument (arg2 =  X  X  X oc X  X ) ( p X blicas ,  X  X ublic X ) realized inside the NP, whereas the Barcelona board X ) is implicitly understood and recovered from the same sentence but outside the NP. Instead, in the same example (6), the implicit theme argument noun desencanto ( X  X isenchantment X ) can be recovered from the previous sentence. In the case of sentence (6), the identification of the implicit arguments implies a gain in the semantic role coverage of two deverbal nouns ( apariciones  X  X ppear-ances X  and desencanto  X  X isenchantment X ), and therefore a gain for the semantic interpretation of these sentences and for the understanding of the text.
It should also be pointed out that in Iarg-AnCora corpus we treat those arguments that are syntactically unrealized in the local context of these predicates, i.e. the arguments realized outside the NP, as implicit arguments of deverbal nouns. But, unlike Meyers ( 2007 ), we also treat those that do not depend directly on the nominal predicate, even though they appear in the NP, as implicit arguments. In other words, the implicit arguments can occur within the scope of a nominal predicate without being directly dominated by it. For instance, constituents inside a subordinate clause of the deverbal noun can be implicit arguments (7). ( X  X eronautics industry X ), which is a constituent inside the subordinate clause ( S ). It is not an explicit argument because the deverbal noun does not directly dominate context is needed in order to recover the referent of the argument. There exist different corpora that are semantically annotated with the argument structure and thematic roles of deverbal nominalizations: NomBank 6 (Meyers et al. 2004 ; Meyers 2007 ) and FrameNet 7 (Ruppenhofer et al. 2006 ) reference resources for English; AnCora-Es 8 (Peris and Taule  X  2012 ) for Spanish; NOMAGE 9 (Balvet et al. 2011 ) for French, and the on-going Copenhagen Dependency Treebank (CDT) 10 project (Mu  X  ller 2011 ), which aims to semantically annotate a set of parallel treebanks for Danish, English, German, Italian and Spanish. However, all of them are focused on the annotation of explicit arguments, that is, those arguments realized inside the NP which includes the nominalization. Corpora annotated with the implicit arguments of deverbal nouns are very scarce, restricted to English, and have limited coverage.

As far as we know, there are two English corpora annotated with implicit arguments specifically created to train and test SRL systems, which are presented in Ruppenhofer et al. ( 2010 ) and in Gerber and Chai ( 2010 , 2012 ). The former corresponds to the training and test corpus developed for SemEval-2010 task 10, Linking events and their participants in discourse 11 (Ruppenhofer et al. 2010 , 2012 ). The corpus consists of literary texts extracted from two of Arthur Conan Doyle X  X  fictional works, annotated following the FrameNet-style (Erk and Pado  X  2004 ). 12 The number of nominal and verbal occurrences tagged is 3073 (corresponding to 769 different frame types) in a total of 963 sentences (17,072 tokens). Therefore, in this corpus each nominal and verbal predicate has a very small number of occurrences (an average of 4 instances per predicate), and data is consequently rather sparse. In fact, this scarcity of data is one of the reasons put forward by Gerber and Chai ( 2010 , 2012 ) for the creation of a new dataset for developing and evaluating their SRL system. They tagged a subset of the standard training, development and testing sections of the Penn TreeBank (Marcus et al. 1993 ) following the PropBank (Palmer et al. 2005 ) and NomBank (Meyers 2007 ) annotation scheme. In order to avoid the problem of sparseness, they tagged a large number of occurrences (1247 in total) of only 10 different nominal predicates. The predicates chosen correspond to the ten 13 most frequent unambiguous deverbal nouns in the corpus. Following a similar approach, Moor et al. (2013) 14 tagged the implicit arguments of 1992 occurrences of five 15 verbal predicates (an average of 398 instances per predicate) selected from the OntoNotes 4.0 corpus (Weischedel et al. 2011 ). They followed the SemEval task 10 guidelines (Ruppenhofer et al. 2010 , 2012 ) for the annotation and linking of null instantiations (NI), except that they distinguished between resolvable and non-resolvable NI within discourse instead of classifying them as Definite NI and Indefinite NI. They use this data to show that the performance of SRL systems, which deal with implicit arguments (or NIs), can be improved when the sparseness of the training corpus is reduced.
There also exist proposals for the automatic creation of  X  X rtificial training data X  (Silberer and Frank 2012 ) to address the sparse data problem and the scarcity of resources annotated with implicit arguments. For instance, Silberer and Frank ( 2012 ) propose a technique for the heuristic acquisition of labelled data from corpora manually annotated with coreference information and semantic roles. Basically, these authors follow an entity-based approach, in which entities are represented by their coreference chains. They artificially delete the semantic role label of the anaphoric pronouns and assign it to the closest antecedent in the coreference chain of these pronouns. Roth and Frank ( 2013 ) propose a heuristic method for acquiring a dataset of implicit arguments and their discourse antecedents, which exploits aligned predicate argument structures from pairs of comparable texts. They compare the argument structures of both predicates searching for the explicit arguments in one predicate argument structure that has been unrealized (implicit) in the other. Once the implicit arguments are identified, they link them to an antecedent taking into account the cross-document coreference chain of its explicit counterpart.

Table 1 summarizes the main characteristics of the above mentioned corpora: the name of the corpus and its corresponding reference (column 1); the source from which they have been created, most of them were built from existing annotated corpora (column 2); the size, specifying the types and tokens of the predicates analyzed with implicit arguments (columns 3 and 4) and their token/type ratio (column 5); the type of predicate annotated, i.e. verbs and deverbal nouns (column 6), and whether the predicates are ambiguous or unambiguous (i.e. whether they have one or more than one sense) (column 7); the annotation scheme used (column 8); the annotation process followed (column 9), and the language (column 10).
With the exception of the datasets created artificially, the above mentioned corpora share the following basic characteristics: (a) they are only annotated with core arguments, so they do not deal with adjunct arguments; (b) they only mark the identity relations between the referents, that is, between the antecedent and the implicit argument instance (no bridging or part-whole relations are considered); (c) the instances of implicit arguments are linked to all mentions of the referents and, therefore to the coreference chain of mentions 16 ; (d) they were all manually annotated; and, (e) their size, especially in terms of tokens, is rather small. These characteristics are also shared by the Spanish Iarg-AnCora corpus presented in this article. But, in contrast to the English corpora, Iarg-AnCora has an extended coverage (18,397 occurrences corresponding to 1454 different types, average of 0.64 implicit arguments per predicate) and, unlike the G&amp;C corpus, all of the deverbal nouns are analyzed, not only a small subset of the unambiguous ones. The Spanish corpus differs from the MR&amp;F corpus in that they annotated the implicit arguments of specific verb predicates. The SemeEval-2010 and G&amp;C corpora are both built for specific tasks, while Iarg-AnCora and the other English corpora could be used as a reference corpus for the annotation of implicit arguments and for the linguistic analysis of this kind of phenomena. The primary goal of Iarg-AnCora is not to be a corpus for a specific semantic task, although it could obviously be used for that purpose. In fact, a subset of the Iarg-AnCora was used as a training and test corpus for creating LIARc (Peris et al. 2013 ) (See Sect. 6 ).

We will now briefly present the systems recently developed to automatically detect and classify implicit arguments, which use as training corpora those described above. Most of them deal with English and can be split in two groups. On the one hand are those systems related to the SemEval-2010 Task 10 (Ruppenhofer et al. 2010 ), and concretely, those that tackled the NI resolution subtask. We include in this group the two participating systems, Semafor (Chen et al. 2010 ) and Venses ?? (Tonelli and Delmonte 2010 ), and those systems that use the same data set and evaluation measures used in this subtask (Silberer and Frank 2012 ; Laparra and Rigau 2012 ; Ruppenhofer et al. 2011 ; Tonelli and Delmonte 2011 ; Wang et al. 2013 ). All these systems identify implicit arguments for different English predicates (verbs and nouns), following the typology of implicit arguments proposed in Fillmore ( 1986 ) and Fillmore and Baker ( 2001 ) and the FrameNet annotation scheme (Baker et al. 1998 ). These systems use different approaches to resolve the binding of NIs. Silberer and Frank ( 2012 ) approach the problem as a CR task; Tonelli and Delmonte ( 2011 ), Semafor, and Venses ?? approach it as an extension of SRL systems, while Ruppenhofer et al. ( 2011 ) and Laparra and Rigau ( 2012 ) adopt a mixed approach to carry out the task combining both strategies. These systems can use supervised ML techniques such as Silberer and Frank ( 2012 ) and Semafor, or they can be based on hand written rulesets that use different type of information (Ruppenhofer et al. ( 2011 ); Laparra and Rigau ( 2012 ); Tonelli and Delmonte 2010 , 2011 ). It is also worth noting that all systems except Chen et al. ( 2010 ) (which works in parallel) deal with the problem sequentially, that is, by breaking down the task into different subtasks. Laparra and Rigau ( 2013 ) base their approach on the discourse coherence of predicates. Roth and Frank ( 2013 ) use as the core of their approach a dataset of automatically aligned predicate pairs released by Roth and Frank ( 2012 ).
 On the other hand, Gerber and Chai ( 2010 , 2012 ) developed a parallel supervised ML feature-based model to detect the core implicit arguments of English deverbal nominalizations, which uses G&amp;C corpus described above. More detailed informa-tion, and some improvements can be found in Gerber ( 2011 ).

In Sect. 6 , the LIARc classifier (Peris et al. 2013 ), the only system dealing with the implicit arguments of deverbal nouns in Spanish, is described in more detail. This classifier uses Iarg-AnCora as a training and test corpus, and it is based on the experiments carried out by Gerber and Chai ( 2010 , 2012 ). In this section, we describe the annotation of the Spanish AnCora corpus with the implicit arguments of deverbal nouns. The annotation process involved two subtasks that were carried out manually. The first subtask consisted of detecting the missing core implicit arguments whose semantic interpretation depends on the linguistic context. This task also involved the assignment of the argument position X  X arg0, iarg1, iarg2, etc. X  X nd its corresponding thematic role -agent, cause, patient, among others. The second subtask consisted of linking the implicit arguments to discourse entities.

The syntactic constituents that can be annotated as antecedents of implicit arguments are: sn (NP), grup.nom (nominal group in a conjoined NP), relatiu (relative pronoun) and S (clause), that is, those constituents that can be discourse entities. 17 A discourse entity can consist of only one mention -that is, a singleton-or can be a coreference chain, which consists of different types of mentions that point to the same referent (Recasens and Vila 2010 ). The instances of implicit arguments are linked to all mentions of the referents and, therefore, to the coreference chain of mentions. For instance, in (8) the entity los pasajeros is a singleton ( X  X  X ingleton1 X  X ) because it has only one mention in this document, whereas entity 4 consists of a coreference chain of three mentions (entity4 =  X  X  X a pasarela X  X ,  X  X  X a que X  X ,  X  X  X a pasarela X  X ), which are underlined in the example.
It is worth noting that we only marked the identity relations between the antecedent and the implicit argument instances, therefore, bridging or part-whole relations were not considered. In fact, these relations were also omitted in the annotation of AnCora corpus with coreference relations.

We use the verbal and nominal lexicons X  X nCora-Verb (Aparicio et al. 2008 ) and AnCora-Nom (Peris and Taule  X  2011 ) X  X s lexical resources to obtain the information about the possible implicit arguments for each predicate. The arguments to be localized in the local discursive context, and to be annotated, are those specified in the nominal or verbal lexical entries and not explicitly realized in the NP.
 We use both lexicons because the verbal one is larger than the nominal one. Moreover, the verbal lexicon was manually created, whereas the nominal lexicon was automatically obtained from the annotation of the explicit arguments of nominalizations in the AnCora corpus. Therefore, only explicit arguments are represented in the AnCora-Nom lexicon. This is why we also need to consult the verbal lexicon to obtain the information missing in AnCora-Nom.

In order to ensure the quality and the consistency of the annotated data, an inter-annotator agreement test was conducted on a subsample of 200 deverbal noun tokens (out of the 18,397 tokens finally annotated) and 500 implicit arguments were revised.

In the following subsections, we introduce the annotation scheme used for the annotation of implicit arguments (Sect. 4.1 ), then we describe the annotation process (Sect. 4.2 ), the linguistic resources (Sect. 4.3 ) and the annotation tool (Sect. 4.4 ) and, finally, we provide details about the inter-annotator agreement test (Sect. 4.5 ). 4.1 Annotation scheme The annotation scheme used for tagging the implicit arguments is the same as the one followed to annotate the explicit arguments of deverbal nouns (Peris and Taule  X  2011 ) and the argument structure of verbs in AnCora (Taule  X  et al. 2008 ), which was in turn based on PropBank/NomBank for argument annotation and VerbNet (Kipper et al. 2006 ) for the annotation of thematic roles. In this way, we ensure the consistency of the annotation of arguments of different predicates X  X ouns and verbs X , as well as the compatibility of Spanish and English resources.

For the sake of simplicity, we use the symbol [ X ] to indicate the presence of an implicit argument. We use the iargn =  X  X  X :entity x  X  X  tag abbreviation to identify implicit arguments and to differentiate them from explicit arguments ( argn =  X  X  X  X  X  tag) (Gerber and Chai 2010 , 2012 ). In this tag, the letter i identifies implicit arguments and n indicates the argument position (from 0 to 4). The r attribute tag is used to indicate the thematic role and the entity x attribute tag indicates the discourse entity to which it is linked ( x indicates the entity number). The list of thematic roles includes 20 different labels based on VerbNet proposal. The combination of the five argument position labels (iarg0, iarg1, iarg2, iarg3, iarg4) with the different thematic roles results in a total of 23 possible semantic tags 18 (Table 2 ).
In order to link an implicit argument to its corresponding discourse entity X  X  singleton or a coreference chain X , we take into account the coreference information tagged in the AnCora corpus. Therefore, we follow the same annotation scheme used in the coreference annotation (Recasens and Mart X   X  2010 ), which was in turn based on the general criteria of the MATE scheme (Poesio 2004 , Poesio and Artstein 2005 ).

The link is established by anchoring the implicit argument ( iargn ) to the corresponding discourse entity, concretely by the attribute entity . The possible values of entity can be a  X  X ingleton X  (identifying discourse entities with only one mention) (11), an  X  X ntity X  (identifying the mentions of a coreference chain) (9) or the combination of two discourse entities (either singletons or coreference chains, for instance  X  X ntity n ? entity n  X  or  X  X ingleton n ? entity n  X ) (10). Each mention has an entity number ( X  X ntity n  X  or  X  X ingleton n  X ) assigned to it, and all the mentions of a coreference chain share the same entity number. Each mention also has its associated entityref, an attribute for indicating whether the mention is referential or not. This attribute has five possible values:  X  X e X  refers to a named entity mention;  X  X ne X  stands for a non-named entity mention;  X  X pec X  basically refers to anaphoric pronouns;  X  X ex X  indicates non-referential mentions that are part of an idiom; and, finally, no entityref stands for the mentions which are not referential. In the case of coreference chains, the attribute coreftype =  X  X  X dent X  X  indicates an identity relation between the antecedent and the implicit argument, the only coreferential relation annotated in AnCora.
In sentence (9), the agent implicit argument of the deverbal noun cr X ticas ( X  X riticisms X ) (iarg0 =  X  X  X gt:entity 24  X  X ) is linked to the discourse entity la alcaldesa ( X  X he Mayor X ) by the attribute entity (entity =  X  X  X ntity 24  X  X ), which is a named entity referential mention (entityref =  X  X  X e X  X ). Since the entity is a mention from a coreference chain, the coreftype attribute indicates that an identity relation (coreftype =  X  X  X dent X  X ) is established with the other mentions in the chain. (11) La construccio  X  n del Fo ` rum exigira  X  [[ la demolicio  X  n de los 80
In sentence (10), the theme implicit argument of the deverbal noun da X os ( X  X amages X ) is linked to two different discourse entities, el avi X n ( X  X he airplane X ) and la pasarela ( X  X oarding bridge X ) (iarg1 =  X  X  X em:entity2 ? entity4 X  X ), which are part of a coordinated NP (sn_coord). In sentence (11), the patient implicit argument of the deverbal noun operaci X n ( X  X peration X ) is linked to a singleton entity and to an entity which is part of a coreference chain, (iarg1 =  X  X  X at:singleton4 ? entity29 X  X ). The combination of different discourse entities is often due to the presence of coordinated NPs, as is shown in the above examples. 4.2 Annotation process The steps we followed in the annotation process were: (a) first, to identify the missing core arguments ( iargn = r:entity x ), taking into account the information contained in the AnCora lexicons, and to assign their argument position and the corresponding thematic role; (b) second, to find the discourse entity ( entity or singleton ) in the discursive context, that is, the antecedent to which to link the implicit argument. Singletons were not annotated in AnCora-Es, but in the Iarg-AnCora corpus they were tagged when they were the antecedents of the implicit argument of a deverbal noun. If it was not possible to find an antecedent, the implicit argument remained unresolved and no specific tag was associated. It is worth noting that, in contrast to Gerber and Chai ( 2010 , 2012 ), we can link an implicit argument to mentions appearing not only within the sentence containing the deverbal noun and within preceding sentences, but also in subsequent sentences. Unlike Ruppenhofer et al. ( 2010 , 2012) , we can also link the arguments to singletons and not only to mentions in coreference chains. Singletons are less likely to be antecedents of implicit arguments (23 % in the corpus) than entities in coreference chains (76.69 %), but they cannot be ignored. 4.3 Linguistic resources The main linguistic resource used for building Iarg-AnCora is the AnCora-Es corpus, a Spanish multi-layered annotated corpus, which consists of 400,000 words derived from newspaper and newswire articles. 19 This corpus was morphologically tagged (with PoS and lemma information), syntactically parsed (with constituents and functions), semantically annotated (with the argument structure of verbs and deverbal nominalizations, WordNet 20 nominal senses and named entities) and, finally, annotated at the discourse level (with coreference information). All of these annotated layers were manually validated in order to ensure the quality of the final resource. The annotation of the verbal and nominal argument structures only dealt with the arguments explicitly realized, which is why we have enriched the corpus with the implicit arguments of deverbal nouns. As for the coreference information, it includes the coreference links between pronouns (including elliptical subjects and clitics), 21 full NPs (including proper nouns) and discourse segments (one or more contiguous sentences), as well as the type of coreference relation established X  identity, discourse deixis and predicative relations X (Recasens and Mart X   X  2010 ).
AnCora-Verb 22 is a Spanish lexicon consisting of 2830 verbal entries, which correspond to the verbs appearing in the corpus. A verb can have different senses and each sense can have different syntactic-semantic frames depending on the diathesis alternations in which it can participate. 23 Each frame provides the mapping between a syntactic function and its constituent, argument position and thematic role, as well as the semantic class to which it belongs. Relevant examples of uses for each frame extracted from the corpus are also provided. Currently, there are 24 different semantic classes (Taule  X  et al. 2011 ), 24 which are based on the proposal of Levin ( 1993 ). Figure 1 shows the information associated with the entry of criticar ( X  X o criticize X ) in AnCora-Verb. The first sense of criticar (&lt;sense id =  X  X 1 X  X &gt;) has two frames with their corresponding semantic classes associated with them: the first belongs to the transitive-agentive-patient semantic class (lss =  X  X  X 21 X  X ), and the second to the unaccusative-passive-transitive semantic class (lss =  X  X  X 22 X  X ), which corresponds to the passive alternation. In the transitive frame, the subject (suj) maps to the first argument (arg0) with the thematic role of agent (agt), whereas the object (cd) corresponds to the second argument (arg1) with the thematic role of patient (pat). In the passive frame, there is an argument crossing: the affected object appears as subject (suj) and maps to the second argument (arg1) with the thematic role of patient (pat); and the agent maps the first argument (arg0) with the agent complement (cag), which is syntactically realized by a prepositional phrase (sp).
AnCora-Nom 25 is a lexicon of Spanish deverbal nominalizations consisting of 1658 entries, which corresponds to the deverbal nouns appearing in the corpus. Each sense of a deverbal noun has an associated denotation type (i.e., event, result, and underspecified), an assigned WordNet synset. The mapping of nominal comple-ments with arguments and the corresponding thematic roles is also annotated. This mapping is established taking into account the syntactic and semantic information of the verb base from which the nominalization is derived and is represented in AnCora-Verb. The AnCora-Nom lexical entries are linked to their corresponding verbal lexical entries in AnCora-Verb.

Figure 2 shows that cr X tica ( X  X riticism X ) is a deverbal noun (origin =  X  X  X everbal X  X  type =  X  X  X oun X  X ) linked to the first sense of the criticar verbal entry (origin-link =  X  X  X erb.criticar.1 X  X ), with which it shares the same argument structure -that is, the first argument (arg0) with the thematic role of agent (agt) and the second (arg1) with the thematic role of patient (pat), which is syntactically realized with a prepositional phrase constituent (sp).

Since the lexicons are generated from the annotated corpus, we took into account the argument structure information declared in both lexical resources to find the possible implicit arguments of each nominal predicate, i.e. those specified in the nominal or verbal lexicons but explicitly unrealized in the local context of the deverbal noun. For instance, in sentence (12) the patient argument (arg1 =  X  X  X at X  X ) is the only argument explicitly realized in the NP. We use the nominal and verbal lexicons to infer that there is an agent argument (arg0 =  X  X  X gt X  X ) to locate, which, in fact, is implicitly understood ( la alcaldesa ,  X  X he Mayor X ) recovered from the same sentence but outside of the NP headed by the nominalization. 4.4 AnCoraPipe annotation tool In order to minimize errors in the annotation process and make the annotator X  X  work easier, we used AnCoraPipe 26 (Bertran et al. 2011 ) to annotate the implicit arguments. This is an environment that enables the creation, editing and analysis of corpora and lexicons. Concretely, the edition process allows for the annotation of corpora using different linguistic interfaces, which are specific for each layer of linguistic analysis. For instance, it was also used for the annotation of the argument structure, named entities and coreference relations in the AnCora corpus. The interfaces integrated in AnCoraPipe were developed with the participation of linguists with the aim of being user-friendly and user-oriented. This resulted in a tool designed for operational simplicity through the minimization of the mouse clicks required to perform operations, the highlighting of the relevant nodes to be annotated and access to specific windows (panels) that allow us to consult, for instance, the AnCora lexicons, but also external lexical resources, such as the Multilingual Central Repository, which can be useful for the semantic annotation of corpora. In addition, it allows the different annotators to work simultaneously with the same version of the corpus. AnCoraPipe is implemented as a plug-in in the Eclipse 27 development platform. Eclipse facilitates the integrated management and collaborative building of linguistic resources using the Subversion (SVN) version control system to update the remote copies. In AnCoraPipe, the corpora texts and the lexical entries are XML documents with UTF-8 encoding.
 Although AnCoraPipe was built for supporting the building and maintenance of AnCora resources (lexicons and corpora for Spanish and Catalan languages), the tool can also be configured for working with other languages 28 and purposes.
Iarg-Annotator, a specialized user-oriented interface for the annotation of implicit arguments, specially designed to carry out this task (Fig. 3 ), is integrated in AnCoraPipe. All of the entities that appear in the document are listed in the Iarg-Annotator panel, and the candidates for implicit arguments to be identified appear at the bottom of the panel (iarg0 =  X  X  X gt X  X  and iarg1 =  X  X  X at X  X , in this example). The annotator has to select the correct discourse entities manually from the list of entities available in the document: in the example, the singleton 1 ( todos los medios ,  X  X ll media X ) for iarg0 =  X  X  X gt X  X  and the combination of two discourse entities, entity 1 ? entity 7 , for iarg1 =  X  X  X at X  X  (entity 1 corresponds to el entrenador|Van_ Gaal ,  X  X he coach|Van_Gaal X  and entity 7 corresponds to el president del club|N X  X ez| ... ,  X  X he president of the club|Nu  X  n  X  ez| ...  X ). 29 The panel also displays the sentence with the deverbal noun highlighted ( cr X ticas ,  X  X riticisms X ).
The panel on the left in Fig. 4 contains two windows: the upper one displays the text separated into paragraphs with the sentence containing the deverbal noun highlighted; the window below shows the tree structure (first column) with associated syntactic and semantic information, i.e. the syntactic function and the argument position and thematic role of the explicit arguments, as well as the possible implicit arguments to be identified (second column), corresponding to the deverbal noun (iarg0 =  X  X  X gt X  X  and iarg1 =  X  X  X at X  X , in this example); the third and fourth columns show the lemma and the words contained in each syntactic node respectively. The panel on the right displays all the Iarg-AnCora files containing occurrences of the deverbal noun to be analyzed along with the file under revision and its specific occurrence highlighted (the noun cr X ticas appears twice in the text, but in this example we are annotating the second occurrence, which is highlighted). Finally, a summary of the implicit arguments, which are identified and associated to their corresponding discourse entities, are shown at the bottom of the screen: the implicit arguments of the noun cr X ticas (second column) are iarg0 =  X  X  X gt:single-ton1 X  X  (third column) and iarg1 =  X  X  X at:entity 1 ? entity 7  X  X  (fourth column).
Therefore, the annotator has to select the correct discourse entity for each implicit argument, taking into account the discourse context and the information specified in the lexicons, which can also be consulted from AnCoraPipe.
One of the benefits of using this annotation tool is that the annotators have all the necessary information for the annotation available on the same screen. 30 The panels can be laid out in the graphic space and opened and closed independently, depending on the preferences of the annotator, making the annotation process easier. 4.5 Interannotator agreement test The manual annotation of Iarg-AnCora was carried out by three trained graduate students in linguistics, who also participated in the annotation of the explicit arguments of verbs and deverbal nouns in AnCora. Therefore, they were already familiar with the annotation scheme and tool to be used. In fact, they needed only minimal instructions to use the new panel specially created for this task. Once they were familiar with the annotation guidelines of implicit arguments (Peris and Taule  X  2013 ), an Inter-Annotator Agreement test was conducted to ensure the consistency and quality of the Iarg-AnCora annotation. The analysis of disagreements enabled us to check whether the annotators had clearly understood the task, to detect the most problematic aspects in the annotation, to resolve them and to improve the annotation guidelines in order to obtain better results.

The data consisted of a subsample of 200 deverbal noun tokens corresponding to 8 unambiguous lemmas X  actuaci X n ( X  X ctuation X ), comunicado ( X  X ommunication X ), da X o ( X  X arm X ), empate ( X  X raw X ), negocio ( X  X usiness X ), opci X n ( X  X ption X ), propuesta ( X  X roposal X ) and viaje ( X  X ravel X ) X , which appear in 88 different documents (files). We selected unambiguous lemmas because the most difficult task for the annotators was to identify the correct discourse entity to which the implicit argument had to be linked. Unambiguous lemmas are monosemous nouns, which do not present problems of ambiguity in the selection of argument position and thematic role. Since each deverbal noun can have more than one implicit argument to be identified, a total of 500 possible implicit arguments were reviewed, some of them were assigned to a discourse entity and other candidates were unresolved. Each annotator tagged the documents separately.

We did not compute the agreement in the assignment of thematic roles because, on the one hand, the annotators had prior annotation experience and they had participated in the annotation of the explicit arguments of verbs and nominaliza-tions 31 and, on the other hand, because the argument positions and thematic roles are specified in the lexicons and there was little room for error.
 In Table 3 , we present the pairwise and total agreement percentages obtained. Columns show the result for each pair of annotators (pairwise agreement) and between all the annotators (total agreement). The rows show the observed agreement and Cohen X  X  kappa coefficient [as in Gerber and Chai ( 2010 ) in order to compare the results obtained]. There is agreement when all the annotators link the implicit argument to the same discourse entity, or when they link it to at least one of the discourse entities if there is more than one. The average pairwise result obtained among the three pairs of annotators was 81 % of observed agreement (0.58 kappa). The total agreement obtained was 71 % (0.39 kappa). The results obtained show a moderate agreement that confirms the complexity of the task.

A direct comparison with agreements obtained by other authors is difficult because of the differences in language and predicates. The most fair comparison could be made between our pairwise average kappa (0.58) and the one reported by G&amp;C (0.67).

The main source of disagreement (85 % of cases) is due to missed links, that is, one of the annotators links an implicit argument to a discourse entity and the others do not, or one annotator does not recognize the link that the other two have identified. Moreover, in 75 % of cases, the source of this type of disagreement is the least experienced annotator. The remaining 15 % corresponds mainly to disagree-ments due to the three following reasons: (a) Different interpretations of the antecedent, especially when a singleton is (b) Different interpretations when the deverbal noun is part of a multiword (c) Metaphorical versus literal interpretation of the deverbal noun:
Due to the complexity of the task and the problems detected in the inter-annotator agreement test, the guidelines were revised; annotator A, who presented less agreement, was excluded from the task, and the other two annotators received more training before proceeding with the annotation of the whole corpus. The remaining annotation was not conducted in parallel.

In order to ensure the consistency in the annotation, we tagged the corpus in two stages: First, the unambiguous deverbal nouns were annotated, i.e. the monosemous nouns, which do not present problems of ambiguity in the selection of argument position and thematic role. In this stage, an expert annotator validated the annotation focusing on the linking of arguments to the discourse entities. In a second stage, the ambiguous deverbal nouns were annotated.
The annotation was carried out by lemma, that is, the same annotator tagged all the occurrences of the same (unambiguous or ambiguous) lemma, instead of annotating all the occurrences of different lemmas in the same document. We also had weekly meetings until the end of the annotation process in which difficult and doubtful cases were discussed and documented. In this section, we present distributional statistics for the implicit arguments in Iarg-AnCora, which can be useful for linguistic analysis. From the total of 18,397 deverbal noun instances (tokens) annotated corresponding to 1454 different lemmas (types), we highlight the following observations for Spanish. 1. Implicit arguments are more frequent than explicit arguments in nominal
In order to perform meaningful comparisons between the distributions of explicit and implicit arguments in Spanish and English, in Table 4 we present information on the average length (in tokens) of nominal (NP) and verbal (VP) phrases for both languages. We compute the figures for three cases: (i) all the phrase, i.e. the number of tokens corresponding to leaves in the trees rooted by NP (respectively for VP), in the row labeled  X  X ll X , (ii) only the phrases not included in other phrases of the same type, in the row labeled  X  X op X , and (iii) only the phrases not including phrases of the same type, in the row labeled  X  X ase X . The statistics have been obtained from subsets of the Penn TreeBank and AnCora-Es corresponding to the dataset used by G&amp;C for English and the similar dataset used for Spanish in the LIARc experiment. From the table, we can confirm our intuition that Spanish is more verbose than English: on average, Spanish base VPs are 1.3 times longer than English ones, and Spanish base NPs are 1.2 times longer than English ones. VPs are longer than NPs for both English (3.4 times longer) and Spanish (3.6 times longer).

Table 5 contains the percentages of explicit (e-args), implicit (i-args) and non-resolvable (nr-args) noun arguments (columns) per argument position (rows). In each cell of the table, as well as the absolute count of the instances 32 found, we include the relative contributions in percentage for the argument type (in rows, tagged with ? ) and for the argument position (in columns, tagged with ; ). The rows show the number and percentage of explicit, implicit and non-resolvable cases for each argument position (arg0 X  X rg4). For instance, arg0 is realized in 19.28 % of cases as an explicit argument, 53.29 % as an implicit argument and 27.43 % as a non-resolvable argument. The columns show the distribution for argument position for each type of argument (explicit, implicit and non-resolvable arguments), for instance, 60.54 % of explicit arguments are arg1 and 28.18 % are arg0; and 49.49 % of implicit arguments are arg0 and 37.25 % are arg1. These figures are in bold in the table for the sake of clarity.

From the total number of possible candidate arguments for annotation (43,550), 24.4 % are realized explicitly, 38.4 % are implicit arguments and 37.1 % are non-resolvable arguments (last row of Table 5 ). Therefore, these results show that the arguments in deverbal nominalizations are realized more implicitly than explicitly. The non-resolvable arguments (37 %) are those that cannot be recovered from the linguistic context, but could probably be recovered from the extralinguistic context. It is worth noting that most non-resolvable arguments are arg2 (66.05 %), arg3 (83.27 %) and arg4 (71.54 %), which correspond to the semantic roles of origin, goal, locative, instrument, initial and final state, that is, more optional semantic roles. Among the core arguments, it is worth noting that those arguments closest to the predicate (arg0, arg1) are more frequently realized (explicitly and implicitly) X  72.57 and 73.28 % respectively (adding columns 2 and 4) X  X han the remaining arguments: arg2 (33.95 %), arg3 (16.73 %) and arg4 (28.46 %).

It is also interesting to highlight that arg0 is more frequently realized as an implicit argument (49.49 %) than as an explicit argument (28.18 %), whereas arg1 is more frequently realized as an explicit argument (60.54 %) than as an implicit argument (37.25 %). This is probably due to the pro-drop nature of Spanish. On the other hand, arg1 is the argument position that is closest to the predicate and it is necessary to complete the meaning of the deverbal noun.

In Table 6 we present the distribution of implicit arguments per argument position for English (from G&amp;C dataset) and Spanish (from AnCora). In Table 6 we can see that iarg0 and iarg1 are the implicit arguments that appear most frequently in both languages. However, iarg1 is more implicitly realized in Spanish than in English, while the opposite holds true for iarg0 in English.

Table 7 shows the number of deverbal noun instances distributed according to their number (0 X 5) of explicit and implicit arguments. For instance, there are 2296 instances without any explicit or implicit argument realized, 3127 instances with only one explicit argument, 3251 instances with only one implicit argument, and 4009 instances with one explicit argument and one implicit argument. The last row contains the total percentages of implicit arguments and the last column shows the total percentages of explicit arguments. It is worth noting that in 35.03 % of cases all the arguments are explicit and in 49.57 % of cases all the arguments are implicit, a difference of 15 points. In contrast, the percentage of instances with more than two explicit arguments realized is smaller than 7 %, and the percentage with more than two implicit arguments is higher than 23 %.

This can be explained by the proper function of nominalizations which focus more on the event expressed than on the participants in the event, which have usually been presented previously in the discourse. This can also be explained by the fact that NPs are constituents that do not tend to be as long as VPs, therefore, the number of explicit arguments in NPs is generally lower than in VPs, as has been mentioned before regarding Table 4 .

Table 8 presents the frequencies of explicit and implicit arguments per argument position and thematic role. As shown in Table 8 , arg0 is the most frequently realized implicit argument and corresponds to the agent role in 91.24 % of cases (7511 instances), followed at some distance by the cause role (800 instances, 8.70 %). However, arg1 is realized slightly more frequently as an explicit argument than as an implicit argument (6428 arg1 vs. 6189 iarg1 instances respectively). In both cases, this argument corresponds mainly to the patient role (4102 instances 63.81 % of arg1 and 3856 instances 62.30 % of iarg1), followed by the theme role (2274 instances 35.37 % of arg1 and 2301 instances 37.16 % of iarg1). It is worth mentioning that arg2 is the third most frequently realized implicit argument, especially in a beneficiary role (800 instances, approximately 42 % of cases). 2. Most implicit arguments are located near their referenced discourse entity. As
Table 9 contains the percentages of implicit arguments (column 1) realized in the same sentence (= 0, column 2), in the previous sentence (= -1, column 3), in previous sentences, i.e. in 2 or more previous sentences (&lt; -1, column 4), in the subsequent sentence (= ? 1, column 5), and in more than 2 subsequent sentences (&gt; ? 1, column 6). The last column includes the total number of instances per argument position. The last row of the table shows the total percentage for referenced entity location per argument position. 3. Most of the implicit arguments can be recovered from coreference chains. We 4. Finally, deverbal noun arguments are more optional than verbal arguments, in A subset of Iarg-AnCora has already been used as a training and test corpus for creating LIARc (Peris et al. 2013 ), a supervised ML feature-based model for detecting the core implicit arguments of deverbal nominalizations based on linguistically informed features. It was the first system to deal with this type of arguments in Spanish. LIARc basically replicated the experiments carried out for English by Gerber and Chai ( 2010 , 2012 ) and proposed a number of variations and improvements on the features used. We selected the G&amp;C model because it was easier to scale up and did not suffer from the data-sparseness problem found in the SemEval training corpus. The eight most frequent unambiguous deverbal nominal-ization lemmas in Iarg-AnCora were selected for the building of LIARc.
 Unambiguous lemmas were those deverbal nouns that only have one sense and one associated syntactic-semantic frame. We selected eight predicates and not ten like in G&amp;C model because there is a severe drop in frequency from the ninth predicate in Iarg-AnCora. This set of eight nominalizations corresponds to a total of 469 instances shown in the first two columns of Table 12 . The remaining four columns present the total number and average number of implicit arguments for each predicate and the same information for explicit arguments.

The main problem for implicit arguments detection approaches is the lack of appropriate learning corpora and the sparseness of the existing ones (such as SemEval). G&amp;C tackle this problem by focusing on a reduced set of the 10 most frequent monosemous deverbal nominalizations in English for which a quite dense dataset has been built (see Table 1 ). G&amp;C X  X  method is based on using supervised MLs for training their own corpus. Some of the features included are widely used in most of the systems, including the distance between the predicate and the candidate implicit argument, the local context of both, statistical coocurrence measures (such as PMI), and properties of the verb from which the nominalization derives, among others. Besides these features, G&amp;C uses highly lexicalized ones, such as the word forms and lemmas of the nominalization and the argument, and their local context, as well as generalizations using WordNet.
 The number of explicit and implicit core arguments is shown for each predicate. These figures are much higher than those reported by G&amp;C for English. Although the figures are not directly comparable, the difference is due to both the lower number of explicit arguments for Spanish nominalizations (0.5 on average) 34 compared to English (1.1 in G&amp;C) and to the higher number of implicit arguments (1.3 vs. 0.8). The average number of implicit arguments per predicate instance is 1.3 with a standard deviation of 0.41 (0.8 in G&amp;C). 35
In AnCora-Es, for each document d , the implicit arguments of a nominalization instance are annotated at entity level, i.e. given a predicate instance p , and an implicit argument tag iargn =  X  X  X  X  X  , the iargn =  X  X  X  X  X  filler, if existing, is annotated with the identifier of an entity e [ E , E being the set of entities occurring in d . Entities in E can be regular ones, occurring in coreference chains, or those appearing just once (singletons). We have observed that 75 % of core implicit arguments are retrieved from regular entities while the remaining 25 % correspond to singletons.

For a regular entity e , the set of mentions (the coreference chain) is noted as e is an explicit argument of a predicate. When e is a regular entity, mentions in e X  tend to be NPs, while in the case of singletons other possibilities exist (prepositional, adjectival, adverbial phrases, possessives or subordinate clauses).

Our learning setting tries to tackle two challenges that are difficult to make compatible: (1) to follow G&amp;C X  X  proposal as closely as possible given the highly accurate performance of its features and the possibility of comparing their results with ours; and (2) to learn LIARc for the semi-automatic annotation of the whole AnCora-Es, i.e., to scale up to the whole corpus. These challenges are difficult to make compatible because most of the best features used by G&amp;C are highly lexicalized.

Hence, the features for the LIARc classification model were inferred from this training corpus. We experimented with four models depending on whether the features were lexicalized or not, and whether the features were specific or generalized: (1) lexicalized-specific; (2) lexicalized-generalized; (3) non-lexical-ized-specific, and (4) non-lexicalized-generalized, of which only the last one was used for building the LIARc classifier. Lexicalized features contained, for instance, the specific predicate involved and the words, lemmas, synsets and predicates surrounding the antecedent to be linked; whereas in the non-lexicalized models a null string replaced the lexicalized features. Specific features contain, for instance, WN synsets corresponding to the nominalization itself or its verbal origin. Using the kind of features presented by G&amp;C involves, in practice, learning a classifier for each lemma. This schema is, obviously, impossible to scale up. Generalization was performed through synsets occurring in the features by the Top Concept Ontology (TCO) labels 36 (A  X  lvez et al. 2008 ) attached to them, 37 in the case of nouns, and, in the case of verbs, their lemmas were replaced by the semantic classes of AnCora-Verb.

Details on the learning process can be found in Peris et al. ( 2013 ). For learning, we used a supervised machine learning approach. Due to the highly lexicalized nature of most of the features, and their precision oriented type, we chose Adaboost as a classifier model. Due to the highly unbalanced distribution of positive and negative examples, we weighted the positive ones by a factor of 69, leading to a more balanced distribution. As in G&amp;C, we used feature templates for generating the features.
For instance, the most accurate features were derived from the feature possible values of the predicate p (8 values), for all the possible values of the iarg n tags (up to 36 argument positions ? thematic roles), for all the possible values of the arg i (up to 6 argument positions) and for all the possible values of pe i . Obviously not all the combinations occur in the learning corpus. Other features include the distance between the predicate and the implicit argument (both in sentences and tokens), the verbal entry from which the predicate is derived, and several kinds of generalizations. See Peris et al. ( 2013 ) for details on the features and their accuracies.

Many of the features and feature templates we used for learning the LIARc were replicated from G&amp;C. As these authors rank their features by accuracy, we took their most accurate features. In some cases, our features basically reproduce theirs, while, in others, our features are often simply inspired by theirs. We have selected the most accurate templates as the core of our system. From the 10 most relevant ones, we reproduced verbatim 5, including the 3 most accurate, while the other 4 are heavily based on the corresponding ones, with changes due to the specific differences between English and Spanish and the available resources (see Peris et al. 2013 for details).

The overall F-Measure for all the models was, on average, 89.9 %, showing that there were no significant differences between lexicalized and non-lexicalized models. This could be explained by the fact that, unlike in G&amp;C, none of the lexicalized features occurred among the top ranked ones. The results obtained were better than those reported by G&amp;C for English. In addition to the previously mentioned differences between English and Spanish, discussed in Sect. 5 , this could be explained by the fact that the explicit arguments in G&amp;C were automatically obtained, while they were manually annotated in Iarg-AnCora.

In its initial setting, learning was performed using cross-validation and the whole available material was therefore used for both learning and testing and the results reported in Peris et al. ( 2013 ) are based on this evaluation. Later, after the whole Iarg-AnCora corpus had been built, an additional test, using the set of iargs corresponding to lemmas not included in the set of 8 monosemous ones used for learning was performed. The results obtained outperformed the initial ones.
Once the building of Iarg-AnCora was finished, we used the corpus for training a new version of LIARc. But this time, we applied the non-lexicalized-generalized model using for the whole corpus for learning, that is, the whole set of nominalizations (1454 different lemmas corresponding to 18,397 instances), and not only the 8 unambiguous lemmas used previously. The results were better than those obtained in the previous experiment with an F-Measure of 92.91 %. Hence, this last model increased the F-Measure performance 3.1 points over the previous one confirming, on the one hand, that the process of delexicalization seems to have a very limited effect on the figures obtained, and, on the other, that the large increase in training data improves the results obtained by the systems. In this paper, we have described the annotation of the Spanish Iarg-AnCora corpus with the implicit arguments of deverbal nouns, focusing on the methodology used and the annotation scheme adopted. In Iarg-AnCora, the core implicit arguments are linked to their corresponding discourse entities (i.e. to all mentions in a coreference chain or to a singleton), where there exists an identity relation between the antecedent (i.e. a discourse entity) and the implicit argument. The annotation scheme combines those schemes used in the annotation of verbal argument structure and coreference in the AnCora corpus, which follow in turn the PropBank argument structure scheme and the general criteria of the MATE coreference scheme. The results of the inter-annotator agreement test conducted are also presented. The agreement obtained (81 % observed agreement) ensures the reliability of the annotation, and the analysis of disagreements enabled us to detect and resolve the errors. Most of the disagreements were related to missed links between the argument and the discourse entity, and to different interpretations of the antecedent selected for linking the argument. We also presented the specialized interface designed for annotating the implicit arguments integrated in AnCoraPipe. This tool allows us to tag different layers of linguistic information and the XML output files containing all the linguistic X  X orphological, syntactic, semantic and discourse X  information.

Our main motivation for building Iarg-AnCora was to provide a corpus annotated with implicit arguments with a wide coverage in order to avoid the problem of data sparseness found in the available English corpora. Our main goal was to have a reference resource to study the implicit arguments of Spanish deverbal nouns empirically. Iarg-AnCora contains 18,397 nominal tagged instances, corresponding to 1454 different deverbal nouns, with an average of 0.64 implicit arguments per predicate. Since we annotated an already existing corpus, the data have different ratios of instances per word token, ranking from 225 to 1 instance per lemma (where 30 % of lemmas have more than 10 occurrences, 48.3 % more than 5, and 25 % have only 1 occurrence per lemma). Therefore, each lemma does not have a comparable density of annotation. The annotation of these arguments results in an important gain in role coverage (128 % on average in the annotation of explicit arguments). Therefore, if we do not take into account the implicit arguments, relevant semantic information is missed, and this missing information is crucial for a better understanding of sentences and, consequently, for a better understanding of texts. The analysis of the annotated corpus confirms our initial hypotheses: (a) implicit arguments are more frequent than explicit arguments in deverbal nominalizations, with the most common being the arguments closest to the predicate (i.e. arg0 and arg1); (b) most implicit arguments are located near their referenced discourse entity; they usually appear within the sentence containing the nominal predicate; (c) most implicit arguments can be recovered from coreference chains and, (d) verbal arguments are more often explicitly realized than deverbal noun arguments, almost 50 % of which do not express an argument explicitly.
All this tagged information can also be very useful for training, developing and testing SRL and CR systems, which can use different learning features. For instance, we used Iarg-AnCora to train the LIARc classifier, which is based on linguistic features obtained from the corpus, and the results obtained indicate that the performance of the classifier improves when the training data is increased and the sparseness of the data is reduced. Our next aim is to develop a SRL system dealing with both nominal and verbal predicates, which will take into account the discourse context. This SRL system could be learned from Iarg-AnCora. Another line of work would be to assess the possibility of applying LIARc to AnCora-Cat, the Catalan version of AnCora-Es as an initial step for building automatically Iarg-AnCora-Cat. It would also be interesting to enrich Iarg-AnCora with the annotation of the implicit arguments of verbs, and also to tag the non-resolvable arguments. References
