 Latent Factor models, which transform both users and items into the same latent feature space, are one of the most successful and ubiquitous models in recommender systems. Most existing models in this paradigm define both users X  and items X  latent factors to be of the same size and use an inner product to represent a user X  X   X  X om-patibility X  with an item. Intuitively, users X  factors encode  X  X ref-erences X  while item factors encode  X  X roperties X , so that the inner product encodes how well an item matches a user X  X  preferences. However, a user X  X  opinion of an item may be more complex, for example each dimension of each user X  X  opinion may depend on a combination of multiple item factors simultaneously. Thus it may be better to view each dimension of a user X  X  preference as a per-sonalized projection of an item X  X  properties so that the preference model can capture complex relationships between items X  properties and users X  preferences.

Therefore, in this paper we propose a novel personalized feature projection method to model users X  preferences over items. Specif-ically, for each user, we define a personalized projection matrix, which takes the place of user-specific factors from existing mod-els. This matrix describes a mapping between items X  factors and users X  preferences in order to build personalized preference models for each user and item. The proposed personalized feature projec-tion method is quite general and existing latent factor models, for example, can be cast as a special case. We present three objec-tive functions to optimize predictions in the form of ranked lists of users X  preferences over items, and demonstrate how each can be used to improve one-class recommendation performance. Exper-iments are conducted on four real-world datasets and our results show that our personalized feature projection method outperforms several state-of-the-art methods on various evaluation metrics. H.4 [ Information Systems Applications ]: Miscellaneous c  X  Algorithms, Experimentation, Performance Collaborative filtering; Personalized feature projection; One-class recommendation
Modeling people X  X  opinions and identifying which items are rel-evant to each person plays a critical role in the online market-place, and is the basic task of a recommender system . A major and ongoing thrust of research on recommender systems is con-cerned with improving the performance of personalized recommen-dation. For example, a significant amount of research has been proposed that aims to improve the performance of Latent Factor (LF) models [10, 27, 28, 29], one of the most successful and ubiq-uitous approaches in recommender systems. Latent factor models assume that each user and each item is associated with some K -dimensional latent factor vector, such that the inner product of a user X  X  and an item X  X  latent factors represents the preference score or compatability between the user and the item.

Given a user-item matrix consisting of the rating scores that users give to items, latent factor models essentially consist of identifying the low-dimensional structure in this matrix. The goal is to identify K -dimensional embeddings of users and items such that their prod-uct best recovers this rating matrix in terms of the mean-squared er-ror (MSE). Besides fitting rating values, some works [8, 32, 37, 39] also adapt latent factor models to optimize a ranking loss with the intuition that higher scoring user-item pairs should have larger in-ner products than lower-scoring items for the given user, e.g., for a user u , their inner product with a 5-star item should be higher than that of a 2-star item, though only the relative rather than the exact ratings are modeled.

Another popular research direction using latent factor models is so-called one-class recommendation, which is the focus of this pa-per. In many real applications, explicit numerical ratings might not be available and one must instead try to model some form of im-plicit feedback from users, such as the media they consume, the pages they browse, the music they listen to, or whom they befriend [6, 42]. This setting is called  X  X ne-class X  recommendation and a variety of solutions have been proposed to solve it by directly mod-eling relative preferences, or rankings , of items for personalized recommendation [13, 19, 26, 43]. However, most existing works are still using an inner product of the latent factor vectors to predict users X  preferences on items, which essentially assumes that each dimension of a user X  X  preferences is associated with one and only one of an item X  X  factors.

In this paper, we generalize this linear structure and assign a pro-jection matrix to each user instead of a latent factor vector. Intu-itively, traditional latent factor models can be interpreted as assum-ing that a user X  X  latent factors represent how the user thinks about the latent features of an item and more restrictively, that each di-mension of their opinion is related to a single latent factor of a product. However, a more expressive model would allow each dimension of a user X  X  opinion to be a function of a combination of an item X  X  latent factors. Therefore, it is better to learn a pro-jection between user preferences and item properties so that the model is capable of expressing complex relationships between the two. Moreover since in latent factor models, the inner product of a user X  X  and an item X  X  latent feature vectors is always used to rep-resent the user X  X  preference toward the item, a user X  X  preference on an item is modeled only by a real number, a one-dimensional value, and thus only numerical preference modeling can be used to design objective functions. As we argued above, each dimension of a user X  X  preference is related to a combination of their tastes to-ward an item X  X  properties, so a simple inner product may not be enough. To address the drawbacks mentioned above, we propose a personalized feature projection (PFP) method that learns users X  la-tent features as a personalized projection matrix instead of a vector. Figure 1 depicts the idea of our PFP method. Based on items X  la-tent feature vectors and users X  projection matrices, our PFP method models users X  preferences over items in terms of projected latent feature vectors instead of a real number. Thus, we can leverage metric learning methods to design the objective function for one-class recommendation. In addition, vector-based (rather than nu-merical) objectives, can be formulated, which provides more flexi-ble structures to describe users X  preferences.

The most similar work to our PFP method is the method called max interest latent factors [39], which also proposes to model mul-tiple user latent vectors to enrich users X  preference representations. In [39], the predicted preference between a user and an item is given by the maximum match between the user vectors and the item vector, and omits other tastes of the user. Different from their work, when modeling user X  X  preference on items, the proposed PFP method tries to consider all tastes of the user simultaneously by em-ploying a matrix projection approach.

We summarize our contributions as follows: 1. We develop Personalized Feature Projection methods, that 2. We evaluate the proposed method on four real-world datasets. 3. We conduct a detailed analysis of the effect that various model The remainder of this paper is organized as follows. Section 2 de-scribes preliminary and related work; Section 3 details the proposed PFP methods and introduces three criteria used to optimize them; Section 4 shows experimental results and verifies the improvements of PFP methods for one-class recommendation problems; Finally, Section 5 concludes the paper.
 Figure 1: Illustration of the key idea behind the PFP method. Unlike traditional latent factor models, we use a more flexible transform that associates each item X  X  latent factor with a com-bination of users X  latent factors. The above figure is based on a model trained on our LibraryThing dataset. Here we set the number of item latent factors to 5 and fit user projection matri-ces of size 5  X  10 . In this case, the preferences of different users toward the item can be represented by a set of 10 -dimensional personalized projection vectors.
We consider the one-class recommendation problem , where the model is trained on implicit feedback (e.g., a set of items a user pur-chased), rather than explicit rating scores. Before presenting our Personalized Feature Projection method, we first give an overview of existing latent factor models and describe how they can be ap-plied to solve one-class recommendation problems.
Latent Factor models can be described in terms of matrix factor-ization. Matrix factorization aims to decompose a matrix into two (or more) low-rank terms whose product reconstructs or approxi-mates the original matrix as closely as possible. Typically, we are given a matrix R  X  R M  X  N representing the observed feedback (say, in the form of numeric ratings) from M users and N items.
This feedback matrix can then be factorized into one user-specific matrix U  X  R M  X  K and one item-specific matrix V  X  R N  X  K where K is the dimensionality of the latent factor vector which characterizes the features of a user or an item. Accordingly, U captures user u  X  X  preference toward item i .

For  X  X ne-class X  recommendation problems, there is no numeric feedback matrix R , but rather for each user we observe two signals in the form of positive feedback and negative feedback : Positive feedback: positive feedback D u = { i } is defined as the set of items i toward which user u explicitly shows positive feedback (e.g., products they purchased, pages they viewed, etc.). Negative feedback: negative feedback is denoted by a set of user-item pairs N u = { j } , which includes those items j toward which user u has not shown positive feedback.

Then, in lieu of an explicit rating score, we follow the assump-tion of [24] that users X  preferences toward positive feedback items should be higher than those of negative feedback items, which is captured by the following objective function: where  X  (  X  ) is the logistic (sigmoid) function, i  X  D u Here u u  X  v i and u u  X  v j represent user u  X  X  preferences towards items i and j modeled by a latent factor model. Eq. (2) can be optimized by using stochastic gradient ascent, which iteratively updates the sampled user-specific latent factors U u and the sampled positive (and negative) feedback-specific latent factors V i and V
Several works have studied one-class collaborative filtering and can be mainly divided into two branches: pointwise methods [7, 19, 21] and pairwise methods [22, 24, 25, 26, 36, 40, 43].
Pointwise methods aim to fit a numeric value associated with each evaluated item. These methods model positive feedback as high preference scores and use several strategies to sample nega-tive feedback as low preference scores. Then existing matrix fac-torization methods can be used to fit the preference scores. Pan et al. [19] solve the one-class recommendation problem in two ways: negative example weighting and negative example sampling . Hu et al. [7] introduced a novel concept called a  X  X onfidence level, X  asso-ciated with positive and negative feedback, and propose an efficient optimization method for confidence-based matrix factorization.
Different from pointwise methods, pairwise methods focus on modeling the order, or ranking of the feedback. Pairwise methods always consider implicit feedback as relative relationships indicat-ing that users show higher preference on positive feedback than on negative feedback items. In [24], Rendle et al. propose a Bayesian personalized ranking ( BPR ) framework. Following this, various ideas have been proposed that incorporate different types of con-textual information into the BPR framework. [13] extends the BPR framework to model both users X  feedback on items and on their social relations. In [26], Rendle et al. extend the BPR framework from matrix factorization to tensor factorization for tag recommen-dation. Pan et al. [20] aggregate the features of a group of related users to reduce the uncertainty of the selected training instances. Du et al. [3] improve one-class recommendation performance by incorporating a social regularization term into the BPR framework. Zhao et al. [45] leverage social connections to improve the per-formance of one-class recommendation. In [8], Kabbur et al. use an item-based method for generating top-N recommendations that learns the item-item similarity matrix as the product of two low dimensional latent factor matrices. All of these existing pairwise methods for one-class recommendation use a numerical value to model user preferences, while our model generalizes this setting and describes each user X  X  preferences toward items as a personal-ized projection vector.
Since the method proposed in the following section also relates to metric learning problems with pairwise constraints [2, 11, 12, 23, 31, 35, 41], here we briefly review existing works in this field. Metric learning, whose goal is to model the similarity/dissimilarity between instances, is one of the most fundamental problems of ma-chine learning and has been widely used for clustering and classifi-cation. [33] learns a Mahalanobis metric to study the semantic sim-ilarity between music songs. In [23], the authors propose a met-ric learning algorithm to improve the prediction performance for multi-task learning by learning one metric that is shared amongst all the tasks and one specific metric unique to each task. Kusner et al. [15] uses distance metric learning to improve the efficiency and accuracy of k -nearest neighbor (kNN) classification. Yue et al. [44] proposes a personalized collaborative clustering algorithm that leverages the idea of metric learning to investigate how existing users cluster or group items in order to predict similarity models for other users X  clustering tasks. Lee et al. [17] assumes the observed user-item feedback matrix is locally low-rank within certain neigh-borhoods of the metric space defined by some anchor (user, item) pairs and employs the Epanechnikov kernel function to measure the local metric. However, most of the existing work on metric learn-ing problems focus on solving clustering-related problems and few works consider the issue of personalized one-class recommenda-tion.
Another line of latent factor models are called non-linear latent factor models [16, 30, 39], which break the mold of scoring each item by a linear embedding of users X  and items X  latent factor vec-tors. The authors of [16] proposed a nonlinear LF approach with Gaussian processes. The authors of [30] proposed a Restricted Boltzmann machine-based method for collaborative filtering. Bal-trunas et al. [1] splits user profiles into several sub-profiles and models each sub-profile in a particular context. In [39], the authors propose a MaxMF method that models a user with multiple latent factor vectors representing their different latent tastes and associate each item with a single latent feature vector. The preference score between a user and a given item is then defined as the maximum match between the user tastes and the given item. This work is the most similar one compared to our method. However, there are explicit differences between their method and ours: our proposed PFP method utilizes all latent factor vectors of the user and models the user X  X  preference on the item as a projected vector rather than the maximum inner product in [39].
We first introduce our Personalized Feature Projection (PFP) method. The proposed method inherits the benefits of both met-ric learning and latent factor models. Then, in Section 3.2 we show how this method can be trained to optimize three different evalua-tion criteria. Our notation is shown in Table 1.
In the PFP method, for each item j , we use a vector v j to repre-sent its latent features, much as is done using existing latent factor models. However, for each user u , we employ a matrix P u resent their latent features. Specifically, let K be the number of latent factors (for each item) and let K  X  be the number of projected user factors. Then we have the following definition: Personalized Projection Matrix : for each user u , we define a personalized projection matrix P u = R K  X  K  X  . The column vector p f = R K represents column f in matrix P u .

Based on the Personalized Projection Matrix, we can use the fol-lowing formula to personalize items X  latent feature vectors and ob-tain the projected item-feature vector.
 Personalized Feature Projection : for a specific user u , item j  X  X  feature vector v j can be projected by multiplying u  X  X  personalized projection matrix. In this way, the projected feature vector of item j , e v u j ( e v j for simplicity), can be represented as One can easily check that, when K  X  = 1 , the personalized projec-tion matrix for each user reduces to a latent feature vector of size K , which is equivalent to the user latent feature vector in a latent factor model so that the projected item-feature vector reduces to the dot product of users X  and items X  latent factors. In this way, we can say that the latent factor model is a special case of the person-alized feature projection method. When K  X  &gt; 1 , the projected item-feature vector provides a more flexible way to model users X  complex preferences.
 Preference Modeling : Based on the personalized projection ma-trix, we propose a factorized model to describe users X  preferences by summarizing all the projected feature vectors from their positive feedback. In particular, for an item j , we consider the preference model as where D u represents user u  X  X  positive feedback. Actually, if we normalize both e v i and e v j to be unit vectors, the above equation rep-resents the average cosine similarity of the projected feature vectors between item j and the user X  X  positive feedback items. Compared with [8] and [10], instead of using only item latent vectors, this for-mula incorporates user X  X  personalized projection matrix into prefer-ence modeling, thus, for different users, Eq. (4) can model his/her personalized preference on items. Based on Eq. (4), we propose an assumption to derive the optimization criterion for personalized ranking that is based on pairs of items: for an item i that has been viewed by user u , the preference score of it calculated by Eq. (4) should be larger than other unviewed items j , f u ( i ) f tually, the proposed assumption indicates that the projected fea-ture vectors of users X  positive feedback items should be closer to users X  average taste than are the negative feedback items. Similar assumptions are commonly used in various pairwise-based recom-mendation methods ([24], [26], [20], [13]). However, unlike ex-isting works, the personalized feature projection method models users X  preferences toward items as a projected vector rather than as an inner product, which provides flexible structure for prefer-ence representation. Another advantage of our approach is that it summarizes all the projected vectors from users X  positive feed-back items to reduce the uncertainty caused by training instance selection. More specifically, when we uniformly sample a positive feedback item from a user, the average similarity of Eq. (4) makes the approach insensitive to the choice of which positive feedback items should be selected. P u ( P u ) T here can be viewed as the per-sonalized metric used to measure the preference difference between items.
According to the pairwise assumption proposed above, we will introduce how the PFP model can be trained to optimize three dif-ferent evaluation criteria to solve the one-class recommendation problem.
In this section, we choose the area under the ROC curve (AUC) as the ranking statistic and explain how to extend the Bayesian Per-sonalized Ranking [24] framework to incorporate our personalized feature projection matrix for recommendation.
 The AUC per user is usually defined as where I (  X  ) is an indicator function. Following [24], maximizing the AUC value can be approximated by maximizing the following likelihood function: ln
Y
Due to the totality and antisymmetry of a pair-wise ordering scheme as in [24], the objective function for a particular user u can be simplified to By incorporating Eq. (4), the above objective can be rewritten as: AUC ( u ) = 1 | D where  X  is the logistic (sigmoid) function:  X  ( x ) = 1 1+ e the gradient-based algorithm to optimize the objective function as Eq. (8). The main process is to randomly pick a (positive, nega-tive) feedback pair and iteratively update parameters based on the sampled feedback pairs.
In this subsection, we describe how to adapt our projected feature representation to design a WARP-Loss (Weighted Approximated Ranking Pairwise Loss) function.

Based on Eq. (4), we can calculate users X  preferences for each item j  X  N and the Weighted Approximate-Rank Pairwise (WARP) Loss function [38, 39, 40] can be defined as where rank i ( f u ) is the margin-based rank of item i , i.e., where I ( . ) is the indicator function.  X ( . ) is a loss function, which transforms the predicted rank of an item into a loss value, Different settings of  X  t allow the loss function to optimize differ-ent objectives. Minimizing  X  with  X  t = 1 N would optimize the mean rank and minimizing  X  with  X  t &gt;  X  t +1 would assign higher importance to the top-ranked items.

In this paper, we use a hinge loss to replace the indicator func-tion so that a margin can be added and stochastic gradient descent (SGD) can be adopted to learn the parameters. Thus, the loss func-tion for a specific item i  X  D u in Eq. (9) can be approximated by Eq. (12) as
 X ( rank i ( f u )) = X where | q | + represents the positive part of q .

To minimize Eq. (12), we first uniformly sample a positive train-ing instance i  X  D u . Then we need to calculate the margin rank of the item i among all items. However, exactly computing the rank of the item i is highly time-consuming when the number of items is very large. Therefore, following [38], at each iteration, we uniformly sample a negative feedback instance j /  X  D u until a pair-wise violation is found, that is, until 1  X  f u ( i ) + f steps are required to find such a pairwise violation, then the rank of item i can be approximated as Now the loss from the chosen item pair { f u ( . ) ,i,j } becomes L WARP ( f u ,i,j ) =  X ( b N  X  1 To optimize Eq. (14), we can simply use gradient descent to per-form updates, i.e., where  X  is the learning rate.
Since most existing latent factor models use the inner product of users X  and items X  latent factors to represent a user X  X  preference or compatibility toward an item, only numerical loss functions can be used to optimize the ranking objective. However, only a one-dimensional number cannot precisely describe user X  X  complex pref-erence on the item, and moreover, numerical loss functions seem to be too arbitrary when comparing users X  preferences on different items. Therefore, we propose to model users X  preferences on items via a projected vector and propose a method that measures users X  preference differences on items in vector space. Here, we describe how to model users X  preferences by directly using the projected vectors. Recalling our AUC and WARP -Loss objective functions, we find that the basic idea behind them is to let the projected fea-ture vectors of positive instances be  X  X ore similar X  to users X  average preferences than are negative instances. Therefore, we can follow this intuition and directly model it via vector similarity. Actually, there are various proposed similarity measures that are applicable to compare two vectors to solve classification, clustering and re-trieval problems. For example, S X rensen distance [34] uses the L norm to measure similarity, Wave Hedges [5] uses an intersection-based measure to model similarity, and the KL-divergence [14] measures the similarity based on Shannon X  X  concept of probabilis-tic uncertainty. In this work, we build our objective function based on the KL-divergence , which is a popular similarity measure in ma-chine learning and data mining. The KL-divergence between two vectors can be represented as where T and W are vectors with size K  X  and W ( q ) represents the q entry in vector W .

Based on Eq. (16), for a particular user u , our goal is to maxi-mize the KL-divergence between the projected vectors from users X  positive and negative instances. More specifically, when given a positive instance i  X  D u and a negative instance j  X  N u jective function can be defined in terms of maximizing To maximize Eq. (17), we uniformly sample a positive instance i  X  D u and a negative instance j  X  N u . Then we can simply per-form updates via gradient ascent. This process is repeated until the model converges. Specifically, the detailed gradients of the corre-sponding latent variables in the matrix factorization are as follows: where P u kf and p u f are as defined above. To avoid overfitting, we also constrain the parameters using the following inequalities and project the parameters back on the constraints when they violate the constraints at each step: where C u and C i are called projection constraint terms.
We note that although KL-divergence is asymmetric, due to the experimental results, this asymmetry has little impact on model per-formance. Thus, we just define the objective function as Eq. 17. Our proposed personalized feature projection method is quite gen-eral and can be easily extended to other vector similarity measures to define new objective functions. We do not discuss other simi-larity measures further, since the focus of this paper is to illustrate how to we can model users X  preferences as a personalized projected vector rather than as an inner product. The computational complexity for PFP (KL) method is O ( M  X  N  X  K  X  K  X  ) . Since we apply stochastic gradient descent methods for optimization, the complexity for each iteration is O ( K  X  K One solution to scale this algorithm is to alternatively optimize the parameters based on multi-threading and parallelization: fist op-timize item-latent factor vectors, then train users X  projection ma-trices. In fact, our proposed method has the same complexity as MaxMF [39], therefore, we could use similar MapReduce algo-rithms to train all user parameters in parallel: when a training triple is sampled, the mapper collects and emits each column vector of the user X  X  projection matrix and the item X  X  latent vector, and the reducer calculates the dot product of each column vector and the item X  X  vector independently. The reducer would then emit the re-sults to build up a final projection vector for training.
In this section, we conduct experiments on the real-world datasets to evaluate the effectiveness of the proposed methods.
The data sets [45] used in this paper are collected from four pop-ular web sites: Ciao, BeerAdvocate, Ratebeer and LibraryThing (Lthing). Statistics of the four datasets are summarized in Table 2. Since this paper focuses on solving the one-class recommendation problem, we filter out explicit negative feedback (rating scores be-low 4 out of 5 stars) and use the remaining instances as positive feedback for model learning. All are available online. 1 2
For each dataset, we randomly split it into a training part, used for model training, and a test part, used for model evaluation. For each user u , we randomly select 90% of their observed feedback items as D u and leave the remainder as T u for testing. Grid search is applied to find projection constraint terms and learning rate is set as 0.01.

Our experiments are intended to address the following questions: 1. How does our approach compare with related personalized 2. Can vector-based recommendation models outperform tradi-3. How does the number of projected factors affect the results? http://www.public.asu.edu/jtang20/ datasetcode/truststudy.htm http://cseweb.ucsd.edu/~jmcauley/ We use two popular metrics, NDCG (Normalized Discounted Cu-mulative Gain) and Area Under the Curve (AUC), to measure the recommendation quality of our proposed approach in comparison to baseline methods. The average AUC statistic is defined as where E ( u ) = { ( i,j ) | ( u,i )  X  T u  X  ( u,j ) /  X  ( D
DCG @ X considers the ranking of the recommended items by discounting the importance and is defined as where rel i represents the relevance score of the item i (we use a binary value for this quantity). NDCG is the ratio of the DCG value to the ideal DCG value for that user. The ideal value of DCG comes from the best ranking function for the user. Here we set X = N  X  D u where N is the total number of items.
In order to demonstrate the benefits of our approach, we compare our model with the following methods for item recommendation. Since the problem we solve in this paper is one-class recommenda-tion (without rating scores), it is unsuitable to compare our methods with rating estimation methods. Instead, we consider some state-of-the-art one-class recommendation methods as baselines. Most of the above baseline methods can be found in [4]. of the proposed method compared with the best baseline method. Results in terms of the AUC and NDCG are shown in Table 3. Although we can assign different values to the number of latent factors and the number of projected factors, here we just report the results by setting the same value for both parameters and leave the discussion of different parameter settings to Section 4.3.
On most datasets, we find that PFP methods outperform base-lines. In particular, three observations can be drawn from the re-sults: First, the proposed PFP methods achieve the best perfor-mance in most cases; from Table 2, we observe that users in these two datasets have more positive feedback items compared to other datasets (the average RateBeer user reviews close to ninety beers in their lifetime as a reviewer). These results corroborate that PFP can better describe users X  preferences when we have sufficiently many positive feedback items.

Second, compared to BPR and GBPR, where the AUC is opti-mized via maximizing the difference of two inner products, PFP (KL) succeeds in enhancing the ranking performance by directly optimizing the difference between two projected vectors. As also can be seen from the results, FISM-AUC performs worse than other AUC-based methods (BPR, GBPR, PFP (WARP) and PFP (KL)) in most datasets. The reason might be that the objective function used in FISM-AUC ignores the influence of user bias for personalized ranking though it should be noted that FISM-AUC is designed for datasets with rating information such that it may be not be suitable for scenarios in which we have only binary feedback. The MaxMF method also uses multiple user latent factors to model users X  pref-erences and this method has the same amounts of parameters as our proposed methods. The better performance of our method validates that modeling users X  preferences by a combination of multiple item factors is more accurate than just using a maximal value as MaxMF does.

Third, from Table 3, we find that PFP (KL) always performs better than PFP (WARP). The improvements suggest that vector-based optimization criteria (such as the one used by PFP (KL)) are more plausible to model users X  preferences and that modeling users X  preferences in terms of a single value may be insufficient.
Note that when setting  X  t as a constant in the WARP-Loss func-tion, PFP (WARP) is equivalent to optimizing the AUC loss; more-over, from the results, we find that the proposed method based on the WARP-Loss always achieves similar results with that on the AUC loss, therefore, we omit AUC-based results from Table 3. Projection Factor Analysis. Different from existing latent factor models, PFP models require us to set not only the number of latent factors per item, but also the number of users X  projection factors as hyperparameters. Therefore in this section, we experimentally investigate how different settings of the two parameter values in-fluence the performance of PFP models. To make the results clear, we also show the performance of the most similar baseline method, MaxMF for comparison. The results are shown in Figure 3 and 4.
We find that in most cases, our proposed methods show bet-ter performance than MaxMF. Since MaxMF has the same num-ber of parameters as our proposed methods, these results clearly verify that employing user X  X  all tastes for preference modeling is better than only considering his/her maximum preference score. Moreover, we can also observe that even when PFP methods has a smaller value of K than MaxMF, the former X  X  performance is still better than latter. This fact verifies our assumption that a user X  X  opinion of an item may be complex and taking more parameters for modeling users X  latent factors is more effective to improve the rec-ommendation accuracy. As introduced before, K and K  X  are two important parameters in PFP methods, we also give some detailed analysis about them below.

First, we examine the case where the number of item latent fac-tors matches the number of users X  projection factors. Results are Figure 3: Impact of #latent factors, k (here we set the number of projected factors value, k  X  as same as k). shown in Figure 3. We vary K from 2 to 10 and compare the per-formance of PFP (KL) with PFP (WARP). AUC and NDCG are used as evaluation metrics. We find that in all datasets, PFP (KL) always performs better than PFP (WARP). In particular, compared with NDCG results, PFP (KL) X  X  AUC performance shows stable improvement as the number of latent factors increases. On the Ciao dataset, the NDCG performance of both methods show poor per-formance when K = K  X  = 10 . The reason we for this might be that when the number of positive feedback items per user is limited for training, a model with many parameters may suffer from over-fitting. This conclusion is verified by our results on the Ratebeer dataset. Since Ratebeer contains sufficient positive feedback items for each user in the training set, the models X  performance improves as we increase the number of latent factors in most cases.
We also conduct experiments to show how PFP methods perform when setting different values of K and K  X  . Figure 4 illustrates the behavior of PFP models on different datasets. We find that dif-ferent settings of the two parameters lead to varying results. On the Ciao dataset, fixing K to 10 and varying K  X  from 2 to 10, PFP (KL) always achieves better performance than PFP (WARP). While on the BeerAdvocate dataset, we find that when we fix K to 6 and gradually increase K  X  from 2 to 10, the performance of PFP (KL) improves significantly. This result indicates that when K  X  is small, PFP (KL) cannot make use of such a low-dimensional projection space to describe users X  preferences, and this also vali-dates our motivation to model a user X  X  preference toward an item as a combination of multiple item factors simultaneously. Similar results can be found on most other datasets. We also find an in-teresting result on Lthing: although PFP (KL) X  X  AUC outperforms PFP (WARP) when K  X  is larger than 3, its NDCG performance is always unsatisfactory. One reason may be that when K = 6 , PFP (KL) cannot project items X  latent factors properly and moreover, the optimization criterion used in PFP (KL) does not focus on top-N ranking compared with the WARP-loss used in PFP (WARP). Based on the experimental results, we conclude that when we have sufficiently enough observed feedback for training, we can assign a large projection number for better user taste modeling, while when Table 4: Impact of projection constraints terms on Ciao dataset (AUC metric).
 Table 5: Impact of projection constraints terms on BeerAdvo-cate dataset. (AUC metric). we have limited training data, we may decrease the projection num-ber and use a simple model to avoid overfitting. When K  X  1, the projected preference vector will degenerate to a dot product, as used in existing methods [8, 32, 37, 39].
 Projection Constraint Analysis. In order to avoid overfitting, we constrain the parameters C u and C i using Eq. (19). Here we analyze the impact of constraint terms on model performance. The experimental results are shown in Tables 4 to 7. These results pro-vide many hints about how to find the proper projection constraint terms for better modeling. On all datasets, we fix K = K In particular, we find that when C u = 10 and C i = 50 , PFP (KL) exhibits the best performance on the Ciao dataset. Such results in-dicate that in order to avoid overfitting, we have to constrict the constraint of user X  X  projection matrix, especially when the number of items is not particularly large (less than 20K). On the Lthing dataset, we obtain the best performance when C u is above 50 and C i is 10. Such results suggest that when the number of candidate items is large, it is better to reduce the constraint on users X  projec-tion matrices so that the model can describe the subtleties of users X  preferences. On the BeerAdvocate and Ratebeer datasets, since the average number of positive feedback instances per user is large, the observed information is enough to model users X  preferences toward items, so that the projection constraint terms do not affect the model performance on these two datasets as significantly as on the others. The best performance on both BeerAdvocate and Ratebeer datasets occur when setting C u = 10 and C i = 10 .
 Impact of  X  . We also perform experiments to investigate the impact of the learning rate  X  . The results are shown in Figure 2. models are insensitive to the value of  X  . Therefore, we conclude that selecting proper values for K and K  X  are much more important to obtain good performance than adjusting the learning rate when training. These results also indicate that we could use relatively large learning rates to improve the convergence time of the model.
In this paper, we proposed a Personalized Feature Projection method in order to improve recommendation accuracy on one-class Table 6: Impact of projection constraints terms on Ratebeer dataset (AUC metric).
 Table 7: Impact of projection constraints terms on Lthing dataset (AUC metric). recommendation problems. Our model learns a projection matrix for each user that is able to capture the complexities of their pref-erences towards certain items over others. In contrast to existing methods that assume a one-to-one relationship between users X  pref-erences and item properties, we assume that each dimension of a user X  X  preference is related to a combination of item factors simul-taneously. We formulated three optimization criteria for one-class recommendation, and performed experiments on four real-world datasets, finding that our method effectively improves the recom-mendation accuracy for one-class recommendation problems.
For future work, we are interested in extending PFP method in three ways: (1) Investigating how to incorporate social network information into the PFP model, in order to model the similarity between users X  and their friends X  preferences via the PFP method. Possible alternatives include modeling the similarity between pro-jection matrices, or modeling the similarity between projected vec-tors. (2) Employing contextual information (such as text) in order to understand the meaning behind each projected latent factor; sim-ilar to [9, 18], we might allow text or time to explain the particular meanings of projected factors. (3) Exploring how to set the number of projected latent factors automatically. This research was in part supported by grants from the National Grand Fundamental Research 973 Program of China (No. 2014-CB340405), the Research Grants Council of the Hong Kong Spe-cial Administrative Region, China (Project No. CUHK 413213), and Microsoft Research Asia Regional Seed Fund in Big Data Re-search (Grant No. FY13-RES-SPONSOR-036).

