 Learning to rank has attracted the focus of many machine learning researchers in the last decade systems. In the simplest form, the so-called pointwise approaches, ranking can be treated as classifi-cation or regression by learning the numeric rank value of documents as an absolute quantity [3, 4]. The second group of algorithms, the pairwise approaches, considers the pair of documents as in-pairs [5, 6, 7, 8, 9, 10, 11]. The main problem with these approaches is that their loss functions are related to individual documents while most evaluation metrics of information retrieval measure the ranking quality for individual queries, not documents.
 This mismatch has motivated the so called listwise approaches for information ranking, which treats each ranking list of documents for a query as a training instance [2, 12, 13, 14, 15, 16, 17]. Unlike the pointwise or pairwise approaches, the listwise approaches aim to optimize the evaluation metrics such as NDCG and MAP. The main difficulty in optimizing these evaluation metrics is that they are dependent on the rank position of documents induced by the ranking function, not the numerical values output by the ranking function. In the past studies, this problem was addressed either by the convex surrogate of the IR metrics or by heuristic optimization methods such as genetic algorithm. In this work, we address this challenge by a probabilistic framework that optimizes the expectation of NDCG over all the possible permutation of documents. To handle the computational difficulty, we present a relaxation strategy that approximates the expectation of NDCG in the space of permutation, and a bound optimization algorithm [18] for efficient optimization. Our experiment with several benchmark data sets shows that our method performs better than several state-of-the-art ranking techniques. The rest of this paper is organized as follows. The related work is presented in Section 2. The proposed framework and optimization strategy is presented in Section 3. We report our experimental study in Section 4 and conclude this work in Section 5. We focus on reviewing the listwise approaches that are closely related to the theme of this work. The listwise approaches can be classified into two categories. The first group of approaches directly optimizes the IR evaluation metrics. Most IR evaluation metrics, however, depend on the sorted order of documents, and are non-convex in the target ranking function. To avoid the computational difficulty, these approaches either approximate the metrics with some convex functions or deploy methods (e.g., genetic algorithm [19]) for non-convex optimization. In [13], the authors introduced LambdaRank that addresses the difficulty in optimizing IR metrics by defining a virtual gradient on each document after the sorting. While [13] provided a simple test to determine if there exists an implicit cost function for the virtual gradient, theoretical justification for the relation between the implicit cost function and the IR evaluation metric is incomplete. This may partially explain why LambdaRank performs very poor when compared to MCRank [3], a simple adjustment of classification for ranking (a pointwise approach). The authors of MCRank paper even claimed that a boosting model for regression produces better results than LambdaRank. Volkovs and Zemel [17] proposed optimizing the expectation of IR measures to overcome the sorting problem, similar to the approach taken in this paper. However they use monte carlo sampling to address the intractable task of computing the expectation in the permutation space which could be a bad approximation for the queries with large number of documents. AdaRank [20] uses boosting to optimize NDCG, similar to our optimization strategy. However they deploy heuristics to embed the IR evaluation metrics in computing the weights of queries and the importance of weak rankers; i.e. it uses NDCG value of each query in the current iteration as the weight for that query in constructing the weak ranker (the documents of each query have similar weight). This is unlike our approach that the contribution of each single document to the final NDCG score is considered. Moreover, unlike our method, the convergence of AdaRank is conditional and not guaranteed. Sun et al. [21] reduced the ranking, as measured by NDCG, to pairwise classification and applied alternating optimization strategy to address the sorting problem by fixing the rank position in getting the derivative. SVM-MAP [2] relaxes the MAP metric by incorporating it into the constrains of SVM. Since SVM-MAP is designed to optimize MAP, it only considers the binary relevancy and cannot be applied to the data sets that have more than two levels of relevance judgements.
 The second group of listwise algorithms defines a listwise loss function as an indirect way to op-timize the IR evaluation metrics. RankCosine [12] uses cosine similarity between the ranking list and the ground truth as a query level loss function. ListNet [14] adopts the KL divergence for loss function by defining a probabilistic distribution in the space of permutation for learning to rank. FRank [9] uses a new loss function called fidelity loss on the probability framework introduced in ListNet. ListMLE [15] employs the likelihood loss as the surrogate for the IR evaluation metrics. The main problem with this group of approaches is that the connection between the listwise loss function and the targeted IR evaluation metric is unclear, and therefore optimizing the listwise loss function may not necessarily result in the optimization of the IR metrics. 3.1 Notation takes a document-query pair ( d, q ) and outputs a real number score, and by j k i the rank of document i within the collection D k for query q k . The NDCG value for ranking function F ( d, q ) is then computed as following: where Z k is the normalization factor [1]. NDCG is usually truncated at a particular rank level (e.g. the first 10 retrieved documents) to emphasize the importance of the first retrieved documents. 3.2 A Probabilistic Framework One of the main challenges faced by optimizing the NDCG metric defined in Equation (1) is that the which makes it computationally challenging. To address this problem, we consider the expectation of L ( Q, F ) over all the possible rankings induced by the ranking function F ( d, q ) , i.e.,  X  L ( Q, F ) = where S m by the expectation of  X  k ( i ) .
 Lemma 1. For any distribution Pr(  X  | F, q ) , the inequality  X  L ( Q, F )  X   X  H ( Q, F ) holds where Proof. The proof follows from the fact that (a) 1 /x is a convex function when x &gt; 0 and therefore log(1 +  X  x  X  ) . Combining these two factors together, we have the result stated in the lemma. simplification, we rewrite  X  k ( i ) as where I ( x ) outputs 1 when x is true and zero otherwise. Hence,  X   X  k ( i )  X  is written as distribution for document d k j to be ranked before document d k i . In the next section, we will dis-cuss how to define a probability model for Pr(  X  k | F, q k ) , and derive pairwise ranking probability Pr(  X  k ( i ) &gt;  X  k ( j )) from distribution Pr(  X  k | F, q k ) . 3.3 Objective Function We model Pr(  X  k | F, q k ) as follows where Z ( F, q k ) is the partition function that ensures the sum of probability is one. Equation (6) with the idea of ranking the documents with largest scores first; intuitively, the more documents in a permutation are in the decreasing order of score, the bigger the probability of the permutation is. By maximizing  X  H ( Q, F ) over F , we could find the optimal solution for ranking function F . To approximate Pr(  X  k ( i ) &gt;  X  k ( j )) , we divide the group of permutation S m one-to-one mapping between these two sets; namely for any ranking  X  k  X  G k a ( i, j ) , we could create versa. The following lemma allows us to bound the marginal distribution Pr(  X  k ( i ) &gt;  X  k ( j )) . Lemma 2. If F ( d k i , q k ) &gt; F ( d k j , q k ) , we have Proof. because Pr(  X  k | F, q k ) is the only term dependent on  X  .
 it has been taken for granted and no justification has been provided in using it for learning to rank. Using the logistic model approximation introduced in Lemma 2, we now have  X   X  k ( i )  X  written as To simplify our notation, we define F k i = 2 F ( d k i , q k ) , and rewrite the above expression as Using the above approximation for  X   X  k ( i )  X  , we have  X  H in Equation (3) written as where We define the following proposition to further simplify the objective function: Proposition 1. The proof is due to the Taylor expansion of convex function 1 /log (2 + x ) , x &gt;  X  1 around x = 0 result of this proposition to the objective function in Equation (9), the new objective is to minimize the following quantity: also important to note that although  X  M is no longer a rigorous lower bound for the original objective function  X  L , our empirical study shows that this approximation is very effective in identifying the appropriate ranking function from the training data. 3.4 Algorithm To minimize  X  M ( Q, F ) in Equation (11), we employ the bound optimization strategy [18] that it-denoted by  X  F k i , is updated as to the following form: the above, we assume the ranking function F ( d, q ) is updated iteratively with an addition of binary Proposition 2. where The proof of this proposition can be found in Appendix A. This proposition separates the term related to F k i from that related to  X f k i in Equation (11), and shows how the new weak ranker (i.e., the above proposition, we can derive the upper bound for M (Theorem 1) as well as a closed form solution for  X  given the solution for F (Theorem 2).
 Theorem 1. Given the solution for binary classifier f d i , the optimal  X  that minimizes the objective function in Equation (11) is Theorem 2. where  X  (  X  ) is only a function of  X  with  X  (0) = 0 .
 The proofs of these theorems are provided in Appendix B and Appendix C respectively. Note that the bound provided by Theorem 2 is tight because by setting  X  = 0 , the inequality reduces to equality can be found without knowing the solution for  X  .
 each document which can be positive or negative. A positive weight w k i indicates that the ranking position of d k i induced by the current ranking function F is less than its true rank position, while a negative weight w k i shows that ranking position of d k i induced by the current F is greater than its true rank position. Therefore, the sign of weight w k i provides a clear guidance for how to construct The magnitude of w k i shows how much the corresponding document is misplaced in the ranking. of improving the value of NDCG. This leads to maximizing  X  given in Equation (17) which can be considered as some sort of classification accuracy. We use sampling strategy in order to maximize  X  because most binary classifiers do not support the weighted training set; that is, we first sample the documents according to | w k i | and then construct a binary classifier with the sampled documents. It can be shown that the proposed algorithm reduces the objective function M exponentially (the proof is removed due to the lack of space). Algorithm 1 NDCG Boost: A Boosting Algorithm for Maximizing NDCG 1: Initialize F ( d k i ) = 0 for all documents 2: repeat 3: Compute the weight for each document as 3: Assign each document the following class label y k i = sign ( w k i ) . 4: Train a classifier f ( x ) : R d  X  X  0 , 1 } that maximizes the following quantity 5: Predict f i for all documents in { D k , i = 1 , . . . , n } 6: Compute the combination weight  X  as provided in Equation (15). 7: Update the ranking function as F k i  X  F k i +  X f k i . 8: until reach the maximum number of iterations To study the performance of NDCG Boost we use the latest version (version 3.0) of LETOR package provided by Microsoft Research Asia [22]. LETOR Package includes several benchmark data data, baselines and evaluation tools for research on learning to rank. 4.1 Letor Data Sets There are seven data sets provided in the LETOR package: OHSUMED, Top Distillation 2003 (TD2003), Top Distillation 2004 (TD2004), Homepage Finding 2003 (HP2003), Homepage Finding There are 106 queries in the OSHUMED data sets with a number of documents for each query. The relevancy of each document in OHSUMED data set is scored 0 (irrelevant), 1 (possibly) or 2 (definitely). The total number of query-document relevancy judgments provided in OHSUMED data set is 16140 and there are 45 features for each query-document pair. For TD2003, TD2004, HP2003, HP2004 and NP2003, there are 50 , 75 , 75 , 75 and 150 queries, respectively, with about 1000 retrieved documents for each query. This amounts to a total number of 49171 , 74170 , 74409 , 73834 and 147606 query-document pairs for TD2003, TD2004, HP2003, HP2004 and NP2003 respectively. For these data sets, there are 63 features extracted for each query-document pair and a binary relevancy judgment for each pair is provided.
 For every data sets in LETOR, five partitions are provided to conduct the five-fold cross validation, each includes training, test and validation sets. The results of a number of state-of-the-art learning to rank algorithms are also provided in the LETOR package. Since these baselines include some of the most well-known learning to rank algorithms from each category (pointwise, pairwise and listwise), we use them to study the performance of NDCG Boost. Here is the list of these baselines (the details can be found in the LETOR web page): RankSVM: RankSVM is a pairwise approach using Support Vector Machine [5].
 FRank: FRank is a pairwise approach. It uses similar probability model to RankNet [7] for the AdaRank NDCG: This is a listwise boosting algorithm that incorporates NDCG in computing the SVM MAP: SVM MAP is a support vector machine with MAP measure used in the constraints. It While the validation set is used in finding the best set of parameters in the baselines in LETOR, it is not being used for NDCG Boost in our experiments. For NDCG Boost, we set the maximum number of iteration to 100 and use decision stump as the weak ranker.
 Figure 1 provides the the average results of five folds for different learning to rank algorithms in terms of NDCG @ each of the first 10 truncation level on the LETOR data sets 3 . Notice that the performance of algorithms in comparison varies from one data set to another; however NDCG Boost performs almost always the best. We would like to point out a few statistics; On OHSUMED data set, NDCG Boost performs 0 . 50 at NDCG @3 , a 4% increase in performance, compared to FRANK, the second best algorithm. On TD2003 data set, this value for NDCG Boost is 0 . 375 that shows a 10% increase, compared with RankSVM ( 0 . 34 ), the second best method. On HP2004 data set, NDCG Boost performs 0 . 80 at NDCG @3 , compared to 0 . 75 of SVM MAP, the second best method, which indicates a 6% increase. Moreover, among all the methods in comparison, NDCG Boost appears to be the most stable method across all the data sets. For example, FRank, which performs well in OHSUMED and TD2004 data sets, yields a poor performance on TD2003, HP2003 and HP 2004. Similarly, AdaRank NDCG achieves a decent performance on OHSUMED data set, but fails to deliver accurate ranking results on TD2003, HP2003 and NP2003. In fact, both AdaRank NDCG and FRank perform even worse than the simple Regression approach on TD2003, which further indicates their instability. As another example, ListNet and RankSVM, which perform well on TD2003 are not competitive to NDCG boost on OHSUMED and TD2004 data sets. Listwise approach is a relatively new approach to learning to rank. It aims to use a query-level loss function to optimize a given IR measure. The difficulty in optimizing IR measure lies in the inherited sort function in the measure. We address this challenge by a probabilistic framework that optimizes the expectation of NDCG over all the possible permutations of documents. We present a relaxation strategy to effectively approximate the expectation of NDCG, and a bound optimization strategy for efficient optimization. Our experiments on benchmark data sets shows that our method is superior to the state-of-the-art learning to rank algorithms in terms of performance and stability. The work was supported in part by the Yahoo! Labs 4 and National Institute of Health (1R01GM079688-01). Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of Yahoo! and NIH. 1 + exp(  X  F k i  X   X  F k j ) The first step is a simple manipulations of the terms and the second step is due to the convexity of inverse function on R + .
 In order to obtain the result of the Theorem 1, we first plug Equation (13) in Equation (11). This leads to minimizing takes binary values 0 and 1 , we have the following: First, we provide the following proposition to handle exp(  X  ( f k j  X  f k i )) .
 Proposition 3. If x, y  X  [0 , 1] , we have Proof. Due to the convexity of exp function, we have: Using the result in the above proposition, we can bound the last term in Equation (13) as follows: Using the result in Equation (19) and (13), we have  X  M ( Q,  X  F ) in Equation (11) bounded as [2] Yisong Yue, Thomas Finley, Filip Radlinski, and Thorsten Joachims. A support vector method [3] Ping Li, Christopher Burges, and Qiang Wu. Mcrank: Learning to rank using multiple classi-[4] Ramesh Nallapati. Discriminative models for information retrieval. In SIGIR  X 04: Proceed-[5] Ralf Herbrich, Thore Graepel, and Klaus Obermayer. Support vector learning for ordinal [6] Yoav Freund, Raj Iyer, Robert E. Schapire, and Yoram Singer. An efficient boosting algorithm [7] Chris Burges, Tal Shaked, Erin Renshaw, Ari Lazier, Matt Deeds, Nicole Hamilton, and Greg [8] Yunbo Cao, Jun Xu, Tie-Yan Liu, Hang Li, Yalou Huang, and Hsiao-Wuen Hon. Adapting [9] Ming Feng Tsai, Tie yan Liu, Tao Qin, Hsin hsi Chen, and Wei ying Ma. Frank: A ranking [10] Rong Jin, Hamed Valizadegan, and Hang Li. Ranking refinement and its application to infor-[11] Steven C.H. Hoi and Rong Jin. Semi-supervised ensemble ranking. In Proceedings of Associ-[12] Tao Qin, Tie yan Liu, Ming feng Tsai, Xu dong Zhang, and Hang Li. Learning to search web [13] Christopher J. C. Burges, Robert Ragno, and Quoc V. Le. Learning to rank with nonsmooth [14] Zhe Cao and Tie yan Liu. Learning to rank: From pairwise approach to listwise approach. In [15] Fen Xia, Tie-Yan Liu, Jue Wang, Wensheng Zhang, and Hang Li. Listwise approach to learning [16] Michael Taylor, John Guiver, Stephen Robertson, and Tom Minka. Softrank: optimizing non-[17] Maksims N. Volkovs and Richard S. Zemel. Boltzrank: learning to maximize expected ranking [18] Ruslan Salakhutdinov, Sam Roweis, and Zoubin Ghahramani. On the convergence of bound [19] Jen-Yuan Yeh, Yung-Yi Lin, Hao-Ren Ke, and Wei-Pang Yang. Learning to rank for infor-[21] Zhengya Sun, Tao Qin, Qing Tao, and Jue Wang. Robust sparse rank learning for non-smooth [22] Tie-Yan Liu, Tao Qin, Jun Xu, Wenying Xiong, and Hang Li. Letor: Benchmark dataset for
