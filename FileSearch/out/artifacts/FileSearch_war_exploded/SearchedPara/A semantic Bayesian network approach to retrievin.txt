 1. Introduction
There has recently been increased interest in conversational agents that act as effective and familiar infor-mation providers. Conversational agents are representative intelligent agents that are capable of responding in an intelligent way (with natural language dialogue) to requests from users. They can understand the intention of users through conversation. After understanding, they are able to offer an appropriate service ( Garcia-Ser-dis, Kehagias, &amp; Mitkas, 2003 ).

Many researchers in the speech recognition community view  X  X  X ialogue methods X  X  as a way of controlling and restricting interactions. This reflects the persistent belief that spoken dialogue is the most natural and powerful user interface with computers ( Allen et al., 2001 ). Most conversational agents lack flexibility in diverse situations because they are only able to respond repeatedly to users with the fixed answers that they have stored in the reply database in advance. Pattern matching, a popular method for constructing conversa-tional agents, works well at sentence level, but it is not feasible when trying to understand dialogues in which context must be considered. Moreover, it is likely to fail to understand complex sentences that require deeper analysis. Recently, researchers have investigated flexible dialogue models using Bayesian networks (BN) ( Hong &amp; Cho, 2003; Horvitz, Breese, Heckerman, Hovel, &amp; Rommelse, 1998 ).

When application domains are complex with many variables, it becomes very difficult to infer the inference of users. In this paper, we propose a conversational agent that uses semantic Bayesian networks (SeBN). This agent not only reduces the complexity of construction, but also infers user X  X  intentions in more detail. Since conversation often contains ambiguous expressions, the ability to manage context or uncertainty is very important in the construction of flexible conversational agents. The proposed method uses mixed-initiative interaction to obtain missing information and clarify for spurious concepts in order to understand the inten-tion of users correctly. This not only reduces the complexity of the networks, but also infers the intention of users more proactively ( Allen, 1999 ).

The remainder of this paper is organized as follows. Section 2 discusses related works in terms of intelligent conversational agents and Bayesian network models in information retrieval systems. Section 3 presents the proposed approach, and Section 4 presents the results of our experiments. Finally, conclusions and sugges-tions for future work will be described. 2. Backgrounds 2.1. Intelligent conversational agents
Conversational agents can communicate with users with natural language dialogue. This method allows an understanding of intentions through conversation and helps the user by executing an appropriate action.
Contrary to conventional interfaces like menus and keywords, the use of dialogue makes it possible to interact more naturally and to include information that is more complicated. Therefore, conversational agents can act as
Techniques such as pattern matching, finite-state-machines and frame-based models are used as popular ways of designing conversational agents. For simple tasks, they are good enough because they are based on a static process that predefines all possible types to match. However, performance is limited with conver-sation that is more realistic. Dynamic topic changing and problem solving present difficulties, and sometimes dialogue is needlessly long and sentences are repeated. In addition, the size of the database needs to increase when analyzing complicated queries, and information might be duplicated unnecessarily. The plan-based model is different from these approaches because it is able to consider the plans and deciding actions of the user. Every time partial information is gathered from each query, and the agent is able to predict intentions gradually ( Perugini &amp; Ramakrishnan, 2003 ).

Using these techniques, conversational agents have been implemented as guiders for web pages and pro-grams, buying commodities, touring groups and so forth ( Zue &amp; Class, 2000 ). Commercial products include
Nicole of NativeMinds, SmartBot of Artificial Life, Verbot of Virtual Personalities, and so on. 2.2. Bayesian networks for information retrieval
Bayesian networks provide graphical representations that explicitly represent the independency among the
It is a DAG (directed acyclic graph) model that evaluates the belief of hidden variables with evidences using the dependency between them based on the Bayes X  rule. Nodes in the networks represent random variables, and the edges denote the dependency of them (parent nodes for causes and child nodes for results). The edge conditional probability P ( c j p ). Using the conditional independency, the joint probability distribution P ( x 1 , x 2 , ... , x n ) can be factored as follows:
Bayesian networks were first used in information retrieval (IR) by Turtle and Croft, where they showed that the proposed IR model worked better than several traditional probabilistic models for ranking documents ( Tutle &amp; Croft, 1990 ). The model proposed by Ribeiro-Neto and Muntz (1996) not only provides probabilistic justification, but also uses evidence from past queries. More recently, Acid, de Campos, Ferna  X  ndez-Luna, and
Huete (2003) presented a model in which network topology can be defined by an exact propagation algorithm, in order to efficiently compute the relevance probabilities of documents. Bayesian networks have been also applied to other problems such as automatic hypertext construction, information filtering, and document clus-tering and classification.

According to the fundamental model of Bayesian networks in information retrieval systems, queries, doc-network ( Fig. 1 ), node D j denotes a document, node Q represents the user query, and node K used in the domain. The vector ~ k refers to any possible state of the root node K document D j and query Q is interpreted as the probability of document D law and the rule of probabilities, probability P ( D j j Q ) can be computed as: 3. Intelligent conversational agents
In previous studies, question X  X nswering systems responded to queries from users by matching their pattern from a predefined knowledge base. For simple types of queries, the systems were able to offer correct answers, but people usually use difficult queries to understand the actual meaning like omitting important words based according to the types of queries. Simple types of queries are dealt by using simple question X  X nswering tech-niques, while the proposed inference model that analyzes semantic relationships between concepts in dialogue manages ambiguous queries. 3.1. Application domain
We developed a flexible conversational agent for virtual representation of websites using MFC, as shown in Fig. 2 . It consists of a main window for displaying information, an input text box, and an avatar system with a speech generation engine. When the user types a query, the avatar responds in speech with a corresponding action. Q-avatar ( www.qavatar.com ) is employed as the avatar system, while Voiceware (voiceware.co.kr), a solution for speech generation, is used to provide the user with a realistic and convenient interface.

The target domain is mobile websites, which can be accessed with cellular phones, digital cameras, and MP3 players. Table 1 describes the attributes of each object in the target database. The database was built by extracting information from five websites: Naver.com ( www.nshopping.naver.com ), Samsung-mall ( www. samsung-mall.co.kr ), LG-eshop ( www.gseshop.co.kr ), Enuri.com ( www.enuri.com ) and DCinside.com ( www.dcincide.com ).
 3.2. System architecture
As shown in Fig. 3 , the proposed conversational agent is composed of two parts: the multi-modal dialogue interface and the inference modules. The multi-modal dialogue interface provides a familiar user interface as well as deals with general queries based on pattern matching, so system developers might easily construct answer-scripts independent from the application domain. The inference module is composed of the inference engine and knowledge management module, where the inference engine analyzes what the user wants from ambiguous queries and the knowledge management stores information in the target domain by extracting spe-cific content from web pages and accumulating this into the knowledge base. If there is not enough informa-tion to infer the intention, additional information is collected proactively from the user to provide proper responses to users. In the viewpoint of scalability of systems, the developers only construct the inference mod-ule according to the target domain.

In order to manage various queries, it is necessary to divide dialogue modules and set a hierarchical priority according to dialogue type. A subsumption architecture ( Brooks, 1986 ), as proposed by Brooks, can be adopted to select one dialogue act per query. As shown in Fig. 4 , the dialogue management module works in advance to respond to simple queries named  X  X  X eneral dialogue. X  X  When it fails, the system regards the query as  X  X  X nformation retrieval dialogue X  X  and uses the inference module to manage it. 3.3. Dialogue management module
Fig. 4 shows the overall procedure of managing dialogue. In the preprocessing stage, keywords are extracted from the input query to match keywords in the answer-scripts. Responses can be output when scripts match. A set of candidate scripts are then sequentially matched to find appropriate responses, where the pat-tern of a given script is composed of keywords in the target domain. In pattern matching, a pattern X  X esponse pair can be selected by estimating the matched keyword frequency.

Traditional matching yields a high score when many keywords match, since it only considers the number of matches. However, it might fail because of the amount of information included in an input query as shown in Table 2 .

As the knowledge base increases, there will be many duplicated or similar patterns. Therefore, it is neces-sary that the matching process consider the amount of information. In this paper, matching scores are calculated by the F-measure, which is a popular form of text classification. It sets up a weight of a as 1, con-sidering both precision and recall equally.
 Pattern X  X esponse pairs Input query Included AB
Not included CD 3.4. Inference module using SeBN
To obtain efficient inference, we design semantic Bayesian networks to be composed of the probabilistic inference and the semantic inference. This stepwise modeling helps to understand intentions of users in detail through conversation.

Fig. 5 shows a brief overview of the proposed semantic Bayesian network. It has three levels according to function: keywords, concepts, and targets. The keyword layer consists of words related to the user X  X  query, while the concept layer is composed of entities of the domain and their semantic relationships. The target layer represents target information (products) whose attributes are defined. The concept layer is divided into three components: objects, attributes, and values. Each object is a set of attribute X  X alue pairs, where node a attribute and node v k is a value in the domain. A solid line represents the probabilistic relationship between nodes, while a dotted line signifies the semantic relationship between them. Especially, in the application domain, there are about 120 concepts and 1400 products used as nodes in the networks.
 The probabilistic relationship in semantic Bayesian networks is similar to that of the traditional IR model. First, it infers probabilistically between the keyword layer and the concept layer. The user X  X  query a keyword node as 1 when the given word in the keyword layer is observed in query Q and otherwise, it is set as 0
It then infers the probability of each node in the concept layer when all evidence variables associated with follows: where N means the sum of the nodes in the keyword set, c 2 O [ A [ V ( W : a set of keywords, O : a set of cept layer, it infers the probability P ( p j C ) of the product p in the target layer, using them as evidence. where L means the sum of the nodes in the concept set, C = O [ A [ V ( C : a set of concepts, O : a set of ob-and the target layer is defined as: provides information about the target product to the user when a proper number of nodes are selected. In this paper, we define successful execution as what happens when a product is selected.

This work also includes a preliminary examination of the portability of the BN-based framework across different application domains. Migration to new applications often implies a lack of domain-specific data to train the BN probabilities. Under such circumstances, the BN probabilities can be hand-assigned to reflect the  X  X  X egree of belief  X  X  of the knowledge domain expert. The hand-assigned model requires human knowledge in order to decide the BN probabilities ( Hix &amp; Hartson, 1993; Meng et al., 2003 ). In this paper, we provide guidelines for assigning conditional probabilities manually in order to consider scalability.
P ( p j c )and P ( w j c ) are designed according to the same principles. We also present the designing guide-formula:
Table 3 presents guidelines by which we assign values to the joint probabilities P ( w =1 j c
P ( w =1 j c i = 0). The assignment is based on the designer X  X  judgment of the possible occurrence frequency of a keyword w and in the concepts of the goal c i . If we identify a keyword w to be mandatory for a concept of goal c i , we will hand-assign a high probability roughly from 0.95 to 0.99 for P ( w =1 j c the assigned values of P ( w =1 j c i = 1) are increased to the range 0.95 X 0.99 since there is close correlation between the keyword  X  X  X ue X  X  and a concept  X  X  X olor. X  X  Similarly, the assigned values of P ( w =1 j c decreased to the range 0.7 X 0.8 because there is high correlation between the keyword  X  X  X ed X  X  and a concept associated with the keyword  X  X  X ed. X  X  In the conditional probability P ( w =1 j c for keywords that often occur for concepts other than C i occur for concepts other than C i .

When there is no product selected, it executes the semantic inference of semantic Bayesian networks in the ferent types ( X  O  X  A  X , and  X  A  X  V  X ) as shown in Table 4 .

Table 5 shows the semantic inference executed when the probabilistic inference fails to infer the user X  X  inten-
It collects supplementary information on the attribute selected and carries out the inference again with infor-mation gathered from the user. It repeats the procedure until a target product is selected. In order to discover exactly what the user wants, it needs to gather enough information to infer target products. Traditional infor-mation retrieval systems work well only when the user X  X  queries includes enough information for inference.
When there is not enough information, however, the proposed method provides a suitable response to the user based on the mixed-initiative interaction.
 4. Experimental results 4.1. Qualitative analysis: illustration of MII for searching targets with insufficient information
In many cases, users have background knowledge in addition to the content of their conversations, so que-ries may not include all the information required to infer the user X  X  intentions. The proposed conversational agent uses a mixed-initiative dialogue by requesting additional information from the user. Finally, informa-tion on the target product is provided to the user after inference.

As shown in Dialogue 1 , the agent searches plural objects from the initial query. Since the agent needs addi-tional information for correct intention inference, it outputs a supplementary query to the user, such as  X  X  X hich color would you like? Red or Silver? X  X  as the mixed-initiative interaction. The user responds  X  X  X  X  X  like red. X  X  The agent then executes the probabilistic inference again using semantic Bayesian networks based on this response. Until it detects plural products as the result of prior inference, the agent keeps up the conversation by using mixed-initiative interaction. If a product is selected, the agent finishes the inference and provides information about the target product. 4.2. Quantitative analysis 4.2.1. Experimental designs
In order to evaluate the opinions of how satisfied younger adults are with the efficiency of the agent, we compared three conversational agents: script-based, BN-based and SeBN-based agents. The experi-ment aimed to estimate the speed and accuracy of the agent X  X  responses. Thirty South Korean subjects aged from 22 to 33 evaluated the different kinds of agents. Table 6 shows the characteristics of these sub-jects. They had to perform ten tasks to search for information on several products, for example  X  X  X ind a small digital camera with a resolution rate of four million pixels. X  X  The users evaluate each system by posing questions constructed according to the QUIS (questionnaire for user interface satisfaction). Satisfaction scores were measured by single items on five-point Likert scales (1.0 =  X  X  X ot at all X  X , 5.0 =  X  X  X ery much X  X ) for each task.
 4.2.2. Analyses of results
The results (see Table 7 ) show that the proposed method ( M = 94.42) is superior to the others ( M = 92.15, 87.51). SeBN-based agents can manage various types of dialogues while script-based and BN-based agents fail to respond. SeBN-based agents also show good performance in providing suitable responses for users with only a few interactions ( M = 2.96).

As shown in Table 8 , satisfaction was very high when using the proposed method. The effects of the pro-posed method were evaluated in terms of the following criteria: ease of use, friendliness, informativeness, rep-etition and level of interest. These criteria were statistically measured by means of a one-way ANOVA with a variant of the SeBN as the among-systems factor. Post-hoc tests were also conducted, whenever one or more significant factor entailed more than two of the criteria. The emotional state measure revealed significant dif-ferences among the systems ( F (2,27) = 21.581, p &lt; .05). It showed that ease of use with SeBN-based agents was much higher ( M = 4.6, SD = .5164) than with script-based agents ( M = 2.9, SD = .7379) and BN-based agents ( M = 4.0, SD = .4714). In terms of friendliness, the average score of the SeBN-based agents ( M = 4.7,
SD = .4830) was significantly higher than that of the script-based agents ( M = 2.7, SD = .6749) and the BN-
SD = .6749) and SeBN-based agents ( M = 4.4, SD = .5164) and the SeBN-based agents rated higher than all the other systems. The most noticeable result was in terms of repetition. The value of the SeBN-based agents ( M = 1.6, SD = .5164) was significantly lower than that of the script-based agents ( M = 3.9, SD = .8756) and minimized unnecessary information in conversations. Finally, as for level of interest, SeBN-based agents ( M = 4.5, SD = .5270) produced a significantly higher score than script-based agents ( M = 3.8, SD = .7888) and BN-based agents ( M = 3.1, SD = .5676), ( F (2,27) = 12.027, p &lt; .05). 5. Conclusions and future works
We have proposed a conversational agent that uses semantic Bayesian networks in order to be more flexible the user to provide more information in order to infer the intention correctly. Finally, answering performance is improved when using SeBN-based agents. It is presumed that the design of networks will become easier and more comprehensible, since designers will be able to use more intuition.

The manual design of networks requires overhead operation, so research on the automatic construction of semantic Bayesian networks remains necessary, which improves the scalability of the proposed method. Several works on automatic learning of Bayesian networks ( Yang &amp; Chang, 2002 ) and semantic networks ( Shamsfard &amp; Barforoush, 2004 ) might be helpful for developing the learning technique for semantic Bayesian networks. Acknowledgement The work was supported by the Korea Research Foundation Grant (KRF-2004-005-H00005).
 References
