 As the size of the web is growing rapidly, a well-recognized challenge for developing web search engines is to optimize the search result towards each user X  X  preference. In this pa-per, we propose and develop a new personalization frame-work that captures the user X  X  preference in the form of con-cepts obtained by mining web search contexts. The search context consists of both the user X  X  clickthroughs and query reformulations that satisfy some specific information need, which is able to provide more information than each individ-ual query in a search session. We also propose a method that discovers search contexts by one-pass of raw search query log. Using the information of the search context, we develop eight strategies that derive conceptual preference judgment. A learning-to-rank approach is employed to combine the de-rived preference judgments and then a Context-Aware User Profile (CAUP) is created. We further employ CAUP to adapt a personalized ranking function. Experimental results demonstrate that our approach captures accurate and com-prehensive user X  X  preference and, in terms of Top-N results quality, outperforms those existing concept-based personal-ization approaches without using search contexts. H.3.3 [ Information Search and Retrieval ]: Search Pro-cess Algorithms, Experimentation Search Personalization, Clickthrough, Query Reformulation
With the exponential growth of information available on the Web, search engines have become an indispensable tool
Figure 1: Main Processes in Personalization Framework of people X  X  daily activities [7]. However, as search queries are typically short and ambiguous, search engines have lim-ited clues to infer a user X  X  true search intents and thus can only return roughly the same result for the same query. This one size fits all strategy makes search engines perform only suboptimally for many users [5]. To alleviate this problem, search personalization has been studied in order to adapt search results to individual X  X  explicit or implicit feedback. Since users are largely reluctant to provided explicit feed-back due to the extra efforts involved, implicit feedback is commonly used as the major resource for search personal-ization [4, 8].

The most widely used implicit feedback is the user X  X  click-through information [4]. Several personalization approaches have been proposed to personalize search results based on each individual query X  X  clickthrough information [4, 8]. How-ever, as the user usually submits a sequence of queries to satisfy the same information need [11], the search context that is composed of previous queries, previous clickthroughs as well as the semantic relations between queries become a potential resource to infer the user X  X  preference with higher accuracy and broader information coverage.

We propose a framework that utilizes search context to personalize search results. Figure 1 shows the general pro-cess of the proposed framework, which consists of two funda-mental activities: (1) Profile Updating and (2) Re-ranking.
In order to realize the proposed personalization approach, we need to overcome some challenging issues. First, we need to develop a method that automatically discovers search con-text from raw search query log. Although many existing methods assume that the context is already known, obtain-ing search context for personalization usage is non-trivial. As providing irrelevant results for the user is frustrating, a high coherency is required to avoid involving irrelevant infor-mation and meanwhile the integrity should also be kept to avoid breaking a context into several separated ones. Thus, we propose a method that utilizes a range of techniques con-cerning temporal cutoff, query relevance and Search Engine Result Pages (SERPs) similarity in order to discover search context by one-pass of the query log.

Second, search context contains different types of informa-tion. Based on the diverse nature of the observed evidence in search context, we need to design different strategies to infer the user X  X  preference. Additionally, preference derived from different sources should be seamlessly combined to up-date CAUP for the user. To meet these requirements, our framework uses three strategies to derive preference judg-ment from the user X  X  clickthrough behaviors and five strate-gies to derive preference judgment from the user X  X  query reformulation behaviors. Then a learning-to-rank method is used to combine the derived preference judgment and update CAUP, which is further used to personalize search results.
The main contributions of this paper can be summarized as follows:
The rest of the paper is organized as follows. Section 2 reviews the related work. Section 3 presents the method of concept extraction. Section 4 details our search context discovery technique. Section 5 explains the strategies of de-riving conceptual preferences from search context. Person-alized ranking function is described in Section 6 and exper-imental results are given in Section 7. Finally, we conclude the paper in Section 8.
The proposed framework utilizes interaction evidence in search context to support search personalization. In this section, we review two related fundamental topics: session segmentation and search personalization .
In the field of session segmentation, the relations between queries are categorized as Topic Continuation and Topic Shift , which are illustrated in Figure 2. Assume that query Q1 and Q2 are semantically related, thus they are grouped in the same session and the relation between them is Topic Continuation . Similarly, Q3, Q4 and Q5 are also from the same session and the relations between them are Topic Con-tinuation . On the contrary, Q2 and Q3 have no semantic relation and the relation between them is Topic Shift ,which generates a session boundary.

In previous studies, a fixed temporal cutoff is widely used as the indicator of Topic Shift . Radlinski et al. [11] used a half-an-hour cutoff on the log of a library search engine and discovered that this helps achieve a good precision in finding search sessions. However, Jones et al. [6] reported that only using timeout cutoff is not good enough for logs from gen-eral search engines. Gayo-Avello [1] provided a good survey about several session segmentation methods, which primar-ily based on temporal cutoff and lexical similarity between queries. More recently, in order to have a better under-standing of the relation between search queries, Huang et al. [3] built a rich taxonomy of query refinement strategies and developed a high precision rule-based classifier to detect related queries. Topic Continuation is further characterized as different types of query reformulation.

Our work on search context discovery is different from pre-vious studies in two ways. First, as high accuracy is required for personalization, keeping the coherency of search context is prioritized by our search context discovery method and meanwhile it also keeps the context integrity to avoid break-ing a search context into several separated ones. Second, the search context discovered by our approach is not simply a group of semantically related queries. Through one-pass of the query log, our method also captures the query refor-mulation type between consecutive queries, which contains valuable information for inferring the user X  X  preference.
Search personalization aims to return the most relevant search results according to the user X  X  interests and prefer-ences. In order to achieve this goal, clickthrough is widely used in previous works to infer the user X  X  preferences. Based on the research of search engine users X  browsing behaviors, Joachims [5] first developed a framework that utilized click-through data to infer users X  preferences on documents and then learned to adapt the ranking function. Radlinski et al. [11] extended Joachims X  method to infer the user X  X  doc-ument preference based on the clickthrough raised by differ-ent queries. As Radlinski X  X  method can deduce new types of preference judgment, the learned ranking function outper-formed the methods that only used information of individual query. Shen et al. [12] proposed a method which incorpo-rates previous queries and clickthroughs to build language models. Luxenburger et al. [10] proposed a personalization framework that match users X  information need with their searching history. Xiang et al. [15] proposed four strategies to re-rank search results by the relation between queries, and their method showed perf ormance improvement com-pared with those without context information. Leung et al. [8] developed several profiling methods to capture the user X  X  positive and negative preferences by concepts. By analyz-ing each search query individually, the profiling methods in [8] captures the user X  X  preference with fine granularity and demonstrates better performance than those based on doc-ument preference. However, with the importance of context and the advantage of concept-based preference representa-tion, few works has been done to study concept-based search personalization in a context-aware approach.

The differences between our work and the previous coun-terparts are: First, our framework utilizes search context rather than individual queries to derive preference and thus obtains more comprehensive information coverage, which improves the accuracy of generated preference judgment. Second, the user X  X  preference is represented by concepts in current search results as well as the related concepts from the concept ontology. In this way, our framework captures the user X  X  preference on more concepts and thus improves personalization accuracy. Third, we propose a learning-to-rank method that seamlessly combines different conceptual preference judgment and use the combined preferences to update the Context-Aware User Profile .
Informally, if a term/phrase c appears frequently in the web-snippets 1 arising from a query q ,then c represents an important concept related to q , as it co-exists in close proximity with the query in the top documents. Our concept extraction method first extr acts all the terms and phrases from the web-snippets arising from q and denote a term use the following formula to clean the concept set and delete those concepts that are not related to the query or the user X  X  interests. (i.e. the number of web-snippets containing c i ), n is the A  X  X eb-snippet X  denotes the title, summary and URL of a Web page returned by search engines.
 number of web-snippet returned and | c i | is the number of term in the term/phrase c i .  X  is the frequency threshold we use to distinguish concepts from other terms.  X  is set to 0.03 in the experiments. We choose a relative small threshold in order to obtain good information coverage.
Search context consists of queries sharing the same topic, clickthrough raised by these queries and various reformula-tion types between queries. In this section, we present our search context discovery method, which captures this infor-mation through one-pass of raw search query log.
Temporal cutoff is widely used as the indicator of topic shift. Temporal cutoffs ranging from 5 minutes to 30 min-utes are frequently used to identify session boundaries. In order to evaluate the effectiveness of these cutoffs, we utilize different temporal cutoffs within 90 minutes to evaluate their performance of search context discovery. We observe that a 30-minute cutoff achieves fairly good performance and the results are presented in Section 7.
We utilize query reformulation taxonomy to evaluate the relevance between query strings. The reasons of using query reformulation taxonomy are twofold: First, the taxonomy-based approach demonstrates the state-of-the-art precision of detecting Topic Continuation , i.e., the approach has a high precision in detecting query relatedness. Second, refor-mulation taxonomy captures the reformulation type between consecutive queries and we will show later that various re-formulation types contain valuable information that helps infer the user X  X  preference.

The taxonomy is presented in Figure 3. Reformulation types except the last one belong to Single Reformulation , which is used to detect a certain type of change between two queries. The Single Reformulation we use is an en-riched version of that in [3] and readers may refer to it for more detailed information. As Huang et al. [3] reported that only using Single Reformulation tends to damage the integrity of search context. To resolve this problem, we use Multiple Reformulation to handle the scenario that a user reformulates his/her queries by combining more than one reformulation types. For example, horses race  X  horse is a reformulation that combines SingularAndPlural and Re-moveWords . Although these two queries are semantically related, reformulation types in Single Reformulation are too strict to capture them. As exhaustively enumerating each combination of reformulation types is infeasible, we propose to evaluate the relevance between two queries by the similar-ity of each pair of their terms. We first tokenize each query into terms by whitespace and then use six term similarity features to train an SVM model. The weight of each feature is listed in Table 1, from which we observe that the features Same , Singular/Plural Conversion and Stemming play the dominant roles.
The limitation of taxonomy-based method is that it can-not capture reformulations beyond the predefined taxonomy. As search results returned from search engine usually con-tain abundant information about the query, Search Engine Result Pages (SERPs) are potentially helpful to detect the similarity between queries. For each query q ,weextract concepts from the top 100 snip pets returned by the search engine and then the query is represented as a concept vec-the similarity between two SERPs. It is defined as follows:
Based on the three metrics proposed in Section 4.1, 4.2 and 4.3, we present our search context discovery method in Algorithm 1. Technically, separating queries from different users is straightforward, since each query is associated with user identifiers in search query log. Thus, we focus on how to discover search context for queries submitted by the same user.
In this section, we discuss the strategies of deriving the user X  X  conceptual preference from the search context. We propose three strategies to derive preference from clickthrough behavior and five strategies to derive preference from query reformulation behavior.
Joachims et al. [5] made an in-depth study about a user X  X  browsing behaviors in the process of web searching and pro-posed three assumptions: Algorithm 1 Search Context Discovery Input: Temporal Cutoff T ; Query Reformulation Taxon-omy Tax ; SERPs Similarity Threshold  X  SERPs ; Output: Search contexts segmented by Topic Shift ; 1: for all q i in log do 2: if Time( q i +1 )-Time( q i ) &gt; T then 3: Relation( q i ,q i +1 )  X  Topic Shift 4: else 5: if (Reformulation( q i , q i +1 )  X  Tax )=FALSE then 6: if SERPs ( q i ,q i +1 ) &lt; X  SERPs then 7: Relation( q i ,q i +1 )  X  Topic Shift 8: else 9: Relation( q i ,q i +1 )  X  Unknown Reformulation 10: end if 11: else 12: Relation( q i ,q i +1 )  X  Reformulation( q i , q i +1 ) 13: end if 14: end if 15: end for
Based the aforementioned assumptions, we define a user X  X  examination range of the search results as follows: The following three strategies focus on snippets within the examination range and ignore those beyond it. 1. Click &gt; q Skip Above : Assume ( s 1 ,s 2 , ... ) is the ranking of snippets arising from query q ,thecorresponding concept set for each snippet is denoted as ( C 1 ,C 2 , ... is clicked while s j is not clicked and i&gt;j , derive a concept preference judgement c a &gt; q c b for concept c a from C concept c b from C j .

The intuition behind this strategy is that a user scans the search results from top to bottom. If he/she skipped a observation, we infer that concepts in s j are more likely to be preferred than concepts in s j and pairwise preference judgment is generated for each concept pair between s i and s 2. Click &gt; q No-Click Next : Assume ( s 1 ,s 2 ,... ) is the ranking of snippets arising from query q ,thecorresponding concept set for each snippet is denoted as ( C 1 ,C s is clicked while s j is not clicked and j = i +1 ,derivea concept preference judgment c a &gt; q c b for concept c a and concept c b from C j .

The intuition behind this strategy is that a user would not scan much below a clicked snippet s i , and he/she usu-ally view the immediately following snippet s j . Therefore in concept pair between s i and s j . Note that the preference generated by this strategy confirms the original ranking. 3. Click &gt; q No-Click Earlier : Assume q is an earlier query of q within the search context. ( s 1 ,s 2 , ... ) is the rank-ing of snippets arising from q and the corresponding concept set for each snippet are denoted as ( C 1 ,C 2 , ... ) . Similarly, ( s 1 ,s 2 , ... ) is the ranking of snippets arising from q and the corresponding concept set for each snippet are denoted as (
C 1 ,C 2 , ... ) .If s i is clicked while s j is skipped by the user, derive a concept preference judgment c a &gt; q c b for concept c from C i and concept c b from C j .

The intuition behind this strategy is that concepts in clicked snippets are more likely to be preferred than concepts in skipped snippets arising from earlier query. This strategy can generate preference judgment over concepts arising from different queries. By applying this strategy, we are able to compare concepts from different queries and thus capture more information to infer the user X  X  preference.
Query reformulation reflects the semantic relation between two consecutive queries. We first evaluate the distribution of query reformulation types from a 10K search query log. We invite human judges to manually label the reformulation type between queries. The result is shown in Table 2. Multiple Reformulation 18.1% No Unknown Reformulation 15.6% No
We design reformulation-based strategies for the first five types in Table 2. These query reformulation types cover 62.2% of the overall reformulations. As Multiple Reformu-lation is the hybrid of different reformulation types, we de-sign no strategy for it. Unknown Reformulation is the re-formulation types that cannot be captured by the reformu-lation taxonomy. From our empirical evaluation, we ob-serve that most of Unknown Reformulation need external information such as SERPs to infer the relevance. Thus, no query reformulation-based preference derivation strategy is designed for Unknown Reformulation . As query refor-mulation types in Others only take up a small proportion, no strategy is designed for it either. However, in practice Type S-S C-S S-C C-C(S) C-C(D) Repeat 51% 13% 15% 8% 13% AddWords 29% 14% 33% 2% 22% RemoveWords 41% 10% 28% 2% 19%
StripURL 40% 6% 42% 6% 6% the effort of capturing Multiple Reformulation , Unknown Re-formulation and Others by the context discovery algorithm would not be wasted. Capturing the three reformulation types is still helpful to glue semantically related queries in thesamesearchcontext,fromwhichwecanderivepref-erence judgment by Click &gt; q No-Click Earlier ,otherwise related queries would be separated into different search con-texts.

In order to better understand the nature of the five query reformulation types, we also conduct an empirical study on the user X  X  Click/Skip behavior before and after query refor-mulation. A query is labeled as Click(C) if it results in click-through, otherwise, it is labeled as Skip(S). Five Click/Skip patterns and their proportions for each reformulation type are listed in Table 3. In the table, the C-C pattern is further categorized as C-C(S/D) if the clicked URL is the same/different for the two queries. We notice that for each reformulation type, S-S and C-S patterns take a large pro-portion of the observed behavior patterns, indicating that query reformulation usually fails to bring satisfactory re-sults. As there is no guarantee that a reformulated query would bring better result, we consider a reformulated query closer to the user X  X  information need only if it results in some clickthrough. 4. Repeat Strategy : Assume q is an earlier query of q within the search context and q is the repeated query of q . ( s 1 ,s 2 , ... ) is the ranking of snippets arising from ( s 1 ,s 2 , ... ) is the ranking of snippets arising from combined snippet ranking is denoted as ( s c 1 ,s c 2 , ... labeled as clicked if s i or s i is clicked. Derive preference using Click &gt; q Skip Above and Click &gt; q No-Click Next from the combined ranking list instead of original ones.
After Repeat reformulation, the second query brings the same result as the previous one. For S-C pattern and C-C(D) pattern, applying the three clickthrough-based strate-gies would generate conflicting preference judgment as well as redundant preference judgment. For C-C(S) pattern, ap-plying the three clickthrough-based strategies would gener-ate redundant preference judgment. In order to alleviate this problem, we propose Repeat Strategy to avoid the undesir-able effects arising from  X  X udgment conflict X  and  X  X udgment inflation X . 5. SpellingCorrection Strategy : Assume q is an ear-lier query of q within a search context. If q results in click-through while q results in no clickthrough, only derive pref-erence judgment for q by Click &gt; q Skip Above and Click &gt; q No-Click Next .

S-C pattern takes a large proportion for SpellingCorrec-tion. We infer that the user usually corrects the spelling mistake and does the search again. Such behavior pattern results from clicking the query suggested by the search en-gine. As there may be no real  X  X reference judgment X  made by the user, we constrain that for S-C pattern of Spelling-Correction, preference judgment is only derived from the search result of the second query. 6. AddWords Strategy : Assume q is an earlier query of q within a search context. Terms belong to q/q are de-noted by the set S .If q results in clickthrough, concepts con-taining terms in S is preferred over those skipped concepts for query q .

Through AddWords reformulation, the second query q contains some terms that do not exist in the first query q We denote these terms as q/q ,whichformaset S .Ifthesec-ond query results in clickthrough, we infer that these terms successfully represent the user X  X  information need and thus concepts containing these terms should be preferred to con-cepts in skipped snippets. From the Click/Skip pattern, we observe that S-C and C-C(D) take a relative large propor-tion. For these two patterns, the clickthrough indicates that the added terms bring results that are closer to the user X  X  information need. 7. RemoveWords Strategy : Assume q is an earlier query of q within a search context. Terms belong to are denoted by the set S .If q results in clickthrough, clicked concepts is preferred over those containing terms in S query q .

Through RemoveWords reformulation, some terms in query q are removed from q .Wedenotethesetermsas q /q ,which form a set S . If the second query results in clickthrough, we infer that the user is looking for more general information than that obtained from q . Query terms in earlier queries that make the search result too specific would not be pre-ferred by the user and clicked concepts are preferred to con-cepts containing these obsolete terms. From the Click/Skip pattern, we also observe that S-C and C-C(D) take a large proportion for RemoveWords. For these two patterns, the clickthrough indicates that removing these terms success-fully brings relevant results to the user. 8. StripURL Strategy : Assume q is an earlier query of q within a search context. If q is obtained by stripping URL from q , snippets whose URLs sharing terms with are preferred by the user.

StripURL implies that the user has navigational search intent, i.e., the user is looking for a specific Web page rather than some informational contents. In our data set, through StripURL reformulation, 80.64% of the clicked URLs share terms with the reformulated query. In contrast to other query reformulation-based strategies, we capture the user X  X  preference with respect to URLs rather than concepts. Thus, we design this strategy to promote results whose URLs share terms with the reformulated query.
Based on the preference judgment obtained from the pre-vious section, we evaluate each concept X  X  attractiveness and generate a ranking function that utilizes weighted concepts to personalize search results.

Suppose we have input preference judgment over concepts c i and c j for a given query q in the following form: c i &gt; We write the above preference as a constraint as follows: where  X  is a function that maps a query to a concept vec-tor. RSVM [4] is employed to find w by which the maximal pairwise preference judgment can be satisfied.

The mapping  X  determines which kind of function RSVM to learn. We first build a concept space , which contains con-cepts in the preference judgment as well concepts have se-mantic relation with them in the concept ontology. Then, for each c i arising from q ,wecreateafeaturevector  X  ( q,c i )= ( f The value of each feature is given by:
The benefit of building concept space from concept ontol-ogy is to capture the semantic relation between concepts. For example, a user submitted the query  X  X un X  and clicked on a snippet containing concept  X  X tar X . From the concept ontology, we observe that  X  X tar X ,  X  X lanet X  and  X  X olar system X  have relative strong relation, thus we infer that these con-cepts would be favored by the user and results interpreting  X  X un X  as a company or a newspaper would not be relevant to the user X  X  information need.

The semantic relation between two concepts, sim ( c i ,c k is measured by Pointwise Mutual Information (PMI). Let p ( p ( used to calculate PMI is given by: where N c i is the number of snippets containing c i , N c and is the number of snippets containing c j and N c i ,c the number of snippets containing both c i and c j . N is the total number of snippets. The value of N c i , N c j , and N are obtained from statistics stored in the concept ontology. PMI may yield negative values; in this case we replace it by zero. In this work, sim ( q,c i ,c k )isreplaced by normalized PMI which is denoted by PMI N ( c i ,c j ). We adapt the formula of normalized PMI used in [2] as follows:
Suppose the original ranking of search results arising from q is denoted by R ( s 1 ,s 2 , ..., s n ), where s i denotes the snip-pet ranked at position i .Let C i be the set of concepts extracted from snippet s i . The preference score for s i is ob-tained by summing up the attractiveness of each concept in C
Based on the preference score of each snippet, we obtain a new ranking and present it to the user. Note that the afore-mentioned re-ranking method will not be apply to StripURL, which relies on URLs rather than concepts. For StripURL, we simply apply StripURL Strategy .
In this Section, we present a comprehensive evaluation of the proposed personalization framework. In Section 7.1, we detail the experimental setup. In Section 7.2, we com-pare the performance of our search context discovery algo-rithm with several baseline methods. In Sections 7.3 and 7.4, we evaluate the clickthrough-based strategies and query reformulation-based strategies. In Section 7.5, we evaluate the effectiveness of combining preference derivation strate-gies and provide an example of the obtained CAUPs.
For the evaluation of search context discovery, we prepare the experimental data from AOL search query log. Each record contains the attributes of user ID, query, timestamp and the URLs that the user clicked. The 8,852 search records are manually segmented into 4,598 search contexts, which are used as the ground truth when evaluating our context discovery algorithm. Table 4 shows the statistics of our ex-perimental data. We compare our context discovery method with several baseline methods such as fixed temporal cutoff and the taxonomy-based method proposed in [3].

For the evaluation of personalization strategies, we com-pareourapproachwithtwomethodsproposedin[8],which shows state-of-art of performance to capture the user X  X  con-ceptual preference. In the evaluation of traditional infor-mation retrieval systems [14], expert judges are employed to judge the relevance of a set of documents (e.g., TREC) based on a description of the information need. However, the same evaluation method cannot be applied to personalize Web search, because the same query issued by two different users may have different goals behind it. Thus, instead of having expert judges to evaluate the results with optimized information goals, we invite the users to examine the results and judge what they would consider as relevant for precision computation. A similar evaluation approach has also been used in [13]. We collect the experimental data from the pro-totype shown in Figure 1. The users were asked to perform relevance judgment on the top 100 results for each query by filling in a score for each search result to reflect the relevance of the search result to the query. We define three level of relevancy (Good, Fair and Poor) on documents. Documents rated as  X  X ood X  are considered relevant while those rated as  X  X oor X  are considered irrelevant to the user X  X  information need. Documents rated as  X  X air X  are treated as unlabeled. In our experiments, documents rated as  X  X ood X  are used to compute the Top-N precisions for different methods.
We evaluate the performance of our search context dis-covery approach in terms of coherency (Precision), integrity (Recall) and overall performance (F-measure). Precision is defined as the fraction of true topic continuation in all the detected topic continuations. Recall is the fraction of true topic continuation that has been detected by the method. F-measure is a metric involving both precision and recall and it is defined as (2  X  P recision  X  Recall ) / ( P recision +
We first evaluate the effectiveness of fixed temporal cutoffs andtheresultisshowninFigure4(a). Theresultdemon-strates that a cutoff between 25 minutes to 30 minutes is a fairly good cutoff for balancing precision and recall be-cause it achieves the highest F-measure. Thus, we choose 30 minutes cutoff to be the default value for context dis-covery methods involving temporal cutoff. The evaluation result of SERPs similarity threshold is presented in Figure 4(b). We observe that SERPs similarity thresholds between 0.5 and 0.9 demonstrate very high precision and low recall. In order to strike a balance between precision and recall, we choose threshold 0.75 to be the default value for context discovery methods involving SERPs similarity.

The performance comparison of different context discov-ery methods is presented in Table 5. We observe that the temporal cutoff method tends to group both relevant and irrelevant queries together, and thus results in a high recall (92.73%), but low precision (78.48%). The low precision re-sults from the risky assumption that queries within a period should be submitted to satisfy the same information need. The Single Reformulation method is solely based on the tax-onomy proposed in [3] and demonstrates a high precision (93.13%). The high precision shows that, by utilizing strict reformulation rules, Single Reformulation can effectively de-tect query relatedness. However, a major drawback of Sin-gle Reformulation is that reformulation rules are too strict, and thus it cannot effectively discover similar queries (e.g., semantically rephrased queries) that are not covered by the reformulation rules, resulting low recall (66.33%). Low recall indicates that Single Reformulation tends to split a search context into several separated ones and therefore context integrity is damaged.

New Reformulation is the method based on the reformu-lation taxonomy in Figure 3. It yields fairly good precision (86.20%) and recall (84.40%). We observe that, by incorpo-rating multiple reformulation, it boosts the recall by 18.07% while sacrifices 11.00% precision. The Multiple Reformula-tion type contributes a lot to the recall improvement. The method only using SERPs similarity is denoted by SERPs, which yields a precision of 91.23% and a recall of 44.14%. The result is consistent with the argument in [9], which re-ported that methods based on document overlap suffer from data sparseness problem, meaning that the chance for two queries to have common documents is very low. The method incorporating new reformulation taxonomy and SERPs sim-ilarity boosts the precision to 99.40%. However, it still suf-Temporal Cutoff 78.48% 92.73% 0.8501 No Single Reformulation 93.13% 66.33% 0.7748 Yes New Reformulation 86.15% 84.38% 0.8525 Yes SERPs 91.23% 44.15% 0.5950 No SERPs and New Reformulation 86.15% 84.75% 0.8544 Yes Temporal Cutoff and New Reformulation 96.89% 78.01% 0.8643 Yes Temporal Cutoff and SERPs 99.41% 40.28% 0.5733 No Temporal Cutoff, New Reformulation and SERPs 96.89% 78.36% 0.8664 Yes
Figure 5: Effectiveness of Clickthrough-based Strategies fers from the data sparseness problem, and thus yielding low recall (40.30%).

The method combining New Reformulation and tempo-ral cutoff achieves good performance, yielding a precision of 96.89% and a recall of 78.01%. Compared with New refor-mulation, this approach improves the precision by 10.74% while sacrifices the recall by 6.37%. The result indicates that temporal cutoff is a good complementary factor for improving precision. The method based SERPs similarity and temporal cutoff shown the highest precision (99.41%), however, due to the data sparseness inherent from SERPs similarity, the method also has the lowest recall (40.28%).
Finally, by integrally using temporal cutoff, New Reformu-lation and SERPs similarity, the context discovery method proposed in Algorithm 1 yields a high precision (96.89%) while keeps a good recall (78.36%). It also achieves the highest F-measure. We use this method in our prototype and experiments. Following the definitions in [8], the method embodying Click &gt; q Skip Above is denoted as Joachims-C and the method embodying both Click &gt; q Skip Above and Click &gt; No-Click Next is denoted as mJoachims-C . As the two meth-ods have been proved useful in [8], we compare them with a new method taking into all the three clickthrough-based strategies. The new method is denoted by Clickthrough .
Figure 5 shows the Top-N precisions of the three meth-ods. The Top-N precisions of all the three personalization methods have an obvious increase compared to the origi-nal ranking, meaning that all the obtained user profiles can correctly capture the users X  preferences. Comparing to the original ranking, Joachims-C and mJoachims-C have a sig-nificant improvement in Top1 (19% and 24%), Top5 (18% and 25%) and Top10 precisions (3% and 9%). However, the improvement for Top20 (2% and 5%) and Top50 (1% and 3%) are not so obvious. We also observe that the ex-tra preferences inferred by mJoachims-C help improve the personalization effectiveness. For example, if only the first search result is clicked, Joachims-C does not generate any preference judgment, while mJoachims-C can still deduce some preference judgments with Click &gt; q No-Click Next to personalize the search results.
 By introducing contextual clickthrough information, the Clickthrough method demonstrates significant improvement comparing to Joachims-C and mJoachims-C in term of Top1 precision(increased by 14% and 9%). We observe that if a user does not click on any search result for a particular query, Joachims-C and mJoachims-C then obtain no preference judgment, and thus no personalization can be done for the query. On the other hand, the Clickthrough method can still deduce preference judgment by utilizing Click &gt; q No-Click Earlier . There are two reasons for the performance improve-ment of incorporating Click &gt; q No-Click Earlier :(1)This strategy is robust to queries that result in no clickthrough; (2) It enables concepts raised from different queries compa-rable and therefore results in better information coverage. Utilization of the two information sources helps yield higher precision comparing to Joachims-C and mJoachims-C .
We now study the effectiveness of each query reformulation-based strategy. In case the evaluation is biased by other fac-tors, for each reformulation type, we sample 50 search con-texts only containing the corresponding reformulation type.
We evaluate each strategy by comparing with the original ranking from search engine (denoted as Original) and the personalized ranking by integrally applied the three click-through based strategies (denoted as Clickthrough). The method of applying all three clickthrough-based strategies as well as the reformulation strategy under evaluation is de-noted by (Clickthrough+ corresponding Strategy). The ex-periment results are shown in Figure 6. A special case is the StripURL Strategy , which is applied without any clickthrough-based strategies.

We observe that Repeat Strategy is effective in boosting the overall precisions. By applying Repeat Strategy refor-mulation, the precision is improved by 8.4% comparing to that without applying it for Top5 precision, 7.8% for Top10 precision, 5.5% for Top20 precision, and 4.5% for Top50 pre-cision. The result validates that, by removing judgment in-flation and judgment conflict, this strategy avoids distorting the user X  X  real search preference and thus boosts the overall personalization effectiveness, especially for Top1, Top5 and Top10 precision.
 By combining SpellingCorrection Strategy , the Top1 and Top5 precisions have been improved by roughly 5% com-pared with that without applying this strategy. We also ob-serve that the Clickthrough method is plagued by Click &gt; No-Click Earlier for two reasons. First, for some queries with spelling mistakes, the backend search engine can suc-cessfully correct them and brings relevant results, in this case, the top two results of the first query may be relevant to the user X  X  information need, even though no clickthrough is raised by the user. Second, if the spelling mistake can-not be corrected by the backend search engine, Click &gt; No-Click Earlier generates preference judgment with some information raised from an irrelevant query and these judg-ment are not helpful to improve the result quality of current query. By applying this strategy, we avoid making such corrupted preference judgment and thus the personalization performance is improved accordingly.

AddWords Strategy is very helpful to boost the Top-N pre-cision. By applying this strategy, the precision is improved by 6.25% comparing to that without it for Top1 precision, 2.5% for Top5 precision, 3.4% for Top10 precision, 4.1% for Top20 precision, and 2.8% for Top50 precision. It can sig-nificantly improve the Top1 precision, showing that when a user reformulates his/her query by adding some terms, these terms bear valuable information for inferring his/her preference. Thus, if a user clicks on the search results of a reformulated query, it is very likely that the reformulated query with the added terms successfully represents the user X  X  actual information need and thus brings satisfactory search results.

RemoveWords Strategy is not as effective as the aforemen-tioned strategies. The performance improvement obtained by applying this strategy is not obvious. For Top1 precision and Top5 precision, the improvement obtained by applying this strategy is less than 2%. The reason is that this strat-egy X  X  effectiveness highly relies on the amount of concepts which are raised by the reformulated query and also contain the discarded terms. We observe that very few concepts raised from the new query contains the obsolete terms, and thus only a few additional preference judgments can be de-duced for the personalization. The sparseness of preference judgment limits the effectiveness of this strategy.
StripURL Strategy is effective for improving the quality of Top1, Top5 and Top10 results. We observe that by ap-plying this strategy, the personalized result outperforms the original ranking as well as that obtained by applying Click-through method. In the experiments, we also find that the extent of improvement relies on the popularity of the query. If the query itself is a popular navigational query, such as  X  X ww.apple.com X , the original result obtained from the back-end search engine is already very good and therefore the im-provement is limited. However, if the query is not so popu-lar, this strategy can effectively boost results with preferred URLs and thus brings a better personalization performance.
In this section, we demonstrate the effectiveness of inte-grally applying the eight proposed strategies on fifty search contexts. We denote the combined strategies as Combined Strategies and compare it with the original ranking, Joachims-C , mJoachims-C and Clickthrough . The result is shown in Figure 6. We observe that the Combined Strategies can ef-fectively improve the quality of the top-ranked search results and achieves the best performance in terms of Top-N preci-sion.
In order to gain a better insight for the profiles obtained from different approaches, we provide an example of the CAUPs obtained by different preference derivation meth-ods. Table 6 shows the queries and the clickthroughs for a user who is searching for the history of  X  X un Microsys-tems X . Table 7 shows the user profile obtained from the four preference derivation methods running on the data in Ta-ble6. Weobservethatthe Joachims-C , mJoachims-C ,and Clickthrough methods predicted the wrong preferences on the concepts  X  X racle and sun X  and  X  X istory X  due to the lim-ited information coverage. The Combined Strategies can fix up the wrong preferences the concepts  X  X racle and sun X  and  X  X istory X . It predicts the correct preferences (i.e., positive preferences on  X  X ompany X ,  X  X racle and sun X ,  X  X echnology X , and  X  X istory X , while negative preferences on  X  X olar system X  and  X  X port X ) from the input training data as shown in Table 6. Comparing to the existing Joachims-C and mJoachims-C methods, the extra cost of CAUP profiling is minimal. The extra cost comes from the additional preferences derived from the simple strategies (i.e. the third clickthrough-based strategy and query reformulation-based strategies), and it is minimal comparing to the overall cost spent in the training and ranking, which is roughly the same for all the strategies.
In this paper, we study the problem of using search con-texts to facilitate concept-based search personalization. We introduce a new method that discovers search contexts from raw search query log. This method captures comprehensive information through one-pass of the query log and has good performance in keeping context coherency and integrity. Eight strategies are then developed to infer the user X  X  conceptual preference from the search context. Through mining click-throughs and query reformulations, the proposed strategies is able to capture the user X  X  preference with higher accu-racy than existing approaches that only consider individ-ual query. We further adopt a learning-to-rank approach to seamlessly combine preference judgment derived from dif-ferent strategies and update the Context-Aware User Pro-file , which is used to personalize the search results returned from the backend search engine. Empirical studies show that our proposed personalization framework yields higher Top-N precision compared to those without considering con-textual information. Importantly, the extra cost of incorpo-rating CAUP into personalized web searching is minimal, since we only incorporates a few more simple rules that ma-nipulate the concept weight in the re-ranking process.
This work is partially supported by RGC GRF under grant number HKUST 618509. [1] Daniel Gayo-Avello, A survey on session detection [2] A. Herdagdelen and et al., Generalized syntactic and [3] J. Huang and E. N. Efthimiadis, Analyzing and [4] T. Joachims, Optimizing search engines using [5] T. Joachims and et al., Evaluating the accuracy of [6] R. Jones and K. L. Klinkner, Beyond the session [7] Y.Ke,L.Deng,W.Ng,andD.L.Lee, Web dynamics [8] K.W.TLeungandD.L.Lee, Deriving concept-based [9] K.W.T.Leung,W.Ng,andD.L.Lee, Personalized [10] J. Luxenburger, S. Elbassuoni, and G. Weikum, [11] F. Radlinski and T. Joachims, Query chains: learning [12] X. Shen, B. Tan, and C. X. Zhai, Context-sensitive [13] Jaime Teevan, Meredith Ringel Morris, and Steve [14] E. Voorhees and D. Harman, Trec experiment and [15] B. Xiang, D. Jiang, J. Pei, X. Sun, E. Chen, and
