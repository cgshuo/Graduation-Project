
R.P. Jagadeesh Chandra Bose 1 , 2 , Wil M.P. van der Aalst 1 , Indr  X  e  X  Zliobait  X  e 1 , In order to retain their competitive advantage in today X  X  dynamic marketplace, it is increasingly necessary for enterprises to streamline their processes so as to reduce costs and to improve performan ce. Moreover, today X  X  customers expect organizations to be flexible and adapt to changing circumstances. New legisla-tion is also forcing organizations to change their processes. It is clear that the economic success of an organization is highly dependent on its ability to react to changes in its operating environment. Therefore, flexibility and change have been studied in-depth in the context of Business Process Management (BPM). For example, process-aware informati on systems have been extended to be able to flexibly adapt to changes in the process. State-of-the-art Workflow Manage-ment (WFM) and BPM systems provide flexibility. Moreover, in processes not driven by WFM/BPM systems there is even more flexibility as processes are controlled by people.
 Although flexibility and change have been studied in-depth in the context of WFM and BPM systems, existing process mining techniques assume processes to be in steady state . Starting point for process mining is an event log contain-ing a sequence of business events record ed by one or more information systems. Based on such an event log, processes can be discovered. Today X  X  process dis-covery techniques are able to extract me aningful process models from event logs not containing any explicit process information. Using ProM, we have analyzed processes in more than 100 organizations. These practical experiences show that it is very unrealistic to assume that the p rocess being studied is in steady state: while analyzing the process, changes can take place. For example, governmen-tal and insurance organizations reduce the fraction of cases being checked when there is too much work in the pipeline. In case of a disaster, hospitals and banks change their operating procedures etc. Such changes are indirectly reflected in the event log. Moreover, analyzing such changes is of the utmost importance when supporting or improving operational processes.

In the data mining and machine learning communities, such second-order dy-namics are referred to as concept drift , and has been studied in both supervised and unsupervised settings. Concept drift has been shown to be important in many applications and several successful stories have been reported in the liter-ature [1,2,3]. However, existing work tends to focus on simple structures such as changing variables rather than changes to complex artifacts such as process mod-els describing concurrency, choices, loo ps, cancelation, etc. In handling concept drifts in process mining, the following three main problems can be identified: 1. Change (Point) Detection: The first and most fundamental problem is to 2. Change Localization and Characterization: Once a point of change has been 3. Unravel Process Evolution: Having identified, locali zed and characterized the In this paper, we focus on the first two problems. We propose features and techniques to detect changes (drifts), change points, and change localization in event logs from a control-flow persp ective. The techniques proposed in this paper show significant promise in handling concept drifts. We further provide an outlook on some of the topics in concept drift and believe that this niche area, with its broad scope and relevance, evokes lots of interest in the research community.

The remainder of this paper is structured as follows. Related work is presented in Section 2. Section 3 describes the vari ous aspects and nature of change. Section 4 introduces various features and techni ques for detecting drifts in event logs. Section 5 describes the effectiveness of t he features and techniques proposed in this paper in discovering change points and localization of changes through a case study. In Section 6, we project an outlook on some of the open research questions and directions in this area. The paper ends with some conclusions in Section 7. Over the last two decades many researchers have been working on process flex-ibility, e.g., making workflow systems adaptive. In [4,5] collections of typical change patterns are described. In [6,7] extensive taxonomies of the various flexi-bility approaches and mechanisms are provided. Ploesser et al. [8] have classified business process changes into three broad categories viz., sudden, anticipatory and evolutionary. This classification is used in this paper, but now in the context of event logs.

Despite that many publications on flexibility, most process mining techniques assume a steady state process. A notable exception is the approach by G  X  unther et al. [9]. This approach uses process mining to provide an aggregated overview of all changes happened so far. However, this approach assumes that change logs are available, i.e., modifications of the workflow model are recorded. At this point in time very few information systems provide change logs. Therefore, this paper focuses on concept drift in pro cess mining assuming only an event log as input. Concept drift refers to changes in the target variable(s)/concept induced by contextual shifts over time [10]. While the topic is well-studied in various branches of the data mining and machine learning community, the problem of concept drift has not been studied in the process mining community. While experiences from data mining and machine learning can be used to investigate concept drift in process mining, existi ng techniques cannot be used due to the complexity of process models a nd the nature of process change. Three important perspectives in the context of business processes are the control-flow, data and resource perspective. One or more of these perspectives may be subjected to a change.  X  Control-flow/Behavioral Perspective: This class of changes deals with the  X  Data Perspective: This class of changes refer to the changes in the require- X  Resource Perspective: This class deals with the c hanges in resources, their Based on the duration for which a change is active, one can classify changes into momentary and permanent. Momentary changes are short-lived and affect only a very few cases while permanent chang es are persistent and stay for a while [6]. In this paper, we consider only perm anent changes. Cha nges are perceived to induce a drift in the concept (process behavior). We identify four classes of drifts as depicted in Fig. 1 based on how they manifest.  X  Sudden Drift: This corresponds to a substitution of an existing process M 1  X  Recurring Drift: This corresponds to the scenario where a set of processes  X  Gradual Drift: This refers to the scenario as depicted in Fig. 1(c) where  X  Incremental Drift: This refers to the scenario where a substitution of pro-We propose approaches to detect potential control-flow changes in a process manifested as sudden drifts over a period of time by analyzing its event log. Detecting drifts in data and resource pers pectives and in the contexts of gradual, recurring and incremental drifts is beyond the scope of this paper. 4.1 Causal Footprints Event logs are characterized by the relat ionships between activities. Dependen-cies between activities in an event log can be captured and expressed using the follows (or precedes ) relationship. For any pair of activities, a and b  X   X  , one can determine whether they exhibit either always , never ,or sometimes fol-lows/precedes relationship. If b follows a in all the traces in an event log, then we say that b always follows a ;if b follows a only in some subset of the traces or in none of the traces, then we say that b sometimes follows a ,and b never follows a respectively. Consider an event log L = { acaebfh , ahijebd , aeghijk } lowing relations hold in L : e always follows a , e never follows b ,and b sometimes follows a . The variants of precedes relation can be defined on similar lines. The follows/precedes relationship is rich enough to reveal many control flow changes in a process. In the next section, we exploit this relationship and define various features for change detection. 4.2 Features Capturing the Manifestation of Activity Relationships We distinguish between two classes of features (i) global features and (ii) local features. Global features are defined over an event log while local features can be defined at a trace level. Based on the fo llows (precedes) relation, we propose two global features viz., Relation Type Count and Relation Entropy, and two local features viz., Window Count and J -measure. These features are defined as follows:  X  Relation Type Count (RC): The relation type count with respect to follows  X  Relation Entropy (RE): The relation entropy with respect to follows  X  Window Count (WC): The window count with respect to follows (precedes)  X  J-Measure: Smyth and Goodman [11] have proposed a metric called J -Though local features are defined at a trace level, it is easy to lift them to the level of an entire event log. 4.3 Statistical Hypothesis Tests to Detect Drifts One can consider an event log L as a time series of traces (traces ordered on their arrival time). Fig. 2 depicts such a perspective on an event log along with change points. An event log can be split into sub-logs of s traces each. We can consider either overlapping or non-overlapping windows when creating such sub-logs. Fig. 2 depicts the scenario where two subsequent sub-logs do not overlap. In this case, we have k = n s sub-logs for n traces. One can estimate the feature values for each trace separately (local features) or cumulatively over a subset of traces (local and global featu res) and generate a dataset defined by a matrix/vector of feature values over a sub-log/trace. For example, the relation count feature type will generate a dataset D of size k  X  3 |  X  | when either the follows/precedes relation counts of all activities are considered over L .Instead, if the follows/precedes relation count o f an individual activity is considered in isolation, it generates a dataset of size k  X  3for L .The J -measure generates a scalar value for each trace (sub-log) when an activity pair is considered thereby generating a vector of size n  X  1or k  X  1 (depending on whether it is measured over traces or sub-logs) over L . If all activity pairs are considered, then a dataset of size n  X |  X  | 2 or k  X |  X  | 2 is generated.
We believe that there should be a characteristic difference in the manifesta-tion of feature values in the traces (sub-logs) before and after the change points with the difference being more pronounced at the boundaries. The goal of con-cept drift in process mining is then to detect the change points and the nature of changes given an event log. We propose the use of statistical hypothesis test-ing to discover these change points. Hypothesis testing is a procedure in which a hypothesis is evaluated on a sample data. One can distinguish between two classes of hypothesis tests (i) tests on a single population (single-sample tests) and (ii) tests on two populations (two-sample tests). Another classification of hypothesis tests is concerned with the dimensionality of each data element in a sample. Tests dealing with scalar data elements are called as univariate tests while those dealing with vector data elements are called as multi-variate tests. For our problem, two-sample univariate and multi-variate tests are appropriate . The dataset D of feature values can be considered as a time series as depicted in Fig. 3. Each d i  X  X  corresponds to a feature value for a trace (or sub-log) andcanbeascalaroravector. The basic idea is to consider a series of suc-cessive populations of values (of size w ) and investigate if there is a significant difference between the two populations . The premise is that differences are ex-pected to be perceived at change points p rovided appropriate characteristics of the change are captured as features. A moving window of size w is used to generate the populations. Fig. 3 depicts a scenario where two populations P 1 = d 1 , d 2 ,..., d w and P 2 = d w +1 , d w +2 ,..., d 2 w of size w are considered. In the next iteration, the populations correspond to P 1 = d 2 , d 3 ,..., d w +1 and P 2 = d w +2 , d w +3 ,..., d 2 w +1 . Given a dataset of m values, the number of population pairs will be m  X  2 w +1. We will use the univariate two sample Kolmogorov-Smirnov test ( KS test) and Mann-Whitney U test ( MW test) as hypothesis tests for univariate data, and the two sample Hotelling T 2 test for multivariate data. The KS test evaluates the hypothesis  X  X o the two independent samples (populations P 1 and P 2 )rep-resent two different cumulative frequency distributions? X  while the MW test evaluates the hypothesis  X  X o the two independent samples have different dis-tributions with respect to the rank-ordering of the values? X . The multi-variate Hotelling T 2 test is a generalization of the t -test and evaluates the hypothesis  X  X o the two samples have the same mean p attern? X . All of these tests yield a significance probability assessing the validity of the hypothesis on the samples. We refer the reader to [13] for a classic introduction to various hypothesis tests. We illustrate the concepts presented in this paper with an example process. The process corresponds to the handling of health insurance claims in a travel agency. Upon registration of a claim, a general questionnaire is sent to the claimant. In parallel, a registered claim is classified into a high or low claim. For low claims, two independent tasks, viz., check insurance and check medical history need to be executed. For high claims, three t asks need to be executed viz., check insurance, check medical history, and contact doctor/hospital for verification. If one of the checks shows that the claim is not valid, then the claim is rejected; otherwise, it is accepted. An insuranc e grant and acceptance decision letter is prepared in cases where a c laim is accepted while a rejection decision letter is created for rejected claims. In both cases , a notification is sent to the claimant. Three modes of notification are supported viz., by email, by telephone (fax) and by postal mail. The case should be archived upon notifying the claimant. This can be done with or without the response for the questionnaire. However, the decision of ignoring the questionnaire can only be made after a notification is sent. The case is closed upon completion of archiving task.
 Fig. 4 depicts five variants of this proces s represented in YAWL [14] notation. The dashed rectangles indicate regions where a change has been done in the pro-cess model with respect to its previous variant. The changes can have various reasons. For example, in Fig. 4(a), the different checks for high insurance claims are modeled using a parallel construct . However, a claim could be rejected if any one of the checks fail. In such cases, the time and resources spent on other checks go waste. To optimize this proce ss, the agency can decide to enforce an order on these checks and proceed on chec ks only if the previous check results are positive. In other words, the process is modified with a knockout strategy adopted for high insurance checks as depicted in Fig. 4(b). As another exam-ple, the OR-construct pertaining to the sending of notification to claimants in Fig. 4(c) has been modified to an exclusive-or (XOR) construct in Fig. 4(d). The organization could have taken a decision to reduce their workforce as a cost-cutting measure. Due to availability of limited resources, they would like to minimize the redundancy of sending the notification through different modes of communication and restrict it to only one of the modes.

Let us denote these process variants as M 1 ,M 2 ,M 3 ,M 4 and M 5 .Wehave modeled each of these process variants in CPN tools [15] and simulated 1200 traces for each model. We created an event log L of 6000 traces by juxtaposing each set of the 1200 traces. The event log contains 15 activities or event classes (i.e., |  X  | = 15) and 58953 events. Given this event log L , our first objective is to detect the four change points pertaining to these five process variants as depicted in Fig. 5.

The ideas presented in this paper have been implemented as the concept drift plugin in ProM. We have considered global features (at sub-log level) and local features (both at trace and sub-log level) for our analysis. To facilitate this, we have split the log into 120 sub-logs using a split size of 50 traces. We have computed the relation type count (RC) of all 15 activities thereby generating a multi-variate vector of 45 features for each sub-log. We have applied the Hotelling T 2 hypothesis test on this multi-variate dataset using a moving window of size, w = 8. For this hypothesis test, we have randomly chosen 6 of the 45 features with a 10-fold cross validation. Fig. 6a depicts the average significance probability of the Hotelling T 2 test for the 10 folds on this feature set. The troughs in the plot signify that there is a change in the distribution of the feature values in the log. In other words, they indicate that there is drift (change) in the concept, which here corresponds to the process. It is interesting to see that the troughs are observed around indices 24, 72 and 96 which are indeed the points of change (remember that we have split the log into 120 sub-logs with the change points at indices 24, 48, 72 and 96). The change at index 48 corresponding to the transition from M 2 to M 3 could not be uncovered using this feature set due to the fact that the relation type counts would be alike for logs generated from these two process variants.
We have computed the J -measure for each sub-log and for every pair of ac-tivities, a , b in  X  ( a F b , b follows a within a window of size 10). The univariate Kolmogorov-Smirnov test using a window size of w =10isappliedonthe J -measure of each activity pair. Fig. 6b depicts the average significance probabil-ity of KS -test on all activity pairs. It could be seen that significant troughs are formed at indices 24, 48, 72 and 96 which correspond to the actual change points. Unlike the relation type count feature, the J -measure feature is able to capture all the four changes in the models. This can be attributed to the fact that the J -measure uses the probability of occurrence of activities and their relations. In M 2 , there could be cases where all the modes of notification are skipped (XOR construct). However in M 3 at least one of the modes need to be executed (OR construct). This results in a difference in the distribution of activity probabilities and their relationship probabilities which is elegantly captured in the J -measure.
We have considered the J -measure for each trace separately instead of at the sub-log level. Each activity pair generates a vector of dimension 6000 cor-responding to the J -measure of that activity pair in each trace. The univariate Kolmogorov-Smirnov test using a window size of w = 400 is applied to the vector corresponding to each activity pair in  X   X   X  . Fig. 7 depicts the aver-age significance probability of KS -test on all activity pairs. It could be seen that significant troughs are formed at indices 1200, 2400, 3600 and 4800. These are indeed the points where the models have been changed. Thus the features and approach proposed in this paper are shown to have significant promise in accurately identifying the points of change.
 The second objective in hand ling concept drift is that of change localization . In order to localize the changes (identify the regions of change), we need to con-sider each activity pair individually or a subset of activity pairs. For example, the change from M 1 to M 2 is localized in the region pertaining to high insur-ance claim checks. We expect characteri stic changes in features pertaining to these activities and other activities rel ated to these activities. For example, in M 1 , the activities  X  X igh Medical History Check X  and  X  X ontact Hospital X  always follow the activity  X  X egister X  whenever a claim is classified as high. In contrast, in M 2 , these activities need not always follow  X  X egister X  due to the fact that both these activities are skipped if  X  X igh Insurance Check X  fails while  X  X ontact Hospital X  is skipped if  X  X igh Medical History Check X  fails. During simulation, we have set the probability of success of a check to 90%. We have considered the window count (WC) feature for the activity relation  X  X ontact Hospital X  follows  X  X egister X  on a window size of 10 in each trace separately. Fig. 8a depicts the significance probability of the univariate KS -test using a window size of w = 200 on this feature. It could be seen that one dominant trough is formed at index 1200 indicating that there exists a change in the region between  X  X egister X  and  X  X ontact Hospital X . No subsequent changes with respect to this activity pair is noticed which is indeed the case in the models.

As another example, we have considered the activity  X  X repare Notification X  along with all the three  X  X end Notification X  activities. There exists a change pertaining to these activities between models M 2 and M 3 , M 3 and M 4 ,and M 4 and M 5 . More specifically, we have considered the window count feature on the activity relations  X  X end Notification By Phone X  follows  X  X repare Notification X ,  X  X end Notification By email X  follows  X  X repare Notification X  and  X  X end Notification By Post X  follows  X  X repare Notification X . Fig. 8b depicts the average significance probability of the univariate KS -tests using a window size of w = 200 on the WC feature of these three activity pairs. We see three dominant troughs at around indices 2400, 3600 and 4800 signifying the changes in the models. Certain false alarms (minor troughs) can also be noticed in this plot. One means of alleviating this is to consider only those alarms with a significance probability less than a threshold,  X  . In this fashion, by considering activities (and/or activity pairs) of interest, one can localize the regions of change. Furthermore, one can also get answers to diagnostic questions such as  X  Is there a change with respect to activity a in the process at time period t  X ? Dealing with concept drifts raises a number of scientific and practical challenges. In this section, we highlight some of these challenges.  X  Change-Pattern Specific Features: In this paper, we pres ented very generic  X  Feature Selection: The feature sets presented in this paper result in a large  X  Holistic Approaches: In this paper, we discussed ideas on change detection  X  Techniques for Drift Detection: In this paper, we explored just the Hotelling  X  Sample Complexity: Sample complexity refers to the number of traces (size This paper introduced the topic of concept drift in process mining, i.e., analyzing process changes based on event logs. We proposed feature sets and techniques to effectively detect the changes in event l ogs and identify the regions of change in a process. The approach has been implemented in ProM and evaluated using synthetic data. This is a first step in the direction of dealing with changes in any process monitoring and analysis efforts. We considered changes only with respect to the control-flow perspective manifested as sudden drifts. However, there is much to be done on various other p erspectives mentioned in this paper. Moreover, to further validate the approach we plan to conduct extensive case studies based on real-life event logs.
 Acknowledgments. R.P.J.C. Bose and W.M.P. van der Aalst are grateful to Philips Healthcare for funding the research in process mining.

