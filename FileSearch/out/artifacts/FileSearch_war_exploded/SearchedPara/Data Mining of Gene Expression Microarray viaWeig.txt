 DNA microarray is technology used to measure simultaneously the expression levels of thousands of genes under various conditions and then provide genome-wide insight. Microarray is a microscope slide to which the thousands of DNA fragments are attached. The DNA microarrays are hybridized with fluorescently labelled cDNA prepared from total mRNA of studied cells. The cDNA of the first cell sample is labelled with a green-fluorescent dye and the second with a red-fluorescent dye. After hybridization, the DNA microarrays are placed in a scanner to create a digital image of the arrays. The intensity of fluorescent light varies with the strength of the hybridization. The measure of expression level of a gene is determined by the logarithm of the ratio of the luminous intensity of the red fluorescence I R to the luminous intensity of the green fluorescence I G , E two cell samples by a factor of greater than 2 was considered significant. Thus, if E  X  X  X  1, it is said down-regulated in the second cell sample [3].
 croarray profiles and gene expression profiles into different clusters according to degree of expression levels. Since some microarray experiments can contain up to 30 000 target spots, the data generated from a single array mounts up quickly. The interpretation of the experiment results requires the mathematic methods and software programs to capture the biological or medical information and to extract new knowledge from these data. There exist already several statistical methods and software programs to analyze the microarrays. Examples include 1) Unsupervised learning methods : hierarchical clustering and k -means clus-tering algorithms based on distance similarity metrics [3, 4] are used to search for genes with maximum similarity. 2) Supervised learning methods : support vector machine approaches based on kernel function [5], the bayesian naive ap-proach based on maximum likelihood method [6, 7] are used to classify the gene expression into a training set. These methods are based essentially on numerical algorithms and do not really require structured data.
 based on structure of weighted prefix trees, to analyze microarray data, i.e : 1. defining the distances to compare different genes and different microarrays, 2. organizing the microarrays of a pathology into the different clusters, 3. classifying the genes of a pathology into the different clusters, 4. researching the characteristic genes and/or characteristic microarrays, 5. determining the group of candidate genes suggestive of a pathology. The key to understanding our approach is the information on gene expression in a microarray is represented by a symbolic sequence, and a collection of microarrays is viewed as a language , which is implementated by weighted prefix trees [8, 9]. In fact, the expression levels of a gene will be modeled as an alphabet whose size is the number of expression levels. Thus, a microarray profile or a gene expression profile is viewed as a word over this alphabet and a collection of microarrays forms a language that is called a DNA microarray language .In this study, we chose three symbols to represent the three expression levels of ageneaccordingto:aspotrepresentingagene up-regulated is encoded by +; a gene no-regulated is encoded by  X  ; a gene down-regulated is encoded by  X  . From this modeling, we obtain an alphabet X = { + ,  X  ,  X  X  and a microarray is then represented by a ternary word over X . And a collection of microarrays is represented as the set of ternary words. The encoding by symbol sequences permits the analysis of the microarrays by using ternary weighted trees. These trees provide a visual of a set of data and also are tools to classify enormous masses of words according to the overlap degree of their prefixes. Thus, these structures open a new way to examine the data mining step in the process of knowledge discovery in databases to understand general characteristics of DNA microarray data. In other words, they permit the extraction of hidden biological and medical informations from the mass of this data. They also address the automatic learning and pattern recognition problems. This paper describes two manners of hierarchical cluster analysis of DNA microarray data, using weighted prefix trees, includes clustering the profile of microarrays and clustering genes expression profiles. The next section recalls elements of words and languages. Section 3 presents weighted prefix trees. Section 4 describes the experimental results on a DNA microarray data of breast cancer cells.
 2.1 Words and Precoding of Words Let X = { x 1 ,...,x m } be an alphabet of the size m .A w is a sequence. The lenght of the word w over X is | w | . In particular, the empty word is denoted by  X  . The set X  X  is the set of words over X . For any h  X  0, we denote X h the is a monoid whose element neuter is the empty word  X  .Aword u (resp. v )is u, v  X  X  X  ,let a be the longest left common factor of u and v , i.e u = au and v = av .For x i  X  X , let precod( x i )= i be the precoding of x i ,for i =1 , .., m . The precoding precod( w )of w in base m = Card X is defined as precod(  X  )=0 and precod( w )= m precod( u ) + precod( x ) , if w = ux ,for u  X  X  X  and x  X  X . 2.2 Languages Let L be a language containing N words over X  X  .For u  X  X  X  , let us consider N u = Card { w  X  X | X  v  X  X  X  ,w = uv } , in particular N  X  = N .Thus,for u  X  X  , Let  X  : L X  IN b e t h e mass function defined as  X  ( u )= N x i u = x i 1 ...x i h  X  X  .For u  X  X  X  , let us consider also the ratios P u = N u /N ,in particular P  X  =1.For u  X  X  X  ,x i  X  X , to simplify the notation, let and we consider the ratios By the formula (1), since x u = x i 1 ...x i h  X  X h ,the appearance probability of u is computed by Note that w  X  X  P w = 1 and for any h  X  0 , u  X  X h P u =1. 2.3 Rearrangement of Language There exists a permutation  X   X  S L such that  X w 1 = av 1 ,..., X w N = av N , where v ,...,v N  X  X  X  and a is the left longest factor of L .The  X  is not unique. The Rearrangement( L ) algorithm is proposed in [9] as : for h  X  L and for x  X  X , let n h ( x ) be the number of letters x in the position h of the words in L and appearing in the order n  X  (1)  X  X  X  X  X  X  n  X  ( L ) by sorting algorithm [2]. Example 1. Let L = { ++  X  X  X  ,  X  ++  X  ,  X  ++  X } . One has n 2 (+) = n 4 (  X  )=3 &gt; n One obtains  X  = 3.1 Counting Prefix Trees Let L X  X  X  be a language. The prefix tree A ( L ) associated to L is usually used to optimize the storage of L and defined as follows comes a counting tree . To enumerate the nodes of a tree, we use the precoding of words defined in (2). The internal nodes p = precod( u ) associated to prefix u are nodes such that N u  X  2 and the simple internal nodes q are nodes such that N u = 1. Thus, an internal node p = precod( u ) corresponds to N u words starting with the same prefix u stored in sub-tree p . The counting tree of the language L is constructed by Insert( L , A ) algorithm in [8, 9]. By this construction, the transitions between the nodes on a counting tree have the form : for x  X  X and u  X  X  X  , precod( u ) comparison of all words of L according to the mass of their prefixes as defined in section 2.2. We proposed the Characteristic-Words ( A ( L )) algorithm in [8, 9], which returns the words having the maximum number of occurences, to extract characteristic words . 3.2 Probabilistic Prefix Trees To compute the appearance probability of an output word over an alphabet X ,we introduce the probabilistic tree . Augmented with the probability P p,q defined in is estimated by the maximum likelihood method (see (3)). It is the conditional probability that the word w accepts the common prefix ux knowing the common prefix u . The transitions between the nodes on a probabilistic tree have the form : for x  X  X and u  X  X  X  ,p = precod( u ) probability of a word is computed by (4).
  X  X  X } be the language over X = { + ,  X  ,  X  X  , we have the weighted trees as below. 3.3 Trees Having Longest Prefix Consider the schema as follows where A ( L )(resp. A (  X  L )) is the tree associated with L (resp.  X  L ). Where the tree A (  X  L ) represents the longest prefix of  X  L (see section 2.3). Example 3. Let L given in Example 2 and let  X  = trees in the Figure 2. into a longest prefix tree and to give a new longest prefix tree [9]. 4.1 Descriptions We employ the weighted trees, to organize microarrays (resp. genes) expression profiles into different clusters such that each cluster contains all microarrays (resp. genes) which represents a highly similar expression in degree of overlap. Here, we describe the cluster according to two manners including 1) the cluster analysis of DNA microarrays for searching common profile of microarray data; 2) the cluster analysis of gene expression profiles to search common expression profile of genes. Consider a collection of L genes across in N different measure experiments. The gene expression profiles or the gene expression patterns is the intensity of the red (resp. green) fluorescence dye of spot i in experiment j .By symbolic represention, the gene expression profiles is represented as a language of L words of length N over alphabet { + ,  X  ,  X  X  . In the same way, the profile of microarray data is the transposition of the matrix E , and the profile of mi-croarray data is representated by a language of N words of lenght L . These two languages are implemented by use of longest prefix tree permitting automatically to classify profile of microarrays (resp. genes) according to common expression levels as Figure 3, where the longest common expression indicates the similarity between microarrays (resp. genes). In the case of gene expression profiles (Sec-tion 4.3), the prefixe indicate also the co-regulated genes. This method returns then the hierarchical clustering using weighted trees which is an unsupervised learning technique and thus it does not requires a priori knowledge of cluster number before clustering. This criterion is important in DNA microarray data analysis since the characteristics of the data are often unknown. 4.2 Clustering of DNA Microarrays As an example, we analyze the data of 77 microarrays of 9216 genes of breast cancer cells coming from 77 patients available at the website http://genome-www.stanford.edu/breast-cancer/. The cluster analysis and the characteristic microarrays were represented in the Figures 4, 5, 6 and Table 1. 4.3 Clustering Gene Expression Profiles The Figure 7 and Table 2 give the cluster analysis of gene expression profiles. 4.4 Observations and Notes There are two groups of co-regulated genes. In Table 2, the maximum co-upregu-Each cluster represents the maximum co-regulated genes with the corresponding microarray identity : the cluster A (resp. a) of Table 2 represents 2 up-regulated (resp. 1 down-regulated) genes over 77 microarrays corresponding to three first depths of Figure 5. These maximum co-regulated genes could be then consid-ered as characteristic genes of breast microarrays. These results permit also to isolate the groups of no-regulated genes : from the depth 4 to the depth 12, there are 9 no-regulated genes over 77 microarrays and at the depth 5500 of the counting tree there are 4348 no-regulated genes (48%) in least 50 microarrays (65%). We used the weighted prefix trees to examine the data mining in the process of knowledge discovery in DNA microarray data. The hierarchical clustering us-ing weighted trees gives a tool to cluster gene expression microarray data. The longest prefix tree is used to establish the characteristic genes and/or character-istic microarrays that have the longest common expression and the maximum degree of overlap. It permits also to determine the groups of candidate (and no-regulated) genes of pathologic condition. We anticipate that with further re-finement these methods may be extremely valuable in analysing the mass of DNA microarray data, with possible significant clinical applications. In addi-tion to application on microarrays, weighted prefix tree could be also used to explore other kinds of genomic data and they are pontentially usefull in other classification problems.
 Acknowledgements. Many thanks to J. Soula for help in the data conversion.
