 Nowadays, Chinese online commodity forums have been increasing at an incredible However, to perform such survey is not an easy task. Customer reviews often contain a large sum of noises. This is especially true in Chinese commodity forums. Besides, when searching for a commodity, the forum often returns hundreds or even thousands of reviews. With the limited operation and the lack of overall structure, it is too time and energy consuming to browse all the reviews. A full survey is nearly impossible. 
In this paper, an effective algorithm called CCRM is proposed. CCRM can be commodity feature reorganization. commodity feature ranking step, a probabilistic model is proposed. We use total probability formula to calculate the probability of each extracted feature. 
In the second stage, we propose a top-to-down algorithm, which finds out the sub algorithm is based on an observation of the characteristic of Chinese language. 
CCRM automatically mines out the reviewed features of a commodity from its that with the help of CCRM, users can easily find out what aspects of the commodity are reviewed. 
The rest of this paper is organized as follows. Section 2 discusses some related but extraction and reorganization in detail. Section 5 shows the experiment results. Finally, we give a conclusion in Section 6. Mining commodity information from customer reviews has been studied a lot in even in English. 
Former researches mostly focus on the extraction of sentiment information and the purposes are to perform judgment on a certain commodity. However, as Liu et al . [14] for every sentiment information is related to a feature, instead of the commodity as a whole. In this paper, we focus on the extraction of commodity feature. We leave sentiment information extraction and sentiment classification to our future work. extracted according to the dict ionary. The third one is the rule based approach, which aims at discovering the general rules of keywords from their context. As the this paper, we use the rule based method to extract the commodity feature because of the observation that reviewers tend to use similar phrases when they comment. [10] first applied association rule mining algorithm (ARM) into commodity feature Ranking has always been a hot topic in IR research. Studies have been made to rank the web pages and search results [4, 5, 9, 13]. Our task is to rank commodity features extracted by rules, which differ a lot from web pages. content. However, the precision is not high enough to put into practical use. 3.1 Rule Mining and Feature Extraction We use semi supervised rule mining to build target rule set. By  X  X emi X  here, it means we do not manually label all the training data; instead, we use seeds to automatically form original rule set. This saves much time and energy. The steps are as follows: 1. We first manually extracted features from reviews of two commodities. These describe the following processes. 
Sentence:  X 5022  X  ( X  X he most outstanding point of 5022 is the screen X ). The feature word is  X   X  ( X  X creen X ). 
Stopwords and digits are then removed from these sentences, POS tagging is also performed. After this, the sentence is formatted into below: 2. Sentences with POS tags are then segmented into triples using the rules below: (1). The feature term with two words before it. (2). The feature term with one word before it and one word after it. (3). The feature term with two words after it. 
Then we replace the feature term with a general term  X  X feature] X . Below are the accepted segments of the example sentence: 
Each segment is transformed into a rule: mine out useful and representative rules. The reason to propose this Improved Association Rule Mining algorithm is that, based on our observation, rules generated commodity feature extraction can be very low. In order to complement this, we have to lower the minimal confidence and support to get more rules. However, the cost of find that most rules could be generalized. The utmost generalization is to use the POS low. Based on this observation we improve ARM as follows: 
The ARM way is, for each rule candidate  X  X , B  X  C X , calculate the confidence and support separately. If the two values are all above the minimal threshold, the rule is selected. 
The IARM way is, for each rule in the original rule set, e.g.: We note it as: &lt;posA&gt;A, &lt;posB&gt;B  X  &lt;posC&gt;C 
We separate it into two rules: A, B  X  C 
For these two rules, we calculate confidence and support separately; and then we use linear addition to merge them together: 
We empirically use 999 . 0 =  X  in IARM. 4. Other consideration
In our algorithm, we also allow rules formed by bigram tuples. In order to balance their confidence and support, we multiply each of them by a punishment function. 
When we use rules for mining commodity features, we also allow gaps in rules. 3.2 Feature Ranking model is described below. In the formula, R is the rule set and D is the review document set. We assume that rule space, and then in the review document space. For P ( r ) in the formula, we use the using the formula below: document d by rule r . 
Then we use P ( f ) to rank the extracted features, and by setting a threshold we are formed by single character can not have exact meaning, so we also filter these terms. hierarchical structure. The basic idea of this algorithm is based on the observation: Observation: In Chinese language, for two successively appearing events A and B in happens that A is affiliated to B. 
Based on the observation, we propose the reorganization algorithm in Table 1. 5.1 Experiment Preparation We crawl down a part of the mobile phone and notebook forum from pconline product BBS as our experiment data. We randomly divide the data into two parts, one for training and the other for testing. Detailed data description can be seen in Table 2. 
A proto type System is implemented based on CCRM. Using this data, we evaluated the extraction and ranking algorithm of CCRM over three widely accepted information retrieval metrics, namely Precision, Recall, and Bpref . 5.2 Experimental Results Table 3 and Table 4 show the mining precision, recall and No. of rules for ARM and IARM with different minimal support. The ARM here is similar to the method in empirically set it to 0.5. In Table 3 we see, with lower minimal support, ARM tends to generate large number of rules and get a higher recall, but meantime, the precision not result in great decrease in precision; in stead, the increase of recall is remarkable. This means IARM effectively filters out most of useless rules and mines out the really overall improvement on the precision, but has a negative effect on recall. 
We note that [10] reported much higher minimal support. That is mainly because it uses supervised mining algorithm and manually labels all the training sentences. more practical and energy saving. 
Table 5 shows the ranking evaluation of our proposed probability model. Here we use bpref as the measuring function and IARM with filtering as the mining approach. On the 5 testing commodities, CCRM achieves an average bpref of 0.71. 
For the reorganization algorithm, as there is no convincing metric, we do not Compaq Presario B2803tx in the prototype system in Figure 1. We note that there are 71 extracted commodity features and frequent commented features like  X   X  In this case,  X   X  (machine) has 13 sub features, each containing about 5 reviews. traverse, thus a maximal level of 2 is just appropriate for this algorithm. In this paper, we concern about mining key information from threaded Chinese customer reviews. In order to provide users a clear overview of a commodity, we propose a novel algorithm named CCRM. CCRM mainly has two contributions: 
