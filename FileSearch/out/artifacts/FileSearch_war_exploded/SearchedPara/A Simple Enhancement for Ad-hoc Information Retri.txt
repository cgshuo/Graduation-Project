 Traditional information retrieval (IR) models, in which a document is normally represented as a bag of words and their frequencies, capture the term-level and document-level information. Topic models, on the other hand, discover se-mantic topic-based information among words. In this paper, we consider term-based information and semantic informa-tion as two features of query terms and propose a simple en-hancement for ad-hoc IR via topic modeling. In particular, three topic-based hybrid models, LDA-BM25, LDA-MATF and LDA-LM, are proposed. A series of experiments on eight standard datasets show that our proposed models can always outperform significantly the corresponding strong baselines over all datasets in terms of MAP and most of datasets in terms of P@5 and P@20. A direct comparison on eight stan-dard datasets also indicates our proposed models are at least comparable to the state-of-the-art approaches.
 Probabilistic Model; Dirichlet Language Model; LDA
Many traditional IR models are based on the assumption that query terms are independent of each other, where a doc-ument is represented as a bag of words. Nevertheless this assumption may not hold in practice. Each document may contain several different topics and terms appeared in the document might belong to different topics, which represent different semantic information. Many researchers have been working on term topic information in IR [1, 10, 15, 16]. How-ever, the nature of the associations among query terms still awaits further study. Some cluster-based approaches con-sider each document has only one topic [10], which is not reasonable to model large collection of documents. Topic-based document representation is effective in the language modeling (LM) framework [1, 15, 16]. But there is no gener-ality in BM25 [2, 6, 20] and MATF (Multi Aspect TF) [13] based frameworks.
 In this paper, we present three hybrid models for enhanc-ing traditional IR model via topic modelling. In our pro-posed approach, term-based information and semantic in-formation are considered as two features of query terms. Latent Dirichlet Allocation (LDA) [3] is utilized to combine these two features and enhance three well-known traditional IR models BM25 [2], MATF [13] and Dirichlet LM [18]. In particular, three hybrid models, denoted as LDA-BM25, LDA-MATF and LDA-LM, are proposed respectively. The main contributions of this paper are as follows. First we propose three simple but effective IR models by combining traditional IR models with topic model. Second we con-duct extensive experiments to confirm the effectiveness of our proposed models.

The remainder of this paper is organized as follows. We describe the related work and propose three topic-based hy-brid models for ad-hoc IR in Section 2 and 3 respectively. In Section 4, we set up our experimental environment on eight TREC collections. In Section 5, the experimental results are presented and discussed. Finally, we conclude our work briefly and present future research directions in Section 6.
Since the 1990s, researchers started to investigate how to integrate term association into IR models [8, 12, 16, 19, 20]. The query-term associations have been modeled by differ-ent approaches according to the distance of the query terms in documents. For example, Buttcher et al. (2006) [4] used a proximity accumulator to associate each query term. Lv and Zhai (2009) [11] proposed a positional language model (PLM) that incorporated the term proximity in a model-based approach using term-propagation functions. Metzler et al. (2005) [12] proposed a Markov Random Fields (MRF) model which modeled the joint distribution over queries and documents. Song et al. (2011) [14] proposed Proximity Probabilistic Model (PPM) which used a position-dependent term count to represent both the number of occurrences of a term and the term counts propagated from other terms. Recently, topic models have been widely used to explore latent term association in knowledge discovery and other re-lated area. Liu and Croft (2004) [10] proposed cluster-based retrieval models under the language modeling framework, which were used to smooth the probabilities in the document model. In their approach, a document is supposed to contain only one topic, which is not reasonable to model large collec-tion of documents. Azzopardi et al. (2004) [1] showed that it was effective to use the LDA model [3] to smooth the prob-abilities in the document model on several small collections. Wei and Croft (2006) [15] also discussed the applications of LDA in large collections, and presented a detailed evalua-tion of the effectiveness. Yi and Allan (2009) [17] explored t he utility of Mixture of Unigrams (MU) model, LDA and Pachinko Allocation Model (PAM) [9] for IR. They showed that topic models were effective for document smoothing. More rigorous topic models like LDA provided gains over cluster-based models and more elaborate topic models that capture topic dependencies provided no additional gains. Although it is effective to integrate topic models into the language modeling framework, how to integrate topical in-formation into other traditional IR models is not clear.
For enhancing performance, topic model is integrated into traditional retrieval models. First, the latent semantic in-formation of query terms in a document is extracted via topic modeling. Then, the term-based information is ob-tained through traditional retrieval models. The documents that are more related to the query according to both seman-tic topic-based information and term-based information are boosted in the ranking process. For clarification, Table 1 outlines the notations used throughout the paper.
T raditional retrieval models only capture term-based in-formation. On the other hand, topic models acquire seman-tic information between words. In this paper, we propose enhanced retrieval models that consider not only term fre-quency, document frequency and document length, but also term topics information. We treat term-based information and semantic topic-based information as two features for query terms. The enhanced retrieval models combine these two features.

Given a query q , for each term q i in query q , w ( q i , d ) is the enhanced weight for document d . In order to capture the two kinds of information, we use a parameter  X  to balance their importance. So the weight of a query term for a document is as follows. where w  X  X  ( q i , d ) represents the explicit term-based related information in traditional retrieval model for document d , w  X  ( q i , d ) is the implicit semantic information in topic model. Finally, a document X  X  weight for a query is given by the sum of its weight for each term in the query. When  X  equals to 0, the hybrid models become traditional IR models such as BM25 and LM. When  X  equals to 1, the hybrid models become topic models. Because traditional IR models and topic models are normalized independently, the value of  X  changes with different combinations. It is well known that BM25, MATF and Dirichlet LM are the state-of-the-art tra-ditional IR models and LDA is a simple but effective topic model. Therefore, we use BM25, MATF and Dirichlet LM as the traditional models and we use LDA as the topic model.
In general, topic model is used to capture latent seman-tic information of terms in document. There are a lot of topic models, such as probabilistic Latent Semantic Index-ing (pLSI) [7], LDA [3] and PAM [9]. LDA is a simple and effective topic model, and is broadly used. In this paper, we use LDA as our topic model.

LDA model can generate the probability of topics in a doc-ument and the probability of words in a topic, which can ob-tain the generated probability of words in a document. We take the probability of a query term in a document as its implicit semantic information in the document. The proba-bility is larger, the term is more related with the document. In order to be the same magnitude with weights in tradi-tional models, the weight of a query term for a document in LDA uses log value of the generated probability as follows. The LDA model can not be solved by exact inference and use Gibbs Sampling for parameter estimation like in [5].
Traditional information retrieval models are mainly classi-fied into classic probabilistic model, vector space model and statistical language model. There are several well-known strong baselines in each class, considering BM25, MATF and Dirichlet LM respectively.

In BM25, the weight of a query term is related to its within-document term frequency and query term frequency. The corresponding weighting function is as follows. where w  X  X  is the weight of a query term, the k i s are tuning constants and K equals to k 1  X  ((1  X  b ) + b  X  dl/avdl ).
In 2013, Jiaul H. Paik [13] proposed a novel TF-IDF term weighting scheme MATF that employed two different within document term frequency normalizations to capture two dif-ferent aspects of term saliency. One component of the term frequency is effective for short queries, while the other per-forms better on long queries. The final weight is measured by taking a weighted combination of these components, which is determined on the basis of the length of the correspond-ing query. Experiments carried out on a set of news and web datasets show that MATF outperforms several well-known state-of-the-art TF-IDF baselines with significantly large margin.

Dirichlet LM presented by Zhai and Lafferty in 2001 [18] used the likelihood probability of query terms in a document to rank relevance between query and document. In order to better computing, the weight of a query term uses the log value of the probability as follows.
We conduct experiments on eight standard collections, which include AP88-89 with queries 51-100, AP88-90 with queries 51-150, FBIS with queries 351-450, FT(91-94) with queries 301-400, LA with queries 301-400, SJMN(1991) with queries 51-150, WSJ(87-92) with queries 151-200 and WT2G with queries 401-450. These datasets are different in size and genre [15, 19]. Queries without judgments are removed. For all test collections used, each term is stemmed by using Porter X  X  English stemmer. Standard English stopwords are removed. The official TREC evaluation measure is used in our experiments, namely Mean Average Precision (MAP). To investigate top retrieved documents, P@5 and P@20 are also used for evaluation. All statistical tests are based on Wilcoxon Matched-pairs Signed-rank test.

For fair comparisons, we use the following parameter set-tings for both the baselines and our proposed models, which are popular in the IR domain for building strong baselines. First, in BM25, setting k 1 , k 3 and b to 1.2, 8 and 0.35 respec-tively gave the best MAP for most datasets in [20]. Second, in Dirichlet LM,  X  = 1000 was shown in [15] to achieve best MAP for most datasets. Finally, in LDA model, we use symmetric Dirichlet priors with  X  = 50 /K t and  X  = 0 . 01, which are common settings in the literature and shown in [15] that retrieval results were not very sensitive to the val-ues of these parameters. The number of topics K t is set to be 400 as recommended in [15].
We first investigate the performance of our proposed topic-based models compared with the corresponding strong base-lines BM25, MATF and Dirichlet LM. The experimental re-sults are presented in Table 2. As shown by the results, our proposed models outperform the corresponding baselines on almost all datasets in terms of MAP, P@5 and P@20. Sta-tistically significant improvement can be observed on most of datasets in terms of MAP and P@20. According to the results in Table 2, each hybrid model has its advantage on some aspects. However, there is no single hybird model that can achieve the best performance on all the datasets.
An important issue that may affect the robustness of our proposed models is the sensitivity of their parameter  X  to retrieval performance. Since the weights of query terms in traditional retrieval models and topic model are normalized independently, the value of  X  reflects the influence of using topic-based model. Figure 1 plots the evaluation metrics MAP obtained by the proposed hybrid models over  X  values ranging from 0 to 1 on all the datasets. It is clear that hybrid models perform better than either traditional models or topic model on all data sets. As we can see from Figure 1, our proposed models LDA-BM25, LDA-MATF and LDA-LM generally perform well over different datasets when  X  has a smaller value.

We also study the performance of our proposed topic-based models with different number of topics compared with the corresponding baselines in terms of MAP. In Figure 2, the traditional models are shown as straight lines since the performance does not change over the number of topics. All the results are presented in Figure 2, which shows that our proposed models with different number of topics outperform corresponding baselines in terms of MAP over all datasets. Figure 2 shows that the proposed hybrid models tend to perform better when the number of topics increases. When the number of topics reaches a certain value, the retrieval performance tends to become more stable. The performance tendency of our proposed models with different number of topics is surprisingly consistent on all the datasets. Similar trends for  X  and with different number of topics can also be observed in terms of P@5 and P@20.
In addition, we compare our proposed models with two state-of-the-art approaches. Zhao etc. [19, 20] showed that bigram cross term model ( CRTER 2 ) is at least comparable to major probabilistic proximity models PPM [14] and BM25TP [4] in BM25-based framework. Xing and Allan [17], which is most close to our proposed model LDA-LM, showed their LDA-based model ( LBDM ) [15] achieved the best performance in topic-based LM framework. So we make a direct compar-ison with CRTER 2 and LBDM . The results in terms of MAP are presented in Table 3.  X   X   X  denotes LDA-BM25 outper-forms CRTER 2 , while X   X   X  X enotes LDA-LM outperforms LBDM . Among eight datasets, LDA-BM25 wins five times and LDA-LM wins four times. By comparison, we can conclude that our proposed models LDA-BM25 and LDA-LM are at least comparable to the state-of-the-art models CRTER 2 and LBDM .
In this paper, a simple enhancement for ad-hoc IR is pro-posed by combining traditional retrieval model and topic model. Specifically, we present three hybrid models LDA-BM25, LDA-MATF and LDA-LM for enhancing traditional IR models via topic modeling. These three models cap-ture both term-based information and latent semantic topic-based information at the same time. Experimental results on eight standard datasets show that the proposed mod-els are effective, and outperform the corresponding strong baselines on most of datasets in terms of MAP, P@5 and P@20. Meanwhile, our proposed models are at least compa-rable to the state-of-the-art CRTER 2 and topic-based model LBDM . Additionally, we carefully analyze the influence of  X  to our proposed models and the performance of our proposed models with different number of topics.

There are several interesting future research directions to further explore. We would like to study the optimal topic number on each dataset. It is also interesting to conduct an in-depth study on the combination traditional IR model with topic model and find the best combination. We also plan to evaluate our models on more datasets including some real datasets and apply our models into real world applications. This research is supported by a Discovery grant from the Natural Sciences &amp; Engineering Research Council (NSERC) of Canada, an NSERC CREATE award and also supported by the National Natural Science Foundation of China. We thank anonymous reviewers for their thorough comments.
