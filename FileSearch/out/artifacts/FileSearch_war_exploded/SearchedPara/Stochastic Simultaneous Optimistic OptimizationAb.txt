 Michal Valko michal.valko@inria.fr Alexandra Carpentier a.carpentier@statslab.cam.ac.uk R  X emi Munos remi.munos@inria.fr We consider a function maximization problem of an unknown function f : X  X  R . We assume that every function evaluation is costly, and therefore we are in-terested in optimizing the function given a finite bud-get of n evaluations. Moreover, the evaluations are perturbed by noise, i.e., the evaluation of f at a point x t  X  X returns a noisy evaluation r t , assumed to be independent from the previous ones, such that: One motivation for this setting is a measurement error when dealing with a stochastic environment. Another example is the optimization of some parametric policy operating in a stochastic system.
 We assume that there exists at least one global max-imizer x  X   X  X of f , i.e. f ( x  X  ) = sup x  X  X  f ( x ). We aim for an algorithm which sequentially evaluates f at points x 1 ,x 2 ,...,x n in the search space X to find a good approximation to a global maximum. After n function evaluations the algorithm outputs a point x ( n ) and its performance is measured with the loss: Our definition of loss is very related to the simple regret in multi-armed bandits (Bubeck et al., 2009). Many algorithms have been developed for this general opti-mization problem. However, a lot of them require some assumption on the global smoothness of f , most typi-cally, they assume a global Lipschitz property (Pint  X er, 1995; Strongin &amp; Sergeyev, 2000; Hansen &amp; Walster, 2004; Kearfott, 1996; Neumaier, 2008). There has been also an interest in designing sample-efficient strategies, only requiring local smoothness around (one) of the global maxima (Kleinberg et al., 2008; Bubeck et al., 2011a; Munos, 2011). However, these approaches still assume the knowledge of this smoothness, i.e., the met-ric under which the function is smooth, which may not be available to the optimizer.
 Recently, Munos (2011) proposed the SOO algorithm for deterministic optimization, that assumes that f is locally smooth with respect to some semi-metric ` , but that this semi-metric does not need to be known to the algorithm. SOO extends the DIRECT algo-rithm (Jones et al., 1993) and other Lipschitz opti-mization without the knowledge of the Lipschitz con-stant (Bubeck et al., 2011b; Slivkins, 2011) to the case of any possible semi-metric by simultaneously consid-ering the subspaces that can contain the optimum. In this paper, we provide an extension of SOO to the case of noisy evaluations, which we call Stochas-tic SOO, or StoSOO . One major difference from SOO is that we cannot base our exploration strategy only on a single evaluation per cell since we are dealing with stochastic functions. Another difference is that we cannot simply return the highest evaluated point we encountered as x ( n ) since it is subject to noise. Our analysis shows that in a large class of functions (precisely defined in Section 5), the loss of StoSOO is  X  O ( n  X  1 / 2 ), which is of same order as the loss of HOO (Bubeck et al., 2011a) or Zooming algorithm (Klein-berg et al., 2008) when using the best possible metric. Optimistic optimization refers to approaches that im-plement the optimism in the face of uncertainty princi-ple. This principle became popular in the multi-armed bandit problem (Auer et al., 2002) and was later ex-tended to the tree search (Kocsis &amp; Szepesv  X ari, 2006; Coquelin &amp; Munos, 2007) where it is referred to as hi-erarchical bandit approach . The reason is that a com-plex problem such as global optimization of the space X is treated as a hierarchy of simple bandit problems. It is therefore an example of Monte Carlo tree search which was shown to be empirically successful for in-stance in computer Go (Gelly et al., 2012).
 Optimistic optimization was also used in many other domains, such as planning (Hren &amp; Munos, 2008; Bubeck et al., 2011a) or Gaussian process optimiza-tion (Srinivas et al., 2010). This paper applies opti-mistic approach to a global black-box function opti-mization. Table 1 displays representative approaches for this setting. The case when the smoothness of the function f is known, means that the function is either (globally) Lipschitz, weakly Lipschitz or locally Lips-chitz around the optimum. There are numerous algo-rithms for this setting, the most related to our work are DOO (Munos, 2011) for the deterministic case and Zooming (Kleinberg et al., 2008) or HOO (Bubeck et al., 2011a) for the stochastic one 1 . This setting has been also considered in a Bayesian framework, in par-ticular the expected-improvement strategy (Osborne, 2010) which was theoretically analyzed when the as-sumption of smoothness is data-driven (Bull, 2011). One of the disadvantages of these algorithms is that however strong or mild are the assumptions on f , the quantities that express them (i.e. a prior, a Lipschitz constant, or a semi-metric in DOO) need to be known smoothness unknown smoothness to the algorithm. On the other hand, for the case of deterministic functions there exist approaches that do not require this knowledge, such as DIRECT or SOO. However, neither DIRECT nor SOO can deal with stochastic functions. Therefore, we extend the SOO algorithm to the stochastic setting and provide a finite-time analysis of its performance. StoSOO is a tree-search based algorithm that itera-tively constructs finer and finer partition of the search space X . The partitions are represented as nodes of a K -ary tree T and the nodes are organized by their depths h  X  0, with h = 0 being the root node, and in-dexed by 1  X  i  X  K h . We denote  X  [ h,i ], the i -th node at depth h . Each of the nodes  X  [ h,i ] corresponds to a cell X h,i  X  X  in the partitioning, i.e., to a subset of X with an associated representative point x h,i  X  X  h,i . 3.1. Assumptions We now state our main assumption, which is also used in SOO (Munos, 2011). The first part of the assump-tion is about the existence of a semi-metric ` such that the function f is locally smooth with respect to it. We stress that although it quantifies the smoothness of f , it only requires the existence of ` and not the knowledge of it. For illustrative examples and discus-sion on this part we refer the reader to (Munos, 2011). The second part is about the structure of the hierar-chical partitioning with respect to ` . This partitioning is fixed and given to the algorithm as a parameter. Assumption There exists a semi-metric ` : X X X  X  IR + (i.e. for x,y  X  X , we have ` ( x,y ) = ` ( y,x ) and ` ( x,y ) = 0 if and only if x = y ) such that:
A1 (local smoothness of f ): For all x  X  X  : A2 (bounded diameters and well-shaped cells): Assumption A1 guarantees that f does not decrease too fast around one global optimum x  X  . This can be thought of as a one-sided local Lipschitz assumption. Note that although we require that (3) is satisfied for all x  X  X  , this assumption essentially sets constraints to the function f locally around x  X  , since when x is such that ` ( x,x  X  ) &gt; sup f  X  inf f , then the assumption is automatically satisfied. Thus when this property holds, we say that f is locally smooth with respect to ` around its maximum .
 Assumption A2 assures the regularity of the partition-ing, in particular that the size of the cells decreases with their depths and that their shape is not skewed in some dimensions. 3.2. Stochastic SOO Algorithm 1 displays the pseudo-code of the StoSOO algorithm. The algorithm operates in the traversals of the tree starting from the root down to the current depth( T ), that is upper bounded by h max , a parameter of the algorithm. During each traversal (a whole pass of the  X  X or X  cycle) StoSOO selects a set of promising nodes, at most one per depth h . These nodes are then either evaluated or expanded .
 Evaluating a node at time t means sampling the func-tion in the representative point x h,i of the cell X h,i and observing the evaluation r t according to (1). Expand-ing a node  X  [ h,i ], means splitting its corresponding cell into its K sub-cells corresponding to the children: We denote by L the set of leaves in T , i.e. the nodes with no children. At any time, only the leaves are eli-gible for an evaluation or expansion and we never ex-pand the leaves beyond depth h max . If the function f were deterministic, such as in SOO (Munos, 2011), we would expand (simultaneously) any leaf  X  [ h,i ] whose value f ( x h,i ) is the largest among all leaves of the same or a lower depth. The reason for this choice is that by Assumption A1 all such nodes may contain x  X  . Unfor-tunately, we do not receive f ( x h,i ), but only a noisy estimate r t . Therefore, the main algorithmic idea of StoSOO is to evaluate the leaves several times in or-der to build a confident estimate of f ( x h,i ). For this purpose, let us define  X   X  h,i ( t ) = 1 T X h,i } the empirical average of rewards obtained at Algorithm 1 StoSOO
Parameters: number of function evaluations n , maximum number of evaluations per node k &gt; 0, maximum depth h max , and  X  &gt; 0.
 Initialization: while t  X  n do end while
Output: The representative point with the highest  X   X  h,j ( n ) among the deepest expanded nodes: state x h,i at time t , where T h,i ( t ) is the number of times that  X  [ h,i ] has been sampled up to time t . StoSOO builds an accurate estimate of f ( x h,i ) before  X  [ h,i ] is expanded. To achieve this, we define an upper confidence bound (or a b -value) for each node  X  [ h,i ] as: where  X  is the confidence parameter. In the case of T h,i ( t ) = 0, we let b h,i ( t ) =  X  . We refer to p log( nk/ X  ) / 2 T h,i ( t ) as to the width of the estimate. Now instead of selecting the promising nodes accord-ing to their values f ( x h,i ) we select them according to their b -values b h,i .
 Our algorithm is optimistic since it considers such leaves for the selection whose b -value is maximal among leaves at depth h or lower depths, since those leaves are likely to contain the optimum x  X  at time t , given the observed samples and Assumption A1 on f . The important question is now how many times should we evaluate the node before we decide to expand it. Again, if we knew the semi-metric ` we would be able to calculate the appropriate count for each depth h . Since we do not know it, we instead evaluate each node a fixed number of k times before its expansion. We ad-dress the setting of k , h max , and  X  in Sections 4 and 5. Our analysis shows that under appropriate assump-tions on f (discussed in Section 5) we can bound the expected regret as E [ R n ] = O log 2 ( n ) / k = n/ log 3 ( n ), h max = p n/k , and  X  = 1 / In the algorithm, we keep track of the number of eval-uations t in order to finish when it reaches n , the maxi-mum number of evaluations, i.e., the budget. Since we are facing a stochastic setting, we cannot simply out-put the value that received the highest reward during n evaluations, as it is the case in most of the deter-ministic approaches. Instead, we return the represen-tative point x h,j of the node with the highest estimate  X   X  h,j ( n ) among the deepest expanded nodes, i.e., such that h = depth( T \L ). In this section we analyze the performance of StoSOO and upper bound the loss (2) as a function of the num-ber of evaluations. We assume that the rewards are bounded 2 by | r t |  X  1 for any t . In order to derive a loss bound we define a measure of the quantity of near-optimal states, called near-optimality dimension . This measure is closely related to similar measures (Klein-berg et al., 2008; Bubeck et al., 2008). For any  X  &gt; 0, let us write the set of  X  -optimal states as: Definition 1. The  X  -near-optimality dimension is the smallest d  X  0 such that there exists C &gt; 0 such that for any  X  &gt; 0 , the maximum number of disjoint ` -balls of radius  X  X  and center in X  X  is less than C X   X  d . StoSOO maintains the upper confidence bounds ( b -values) for each cell in order to decide which cell to sample or expand. We start by quantifying the proba-bility that all the average estimates  X   X  h,j ( t ) are at any time t within those b h,j ( t )-values. For this purpose we define the event in which this occurs and then show that this event happens with high probability. Lemma 1. Let  X  be the event under which all average estimates are within their widths:  X  = n  X  h,i,t s.t. h  X  0 , 1  X  i &lt; K h , 1  X  t  X  n, and then P (  X  )  X  1  X   X  .
 Proof. Let m denote the (random) number of different nodes sampled by the algorithm up to time n . Let  X  1 i be the first time when the i -th new node  X  [ H i ,J i ] is sampled, i.e., at time  X  1 i  X  1 there are only i  X  1 different nodes that have been sampled whereas at time  X  1 i , the i -th new node  X  [ H i ,J i ] is sampled for the first time. Let  X  s i , for 1  X  s  X  T H i ,J i ( n ), be the time when the node  X  [ H i ,J i ] is sampled for the s -th time. Moreover, we denote Y s i = r  X  s we rewrite  X  as: dom and depends on the past samples (before time  X  ) but the ( Y s i ) s are conditionally independent given this node and consequently: P  X  1  X   X  using Chernoff-Hoeffding X  X  inequality. We finish the proof by taking a union bound over all values of 1  X  i  X  n and 1  X  u  X  k .
 Lemma 1 shows that when the leaf is expanded then with high probability the mean estimate  X   X  h,j ( t ) is very close to its true value. Specifically, when the node is expanded then with probability 1  X   X  uniformly for all h,j, and t , we have that: where  X  = p log( nk/ X  ) / 2 k . We use this lemma to show that the expanded nodes are with high probabil-ity close to optimal.
 Definition 2. Let the expansion set at depth h be the set of all nodes that could be potentially expanded be-fore the optimal node at depth h is expanded: 3 I Recall that even though this definition uses w ( h ) that depends on the unknown metric ` , the StoSOO algo-rithm does not need to know it. Now, let us denote h  X  t the deepest depth of the expanded node at time t , that contains the optimum x  X  . Notice that in general the algorithm may have at time t also expanded some (sub-optimal) nodes in the deeper depths. In the following, we show that they are not too many of these. Specifi-cally, for each depth h , we lower bound the number of evaluations after which the h  X  t needs to be at least h . Lemma 2. Let depth h  X  X  0 ,h max } be any depth and: After we evaluated at least t  X  t h nodes, then in the event  X  , the depth h  X  t of the deepest node in the optimal branch is at least h , i.e., h  X  t  X  h .
 Proof. By induction on h . For h = 0, the lemma holds trivially since h  X  t  X  0. For the induction step, let us assume that the lemma holds for all h  X  { 0 ,...,h 0 } , where h 0 &lt; h max and we are to show it holds for h 0 + 1 as well. Assume we have already evaluated t h 0 +1 nodes, i.e. that we are at time t  X  t h 0 +1 . Since t h increasing in h , we have also evaluated t h 0 nodes and h t  X  h 0 from the induction step. That means that the optimal branch is expanded at least up to the depth h . Now consider any node  X  [ h 0 + 1 ,i ] at depth h 0 + 1, that was expanded. If it was expanded before the optimal node  X  [ h 0 +1 ,i  X  ] at depth h 0 +1 was expanded, the average estimates  X   X  h,j ( t ) are at most  X  away from their true values, with  X  defined in (6). Therefore in the event  X  , the true values of the expanded and the optimal node are at most 2  X  apart: Since the node  X  [ h  X  t + 1 ,i  X  ] contains the optimum x then by Assumptions A1-2, we get: Combining this with (7), we obtain that: This means that all the nodes  X  [ h 0 + 1 ,i ] expanded Definition 2, there are exactly | I  X  h 0 +1 | such nodes. Each traversal of the tree in the StoSOO algorithm selects one of these nodes for evaluation. Since k evaluations are required before the expansion, after expanded. To guarantee this many traversals, we need ations. This is equal to t h 0 +1 and thus h  X  t  X  h 0 + 1. Lemma 2 bounds the number of needed evaluations in the terms of the expansion set sizes to assure that the optimal node was expanded. Naturally, we would like to know, how big these expansion sets can be. The following lemma upper bounds the size of expansion sets up to depth where w ( h ) is of the order of  X  . For this purpose, we define h  X  as: Lemma 3. Let d be a  X / 3 -near-optimality dimension and C the related constant. Then for each h  X  h  X  , the cardinality of the expansion set at depth h is in the event  X  bounded as: Proof. By contradiction. Assume that for some h  X  h each representative point x h,i of the node  X  [ h,i ] is [ w ( h ) + 2  X  ]-optimal. By Assumption A2, each cell as-sociated with the node  X  [ h,i ] at depth h contains a the representative point x h,i , because for h  X  h  X  , we have that  X   X  w ( h ) by (8). Since the cells are disjoint, we have a contradiction with  X / 3-near-optimality di-mension being d .
 We now link the depth of the tree after n iterations with the loss as defined in (2).
 Theorem 1. Assume that Assumptions A1-2 hold. Let d be the  X / 3 -near-optimality dimension and C be the corresponding constant. Then the loss of StoSOO run with parameters k , h max , and  X  &gt; 0 , after n iter-ations is bounded, with probability 1  X   X  , as: where  X  = p log( nk/ X  ) / (2 k ) and h ( n ) is the smallest h  X  N , such that: Proof. Let us first consider the case when h ( n )  X  1  X  h . Then we can use Lemma 3 to show that: If h ( n )  X  1  X  h max then by Lemma 2, h  X  n  X  h ( n )  X  1. If, however, h ( n )  X  1 &gt; h max , then by (9) the algo-rithm has expanded all potentially optimal nodes on the level h max and therefore h  X  n  X  h max . Nonetheless the algorithm does not go beyond h max , so necessarily h n = h max . Hence, in the case when h ( n )  X  1  X  h  X  , h n  X  min { h ( n )  X  1 ,h max } . Now consider the op-posite case, i.e., when h ( n )  X  1  X  h  X  + 1. We can now use Lemma 3, but only up to depth h  X  , to get that n &gt; t h  X  . Similarly to the previous case, we de-duce that h  X  n  X  min { h  X  ,h max } . Altogether, h  X  that has been expanded after n evaluations. We know at the depth h  X  n . As  X  [ h,j ] was expanded, the true value of its representative point and the representa-tive point of  X  [ h  X  n ,i  X  ] is in the event  X  at most 2  X  away and therefore we conclude that: We now deduce the following corollaries for the case when the near-optimality dimension d = 0 and the di-ameters w ( h ) are exponentially decreasing. We post-pone the discussion about this important case d = 0 to Section 5.1.
 Corollary 1. Assume that the diameters of the cells decrease exponentially fast, i.e., w ( h ) = c X  h for some c &gt; 0 and  X  &lt; 1 . Assume that the  X / 3 -near-optimality dimension is d = 0 and let C be the corresponding constant. Then the expected loss of StoSOO run with parameters k , h max = p n/k , and  X  &gt; 0 , is bounded as:
E [ R n ]  X  (2 + 1 / X  )  X  + c X  Proof. When d = 0, then w ( l ) + 2  X   X  d = 1 and by definition of h ( n ), we have that n  X  C ( k + which implies h ( n )  X  n/ ( C ( k +1) h max )  X  1. Intuitively, the deeper is the node we return, the lower regret we can incur. This suggests the choice of h max = p n/k , in which case we get h ( n )  X  k  X  1. Moreover, since w ( h ) = c X  h , then by definition of h  X  we have that: By Theorem 1, we have that in the event  X  , the regret of StoSOO is at most: We obtain the upper bound on the expected loss (10), by considering that by Lemma 1,  X  holds with proba-bility 1  X   X  and | r t | X  1.
 Corollary 2. For the choice k = n/ log 3 ( n ) and  X  = 1 /  X  This result shows that, surprisingly, StoSOO achieves the same rate  X  O ( n  X  1 / 2 ), up to a logarithmic factor, as the HOO algorithm run with the best possible metric, although StoSOO does not requires the knowledge of it. Proof. Setting k = n/ log 3 ( n ) and  X  = 1 / upper bound  X  in (10) which was defined in (6) as:  X  = Now for n bigger than a quantity exponential in C/ log(1 / X  ), the second term in (10) becomes negli-gible and the upper bound for this choice follows. 5.1. Some intuition about the case d = 0 We have seen that the near-optimality dimension d is a property of both the function and the semi-metric ` . Since StoSOO does not require the knowledge of the semi-metric ` (it is only used in the analysis), one can choose the best possible semi-metric ` , possibly according to the function f itself , in order to have the lowest possible value of d . The case d = 0 thus corresponds to the following assumption on f : there exists a semi-metric ` such that: 1) f is locally smooth w.r.t. ` around a global optimum x  X  (i.e. such that (3) holds) 2) the diameters of the cells (measured with ` ) decrease exponentially fast, and 3) there exists C &gt; 0 such that for any  X  &gt; 0, the maximal number of disjoint ` -balls of radius  X  X / 3 centered in X  X  is less than C (i.e. the near-optimality dimension d is 0). 5.2. Examples Let us consider the case of functions f defined on [0 , 1] D that are locally equivalent to a polynomial of degree  X  around their maximum, i.e., f ( x )  X  f ( x  X  ) =  X ( k x  X  x  X  k  X  ) for some  X  &gt; 0, where k X k is any norm. The choice of semi-metric ` ( x,y ) = k x  X  y k  X  implies that the near-optimality dimension d = 0. This covers already a large class of functions (such as the functions plotted in Figure 1: the two-sine product function for which  X  = 2 and the non-Lipschitz garland function for which  X  = 1 / 2).
 More generally, we consider a finite dimensional and bounded space, i.e., such that X can be packed by C
X  X   X  D ` -balls with radius  X  (e.g., Euclidean space [0 , 1] D ) and such that X has a finite doubling constant (defined as minimum value q such that every ball in X can be packed by at most q balls in X of half the radius). Let a function in such space have upper-and lower envelope around x  X  of the same order (Figure 2), i.e., there exists constants c  X  (0 , 1), and  X  &gt; 0, such that for all x  X  X  : We show that all such functions have a near-optimality dimension d = 0 according to Definition 1, (where  X  = 1 for simplicity), which means that for all  X  &gt; 0, the packing number of X  X  is upper-bounded by a constant. In the case when  X  &lt;  X  , due the upper envelope we have that: X  X   X  { x : c` ( x,x  X  )  X   X  } , which corre-sponds to an ` -ball centered in x  X  with radius  X /c . This ball can be packed by no more than a constant number of C 0 ` -balls of radius  X  . C 0 is necessarily finite because the doubling constant q is finite. For example in [0 , 1] D , if ` ( x,y ) = k x  X  y k  X  then C 0 = (1 /c ) In the opposite case when  X   X   X  , the radius of dis-joint ` -balls that could possibly pack X  X  is at least  X  . Noting that X  X   X  X , we can upper bound the packing number of the whole space X , by a constant C X (  X  )  X  D that is independent of  X  . Finally, defining C = max { C 0 ,C X (  X  )  X  D } we have that for all  X  , the maximum number of disjoint ` -balls of radius  X  and center in X  X  is less than a C and therefore d = 0. Even more generally, one can even define the semi-metric ` according to the behavior of f around x  X  in order that (3) holds. For example if the space X is a normed space (with norm k X k ), one can define the metric ` ( x,y ) def =  X  ` ( k x  X  y k ) for any r  X  0 as: Thus f ( x  X  )  X  ` ( x,x  X  ) naturally forms a lower-envelope of f . Thus assuming that the first inequality of (11) (upper-envelope) holds, then d = 0 again.
 However, although the case d = 0 is quite general, it does not hold in situations where there is a discrepancy between the upper-and lower-envelopes (Figure 3). In this section we numerically evaluate the perfor-mance of StoSOO 4 . In all experiments with set the pa-rameters k ,  X  , and h max to the values from Corollary 2. Moreover, we set the branching factor to K = 3. Note that when the branching factor is an odd num-ber ( K  X  3), we can reuse the evaluations (samples) from the parent node. Indeed, if K is odd, the repre-sentative point of the parent node  X  [ h,i ] will have the same value as the middle child  X  [ h + 1 , ( K + 1) / 2], i.e., x is multi-dimensional, we only need to split along one dimension at the time, when expanding the node. In order to preserve bounded diameters assumption, we can split each time along the dimension in which the cell is the largest.
 For the evaluation we added a truncated (so that re-wards are bounded) zero mean Gaussian noise N T , sample of which is shown in Figure 4. In all the ex-periments we performed 10 trials and the error bars in the figures correspond to standard deviations. Two-sine product: In the first set of experiments we consider a two-sine product function displayed in Figure 1 (left) maximized for f (0 . 867526)  X  0 . 975599. Figure 5 displays the performance of StoSOO for differ-ent levels of noise. We observe that as we increase the number of evaluations, the regret of StoSOO decreases. In Figure 6, we compare StoSOO to the straightfor-ward stochastic version of DOO (Munos, 2011), where we expand each node after log( n 2 / X  ) / (2 w ( h ) 2 ) evalua-tions (i.e. when the size of the confidence interval be-comes smaller than the di-ameter w ( h ) of the cell).
 However, (stochastic) DOO needs to know the semi-metric ` in order to define w ( h ). We evaluate the performance of this stochastic DOO using two semi-metrics that satisfy Assumption A1: ` 1 ( x,y ) = 12 | x  X  y | (for which d = 1 / 2) and ` 2 ( x,y ) = 144 | x  X  y | which d = 0). We observe that StoSOO performs as well as stochastic DOO for the better metric without the knowledge of it.
 Garland function: Next, we consider a garland func-tion displayed in Figure 1 (right). The optimization of this function is challenging because f 2 is not Lipschitz for any L . However its near-optimality dimension is still d = 0 (Section 5.2). Figure 7 shows the perfor-mance of StoSOO as we vary the number of the eval-uations. Notice a higher variance at iteration 200 in the left plot; this is because for that many iterations, StoSOO was able to reach the depth h = 6 but only for a few nodes (while only h = 5 for less iterations) with small number of d 200 / (log 3 (200)) e = 2 evaluations. We presented the StoSOO algorithm that is able to optimize black-box stochastic functions, without the knowledge of their smoothness. We derived a finite-time performance bound on the expected loss for the important case when there exists a semi-metric such that the near-optimality dimension d = 0. We showed that this case corresponds to a large class of functions. In such cases, the performance is almost as good as with an algorithm that would know the best valid semi-metric. In the future we plan to derive finite-time per-formance for the case d &gt; 0. This research work presented in this paper was sup-ported by European Community X  X  Seventh Framework Programme (FP7/2007-2013) under grant agreement n o 270327 (project CompLACS).
 Auer, Peter, Cesa-Bianchi, Nicol`o, and Fischer, Paul. Finite-time Analysis of the Multiarmed Bandit Problem. Machine Learning , 47(2-3):235 X 256, 2002. Bubeck, S  X ebastien, Munos, R  X emi, Stoltz, Gilles, and Szepesv  X ari, Csaba. Online Optimization of X-armed
Bandits. In Advances in Neural Information Pro-cessing Systems , pp. 201 X 208, 2008.
 Bubeck, S  X ebastien, Munos, R  X emi, and Stoltz, Gilles. Pure Exploration in Multi-armed Bandits Problems. Algorithmic Learning Theory , pp. 23 X 37, 2009. Bubeck, S  X ebastien, Munos, R  X emi, Stoltz, Gilles, and Szepesvari, Csaba. X-armed bandits. Journal of Machine Learning Research , 12:1587 X 1627, 2011a. Bubeck, S  X ebastien, Stoltz, Gilles, and Yuan, Yu-
Jia. Lipschitz bandits without the Lipschitz con-stant. In Algorithmic Learning Theory , pp. 144 X 158. Springer, 2011b.
 Bull, Adam. Convergence rates of efficient global optimization algorithms. The Journal of Machine Learning Research , 12:2879 X 2904, 2011.
 Coquelin, Pierre-Arnaud and Munos, R  X emi. Bandit
Algorithms for Tree Search. In Uncertainty in Arti-ficial Intelligence , pp. 67 X 74, 2007.
 Gelly, Sylvain, Kocsis, Levente, Schoenauer, Marc, Se-bag, Mich`ele, Silver, David, Szepesv  X ari, Csaba, and Teytaud, Olivier. The grand challenge of computer
Go: Monte Carlo tree search and extensions. Com-mun. ACM , 55(3):106 X 113, March 2012.
 Hansen, Eldon and Walster, William. Global Opti-mization Using Interval Analysis: Revised and Ex-panded . Pure and Applied Mathematics Series. Mar-cel Dekker, 2004.
 Hren, Jean-Francois and Munos, R  X emi. Optimistic Planning of Deterministic Systems. In European
Workshop on Reinforcement Learning , pp. 151 X 164, 2008.
 Jones, David, Perttunen, Cary, and Stuckman, Bruce.
Lipschitzian optimization without the Lipschitz con-stant. Journal of Optimization Theory and Applica-tions , 79(1):157 X 181, 1993.
 Kearfott, R Baker. Rigorous Global Search: Continu-ous Problems . Nonconvex Optimization and Its Ap-plications. Springer, 1996.
 Kleinberg, Robert, Slivkins, Alexander, and Upfal, Eli. Multi-armed bandit problems in metric spaces. In Proceedings of the 40th ACM symposium on Theory Of Computing , pp. 681 X 690, 2008.
 Kocsis, Levente and Szepesv  X ari, Csaba. Bandit based Monte-Carlo Planning. In Proceedings of the 15th
European Conference on Machine Learning , pp. 282 X 293. Springer, 2006.
 Munos, R  X emi. Optimistic Optimization of Determinis-tic Functions without the Knowledge of its Smooth-ness. In Advances in Neural Information Processing Systems , pp. 783 X 791, 2011.
 Neumaier, Arnold. Interval Methods for Systems of Equations . Encyclopedia of Mathematics and its Applications. Cambridge University Press, 2008. Osborne, Michael. Bayesian Gaussian processes for sequential prediction, optimisation and quadrature . PhD thesis, University of Oxford, 2010.
 Pint  X er, J  X anos. Global Optimization in Action: Contin-uous and Lipschitz Optimization: Algorithms, Im-plementations and Applications . Nonconvex Opti-mization and Its Applications. Springer, 1995. Slivkins, Aleksandrs. Multi-armed bandits on implicit metric spaces. In Advances in Neural Information Processing Systems 24 , pp. 1602 X 1610. 2011.
 Srinivas, Niranjan, Krause, Andreas, Kakade, Sham, and Seeger, Matthias. Gaussian Process Optimiza-tion in the Bandit Setting: No Regret and Exper-imental Design. Proceedings of International Con-ference on Machine Learning , pp. 1015 X 1022, 2010. Strongin, Roman and Sergeyev, Yaroslav. Global Opti-mization with Non-Convex Constraints: Sequential and Parallel Algorithms . Nonconvex Optimization
