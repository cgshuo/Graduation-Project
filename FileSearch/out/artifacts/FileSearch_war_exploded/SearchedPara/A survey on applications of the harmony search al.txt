 1. Introduction
The application of optimization algorithms to real world problems has gained momentum in the last decade. Dating back to the early 1940s, diverse traditional mathematical methods such as linear programming (LP), nonlinear programming (NLP) or dynamic pro-gramming (DP) were fi rst employed for solving complex optimiza-tion problems by resorting to different relaxation methods of the underlying formulation. These techniques are capable of cost-ef fi ciently obtaining a global optimal solution in problem models subject to certain particularities (e.g. optimal substructurability and subproblem overlap for dynamic programming), but unfortunately their application range does not cover the whole class of NP-complete problems, where an exact solution cannot be found in polynomial time. In fact, the solution space (and hence, the solving time) of the problem increases exponentially with the number of inputs, which makes them unfeasible for practical applications.
In order to cope up with the above shortcoming, meta-heuristic techniques  X  conceived as intelligent self-learning algorithms stem-ming from the study and mimicking of intelligent processes and behaviors arising in nature, sociology and other disciplines (see Fig. 1 for a general overview)  X  have come into sight for ef fi ciently tacking this type of hard optimization paradigms. In many cases (especially when large-scale problems are addressed), meta-heuristics are deemed one of the most ef fi cient alternatives to seek and deter-mine a near-optimal solution 1 without relying on exact yet computationally demanding algorithms, and by overcoming the major drawback of local search algorithms, i.e. getting trapped in biased local regions far from the sought global solution. Indeed, on the latter lies one of the main design challenges of modern meta-heuristic methods: to avoid local optima so as to get global optima, which can be achieved by exploring the whole search space through the use of intelligent stochastically driven operators. On this purpose, it is of utmost importance for enhancing the overall search performance of the meta-heuristic to balance the tradeoff between two important related aspects: diversi fi cation and inten-si fi cation. On one hand, diversi fi cation refers to a form of rando-mization added to the deterministic components driving the algorithm operation in order to explore the search space in a diverse manner, while intensi fi cation stands for the improvement of existing partial solutions to the problem by exploring the vicinity of such solutions in the region space (e.g. by means of elitism mechanisms). If diversi fi cation is strong enough, a great number of zones of the search space may be loosely explored, which will reduce the convergence rate of the algorithm. By contrast, if diversi fi cation is kept low in the algorithm design, there is a signi fi cant risk of leaving a fraction of the solution space unex-plored or even producing far-from-optimal solutions due to trap-ping in local optima. An appropriate intensi fi cation is carried out by means of exploiting the knowledge acquired from past solu-tions, and by properly fi ne-tuning the parameters that control the performance of the algorithm for a particular problem so as to enhance its convergence properties.

Based on the above rationale, the last four decades have witnessed the advent and rise of new innovative meta-heuristic algorithms, grouped on many branches based on their working methodology, and applied to a wide variety of different optimization problems such as resource allocation , industrial planning, scheduling, decision making, medical, engineering and computer science appli-cations, among many others. Many of them are actually inspired by natural phenomena and have been developed by mimicking the intelligence characteristics of biological and physical agents such as
Genetic Algorithms, Cuckoo Search, Ant Colony Optimization, Simu-lated Annealing, Particle Swarm Optimization or Harmony Search.
The main difference among existing meta-heuristics concerns (1) the way diversi fi cation and intensi fi cation are mutually balanced in the algorithm thread; (2) the search path they follow; and/or (3) the observed phenomena that inspires the algorithm design. Another characteristic of meta-heuristic algorithms is the distinction between memory usage versus memoryless methods, as well as the de of population-based and single-poi nt search-based strategies. For instance, in Ant Colony Optimization a memory of previously obtained solutions is kept in the pheromone trail matrix in order to construct new re fi ned solutions. Likewise, the population in
Genetic Algorithms can be regarded as a memory register of recently encountered partial solutions. On the contrary, Simulated Annealing exempli fi esthecaseofamemorylessalgorithminwhichnorecordof past solutions is employed.

In contrast to single-point search-based algorithms in which a unique solution is generated at each iteration, population-based meta-heuristic algorithms maintain a set of solutions (i.e. popula-tion) which evolve at each iteration. Therefore, population-based algorithms provide an ef fi cient and natural way for exploring the search space and obtaining an acceptable solution. Interestingly,
Memetic Algorithms hybridize these two strategies in order to balance the diversi fi cation and intensi fi cation of its search procedure. Most of single-point search algorithms such as Simu-lated Annealing and Tabu Search are based on a single neighbor-hood structure which de fi nes the allowed movements through the search space. However, Iterated Local Search algorithms normally de fi ne two different neighborhood structures among which the algorithm shifts when reaching a local optimum.
 comparative analysis with respect to other meta-heuristics, and a detailed report of recent applications and associated develop-ments attained during the last few years. This review allows the interested reader not only to get a clear insight on the design and working principles of this algorithm, but also to identify technical advances and application trends of Harmony Search in diverse fi elds. To ful fi ll these goals, the manuscript is structured as follows: once the structure and steps of the original algorithm have been posed in Section 1.1 , its intrinsic characteristics are analyzed and compared to other meta-heuristics in Section 1.2 .
Then, an overview of its application areas and an outline of current trends in such fi elds is tackled by classifying the applications cases in the related literature by discipline area, and by highlighting the modi fi cations and improvements of each particular fi eld in
Sections 2 and 3 . Finally, Section 4 draws some concluding remarks and outlines several future research lines of interest. 1.1. Fundamentals of the harmony search algorithm based meta-heuristic algorithm which has obtained excellent results in the fi eld of combinatorial optimization ( Geem, 2000 ).
It mimics the behavior of a music orchestra when aiming at composing the most harmonious melody, as measured by aes-thetic standards. When comparing the improvisation process of musicians with the optimization task, we can realize that each musician corresponds to a decision variable; the musical instru-ment ' s pitch range refers to the alphabet of the decision variable; the musical harmony improvised at a certain time corresponds to a solution vector at a given iteration; and audience ' s aesthetic impression links to the objective function of fi tness of the optimization problem at hand. Just like musicians improve the melody time after time, the HS algorithm progressively enhances the fi tness of the solution vector in an iterative fashion.

As previously mentioned, HS is a population-based algorithm; it hence maintains a set of solutions in the so-called Harmony
Memory (HM). An estimation of the optimal solution is achieved at every iteration by applying a set of optimization parameters to the HM, which produces a new harmony vector every time. Fig. 2 illustrates the fl ow diagram of the HS algorithm, which can be summarized in four steps: (i) initialization of the HM; (ii) impro-visation of a new harmony; (iii) inclusion of the newly generated harmony in the HM provided that its fi tness improves the worst fi tness value in the previous HM; and (iv) returning to step (ii) until a termination criteria (e.g. maximum number of iterations or fi tness stall) is satis fi ed.

The above improvisation procedure is mainly controlled by two different probabilistic operators, which are sequentially applied to each note so as to produce a new set of improvised harmonies or candidate solutions:
The Harmony Memory Considering Rate, HMCR  X   X  0 ; 1 , estab-lishes the probability that the new value for a certain note is drawn uniformly from the values of this same note in all the remaining melodies. Otherwise (i.e. with a probability 1  X 
HMCR), the note values are randomly chosen according to their alphabet. This case is commonly referred to as random consideration , as it increases the diversity of the solutions towards the global optimality; however, some works (e.g. Gil-
Lopez et al., 2011 ) implement the random consideration as a third, separated probabilistic operator.

The Pitch Adjusting Rate, PAR  X   X  0 ; 1 , establishes the probability that the new value x new for a given note value x is obtained by adding a small random amount to the existing value x old .
For continuous alphabets, this operation reduces to where  X  x represents the pitch bandwidth, and  X  is a random number drawn from an uniform distribution with support  X   X  1 ; 1 . A low pitch adjusting rate with a narrow bandwidth may restrict the diversi fi cation of the algorithm within a small search subspace and consequently, decrease the convergence rate of the overall solver. On the other hand, a high pitch adjusting rate with a high value of  X  x may force the algorithm to unnecessarily escape from areas with potentially near-optimal solutions. When dealing with discrete alphabets, a similar de fi nition holds for this PAR operator, the difference being that the underlying alphabet must be sorted under some vicinity ordering criteria, which in general depends roughly on the characteristics of the metric de fi ning the problem at hand.
By analyzing these parameters in detail, it can be identi how the HS algorithm balances diversi fi cation and intensi Both the pitch adjusting rate and the random consideration parameter control the diversi fi cation factor. The pitch adjustment can be essentially viewed as a re fi nement process of local solu-tions, while the randomization procedure allows examining the search space in a more explorative fashion. The intensi fi the HS algorithm is represented by the harmony memory con-sidering rate, which fi xes the level of elitism, i.e. the amount of solutions from the harmony memory to be kept for subsequent generation. If the considering rate is set to a low value, the algorithm will converge slowly to the optimum solution; however, a high HMCR value will favor the intensi fi cation based on the knowledge contained in the present harmony memory, but at the risk of trapping the algorithm into local optima. In summary, it is essential to properly adjust the parameters controlling the above operators in order to boost the algorithm performance. 1.2. Intrinsic characteristics and comparison to existing algorithms
Given their strong dependency on the shape of the solution space drawn by the metric function at hand, the outperforming convergence and behavior of any meta-heuristic algorithm cannot be claimed in a general manner, but instead needs to be assessed by focusing on a certain problem, along with the side constraints that may hold in the mathematical formulation at hand. Therefore, even though a globally optimal algorithm that renders the best performance in all optimization schemes does not exist (in line with the statements of the so-called No Free Lunch Theorem Wolpert and MacReady, 1997 ), the HS algorithm has so far elucidated in practice a great potential and ef fi ciency in compar-ison with other meta-heuristic methods in a wide spectrum of real applications. HS possesses a similar structure to other existing population-based meta-heuristic solvers, but it incorporates some distinctive features that make it widely utilized in the literature. Similarly to other related population-based algorithms, i.e. Genetic Algorithms or Ant Colony Optimization, the HS relies on a group of solutions that can be simultaneously exploited for improving the ef fi ciency of the algorithm. However, the na X ve Genetic Algorithm considers only two vectors (referred to as parents ) for generating a new solution or offspring, whereas the original implementation of HS takes into account, component-wise and on a probabilistic basis, all the existing solutions (melodies) in the harmony memory. Nevertheless, further mod-i fi cations of the na X ve Genetic Algorithm have been proposed in the literature, such as the multi-parent crossover. It modi original formulation of the algorithm to take into account more than two individuals in the generation of the new population. On the contrary, the HS Algorithm, in its original version, is able to infer new solutions merging the characteristics of all individuals by simply tuning the values of its probabilistic parameters.
Besides, it independently operates on each constituent variable ( note ) of a solution vector ( harmony ), to which stochastic operators for fi ne-tuning and randomization are applied. As opposed to gradient-search techniques, the convergence rate of HS and the quality of its produced solutions are not dramatically affected by the initialized values of the constituent melodies in the harmony memory. Besides, HS utilizes a probabilistic gradient which, in contrast to traditional gradient-based mathematical methods, does not require the derivative of the fi tness function to be analytically solvable, nor even differentiable over the whole solution space. Instead, the probabilistic gradient converges to progressively better solutions iteration by iteration, since the operators driving the algorithm behavior intelligently guide the harmony memory to regions of the solution space with better fi tness without addressing at all the differentiability of the metric function. As a result, HS has been shown to perform satisfactorily in both continuous and discrete optimization problems: indeed, it is able to handle both decimal and binary alphabets without modifying the de fi nition of the original HMCR and PAR parameters of the algorithm.

Another remarkable strength of HS hinges on its improvisation operators, which play a major role in achieving a good trade-off between diversi fi cation and intensi fi cation. As mentioned before, the correct choice of the parameters becomes essential in order to attain progressively better candidate solutions, and HS facilitates this re fi nement stage by signi fi cantly reducing the number of con fi gurable parameters. In addition, the steps and the structure of the HS algorithm are relatively simple, which makes it fl its combination with other meta-heuristics ( Fesanghary et al., 2008 ) and implementation in parallel hardware architectures.
Consequently, since the advent of this algorithm, the research community has thoroughly proposed and examined variants of HS based on incorporating new components into the HS structure and/or hybridizing it with other solvers so as to improve its searching capabilities. 2. Application areas
Originally, applications where HS was fi rst assessed as an effective meta-heuristic focused mainly on the design of water distribution networks ( Geem, 2006 ), benchmark optimization ( Li and Li, 2007 ), structural design ( Lee et al., 2005 ) and vehicle routing problems ( Geem, 2005 ; Geem et al., 2005 ). In 2004 a fl owchart representation of HS was published in Lee and Geem (2004) and since then several studies were devoted to the development of new HS variants and hybridizations with other meta-heuristic algorithms ( Li et al., 2005 ). Since then, the activity around this algorithm has increased sharply, spanning its applic-ability to a very heterogeneous portfolio of application scenarios.
This section presents an overview of the discipline areas in which the HS algorithm has been applied during recent years. presented in the following sections, Fig. 3 depicts the current approximate distribution of areas of HS application as measured by the number of publications of each particular topic. This literature survey is based on a reference repository including 160 papers indexed during the last years in relevant scienti fi c databases such as Elsevier, IEEE and Springer. As shown in this fi gure, the range of activity spans from engineering problems  X  which comprise a great portion (31%) of the related literature  X  to variants of the HS algo-rithm (23%), which have also acquired a notable importance. In
Table 1 the distinct areas of activity are presented together with a classi fi cation of articles from recent years. 3. Overview of HS applications by application area areas by describing some of the optimization challenges arising therein, as well as analyzing the modi fi cations done to the original
HS algorithm in order to ef fi ciently cope with such problems. 3.1. HS and its variants reviewed in this manuscript incorporates some modi fi cation to the original HS algorithm in Geem et al. (2001) without targeting any speci fi c application scenario. These variants include (1) alternative initialization procedures for the HM; (2) variable parameters for the improvisation procedure; (3) options for handling constraints when generating new harmonies; (4) different criteria for and selecting new harmonies for the HM; (5) distinct termination criteria; and fi nally (6) modi fi cations in the structure of the algorithm by adding or removing blocks or hybridizing it with other existing heuristics. Reviews on the existing HS fl avors abound in the literature, e.g. Alia and Mandava (2011) and references therein. Yet far from the application-oriented perspec-tive on which this manuscript is intended to focus, this subsection aims at shedding some light on several modi fi cations of the nominal HS algorithm grounded on recent bibliographic examples.
Nevertheless, the authors recommend to resort to any of the previously cited reviews to get a broader insight on HS variants.
A research work exemplifying different HS modi fi cations can be found in Al-Betar et al. (2012a) , where a hybrid HS algorithm is used in order to tackle the so-called university course timetabling problem (UCTP). This problem is considered to be a hard combi-natorial optimization problem based on allocating a set of events to a set of rooms and time slots. The algorithm presented in this work builds on the hybridization of HS and a local search approach in order to reach a balance between diversi fi cation and intensi cation of the search procedure on the solution space. Speci classical Hill Climbing approach is combined with the global search process performed by HS so as to improve the local intensi fi cation of the overall solver. In addition, a global-best
Particle Swarm Optimization approach is further incorporated in order to achieve a best convergence rate than that rendered by the
HMCR operator. Other considerations and adjustments to the original HS algorithm performed in Al-Betar et al. (2012a) include (1) novel repair methods for maintaining the feasibility of the solutions in the HM; and (2) a modi fi cation of the PAR procedure under which only pitch adjustments improving the quality of the produced solutions are accepted. Besides, the hybridization of the algorithm changes the behavior of the original HMCR operator; instead of randomly selecting harmonies (which may exclude the best solutions from the HM and consequently, decrease the convergence rate), in this scenario this parameter is designed so as to keep the feasibility of existing solutions. Additionally, a local optimizer based on a Hill Climbing approach is introduced in this hybrid scheme in an attempt at guaranteeing the fi ne-tuning of the new harmonies and the avoidance of getting stuck in local optima.

Another modi fi cation widely adopted for improving the per-formance of the HS algorithm hinges on imposing a certain progression along iterations on the values of its operational parameters of HMCR and PAR. For instance, an improved harmony search algorithm that uses variable PAR and a pitch bandwidth in the improvisation step is proposed in Coelho and Bernert (2009) for the tuning of a proportional integral derivative (PID) controller aimed at the synchronization of two identical discrete chaotic systems. The value of the PAR is dynamically updated according to PAR  X  t  X  X  PAR min  X  X  PAR max  X  PAR min  X   X   X  t  X  X  2  X  where PAR min and PAR max are minimum and maximum values of the adjusting rate, and PAR  X  t  X  is the pitch adjusting rate for iteration t . The grade  X   X  t  X  is calculated based on the maximum and minimum objective function values in iteration t , denoted as  X   X  t  X  and  X  l  X  t  X  , namely  X   X  t
 X  X   X  h  X  t  X   X   X   X  t  X   X  where  X   X  t  X  stands for the average value of the objective function value computed over the whole harmony memory. Other progres-sion rules proposed in the literature range from purely linear to more involved logarithmic models driven by a single concavity parameter ( Del Ser et al., 2012 ).

In order to cope with realistic design situations, Geem (2007) proposed a novel derivative for discrete design variables based on the HS algorithm. In such a reference, the HS can ultimately the optimal solution or near-optimal solutions by the help of the stochastic derivative for discrete variables. Based on the contents of the HM at a given iteration of the algorithm, the stochastic derivative for discrete variables provides the algorithm with information on the probability of selecting optimal values, which in general increases progressively along the iterations. While the traditional calculus-based derivative generates information on the search direction and step size for a function of continuous variables, the stochastic derivative utilized in this work computes the probabilistic trend of the algorithm to select a certain discrete point based on multiple vectors stored in the HM for a function of discrete variables. This approach evidences that optimal and neighboring values have higher chances to be selected along the iterative process.

To conclude with, an interesting contribution focused on deriving a new variant of this algorithm from a simple yet intuitive mathematical analysis on its exploratory behavior ( Das et al., 2011 ). In this work Das et al. analytically show that the standard deviation of the na X ve HS algorithm computed over the harmony memory can be used as a proportionality factor for adaptively controlling the bandwidth  X  x . This approach introduces no addi-tional complexity burdens to the original HS framework, and is assessed, through computer simulations over a benchmark of unconstrained and constrained numerical problems, to outper-form other HS variants and well-known evolutionary counterparts. 3.2. Engineering
Let us start with the application-oriented review by addressing uses of the HS algorithm in problems related to engineering disciplines, where this solver has been reported to be a viable alternative to other conventional optimization techniques. Hence, it has been broadly utilized in complex optimization problems arising in most engineering applications such as design optimiza-tion of heat exchangers, steel, electronic, mechanical, telecommu-nication, construction and engineering structures problems, among others. In the next subsections different problems stem-ming from several of these engineering areas and their solving via
HS heuristics are described in detail. 3.2.1. Steel
Typical steel engineering problems involve structural design optimization problems. Such problems generally require the selection of steel sections for its beams and columns under the criteria that the frame satis fi es the serviceability and strength requirements while minimizing the material cost of the frame.
In addition to the budget constraint, this selection is commonly carried out in such a way that the steel frame has the minimum weight.

The problem presented in Saka (2009b) falls into discrete optimization problems in which fi nding the optimum feasible solution results in a dif fi cult task. The proposed design algorithm imposes the behavior and performance constraints in accordance with BS5950 (British Standard for the design, fabrication and erection of structural steelwork). In this approach, the BS5950 imposes eight restrictions to the structures that limit the de tions in beams, weight of the steel section, the horizontal de tion of columns due to imposed load and wind loads, among others. The HS algorithm implemented in this paper follows the traditional scheme and adds a repair procedure for the harmonies that violate the problem constraints. The initialization step gen-erates random values for each note within the speci fi ed alphabet for each design variable. During the iterative process, unfeasible solutions are accepted following a novel method; once the new harmony vector is obtained, it is then checked whether it violates the problem constraints. If the new harmony vector is severely unfeasible, it is discarded, whereas if it is slightly unfeasible, there are two ways to be followed: the fi rst reduces to including it in the harmony memory by imposing a penalty on its associated fi value. Thereby, the violated harmony, which is slightly unfeasible in any or several of its constraints, is used as a basis for the pitch adjustment operation to provide a new feasible harmony. The other option is to resort to larger tolerance values for the accept-ability of the new unfeasible harmonies, and reduce this tolerance gradually during the iterative process. This adaptive error strategy results to be quite effective when handling the constraints estab-lished in this design problem.
 involves the optimum design of cellular beams, i.e. the hole diameter, the total number of holes in the beam, and the sequence number of Universal Beam section, in order to obtain the mini-mum weight of the cellular beam ( Erdal et al., 2011 ). The study also incorporates some design constraints taken from the Steel
Construction Institute (Publication Number 100, which contents are consistent with the speci fi cations in BS5950 parts 1 and 3).
Speci fi cally, the constraints to be considered include the displace-ment limitations, overall beam fl exural capacity, beam shear capacity and the overall beam buckling strength, among others.
As a result, the cellular beam is subject to 12 geometrical and behavioral restrictions. The proposed algorithm to ef fi ciently tackle this problem consists of fi ve steps: (1) selection of the parameters ' values of the HS algorithm; (2) initialization of the harmony memory by randomly selecting the sequence numbers of steel sections from a discrete list, as well as the hole diameters and number of holes for cellular beam; (3) improvisation of new harmonies and analysis of the cellular beam under the external loading, checking whether the design limitations are satis not (if this vector is severely unfeasible it is discarded and another harmony is sought, whereas if it is slightly unfeasible, it is included in the harmony memory); (4) fi ltering of the best harmonies, which are kept in the harmony memory for subsequent iterations; and (5) repetition of steps (3) and (4) until the termination criterion is satis fi ed. The design examples presented in this paper utilize constant values for the algorithm parameters obtained from a modest optimization process, and clearly re fl ects the strong dependence between the HS results and the selected parameter values. 3.2.2. Shell and tube heat exchangers used heat exchangers in process industries because of their relatively simple manufacturing and their adaptability to different operating conditions. The design of STHXs, including thermody-namic and fl uid dynamic design, cost estimation and optimization, represents a complex process containing an integrated whole of design rules and empirical knowledge from various fi elds. The study presented in Fesanghary et al. (2009) demonstrates a successful application of the HS algorithm for the optimal design of shell and tube heat exchangers. It explores the joint use of
Global Sensitivity Analysis (GSA Saltelli et al., 2005 ) and the HS algorithm for design optimization of shell and tube heat exchan-gers from the economic point of view. First, it is necessary to identify the geometrical parameters that have the largest impact on total cost of STHXs. This task is successfully achieved by means of the GSA. Next, the HS algorithm is applied for optimizing the in fl uential parameters. The end goal lies on fi nding the STHX optimal design capable of accomplishing the prescribed thermal duty with minimum combined investment and operating cost.
Among all the bene fi ts that HS presents, three of them are particularly interesting for this involved application scenario:
HS imposes fewer mathematical requirements and does not require initial value settings of the decision variables. Second, as it resorts to stochastic random operators for guiding the search process, derivative information is deemed unnecessary. Third, HS is capable of searching for solutions from disjoint feasible domains. These features enhances the applicability of HS to the design of thermal systems, setup where the problems are usually non-convex and have a large amount of discrete variables and discontinuities in the fi tness function. 3.2.3. Telecommunications
The increasingly close attention grasped by the so-called Wire-less Sensor Network (WSN) concept during the last decade arises from its capacity to ef fi ciently and collaboratively sense physical phenomena without the need of any wired link and at a reduced per-node computational complexity. Traditional approaches are focused on extending the WSN coverage and lifetime of the network, such as the work in Mahdavi et al. (2007) which proposes an Improved Harmony Search algorithm in a k-covered and con-nected wireless sensor network. The aim of this work is to achieve a sensor node deployment with optimal coverage and energy ef ciency by preserving node connectivity and k-coverage property for hot-spot areas. Through computer simulations, Improved Harmony
Search algorithm is shown to fi nd better solutions (i.e. maximum covered area and lower energy consumption) than the original HS algorithm and their genetically-inspired counterparts.
Within this line of research, besides the classical monitoring applications which WSNs initially targeted, their proliferation and the intrinsic value of their sensed information have ignited the research interest in context-aware services and applications, in which the availability of accurate nodes ' location information is essential to make collected data meaningful. Hence, in such applications it is important to associate the captured data with the location of the node. In order to ef fi ciently tackle this problem, novel localization approaches based on the combination of the HS algorithm and a novel local search procedure have been recently proposed in Manjarres et al. (2012a , 2013) . The latter presents a comparative study of a multi-objective HS algorithm and a Pareto
Archived Evolution Strategy (PAES) approach concluding in a better performance of the proposed multi-objective HS in terms of accuracy, further buttressed by a statistical Wilcoxon hypothesis test. Connectivity-based geometrical constraints are de fi these works in order to exploit and limit the areas in which sensor nodes can be located.

When turning the scope to metropolitan wireless local area networks, a shared-infrastructure deployment problem is pro-posed in Landa-Torres et al. (2012b) where the coverage level of the deployed network must be maximized while meeting an assigned maximum budget. Speci fi cally, an approach based on the HS algorithm is proposed with three main technical contribu-tions: (1) the adaptation of the HS algorithm (i.e problem encod-ing) to a grouping scheme, used for mapping users to access points; (2) the adaptation of the improvisation operators driving the algorithm to the speci fi c characteristics of the optimization problem to be tackled; and (3) its performance assessment via a simulated experiment inspired by real statistics in the city of
Bilbao, Spain. The HS algorithm utilized in this contribution not only adapts its encoding to tackle this clustering problem, but it also includes a coverage matrix and access point ' s information into the de fi nition of the improvisation operators.

Other telecommunication areas where HS has been recently shown to ef fi ciently solve computationally hard optimization challenges include multiuser detection in CDMA systems ( Zhang and Hanzo, 2010 ), dynamic resource management in wireless systems ( Del Ser et al., 2011 , 2012 ), design of radar codes ( Gil-Lopez et al., 2012 ) and maintenance planning of communication equipment ( Harrou and Zeblah, 2011 ). 3.2.4. Construction and engineering structures
The improvement of energy ef fi ciency and environmental performance of buildings is considered a major priority world-wide. New building regulations have an explicit orientation toward low-emission and energy-ef fi cient designs. However, the optimal design of residential buildings should consider multiple and usually competitive objectives such as energy consumption optimization, fi nancial costs reduction and minimization of envir-onmental impacts.

The approach presented in Fesanghary et al. (2012) proposes a multi-objective HS solver for minimizing the life cycle cost and CO 2 emissions of residential buildings. These objectives are natu-rally competitive: the cost of environmental friendly materials is usually higher than those of the corresponding conventional ones, while the energy-ef fi cient materials may be less environmental friendly than other materials that are less ef fi cient. As a result, the need for a multi-objective optimization approach to ef fi take both issues is evident. On the one hand, the life cycle cost (LCC) can be obtained from the initial investment costs, replace-ment costs, energy costs, operational, maintenance and repair costs. The second objective is to minimize CO 2 ,CH 4 and N emissions over the life cycle of the building. The schema devel-oped in this multi-objective approach provides a range of non-dominated solutions along the Pareto front in which a reduction in the CO 2 emission can only be achieved by increasing the life cycle cost. A trade-off between these two objectives is needed and thus, several optimum solutions that favor each criterion at a higher or lower level are given.

Another aspect of relevant importance nowadays includes engineering structures tasks in which distinct structures are optimized according to several parameters and technological constraints. In Zarei et al. (2009) a HS algorithm is presented in order to determine the optimum cutting parameters for multi-pass face-milling. The optimization task involves obtaining the number of passes and also the corresponding speed, feed and depth of cut for each pass that minimize the total production cost while considering technological constraints such as available speeds, depth of cut, feed, cutting force and power, tool life and machine tool capabilities. Then, from all of the possible cutting strategies, the best one according to the value of the correspond-ing objective function is selected.

Another set of studies deal with the optimization of truss structures ( Kaveh and Talatahari, 2009 ), which involves obtaining the optimum values for member cross-sectional areas that mini-mize the structural weight. This minimum design has to satisfy inequality constraints that limit the design variable sizes and the structural responses. Thus, the optimal design problem must minimize the weight of the structure, the number of nodes, the number of compression elements, the material density and the length of members and cross-sectional areas. In this paper, a Heuristic Particle Swarm Ant Colony Optimization (HPSACO) is presented for optimum design of trusses. The algorithm is based on the Particle Swarm Optimizer with Passive Congregation (PSOPC), an Ant Colony Optimization (ACO) and a HS scheme. HPSACO applies PSOPC for global optimization, whereas the ACO is used for updating the positions of particles in order to attain a feasible solution space. Besides, there are some problem-speci constraints in this type of optimization problems that must be considered. Hence, the proposed approach handles these con-straints by employing a fl y-back mechanism in which the particle will be forced to fl y-back to its previous position if any of the constraints is violated. Furthermore, if it fl ies off the variable boundaries, the solution cannot be used even if the problem-speci fi c constraints are satis fi ed. In order to do so, the HS heuristic has been used to check whether the variables ' boundaries have been violated. The resulting method has a good control on the diversi fi cation and intensi fi cation when compared to PSO and
PSOPC. It increases the diversi fi cation and properly guides the intensi fi cation. As a result the convergence rate of the proposed algorithm is higher than that of other heuristic approaches. 3.3. Water/groundwater system management
Several studies have focused on the design of water distribu-tion networks, in particular on the selection of optimal pipe diameters. Typically, there is one fi xed-pressure supply node and many demand nodes which connectivity makes the structure of the distribution network. Both the elevations and distances between nodes (pipe lengths) are speci fi ed. Therefore, the aim of these studies is to select the diameter for each pipe segment that minimizes the total cost of the water distribution network. The problem is subjected to certain constraints, such as the continuity equation, the conservation of energy equation, minimum pressure requirements, the maximum pressure, the fl ow velocity and the reliability.
 In the water distribution network design problem described in
Geem (2006) , the objective function is the pipe cost function; the pipe diameter is the decision variable; the number of decision variables corresponds to the number of pipes in the network and the set of decision variable values is the range of possible candidate diameters. Thus, the cost of the water network design is mathematically assumed to be a cost function of pipe diameters and lengths. In this work the nominal HS algorithm is implemen-ted for a wide range of HM sizes, HMCR and PAR values. On the other hand, the number of iterations is determined based on the number of objective function evaluations of other competitive algorithms. It is important to note that for the sake of its practical implementability, this approach interfaces with the popular hydraulic simulator EPANET to check the hydraulic constraints; if the design solution vector violates the hydraulic constraints, the amount of violation is considered in the cost function as a penalty. 3.4. Medical
The potential characteristics of the HS algorithm has made it also suitable for its application in medical issues. On the one hand, in therapeutic medical physics, ionizing radiation is employed to treat patients with cancer in which a radiation treatment planning is essential to improve patient care. This planning requires the optimization of radioisotope placement as well as the radiation beam intensities by means of meta-heuristic algorithms ( Panchal, 2009 ).

Following this line of research, the study presented in Panchal (2008) delves into high dose-rate prostate brachytherapy optimi-zation using HS. It involves calculating and determining the best dose distribution to the target and organs-at-risk by means of optimizing the time that the radioactive source dwells at speci positions within the catheters. Another recent work focuses on the detection of the epileptic seizure activity with fast and high accuracy from electro encephalogram data ( Gandhi et al., 2012 ).
The proposed scheme, a wavelet based Probabilistic Neural Net-work (PNN) classi fi er, is based on the discrete wavelet packet transform followed by the application of Differential Harmony Search algorithm (DHS) and a Probabilistic Neural Network (PNN).
The proposed robust method for selecting optimal features by DHS maximizes the classi fi cation accuracy with reduced computational complexity. Speci fi cally, it is designed to discern between two signal classes: normal and epileptic. After the data is decomposed into several features obtained from the discrete wavelet packet transform, DHS is utilized for selecting optimal features that are introduced into a PNN classi fi er. To that end, the dimension of each vector used in the optimization algorithm is reduced, as DHS chooses the features that maximize the classi fi cation accuracy.
Furthermore, the problem of premature convergence encountered in the classical HS algorithm is alleviated due to the greater explorative capability featured by DHS. 3.5. Robotics heuristic algorithms to several applications in the robotic such as the optimal design of recon fi gurable robots, the optimal trajectory planning and the control of robot ' s movements. In this context, a desired trajectory generation method based on the combination of neural networks and HS (the latter used for feature selection) has been applied to three-dimensional bipedal walking in Yazdi et al. (2011) . This controller is able to control the arm movements during walking with emphasis on make robot ' s walking more stable and faster. Thus, in order to reach smoother walking and increase speed and robustness this system controls roll of arms during locomotion. In this regard, Matsuoka neural oscillators have been used to generate control signals for govern-ing the locomotion of a humanoid robot. The neural network designed for robot motion needs 18 parameters where 10 of them are used for Matsuoka neural oscillators, 6 parameters for linear neurons, and 2 for gait period and knee threshold. There-fore, each solution in the HM is encoded as an array of 18 elements which is randomly fi lled during the initialization process. Alter-natively, upper and lower bounds have been de fi ned for initializa-tion of each variable. Regarding the HS algorithm, a nominal structure is employed in order to fi nd optimum values for these parameters, i.e. to fi nd the best angular trajectory and optimize neural oscillator parameters. Finally, in order to achieve stable and faster walk, a fi tness function based on robot ' s straight movement is assumed. The amount of deviation from straight walking is subtracted from the fi tness as a punishment to force the robot to walk straight. 3.6. Control broadly utilized in many technical and industrial applications as a potential tool for handling the uncertainties and nonlinearities of modern control systems. The success of these techniques relies on the ability of incorporating human expertise in control strategies.
Nevertheless, the main drawback of FLC methodologies is the considerable amount of parameters that need to be tuned. To overcome this issue, a wide class of meta-heuristic solvers have been developed for control optimization purposes. As to mention, in Das Sharma et al. (2010) an hybrid stable adaptive fuzzy controller utilizes the conventional Lyapunov theory jointly with the HS algorithm. The goal of this approach is to optimize both structures and free parameters such that the designed controller can guarantee desired stability and satisfactory performance with a high degree of automation in the design process. Two variants of this hybrid model are proposed and implemented for simulated and real-case studies.
 3.7. Power and energy
Another discipline area in which the HS algorithm has achieved successful results is power and energy, where several related optimization problems have been addressed such as the optimal design of wind generators, the ef fi cient model for transport energy demand, the power fl ow problem and the optimal allocation of capacitors and compensators in power systems.

The majority of the power related works focus on the power fl ow optimization problem which aim is to specify the loads in megawatts to be supplied at certain nodes or busbars of a transmission system in such a way that a minimum cost is needed.
In mathematical terms, the problem can be reduced to a set of non-linear equations where real and imaginary components of the nodal voltages are the variables to be optimized. On this purpose, the authors in Sivasubramani and Swarup (2011a) propose a multi-objective HS approach in which a fast elitist non-dominated sorting strategy and a crowding distance procedure are used to fi nd and populate an estimation of the Pareto optimum front. The objective functions to be minimized are the total fuel cost and the real power transmission line losses of the system.
Finally, a fuzzy-based mechanism selects a compromise solution from the estimated Pareto set.

Several other studies have concentrated on the so-called power economic dispatch problem, which aims at minimizing the energy production cost while meeting the power demands. Nowadays, the conversion of primary fossil fuels  X  such as coal and gas electricity is a relatively inef fi cient process in which even the most modern combined cycle plants are able to achieve ef fi ciencies only between 50 and 60%. Most of the energy loss in this conversion process is released to the environment as waste heat. The principle of combined heat and power (CHP), also known as cogeneration, is to recover and make bene fi cial use of this heat towards signi cantly raising the overall ef fi ciency of the conversion process (the best CHP schemes can achieve fuel conversion ef fi ciencies in the order of 90%). In this context, the authors in Vasebi et al. (2007) deal with the CHP economic dispatch problem by means of a HS algorithm, which essentially consists of determining the heat and power production so that the system production cost is minimized while heat-power demands and other side constraints are met. In order to illustrate the utilized method a test case taken from the literature (as well as a new one proposed by the authors) is presented. The steps of the proposed HS technique and also the parameters driving the algorithm follow the traditional scheme, and in the improvisation step, the Harmony Memory Size, HMCR and PAR values are kept constant along the iterations.
In Sivasubramani and Swarup (2011b) a multi-objective har-mony search algorithm is presented in order to optimize simulta-neously two competing objectives: fuel cost and emission. The algorithm utilizes a non dominated sorting and a ranking proce-dure based on crowding distance values to develop and maintain a well distributed Pareto-optimal set. The obtained results are compared with the Non-dominated Sorting Genetic Algorithm (NSGA-II) showing a better performance of the proposed multi-objective HS method in the achievement of the Pareto-optimal solutions. 3.8. Cross-application uses of HS
HS has so far been thoroughly utilized as a support algorithm for different knowledge inferring techniques used in different disciplines and diverse application fi elds, such as feature selection, clustering and scheduling. This subsection elaborates on the contributions corresponding to each of these techniques in an application-agnostic fashion, since all share the same HS-inspired algorithmic strategy.

Regarding the fi rst, one of the main aims of feature selection (FS) is to determine a minimal feature subset from a problem domain while retaining a high accuracy in the representation of the original feature set. Harmony search is best suited to solve problems with a fi xed set of decision attributes and an objective function to be optimized, whereas feature selection is a problem with variable-sized solutions. Therefore, there is a need to map each key concept of HS into elements in FS. It can be done by considering evident analogies, i.e. each feature subset can be seen as a harmony and the objective function can be substituted by a subset evaluation method such as the so-called fuzzy-rough dependency measure.

In this context, the goal of the recent work presented in Diao (2010) is to develop two HS-based, stand alone, reusable search strategies capable of fi nding optimal feature subsets according to a wide range of subset evaluation methods. In particular, the HS algorithm utilized in this approach is an improved version of the original scheme in which different methods are included for dynamically tuning parameters, similar to what was done pre-viously in Mahdavi et al. (2007) . Such two different strategies can be summarized as
Horizontal approach : The horizontal approach maps musicians onto the available features to be selected. The note domain of each musician is then a binary value, indicating whether or not the corresponding feature is included in the harmony. There-fore, in this approach the HMCR operator has little practical impact and can be seen as a simple bit fl ip rate.
 Vertical approach : The vertical approach tackles the problem of
FS from a different viewpoint. It treats musicians as indepen-dent experts, i.e. each musician can vote for one feature to be included in the feature subset when improvising a new harmony. The harmony is then the combined vote from all musicians, indicating which features are being nominated.
Thus, the vertical approach allows a much greater range of notes for musicians, which enables the use of the HMCR to its full potential and increases the chance of escaping from local optima.

Experimental comparative studies show that the horizontal approach requires much longer processing time in order to comparable quality subsets. The vertical approach makes better use of the algorithm and can converge much faster than the horizontal scheme with a smaller harmony memory and fewer number of iterations. Besides, it is capable of identifying similar or superior feature subsets for most of the datasets with notable classi fi cation accuracy.

On the other hand, clustering is one of the most powerful data mining techniques used for discovering intentional structures in data and grouping instances that have similar features. As a result, it has become an important technique for managing databases and extracting new knowledge therefrom. Many different applications have arisen based on clustering such as knowledge discovery, data compression, vector quantization, pattern recognition and pattern classi fi cation. In order to decrease the computational effort when handling large problems, meta-heuristic algorithms have been also utilized in this area.

Within this research scope, the authors in Alia et al. (2010) present a Dynamic Clustering algorithm called DCHS based on the HS algorithm hybridized with a Fuzzy C-means (FCM) algorithm to automatically segment the brain Magnetic Resonance Imaging (MRI) image in an intelligent manner. DCHS is used as an image segmentation algorithm to dynamically segment both simulated normal and multiple sclerosis-damaged brain MRI images. The proposed algorithm has the ability to cluster the given data set automatically without any prior knowledge of the number of clusters. Therefore, the capability of standard HS is modi automatically tailor the number of clusters as well as the locations of cluster centers. By incorporating the concept of variable length in each harmony memory vector, DCHS is able to encode a variable numbers of candidate clusters at each iteration. To further enhance the concept of variable-length of the harmony memory vectors, a new HS operator called the  X  empty operator  X  is proposed. This new operator is introduced to minimize the variation of the results (i.e. number of clusters) that are obtained from DCHS in case of multiple runs. The inconsistent results from multiple runs can be due to the dominating effect of a number of solution vectors of the
HM through the improvisation process (premature convergence problem). Therefore, the ability of generating a new vector with different number of cluster centers is very poor. In order to cope with this issue, the new operator is introduced to add a new method of having empty  X  don ' t care  X  decision variables in the newly generated harmony vector. By virtue of this additional operator, the DCHS algorithm has the ability to generate a new harmony vector with distinct number of clusters, even in the stages of the DCHS algorithm search process.

Additionally, an hybridizing step with a FCM algorithm is introduced to increase the quality of the clustering results by tuning the best solution that has been optimized by DCHS. The solution vector with highest fi tness value is selected from the harmony memory and considered as initial values for FCM ' centers. In this case, FCM modi fi es the cluster centers values until the variance of the clusters is minimum, thus yielding more compact clusters. Consequently, the clustering results achieved by DCHS will decrease the variation within each cluster members (intra-cluster variation) and, at a same time, increase the variation between clusters (inter-cluster variation). Then, the PBMF cluster validity index is used as an objective function to validate the clustering result obtained from each harmony memory vector.
Finally, the need for a scheduling algorithm arises from the requirement of most modern systems to perform several tasks and/or transmit multiple fl ows simultaneously. In real environ-ments, the scheduling is concerned with the optimal allocation of scarce resources to activities over time, which is crucial for keeping the system stable and meeting deadlines. More generally, scheduling problems involve the planning of the tasks subject to certain constraints in order to optimize an objective function. In this context, a large variety of scheduling problems have been tackled in the literature which have been solved by means of meta-heuristic algorithms.

An example of the application of the HS algorithm to schedul-ing problems is Ayachi et al. (2011) . In this paper an adaptation of
HS is presented in order to solve the unbound container storage location problem, in which the main goal is to reduce the unloading time of all containers when they are delivered to their customers. Speci fi cally, the wait time of customer trucks and the transfer time of the yard crane are regarded as optimization variables in the formulation. In the algorithm implementation, the initial harmony memory is randomly generated and every stored solution must meet all the problem constraints. The decision variables represent the possible locations for the contain-ers according to the allocated storage area. After that, a new solution is improvised based on the nominal HS proposed in Geem (2000) . In order to assess the performance of the proposed approach, the value of the parameters driving the algorithms ' behavior is also optimized. In fact, the harmony memory size (HMS), the harmony memory considering rate (HMCR), the pitch adjustment rate (PAR) and the number of generations undergo an enumerative optimization process in order to select the values that best balance optimality for computational time. This enumerative optimization stage comprises seven independent experiments for different HMS, HMCR and PAR values, as well as a method for measuring the number of iterations needed for the algorithm to stabilize.
 research community in recent years is the so-called fl ow shop scheduling problem, in which an appropriate sequence order for each task is sought in order to obtain a minimum idle and waiting time. The authors in Ren et al. (2011) propose several HS-based heuristics for minimizing the maximum completion time ( make-span ) and the total fl ow time for non-idle fl ow shop problems.
Other scheduling-related contributions include the multi-mode resource constrained project scheduling problem ( Fu and Zhang, 2011 ), and the broadcast scheduling in packet radio networks ( Ahmad et al., 2012 ). 3.9. Other applications chemical ( Zou et al., 2010a ), visual tracking ( Fourie et al., 2008 ), bioinformatics ( Mohsen et al., 2010 ), mathematics ( Cheng and
Yong, 2010 ), logistics ( Bo et al., 2010 ), image ( Fourie et al., 2010 ), neural network training ( Kattan et al., 2010 ), puzzle solving ( Geem, 2007 ) and commercial consulting services ( Landa-Torres et al., 2012c ), among many others (see attached bibliography). 4. Concluding remarks where the music-inspired Harmony Search algorithm has been shown to be an effective meta-heuristic to solve computationally involved optimization paradigms. This overview is broken down into a set of categories divided by application area, which serves as an useful tool for experimented practitioners and beginners to get a brief description of the latest activity and trends around HS in every such area. For the sake of brevity each category is brie introduced to the reader by commenting on the most-cited articles found at each application group.
 manuscript, the HS algorithm features a great potential and ef fi ciency when seeking near-optimal solutions to computationally hard optimization problems. Indeed, the excellent behavior of this meta-heuristic solver has been widely proven in such references by resorting to intensive simulation-based studies, further but-tressed by different statistical hypothesis tests. In light of the sharp increase of activity around HS noted in the last years, it is expected that the computational bene fi ts stemming from this meta-heuristic will span to other emerging fi elds (e.g. genomics, business intelligence, crime prevention, forensics, smart grids, renewable energy and many other disciplines linked to the so-called Big Data concept), as well as unchain new functionalities and variants of the nominal HS algorithm itself.
 way to interesting lines of future research, some of which are already being pursued by the scienti fi c community. Computation-ally speaking, methods for an ef fi cient management of the mem-ory and for speeding up the performance of the algorithm are within such next steps and directions in this area. In fact, many meta-heuristic approaches make use of the whole memory in order to obtain the new set of solutions. Therefore, the paralleliza-tion of the code for reducing the computation time to its minimum yields a research target of utmost relevance when tackling optimization problems of extremely high dimensionality (as those mentioned above).
 (often called as adaptive technique in other meta-heuristic algo-rithms Geem and Sim, 2010 ) is to be further developed because in practical applications engineers and decision makers are willing to use HS without performing any parameter tuning procedure. In many cases, they just want to  X  push the button  X  to get good solutions for their systems instead of getting seriously involved in the algorithm. Thus, how to provide more user-friendly parameter-setting-free environments to end-users is critical for the future success of this algorithm.

Last but not least, the communication between algorithm developers and fi eld users is another critical factor for the future of this algorithm. So far, assorted variants of HS have been proposed by many researchers. However, they seldom feed fi users ' requests back to their algorithmic derivations, but instead resort to a number of assumptions relatively far from the needs and demands of end users. Thus, more cooperation between research and fi eld user groups is expected in order for HS to endure as a practical tool for obtaining better solutions in real-world decision-making problems.
 Acknowledgments
This work was supported by the Gachon University research fund of 2012 (GCU-2012-R034).
 References
