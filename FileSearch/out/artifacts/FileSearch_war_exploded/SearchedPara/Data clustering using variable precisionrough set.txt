
Department of Mathematics, Universitas Ahmad Dahlan, Yogyakarta, Indonesia
Department of Mathematics Education, Universitas Ahmad Dahlan, Yogyakarta, Indonesia Johor, Malaysia 1. Introduction clustering attribute.
 RAHCA.
 on the probabilistic space. It will give us a new way to deal with the noisy data. Section 6. 2. Rough set theory 2.1. Information system and set approximations a , V = can be intuitively expressed in terms of an information table (refer to Table 1). B  X  A in S ) if and only if f ( x, a )= f ( y, a ) for every a  X  B . of x  X  U , is denoted by [ x ] follows.
 denoted by B ( X ) , respectively, are de fi ned by measured by respect to B ( X is vague with respect to B ).
 X, Y  X  U , the MZ metric measuring the distance X and Y is de fi ned as Then we have Notice that, in information system S ,wehave 2.2. Variable Precision Rough Set outside the dataset itself.
 X relative to Y is denoted by e ( X, Y ) ,isde fi ned by denoted by B  X  ( X ) , respectively, are de fi ned by The set B  X  X ower X  approximations. 3. Rough set-based techniques for selecting a clustering attribute 3.1. Total Roughness 1 , 2 ,  X  X  X  ,n .Let X ( a where i = j , denoted by R a where, | X a i = j , denoted Rough where V ( a i ) is the set of values of attribute a i  X  A . is obtained by the following formula 3.2. Min-Min Roughness which is equivalent with that has been proposed in [5], i.e., 1 , 2 ,  X  X  X  ,n , with respect to a also the opposite of that TR technique, i.e., clustering attribute.
 have the same result in selecting a clustering attribute. 4. The proposed technique 4.1. VPRS for selecting a clustering attribute clustering attribute, is stated in Proposition 1.
 ness ) of any subset X  X  U with respect to B  X  A is denoted by  X  B and  X  B ( 0  X &lt; 0.5 )  X   X  B ( X )  X  B proof . Based on De fi nition 4, if  X  0.5, then B B For  X  = 0, based on De fi nition 5,  X  B ( X )=  X  B For 0 &lt; X &lt; 0.5, we have | B 0 ( X ) | | B Therefore,  X  B ( X )  X  B  X  denoted  X   X a evaluated as follows where V ( a i ) is the set of values of attribute a i  X  A . a formula a i with respect to all a j ,where i ( n 2 l + mn + n ) . 4.2. Example singleton attribute. a. X (Prog = bad) = { 1,2,3,4,5 } , b. X (Math = low) = { 1,4,6,10,12,14 } , c. X (Stat = no) = { 1,5,8,9,11 } , d. X (Eng = fl uent) = { 1,2,6,8,10,11 } , e. X (French = poor) = { 1,5,6,7,8,9,12,13,14 } , are given below. a. Statistics with respect to attribute Programming b. Statistics with respect to attribute Mathematics c. Statistics with respect to attribute English d. Statistics with respect to attribute French below. a. Statistics with respect to attribute Programming b. Statistics with respect to attribute Mathematics c. Statistics with respect to attribute English d. Statistics with respect to attribute French Using equation (5), we have the total roughness as follows The TR of all attributes of Table 2 can be summarized in Table 3. a. Statistics with respect to attribute Programming b. Statistics with respect to attribute Mathematics c. Statistics with respect to attribute English d. Statistics with respect to attribute French The MMR of all attributes in Table 2 can be summarized as in Table 4. By given  X  = 0.2, the B  X  -lower and B  X  -upper approximations are The mean accuracy of attribute Statistics with respect to Programming are clustering attribute. 4.3. Objects splitting this, we can split the objects using the hierarchical tree captured in Fig. 2. domain knowledge.
 5. Experimental results 5.1. Selecting the clustering attribute datasets are shown in appendix. The experiment result is summarized in Table 6. 5.2. Clustering objects and its visualization purity are de fi ned as and 5.2.1. Balloon dataset Act and Age, we have the following clusters purity.
 The visualization of the clusters is given in Fig. 4. 5.2.2. Tic-Tac-Toe Endgame dataset we have the following clusters purity.
 The visualization of the clusters is given in Fig. 5. 5.2.3. SPECT heart dataset 5.2.4. Hayes-Roth dataset thus the purities of TR and MMR cannot be addressed here. 6. Conclusion purity of benchmark datasets up to 83 %, 69 %, 100 %, 64 % and 63 %, respectively. Acknowledgement Malaysia.
 References
