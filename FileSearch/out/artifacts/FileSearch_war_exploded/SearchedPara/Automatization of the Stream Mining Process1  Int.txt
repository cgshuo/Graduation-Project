 With emergence of pervasive distributed computing environments, such as cell phones and sensor networks, the data production has enormously increased [8]. In such environments, data are frequently seen as continuous infinite streams, which cannot be stored for later use. The storage and processing characteris-tics of streams do not allow for the application of conventional techniques for data analysis and mining; instead, specialized approaches are required that are capable of timely analysis and efficien t memory usage. Data stream mining re-ceived a lot of attention among research ers and a lot of aspects have already been investigated and resolved [2,13].

The approaches that are available today offer a reasonable trade-off between predictive accuracy and timely respo nsiveness and can be efficiently used to handle various practical situations [8]. However, data mining requires a deep understanding of the problem domain and data (provided by domain experts) and processing techniques (algorithms, their usage and optimization) that can be employed to perform the analysis (provi ded by data mining experts). This neces-sity to employ data and domain experts is recognized as an important obstacle which limits the usage of the data stream mining approaches in practice [9]. In this paper we focus on automatization of the data stream mining process. We do this by capturing and storing the knowledge that the experts employ in various steps of the stream mining process. The main steps of our approach in-clude: (1) the acquisition of the client X  X  requirements and main data properties, (2) the selection of methods that best match the given problem, (3) the setting and trimming methods X  parameters, and (4) learning from the method applica-tion on the given problem. We carefully analyzed and discussed the above steps over four case studies with two selected experts. As a result we developed an expert system that fully automatizes the stream mining process. We show that the stream mining of a reasonable quality can be performed using only a min-imal domain knowledge and without involvement of data mining experts. This is an important finding which reveals that the stream mining can become more widely used within information systems dealing with streams of data. The paper is structured as follows: Sectio n 2 briefly explains the related work, Section 3 the expert system, and Section 4 the evaluation. The conclusion is given in Section 5. We relate our work to the two relevant sub-fields of machine learning: (1) the field of incremental learning, which deals with the complexity of this task, and (2) the field of meta-learning, which focuses on automatically relating algorithm performance to the characteristics of the data and prior domain knowledge. In the following we review the important works in the both fields. 2.1 Data Stream Processing and Its Complexity A data stream consists of an ordered se quence of examples , which arrive on-line. Examples of such applications include sensor measurements, financial ap-plications, telecommunication and network transactions, and others. To achieve processing in real time, the examples are read only once, processed and then discarded or archived. If the example is archived, it has to be stored in memory, which is relatively small compared with the potentially unbounded size of the whole data stream. Several works [2,8] discuss characteristics of data streams and emphasize the following:  X  stream mining is performed by sliding window techniques which maintain  X  batch processing approaches are inadequate due to the fast processing re- X  adaptivity to changes in data is important due to potentially changing data  X  summarization, sampling and synopsis techniques are required to compress  X  queries over streams canno t be evaluated precisely and are approximated. Different research directions stem from the listed set of challenges, e.g., propos-ing learning algorithms for supervised and unsupervised learning [4], improving their accuracy [13], performing queries over transient examples in a stream [2], sampling over data streams, dealing with concept drift [8], and others. The di-versity of the former challenges illustrates the complexity of the decisions that need to be taken by users. 2.2 Meta-modeling of Algorithm Performance Meta-learning focuses on modeling relatio nship between characteristics of a prob-lem domain and the learning algorithm performance [6]. To predict the perfor-mance, the meta-learning algorithm reco rds the past empirical performance of different learning algorithms along with the attributes that describe the prob-lem domain. Choosing these meta-attributes appropriately is a challenge in this field; they can be based either on the data parameters (e.g., data set size, num-ber of attributes, class distributions etc.) or the parameters of the particular underlying learning algorithm [1]. An alternative to automatic construction of meta-learning knowledge is to construct them manually.

Related meta-learning based approaches include stacked generalization [16], which is considered a form of meta-learning because the transformation of the training set conveys information about the predictions of the base-learners; se-lecting a learning algorithm for each individual test example based on the algo-rithm X  X  performance exhibited in the example X  X  neighborhood [11]; and inductive transfer of learned knowledge across domains or tasks [12].

Both mentioned fields of the related work motivate us to develop an ex-perimental automated stream mining system that addresses the challenges of the incremental learning and uses meta-modeling to facilitate automation of parameter-setting tasks. Our wishful goal is to enable the non-data mining ex-perts to use the proposed system and achieve comparable performance to the performance of algorithms used by field experts. 3.1 Stream Mining Process As emphasized in the introduction, the goal of our research was (a) to capture the expert knowledge of stream mining experts and (b) to formalize this knowledge within an expert system for the automatization of the stream mining process.
In a typical stream mining scenario, there are two kinds of experts involved, both having important roles: data mining experts and domain experts. Whereas the former provide expertise on strea m mining techniques, the latter help the stream mining experts to faster identify crucial data properties which would oth-erwise remain hidden. It is important to note here that in our work we assumed that only a minimal knowledge on the domain is available; by avoiding require-ment for domain expertise we therefor e aimed to make the system as general as possible. Based on the above limitation and discussion with two stream mining experts we constructed a s implified stream mining process, shown in Figure 1 (explanation in the following). In this process we identified three main areas where the expert knowledge is most important, which are:  X  the construction, aggregation and selection of relevant attributes (Figure 1,  X  the selection of most appropriate stream mining methods based on problem  X  setting and re-setting of stream mining methods X  parameters (Figure 1, Ac-In the following sections we first explain the minimal domain knowledge that is required in order to mine streams (with or without experts). Then we describe the activities within the stream mining process where the mining expertise is the most beneficial and explain how these activities were implemented within our expert system. 3.2 Minimal Required Knowledge For an expert or an expert system some m inimal required prior knowledge (RK) is beneficial to make reasonably informed decisions and recommendations: RK1. Client X  X  subjective preferences : requirements such as transparency, visu-RK2. Client X  X  objective preferences : requirements for data stream predictors. RK3. Known data stream properties : number of attributes, attribute types, at-RK4. Known data stream mining problem properties : also based on client X  X  Initial recommendations of the stream mining experts are produced by consider-ation of RK1 X  X K4 without looking into the data stream, which is assumed not to be available at this point. This activity (requirements acquisition) is not yet implemented in our expert system and thus has to be performed manualy in dis-cussion with the client. In future, we intend to develop wizard-based interfaces that will allow clients to provide requirements and domain knowledge directly to the system, i.e., without any involvement of the experts. 3.3 Choosing Appropriate Stream Mining Methods After acquiring the main client prefer ences (RK1 and RK2) and data proper-ties (RK3), a stream mining expert sel ects a set of methods that best match the given problem. This is typically done by considering the importance of dif-ferent methods X  characteristics for the client. The following characteristics are considered as the most important and included in the discussion:  X  Transparency reflects experts X  opinion on how readable and transparent will  X  Visualization describes possibilities for visual representation of the model;  X  Explanation refers to model X  X  abilities to automatically explain its predic- X  Reliability describes model X  X  abilities to automatically estimate reliability of  X  Response is an estimate of model X  X  expected response time, both in terms of  X  Performance is an estimate of model X  X  performance (in terms of established In our expert system, we first filter the available stream mining methods and select only a subset that best matches clie nt X  X  requirements and domain descrip-tion. Later, during stream mining we on-line evaluate the selected methods on real data and further refine their selection, if necessary. The knowledge that we acquired from the experts and used to filter out the methods that best match the client X  X  requirements, is summarized in the Table 1 (for classification methods only, due to lack of space).

Our system supports 12 classifiers (methods for predicting a discrete class at-tribute), 9 regressors (methods for predicting a continuous class attribute) and 5 clustering algorithms from WEKA, MOA and IBLStreams toolkits [7,3,15]. For classification we use: bayes : a simple Naive Bayesian classifier; rules : decision rules with Naive Bayes classifiers; tree : a Hoeffding tree with information gain split criterion; ensmb : a weighted ensemble with Hoeffding trees; boost :Ad-aBoost boosting approach based; knn : simple nearest neighbors; and meta :a meta approach with all above based on  X  statistic. For regression we use: knn : nearest neighbors with linear regression; rules : adaptive model rules regres-sion; tree : a Hoeffding regression tree with options; addit : stochastic gradient boosting; disct : discretization based approach; svm : support vector machines based; and meta : meta approach with all above based on MSE . 3.4 Setting and Trimming Stream Mining Methods X  Parameters In a stream mining experiment the stre am mining experts start by setting some reasonable parameter values. When data arrives, the experts observe methods X  performance and experiment with their parameters. The choice and magnitude of parameter changes is based on experts X  experience and intuition and is difficult to formalize.

For our initial experiments, the expert s provided parameter values that were expected to provide reaso nable performance of the selected methods. Some pa-rameters (e.g., initial window size) were set according to expected frequency of data generation (RK3), required timespans and frequency of predictions (RK3), thus, to include all possible natural and human cycles. For each of the chosen data stream mining methods, experts also identified a small number of parame-ters that were sensible to further tune to increase methods X  performance.
For the automatization of this activity (Figure 1, Activities 4 X 6), we initially set the parameters to their default values and then tune them based on the methods X  performance. While the first step is rather trivial (the default values are typically suggested by the methods X  authors), the second one is much more complicated, as it requires a learning system. We implemented such a system that executes data mining methods in a batch and tunes their parameters on recent subsets of data in order to op timize performance indicators (  X  statistic or mean squared error). When the improv ement of tuned performance compared with the online performance is statistically significant, the parameter values are applied also within the production (online) stream mining methods. In contrast to the manual parameter setting, where stream mining experts work only with a subset of parameters, the expert system deals with all the parameters in parallel. In addition, if some of the initially selected methods significantly decline in their expected performance, they are termina ted and possibly replaced with others. Please note that the herein described on line parameter tuning feedback loop is still a work in progress, and its results are not included in this paper. 3.5 Construction, Aggregation and Selection of Relevant Attributes Data preprocessing, cleaning and filtering, attribute construction, aggregation, and subset selection, are very important for successful data mining. Many meth-ods are prone to perform poorly when using irrelevant and noisy attributes. While some data mining methods implement constructive induction of attributes [10], they are very complex and time consuming and therefore inappropriate for stream mining. Data expert knowledge (if available) can be used to construct more relevant general attributes; however, for data streams, temporal aggrega-tions are relatively straightforward.

In the observed experiments the stream mining experts started with the ap-plication of some basic data preprocessing techniques, such as imputation of missing values detection and imputation of outliers, and adaptive normalization of continuous values. For the supervise d stream mining problems, they extended the data with a class attribute lagged by one time step and by the size of the prediction window. They proceeded with a ttribute aggregation, mostly based on prior data knowledge and their experience.

In our system, we include all basic data preprocessing techniques that are described above. We also provide lagged class attributes, and descriptive statis-tics, such as the average, mode and others. Temporal attribute aggregation is based on online implementations of discrete and continuous distributions that allow on-the-fly construction of different attributes (e.g., lagged, minimum, av-erage, mode, median, randomly sampled etc.). Stream mining experts defined several periods, based upon natural and human cycles (e.g., hourly, daily, weekly, monthly, yearly). In conjunction with ex pected frequency of data generation (RK3) we automatically generate aggregate and lagged attributes, such as (for an hourly cycle) data reading an hour ago and hourly cyclic attributes (i.e., sine and cosine with an hourly period). 3.6 Architecture of the Stream Mining Expert System Figure 2 illustrates the high-level architecture of our proposed system. The sys-tem in the figure has two inputs: (1) domain description and user requirements (denoted with 2 ) and (2) a data stream itself (denoted with 1 ). Knowledge base consists of decision rules and tables that were elicited from data min-ing experts. We use it for initial method and parameter select ion, selection of evaluation protocol with respect to the stream properties, and on-line parame-ter trimming (denoted with 3 and 4 ). These entries are continuously refined during stream mining by including better parameter settings produced by meta learner (denoted with 6 and 7 ).
 A selected subset of appropriate stream mining methods (utilizing WEKA, MOA, and IBLStreams toolkits) is run in parallel for a given data stream (de-noted with 9 ). The induced stream models are evaluated in the model evaluator (denoted with 5 ). Its function is twofold: (1) to assist meta learner X  X  feedback loop in order to select better methods and their parameters, and (2) to provide the best current model X  X  results (usually a prediction) to GUI (denoted with 8 ). 3.7 Meta Learner In our stream mining expert system, as depicted in Figure 2, the meta learner component plays a crucial part. It is used for both initial selection of applicable stream mining methods and their parameter setting and optimization of stream mining methods X  parameters during execution.

Initially, a subset of methods is selected , based upon client X  X  requirements and domain description. For this purpose, expert knowledge encoded in the knowl-edge base is used. An example of encode d knowledge used for method selection is shown in Table 1. When a subset of methods M = { M 1 ,M 2 ,...,M n } is se-lected, they are also assigned a set of de fault parameters (part of the knowledge base), and a set of tunable 1 parameters with their tuning range (both default parameters and sensible tuning range are also parts of the knowledge base).
For the purpose of parameter optimization, for each method M i we run several instances M ij in parallel with slightly (randomly) perturbed tunable parameters. All method instances M ij are run in parallel on the same data stream. Fur-ther parameter optimization is performed with fairly standard genetic algorithm approach [14]. The interval for production of fitness values is determined from client X  X  required timespans and frequency of predictions (RK3).
For the purpose of genetic operators parameter values are Gray-encoded within the tuning range with resolution of 10 bits. Standard crossover and mu-tation operators are used in conjunction with tournament selection. Besides this we also use twofold elitist approach. For the next generation we always save the currently best instance M i max j and the instance with default parameter settings M i 0 . When performance of the currently best instance is significantly ( p&lt; 0 . 01) better than the performance of the instance M i 0 with default parameters, the new set of parameters is forwarded (see 4 in Figure 2) from the method pro-cessor into the knowledge base alongside with the domain description.
Our current approach assumes that we have enough resources available to run several method instances in parallel (in total possibly hundreds of instances). We intend to explore also a resource-sc arce scenario when for each method M i we will have only a single instance for parameter tuning. It will work on windowed samples and serially optimize parameter values. 3.8 Integration within an Information System From the information system engineering point of view, such an expert system, once developed, can be reused in vario us contexts and information systems. Its integration within an information system that deals with data streams and requires the stream prediction, is straightforward due to a very clear interface -the data stream is routed to the expert system for the mining and the predicted stream with the measure of confidence is sent back. 4.1 Experimental Framework We adopt standard statistics for measuring the performance of classifiers: the classification accuracy ( CA ), Cohen X  X   X  (Kappa) statistic, geometric mean of recall and precision denoted F -score, and Rand index. We evaluate regression algorithms with the mean absolute error ( MAE ), mean absolute percentage error ( MAPE ), root mean squared error ( RMSE ) and Pearson correlation coefficient. All statistics are computed using a slid ing window of the most recent examples.
Additionally, for comparing the performance of two particular classifiers A and B ,weusethe Q -statistic: When Q A,B &gt; 0, classifier A performs better that B (and vice-versa). 4.2 Experimental Datasets The stream mining tool was analyzed on four datasets from real-world problems (Table 2). First two datasets were used to t est the system X  X  classification perfor-mance and the remaining two were used to test the regression prediction perfor-mance. The datasets were fed to the strea m mining methods in temporal order of learning examples. Short description of these datasets is as follows:  X  Flight delay prediction within the USA. The dataset 2 was published at  X  Electricity market price in New South Wales. The dataset was col- X  Electric energy consumption of Portugal. The prediction goal is to con- X  Solar energy forecast for Oklahoma. The  X  X olar energy forecast for 4.3 Results and Discussion To objectively evaluate our approach, we performed the experiments in the fol-lowing three iterations: 1. As a baseline approach, we utilized our stream mining system without any 2. In the next step we executed tests by fully involving the stream mining 3. In the last iteration, we repeated the experiments using a support of the
The results for each of four used datasets are shown in tables, which show the results of our expert system (System ) with respect to the baseline approach (Raw) and stream mining experts (Expert), and figures, which display evolutions of the Q -statistic or MAPE over time. The detailed results are as follows:  X  Flight delay prediction within the USA. The results are shown in  X  Electricity market price in New South Wales. The results are shown  X  Electric energy consumption of Portugal. The results are shown in  X  Solar energy forecast for Oklahoma. The results are shown in Table 6
The results show that our expert system often performs similarly to stream mining experts. In the  X  X irline flight delay prediction X  and the  X  X lectricity mar-ket price in New South Wales X  datasets, expert system performed almost the same as the stream mining experts, in the former it initially even outperformed them. We can attribute this to use of the knowledge base, using which the expert system was able to quickly select a well-performing mining method, opposed to the approach of experts that included extensive initial testing of various param-eters. Nevertheless, in the long run, the experts X  predictions performed better.
The expert system performed better that the baseline approach (best stream-ing method on raw data), as we expect ed, in three out of four datasets. It achieved poor performance only on the  X  X olar energy forecast for Oklahoma X  dataset, which turned out to be a difficult prediction problem even for the stream mining experts who achieved poor performance as well. The reason for this is that due to weather factors which cause that the last year X  X  data on the same day may be considerably different from this year X  X . In this paper, we focus on data that comes in streams. Mining streams has additional challenges as data is only available limited amount of time and  X  as a whole  X  cannot be stored for later use. We show that the stream mining process which normally depends on both the streaming data and data mining experts, can be fully automatized within an information system encoding the experts X  knowledge. Although implemen ted expert knowledge is limited both in expressiveness and functionality, abundance of data in data streams seems to largely compensate this gap, as in the long run, experts X  and expert system X  X  performance is (at least in our experiments) quite similar.

In our work we wished to emphasize that solving data mining problems typ-ically requires involvement of individuals with expertise in data mining tech-niques and approaches. This alone puts some limitations on the application of data mining in business practice as such knowledge is rarely available among employees and needs to be outsourced. Bes ides the obvious financial limitations (such expertise is costly), and, especially in stream mining, there is an ongoing need for experts X  involvement due to data streams X  dynamic nature. Therefore, each data mining problem needs to be tackled independently as there seems to be no general solution. The above indicates that the data mining is not fully exploited in business environments and computerized within their supporting information systems. This is a pity, since many information systems today have access to immense amounts of current and historical data.

The results of our study show that the stream mining expertise has become routinized enough to be captured in a form of explicit knowledge and thus computerized. We believe that this represents an important finding which might impact the level of possible automatization of problems known from the Big Data , Internet of Things and similar domains.

