 Query processing over weighted data graphs often involves search-ing for a minimum weighted subgraph  X  X  tree X  which covers the nodes satisfying the given query criteria (such as a given set of keywords). Existing works often focus on graphs where the edges have scalar valued weights. In many applications, however, edge weights need to be represented as ranges (or interval s) of possi-ble values. In this paper, we introduce the problem of skynet s, for searching minimum weighted subgraphs, covering the nodes satis-fying given query criteria, over interval-weighted graphs. The key challenge is that, unlike scalars which are often totally ordered, de-pending on the application specific semantics of the operator, intervals may be partially ordered. Naturally, the need to main-tain alternative, incomparable solutions can push the computational complexity of the problem (which is already high for the case with totally ordered scalar edge weights) even higher. In this paper, we first provide alternative definitions of the operator for intervals and show that some of these lend themselves to efficient solutions. To tackle the complexity challenge in the remaining cases, we pro-pose two optimization criteria that can be used to constrain the so-lution space. We also discuss how to extend existing approxima-tion algorithms for Steiner trees to discover solutions to the skynet problem. For efficient calculation of the results, we introduce a novel skyline union operator . Experiments show that the proposed approach achieves significant gains in efficiency, while providing close to optimal results.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval: Search process.
 Algorithms, Performance.
 Graph search, skyline union, incomparable edge weights, interval weighted graph, minimum spanning tree  X  Figure 1: A sample knowledge base (integeration of two tax-onomies) where utilities associated to each edge indicates the range of confidence associated to each assertion
Graphs and networks are widely used in many applications. For example, the Web can be modeled as a directed graph by treating each page as a graph vertex (or node) and the hyper-links between pages as edges. A resource description framework (RDF) database, consisting of triples describing relationships between pairs of data objects, is often seen as a graph. Discover [13] views relational databases as graphs. Many systems, such as [12], treat XML docu-ments as graphs. Some scientific knowledge management systems, such as [4], also represent integrated data as a graph.
In these and many other works, each node in the graph is asso-ciated with one or more data elements (e.g., tags or keywords) and each edge is given a weight, representing the application-specific desirability or cost of the edge. The ability to annotate statements in the database is especially important for applications which need to impose additional parameters, like validity, trust, or preference. In other applications, such as transportation networks (Figure 2(a), [7,14,20,36]), weights may represent costs of the edges.
Query processing over graphs and networks has gained signifi-cant interest [2, 8, 9, 12, 16, 17, 22, 27]. In a graph database, given a query, the system X  X  goal is often to return a subgraph  X  e.g. a Steiner tree  X  whose nodes collectively satisfy the query (e.g. cover all the query keywords) and whose total edge weight is minimum among all possible subgraphs satisfying the query.

We note that, despite the flurry of works tackling diverse (Web, relational, XML, RDF) data graphs, existing approaches to the problem are often limited to graphs where the edges have scalar valued weights. In many applications, however, the weights of the edges in the graph are not precisely known and, as in Figure 1, need to be represented as ranges (or interval s)  X  as opposed to scalar weights. Interval based computations and interval weighted graphs also commonly appear in various application domains [18] (includ-ing transportation networks, spatial databases (Figure 2(a) [31]).
Other data management applications that require interval weighted edges include Steiner searches over summarized graphs Figure 2: (a) Expected driving time between two cities may be impricise due to the weather and road conditions as well as the driving style and other driver choices; (b) in summa-rized/anonymized graphs, each summarized edge may repre-sent multiple edges, with a range of weights (where several nodes in the original data graph are grouped and collapsed into a single node, res ulting in edge s that cannot be rep-resented with scalar edge weights  X  see Figure 2(b)) and searches over anonymized graphs [23] (where edge weights are anonymized using recoding techniques [32], which replace precise scalar val-ues, with less precise value ranges or intervals).
When the weights of the edges in the graph are represented using intervals  X  X pecifying a minimum and maximum value for each edge X  standard operator semantics, that assume scalar edge weights, are not applicable: For example, the total weight of a subgraph with two edges with scalar weights, 6 and 7 ,is 13 the other hand, computing the total weight of a subgraph with two definition for the interval summation .

A more significant challenge in developing query processing al-gorithms for graphs with interval edge weights is that the mini-mum weight condition cannot always be evaluated in an unambigu-ous manner. For example, given two edges with totally-ordered scalar weights, it is trivial to unambiguously pick the edge with the smaller weight. On the other hand, picking the smaller weighted edge among two edges with interval weights, is not trivial. In fact, different preference, , semantics can give us different results. For example, if we use the average values of the intervals to compare two edge weights [1 . 0 , 5 . 0] and [3 . 0 , 4 . 0] , the interval be said to be smaller than [3 . 0 , 4 . 0] . However, if we require for that both starting and ending points of one edge be smaller than or equal to the corresponding bounds of the other, these two inter-vals would be incomparable . Unfortunately, in cases where edge weights can be incomparable (i.e., are partially ordered), existing Steiner tree solutions are not applicable.

As we discuss in Section 3, many basic graph operations (such as selecting the minimum weighted subgraph among many can-didates or recomputing the weight of a larger subgraph after two small subgraphs are combined) need to be redefined to accommo-date non-singular subgraph weights. Moreover, these need to be implemented in ways that avoid significant increases in compu-tational costs due to the potentially large numbers of alternative weights that may need to be considered.

When there are large numbers of incomparable objects, one way to reduce the number of results is to focus on the sky-lines [1, 3, 7, 14, 15, 20, 30] of the result sets instead of all possi-ble results. In this paper, we introduce the skynet discovery prob-lem: i.e., searching for minimum weighted sub-graphs, covering the nodes satisfying given query criteria, over graphs with partially ordered (more specifically, interval weighted) edge weights:
The paper is organized as follows: We formally define the met-rics, optimization criteria, and our problem in Section 3. In Section 4, we present the skyline union operator used for limiting the com-putational cost of the graph algorithms we develop in the rest of the paper. Section 5 proposes an approximation algorithm to solve the problem and provides the corresponding error bound. Section 6 reports our experimental results over real datasets. Finally, Section 7 summarizes our work.
In this section, we describe related works on searches on graphs and skyline query processing.
For data represented as a graph, where each vertex represents a data unit (e.g., a tuple in RDB, or a web page) and where edges represent connections between the data units, the search problem can often be formulated as follows: given a graph G and a query Q = { K 1 ,  X  X  X  ,K m } with m keywords, a query result over G is a minimum-weighted subgraph G of G such that the vertices in G collectively contain all the keywords in G . [22] is one of the first papers focused on keyword searches over (web) graphs. Other works, such as DBXplorer, DISCOVER [13] and others [2,9,12,17,24,27] focus on answering keyword queries on structured (such as relational) databases by returning results which collectively contain the query keywords and are connected (for example using foreign key constraints). It has been shown [22] that the search problem over weighted graphs can be formulated as an instance of Steiner or Group Steiner Tree (GST) problem. Since it is known [28] that both of these problems are NP-complete, ex-isting algorithms are often heuristics or provide approximate solu-tions. [2,17,22] present memory-based techniques to perform graph search (i.e., the graph data are all in the memory). [22] introduced a heuristic algorithm to perform the query and discover information unit (IU). Initially, the algorithm treats all the vertex nodes covering any query keyword as a forest. Then, it expands this forest by link-ing subtrees using smaller cost edges. Later, the BANKS system proposed a backward expanding technique [2] and the bidirectional search strategy [17]. A second group of algorithms, including [12], leverage indexes to further improve the search efficiency. BLINKS presented by He et al. in [12], for example, utilizes a bi-level index to facilitate ranked top-k keyword searches.
Given an ordering relation on multidimensional data, the skyline operation searches for a set of objects that are not dominated by other objects in the database [3]. Intuitively, the skyline is the set of maximal vectors in the space [21] and is also known as the pareto frontier (or pareto curve) on the vector space. As mentioned above, most existing skyline algorithms [3, 5, 21, 33] consider the case where the data elements within which the skyline set is searched are all available in advance. R ecent works, such as [1,15,30], con-sider skyline joins where the skyline sets of the result of join queries are sought. In this paper, we are interested in finding Pareto opti-mal solutions to common graph problems, such as shortest paths, minimum spanning trees, and Steiner trees. [7,14,20] and other consider various skyline problems with fo-cus on road network applications; i.e., unlike our work, these works assume Euclidean constraints on the original graph. The ordering operator considered in [20] is equivalent to one of the ordering se-mantics we study in our work (the se _ bef operator introduced in the next section). Unlike the more general approach presented in this paper, however, the approach proposed in [20] selects among the many candidates a dominating path based on a weighted com-bination of the attributes.
In the literature, there are man y works that recognize that the graph edges may represent more than one data dimension. For ex-ample, in a communication network, each edge may have both de-lay and jitter parameters. On a road network, the edge weights may represent distances as well as expected times to travel through. As a consequence, there has been a plethora of work addressing multi-constrained and multi-objective graph problems (see [10,11,34,35] for samples and overview of works in the area). In this paper, we note that while an interval may also be seen as a bi-dimensional weight, there is a key difference from multi-constrained and multi-objective graph problems: since the ending value of an interval is always larger than or equal to the starting value, an interval cannot be seen as consisting of two separate parameters. Here, we focus on interval weights as opposed to generic bi-criteria problems.
We introduce the problem of searches over graphs with interval-valued edge weights.
Each interval I =[ i  X  ,i ] has a starting point i  X   X  0 and an ending point i  X  i  X  . As a convention, in this paper, we use a capital letter (e.g., I , U , W ) to represent an interval and use its corresponding non-capital letter with subscript  X   X   X  X nd X   X  X orep-resent the starting and ending points of the interval.
Many graph operations, including those involved in the computa-tion of Steiner trees, assume that the edge weights are commutative monoids : A monoid is a set, W , on which a binary operation defined, such that (a) the set W is closed under  X  ,(b)  X  ciative, and (c) there exists an element 0  X  W , such that for all elements w  X  W , w  X  0=0  X  w = w . A monoid where  X  is commutative is called a commutative monoid and each commuta-tive monoid has an associated such that a b iff there exists positive c such that a  X  c = b . Scalars (integers, rational, real, and complex numbers) are all commutative monoids when the addition semantics is associated to  X  operation.

Graph algorithms leverage the commutative monoid nature of the scalar edge weights: the  X  operator is used to define the sub-graph weight in terms of the weights of the constituents edges and enables the comparison of different subgraphs (or sub-results) to choose the one that is more desirable. The associativity and the commutativity of these operators are leveraged to reduce the com-putational complexity of the underlying search problems.
To define search problems over interval-weighted graphs, we need counterparts of the  X  +  X  X nd X   X   X  operators (commonly used for integers, rational, real, and complex numbers) . Thus, we first need to define interval-based counterparts,  X   X   X  X nd X   X , of these two operators.
While many definitions of the  X  operator are possible, the fol-lowing definition for  X  is intuitive:
D EFINITION 3.1 (I NTERVAL  X  ). Given two intervals U = [ u  X  ,u ] and W =[ w  X  ,w ] , the plus operator (denoted as  X  on them is defined as U  X  W =[ u  X  + w  X  ,u + w ] . [0 , 0] is the zero element under  X  and it is trivial to show that this operator is associative and commutative.
The following are commonly used definitions for in various application domains.
 D EFINITION 3.2 (I NTERVAL ). Let U =[ u  X  ,u ] and W =[ w  X  ,w ] be two intervals. We can define as follows: U and W are equivalent (i.e., U  X  W )iff U W and W U .
 If U W and U is not equivalent to W , in this paper, we consider that U dominates W .
The first four of the semantics above lead to non-ambiguous selection of the minimal interval(s) in I . This is, however, not the case for the latter two semantics (i.e., bef and se _ bef comparable to each other based on either bef or se _ bef . In fact bef and se _ bef define not a total order, but a partial order on the elements in I . In the presence of such partially ordered intervals, we need an appropriate minimality criterion:
D EFINITION 3.3 (M INIMAL I NTERVAL ( S )). Let I be a set of intervals and let impose a partial order among the elements in I . The interval I  X  X  is said to be minimal in I iff there exists no other interval J  X  X  such that ( J  X  I ) and ( J I ) .
 In other words, I  X  X  is minimal in I iff for all J  X  X  , one of the following is true: ( I  X  J ) , ( I J ) ,or I and J are incomparable.
Let G = V,E, X  be a graph where each edge, e , is associated with an interval-valued edge weight  X  ( e )
D EFINITION 3.4 (W EIGHT OF A G RAPH ). We define the weight of a graph, G = V,E, X  ,as
Here, i e,  X  and i e, refer to the starting and ending points of the interval on the edge e respectively.

Given this, we can define the general skynet problem over interval-weighted graphs as follows:
D EFINITION 3.5 (S KYNET P ROBLEM ). Given an interval-weighted graph G = V,E, X  , operators  X   X   X  and  X   X  X nin-tervals, and a search condition  X  , find subgraph(s) G res that (a)  X ( G res )= true and (b) G res is minimal among all the subgraphs of G that satisfy the query condition  X  .
 Note that, there can be several minimal solutions to the problem that have different (and incomparable) overall weights (this is a major difference from the traditional search problems, where all minimal solutions have the same weight). Traditionally, most graph prob-lems (including the Steiner tree search problem, the shortest path problem, and the minimum spanning tree problem [6]) are all com-monly formulated to seek for only one result among all minimal results. In this paper, we formulate two distinct search problems, eliminating redundant matches and maintaining a core subset of re-sults in different ways: let M be the set of all minimal matches,
A common aspect of the skynet problems we consider is that they require the ability to combine two sets, each containing a group of mutually incomparable intervals, in such a way that the resulting set consists of the Pareto optimal intervals of the union of the two sets. We refer to this as the skyline union ( ) operation: two sets of mutually incomparable intervals, I 1 and I 2 , gen-erates another set I = I 1 I 2 such that  X  U  X  X  ,(1) U  X  X  or U  X  X  2 ; and (2)  X  U  X  X  1  X  X  2 , either U  X  X  or  X  W  X  X  W  X  U and W U .
 In other words, I contains all the intervals which are not dominated by any other interval in I 1 or I 2 .

E XAMPLE 4.1. Given I 1 = { [3 , 5] , [2 , 8] } , I 2 = { [1 , 7] , [4 , 6] } . When we consider the  X  se _ bef  X  definition, I is not in I and, similarly, [3 , 5] se _ bef [4 , 6] , [4 in I . When we consider the  X  bef  X  definition, however, I 1 bef I 2 = { [3 , 5] , [2 , 8] , [1 , 7] , [4 , 6] } . In this section, we describe the interval-based skyline union opera-tions for both se _ bef and bef partial order semantics.
Given two interval sets I 1 and I 2 , the skyline union operator algorithm for se _ bef works as follows. Initially, all intervals in I During the process, the algorithm maintains the smallest ending point I min for the intervals in the solution set I to facilitate the calculation of incomparable intervals. In particular, for a newly seen interval I , only when (a) its starting point i  X   X I (b) its ending point i &lt; I min , which means that interval I is incomparable with all the existing intervals in I , we can put I into I . The pseudo-code is presented in Figure 3.

E XAMPLE 4.2. Consider Figure 4 with four intervals: The complexity of the algorithm is linear in the sizes of the two sorted (as is the case in our scenario). Figure 5: Illustration of the operation of the bef operator: after seeing I 1 and I 2 , the range for the interval intersection is shown as the bold line I  X  =[ I  X   X  , I  X  ]=[3 , 5] .(a)Anynew coming interval with ending point not greater than 5 ( I  X  e.g. I 3  X  will be in the union result; (b) any new interval with starting point greater than 5  X  e.g., I 4  X  is not put in the result. The algorithm stops once it sees a new interval with starting pointer larger than 5.
 Figure 6: Sample execution scenario for bef :theinterval intersection gradually shrinks after seeing I 1 , I 2 (shrinks to [2,7]), I 3 (shrinks to [3,5]), and I 4 (shrinks to [4,5]).
For the bef ordering of the intervals, the skyline union opera-tor needs to work slightly differently. Figure 5 illustrates the algo-rithm: As is the case for se _ bef , initially, all intervals in are sorted in ascending order of the starting points and I  X  . Different from the algorithm for se _ bef , however, this time we maintain an intersection point range I  X  =[ I  X   X  , I  X  ] sected intervals in I . If a new interval I [ i  X  ,i ] intersects with it is incomparable with the intervals in I . On the other hand, if (a) i &lt; I  X   X  or (b) i  X  &gt; I  X  , the new interval I is smaller or greater than some interval in I . To make the computation easier, the oper-ator first gets the intervals with smaller starting points, then unions the intervals with larger starting points. This way, I  X   X  monotonically and I  X  decreases monotonically. Then, when the operator sees a new interval, it only needs to check condition (b). If the new interval X  X  starting point i  X  is larger than the upper bound of the intersection I  X  , then there must be some existing interval in I which is bef than this interval and, thus, we do not need to place the new interval in I . At this point the algorithm stops.
E XAMPLE 4.3. Figure 6 shows how bef computation works for I 1 = { [2 , 8] , [3 , 5] } and I 2 = { [1 , 7] , [4 , result I 1 s I 2 = { [3 , 5] , [2 , 8] , [1 , 7] , [4 , 6] } Again, assuming that the input sets are sorted, the complexity of this algorithm is O ( |I 1 | + |I 2 | ) .
In this section, we consider the computation of Steiner tree skynets, with incomparable edge weights.
 undirected interval-weighted graph G = V,E, X  , operators  X   X   X  and  X   X  on intervals, and a set of query vertices V S find subgraph(s) G res of G such that (a) G res satisfies the condition  X  G res .V covers V S  X  and (b) G res is minimal among all graphs that cover V S .

The basic Steiner tree problem (on undirected graphs with scalar edge weights) is known to be NP-complete; thus, most non-trivial solutions are often heuristics or approximation algorithms [19,29]. In [19], Kou et al. present Algorithm H, an approximate algorithm known to return trees with at most 2  X  the weight of the optimal Steiner tree. While Algorithm H is not the best known approx-imate Steiner tree algorithm 1 , with the tightest known bounds, it provides the appropriate structure 2 for us to explain the challenges that are faced in developing solutions for the problem of searching for minimal Steiner trees on graphs with incomparable weights:
Path Skynet Discovery: The Steiner tree algorithm first con-structs a complete graph G such that the weight of the edge be-tween two nodes v j and v k in V is the weight of the shortest path from v j to v k in V . In the presence of interval weights, there may exist multiple paths from v j to v k with incomparable weights. Thus, we need to identify  X  path skynet s X  in the graph.
Spanning Tree Skynet Discovery: Next, the algorithm identi-fies minimum spanning trees on the modified graph. When we are dealing with graphs with interval weighted edges, we need to be able to identify  X  spanning tree skynet s X  in the graph.
Let us first consider the well known Dijkstra X  X  shortest path al-gorithm [6] for scalar weighted graphs: The algorithm starts from a given source vertex and continuously updates the distance from the source vertex to the vertices in the graph (reachable from the source) by always picking the currently closest unconsidered vertex from a priority queue. For each vertex v in the graph, the algorithm maintains the minimum distance minDist ( v ) from the source to v . In addition, in order to be able to reconstruct the shortest path, for each vertex v , the algorithm also maintains the previous vertex prevV ertex ( v ) which is currently on the shortest path from the source to v . In contrast, as Example 5.1 illustrates, in the pres-ence of incomparable edge weights, it is not sufficient to maintain a single minDist ( v ) for vertex, v .
 E XAMPLE 5.1. Let us consider the interval-weighted graph in Figure 7 to illustrate the skyline path discovery. Let v 0 be the source vertex and assume that we are using se _ bef comparison operator. From v 0 to v 1 there is one path with smallest interval [1,1]. From v 0 to v 2 , there are two paths with incomparable in-v v we union the four intervals, [4,6] and [2,8] are in the result since [3 , minimal paths from v 0 to other vertices. For v 3 , one path is from the source vertex v 0 . The second is reached through v 2 .
Since there may be more than one (mutually-incomparable) min-imal paths from the source to a vertex, we potentially need to main-tain multiple minimal path weights for each vertex, v .Inorderto
The problem is APX-complete, which means that arbitrarily good approximation ratios cannot be achieved using a polynomial time approximation scheme, unless P=NP. The other Steiner tree algo-rithms (e.g., relative greedy [37] and loss contracting algorithms [29]) provide similar upper-(  X  1 . 6 )andlower-(  X  1 . 3
The relative greedy [37] and loss contracting algorithms [29] also have similar structures: they compute minimum spanning trees and Steiner trees over subsets of the input graph. Figure 8: (Quadruple-clustered) Path skynets algorithm; at each iteration, the algorithm picks and operates on the entire maximal subset of quadruples from the selected vertex v be able to trace these minimal paths back to the source, we also need to keep track of the corresponding previous vertex informa-tion for each path weight. Note that, unlike the basic case with scalar edge weights, since now each previous vertex may itself have several incomparable weights, for each minimum distance/previous vertex combination, minDist i ( v ) ,prevVertex i ( v ) ,wealso need to maintain the relevant weight, prevV ertexDist i ( ( = minDist j ( prevV ertex i ( v )) ), of the previous vertex from which minDist i ( v ) has been computed. Therefore, during the execution of the algorithm, for each vertex v , we need to maintain a set of quadruples of the form v,minDist i ( v ) ,prevVertex i ( v ) ,prevVertexDist i (
Figure 8 provides the pseudo-code for path skynet computation: unlike the basic algorithm which considers nodes of the graph by picking them one at a time from a priority queue, this algorithm maintains a priority queue of quadruples, in the form of a lattice of the corresponding intervals. At all times, minSet ( PQ ) is the set of minimal quadruples in the priority queue. As long as the prior-ity queue of the quadruples is not empty, the algorithm dequeues a quadruple, v,int,  X  ,  X  in minSet ( PQ ) and relaxes the nodes reachable by the outgoing edges of v .

In the standard Dijkstra X  X  algorithm, relaxing the weight of a vertex involves selecting the minimum among all possible (scalar) candidate weights. In the case of path skynets, however, we need to maintain the Pareto-optimal set of weights (i.e., a set of weights that are minimal and mutually incomparable) as discussed next:
The algorithm assumes that the minSet ( PQ ) is available and uses this to reduce the overall cost of relaxations. We refer to this as the quadruple-clustered processing: Instead of considering de-queuing intervals one at a time, when a quadruple corresponding to a node, v , is picked from the priority queue, the algorithm considers the entire maximal subset of minSet ( PQ ) consisting of quadru-ples from v . The algorithm relaxes the weights of the neighbors of v (using ) with this maximal subset of quadruples. This reduces the number of times each node needs to be relaxed.

Note that due to the partially ordered nature of the intervals, we cannot implement the priority queue as a simple minheap; instead, this priority queue of partially ordered intervals is implemented in the form of a dynamically maintained lattice or Hasse diagram; the worst case maintenance cost of adding one interval to this lattice is O ( |I| ) ,where I is the set of intervals in the priority queue.
Alternatively, we could impose a total order on the intervals by breaking the incomparabilities: if two intervals are incomparable, we can declare the node with the smaller t s (or smaller t is the same) as the smaller one. The intervals can then be indexed in a minheap based priority queue, which relies on the resulting total order: since, both in bef and in se _ bef , an interval with the smallest t s is either smaller than or incomparable to others with largest t s , this order will ensure that the interval dequeued from the priority queue is always in the minimal set. This strategy, on the other hand, has the disadvantage that the minSet ( PQ ) will not be available as a whole and consequently, it is not possible to select the maximal subset of minSet ( PQ ) consisting of quadruples from avertex v .When minSet ( PQ ) is not available, the following priority management strategies are applicable:
In the standard Dijkstra X  X  shortest path algorithm with scalar weights, each vertex is visited once, even in the presence of cy-Figure 9: (a) Impacts of cycles in a graph; (b) the path A E  X  C  X  D  X  B  X  F on this graph would require forward-backward-forward-backward-forward relaxation stages (red edges correspond to the  X  X ackward X  edges)
Figure 10: Exponential growth in the number of quadruples cles (as long as cycles are not negative). As shown in Figure 9(a), however, during path skynet computation a given node may be vis-ited multiple times for different incomparable paths and thus the paths that are discovered may stop being simple paths.

One way to avoid cycles in the identified paths is to  X  X race-back X  the attached pointers at each relaxation step to ensure that there are no cycles. This, however, is likely to be extremely costly. In this paper, we consider two different mechanisms: In the path signa-tures based strategy, we associate a path signature to each quadru-ple: each path signature is used for quickly identifying the vertices that are on the path from the source to this quadruple.
In the iterative topological sort strategy, on the other hand, we eliminate cycles on the graph using a topological sort operation, which will label edges in the graph as  X  X orward edges X  and  X  X ack-ward edges X . We can then perform shortest path computation in repeated forward and backward stages: Since the cycles are elim-inated, in the forward stage (where only forward edges are used), there is no reason to check for cycles. The backward stage (where only backward edges are used) may introduce quadruples corre-sponding to cycles and these can be eliminated by post-processing after that stage. Note that, as shown in Figure 9(b), a path of length, l , may include up to l/ 2 alternating forward and backward edge pairs. Thus, this approach may require up to | V | / 2 iterations of the forward/backward stages until the list of quadruples stabilizes.
The precise complexity of the algorithm depends on the specific priority queue and cycle management strategies selected. In the worst case, however, as shown in Figure 10 the number of quadru-ples maintained may grow exponentially with the length of the paths on the graph. In practice, however, since many of the weights associated to the same node will be comparable to each other, the minimal incomparable set that needs to be maintained tends to be much smaller. Indeed, as we see in Section 6, in practice, the com-plexity of this step is much closer to linear in the graph size. There-fore, in this paper, we do not consider any further heuristics to re-duce the number of quadruples.
Once the necessary shortest path information is collected, in its second step, the Steiner tree H algorithm constructs a complete graph G and finds its minimum spanning tree. However, in the presence of incomparable weights, each edge of the complete graph G may be associated with a set of incomparable weights . Instead of treating each such edge independently, we design the minimum spanning tree skynet algorithm in a way that leverages the skyline union operator ( ) described in Section 4.

The well known Kruskal X  X  minimum spanning tree algorithm [6] grows the minimum spanning tree by starting from individual ver-tices and incrementally combining partial spanning trees. The algo-rithm repeatedly picks the edge ( v i , v j ) with the minimum weight from a priority queue and, if no path exists between v i and v the existing forest of minimum spanning trees, this edge is used to combine the two partial spanning trees containing v i and v urally, in the presence of sets of incomparable weights the priority queue needs to be maintained differently.
If the user X  X  goal is to find only one tree whose overall weight is smaller than or incomparable to all the others, then we can achieve this relatively cheaply: A min-heap based priority queue can main-tain intervals; to achieve this we impose a total order on the inter-vals by breaking the incomparabilities: if two intervals are incom-parable, we can declare the node with the smaller t s (or smaller t when t s is the same) as the smaller one. Note that, for each edge of G , in the priority queue, we need to maintain only one interval; i.e., the minimal interval, according to the total order, correspond-ing to that edge. Let the number of edges in G be | E | ; then, this operation is of complexity O ( | E | X  log | E | ) .
If we want to find a set of incomparable solutions, as before we first impose a total order on the intervals and sort the available in-tervals in the ascending order. Then, we maintain two cursors on this ordered interval list to control the exploration of the search space. The first cursor denotes the starting checking point of one candidate solution space. The second cursor plays the role of the priority query in this search space. Initially, the first cursor points to the first interval in the list. Once all the incomparable solutions containing the interval that the first cursor points to are found, this cursor moves forward to test another candidate solution. The sec-ond cursor retrieves intervals in order from the interval that the first cursor points to. When a tree is found or the second cursor reaches the end of the list, the search of this solution space finishes. When the first cursor gets to the end of the list, we have found all the in-comparable trees. Let the length of the list (i.e., the total number of incomparable intervals considered) be L (which is exponential in the size of the graph G in the worst case as discussed earlier); then, this operation is of complexity O ( L 2 | E | ) .
Given the spanning tree skynets, in the final step, we construct the sought after Steiner tree skynets. It has been shown that the trees returned by the algorithm with scalar edge weights have at most 2  X  the weight of the optimal Steiner tree [19]. A similar result also holds for the version with incomparable edge weights:
T HEOREM 5.1. The proposed algorithm returns solutions to the Steiner tree skynet problem, such that S appx  X  2  X  OPT ,where OPT is a Pareto-optimal solution. More specifically, let U be the interval weight of S appx . Then, either (a) there exists a Pareto-optimal solution OPT =[ opt  X  ,opt ] , such that u  X   X  2  X  and u  X  2  X  opt ,or(b) U is incomparable with [2  X  opt  X  , for all Pareto-optimal solutions OPT =[ opt  X  ,opt ] .

Proof Sketch :Let G =( V,E, X  ) be an undirected graph with interval weights and let us assume that we are given a set, V Steiner points. Let T be a Steiner tree produced by our approxi-mate algorithm and weight ( T )=[ t  X  ,t ] be the total weight of this tree. Let OPT be an optimal Steiner tree with total weight [ opt  X  ,opt ] . The proof follows the outline of the proof of Kou X  X  algorithm [19]. First, let us consider an Eulerian graph G tained from OPT by doubling each edge in OPT . Obviously, G  X  connects all the Steiner points. Second, consider a Euler tour of graph G  X  . The weight of this Euler tour, g  X  ,is weight 2  X  weight ( OPT ) ; i.e., g  X  =2  X  opt  X  and g =2  X  opt .Next,we obtain a Hamiltonian cycle H on the Steiner vertices by traversing the Euler tour and short-cut previously discovered vertices. The construction of G  X  ensures triangular inequality 3 of the edges of the graph and this guarantees that this Hamiltonian cycle X  X  weight is no more than 2  X  weight ( OPT ) . This Hamiltonian cycle H is also a spanning tree. Based on the process of the approximation al-gorithm, H either equals to T or H  X  X  weight is incomparable with T . Thus, t  X   X  2  X  opt  X  and t  X  2  X  opt .

Next, we experimentally show that, in practice, the observed ap-proximation ratios for both se _ bef and bef are much better than 2  X  . Note that the Algorithm H does not lend itself into tighter bounds; as mentioned earlier, other Steiner tree algorithms also have lax bounds (e.g., relative greedy [37] and loss contracting al-gorithms [29] provide  X  1 . 6  X  upper-and  X  1 . 3  X  lower bounds).
The worst case complexity of approximate Steiner tree skynet discovery is exponential in the size of the graph since, as described earlier, the number of quadruples maintained may grow exponen-tially in the length of the paths embedded in the graph (see Fig-ure 10). This is not surprising since the Steiner tree problem itself is APX-complete and the Steiner tree skynet problem is doubly expo-nential (firstly due to Steiner requirement and secondly due to the existence of incomparable intervals). While additional heuristics (such as the size of the intervals) can be used to prune the number of quadruples to polynomial in the graph size, we do not consider such heuristics in the paper because, as we see in the next section, in practice the growth in the execution time is much closer to linear in the graph size even without such heuristics.
In this section, we examine the effectiveness of the pro-posed skynet approach by comparing the optimal and the ap-proximate solutions under different semantics of .Weim-plemented the algorithms using Java with the JGraphT library ( jgrapht.sourceforge.net ). The experiments were run with 2.99 GHZ CPU and 2G memory on a Java virtual machine.
The graph topology used in our s calability experiments are gen-erated using the DBLP dataset ( dblp.uni-trier.de/xml/ ). First, as is common, we have removed the isolated entries from the graph using common data cleaning steps [12] to obtain a graph with  X  400 K vertices and  X  600 K edges. Then, to obtain in-terval edge weights (as in Figure 2(b)), we partitioned the graph using the METIS graph partitioning strategy [25]. We construct a reduced undirected graph by tr eating each partition as a single vertex and connecting these verti ces if the corresponding partitions are connected with an edge in the original graph. We tested our al-gorithm over summarized graphs with various number of vertices: 100 , 1 K , 2 K , 5 K , 10 K ,and 20 K (with corresponding approx-imate number of edges 7 K , 60 K , 80 K , 104 K , 130 K , We considered three different interval weight distributions: DBLP distance , uniform ,and Gaussian distributions  X  details about the distance calculation are omitted because of space limitation.
We have computed the optimal results by enumerating all possi-ble edge combinations and maintaining the incomparable solutions (Steiner trees) in the result set. Note that the problem is doubly ex-ponential (firstly due to Steiner requirement and secondly due to the existence of incomparable intervals). This leads to high time and
We extended the definition of triangular inequality for incompa-rable edge weights; details are outside of the scope of this paper. Figure 11: Impact of the graph size on the execution time of the Pareto set search ( qvn =3 ) Figure 12: Comparison of execution times for approximate and optimal solutions (quadruple-at-a-time strategy) space complexities in O (2 | E | ) and, using the available memory, an optimal algorithm that could give us the ground truth was feasible only for very small graphs (num of nodes  X  10, num of edges Thus, in those experiments in which we need to compare the ex-ecution time or approximation effectiveness of the the proposed skynets directly to the optimal algorithm, we could only use rela-tively small graphs for which the execution of the optimal algorithm was feasible. However, we used larger graphs (num of nodes num of edges  X  200K) in scalability experime nts which did not re-quire comparison with the ground truth.
In this subsection, we present experiments that relate the perfor-mance of the approximate Steiner tree skynets to optimal Steiner tree skynets and analyze the impact of various decision parameters on the proposed schemes. Here, | D | refers to the number of ver-tices and | E | refers to the number of edges in the graph; qvn is the number of query vertices. Unless specified otherwise values reported in the experiments are averaged over 20 different queries. Efficiency. We first evaluate the scalability of the algorithm. Fig-ure 11 analyzes the impact of the graph size on the execution cost of the Pareto set search problem. As Figure 11 shows the cost of Pareto set search is much better than the worst case estimations. The cost of the algorithm increases only slightly higher than linear with the number of edges. Note that a significant portion of the increase in the execution time is due to a parallel increase in the number of results in the resulting Pareto set.

Figure 12 compares the execution times for the approximation Figure 13: Impact of the query size on the Pareto set search (the reduced graph contains 5000 vertices) Figure 14: Impact of the query size on the Pareto set search (per Pareto-solution time, the reduced graph contains 5000 ver-tices) Figure 15: The mean deviations of the start and end times of the approximate Steiner tree weights from those of the optimal Steiner tree weights ( | D | =10, | E | =20, qvn =3), DBLP-distance and optimal approaches to skynet Steiner tree computation, under the DBLP distance weight distribution and the quadruple-at-a-time relaxation strategy. This figure shows that for most semantics, the approximation approach works several of orders faster than the optimal computation. The only case where the approximation approach fails to provide an advantage is when the user is searching for the entire Pareto-optimal set under the DBLP-distance distribu-tion. The reason for this is that, under this distribution all edge weights are of the form [1 ,  X  ] and this leads to a large Pareto op-timal set, even under the approximation scheme as Table 1 shows. This does not occur for the other distributions, whose results are omitted because of space limitation.

Figure 13 considers the impact of the number of Steiner vertices on the Steiner tree skynet computation. As Figure 13 shows, the algorithm scales roughly linearly with the number of query vertices. Again, as the Figure 14 shows that the per Pareto-solution time scales even better than the full Pareto set search.
 Effectiveness of the Approximation. We can see from Figure 15 that when using DBLP-distance weights, the search problem search-for-one using both comparison operators se _ bef and we are able to obtain a solution tree which is very close to the Figure 16: Comparison of the impacts of different relaxation approaches on the Pareto set search for the bef ordering se-mantics ( | D | =5K, | E | =104K, qvn =3) Figure 17: Comparison of the impacts of different relaxation approaches on the Pareto set search for the bef ordering se-mantics ( | D | =100, | E | =7K, qvn =3) optimal solution ( OPT-sebef-search-one and OPT-bef-search-one ). Similarly, for search-for-ps , the solutions returned by our approach are very close to the optimal solutions. Similar results are also obtained for the other weight distributions. Table 1 provides a con-firmation of the similarities between the approximation results and optimal results: the table shows that the Pareto sets located by the approximation are similar to the sizes of the optimal Pareto sets.
These results suggest that the 2  X  approximation ratio is a very conservative worst case and the solutions we obtain in practice are much closer to the optimal solutions (on the average &lt; ation in interval start and end times).
 Impact of the Different Relaxation Approaches. Figure 16 com-pares the impact of two different relaxation approaches (quadruple-at-a-time and node-clustered) mentioned in Section 5.1.1. As Fig-ure 16(a) shows, both schemes have execution times that are com-parable to each other. Figure 16(b) confirms that this is because both schemes result in the similar numbers of obsolete quadru-ples. Figure 17 also reports the third relaxation approach, node-as-a-whole, for a smaller dataset | D | = 100 . As the figure shows, node-as-a-whole strategy is much c ostlier than the other relaxation approaches.
 Impact of the Skyline Union Operator. As Figure 18 shows, un-der most edge weight distributions and relaxation strategies, the skyline union operator ( ) provides  X  10  X  20% reduction in exe-cution times for the Pareto set search process. Figure 18: Impact of the skyline union ( )ontheParetoset search for the bef ordering semantics ( | D | =5K, | E | =104K, qvn =3) Figure 19: Comparison of the impacts of the two alternative cycle management techniques on the Pareto set search for the bef ordering semantics ( | D | =5K, | E | =104K, qvn =3) Impact of the Cycle Management Strategies. In Section 5.1.2, we have seen that there are two different strategies for cycle man-agement: propagating path signatures to eliminate cycles in the identified paths and performing topological sort to limit the trace-back operations to the ends of the forward and backward relaxation stages. As Figure 19 shows, under different edge weight distribu-tions, the path signature mechanism is faster; this is because the topological sort trades-off signature storage for more iterations.
In this paper, we introduced and studied the search problem on interval-weighted graphs that appear in various applications, in-cluding graph summarization, transportation and communication network, data (tree or graph) integration. In particular, we have for-mulated a general skynet problem of searches on graphs with par-tially ordered weights. We introduced alternative interval weight combination and comparison operators. We have also proposed al-ternative optimization criteria for the skynet search problem. We have then discussed how to extend existing Steiner tree search ap-proximation algorithms to handle searches for Steiner tree skynets on graphs with incomparable edge weights. We have seen that computation of Steiner tree skynets also necessitate the definition and implementation of path and spanning tree skynets. We also presented a skyline union operator to efficiently process intervals when we try to find the incomparable solution trees to cover the query keywords. The experiment results have shown that the pro-posed approximation algorithm provides close to optimal results and shows excellent scalability against graph and query sizes. In fact, experiments show that the actual approximation factor is bet-ter than the analytic upper-bound. Unfortunately, the algorithm H used in this paper for Steiner tree construction does not lend it-self into lower-bound computations. We note that there are other Steiner tree algorithms (such as relative greedy and loss contracting algorithms) with upper-(  X  1.6) and lower-(  X  1.3) bounds. Inves-tigation of SkyNets based on these, for cases where tighter upper-bounds are needed, is our future work.
