 IMED ZITOUNI and RADU FLORIAN IBM T. J. Watson Research Center 1. INTRODUCTION Information extraction is a crucial step toward understanding a text segment, as it identifies the important conceptual objects and relations between them in a discourse. It includes classification, filtering, and selection based on the language content of the source data. It i s a crucial preprocessing step for sev-eral applications, such as summarization, information retrieval, data mining, question answering, language understanding, etc. This article addresses an important and basic task of information extraction, mention detection , 1 the identification and classification of textual references to objects/abstractions mentions, which can be either named (e.g., Mohammed Ghannouchi), nominal (president), or pronominal (e.g., he, she). This is similar to the named entity recognition (NER) task with the additional twist of also identifying nominal and pronominal mentions. For instance, in the Arabic sentence which translates to: there are five mentions: two nominal ( and  X  ) that have the Eng-lish translation  X  X resident X  and  X  X inister, X  respectively; two named ( and Ghannouchi, X  respectively; and one pronominal (  X  X is X ). The word (minister) and the pronominal mention (last character of the word) In contrast to English mention detection, special attention is required when processing Arabic text in order to be able to detect partial parts of a word as a mention. This is because in Arabic, nominals and pronouns are attached to the word they modify. This rich morphology in Arabic presents additional challenges for mention detection when compared to English.
 guage resources that were created; f or instance, in English one has access to labeled part-of-speech data, word sense information, parse tree structure, discourse, semantic role labeles, and named entity data, to name just a few (our apologies if we missed your favorite resource). There are a few other lan-guages that also have annotated resources (such as Arabic, Chinese, German, French, Spanish, etc.), but also a very large number of languages with few re-sources. It would be very useful if one could make use of the resources in the former languages to help bootstrapping (or just the projection) of resource in any resource-challenged language. formation from a resource-rich langu age such as English to Arabic in order to improve Arabic mention detection system performance. Information trans-fer from a language to another can be very useful when the donor language has more resources than the receiving one. As resources grow in quantity and quality in the receiving language, it becomes less and less likely that there will be a gain in performance by transferring information, as there are sev-eral sources of noise involved in the process, such as the translation (machine generated or not) and the inherent imperfection of the mention detection in the donor language. To test this hypothesis, we conducted experiments on sys-tems built with a varied number of resources in the receiving language Arabic, starting with the case where there are none 2 (all information is transferred through translation alignment), and ending with the case where we used all the resources we could gather. The experiments will show that the gain in per-formance decreases with the amount of re sources used in the source language, but even when all resources were used, a statistically significant gain was still observed. In addition to Arabic-English language pair, we also show the effec-tiveness of our approach on other language pairs such as Chinese-English and Spanish-English.
 Marcus 1995] and named entity recognition [Tjong Kim Sang 2002], we for-mulate mention detection as a sequence classification problem by assigning a label to each token in the text, indicating whether it starts a specific men-tion, is inside a specific mention, or is outside any mentions. The classification is performed with a statistical approach, built around the maximum entropy (MaxEnt) principle [Berger et al. 1996], that has the advantage of combining arbitrary types of information in making a classification decision. In Section 3 we introduce the unit of analysis used by the Arabic mention de-tection classifier and we explain the re quired preprocessing steps. Section 4 describes the technique used by our Arabic mention detection system ans well as the set of used features. Section 5 presents our approach of using cross-language mention propagation information that makes use of large, existent resources in one language to improve mention detection system in another language (source language). While the method works in cases where linguistic resources do not exist in the source la nguage, we are more interested in the gain in performance one can get while using the technique in languages where such resources exist. Section 6 shows the resources we used to validate the ap-proach we propose, and Section 7 presents the resource-rich language we chose for our experiments. Section 8 describes the conducted experiments where we confirm the effectiveness of the proposed approach to improve the performance of our mention detection system. Section 11 concludes the article. 2. PREVIOUS WORK There are several investigations in literature that explore using parallel corpora to transfer information content from one language (most of the time English) to another. The earliest investigations of the subject have been per-formed on word sense disambiguation [Dagan et al. 1991; Brown et al. 1991; Gale et al. 1992]. Perhaps unsurprisingly given its close connection to ma-chine translation, all propose and (lightly) evaluate methods to use word sense information extracted from the target language to help the sense resolution in the source language and machine translation. Dagan and Itai [1994] ex-plicitly suggest performing word sense disambiguation in the target language (English in the article) with the goal of resolving ambiguity in the source lan-guage (Hebrew), and show moderate improvement on a small data set. 3 More recently, Diab and Resnik [2001] present a method for performing word sense tagging in both the source and target texts of parallel bilingual corpora with the English WordNet sense inventory by using translation correspondences. [2001] proposed and evaluated a method of propagating POS tagging, named mention, base noun phrase, and morphological information from English into a foreign language, which is very similar to the one presented in this article (experiments were run on French, Chinese, Czech, and Spanish on human-generated translations). Their results show a significant improvement in per-formance while building an automatic classifier on the projected annotations over the same automatic classifier trained on a small amount of annotated data in the source language. Riloff et al. [2002] extends the ideas in Yarowsky et al. [2001], by showing how it can be used in conjunction with an automatically trained information extraction system on the source language to bootstrap the annotation of resources in the target language. They show that they can obtain 48 F -measure on a information extraction task identifying locations, vehicles, and victims in plane crashes. Hwa et al. [2002] propose a framework that enables the acquisition of syntactic dependency trees for low-resource languages by importing linguistic annotation from rich-resource languages (English). The authors run a large-scale experiment in which Chinese depen-dency parses were induced from English, and show that a parser trained on the resulting trees outperformed simple baselines. Cabezas et al. [2001] in-vestigate a similar method of propagating syntactic treebank-like annotations from English to Spanish.
 information retrieval , where the goal is to find information in one language (e.g., Chinese newswire) corresponding to a query in a different language (e.g., English), although the list of relevant articles is too long to be mentioned here (see, for instance, Grefenstette [1998]). tions presented in two aspects.  X  X t handles unrestricted text and a full set of mention types (the ACE entity types) during the information transfer.  X  X t investigates whether using a resource-rich language (English) can improve on the performance obtained by using various degrees of existent resources in the source language (Arabic, Chinese, Spanish).  X  X he information transfer is performed over machine generated translations and alignments. 3. THE UNIT OF ANALYSIS Arabic words are composed of zero or more prefixes, followed by a stem and zero or more suffixes; most morpheme s are comprised of a basic word form (root or stem), to which many affixes can be attached to form Arabic words. Enclitic pronouns are attached to the word they modify: pronouns are often realized as prefixes or suffixes attached to an Arabic base form (stem). mentions, it is essential to define a unit of analysis which splits Arabic words into sub-word tokens (segments) or characters. On one side of the spectrum, if we consider a character as the subject of analysis (i.e., split all words into indi-vidual characters), the mention detection system will make a decision whether it is the beginning of a mention, inside a mention, or outside a mention, for every character in the document. This idea was successfully applied for lan-guages like Chinese [Jing et al. 2003], but for a language having rich morphol-ogy, this will be suboptimal, as contexts would have to be quite long to capture interesting phenomena. On the other side of the spectrum, using a white-space delimited word as the analysis unit leads to data sparseness and does not allow the detection of any sub-word units (such as inflected pronouns).
 We start with the segmentation of the Arabic document into a sequence of segments, which then become the subject of analysis (tokens). The segmen-tation process consists of separating the normal white-space delimited words into hypothesized prefixes, stems, and suffixes. The Arabic mention detection system proceeds then on each token to make a decision if it is the beginning of a mention, inside a mention or outside a mention. The resulting granularity of breaking words into segments allows a prefix or a suffix to receive a label dif-ferent from that of the stem (for instance, in the case of pronominal mentions). scribed in Benajiba and Zitouni [2010]. This segmentation system that is based on the weighted finite state transducers (WFST) technique, which has an accu-racy of 97.8% when tested on data from the combined Arabic Treebanks 1V2, 2V2, and 3V1. The following are two examples of how we segment the text: in the first, the word (she) and system will split this word into three segments: (them). Then, the mention detection (MD) system should be able to correctly classify the character strings (segments) referring to the mentions: in this example. As the second example, for the word segmentation system splits it into two tokens: 3 (location) and The mention detection system then detects that the token 3 (location) is a mention that refers to the entity location, whereas the token mention, but one that might refer to a group of persons. In addition, the prep-ositions, for example, (for their location), respectively, should not to be considered as part of a mention. 4. MENTION DETECTION As mentioned in the introduction, the mention detection problem is formulated as a classification problem by assigning a label to each token in the text indi-cating whether it starts a specific mention, is inside a specific mention, or is outside any mentions.
 shown to depend heavily on integrating many sources of information [Florian et al. 2004]. 4 Given this observation, we are interested in algorithms that can easily integrate and make effective use of diverse input types. Similar to Benajiba and Zitouni [2010], we select a maximum entropy (MaxEnt hence-forth) classifier that integrates arbit rary types of information and makes a classification decision by aggregating all information available for a given clas-sification. In this article, the MaxEnt model is trained using the sequential conditional generalized iterative scaling (SCGIS) technique [Goodman 2002], and it uses a Gaussian prior for regularization [Chen and Rosenfeld 2000]. For more details about this technique and how it is applied to MD, the reader may refer to Benajiba and Zitouni [2010], Zitouni and Florian [2008], and Florian et al. [2004].
 tence or a document) in the source language. The goal of mention detection matches the input x N 1 . In the mention detection case, each token x i in x N 1 is tagged with a label y i as follows: 5  X  X f it is not part of any entity, y i = O (O for  X  X utside any mentions X ).  X  X f it is part of an entity, it is composed of a subtag specifying whether it starts a mention ( B -) or is inside a mention ( I -), and a subtype corresponding to mention type (e.g., B-PERSON ). In ACE, there are seven possible types: per-son, organization, location, facility, geopolitical entity (GPE), weapon, and vehicle. To compute the best sequence y N 1 ,weuse where P  X  y j | x N 1 , y j  X  1 j  X  k has an exponential form computed with the MaxEnt probability distribution [Berger et al. 1996]. We also used the standard Markov classifications, similar to Benajiba and Zitouni [2010] and Zitouni and Florian [2008]. 4.1 Mention Detection: Features The particular features used in our mention detection system can be divided into four different categories: lexical, gazetteers-based, syntactic, and informa-tion obtained from other named-entity classifiers (with different semantic tag sets) features. The Markov size of the model is 2 (i.e., using tag trigrams). (1) Lexical Features. The identity and the context of a current token (segment) (2) Syntactic Features. The syntactic features include POS tags [Toutanova (3) Features from Other Named-Entity Classifiers. In addition to using lexi-5. CROSS-LANGUAGE MENTION PROPAGATION The approach proposed in this article requires a mention detection system built in a resource-rich language, and a translation from the source language to the resource-rich language, together with word alignment. This assump-tion is realistic: while truly parallel data (humanly created) might be in short supply or harder to acquire, adapting statistical machine translation (SMT) systems from one language-pair to another is not as challenging as it used to be [Al-Onaizan and Papineni 2006]. We also find that there is a large number of parallel corpora available these days which cover many language pairs. For example, for the European Union X  X  23 official languages we find 253 language pairs; each document in one language might have to be translated in all other 22 languages. This is in addition to parallel corpora one could get from books, including religious texts such as the Bible, that are translated into a large number of languages. On the other hand, even though mention detection sys-tem is important for many natural language processing applications, we still find lack of mention-annotated corpora in many languages. In the approach we propose below, the annotated corpus used to train the mention detection classifier does not have to be part of a parallel corpus.
 unit (document or sentence) x N 1 into the resource-rich language, yielding the sequence  X  M 1 =(  X  1 , X  2 ,... X  M ). Taking the sequence of tokens  X  M 1 as input, the MaxEnt classifier assigns a mention label to each token, building the label sequence  X  M 1 =(  X  1 , X  2 ... X  M ). Using the SMT-produced word align-ment between source text x N 1 and translated text  X  M 1 [Koehn 2004], we propa-gate the target labels  X  M 1 to the source language building the label sequence  X  y 1 =(  X  y 1 tagged as a location mention, then the sequence x j x j +1 can be labeled as a location mention: B-LOC, I-LOC. Hence, each token x i in x N 1 is tagged with alignment between the source and resource-rich languages. In cases when the alignment is 1-to-1 the function becomes the identity, but one can imagine dif-ferent scenarios which can be used in many-to-many alignment cases. The alignment we use in this article is 1-to-many ( { 1 ... n } ) from the source language (e.g., Arabic) to the resource-rich language (e.g., English). Once we use SMT word alignment to propagate label sequence  X  M 1 of  X  M 1 to the corresponding text x N 1 in the target language, we end up with a sequence of labels  X  y N 1 where span, and if the strategy results in two mentions where one contains the other, we eliminate the inner one.
 automatic translation. It also shows a good match between the gold-standard tags in Arabic and the automatically extracted tags in English.
 (1) Consider  X  y N 1 as the result of propagating the detected mentions in the orig-(2) Use the label sequence  X  y N 1 as an additional feature in the MaxEnt frame-(3) Starting with a large corpus (possibly including the training data), trans-From a runtime point of view, the CIP method has the advantage that there is no need to perform machine translation, and it can incorporate data from a very large amount of text. The CDP method, on the other hand, has the advan-tage that features are computed in context, and will not fire unless the corre-sponding mentions were found in the translated version (hence the name). Of course, the CDP method can incorporate features generated in the dictionary G . The experimental section analyzes the impact of each of these techniques on mention detection task performance. 6. RESOURCES Experiments are conducted on the ACE 2007 data sets. 9 This data is selected from a variety of sources (broadcast news, broadcast conversations, newswire, Web log, newswire, conversational telephony) and is labeled with seven types: person (PER), organization (ORG), location (LOC), facility (FAC), geo-political entity (GPE), vehicle (VEH), and weapon (WEA). Besides mention-level infor-mation, also labeled are coreference between the mentions, relations, events, and time resolution.
 licly available training corpus into an 85%/15% data split. To facilitate future comparisons with work presented here , and to simulate a realistic scenario, the splits are created based on article dates: the test data is selected as the latest 15% of the data in chronological order. This way the documents in the training and test data sets do not overlap in time, and the content of the test data is more recent than the training data. Table I presents the number of documents in the training/test datasets for Arabic and English.
 purpose measure, the ACE value metric [NIST 2007], given that we are inter-ested in the mention detection task only, we decided to use the more intuitive and popular (unweighted) F -measure, which is the harmonic mean of precision and recall.
 pared to another system is statistically significant or not, we use the stratified bootstrap resampling approach [Noreen 1989]. This approach is used in the named entity recognition shared task of CoNNL-2002. 10 In the following ta-bles,weaddthedaggersign(  X  ) to results that are statistically insignificant when compared to baseline results. 7. ENGLISH AS RESOURCE-RICH LANGUAGES From the set of four languages in ACE 2007, we will unsurprisingly select English as the resource-rich language. Table II shows the performance of mention detection systems in all four languages one can obtain by using all available resources. Systems have access to a large range of features, includ-ing lexical (words and morphs in a three-word window, prefixes, and suffixes of length up to four, WordNet [Miller 1995] for English), syntactic (POS tags, text chunks), and the output of other information extraction models. formance when compared to systems dealing with other languages such as Arabic, Chinese, and Spanish. These results are expected since our English model has access to a larger training data and uses richer set of information such as WordNet [Miller 1995] and the output of a larger set of information extraction models. English mention detection systems are similar to the one described in Florian et al. [2004] where words are the tokens to classify. tational linguistics community in the last 30 years, especially when it comes to applications such as named entity recognition and automatic content extrac-tion Florian et al. [2004]. In the rest of this article we will consider English as the resource-rich language to be used to help improve the performance of Arabic (source language) mention detections system. 8. EXPERIMENTS To show the effectiveness of cross-language mention propagation information in improving Arabic mention detection system performance, we use an Arabic to English SMT system with very compet itive performance in terms of BLEU [Papineni et al. 2002]. The Arabic to English SMT system is similar to the one described in Huang and Papineni [2007]; it has a 0 . 55 BLEU score on NIST 2003 Arabic-English machine translation evaluation test set and is ranked among the top two systems participating in NIST evaluations. Also, the Eng-lish mention detection system used for experiments has an F -measure of 82.7 and that has very competitive results among systems participating in the ACE 2007 evaluation. As mentioned in Section 5, we assume the availability of two components: (1) a statistical machine translation system that translates text from Arabic to English, and (2) an English mention detection system. the effectiveness of our approach in improving mention detection system per-formance on languages wit h different resources. (1) The system does not have access to any training data in Arabic. (2) The system has access to only lexical information. (3) The system has access to lexical and syntactic (e.g., POS tags, text chunks) (4) The system that has access to lexical, syntactic, and semantic information The rest of this section examines these four cases. 8.1 No Arabic Training Data In this first case, as described in Section 5, the mention labels in the source language are obtained directly through the alignment from the mentions in the translated text. This is a very simple scenario which can be implemented with ease, and, as we will see, yields reasonable performance out-of-the-box. the text x N 1 into English producing the text  X  M 1 . We run the English mention detection system on  X  M 1 to find the most likely mention label sequence  X  M 1 .As shown in Section 5, we then use the alignment between x N 1 and  X  M 1 to propagate is the system output.
 ing this information transfer approach from the English text. Even though no training data to build a source language mention classifier is available, we still can detect mentions with reasonably good accuracy. We consider the ob-tained accuracy as reasonably good because, as an example, the performance of a system that attaches to every word its most frequent label (unigram) is around 25% F -measure on Arabic. 8.2 Lexical Resources In this section, we assume that we have available training data in the source language to be able to train a statistical classifier. We also consider that the MaxEnt classifier have access to lexical information only on the source lan-guage. In our case, we also use Arabic morphological analysis information to specify which part of the word is a prefix, stem, or a suffix [Lee et al. 2003]. Our goal here is to study the effectiveness of adding cross-language mention prop-agation information to improve mention detection performance on languages with limited resources.
 and without cross-language mention propagation information from English:  X  Baseline represents system performance without any cross-language mention propagation information.  X  CIP represents system performance when adding cross-language context independent mention propagation information (see Section 5 for details).  X  CDP represents system performance when adding cross-language context dependent mention propagation information.

Results in Table IV show that cross-language mention propagation informa-tion improves mention detection systems performance. Compared to baseline results, obtained improvements are statistically significant, 11 except those re-sults with a dagger sign (  X  ) next to them. When systems use the CIP method, no improvement can be noticed on Arabic (76.4 F vs. 76.4 F ). In contrast, when systems use the CDP method an interesting improvement is obtained in re-call which is to be expected, given the method, but also in precision (not as marked), leading to systems with better performance in terms of F -measure: 1.6 F points improvement for Arabic (76.4 F vs. 78.0 F ).Onehypothesisisthat the CIP method didn X  X  improve the performance because dictionaries are not rich enough and cover only limited part of the language. Also, we notice that the use of CDP is effective for all mention types, except weapon mentions. We think that this is due to their count that is low in source and rich language texts we use for training and decoding. 8.3 Lexical and Syntactic Resources We represent in Table V mention detection system performance when syntactic resources are available in Arabic, in a ddition to lexical resources available in Section 8.2. This experiment is important because it tests the effectiveness of the propagation approach in improving performance on languages with a typical level of resources.
 information, the use of cross-language mention propagation information still leads to considerable improvement: when CDP information is used we obtain 1.5 F improvement (78.6 vs. 77.1). Similar to previous section where systems have access to lexical information only, the use of CIP information did not improve performance (77.5 vs. 77.1). Results show improvements that are statistically significant based on the stratified bootstrap resampling technique [Noreen 1989].
 cross-language mention propagation information has better impact on system with lexical resources only: adding CDP information gives 1.6 F points im-provement (78.0 F vs. 76.4 F ) compared to syntactic information that gives only 0.7 F improvement (77.1 F vs. 76.4 F ). This is expected, because the more accu-rate the model gets, the more difficult it becomes to improve its performance. 8.4 Lexical, Syntactic, and Semantic Resources This section investigates whether the access to cross-language mention prop-agation information can still improve the performance of existing competitive mention detection systems trained on languages with large resources. We con-sider here the case where systems have a ccess to a full array of lexical, syntax, semantic information, including the output from other information extraction models. Table VI presents the performa nce of Arabic mention detection sys-tems in cases where no cross-language propagation is used, and also where the CIP and CDP methods are used. Results show that better performance is ob-tained when cross-language mention information is used. When CIP is used, almost no change in terms of performance is obtained: slight improvement by 0.2 F (80.2 F vs. 80.0 F ). When CDP is used the performance of mention de-tection systems is improved by 0.9 F for Arabic (80.9 vs. 80.0). Once again, the results prove that the use of cross-langua ge mention propagation information, especially through CDP, is effectiv e in improving the performance. formance has a decreasing tendency a s more resources are available. The performance gain for CDP in Arabic goes from 1.6 to 1.5 to 0.9. While the evidence here is not definitive, one can indeed note the reduced effectiveness of the method as more resources are available, which was indeed what we expected.
 9. APPLICATION TO CHINESE AND SPANISH In order to investigate the effectiveness of our approach, we also applied it to enhance mention detection systems in other languages such as Chinese and Spanish. These two language are part of the four languages of interest in ACE 2007, in addition to Arabic and English.
 Spanish-English SMT systems as well as an English mention detection sys-tem. Table VII shows the performance of the translation systems on Arabic-English, Chinese-English, and Spanish-English language pairs, computed on standard test sets. The Chinese to English SMT system has similar archi-tecture to the one described in Al-Onaizan and Papineni [2006]. This system obtains a score of 0 . 32 cased BLUE on NIST 2003 Chinese-English machine translation evaluation test set. The Spanish to English SMT system is similar to the one described in Lee et al. [2006]; it has a 0 . 55 BLEU score on the final text edition of the European Parliament Plenary Speech corpus in TC-STAR 2006 evaluation. These SMT systems have very competitive performance and are ranked among top two systems participating in NIST or TC-STAR evaluations.

As mentioned earlier, the mention detection problem is formulated as a se-quence classification problem by assigning to each token in the text a label. For Chinese we consider the character as the token to be labeled, whether in Spanish we take the word itself as the token to classify. In Chinese text, unlike in Indo-European languages, words neither are white-space delimited nor do they have capitalization markers. Instead of a word-based model, we build a character-based one, since word segment ation errors can lea d to irrecoverable mention detection errors; [Jing et al. 2003] also observes that character-based models are better performing than word-based ones. Word segmentation infor-mation is still useful and is integrated as an additional feature stream. The architecture of the Spanish mention detection system is similar to the English model where words are the tokens to classify. 9.1 No Source Language Training Data When the mention labels in the source language are obtained directly through the alignment from the mentions in the translated text, we obtain reasonable accuracy. Results in Table VIII show that even though the Chinese-to-English SMT system is lower in terms of BLEU than the Arbic-to-English SMT system (0.32 vs. 0.55), performance of the cross-language propagation from English mention detection system onto Chinese is better than the performance of the propagation from English mention detection system onto Arabic. One reason for this is that we notice that the Chinese-to-English SMT system translates and aligns ACE categories better than the Arabic-to-English SMT system. 9.2 Lexical Resources When we only have access to lexical information and a training data in the source language to train a statistical classifier, the use of mention propagation information results in system performa nce increase (c.f., Table IX). When sys-tems use the CIP method, no improvement can be observed on Chinese (simi-lar to Arabic), while a small improvement of 0 . 5F point is obtained on Spanish (74 . 5vs. 75 . 0). In contrast, when systems use the CDP method an improve-ment is obtained in recall which is to be expected given the method, leading to systems with better performance in terms of F -measure: 1.6 F points improve-ment for Arabic, 1.5 F points improvement for Chinese and almost 3 F points improvement for Spanish. The results for all the CDP transfers and the CIP for Spanish are statistically significant. 9.3 Lexical and Syntactic Resources When lexical and syntactic resources are available in the source language, re-sults reported in Table X show once again the effectiveness of this approach to improve performance. Using the CDP transfer method yields improvements from 1 . 1 F in Chinese to 2 . 6 F in Spanish. Similar to the previous section on Arabic, the use of CIP information did not improve performance significantly on Chinese (75 . 5vs.75 . 5) system, but we notice an improvement in Spanish. 12 9.4 Lexical, Syntactic, and Semantic Resources In this experiment, systems have access to a full array of lexical, syntax, and semantic information, including the output from other information extraction models. Table XI presents the performance of mention detection systems on the three languages, in the familiar three propagation methods: again, results for Chinese and Spanish are similar to those obtained in the previous sec-tion for Arabic. Better performance is obtained when cross-language mention information is used. Under CIP, almost no change in terms of performance is obtained for Arabic and Spanish, though a slight improvement can be observed for Chinese (76.9 F vs. 75.8 F ). When CDP is used the performance of mention detection systems is improved by 0.9 F for Arabic (80.9 vs. 80.0), 2.3 F for Chinese (78.1 F vs. 75.8 F )and1.9 F for Spanish (78.1 vs. 76.2 F ). Once again, the results prove that the use of cross-language mention propagation in-formation, especially through CDP, is e ffective in improving the performance even in this case. 10. DISCUSSION By comparing results across tables, one can note that systems having access to only lexical and cross-language mention propagation information are as ef-fective as systems having access to large set of information. For Chinese, we obtain a performance of 75.8 F when the system has access to lexical, syntac-tic, and output of other information extraction models. On the other hand, the same system has a slightly better performance of 76 . 0 when it has access to lexical and cross language mention propagation information. The same behav-ior is observed for Spanish, we obtain a performance of 76.2 F when the sys-tem has access to lexical, syntactic, and o utput of other information extraction models; compared to 77.4 F when lexical and cross-language mention informa-tion are used. This is not true for Arabic, where having access to larger set of information led to better performance when compared to systems having ac-cess to lexical information and CDP information (80.0 F vs. 78.0). We attribute this difference to the fact that in Arabic we use the output of larger number of information extraction models and consequently a richer set of information. performance has a decreasing tendency as more resources are available. The performance gain for CDP in Arabic goes from 1.6 to 1.5 to 0.9, and the one in Spanish goes from 2.9 to 2.6 to 1.9. The one in Chinese follows part of this trend, as it goes from 1.4 to 1.1 to 2.3. While the evidence here is not definitive, one can indeed note the reduced effectiveness of the method as more resources are available, which was what we expected.
 tion: when trying to improve mention detection systems in a resource-poor language, should we invest in building resources or should we use propagation from a resource-rich language to (at least) bootstrap the process? The answer seems to be the latter. 11. CONCLUSION This article investigates a new approach to mention detection in low, medium, or high-resource languages, which benefits from projecting the output of a system trained in a resource-rich language, such as English. We show that even when no training data is available in one source language, we can still build a decently performing baseline mention detection system by only using resources from English. This approach requires a mention detection system on a resource-rich language and an SMT system that translate text from the source to the resource-rich language, both of which can be readily attained. language mention propagation technique is still able to further improve men-tion detection system performance. Experiments performed on the four lan-guages of ACE 2007, with English chosen as the resource-rich language, show consistent and significant improvements across conditions and levels of lin-guistic sophistication. The experiments are conducted on clearly specified par-titions of the ACE 2007 data set, so future comparisons against the presented work can be correctly and accurately made. We also note that systems that have access to lexical and cross-language mention pro pagation information are as accurate as those that have access to lexical, syntactic, and output of other information extraction models in the source language (but no cross-language resources). As future work, we plan to extend this work to use semi-supervised and unsupervised approaches that can make use of cross-language information propagation.

We believe that it is important for the research community to continue to invest in building better resources in source languages, as it looks the most promising approach. It is also our believe that using a propagation approach can definitely help bootstrap the process.

