 Michael Karlen  X  X  michael.karlen@gmail.com Jason Weston  X  jasonw@nec-labs.com Ayse Erkan  X  X  naz@cs.nyu.edu Ronan Collobert  X  collober@nec-labs.com Several methods for improving discriminative classi-fiers using unlabeled data have been developed in the last few years. Perhaps the two most popular ways of utilizing the unlabeled data are: (i) maximizing the margin on the unlabeled data (ii) learning the cluster or manifold structure from Both approaches can be seen as making the same structure assumption on the data, that the cluster or manifold structure in the data is correlated with the class labels of interest.
 The Low Density Separation algorithm (LDS) (Chapelle &amp; Zien, 2005) is a two-stage algorithm that combines both of these approaches, with improved re-sults over using only one of the techniques, however the combination method is somewhat ad-hoc .
 A serious problem with all these methods is that they suffer from an inability to scale to very large datasets, apart from in the linear case (Sindhwani &amp; Keerthi, 2006). This is ironic because the potential gain of semi-supervised learning lies in the vast amounts of readily available unlabeled data. This performance gain is never attained simply because of the compu-tational burden of calculating the result. In the con-clusion of the article describing the LDS algorithm the authors state:  X  X e observe that the time (and to some degree, also space) complexities of all methods investigated here prohibit the application to really large sets of unla-beled data, say, more than a few thousand. Thus, work should also be devoted to improvements of the com-putational efficiency of algorithms, ideally of LDS. X  In this work we propose a new method for semi-supervised learning which features the following im-provements over existing approaches:  X  A new regularizer for semi-supervised learning is  X  We train our system using stochastic gradient de- X  We show it is also possible to encode domain The rest of the article is as follows. Section 2 describes in detail existing margin and manifold based regular-ization approaches, and scalability of the resulting al-gorithms. Section 3 describes our proposed approach, Section 4 compares it experimentally to existing meth-ods, and Section 5 concludes. As stated in the introduction, two of the most pop-ular loss functions (regularizers) for using unlabeled data are margin -based regularization as in TSVMs and manifold -based regularization. We will discuss each of these in turn. 2.1. TSVMs The Transductive Support Vector Machine (TSVM) is an algorithm originally proposed by Vapnik (1998) to take advantage of both a labeled training set and an unlabeled test set during prediction time. It was named that way because Vapnik proved bounds on generalization performance given the availability of the test set that were superior to induction based on using the labeled training set alone. The idea of the algo-rithm was: (i) Choose a nested set of functions F 1  X  X  2  X  . . . (ii) For each possible labeling of the test examples, (iii) Choose the labeling which required the smallest In terms of actual implementation it is known that the notion of margin  X  the distance of examples from the classifier X  X  decision rule  X  is connected to the concept of capacity (Vapnik, 1998), so a simple algorithm is the following: choose the decision rule that maximizes the margin on both labeled and unlabeled examples. The Support Vector Machine (Vapnik, 1998) for two-class classification already implements a margin based capacity control on labeled examples, using an opti-mization problem of the following form: where the family of functions are beled training examples, and the loss function ` (  X  ,  X  ) is the so-called hinge loss: To implement Transductive SVMs it is (almost) suffi-cient to take the SVM optimization problem (1) and add an extra term for the unlabeled examples: min where the U unlabeled examples use the so-called sym-metric hinge loss function which, intuitively speaking, pushes the unlabeled ex-amples far from the margin: the absolute value is necessary in equation (5) because one does not know which side of the hyperplane those examples should lie on, unlike the labeled examples, so effectively the classifier trains on its own predictions. This notion of self-learning (Chapelle et al., 2006) can cause disas-trous consequences in some cases: especially when the dimensionality d L one might be able to classify all unlabeled examples as belonging to one class whilst still classifying the labeled data correctly, giving a low value of the objective function, but nonsense results. This is solved by introducing a so-called balancing con-straint which attempts to keep some of the unlabeled examples in each class.
 Many researchers seem to be believe that the TSVM objective function is a good choice for semi-supervised learning. However, finding a solution to the non-convex problem is far from easy, and thus several im-plementations have been attempted thus far. We will now describe some of those specific implementations, and their key differences.
 S
VM The authors of (Bennet &amp; Demiriz, 1998) proposed to use mixed integer programming to find the labeling with the lowest objective function. The optimization appears intractable for large datasets, as  X  X he solver failed due to excessive branching X  in those cases. Only the linear case was considered, and no balancing constraint was used.
 SVMLight-TSVM In (Joachims, 1999) a heuristic algorithm was proposed that at first fixes the labels of the unlabeled examples and then iteratively switches those labels to improve the TSVM objective function, solving a convex SVM objective function at each step. The nonlinear case is implemented by solving in the dual, resulting in a kernel model of the form: A balancing constraint enforces that the fraction of positive and negatives assigned to the unlabeled data should be the same fraction as found in the labeled data. According to the proof of convergence, the al-gorithm at worst case could look at all 2 U labelings, but this is rather unlikely. The algorithm can deal with a few thousand examples in the nonlinear case in practice, but is faster in the linear case.
 VS 3 VM In (Fung &amp; Mangasarian, 2001) a concave-convex minimization approach was proposed that solves successive convex problems, usually requiring only 5-7 linear programs, where they chose the L 1 norm of w as a regularizer instead of the L 2 norm. They studied the linear case, with no balancing con-straint. This method will scale like the linear solver used in each iteration.  X  TSVM More recently, the authors of (Chapelle &amp; Zien, 2005) proposed to optimize TSVM by gradient descent in the primal. For the nonlinear case, Ker-nel PCA has to be performed so that optimization in the primal is possible. This algorithm is faster than SVMLight-TSVM at least for small datasets (Col-lobert et al., 2006), but still has cubic complexity O (( U + L ) 3 ). This method also requires one to store the entire kernel matrix of ( U + L ) 2 elements in mem-ory, which clearly becomes infeasible for large datasets. The authors introduced a balancing constraint that is amenable to gradient descent: CCCP-TSVM The authors of (Collobert et al., 2006) proposed to apply the Concave-Convex proce-dure for non-convex problems to TSVMs, which can be seen as a nonlinear extension of VS 3 VMs. It uses the same balancing constraint as  X  TSVM. This im-plementation is over 100 times faster than SVMLight-TSVM and 50 times faster than  X  TSVM (for L + U = 2000), and appears to scale better as well. It has em-pirically quadratic complexity because it relies on the sparsity of the SVM solution for improved speed and memory requirements. However, it still takes around 40 hours on a modern machine to solve a problem with 60,000 unlabeled examples in the nonlinear case. Large Scale Linear TSVMs The authors of (Sind-hwani &amp; Keerthi, 2006) recently proposed a large scale TSVM method for the linear case. They focused on text problems with large sparse feature vectors and train the model (2) directly in the primal. In particu-lar, they use a label switching heuristic like SVMLight-TSVM, but switch multiple labels at once.
 In the nonlinear case things are not so easy. One is restricted in the quest to reduce training time by the prediction speed of the model (6) . Moreover, compu-tation grows as the training data grows (Steinwart &amp; Scovel, 2005). Even if one tries tricks to keep a fixed number of basis functions these methods are still slow compared to multi-layer models (Burges, 1996). 2.2. Manifold-based regularization A separate direction of research in semi-supervised learning is manifold-learning based regularization. The main idea in these approaches is to find a rep-resentation of the data which collapses points lying in the same manifold so that a classification algorithm can easily predict that they share the same class label. These methods can be split into two categories: those which treat this as a two-stage problem: (i) learn an embedding and (ii) train a classifier in this new space, and those which try to do everything in a single step. To train a two-stage classifier, in the first stage one employs any manifold-learning algorithm such as Isomap (Tenenbaum et al., 2000), Laplacian Eigen-maps (Belkin &amp; Niyogi, 2003) or spectral clustering (Ng et al., 2002). The authors of (Chapelle et al., 2003) use such methods to build a kernel for SVMs and call these kernels  X  X luster kernels X . The  X  X raph X -SVM method proposed in (Chapelle &amp; Zien, 2005) also builds a kernel for SVM. In this method one embeds in a space where distances are the shortest paths on the graph weighted with the original distance mea-sure, similar to the Isomap algorithm. Thus, points connected by regions of high density are close to each other in the new space.
 To learn a single stage classifier, one has to introduce a regularizing term in the objective function which di-rectly encodes behavior such as that described in the previous paragraph. The Laplacian Eigenmaps em-bedding algorithm in particular employs an objective function that is easily encoded in a classifier: Such a regularizer has been used both to generalize a Parzen-windows (Duda &amp; Hart, 1973) type classifier resulting in a method called label propagation (Zhu &amp; Ghahramani, 2002), and in SVMs. The SVM method is called Laplacian SVMs (LapSVM) (Sindhwani et al., 2005) and minimizes: min We speculate here that forcing the Euclidean distance to be small if two points are assumed to be the same label might be a little stringent as for prediction it is only the sign of f ( x  X  ) that is important. Moreover, we also note that the lack of balancing constraint might mean in high dimensions that all the unlabeled exam-ples can collapse to a single prediction.
 In contrast, the LDS method (Chapelle &amp; Zien, 2005) proposes to use both TSVM and manifold regularizers at once in a two-stage method. First, the Isomap-like embedding method of  X  X raph X -SVM is used whereby data is clustered. Then, in the new embedding space,  X  TSVM is applied. The authors found that using both regularizers at once was better than using one type of regularizer alone.
 In summary, we have discussed several algorithms which use two main types of regularizer: a cluster-ing or an embedding that takes into account struc-ture in the unlabeled data. Indeed TSVM is a kind of large margin clustering as has been exploited in (Xu et al., 2005) and is strongly related to classical tech-niques like competitive learning (Duda &amp; Hart, 1973). In (Chapelle &amp; Zien, 2005) the authors speculate that manifold-based regularization has a stabilizing effect on TSVM optimization. Without such neighborhood-based regularization TSVMs only compare unlabeled examples to the existing model, and not to each other. Using both approaches as in LDS is thus a smart idea, however it suffers from two problems: (i) the two-stage approach seems ad-hoc and (ii) the method is slow. In the next Section we propose a new approach which remedies these problems. We propose the following algorithm, named Manifold Transduction: minimize 1 L where where the edge weights W ij define pairwise similarity relationships between unlabeled examples x  X  . This objective, like TSVMs objective, is non-convex and there is no simple optimization scheme for solv-ing it even for linear models such as kernel machines. Because of this fact, and the scalability problems with nonlinear kernel methods, we propose several novel al-gorithmic choices in its implementation: (i) We minimize this function in the primal by (ii) In the nonlinear case we employ a multi-layer ar-(iii) We also make a specific recommendation for the We will now study this algorithm, and explain the rea-son for these choices in detail. 3.1. Objective function In (10) we propose a new loss function for unlabeled examples : where N is a set of examples that one believes share the same label, e.g. a set of neighboring examples. The function y  X  predicts the label of that set by taking the mean prediction.
 For both labeled and unlabeled training data we use the hinge loss (3) as in SVMs.
 In equation (10) we consider pairs of examples, weighted by the graph W ij . If W ii = 1 and W ij = 0 for i 6 = j then we recover the TSVM loss function: because we do not take neighborhood information into account.
 Setting W ij = 1 if x  X  i is among the k -nearest neighbors of x  X  j , and zero otherwise, our algorithm becomes a natural generalization of TSVM that regularizes using neighborhood information. This is a similar regular-izer to the neighborhood-based manifold regularizers of Section 2.2 but based on clustering rather than em-bedding .
 We make the assumption that if two examples are neighbors then they have the same class label , whereas manifold-based regularization assumes they are close in an embedding space . Our constraint is not as strict, but captures the prior we wish to encode. For exam-ple, if one class of data has more variance than the other, then the regularization of (9) might focus on that class, and ignore the other.
 Extensions of our algorithm are also possible. First, in the multi-class case where f ( x  X  ) outputs a c -dimensional vector, we can define y  X  ( N ) = argmax P k  X  N f ( x  X  k ). Further, if the set N contains more than two examples then our algorithm takes into account a neighborhood in analogy to k -nearest neigh-bor. This is not easily possible with the approach of (9) which is limited to pairs. 3.2. Model: Multi-Layer Architecture As already discussed, the issue that makes all the pre-viously described algorithms computationally expen-sive in the nonlinear case is their choice of the kernel expansion (6). Instead we propose to use a multi-layer model of the form: where typically one chooses hidden units Algorithm 1 Online Manifold Transduction
Input: labeled data ( x i , y i ) and unlabeled data x  X  i repeat until stopping criteria is met. where S is a non-linear squashing function. We use the Hard Tanh function: In the multi-class case we define one output f i ( x ) for each class, but each function f i shares the same hidden units h j , as is often done in neural network models. The flexibility of using multi-layer architectures also allows us to encode prior knowledge into our model. For example, convolutional neural networks (CNNs) (LeCun et al., 1998) have several layers of image patch based feature maps applied across the input image. Such networks have been shown to perform very well in digit, face and 3D object detection tasks. 3.3. Optimization: Stochastic Gradient We optimize our objective online , in the primal, using stochastic gradient descent. Recent experimental com-parisons show this approach often outperforms sophis-ticated optimizer schemes (Bottou, 2007). To simplify the hyperparameters we fix  X  = 1 in our experiments, yielding the method described in Algorithm 1. If the model is multi-layered then we use backpropagation (see, e.g. (Duda &amp; Hart, 1973)) during the gradient step. A typical stopping criteria is to use a validation set or to measure the objective function value. 3.4. Balancing Constraint To implement a balancing constraint while learning online we keep a cache of (arbitrarily) the last 25 c pre-dictions f ( x  X  i ) where c is the number of classes. This is dependent on c because if c is large the cache must also be large or the estimates will be too poor. We then try to make the next prediction balanced assuming we have a fixed estimate p est ( y ) of the probability of each class, which without further information, can be esti-mated from the labeled data: p trn ( y = i ) = |{ i : y i We consider two alternatives: 1.  X  bal Adding the term (7) to the objective func-2. ignore  X  bal Count how many examples in the We note that the quality of p trn depends on the ratio of labeled examples L to the number of classes c , not the input dimensionality d . Thus it may be a good estimate in many real datasets. However, because in some of the small datasets used in (Chapelle &amp; Zien, 2005) it is a poor estimate we consider improving this estimate by taking into account that we have access to unlabeled data. We suggest the following simple method p knn : label the k nearest neighbors of each labeled example with its label. If k is large enough some labeled points will label the same examples, and so when we count the number of points assigned to each class, we achieve a smoothed version of p trn . 4.1. Small Scale Datasets We first report results on three small-scale datasets, summarized in Table 1. We follow the methodology in (Chapelle &amp; Zien, 2005; Collobert et al., 2006) and report the best mean test error for a fixed set of hyper-parameters over 10 splits of the data. For our method, we test standard transduction (our regularizer with no neighborhood information), called TNN (Transductive Neural Network), and our method with neighborhood information, called ManTNN (Manifold Transduction Neural Network). We also compute a baseline Neural Network (NN).
 For NN, TNN and ManTNN we fixed 50000 iterations of Algorithm 1 and for ManTNN we chose 10 near-est neighbors for all datasets. We also choose not to that the classifier first finds a good model with la-beled data alone before using the unlabeled data. We thus have two free parameters: the choice of hidden units { 0,50,100,150,200 } and the choices of learning rate { 0.5, 0.1, 0.05, 0.01, 0.005, 0.001, 0.0005 } . data set classes dims points labeled g50c 2 50 500 50 Text 2 7511 1946 50 Uspst 10 256 2007 50 Mnist1h 10 784 70k 100 Mnist1k 10 784 70k 1000 Mnist1k+Invar 10 784 630k 1000 Training time for TNNs and ManTNNs are given in Figure 1. The results are shown for the best choice of hidden units and learning rate as chosen on the valida-tion set. TNNs take around one hour to reach conver-gence, and ManTNNs (omitting the time to compute neighbors for ManTNN) take slightly longer. These times should be compared to the fastest TSVM imple-mentation, CCCP-TSVMs, which took 41.9 hours on the same machine. Our code is not particularly op-timized and is written in a scripting language with a C++ back-end. On MNIST, a nonlinear TNN with 200 hidden units can process 1 million unlabeled ex-amples in an online fashion in 12.5 minutes. Mnist1k+Invar We also performed experiments on MNIST1k with a larger unlabeled set of 630,000 exam-ples by translating the original set by at most one pixel in each direction. TNN achieves a test error of 5.23% on the original test set, when choosing the training it-eration that gives the minimum validation error, and ManTNN achieves a test error of 2.43%. Both methods outperform their counterparts trained with less unla-beled data using MNIST1k. Training time took 4.47 hours and 3.96 hours respectively for the two algo-rithms, including the computation time for generating the invariances. In this article we introduced a large scale non-linear method that elegantly combines the two main regularization principles for discriminative semi-supervised learning: transduction and neighborhood-based (manifold-based) regularization. Our future work will be to apply this approach to real large-scale nonlinear problems e.g. applications in vision and nat-ural language processing.

