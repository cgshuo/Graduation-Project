 Flash solid-state drives (SSDs) provide much faster access to data compared with traditional hard disk drives (HDDs). The current price and performance of SSD suggest it can be adopted as a data buffer between main memory and HD-D, and buffer management policy in such hybrid systems has attracted more and more interest from research commu-nity recently. In this paper, we propose a novel approach to manage the buffer in flash-based hybrid storage system-s, named Hotness Aware Hit (HAT). HAT exploits a page reference queue to record the access history as well as the status of accessed pages, i.e., hot, warm and cold. Addition-ally, the page reference queue is further split into hot and warm regions which correspond to the memory and flash in general. The HAT approach updates the page status and deals with the page migration in the memory hierarchy ac-cording to the current page status and hit position in the page reference queue. Our empirical evaluation on bench-mark traces demonstrates the superiority of the proposed strategy against the state-of-the-art competitors. H.2.4 [ DATABASE MANAGEMENT ]: Systems X  Query processing Flash memory; SSD; Buffer management; Hybrid Storage With the development of flash memory technology, the NAND flash-based solid state drive (SSD) has been wide-ly used as the storage device for various systems, ranging from personal computer to enterprise scale data center. Al-though SSD shows better read/write performance than the traditional hard disk drive (HDD), the adoption of the SSD is still limited by its price and capacity. The price per bit of SSD is still much higher than that of HDD. Thus, it may take a long time for the SSD to completely replace the HD-D [10]. Therefore, flash-HDD hybrid storage becomes more and more attractive because it can leverage the advantages from both technologies.

There are several existing approaches attempting to better utilize the memory hierarchy in flash-based hybrid storage systems [2, 6, 7]. TAC (Temperature-Aware Caching) [2] uses the concept temperature to perform hotness detection, which divides the pages on disk into regions and maintains the whole history of page accesses. TAC identifies the hot ones by monitoring the number of accesses on each region. The pages with higher temperature will be held on the flash memory. The paper [6] analyzes the design of hybrid storage system and presents three alternative designs implemented in SQL Server: CW (clean-write), DW (dual-write), and LC (lazy-cleaning). As illustrated in the paper, LC is the best design, which keeps the random accessed pages on the flash. In LC policy, a dirty page is written to flash first and flush to disk afterward. LC method shows better performance than TAC on write intensive traces. FaCE (Flash as Cache Ex-tension) [7] adopts the SSD in a FIFO manner. In this way, FaCE can facilitate the high sequential write performance of SSD. Furthermore, FaCE proposes GSC to increase the hit ratio on flash memory. The GSC gives a page a second chance for eviction if the page is referenced while staying in the flash cache. FaCE also modifies the recovery component to extend persistent scope to flash memory in hybrid storage. The main drawback of these designs is they do not make full use of the storage hierarchy. All the pages replaced out of main memory will be kept on the flash no matter whether they will be reused again. Nevertheless, sometimes a page is visited only once but never referenced in the future, this kind of page may waste the flash memory and bring unnecessary write to the flash.

In order to overcome the problems in the existing ap-proaches, in this paper we propose a novel strategy named Hotness Aware Hit (HAT) for efficient buffer management in flash-based hybrid storage systems. The pages in HAT are divided into three hotness categories: hot, warm and cold. In general, the hot, warm and cold pages are kept in main memory, flash and hard disk respectively. Furthermore, we construct a page reference queue which is an LRU list to record the access history and the status of accessed pages, and the queue itself is split into hot and warm regions. Based on these data structures, we design a novel light weight page replacement mechanism for hybrid storage systems.
In stead of recording the exact access frequency of a page, our proposed HAT mechanism shows that integration of page status and page hit position is effective and incurs lower computational cost. Moreover, our approach is more adap-tive to the access pattern change and shows considerable improvements on different workloads.

We evaluate the performance of the proposed HAT ap-proaches by comparing with the state-of-the-art buffer s-trategies on flash-based hybrid systems. The experiments are conducted on real traces from public benchmarks includ-ing TPC-B, TATP, TPC-H and MLK (Make Linux Kernel), and our experimental study shows that the HAT approach is superior to the existing buffer replacement methods.
The remainder of the paper is organized as follows. Re-lated work is introduced in Section 2. Section 3 describes our framework and detailed algorithms. Experimental re-sults are shown in Section 4, and we make a conclusion in Section 5.
Nowadays, flash-based hybrid storage has been gradually recognized as an economical way for a practical system by more and more researchers. In this section, we briefly review the related work on flash-based hybrid system management.
Recently, the popular method is to adopt flash as a middle-level cache between disk and main memory. Existing works can be separated into two categories, i.e., static deploymen-t and dynamical loading. An object placement method [1] is developed to give a proper deployment for the objects of Database. By comparing the object performance on SS-D and disk beforehand, those with higher benefit per size are chosen to be placed on SSD. Other methods suggest putting certain part of the system to flash. FlashLogging [3] illustrates that storing the log of DMBS to flash can large-ly improve the overall performance. Debnath et al. [4, 5] proposed FlashStore and SkimpyStash to discuss the proper way to put the key-value pair to SSD. The static methods need to know the specific information about the application and cannot be self-adaptive to various environments.
Dynamical page transferring is more attractive compared with static strategies. Ou Yi et al. [9] tested the perfor-mance for different hybrid structures, which shows global structure outperforms local with less flash/main memory ra-tio, and vise versa. TAC (Temperature-Aware Caching) [2] is the dynamic version of object placement strategy. It allo-cates temperature to the extents according to access pattern and I/O cost and keeps the data with higher temperature to higher level of the storage structure. To deal with access pat-tern changes, the authors of TAC proposed to use the aging policy [11] to reflect changing access patterns, that is, the temperatures of pages are halved periodically to give high-er priority to the recently accessed pages. The aging policy forgets the access history of all the pages no matter the page is still hot or it is just accessed. In addition, the aging fre-quency is difficult to determine. Our testing on a variety of traces shows that the best aging interval ranges from thou-sands of accesses to the length of trace (which corresponds to the case without aging). Researchers from Microsoft [6] discussed several possible designs for hybrid storage meth-ods. According to the test, the LC (Lazy-Cleaning) method is the best design. LC method shows better performance than TAC on write intensive traces and similar on read-intensive traces. FaCE proposes to use the flash in FIFO manner to improve throughput and provide faster recovery, which yields better performance than LC [7]. HStorageDB [8] adopts semantic information to exploit the capability of hybrid storage system, which is from another aspect to solve the hybrid storage problem. The popular hybrid way is using flash as a buffer for disk. In this structure, all the data is stored on hard disk and organized as data pages. A page needs to be loaded into main memory before being accessed. When a page miss happens in main memory, flash will be checked first. Disk is only accessed when the page is not found in flash. In this section, we will introduce the basic idea of our approach for effective buffer management in flash-based hybrid system, named Hotness Aware Hit (HAT).

In HAT, we exploit a page reference queue to record the page reference history. Based on the reference information, the pages are marked with different hotness levels, e.g., hot, warm and cold. Pages are allocated to different levels in the storage hierarchy according to the page access sequence and pages X  hotness. For ease of the following presentation, we define some key notations and provide their detailed de-scription as follows.

Page reference queue In order to perform hotness detec-tion, we record a recent part of the page access history with a page reference queue, as illustrated in Figure 1. Only the IDs of accessed pages are kept in the page reference queue. The length of page reference queue corresponds to the size of memory and flash, as well as the page access pattern, and less recently visited pages will be discarded eventually. The page reference queue is organized in an LRU manner, that is, a newly referenced page will be added or moved to the MRU end of the queue. In the rest part of the paper, we name the MRU end of the queue as the head of the queue, while name LRU end of the queue as the tail for simplicity.
Hot Region and Warm Region In such an LRU based page reference queue, pages near to the head of the queue have higher hotness, while pages at the tail are colder. The page reference queue is divided into two regions named Hot Region and Warm Region respectively. The sizes of Hot Re-gion and Warm Region are determined by the reference his-tory and buffer sizes of memory and flash in general, which will be introduced in detail later. In our design, instead of recording the exact access frequency of a page, ascertaining the hotness level is sufficient as there are two level caches in the hybrid storage system. Note that, the Hot Region and Warm Region are proposed based on reference history and do not correspond to the buffer space holding the real da-ta pages. HAT uses these regions to facilitate page hotness d etection and thus make the page replacement computation more efficient.

Hit We name a page reference a hit on a region in the page reference queue if a page is referenced when it is cur-rently in the region. For example, in Figure 1, if page 3 is referenced again, we can name the reference a page 3 hit on the hot region, and page 3 turns to be hot afterward. Simi-larly, a reference of page 6 hits on the warm region. We use the information of hit as the measurement for hot detection. Hit can reflect the reference status of a page effectively. As described above, a page hit happens only when the page ID is already contained in the corresponding region which indi-cates the historical access information of this page. Thereby the hit can provide accurate hotness judgement by consid-ering both the historical information and the current status. At the same time, the hit reacts quickly for the page hotness change. If a page turns to be hot, then this change can be detected only after one hit in hot region and HAT can ad-just to this change efficiently. Additionally, the information needed to detect hit is the last reference of a certain page, and the process of hit detection can be performed easily and quickly, and hence the hit-based page hotness detection is efficient both on space and time consumption.
HAT categories the pages into three priority levels based on their hotness, namely hot, warm and cold, which are re-ferred as page status in this paper. The status of a page is determined according to the hit region on the page ref-erence queue. Generally, a hit on the hot region marks the corresponding page to hot, and a hit on warm region marks the page to warm. Each status has different behaviors on page accesses and is used to conduct page deployment. We introduce three types of pages in detail as follows. Hot page Hot page is with the highest priority in the HAT approach, and thus all the hot pages are determined to be kept in main memory and occupy a fixed percentage of main memory space. A page is marked as hot if a reference on this page hits on the hot region. For example, in Figure 1 a hit on page 1 will turn page 1 to hot page. If the number of hot pages exceeds the threshold, the hot page with the maximum recency is degraded to warm page, and the hot region shrinks.

Warm page A page may turn to warm in two ways: 1) a reference hit on the warm region will turn a cold page to warm; 2) a hot page is degraded to warm from the hot region as discussed previously. The number of warm pages on the flash is limited by the capacity of flash device, and thus if the flash is full, the warm page with the largest recency will be degraded to cold and evicted from the flash to the disk. All the pages on the flash are warm pages. However, although the amount is not large, some recently accessed warm pages may be buffered in the main memory. For example a newly referenced page will be kept in main memory for a while. A special case is an in-memory cold or hot page may turn to warm, and in this case, the page becomes in-memory warm page. After evicted from the main memory, the warm page will be moved to the flash.

Cold page A newly referenced page from the hard disk is considered to be cold, though its page ID will be queued in the hot region of page reference queue. A certain percentage of main memory space is allocated to store the newly refer-enced cold pages and warm pages regardless of their status. After evicted from the main memory, the cold page will be flushed back to the disk directly.

Tagging pages with different status based on their hot-ness is one of the key operations in our buffer management strategy. Here we provide details about how to use the tag information to effectively manage the data in storage hier-archy. The page deployment in the hierarchy roughly cor-responds to the status of the page, and we basically try to put the hot pages in the main memory, warm pages in the flash and remain the cold ones on the disk. However some newly referenced cold/warm pages are likely to be referenced again, so HAT allocates a certain percentage of main mem-ory to buffer these cold/warm pages, puts their IDs in the hot region of page reference queue but remains their sta-tus unchanged. These new comers will be temporarily kept in main memory for further hotness examination. If these pages are accessed again, they can be obtained directly from main memory and upgraded to hot pages.

The memory space used to cache the hot pages is named hot buffer zone , and the memory space used to cache the non-hot pages is named non-hot buffer zone . The sum of hot buffer zone and non-hot buffer zone is the size of main memory buffer. Thus, the page deployment of HAT is listed as follows. 1. Put all the hot pages to hot buffer zone in the main 2. Allocate the non-hot buffer zone to the newly arrival 3. Keep the warm pages at least on flash memory. Note 4. Remain all the other cold pages on the disk.

The principle of data placement also determines the data transferring between different storage hierarchies, which will be presented in details in the following section. For example, if a page turns to be hot, it will be moved to the main memory. Another example is a cold page evicted from the main memory is flushed back to the disk, while a warm one is flushed to the flash, which is a key difference from FaCE [7] and LC [6].
In previous sections, we have introduced some key nota-tions and basic HAT structure features. In the following, we will present the page replacement strategy of HAT in the hybrid storage hierarchy. Since the capacities of main mem-ory and flash are limited, we set some quantity constraints on the number of pages with a certain status.

When a certain constraint is violated, data page replace-ment in the storage hierarchy should be performed. The key in novation of HAT is how to conduct the place deployment of relevant pages according to the status and hit position of the accessed page, and modify the relevant pages X  status accordingly.

In our approaches, we can enumerate 6 data page access scenarios for buffer replacement in the hybrid storage hierar-chy according to current page status and its access history. These scenarios can cover all the cases for a data access workload. We present the operations and structure update for each case as follows:
Note that, in some cases above, the constraint violation may appear cascadingly. In this case, the HAT will conduct a sequence of adjustments to ensure the system satisfy al-l the constraints. Second, we call the pages whose status to be downgraded as the victim of status downgrade. The victim hot and warm pages are all determined in LRU man-ner. Third, the Non-hot buffer zone in main memory is also managed in LRU manner. The cold/warm page with the largest recency in the reference queue will be evicted. The evicted warm or cold page will be flushed to flash or disk respectively.
The size of hot buffer zone is set to a fixed percentage of main memory buffer capacity, and if the number of hot page exceeds the threshold, a hot page will be downgraded. Our implementation of HAT ensures that the tail of hot region is hot page and tail of warm region is a flash-resident warm page. This design can facilitate victim searching and simplify the implementation. When a hot victim is needed, the tail page of hot list is selected directly and the same operation holds for the warm victim. There are two cases that may cause the tail of hot region not ended with a hot page. First, when the number of hot page exceeds threshold, the tail of hot region will be degraded to warm and moved to the head of warm region. Thus the tail of hot region may no longer be a hot page. Second, this case may also take place when the tail page of hot list is referenced and moved to the head. In this case, we move pages from the tail of hot region to the head of warm region until encountering a hot one. We name this process Brush . The same process can take place for the warm region.
When the main memory buffer is full and an empty slot is required for new page access, an in-memory page has to be evicted out of the maim memory. In this case, we evict the non-hot page with the largest recency, that is, the in-memory non-hot page which is nearest to the tail in the page reference queue. This page can be obtained by scanning backward from the tail of reference queue, but the process could be time consuming, as the queue maintains at lease all the pages residing in the memory and flash.

We introduce an auxiliary LRU list in order to accelerate this searching process. The pages in auxiliary list are all non-hot pages that are buffered in the main memory. The pages in the auxiliary list are organized in LRU manner as page reference queue. Thus if a page in the auxiliary list is referenced, we should update its order in auxiliary list besides the operations on page reference queue. When a page is needed to be replaced out of the main memory, the tail of auxiliary list is simply selected.

We adopt a structure named frame to store all the in-formation of pages, including the hotness flag and the page location in storage hierarchy. The frames are organized in a hash table to facilitate fast searching. The ratio of non-hot buffer zone (Non-hot Ratio) in the system is a parameter of our approach. Our experiments illustrates the performance of HAT is not very sensitive to Non-hot Ratio, and HAT can achieve a good performance with a small Non-hot Ratio (such as 0.1) on most of the applications.
In this section, a trace-driven simulation is conducted to evaluate the effectiveness of our HAT approach, and the ex-p erimental results are illustrated in comparison with some state-of-the-art flash-based hybrid buffer replacement algo-rithms, including FaCE [7] and TAC [2]. We implement the FaCE approach with GSC (Group Second Chance), since the experiments indicate FaCE+GSC performs the best among FaCE variants. The aging frequency of TAC is an importan-t parameter. We tested TAC with different aging intervals ranging from 0.1M to 10M and choose the parameter with the best performance for the comparison. The simulation is developed in Visual Studio 2010 using C#. All experiments are run on a Windows 2008 server with two 2.4 GHz Intel E5530 CPU and 32 GB of physical memory equipped with Samsung SSD (64GB, 470 series) and Seagate disk (7200.7 ST380011A).
We use traces replay for performance evaluation. We ex-ploit four real traces, TPC-B, TPC-H, TATP and making Linux kernel (MLK for short) to evaluate the performance on various workloads. The three benchmarks are run on PostgreSQL 9.0.0 with default settings, e.g., the page size is 8KB. The MLK is a record of the page accesses of making Linux kernel 2.6.27.39. We utilize a tool named strace to monitor these processes and obtain the disk access history. Specification on these traces is shown in Table 1.
The total I=O time including both flash and disk accesses is used as the primary metric to evaluate the performance, while we also show the number of accesses in our experi-ments. The parameters used in our experiments are listed in Table 2. The first parameter S M is the memory buffer size, and we also consider various memory and flash sizes to test the performance under different environments, where pa-rameter Ratio F=M is used to represent the ratio between the flash and memory. The costs of flash I/O and disk I/O are obtained from testing on Samsung SSD (64GB, 470 series) and Seagate disk (7200.7 ST380011A), where C Fr ; C Fw ; C and C Dw represent read and write costs of the flash and disk respectively. We conduct the experiments on different SS-Ds including Samsung and Intel, and our approach yields similar performance on different devices, and hence we only present the results one Samsung SSD due to the space con-straint. The percentage of non-hot buffer zone out of the overall memory buffer space is set to 0.1, the performance of HAT is not sensitive to this parameter.
We proceed to show the comparison with other existing approaches, i.e., TAC and FaCE. We fix the main memory size and vary the flash memory size to evaluate total I/O time on each trace. The results are illustrated in Figure 2. The horizontal ordinate stands for the ratio between the flash and memory. With the increment of ratio, the total buffer size of the system also increases as we consider the fla sh as a second level buffer. Consequently, the total I/O time decreases for all the approaches. However, our ap-proach is better than other approaches in most of the cases and achieves up to 50% speedup against the competitors. On TPC-B trace, when the flash/memory ratio is low, TAC yields better performance than other approaches. TPC-B is a trace with stable pattern; TAC can precisely detect the hottest pages and store them in the flash on this kind of workload, which shows superiority especially when the buffer is small. However, the performance of TAC degrades very fast when the size of the flash increases. The reason to this result is that the TPC-B trace is a write-intensive trace, the ratio of write operations is around 20% as shown in Table 1. TAC adopts the flash as a write through cache, and thus, when the flash size is large, the drawback of this policy is more obvious. FaCE and HAT outperform TAC with the increment of flash memory size ratio. Our HAT strategy steadily outperforms FaCE, as HAT has better hot page detection mechanism than FaCE. The results in Figure 2 (b) on TATP shows similar trend with TPC-B.

As an OLAP workload, TPC-H is read-intensive and in-cludes 22 complex queries. Figure 2 (c) illustrates the per-formance comparison on the TPC-H trace. As the access pattern varies among these 22 queries, the lines in this figure are not as smooth as in TPC-B trace for all the approaches. Our approach HAT steadily outperforms TAC and FaCE, and achieves up to 30% performance improvement. The temperature-based statistics become invalid when the ac-cess pattern changes. FaCE has similar performance with TAC. The change of access pattern also has effects on the page management in FaCE. The workload size of TPC-H is larger than TPC-B and TATP, which validates the efficiency of our approach on various data sizes.

The making Linux kernel process needs to compile the source code to object code which will be then linked to the executable files, and thus this process contains a large num-ber of read operations and a few write operations. As shown in Table 1, the ratio of write operations is very low in M-LK trace and most of the write operations are sequential one. As the access pattern of MLK trace is also not stable, HAT is always better than TAC. Although using the second chance mechanism, the hot detection of FaCE is still ineffi-cient in hot page detection, which can not learn frequently accessed data well. Hence, a large number of cold pages are flushed from main memory to flash which wastes the flash capacity. Our approach has an effective hot page detection mechanism so that HAT can prevent this kind of drawback and shows better performance.
In this paper, we have presented a novel buffer manage-ment strategy HAT for flash-based hybrid storage systems. HAT utilizes a page reference queue to maintain the histor-ical access information, and the queue itself is divided into hot region and warm region. Furthermore, we propose to categorize the status of accessed pages to three levels, i.e., hot, warm and cold. We exploit the  X  X otness aware hit X  to process the buffer replacement, which migrates the relevant pages in the memory hierarchy according to the current page status and hit position in the page reference queue. Com-pared with the existing methods, HAT can effectively buffer frequently accessed pages with a low computational cost and better adapt to the workload changes as demonstrated in the experimental study.
 This research was supported by NSFC under Grant No. 61272155 and MIIT grant 2010ZX01042-001-001-04. [1] Mustafa Canim, Bishwaranjan Bhattacharjee, [2] Mustafa Canim, George A. Mihaila, Bishwaranjan [3] Shimin Chen. Flashlogging: exploiting flash devices [4] Biplob K. Debnath, Sudipta Sengupta, and Jin Li. [5] Biplob K. Debnath, Sudipta Sengupta, and Jin Li. [6] Jaeyoung Do, Donghui Zhang, Jignesh M. Patel, [7] Woon-Hak Kang, Sang-Won Lee, and Bongki Moon. [8] Tian Luo, Rubao Lee, Michael P. Mesnier, Feng Chen, [9] Yi Ou and Theo H  X  arder. Trading memory for [10] EE Times. SSDs: Still not a 'Solid State' Business . [11] Yuanyuan Zhou, Zhifeng Chen, and Kai Li.

