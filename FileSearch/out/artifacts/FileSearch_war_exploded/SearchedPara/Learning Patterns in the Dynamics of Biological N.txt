 Our dynamic graph-based relational mining approach has been developed to learn structural patterns in biological net-works as they change over time. The analysis of dynamic networks is important not only to understand life at the system-level, but also to discover novel patterns in other structural data. Most current graph-based data mining ap-proaches overlook dynamic features of biological networks, because they are focused on only static graphs. Our ap-proach analyzes a sequence of graphs and discovers rules that capture the changes that occur between pairs of graphs in the sequence. These rules represent the graph rewrite rules that the first graph must go through to be isomorphic to the second graph. Then, our approach feeds the graph rewrite rules into a machine learning system that learns general transformation rules describing the types of changes that occur for a class of dynamic biological networks. The dis-covered graph-rewriting rules show how biological networks change over time, and the transformation rules show the repeated patterns in the structural changes. In this paper, we apply our approach to biological networks to evaluate our approach and to understand how the biosystems change over time. We evaluate our results using coverage and prediction metrics, and compare to biological literature.
 I.2.6 [ Artificial Intelligence ]: Learning; J.3 [ Life and Medical Science ]: Biology and genetics Algorithms Dynamic Network Analysis, Graph Mining, Biological Net-work, Graph Rewriting Rule
There are many data that can be represented as graphs, where vertices represent entities and edges represent rela-tionships between entities. Moreover, many of them have dynamic properties such that the structure of graphs can be changed over time. Our bodies are well-organized and vig-orous systems, which promote reproduction and sustain our lives. These well-organized systems can be defined by the attributes and structural prope rties of biological networks, which include various molecules and relationships between molecules. Vigorous systems refer to dynamic properties of biological networks, which continuously change, while an organism performs various biological activities. Therefore, analysis of the dynamics of biological networks is necessary to understand biosystems.

Our approach first learns how one graph is structurally transformed into another using graph rewriting rules, and abstracts these rules into abs tract patterns that represent the dynamics of a sequence of graphs. Our goal is to describe how the graphs change over time, not merely whether they change or by how much. In this way, our approach can help us understand the dynamics of biological networks.
This paper introduces our definition of graph-rewriting rules and more genera l transformation rules. We also present our two step algorithm to discover graph-rewriting rules in a dynamic graph, and transformation rules in the discovered graph-rewriting rules. In our experiments, we generate sev-eral dynamic graphs using the KEGG pathway database [9] in combination with the artificial generation and real data sets. We apply our approach to the pathways to understand how the biosystems change over time. We evaluate our re-sults using coverage and prediction metrics, and compare to biological literature. Our results show important patterns in the dynamics of biological networks, i.e., discovering known patterns in the networks. Results also show the learned rules accurately predict future changes in the networks. A graph is a natural way to represent biological networks. There are several graph mining approaches to biological net-works [10, 11, 24]. These approaches represent biological networks as graphs, where vertices represent molecules and edges represent relations between molecules, and discover frequent patterns in these graphs. They discover structural features of networks, but they overlook temporal properties.
There is much research work on the dynamics of biosys-tems, such as mathematical modeling [16] and microarray analysis [22]. Mathematical modeling is an abstract model to describe a system using mathematical formulae. They model the kinetics of pathways and analyze the trends in the amounts of molecules and the flux of biochemical reactions. The microarray is a tool for measuring gene expression levels for thousands of genes at the same time [3, 15]. Microarrays can also monitor patterns in gene expression levels over a period of time or for the different conditions. Patterns in gene expression levels can represent changes in the biolog-ical status or distinguish two different states, such as the normal and disease state. However, these two approaches disregard the structural aspect of networks.

Temporal data mining attempts to learn temporal pat-terns in sequential data, which is ordered with respect to some index like time stamps [17]. Temporal data mining is focused on discovery of relational aspects in data such as discovery of temporal relatio ns or cause-effect association so that we can understand how or why the object changes rather than merely static properties of the object. Temporal data mining approaches discover temporal patterns in data, but they disregard relational aspects among entities. Several methods have addressed dynamic graph analysis. Sun et al. [19] propose a technique to discover communities and detect changes in dynamic graphs that is represented as matrix and encoding schemes. Tensor analysis is also applied to dynamic graphs [20, 21]. Other work [1, 2, 18] proposes several detection measures of abnormal changes in the se-quence of graphs and graph distance measures between two graphs. They can measure how much two graphs are differ-ent, but not show how they are different. Lahiri et. al. [13, 14] introduce an approach to predict the future structure in a dynamic network and mine periodic patterns using fre-quent subgraphs. Our approach uses a compression-based metric instead of the frequency-based approach to discover patterns in a dynamic graph.
In this section, we define the graph rewriting rule and the transformation rule to describe the dynamic of a graph. Graph rewriting rules represent topological changes between two sequential versions of the graph, and transformation rules abstract the graph rewriting rules into the repeated patterns that represent the dynamics of the graph. Figure 1 shows a framework of our approach. The dynamic graph contains a sequence of graphs that are generated from sam-pling snapshots of the graph from a continuously-changing graph, i.e., a sequence of graphs represent one biological Figure 2: An instance of graph rewriting rules between network that changes its structure over time. First, our ap-proach learns graph rewriting rules including removals ( R and additions ( A i ) between two sequential graphs G i and G +1 (figure 1 (B)), and generates a list of the entire graph rewriting rules (figure 1 (C)). Then, the final step is to learn the transformation rules to abstract the structural change of the dynamic graph based on the repeated patterns in the graph rewriting rules.
First, we briefly describe graph rewriting rules for our approach with an example in figure 2. In our research, a graph G denotes the directed labeled graph that is defined as G =( V, E, L v ( V ) ,L e ( E )), where V is a set of vertices, E is a set of edges. To discover graph rewriting rules be-tween two graphs, we first discover maximum common sub-graphs (denoted by S ) between two sequential graphs G 1 and G 2 . Then, we derive removal (remainder in G 1 denoted by R ) and addition subgraphs (remainder in G 2 denoted by A ). Our graph-rewriting rules also contain connection edges. The connection edges are edges, which are used to link re-moval (or addition) subgraphs to the original graphs. The edges with boxed labels in figure 2 represent the connection edges between G 1 ( G 2 ) and removal subgraph R (addition subgraph A ). The connection edges are important because they show how the subgraphs are connected to the original graphs. There can be more than one connection edge linking one subgraph to the original graph. The connection edges represent relations between the learned patterns and other elements in the input networks.

Formally, we define DG = { G 1 ,G 2 ,  X  X  X  ,G n } as a dynamic graph, where each graph G i is a graph at time i for 1  X  i n . For two consecutive graphs G i and G i +1 , we define S as the maximum common subgraph between G i and G i +1 . S i,i +1 can be a disconnected graph, i.e., describing the set of connected subgraphs common to G i and G i +1 . Then, we define a graph rewriting rule GR i,i +1 as follows. Then, a removal subgraph R i and an addition subgraph A i are defined as follows.
 C
R i and C A i +1 are the sets of connection edges for R i A +1 respectively. The graph rewriting rule GR 1 , 2 in figure 2 can be represented as follows.
 The graph R 1 denotes R (in G 1 ) that is linked by two con-nection edges labeled by  X  X c X  and  X  X d X . A 2 denotes A (in G ) that is linked by one connection edge labeled by  X  X e X . In each edge, sX and gY denote the starting and ending vertices, where s denotes the vertex in the subgraph and g denotes the vertex in the original graph.

After iterating this process for n graph, i.e., the entire se-quence in the dynamic graph, we have n  X  1 R sand n  X  1 A s as shown in figure 1 (C). Here, we consider a set of graphs L that is a list of graph rewriting rules learned in DG . L con-tains n  X  1 R sand n  X  1 A s like L = { R 1 ,A 2 ,R 2 ,A 3 ,A n } . We arrange R and A in order of time when the event occurs.
Next, we discover transformation rules in the learned graph rewriting rules to abstract the structural changes in the dy-namic graph as shown in figure 1 (D). A transformation rule is defined as a pattern in the learned graph rewriting rules, where the pattern best abstracts (compresses) the learned graph rewriting rules to best describe structural changes. More description will be in section 4. If some structural changes are repeated in the dynamic graph, there exist com-mon subgraphs in the R sand A s. Then, we can discover the common patterns over L as our transformation rules. Bio-logically speaking, if there exists a repeated change of the structure of a biological network, the change can be an im-portant pattern in the network. Here, we propose one simple transformation rule TR , which represents repeated additions and removals (or vice versa), as follows.
 In the case when the transformation rule represents only repeated removals (or additions),  X  t r (or + t a )wouldbe like Sub  X  t r (or Sub + t a ). Sub represents a subgraph, which adds to and/or removes from the graph repeatedly. + t a represents the time interval from the last removal to the current addition, and  X  t r represents the time interval from the last addition to the current removal. If + t a is shown before  X  t r , the addition precedes the removal. For instance, Sub +4 ,  X  2 denotes a repeated structure added after 4 time intervals from the last removal and removed after 2 time intervals from the last addition as shown in figure 1 (D). e denotes the number of the transformation rules in one dynamic graph. There can be multiple patterns over L to describe the structural change of the dynamic graph, where the best transformation rule that is labeled as TR 1 best describes the change.
 Figure 3: Discovery of the best compressed subgraph in
There are other forms of transformation rules besides re-peated add/remove rules, such as patterns conditional on context, i.e., removal/addition of structure X if structure Y is present (or absent), or patterns that describe numeric changes in combination with structure, i.e., describing trends of concentration, not just appearance. We will consider other types of transformation rules in future work.
This section describes our approach to analyze dynamic graphs. We present a two step algorithm: Learning Graph Rewriting Rules and Learning Transformation Rules. Al-gorithm 1 learns graph rewriting rules in a dynamic graph to represent how two sequential graphs are different. Al-gorithm 2 learns the repeated transformation rules in the learned graph rewriting rules to describe how the graph changes over time, where the changes are actually repre-sented as a sequence of revised graphs. For both algorithms we rely on a previously-developed method for finding the best-compressing subgraph in a set of graphs. For the first algorithm, repeated application of this method allows us to find the set of all subgraphs common to a pair of consecutive graphs. For the second algorithm this method allows us to find the subgraphs repeatedly added and removed in the dy-namic graph. While we could use a frequent subgraph miner [12, 23] for this purpose, experiments have shown that the best-compressing patterns comparably capture the complete repeated structural changes [25].

We define the best-compressing subgraphs as those which minimize the description length of the input graph after be-ing compressed by the subgraphs based on the Minimum Description Length (MDL) principle [4, 5]. Formally, the description length of the substructure S is represented by DL ( S ), the description length of the input graph is DL ( G ), and the description length of the input graph after compres-sion is DL ( G | S ). The approach finds a substructure S that minimizes the Compression of the graph defined as follows. Figure 3 shows an example of the subgraph discovery by this compression-based approach. First, we can discover four instances of one common subgraph denoted by a red circle (A). After discovery, we compress each instance replacing by one vertex ( S 1 ), and we iterate the discovery process. In the second iteration (B), we discover two instances of the next common subgraph, and compress them by one vertex ( S 2 ). We stop the iteration because there is no more common subgraph, i.e., no more compression (C). Algorithm 1 : Learning Graph Rewriting Rules Input: Dynamic graph DG = { G 1 ,G 2 ,  X  X  X  ,G n } Output: Rewrite rules L , connection edges C 1: L = {} ,C = {} 2: for i =1to n  X  1 do 3: Graphs = { G i ,G i +1 } , S = {} 4: while More compression possible do 5: BestSub = DiscoverCommonSub in Graphs 6: S = S  X  BestSub 7: Compress Graphs by BestSub 8: end while 9: Find R i = G i \ S and C R i in G i 10: Add R i into L ,andAdd C R i into C 12: Add A i +1 into L ,andadd C A i +1 into C 13: end for
Using the compression-based approach (as DiscoverCom-monSub in the algorithm), we describe our two step algo-rithm. Algorithm 1 shows the lea rning graph rewriting rules algorithm, where the entire algorithm denotes figure 1 (C) andtheeachiterationintheouterloopdenotesfigure1(B). First, the algorithm initialize L and C to store removal and addition subgraphs, and connection edges. At line 3, the al-gorithm prepares two sequential graphs as Graphs ,andthen discovers one common subgraph by the compression-based approach. After compression, the algorithm discovers an-other subgraph at the next iteration until there is no more compression. In this way, the algorithm can discover the maximum common subgraph between two sequential graphs. After compressing the two graphs by the maximum common subgraph, the algorithm identifies removal (or addition) sub-graphs and connection edges (lines 9 and 11) using a modi-fied Breadth First Search (mB FS), which adds each edge as well as each vertex into the queues as visited or to be visited. After compression, each maximum common subgraph is re-placed by one vertex S i . mBFS starts to search from one edge linked to S i to find one disconnected subgraph, and the starting edge is added into C . During the search, if there is one more edge between the disconnected subgraph and maximum common subgraph, the edge becomes the other connection edge. In this way, mBFS can find all discon-nected subgraphs (without considering the link by the con-nection edges), and they become removal (or addition) sub-graphs. mBFS stops the search when all connected edges are added in C . For example, in figure 3 (C), mBFS starts from one edge linked to S 2 (in case of G 1 ,choose e 1 ), and these starting edges are added into in C .Sincethereisone more linked edge ( e 2 )to S 2 in case of G 1 , e 2 is added into C . Then, there is no place to visit from the vertex E , E becomes a disconnected subgraph as an addition subgraph. Since there is no place to visit from the vertex F in G 2 becomes a disconnected subgraph as a removal subgraph. In this way, mBFS identifies removal subgraphs R i and ad-dition subgraphs A i +1 with connection edges. The output of Algorithm 1 includes L and C . L and C are bijective. L = { R 1 ,A 2 ,  X  X  X  ,R n  X  1 ,A n } is used in Algorithm 2 as an ize the relations between the learned subgraphs and original graphs. Algorithm 2 : Learning Transformation Rules Input: L , Iter Output: BestCommonSubs , ListOfDist 1: while More compression possible and Iter &gt; 0 do 2: BestSub = DiscoverCommonSub in L 3: Add BestSub into BestCommonSubs 4: Calculate distance between instances of BestSub 5: Add distance into ListOfDist 6: Compress L by BestSub 7: Iter = Iter -1 8: end while
From the result of Algorithm 1, we try to discover re-peated rewrites as our transformation rules to better un-derstand how graphs change over time as shown in figure 1 (D). The input L contains 2( n  X  1) graphs: n  X  1 R sand n  X  1 A s. Note that each example (each R or A )contains one or more graphs, which may not be connected to each other. We then use DiscoverCommonSub again to find com-mon subgraphs in L (line 2). As described in figure 3, the best common subgraph in L represents the subgraph in our transformation rule. We calculate the temporal distance between two consecutive instances of the best-compressing subgraphs to describe the time at which the removal (or ad-dition) occurs after the previous addition (or removal) at line 4. After the discovery of the common subgraph, L is compressed by this subgraph (line 6), and the discovery pro-cess is iterated until no more compression is achieved or we reach a user-defined limit Iter on the number of iterations. When the best subgraph at a latter iteration includes the best subgraph from a former iteration, the results can show the latter best subgraph includes a previously-learned sub-graph that is replaced by one vertex. More detail will be described with examples in the results section. In TR e ,the e denotes the number of iterations. If a transformation rule is discovered in the first iteration, the rule is labeled as TR that is the best subgraph in L .If Iter is not specified, Al-gorithm 2 finds all possible TR in L .
One challenge of our algorithm is to discover maximum common subgraphs between two sequential graphs, because this problem is known to be NP-complete [8]. To address this issue we use a parameter, limit ,in DiscoverCommonSub to restrict the number of substructures to consider in each iteration. We can express the Algorithm 1 X  X  total runtime as N 1 = N DCS ( T  X  1), where N DCS is the runtime of Dis-coverCommonSub and it runs for T-1 times. Algorithm 2 X  X  running time is dominated by N DCS . N DCS is restricted by limit that is calculated based on input data, specifically, the number of unique vertex and edge labels. A previous work [6] shows N DCS running with a fully-connected graph in time polynomial with limit . We can avoid the worst case in our domain, because biological networks are usually sparse graphs and there are not many instances due to plenty of unique labels. But we still need to pursue reducing the running time for other domains. Also, our algorithm does not try to discover the entire set of maximum common sub-structures at once. In each step, the algorithm discovers a common, connected substructure and iterates the discovery process until discovering the entire set.

Graphs that represent biological networks usually contain unique vertex labels, because each vertex label usually de-notes the name of the molecule. Because the maximum com-mon subgraph problem in graphs with unique vertex labels is known to have quadratic complexity [7], discovery of the graph rewriting rules is still feasible. However, there will be a tradeoff between exactness and computation time when analyzing very large graphs.
We use two metrics to evaluate the learned transformation rules. The first metric is Coverage that represents how well the rule describes the changes in the graphs. The Coverage of the BestSub discovered at iteration i in Algorithm 2 is computed as follows.

Coverage = where the covered A sand R s are the addition and removal subgraphs in L that contain BestSub . The size of a graph G is calculated as size ( G )= | V | + | E | . These graphs are effi-ciently identified during the discovery of BestSub , avoiding the need for costly subgraph isomorphism tests. Coverage represents the portion of the learned subgraphs (the re-moval or addition subgraphs) described by the transforma-tion rule to be based on BestSub . For example, suppose we have n = 3 graphs from which we find two graph-rewriting rules. Then, we have two removal and two addition sub-graphs. Assume the size of R 1 is 10, R 2 is 12, A 2 is 10, and A 3 is 15. Also assume the BestSub is found in R 1 and A 2 ,the BestSub has a size of 5. Coverage is com-puted as 5(1 / 10+1 / 10) 4 =0 . 25. Higher Coverage indicates the subgraph can describe more significant (larger portions of) changes. Currently, Coverage does not consider the size of connection edges ( | C | ). Unless the subgraph is isomorphic with all AGs and RGs, Coverage &lt; 1.

We define Prediction as our second metric to evaluate the prediction capability of the learned transformation rules as follows.
 P is the set of positions where we predict the PredictedSub will show up, RealSub i is the actual subgraph found at po-sition i, and d ( G m ,G n )isdefinedasfollows. d ( G m ,G n ) is a graph distance metric by Bunke et. al. [2, 18], where mcs ( G m ,G n ) denotes the maximum common subgraph between G m and G n . In contrast to their work that defines the size of G as the number of vertices in G ,we consider the number of vertices and edges defined in the pre-vious paragraph. If two graphs G m and G n are isomorphic, d ( G m ,G n )=1. Forexample, d ( G 1 ,G 2 )infigure3is11 / 16, Figure 4: The generation of a dynamic graph in combi-where mcs ( G 1 ,G 2 ) = 11 and | G m  X  G n | = 16. Prediction represents how much the predicted subgraph covers the sub-graphs in the testing experiments. For example, suppose we predict a subgraph s will be shown 3 times in the testing data. Then, we discover the subgraph rs that is partially different from s at one time point (( G rs ,G s )=0 . 5), and iso-morphic subgraphs with s at another time point. Prediction is computed as 0 . 5+1 . 0+0 3 =0 . 5. Currently, our Prediction measure is not for a temporal prediction, i.e., the exact time the subgraph appears, but for a sequential prediction, i.e., whether the correct sequence of the subgraphs appears.
We perform four experiments to evaluate our approach using three ways: artificial generation, and combinations with two real world data sets. We generate a static graph representing the biological networks from the KEGG PATH-WAY data [9], where vertices represent compounds, genes, enzymes, relations and reactions, and edges represent rela-tionships between vertices. Then, we use our data sets to transform the static graph to a dynamic graph as shown in figure 4. In the artificial generation, we use a real biological network, but we remove and add some subgraphs manually to generate the dynamic graphs. In the real world data, we use the KEGG data [9] in combination with additional data to generate dynamic graphs. Because the KEGG data con-tains only the static structure of pathways, we need to use additional data including dynamic properties of pathways. We refer to results of two researches: one for the cell cycle signaling pathway with mathematical modeling [16] and the other for metabolic pathways with microarray data [22].
The biological network used in the artificial generations is the Notch signaling pathway in humans generated from the KEGG data. The Notch signaling pathway contains 46 genes in our experiments, and we assume that each gene can be shown at most once at each time slice. First, we create one list that contains the names of 46 genes, and then duplicate the list for 20 time slices. For varying several conditions, we remove one or more genes at specific times. Because of the biological semantics, the removal of even one gene can cause the removal of one or more larger subgraphs. We generate four dynamic graphs, each of which has 20 time slices. The size of each dynamic graph varies: 3,380 (164 to Table 1: Coverage of the best subgraphs in Artificial Figure 5: The best subgraph discovered in the graph 177) for N A , 3,350 (149 to 174) for N B , 2,733 (102 to 174) for N C and 3,332 (152 to 174) for N D .Thenumbersin() denote the minimum size and maximum size of a graph in a dynamic graph respectively.

The goal of the artificial generation experiment is to iden-tify the strengths and weaknesses of our approach. Table 1 shows the coverage of the best subgraph (our rule) discov-ered at each iteration of Algorithm 2. The first two dynamic graphs, N A and N B , can be represented by one transforma-tion rule, because the removals and additions are simple and regular. Generally, the structural change in the dynamic graph is represented by multiple transformation rules like N
C and N D . For example, N C is represented by TR 1 as a portion of the coverage 0.16. But N A is fully covered by TR 1 , i.e., TR 1 can describe the whole structural change.
Figure 5 shows the best subgraph discovered in the N B experiments. The instances of the best subgraphs are discov-ered in the 9 examples (4 removals and 5 additions).  X  X Erel X  denotes the relation between a gene and protein, and  X  X Prel X  denotes the relation between two proteins. Therefore, the enzyme generated by a gene, hsa:3516, has 7 relations, such as 2 relations to other genes and 5 relations to other pro-teins. The transformation rule including this subgraph can be visualized as shown in figure 6. The above rhombuses de-note the removals at the specified time. The below eclipses denote the additions at the specified time. The numbers on the arrow denote the temporal distance between two events: removals and additions. The first addition occurs at time 1, and the first removal occurs after 3 time intervals. From the first addition at time 1 to the last addition at time 17, every removal is repeated after 3 time intervals from the last addition, and every addition is repeated after 1 time interval from the last removal. The repeated transformation rule can be represented as shown in figure 6 and can be expressed as TR 1 = Sub 1 +3 ,  X  1 . Figure 6: Visualization of transformation rules includ-Figure 7: Two best subgraphs discovered in N D . Sub 1
As described in section 4.2, figure 7 shows an example of a previously-learned subgraph that Sub 2 includes Sub 1 dis-covered in N D . At the first iteration (as TR 1 ), the first sub-graph ( Sub 1 ) is discovered at times 5, 10, 15 as removals and at times 3, 8, 18 as additions. Then, this subgraph is com-pressed and replaced by one vertex labeled by  X  X ub 1 X . At the second iteration (as TR 2 ), the second subgraph ( Sub is discovered at times 5, 15 as removals, and at times 3, 8, 18 as additions. Because Sub 2 includes Sub 1 , Sub 1 is included into Sub 2 as a vertex  X  X ub 1 X . In figure 7, the dashed-line ar-row represents a pointer to the previously-learned subgraph Sub 1 from Sub 2 . Biologically hsa:1387 in Sub 1 and hsa:9794 in Sub 2 are included into a  X  X roup X  ( Sub 1 )as X  X omponent X  X .
Here, we discuss the advantage of the compression-based subgraph discovery. In N C , the first best subgraphs are discovered 8 times. Actually, the third best subgraphs are discovered 10 times. Because the Compression of the first subgraph is better than the Compression of the third sub-graph, our approach prefers the first subgraph. A frequency-based approach would prefer the third subgraph. The size of the first subgraph is 51, and the size of the third subgraph is 5. Also, the Coverage (0.16) of the first s ubgraph is larger than the Coverage (0.05) of the third subgraph. For this reason, the compression-based approach can be more use-ful than frequent graph mining in the analysis of dynamic graphs. The detailed comparison results are in [25].
We also apply our approach to a dynamic graph based on the mathematical modeling data. The dynamic graph rep-resents the cell cycle signaling pathway [16]. The cell cycle signaling network in our experiment contains 14 molecules (genes and compounds) and 11 reactions between molecules. We use a threshold th to activate each compound or gene. At each time, a compound or gene, which has more than th amount, is shown in the graph. In other words, the biological network contains a portion of the 14 molecules with related reactions at each time. We normalize the concentrations of 14 molecules from 0 to 1, because we are focused on trends in the changes, and the concentrations of different molecules vary significantly. Because the simulation is performed for 700 seconds and we take a snapshot at every 10 seconds, we  X  0 27 0.115 1.0  X  1 30 0.153 0.962  X  0 27 0.051 1.0  X  1 25 0.155 1.0  X  4 28 0.084 1.0  X  0 27 0.080 0.864  X  2 27 0.119 0.852  X  0 27 0.066 0.944  X  0 27 0.033 1.0  X  0 27 0.185 1.0 have 51 time slices ( t = 1 to 51) of data for training and the following 20 time series for testing.

Figure 8 shows the best subgraph ( Sub 1 )in TR 1 discov-ered at 16 time slices as visualized in figure 9 (A). The vertices containing  X  X ct X  in the labels denote reactions like  X  X ct:+p CDC X . The vertices without  X  X ct X  X enote molecules (genes or proteins). The three edges,  X  X ct to R X ,  X  X ct to P X  and  X  X ct to M X , denote how the molecules are related to the reactions as reactant, product and modifier respectively. These results are biologically significant, because they de-scribe the repeated structural changes in the networks. Qu et al. [16] describe periodic changes of molecules (i.e., amount of molecules). Specifically, they mention several molecules such as Active Cyclin:CDK and Free Cyclin that show pe-riodic increase and decrease, where the cycles correspond to the change of the cell size. Figure 9 (A) shows the sub-graph including Active Cyclin:CDK, that is added and re-moved periodically corresponding to periodic changes in the amount of the molecule. In addition, figure 8 show how the changes are related to other elements (i.e., which elements are removed or added at the same time) as shown in the dis-covered subgraphs and how the subgraphs are linked to the original graphs. Our results show patterns in the structural changes, not merely changes of amount.

The Coverage is calculated as 0.181. Based on this rule, we predict the future change as shown in figure 9 (B). We predict 6 graph rewriting rules (future changes), as we choose the predicted temporal distance based on the distances ob-Figure 9: Visualization of the graph rewriting rules in-served in training. The temporal distance and graph rewrit-ing rules denoted by the bold fonts represent the same pat-terns with the testing data. 5 patterns out of 6 predictions are same as training data. The only 6th pattern at time 70 is a non-isomorphic graph with Sub 1 . d ( Sub 1 ,R 70 computed as 0.833, and the Prediction is 0.972.
Next, we process a simple prediction experiment. Because our research is focused on patte rns in graph rewriting rules (i.e., patterns in structural changes), we can predict which graph rewriting rules appear (i.e., which structural changes occur). To evaluate prediction ability of the learned trans-formation rules, we perform ten prediction experiments us-ing the above modeling data.

We modify some initial parameters in the model to gener-ate different dynamic graphs. The modified parameters and values are shown in table 2. Like the above modeling exper-iment, we use 51 time series as training and 20 time series as testing. Table 2 shows the results. M 1 shows the transfor-mation rule Sub 1 +8 ,  X  0 that describes Sub 1 is added after 8 times from the last removal and is removed right after the last addition. For example, Sub 1 is added at time 12 (during the time from 11 to 12), and is removed at time 12 (during the time from 12 to 13).

As shown in table 2, the averages of the rule coverage and prediction coverage are larger than 0.9, indicating that our approach is able to learn accurate rules across the differ-ent conditions yielding different dynamic graphs. In case of Figure 10: Two best subgraphs discovered in the exper-the M 1 , M 3 , M 5 , M 6 and M 8 , they show relatively small coverage, because some elements in the best subgraph are removed (or added) separately. The detail discussion of this problem is in [25]. M 9 contains the entire sequence of discov-ered subgraphs in the transformation rule, but the oscillation in M 9 shows only two cycles. In most cases, the oscillation shows more than 5 cycles (i.e., figure 9). Our algorithm can predict the future structural changes from the learned trans-formation rules of the graph re writing rules that represent the structural changes of dynamic graphs. We will compare our result with other approaches in the future work.
Now, we show the result of the dynamic graphs based on microarray data. Table 3 shows brief information of the dy-namic graphs and results. In previous results we show TR 1 Here, it is a little bit different, because the pathway is bigger than the previous cases and contains many redundant labels. In the aspect of the dynamic graph mining, TR 1 including Sub 1 best describe the structural change. Biologically, TR is too general to describe the structural change. In figure 10, Sub 1 that is discovered 46 times at 20 time points contains only general information: three maplink-relations (relation between a gene (protein) and pathway) and one enzyme. Without any specific name of gene or pathway, Sub 1 repre-sents too general information. For this reason, we show Sub (as TR 3 ) in figure 10 that contains any specific name of the gene, because our microarray data represent the trends of the gene expression values, and the gene is the only infor-mation that can be changed over time. Sub 1 is included into Sub 3 as a previously-learned subgraph. Sub 3 includes one gene (YPL262W) and one pathway (sce00220) and one re-action (R01082) and two co mpounds (C00122 and C00149).
Sub 3 is discovered as removals at time 14, 23, 26 and as additions at time 2, 23, 25. Because the original microar-ray research [22] has only 36 time series, we do not perform the prediction task. But this experiment shows that our ap-proach can be applied to real data, because the microarray data is generated from the yeast cells. The original result of microarray shows more than 50% of genes have three peri-odic cycles in the gene expression. In our experiment, the appearance of most learned graph rewriting rules in four pathways also shows three periodic cycles like Sub 3 .
Figure 11 shows the visualization of Sub 3 from figure 10 to describe biological meaning of structural patterns. (A) shows an addition rule in our output, and (B) shows the same rule marked on the KEGG pathway map [9]. The la-bels marked by  X +[] (-[]) X  represent the labeled vertices and edges belonging to the subgraphs of addition rules (removal rules). Connection edges between the discovered substruc-tures and original graphs are marked by  X () X . In figure 10, we can notice the three edges labeled by  X  X alue X  linked to C00122, which are from the three  X  X aplink X  vertices in Sub These three edges are marked by the red boxes in figure 11 (A). The maplink denotes a relation between one gene (X) in a pathway (Y) and another pathway (Z). The com-pound that is linked to  X  X aplink X -relation by  X  X alue X  edge denotes a compound shared in two pathways (Y and Z). Precisely, the compound has two relations with a gene (X) and another gene (that cannot be known at this point) in pathway (Z). Figure 11 (A) can help us understand these relationships. C00122 is added at time 25 with relations to three maplink-relations. Two relations out of three maplink-relations are connected to the other two pathways (sce00330 and sce00350) marked by the blue eclipses. These two path-ways are not marked by  X  X ] X  or  X () X , because they already exist before time 25. In other words, Sub 3 is added at time 25, and connected to two pathways by two connection edges.
Microarray data [22] can show three periodic cycles in the change of the gene expression values. Our approach also can discover three periodic cycles of removals and additions of the genes (i.e., YPL262W). In addition to the three periodic cycles of removal and addition of one element, our results also show what other elements are related to the removed (or added) genes, i.e., how the removed (or added) genes relate to others in the pathway. The connection edge can help us understand how the learned subgraphs relate to the original graph at each time.
This research introduces the use of graph rewriting rules to describe structurally changing networks, and more gen-eral transformation rules abstracting the graph rewriting rules. We also present a two step algorithm to discover graph rewriting rules and transformation rules in a dynamic graph. The algorithm is evaluated with the dynamic graphs representing the biological networks in combination with the artificial generation, mathematical modeling and microar-ray data. The graph rewriting rules show how one graph is transformed into another. The learned transformation rules over the graph rewriting rules can describe repeated patterns in the series of the structural changes.

Our results show important patterns in the dynamics of biological networks, for example, discovering known patterns in the various networks. Results also show the learned rules accurately predict future changes in the networks. The con-nection edge can help us understand how the learned sub-graphs relate to the original pathway at each time. Our approach also helps us visualize the change of subgraphs at each time to show how the networks structurally change, helps us better explore how networks change over time, and guides us to understand the structural behaviors of the dy-namic network.

For our future work we will explore a better approach to learn transformation rules that can cover graph rewriting rules that are divided over several consecutive time slices. Also, our prediction measure needs to include a temporal distance factor to better evaluate rules in terms of predicting the precise time at which a change occurs. [1] H. Bunke, M. Kraetzl, P. Shoubridge, and W. Wallis. [2] H. Bunke and K. Shearer. A graph distance metric [3] H. Causton, J. Quackenbush, and A. Brazma. A [4] D. Cook and L. Holder. Substructure discovery using [5] D. Cook and L. Holder. Graph-based data mining. [6] D. Cook, L. Holder, and S. Djoko. Scalable discovery [7] P. Dickinson, H. Bunke, A. Dadej, and M. Kraetzl. On [8] M. Garey and D. Johnson. Computers and [9] KEGG. http://www.genome.jp. [10] M. Koyuturk, A. Grama, and W. Szpankowski. An [11] J. Kukluk, C. You, L. Holder, and D. Cook. Learning [12] M. Kuramochi and G. Karypis. Frequent subgraph [13] M. Lahiri and T. Berger-Wolf. Structure prediction in [14] M. Lahiri and T. Berger-Wolf. Mining periodic [15] D. J. Lockhart and E. A. Winzeler. Genomics, gene [16] Z. Qu, W. MacLellan, and J. Weiss. Dynamics of the [17] J. F. Roddick and M. Spiliopoulou. A survey of [18] P. Shoubridge, M. Kraetzl, W. Wallis, and H. Bunke. [19] J. Sun, C. Faloutsos, S. Papadimitriou, and P. S. Yu. [20] J. Sun, D. Tao, and C. Faloutsos. Beyond streams and [21] H. Tong, S. Papadimitriou, J. Sun, P. S. Yu, and [22] B. Tu, A. Kudlicki, M. Rowicka, and S. McKnight. [23] X. Yan and J. Han. gspan: Graph-based substructure [24] C. You, L. Holder, and D. Cook. Application of [25] C. You, L. Holder, and D. Cook. Graph-based data
