 1. Introduction
Content-based image retrieval (CBIR), also known as query by image content, is to search for images with similar content in a large collection of images with computer vision technologies ( Gudivada &amp; Raghavan, 1995 ). Thus, it is paramount for CBIR system to store and manage collected images efficiently. Meanwhile, the use of computer-aided diagnosis (CAD) system by radiologists in practice has led to an increasing demand for efficient medical imaging data storage and retrieval techniques based on its specific image features is an important alternative and complement to text-based retrieval using keywords ( Shyu etal.,1999;Kim,Cai,Feng,&amp;Wu,2006;Zheng,Wetzel,Gilbertson,&amp;Becich,2003 ). Fig.1 showsthearchitectureofCBIRsystem. image features have been applied to medical images, which significantly improves the development of CAD system. M X ller et al. (2004) have reviewed the increasing research on content-based retrieval approaches in medical applications and found that the majority of the research mainly focuses on particular image content, modality, body region, or pathology with some extraction and database building should and would be paid more attention to. Although Stefanescu and Leventon (2003) introduced the database organization for CBIR system, they did not discuss it in detail.
In this study, we summarized our successful experiences of building a database for computer-aided brain CT images diag-nosis system based on CBIR technology. We introduced the process of database building including data collection and val-idation, image normalization, registration and feature extraction in detail. In image normalization, we found an ellipse to best match the whole brain region and use its long radius and short radius to correct the rotation angle and rescale the el-lipse region. Besides, we used non-negative tensor factorization (NTF) algorithm to extract image features and also compare this approach with other three feature extraction methods: principal components analysis (PCA), Gabor filters and non-neg-ative matrix factorization (NMF). Three datasets were used to build database respectively and the accuracy and speed of im-age retrieval with the built database were evaluated.

This paper is organized as follows: In Section 2 , the data acquisition and verification process is introduced. Image prepro-cessing including normalization and registration is described and illustrated in Section 3 . Feature extraction and manage-ment is summarized in Section 4 . Image retrieval experimental results and evaluation are presented in Section 5 . Finally, in Section 6 , discussion and concluding remarks are provided. 2. Image collection and management
The function of our CBIR system crucially depends on the image database that we built. The database consists of a large collection of normalized, high quality, anonymous medical imaging cases. It is continuously and monotonically updated through a distributed process in which data from luminary sites are securely acquired, cleansed, validated, enhanced and tested. Here, a case is defined as one or more series of scans acquired from the same patient in the same medical institution within a relatively short time. A series is a collection of two-dimensional digital slice images. Images within the same series ture representation or saliency map for each image, clinical reports and diagnosis information for each case. 2.1. Data acquisition and validation
The images of our database are provided by collaborators and partnering hospitals. Currently, the pathologies presented in the database are the diseases often seen in conventional radiological imaging centers. However, it would become increas-ingly important to preferentially populate the database with specific diseases. To populate the database, several types of data are acquired in our system at the same time, including image data in DICOM format, the radiological report, histopathology report and any other relevant reports if available. All data are collected anonymously by removing all patient confidential information before being sent to our system via DICOM push, CDs, Zip disks, or FTP. All internet-based transfers are done on secure lines. Upon arrival at the system, data is processed through a number of preparatory steps into a standard format.
The radiological clinical reports and integer values labeling pathology classifications are amalgamated to the corresponding image data. Next, the aggregate dataset representing a case is processed through a validation and enhancement stage, per-formed by Registered/Licensed Radiologic Technologists who are also registered in specialty imaging. The technologists re-view the images for quality (sub-optimal images are discarded), pulse sequence accuracy, and contrast indicators. Finally, clinical image data is reviewed for accuracy and consistency. During the review process, each pulse sequence (series) is re-viewed individually and compared to the clinical report with the identified abnormalities in the images. The abnormalities or are delineated as region of interest (ROIs).

Throughout this process, difficult cases are reviewed by neuroradiologists. When appropriate, ROIs for these difficult cases are delineated under the direction of the neuroradiologist. For further validation, random samples of the recently en-tered cases are reviewed on a regular basis. Furthermore, regression analysis is performed on every base before entry into the database. Finally, random samples of the entire database are reviewed regularly to ensure the accuracy and integrity of both the data and the processing. The final stage of data loading is to process and store the resulting data in the database. 2.2. Disease types The following list shows the main types of CT image cases: Normal brain Atrophy Stroke Cystis Tumor Trauma/hemorrhage
Other 2.3. Standard axial image position
The brain CT series includes many slices. In axial cases, each image in one series has an anatomy position, called Z -posi-tion, which is used as an index for the construction of a subset of images with same/close Z -position. Therefore, for any query image, its Z -position is initially estimated, and then image retrieval would proceed in the image subset of close Z -position, which makes retrieval more efficient and effective than performing retrieval in the entire database. Setting up standard axial image position includes following steps: randomly select a series of images from the database; manually label the  X  Z -posi-type as training samples to create a robust fitting model. Partial-least-square method and Gabor texture feature matching were used in training and the fitting model was created based on features with the  X  Z -position X  for each sequence type to automatically estimate image anatomy position. In our study, the error of Z -position auto registration was within 5% of brain size level when registering the images in one series as a whole. While, the registration result of single image, especially for the pathology image, was a little worse. 3. Image normalization and registration
Our system combines advanced image processing algorithms with direct access to a large medical image database to reli-ably return the images which are similar to the queries submitted by the user. The database matching system relies on a very large, well organized database of images. In this framework, the images in the database are organized in such a way to make the most effective use of the information provided for the matching of a query image.

All of the current medical images are pixel-based digitalized images (MR, CT), or can be transferred to pixel-based digital images (e.g. X-ray to CR). The number of pixels in a standard medical image is very large (e.g. 256 256 for CT and 512 512 for CT images) and the pixel-related physical parameters show a very pronounced variability in terms of pixel size and pixel content variations which are related with human object rotation, shift, human normal anatomic variation and so on. There-fore, matching pixel-based image directly is not reliable and practical. Some image processing algorithms are needed to nor-malize the images in the database, which is a key step of the organization of the database.

Here, our approach is to choose an ellipse structure that would cover the whole brain region without retaining too many useless background pixels. Furthermore, the ellipse should not be sensitive to small oblique imaging angle and human brain normal anatomical variations in the terms of age, physical size and shape. Before fitting the ellipse, image preprocessing including denoising, preserving region of interest, cutting region of background and locating the skull contour is needed. Then the ellipse would be easily found on the axial and coronal images.

Image normalization is performed in two steps: rotation correction and image scaling. The direction of the ellipse X  X  long radius is compared with a standard direction to compute the correction angle for rotation correction. Both long radius and short radius of the ellipse are compared with the standard ones to rescale the ellipse region. More details about image nor-image to the normalized result. Fig. 3 shows original images and normalization results of different slices of one person (left) respectively, which illustrates the importance and effectiveness of image normalization.

When additional images are loaded to the database or new query images are submitted, image registration is employed to register the images to the standard coordinate system defined by all other images in the database, which ensures the con-tinued consistency of the database. Besides, image registration ensures only corresponding regions of images are compared during a match, which saves time and reduces the possibility of false matches. A registered database of medical images pro-vides tremendous information about statistical anatomic and pathologic properties of regions. Thus, when a query image is matched to the large, organized database of images, the best matches provide a very useful statistical information about the query image (such as diagnosis) with a high level of confidence. 4. Feature extraction and format
Since CBIR means that the search will analyze the actual image contents, which refer to colors, shapes, textures, or any other information that can be derived from the image itself, and search for similar images based on the contents, thus some features are needed to be extracted to express the contents. For medical images, the chosen features are expected to capture the salient information in the images and highlight the indications of pathology. Moreover, they should be robust to slight misalignment and invariant to various imaging artifacts. These features are the input into the database and used in the image match algorithm. 4.1. Region of interest and non-specific abnormal slices When the indication of an abnormality manifests itself (visibly) in an image, the image is marked with one or more ROIs. It provides a means to focus the attention on a consistent particular region of interest corresponding to the given pathology. The attention mechanism eliminates distracters that would contribute to a false match. In our system, ROIs are rectangular regions of pixels within a fixed size grid which is superimposed on each image. A variable number of ROIs can be identified for a single DB image, and stored in the database. In this study we employ gaussian mixture model and region spreading automatic detection of stroke cases and tumor cases respectively.
 One or more images within an abnormal series or an abnormal case have associated ROIs. The slices that have associated
ROIs would be referred to as abnormal images (or simply as abnormal). However, in most cases, the abnormality does not manifest in all images (slices) of the entire series, that is, there might be some images within an abnormal series of an abnor-mal case that do not have any associated ROIs. They are referred to as non-specific abnormal images (or non-specific abnor-mals) and can never be selected for scoring against any query image. Non-specific abnormal images are only available for viewing as part of a series for which a match has occurred with an abnormal image in the same series. 4.2. Feature extraction methods
When a user submits a query image, the image must be aligned to the database coordinate system before matching to make sure that only corresponding anatomy regions are compared during image matching. The same type of features pre-viously extracted from the reference images in the database are extracted from the query image in a similar manner. The features are input to the database and used to search the similar images, then the match scores are sorted with the best matches being reported to the user, along with additional information such as the diagnosis and findings associated with each matching case.

We use non-negative tensor factorization (NTF) for extracting feature of brain CT image ( Zou, Yuan, &amp; Liu, 2008 ). Given a 3-order tensor T with non-negative values for all entries, NTF is to minimize the objective function to get three component matrices: U , V , W , where u j , v denotes the square Frobenious norm, that is the sum of squares of all entries of tensor elements. Note that the constraint condition u j , v j , w j P 0 is necessary for NTF to preserve non-negative factorization.

The reason we choose NTF is that it treats the whole CT image set as a 3D tensor which keeps each CT image in 2D rep-resentation, and therefore preserves the spatial structure information. In addition, it represents local parts of the image set, which is consistent with certain theories in visual recognition and psychological and physiological evidence that support part-based representations in the brain.

In this study, the tensor T means a brain CT image dataset. The 1st dimension and 2nd dimension of T represent the row and column of a CT image, and the 3rd dimension denotes the number of samples in the CT dataset. Each of the matrices of W in non-negative matrix factorization (NMF) ( Liu et al., 2008 ). Each row of the component matrix W is similar to each column of H in NMF ( Liu et al., 2008 ) and represents the feature of each image in CT dataset, which will be used in the sub-sequent image retrieval. Instead of applying NTF on the whole dataset, we use only one type of cases in the dataset as the tensor T 1 to obtain component matrices: U 1 , V 1 and W 1 features of these cases; then apply NTF respectively on the other types of cases in the dataset replacing the component matrices U , V with U 1 and V 1 and keeping them fixed in order to get W as their corresponding features. Here, the dimension of feature extracted by NTF is 50. More information of the detailed factorization process can be found in Zou et al. (2008) . 4.3. Feature file format
Given the simplicity of this searching algorithm, we encode the  X  X  X atabase X  of features and Z -positions simply as files that can be either entirely read into memory (space permitting), or accessed randomly (using fseek) from the disk. Relational dat-abases are extremely useful whenever the data is read from/written to multiple sources or when the queries supported are quite general. In the case of feature database (FDB), we have a very limited set of queries that operate effectively on read-only database (in the sense that database will be frozen at discrete intervals and transferred to the production  X  X  X atabase X  or production data files). However, we may have a small, simple accessing database to keep the patient-specific information (such as age, gender, pathology, and clinical reports) which is independent from the FDB algorithms. While we expect the user to constrain the search by age, gender and so on, we believe that the user will actually rarely select such options, in which case we do not want to bog down the filter/match stage by adding this generality. If the filter/match only takes a cou-ple of seconds (which is the expectation), adding functionality to do text filter at the end should not affect the search per-formance, and will allow the core filtering/searching algorithms to remain simple and clean.

There are two primary files that need to be read as input in image matching. The first is an Z -position index file used for filtering, and the second is a feature file used for matching. The index file is expected to be in the order of 1 Megabyte, and should always be read into memory in its entirety. The feature file may be as large as 100 Megabytes, and should (initially) be accessed randomly from the disk. The two corresponding files consist of a list of N -corresponding records (e.g. record i from the index file corresponds to the same database image as record i from the feature file). 5. Image retrieval and evaluation
We built the database of brain CT images using three datasets respectively: dataset 1 with 17 normal cases and 92 tumor cases, dataset 2 with 17 normal cases and 25 stroke cases, dataset 3 with 17 normal cases, 25 stroke cases and 92 tumor cases. The feature extraction method is NTF with the reduced dimension r = 50, and the query image is factorized with the same method using in database creation. Three other feature extraction methods : PCA, Gabor filters and NMF are also used to make a comparison with NTF. There are two types of retrieval scheme used in our study: one is using support vector machine (SVM) to recognize the type of query image to return images of the same type; the other is using K -nearest neighbor (KNN) to find the top k nearest neighbors of the query image. Euclidean distance of features is used as the distance measure in KNN. Here we set k =1.

We evaluate the database built for our CAD system mainly in terms of retrieval accuracy and speed. 5.1. Retrieval accuracy evaluation
The accuracy of image retrieval is evaluated based on the similarity between the query image and the retrieval image. The common similarity measurements such as normalized correlation coefficients (NCC) and mutual information (MI) do not suit for medical image retrieval evaluation. Table 1 shows the average of NCC (ANCC) of every two images when they belong to the same type (normal, tumor or stroke) or different types respectively. The row and column stand for the types two images belong to respectively. The absolute value of ANCC between tumor cases is observed to be smaller than that between different types of images, which can be mainly attributed to pathologic variations such as different size, shape and position of tumors, considering that other variations related with human object rotation, shift and human normal anatomic variation have been reduced by preprocessing. Therefore, here we refer similarity evaluation of two brain CT images to that whether they belong to the same type. Thus, the retrieval accuracy is defined as the following: where n c is the total number of c th class to which the sample i belongs, C is the total number of classes. neighbors of sample i ; d [ ID ( i ), ID ( j )] =1if ID ( i )= ID ( j ), or zero otherwise.

The retrieval accuracy in three datasets with two retrieval schemes (SVM and KNN) using NTF feature extraction method are shown in Table 2 . Leave-one-out method is used here to get mean accuracy and standard deviation which is shown in parentheses. We can see that nearly all the results are more than 80%, which illustrates the effectiveness of our database built for computer-aided medical diagnosis. We can observe that in both retrieval schemes, dataset 1 has the highest accu-or the number of stroke cases in our database is too small to cover the pathologic variations of stroke.

We compared NTF with three other feature extraction methods (PCA, Gabor and NMF) and their corresponding retrieval
The x -axis stands for these four different feature extraction methods: NTF, PCA, Gabor and NMF, and y -axis shows their cor-responding accuracies. Note that the dimensions of features extracted are all 50 except PCA in dataset 2 where the dimension is 40 instead, since there are not enough cases in dataset 2 to extract 50 dimensional features with PCA. In both (a) and (b), the accuracies of NTF in three datasets are all the largest compared with the others, which proves that NTF performs better than PCA, Gabor and NMF in preserving the spatial structures and extracting local features of images that highlight the indi-cation of pathology. We can also observe that the accuracies of four feature extraction methods in dataset 1 are all larger than those in dataset 2 and dataset 3, which is consistent with the phenomenon observed in Table 2 .

There are two important parameters to evaluate medical diagnosis: True positive rate (TP) and False positive rate (FP). TP is the proportion of positive cases that are correctly diagnosed as being positive, while FP is the proportion of negative cases that are erroneously diagnosed as being positive. It is expected to get higher TP and lower FP to ensure that less patients would be missed and less normal people be erroneously diagnosed. Because our database built for computer-aided medical diagnosis aims to select out the suspicious patients and offer some preliminary diagnosis results for doctors X  further diag-nosis, so we prefer higher TP to lower FP when the total accuracy (the proportion of both positive and negative cases that were correctly diagnosed) is above an acceptable threshold. Fig. 8 illustrates the TP X  X P distribution of retrieval accuracy with these four feature extraction methods for a further comparison. (a) and (b) show the results with SVM or KNN respectively. has the highest TP and lowest FP. In dataset 2 of (b), although NTF has a higher FP than NMF, the former has a much higher TP than the latter. Thus, NTF is proved to be more effective to extract the pathological features for medical diagnosis. 5.2. Retrieval speed evaluation
All processes including database building and image retrieval were done on a standard PC computer with a Windows XP operating system and a Pentium 4 Processor at 2.6 GHZ, 768 MB of RAM. Database building mainly includes feature extrac-tion using NTF and classifier training with these features if SVM is employed. Therefore, the algorithmic time complexity of database building with KNN as the retrieval scheme equals to that of feature extraction, which can be denoted as
N 1 O (( I J + J K 1 + I K 1 ) r 2 +( I + J + K 1 ) r 3 )+ N component matrix U , V , W in NTF. N 2 represents the number of iterations to extract features of an image with already known matrix U , V . I and J represent the dimensions of images, K represents the number of the rest cases in dataset to be factorized using the U and V . r represents the dimension of features. While, when SVM is employed as the retrieval scheme, the time complexity of SVM training which can be denoted as
O  X  N s v  X  L N of support vectors and L is the number of samples used for training. In our study, it takes about several hours to build the database with 50 dimensional features extracted by NTF and train the support vector machine, however, because the database is built off-line, so the very speed that users of the database really care is query speed. Image retrieval includes feature extraction of query image and classification, so the corresponding time complexity is N where N c is N sv when SVM is used or the number of all cases in dataset when KNN is used. In our study, less than one minute is needed for an image retrieval which is acceptable for the interactive system. In some situations when speed is much more preferred than accuracy, least squares method without limiting the feature vector to be non-negative can be employed in feature extraction of query images to further speed up the retrieval. 6. Discussion and conclusion
Cost containment, reimbursement capitation, and the drive towards more streamlined operations have all added consid-erable pressure to the practicing radiologist to read more cases in a shorter time, while retaining as much accuracy as possible. An optimizing solution is to provide them with a mechanism for retrieving pre-diagnosed, validated, and highly relevant examples from a large database based on image content. To meet the request, we built an image database for brain
CT. The database consists of a large collection of normalized, high quality, anonymous medical imaging cases. To load images into the database, sophisticated image processing algorithms including image normalization, registration and feature extrac-tion are applied in order to extract and associate with each image a vector of features that are essential for the matching process. The database is continuously and monotonically updated through a distributed process in which data from luminary sites are securely acquired, cleansed, validated, enhanced and tested. Internet can be used to make a ubiquitous access to the database, and CBIR algorithms are used to rapidly and accurately retrieve the most relevant images in the database. Our primary experiments have proved the efficiency and robustness of the method of database building for CAD system. While this paper has focused on CT brain images, similar mechanisms would be developed for retrieving brain images of MRI,
SPECT or other modalities. We also expect to collect more data, especially cases of brain lesions such as stroke, hemorrhage and so on to enlarge and improve our database. Besides, we expect to improve our retrieval system with some quantitative analysis of brain lesions based on their simatic features.
 Acknowledgments This work was supported by the Scientific and Technological Planning Program of Guangdong Province of China (Grant No. 2008B030303055), and the Scientific and Technological Planning Program of Heilongjiang Province of China (Grant No. GZ05C402). The authors would also like to thank their partnering hospitals.
 References
