 We present a novel technique that optimizes the dispatching of incident tickets to the agents in an IT Service Support Environ-ment. Unlike the common skill-based dispatching, our approach also takes empirical evidence on the agent X  X  speed from historical data into account.

Our solution consists of two parts. First, a novel technique clus-ters historic tickets into incident categories that are discriminative in terms of agent X  X  performance. Second, a dispatching policy se-lects, for an incoming ticket, the fastest available agent according to the target cluster. We show that, for ticket data collected from several Service Delivery Units, our new dispatching technique can reduce service time between 35% and 44% .
 I.5.3 [ Pattern Recognition ]: Clustering algorithms; I.2.7 [ Natural Language Processing ]: Text analysis; I.2.8 [ Problem Solving, Control Methods, and Search ]: Scheduling Combined affinity matrix; Graph Cut; Spectral Clustering; Fuzzy Clustering, Ticket clustering; Ticket dispatching
Enterprises and IT service providers are constantly striving to improve the quality of service and in the same time maintain or reduce the cost of service delivery. One of the major challenges in service delivery is resolving the hundreds of incidents as efficiently as possible. This is an important but labor intensive task, assigned to the service agents that are responsible for solving the customer X  X  incident reports.

In our setting, incidents in the customer environment are submit-ted to the IT Service Provider in the form of a ticket which is a snip-Figure 1: Integration of the clustering and dispatching compo-nent. pet of text describing a particular IT problem. The reported prob-lems range widely from authentication errors, application crashes, to broken transactions or server unavailabilities.

The dispatching to the service agent is generally done on two levels. First, a human dispatcher reviews the problem description text and decides which delivery unit (a team of service agents) is responsible for addressing that type of ticket. Second, within the delivery unit, a service agent is either chosen by the group leader or on a voluntary basis. The dispatching at this level is based on the qualification of the agents, the availability and the workload of the agents, as well as the complexity of the ticket. At this level we have identified an opportunity for automation and optimization of the dispatching process. Empirical evidence on which agent is most efficient in solving a certain category of tickets is not explic-itly taken into consideration. Therefore we derive a method for ticket clustering, which identifies ticket topics (categories) that are discriminative in terms of an agent X  X  performance and dispatches each ticket from every category to the agent that is the most effi-cient in executing it.

The clustering and dispatching component is designed to be inte-grated in the IT Service Delivery Environment as shown in Figure 1. In this paper, we show that the existence of such a component that takes informed dispatching decisions, can reduce the resolution time and by extension, the business costs. We demonstrate this by conducting experiments on real data collected from different ser-vice delivery units. This data comprises the ticket description and its complexity, the agent who resolved it, the duration recorded for resolving it, etc.

Our approach partitions the tickets into clusters that are relevant with respect to the problem they describe and that are also homo-geneous in terms of the agent X  X  performance. We achieve this by leveraging multiple views of the ticket data. A cluster is homo-geneous in terms of an agent X  X  performance if the variation in the time it takes for an agent to solve tickets from that cluster is small (the distribution is narrow, as illustrated in Figure 2). This way, we can infer the approximate duration needed for an agent to solve the tickets that pertain to a certain cluster from the historical data. Fur-ther, we use this information in the dispatching process, by always assigning the ticket of a given cluster, to the agent that is the most efficient in solving tickets of that cluster. The difficulty in find-ing these clusters is that applying a standard algorithm that groups the tickets based solely on their most prominent topics, leads to clusters that are non-homogenous in terms of the agent X  X  perfor-mance. Therefore, we propose a clustering approach that performs a partitioning that can discover meaningful ticket categories with homogeneous agent performance.

Our contributions are manifold:
The outline of this paper is as follows. Section 2 presents the in-cident ticket clustering method. Section 3 provides an overview of the data-informed dispatching policy. The experimental evaluation on real-world datasets is presented in Section 4, followed by the related work in section 5 and the conclusions in Section 6.
We devise a method that partitions the set of tickets into groups of similar tickets both in terms of the incident they report and the time needed for an agent to resolve them. The method utilizes both the matrix of semantic similarities between tickets, and the diver-gence matrix -a matrix which captures information on the differ-ence in the duration of resolution of two tickets assigned to the same agent. More specifically, we first modify the semantic sim-ilarity matrix based on the information represented in the diver-gence matrix, and then, we run a clustering algorithm that operates on the resulting matrix. For each cluster, we derive an estimate for the time each agent needs to resolve tickets pertaining to that clus-ter. Ultimately, we devise a dispatching policy that assigns each ticket to the agent who is the fastest at resolving it and compute the achieved reduction in terms of service time due to the new assign-ment.

In the method described above, a small variation in the agent X  X  performance for the clusters is part of the output. We also propose an algorithm that takes a clustering and a target variation for the clusters as an input and then adjusts the clusters structure to achieve the target variation specified in the input.

In Figure 3 we show an example of the desired clustering assum-ing we had only four tickets. Even though the semantic similarity between tickets T 1 and T 3 and tickets T 2 and T 4 is high, we do not put them in the same cluster due to the large difference in the resolution times. Instead we cut the edge that links them in the sim-ilarity graph. Therefore, for this example, instead of reporting the two clusters  X  X ervers issues" and  X  X B issues", we would discover  X  X etwork issues" (as denoted by bigrams  X  X ost connection" or  X  X ing statistics") and  X  X unctional errors" (as denoted by bigrams  X  X erver crashed" or  X  X nconsistent state").

Let T be a ticket consisting of | T | words w 1 ,  X  X  X  ,w | T | K = { T 1 ,T 2 ,  X  X  X  ,T n } be a set of n tickets. Also, let A = { a 1 ,a 2 ,  X  X  X  ,a | A | } denote the set of agents who resolved the tick-ets. Each ticket T i , is associated with several fields: d tion for resolving it, a ( i ) the agent who resolved it and c {  X  X ", X  X ", X  X " } the complexity of the ticket (where  X  X " denotes the highest complexity and  X  X " the lowest).

For each agent a i there is a mapping to its skill level s An agent with skill level  X  X " is entitled to resolve tickets of any complexity class, an agent with skill level  X  X " is entitled to resolve tickets of complexity  X  X " and  X  X ", and an agent with skill level  X  X " is entitled to resolve only tickets of complexity  X  X ".
The typical approach to measuring the similarity between two blocks of text is to use a lexical matching method, and compute a similarity score based on the number of lexical units (words) that occur in both input texts. Pre-processing the texts via stemming, removal of the stop words, longest subsequence matching and addi-tional normalization and weighting factors have shown to improve the results of such lexical methods [18, 10]. However the lexical similarity measures alone have an important limitation: they fail in identifying the semantic similarity between texts (i.e., the similar-ity score between  X  X rocess shutdown" and  X  X pplication terminated" would be zero).

In this section, we describe the method we used to compute the semantic similarity metric between tickets [19]. It is derived from the semantic-similarity metric between words, described in the next section. We define the semantic similarity between two tickets T and T j , given the semantic similarity between words. Each word w in T i is assigned a semantic similarity score maxSim ( w,T based on the most similar word in T j . The procedure is applied symmetrically, for each word in T j . The word similarity scores for each ticket are added and each summation is normalized with the length of its corresponding ticket. The final result is the average of the normalized summation of each ticket:
Let S  X  R n  X  n denote the ticket-ticket semantic similarity ma-trix, where S ij = Similarity ( T i ,T j ) .

Another type of proximity relation between tickets is given by the divergence matrix described below. If two tickets T i that are annotated with the same complexity level (i.e., c have been resolved by the same agent ( a ( i ) = a ( j ) ) and the ratio in their corresponding resolution times is higher than a certain thresh-old  X  then they have different level of difficulty and they should not be clustered in the same group of incidents. We define the diver-gence matrix D  X  R n  X  n : Two tickets which are similar in terms of both their topics and the duration it took an agent to resolve them may reveal stronger con-nection than two other tickets which are similar only in terms of topic. Motivated by this statement we combine the two proximity relations (views) into one matrix S 0  X  R n  X  n as follows:
We induced sparsity on S by setting the similarity scores in S to 0 when D ij = 1 .
As the same incident may be documented with different words, we are interested in assessing the degree of similarity between words in the specific IT Service Delivery domain.

For extracting the semantic similarity scores between pairs of words, we have explored three corpus-based methods which have been reported to give good results [22, 8]. The methods are: PMI-IR [14], the Google similarity distance (GSD) [6] and LSA [26].
PMI-IR only requires simple statistics about two words: their marginal frequencies and their co-occurrence frequency in a cor-pus.
 where p ( w i ,w j ) denotes the probability that words w occur in the same ticket, p ( w ) is the probability that the word w occurs in a ticket. Please note that we do not need to specify a window size for estimating the co-occurrence frequencies of w and w 2 as the ticket descriptions are usually short ( &lt; 20 words).
GSD is based on information distance and Kolmogorov com-plexity. In the original paper, the authors rely on Google to retrieve pages for co-occurrence statistics. We adapt the extraction of co-occurrence statistics to our setting, as follows: GSD( w 1 ,w 2 ) = max { log( | f ( w 1 ) | , log( | f ( w where Q = P w bers of occurrences of search terms in each ticket, summed over all tickets) and f ( w 1 ,  X  X  X  ,w k ) represents the set of all tickets in which the words w 1 ,  X  X  X  ,w k appear together.

In LSA , term co-occurrences in a corpus are captured via di-mensionality reduction operated by a singular value decomposition (SVD) on the term-by-document matrix representing the corpus.
While all the methods gave meaningful results regarding the re-latedness of words in a broader sense (i.e., flagging associations between pairs of words such as  X  X ung" and  X  X ing" or  X  X isk" and  X  X ull" as significant), LSA outperformed the other two methods in identifying synonyms. In order to perform a quantiative evaluation of how well each method performs on our corpus (comprised of a large set of ticket descriptions and ticket resolutions) we did the following: The process described above has resulted in a list of 72 pairs of words that are synonyms in the IT Service Delivery domain (e.g.,  X  X ingable" and  X  X esponsive" or  X  X rchive" and  X  X ackup" ). We con-sider a method has identified a pair of synonyms ( w 1 ,w scaled semantic similarity score between ( w 1 ,w 2 ) is above the mean of the semantic similarity scores between w 1 and any other word in the corpus (or w 2 and any other word in the corpus).
We count the number of synonyms identified by each method and divide the result by the total number of pairs of synonyms. The results are shown in Table 1.

There are several reasons why LSA outperformed the other two methods. First, the conventional wisdom is that synonym words, with a high degree of relatedness are unlikely to co-occur in a small window size. Second, it is plausible to represent the meaning of a Figure 4: Sparsity: similarity matrix (left), divergence matrix (right). word by a context vector of co-occuring words and the correspond-ing co-occurrence counts measured in a text window context. LSA performs this and in addition, it transforms the context vectors to a lower dimensional space by applying singular value decomposi-tion (SVD). The similarity is further reduced to the similarity of the context vectors where the cosine of the angle is employed as a similarity metric.
The tickets are related via two types of similarity measures that originate from different sources: one that comes from the ticket content -the ticket similarity matrix S , and one that comes from the agents who resolved the tickets -the divergence matrix D .
Due to the extreme sparsity shown in Figure 4, the divergence matrix alone does not contain complete information of the structure of the clusters. Since both matrices capture important information, we propose an approach that uses the two matrices in the combined matrix S 0 as defined in equation (3) and has the following objec-tives:
I Cluster similar tickets together (we want to be able to extract
II Minimize the number of pairs of tickets in the same cluster that
We achieve this using three candidate clustering algorithms namely: hierarchical clustering with complete linkage [7], spectral cluster-ing [20] and our adjusted version of fuzzy k-means [3]: homogene-ity optimized fuzzy k-means.

Hierarchical clustering and spectral clustering are hard cluster-ing algorithms, i.e., each ticket is a member of exactly one cluster. The input for these algorithms is the matrix S 0 .

Fuzzy k-means is a soft clustering algorithm -and therefore re-turns a partition of the n tickets { T 1 ,T 2 ,  X  X  X  ,T n } into k clusters { C 1 ,C 2 ,  X  X  X  ,C k } specified by a membership matrix M  X  R M ij  X  0 and P k j =1 M ij = 1 , whose components quantify the membership degree of ticket T i in cluster C k . The input for fuzzy k-means is the similarity matrix S . We optimize the homogeneity of these clusters by iteratively moving tickets from their most prob-able clusters to the second, third, up to the least probable clusters, as will be described later on. We selected fuzzy k-means and not LDA [4] because the ticket descriptions are very short, which is too sparse for traditional topic modeling. Therefore we used a soft clustering algorithm that is able to leverage the similarity matrix S .
While hierarchical clustering does not require the specification of the number of clusters, k , spectral clustering and fuzzy k-means take k as input. In order to estimate the optimal number of clusters for the two latter algorithms we use the silhouette statistic , a well-balanced coefficient introduced in [11] and which has shown good performance in experiments.
 Let C = { C 1 ,C 2 ,  X  X  X  ,C k } be a clustering of the set of tickets. For each cluster C i  X  C , for each complexity class c  X  W and for each agent a c  X  A (such that a c has solved tickets in C complexity c ) , one can measure the dispersion in the duration of resolution. The metric we propose for this is the coefficient of vari-ation (CV), defined as the ratio of the standard deviation of these durations to their mean: where s x is the standard deviation of a set of samples x their mean.

The motivation for using the coefficient of variation is the fol-lowing: the standard deviations of two sets are not comparable to each other in a meaningful way to determine which set has greater dispersion because the values in the sets may have different magni-tudes. The coefficient of variation does however show the extent of variability in relation to the mean.
The agglomerative hierarchical clustering algorithm with com-plete linkage, works as follows:(i) the algorithm starts with n clus-ters, each containing one object; (ii) the most similar pair of clus-ters C i , C j is found using the combined similarity matrix S merged into a single cluster. (iii) the similarity matrix is updated (its order is reduced by one by substituting the individual clusters with the newly merged one). Steps (ii) and (iii) are repeated until a certain stopping criterion is reached.

This method is relevant for our study because of the distance measure that is used between two clusters in the merging step in S lm ) . If s k denotes the similarity of the two clusters merged in step k , this distance measure ensures that no pair of tickets with similarity 0 (distance 1) will be put in the same cluster. The clusters at step k are maximal sets of points that are completely connected with each other by edges of weights (similarity) s  X  s k .
Using the combined similarity matrix S 0 in a spectral clustering algorithm there will result a partitioning obtained by minimizing the cuts in the input graph and thus implicitly maximally satisfying the objective II above.

Spectral clustering works as follows: 1. Construct the Graph Laplacian L from the combined similar-2. Select the first k eigenvalues  X  1 ,  X  X  X  , X  k and determine their 3. Perform clustering in the new subspace using K-means.
We use the similarity matrix S to perform the soft clustering with fuzzy k-means. The resulting clusters will not be homogeneous in terms of duration because we only pass the semantic similarity matrix to the algorithm. In the following, we propose an approach that utilizes the clusters returned by fuzzy k-means and reduces the variation in duration inside the cluster by iteratively removing tickets.

Let C = { C 1 ,C 2 ,  X  X  X  ,C k } be the clusters returned by fuzzy k-means and Pr ( T | C i ) denote the probability of ticket T belonging minimizes the variation from a sub-cluster C ( a )( c ) i tickets in C i that have been solved by agent a and have complexity c ) and removes it from the cluster. The ticket is then tentatively inserted in the the next most probable clusters in an order given by the ranking from fuzzy k-means. A ticket is inserted in another cluster if the variation in duration of the cluster with the ticket does not increase. If the ticket can not be inserted in any of the clusters it is dropped. This procedure continues until the variation in duration inside C ( a )( c ) i reaches a target value  X  . These steps are formalized in Algorithm 1 and Algorithm 2: Algorithm 1 Optimize homogeneity of the clusters. 1: function OPTIMIZE ( C ) 2: for all C i  X  C do 7: MOVE ( T ) 8: end while 9: end for 10: end for 11: end function Algorithm 2 Move a ticket. 1: function MOVE ( T ) 2: for C i  X  C \{ T } sorted in decreasing order of Pr ( T | C 5: else 6: DROP ( T ) 7: end if 8: end for 9: end function
Homogeneity optimized fuzzy k-means has the following prop-erties: (i) the variation inside the final clusters is not an output of the algorithm but an input parameter of the algorithm and that en-ables finer control. The variation of the resulting clustering will not exceed the one given as an input. (ii) The algorithm can be used for identifying the outliers in the data set. To achieve this we only move the ticket to the second or the third most probable clus-ters and drop it if it cannot be placed. The advantage of doing this is that the coherence of the clusters with respect to the topics re-mains unaltered (unlike the base algorithm where we tradeoff topic relevance for high homogeneity). Additionally one can inspect the set of dropped tickets and observe which type of incidents have inherently higher variation in the resolution time.
For a given partitioning C = { C 1 ,C 2 ,  X  X  X  ,C | C | } , we build a matrix P  X  R | A | X | C | X | W | which stores the median duration for the execution time for each agent in resolving a ticket pertaining to Figure 5: Agent X  X  performance for a given cluster and complex-ity level. one of the clusters for a certain complexity class. Some entries in this matrix will be  X  1 . When an entry P ijk =  X  1 it means that there are no records in the data of agent a i working on a ticket from cluster C j of complexity k where k is an id for each complexity class {  X  A  X  ,  X  B  X  ,  X  C  X  } .

We implement the data-informed dispatching policy and the non data-informed dispatching policy. Unlike the non data-informed dispatching policy, the data-informed policy, dispatches a ticket T j  X  C j to the agent that is the most efficient in resolving it from all the agents that are available, i.e., it selects a i . such that P is minimal. The implementation of the dispatching aligns to the following setting: For the implementation of the dispatching, we split the data in sep-arate chunks for each working day. For every chunk, we store a list with all the agents available that day by mining the log for agents that have tickets associated to their id in that particular day. We also maintain a queue with the tickets that need to be completed that day by extracting the list of tickets from the logs that were recorded as started and completed that day. Ultimately, we run the data-informed dispatching policy and the policy that works un-der exactly the same assumptions, but without being data-informed (equivalent to the setting when an agent voluntarily selects the next ticket to resolve, provided that the agent has the necessary quali-fication -skill based dispatching [27]), and compare the recorded service times for each delivery unit.
We use three datasets: DU1, DU2, DU3 from three service de-livery units comprising 3696, 2373 and 1916 tickets respectively.
The first step in the analysis is the data cleaning procedure where we take the raw unstructured data and remove unnecessary infor-mation such as , email headers, punctuation, html formatting, server names, stop words and we also do stemming. This step is impor-tant as it severely impacts the performance of the algorithms. The ticket descriptions are a mixture of machine and human-generated text and contain many domain-specific technical words, some of which are not present in a standard dictionary (e.g.,  X  X npingable",  X  X sd",  X  X w"), but are still relevant in identifying the incident cat-egory. Some examples of ticket descriptions are given in Table 2. serverXYXY error : DISK Utilization :Object = /dev/sda3/var : percent full: 95% : MB free: 219 MB New User Request Form: XYXY backup missed on this server We are unable to connect to hosts serverXYXY.
 Please investigate
In the experiments we set the threshold to  X  = 0 . 8 , meaning that for two tickets from the same cluster, solved by the same agent and of the same complexity the variation of duration of executing them is within 20% . Using such small variation is reflected in the connectedness of the similarity graph. In Figure 6 we show how the percentage of deleted edges increases by increasing the value of  X  .
 Figure 6: Percentage of edges removed when increasing  X  (for DU1).
In what follows, we show that spectral clustering and homogene-ity optimized fuzzy k-means exhibit the best performance for this task.

We run hierarchical clustering with complete linkage (stopped at dissimilarity threshold 0.8). For DU1 we obtain a large set of clusters (176 clusters) with a low abundance of tickets (on aver-age 19 tickets per cluster), and also the clusters tend to have simi-lar sizes. This is illustrated in Figure 7 where we observe skewed distribution when plotting the cluster abundances. The results re-main similar when varying both  X  and the dissimilarity threshold for stopping (i.e., for  X  = 0 . 8 , dissimilarity threshold=0.9 we ob-tain 130 clusters, or for  X  = 0 . 5 , dissimilarity threshold=0.8 we obtain 92 clusters). The resulting clusters are small and with low variation in both topic and resolution time per agent, but they are not unique, i.e., they are fragments of larger clusters.

With spectral clustering we obtain 12 clusters with sizes between 193 and 659 tickets for DU1, 7 clusters with sizes between 232 and 601 for DU2 and 5 clusters with sizes between 134 and 385 for DU3. By analyzing the frequent words in the clusters we ob-serve that the algorithm is able to correctly capture relevant incident ticket categories in each cluster. This is shown in the Table 3 Table 3: Frequent words in the clusters obtained by spectral clustering using S 0 for DU1.

Homogeneity optimized fuzzy k-means exhibits also good per-formance in identifying incident categories. We obtain 12 clusters with sizes between 195 and 429 tickets for DU1, 7 clusters with sizes between 206 and 387 for DU2 and 5 clusters with sizes be-tween 127 and 368 for DU3.

We first run the algorithm such that no tickets are dropped. We choose the minimum value for the target coefficient of variation,  X  min , for each delivery unit, such that all the tickets are assigned to a cluster. The values for  X  min when no tickets are dropped for each delivery unit are given in Table 4. Note that the values for the coefficient of variation are small, due to the fact that we allow tickets to be assigned to less probable clusters. The frequent words in the clusters discovered are presented in Table 5. We observe that Table 5: Frequent words in the clusters obtained homogeneity optimized fuzzy k-means for DU1. both clustering approaches identify ticket categories documenting  X  X ile limit exceeded", problems related to the  X  X ower supply", or  X  X ackup" related issues. While the clusters obtained with spectral clustering place all the disk related tickets in one single cluster, with the homogeneity optimized fuzzy k-means we obtain two clusters documenting disk errors: one which was documenting disk replace-ment, and one reporting disk fan sensor issues. Also for homogene-ity optimized fuzzy k-means it is not always straightforward to es-tablish the incident category of a certain cluster. One such example is the cluster with top words  X  X sd, database, memory, corruption". Also, it merged tickets documenting  X  X ode down" with tickets doc-umenting  X  X ost, contact, agent". This hints to the fact that for an agent, these two categories of incidents take similar amount of time to be resolved.

When we introduced homogeneity optimized fuzzy k-means we also mentioned the possibility of identifying outliers, tickets that take either too long or too little time to be resolved by an agent rel-ative to the cluster they pertain to. This can be achieved by modify-ing the algorithm to move tickets only in the first three most likely clusters. This leads to a significant number of tickets dropped and this grows inversely proportional with the value of  X  as illustrated in Figure 8. By inspecting the dropped tickets we observe that they mostly document disk errors, and filesystem issues. The recorded duration for the dropped tickets is either very short either very large. This indicates that in the dispatching, for those tickets with larger duration one needs to have some margin with respect to filling the day completely.

In the following we evaluate the quality of the clustering ob-tained from running spectral clustering with the combined simi-larity matrix, and homogeneity optimized fuzzy k-means with the minimum values of  X  for which no tickets are dropped,  X  min inspect both the reduction in service time from implementing the data informed dispatching policy and the homogeneity in agent X  X  performance.
Let C = { C 1 ,C 2 ,  X  X  X  ,C k } be the partitioning of the corpus of tickets C . We measure the service time which is the total number of working hours needed for resolving all the tickets in a given pe-riod of time. We use the matrix P that for each cluster and for each complexity level stores the agent X  X  performance (as depicted in the Figure 5), and we run the data informed dispatching policy, both on the clustering obtained with spectral clustering and with the homo-geneity optimized fuzzy k-means. The data informed dispatching policy is evaluated against the dispatching that does not take the in-sight from the data into account (which agent is fastest in resolving an incoming ticket).

We observe a major reduction in the service time up to 44% (for DU2) when running the data-informed dispatching policy com-pared to the dispatching policy that does not consider the insight from the data. The reductions are apparent for dispatching based on both the homogeneity optimized fuzzy k-means clustering and the spectral clustering, slightly better in the former one (possibly due to the more uniform cluster sizes). The speedup is shown in Figure 9 where we denote by (DI) the data-informed dispatching policy and by (non-DI) the non data informed dispatching policy.
Figure 11 shows that the discrepancies in agent X  X  performance for a given cluster and complexity are large and exploiting these differences in dispatching leads to a significant reduction in the ser-vice time. Also we have identified that agents with skill level  X  X " are faster than agents with skill level  X  X " in solving tickets docu-menting  X  X etwork errors" of complexity  X  X ", shown in Figure 10. This illustrates that a higher skill (which is established based on experience or training level) does not directly translate into higher speed (which can only be established empirically, by analyzing the historical data). Note that we did not include service level agree-ments in both dispatching policies In particular we only kept the or-der of ticket arrival, but assumed that a ticket can be resolved by the optimal agent even if that meant ticket resolution could only start when this agent becomes free. Naturally this might delay ticket res-olution potentially conflicting with SLA requirements on resolution times. In contexts with such SLA constraints, a simulation taking arrival patterns into account can yield more precise assessments. Please note however that both dispatching policies considered in our experiments, work under exactly the same assumptions and are therefore comparable.
As the quality of the clustering is given by the qualities of the individual clusters we define the homongeneity of a clustering as the average of the homogeneity of each cluster: The homogeneity of the cluster C i is defined as the average coef-ficient of variation for the durations recorded for a certain agent and complexity class. Formally, let C ( a )( c ) i = { d C variation of C ( a )( c ) i . Then, we define the homogeneity of a cluster C as:
For the spectral clustering, the results are shown in Figure 12 where we compared the homogeneity in terms of agent X  X  perfor-mance for the algorithm that uses the combined matrix S 0 algorithm ran on the semantic similarity matrix S .
Figure 10: Differences in agent X  X  performance in resolving tickets of the same complexity from different clusters.

Figure 11: Example of agent with skill level  X  X " being slower than agent with skill level  X  X ". Figure 12: Homogeneity of different clustering methods.

We compare these two version to illustrate the homogeneity gain obtained when using the divergence matrix. This also demonstrates that topics alone are not informative enough for estimating the agent X  X  performance.

For homogeneity optimized fuzzy k-means, the coefficient of variation provided as input will reflect the homogeneity of the fi-nal clustering. The minimum values for the coefficient of variation for which no tickets are dropped, for each delivery unit, were given previously in Table 4.
As mentioned previously, the clustering and dispatching compo-nent is designed to be integrated in the IT Service Delivery Envi-ronment and a depiction of the elements the component interfaces with is shown in Figure 1. Our method succeeded in the evaluation phase, demonstrated effectiveness and we work on its deployment.
One important aspect that must be noted in deploying the dis-patcher is the handling of a new agent. A new agent is assigned a default duration for solving a ticket of a particular topic, more pre-cisely the median duration across agents for solving tasks of that topic. This way we ensure that enough tickets are sent to the new agent and therefore, the system can rapidly estimate the agent X  X  ac-tual speed.

Another aspect of the dispatching component is that since it fa-vors the best agent for each ticket category, this may potentially lead to uneven workload distribution. To avoid this, one can adjust the greedy dispatching policy to include some regularization.
The performance gaps between agents need to be continuously reduced. Apart from its utility in the automatic dispatching, our system finds execution differences among agents and can show agent training needs and best practices. It can serve in targeted mentoring for ramp-up of skills for new employees which is very useful in a high turn-over environment.
Several works have previously addressed the possibility of im-proving the efficiency of ticket routing by mining ticket resolution sequence data or ticket descriptions [23, 1]. The authors in [23] capture the ticket transfer decisions embedded in ticket resolution sequences to develop a model to generate ticket routing recom-mendations. In [1] supervised learning techniques (SVM) and a discriminative term based heuristic are used to analyze ticket de-scriptions and predict the most appropriate resolution group. While we also investigate optimal ticket routing based on ticket descrip-tions, our focus is not matching the correct resolution group for a given ticket but rather on matching the most cost effective agent to resolve the ticket within a resolution group.

Researchers have also previously looked into clustering alerts and incident tickets [16, 17] for both structured and unstructured text using either graph theoretic approaches [16] or a combination of a latent semantic indexing based technique with a hierarchical n-gram based technique [17]. We have observed that standard text similarity measures as Jaccard used by the authors in [16] perform poorly when used in clustering tasks due to data sparseness and the lack of context. We differentiate from these approaches by propos-ing a similarity metric between tickets that tries to overcome the vo-cabulary mismatch problem, by using semantic similarity between words inferred from a large corpus.

We are not aware of any previous work on ticket clustering that aims at discovering topics with high homogeneity in the agent X  X  performance. From a theoretical point of view, the problem we are trying to solve is similar to clustering with multiple graphs. Clus-tering with multiple graphs aims to fully exploit the links between different dimensions of a given network. While there is a rich body of work in the context of single graph clustering [2, 5, 12, 9, 13] the problem of clustering with multiple graphs has gained interest only recently [24, 21, 28]. In [24] the authors propose a factor-ization method based on linked matrices to solve the multi-graph clustering problem. In this model, each graph is approximated by a graph specific factor with a common factor shared by all the graphs. In [21] the authors propose two multi-graph clustering techniques (one tailored for unweighted graphs and one that performs well also on weighted graphs) with the goal of finding well-defined clusters across all the views of the graph. In [28] the authors propose a gen-eralization of normalized cut for multi-dimensional graphs. Their model leads to a mixture of Markov chains defined on the different graphs.

We want to identify clusters that persist under different mea-sures. Leskovec et al. have shown in [15] that strong communities are still identifiable under various measures. We choose to combine the adjacency matrices in one in a way such that the information in the divergence matrix is manifested in the final matrix as pairwise cannot-link constraints (constraints that express that entity i and entity j should be in different clusters). Having a single matrix, the problem becomes again a single graph clustering problem which we try to solve employing matrix factorization based clustering al-gorithms or by iteratively adjusting a fuzzy partitioning.
Work by Leskovec et al. has recently demonstrated that, al-though different quality measures produce differences in terms of specific communities, strong communities persist under a variety of measures
In this paper, we presented a novel approach that optimizes the service time in IT Service Delivery industry. We demonstrated on real data that considering empirical evidence on which agent is the most efficient on resolving certain incident tickets in the dispatch-ing process significantly reduces service time.

We first build a model able to cluster the tickets into categories that both reflect the problem they document and are homogeneous in the duration time for an agent to solve them. Then we devise a data-informed dispatching policy that assigns an incoming ticket to the agent that is the fastest in resolving it. Experiments conducted on real data from several IBM Service Delivery Units demonstrate the benefits of our approach. More specifically, we compare the data-informed dispatching with the non-data informed dispatching and observe that the former exhibits 35% to 44% reduction in the service time. [1] S. Agarwal, R. Sindhgatta, and B. Sengupta. Smartdispatch: [2] C. C. Aggarwal and H. Wang. Managing and Mining Graph [3] J. C. Bezdek. Pattern Recognition with Fuzzy Objective [4] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet [5] Y. Chen, S. Sanghavi, and H. Xu. Clustering sparse graphs. [6] R. Cilibrasi and P. Vitanyi. The google similarity distance. [7] D. Defays. An efficient algorithm for a complete link [8] R. El-Yaniv and D. Yanay. Supervised learning of semantic [9] A. Gionis, H. Mannila, and P. Tsaparas. Clustering [10] T. H. Haveliwala, A. Gionis, D. Klein, and P. Indyk. [11] L. Kaufman and P. J. Rousseeuw. Finding Groups in Data: [12] J. Kleinberg. An impossibility theorem for clustering. pages [13] H.-P. Kriegel, P. Kr X ger, and A. Zimek. Clustering [14] T. K. Landauer, P. W. Foltz, and D. Laham. An introduction [15] J. Leskovec, K. J. Lang, and M. Mahoney. Empirical [16] D. Lin, R. Raghu, V. Ramamurthy, J. Yu, R. Radhakrishnan, [17] S. Mani, K. Sankaranarayanan, V. S. Sinha, and P. Devanbu. [18] D. Metzler, S. Dumais, and C. Meek. Similarity measures for [19] R. Mihalcea, C. Corley, and C. Strapparava. Corpus-based [20] A. Y. Ng, M. I. Jordan, and Y. Weiss. On spectral clustering: [21] E. E. Papalexakis, L. Akoglu, and D. Ience. Do more views [22] G. Recchia and M. Jones. More data trumps smarter [23] Q. Shao, Y. Chen, S. Tao, X. Yan, and N. Anerousis. Efficient [24] W. Tang, Z. Lu, and I. Dhillon. Clustering with multiple [25] K. Toutanova, D. Klein, C. D. Manning, and Y. Singer. [26] P. D. Turney. Mining the web for synonyms: Pmi-ir versus [27] R. B. Wallace and W. Whitt. A staffing algorithm for call [28] D. Zhou and C. J. C. Burges. Spectral clustering and
