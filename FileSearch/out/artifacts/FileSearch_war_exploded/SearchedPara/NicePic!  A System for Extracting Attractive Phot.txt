 A large number of images are continuously uploaded to pop-ular photo sharing websites and online social communities. In this demonstration we show a novel application which au-tomatically classifies images in a live photo stream according to their attractiveness for the community, based on a num-ber of visual and textual features. The system effectively introduces an additional facet to browse and explore photo collections by highlighting the most attractive photographs and demoting the least attractive.
 H.3.5 [ Online Information Services ]: Web-based services
The rapid increase in size of online communities and the availability of large amounts of shared visual data make dis-covering relevant content a difficult task. For instance, thou-sands of new photos are uploaded to Flickr every minute making effective automatic content filtering techniques a ne-cessity.

Flickr photos are accompanied by a variety of metadata such as tags, number of views, user comments, upload date, etc. The Flickr search interface exploits the explicit and implicit ratings in the metadata to infer rankings. For in-stance, the number of views is an indicator for the popularity of a photo. Adding a photo to one X  X  favorite list is probably the most direct positive indicator of relevance assignment in Flickr, and is an explicit expression of interest in the photo.
However, for recently uploaded photos community feed-back in any form might not yet be available. Furthermore, many photos are just sparsely annotated which might pre-vent text-based search and mining methods from retrieving this potentially attractive content.

In this work we demonstrate the NicePic! 1 application, based on a web service for automatically classifying and ranking photos according to their attractiveness. We ex-ploit the vast amount of social feedback available in Flickr, to obtain a training set of photos considered as more or less attractive by the community. This allows us to build classi-fication and regression models based on multi-modal visual and textual features, and to apply them to identify new at-tractive content. In a wider system context, such techniques can be useful to enhance ranking functions for photo search [4], and, more generally, to complement mining and retrieval methods based on text, other metadata and social dimen-sions.

NicePic! allows users to explore the live flickr photo stream in an attractiveness-centered way. NicePic! shows the top photos submitted to Flickr during the last hour, day and week according to our aesthetic inference model, enabling users to rapidly see the best content uploaded to Flickr in the recent past. In addition, users can introduce query terms in the search box to get results relevant to their information needs. These results are organized into two columns, sep-arating the most attractive from the least attractive pho-tographs.
This section describes the main components of the sys-tem. The architecture is illustrated in Figure 2. Firstly, we build a training set of images with and without favorite assignments. In the second step we extract visual, and if available, textual features , from the images. We then train aSVM classifier which is used by our system for identifying potentially attractive visual content. Finally, the user can access the application from arbitrary clients , including desk-tops and mobile devices featuring web browsing capabilities. In the following we provide a brief overview of the system components and show how results are presented to the user. A fully detailed description of the underlying scientific ap-proach can be found in our work [3].
 Data. We randomly selected time periods of 20 minutes from a time span of 5 years 2005-2010. From each of the periods we selected at most 5 pictures with the highest num-ber of favorite assignments as positive example as well as the same number of photos without favorite assignments as neg-ative examples. We stopped after obtaining a set of 200 , photos from each class.
 Features. Even though aesthetic and artistic quality can-not be quantitatively computed, it has been shown that cer-tain visual features [1] of images have significant correlation with them. For instance, appealing images tend to have higher colorfulness ,increased contrast and sharpness .Tex-tual features like title and tags can also provide precise in-formation about the image quality. These correlations were described in [3] which forms the base for this demonstration. Classi fi cation. In the next step we built a classifier using the SVMlight [2] classification software and the dataset of consisting of pictures with and without favorite assignments as described in Section 2. Our quality measures were the precision-recall curves as well as the precision-recall break-even points for these curves. The break-even point (BEP) is the precision/recall value at the point where precision equals recall, which is equal to the F 1 measure and is the harmonic mean of precision and recall. The curves for the classifi-cation experiments for selected visual features described in Section 2 are presented in Figure 3. The combination of textual and visual features have shown the best applicabil-ity resulting in BEP 0.84. Classification with only visual features alone also produces promising results (BEP 0.67), and can be useful if no or insufficient textual annotations are available as is usually the case for freshly uploaded photos. Extraction of visual features is a computationally intensive process, using only textual features (if available) provides a cheaper alternative with a BEP of 0.79.
 Search. In order to create a list of images ranked by quality, we estimated the likelihood of image attractiveness using the output of the SVM classifier trained on a set of images labeled as  X  X ttractive X  or  X  X on attractive X . One of the three classifiers (textual, visual, or textual+visual) is selected for each image based on the availability of the image features. We use the Flickr API as the underlying search provider for our NicePic! service. It is possible to process the most recent uploaded pictures, a user image stream, or a selection for an arbitrary keyword.
Figure 3: P/R curves for the features and their combination. In the demonstration we will primarily show how the NicePic! search system works. The user interface of the ap-plication simply consists of a text box and a keyword search can be performed pressing the  X  X earch X  button. The differ-ence to other engines is mainly in the search result represen-tation. NicePic! divides the results into two sets: left ( X  X ost Attractive X ) and right( X  X east Attractive X ). The server in the background continuously obtains the most recent pho-tos from the Flickr stream and classifies them. The GUI also shows the top attractive and non attractive photos in the last week, 24h and 1h as selected by the classifier. Additionally the user can use the keyword search function and obtain the most/least attractive photos for a particular query, or par-ticular user. For example query X  X ecent:: X  would analyze the most recent photos (the maximum number can be selected by user) and query  X  X ser::username X  would pick only photos uploaded by a single user.

The user starts with the execution of the search. As soon as the first results are ready, they are immediately dis-played. The view with the top 20 most-attractive and least-attractive images is continuously updated until the set is classified completely. The user can move the mouse pointer over a result image and see additional information including the attractiveness value computed by the classifier. Clicking on the image opens a larger view.
 Future Work. In the future we plan to experiment with other datasets such as photos taken with mobile devices and exploit other visual features such as SURF, as well as the EXIF data.
This work was partially funded by the European Commis-sion FP7 under grant agreement No. 287704 (CUbRIK) and COST Action KEYSTONE IC1302 [1] J. S. Hare, S. Samangooei, and D. Dupplaw. Openimaj [2] T. Joachims. Making large-scale support vector [3] J. San Pedro and S. Siersdorfer. Ranking and classifying [4] J. San Pedro, T. Yeh, and N. Oliver. Leveraging user
