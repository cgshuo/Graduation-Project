 Finding proximities between objects based on graph topology is an important task in web data management. It has a wide range of applications, e.g. near-est neighbor search, image segmentation , and collaborative filtering. With the growing quantities of complex structured data, many fundamental problems have been naturally arising in graph analysis : How closely connected are two nodes in a graph? How to efficiently assess the closeness between two nodes?
To tackle these questions, recent years have witnessed growing attention to node-to-node proximities ( e.g. [5,6,4,8,10,11,9]). Among them, R andom W alk with R estart (RWR) has become a very popul ar one, which is originally patented by Tong et al. [5]. RWR is a PageRank-like node proximity based on a random surfer model. In comparison with other r elevance measures, RWR has the follow-ing two benefits [5]: (1) it can globally capture the entire topology of a graph; (2) its proximity values can be used for ra nking objects with respects to a certain query, as opposed to PageRank that is query-independent.
 Prior Approaches. However, existing methods to compute RWR are less de-sirable. To the best of our knowledge, th ere exist two noteworthy methods for RWR computation: Tong et al. [5] developed a closed form of RWR, convert-ing the computation of RWR into a matrix inversion problem, which requires O ( n 3 ) time for assessing all RWR proximities for n 2 pairs of nodes in a graph. Very recently, for top-K search, Fujiwara et al. [1] has proposed an excellent algorithm called k-dash , which can be regarded as the state-of-the-art one for computing RWR. Unfortunately, their strategy involves a large LU matrix de-composition over an entire graph, which is still time-consuming. Therefore, it is very imperative to devise novel techni ques for accelerating RWR computation. Our Contributions. In this paper, hybrid optimization techniques are pro-posed for optimizing RWR computation. Different to the framework of [1] that performs large LU decomposition on an entire graph, we utilize a novel divide-and-conquer method, with the aim to convert large LU decomposition into small triangular matrix operations on some partitioned subgraphs in a recursive man-ner. This enables a substantial improvement on the computational time of RWR. Besides, we take advantage of the sparsity of triangular matrix multiplications with a node prioritizing strategy, and apply a fast matrix multiplication algo-rithm, to further accelerate RWR computation. Finally, we conduct extensive experiments on real and synthetic datas ets to verify the high efficiency of our proposed algorithms against other baselines.
 Organization. The rest of this paper is struct ured as follows. Section 2 re-visits the related work. Section 3 over views the background of RWR. Section 4 proposes our divide-and-conquer method, k-LU-RWR , for RWR acceleration, followed by some improved strategies in S ection 4.3. Experiment results are re-ported in Section 5. Section 6 concludes the paper. RWR has been widely accepted as a useful measure of node proximity based on graph topology since the pioneering work of Tong et al. [5]. In that work, a singular vector decomposition (SVD) based algorithm, B LIN , was also proposed for computing RWR, by taking advantage of block structure of a graph. However, this method still involves an matrix inversion on very dense matrices, which is rather expensive, requiring cubic time in the number of nodes.

Later, Fujiwara et al. [1] proposed a fast top-K search based on RWR prox-imities. Their algorithm involves two strategies: first, they deployed a large LU decomposition on an entire graph for computing RWR; second, they used BFS tree estimation and devised a pruning technique to skip unnecessary scanning of nodes for top-K results. However, after LU decomposition, matrix inversions of L and U on the entire graph are still costly. In contrast, our work deploys a divide-and-conquer method to invert L and U recursively on small subgraphs, therefore achieving high computational efficiency.

Most recently, Yu et al. [7] have developed an incremental algorithm that supports link incremental updates for RWR on dynamical graphs. In comparison, our work focuses on efficient computations of RWR on static graphs. Notations. Table 1 lists the notations used throughout this paper.
 RWR Overview. The formal definition of RWR is as follows [5]: Intuitively, Equation (1) suggests that a random particle starts to walk from a given query node i , and the particle iteratively transmits to its neighbor with the transition possibility in proportion to the edge weight between them. At each step, it has a probability c to return to the original node i until it reaches a steady state. The element p i,j in vector p i refers to the probability of the particle finally stays at node j .

Based on Equation (1), we have the following closed-form of p i : The straightforward way of solving p i in Equation (1) is to adopt an iterative vector w.r.t. query node i . There are two stopping criteria for this iterative method: one is, given a threshold , to check whether the norm of the difference of two consecutive iterative RWR vectors is below , i.e. , p i ( k +1)  X  p i ( k )  X  ;the other is, given the total number of iterations K , to check whether the number of iterations increasingly reaches K . However, both of these criteria may sacrifice a little accuracy, as compared with non-itera tive methods. Therefore, in this paper our optimization techniques for RWR are based on non-iterative framework. LU Factorization. Regarding the non-iterative methods for RWR, LU decom-position is the best-known method, which is based on a closed-form of p i ,as shown in Equation (2). However, directly calculating W  X  1 requires high com-putation time as the inversion matrix could be dense even though W is sparse in most cases. To deal with this problem, we take advantage of the Crout X  X  algo-rithm [2] to do LU decomposition. Consequently, we can compute the inversions of L and U instead, namely, W  X  1 = U  X  1 L  X  1 .
 Algorithm 1. k-LU-RWR Algorithm 4.1 A Divide-and-Conquer Strategy for RWR To meet the challenges raised by RWR, we propose an algorithm named k-LU-RWR shown in Algorithm 1. In consideration of Equation (2), we pre-compute and store W  X  1 offline which is from step 1 to step 4 in the algorithm. When a query node i comes, we simply calculate the proximities p i online by only two multiplication operations of matrix-vector according to step 5.
Now let us concentrate on step 3 and step 4. As we have decided in Section 3, we take advantage of LU decomposition on W . However, directly utilizing LU decomposition still requires to co mpute inversion matrices for both L and U ,so we apply following optimization strategies. We partition L and U into four parts, as presented in Figure 1. After that, we compute the matrix inversions of L and U according to Equation (3). Specifically, we do matrix inversions on L 1 , 1 , L 2 , 2 , U 1 , 1 and U 2 , 2 , referred to as triangle inversion , and matrix multiplications on L 2 , 1 , U 1 , 2 part, referred to as rectangle multiplication . When finished, we merge the block matrices into L  X  1 and U  X  1 .

From Figure 1, it is clear that L 1 , 1 , L 2 , 2 remain to be lower triangular matri-ces, and U 1 , 1 , U 1 , 2 remain to be upper triangular matrices. This inspires us to do the partition and inversion procedures recursively, as represented in Figure 2. So we further devise a recursive algorithm recInvLU in Algorithm 2 to calculate triangle matrix inversions in step 3 and step 4 of Algorithm 1. 4.2 Time Complexity of k-LU-RWR In the pre-computation stage, i.e. step 1 to step 4, the main time cost includes LU decomposition and matrix inversion. In LU decomposition part, we adopt Algorithm 2. recInvLU( M , n , k ) Crout X  X  algorithm, whose theoretical time complexity is O ( n 3 ). Similarly, in the inversion part, if we inverse L and U directly, the time complexity is O ( n 3 )too. However, we applied partitioning strategy and the time complexity is given by Equation (4), where T ( MM ( n 2 )) represents the cost of rectangle multiplication part in Algorithm 2.
 In the query stage, we simply do two multiplications of matrix-vector. For this reason, the query response is nearly real-time. 4.3 Further Improvement of k-LU-RWR From Equation (4), we know that the time of RWR mainly depends on the matrix multiplications. A straightforward implementation of the matrix multiplications needs cubic time in the number of nodes. We now introduce two enhanced ver-sions for accelerating the matrix multip lications: (1) We can a dopt sparse matrix storage data structure. Since the adjacency matrix A is often sparse, we can use the reordering strategy [1] to keep the s parsity of LU decomposition. This re-ordering strategy has a good performance in practice. However, when matrices are becoming dense, the w orst case time is still O ( n 3 ). (2) We can also ap-ply Strassen X  X  algorithm [3] to reduce the time of the matrix multiplications to O ( n log 2 7 ). Combining these two methods together, it requires O ( n log 2 7 ) time in total for computing RWR, while eliminating unnecessary multiplications by filtering zero entries. 5.1 Experiments Settings We set the restart probability c =0 . 9, as previously used in [5].

We conduct a set of experiments on the value of partition times k ,tosee how it effects on the experiment performance. To verify the effect of the reorder strategy, we also do experiments on k-LU-RWR without reorder procedure called Un-LU-RWR , compared with k-LU-RWR . The ratio of the number of nonzero entries in L  X  1 and U  X  1 to the edges in matrices is introduced to indicate the time and storage costs we preserve. Moreover, the proposed algorithm is compared with NB LIN [5] and k-dash [1] in terms of pre-computation time to show the efficiency of our a lgorithm. In k-dash , we compute proximities of top-n nodes for fair comparison. Besides, we do experiments to show the high response time on queries of k-LU-RWR .

We use real and synthetic datasets. All experiments were conducted on the machine with 2.5GHz CPU and 4.00GB main memory. Our algorithms are im-plemented in C++. The details of datasets are listed in Table 2.
 5.2 Experiment Results We first conduct experiments on how the value of k influences on the efficiency of k-LU-RWR . The results are shown in Figure 3. When k varies from 0 to 10, we see the time costs decrease gradually on both real datasets and synthetic datasets. For the case k = 0, we directly calculate the inversions of L and U without partition technique. When k increases, the falling speeds differ on each dataset due to the different architectur es, but the performance changes little when k grows to a certain degree. When k = 10, it preserves about 50% pre-computation cost with regard to k =0.

To demonstrate the sparsity of matrices after applying Reorder strategy, we show the ratio of non-zero element numbers to matrix edges in Figure 4. From the figure, we can see almost 70% storage costs are saved by reordering the ele-ments. It also indicates the storages and computation costs we saved by adopting Reorder strategy and sparse storage.
 We compare pre-computation costs between k-LU-RWR , NB LIN and k-dash . The results on real datasets are shown in Figure 5 and the results on synthetic datasets are shown in Figure 6. Figure 5 demonstrates that our algorithm pre-serves about 50% pre-computation w.r.t NB LIN and about 70% pre-computation w.r.t k-dash . Figure 6 shows our algorithm saves over 50% pre-computation cost w.r.t NB LIN and k-dash . There are mainly two reasons for the enhancements: (1) our algorithm adopts the idea of divide and conquer and takes advantage of a sparse manner so that it skips unnecessary calculations by ignoring zero entries; (2) by utilizing a fast matrix multiplication algorithm Strassen X  X  Algorithm we saved one multiplication operation in each iteration by partitioning k times and reduce the time complexity.

We also do experiments to verify the efficiency of the query stage, in which we perform two matrix-vector multiplications. The query time on each datasets is a few hundred milliseconds, as expected. This paper addressed the problem of efficiently computing RWR proximities based on graph topology. We first devised a divide-and-conquer paradigm to re-cursively do LU factorization over small subgraphs. Then, by taking advantage of sparsity of triangular matrix stru cture, we further accelerated RWR compu-tation via fast matrix multiplication. Finally, we conducted extensive empirical results using real and synthetic dataset, showing the superiority of our proposed algorithm against the baselines in terms of computational time.
 Acknowledgement. The work is supported by NSFC61232006,NSFC61021004.
