 In this paper we study three basic and key issues related to Web query processing: load balance, broker behavior, and performance by individual index servers. Our study, while preliminary, does reveal interesting tradeo s: (1) load un-balance at low query arrival rates can be controlled with a simple measure of randomizing the distribution of doc-uments among the index servers, (2) the broker is not a bottleneck, and (3) disk utilization is higher than CPU uti-lization.
 Categories and Subject Descriptors: H.3.4 Informa-tion Storage and Retrieval : Systems and Software -dis-tributed systems, performance evaluation ; H.3.5 Online In-formation Services -Web-based services General Terms: Performance, design.
 Keywords: Distributed query processing, search engines, load balance.
When a user query reaches a search engine, its processing is broken down into two phases. The rst phase consists of taking the query terms, extracting from the disks informa-tion on documents that contain each query term, executing a conjunction of the sets of documents that contain each query term, and nally ranking the selected documents. The second phase consists typically of taking the top 10 ranked answers and generating snippets, title, and URL information for each of them.

In this work, we concentrate our attention on the rst phase of the query processing task, studying three basic is-sues that a ect the internal operation and ne tuning of the cluster of servers where the indexes are stored.

Search engines use a cluster of servers as platform for query processing [1, 4]. Typically, in this network there are two types of machines: a single broker and p index servers. The whole collection of documents is evenly parti-tioned among the index servers, such that each server stores its own local subcollection with approximated size (in bytes). This type of index organization, here referred to as a local index organization [3], is the standard \the facto" in all ma-jor search engines.
 A user query reaches the broker through a client machine. The broker then broadcasts the query to all index servers. Each index server searches its own local index and produces a partial ranked answer. These partial ranked answers are collected by the broker and combined through an in-memory merging operation. The nal list of ranked documents is then sent back to the client machine.

An inverted le is adopted as the indexing structure for each subcollection. To rank documents, the index server reads from disk the inverted lists relative to query terms, intersect the lists to produce the set of documents that con-tain all query terms, and compute a relevance score for each document. The relevance score is computed in function of the relative frequencies of occurrence of terms within doc-uments and anchor texts, the authoritative degree of docu-ments [2], URL and title information of documents, and the proximity of query terms within documents.

For the experiments reported in this work we use a cluster of 8 index servers. The test collection is composed of Web pages collected by the TodoBR [5] search engine from the Brazilian Web in 2003. Each index server holds a subcol-lection of 10 million pages. The index for each subcollec-tion occupies roughly 16 gigabytes. The queries are a set of 10,000 unique queries submitted to the TodoBR search engine in January of 2003.
To reduce load unbalance among index servers we opt for balancing the distributions of the sizes of the inverted lists that compose the local inverted les. (stored locally at the index servers). This can be accomplished by a random dis-tribution of documen ts among index serv ers, whic h natu-rally spreads documen ts of various sizes across the cluster. As a result, the distributions of documen t sizes in the index serv ers become similar in shap e, whic h re ects in inverted lists whose size distributions are also similar.

First, we programmed the clien t to submit queries one at a time, for evaluating local pro cessing times indep enden tly of interference among the various pro cessing threads at in-dex serv ers. Figure 1 illustrates the distributions of average, maxim um, and minim um local pro cessing times per query . Average time for a query q is computed as the average time among all 8 local pro cessing times. The time interv al sur-rounding average times have limits given by the slowest and the fastest index serv er for that query .
We notice that load unbalance is con trolled when queries are submitted sequen tially . Second, we programmed the clien t to submit queries at an average rate of r queries per second. We vary r until the cluster saturates. We notice that at high arriv al rates, variance of local pro cessing times quic kly increases limiting scalabilit y of cluster throughput. That is, randomizing the distribution of documen ts among serv ers does not help at high query arriv al rates. This clearly suggests that adding a mo dule of dynamic load balance to a cluster of serv ers (of a searc h engine) migh t be an e ectiv e measure to impro ve throughput at high arriv al rates.
In this cluster architecture, the brok er constitutes a po-ten tial bottlenec k. To stress the brok er and observ e how it beha ves, we implemen ted a concurren t pro cess monitor that sim ulates a cluster with p index serv ers. The brok er tak es queries at an arriv al rate r (whic h we varied) and passes them to a single mac hine that runs our concurren t monitor. For eac h query , the brok er sends p requests to our monitor, one for eac h index serv er. For eac h request it receiv es, the monitor sim ulates a local query pro cessing task.
We observ e that even at high loads and with a large num-ber of serv ers, time at the brok er is not a ected. In fact, with 256 serv ers and query arriv al rates around 100 queries per second, average time at the brok er per query is less than 10 milliseconds. That is, the brok er is not a bottlenec k in our architecture. This is because all the tasks the brok er executes are simple tasks that do not tak e much CPU time and carried out fully in main memory .
For examining how local pro cessing time is split among disk and CPU at index serv ers, we again submitted the queries to the serv ers one at a time. Figure 2 illustrates average local pro cessing time, average disk access time, and average CPU execution time (in seconds). We observ e that disk times are remark ably dominan t.
We have studied three basic and key issues related to the internal operation and ne tuning of a cluster of index serv ers for searc h engines: load balance, brok er beha vior, and CPU and disk times at individual index serv ers. Load unbalance among index serv ers can be con trolled by ran-domizing the distribution of the documen ts of the collection among the serv ers. This works well at low arriv al rates, but is not e ectiv e at high arriv al rates. The brok er is not a bottlenec k in a shared-nothing architecture of indep enden t index serv ers. Disk times dominate local pro cessing times. This work was supp orted by the GERINDO pro ject{gran t MCT/CNPq/CT-INF O 552.087/02-5, by CNPq scholarship 140262/2001-6 (Claudine Badue), by CNPq gran t 520.916/94-8 (Nivio Ziviani) and by CNPq gran t 30.0188/95-1 (Berthier Rib eiro-Neto).
