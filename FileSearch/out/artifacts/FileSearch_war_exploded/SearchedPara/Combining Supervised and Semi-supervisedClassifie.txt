 For most email users, email filtering s eems to be an effective way to block spam. Traditional spam filters use rule-based techniques that discriminate spam from normal emails. This approach uses a combination of spammers X  email addresses, IP addresses, header information, keywords of the subject line, and even the keywords in email contents to formulate the rules that identify spam emails. Machine learning, e.g. Bayesian learning [1], is another common approach to filter spam. Instead of specifying a set of rules explicitly, this approach uses a set of classified documents, including both spam and normal emails, to learn the rules implicitly. Sometime, domain specific properties, such as the presence of  X !!!! X  or  X  X e over 21 X  are cooperated to make the filter more accurate. Recently, support vector machine (SVM) [4,5] is also a very popular technique in filtering emails. It works well even under high dimensional input space and sparse attributes. Combination of both approaches is now becoming popular, e.g. SpamAssassin [2].
With modern machine learning techniques, it is not difficult to achieve high accuracy in spam filtering. For example, Tretyakov [3] reported their simple SVM and multi-layer perceptron [6] had false positive and false negative values below 5%. These good results however require a working condition that the training data and the testing data are drawn randomly from the same source as most learning paradigms assume that all the data is drawn under the iid (independent and identical distribution) condition. Fig. 1a shows the hyperplane H1 separating all the training patterns correctly can perform badly (see Fig. 1b) if the testing patterns have different distribution, in which H2 should be the correct separating hyperplane. To tra in a personalized spam filter for a user, both labeled spam and legitimate emails, getting from the same user X  X  email inbox, are required. However, due to the privacy reason, it is difficult to get emails from the user. Even the user provides his emails, labeling them manually is a very costly and time consuming task. Without labeled emails from the user, the performance of a spam filter will be downgraded drastically. A spam filter test running on a dataset [7] shows that the accuracy drops from over 90% to about 78% when training are based on public domain email dataset only and no user X  X  labeled emails are provided. The is due to the discrepancy between the word distributions of emails from public domain and that of the users X  inbox.
In this paper, a combined SVM and semi-supervised classifier is proposed to label a user X  X  emails. Firstly a SVM is trained with labeled public domain emails and it is used to classify a user X  X  emails. The discrepancy between them and user X  X  emails is modeled as variation of decision hyperplane and  X  X eliable labeled emails X  with classified labels which are likely to be agreed by the user are selected. A semi-supervised classifier [ 8] then uses these emails as the training set and propagates the label information to other unlabeled emails by exploiting the distribution of them in feature space. Throughout this paper, ranking of emails by classifier output values is used to indicate their likelihood to be spam, rather than using simple binary labeling, e.g. { -1,1 } , unless specified otherwise. An email with higher classifier output value is ranked higher and it is more probable to be spam. The classification is evaluated with Area under the ROC curve (AUC) metric [9]. In this case it can be regarded as the Wilcoxon-Mann-Whitney (WMW) statistic [10] given as: where p is the number of spam emails and n is the number of legitimate emails, x i and y j represent a spam and a legitimate email respectively. The function f is a classifier which assigns a score to x i and y j for ranking. A view of the AUC value with this setting is the probability of spam email having higher ranking than a legitimate email.

The remainder of this paper is organized as follows. Section 2 discusses the classification of user X  X  emails using SVM. Modeling of different users X  email distri-butions and the criterion for selecting  X  X eliable labeled emails X  is also proposed. Section 3 presents the using of the semi-supervised learning algorithm to propa-gates the label information to unlabeled emails. Section 4 su mmarizes the testing results. Finally, a conclusion is given in Section 5. Support Vector Machine (SVM) [4,5] is a very popular classifying tool in recent years. SVM employs kernel function to map the input data into some much higher dimensional feature space implicitly in which data becomes linearly separable. The linear decision boundary is drawn in a manner that the margin, minimum distance between training examples and the boundary, is maximized. In case that the mapped data points are non-linearly separable, a cost is included to account for the wrongly classified examples and the margin is maximized while the cost is minimized. For spam filtering, linear kernels are found to have good performance and thus they are used in our study.

If we form a SVM with labeled public domain emails as the training dataset and classify a person X  X  email, the classifier may not give accurate result because a considerable number of emails are classified wrongly due to the distribution difference as described in Section 1. Fig. 2 gives another example on the situation in a highly simplified two-dimensional plane. Referring to Fig. 2, points far away from the decision line H 1 is less likely to be affected when the decision line is changed from H 1to H 2. In fact, under certain conditions, the class label of these points is preserved. Consider a SVM classification in N dimensional feature space with decision hyperplane H 1 which can be represented by where W is the normal vector of the hyperplane and W denotes its transpose. The distance d 1 between a point X  X  R N (assume data normalized in feature space, i.e. X = 1) and the hyperplane is If the decision hyperplane of the SVM is changed to H 2, the new distance is Without loss of generality, we assume W X + b&gt; 0, then Label of X will not be changed if or, under the more strict condition, Thus, class label of data points having the distance greater than (  X W + |  X b | ) / W to H1 will be preserved even the decision hyperplane is switched to H2. These data points are called  X  X eliable X  data points in the sequel. Practically, it is hard to identify reliable data points or even their existence because  X W and |  X b | are not known. The above formulation, however, points out class labels of data points are likely to be preserved if they are far from the original decision hyperplane.

As a result, if a person X  X  emails having distribution not too different from the counterparts of the public domain, these discrepancies can be modeled as changing of decision hyperplane. Then a SVM can be trained with public domain emails and classify the person X  X  emails. Classified personal emails far from the decision hyperplane can be selected as tr aining data for other classifiers or next stage classification because they are likely to be reliable data points. { x ability to the unlabeled emails such that a cost function is minimized. Let w ij represents the similarity between x i and x j . Then a graph where nodes represent x j can be created. Similarity is often evaluated with radial basis function or cosine similarity In this graph, the label of x i can propagate through edges to another node x j according to a transition probability and the transition of the whole graph can be represented by the ( l + u  X  l + u ) dimension matrix P . Define a label matrix Y with dimension ( l + u  X  2), whose i th row has two elements having values between 0.0 and 1.0. The first element indicates the probability that the i th email is a legitimate email and the second this configuration, the class probability of unlabeled emails can be computed, by using the label propagation algorithm [8] given as follows. 1. Initialize the label matrix Y 2. Update Y by Computing Y n +1 = PY n . 3. Clamp the labels of labeled node to its original values. 4. Repeat 2, and 3 until Y n converge. This algorithm propagates the values of lab eled nodes to class boundaries accord-ing to the distribution of the unlabeled emails. The convergence of the algorithm is guaranteed if the graph is connected. I n addition, the convergence to trivial casessuchasall y i, 1 =0 . 0 are avoided because there are both labeled spam and legitimate emails. Thetestingdatasetin[7]areusedinevalu ating the combined classifier strategy. In this dataset, there are 4,000 labeled emails coming from public domain and they are used as the training data. Three sets of unlabeled data, each contain-ing 2,500 emails from three different users X  email inboxes, are also provided for testing. Ground true of the emails are given for evaluation. It should be noted that the email distributions of public domain is different from that coming from individual users X  inboxes. Direct usage of training data to train a classifier and to classify unlabeled emails will give unsatisfactory results. The goal is to rank the emails for each user such that spam emails should have higher ranking than legitimate emails. The correctness of ranking is measured with AUC value. It has maximum value 1.0 representing the perfect case that all spam emails are ranked higher than legitimate emails. In this dataset, there are also two additional sets of data,  X  X  X  and  X  X  X  but they are not used in the test. Table 1 summarizes the properties of the dataset.

A SVM is first trained with Dataset  X  X  X  and then it is used to classify Dataset  X  X  X , X  X  X , X  X  X  with the distance of each email to the decision hyperplane is then evaluated. As described in Section 2, emails that far from the hyperplane are likely to be  X  X eliable data point X . A number of classified emails farthest from the hyperplane are selected forming the traini ng set of a semi-supervised classifier. Ranking of emails are obtained from the output of the classifier. Finally, AUC of the ranking is evaluated. The testing result is given in Table 2. Referring to this table, it is clear that the proposed approach performs much better than SVM or SVM1. Cases with different number of emails which are far from the hyperplane are tested and the result shows that the proposed approach is quite stable to the variation of this number. Finally, it is worth noting that in Table 2 the AUC value drops as the number of  X  X eliable data point X  is over 300. It is because the additional selected  X  X eliable data point X  is no longer  X  X eliable X . However, the AUC for User 2 is still very high because its email distribution is a bit similar to that of the public domain.
 Spam or junk emails, are very annoying to email users and filtering is one of the ways to block spam. However, tuning a spam filter for individual user is costly and time consuming and sometimes impractical because of privacy reason. This paper proposes a combined supervis ed and semi-supervised classifier that helps the labeling/ranking of user X  X  emails. As the distribution of public domain emails is different from that of emails of individual user, classical supervised classifiers such as SVM or na  X   X ve Bayes classifier do not gives satisfactory results. We model the discrepancy of distribution by variation of decision hyperplanes and come up with a criterion selecting some  X  X eliable X  SVM classified emails as training examples for next stage classific ation. A semi-supervised classifier using these examples together with exploiting user X  X  email distribution to classify the unlabeled emails. Interestingly, this s imple approach can classify user X  X  emails with a high accuracy, in AUC metric. Of course, the war between spammers and anti-spammers is not over. Some spammers are now using hyperlinks to divert people to their websites or even put their messages in image format so that they cannot be detected easily.

