 knowledge gained from previously solved, related problems to solve new problems quicker. Transfer speed up learning of new ones.
 becomes difficult to answer questions such as how much inform ation to transfer between tasks and when not to transfer information. the existence of these functions, the authors are able to der ive PAC sample complexity bounds for complexity (see below) determines the relatedness between tasks. However, the bounds hold only for  X  8192 tasks (Theorem 3).
 using conditional Kolmogorov complexity of the hypothesis. We describe the ba sics of the theory (details in [ 6; 7 ] ). We then perform experiments to show the effectiveness of t his method. ensemble of objects with respect to a distribution over the ensemble. The conditional Kolmogorov h relatedness for performing sequential transfer learning i n the Bayesian setting. in Bayesian decision trees by using a fairly simple approxim ation to the 2  X  K ( | ) prior. In the rest of the paper we proceed as follows. In section 3 we d efine Kolmogorov complexity more then describe our Kolmogorov complexity based Bayesian tra nsfer learning method. In section 4 we describe our method for approximation of the above using B ayesian decision trees, and then in section 5 we describe 12 transfer experiments using 8 standard databases from the UCI machine also makes it difficult to compare our method to other existin g methods (see also section 6). We consider Bayesian transfer learning for finite input spac es I assume finite hypothesis spaces H conditioned on elements of I being y given input x . Given D of
D n according to h  X  H i is given by: The conditional probability of a new sample ( x measure (e.g. h  X  H So the learning problem is: given a training sample D assumed to have been chosen according a h  X  H the label of the new sample x Machine learning setting (e.g. [ 10 ] ).
 We use MCMC simulations in a computer to sample for our Bayesi an learners, and so considering setting (see section 6). We further assume that each h  X  H program, we will write p ( x ) to denote U ( p, x ) , i.e. running program p on input x . 3.1 Kolmogorov Complexity based Task Relatedness A program is a bit string, and a measure of absolute constructive information that a bit string x contains about another bit string y is given by the conditional Kolmogorov complexity of x given y program h  X  contains about constructing another hypothesis h is also given by the same: Definition 1. The conditional Kolmogorov complexity of h  X  H length of the shortest program that given the program h  X  as input, outputs the program h . to accuracy  X  &lt; 2  X  n in finite time. Now assume that f ( x, y ) satisfies for each y P Then for a constant c of shortest program computing f , and some small constant ( O (1) ) [ 5, Corollary 4.3.1 ] : 3.2 Bayesian Convergence Results A Bayes mixture M ated by a h Then the following impressive result holds true for each ( x, y )  X  I So for finite  X  ln W ( h h 12 ] . In essence these results hold as long as H with infinite resources. These results also hold if h KL divergence between h f ( x, y ) in ( 3.1). So by ( 3.3), with y = the empty string, we get: By ( 3.3), this means that for all h  X  H ( = O (1) ), c W = O (1) and this prior is universally optimal [ 11, section 5.3 ] . 3.3 Bayesian Transfer Learning Assume we have previously observed/learned m  X  1 tasks, with task t be learned is in H scheme corresponds to a computable prior W ( | t ) over the space H In this case, by ( 3.3), the error bound of the transfer learni ng scheme M is For M So for a reasonable computable transfer learning scheme M error bound for M ( 3.4) the transfer learning scheme M the transfer prior W ( | t ) because the inequality ( 3.4) now holds only upto the constan t c the transfer learning prior 2  X  K ( h | t ) . to approximate K and hence M how to sample from the approximation of M 4.1 Decision Trees We will consider standard binary decision trees as our hypot heses. Each hypothesis space H sists of decision trees for I C is a vector of size |O of the form f &lt; v , where f  X  f only when the corresponding node has one or more  X  children. The size of each tree is N c pointers, and C . Since c constants independent of the tree, we define the length of a tr ee as l ( h ) := N . 4.2 Approximating K and the Prior 2  X  K ( | t ) Approximation for a single previously learned tree: We will approximate K ( | ) using a function that is defined for a single previously learned tree as follow s: where d ( h, h  X  ) is the maximum number of overlapping nodes starting from the root nodes: In the single task case, the prior is just 2  X  l ( h ) /Z generator). Then at each step we select a hole uniformly at ra ndom and then create a node there (with two more holes) and generate the corresponding rule ra ndomly. We do so until we get a tree It can be seen with a little thought that these procedures sam ple from the respective priors. Approximation for multiple previously learned trees: We define C ing of the contributions of each of the m  X  1 previously learned trees: In the transfer learning case, we need to sample according 2  X  C m ld ( | ) /Z The transfer learning mixture: The approximation of the transfer learning mixture M So by ( 3.3), the error bound for P that is same for all h  X  H that C m make larger trees more likely and hence speed up convergence of MCMC sampling. 4.3 Approximating P As in standard Bayesian MCMC methods, the idea will be to draw N samples h rior, P ( h | D Then we will approximate P We will use the standard Metropolis-Hastings algorithm to s ample from P some J = T , to get the Markov chain q  X  A to converge, and then starting from the last h the run, the algorithm is run again for J = N times to get N samples for  X  P we set T to 1000 and N = 50 . We set q to our prior 2  X  C m ld ( | t ) /Z probability A is reduced to min { 1 , h ( D according to q , we set the C entries using the training sample D show transfer of information we used 20% of the data for a task as the training sample, but also used as prior knowledge trees learned on another task using 80% of the data as training sample. knowledge our transfer experiments are the most general per formed so far, in the sense that the databases information is transferred between have semanti c relationship that is often tenuous. We performed 3 sets of experiments. In the first set we learned each classifie r using 80% of the data as training sample and 20% as testing sample (since it is a Bayesian method, we did not us e reasonably powerful and that any improvement in performanc e in the transfer experiments (set 3) worse than these for German Credit .
 of the database as training sample, and 80% of the data as the testing sample. This was done to database split.
 As can be seen from comparing the tables, in most cases transf er of information improves the per-for mushroom and bc-wisc did not move up to 80 / 20 levels, there was improvement. Interestingly idealized setting.
 Table 3: Results of 12 transfer experiments. Transfer To and From rows gives databases information PI gives percentage improvement in performance due to transfe r. With our admittedly inefficient code, each experiment took between 15  X  60 seconds on a 2 . 4 GHz laptop with 512 MB RAM. compressor [ 8 ] 3 .
 lem of cross-domain transfer, where we transfer informatio n between tasks that are defined over of course, a way to measure constructive similarity between the hypotheses, and hence an approx-imation to Kolmogorov complexity based similarity. So Kolm ogorov complexity elegantly unifies practical approximations such as [ 8 ] and this paper suggests that we can get good performance by just using generalized compressors, such as gzip, etc., to m easure similarity. Acknowledgments We would like to thank Kiran Lakkaraju for their comments and Samarth Swarup for many fruitful disucssions.
 References
