 There is a growing wealth of data describing networks of var-ious types, including social networks, physical networks such as transportation or communication networks, and biologi-cal networks. At the same time, there is a growing interest in analyzing these networks, in order to uncover general laws that govern their structure and evolution, and patterns and predictive models to develop better policies and practices. However, a fundamental challenge in dealing with this newly available observational data describing networks is that the data is often of dubious quality  X  it is noisy and incom-plete  X  and before any analysis method can be applied, the data must be cleaned, and missing information inferred. In this paper, we introduce the notion of graph identification , which explicitly models the inference of a  X  X leaned X  output network from a noisy input graph. It is this output net-work that is appropriate for further analysis. We present an illustrative example and use the example to explore the types of inferences involved in graph identification, as well as the challenges and issues involved in combining those in-ferences. We then present a simple, general approach to combining the inferences in graph identification and exper-imentally show the utility of our combined approach and how the performance of graph identification is sensitive to the inter-dependencies among these inferences.
 E.1 [ Data ]: Graphs and networks; G.2.2 [ Discrete Math-ematics ]: Graph Theory X  graph algorithms Algorithms data mining, statistical relational learning, social networks, classification, entity resolution, link prediction Data describing networks of various types, including social networks (e.g., friendship networks, affiliation networks), physical networks (e.g., transportation networks, computer networks), and biological networks (e.g., protein interaction networks, transcriptional regulatory networks) are increas-ingly becoming available. At the same time, there is a grow-ing interest in analyzing these networks, in order to uncover general laws that govern their structure and evolution, and patterns and predictive models to develop better policies and practices. However, a fundamental challenge in dealing with this newly available observational data describing net-works is that the data is often of dubious quality. Methods to directly acquire accurate and complete networks, if even possible, are often prohibitively expensive. Thus, more often data is gathered from indirect sources or high throughput experimental methods. This results in networks that are noisy and incomplete. If analysis is done directly on these networks it is likely to be biased and lead to faulty conclu-sions. Before any analysis method can be applied, the data must be cleaned, and missing information inferred. It is this output network that is appropriate for further analysis. In this paper, we introduce the notion of graph identification , which explicitly models the inference of a  X  X leaned X  output network from a noisy input graph. In section 2, we present an illustrative example and use the example to explore the types of inferences involved in graph identification, as well as the challenges and issues involved in combining those in-ferences, in section 3. We then present a simple, general ap-proach to combining the inferences for graph identification in section 4. We propose a novel synthetic data generator to evaluate this approach in section 5 and experimentally show how the performance of graph identification is sensitive to the inter-dependencies among these inferences. We present related work in section 6 and discuss our conclusions and future work in section 7. Suppose we wish to understand and analyze the social net-work of a large organization. Specifically, we wish to explore the network which identifies the individuals in the organiza-tion, the close friendships between those individuals, and the roles of the individuals. For large organizations, it may be very difficult, if possible, to gather such a network directly. What may instead be available for such an organization are the archived email communications. Using these communi-cations, we can construct a communication network where nodes represent email addresses, edges represent a communi-cation between the email addresses, and attributes for these nodes and edges may include traffic statistics (e.g., frequency of communications) and content (e.g., presence of a word or phrase in an email). This available network, however, is noisy and incomplete for our analysis. To illustrate, con-communication network. sider the small example networks shown in Figure 1. The nodes in the communication network do not accurately re-flect the individuals in the organization. If we perform anal-ysis, substituting email address nodes for people nodes, even a simple statistic, like the number of individuals, would be inflated by the fact that people have multiple email ad-dresses (i.e., mary@example.com and mtaylor@example.com both belong to Mary Taylor). Moreover, the communica-tion network links are not the same as the social relation-ships between individuals (i.e., email communications exist between robert@example.com and mjones@example.com al-though their users, Robert Lee and Mary Jones, are not close friends) nor the attributes for our analysis (i.e., the email addresses are not explicitly annotated with roles). Although the communication network is not directly appropriate for our task, we can use the information in the communication network to infer the social network that we would like to analyze. This requires identifying the people and the corre-spondence of email addresses to people (these may be email addresses which have similar writing and communication patterns), friends (who are likely to email each other regard-ing social events), and their roles (reflected in the content of communications and/or with whom they communicate). We refer to this process, from the available noisy network to the network appropriate for our analysis as graph identification . Graph identification involves identifying the output graph from a given input graph, and involves constructing the mapping from the input to the output graph. The output graph ( G O ) is the graph that is appropriate for further anal-ysis. Ideally, the output graph can be acquired directly. In most cases, however, the output would be too difficult or expensive to directly acquire. What may be available, in-stead, is another graph which reflects the output graph but is too noisy and incomplete to directly use for our analysis. We refer to this available graph as the input graph ( G Given these graphs, we define graph identification as the general problem of inferring the desired output graph given a noisy input graph. The process of doing graph identifica-tion results in a mapping from elements (i.e., nodes, edges, and/or attributes) of the input graph to nodes in the output graph, the identification, or prediction, of edges that exist in the output graph, and mapping attributes of the nodes and edges in the output graph to values.
 By its nature, graph identification is domain dependent. The specific inferences needed to perform graph identifica-tion will vary based on what the input and output graphs are and how the those graphs are related. In the scenario presented in section 2, for example, we are interested in the friendship network of individuals in a company as our out-put graph while our available input graph is the company X  X  email communication network. We know, given our domain, that the mapping from the elements of the input graph to the nodes of the output graph is a many-to-one mapping from the email address nodes of the communication graph to the person nodes of the social network. Specifically, all in-dividuals in our social network likely own at least one email address in the communication network and are likely to have multiple. Thus, we can identify the set of person nodes by mapping all email address nodes, which belong to the same person, to a single person node in the output graph. The problem of creating this type of mapping is commonly re-ferred to as entity resolution [1]. Once we define the map-ping between the nodes of the input and output graph, we can identify the set of edges that exist between the nodes of the output graph. In our domain, we can use the do-main knowledge that people who are friends likely email each other, likely have similar attributes (e.g., interests) and likely communicate using terms common to that type of re-lationship (e.g., invitations to social events). We can thus use this knowledge to construct an edge prediction function for friendship edges which we can then apply over all peo-ple nodes in the output graph. The problem of defining (or learning) this existence function is commonly referred to as link prediction [10]. Finally, we know that individuals who fill a particular role are likely to discuss their role in their communications. We also know that social networks are of-ten homophilic such that individuals who fill the same role are likely to be friends. We can use this knowledge to define a mapping for the attribute value of a person X  X  role. The problem of predicting the values of these types of attributes is commonly referred to as collective classification [13]. Con-sequently, in our example in section 2, graph identification is performed by the application of entity resolution, link pre-diction, and collective classification over the input graph. Although the specific inferences in graph identification is do-main dependent, at its core graph identification is still the problem of performing three general inferences: the node mapping, edge existence function, and attribute value map-ping. An important aspect of graph identification is how these three inferences should be applied and how they inter-act. One method for doing graph identification involves ap-plying a collection of local predictors for the three inferences (e.g., applying entity resolution ( ER ), link prediction ( LP ), and collective classification ( CC ) models). Another method for doing graph identification involves defining a joint model, and extracting the output graph with the most likely con-figuration. For the rest of this paper, we will explore the former method. We will examine a simple, general way the local predictors can be combined, discuss issues involved us-ing this method of combination, and show, in general, how inter-dependent these inferences are. One method to perform graph identification is to apply a collection of local predictors. The benefit of this method is that we can use any previously defined models for each of the individual predictors. For our scenario in section 2, for example, this method allows us to apply a previously learned local entity resolution, link prediction, and collec-tive classification models. When applying local predictors, however, we have to address the additional challenge of how to combine these predictors. First, we need to consider what order the predictors are applied. This is important for any approaches which focus on a single pass, sequential applica-tion of the predictors. In these approaches, order defines the set of previous predictions a predictor can use for its infer-ence. In our motivating example, in particular, application of link prediction prior to collective classification provides the collective classification models predicted links to define relational features. Conversely, application of collective clas-sification prior to link prediction allows the link prediction to use the labels of incident nodes in its features. Another issue to consider is when and how the predictions should be committed and information shared between the predictors. Predictions can be applied all at once or be applied iter-atively. Since our predictors are strongly inter-dependent it may be beneficial to perform each task partially and ex-change information more frequently. We may also want to vary how much information is shared between predictors. Committing only the most likely predictions at each itera-tion[12] may mitigate the propagation of incorrect informa-tion between the predictors. Predictions can also be shared as hard or soft predictions. Depending on the predictors used for each inference, there may be information about the probability or confidence of the predictions that maybe use-ful to share among the predictors. Graph identification also provides challenges in that there are two graphs whose in-formation we can use in our predictors. When predicting over the nodes of the output graph, we not only have the attributes and edges of the output graph to use, we also have the additional information provided by the parts of the input graph mapped to those nodes. For example, the words used in email communications of a subset of email addresses may be used to infer the label of the person they belong to. We need to figure out how best to combine and exploit the information in both graphs during both learning and inference. Finally, we need to consider constraints be-tween the predictions. In our motivating example, we can have constraints like all friends must have shared email com-munications or that individuals with a certain role must be friends. We must consider how and when to enforce these constraints in the final output graph.
 In this paper, we present and analyze the most direct way of applying these inferences, in a pipeline [17]. In the pipeline approach , we apply the predictors one at a time and in se-quence where all predictions are committed as hard predic-tions at the end of each turn and are available for use in the next predictor in the pipeline. Referring to the example in section 2, this means applying entity resolution, link pre-diction, and a collective classification in turn, as defined in section 4.1. Let G I ( V I , E I ) represent the input graph, and G O ( V represent the output graph where V I and V O are the sets of nodes and E I and E O are the sets of edges for the cor-responding graphs. For all input graph nodes, v I  X  V I , let entity ( v I ) = v O denote the unknown output graph node, v
O  X  V O , which v I corresponds to (e.g., the person who owns a given email address). In this instance of the pipeline approach, we begin by applying an entity resolution model, ER model , to create a set of disjoint clusters, c  X  C , of input graph nodes such that a pair of input graph nodes, v 1 I ,v are in the same cluster if entity ( v 1 I ) = entity ( v different clusters if entity ( v 1 I ) 6 = entity ( v 2 ate a node in the output graph mapped from each cluster resulting in the full set of output graph nodes. Next, we consider all pairs of the newly created output graph nodes, v ,v k O  X  V O , and apply the LP model over these pairs. The LP model defines an indicator function such that: We create an output graph edge between all output graph nodes where LP model ( v j O ,v k O ) = 1. Finally, we apply the CC model over the output graph nodes, v O  X  X  O in order to predict the value of the label attribute, v O .A . Given a set of possible values, L , of the target attribute, A, the CC model defines a function, CC model ( v O ) = l where l  X  L . For all v O  X  X  O , we assign v O .A = CC model ( v O ).
 To further illustrate the inferences involved in this approach, we now present a specific instance of the approach over the motivating problem. In this instance, we assume a super-vised scenario where we have test and train pairs of input and output graphs, as well as the mapping between them. We also use three commonly used predictors and sets of fea-tures for the ER, LP, and CC models. For entity resolution, we use collective relational clustering (CRC) [1] which iter-atively creates subsets of references, each corresponding to Algorithm 1 Example Pipeline Graph Identification Output: G O 1: Apply ER model on G I (i.e., cluster nodes) 2: Create nodes V O  X  X  O mapped from the clusters 3: Apply LP model over possible edges between V O 4: Create edges E O  X  X  O for existing edges 5: Apply CC model on V O and E O (i.e., predict labels) 6: Set labels for all V O and E O to their predicted value a single entity, using a weighted combination of the similar-ity of local attributes and neighborhoods of the references. In CRC, for a given pair of nodes we use the normalized similarity between the node entity attributes of the input graph nodes for the feature similarity (e.g., similarity of the email address strings[6]) and the Jaccard-Coefficient sim-ilarity[1] of their neighborhoods (e.g., email address nodes adjacent to a given node with a communication edge) for the relational similarity. We vary the  X  parameter, controlling the weighting between the local and neighborhood similar-ities, and threshold parameter, the minimum similarity of two reference clusters predicted to refer to the same entity, in CRC based on the training graphs and the mapping be-tween them. For link prediction and collective classification, we use the aggregate values of input graph nodes mapped to each output graph node. We take the aggregate by setting the value of an attribute a for an output graph node with the mapping v o = { v 1 i ,v 2 i ,...,v j i } as: where mode takes the most common value of an attribute a among the mapped input graph nodes. In link predic-tion, we use these aggregates to create a feature which mea-sures the percent similarity of the aggregate values of a given output graph node pair. Specifically, given two out-put graph nodes and their mapped input graph node sub-sets, v 1 o = { v 11 i ,v 12 i ,...,v 1 j i } and v 2 o = { v compute: where A is the set of all attributes of the input graph nodes, | A | is the set size of A , and  X  ( x,y ) is an indicator func-tion which returns 1 if x = y and 0 otherwise. We use this similarity as a feature in logistic regression[20] model to predict whether or not an edge exists. Finally, for collective classification, we use the iterative classification algorithm (ICA)[11], using logistic regression for the bootstrap and re-lational classifiers. For a given output graph node, we use aggregates of the attributes over the mapped input graph nodes in the bootstrap classifier (i.e.,  X  a  X  A,v o .a ). For the relational classifier, we use these aggregates, as well as the percent of neighboring nodes (i.e., nodes adjacent to a given node with a friendship edge) which have a specific label. In order to study the pipeline approach of graph identifi-cation, we experiment to see the strengths and weaknesses this approach has for different types of networks. First, we developed a novel synthetic data generator which allows us to create an input and output graph modeled after the com-munication and social networks presented in section 2. In our generator, we can control the reference, link existence, and label ambiguity in the inference so that we can vary the ability of each predictor, ER, LP, and CC, respectively, to make an accurate inference. We generate networks with different ambiguity levels (Low, Med, High) for each type of ambiguity. We provide specific details of the synthetic data generator in section 5.1. We perform graph identification by applying Algorithm 1 and using the models and features described in section 4.1. We train predictors, for all com-binations of ambiguity (27 in total), on one graph and test on another graph to compute the F1 performance, averaged over six runs, for each predictor. We also explored the ef-fects of order, as discussed in section 4, by using a variant which exchanges the order we apply LP and CC (lines 4 and 5 in Algorithm 1). For both versions, we also explored the challenge of how to make use of both the input and output graphs by varying how the LP and CC were trained. We note that in this example, there are two ways to train LP and CC. The first is to train the models directly over the edges and labels of the training output graph. Another way to train LP and CC is to use the correspondence between the output and input graph to transfer equivalent edges and labels to the input graph. Specifically, an equivalent edge is created between two input graph nodes if the known corre-sponding output graph nodes also share an edge. Similarly, an input graph node is assigned a label if the known corre-sponding output graph node has that label. We then train the models over the modified training input graph. To evaluate the performance improvements of our optimiza-tions, we developed a novel synthetic data generator that creates a noisy network with ambiguous references which need to be merged to entities, missing labels which need to be classified, missing edges which need to be predicted, and the graph structure and attributes commonly used for those types of inferences. The graph and the attributes created by this synthetic data generator is modeled after the motivat-ing problem presented in the paper where the desired output graph is a social network where nodes are people, edges are close friendships between those people, and attributes rep-resent a trait of that person (e.g., role). Intuitively, the generator works by creating a synthetic output graph which mimics the structure and attributes of real world social net-works. The generator then creates communication network input graph from the social network output graph by adding different types of noise common to these types of network. The algorithm for the synthetic data generator is shown in Algorithm 2.
 The synthetic data generator begins by creating the struc-ture of the network (i.e., the set of nodes and edges of the output graph). A number of network generation models have been proposed which create networks which exhibit properties, observed in many real world networks. For our experiments, we implemented the widely used Forest Fire generation model [9] which models many of these properties including heavy tailed degree distribution,  X  X mall world X  phenomenon, and densification over time. We used a for-ward burn probability of 0 . 4 and a backward burn probability Algorithm 2 Synthetic Data Generator Output: Output Graph ( G O ), Input Graph ( G I ) 1: G temp  X  Generate network structure 2: Add node labels to G temp 3: Add node attributes based on node labels to G temp 4: Add node attributes based on neighboring nodes to 5: Add node entity attributes to G temp 6: G O  X  X  temp { Set clean graph as output graph } 7: G temp  X  Create ambiguous references for nodes in G temp 8: Remove node labels from G temp 9: Randomly change values of attributes from G temp 10: Randomly remove edges from G temp 11: Add random edges between some node pairs to G temp 12: G I  X  X  temp { Set noisy graph as input graph } of 0 . 2. This creates the output graph nodes (people nodes) and output graph edges (friendship edges).
 Once the initial network structure is generated, we add three sets of attributes to the nodes corresponding to the three types of inferences we will perform on the graph. The first set is for use with collective classification and includes the labels and attributes based on those labels. We use the la-bel generation method described in [14] (2 labels, with 1 / 10 of the graph initially labeled randomly) to create the  X  X ole X  label of the people nodes where  X  X ole X  has a high positive autocorrelation (i.e., people who are friends like have the same role). We then create binary attributes based on those labels using the method described in [3] (5 attributes per la-bel where secondary probability is set to 0 . 45 while the pri-mary probability is varied to control label ambiguity ). The second set of attributes is used for link prediction and con-sist of between 1 and 100 attributes (varied to control link existence ambiguity ) generated using the method described in [14]. These attributes were generated for link predic-tion with the intuition that nodes with similar attributes are likely to share an edge. The last set of attributes are used for entity resolution and represent attributes that imply, non-uniquely, the entity it refers to (e.g., first name references non-uniquely imply who the individuals are as multiple in-dividuals may have the same first name). To generate these attributes, we use the method described in [1] and vary p to control the reference ambiguity . The resulting network is our synthetic output graph (friendship network).
 We create an input graph from our output graph by creating a noisy version of the output graph. We add noise in four ways. First, we add ambiguous references (email addresses) to the input graph by adding a random number of nodes (be-tween 1 and 3) for a percentage of the nodes in the graph (25% of the original nodes). Each input graph node initially has the same attributes and labels as the corresponding node in the output graph and we also create edges similar to those of the output graph by ensuring all input graph nodes have an edge  X  X quivalent X  to the edges of the corresponding out-put graph nodes. Equivalent edges are created by adding at least one edge from an input graph node, corresponding to a node v j o of the output graph, to a input graph node, corre-sponding to an output graph node v k o , if v j o and v k edge. Once the reference nodes are generated, we add noise to the attributes of those nodes by removing the  X  X ole X  la-bels of all the nodes and randomly changing, as appropriate, the values of the other attributes. Finally, we add edge noise to the graph by randomly removing a percent of the exist-ing edges (20% of the current number of edges) and adding edges between randomly selected pairs of nodes in the graph (adding 50% more edges) where the resulting edges are our communication edges. The resulting noisy network is our synthetic input graph (communication network). We evaluate the performance of the ER, LP, and CC models using the average F1 performance of each predictor over the different networks. For entity resolution, we use the method of calculating F1 over ER predictions as described in [1] where we consider all possible pairs of input graph nodes and whether or not each pair is accurately mapped to the same or different output graph node. For link prediction and object classification, however, we cannot compute the F1 performance directly over the nodes of the predicted out-put graph because the set of output graph nodes will vary based on the entity resolution performance. We address this by evaluating link prediction and object classification over predictions mapped onto the input graph. A predicted edge is mapped between nodes in the input graph if the predicted output graph nodes of the two input graph nodes have a pre-dicted edge between them. Moreover, the predicted edge be-tween two nodes in the input graph is a true positive edge if an edge exists between the mapped true output graph nodes and a false positive edge otherwise. Similarly, the predicted label of a node in the input graph is the label of the node it is mapped to in the predicted output graph and the true label of that node is the label of the node it is mapped to in the true output graph.
 The results are presented in Table 1 and Table 2. For clarity, we only show results where we vary one type of ambiguity while holding the others at medium. First, in general, we see that good performance of predictors early in the pipeline result in improved performance of later predictors. In fact, the best performances are seen when the entity ambiguity is low resulting in ER performing well. Good ER performance results in a more accurate set of person nodes, and thus a more accurate set of mappings for use by the features of LP and CC. We see the same trend in CC performance when link existence ambiguity is low in Table 1. LP performance improves which results in more accurate links for the rela-tional features used in CC. Note though the improvement in LP performance does not affect ER and the improvement in CC performance does not affect LP and ER. This is a weakness in the pipeline approach in that the flow of infor-mation is only one way. Ideally, in graph identification, the models and features used by the predictors should be able to make use of predictions from all other predictors to improve its performance (e.g., use labels and predicted edges in the ER feature and relational similarity, use predicted labels in LP relational features). An obvious extension to address this weakness is an iterative pipeline approach where the pipeline is repeatedly applied over the network. We per-formed an initial study of the iterative pipeline approach but the results were inconclusive indicating a naive itera-tive approach may not be enough. This is a subject of fu-ture work. Next, we note that when predictors early in the pipeline perform poorly, the effect is reduced performance for all predictors later in the pipeline. In fact, the result-ing reduction in performance can be drastic as shown when we increase reference ambiguity. Although link existence and label ambiguity is held constant, poor performance by ER early in the pipeline results in substantial drop in LP and CC performance as both are forced to make predictions over people nodes whose mapped email address nodes inac-curately and incompletely reflect a person and that person node X  X  friendships and attributes. Thus, in graph identifica-tion, we need to be aware of what the expected performance of each predictor is and how each predictor will impact the other predictors in the overall inference.
 Comparing the results from the two ways of training our LP and CC models, shown in Table 1, we see a general trend where LP performs better when trained over the out-put graph. On the other hand, we see that CC generally performs better when trained over the input graph. The improvement in both cases demonstrates two things. First, the improvement shows the importance of understanding and exploiting information in both the input and output graphs in the inferences. Second, the differences over the two sets of results, where the output graph predicted over models trained over the output graph has better LP per-formance but worse CC performance than the alternative, demonstrate the complexity of the inference interactions, as well as the difficulty in comparing the quality of one pre-dicted output graph from another.
 In the comparison between approaches varying the order the inferences are performed, shown in Table 2, we see that or-der can substantially impact the overall performance. Both LP and CC performance declines when applying CC prior to LP. The decline is particularly noticeable for CC per-formance when the label ambiguity is high. When label ambiguity is high, the classifier used must rely on relational features more. However, given that the edges LP predicts, over which the nodes are homophilic, are not available the classifier is unable to accurately predict the label. This in turn affects the performance of LP which uses the predicted label in its predictions. Although the inter-dependence of these inference have the potential to positively affect their performance as a whole, the inverse is also true. In graph identification, the impact of a poorly performing predictor must be mitigated when combining the inferences. There have been a number of machine learning problems de-fined over network data[7]. In this work, we discussed how some of these problems (i.e., entity resolution, link predic-tion, and entity resolution) correspond to types of inferences involved in graph identification. We note however, that these problems only infer specific parts of a graph. They do not, individually, address all the inferences involved in inferring both the structure and attributes of a whole graph. There are previous work which infer more of the graph by combining many of these inferences. Many attempts per-form pairwise combinations of these inferences such as com-bining model link prediction and collective classification[4; 5; 19] or combining entity resolution and collective classifi-cation[2]. There have also been work on creating a general framework which allows for a general combination of these problems[16; 17; 8; 15; 18]. To our knowledge, none of the previous work have explored the benefits, issues, and chal-lenges in performing this combination to explicitly infer a full graph. In this paper, we introduce the notion of graph identifica-tion. We discuss the types of inferences involved in graph identification and explore those inferences using an illustra-tive example problem. We discuss the types of approaches applicable for graph identification and explored one approach which uses a combination of local predictors. We discuss the issues we must consider when using this approach and present a simple, general approach to applying these infer-ences in graph identification. We then experimentally eval-uate the general approach and show the importance of the inter-dependence of these inferences is in accurately predict-ing the output graph. In future work, we plan to further ex-plore these inter-dependencies by exploring alternate ways to combine local predictors and comparing those methods to a full joint approach to graph identification. We are also ex-ploring methods for comparing the quality of two predicted output graphs. and are in the process of collecting real world datasets we can evaluate our approaches over. We are grateful to Mustafa Bilgic for help with the synthetic data generator. The work was supported by NSF Grant No. 0746930. [1] I. Bhattacharya and L. Getoor. Collective entity reso-[2] I. Bhattacharya, S. Godbole, and S. Joshi. Structured [3] M. Bilgic and L. Getoor. Effective label acquisition [4] M. Bilgic, G. M. Namata, and L. Getoor. Combining [5] Y. Choi, E. Breck, and C. Cardie. Joint extraction of [6] W. W. Cohen, P. Ravikumar, and S. E. Fienberg. [7] L. Getoor and C. P. Diehl. Link mining: a survey. [8] L. Getoor, N. Friedman, D. Koller, and B. Taskar. Ambiguity Level ER (F1) LP (F1) CC (F1) ER (F1) LP (F1) CC (F1) Ambiguity Level ER (F1) LP (F1) CC (F1) ER (F1) LP (F1) CC (F1) [9] J. Leskovec, J. Kleinberg, and C. Faloutsos. Graph evo-[10] D. Liben-Nowell and J. Kleinberg. The link predic-[11] Q. Lu and L. Getoor. Link-based classification. In Pro-[12] L. McDowell, K. M. Gupta, and D. W. Aha. Cautious [13] G. M. Namata, P. Sen, M. Bilgic, and L. Getoor. Col-[14] M. J. Rattigan, M. Maier, and D. Jensen. Exploiting [15] M. Richardson and P. Domingos. Markov logic net-[16] D. Roth, K. Small, and I. Titov. Sequential learning of [17] D. Roth and W. Yih. A linear programming formula-[18] B. Taskar, A. Pieter, and D. Koller. Discriminative [19] B. Taskar, M.-F. Wong, P. Abbeel, and D. Koller. Link [20] I. H. Witten and E. Frank. Data Mining: Practical Ma-
